{"home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.mpe_local.make_env.make_env": [[15, 45], ["print", "scenarios.load().Scenario", "scenarios.load().Scenario.make_world", "MultiAgentEnv", "MultiAgentEnv", "scenarios.load"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.make_world", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.load"], ["def", "make_env", "(", "scenario_name", ",", "benchmark", "=", "False", ")", ":", "\n", "    ", "'''\n    Creates a MultiAgentEnv object as env. This can be used similar to a gym\n    environment by calling env.reset() and env.step().\n    Use env.render() to view the environment on the screen.\n\n    Input:\n        scenario_name   :   name of the scenario from ./scenarios/ to be Returns\n                            (without the .py extension)\n        benchmark       :   whether you want to produce benchmarking data\n                            (usually only done during evaluation)\n\n    Some useful env properties (see environment.py):\n        .observation_space  :   Returns the observation space for each agent\n        .action_space       :   Returns the action space for each agent\n        .n                  :   Returns the number of Agents\n    '''", "\n", "from", "multiagent", ".", "environment", "import", "MultiAgentEnv", "\n", "import", "multiagent", ".", "scenarios", "as", "scenarios", "\n", "print", "(", "'shabi'", ")", "\n", "# load scenario from script", "\n", "scenario", "=", "scenarios", ".", "load", "(", "scenario_name", "+", "\".py\"", ")", ".", "Scenario", "(", ")", "\n", "# create world", "\n", "world", "=", "scenario", ".", "make_world", "(", ")", "\n", "# create multiagent environment", "\n", "if", "benchmark", ":", "\n", "        ", "env", "=", "MultiAgentEnv", "(", "world", ",", "scenario", ".", "reset_world", ",", "scenario", ".", "reward", ",", "scenario", ".", "observation", ",", "scenario", ".", "benchmark_data", ")", "\n", "", "else", ":", "\n", "        ", "env", "=", "MultiAgentEnv", "(", "world", ",", "scenario", ".", "reset_world", ",", "scenario", ".", "reward", ",", "scenario", ".", "observation", ",", "done_callback", "=", "scenario", ".", "done", ")", "\n", "", "return", "env", "\n", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment_neighbor.MultiAgentEnv.__init__": [[14, 63], ["len", "enumerate", "environment_neighbor.MultiAgentEnv._reset_render", "hasattr", "hasattr", "hasattr", "environment_neighbor.MultiAgentEnv.observation_space.append", "environment_neighbor.MultiAgentEnv.reset_callback", "len", "environment_neighbor.MultiAgentEnv.obs_dim_n.append", "environment_neighbor.MultiAgentEnv.observation_space.append", "environment_neighbor.MultiAgentEnv.action_space.append", "gym.spaces.MultiBinary", "environment_neighbor.MultiAgentEnv.action_space.append", "observation_callback", "gym.spaces.Box", "gym.spaces.Discrete", "gym.spaces.Discrete"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._reset_render"], ["def", "__init__", "(", "self", ",", "world", ",", "reset_callback", "=", "None", ",", "reward_callback", "=", "None", ",", "\n", "observation_callback", "=", "None", ",", "info_callback", "=", "None", ",", "\n", "done_callback", "=", "None", ",", "shared_viewer", "=", "True", ")", ":", "\n", "\n", "        ", "self", ".", "world", "=", "world", "\n", "self", ".", "agents", "=", "self", ".", "world", ".", "policy_agents", "\n", "# set required vectorized gym env property", "\n", "self", ".", "n", "=", "len", "(", "world", ".", "policy_agents", ")", "\n", "# scenario callbacks", "\n", "self", ".", "reset_callback", "=", "reset_callback", "\n", "self", ".", "reward_callback", "=", "reward_callback", "\n", "self", ".", "observation_callback", "=", "observation_callback", "\n", "self", ".", "info_callback", "=", "info_callback", "\n", "self", ".", "done_callback", "=", "done_callback", "\n", "# environment parameters", "\n", "self", ".", "discrete_action_space", "=", "True", "\n", "# if true, action is a number 0...N, otherwise action is a one-hot N-dimensional vector", "\n", "self", ".", "discrete_action_input", "=", "False", "\n", "# if true, even the action is continuous, action will be performed discretely", "\n", "self", ".", "force_discrete_action", "=", "world", ".", "discrete_action", "if", "hasattr", "(", "world", ",", "'discrete_action'", ")", "else", "False", "\n", "# if true, every agent has the same reward", "\n", "self", ".", "shared_reward", "=", "world", ".", "collaborative", "if", "hasattr", "(", "world", ",", "'collaborative'", ")", "else", "False", "\n", "self", ".", "time", "=", "0", "\n", "\n", "# configure spaces", "\n", "self", ".", "action_space", "=", "[", "]", "\n", "self", ".", "observation_space", "=", "[", "]", "\n", "self", ".", "obs_dim_n", "=", "[", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "self", ".", "agents", ")", ":", "\n", "            ", "if", "hasattr", "(", "world", ",", "'ising'", ")", ":", "\n", "                ", "if", "i", "<", "self", ".", "world", ".", "max_good_neighbor", ":", "\n", "                    ", "self", ".", "action_space", ".", "append", "(", "spaces", ".", "Discrete", "(", "self", ".", "world", ".", "dim_spin", ")", ")", "\n", "", "self", ".", "observation_space", ".", "append", "(", "spaces", ".", "MultiBinary", "(", "5", "*", "self", ".", "world", ".", "agent_view_sight", ")", ")", "\n", "#self.obs_dim_n.append(4)", "\n", "", "else", ":", "\n", "                ", "if", "i", "<", "self", ".", "world", ".", "max_good_neighbor", ":", "\n", "                    ", "self", ".", "action_space", ".", "append", "(", "spaces", ".", "Discrete", "(", "world", ".", "dim_p", "*", "2", "+", "1", ")", ")", "\n", "", "self", ".", "reset_callback", "(", "self", ".", "world", ",", "i", ")", "\n", "obs_dim", "=", "len", "(", "observation_callback", "(", "i", ",", "self", ".", "world", ")", ")", "\n", "self", ".", "obs_dim_n", ".", "append", "(", "obs_dim", ")", "\n", "self", ".", "observation_space", ".", "append", "(", "spaces", ".", "Box", "(", "low", "=", "-", "np", ".", "inf", ",", "high", "=", "+", "np", ".", "inf", ",", "shape", "=", "(", "obs_dim", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "\n", "# rendering", "\n", "", "", "self", ".", "shared_viewer", "=", "shared_viewer", "\n", "if", "self", ".", "shared_viewer", ":", "\n", "            ", "self", ".", "viewers", "=", "[", "None", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "viewers", "=", "[", "None", "]", "*", "self", ".", "n", "\n", "", "self", ".", "_reset_render", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment_neighbor.MultiAgentEnv.step": [[65, 97], ["environment_neighbor.MultiAgentEnv.world.step", "environment_neighbor.MultiAgentEnv._get_obs", "environment_neighbor.MultiAgentEnv._get_reward", "environment_neighbor.MultiAgentEnv._set_action", "hasattr", "enumerate", "list", "range", "numpy.sqrt", "environment_neighbor.MultiAgentEnv._get_obs", "numpy.sum", "environment_neighbor.MultiAgentEnv._get_obs", "neighbors.append", "numpy.where", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.step", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._get_obs", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._get_reward", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._set_action", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._get_obs", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._get_obs"], ["", "def", "step", "(", "self", ",", "action_n", ")", ":", "\n", "#obs_n = [[]] *self.n", "\n", "# action_n is the full set of all agents", "\n", "        ", "agent", "=", "self", ".", "world", ".", "agents", "[", "self", ".", "agent_id", "]", "\n", "\n", "for", "i", "in", "self", ".", "action_agents", ":", "\n", "            ", "self", ".", "_set_action", "(", "action_n", "[", "i", "]", ",", "self", ".", "agents", "[", "i", "]", ")", "\n", "\n", "", "self", ".", "world", ".", "step", "(", "self", ".", "action_agents", ")", "\n", "\n", "# obs_n = [[np.zeros((self.obs_dim_n[i]))] for i in range(self.n)]", "\n", "obs_n", "=", "[", "[", "]", "for", "i", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "obs_n", "[", "self", ".", "agent_id", "]", "=", "self", ".", "_get_obs", "(", "self", ".", "agent_id", ")", "\n", "neighbors", "=", "[", "]", "\n", "if", "not", "hasattr", "(", "self", ".", "world", ",", "'ising'", ")", ":", "\n", "\n", "            ", "for", "i", ",", "other", "in", "enumerate", "(", "self", ".", "world", ".", "agents", ")", ":", "\n", "                ", "if", "other", "is", "agent", ":", "continue", "\n", "distance", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", ")", ")", "\n", "if", "distance", "<", "self", ".", "world", ".", "good_neigh_dist", ":", "\n", "                    ", "obs_n", "[", "i", "]", "=", "self", ".", "_get_obs", "(", "i", ")", "\n", "neighbors", ".", "append", "(", "i", ")", "\n", "", "", "agent", ".", "neighbors", "=", "neighbors", "\n", "\n", "", "else", ":", "\n", "            ", "self_agent_neg", "=", "list", "(", "np", ".", "where", "(", "self", ".", "world", ".", "agents", "[", "self", ".", "agent_id", "]", ".", "spin_mask", "==", "1", ")", "[", "0", "]", ")", "\n", "for", "other", "in", "self_agent_neg", ":", "\n", "                ", "obs_n", "[", "other", "]", "=", "self", ".", "_get_obs", "(", "other", ")", "\n", "\n", "", "", "reward", "=", "self", ".", "_get_reward", "(", "self", ".", "agent_id", ")", "\n", "\n", "return", "obs_n", ",", "reward", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment_neighbor.MultiAgentEnv.reset": [[99, 110], ["environment_neighbor.MultiAgentEnv.reset_callback", "environment_neighbor.MultiAgentEnv._reset_render", "environment_neighbor.MultiAgentEnv._get_obs", "range"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._reset_render", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._get_obs"], ["", "def", "reset", "(", "self", ",", "agent_id", ",", "step", "=", "0", ")", ":", "\n", "# Set the central agent", "\n", "        ", "self", ".", "agent_id", "=", "agent_id", "\n", "# reset world", "\n", "self", ".", "action_agents", ",", "self", ".", "neighbor", "=", "self", ".", "reset_callback", "(", "self", ".", "world", ",", "agent_id", ",", "step", ")", "\n", "self", ".", "_reset_render", "(", ")", "\n", "obs_n", "=", "[", "[", "]", "for", "i", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "for", "i", "in", "self", ".", "action_agents", ":", "\n", "            ", "obs_n", "[", "i", "]", "=", "self", ".", "_get_obs", "(", "i", ")", "\n", "\n", "", "return", "obs_n", ",", "self", ".", "neighbor", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment_neighbor.MultiAgentEnv._get_info": [[113, 122], ["enumerate", "numpy.sqrt", "numpy.sum", "neighbors.append", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "_get_info", "(", "self", ",", "i", ",", "agent", ")", ":", "\n", "        ", "neighbors", "=", "[", "]", "\n", "for", "j", ",", "other", "in", "enumerate", "(", "self", ".", "world", ".", "policy_agents", ")", ":", "\n", "            ", "if", "other", "==", "agent", ":", "continue", "\n", "dist_ij", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", ")", ")", "\n", "if", "(", "dist_ij", "<=", "self", ".", "world", ".", "neigh_dist", ")", ":", "\n", "                ", "neighbors", ".", "append", "(", "j", ")", "\n", "\n", "", "", "return", "neighbors", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment_neighbor.MultiAgentEnv._get_obs": [[124, 128], ["environment_neighbor.MultiAgentEnv.observation_callback", "numpy.zeros"], "methods", ["None"], ["", "def", "_get_obs", "(", "self", ",", "i", ")", ":", "\n", "        ", "if", "self", ".", "observation_callback", "is", "None", ":", "\n", "            ", "return", "np", ".", "zeros", "(", "0", ")", "\n", "", "return", "self", ".", "observation_callback", "(", "i", ",", "self", ".", "world", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment_neighbor.MultiAgentEnv._get_done": [[131, 135], ["environment_neighbor.MultiAgentEnv.done_callback"], "methods", ["None"], ["", "def", "_get_done", "(", "self", ",", "agent", ")", ":", "\n", "        ", "if", "self", ".", "done_callback", "is", "None", ":", "\n", "            ", "return", "False", "\n", "", "return", "self", ".", "done_callback", "(", "agent", ",", "self", ".", "world", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment_neighbor.MultiAgentEnv._get_reward": [[137, 141], ["environment_neighbor.MultiAgentEnv.reward_callback"], "methods", ["None"], ["", "def", "_get_reward", "(", "self", ",", "i", ")", ":", "\n", "        ", "if", "self", ".", "reward_callback", "is", "None", ":", "\n", "            ", "return", "0.0", "\n", "", "return", "self", ".", "reward_callback", "(", "i", ",", "self", ".", "world", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment_neighbor.MultiAgentEnv._set_action": [[143, 157], ["numpy.zeros", "numpy.zeros"], "methods", ["None"], ["", "def", "_set_action", "(", "self", ",", "action", ",", "agent", ")", ":", "\n", "        ", "if", "agent", ".", "movable", ":", "\n", "            ", "agent", ".", "action", ".", "u", "=", "np", ".", "zeros", "(", "self", ".", "world", ".", "dim_p", ")", "\n", "agent", ".", "action", ".", "c", "=", "np", ".", "zeros", "(", "self", ".", "world", ".", "dim_c", ")", "\n", "# physical action", "\n", "agent", ".", "action", ".", "u", "[", "0", "]", "+=", "action", "[", "1", "]", "-", "action", "[", "2", "]", "\n", "agent", ".", "action", ".", "u", "[", "1", "]", "+=", "action", "[", "3", "]", "-", "action", "[", "4", "]", "\n", "sensitivity", "=", "5.0", "\n", "if", "agent", ".", "accel", "is", "not", "None", ":", "\n", "                ", "sensitivity", "=", "agent", ".", "accel", "\n", "", "agent", ".", "action", ".", "u", "*=", "sensitivity", "\n", "\n", "", "else", ":", "\n", "            ", "agent", ".", "action", ".", "a", "=", "0", "if", "action", "[", "0", "]", "<=", "0.5", "else", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment_neighbor.MultiAgentEnv._reset_render": [[159, 162], ["None"], "methods", ["None"], ["", "", "def", "_reset_render", "(", "self", ")", ":", "\n", "        ", "self", ".", "render_geoms", "=", "None", "\n", "self", ".", "render_geoms_xform", "=", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core.EntityState.__init__": [[5, 10], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "# physical position", "\n", "        ", "self", ".", "p_pos", "=", "None", "\n", "# physical velocity", "\n", "self", ".", "p_vel", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core.AgentState.__init__": [[13, 17], ["core.EntityState.__init__"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "AgentState", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# communication utterance", "\n", "self", ".", "c", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core.Action.__init__": [[20, 25], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "# physical action", "\n", "        ", "self", ".", "u", "=", "None", "\n", "# communication action", "\n", "self", ".", "c", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core.Entity.__init__": [[28, 48], ["core.EntityState"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "# name", "\n", "        ", "self", ".", "name", "=", "''", "\n", "# properties:", "\n", "self", ".", "size", "=", "0.050", "\n", "# entity can move / be pushed", "\n", "self", ".", "movable", "=", "False", "\n", "# entity collides with others", "\n", "self", ".", "collide", "=", "True", "\n", "# material density (affects mass)", "\n", "self", ".", "density", "=", "25.0", "\n", "# color", "\n", "self", ".", "color", "=", "None", "\n", "# max speed and accel", "\n", "self", ".", "max_speed", "=", "None", "\n", "self", ".", "accel", "=", "None", "\n", "# state", "\n", "self", ".", "state", "=", "EntityState", "(", ")", "\n", "# mass", "\n", "self", ".", "initial_mass", "=", "1.0", "\n", "# self.live = 1", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core.Entity.mass": [[50, 53], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "mass", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "initial_mass", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core.Landmark.__init__": [[56, 58], ["core.Entity.__init__"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__"], ["     ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Landmark", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core.Agent.__init__": [[61, 82], ["core.Entity.__init__", "core.AgentState", "core.Action"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Agent", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# agents are movable by default", "\n", "self", ".", "movable", "=", "True", "\n", "# cannot send communication signals", "\n", "self", ".", "silent", "=", "False", "\n", "# cannot observe the world", "\n", "self", ".", "blind", "=", "False", "\n", "# physical motor noise amount", "\n", "self", ".", "u_noise", "=", "None", "\n", "# communication noise amount", "\n", "self", ".", "c_noise", "=", "None", "\n", "# control range", "\n", "self", ".", "u_range", "=", "1.0", "\n", "# state", "\n", "self", ".", "state", "=", "AgentState", "(", ")", "\n", "# action", "\n", "self", ".", "action", "=", "Action", "(", ")", "\n", "# script behavior to execute", "\n", "self", ".", "action_callback", "=", "None", "\n", "self", ".", "eaten", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core.World.__init__": [[85, 103], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "# list of agents and entities (can change at execution-time!)", "\n", "        ", "self", ".", "agents", "=", "[", "]", "\n", "self", ".", "landmarks", "=", "[", "]", "\n", "# communication channel dimensionality", "\n", "self", ".", "dim_c", "=", "0", "\n", "# position dimensionality", "\n", "self", ".", "dim_p", "=", "2", "\n", "# color dimensionality", "\n", "self", ".", "dim_color", "=", "3", "\n", "# simulation timestep", "\n", "self", ".", "dt", "=", "0.1", "\n", "# physical damping", "\n", "self", ".", "damping", "=", "0.25", "\n", "# contact response parameters", "\n", "self", ".", "contact_force", "=", "1e+2", "\n", "self", ".", "contact_margin", "=", "1e-3", "\n", "self", ".", "size", "=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core.World.entities": [[105, 108], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "entities", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "agents", "+", "self", ".", "landmarks", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core.World.policy_agents": [[110, 113], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "policy_agents", "(", "self", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "self", ".", "agents", "if", "agent", ".", "action_callback", "is", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core.World.scripted_agents": [[115, 118], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "scripted_agents", "(", "self", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "self", ".", "agents", "if", "agent", ".", "action_callback", "is", "not", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core.World.step": [[120, 135], ["core.World.apply_action_force", "core.World.apply_environment_force", "core.World.integrate_state", "agent.action_callback", "len", "core.World.update_agent_state"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.World.apply_action_force", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.World.apply_environment_force", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.World.integrate_state", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising_neighbor.IsingWorld.update_agent_state"], ["", "def", "step", "(", "self", ")", ":", "\n", "# set actions for scripted agents", "\n", "        ", "for", "agent", "in", "self", ".", "scripted_agents", ":", "\n", "            ", "agent", ".", "action", "=", "agent", ".", "action_callback", "(", "agent", ",", "self", ")", "\n", "# gather forces applied to entities", "\n", "", "p_force", "=", "[", "None", "]", "*", "len", "(", "self", ".", "entities", ")", "\n", "# apply agent physical controls", "\n", "p_force", "=", "self", ".", "apply_action_force", "(", "p_force", ")", "\n", "# apply environment forces", "\n", "p_force", "=", "self", ".", "apply_environment_force", "(", "p_force", ")", "\n", "# integrate physical state", "\n", "self", ".", "integrate_state", "(", "p_force", ")", "\n", "# update agent state", "\n", "for", "agent", "in", "self", ".", "agents", ":", "\n", "            ", "self", ".", "update_agent_state", "(", "agent", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core.World.apply_action_force": [[137, 144], ["enumerate", "numpy.random.randn"], "methods", ["None"], ["", "", "def", "apply_action_force", "(", "self", ",", "p_force", ")", ":", "\n", "# set applied forces", "\n", "        ", "for", "i", ",", "agent", "in", "enumerate", "(", "self", ".", "agents", ")", ":", "\n", "            ", "if", "agent", ".", "movable", ":", "\n", "                ", "noise", "=", "np", ".", "random", ".", "randn", "(", "*", "agent", ".", "action", ".", "u", ".", "shape", ")", "*", "agent", ".", "u_noise", "if", "agent", ".", "u_noise", "else", "0.0", "\n", "p_force", "[", "i", "]", "=", "agent", ".", "action", ".", "u", "+", "noise", "\n", "", "", "return", "p_force", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core.World.apply_environment_force": [[146, 159], ["enumerate", "enumerate", "core.World.get_collision_force"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.World.get_collision_force"], ["", "def", "apply_environment_force", "(", "self", ",", "p_force", ")", ":", "\n", "# simple (but inefficient) collision response", "\n", "        ", "for", "a", ",", "entity_a", "in", "enumerate", "(", "self", ".", "entities", ")", ":", "\n", "            ", "for", "b", ",", "entity_b", "in", "enumerate", "(", "self", ".", "entities", ")", ":", "\n", "                ", "if", "(", "b", "<=", "a", ")", ":", "continue", "\n", "[", "f_a", ",", "f_b", "]", "=", "self", ".", "get_collision_force", "(", "entity_a", ",", "entity_b", ")", "\n", "if", "(", "f_a", "is", "not", "None", ")", ":", "\n", "                    ", "if", "(", "p_force", "[", "a", "]", "is", "None", ")", ":", "p_force", "[", "a", "]", "=", "0.0", "\n", "p_force", "[", "a", "]", "=", "f_a", "+", "p_force", "[", "a", "]", "\n", "", "if", "(", "f_b", "is", "not", "None", ")", ":", "\n", "                    ", "if", "(", "p_force", "[", "b", "]", "is", "None", ")", ":", "p_force", "[", "b", "]", "=", "0.0", "\n", "p_force", "[", "b", "]", "=", "f_b", "+", "p_force", "[", "b", "]", "\n", "", "", "", "return", "p_force", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core.World.integrate_state": [[161, 183], ["enumerate", "numpy.sqrt", "numpy.square", "numpy.square", "numpy.sqrt", "numpy.square", "numpy.square"], "methods", ["None"], ["", "def", "integrate_state", "(", "self", ",", "p_force", ")", ":", "\n", "        ", "for", "i", ",", "entity", "in", "enumerate", "(", "self", ".", "entities", ")", ":", "\n", "            ", "if", "not", "entity", ".", "movable", ":", "continue", "\n", "entity", ".", "state", ".", "p_vel", "=", "entity", ".", "state", ".", "p_vel", "*", "(", "1", "-", "self", ".", "damping", ")", "\n", "if", "(", "p_force", "[", "i", "]", "is", "not", "None", ")", ":", "\n", "                ", "entity", ".", "state", ".", "p_vel", "+=", "(", "p_force", "[", "i", "]", "/", "entity", ".", "mass", ")", "*", "self", ".", "dt", "\n", "", "if", "entity", ".", "max_speed", "is", "not", "None", ":", "\n", "                ", "speed", "=", "np", ".", "sqrt", "(", "np", ".", "square", "(", "entity", ".", "state", ".", "p_vel", "[", "0", "]", ")", "+", "np", ".", "square", "(", "entity", ".", "state", ".", "p_vel", "[", "1", "]", ")", ")", "\n", "if", "speed", ">", "entity", ".", "max_speed", ":", "\n", "                    ", "entity", ".", "state", ".", "p_vel", "=", "entity", ".", "state", ".", "p_vel", "/", "np", ".", "sqrt", "(", "np", ".", "square", "(", "entity", ".", "state", ".", "p_vel", "[", "0", "]", ")", "+", "\n", "np", ".", "square", "(", "entity", ".", "state", ".", "p_vel", "[", "1", "]", ")", ")", "*", "entity", ".", "max_speed", "\n", "# location change only when entity is alive", "\n", "", "", "if", "entity", ".", "live", ":", "\n", "                ", "entity", ".", "state", ".", "p_pos", "+=", "entity", ".", "state", ".", "p_vel", "*", "self", ".", "dt", "\n", "if", "entity", ".", "state", ".", "p_pos", "[", "0", "]", ">", "self", ".", "size", ":", "\n", "                    ", "entity", ".", "state", ".", "p_pos", "[", "0", "]", "=", "self", ".", "size", "\n", "", "if", "entity", ".", "state", ".", "p_pos", "[", "1", "]", ">", "self", ".", "size", ":", "\n", "                    ", "entity", ".", "state", ".", "p_pos", "[", "1", "]", "=", "self", ".", "size", "\n", "", "if", "entity", ".", "state", ".", "p_pos", "[", "0", "]", "<", "-", "self", ".", "size", ":", "\n", "                    ", "entity", ".", "state", ".", "p_pos", "[", "0", "]", "=", "-", "self", ".", "size", "\n", "", "if", "entity", ".", "state", ".", "p_pos", "[", "1", "]", "<", "-", "self", ".", "size", ":", "\n", "                    ", "entity", ".", "state", ".", "p_pos", "[", "1", "]", "=", "-", "self", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core.World.update_agent_state": [[186, 193], ["numpy.zeros", "numpy.random.randn"], "methods", ["None"], ["", "", "", "", "def", "update_agent_state", "(", "self", ",", "agent", ")", ":", "\n", "# set communication state (directly for now)", "\n", "        ", "if", "agent", ".", "silent", ":", "\n", "            ", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "self", ".", "dim_c", ")", "\n", "", "else", ":", "\n", "            ", "noise", "=", "np", ".", "random", ".", "randn", "(", "*", "agent", ".", "action", ".", "c", ".", "shape", ")", "*", "agent", ".", "c_noise", "if", "agent", ".", "c_noise", "else", "0.0", "\n", "agent", ".", "state", ".", "c", "=", "agent", ".", "action", ".", "c", "+", "noise", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core.World.get_collision_force": [[195, 217], ["numpy.sqrt", "numpy.isnan", "numpy.sum", "numpy.logaddexp", "time.sleep", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "", "def", "get_collision_force", "(", "self", ",", "entity_a", ",", "entity_b", ")", ":", "\n", "        ", "if", "(", "not", "entity_a", ".", "collide", ")", "or", "(", "not", "entity_b", ".", "collide", ")", ":", "\n", "            ", "return", "[", "None", ",", "None", "]", "# not a collider", "\n", "", "if", "(", "entity_a", "is", "entity_b", ")", ":", "\n", "            ", "return", "[", "None", ",", "None", "]", "# don't collide against itself", "\n", "# compute actual distance between entities", "\n", "", "delta_pos", "=", "entity_a", ".", "state", ".", "p_pos", "-", "entity_b", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "if", "dist", "==", "0", ":", "\n", "            ", "dist", "=", "1e-5", "\n", "# minimum allowable distance", "\n", "", "dist_min", "=", "entity_a", ".", "size", "+", "entity_b", ".", "size", "\n", "# softmax penetration", "\n", "k", "=", "self", ".", "contact_margin", "\n", "penetration", "=", "np", ".", "logaddexp", "(", "0", ",", "-", "(", "dist", "-", "dist_min", ")", "/", "k", ")", "*", "k", "\n", "if", "np", ".", "isnan", "(", "penetration", ")", ":", "\n", "            ", "time", ".", "sleep", "(", "2000", ")", "\n", "", "force", "=", "self", ".", "contact_force", "*", "delta_pos", "/", "dist", "*", "penetration", "\n", "force", "=", "0", "\n", "force_a", "=", "+", "force", "if", "entity_a", ".", "movable", "else", "None", "\n", "force_b", "=", "-", "force", "if", "entity_b", ".", "movable", "else", "None", "\n", "return", "[", "force_a", ",", "force_b", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Viewer.__init__": [[48, 67], ["rendering.get_display", "pyglet.window.Window", "rendering.Transform", "glEnable", "glEnable", "glHint", "glLineWidth", "glBlendFunc"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.get_display"], ["    ", "def", "__init__", "(", "self", ",", "width", ",", "height", ",", "display", "=", "None", ")", ":", "\n", "        ", "display", "=", "get_display", "(", "display", ")", "\n", "\n", "self", ".", "width", "=", "width", "\n", "self", ".", "height", "=", "height", "\n", "\n", "self", ".", "window", "=", "pyglet", ".", "window", ".", "Window", "(", "width", "=", "width", ",", "height", "=", "height", ",", "display", "=", "display", ")", "\n", "self", ".", "window", ".", "on_close", "=", "self", ".", "window_closed_by_user", "\n", "self", ".", "geoms", "=", "[", "]", "\n", "self", ".", "onetime_geoms", "=", "[", "]", "\n", "self", ".", "transform", "=", "Transform", "(", ")", "\n", "\n", "glEnable", "(", "GL_BLEND", ")", "\n", "# glEnable(GL_MULTISAMPLE)", "\n", "glEnable", "(", "GL_LINE_SMOOTH", ")", "\n", "# glHint(GL_LINE_SMOOTH_HINT, GL_DONT_CARE)", "\n", "glHint", "(", "GL_LINE_SMOOTH_HINT", ",", "GL_NICEST", ")", "\n", "glLineWidth", "(", "2.0", ")", "\n", "glBlendFunc", "(", "GL_SRC_ALPHA", ",", "GL_ONE_MINUS_SRC_ALPHA", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Viewer.close": [[68, 70], ["rendering.Viewer.window.close"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.SimpleImageViewer.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "window", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Viewer.window_closed_by_user": [[71, 73], ["rendering.Viewer.close"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.SimpleImageViewer.close"], ["", "def", "window_closed_by_user", "(", "self", ")", ":", "\n", "        ", "self", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Viewer.set_bounds": [[74, 81], ["rendering.Transform"], "methods", ["None"], ["", "def", "set_bounds", "(", "self", ",", "left", ",", "right", ",", "bottom", ",", "top", ")", ":", "\n", "        ", "assert", "right", ">", "left", "and", "top", ">", "bottom", "\n", "scalex", "=", "self", ".", "width", "/", "(", "right", "-", "left", ")", "\n", "scaley", "=", "self", ".", "height", "/", "(", "top", "-", "bottom", ")", "\n", "self", ".", "transform", "=", "Transform", "(", "\n", "translation", "=", "(", "-", "left", "*", "scalex", ",", "-", "bottom", "*", "scaley", ")", ",", "\n", "scale", "=", "(", "scalex", ",", "scaley", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Viewer.add_geom": [[82, 84], ["rendering.Viewer.geoms.append"], "methods", ["None"], ["", "def", "add_geom", "(", "self", ",", "geom", ")", ":", "\n", "        ", "self", ".", "geoms", ".", "append", "(", "geom", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Viewer.add_onetime": [[85, 87], ["rendering.Viewer.onetime_geoms.append"], "methods", ["None"], ["", "def", "add_onetime", "(", "self", ",", "geom", ")", ":", "\n", "        ", "self", ".", "onetime_geoms", ".", "append", "(", "geom", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Viewer.render": [[88, 115], ["glClearColor", "rendering.Viewer.window.clear", "rendering.Viewer.window.switch_to", "rendering.Viewer.window.dispatch_events", "rendering.Viewer.transform.enable", "rendering.Viewer.transform.disable", "rendering.Viewer.window.flip", "geom.render", "geom.render", "pyglet.image.get_buffer_manager().get_color_buffer", "pyglet.image.get_buffer_manager().get_color_buffer.get_image_data", "numpy.fromstring", "arr.reshape.reshape.reshape", "pyglet.image.get_buffer_manager"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.clear", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.LineWidth.enable", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.LineStyle.disable", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.render", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.render"], ["", "def", "render", "(", "self", ",", "return_rgb_array", "=", "False", ")", ":", "\n", "        ", "glClearColor", "(", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "self", ".", "window", ".", "clear", "(", ")", "\n", "self", ".", "window", ".", "switch_to", "(", ")", "\n", "self", ".", "window", ".", "dispatch_events", "(", ")", "\n", "self", ".", "transform", ".", "enable", "(", ")", "\n", "for", "geom", "in", "self", ".", "geoms", ":", "\n", "            ", "geom", ".", "render", "(", ")", "\n", "", "for", "geom", "in", "self", ".", "onetime_geoms", ":", "\n", "            ", "geom", ".", "render", "(", ")", "\n", "", "self", ".", "transform", ".", "disable", "(", ")", "\n", "arr", "=", "None", "\n", "if", "return_rgb_array", ":", "\n", "            ", "buffer", "=", "pyglet", ".", "image", ".", "get_buffer_manager", "(", ")", ".", "get_color_buffer", "(", ")", "\n", "image_data", "=", "buffer", ".", "get_image_data", "(", ")", "\n", "arr", "=", "np", ".", "fromstring", "(", "image_data", ".", "data", ",", "dtype", "=", "np", ".", "uint8", ",", "sep", "=", "''", ")", "\n", "# In https://github.com/openai/gym-http-api/issues/2, we", "\n", "# discovered that someone using Xmonad on Arch was having", "\n", "# a window of size 598 x 398, though a 600 x 400 window", "\n", "# was requested. (Guess Xmonad was preserving a pixel for", "\n", "# the boundary.) So we use the buffer height/width rather", "\n", "# than the requested one.", "\n", "arr", "=", "arr", ".", "reshape", "(", "buffer", ".", "height", ",", "buffer", ".", "width", ",", "4", ")", "\n", "arr", "=", "arr", "[", ":", ":", "-", "1", ",", ":", ",", "0", ":", "3", "]", "\n", "", "self", ".", "window", ".", "flip", "(", ")", "\n", "self", ".", "onetime_geoms", "=", "[", "]", "\n", "return", "arr", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Viewer.draw_circle": [[117, 122], ["rendering.make_circle", "rendering._add_attrs", "rendering.Viewer.add_onetime"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.make_circle", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering._add_attrs", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Viewer.add_onetime"], ["", "def", "draw_circle", "(", "self", ",", "radius", "=", "10", ",", "res", "=", "30", ",", "filled", "=", "True", ",", "**", "attrs", ")", ":", "\n", "        ", "geom", "=", "make_circle", "(", "radius", "=", "radius", ",", "res", "=", "res", ",", "filled", "=", "filled", ")", "\n", "_add_attrs", "(", "geom", ",", "attrs", ")", "\n", "self", ".", "add_onetime", "(", "geom", ")", "\n", "return", "geom", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Viewer.draw_polygon": [[123, 128], ["rendering.make_polygon", "rendering._add_attrs", "rendering.Viewer.add_onetime"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.make_polygon", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering._add_attrs", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Viewer.add_onetime"], ["", "def", "draw_polygon", "(", "self", ",", "v", ",", "filled", "=", "True", ",", "**", "attrs", ")", ":", "\n", "        ", "geom", "=", "make_polygon", "(", "v", "=", "v", ",", "filled", "=", "filled", ")", "\n", "_add_attrs", "(", "geom", ",", "attrs", ")", "\n", "self", ".", "add_onetime", "(", "geom", ")", "\n", "return", "geom", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Viewer.draw_polyline": [[129, 134], ["rendering.make_polyline", "rendering._add_attrs", "rendering.Viewer.add_onetime"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.make_polyline", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering._add_attrs", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Viewer.add_onetime"], ["", "def", "draw_polyline", "(", "self", ",", "v", ",", "**", "attrs", ")", ":", "\n", "        ", "geom", "=", "make_polyline", "(", "v", "=", "v", ")", "\n", "_add_attrs", "(", "geom", ",", "attrs", ")", "\n", "self", ".", "add_onetime", "(", "geom", ")", "\n", "return", "geom", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Viewer.draw_line": [[135, 140], ["rendering.Line", "rendering._add_attrs", "rendering.Viewer.add_onetime"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering._add_attrs", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Viewer.add_onetime"], ["", "def", "draw_line", "(", "self", ",", "start", ",", "end", ",", "**", "attrs", ")", ":", "\n", "        ", "geom", "=", "Line", "(", "start", ",", "end", ")", "\n", "_add_attrs", "(", "geom", ",", "attrs", ")", "\n", "self", ".", "add_onetime", "(", "geom", ")", "\n", "return", "geom", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Viewer.get_array": [[141, 148], ["rendering.Viewer.window.flip", "pyglet.image.get_buffer_manager().get_color_buffer().get_image_data", "rendering.Viewer.window.flip", "numpy.fromstring", "arr.reshape.reshape.reshape", "pyglet.image.get_buffer_manager().get_color_buffer", "pyglet.image.get_buffer_manager"], "methods", ["None"], ["", "def", "get_array", "(", "self", ")", ":", "\n", "        ", "self", ".", "window", ".", "flip", "(", ")", "\n", "image_data", "=", "pyglet", ".", "image", ".", "get_buffer_manager", "(", ")", ".", "get_color_buffer", "(", ")", ".", "get_image_data", "(", ")", "\n", "self", ".", "window", ".", "flip", "(", ")", "\n", "arr", "=", "np", ".", "fromstring", "(", "image_data", ".", "data", ",", "dtype", "=", "np", ".", "uint8", ",", "sep", "=", "''", ")", "\n", "arr", "=", "arr", ".", "reshape", "(", "self", ".", "height", ",", "self", ".", "width", ",", "4", ")", "\n", "return", "arr", "[", ":", ":", "-", "1", ",", ":", ",", "0", ":", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Geom.__init__": [[156, 159], ["rendering.Color"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_color", "=", "Color", "(", "(", "0", ",", "0", ",", "0", ",", "1.0", ")", ")", "\n", "self", ".", "attrs", "=", "[", "self", ".", "_color", "]", "\n", "", "def", "render", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Geom.render": [[159, 165], ["reversed", "rendering.Geom.render1", "attr.enable", "attr.disable"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Image.render1", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.LineWidth.enable", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.LineStyle.disable"], ["", "def", "render", "(", "self", ")", ":", "\n", "        ", "for", "attr", "in", "reversed", "(", "self", ".", "attrs", ")", ":", "\n", "            ", "attr", ".", "enable", "(", ")", "\n", "", "self", ".", "render1", "(", ")", "\n", "for", "attr", "in", "self", ".", "attrs", ":", "\n", "            ", "attr", ".", "disable", "(", ")", "\n", "", "", "def", "render1", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Geom.render1": [[165, 167], ["None"], "methods", ["None"], ["", "", "def", "render1", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "add_attr", "(", "self", ",", "attr", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Geom.add_attr": [[167, 169], ["rendering.Geom.attrs.append"], "methods", ["None"], ["", "def", "add_attr", "(", "self", ",", "attr", ")", ":", "\n", "        ", "self", ".", "attrs", ".", "append", "(", "attr", ")", "\n", "", "def", "set_color", "(", "self", ",", "r", ",", "g", ",", "b", ",", "alpha", "=", "1", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Geom.set_color": [[169, 171], ["None"], "methods", ["None"], ["", "def", "set_color", "(", "self", ",", "r", ",", "g", ",", "b", ",", "alpha", "=", "1", ")", ":", "\n", "        ", "self", ".", "_color", ".", "vec4", "=", "(", "r", ",", "g", ",", "b", ",", "alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Attr.enable": [[173, 175], ["None"], "methods", ["None"], ["    ", "def", "enable", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "disable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Attr.disable": [[175, 177], ["None"], "methods", ["None"], ["", "def", "disable", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Transform.__init__": [[179, 183], ["rendering.Transform.set_translation", "rendering.Transform.set_rotation", "rendering.Transform.set_scale"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Transform.set_translation", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Transform.set_rotation", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Transform.set_scale"], ["    ", "def", "__init__", "(", "self", ",", "translation", "=", "(", "0.0", ",", "0.0", ")", ",", "rotation", "=", "0.0", ",", "scale", "=", "(", "1", ",", "1", ")", ")", ":", "\n", "        ", "self", ".", "set_translation", "(", "*", "translation", ")", "\n", "self", ".", "set_rotation", "(", "rotation", ")", "\n", "self", ".", "set_scale", "(", "*", "scale", ")", "\n", "", "def", "enable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Transform.enable": [[183, 188], ["glPushMatrix", "glTranslatef", "glRotatef", "glScalef"], "methods", ["None"], ["", "def", "enable", "(", "self", ")", ":", "\n", "        ", "glPushMatrix", "(", ")", "\n", "glTranslatef", "(", "self", ".", "translation", "[", "0", "]", ",", "self", ".", "translation", "[", "1", "]", ",", "0", ")", "# translate to GL loc ppint", "\n", "glRotatef", "(", "RAD2DEG", "*", "self", ".", "rotation", ",", "0", ",", "0", ",", "1.0", ")", "\n", "glScalef", "(", "self", ".", "scale", "[", "0", "]", ",", "self", ".", "scale", "[", "1", "]", ",", "1", ")", "\n", "", "def", "disable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Transform.disable": [[188, 190], ["glPopMatrix"], "methods", ["None"], ["", "def", "disable", "(", "self", ")", ":", "\n", "        ", "glPopMatrix", "(", ")", "\n", "", "def", "set_translation", "(", "self", ",", "newx", ",", "newy", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Transform.set_translation": [[190, 192], ["float", "float"], "methods", ["None"], ["", "def", "set_translation", "(", "self", ",", "newx", ",", "newy", ")", ":", "\n", "        ", "self", ".", "translation", "=", "(", "float", "(", "newx", ")", ",", "float", "(", "newy", ")", ")", "\n", "", "def", "set_rotation", "(", "self", ",", "new", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Transform.set_rotation": [[192, 194], ["float"], "methods", ["None"], ["", "def", "set_rotation", "(", "self", ",", "new", ")", ":", "\n", "        ", "self", ".", "rotation", "=", "float", "(", "new", ")", "\n", "", "def", "set_scale", "(", "self", ",", "newx", ",", "newy", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Transform.set_scale": [[194, 196], ["float", "float"], "methods", ["None"], ["", "def", "set_scale", "(", "self", ",", "newx", ",", "newy", ")", ":", "\n", "        ", "self", ".", "scale", "=", "(", "float", "(", "newx", ")", ",", "float", "(", "newy", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Color.__init__": [[198, 200], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "vec4", ")", ":", "\n", "        ", "self", ".", "vec4", "=", "vec4", "\n", "", "def", "enable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Color.enable": [[200, 202], ["glColor4f"], "methods", ["None"], ["", "def", "enable", "(", "self", ")", ":", "\n", "        ", "glColor4f", "(", "*", "self", ".", "vec4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.LineStyle.__init__": [[204, 206], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "style", ")", ":", "\n", "        ", "self", ".", "style", "=", "style", "\n", "", "def", "enable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.LineStyle.enable": [[206, 209], ["glEnable", "glLineStipple"], "methods", ["None"], ["", "def", "enable", "(", "self", ")", ":", "\n", "        ", "glEnable", "(", "GL_LINE_STIPPLE", ")", "\n", "glLineStipple", "(", "1", ",", "self", ".", "style", ")", "\n", "", "def", "disable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.LineStyle.disable": [[209, 211], ["glDisable"], "methods", ["None"], ["", "def", "disable", "(", "self", ")", ":", "\n", "        ", "glDisable", "(", "GL_LINE_STIPPLE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.LineWidth.__init__": [[213, 215], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "stroke", ")", ":", "\n", "        ", "self", ".", "stroke", "=", "stroke", "\n", "", "def", "enable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.LineWidth.enable": [[215, 217], ["glLineWidth"], "methods", ["None"], ["", "def", "enable", "(", "self", ")", ":", "\n", "        ", "glLineWidth", "(", "self", ".", "stroke", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Point.__init__": [[219, 221], ["rendering.Geom.__init__"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "Geom", ".", "__init__", "(", "self", ")", "\n", "", "def", "render1", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Point.render1": [[221, 225], ["glBegin", "glVertex3f", "glEnd"], "methods", ["None"], ["", "def", "render1", "(", "self", ")", ":", "\n", "        ", "glBegin", "(", "GL_POINTS", ")", "# draw point", "\n", "glVertex3f", "(", "0.0", ",", "0.0", ",", "0.0", ")", "\n", "glEnd", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.FilledPolygon.__init__": [[227, 230], ["rendering.Geom.__init__"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "v", ")", ":", "\n", "        ", "Geom", ".", "__init__", "(", "self", ")", "\n", "self", ".", "v", "=", "v", "\n", "", "def", "render1", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.FilledPolygon.render1": [[230, 244], ["glEnd", "glColor4f", "glBegin", "glEnd", "len", "glBegin", "glVertex3f", "glVertex3f", "len", "glBegin", "glBegin"], "methods", ["None"], ["", "def", "render1", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "v", ")", "==", "4", ":", "glBegin", "(", "GL_QUADS", ")", "\n", "elif", "len", "(", "self", ".", "v", ")", ">", "4", ":", "glBegin", "(", "GL_POLYGON", ")", "\n", "else", ":", "glBegin", "(", "GL_TRIANGLES", ")", "\n", "for", "p", "in", "self", ".", "v", ":", "\n", "            ", "glVertex3f", "(", "p", "[", "0", "]", ",", "p", "[", "1", "]", ",", "0", ")", "# draw each vertex", "\n", "", "glEnd", "(", ")", "\n", "\n", "color", "=", "(", "self", ".", "_color", ".", "vec4", "[", "0", "]", "*", "0.5", ",", "self", ".", "_color", ".", "vec4", "[", "1", "]", "*", "0.5", ",", "self", ".", "_color", ".", "vec4", "[", "2", "]", "*", "0.5", ",", "self", ".", "_color", ".", "vec4", "[", "3", "]", "*", "0.5", ")", "\n", "glColor4f", "(", "*", "color", ")", "\n", "glBegin", "(", "GL_LINE_LOOP", ")", "\n", "for", "p", "in", "self", ".", "v", ":", "\n", "            ", "glVertex3f", "(", "p", "[", "0", "]", ",", "p", "[", "1", "]", ",", "0", ")", "# draw each vertex", "\n", "", "glEnd", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Compound.__init__": [[272, 277], ["rendering.Geom.__init__", "isinstance"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "gs", ")", ":", "\n", "        ", "Geom", ".", "__init__", "(", "self", ")", "\n", "self", ".", "gs", "=", "gs", "\n", "for", "g", "in", "self", ".", "gs", ":", "\n", "            ", "g", ".", "attrs", "=", "[", "a", "for", "a", "in", "g", ".", "attrs", "if", "not", "isinstance", "(", "a", ",", "Color", ")", "]", "\n", "", "", "def", "render1", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Compound.render1": [[277, 280], ["g.render"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.render"], ["", "", "def", "render1", "(", "self", ")", ":", "\n", "        ", "for", "g", "in", "self", ".", "gs", ":", "\n", "            ", "g", ".", "render", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.PolyLine.__init__": [[282, 288], ["rendering.Geom.__init__", "rendering.LineWidth", "rendering.PolyLine.add_attr"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Geom.add_attr"], ["    ", "def", "__init__", "(", "self", ",", "v", ",", "close", ")", ":", "\n", "        ", "Geom", ".", "__init__", "(", "self", ")", "\n", "self", ".", "v", "=", "v", "\n", "self", ".", "close", "=", "close", "\n", "self", ".", "linewidth", "=", "LineWidth", "(", "1", ")", "\n", "self", ".", "add_attr", "(", "self", ".", "linewidth", ")", "\n", "", "def", "render1", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.PolyLine.render1": [[288, 293], ["glBegin", "glEnd", "glVertex3f"], "methods", ["None"], ["", "def", "render1", "(", "self", ")", ":", "\n", "        ", "glBegin", "(", "GL_LINE_LOOP", "if", "self", ".", "close", "else", "GL_LINE_STRIP", ")", "\n", "for", "p", "in", "self", ".", "v", ":", "\n", "            ", "glVertex3f", "(", "p", "[", "0", "]", ",", "p", "[", "1", "]", ",", "0", ")", "# draw each vertex", "\n", "", "glEnd", "(", ")", "\n", "", "def", "set_linewidth", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.PolyLine.set_linewidth": [[293, 295], ["None"], "methods", ["None"], ["", "def", "set_linewidth", "(", "self", ",", "x", ")", ":", "\n", "        ", "self", ".", "linewidth", ".", "stroke", "=", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Line.__init__": [[297, 303], ["rendering.Geom.__init__", "rendering.LineWidth", "rendering.Line.add_attr"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Geom.add_attr"], ["    ", "def", "__init__", "(", "self", ",", "start", "=", "(", "0.0", ",", "0.0", ")", ",", "end", "=", "(", "0.0", ",", "0.0", ")", ")", ":", "\n", "        ", "Geom", ".", "__init__", "(", "self", ")", "\n", "self", ".", "start", "=", "start", "\n", "self", ".", "end", "=", "end", "\n", "self", ".", "linewidth", "=", "LineWidth", "(", "1", ")", "\n", "self", ".", "add_attr", "(", "self", ".", "linewidth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Line.render1": [[304, 309], ["glBegin", "glVertex2f", "glVertex2f", "glEnd"], "methods", ["None"], ["", "def", "render1", "(", "self", ")", ":", "\n", "        ", "glBegin", "(", "GL_LINES", ")", "\n", "glVertex2f", "(", "*", "self", ".", "start", ")", "\n", "glVertex2f", "(", "*", "self", ".", "end", ")", "\n", "glEnd", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Image.__init__": [[311, 318], ["rendering.Geom.__init__", "pyglet.image.load"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.load"], ["    ", "def", "__init__", "(", "self", ",", "fname", ",", "width", ",", "height", ")", ":", "\n", "        ", "Geom", ".", "__init__", "(", "self", ")", "\n", "self", ".", "width", "=", "width", "\n", "self", ".", "height", "=", "height", "\n", "img", "=", "pyglet", ".", "image", ".", "load", "(", "fname", ")", "\n", "self", ".", "img", "=", "img", "\n", "self", ".", "flip", "=", "False", "\n", "", "def", "render1", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Image.render1": [[318, 320], ["rendering.Image.img.blit"], "methods", ["None"], ["", "def", "render1", "(", "self", ")", ":", "\n", "        ", "self", ".", "img", ".", "blit", "(", "-", "self", ".", "width", "/", "2", ",", "-", "self", ".", "height", "/", "2", ",", "width", "=", "self", ".", "width", ",", "height", "=", "self", ".", "height", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.SimpleImageViewer.__init__": [[324, 328], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "display", "=", "None", ")", ":", "\n", "        ", "self", ".", "window", "=", "None", "\n", "self", ".", "isopen", "=", "False", "\n", "self", ".", "display", "=", "display", "\n", "", "def", "imshow", "(", "self", ",", "arr", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.SimpleImageViewer.imshow": [[328, 342], ["pyglet.image.ImageData", "rendering.SimpleImageViewer.window.clear", "rendering.SimpleImageViewer.window.switch_to", "rendering.SimpleImageViewer.window.dispatch_events", "pyglet.image.ImageData.blit", "rendering.SimpleImageViewer.window.flip", "pyglet.window.Window", "arr.tobytes"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.clear"], ["", "def", "imshow", "(", "self", ",", "arr", ")", ":", "\n", "        ", "if", "self", ".", "window", "is", "None", ":", "\n", "            ", "height", ",", "width", ",", "channels", "=", "arr", ".", "shape", "\n", "self", ".", "window", "=", "pyglet", ".", "window", ".", "Window", "(", "width", "=", "width", ",", "height", "=", "height", ",", "display", "=", "self", ".", "display", ")", "\n", "self", ".", "width", "=", "width", "\n", "self", ".", "height", "=", "height", "\n", "self", ".", "isopen", "=", "True", "\n", "", "assert", "arr", ".", "shape", "==", "(", "self", ".", "height", ",", "self", ".", "width", ",", "3", ")", ",", "\"You passed in an image with the wrong number shape\"", "\n", "image", "=", "pyglet", ".", "image", ".", "ImageData", "(", "self", ".", "width", ",", "self", ".", "height", ",", "'RGB'", ",", "arr", ".", "tobytes", "(", ")", ",", "pitch", "=", "self", ".", "width", "*", "-", "3", ")", "\n", "self", ".", "window", ".", "clear", "(", ")", "\n", "self", ".", "window", ".", "switch_to", "(", ")", "\n", "self", ".", "window", ".", "dispatch_events", "(", ")", "\n", "image", ".", "blit", "(", "0", ",", "0", ")", "\n", "self", ".", "window", ".", "flip", "(", ")", "\n", "", "def", "close", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.SimpleImageViewer.close": [[342, 346], ["rendering.SimpleImageViewer.window.close"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.SimpleImageViewer.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "isopen", ":", "\n", "            ", "self", ".", "window", ".", "close", "(", ")", "\n", "self", ".", "isopen", "=", "False", "\n", "", "", "def", "__del__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.SimpleImageViewer.__del__": [[346, 348], ["rendering.SimpleImageViewer.close"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.SimpleImageViewer.close"], ["", "", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.get_display": [[34, 46], ["isinstance", "pyglet.canvas.Display", "gym.error.Error"], "function", ["None"], ["def", "get_display", "(", "spec", ")", ":", "\n", "    ", "\"\"\"Convert a display specification (such as :0) into an actual Display\n    object.\n\n    Pyglet only supports multiple Displays on Linux.\n    \"\"\"", "\n", "if", "spec", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "elif", "isinstance", "(", "spec", ",", "six", ".", "string_types", ")", ":", "\n", "        ", "return", "pyglet", ".", "canvas", ".", "Display", "(", "spec", ")", "\n", "", "else", ":", "\n", "        ", "raise", "error", ".", "Error", "(", "'Invalid display specification: {}. (Must be a string like :0 or None.)'", ".", "format", "(", "spec", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering._add_attrs": [[149, 154], ["geom.set_color", "geom.set_linewidth"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Geom.set_color", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.PolyLine.set_linewidth"], ["", "", "def", "_add_attrs", "(", "geom", ",", "attrs", ")", ":", "\n", "    ", "if", "\"color\"", "in", "attrs", ":", "\n", "        ", "geom", ".", "set_color", "(", "*", "attrs", "[", "\"color\"", "]", ")", "\n", "", "if", "\"linewidth\"", "in", "attrs", ":", "\n", "        ", "geom", ".", "set_linewidth", "(", "attrs", "[", "\"linewidth\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.make_circle": [[245, 254], ["range", "points.append", "rendering.FilledPolygon", "rendering.PolyLine", "math.cos", "math.sin"], "function", ["None"], ["", "", "def", "make_circle", "(", "radius", "=", "10", ",", "res", "=", "30", ",", "filled", "=", "True", ")", ":", "\n", "    ", "points", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "res", ")", ":", "\n", "        ", "ang", "=", "2", "*", "math", ".", "pi", "*", "i", "/", "res", "\n", "points", ".", "append", "(", "(", "math", ".", "cos", "(", "ang", ")", "*", "radius", ",", "math", ".", "sin", "(", "ang", ")", "*", "radius", ")", ")", "\n", "", "if", "filled", ":", "\n", "        ", "return", "FilledPolygon", "(", "points", ")", "\n", "", "else", ":", "\n", "        ", "return", "PolyLine", "(", "points", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.make_polygon": [[255, 258], ["rendering.FilledPolygon", "rendering.PolyLine"], "function", ["None"], ["", "", "def", "make_polygon", "(", "v", ",", "filled", "=", "True", ")", ":", "\n", "    ", "if", "filled", ":", "return", "FilledPolygon", "(", "v", ")", "\n", "else", ":", "return", "PolyLine", "(", "v", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.make_polyline": [[259, 261], ["rendering.PolyLine"], "function", ["None"], ["", "def", "make_polyline", "(", "v", ")", ":", "\n", "    ", "return", "PolyLine", "(", "v", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.make_capsule": [[262, 270], ["rendering.make_polygon", "rendering.make_circle", "rendering.make_circle", "make_circle.add_attr", "rendering.Compound", "rendering.Transform"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.make_polygon", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.make_circle", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.make_circle", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Geom.add_attr"], ["", "def", "make_capsule", "(", "length", ",", "width", ")", ":", "\n", "    ", "l", ",", "r", ",", "t", ",", "b", "=", "0", ",", "length", ",", "width", "/", "2", ",", "-", "width", "/", "2", "\n", "box", "=", "make_polygon", "(", "[", "(", "l", ",", "b", ")", ",", "(", "l", ",", "t", ")", ",", "(", "r", ",", "t", ")", ",", "(", "r", ",", "b", ")", "]", ")", "\n", "circ0", "=", "make_circle", "(", "width", "/", "2", ")", "\n", "circ1", "=", "make_circle", "(", "width", "/", "2", ")", "\n", "circ1", ".", "add_attr", "(", "Transform", "(", "translation", "=", "(", "length", ",", "0", ")", ")", ")", "\n", "geom", "=", "Compound", "(", "[", "box", ",", "circ0", ",", "circ1", "]", ")", "\n", "return", "geom", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.multi_discrete.MultiDiscrete.__init__": [[25, 29], ["numpy.array", "numpy.array"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "array_of_param_array", ")", ":", "\n", "        ", "self", ".", "low", "=", "np", ".", "array", "(", "[", "x", "[", "0", "]", "for", "x", "in", "array_of_param_array", "]", ")", "\n", "self", ".", "high", "=", "np", ".", "array", "(", "[", "x", "[", "1", "]", "for", "x", "in", "array_of_param_array", "]", ")", "\n", "self", ".", "num_discrete_space", "=", "self", ".", "low", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.multi_discrete.MultiDiscrete.sample": [[30, 35], ["prng.np_random.rand", "int", "numpy.floor", "numpy.multiply"], "methods", ["None"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns a array with one sample from each discrete action space \"\"\"", "\n", "# For each row: round(random .* (max - min) + min, 0)", "\n", "random_array", "=", "prng", ".", "np_random", ".", "rand", "(", "self", ".", "num_discrete_space", ")", "\n", "return", "[", "int", "(", "x", ")", "for", "x", "in", "np", ".", "floor", "(", "np", ".", "multiply", "(", "(", "self", ".", "high", "-", "self", ".", "low", "+", "1.", ")", ",", "random_array", ")", "+", "self", ".", "low", ")", "]", "\n", "", "def", "contains", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.multi_discrete.MultiDiscrete.contains": [[35, 37], ["len", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "contains", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "len", "(", "x", ")", "==", "self", ".", "num_discrete_space", "and", "(", "np", ".", "array", "(", "x", ")", ">=", "self", ".", "low", ")", ".", "all", "(", ")", "and", "(", "np", ".", "array", "(", "x", ")", "<=", "self", ".", "high", ")", ".", "all", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.multi_discrete.MultiDiscrete.shape": [[38, 41], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "shape", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_discrete_space", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.multi_discrete.MultiDiscrete.__repr__": [[41, 43], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"MultiDiscrete\"", "+", "str", "(", "self", ".", "num_discrete_space", ")", "\n", "", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.multi_discrete.MultiDiscrete.__eq__": [[43, 45], ["numpy.array_equal", "numpy.array_equal"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "np", ".", "array_equal", "(", "self", ".", "low", ",", "other", ".", "low", ")", "and", "np", ".", "array_equal", "(", "self", ".", "high", ",", "other", ".", "high", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.policy.Policy.__init__": [[6, 8], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "def", "action", "(", "self", ",", "obs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.policy.Policy.action": [[8, 10], ["NotImplementedError"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "obs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.policy.InteractivePolicy.__init__": [[14, 23], ["policy.Policy.__init__", "range", "range"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "agent_index", ")", ":", "\n", "        ", "super", "(", "InteractivePolicy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "env", "=", "env", "\n", "# hard-coded keyboard events", "\n", "self", ".", "move", "=", "[", "False", "for", "i", "in", "range", "(", "4", ")", "]", "\n", "self", ".", "comm", "=", "[", "False", "for", "i", "in", "range", "(", "env", ".", "world", ".", "dim_c", ")", "]", "\n", "# register keyboard events with this environment's window", "\n", "env", ".", "viewers", "[", "agent_index", "]", ".", "window", ".", "on_key_press", "=", "self", ".", "key_press", "\n", "env", ".", "viewers", "[", "agent_index", "]", ".", "window", ".", "on_key_release", "=", "self", ".", "key_release", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.policy.InteractivePolicy.action": [[24, 41], ["numpy.concatenate", "numpy.zeros", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.concatenate"], ["", "def", "action", "(", "self", ",", "obs", ")", ":", "\n", "# ignore observation and just act based on keyboard events", "\n", "        ", "if", "self", ".", "env", ".", "discrete_action_input", ":", "\n", "            ", "u", "=", "0", "\n", "if", "self", ".", "move", "[", "0", "]", ":", "u", "=", "1", "\n", "if", "self", ".", "move", "[", "1", "]", ":", "u", "=", "2", "\n", "if", "self", ".", "move", "[", "2", "]", ":", "u", "=", "4", "\n", "if", "self", ".", "move", "[", "3", "]", ":", "u", "=", "3", "\n", "", "else", ":", "\n", "            ", "u", "=", "np", ".", "zeros", "(", "5", ")", "# 5-d because of no-move action", "\n", "if", "self", ".", "move", "[", "0", "]", ":", "u", "[", "1", "]", "+=", "1.0", "\n", "if", "self", ".", "move", "[", "1", "]", ":", "u", "[", "2", "]", "+=", "1.0", "\n", "if", "self", ".", "move", "[", "3", "]", ":", "u", "[", "3", "]", "+=", "1.0", "\n", "if", "self", ".", "move", "[", "2", "]", ":", "u", "[", "4", "]", "+=", "1.0", "\n", "if", "True", "not", "in", "self", ".", "move", ":", "\n", "                ", "u", "[", "0", "]", "+=", "1.0", "\n", "", "", "return", "np", ".", "concatenate", "(", "[", "u", ",", "np", ".", "zeros", "(", "self", ".", "env", ".", "world", ".", "dim_c", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.policy.InteractivePolicy.key_press": [[43, 48], ["None"], "methods", ["None"], ["", "def", "key_press", "(", "self", ",", "k", ",", "mod", ")", ":", "\n", "        ", "if", "k", "==", "key", ".", "LEFT", ":", "self", ".", "move", "[", "0", "]", "=", "True", "\n", "if", "k", "==", "key", ".", "RIGHT", ":", "self", ".", "move", "[", "1", "]", "=", "True", "\n", "if", "k", "==", "key", ".", "UP", ":", "self", ".", "move", "[", "2", "]", "=", "True", "\n", "if", "k", "==", "key", ".", "DOWN", ":", "self", ".", "move", "[", "3", "]", "=", "True", "\n", "", "def", "key_release", "(", "self", ",", "k", ",", "mod", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.policy.InteractivePolicy.key_release": [[48, 53], ["None"], "methods", ["None"], ["", "def", "key_release", "(", "self", ",", "k", ",", "mod", ")", ":", "\n", "        ", "if", "k", "==", "key", ".", "LEFT", ":", "self", ".", "move", "[", "0", "]", "=", "False", "\n", "if", "k", "==", "key", ".", "RIGHT", ":", "self", ".", "move", "[", "1", "]", "=", "False", "\n", "if", "k", "==", "key", ".", "UP", ":", "self", ".", "move", "[", "2", "]", "=", "False", "\n", "if", "k", "==", "key", ".", "DOWN", ":", "self", ".", "move", "[", "3", "]", "=", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising.IsingEntityState.__init__": [[5, 8], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "self", ".", "id", "=", "None", "\n", "self", ".", "p_pos", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising.IsingAgentState.__init__": [[11, 15], ["core_ising.IsingEntityState.__init__"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", "IsingAgentState", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# up or down", "\n", "self", ".", "spin", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising.IsingAction.__init__": [[18, 21], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "# action", "\n", "    ", "self", ".", "a", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising.IsingEntity.__init__": [[25, 36], ["core_ising.IsingEntityState"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "# name", "\n", "    ", "self", ".", "name", "=", "''", "\n", "# properties:", "\n", "self", ".", "size", "=", "0.050", "\n", "# entity can move / be pushed", "\n", "self", ".", "movable", "=", "False", "\n", "# color", "\n", "self", ".", "color", "=", "None", "\n", "# state: position and spin", "\n", "self", ".", "state", "=", "IsingEntityState", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising.IsingAgent.__init__": [[39, 54], ["core_ising.IsingEntity.__init__", "core_ising.IsingAgentState", "core_ising.IsingAction"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__"], ["  ", "def", "__init__", "(", "self", ",", "view_sight", "=", "1", ")", ":", "\n", "    ", "super", "(", "IsingAgent", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# agents are movable by default", "\n", "self", ".", "movable", "=", "False", "\n", "# -1: observe the whole state, 0: itself, 1: neighbour of 1 unit", "\n", "self", ".", "view_sight", "=", "view_sight", "\n", "self", ".", "spin_mask", "=", "None", "# the mask for who is neighbours", "\n", "# state", "\n", "self", ".", "state", "=", "IsingAgentState", "(", ")", "\n", "self", ".", "state", ".", "spin_range", "=", "[", "0", ",", "1", "]", "\n", "# action", "\n", "self", ".", "action", "=", "IsingAction", "(", ")", "\n", "self", ".", "action", ".", "a_range", "=", "[", "0", ",", "1", "]", "\n", "# script behavior to execute", "\n", "self", ".", "action_callback", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising.IsingWorld.__init__": [[58, 82], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "# list of agents and entities (can change at execution-time!)", "\n", "    ", "self", ".", "agents", "=", "[", "]", "\n", "self", ".", "n_agents", "=", "1", "\n", "self", ".", "agent_view_sight", "=", "1", "\n", "# position dimensionality", "\n", "self", ".", "dim_pos", "=", "2", "\n", "# state dimension", "\n", "self", ".", "dim_spin", "=", "2", "\n", "# color dimensionality", "\n", "self", ".", "dim_color", "=", "3", "\n", "# world size", "\n", "self", ".", "shape_size", "=", "1", "\n", "# ising specific", "\n", "self", ".", "global_state", "=", "None", "# log all spins", "\n", "self", ".", "moment", "=", "1", "\n", "self", ".", "field", "=", "None", "# external magnetic field", "\n", "self", ".", "temperature", "=", ".1", "# Temperature (in units of energy)", "\n", "self", ".", "interaction", "=", "1", "# Interaction (ferromagnetic if positive,", "\n", "# antiferromagnetic if negative)", "\n", "self", ".", "order_param", "=", "1.0", "\n", "self", ".", "order_param_delta", "=", "0.01", "# log the change of order parameter for \"done\"", "\n", "self", ".", "n_up", "=", "0", "\n", "self", ".", "n_down", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising.IsingWorld.entities": [[84, 87], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "entities", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "agents", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising.IsingWorld.policy_agents": [[89, 92], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "policy_agents", "(", "self", ")", ":", "\n", "    ", "return", "[", "agent", "for", "agent", "in", "self", ".", "agents", "if", "agent", ".", "action_callback", "is", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising.IsingWorld.scripted_agents": [[94, 97], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "scripted_agents", "(", "self", ")", ":", "\n", "    ", "return", "[", "agent", "for", "agent", "in", "self", ".", "agents", "if", "agent", ".", "action_callback", "is", "not", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising.IsingWorld.step": [[99, 115], ["numpy.count_nonzero", "agent.action_callback", "core_ising.IsingWorld.update_agent_state", "core_ising.IsingWorld.global_state.flatten", "abs"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising_neighbor.IsingWorld.update_agent_state"], ["", "def", "step", "(", "self", ")", ":", "\n", "\n", "# set actions for scripted agents, no use for now", "\n", "    ", "for", "agent", "in", "self", ".", "scripted_agents", ":", "\n", "      ", "agent", ".", "action", "=", "agent", ".", "action_callback", "(", "agent", ",", "self", ")", "\n", "\n", "# update agent state, and to the global_state", "\n", "", "for", "agent", "in", "self", ".", "agents", ":", "\n", "      ", "self", ".", "update_agent_state", "(", "agent", ")", "\n", "self", ".", "global_state", "[", "agent", ".", "state", ".", "p_pos", "]", "=", "agent", ".", "state", ".", "spin", "\n", "\n", "# update the world's order parameters", "\n", "", "self", ".", "n_up", "=", "np", ".", "count_nonzero", "(", "self", ".", "global_state", ".", "flatten", "(", ")", ")", "\n", "self", ".", "n_down", "=", "self", ".", "n_agents", "-", "self", ".", "n_up", "\n", "order_param_old", "=", "self", ".", "order_param", "\n", "self", ".", "order_param", "=", "abs", "(", "self", ".", "n_up", "-", "self", ".", "n_down", ")", "/", "(", "self", ".", "n_agents", "+", "0.0", ")", "\n", "# self.order_param_delta = (self.order_param - order_param_old) /", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising.IsingWorld.update_agent_state": [[118, 126], ["None"], "methods", ["None"], ["", "def", "update_agent_state", "(", "self", ",", "agent", ")", ":", "\n", "    ", "if", "agent", ".", "action", ".", "a", "==", "0", ":", "\n", "# agent.state.spin = agent.state.spin", "\n", "      ", "agent", ".", "state", ".", "spin", "=", "0", "\n", "", "else", ":", "\n", "# print(agent.name + \" change spin\")", "\n", "# agent.state.spin = 1.0 - agent.state.spin", "\n", "      ", "agent", ".", "state", ".", "spin", "=", "1", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising_neighbor.IsingEntityState.__init__": [[5, 8], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "self", ".", "id", "=", "None", "\n", "self", ".", "p_pos", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising_neighbor.IsingAgentState.__init__": [[11, 15], ["core_ising_neighbor.IsingEntityState.__init__"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", "IsingAgentState", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# up or down", "\n", "self", ".", "spin", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising_neighbor.IsingAction.__init__": [[18, 21], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "# action", "\n", "    ", "self", ".", "a", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising_neighbor.IsingEntity.__init__": [[25, 36], ["core_ising_neighbor.IsingEntityState"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "# name", "\n", "    ", "self", ".", "name", "=", "''", "\n", "# properties:", "\n", "self", ".", "size", "=", "0.050", "\n", "# entity can move / be pushed", "\n", "self", ".", "movable", "=", "False", "\n", "# color", "\n", "self", ".", "color", "=", "None", "\n", "# state: position and spin", "\n", "self", ".", "state", "=", "IsingEntityState", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising_neighbor.IsingAgent.__init__": [[39, 54], ["core_ising_neighbor.IsingEntity.__init__", "core_ising_neighbor.IsingAgentState", "core_ising_neighbor.IsingAction"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__"], ["  ", "def", "__init__", "(", "self", ",", "view_sight", "=", "1", ")", ":", "\n", "    ", "super", "(", "IsingAgent", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# agents are movable by default", "\n", "self", ".", "movable", "=", "False", "\n", "# -1: observe the whole state, 0: itself, 1: neighbour of 1 unit", "\n", "self", ".", "view_sight", "=", "view_sight", "\n", "self", ".", "spin_mask", "=", "None", "# the mask for who is neighbours", "\n", "# state", "\n", "self", ".", "state", "=", "IsingAgentState", "(", ")", "\n", "self", ".", "state", ".", "spin_range", "=", "[", "0", ",", "1", "]", "\n", "# action", "\n", "self", ".", "action", "=", "IsingAction", "(", ")", "\n", "self", ".", "action", ".", "a_range", "=", "[", "0", ",", "1", "]", "\n", "# script behavior to execute", "\n", "self", ".", "action_callback", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising_neighbor.IsingWorld.__init__": [[58, 82], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "# list of agents and entities (can change at execution-time!)", "\n", "    ", "self", ".", "agents", "=", "[", "]", "\n", "self", ".", "n_agents", "=", "1", "\n", "self", ".", "agent_view_sight", "=", "1", "\n", "# position dimensionality", "\n", "self", ".", "dim_pos", "=", "2", "\n", "# state dimension", "\n", "self", ".", "dim_spin", "=", "2", "\n", "# color dimensionality", "\n", "self", ".", "dim_color", "=", "3", "\n", "# world size", "\n", "self", ".", "shape_size", "=", "1", "\n", "# ising specific", "\n", "self", ".", "global_state", "=", "None", "# log all spins", "\n", "self", ".", "moment", "=", "1", "\n", "self", ".", "field", "=", "None", "# external magnetic field", "\n", "self", ".", "temperature", "=", ".1", "# Temperature (in units of energy)", "\n", "self", ".", "interaction", "=", "1", "# Interaction (ferromagnetic if positive,", "\n", "# antiferromagnetic if negative)", "\n", "self", ".", "order_param", "=", "1.0", "\n", "self", ".", "order_param_delta", "=", "0.01", "# log the change of order parameter for \"done\"", "\n", "self", ".", "n_up", "=", "0", "\n", "self", ".", "n_down", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising_neighbor.IsingWorld.entities": [[84, 87], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "entities", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "agents", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising_neighbor.IsingWorld.policy_agents": [[89, 92], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "policy_agents", "(", "self", ")", ":", "\n", "    ", "return", "[", "agent", "for", "agent", "in", "self", ".", "agents", "if", "agent", ".", "action_callback", "is", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising_neighbor.IsingWorld.scripted_agents": [[94, 97], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "scripted_agents", "(", "self", ")", ":", "\n", "    ", "return", "[", "agent", "for", "agent", "in", "self", ".", "agents", "if", "agent", ".", "action_callback", "is", "not", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising_neighbor.IsingWorld.step": [[99, 111], ["core_ising_neighbor.IsingWorld.update_agent_state"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising_neighbor.IsingWorld.update_agent_state"], ["", "def", "step", "(", "self", ",", "action_agents", ")", ":", "\n", "    ", "self", ".", "action_agents", "=", "action_agents", "\n", "\n", "\n", "# set actions for scripted agents, no use for now", "\n", "# for agent in self.scripted_agents:", "\n", "#   agent.action = agent.action_callback(agent, self)", "\n", "\n", "# update agent state, and to the global_state", "\n", "for", "index", "in", "self", ".", "action_agents", ":", "\n", "      ", "self", ".", "update_agent_state", "(", "self", ".", "agents", "[", "index", "]", ")", "\n", "self", ".", "global_state", "[", "self", ".", "agents", "[", "index", "]", ".", "state", ".", "p_pos", "]", "=", "self", ".", "agents", "[", "index", "]", ".", "state", ".", "spin", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_ising_neighbor.IsingWorld.update_agent_state": [[113, 121], ["None"], "methods", ["None"], ["", "", "def", "update_agent_state", "(", "self", ",", "agent", ")", ":", "\n", "    ", "if", "agent", ".", "action", ".", "a", "==", "0", ":", "\n", "# agent.state.spin = agent.state.spin", "\n", "      ", "agent", ".", "state", ".", "spin", "=", "0", "\n", "", "else", ":", "\n", "# print(agent.name + \" change spin\")", "\n", "# agent.state.spin = 1.0 - agent.state.spin", "\n", "      ", "agent", ".", "state", ".", "spin", "=", "1", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.scenario.BaseScenario.make_world": [[6, 8], ["NotImplementedError"], "methods", ["None"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "# create initial conditions of the world", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.scenario.BaseScenario.reset_world": [[9, 11], ["NotImplementedError"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.EntityState.__init__": [[5, 10], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "# physical position", "\n", "        ", "self", ".", "p_pos", "=", "None", "\n", "# physical velocity", "\n", "self", ".", "p_vel", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.AgentState.__init__": [[13, 17], ["core_neighbor.EntityState.__init__"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "AgentState", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# communication utterance", "\n", "self", ".", "c", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.Action.__init__": [[20, 25], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "# physical action", "\n", "        ", "self", ".", "u", "=", "None", "\n", "# communication action", "\n", "self", ".", "c", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.Entity.__init__": [[28, 48], ["core_neighbor.EntityState"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "# name", "\n", "        ", "self", ".", "name", "=", "''", "\n", "# properties:", "\n", "self", ".", "size", "=", "0.050", "\n", "# entity can move / be pushed", "\n", "self", ".", "movable", "=", "False", "\n", "# entity collides with others", "\n", "self", ".", "collide", "=", "True", "\n", "# material density (affects mass)", "\n", "self", ".", "density", "=", "25.0", "\n", "# color", "\n", "self", ".", "color", "=", "None", "\n", "# max speed and accel", "\n", "self", ".", "max_speed", "=", "None", "\n", "self", ".", "accel", "=", "None", "\n", "# state", "\n", "self", ".", "state", "=", "EntityState", "(", ")", "\n", "# mass", "\n", "self", ".", "initial_mass", "=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.Entity.mass": [[49, 52], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "mass", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "initial_mass", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.Landmark.__init__": [[55, 57], ["core_neighbor.Entity.__init__"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__"], ["     ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Landmark", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.Agent.__init__": [[60, 82], ["core_neighbor.Entity.__init__", "core_neighbor.AgentState", "core_neighbor.Action"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Agent", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# agents are movable by default", "\n", "self", ".", "movable", "=", "True", "\n", "# cannot send communication signals", "\n", "self", ".", "silent", "=", "False", "\n", "# cannot observe the world", "\n", "self", ".", "blind", "=", "False", "\n", "# physical motor noise amount", "\n", "self", ".", "u_noise", "=", "None", "\n", "# communication noise amount", "\n", "self", ".", "c_noise", "=", "None", "\n", "# control range", "\n", "self", ".", "u_range", "=", "1.0", "\n", "self", ".", "neighbors", "=", "[", "]", "\n", "self", ".", "pro_neighbors", "=", "[", "]", "\n", "# state", "\n", "self", ".", "state", "=", "AgentState", "(", ")", "\n", "# action", "\n", "self", ".", "action", "=", "Action", "(", ")", "\n", "# script behavior to execute", "\n", "self", ".", "action_callback", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.World.__init__": [[85, 103], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "# list of agents and entities (can change at execution-time!)", "\n", "        ", "self", ".", "agents", "=", "[", "]", "\n", "self", ".", "landmarks", "=", "[", "]", "\n", "# communication channel dimensionality", "\n", "self", ".", "dim_c", "=", "0", "\n", "# position dimensionality", "\n", "self", ".", "dim_p", "=", "2", "\n", "# color dimensionality", "\n", "self", ".", "dim_color", "=", "3", "\n", "# simulation timestep", "\n", "self", ".", "dt", "=", "0.1", "\n", "# physical damping", "\n", "self", ".", "damping", "=", "0.25", "\n", "# contact response parameters", "\n", "self", ".", "contact_force", "=", "1e+2", "\n", "self", ".", "contact_margin", "=", "1e-3", "\n", "self", ".", "size", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.World.entities": [[105, 108], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "entities", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "agents", "[", "i", "]", "for", "i", "in", "self", ".", "action_agents", "]", "+", "self", ".", "landmarks", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.World.policy_agents": [[110, 113], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "policy_agents", "(", "self", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "self", ".", "agents", "if", "agent", ".", "action_callback", "is", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.World.scripted_agents": [[115, 118], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "scripted_agents", "(", "self", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "self", ".", "agents", "if", "agent", ".", "action_callback", "is", "not", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.World.step": [[120, 134], ["core_neighbor.World.apply_action_force", "core_neighbor.World.apply_environment_force", "core_neighbor.World.integrate_state", "agent.action_callback", "len"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.World.apply_action_force", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.World.apply_environment_force", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.World.integrate_state"], ["", "def", "step", "(", "self", ",", "action_agents", ")", ":", "\n", "        ", "self", ".", "action_agents", "=", "action_agents", "\n", "\n", "# set actions for scripted agents", "\n", "for", "agent", "in", "self", ".", "scripted_agents", ":", "\n", "            ", "agent", ".", "action", "=", "agent", ".", "action_callback", "(", "agent", ",", "self", ")", "\n", "# gather forces applied to entities", "\n", "", "p_force", "=", "[", "None", "]", "*", "2", "*", "len", "(", "self", ".", "agents", ")", "\n", "# apply agent physical controls", "\n", "p_force", "=", "self", ".", "apply_action_force", "(", "p_force", ")", "\n", "# apply environment forces", "\n", "p_force", "=", "self", ".", "apply_environment_force", "(", "p_force", ")", "\n", "# integrate physical state", "\n", "self", ".", "integrate_state", "(", "p_force", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.World.apply_action_force": [[137, 143], ["None"], "methods", ["None"], ["", "def", "apply_action_force", "(", "self", ",", "p_force", ")", ":", "\n", "# set applied forces", "\n", "        ", "for", "i", "in", "self", ".", "action_agents", ":", "\n", "            ", "p_force", "[", "i", "]", "=", "self", ".", "agents", "[", "i", "]", ".", "action", ".", "u", "\n", "\n", "", "return", "p_force", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.World.apply_environment_force": [[145, 160], ["range", "len", "range", "len", "core_neighbor.World.get_collision_force", "len"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.World.get_collision_force"], ["", "def", "apply_environment_force", "(", "self", ",", "p_force", ")", ":", "\n", "# simple (but inefficient) collision response", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "action_agents", ")", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "len", "(", "self", ".", "entities", ")", ")", ":", "\n", "                ", "[", "f_a", ",", "f_b", "]", "=", "self", ".", "get_collision_force", "(", "self", ".", "agents", "[", "self", ".", "action_agents", "[", "i", "]", "]", ",", "self", ".", "entities", "[", "j", "]", ")", "\n", "if", "(", "f_a", "is", "not", "None", ")", ":", "\n", "                    ", "if", "(", "p_force", "[", "self", ".", "action_agents", "[", "i", "]", "]", "is", "None", ")", ":", "p_force", "[", "self", ".", "action_agents", "[", "i", "]", "]", "=", "0.0", "\n", "p_force", "[", "self", ".", "action_agents", "[", "i", "]", "]", "=", "f_a", "+", "p_force", "[", "self", ".", "action_agents", "[", "i", "]", "]", "\n", "\n", "", "if", "(", "f_b", "is", "not", "None", "and", "j", "<", "len", "(", "self", ".", "action_agents", ")", ")", ":", "\n", "                    ", "if", "(", "p_force", "[", "self", ".", "action_agents", "[", "j", "]", "]", "is", "None", ")", ":", "p_force", "[", "self", ".", "action_agents", "[", "j", "]", "]", "=", "0.0", "\n", "p_force", "[", "self", ".", "action_agents", "[", "j", "]", "]", "=", "f_b", "+", "p_force", "[", "self", ".", "action_agents", "[", "j", "]", "]", "\n", "\n", "\n", "", "", "", "return", "p_force", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.World.integrate_state": [[162, 184], ["numpy.sqrt", "numpy.square", "numpy.square", "numpy.sqrt", "numpy.square", "numpy.square"], "methods", ["None"], ["", "def", "integrate_state", "(", "self", ",", "p_force", ")", ":", "\n", "        ", "for", "i", "in", "self", ".", "action_agents", ":", "\n", "            ", "entity", "=", "self", ".", "agents", "[", "i", "]", "\n", "#if not entity.movable: continue", "\n", "entity", ".", "state", ".", "p_vel", "=", "entity", ".", "state", ".", "p_vel", "*", "(", "1", "-", "self", ".", "damping", ")", "\n", "if", "(", "p_force", "[", "i", "]", "is", "not", "None", ")", ":", "\n", "                ", "entity", ".", "state", ".", "p_vel", "+=", "(", "p_force", "[", "i", "]", "/", "entity", ".", "mass", ")", "*", "self", ".", "dt", "\n", "", "if", "entity", ".", "max_speed", "is", "not", "None", ":", "\n", "                ", "speed", "=", "np", ".", "sqrt", "(", "np", ".", "square", "(", "entity", ".", "state", ".", "p_vel", "[", "0", "]", ")", "+", "np", ".", "square", "(", "entity", ".", "state", ".", "p_vel", "[", "1", "]", ")", ")", "\n", "if", "speed", ">", "entity", ".", "max_speed", ":", "\n", "                    ", "entity", ".", "state", ".", "p_vel", "=", "entity", ".", "state", ".", "p_vel", "/", "np", ".", "sqrt", "(", "np", ".", "square", "(", "entity", ".", "state", ".", "p_vel", "[", "0", "]", ")", "+", "\n", "np", ".", "square", "(", "entity", ".", "state", ".", "p_vel", "[", "1", "]", ")", ")", "*", "entity", ".", "max_speed", "\n", "", "", "if", "entity", ".", "live", ":", "\n", "                ", "entity", ".", "state", ".", "p_pos", "+=", "entity", ".", "state", ".", "p_vel", "*", "self", ".", "dt", "\n", "if", "entity", ".", "state", ".", "p_pos", "[", "0", "]", ">", "self", ".", "size", ":", "\n", "                    ", "entity", ".", "state", ".", "p_pos", "[", "0", "]", "=", "self", ".", "size", "\n", "", "if", "entity", ".", "state", ".", "p_pos", "[", "1", "]", ">", "self", ".", "size", ":", "\n", "                    ", "entity", ".", "state", ".", "p_pos", "[", "1", "]", "=", "self", ".", "size", "\n", "", "if", "entity", ".", "state", ".", "p_pos", "[", "0", "]", "<", "-", "self", ".", "size", ":", "\n", "                    ", "entity", ".", "state", ".", "p_pos", "[", "0", "]", "=", "-", "self", ".", "size", "\n", "", "if", "entity", ".", "state", ".", "p_pos", "[", "1", "]", "<", "-", "self", ".", "size", ":", "\n", "                    ", "entity", ".", "state", ".", "p_pos", "[", "1", "]", "=", "-", "self", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.core_neighbor.World.get_collision_force": [[187, 206], ["numpy.sqrt", "numpy.sum", "numpy.logaddexp", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "", "", "", "def", "get_collision_force", "(", "self", ",", "entity_a", ",", "entity_b", ")", ":", "\n", "        ", "if", "(", "not", "entity_a", ".", "collide", ")", "or", "(", "not", "entity_b", ".", "collide", ")", ":", "\n", "            ", "return", "[", "None", ",", "None", "]", "# not a collider", "\n", "", "if", "(", "entity_a", "is", "entity_b", ")", ":", "\n", "            ", "return", "[", "None", ",", "None", "]", "# don't collide against itself", "\n", "# compute actual distance between entities", "\n", "", "delta_pos", "=", "entity_a", ".", "state", ".", "p_pos", "-", "entity_b", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "if", "dist", "==", "0", ":", "\n", "            ", "dist", "=", "1e-5", "\n", "# minimum allowable distance", "\n", "", "dist_min", "=", "entity_a", ".", "size", "+", "entity_b", ".", "size", "\n", "# softmax penetration", "\n", "k", "=", "self", ".", "contact_margin", "\n", "penetration", "=", "np", ".", "logaddexp", "(", "0", ",", "-", "(", "dist", "-", "dist_min", ")", "/", "k", ")", "*", "k", "\n", "force", "=", "self", ".", "contact_force", "*", "delta_pos", "/", "dist", "*", "penetration", "\n", "force_a", "=", "+", "force", "if", "entity_a", ".", "movable", "else", "None", "\n", "force_b", "=", "-", "force", "if", "entity_b", ".", "movable", "else", "None", "\n", "return", "[", "force_a", ",", "force_b", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv.__init__": [[15, 63], ["len", "enumerate", "environment.MultiAgentEnv._reset_render", "hasattr", "hasattr", "hasattr", "environment.MultiAgentEnv.observation_space.append", "environment.MultiAgentEnv.action_space.append", "len", "environment.MultiAgentEnv.observation_space.append", "environment.MultiAgentEnv.action_space.append", "gym.spaces.MultiBinary", "gym.spaces.Discrete", "observation_callback", "gym.spaces.Box", "gym.spaces.Discrete"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._reset_render"], ["def", "__init__", "(", "self", ",", "world", ",", "reset_callback", "=", "None", ",", "reward_callback", "=", "None", ",", "\n", "observation_callback", "=", "None", ",", "info_callback", "=", "None", ",", "\n", "done_callback", "=", "None", ",", "shared_viewer", "=", "True", ",", "export_episode", "=", "False", ")", ":", "\n", "\n", "# np.random.seed(int.from_bytes(os.urandom(4), byteorder='little'))", "\n", "        ", "self", ".", "world", "=", "world", "\n", "self", ".", "agents", "=", "self", ".", "world", ".", "policy_agents", "\n", "# set required vectorized gym env property", "\n", "self", ".", "n", "=", "len", "(", "world", ".", "policy_agents", ")", "\n", "# scenario callbacks", "\n", "self", ".", "reset_callback", "=", "reset_callback", "\n", "self", ".", "reward_callback", "=", "reward_callback", "\n", "self", ".", "observation_callback", "=", "observation_callback", "\n", "self", ".", "info_callback", "=", "info_callback", "\n", "self", ".", "done_callback", "=", "done_callback", "\n", "# environment parameters", "\n", "self", ".", "discrete_action_space", "=", "True", "\n", "# if true, action is a number 0...N, otherwise action is a one-hot N-dimensional vector", "\n", "self", ".", "discrete_action_input", "=", "False", "\n", "# if true, even the action is continuous, action will be performed discretely", "\n", "self", ".", "force_discrete_action", "=", "world", ".", "discrete_action", "if", "hasattr", "(", "world", ",", "'discrete_action'", ")", "else", "False", "\n", "# if true, every agent has the same reward", "\n", "self", ".", "shared_reward", "=", "world", ".", "collaborative", "if", "hasattr", "(", "world", ",", "'collaborative'", ")", "else", "False", "\n", "self", ".", "time", "=", "0", "\n", "self", ".", "export_episode", "=", "export_episode", "\n", "self", ".", "episode_memory", "=", "[", "]", "\n", "# configure spaces", "\n", "self", ".", "action_space", "=", "[", "]", "\n", "self", ".", "observation_space", "=", "[", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "self", ".", "agents", ")", ":", "\n", "\n", "            ", "if", "hasattr", "(", "world", ",", "'ising'", ")", ":", "\n", "                ", "if", "i", "<", "self", ".", "world", ".", "max_good_neighbor", ":", "\n", "                    ", "self", ".", "action_space", ".", "append", "(", "spaces", ".", "Discrete", "(", "self", ".", "world", ".", "dim_spin", ")", ")", "\n", "", "self", ".", "observation_space", ".", "append", "(", "spaces", ".", "MultiBinary", "(", "5", "*", "self", ".", "world", ".", "agent_view_sight", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "action_space", ".", "append", "(", "spaces", ".", "Discrete", "(", "world", ".", "dim_p", "*", "2", "+", "1", ")", ")", "\n", "obs_dim", "=", "len", "(", "observation_callback", "(", "agent", ",", "self", ".", "world", ")", ")", "\n", "self", ".", "observation_space", ".", "append", "(", "spaces", ".", "Box", "(", "low", "=", "-", "np", ".", "inf", ",", "high", "=", "+", "np", ".", "inf", ",", "shape", "=", "(", "obs_dim", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "\n", "\n", "# rendering", "\n", "", "", "self", ".", "shared_viewer", "=", "shared_viewer", "\n", "if", "self", ".", "shared_viewer", ":", "\n", "            ", "self", ".", "viewers", "=", "[", "None", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "viewers", "=", "[", "None", "]", "*", "self", ".", "n", "\n", "", "self", ".", "_reset_render", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._save_state": [[64, 67], ["environment.MultiAgentEnv.episode_memory.append", "copy.deepcopy"], "methods", ["None"], ["", "def", "_save_state", "(", "self", ")", ":", "\n", "        ", "import", "copy", "\n", "self", ".", "episode_memory", ".", "append", "(", "copy", ".", "deepcopy", "(", "self", ".", "world", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv.export_memory": [[68, 70], ["None"], "methods", ["None"], ["", "def", "export_memory", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "episode_memory", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv.step": [[71, 90], ["enumerate", "environment.MultiAgentEnv.world.step", "environment.MultiAgentEnv._set_action", "obs_n.append", "reward_n.append", "done_n.append", "info_n.append", "environment.MultiAgentEnv._get_obs", "environment.MultiAgentEnv._get_reward", "environment.MultiAgentEnv._get_done", "environment.MultiAgentEnv._get_info"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.step", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._set_action", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._get_obs", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._get_reward", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._get_done", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._get_info"], ["", "def", "step", "(", "self", ",", "action_n", ")", ":", "\n", "        ", "obs_n", "=", "[", "]", "\n", "reward_n", "=", "[", "]", "\n", "done_n", "=", "[", "]", "\n", "info_n", "=", "[", "]", "\n", "self", ".", "agents", "=", "self", ".", "world", ".", "policy_agents", "\n", "# set action for each agent", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "self", ".", "agents", ")", ":", "\n", "            ", "self", ".", "_set_action", "(", "action_n", "[", "i", "]", ",", "agent", ")", "\n", "# advance world state", "\n", "", "self", ".", "world", ".", "step", "(", ")", "\n", "# record observation for each agent", "\n", "for", "agent", "in", "self", ".", "agents", ":", "\n", "            ", "obs_n", ".", "append", "(", "self", ".", "_get_obs", "(", "agent", ")", ")", "\n", "reward_n", ".", "append", "(", "self", ".", "_get_reward", "(", "agent", ")", ")", "\n", "done_n", ".", "append", "(", "self", ".", "_get_done", "(", "agent", ")", ")", "\n", "info_n", ".", "append", "(", "self", ".", "_get_info", "(", "agent", ")", ")", "\n", "\n", "", "return", "obs_n", ",", "reward_n", ",", "done_n", ",", "info_n", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv.reset": [[91, 104], ["environment.MultiAgentEnv.reset_callback", "environment.MultiAgentEnv._reset_render", "environment.MultiAgentEnv._save_state", "obs_n.append", "environment.MultiAgentEnv._get_obs"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._reset_render", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._save_state", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._get_obs"], ["", "def", "reset", "(", "self", ")", ":", "\n", "# reset world", "\n", "        ", "self", ".", "reset_callback", "(", "self", ".", "world", ")", "\n", "# reset renderer", "\n", "self", ".", "_reset_render", "(", ")", "\n", "# record observations for each agent", "\n", "obs_n", "=", "[", "]", "\n", "self", ".", "agents", "=", "self", ".", "world", ".", "policy_agents", "\n", "for", "agent", "in", "self", ".", "agents", ":", "\n", "            ", "obs_n", ".", "append", "(", "self", ".", "_get_obs", "(", "agent", ")", ")", "\n", "", "self", ".", "episode_memory", "=", "[", "]", "\n", "self", ".", "_save_state", "(", ")", "\n", "return", "obs_n", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._get_info": [[106, 110], ["environment.MultiAgentEnv.info_callback"], "methods", ["None"], ["", "def", "_get_info", "(", "self", ",", "agent", ")", ":", "\n", "        ", "if", "self", ".", "info_callback", "is", "None", ":", "\n", "            ", "return", "{", "}", "\n", "", "return", "self", ".", "info_callback", "(", "agent", ",", "self", ".", "world", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._get_obs": [[112, 116], ["environment.MultiAgentEnv.observation_callback", "numpy.zeros"], "methods", ["None"], ["", "def", "_get_obs", "(", "self", ",", "agent", ")", ":", "\n", "        ", "if", "self", ".", "observation_callback", "is", "None", ":", "\n", "            ", "return", "np", ".", "zeros", "(", "0", ")", "\n", "", "return", "self", ".", "observation_callback", "(", "agent", ",", "self", ".", "world", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._get_done": [[119, 123], ["environment.MultiAgentEnv.done_callback"], "methods", ["None"], ["", "def", "_get_done", "(", "self", ",", "agent", ")", ":", "\n", "        ", "if", "self", ".", "done_callback", "is", "None", ":", "\n", "            ", "return", "False", "\n", "", "return", "self", ".", "done_callback", "(", "agent", ",", "self", ".", "world", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._get_reward": [[125, 131], ["environment.MultiAgentEnv.reward_callback"], "methods", ["None"], ["", "def", "_get_reward", "(", "self", ",", "agent", ")", ":", "\n", "        ", "if", "self", ".", "reward_callback", "is", "None", ":", "\n", "            ", "return", "0.0", "\n", "", "ret", "=", "self", ".", "reward_callback", "(", "agent", ",", "self", ".", "world", ")", "\n", "# print(\"ass\", agent.color)", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._set_action": [[133, 147], ["numpy.zeros", "numpy.zeros"], "methods", ["None"], ["", "def", "_set_action", "(", "self", ",", "action", ",", "agent", ")", ":", "\n", "        ", "if", "agent", ".", "movable", ":", "\n", "            ", "agent", ".", "action", ".", "u", "=", "np", ".", "zeros", "(", "self", ".", "world", ".", "dim_p", ")", "\n", "agent", ".", "action", ".", "c", "=", "np", ".", "zeros", "(", "self", ".", "world", ".", "dim_c", ")", "\n", "# physical action", "\n", "agent", ".", "action", ".", "u", "[", "0", "]", "+=", "action", "[", "1", "]", "-", "action", "[", "2", "]", "\n", "agent", ".", "action", ".", "u", "[", "1", "]", "+=", "action", "[", "3", "]", "-", "action", "[", "4", "]", "\n", "sensitivity", "=", "5.0", "\n", "if", "agent", ".", "accel", "is", "not", "None", ":", "\n", "                ", "sensitivity", "=", "agent", ".", "accel", "\n", "", "agent", ".", "action", ".", "u", "*=", "sensitivity", "\n", "\n", "", "else", ":", "\n", "            ", "agent", ".", "action", ".", "a", "=", "0", "if", "action", "[", "0", "]", "<=", "0.5", "else", "1", "\n", "# make sure we used all elements of action", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._reset_render": [[151, 154], ["None"], "methods", ["None"], ["", "", "def", "_reset_render", "(", "self", ")", ":", "\n", "        ", "self", ".", "render_geoms", "=", "None", "\n", "self", ".", "render_geoms_xform", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv.render_from_memory": [[155, 163], ["environment.MultiAgentEnv._reset_render", "enumerate", "print", "ret.append", "environment.MultiAgentEnv.render"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._reset_render", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.render"], ["", "def", "render_from_memory", "(", "self", ",", "memory", ",", "mode", "=", "'human'", ")", ":", "\n", "        ", "self", ".", "_reset_render", "(", ")", "\n", "ret", "=", "[", "]", "\n", "# print(len(memory))", "\n", "for", "i", ",", "world", "in", "enumerate", "(", "memory", ")", ":", "\n", "            ", "print", "(", "\"step {}\"", ".", "format", "(", "i", ")", ")", "\n", "ret", ".", "append", "(", "self", ".", "render", "(", "mode", "=", "mode", ",", "world", "=", "world", ")", "[", "0", "]", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv.render": [[165, 274], ["enumerate", "enumerate", "range", "range", "numpy.array", "len", "len", "environment.MultiAgentEnv.viewers[].set_bounds", "enumerate", "results.append", "numpy.array", "rendering.Viewer", "rendering.make_circle", "rendering.Transform", "rendering.make_circle.add_attr", "environment.MultiAgentEnv.render_geoms.append", "environment.MultiAgentEnv.render_geoms_xform.append", "environment.MultiAgentEnv.sight_render_geoms.append", "environment.MultiAgentEnv.sight_render_geoms_xform.append", "numpy.zeros", "environment.MultiAgentEnv.render_geoms_xform[].set_translation", "environment.MultiAgentEnv.viewers[].render", "numpy.array", "numpy.array", "numpy.all", "rendering.make_circle.set_color", "rendering.make_circle.set_color", "viewer.add_geom", "rendering.make_circle.set_color", "rendering.make_circle.set_color", "rendering.make_circle", "rendering.make_circle.set_color", "rendering.Transform", "rendering.make_circle.add_attr", "viewer.add_geom", "environment.MultiAgentEnv.sight_render_geoms_xform[].set_translation", "rendering.make_circle.set_color", "rendering.make_circle.set_color", "numpy.argmax"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Viewer.set_bounds", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.make_circle", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Geom.add_attr", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Transform.set_translation", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.render", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Geom.set_color", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Geom.set_color", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Viewer.add_geom", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Geom.set_color", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Geom.set_color", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.make_circle", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Geom.set_color", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Geom.add_attr", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Viewer.add_geom", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Transform.set_translation", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Geom.set_color", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.Geom.set_color", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.argmax"], ["", "def", "render", "(", "self", ",", "mode", "=", "'human'", ",", "world", "=", "None", ")", ":", "\n", "        ", "world", "=", "world", "or", "self", ".", "world", "\n", "# draw_sight = hasattr(world, \"sight\")", "\n", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "if", "agent", ".", "live", ":", "\n", "                ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.45", ",", "0.45", ",", "0.95", "]", ")", "if", "not", "agent", ".", "adversary", "else", "np", ".", "array", "(", "[", "0.95", ",", "0.45", ",", "0.45", "]", ")", "\n", "", "else", ":", "\n", "                ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.0", ",", "0.0", ",", "0.0", "]", ")", "\n", "\n", "", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "food", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.15", ",", "0.65", ",", "0.15", "]", ")", "\n", "\n", "", "draw_sight", "=", "False", "\n", "if", "mode", "==", "'human'", ":", "\n", "            ", "alphabet", "=", "'ABCDEFGHIJKLMNOPQRSTUVWXYZ'", "\n", "message", "=", "''", "\n", "for", "agent", "in", "world", ".", "agents", ":", "\n", "                ", "comm", "=", "[", "]", "\n", "for", "other", "in", "world", ".", "agents", ":", "\n", "                    ", "if", "other", "is", "agent", ":", "continue", "\n", "if", "np", ".", "all", "(", "other", ".", "state", ".", "c", "==", "0", ")", ":", "\n", "                        ", "word", "=", "'_'", "\n", "", "else", ":", "\n", "                        ", "word", "=", "alphabet", "[", "np", ".", "argmax", "(", "other", ".", "state", ".", "c", ")", "]", "\n", "", "message", "+=", "(", "other", ".", "name", "+", "' to '", "+", "agent", ".", "name", "+", "': '", "+", "word", "+", "'   '", ")", "\n", "# print(message)", "\n", "\n", "", "", "", "for", "i", "in", "range", "(", "len", "(", "self", ".", "viewers", ")", ")", ":", "\n", "# create viewers (if necessary)", "\n", "            ", "if", "self", ".", "viewers", "[", "i", "]", "is", "None", ":", "\n", "# import rendering only if we need it (and don't import for headless machines)", "\n", "#from gym.envs.classic_control import rendering", "\n", "                ", "from", "mpe_local", ".", "multiagent", "import", "rendering", "\n", "self", ".", "viewers", "[", "i", "]", "=", "rendering", ".", "Viewer", "(", "700", ",", "700", ")", "\n", "\n", "# create rendering geometry", "\n", "", "", "if", "self", ".", "render_geoms", "is", "None", ":", "\n", "# import rendering only if we need it (and don't import for headless machines)", "\n", "#from gym.envs.classic_control import rendering", "\n", "            ", "from", "mpe_local", ".", "multiagent", "import", "rendering", "\n", "self", ".", "render_geoms", "=", "[", "]", "\n", "self", ".", "render_geoms_xform", "=", "[", "]", "\n", "self", ".", "sight_render_geoms", "=", "[", "]", "\n", "self", ".", "sight_render_geoms_xform", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "entities", ":", "\n", "                ", "geom", "=", "rendering", ".", "make_circle", "(", "entity", ".", "size", ")", "\n", "xform", "=", "rendering", ".", "Transform", "(", ")", "\n", "sight_geom", "=", "None", "\n", "sight_xform", "=", "None", "\n", "if", "'agent'", "in", "entity", ".", "name", ":", "\n", "# print(*entity.color)", "\n", "                    ", "geom", ".", "set_color", "(", "*", "entity", ".", "color", ",", "alpha", "=", "0.5", ")", "\n", "if", "draw_sight", ":", "\n", "                        ", "sight_geom", "=", "rendering", ".", "make_circle", "(", "world", ".", "sight", ")", "\n", "sight_geom", ".", "set_color", "(", "*", "entity", ".", "color", ",", "alpha", "=", "0.1", ")", "\n", "sight_xform", "=", "rendering", ".", "Transform", "(", ")", "\n", "sight_geom", ".", "add_attr", "(", "sight_xform", ")", "\n", "", "", "else", ":", "\n", "                    ", "geom", ".", "set_color", "(", "*", "entity", ".", "color", ")", "\n", "", "geom", ".", "add_attr", "(", "xform", ")", "\n", "self", ".", "render_geoms", ".", "append", "(", "geom", ")", "\n", "self", ".", "render_geoms_xform", ".", "append", "(", "xform", ")", "\n", "self", ".", "sight_render_geoms", ".", "append", "(", "sight_geom", ")", "\n", "self", ".", "sight_render_geoms_xform", ".", "append", "(", "sight_xform", ")", "\n", "\n", "# add geoms to viewer", "\n", "", "for", "viewer", "in", "self", ".", "viewers", ":", "\n", "                ", "viewer", ".", "geoms", "=", "[", "]", "\n", "for", "geom", "in", "self", ".", "render_geoms", ":", "\n", "                    ", "viewer", ".", "add_geom", "(", "geom", ")", "\n", "", "for", "geom", "in", "self", ".", "sight_render_geoms", ":", "\n", "                    ", "if", "geom", "is", "not", "None", ":", "\n", "                        ", "viewer", ".", "add_geom", "(", "geom", ")", "\n", "\n", "", "", "", "", "results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "viewers", ")", ")", ":", "\n", "            ", "from", "mpe_local", ".", "multiagent", "import", "rendering", "\n", "# update bounds to center around agent", "\n", "cam_range", "=", "world", ".", "size", "\n", "if", "self", ".", "shared_viewer", ":", "\n", "                ", "pos", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "", "else", ":", "\n", "                ", "pos", "=", "self", ".", "agents", "[", "i", "]", ".", "state", ".", "p_pos", "\n", "", "self", ".", "viewers", "[", "i", "]", ".", "set_bounds", "(", "pos", "[", "0", "]", "-", "cam_range", ",", "pos", "[", "0", "]", "+", "cam_range", ",", "pos", "[", "1", "]", "-", "cam_range", ",", "pos", "[", "1", "]", "+", "cam_range", ")", "\n", "# update geometry positions", "\n", "for", "e", ",", "entity", "in", "enumerate", "(", "world", ".", "entities", ")", ":", "\n", "#print(entity, *entity.state.p_pos)", "\n", "                ", "self", ".", "render_geoms_xform", "[", "e", "]", ".", "set_translation", "(", "*", "entity", ".", "state", ".", "p_pos", ")", "\n", "geom", "=", "self", ".", "render_geoms", "[", "e", "]", "\n", "if", "'agent'", "in", "entity", ".", "name", ":", "\n", "# print(*entity.color)", "\n", "# if e != 3 and e != 0:", "\n", "                    ", "geom", ".", "set_color", "(", "*", "entity", ".", "color", ",", "alpha", "=", "0.5", ")", "\n", "# else:", "\n", "#     geom.set_color(*entity.color, alpha=1.0)", "\n", "if", "draw_sight", ":", "\n", "                        ", "sight_geom", "=", "self", ".", "sight_render_geoms", "[", "e", "]", "\n", "if", "entity", ".", "live", ":", "\n", "                            ", "sight_geom", ".", "set_color", "(", "*", "entity", ".", "color", ",", "alpha", "=", "0.1", ")", "\n", "", "else", ":", "\n", "                            ", "sight_geom", ".", "set_color", "(", "*", "entity", ".", "color", ",", "alpha", "=", "0.0", ")", "\n", "", "self", ".", "sight_render_geoms_xform", "[", "e", "]", ".", "set_translation", "(", "*", "entity", ".", "state", ".", "p_pos", ")", "\n", "", "", "else", ":", "\n", "                    ", "geom", ".", "set_color", "(", "*", "entity", ".", "color", ")", "\n", "# render to display or array", "\n", "", "", "results", ".", "append", "(", "self", ".", "viewers", "[", "i", "]", ".", "render", "(", "return_rgb_array", "=", "mode", "==", "'rgb_array'", ")", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv._make_receptor_locations": [[276, 294], ["numpy.linspace", "dx.append", "numpy.linspace", "numpy.linspace", "numpy.array", "numpy.linspace", "dx.append", "dx.append", "numpy.array", "numpy.array", "numpy.cos", "numpy.sin"], "methods", ["None"], ["", "def", "_make_receptor_locations", "(", "self", ",", "agent", ")", ":", "\n", "        ", "receptor_type", "=", "'polar'", "\n", "range_min", "=", "0.05", "*", "2.0", "\n", "range_max", "=", "1.00", "\n", "dx", "=", "[", "]", "\n", "# circular receptive field", "\n", "if", "receptor_type", "==", "'polar'", ":", "\n", "            ", "for", "angle", "in", "np", ".", "linspace", "(", "-", "np", ".", "pi", ",", "+", "np", ".", "pi", ",", "8", ",", "endpoint", "=", "False", ")", ":", "\n", "                ", "for", "distance", "in", "np", ".", "linspace", "(", "range_min", ",", "range_max", ",", "3", ")", ":", "\n", "                    ", "dx", ".", "append", "(", "distance", "*", "np", ".", "array", "(", "[", "np", ".", "cos", "(", "angle", ")", ",", "np", ".", "sin", "(", "angle", ")", "]", ")", ")", "\n", "# add origin", "\n", "", "", "dx", ".", "append", "(", "np", ".", "array", "(", "[", "0.0", ",", "0.0", "]", ")", ")", "\n", "# grid receptive field", "\n", "", "if", "receptor_type", "==", "'grid'", ":", "\n", "            ", "for", "x", "in", "np", ".", "linspace", "(", "-", "range_max", ",", "+", "range_max", ",", "5", ")", ":", "\n", "                ", "for", "y", "in", "np", ".", "linspace", "(", "-", "range_max", ",", "+", "range_max", ",", "5", ")", ":", "\n", "                    ", "dx", ".", "append", "(", "np", ".", "array", "(", "[", "x", ",", "y", "]", ")", ")", "\n", "", "", "", "return", "dx", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.__init__": [[304, 306], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "env_batch", ")", ":", "\n", "        ", "self", ".", "env_batch", "=", "env_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.n": [[307, 310], ["numpy.sum"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "@", "property", "\n", "def", "n", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "sum", "(", "[", "env", ".", "n", "for", "env", "in", "self", ".", "env_batch", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.action_space": [[311, 314], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_space", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "env_batch", "[", "0", "]", ".", "action_space", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.observation_space": [[315, 318], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "observation_space", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "env_batch", "[", "0", "]", ".", "observation_space", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.step": [[319, 333], ["env.step"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.step"], ["", "def", "step", "(", "self", ",", "action_n", ",", "time", ")", ":", "\n", "        ", "obs_n", "=", "[", "]", "\n", "reward_n", "=", "[", "]", "\n", "done_n", "=", "[", "]", "\n", "info_n", "=", "{", "'n'", ":", "[", "]", "}", "\n", "i", "=", "0", "\n", "for", "env", "in", "self", ".", "env_batch", ":", "\n", "            ", "obs", ",", "reward", ",", "done", ",", "_", "=", "env", ".", "step", "(", "action_n", "[", "i", ":", "(", "i", "+", "env", ".", "n", ")", "]", ",", "time", ")", "\n", "i", "+=", "env", ".", "n", "\n", "obs_n", "+=", "obs", "\n", "# reward = [r / len(self.env_batch) for r in reward]", "\n", "reward_n", "+=", "reward", "\n", "done_n", "+=", "done", "\n", "", "return", "obs_n", ",", "reward_n", ",", "done_n", ",", "info_n", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.reset": [[334, 339], ["env.reset"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs_n", "=", "[", "]", "\n", "for", "env", "in", "self", ".", "env_batch", ":", "\n", "            ", "obs_n", "+=", "env", ".", "reset", "(", ")", "\n", "", "return", "obs_n", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.render": [[341, 346], ["env.render"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.render"], ["", "def", "render", "(", "self", ",", "mode", "=", "'human'", ",", "close", "=", "True", ")", ":", "\n", "        ", "results_n", "=", "[", "]", "\n", "for", "env", "in", "self", ".", "env_batch", ":", "\n", "            ", "results_n", "+=", "env", ".", "render", "(", "mode", ",", "close", ")", "\n", "", "return", "results_n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.grassland.Scenario.__init__": [[8, 24], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "n_good", ",", "n_adv", ",", "n_landmarks", ",", "n_food", ",", "n_forests", ",", "alpha", ",", "good_sight", ",", "adv_sight", ",", "no_wheel", ",", "ratio", ",", "max_good_neighbor", ",", "max_adv_neighbor", ")", ":", "\n", "        ", "self", ".", "n_good", "=", "n_good", "\n", "self", ".", "n_adv", "=", "n_adv", "\n", "self", ".", "n_landmarks", "=", "n_landmarks", "\n", "self", ".", "n_food", "=", "n_food", "\n", "self", ".", "n_forests", "=", "n_forests", "\n", "self", ".", "num_agents", "=", "n_adv", "+", "n_good", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "no_wheel", "=", "no_wheel", "\n", "self", ".", "size_food", "=", "ratio", "\n", "self", ".", "size", "=", "ratio", "\n", "self", ".", "ratio", "=", "ratio", "\n", "self", ".", "good_neigh_dist", "=", "good_sight", "\n", "self", ".", "adv_neigh_dist", "=", "adv_sight", "\n", "self", ".", "max_good_neighbor", "=", "max_good_neighbor", "\n", "self", ".", "max_adv_neighbor", "=", "max_adv_neighbor", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.grassland.Scenario.make_world": [[29, 84], ["mpe_local.multiagent.core.World", "enumerate", "enumerate", "enumerate", "grassland.Scenario.reset_world", "mpe_local.multiagent.core.Agent", "mpe_local.multiagent.core.Landmark", "mpe_local.multiagent.core.Landmark", "range", "numpy.zeros", "numpy.zeros", "range", "range"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.reset_world"], ["", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "world", ".", "good_neigh_dist", "=", "self", ".", "good_neigh_dist", "\n", "world", ".", "adv_neigh_dist", "=", "self", ".", "adv_neigh_dist", "\n", "world", ".", "max_good_neighbor", "=", "self", ".", "max_good_neighbor", "\n", "world", ".", "max_adv_neighbor", "=", "self", ".", "max_adv_neighbor", "\n", "# set any world properties first", "\n", "world", ".", "collaborative", "=", "True", "\n", "world", ".", "dim_c", "=", "2", "\n", "world", ".", "size", "=", "self", ".", "ratio", "\n", "num_good_agents", "=", "self", ".", "n_good", "\n", "num_adversaries", "=", "self", ".", "n_adv", "\n", "world", ".", "num_good_agents", "=", "num_good_agents", "\n", "world", ".", "num_adversaries", "=", "num_adversaries", "\n", "num_agents", "=", "num_adversaries", "+", "num_good_agents", "\n", "num_landmarks", "=", "self", ".", "n_landmarks", "\n", "num_food", "=", "self", ".", "n_food", "\n", "num_forests", "=", "self", ".", "n_forests", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", ")", "for", "i", "in", "range", "(", "num_agents", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "True", "\n", "agent", ".", "silent", "=", "True", "\n", "agent", ".", "adversary", "=", "True", "if", "i", "<", "num_adversaries", "else", "False", "\n", "agent", ".", "size", "=", "(", "0.075", "if", "agent", ".", "adversary", "else", "0.05", ")", "\n", "agent", ".", "accel", "=", "(", "2.0", "if", "agent", ".", "adversary", "else", "4.0", ")", "\n", "if", "agent", ".", "adversary", ":", "\n", "                ", "agent", ".", "showmore", "=", "np", ".", "zeros", "(", "num_good_agents", ")", "\n", "", "else", ":", "\n", "                ", "agent", ".", "showmore", "=", "np", ".", "zeros", "(", "num_food", ")", "\n", "#agent.accel = 20.0 if agent.adversary else 25.0", "\n", "", "agent", ".", "max_speed", "=", "(", "2", "if", "agent", ".", "adversary", "else", "3", ")", "\n", "agent", ".", "live", "=", "1", "\n", "\n", "\n", "", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_landmarks", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0", "\n", "landmark", ".", "boundary", "=", "False", "\n", "# make initial conditions", "\n", "", "world", ".", "food", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_food", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "food", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'food %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.03", "\n", "landmark", ".", "boundary", "=", "False", "\n", "\n", "", "world", ".", "landmarks", "=", "world", ".", "food", "\n", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.grassland.Scenario.reset_world": [[86, 112], ["enumerate", "enumerate", "enumerate", "enumerate", "numpy.array", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.random.uniform", "numpy.zeros", "numpy.array", "numpy.array", "numpy.zeros", "numpy.zeros"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "# random properties for agents", "\n", "#########", "\n", "        ", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.45", ",", "0.45", ",", "0.95", "]", ")", "if", "not", "agent", ".", "adversary", "else", "np", ".", "array", "(", "[", "0.95", ",", "0.45", ",", "0.45", "]", ")", "\n", "agent", ".", "live", "=", "1", "\n", "if", "agent", ".", "adversary", ":", "\n", "                ", "agent", ".", "showmore", "=", "np", ".", "zeros", "(", "world", ".", "num_good_agents", ")", "\n", "", "else", ":", "\n", "                ", "agent", ".", "showmore", "=", "np", ".", "zeros", "(", "world", ".", "num_adversaries", ")", "\n", "\n", "", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.25", "]", ")", "\n", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "food", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.15", ",", "0.65", ",", "0.15", "]", ")", "\n", "\n", "# set random initial states", "\n", "", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", "*", "self", ".", "ratio", ",", "1", "*", "self", ".", "ratio", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", "*", "self", ".", "ratio", ",", "1", "*", "self", ".", "ratio", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "#", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.grassland.Scenario.is_collision": [[115, 120], ["numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "", "def", "is_collision", "(", "self", ",", "agent1", ",", "agent2", ")", ":", "\n", "        ", "delta_pos", "=", "agent1", ".", "state", ".", "p_pos", "-", "agent2", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "dist_min", "=", "agent1", ".", "size", "+", "agent2", ".", "size", "\n", "return", "True", "if", "dist", "<", "dist_min", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.grassland.Scenario.good_agents": [[122, 124], ["None"], "methods", ["None"], ["", "def", "good_agents", "(", "self", ",", "world", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "world", ".", "agents", "if", "not", "agent", ".", "adversary", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.grassland.Scenario.adversaries": [[126, 128], ["None"], "methods", ["None"], ["", "def", "adversaries", "(", "self", ",", "world", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "world", ".", "agents", "if", "agent", ".", "adversary", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.grassland.Scenario.done": [[130, 140], ["grassland.Scenario.adversaries", "grassland.Scenario.good_agents"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial_neighbor.Scenario.adversaries", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial_neighbor.Scenario.good_agents"], ["", "def", "done", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "if", "agent", "in", "self", ".", "adversaries", "(", "world", ")", ":", "\n", "            ", "for", "ag", "in", "self", ".", "good_agents", "(", "world", ")", ":", "\n", "                ", "if", "ag", ".", "live", ":", "\n", "                    ", "return", "0", "\n", "", "", "return", "1", "\n", "", "else", ":", "\n", "            ", "if", "not", "agent", ".", "live", ":", "\n", "                ", "return", "1", "\n", "", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.grassland.Scenario.info": [[141, 160], ["numpy.concatenate", "time_live.append", "time_live.append", "time_grass.append", "time_grass.append", "grassland.Scenario.is_collision", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.concatenate", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision"], ["", "def", "info", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "time_grass", "=", "[", "]", "\n", "time_live", "=", "[", "]", "\n", "\n", "mark_grass", "=", "0", "\n", "if", "agent", ".", "live", ":", "\n", "            ", "time_live", ".", "append", "(", "1", ")", "\n", "for", "food", "in", "world", ".", "food", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "agent", ",", "food", ")", ":", "\n", "                    ", "mark_grass", "=", "1", "\n", "break", "\n", "", "", "", "else", ":", "\n", "            ", "time_live", ".", "append", "(", "0", ")", "\n", "", "if", "mark_grass", ":", "\n", "            ", "time_grass", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "time_grass", ".", "append", "(", "0", ")", "\n", "\n", "", "return", "np", ".", "concatenate", "(", "[", "np", ".", "array", "(", "time_grass", ")", "]", "+", "[", "np", ".", "array", "(", "time_live", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.grassland.Scenario.reward": [[161, 197], ["min", "grassland.Scenario.is_collision", "numpy.sqrt", "len", "min", "grassland.Scenario.is_collision", "numpy.sqrt", "numpy.random.uniform", "grassland.Scenario.is_collision", "numpy.sum", "numpy.sum", "numpy.square", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.min", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.min", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# Agents are rewarded based on minimum agent distance to each landmark", "\n", "# main_reward = self.adversary_reward(agent, world) if agent.adversary else self.agent_reward(agent, world)", "\n", "# Live agent:", "\n", "        ", "rew", "=", "0", "\n", "if", "agent", ".", "live", ":", "\n", "# Good agent:", "\n", "            ", "if", "not", "agent", ".", "adversary", ":", "\n", "                ", "for", "other", "in", "world", ".", "agents", ":", "\n", "                    ", "if", "other", "==", "agent", ":", "continue", "\n", "# Eaten by wolf", "\n", "if", "self", ".", "is_collision", "(", "agent", ",", "other", ")", "and", "other", ".", "adversary", ":", "\n", "                        ", "rew", "-=", "5", "\n", "agent", ".", "live", "=", "False", "\n", "", "", "distance_min", "=", "min", "(", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "food", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", ")", ")", "for", "food", "in", "world", ".", "food", "]", ")", "\n", "rew", "-=", "distance_min", "\n", "for", "food", "in", "world", ".", "food", ":", "\n", "                    ", "if", "self", ".", "is_collision", "(", "agent", ",", "food", ")", ":", "\n", "                        ", "food", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", "*", "self", ".", "ratio", ",", "1", "*", "self", ".", "ratio", ",", "world", ".", "dim_p", ")", "\n", "rew", "+=", "20", "\n", "\n", "# Adv agent:", "\n", "", "", "", "else", ":", "\n", "                ", "for", "other", "in", "world", ".", "agents", ":", "\n", "                    ", "if", "other", "==", "agent", ":", "continue", "\n", "if", "not", "other", ".", "live", ":", "continue", "\n", "# Eat sheep", "\n", "if", "self", ".", "is_collision", "(", "agent", ",", "other", ")", "and", "not", "other", ".", "adversary", ":", "\n", "                        ", "rew", "+=", "15", "\n", "\n", "# Distance to cloest sheep", "\n", "", "", "dist2good", "=", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "other", ".", "state", ".", "p_pos", ")", ")", ")", "for", "other", "in", "world", ".", "agents", "if", "not", "other", ".", "adversary", "]", "\n", "if", "len", "(", "dist2good", ")", ">", "0", ":", "\n", "                    ", "rew", "-=", "min", "(", "dist2good", ")", "\n", "\n", "", "", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.grassland.Scenario.observation": [[199, 237], ["enumerate", "sorted", "range", "enumerate", "numpy.concatenate", "sorted.append", "entity_pos.append", "entity_pos.append", "entity_pos.append", "entity_pos.append", "numpy.sqrt", "int", "len", "range", "range", "range", "numpy.sum", "numpy.sum", "numpy.square", "numpy.square", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.concatenate", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# get positions of all entities in this agent's reference frame", "\n", "        ", "if", "agent", ".", "adversary", ":", "\n", "            ", "max_neighbor", "=", "self", ".", "max_adv_neighbor", "\n", "neighbor_sight", "=", "self", ".", "adv_neigh_dist", "\n", "", "else", ":", "\n", "            ", "max_neighbor", "=", "self", ".", "max_good_neighbor", "\n", "neighbor_sight", "=", "self", ".", "good_neigh_dist", "\n", "\n", "\n", "", "dist", "=", "[", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "dist", ".", "append", "(", "(", "i", ",", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "landmark", ".", "state", ".", "p_pos", ")", ")", ")", ")", "\n", "", "dist", "=", "sorted", "(", "dist", ",", "key", "=", "lambda", "t", ":", "t", "[", "1", "]", ")", "\n", "entity_pos", "=", "[", "]", "\n", "for", "i", ",", "land_dist", "in", "dist", ":", "\n", "            ", "entity_pos", ".", "append", "(", "world", ".", "landmarks", "[", "i", "]", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "entity_pos", ".", "append", "(", "[", "0", "]", ")", "\n", "\n", "", "for", "j", "in", "range", "(", "int", "(", "max_neighbor", "/", "2", ")", "-", "len", "(", "world", ".", "landmarks", ")", ")", ":", "\n", "            ", "entity_pos", ".", "append", "(", "[", "0", ",", "0", "]", ")", "\n", "entity_pos", ".", "append", "(", "[", "0", "]", ")", "\n", "\n", "", "other_pos", "=", "[", "[", "0", ",", "0", "]", "for", "i", "in", "range", "(", "max_neighbor", "-", "1", ")", "]", "\n", "other_live", "=", "[", "[", "0", "]", "for", "i", "in", "range", "(", "max_neighbor", "-", "1", ")", "]", "\n", "other_vel", "=", "[", "[", "0", ",", "0", "]", "for", "i", "in", "range", "(", "max_neighbor", "-", "1", ")", "]", "\n", "num_neighbor", "=", "0", "\n", "\n", "for", "i", ",", "other", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "if", "other", "is", "agent", ":", "continue", "\n", "distance", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", ")", ")", "\n", "if", "distance", "<=", "neighbor_sight", "and", "num_neighbor", "<", "max_neighbor", "-", "1", ":", "\n", "                ", "other_vel", "[", "num_neighbor", "]", "=", "other", ".", "state", ".", "p_vel", "\n", "other_pos", "[", "num_neighbor", "]", "=", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", "\n", "other_live", "[", "num_neighbor", "]", "=", "[", "other", ".", "live", "]", "\n", "num_neighbor", "+=", "1", "\n", "# print(result.shape,\"shape#################\")", "\n", "", "", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "[", "agent", ".", "state", ".", "p_pos", "]", "+", "[", "np", ".", "array", "(", "[", "agent", ".", "live", "]", ")", "]", "+", "entity_pos", "+", "other_pos", "+", "other_vel", "+", "other_live", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.ising_neighbor.Scenario.__init__": [[6, 22], ["numpy.random.seed"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "n_good", ",", "n_adv", ",", "n_landmarks", ",", "n_food", ",", "n_forests", ",", "alpha", ",", "good_sight", ",", "adv_sight", ",", "no_wheel", ",", "ratio", ",", "prosp", ",", "max_good_neighbor", ",", "max_adv_neighbor", ")", ":", "\n", "    ", "self", ".", "n_good", "=", "n_good", "\n", "self", ".", "n_landmarks", "=", "n_landmarks", "\n", "self", ".", "n_food", "=", "n_food", "\n", "self", ".", "n_adv", "=", "n_adv", "\n", "self", ".", "n_forests", "=", "n_forests", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "sight", "=", "good_sight", "\n", "self", ".", "no_wheel", "=", "no_wheel", "\n", "self", ".", "good_neigh_dist", "=", "good_sight", "\n", "self", ".", "adv_neigh_dist", "=", "adv_sight", "\n", "self", ".", "max_good_neighbor", "=", "max_good_neighbor", "\n", "self", ".", "max_adv_neighbor", "=", "max_adv_neighbor", "\n", "self", ".", "num_agents", "=", "self", ".", "n_good", "+", "self", ".", "n_adv", "\n", "#print(self.num_agents)", "\n", "np", ".", "random", ".", "seed", "(", "30", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.ising_neighbor.Scenario._calc_mask": [[23, 75], ["list", "list.remove", "range", "numpy.array", "numpy.array", "range", "range", "len", "len", "range", "len", "range", "len", "int", "int", "numpy.array", "numpy.array", "int", "int", "range", "range", "int", "int"], "methods", ["None"], ["", "def", "_calc_mask", "(", "self", ",", "agent", ",", "shape_size", ")", ":", "\n", "# compute the neighbour mask for each agent", "\n", "    ", "if", "agent", ".", "view_sight", "==", "-", "1", ":", "\n", "# fully observed", "\n", "      ", "agent", ".", "spin_mask", "+=", "1", "\n", "", "elif", "agent", ".", "view_sight", "==", "0", ":", "\n", "# observe itself", "\n", "      ", "agent", ".", "spin_mask", "[", "agent", ".", "state", ".", "id", "]", "=", "1", "\n", "", "elif", "agent", ".", "view_sight", ">", "0", ":", "\n", "# observe neighbours", "\n", "      ", "delta", "=", "list", "(", "range", "(", "-", "int", "(", "agent", ".", "view_sight", ")", ",", "int", "(", "agent", ".", "view_sight", ")", "+", "1", ",", "1", ")", ")", "\n", "delta", ".", "remove", "(", "0", ")", "# agent itself is not counted as neighbour of itself", "\n", "for", "dt", "in", "delta", ":", "\n", "        ", "row", "=", "agent", ".", "state", ".", "p_pos", "[", "0", "]", "\n", "col", "=", "agent", ".", "state", ".", "p_pos", "[", "1", "]", "\n", "row_dt", "=", "row", "+", "dt", "\n", "col_dt", "=", "col", "+", "dt", "\n", "if", "row_dt", "in", "range", "(", "0", ",", "shape_size", ")", ":", "\n", "          ", "agent", ".", "spin_mask", "[", "agent", ".", "state", ".", "id", "+", "shape_size", "*", "dt", "]", "=", "1", "\n", "", "if", "col_dt", "in", "range", "(", "0", ",", "shape_size", ")", ":", "\n", "          ", "agent", ".", "spin_mask", "[", "agent", ".", "state", ".", "id", "+", "dt", "]", "=", "1", "\n", "\n", "# the graph is cyclic, most left and most right are neighbours", "\n", "", "", "if", "agent", ".", "state", ".", "p_pos", "[", "0", "]", "<", "agent", ".", "view_sight", ":", "\n", "        ", "tar", "=", "shape_size", "-", "(", "np", ".", "array", "(", "\n", "range", "(", "0", ",", "int", "(", "agent", ".", "view_sight", "-", "agent", ".", "state", ".", "p_pos", "[", "0", "]", ")", ",", "1", ")", ")", "+", "1", ")", "\n", "tar", "=", "tar", "*", "shape_size", "+", "agent", ".", "state", ".", "p_pos", "[", "1", "]", "\n", "agent", ".", "spin_mask", "[", "tar", "]", "=", "[", "1", "]", "*", "len", "(", "tar", ")", "\n", "\n", "", "if", "agent", ".", "state", ".", "p_pos", "[", "1", "]", "<", "agent", ".", "view_sight", ":", "\n", "        ", "tar", "=", "shape_size", "-", "(", "np", ".", "array", "(", "\n", "range", "(", "0", ",", "int", "(", "agent", ".", "view_sight", "-", "agent", ".", "state", ".", "p_pos", "[", "1", "]", ")", ",", "1", ")", ")", "+", "1", ")", "\n", "tar", "=", "agent", ".", "state", ".", "p_pos", "[", "0", "]", "*", "shape_size", "+", "tar", "\n", "agent", ".", "spin_mask", "[", "tar", "]", "=", "[", "1", "]", "*", "len", "(", "tar", ")", "\n", "\n", "", "if", "agent", ".", "state", ".", "p_pos", "[", "0", "]", ">=", "shape_size", "-", "agent", ".", "view_sight", ":", "\n", "        ", "tar", "=", "np", ".", "array", "(", "\n", "range", "(", "0", ",", "int", "(", "agent", ".", "view_sight", "-", "(", "shape_size", "-", "1", "-", "\n", "agent", ".", "state", ".", "p_pos", "[", "0", "]", ")", ")", ",", "\n", "1", ")", "\n", ")", "\n", "tar", "=", "tar", "*", "shape_size", "+", "agent", ".", "state", ".", "p_pos", "[", "1", "]", "\n", "agent", ".", "spin_mask", "[", "tar", "]", "=", "[", "1", "]", "*", "len", "(", "tar", ")", "\n", "\n", "", "if", "agent", ".", "state", ".", "p_pos", "[", "1", "]", ">=", "shape_size", "-", "agent", ".", "view_sight", ":", "\n", "        ", "tar", "=", "np", ".", "array", "(", "\n", "range", "(", "0", ",", "int", "(", "agent", ".", "view_sight", "-", "(", "shape_size", "-", "1", "-", "\n", "agent", ".", "state", ".", "p_pos", "[", "1", "]", ")", ")", ",", "\n", "1", ")", "\n", ")", "\n", "tar", "=", "agent", ".", "state", ".", "p_pos", "[", "0", "]", "*", "shape_size", "+", "tar", "\n", "agent", ".", "spin_mask", "[", "tar", "]", "=", "[", "1", "]", "*", "len", "(", "tar", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.ising_neighbor.Scenario.make_world": [[76, 98], ["mpe_local.multiagent.core_ising_neighbor.IsingWorld", "int", "numpy.zeros", "numpy.zeros", "enumerate", "numpy.ceil", "mpe_local.multiagent.core_ising_neighbor.IsingAgent", "ising_neighbor.Scenario.reset_world", "numpy.power", "range"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.reset_world"], ["", "", "", "def", "make_world", "(", "self", ")", ":", "\n", "    ", "world", "=", "IsingWorld", "(", ")", "\n", "world", ".", "agent_view_sight", "=", "1", "\n", "world", ".", "dim_spin", "=", "2", "\n", "world", ".", "dim_pos", "=", "2", "\n", "num_agents", "=", "self", ".", "num_agents", "\n", "world", ".", "n_agents", "=", "num_agents", "\n", "world", ".", "shape_size", "=", "int", "(", "np", ".", "ceil", "(", "np", ".", "power", "(", "num_agents", ",", "1.0", "/", "world", ".", "dim_pos", ")", ")", ")", "\n", "world", ".", "global_state", "=", "np", ".", "zeros", "(", "(", "world", ".", "shape_size", ",", ")", "*", "world", ".", "dim_pos", ")", "\n", "# assume 0 external magnetic field", "\n", "world", ".", "field", "=", "np", ".", "zeros", "(", "(", "world", ".", "shape_size", ",", ")", "*", "world", ".", "dim_pos", ")", "\n", "\n", "world", ".", "agents", "=", "[", "IsingAgent", "(", "view_sight", "=", "world", ".", "agent_view_sight", ")", "\n", "for", "i", "in", "range", "(", "num_agents", ")", "]", "\n", "world", ".", "ising", "=", "True", "\n", "world", ".", "max_good_neighbor", "=", "self", ".", "max_good_neighbor", "\n", "world", ".", "max_adv_neighbor", "=", "self", ".", "max_adv_neighbor", "\n", "# make initial conditions", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "        ", "self", ".", "reset_world", "(", "world", ",", "i", ")", "\n", "\n", "", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.ising_neighbor.Scenario.reset_world": [[99, 136], ["numpy.array().reshape", "enumerate", "list", "list", "numpy.count_nonzero", "numpy.array", "numpy.where", "numpy.random.choice", "numpy.zeros", "ising_neighbor.Scenario._calc_mask", "list", "set", "world.global_state.flatten", "abs", "numpy.array", "numpy.where", "range", "numpy.where", "numpy.power"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.ising.Scenario._calc_mask"], ["", "def", "reset_world", "(", "self", ",", "world", ",", "agent_id", ",", "step", "=", "0", ")", ":", "\n", "\n", "    ", "world_mat", "=", "np", ".", "array", "(", "\n", "range", "(", "np", ".", "power", "(", "world", ".", "shape_size", ",", "world", ".", "dim_pos", ")", ")", ")", ".", "reshape", "(", "(", "world", ".", "shape_size", ",", ")", "*", "world", ".", "dim_pos", ")", "\n", "# init agent state and global state", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "      ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.35", ",", "0.35", ",", "0.85", "]", ")", "\n", "agent", ".", "state", ".", "id", "=", "i", "\n", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "where", "(", "world_mat", "==", "i", ")", "\n", "agent", ".", "state", ".", "spin", "=", "np", ".", "random", ".", "choice", "(", "world", ".", "dim_spin", ")", "\n", "agent", ".", "spin_mask", "=", "np", ".", "zeros", "(", "world", ".", "n_agents", ")", "\n", "world", ".", "global_state", "[", "agent", ".", "state", ".", "p_pos", "]", "=", "agent", ".", "state", ".", "spin", "\n", "self", ".", "_calc_mask", "(", "agent", ",", "world", ".", "shape_size", ")", "\n", "\n", "", "agent", "=", "world", ".", "agents", "[", "agent_id", "]", "\n", "assert", "world", ".", "dim_pos", "==", "2", ",", "\"cyclic neighbour only support 2D now\"", "\n", "\n", "self_agent_neg", "=", "list", "(", "np", ".", "where", "(", "agent", ".", "spin_mask", "==", "1", ")", "[", "0", "]", ")", "\n", "#print('agent id', agent_id)", "\n", "#print('self neg', self_agent_neg)", "\n", "neighbor_agent_neighbor", "=", "[", "]", "\n", "for", "neighbor_index", "in", "self_agent_neg", ":", "\n", "#self._calc_mask(world.agents[neighbor_index], world.shape_size)", "\n", "      ", "neighbor_index_neg", "=", "list", "(", "np", ".", "where", "(", "world", ".", "agents", "[", "neighbor_index", "]", ".", "spin_mask", "==", "1", ")", "[", "0", "]", ")", "\n", "neighbor_agent_neighbor", "+=", "neighbor_index_neg", "\n", "\n", "", "action_agents", "=", "self_agent_neg", "+", "neighbor_agent_neighbor", "+", "[", "agent_id", "]", "\n", "action_agents", "=", "list", "(", "set", "(", "action_agents", ")", ")", "\n", "#print('action agents', action_agents)", "\n", "#print(len(action_agents))", "\n", "n_ups", "=", "np", ".", "count_nonzero", "(", "world", ".", "global_state", ".", "flatten", "(", ")", ")", "\n", "n_downs", "=", "world", ".", "n_agents", "-", "n_ups", "\n", "world", ".", "order_param", "=", "abs", "(", "n_ups", "-", "n_downs", ")", "/", "(", "world", ".", "n_agents", "+", "0.0", ")", "\n", "#print(action_agents)", "\n", "return", "action_agents", ",", "self_agent_neg", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.ising_neighbor.Scenario.reward": [[138, 147], ["agent.spin_mask.reshape", "numpy.sum", "numpy.where", "int", "numpy.where", "numpy.sqrt", "world.global_state.flatten"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "reward", "(", "self", ",", "index", ",", "world", ")", ":", "\n", "# turn the state into -1/1 for easy computing", "\n", "    ", "agent", "=", "world", ".", "agents", "[", "index", "]", "\n", "world", ".", "global_state", "[", "np", ".", "where", "(", "world", ".", "global_state", "==", "0", ")", "]", "=", "-", "1", "\n", "mask_display", "=", "agent", ".", "spin_mask", ".", "reshape", "(", "(", "int", "(", "np", ".", "sqrt", "(", "world", ".", "n_agents", ")", ")", ",", "-", "1", ")", ")", "\n", "local_reward", "=", "-", "0.5", "*", "world", ".", "global_state", "[", "agent", ".", "state", ".", "p_pos", "]", "*", "np", ".", "sum", "(", "world", ".", "global_state", ".", "flatten", "(", ")", "*", "agent", ".", "spin_mask", ")", "\n", "world", ".", "global_state", "[", "np", ".", "where", "(", "world", ".", "global_state", "==", "-", "1", ")", "]", "=", "0", "\n", "return", "-", "local_reward", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.ising_neighbor.Scenario.observation": [[149, 155], ["[].tolist", "numpy.asarray", "world.global_state.flatten", "numpy.where"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "index", ",", "world", ")", ":", "\n", "    ", "agent", "=", "world", ".", "agents", "[", "index", "]", "\n", "ret", "=", "[", "world", ".", "global_state", "[", "agent", ".", "state", ".", "p_pos", "]", "[", "0", "]", "]", "\n", "ret", "+=", "world", ".", "global_state", ".", "flatten", "(", ")", "[", "np", ".", "where", "(", "agent", ".", "spin_mask", "==", "1", ")", "]", ".", "tolist", "(", ")", "\n", "ret", "=", "np", ".", "asarray", "(", "ret", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.ising.Scenario.__init__": [[6, 20], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "n_good", ",", "n_adv", ",", "n_landmarks", ",", "n_food", ",", "n_forests", ",", "alpha", ",", "good_sight", ",", "adv_sight", ",", "no_wheel", ",", "ratio", ",", "max_good_neighbor", ",", "max_adv_neighbor", ")", ":", "\n", "    ", "self", ".", "n_good", "=", "n_good", "\n", "self", ".", "n_landmarks", "=", "n_landmarks", "\n", "self", ".", "n_food", "=", "n_food", "\n", "self", ".", "n_adv", "=", "n_adv", "\n", "self", ".", "n_forests", "=", "n_forests", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "sight", "=", "good_sight", "\n", "self", ".", "no_wheel", "=", "no_wheel", "\n", "self", ".", "good_neigh_dist", "=", "good_sight", "\n", "self", ".", "adv_neigh_dist", "=", "adv_sight", "\n", "self", ".", "num_agents", "=", "self", ".", "n_good", "+", "self", ".", "n_adv", "\n", "self", ".", "max_good_neighbor", "=", "max_good_neighbor", "\n", "self", ".", "max_adv_neighbor", "=", "max_adv_neighbor", "\n", "#print(self.num_agents)", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.ising.Scenario._calc_mask": [[23, 75], ["list", "list.remove", "range", "numpy.array", "numpy.array", "range", "range", "len", "len", "range", "len", "range", "len", "int", "int", "numpy.array", "numpy.array", "int", "int", "range", "range", "int", "int"], "methods", ["None"], ["", "def", "_calc_mask", "(", "self", ",", "agent", ",", "shape_size", ")", ":", "\n", "# compute the neighbour mask for each agent", "\n", "    ", "if", "agent", ".", "view_sight", "==", "-", "1", ":", "\n", "# fully observed", "\n", "      ", "agent", ".", "spin_mask", "+=", "1", "\n", "", "elif", "agent", ".", "view_sight", "==", "0", ":", "\n", "# observe itself", "\n", "      ", "agent", ".", "spin_mask", "[", "agent", ".", "state", ".", "id", "]", "=", "1", "\n", "", "elif", "agent", ".", "view_sight", ">", "0", ":", "\n", "# observe neighbours", "\n", "      ", "delta", "=", "list", "(", "range", "(", "-", "int", "(", "agent", ".", "view_sight", ")", ",", "int", "(", "agent", ".", "view_sight", ")", "+", "1", ",", "1", ")", ")", "\n", "delta", ".", "remove", "(", "0", ")", "# agent itself is not counted as neighbour of itself", "\n", "for", "dt", "in", "delta", ":", "\n", "        ", "row", "=", "agent", ".", "state", ".", "p_pos", "[", "0", "]", "\n", "col", "=", "agent", ".", "state", ".", "p_pos", "[", "1", "]", "\n", "row_dt", "=", "row", "+", "dt", "\n", "col_dt", "=", "col", "+", "dt", "\n", "if", "row_dt", "in", "range", "(", "0", ",", "shape_size", ")", ":", "\n", "          ", "agent", ".", "spin_mask", "[", "agent", ".", "state", ".", "id", "+", "shape_size", "*", "dt", "]", "=", "1", "\n", "", "if", "col_dt", "in", "range", "(", "0", ",", "shape_size", ")", ":", "\n", "          ", "agent", ".", "spin_mask", "[", "agent", ".", "state", ".", "id", "+", "dt", "]", "=", "1", "\n", "\n", "# the graph is cyclic, most left and most right are neighbours", "\n", "", "", "if", "agent", ".", "state", ".", "p_pos", "[", "0", "]", "<", "agent", ".", "view_sight", ":", "\n", "        ", "tar", "=", "shape_size", "-", "(", "np", ".", "array", "(", "\n", "range", "(", "0", ",", "int", "(", "agent", ".", "view_sight", "-", "agent", ".", "state", ".", "p_pos", "[", "0", "]", ")", ",", "1", ")", ")", "+", "1", ")", "\n", "tar", "=", "tar", "*", "shape_size", "+", "agent", ".", "state", ".", "p_pos", "[", "1", "]", "\n", "agent", ".", "spin_mask", "[", "tar", "]", "=", "[", "1", "]", "*", "len", "(", "tar", ")", "\n", "\n", "", "if", "agent", ".", "state", ".", "p_pos", "[", "1", "]", "<", "agent", ".", "view_sight", ":", "\n", "        ", "tar", "=", "shape_size", "-", "(", "np", ".", "array", "(", "\n", "range", "(", "0", ",", "int", "(", "agent", ".", "view_sight", "-", "agent", ".", "state", ".", "p_pos", "[", "1", "]", ")", ",", "1", ")", ")", "+", "1", ")", "\n", "tar", "=", "agent", ".", "state", ".", "p_pos", "[", "0", "]", "*", "shape_size", "+", "tar", "\n", "agent", ".", "spin_mask", "[", "tar", "]", "=", "[", "1", "]", "*", "len", "(", "tar", ")", "\n", "\n", "", "if", "agent", ".", "state", ".", "p_pos", "[", "0", "]", ">=", "shape_size", "-", "agent", ".", "view_sight", ":", "\n", "        ", "tar", "=", "np", ".", "array", "(", "\n", "range", "(", "0", ",", "int", "(", "agent", ".", "view_sight", "-", "(", "shape_size", "-", "1", "-", "\n", "agent", ".", "state", ".", "p_pos", "[", "0", "]", ")", ")", ",", "\n", "1", ")", "\n", ")", "\n", "tar", "=", "tar", "*", "shape_size", "+", "agent", ".", "state", ".", "p_pos", "[", "1", "]", "\n", "agent", ".", "spin_mask", "[", "tar", "]", "=", "[", "1", "]", "*", "len", "(", "tar", ")", "\n", "\n", "", "if", "agent", ".", "state", ".", "p_pos", "[", "1", "]", ">=", "shape_size", "-", "agent", ".", "view_sight", ":", "\n", "        ", "tar", "=", "np", ".", "array", "(", "\n", "range", "(", "0", ",", "int", "(", "agent", ".", "view_sight", "-", "(", "shape_size", "-", "1", "-", "\n", "agent", ".", "state", ".", "p_pos", "[", "1", "]", ")", ")", ",", "\n", "1", ")", "\n", ")", "\n", "tar", "=", "agent", ".", "state", ".", "p_pos", "[", "0", "]", "*", "shape_size", "+", "tar", "\n", "agent", ".", "spin_mask", "[", "tar", "]", "=", "[", "1", "]", "*", "len", "(", "tar", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.ising.Scenario.make_world": [[76, 96], ["mpe_local.multiagent.core_ising.IsingWorld", "int", "numpy.zeros", "numpy.zeros", "ising.Scenario.reset_world", "numpy.ceil", "mpe_local.multiagent.core_ising.IsingAgent", "numpy.power", "range"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.reset_world"], ["", "", "", "def", "make_world", "(", "self", ")", ":", "\n", "    ", "world", "=", "IsingWorld", "(", ")", "\n", "world", ".", "agent_view_sight", "=", "1", "\n", "world", ".", "dim_spin", "=", "2", "\n", "world", ".", "dim_pos", "=", "2", "\n", "num_agents", "=", "self", ".", "num_agents", "\n", "world", ".", "n_agents", "=", "num_agents", "\n", "world", ".", "shape_size", "=", "int", "(", "np", ".", "ceil", "(", "np", ".", "power", "(", "num_agents", ",", "1.0", "/", "world", ".", "dim_pos", ")", ")", ")", "\n", "world", ".", "global_state", "=", "np", ".", "zeros", "(", "(", "world", ".", "shape_size", ",", ")", "*", "world", ".", "dim_pos", ")", "\n", "# assume 0 external magnetic field", "\n", "world", ".", "field", "=", "np", ".", "zeros", "(", "(", "world", ".", "shape_size", ",", ")", "*", "world", ".", "dim_pos", ")", "\n", "\n", "world", ".", "agents", "=", "[", "IsingAgent", "(", "view_sight", "=", "world", ".", "agent_view_sight", ")", "\n", "for", "i", "in", "range", "(", "num_agents", ")", "]", "\n", "world", ".", "ising", "=", "True", "\n", "world", ".", "max_good_neighbor", "=", "self", ".", "max_good_neighbor", "\n", "# make initial conditions", "\n", "self", ".", "reset_world", "(", "world", ")", "\n", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.ising.Scenario.reset_world": [[97, 118], ["numpy.array().reshape", "enumerate", "numpy.count_nonzero", "numpy.array", "numpy.where", "numpy.random.choice", "numpy.zeros", "ising.Scenario._calc_mask", "world.global_state.flatten", "abs", "numpy.array", "range", "numpy.power"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.ising.Scenario._calc_mask"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "\n", "    ", "world_mat", "=", "np", ".", "array", "(", "\n", "range", "(", "np", ".", "power", "(", "world", ".", "shape_size", ",", "world", ".", "dim_pos", ")", ")", ")", ".", "reshape", "(", "(", "world", ".", "shape_size", ",", ")", "*", "world", ".", "dim_pos", ")", "\n", "# init agent state and global state", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "      ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.35", ",", "0.35", ",", "0.85", "]", ")", "\n", "agent", ".", "state", ".", "id", "=", "i", "\n", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "where", "(", "world_mat", "==", "i", ")", "\n", "agent", ".", "state", ".", "spin", "=", "np", ".", "random", ".", "choice", "(", "world", ".", "dim_spin", ")", "\n", "agent", ".", "spin_mask", "=", "np", ".", "zeros", "(", "world", ".", "n_agents", ")", "\n", "\n", "assert", "world", ".", "dim_pos", "==", "2", ",", "\"cyclic neighbour only support 2D now\"", "\n", "self", ".", "_calc_mask", "(", "agent", ",", "world", ".", "shape_size", ")", "\n", "world", ".", "global_state", "[", "agent", ".", "state", ".", "p_pos", "]", "=", "agent", ".", "state", ".", "spin", "\n", "\n", "", "n_ups", "=", "np", ".", "count_nonzero", "(", "world", ".", "global_state", ".", "flatten", "(", ")", ")", "\n", "n_downs", "=", "world", ".", "n_agents", "-", "n_ups", "\n", "world", ".", "order_param", "=", "abs", "(", "n_ups", "-", "n_downs", ")", "/", "(", "world", ".", "n_agents", "+", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.ising.Scenario.reward": [[119, 135], ["agent.spin_mask.reshape", "numpy.sum", "numpy.where", "int", "numpy.where", "numpy.sqrt", "world.global_state.flatten"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# turn the state into -1/1 for easy computing", "\n", "    ", "world", ".", "global_state", "[", "np", ".", "where", "(", "world", ".", "global_state", "==", "0", ")", "]", "=", "-", "1", "\n", "\n", "mask_display", "=", "agent", ".", "spin_mask", ".", "reshape", "(", "(", "int", "(", "np", ".", "sqrt", "(", "world", ".", "n_agents", ")", ")", ",", "-", "1", ")", ")", "\n", "\n", "local_reward", "=", "-", "0.5", "*", "world", ".", "global_state", "[", "agent", ".", "state", ".", "p_pos", "]", "*", "np", ".", "sum", "(", "world", ".", "global_state", ".", "flatten", "(", ")", "*", "agent", ".", "spin_mask", ")", "\n", "# print('index', agent.state.id)", "\n", "# print('state', world.global_state)", "\n", "# print('mask', agent.spin_mask)", "\n", "# print('reward', -local_reward[0])", "\n", "world", ".", "global_state", "[", "np", ".", "where", "(", "world", ".", "global_state", "==", "-", "1", ")", "]", "=", "0", "\n", "\n", "#print(world.global_state[agent.state.p_pos])", "\n", "return", "-", "local_reward", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.ising.Scenario.observation": [[136, 142], ["[].tolist", "numpy.asarray", "world.global_state.flatten", "numpy.where"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "    ", "ret", "=", "[", "world", ".", "global_state", "[", "agent", ".", "state", ".", "p_pos", "]", "[", "0", "]", "]", "\n", "ret", "+=", "world", ".", "global_state", ".", "flatten", "(", ")", "[", "np", ".", "where", "(", "agent", ".", "spin_mask", "==", "1", ")", "]", ".", "tolist", "(", ")", "\n", "#ret.append(world.global_state[agent.state.p_pos][0])", "\n", "ret", "=", "np", ".", "asarray", "(", "ret", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.ising.Scenario.info": [[143, 145], ["None"], "methods", ["None"], ["", "def", "info", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "    ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.ising.Scenario.done": [[146, 148], ["None"], "methods", ["None"], ["", "def", "done", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "    ", "return", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread_neighbor.Scenario.__init__": [[8, 23], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "n_good", ",", "n_adv", ",", "n_landmarks", ",", "n_food", ",", "n_forests", ",", "alpha", ",", "good_sight", ",", "adv_sight", ",", "no_wheel", ",", "ratio", ",", "prosp", ",", "max_good_neighbor", ",", "max_adv_neighbor", ")", ":", "\n", "        ", "self", ".", "n_good", "=", "n_good", "\n", "self", ".", "n_landmarks", "=", "n_food", "\n", "self", ".", "n_food", "=", "n_food", "\n", "self", ".", "n_adv", "=", "n_adv", "\n", "self", ".", "n_forests", "=", "n_forests", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "ratio", "=", "ratio", "\n", "self", ".", "good_neigh_dist", "=", "good_sight", "\n", "self", ".", "adv_neigh_dist", "=", "adv_sight", "\n", "self", ".", "no_wheel", "=", "no_wheel", "\n", "self", ".", "neigh_dist", "=", "good_sight", "\n", "self", ".", "prosp_dist", "=", "prosp", "\n", "self", ".", "max_good_neighbor", "=", "max_good_neighbor", "\n", "self", ".", "max_adv_neighbor", "=", "max_adv_neighbor", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread_neighbor.Scenario.make_world": [[25, 63], ["mpe_local.multiagent.core_neighbor.World", "enumerate", "enumerate", "mpe_local.multiagent.core_neighbor.Agent", "numpy.array", "numpy.zeros", "mpe_local.multiagent.core_neighbor.Landmark", "numpy.array", "range", "range"], "methods", ["None"], ["", "def", "make_world", "(", "self", ")", ":", "\n", "# np.random.seed(24)", "\n", "        ", "world", "=", "World", "(", ")", "\n", "world", ".", "dim_c", "=", "2", "\n", "world", ".", "size", "=", "self", ".", "ratio", "\n", "self", ".", "num_agents", "=", "self", ".", "n_good", "+", "self", ".", "n_adv", "\n", "num_landmarks", "=", "self", ".", "n_food", "\n", "num_agents", "=", "self", ".", "num_agents", "\n", "world", ".", "collaborative", "=", "True", "\n", "world", ".", "good_neigh_dist", "=", "self", ".", "good_neigh_dist", "\n", "world", ".", "adv_neigh_dist", "=", "self", ".", "adv_neigh_dist", "\n", "world", ".", "max_good_neighbor", "=", "self", ".", "max_good_neighbor", "\n", "world", ".", "max_adv_neighbor", "=", "self", ".", "max_adv_neighbor", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", ")", "for", "i", "in", "range", "(", "num_agents", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "True", "\n", "agent", ".", "silent", "=", "True", "\n", "agent", ".", "size", "=", "0.05", "\n", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.15", ",", "0.65", ",", "0.15", "]", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "self", ".", "num_agents", ")", "\n", "agent", ".", "max_speed", "=", "3", "\n", "agent", ".", "live", "=", "1", "\n", "\n", "# add landmarks", "\n", "", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_landmarks", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "occupied", "=", "-", "1", "\n", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.15", ",", "0.15", ",", "0.15", "]", ")", "\n", "landmark", ".", "size", "=", "0.03", "\n", "# world.landmarks[i].state.p_pos = position[i]", "\n", "# world.landmarks[i].state.p_vel = np.zeros(world.dim_p)", "\n", "\n", "", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread_neighbor.Scenario.reset_world": [[64, 78], ["range", "numpy.random.uniform", "range", "numpy.linalg.norm", "list", "list", "list.remove", "numpy.random.uniform", "numpy.zeros", "numpy.random.uniform", "numpy.where", "numpy.where"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ",", "agent_id", ",", "step", "=", "0", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "self", ".", "n_landmarks", ")", ":", "\n", "            ", "world", ".", "landmarks", "[", "i", "]", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "self", ".", "ratio", "*", "1", ",", "self", ".", "ratio", "*", "1", ",", "world", ".", "dim_p", ")", "\n", "world", ".", "landmarks", "[", "i", "]", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "", "all_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "self", ".", "ratio", "*", "1", ",", "+", "self", ".", "ratio", "*", "1", ",", "(", "self", ".", "num_agents", ",", "world", ".", "dim_p", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_agents", ")", ":", "\n", "            ", "world", ".", "agents", "[", "i", "]", ".", "state", ".", "p_pos", "=", "all_pos", "[", "i", "]", "\n", "world", ".", "agents", "[", "i", "]", ".", "state", ".", "p_vel", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", "-", "self", ".", "ratio", ",", "1", "+", "self", ".", "ratio", ",", "world", ".", "dim_p", ")", "\n", "# Calculate the distance between the agent and all agents", "\n", "", "distance", "=", "np", ".", "linalg", ".", "norm", "(", "all_pos", "-", "all_pos", "[", "agent_id", "]", ",", "axis", "=", "1", ")", "\n", "action_agents", "=", "list", "(", "np", ".", "where", "(", "distance", "<=", "2", "*", "(", "self", ".", "prosp_dist", "+", "self", ".", "good_neigh_dist", ")", ")", "[", "0", "]", ")", "\n", "neighbors", "=", "list", "(", "np", ".", "where", "(", "distance", "<=", "self", ".", "good_neigh_dist", ")", "[", "0", "]", ")", "\n", "neighbors", ".", "remove", "(", "agent_id", ")", "\n", "return", "action_agents", ",", "neighbors", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread_neighbor.Scenario.is_collision": [[80, 85], ["numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "is_collision", "(", "self", ",", "agent1", ",", "agent2", ")", ":", "\n", "        ", "delta_pos", "=", "agent1", ".", "state", ".", "p_pos", "-", "agent2", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "dist_min", "=", "agent1", ".", "size", "+", "agent2", ".", "size", "\n", "return", "True", "if", "dist", "<", "dist_min", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread_neighbor.Scenario.reward": [[86, 101], ["min", "numpy.sqrt", "simple_spread_neighbor.Scenario.is_collision", "simple_spread_neighbor.Scenario.is_collision", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.min", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "reward", "(", "self", ",", "index", ",", "world", ")", ":", "\n", "        ", "agent", "=", "world", ".", "agents", "[", "index", "]", "\n", "rew", "=", "0", "\n", "dists", "=", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "l", ".", "state", ".", "p_pos", ")", ")", ")", "for", "l", "in", "world", ".", "landmarks", "]", "\n", "rew", "-=", "min", "(", "dists", ")", "\n", "\n", "for", "food", "in", "world", ".", "landmarks", ":", "\n", "            ", "if", "self", ".", "is_collision", "(", "food", ",", "agent", ")", ":", "\n", "                ", "rew", "+=", "1", "\n", "\n", "", "", "for", "a", "in", "world", ".", "agents", ":", "\n", "            ", "if", "a", "==", "agent", ":", "continue", "\n", "if", "self", ".", "is_collision", "(", "a", ",", "agent", ")", ":", "\n", "                ", "rew", "-=", "1", "\n", "", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread_neighbor.Scenario.observation": [[103, 134], ["enumerate", "sorted", "range", "enumerate", "numpy.concatenate", "sorted.append", "entity_pos.append", "entity_pos.append", "entity_pos.append", "entity_pos.append", "numpy.sqrt", "range", "range", "range", "numpy.sum", "numpy.sum", "numpy.square", "numpy.square", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.concatenate", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "observation", "(", "self", ",", "index", ",", "world", ")", ":", "\n", "# current agent", "\n", "        ", "agent", "=", "world", ".", "agents", "[", "index", "]", "\n", "dist", "=", "[", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "dist", ".", "append", "(", "(", "i", ",", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "landmark", ".", "state", ".", "p_pos", ")", ")", ")", ")", "\n", "", "dist", "=", "sorted", "(", "dist", ",", "key", "=", "lambda", "t", ":", "t", "[", "1", "]", ")", "\n", "entity_pos", "=", "[", "]", "\n", "for", "i", ",", "land_dist", "in", "dist", ":", "\n", "            ", "entity_pos", ".", "append", "(", "world", ".", "landmarks", "[", "i", "]", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "entity_pos", ".", "append", "(", "[", "0", "]", ")", "\n", "\n", "", "for", "j", "in", "range", "(", "self", ".", "max_good_neighbor", "-", "self", ".", "num_agents", ")", ":", "\n", "            ", "entity_pos", ".", "append", "(", "[", "0", ",", "0", "]", ")", "\n", "entity_pos", ".", "append", "(", "[", "0", "]", ")", "\n", "\n", "", "other_pos", "=", "[", "[", "0", ",", "0", "]", "for", "i", "in", "range", "(", "self", ".", "max_good_neighbor", "-", "1", ")", "]", "\n", "other_live", "=", "[", "[", "0", "]", "for", "i", "in", "range", "(", "self", ".", "max_good_neighbor", "-", "1", ")", "]", "\n", "other_vel", "=", "[", "[", "0", ",", "0", "]", "for", "i", "in", "range", "(", "self", ".", "max_good_neighbor", "-", "1", ")", "]", "\n", "num_neighbor", "=", "0", "\n", "\n", "for", "i", ",", "other", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "if", "other", "is", "agent", ":", "continue", "\n", "distance", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", ")", ")", "\n", "if", "distance", "<=", "self", ".", "good_neigh_dist", "and", "num_neighbor", "<", "self", ".", "max_good_neighbor", "-", "1", ":", "\n", "                ", "other_vel", "[", "num_neighbor", "]", "=", "other", ".", "state", ".", "p_vel", "\n", "other_pos", "[", "num_neighbor", "]", "=", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", "\n", "other_live", "[", "num_neighbor", "]", "=", "[", "1", "]", "\n", "num_neighbor", "+=", "1", "\n", "\n", "", "", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "[", "agent", ".", "state", ".", "p_pos", "]", "+", "[", "np", ".", "array", "(", "[", "1", "]", ")", "]", "+", "entity_pos", "+", "other_pos", "+", "other_vel", "+", "other_live", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.grassland_neighbor.Scenario.__init__": [[8, 27], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "n_good", ",", "n_adv", ",", "n_landmarks", ",", "n_food", ",", "n_forests", ",", "alpha", ",", "good_sight", ",", "adv_sight", ",", "no_wheel", ",", "ratio", ",", "prosp", ",", "max_good_neighbor", ",", "max_adv_neighbor", ")", ":", "\n", "        ", "self", ".", "n_good", "=", "n_good", "\n", "self", ".", "n_adv", "=", "n_adv", "\n", "self", ".", "n_landmarks", "=", "n_landmarks", "\n", "self", ".", "n_food", "=", "n_food", "\n", "self", ".", "n_forests", "=", "n_forests", "\n", "self", ".", "num_agents", "=", "n_adv", "+", "n_good", "\n", "self", ".", "alpha", "=", "alpha", "\n", "#self.good_sight = good_sight", "\n", "#self.adv_sight = adv_sight", "\n", "self", ".", "no_wheel", "=", "no_wheel", "\n", "self", ".", "size_food", "=", "ratio", "\n", "self", ".", "size", "=", "ratio", "\n", "self", ".", "ratio", "=", "ratio", "\n", "self", ".", "good_neigh_dist", "=", "good_sight", "\n", "self", ".", "adv_neigh_dist", "=", "adv_sight", "\n", "self", ".", "max_good_neighbor", "=", "max_good_neighbor", "\n", "self", ".", "max_adv_neighbor", "=", "max_adv_neighbor", "\n", "self", ".", "prosp_dist", "=", "prosp", "\n", "# print(sight,\"sight___wolf_sheep_v2\")", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.grassland_neighbor.Scenario.make_world": [[30, 82], ["mpe_local.multiagent.core_neighbor.World", "enumerate", "enumerate", "range", "mpe_local.multiagent.core_neighbor.Agent", "mpe_local.multiagent.core_neighbor.Landmark", "grassland_neighbor.Scenario.reset_world", "range", "numpy.zeros", "numpy.zeros", "range"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.reset_world"], ["", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "collaborative", "=", "False", "\n", "world", ".", "dim_c", "=", "2", "\n", "world", ".", "size", "=", "self", ".", "ratio", "\n", "#world.sight = self.sight", "\n", "num_good_agents", "=", "self", ".", "n_good", "\n", "num_adversaries", "=", "self", ".", "n_adv", "\n", "world", ".", "num_good_agents", "=", "num_good_agents", "\n", "world", ".", "num_adversaries", "=", "num_adversaries", "\n", "num_agents", "=", "num_adversaries", "+", "num_good_agents", "\n", "self", ".", "num_agents", "=", "num_agents", "\n", "num_landmarks", "=", "self", ".", "n_landmarks", "\n", "num_food", "=", "self", ".", "n_food", "\n", "num_forests", "=", "self", ".", "n_forests", "\n", "\n", "world", ".", "good_neigh_dist", "=", "self", ".", "good_neigh_dist", "\n", "world", ".", "adv_neigh_dist", "=", "self", ".", "adv_neigh_dist", "\n", "world", ".", "max_good_neighbor", "=", "self", ".", "max_good_neighbor", "\n", "world", ".", "max_adv_neighbor", "=", "self", ".", "max_adv_neighbor", "\n", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", ")", "for", "i", "in", "range", "(", "num_agents", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "True", "\n", "agent", ".", "silent", "=", "True", "\n", "agent", ".", "adversary", "=", "True", "if", "i", "<", "num_adversaries", "else", "False", "\n", "agent", ".", "size", "=", "(", "0.075", "if", "agent", ".", "adversary", "else", "0.05", ")", "\n", "agent", ".", "accel", "=", "(", "2.0", "if", "agent", ".", "adversary", "else", "4.0", ")", "\n", "if", "agent", ".", "adversary", ":", "\n", "                ", "agent", ".", "showmore", "=", "np", ".", "zeros", "(", "num_good_agents", ")", "\n", "", "else", ":", "\n", "                ", "agent", ".", "showmore", "=", "np", ".", "zeros", "(", "num_food", ")", "\n", "#agent.accel = 20.0 if agent.adversary else 25.0", "\n", "", "agent", ".", "max_speed", "=", "(", "2", "if", "agent", ".", "adversary", "else", "3", ")", "\n", "agent", ".", "live", "=", "1", "\n", "\n", "# make initial conditions", "\n", "", "world", ".", "food", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_food", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "food", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'food %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.03", "\n", "landmark", ".", "boundary", "=", "False", "\n", "\n", "", "world", ".", "landmarks", "=", "world", ".", "food", "\n", "for", "i", "in", "range", "(", "num_agents", ")", ":", "\n", "            ", "self", ".", "reset_world", "(", "world", ",", "i", ")", "\n", "", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.grassland_neighbor.Scenario.reset_world": [[84, 108], ["enumerate", "numpy.random.uniform", "enumerate", "numpy.linalg.norm", "list", "list", "list.remove", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.random.uniform", "numpy.zeros", "numpy.array", "numpy.array", "numpy.zeros", "numpy.zeros", "numpy.where", "numpy.where"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ",", "agent_id", ",", "step", "=", "0", ")", ":", "\n", "        ", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "food", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.15", ",", "0.65", ",", "0.15", "]", ")", "\n", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "self", ".", "ratio", "*", "1", ",", "self", ".", "ratio", "*", "1", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n", "", "all_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "self", ".", "ratio", "*", "1", ",", "+", "self", ".", "ratio", "*", "1", ",", "(", "self", ".", "num_agents", ",", "world", ".", "dim_p", ")", ")", "\n", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.45", ",", "0.45", ",", "0.95", "]", ")", "if", "not", "agent", ".", "adversary", "else", "np", ".", "array", "(", "[", "0.95", ",", "0.45", ",", "0.45", "]", ")", "\n", "agent", ".", "live", "=", "1", "\n", "agent", ".", "state", ".", "p_pos", "=", "all_pos", "[", "i", "]", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", "-", "self", ".", "ratio", ",", "1", "+", "self", ".", "ratio", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "if", "agent", ".", "adversary", ":", "\n", "                ", "agent", ".", "showmore", "=", "np", ".", "zeros", "(", "world", ".", "num_good_agents", ")", "\n", "", "else", ":", "\n", "                ", "agent", ".", "showmore", "=", "np", ".", "zeros", "(", "world", ".", "num_adversaries", ")", "\n", "\n", "", "", "distance", "=", "np", ".", "linalg", ".", "norm", "(", "all_pos", "-", "all_pos", "[", "agent_id", "]", ",", "axis", "=", "1", ")", "\n", "action_agents", "=", "list", "(", "np", ".", "where", "(", "distance", "<=", "2", "*", "(", "self", ".", "prosp_dist", "+", "self", ".", "good_neigh_dist", ")", ")", "[", "0", "]", ")", "\n", "neighbors", "=", "list", "(", "np", ".", "where", "(", "distance", "<=", "self", ".", "good_neigh_dist", ")", "[", "0", "]", ")", "\n", "neighbors", ".", "remove", "(", "agent_id", ")", "\n", "return", "action_agents", ",", "neighbors", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.grassland_neighbor.Scenario.is_collision": [[110, 115], ["numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "is_collision", "(", "self", ",", "agent1", ",", "agent2", ")", ":", "\n", "        ", "delta_pos", "=", "agent1", ".", "state", ".", "p_pos", "-", "agent2", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "dist_min", "=", "agent1", ".", "size", "+", "agent2", ".", "size", "\n", "return", "True", "if", "dist", "<", "dist_min", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.grassland_neighbor.Scenario.good_agents": [[117, 119], ["None"], "methods", ["None"], ["", "def", "good_agents", "(", "self", ",", "world", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "world", ".", "agents", "if", "not", "agent", ".", "adversary", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.grassland_neighbor.Scenario.adversaries": [[121, 123], ["None"], "methods", ["None"], ["", "def", "adversaries", "(", "self", ",", "world", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "world", ".", "agents", "if", "agent", ".", "adversary", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.grassland_neighbor.Scenario.done": [[125, 135], ["grassland_neighbor.Scenario.adversaries", "grassland_neighbor.Scenario.good_agents"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial_neighbor.Scenario.adversaries", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial_neighbor.Scenario.good_agents"], ["", "def", "done", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "if", "agent", "in", "self", ".", "adversaries", "(", "world", ")", ":", "\n", "            ", "for", "ag", "in", "self", ".", "good_agents", "(", "world", ")", ":", "\n", "                ", "if", "ag", ".", "live", ":", "\n", "                    ", "return", "0", "\n", "", "", "return", "1", "\n", "", "else", ":", "\n", "            ", "if", "not", "agent", ".", "live", ":", "\n", "                ", "return", "1", "\n", "", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.grassland_neighbor.Scenario.info": [[136, 155], ["numpy.concatenate", "time_live.append", "time_live.append", "time_grass.append", "time_grass.append", "grassland_neighbor.Scenario.is_collision", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.concatenate", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision"], ["", "def", "info", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "time_grass", "=", "[", "]", "\n", "time_live", "=", "[", "]", "\n", "\n", "mark_grass", "=", "0", "\n", "if", "agent", ".", "live", ":", "\n", "            ", "time_live", ".", "append", "(", "1", ")", "\n", "for", "food", "in", "world", ".", "food", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "agent", ",", "food", ")", ":", "\n", "                    ", "mark_grass", "=", "1", "\n", "break", "\n", "", "", "", "else", ":", "\n", "            ", "time_live", ".", "append", "(", "0", ")", "\n", "", "if", "mark_grass", ":", "\n", "            ", "time_grass", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "time_grass", ".", "append", "(", "0", ")", "\n", "\n", "", "return", "np", ".", "concatenate", "(", "[", "np", ".", "array", "(", "time_grass", ")", "]", "+", "[", "np", ".", "array", "(", "time_live", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.grassland_neighbor.Scenario.reward": [[156, 191], ["min", "grassland_neighbor.Scenario.is_collision", "numpy.sqrt", "len", "min", "grassland_neighbor.Scenario.is_collision", "numpy.sqrt", "numpy.random.uniform", "grassland_neighbor.Scenario.is_collision", "numpy.sum", "numpy.sum", "numpy.square", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.min", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.min", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "reward", "(", "self", ",", "index", ",", "world", ")", ":", "\n", "        ", "agent", "=", "world", ".", "agents", "[", "index", "]", "\n", "# Agents are rewarded based on minimum agent distance to each landmark", "\n", "# main_reward = self.adversary_reward(agent, world) if agent.adversary else self.agent_reward(agent, world)", "\n", "# Live agent:", "\n", "rew", "=", "0", "\n", "if", "agent", ".", "live", ":", "\n", "# Good agent:", "\n", "            ", "if", "not", "agent", ".", "adversary", ":", "\n", "                ", "for", "other_id", "in", "agent", ".", "neighbors", ":", "\n", "# Eaten by wolf", "\n", "                    ", "if", "self", ".", "is_collision", "(", "agent", ",", "world", ".", "agents", "[", "other_id", "]", ")", "and", "world", ".", "agents", "[", "other_id", "]", ".", "adversary", ":", "\n", "                        ", "rew", "-=", "5", "\n", "agent", ".", "live", "=", "False", "\n", "", "", "distance_min", "=", "min", "(", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "food", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", ")", ")", "for", "food", "in", "world", ".", "food", "]", ")", "\n", "rew", "-=", "distance_min", "\n", "for", "food", "in", "world", ".", "food", ":", "\n", "                    ", "if", "self", ".", "is_collision", "(", "agent", ",", "food", ")", ":", "\n", "                        ", "food", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", "*", "self", ".", "ratio", ",", "1", "*", "self", ".", "ratio", ",", "world", ".", "dim_p", ")", "\n", "rew", "+=", "20", "\n", "\n", "# Adv agent:", "\n", "", "", "", "else", ":", "\n", "                ", "for", "other_id", "in", "agent", ".", "neighbors", ":", "\n", "                    ", "if", "not", "world", ".", "agents", "[", "other_id", "]", ".", "live", ":", "continue", "\n", "# Eat sheep", "\n", "if", "self", ".", "is_collision", "(", "agent", ",", "world", ".", "agents", "[", "other_id", "]", ")", "and", "not", "world", ".", "agents", "[", "other_id", "]", ".", "adversary", ":", "\n", "                        ", "rew", "+=", "15", "\n", "\n", "# Distance to cloest sheep", "\n", "", "", "dist2good", "=", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "world", ".", "agents", "[", "other_id", "]", ".", "state", ".", "p_pos", ")", ")", ")", "for", "other_id", "in", "agent", ".", "neighbors", "if", "not", "world", ".", "agents", "[", "other_id", "]", ".", "adversary", "]", "\n", "if", "len", "(", "dist2good", ")", ">", "0", ":", "\n", "                    ", "rew", "-=", "min", "(", "dist2good", ")", "\n", "\n", "", "", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.grassland_neighbor.Scenario.observation": [[193, 234], ["enumerate", "sorted", "range", "enumerate", "numpy.concatenate", "sorted.append", "entity_pos.append", "entity_pos.append", "entity_pos.append", "entity_pos.append", "numpy.sqrt", "int", "len", "range", "range", "range", "numpy.sum", "numpy.sum", "numpy.square", "numpy.square", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.concatenate", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "observation", "(", "self", ",", "index", ",", "world", ")", ":", "\n", "        ", "agent", "=", "world", ".", "agents", "[", "index", "]", "\n", "\n", "if", "agent", ".", "adversary", ":", "\n", "            ", "max_neighbor", "=", "self", ".", "max_adv_neighbor", "\n", "neighbor_sight", "=", "self", ".", "adv_neigh_dist", "\n", "", "else", ":", "\n", "            ", "max_neighbor", "=", "self", ".", "max_good_neighbor", "\n", "neighbor_sight", "=", "self", ".", "good_neigh_dist", "\n", "\n", "# get positions of all entities in this agent's reference frame", "\n", "", "dist", "=", "[", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "dist", ".", "append", "(", "(", "i", ",", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "landmark", ".", "state", ".", "p_pos", ")", ")", ")", ")", "\n", "\n", "", "dist", "=", "sorted", "(", "dist", ",", "key", "=", "lambda", "t", ":", "t", "[", "1", "]", ")", "\n", "entity_pos", "=", "[", "]", "\n", "\n", "for", "i", ",", "land_dist", "in", "dist", ":", "\n", "            ", "entity_pos", ".", "append", "(", "world", ".", "landmarks", "[", "i", "]", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "entity_pos", ".", "append", "(", "[", "0", "]", ")", "\n", "\n", "", "for", "j", "in", "range", "(", "int", "(", "max_neighbor", "/", "2", ")", "-", "len", "(", "world", ".", "landmarks", ")", ")", ":", "\n", "            ", "entity_pos", ".", "append", "(", "[", "0", ",", "0", "]", ")", "\n", "entity_pos", ".", "append", "(", "[", "0", "]", ")", "\n", "\n", "", "other_pos", "=", "[", "[", "0", ",", "0", "]", "for", "i", "in", "range", "(", "max_neighbor", "-", "1", ")", "]", "\n", "other_live", "=", "[", "[", "0", "]", "for", "i", "in", "range", "(", "max_neighbor", "-", "1", ")", "]", "\n", "other_vel", "=", "[", "[", "0", ",", "0", "]", "for", "i", "in", "range", "(", "max_neighbor", "-", "1", ")", "]", "\n", "num_neighbor", "=", "0", "\n", "\n", "for", "i", ",", "other", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "if", "other", "is", "agent", ":", "continue", "\n", "distance", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", ")", ")", "\n", "if", "distance", "<=", "neighbor_sight", "and", "num_neighbor", "<", "max_neighbor", "-", "1", ":", "\n", "                ", "other_vel", "[", "num_neighbor", "]", "=", "other", ".", "state", ".", "p_vel", "\n", "other_pos", "[", "num_neighbor", "]", "=", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", "\n", "other_live", "[", "num_neighbor", "]", "=", "[", "other", ".", "live", "]", "\n", "num_neighbor", "+=", "1", "\n", "# print(result.shape,\"shape#################\")", "\n", "", "", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "[", "agent", ".", "state", ".", "p_pos", "]", "+", "[", "np", ".", "array", "(", "[", "agent", ".", "live", "]", ")", "]", "+", "entity_pos", "+", "other_pos", "+", "other_vel", "+", "other_live", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial.Scenario.__init__": [[10, 25], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "n_good", ",", "n_adv", ",", "n_landmarks", ",", "n_food", ",", "n_forests", ",", "alpha", ",", "good_sight", ",", "adv_sight", ",", "no_wheel", ",", "ratio", ",", "max_good_neighbor", ",", "max_adv_neighbor", ")", ":", "\n", "        ", "self", ".", "n_good", "=", "n_good", "\n", "self", ".", "n_adv", "=", "n_adv", "\n", "self", ".", "n_landmarks", "=", "n_landmarks", "\n", "self", ".", "n_food", "=", "n_food", "\n", "self", ".", "n_forests", "=", "n_forests", "\n", "self", ".", "num_agents", "=", "n_adv", "+", "n_good", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "good_neigh_dist", "=", "good_sight", "\n", "self", ".", "adv_neigh_dist", "=", "adv_sight", "\n", "self", ".", "ratio", "=", "ratio", "\n", "self", ".", "size", "=", "ratio", "\n", "self", ".", "no_wheel", "=", "no_wheel", "\n", "self", ".", "max_good_neighbor", "=", "max_good_neighbor", "\n", "self", ".", "max_adv_neighbor", "=", "max_adv_neighbor", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial.Scenario.make_world": [[27, 75], ["mpe_local.multiagent.core.World", "enumerate", "enumerate", "adversarial.Scenario.reset_world", "mpe_local.multiagent.core.Agent", "mpe_local.multiagent.core.Landmark", "range", "numpy.zeros", "numpy.zeros", "range"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.reset_world"], ["", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "world", ".", "size", "=", "self", ".", "ratio", "\n", "world", ".", "good_neigh_dist", "=", "self", ".", "good_neigh_dist", "\n", "world", ".", "adv_neigh_dist", "=", "self", ".", "adv_neigh_dist", "\n", "world", ".", "max_good_neighbor", "=", "self", ".", "max_good_neighbor", "\n", "world", ".", "max_adv_neighbor", "=", "self", ".", "max_adv_neighbor", "\n", "# set any world properties first", "\n", "world", ".", "dim_c", "=", "2", "\n", "num_good_agents", "=", "self", ".", "n_good", "\n", "num_adversaries", "=", "self", ".", "n_adv", "\n", "world", ".", "num_good_agents", "=", "num_good_agents", "\n", "world", ".", "num_adversaries", "=", "num_adversaries", "\n", "num_agents", "=", "num_adversaries", "+", "num_good_agents", "\n", "num_landmarks", "=", "self", ".", "n_landmarks", "\n", "num_food", "=", "self", ".", "n_food", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", ")", "for", "i", "in", "range", "(", "num_agents", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "True", "\n", "agent", ".", "silent", "=", "True", "\n", "agent", ".", "adversary", "=", "True", "if", "i", "<", "num_adversaries", "else", "False", "\n", "agent", ".", "size", "=", "0.08", "if", "agent", ".", "adversary", "else", "0.08", "\n", "agent", ".", "accel", "=", "4.0", "if", "agent", ".", "adversary", "else", "4.0", "\n", "if", "agent", ".", "adversary", ":", "\n", "                ", "agent", ".", "showmore", "=", "np", ".", "zeros", "(", "num_good_agents", ")", "\n", "", "else", ":", "\n", "                ", "agent", ".", "showmore", "=", "np", ".", "zeros", "(", "num_food", ")", "\n", "#agent.accel = 20.0 if agent.adversary else 25.0", "\n", "", "agent", ".", "max_speed", "=", "3", "if", "agent", ".", "adversary", "else", "3", "\n", "agent", ".", "live", "=", "1", "\n", "\n", "\n", "# make initial conditions", "\n", "", "world", ".", "food", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_food", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "food", ")", ":", "\n", "            ", "landmark", ".", "sight", "=", "1", "\n", "landmark", ".", "name", "=", "'food %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.03", "\n", "landmark", ".", "boundary", "=", "False", "\n", "\n", "", "world", ".", "landmarks", "=", "world", ".", "food", "\n", "\n", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial.Scenario.reset_world": [[77, 100], ["enumerate", "enumerate", "enumerate", "enumerate", "numpy.array", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.random.uniform", "numpy.zeros", "numpy.array", "numpy.array", "numpy.zeros", "numpy.zeros"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "        ", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.45", ",", "0.45", ",", "0.95", "]", ")", "if", "not", "agent", ".", "adversary", "else", "np", ".", "array", "(", "[", "0.95", ",", "0.45", ",", "0.45", "]", ")", "\n", "agent", ".", "live", "=", "1", "\n", "if", "agent", ".", "adversary", ":", "\n", "                ", "agent", ".", "showmore", "=", "np", ".", "zeros", "(", "world", ".", "num_good_agents", ")", "\n", "", "else", ":", "\n", "                ", "agent", ".", "showmore", "=", "np", ".", "zeros", "(", "world", ".", "num_adversaries", ")", "\n", "", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.25", "]", ")", "\n", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "food", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.15", ",", "0.65", ",", "0.15", "]", ")", "\n", "\n", "# set random initial states", "\n", "", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", "*", "self", ".", "ratio", ",", "+", "1", "*", "self", ".", "ratio", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", "*", "self", ".", "ratio", ",", "1", "*", "self", ".", "ratio", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial.Scenario.is_collision": [[102, 107], ["numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "", "def", "is_collision", "(", "self", ",", "agent1", ",", "agent2", ")", ":", "\n", "        ", "delta_pos", "=", "agent1", ".", "state", ".", "p_pos", "-", "agent2", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "dist_min", "=", "agent1", ".", "size", "+", "agent2", ".", "size", "\n", "return", "True", "if", "dist", "<", "dist_min", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial.Scenario.good_agents": [[109, 111], ["None"], "methods", ["None"], ["", "def", "good_agents", "(", "self", ",", "world", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "world", ".", "agents", "if", "not", "agent", ".", "adversary", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial.Scenario.adversaries": [[113, 115], ["None"], "methods", ["None"], ["", "def", "adversaries", "(", "self", ",", "world", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "world", ".", "agents", "if", "agent", ".", "adversary", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial.Scenario.done": [[117, 119], ["None"], "methods", ["None"], ["", "def", "done", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial.Scenario.info": [[120, 139], ["numpy.concatenate", "time_live.append", "time_live.append", "time_grass.append", "time_grass.append", "adversarial.Scenario.is_collision", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.concatenate", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision"], ["", "def", "info", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "time_grass", "=", "[", "]", "\n", "time_live", "=", "[", "]", "\n", "\n", "mark_grass", "=", "0", "\n", "if", "agent", ".", "live", ":", "\n", "            ", "time_live", ".", "append", "(", "1", ")", "\n", "for", "food", "in", "world", ".", "food", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "agent", ",", "food", ")", ":", "\n", "                    ", "mark_grass", "=", "1", "\n", "break", "\n", "", "", "", "else", ":", "\n", "            ", "time_live", ".", "append", "(", "0", ")", "\n", "", "if", "mark_grass", ":", "\n", "            ", "time_grass", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "time_grass", ".", "append", "(", "0", ")", "\n", "\n", "", "return", "np", ".", "concatenate", "(", "[", "np", ".", "array", "(", "time_grass", ")", "]", "+", "[", "np", ".", "array", "(", "time_live", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial.Scenario.reward": [[141, 210], ["min", "adversarial.Scenario.is_collision", "numpy.sqrt", "numpy.random.uniform", "numpy.sqrt", "len", "min", "numpy.sqrt", "len", "min", "numpy.sum", "adversarial.Scenario.is_collision", "numpy.sum", "adversarial.Scenario.is_collision", "numpy.sum", "numpy.square", "adversarial.Scenario.is_collision", "numpy.square", "adversarial.Scenario.is_collision", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.min", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.min", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.min", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# Agents are rewarded based on minimum agent distance to each landmark", "\n", "# main_reward = self.adversary_reward(agent, world) if agent.adversary else self.agent_reward(agent, world)", "\n", "        ", "rew", "=", "0", "\n", "\n", "if", "agent", ".", "live", ":", "\n", "# Good agent", "\n", "            ", "dist2food", "=", "min", "(", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "food", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", ")", ")", "for", "food", "in", "world", ".", "food", "]", ")", "\n", "rew", "-=", "dist2food", "\n", "for", "food", "in", "world", ".", "food", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "agent", ",", "food", ")", ":", "\n", "                    ", "rew", "+=", "10", "\n", "food", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", "*", "self", ".", "ratio", ",", "1", "*", "self", ".", "ratio", ",", "world", ".", "dim_p", ")", "\n", "\n", "", "", "if", "not", "agent", ".", "adversary", ":", "# Good agents", "\n", "                ", "num_collide", "=", "0", "\n", "good_collide", "=", "0", "\n", "for", "other_agent", "in", "world", ".", "agents", ":", "\n", "                    ", "if", "other_agent", "==", "agent", ":", "continue", "\n", "if", "not", "other_agent", ".", "live", ":", "continue", "\n", "if", "self", ".", "is_collision", "(", "agent", ",", "other_agent", ")", "and", "other_agent", ".", "adversary", ":", "# Collide with one agent of another side", "\n", "                        ", "num_collide", "+=", "1", "\n", "good_collide", "+=", "1", "\n", "for", "other_good_agent", "in", "world", ".", "agents", ":", "\n", "                            ", "if", "not", "other_good_agent", ".", "live", ":", "continue", "\n", "if", "other_good_agent", "==", "other_agent", ":", "continue", "\n", "if", "other_good_agent", "==", "agent", ":", "continue", "\n", "if", "other_good_agent", ".", "adversary", ":", "continue", "\n", "if", "self", ".", "is_collision", "(", "other_good_agent", ",", "other_agent", ")", ":", "\n", "                                ", "good_collide", "+=", "1", "\n", "rew", "+=", "5", "\n", "good_collide", "=", "0", "\n", "\n", "", "", "", "", "if", "num_collide", ">=", "2", ":", "\n", "                    ", "agent", ".", "live", "=", "False", "\n", "rew", "-=", "5", "\n", "\n", "", "distance_min", "=", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "other_agent", ".", "state", ".", "p_pos", ")", ")", ")", "for", "other_agent", "in", "world", ".", "agents", "if", "other_agent", ".", "adversary", "and", "other_agent", ".", "live", "]", "\n", "if", "(", "len", "(", "distance_min", ")", ">", "0", ")", ":", "\n", "                    ", "rew", "-=", "min", "(", "distance_min", ")", "\n", "\n", "", "", "if", "agent", ".", "adversary", ":", "\n", "                ", "num_collide", "=", "0", "\n", "good_collide", "=", "0", "\n", "for", "other_agent", "in", "world", ".", "agents", ":", "\n", "                    ", "if", "other_agent", "==", "agent", ":", "continue", "\n", "if", "not", "other_agent", ".", "live", ":", "continue", "\n", "if", "self", ".", "is_collision", "(", "agent", ",", "other_agent", ")", "and", "not", "other_agent", ".", "adversary", ":", "\n", "                        ", "num_collide", "+=", "1", "\n", "good_collide", "+=", "1", "\n", "for", "other_good_agent", "in", "world", ".", "agents", ":", "\n", "                            ", "if", "not", "other_good_agent", ".", "live", ":", "continue", "\n", "if", "other_good_agent", "==", "other_agent", ":", "continue", "\n", "if", "other_good_agent", "==", "agent", ":", "continue", "\n", "if", "not", "other_good_agent", ".", "adversary", ":", "continue", "\n", "if", "self", ".", "is_collision", "(", "other_good_agent", ",", "other_agent", ")", ":", "\n", "                                ", "good_collide", "+=", "1", "\n", "rew", "+=", "5", "\n", "good_collide", "=", "0", "\n", "\n", "", "", "", "", "if", "num_collide", ">=", "2", ":", "\n", "                    ", "agent", ".", "live", "=", "False", "\n", "rew", "-=", "5", "\n", "\n", "", "distance_min", "=", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "other_agent", ".", "state", ".", "p_pos", ")", ")", ")", "for", "other_agent", "in", "world", ".", "agents", "if", "not", "other_agent", ".", "adversary", "and", "other_agent", ".", "live", "]", "\n", "if", "(", "len", "(", "distance_min", ")", ">", "0", ")", ":", "\n", "                    ", "rew", "-=", "min", "(", "distance_min", ")", "\n", "\n", "", "", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial.Scenario.observation": [[213, 257], ["enumerate", "sorted", "range", "enumerate", "numpy.concatenate", "sorted.append", "entity_pos.append", "entity_pos.append", "entity_pos.append", "entity_pos.append", "numpy.sqrt", "int", "len", "range", "range", "range", "numpy.sum", "numpy.sum", "numpy.square", "numpy.square", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.concatenate", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# get positions of all entities in this agent's reference frame", "\n", "        ", "if", "agent", ".", "adversary", ":", "\n", "            ", "max_neighbor", "=", "self", ".", "max_adv_neighbor", "\n", "neighbor_sight", "=", "self", ".", "adv_neigh_dist", "\n", "", "else", ":", "\n", "            ", "max_neighbor", "=", "self", ".", "max_good_neighbor", "\n", "neighbor_sight", "=", "self", ".", "good_neigh_dist", "\n", "\n", "", "dist", "=", "[", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "dist", ".", "append", "(", "(", "i", ",", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "landmark", ".", "state", ".", "p_pos", ")", ")", ")", ")", "\n", "", "dist", "=", "sorted", "(", "dist", ",", "key", "=", "lambda", "t", ":", "t", "[", "1", "]", ")", "\n", "entity_pos", "=", "[", "]", "\n", "for", "i", ",", "land_dist", "in", "dist", ":", "\n", "            ", "entity_pos", ".", "append", "(", "world", ".", "landmarks", "[", "i", "]", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "entity_pos", ".", "append", "(", "[", "0", "]", ")", "\n", "\n", "", "for", "j", "in", "range", "(", "int", "(", "max_neighbor", "/", "2", ")", "-", "len", "(", "world", ".", "landmarks", ")", ")", ":", "\n", "            ", "entity_pos", ".", "append", "(", "[", "0", ",", "0", "]", ")", "\n", "entity_pos", ".", "append", "(", "[", "0", "]", ")", "\n", "\n", "", "other_pos", "=", "[", "[", "0", ",", "0", "]", "for", "i", "in", "range", "(", "max_neighbor", "-", "1", ")", "]", "\n", "other_live", "=", "[", "[", "0", "]", "for", "i", "in", "range", "(", "max_neighbor", "-", "1", ")", "]", "\n", "other_vel", "=", "[", "[", "0", ",", "0", "]", "for", "i", "in", "range", "(", "max_neighbor", "-", "1", ")", "]", "\n", "num_neighbor", "=", "0", "\n", "no_live", "=", "False", "\n", "for", "i", ",", "other", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "if", "other", "is", "agent", ":", "continue", "\n", "distance", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", ")", ")", "\n", "if", "distance", "<=", "neighbor_sight", "and", "num_neighbor", "<", "max_neighbor", "-", "1", ":", "\n", "                ", "other_vel", "[", "num_neighbor", "]", "=", "other", ".", "state", ".", "p_vel", "\n", "other_pos", "[", "num_neighbor", "]", "=", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", "\n", "other_live", "[", "num_neighbor", "]", "=", "[", "other", ".", "live", "]", "\n", "no_live", "=", "no_live", "or", "other", ".", "live", "\n", "num_neighbor", "+=", "1", "\n", "\n", "#agent.live = 1", "\n", "#other_live[-1] = [1]", "\n", "\n", "\n", "\n", "#print('observation', result)", "\n", "", "", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "[", "agent", ".", "state", ".", "p_pos", "]", "+", "[", "np", ".", "array", "(", "[", "agent", ".", "live", "]", ")", "]", "+", "entity_pos", "+", "other_pos", "+", "other_vel", "+", "other_live", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial_neighbor.Scenario.__init__": [[8, 25], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "n_good", ",", "n_adv", ",", "n_landmarks", ",", "n_food", ",", "n_forests", ",", "alpha", ",", "good_sight", ",", "adv_sight", ",", "no_wheel", ",", "ratio", ",", "prosp", ",", "max_good_neighbor", ",", "max_adv_neighbor", ")", ":", "\n", "        ", "self", ".", "n_good", "=", "n_good", "\n", "self", ".", "n_adv", "=", "n_adv", "\n", "self", ".", "n_landmarks", "=", "n_landmarks", "\n", "self", ".", "n_food", "=", "n_food", "\n", "self", ".", "n_forests", "=", "n_forests", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "num_agents", "=", "n_adv", "+", "n_good", "\n", "self", ".", "no_wheel", "=", "no_wheel", "\n", "self", ".", "size_food", "=", "ratio", "\n", "self", ".", "size", "=", "ratio", "\n", "self", ".", "ratio", "=", "ratio", "\n", "self", ".", "good_neigh_dist", "=", "good_sight", "\n", "self", ".", "adv_neigh_dist", "=", "adv_sight", "\n", "self", ".", "prosp_dist", "=", "prosp", "\n", "self", ".", "max_good_neighbor", "=", "max_good_neighbor", "\n", "self", ".", "max_adv_neighbor", "=", "max_adv_neighbor", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial_neighbor.Scenario.make_world": [[27, 77], ["mpe_local.multiagent.core_neighbor.World", "enumerate", "enumerate", "range", "mpe_local.multiagent.core_neighbor.Agent", "mpe_local.multiagent.core_neighbor.Landmark", "adversarial_neighbor.Scenario.reset_world", "range", "numpy.zeros", "numpy.zeros", "range"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.reset_world"], ["", "def", "make_world", "(", "self", ")", ":", "\n", "\n", "        ", "world", "=", "World", "(", ")", "\n", "world", ".", "size", "=", "self", ".", "ratio", "\n", "world", ".", "good_neigh_dist", "=", "self", ".", "good_neigh_dist", "\n", "world", ".", "adv_neigh_dist", "=", "self", ".", "adv_neigh_dist", "\n", "world", ".", "collaborative", "=", "False", "\n", "world", ".", "max_good_neighbor", "=", "self", ".", "max_good_neighbor", "\n", "world", ".", "max_adv_neighbor", "=", "self", ".", "max_adv_neighbor", "\n", "# set any world properties first", "\n", "world", ".", "dim_c", "=", "2", "\n", "num_good_agents", "=", "self", ".", "n_good", "\n", "num_adversaries", "=", "self", ".", "n_adv", "\n", "world", ".", "num_good_agents", "=", "num_good_agents", "\n", "world", ".", "num_adversaries", "=", "num_adversaries", "\n", "num_agents", "=", "num_adversaries", "+", "num_good_agents", "\n", "self", ".", "num_agents", "=", "num_agents", "\n", "num_landmarks", "=", "self", ".", "n_landmarks", "\n", "num_food", "=", "self", ".", "n_food", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", ")", "for", "i", "in", "range", "(", "num_agents", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "True", "\n", "agent", ".", "silent", "=", "True", "\n", "agent", ".", "adversary", "=", "True", "if", "i", "<", "num_adversaries", "else", "False", "\n", "agent", ".", "size", "=", "0.08", "if", "agent", ".", "adversary", "else", "0.08", "\n", "agent", ".", "accel", "=", "4.0", "if", "agent", ".", "adversary", "else", "4.0", "\n", "if", "agent", ".", "adversary", ":", "\n", "                ", "agent", ".", "showmore", "=", "np", ".", "zeros", "(", "num_good_agents", ")", "\n", "", "else", ":", "\n", "                ", "agent", ".", "showmore", "=", "np", ".", "zeros", "(", "num_food", ")", "\n", "#agent.accel = 20.0 if agent.adversary else 25.0", "\n", "", "agent", ".", "max_speed", "=", "3", "if", "agent", ".", "adversary", "else", "3", "\n", "agent", ".", "live", "=", "1", "\n", "\n", "# make initial conditions", "\n", "", "world", ".", "food", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_food", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "food", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'food %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.03", "\n", "landmark", ".", "boundary", "=", "False", "\n", "\n", "", "world", ".", "landmarks", "=", "world", ".", "food", "\n", "for", "i", "in", "range", "(", "num_agents", ")", ":", "\n", "            ", "self", ".", "reset_world", "(", "world", ",", "i", ")", "\n", "\n", "", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial_neighbor.Scenario.reset_world": [[79, 107], ["enumerate", "numpy.random.uniform", "enumerate", "numpy.linalg.norm", "list", "list", "list.remove", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.random.uniform", "numpy.zeros", "numpy.array", "numpy.array", "numpy.zeros", "numpy.zeros", "numpy.where", "numpy.where"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ",", "agent_id", ",", "step", "=", "0", ")", ":", "\n", "# random properties for agents", "\n", "#########", "\n", "        ", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "food", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.15", ",", "0.65", ",", "0.15", "]", ")", "\n", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", "*", "self", ".", "ratio", ",", "1", "*", "self", ".", "ratio", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n", "", "all_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", "*", "self", ".", "ratio", ",", "+", "1", "*", "self", ".", "ratio", ",", "(", "self", ".", "num_agents", ",", "world", ".", "dim_p", ")", ")", "\n", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.45", ",", "0.45", ",", "0.95", "]", ")", "if", "not", "agent", ".", "adversary", "else", "np", ".", "array", "(", "[", "0.95", ",", "0.45", ",", "0.45", "]", ")", "\n", "agent", ".", "live", "=", "1", "\n", "if", "agent", ".", "adversary", ":", "\n", "                ", "agent", ".", "showmore", "=", "np", ".", "zeros", "(", "world", ".", "num_good_agents", ")", "\n", "", "else", ":", "\n", "                ", "agent", ".", "showmore", "=", "np", ".", "zeros", "(", "world", ".", "num_adversaries", ")", "\n", "", "agent", ".", "state", ".", "p_pos", "=", "all_pos", "[", "i", "]", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", "-", "self", ".", "ratio", ",", "1", "+", "self", ".", "ratio", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "\n", "", "distance", "=", "np", ".", "linalg", ".", "norm", "(", "all_pos", "-", "all_pos", "[", "agent_id", "]", ",", "axis", "=", "1", ")", "\n", "action_agents", "=", "list", "(", "np", ".", "where", "(", "distance", "<=", "2", "*", "(", "self", ".", "prosp_dist", "+", "self", ".", "good_neigh_dist", ")", ")", "[", "0", "]", ")", "\n", "neighbors", "=", "list", "(", "np", ".", "where", "(", "distance", "<=", "self", ".", "good_neigh_dist", ")", "[", "0", "]", ")", "\n", "neighbors", ".", "remove", "(", "agent_id", ")", "# Neighbors do not include agent itself here", "\n", "world", ".", "agents", "[", "agent_id", "]", ".", "neighbors", "=", "neighbors", "\n", "\n", "return", "action_agents", ",", "neighbors", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial_neighbor.Scenario.is_collision": [[109, 114], ["numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "is_collision", "(", "self", ",", "agent1", ",", "agent2", ")", ":", "\n", "        ", "delta_pos", "=", "agent1", ".", "state", ".", "p_pos", "-", "agent2", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "dist_min", "=", "agent1", ".", "size", "+", "agent2", ".", "size", "\n", "return", "True", "if", "dist", "<", "dist_min", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial_neighbor.Scenario.good_agents": [[116, 118], ["None"], "methods", ["None"], ["", "def", "good_agents", "(", "self", ",", "world", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "world", ".", "agents", "if", "not", "agent", ".", "adversary", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial_neighbor.Scenario.adversaries": [[120, 122], ["None"], "methods", ["None"], ["", "def", "adversaries", "(", "self", ",", "world", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "world", ".", "agents", "if", "agent", ".", "adversary", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial_neighbor.Scenario.done": [[124, 126], ["None"], "methods", ["None"], ["", "def", "done", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial_neighbor.Scenario.info": [[127, 146], ["numpy.concatenate", "time_live.append", "time_live.append", "time_grass.append", "time_grass.append", "adversarial_neighbor.Scenario.is_collision", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.concatenate", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision"], ["", "def", "info", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "time_grass", "=", "[", "]", "\n", "time_live", "=", "[", "]", "\n", "\n", "mark_grass", "=", "0", "\n", "if", "agent", ".", "live", ":", "\n", "            ", "time_live", ".", "append", "(", "1", ")", "\n", "for", "food", "in", "world", ".", "food", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "agent", ",", "food", ")", ":", "\n", "                    ", "mark_grass", "=", "1", "\n", "break", "\n", "", "", "", "else", ":", "\n", "            ", "time_live", ".", "append", "(", "0", ")", "\n", "", "if", "mark_grass", ":", "\n", "            ", "time_grass", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "time_grass", ".", "append", "(", "0", ")", "\n", "\n", "", "return", "np", ".", "concatenate", "(", "[", "np", ".", "array", "(", "time_grass", ")", "]", "+", "[", "np", ".", "array", "(", "time_live", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial_neighbor.Scenario.reward": [[149, 215], ["min", "adversarial_neighbor.Scenario.is_collision", "numpy.sqrt", "numpy.random.uniform", "numpy.sqrt", "len", "min", "numpy.sqrt", "len", "min", "numpy.sum", "adversarial_neighbor.Scenario.is_collision", "numpy.sum", "adversarial_neighbor.Scenario.is_collision", "numpy.sum", "numpy.square", "adversarial_neighbor.Scenario.is_collision", "numpy.square", "adversarial_neighbor.Scenario.is_collision", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.min", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.min", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.min", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision"], ["", "def", "reward", "(", "self", ",", "index", ",", "world", ")", ":", "\n", "        ", "agent", "=", "world", ".", "agents", "[", "index", "]", "\n", "rew", "=", "0", "\n", "\n", "if", "agent", ".", "live", ":", "\n", "# Good agent", "\n", "            ", "dist2food", "=", "min", "(", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "food", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", ")", ")", "for", "food", "in", "world", ".", "food", "]", ")", "\n", "rew", "-=", "dist2food", "\n", "for", "food", "in", "world", ".", "food", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "agent", ",", "food", ")", ":", "\n", "                    ", "rew", "+=", "10", "\n", "food", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", "*", "self", ".", "ratio", ",", "1", "*", "self", ".", "ratio", ",", "world", ".", "dim_p", ")", "\n", "\n", "", "", "if", "not", "agent", ".", "adversary", ":", "\n", "                ", "num_collide", "=", "0", "\n", "good_collide", "=", "0", "\n", "#print(agent.neighbors)", "\n", "for", "other_id", "in", "agent", ".", "neighbors", ":", "\n", "                    ", "if", "not", "world", ".", "agents", "[", "other_id", "]", ".", "live", ":", "continue", "\n", "#print('Agent Neighbors')", "\n", "if", "self", ".", "is_collision", "(", "agent", ",", "world", ".", "agents", "[", "other_id", "]", ")", "and", "world", ".", "agents", "[", "other_id", "]", ".", "adversary", ":", "\n", "                        ", "num_collide", "+=", "1", "\n", "good_collide", "+=", "1", "\n", "for", "other_good_id", "in", "agent", ".", "neighbors", ":", "\n", "                            ", "if", "not", "world", ".", "agents", "[", "other_good_id", "]", ".", "live", ":", "continue", "\n", "if", "other_good_id", "==", "other_id", "or", "other_good_id", "==", "index", ":", "continue", "\n", "if", "world", ".", "agents", "[", "other_good_id", "]", ".", "adversary", ":", "continue", "\n", "if", "self", ".", "is_collision", "(", "world", ".", "agents", "[", "other_good_id", "]", ",", "world", ".", "agents", "[", "other_id", "]", ")", ":", "\n", "                                ", "good_collide", "+=", "1", "\n", "rew", "+=", "5", "\n", "good_collide", "=", "0", "\n", "\n", "", "", "", "", "if", "num_collide", ">=", "2", ":", "\n", "                    ", "agent", ".", "live", "=", "False", "\n", "rew", "-=", "5", "\n", "\n", "", "distance_min", "=", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "world", ".", "agents", "[", "other_id", "]", ".", "state", ".", "p_pos", ")", ")", ")", "for", "other_id", "in", "agent", ".", "neighbors", "if", "world", ".", "agents", "[", "other_id", "]", ".", "adversary", "and", "world", ".", "agents", "[", "other_id", "]", ".", "live", "]", "\n", "if", "(", "len", "(", "distance_min", ")", ">", "0", ")", ":", "\n", "                    ", "rew", "-=", "min", "(", "distance_min", ")", "\n", "\n", "", "", "if", "agent", ".", "adversary", ":", "\n", "                ", "num_collide", "=", "0", "\n", "good_collide", "=", "0", "\n", "for", "other_id", "in", "agent", ".", "neighbors", ":", "\n", "                    ", "if", "not", "world", ".", "agents", "[", "other_id", "]", ".", "live", ":", "continue", "\n", "if", "self", ".", "is_collision", "(", "agent", ",", "world", ".", "agents", "[", "other_id", "]", ")", "and", "not", "world", ".", "agents", "[", "other_id", "]", ".", "adversary", ":", "\n", "                        ", "num_collide", "+=", "1", "\n", "good_collide", "+=", "1", "\n", "for", "other_good_id", "in", "agent", ".", "neighbors", ":", "\n", "                            ", "if", "not", "world", ".", "agents", "[", "other_good_id", "]", ".", "live", ":", "continue", "\n", "if", "other_good_id", "==", "other_id", "or", "other_good_id", "==", "index", ":", "continue", "\n", "if", "not", "world", ".", "agents", "[", "other_good_id", "]", ".", "adversary", ":", "continue", "\n", "if", "self", ".", "is_collision", "(", "world", ".", "agents", "[", "other_good_id", "]", ",", "world", ".", "agents", "[", "other_id", "]", ")", ":", "\n", "                                ", "good_collide", "+=", "1", "\n", "rew", "+=", "5", "\n", "good_collide", "=", "0", "\n", "\n", "", "", "", "", "if", "num_collide", ">=", "2", ":", "\n", "                    ", "agent", ".", "live", "=", "False", "\n", "rew", "-=", "5", "\n", "\n", "", "distance_min", "=", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "world", ".", "agents", "[", "other_id", "]", ".", "state", ".", "p_pos", ")", ")", ")", "for", "other_id", "in", "agent", ".", "neighbors", "if", "not", "world", ".", "agents", "[", "other_id", "]", ".", "adversary", "and", "world", ".", "agents", "[", "other_id", "]", ".", "live", "]", "\n", "if", "(", "len", "(", "distance_min", ")", ">", "0", ")", ":", "\n", "                    ", "rew", "-=", "min", "(", "distance_min", ")", "\n", "\n", "", "", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.adversarial_neighbor.Scenario.observation": [[217, 258], ["enumerate", "sorted", "range", "enumerate", "numpy.concatenate", "sorted.append", "entity_pos.append", "entity_pos.append", "entity_pos.append", "entity_pos.append", "numpy.sqrt", "int", "len", "range", "range", "range", "numpy.sum", "numpy.sum", "numpy.square", "numpy.square", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.concatenate", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "observation", "(", "self", ",", "index", ",", "world", ")", ":", "\n", "        ", "agent", "=", "world", ".", "agents", "[", "index", "]", "\n", "\n", "# get positions of all entities in this agent's reference frame", "\n", "if", "agent", ".", "adversary", ":", "\n", "            ", "max_neighbor", "=", "self", ".", "max_adv_neighbor", "\n", "neighbor_sight", "=", "self", ".", "adv_neigh_dist", "\n", "", "else", ":", "\n", "            ", "max_neighbor", "=", "self", ".", "max_good_neighbor", "\n", "neighbor_sight", "=", "self", ".", "good_neigh_dist", "\n", "\n", "", "dist", "=", "[", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "dist", ".", "append", "(", "(", "i", ",", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "landmark", ".", "state", ".", "p_pos", ")", ")", ")", ")", "\n", "", "dist", "=", "sorted", "(", "dist", ",", "key", "=", "lambda", "t", ":", "t", "[", "1", "]", ")", "\n", "entity_pos", "=", "[", "]", "\n", "\n", "for", "i", ",", "land_dist", "in", "dist", ":", "\n", "            ", "entity_pos", ".", "append", "(", "world", ".", "landmarks", "[", "i", "]", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "entity_pos", ".", "append", "(", "[", "0", "]", ")", "\n", "\n", "", "for", "j", "in", "range", "(", "int", "(", "max_neighbor", "/", "2", ")", "-", "len", "(", "world", ".", "landmarks", ")", ")", ":", "\n", "            ", "entity_pos", ".", "append", "(", "[", "0", ",", "0", "]", ")", "\n", "entity_pos", ".", "append", "(", "[", "0", "]", ")", "\n", "\n", "", "other_pos", "=", "[", "[", "0", ",", "0", "]", "for", "i", "in", "range", "(", "max_neighbor", "-", "1", ")", "]", "\n", "other_live", "=", "[", "[", "0", "]", "for", "i", "in", "range", "(", "max_neighbor", "-", "1", ")", "]", "\n", "other_vel", "=", "[", "[", "0", ",", "0", "]", "for", "i", "in", "range", "(", "max_neighbor", "-", "1", ")", "]", "\n", "num_neighbor", "=", "0", "\n", "\n", "for", "i", ",", "other", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "if", "other", "is", "agent", ":", "continue", "\n", "distance", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", ")", ")", "\n", "if", "distance", "<=", "neighbor_sight", "and", "num_neighbor", "<", "max_neighbor", "-", "1", ":", "\n", "                ", "other_vel", "[", "num_neighbor", "]", "=", "other", ".", "state", ".", "p_vel", "\n", "other_pos", "[", "num_neighbor", "]", "=", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", "\n", "other_live", "[", "num_neighbor", "]", "=", "[", "other", ".", "live", "]", "\n", "num_neighbor", "+=", "1", "\n", "\n", "# print(result.shape,\"shape#################\")", "\n", "", "", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "[", "agent", ".", "state", ".", "p_pos", "]", "+", "[", "np", ".", "array", "(", "[", "agent", ".", "live", "]", ")", "]", "+", "entity_pos", "+", "other_pos", "+", "other_vel", "+", "other_live", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.__init__": [[7, 22], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "n_good", ",", "n_adv", ",", "n_landmarks", ",", "n_food", ",", "n_forests", ",", "alpha", ",", "good_sight", ",", "adv_sight", ",", "no_wheel", ",", "ratio", ",", "max_good_neighbor", ",", "max_adv_neighbor", ")", ":", "\n", "        ", "self", ".", "n_good", "=", "n_good", "\n", "self", ".", "n_adv", "=", "n_adv", "\n", "self", ".", "n_landmarks", "=", "n_landmarks", "\n", "self", ".", "n_food", "=", "n_food", "\n", "self", ".", "n_forests", "=", "n_forests", "\n", "self", ".", "num_agents", "=", "n_adv", "+", "n_good", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "good_neigh_dist", "=", "good_sight", "\n", "self", ".", "adv_neigh_dist", "=", "adv_sight", "\n", "self", ".", "ratio", "=", "ratio", "\n", "self", ".", "size", "=", "ratio", "\n", "self", ".", "no_wheel", "=", "no_wheel", "\n", "self", ".", "max_good_neighbor", "=", "max_good_neighbor", "\n", "self", ".", "max_adv_neighbor", "=", "max_adv_neighbor", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.make_world": [[24, 59], ["mpe_local.multiagent.core.World", "enumerate", "enumerate", "simple_spread.Scenario.reset_world", "mpe_local.multiagent.core.Agent", "mpe_local.multiagent.core.Landmark", "range", "range"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.reset_world"], ["", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "world", ".", "dim_c", "=", "2", "\n", "world", ".", "size", "=", "self", ".", "ratio", "\n", "world", ".", "good_neigh_dist", "=", "self", ".", "good_neigh_dist", "\n", "world", ".", "adv_neigh_dist", "=", "self", ".", "adv_neigh_dist", "\n", "world", ".", "max_good_neighbor", "=", "self", ".", "max_good_neighbor", "\n", "world", ".", "max_adv_neighbor", "=", "self", ".", "max_adv_neighbor", "\n", "num_agents", "=", "self", ".", "n_good", "\n", "self", ".", "num_agents", "=", "num_agents", "\n", "num_landmarks", "=", "self", ".", "n_food", "\n", "world", ".", "collaborative", "=", "False", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", ")", "for", "i", "in", "range", "(", "num_agents", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "True", "\n", "agent", ".", "silent", "=", "True", "\n", "agent", ".", "size", "=", "0.05", "\n", "agent", ".", "live", "=", "1", "\n", "agent", ".", "adversary", "=", "False", "\n", "agent", ".", "max_speed", "=", "3", "\n", "\n", "# add landmarks", "\n", "", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_landmarks", ")", "]", "\n", "world", ".", "food", "=", "world", ".", "landmarks", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.03", "\n", "\n", "# make initial conditions", "\n", "", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.reset_world": [[60, 79], ["enumerate", "enumerate", "enumerate", "numpy.array", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.random.uniform", "numpy.zeros", "numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "# random properties for agents", "\n", "        ", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.35", ",", "0.35", ",", "0.85", "]", ")", "#np.random.uniform(0, 1, 3)", "\n", "# random properties for landmarks", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.25", "]", ")", "#world.agents[i].color", "\n", "# set random initial states", "\n", "", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "self", ".", "ratio", "*", "1", ",", "+", "self", ".", "ratio", "*", "1", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "self", ".", "ratio", "*", "1", ",", "+", "self", ".", "ratio", "*", "1", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n", "", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "dists", "=", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "landmark", ".", "state", ".", "p_pos", ")", ")", ")", "for", "landmark", "in", "world", ".", "landmarks", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.done": [[81, 83], ["None"], "methods", ["None"], ["", "", "def", "done", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.info": [[85, 87], ["None"], "methods", ["None"], ["", "def", "info", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision": [[88, 93], ["numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "is_collision", "(", "self", ",", "agent1", ",", "agent2", ")", ":", "\n", "        ", "delta_pos", "=", "agent1", ".", "state", ".", "p_pos", "-", "agent2", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "dist_min", "=", "agent1", ".", "size", "+", "agent2", ".", "size", "\n", "return", "True", "if", "dist", "<", "dist_min", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.reward": [[94, 106], ["min", "numpy.sqrt", "simple_spread.Scenario.is_collision", "simple_spread.Scenario.is_collision", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.min", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.is_collision", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "rew", "=", "0", "\n", "dists", "=", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "l", ".", "state", ".", "p_pos", ")", ")", ")", "for", "l", "in", "world", ".", "landmarks", "]", "\n", "rew", "-=", "min", "(", "dists", ")", "\n", "for", "food", "in", "world", ".", "landmarks", ":", "\n", "            ", "if", "self", ".", "is_collision", "(", "food", ",", "agent", ")", ":", "\n", "                ", "rew", "+=", "1", "\n", "", "", "for", "a", "in", "world", ".", "agents", ":", "\n", "            ", "if", "a", "==", "agent", ":", "continue", "\n", "if", "self", ".", "is_collision", "(", "a", ",", "agent", ")", ":", "\n", "                ", "rew", "-=", "1", "\n", "", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.observation": [[107, 136], ["enumerate", "sorted", "range", "enumerate", "numpy.concatenate", "sorted.append", "entity_pos.append", "entity_pos.append", "entity_pos.append", "entity_pos.append", "numpy.sqrt", "range", "range", "range", "numpy.sum", "numpy.sum", "numpy.square", "numpy.square", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.concatenate", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# current agent", "\n", "        ", "dist", "=", "[", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "dist", ".", "append", "(", "(", "i", ",", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "landmark", ".", "state", ".", "p_pos", ")", ")", ")", ")", "\n", "", "dist", "=", "sorted", "(", "dist", ",", "key", "=", "lambda", "t", ":", "t", "[", "1", "]", ")", "\n", "entity_pos", "=", "[", "]", "\n", "for", "i", ",", "land_dist", "in", "dist", ":", "\n", "            ", "entity_pos", ".", "append", "(", "world", ".", "landmarks", "[", "i", "]", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "entity_pos", ".", "append", "(", "[", "0", "]", ")", "\n", "\n", "", "for", "j", "in", "range", "(", "self", ".", "max_good_neighbor", "-", "self", ".", "num_agents", ")", ":", "\n", "            ", "entity_pos", ".", "append", "(", "[", "0", ",", "0", "]", ")", "\n", "entity_pos", ".", "append", "(", "[", "0", "]", ")", "\n", "\n", "", "other_pos", "=", "[", "[", "0", ",", "0", "]", "for", "i", "in", "range", "(", "self", ".", "max_good_neighbor", "-", "1", ")", "]", "\n", "other_live", "=", "[", "[", "0", "]", "for", "i", "in", "range", "(", "self", ".", "max_good_neighbor", "-", "1", ")", "]", "\n", "other_vel", "=", "[", "[", "0", ",", "0", "]", "for", "i", "in", "range", "(", "self", ".", "max_good_neighbor", "-", "1", ")", "]", "\n", "num_neighbor", "=", "0", "\n", "for", "i", ",", "other", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "if", "other", "is", "agent", ":", "continue", "\n", "distance", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", ")", ")", "\n", "if", "distance", "<=", "self", ".", "good_neigh_dist", "and", "num_neighbor", "<", "self", ".", "max_good_neighbor", "-", "1", ":", "\n", "                ", "other_vel", "[", "num_neighbor", "]", "=", "other", ".", "state", ".", "p_vel", "\n", "other_pos", "[", "num_neighbor", "]", "=", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", "\n", "other_live", "[", "num_neighbor", "]", "=", "[", "1", "]", "\n", "num_neighbor", "+=", "1", "\n", "\n", "", "", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "[", "agent", ".", "state", ".", "p_pos", "]", "+", "[", "np", ".", "array", "(", "[", "1", "]", ")", "]", "+", "entity_pos", "+", "other_pos", "+", "other_vel", "+", "other_live", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.maddpg_local.__init__.AgentTrainer.__init__": [[2, 4], ["NotImplemented"], "methods", ["None"], ["\n", "# Multiagent envs", "\n", "# ----------------------------------------", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.maddpg_local.__init__.AgentTrainer.action": [[5, 7], ["NotImplemented"], "methods", ["None"], ["\n", "# print(\"sada\")", "\n", "# register(", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.maddpg_local.__init__.AgentTrainer.process_experience": [[8, 10], ["NotImplemented"], "methods", ["None"], ["#     id='MultiagentSimple-v0',", "\n", "#     entry_point='multiagent.envs:SimpleEnv',", "\n", "#     # FIXME(cathywu) currently has to be exactly max_path_length parameters in", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.maddpg_local.__init__.AgentTrainer.preupdate": [[11, 13], ["NotImplemented"], "methods", ["None"], ["#     # rllab run script", "\n", "#     max_episode_steps=100,", "\n", "# )", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.maddpg_local.__init__.AgentTrainer.update": [[14, 16], ["NotImplemented"], "methods", ["None"], ["\n", "# register(", "\n", "#     id='MultiagentSimpleSpeakerListener-v0',", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_neighbor.MADDPGAgentTrainer.__init__": [[114, 160], ["len", "maddpg_o.BatchInput().get", "maddpg_neighbor.q_train", "maddpg_neighbor.p_train", "maddpg_o.maddpg_local.micro.replay_buffer_neighbor.ReplayBuffer", "maddpg_neighbor.MADDPGAgentTrainer.get_p_q_variables", "maddpg_neighbor.MADDPGAgentTrainer.assign_weight", "range", "maddpg_o.BatchInput", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer", "str"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.Uint8Input.get", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.q_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.PolicyTrainer.get_p_q_variables", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.PolicyTrainer.assign_weight"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "model", ",", "obs_shape_n", ",", "session", ",", "act_space_n", ",", "agent_index", ",", "args", ",", "local_q_func", "=", "False", ")", ":", "\n", "        ", "self", ".", "session", "=", "session", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "n", "=", "len", "(", "obs_shape_n", ")", "\n", "self", ".", "num_agents", "=", "args", ".", "num_agents", "\n", "self", ".", "max_neighbors", "=", "args", ".", "good_max_num_neighbors", "\n", "# print(self.max_neighbors - self.num_agents)", "\n", "# print(act_space_n)", "\n", "act_space_n", "+=", "[", "act_space_n", "[", "-", "1", "]", "for", "i", "in", "range", "(", "self", ".", "max_neighbors", "-", "self", ".", "num_agents", ")", "]", "\n", "self", ".", "agent_index", "=", "agent_index", "\n", "self", ".", "args", "=", "args", "\n", "#obs_ph = []", "\n", "#obs_ph_n = [U.BatchInput(obs_shape_n[i], name=\"observation\"+str(i)).get() for i in range()]", "\n", "#for i in range(self.n):", "\n", "obs_ph", "=", "U", ".", "BatchInput", "(", "obs_shape_n", "[", "self", ".", "agent_index", "]", ",", "name", "=", "\"observation\"", "+", "str", "(", "self", ".", "agent_index", ")", ")", ".", "get", "(", ")", "\n", "\n", "# Create all the functions necessary to train the model", "\n", "self", ".", "q_train", ",", "self", ".", "q_update", ",", "self", ".", "q_debug", "=", "q_train", "(", "\n", "scope", "=", "self", ".", "name", ",", "\n", "make_obs_ph", "=", "obs_ph", ",", "\n", "act_space_n", "=", "act_space_n", ",", "\n", "q_index", "=", "agent_index", ",", "\n", "q_func", "=", "model", ",", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "args", ".", "lr", ")", ",", "\n", "grad_norm_clipping", "=", "0.5", ",", "\n", "local_q_func", "=", "local_q_func", ",", "\n", "num_units", "=", "args", ".", "num_units", "\n", ")", "\n", "self", ".", "act", ",", "self", ".", "p_train", ",", "self", ".", "p_update", ",", "self", ".", "p_debug", "=", "p_train", "(", "\n", "scope", "=", "self", ".", "name", ",", "\n", "make_obs_ph", "=", "obs_ph", ",", "\n", "act_space_n", "=", "act_space_n", ",", "\n", "p_index", "=", "agent_index", ",", "\n", "p_func", "=", "model", ",", "\n", "q_func", "=", "model", ",", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "args", ".", "lr", ")", ",", "\n", "grad_norm_clipping", "=", "0.5", ",", "\n", "local_q_func", "=", "local_q_func", ",", "\n", "num_units", "=", "args", ".", "num_units", "\n", ")", "\n", "# Create experience buffer", "\n", "self", ".", "replay_buffer", "=", "ReplayBuffer", "(", "1e6", ",", "self", ".", "num_agents", ",", "self", ".", "max_neighbors", ",", "self", ".", "agent_index", ")", "\n", "self", ".", "max_replay_buffer_len", "=", "args", ".", "batch_size", "*", "args", ".", "max_episode_len", "\n", "self", ".", "replay_sample_index", "=", "None", "\n", "self", ".", "get_p_q_variables", "(", ")", "\n", "self", ".", "assign_weight", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_neighbor.MADDPGAgentTrainer.action": [[161, 164], ["maddpg_neighbor.MADDPGAgentTrainer.act"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "obs", ")", ":", "\n", "\n", "        ", "return", "self", ".", "act", "(", "obs", "[", "None", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_neighbor.MADDPGAgentTrainer.target_action": [[166, 169], ["None"], "methods", ["None"], ["", "def", "target_action", "(", "self", ",", "obs", ")", ":", "\n", "\n", "        ", "return", "self", ".", "p_debug", "[", "'target_act'", "]", "(", "obs", "[", "None", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_neighbor.MADDPGAgentTrainer.get_p_q_variables": [[170, 176], ["tensorflow.variable_scope", "maddpg_o.scope_vars", "maddpg_o.scope_vars", "maddpg_o.scope_vars", "maddpg_o.scope_vars", "maddpg_o.absolute_scope_name", "maddpg_o.absolute_scope_name", "maddpg_o.absolute_scope_name", "maddpg_o.absolute_scope_name"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name"], ["", "def", "get_p_q_variables", "(", "self", ",", "reuse", "=", "True", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "name", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "self", ".", "p_variables", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"p_func\"", ")", ")", "\n", "self", ".", "target_p_variables", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_p_func\"", ")", ")", "\n", "self", ".", "q_variables", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"q_func\"", ")", ")", "\n", "self", ".", "target_q_variables", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_q_func\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_neighbor.MADDPGAgentTrainer.get_weigths": [[177, 184], ["dict", "maddpg_neighbor.MADDPGAgentTrainer.session.run", "maddpg_neighbor.MADDPGAgentTrainer.session.run"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run"], ["", "", "def", "get_weigths", "(", "self", ")", ":", "\n", "        ", "weigths_dict", "=", "dict", "(", ")", "\n", "weigths_dict", "[", "'p_variables'", "]", "=", "self", ".", "session", ".", "run", "(", "self", ".", "p_variables", ")", "\n", "weigths_dict", "[", "'target_p_variables'", "]", "=", "self", ".", "session", ".", "run", "(", "self", ".", "target_p_variables", ")", "\n", "# weigths_dict['q_variables']=self.session.run(self.q_variables)", "\n", "# weigths_dict['target_q_variables']=self.session.run(self.target_q_variables)", "\n", "return", "weigths_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_neighbor.MADDPGAgentTrainer.get_all_weights": [[185, 192], ["dict", "maddpg_neighbor.MADDPGAgentTrainer.session.run", "maddpg_neighbor.MADDPGAgentTrainer.session.run", "maddpg_neighbor.MADDPGAgentTrainer.session.run", "maddpg_neighbor.MADDPGAgentTrainer.session.run"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run"], ["", "def", "get_all_weights", "(", "self", ")", ":", "\n", "        ", "weigths_dict", "=", "dict", "(", ")", "\n", "weigths_dict", "[", "'p_variables'", "]", "=", "self", ".", "session", ".", "run", "(", "self", ".", "p_variables", ")", "\n", "weigths_dict", "[", "'target_p_variables'", "]", "=", "self", ".", "session", ".", "run", "(", "self", ".", "target_p_variables", ")", "\n", "weigths_dict", "[", "'q_variables'", "]", "=", "self", ".", "session", ".", "run", "(", "self", ".", "q_variables", ")", "\n", "weigths_dict", "[", "'target_q_variables'", "]", "=", "self", ".", "session", ".", "run", "(", "self", ".", "target_q_variables", ")", "\n", "return", "weigths_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_neighbor.MADDPGAgentTrainer.assign_weight": [[193, 223], ["dict", "len", "len", "range", "range", "range", "range", "maddpg_neighbor.MADDPGAgentTrainer.x.append", "maddpg_neighbor.MADDPGAgentTrainer.assign_op[].append", "maddpg_neighbor.MADDPGAgentTrainer.y.append", "maddpg_neighbor.MADDPGAgentTrainer.assign_op[].append", "maddpg_neighbor.MADDPGAgentTrainer.z.append", "maddpg_neighbor.MADDPGAgentTrainer.assign_op[].append", "maddpg_neighbor.MADDPGAgentTrainer.w.append", "maddpg_neighbor.MADDPGAgentTrainer.assign_op[].append", "tensorflow.placeholder", "maddpg_neighbor.MADDPGAgentTrainer.p_variables[].assign", "tensorflow.placeholder", "maddpg_neighbor.MADDPGAgentTrainer.target_p_variables[].assign", "tensorflow.placeholder", "maddpg_neighbor.MADDPGAgentTrainer.q_variables[].assign", "tensorflow.placeholder", "maddpg_neighbor.MADDPGAgentTrainer.target_q_variables[].assign", "maddpg_neighbor.MADDPGAgentTrainer.p_variables[].get_shape", "maddpg_neighbor.MADDPGAgentTrainer.target_p_variables[].get_shape", "maddpg_neighbor.MADDPGAgentTrainer.q_variables[].get_shape", "maddpg_neighbor.MADDPGAgentTrainer.target_q_variables[].get_shape"], "methods", ["None"], ["", "def", "assign_weight", "(", "self", ")", ":", "\n", "        ", "self", ".", "assign_op", "=", "dict", "(", ")", "\n", "self", ".", "assign_op", "[", "'p_variables'", "]", "=", "[", "]", "\n", "self", ".", "assign_op", "[", "'target_p_variables'", "]", "=", "[", "]", "\n", "self", ".", "assign_op", "[", "'q_variables'", "]", "=", "[", "]", "\n", "self", ".", "assign_op", "[", "'target_q_variables'", "]", "=", "[", "]", "\n", "\n", "k1", "=", "len", "(", "self", ".", "p_variables", ")", "\n", "k2", "=", "len", "(", "self", ".", "q_variables", ")", "\n", "\n", "self", ".", "x", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k1", ")", ":", "\n", "            ", "self", ".", "x", ".", "append", "(", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "self", ".", "p_variables", "[", "i", "]", ".", "get_shape", "(", ")", ")", ")", "\n", "self", ".", "assign_op", "[", "'p_variables'", "]", ".", "append", "(", "self", ".", "p_variables", "[", "i", "]", ".", "assign", "(", "self", ".", "x", "[", "i", "]", ")", ")", "\n", "\n", "", "self", ".", "y", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k1", ")", ":", "\n", "            ", "self", ".", "y", ".", "append", "(", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "self", ".", "target_p_variables", "[", "i", "]", ".", "get_shape", "(", ")", ")", ")", "\n", "self", ".", "assign_op", "[", "'target_p_variables'", "]", ".", "append", "(", "self", ".", "target_p_variables", "[", "i", "]", ".", "assign", "(", "self", ".", "y", "[", "i", "]", ")", ")", "\n", "\n", "\n", "", "self", ".", "z", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k2", ")", ":", "\n", "            ", "self", ".", "z", ".", "append", "(", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "self", ".", "q_variables", "[", "i", "]", ".", "get_shape", "(", ")", ")", ")", "\n", "self", ".", "assign_op", "[", "'q_variables'", "]", ".", "append", "(", "self", ".", "q_variables", "[", "i", "]", ".", "assign", "(", "self", ".", "z", "[", "i", "]", ")", ")", "\n", "\n", "", "self", ".", "w", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k2", ")", ":", "\n", "            ", "self", ".", "w", ".", "append", "(", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "self", ".", "target_q_variables", "[", "i", "]", ".", "get_shape", "(", ")", ")", ")", "\n", "self", ".", "assign_op", "[", "'target_q_variables'", "]", ".", "append", "(", "self", ".", "target_q_variables", "[", "i", "]", ".", "assign", "(", "self", ".", "w", "[", "i", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_neighbor.MADDPGAgentTrainer.set_weigths": [[226, 232], ["enumerate", "enumerate", "maddpg_neighbor.MADDPGAgentTrainer.session.run", "maddpg_neighbor.MADDPGAgentTrainer.session.run"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run"], ["", "", "def", "set_weigths", "(", "self", ",", "weight_dict", ")", ":", "\n", "        ", "for", "i", ",", "weight", "in", "enumerate", "(", "weight_dict", "[", "'p_variables'", "]", ")", ":", "\n", "            ", "self", ".", "session", ".", "run", "(", "self", ".", "assign_op", "[", "'p_variables'", "]", "[", "i", "]", ",", "feed_dict", "=", "{", "self", ".", "x", "[", "i", "]", ":", "weight", "}", ")", "\n", "\n", "", "for", "i", ",", "weight", "in", "enumerate", "(", "weight_dict", "[", "'target_p_variables'", "]", ")", ":", "\n", "            ", "self", ".", "session", ".", "run", "(", "self", ".", "assign_op", "[", "'target_p_variables'", "]", "[", "i", "]", ",", "feed_dict", "=", "{", "self", ".", "y", "[", "i", "]", ":", "weight", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_neighbor.MADDPGAgentTrainer.set_all_weights": [[241, 253], ["enumerate", "enumerate", "enumerate", "enumerate", "maddpg_neighbor.MADDPGAgentTrainer.session.run", "maddpg_neighbor.MADDPGAgentTrainer.session.run", "maddpg_neighbor.MADDPGAgentTrainer.session.run", "maddpg_neighbor.MADDPGAgentTrainer.session.run"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run"], ["", "", "def", "set_all_weights", "(", "self", ",", "weight_dict", ")", ":", "\n", "        ", "for", "i", ",", "weight", "in", "enumerate", "(", "weight_dict", "[", "'p_variables'", "]", ")", ":", "\n", "            ", "self", ".", "session", ".", "run", "(", "self", ".", "assign_op", "[", "'p_variables'", "]", "[", "i", "]", ",", "feed_dict", "=", "{", "self", ".", "x", "[", "i", "]", ":", "weight", "}", ")", "\n", "\n", "", "for", "i", ",", "weight", "in", "enumerate", "(", "weight_dict", "[", "'target_p_variables'", "]", ")", ":", "\n", "            ", "self", ".", "session", ".", "run", "(", "self", ".", "assign_op", "[", "'target_p_variables'", "]", "[", "i", "]", ",", "feed_dict", "=", "{", "self", ".", "y", "[", "i", "]", ":", "weight", "}", ")", "\n", "\n", "", "for", "i", ",", "weight", "in", "enumerate", "(", "weight_dict", "[", "'q_variables'", "]", ")", ":", "\n", "            ", "self", ".", "session", ".", "run", "(", "self", ".", "assign_op", "[", "'q_variables'", "]", "[", "i", "]", ",", "feed_dict", "=", "{", "self", ".", "z", "[", "i", "]", ":", "weight", "}", ")", "\n", "\n", "", "for", "i", ",", "weight", "in", "enumerate", "(", "weight_dict", "[", "'target_q_variables'", "]", ")", ":", "\n", "            ", "self", ".", "session", ".", "run", "(", "self", ".", "assign_op", "[", "'target_q_variables'", "]", "[", "i", "]", ",", "feed_dict", "=", "{", "self", ".", "w", "[", "i", "]", ":", "weight", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_neighbor.MADDPGAgentTrainer.experience": [[254, 257], ["maddpg_neighbor.MADDPGAgentTrainer.replay_buffer.add"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.add"], ["", "", "def", "experience", "(", "self", ",", "obs", ",", "action_n", ",", "new_obs", ",", "target_action_n", ",", "rew", ")", ":", "\n", "# Store transition in the replay buffer.", "\n", "        ", "self", ".", "replay_buffer", ".", "add", "(", "obs", ",", "action_n", ",", "new_obs", ",", "target_action_n", ",", "rew", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_neighbor.MADDPGAgentTrainer.preupdate": [[259, 261], ["None"], "methods", ["None"], ["", "def", "preupdate", "(", "self", ")", ":", "\n", "        ", "self", ".", "replay_sample_index", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_neighbor.MADDPGAgentTrainer.update": [[263, 285], ["maddpg_neighbor.MADDPGAgentTrainer.replay_buffer.make_index", "maddpg_neighbor.MADDPGAgentTrainer.replay_buffer.sample_index", "maddpg_neighbor.MADDPGAgentTrainer.q_train", "maddpg_neighbor.MADDPGAgentTrainer.p_train", "maddpg_neighbor.MADDPGAgentTrainer.p_update", "maddpg_neighbor.MADDPGAgentTrainer.q_update", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.std"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.make_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.q_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.std"], ["", "def", "update", "(", "self", ",", "agents", ")", ":", "\n", "\n", "#learning_start_time = time.time()", "\n", "        ", "self", ".", "replay_sample_index", "=", "self", ".", "replay_buffer", ".", "make_index", "(", "1024", ")", "\n", "# collect replay sample from all agents", "\n", "target_q", "=", "0.0", "\n", "index", "=", "self", ".", "replay_sample_index", "\n", "obss", ",", "act_ns", ",", "next_obss", ",", "target_action_ns", ",", "rews", "=", "self", ".", "replay_buffer", ".", "sample_index", "(", "index", ",", "agents", ")", "\n", "# concat_next_obss = next_obss", "\n", "# concat_obss = obss", "\n", "\n", "# target_action_ns = [agents[i%self.num_agents].p_debug['target_act'](concat_next_obss[i]) for i in range(self.n)]", "\n", "target_q_next", "=", "self", ".", "q_debug", "[", "'target_q_values'", "]", "(", "*", "(", "next_obss", "+", "target_action_ns", ")", ")", "\n", "target_q", "+=", "rews", "+", "self", ".", "args", ".", "gamma", "*", "target_q_next", "\n", "\n", "q_loss", "=", "self", ".", "q_train", "(", "*", "(", "obss", "+", "act_ns", "+", "[", "target_q", "]", ")", ")", "\n", "# train p network", "\n", "p_loss", "=", "self", ".", "p_train", "(", "*", "(", "obss", "+", "act_ns", ")", ")", "\n", "self", ".", "p_update", "(", ")", "\n", "self", ".", "q_update", "(", ")", "\n", "\n", "return", "[", "q_loss", ",", "p_loss", ",", "np", ".", "mean", "(", "target_q", ")", ",", "np", ".", "mean", "(", "rews", ")", ",", "np", ".", "mean", "(", "target_q_next", ")", ",", "np", ".", "std", "(", "target_q", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_neighbor.discount_with_dones": [[9, 17], ["zip", "discounted.append"], "function", ["None"], ["def", "discount_with_dones", "(", "rewards", ",", "dones", ",", "gamma", ")", ":", "\n", "    ", "discounted", "=", "[", "]", "\n", "r", "=", "0", "\n", "for", "reward", ",", "done", "in", "zip", "(", "rewards", "[", ":", ":", "-", "1", "]", ",", "dones", "[", ":", ":", "-", "1", "]", ")", ":", "\n", "        ", "r", "=", "reward", "+", "gamma", "*", "r", "\n", "r", "=", "r", "*", "(", "1.", "-", "done", ")", "\n", "discounted", ".", "append", "(", "r", ")", "\n", "", "return", "discounted", "[", ":", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_neighbor.make_update_exp": [[18, 25], ["zip", "tensorflow.group", "maddpg_o.function", "sorted", "sorted", "tf.group.append", "var_target.assign"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function"], ["", "def", "make_update_exp", "(", "vals", ",", "target_vals", ")", ":", "\n", "    ", "polyak", "=", "1.0", "-", "1e-2", "\n", "expression", "=", "[", "]", "\n", "for", "var", ",", "var_target", "in", "zip", "(", "sorted", "(", "vals", ",", "key", "=", "lambda", "v", ":", "v", ".", "name", ")", ",", "sorted", "(", "target_vals", ",", "key", "=", "lambda", "v", ":", "v", ".", "name", ")", ")", ":", "\n", "        ", "expression", ".", "append", "(", "var_target", ".", "assign", "(", "polyak", "*", "var_target", "+", "(", "1.0", "-", "polyak", ")", "*", "var", ")", ")", "\n", "", "expression", "=", "tf", ".", "group", "(", "*", "expression", ")", "\n", "return", "U", ".", "function", "(", "[", "]", ",", "[", "]", ",", "updates", "=", "[", "expression", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_neighbor.p_train": [[26, 74], ["tensorflow.variable_scope", "p_func", "maddpg_o.scope_vars", "act_pdtype_n[].pdfromflat", "act_pdtype_n[].pdfromflat.sample", "tensorflow.reduce_mean", "act_pdtype_n[].pdfromflat.sample", "tensorflow.concat", "maddpg_o.minimize_and_clip", "maddpg_o.function", "maddpg_o.function", "maddpg_o.function", "p_func", "maddpg_o.scope_vars", "maddpg_neighbor.make_update_exp", "act_pdtype_n[].pdfromflat().sample", "maddpg_o.function", "maddpg_o.maddpg_local.common.distributions.make_pdtype", "act_pdtype_n[].sample_placeholder", "int", "maddpg_o.absolute_scope_name", "tensorflow.square", "q_func", "tensorflow.reduce_mean", "int", "maddpg_o.absolute_scope_name", "range", "act_pdtype_n[].pdfromflat.flatparam", "act_pdtype_n[].pdfromflat", "len", "act_pdtype_n[].param_shape", "act_pdtype_n[].param_shape", "str"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.minimize_and_clip", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.make_update_exp", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.make_pdtype", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.flatparam", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape"], ["", "def", "p_train", "(", "make_obs_ph", ",", "act_space_n", ",", "p_index", ",", "p_func", ",", "q_func", ",", "optimizer", ",", "grad_norm_clipping", "=", "None", ",", "local_q_func", "=", "False", ",", "num_units", "=", "64", ",", "scope", "=", "\"trainer\"", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "# create distribtuions", "\n", "        ", "act_pdtype_n", "=", "[", "make_pdtype", "(", "act_space", ")", "for", "act_space", "in", "act_space_n", "]", "\n", "\n", "# set up placeholders", "\n", "obs_ph", "=", "make_obs_ph", "\n", "act_ph_n", "=", "[", "act_pdtype_n", "[", "i", "]", ".", "sample_placeholder", "(", "[", "None", "]", ",", "name", "=", "\"action\"", "+", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "act_space_n", ")", ")", "]", "\n", "\n", "p_input", "=", "obs_ph", "\n", "\n", "p", "=", "p_func", "(", "p_input", ",", "int", "(", "act_pdtype_n", "[", "0", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "p_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"p_func\"", ")", ")", "\n", "\n", "# wrap parameters in distribution", "\n", "act_pd", "=", "act_pdtype_n", "[", "0", "]", ".", "pdfromflat", "(", "p", ")", "\n", "\n", "act_sample", "=", "act_pd", ".", "sample", "(", ")", "\n", "p_reg", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "act_pd", ".", "flatparam", "(", ")", ")", ")", "\n", "\n", "act_input_n", "=", "act_ph_n", "+", "[", "]", "\n", "act_input_n", "[", "0", "]", "=", "act_pd", ".", "sample", "(", ")", "\n", "q_input", "=", "tf", ".", "concat", "(", "[", "obs_ph", "]", "+", "act_input_n", ",", "1", ")", "\n", "#q_input = tf.concat(obs_ph_n + act_input_n, 1)", "\n", "# if local_q_func:", "\n", "#     q_input = tf.concat([obs_ph_n[p_index]] + act_input_n, 1)", "\n", "\n", "q", "=", "q_func", "(", "q_input", ",", "1", ",", "scope", "=", "\"q_func\"", ",", "reuse", "=", "True", ",", "num_units", "=", "num_units", ")", "[", ":", ",", "0", "]", "\n", "pg_loss", "=", "-", "tf", ".", "reduce_mean", "(", "q", ")", "\n", "\n", "loss", "=", "pg_loss", "+", "p_reg", "*", "1e-3", "\n", "\n", "optimize_expr", "=", "U", ".", "minimize_and_clip", "(", "optimizer", ",", "loss", ",", "p_func_vars", ",", "grad_norm_clipping", ")", "\n", "\n", "# Create callable functions", "\n", "train", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph", "]", "+", "act_ph_n", ",", "outputs", "=", "loss", ",", "updates", "=", "[", "optimize_expr", "]", ")", "\n", "act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph", "]", ",", "outputs", "=", "act_sample", ")", "\n", "p_values", "=", "U", ".", "function", "(", "[", "obs_ph", "]", ",", "p", ")", "\n", "\n", "# target network", "\n", "target_p", "=", "p_func", "(", "p_input", ",", "int", "(", "act_pdtype_n", "[", "0", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"target_p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "target_p_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_p_func\"", ")", ")", "\n", "update_target_p", "=", "make_update_exp", "(", "p_func_vars", ",", "target_p_func_vars", ")", "\n", "\n", "target_act_sample", "=", "act_pdtype_n", "[", "0", "]", ".", "pdfromflat", "(", "target_p", ")", ".", "sample", "(", ")", "\n", "target_act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph", "]", ",", "outputs", "=", "target_act_sample", ")", "\n", "\n", "return", "act", ",", "train", ",", "update_target_p", ",", "{", "'p_values'", ":", "p_values", ",", "'target_act'", ":", "target_act", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_neighbor.q_train": [[75, 112], ["tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.concat", "maddpg_o.scope_vars", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "maddpg_o.minimize_and_clip", "maddpg_o.function", "maddpg_o.function", "maddpg_o.scope_vars", "maddpg_neighbor.make_update_exp", "maddpg_o.function", "maddpg_o.maddpg_local.common.distributions.make_pdtype", "act_pdtype_n[].sample_placeholder", "q_func", "maddpg_o.absolute_scope_name", "tensorflow.square", "tensorflow.square", "q_func", "maddpg_o.absolute_scope_name", "range", "len", "str"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.minimize_and_clip", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.make_update_exp", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.make_pdtype", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name"], ["", "", "def", "q_train", "(", "make_obs_ph", ",", "act_space_n", ",", "q_index", ",", "q_func", ",", "optimizer", ",", "grad_norm_clipping", "=", "None", ",", "local_q_func", "=", "False", ",", "scope", "=", "\"trainer\"", ",", "reuse", "=", "None", ",", "num_units", "=", "64", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "# create distribtuions", "\n", "        ", "act_pdtype_n", "=", "[", "make_pdtype", "(", "act_space", ")", "for", "act_space", "in", "act_space_n", "]", "\n", "\n", "# set up placeholders", "\n", "obs_ph", "=", "make_obs_ph", "\n", "act_ph_n", "=", "[", "act_pdtype_n", "[", "i", "]", ".", "sample_placeholder", "(", "[", "None", "]", ",", "name", "=", "\"action\"", "+", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "act_space_n", ")", ")", "]", "\n", "target_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ",", "name", "=", "\"target\"", ")", "\n", "\n", "q_input", "=", "tf", ".", "concat", "(", "[", "obs_ph", "]", "+", "act_ph_n", ",", "1", ")", "\n", "#q_input = tf.concat(obs_ph_n + act_ph_n, 1)", "\n", "# if local_q_func:", "\n", "#     q_input = tf.concat([obs_ph_n[q_index], act_ph_n[q_index]], 1)", "\n", "q", "=", "q_func", "(", "q_input", ",", "1", ",", "scope", "=", "\"q_func\"", ",", "num_units", "=", "num_units", ")", "[", ":", ",", "0", "]", "\n", "q_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"q_func\"", ")", ")", "\n", "\n", "q_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "q", "-", "target_ph", ")", ")", "\n", "\n", "# viscosity solution to Bellman differential equation in place of an initial condition", "\n", "q_reg", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "q", ")", ")", "\n", "loss", "=", "q_loss", "#+ 1e-3 * q_reg", "\n", "\n", "optimize_expr", "=", "U", ".", "minimize_and_clip", "(", "optimizer", ",", "loss", ",", "q_func_vars", ",", "grad_norm_clipping", ")", "\n", "\n", "# Create callable functions", "\n", "train", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph", "]", "+", "act_ph_n", "+", "[", "target_ph", "]", ",", "outputs", "=", "loss", ",", "updates", "=", "[", "optimize_expr", "]", ")", "\n", "q_values", "=", "U", ".", "function", "(", "[", "obs_ph", "]", "+", "act_ph_n", ",", "q", ")", "\n", "\n", "# target network", "\n", "target_q", "=", "q_func", "(", "q_input", ",", "1", ",", "scope", "=", "\"target_q_func\"", ",", "num_units", "=", "num_units", ")", "[", ":", ",", "0", "]", "\n", "target_q_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_q_func\"", ")", ")", "\n", "update_target_q", "=", "make_update_exp", "(", "q_func_vars", ",", "target_q_func_vars", ")", "\n", "\n", "target_q_values", "=", "U", ".", "function", "(", "[", "obs_ph", "]", "+", "act_ph_n", ",", "target_q", ")", "\n", "\n", "return", "train", ",", "update_target_q", ",", "{", "'q_values'", ":", "q_values", ",", "'target_q_values'", ":", "target_q_values", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.replay_buffer_neighbor.ReplayBuffer.__init__": [[5, 20], ["int"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "num_agents", ",", "max_neighbors", ",", "agent_index", ")", ":", "\n", "        ", "\"\"\"Create Prioritized Replay buffer.\n\n        Parameters\n        ----------\n        size: int\n            Max number of transitions to store in the buffer. When the buffer\n            overflows the old memories are dropped.\n        \"\"\"", "\n", "self", ".", "_storage", "=", "[", "]", "\n", "self", ".", "_maxsize", "=", "int", "(", "size", ")", "\n", "self", ".", "_next_idx", "=", "0", "\n", "self", ".", "num_agents", "=", "num_agents", "\n", "self", ".", "max_neighbors", "=", "max_neighbors", "\n", "self", ".", "agent_index", "=", "agent_index", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.replay_buffer_neighbor.ReplayBuffer.__len__": [[21, 23], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_storage", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.replay_buffer_neighbor.ReplayBuffer.clear": [[24, 27], ["None"], "methods", ["None"], ["", "def", "clear", "(", "self", ")", ":", "\n", "        ", "self", ".", "_storage", "=", "[", "]", "\n", "self", ".", "_next_idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.replay_buffer_neighbor.ReplayBuffer.add": [[28, 36], ["len", "replay_buffer_neighbor.ReplayBuffer._storage.append"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "obs", ",", "action_n", ",", "new_obs", ",", "target_action_n", ",", "rew", ")", ":", "\n", "        ", "data", "=", "(", "obs", ",", "action_n", ",", "new_obs", ",", "target_action_n", ",", "rew", ")", "\n", "\n", "if", "self", ".", "_next_idx", ">=", "len", "(", "self", ".", "_storage", ")", ":", "\n", "            ", "self", ".", "_storage", ".", "append", "(", "data", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_storage", "[", "self", ".", "_next_idx", "]", "=", "data", "\n", "", "self", ".", "_next_idx", "=", "(", "self", ".", "_next_idx", "+", "1", ")", "%", "self", ".", "_maxsize", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.replay_buffer_neighbor.ReplayBuffer._encode_sample": [[37, 65], ["obss[].append", "new_obss[].append", "range", "rews.append", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "range", "range", "obs.tolist", "new_obs.tolist", "target_action_ns[].append", "action_ns[].append", "target_action_n[].tolist", "action_n[].tolist"], "methods", ["None"], ["", "def", "_encode_sample", "(", "self", ",", "idxes", ",", "agents", ")", ":", "\n", "#obss, action_ns, new_obss, target_action_ns, rews = [], [], [], [], []", "\n", "        ", "target_action_ns", "=", "[", "[", "]", "for", "i", "in", "range", "(", "self", ".", "max_neighbors", ")", "]", "\n", "action_ns", "=", "[", "[", "]", "for", "i", "in", "range", "(", "self", ".", "max_neighbors", ")", "]", "\n", "obss", "=", "[", "[", "]", "]", "\n", "new_obss", "=", "[", "[", "]", "]", "\n", "rews", "=", "[", "]", "\n", "\n", "for", "i", "in", "idxes", ":", "\n", "            ", "data", "=", "self", ".", "_storage", "[", "i", "]", "\n", "obs", ",", "action_n", ",", "new_obs", ",", "target_action_n", ",", "rew", "=", "data", "\n", "obss", "[", "0", "]", ".", "append", "(", "obs", ".", "tolist", "(", ")", ")", "\n", "new_obss", "[", "0", "]", ".", "append", "(", "new_obs", ".", "tolist", "(", ")", ")", "\n", "\n", "for", "j", "in", "range", "(", "self", ".", "max_neighbors", ")", ":", "\n", "                ", "target_action_ns", "[", "j", "]", ".", "append", "(", "target_action_n", "[", "j", "]", ".", "tolist", "(", ")", ")", "\n", "action_ns", "[", "j", "]", ".", "append", "(", "action_n", "[", "j", "]", ".", "tolist", "(", ")", ")", "\n", "\n", "", "rews", ".", "append", "(", "rew", ")", "\n", "\n", "", "target_action_array", "=", "[", "np", ".", "array", "(", "value", ")", "for", "value", "in", "target_action_ns", "]", "\n", "#print(target_action_array)", "\n", "action_array", "=", "[", "np", ".", "array", "(", "value", ")", "for", "value", "in", "action_ns", "]", "\n", "#print(action_array)", "\n", "obss_array", "=", "[", "np", ".", "array", "(", "value", ")", "for", "value", "in", "obss", "]", "\n", "new_obss_array", "=", "[", "np", ".", "array", "(", "value", ")", "for", "value", "in", "new_obss", "]", "\n", "\n", "return", "obss_array", ",", "action_array", ",", "new_obss_array", ",", "target_action_array", ",", "np", ".", "array", "(", "rews", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.replay_buffer_neighbor.ReplayBuffer.make_index": [[66, 68], ["random.randint", "range", "len"], "methods", ["None"], ["", "def", "make_index", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "return", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_storage", ")", "-", "1", ")", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.replay_buffer_neighbor.ReplayBuffer.make_latest_index": [[69, 73], ["numpy.random.shuffle", "range"], "methods", ["None"], ["", "def", "make_latest_index", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "idx", "=", "[", "(", "self", ".", "_next_idx", "-", "1", "-", "i", ")", "%", "self", ".", "_maxsize", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "np", ".", "random", ".", "shuffle", "(", "idx", ")", "\n", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.replay_buffer_neighbor.ReplayBuffer.sample_index": [[74, 76], ["replay_buffer_neighbor.ReplayBuffer._encode_sample"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer._encode_sample"], ["", "def", "sample_index", "(", "self", ",", "idxes", ",", "agents", ")", ":", "\n", "        ", "return", "self", ".", "_encode_sample", "(", "idxes", ",", "agents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.replay_buffer_neighbor.ReplayBuffer.sample": [[77, 104], ["replay_buffer_neighbor.ReplayBuffer._encode_sample", "replay_buffer_neighbor.ReplayBuffer.make_index", "range", "len"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer._encode_sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.make_index"], ["", "def", "sample", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"Sample a batch of experiences.\n\n        Parameters\n        ----------\n        batch_size: int\n            How many transitions to sample.\n\n        Returns\n        -------\n        obs_batch: np.array\n            batch of observations\n        act_batch: np.array\n            batch of actions executed given obs_batch\n        rew_batch: np.array\n            rewards received as results of executing act_batch\n        next_obs_batch: np.array\n            next set of observations seen after executing act_batch\n        done_mask: np.array\n            done_mask[i] = 1 if executing act_batch[i] resulted in\n            the end of an episode and 0 otherwise.\n        \"\"\"", "\n", "if", "batch_size", ">", "0", ":", "\n", "            ", "idxes", "=", "self", ".", "make_index", "(", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "idxes", "=", "range", "(", "0", ",", "len", "(", "self", ".", "_storage", ")", ")", "\n", "", "return", "self", ".", "_encode_sample", "(", "idxes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.replay_buffer_neighbor.ReplayBuffer.collect": [[105, 107], ["replay_buffer_neighbor.ReplayBuffer.sample"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample"], ["", "def", "collect", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sample", "(", "-", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.n_replay_buffer.ReplayBuffer.__init__": [[5, 17], ["int"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "\"\"\"Create Prioritized Replay buffer.\n\n        Parameters\n        ----------\n        size: int\n            Max number of transitions to store in the buffer. When the buffer\n            overflows the old memories are dropped.\n        \"\"\"", "\n", "self", ".", "_storage", "=", "[", "]", "\n", "self", ".", "_maxsize", "=", "int", "(", "size", ")", "\n", "self", ".", "_next_idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.n_replay_buffer.ReplayBuffer.__len__": [[18, 20], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_storage", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.n_replay_buffer.ReplayBuffer.clear": [[21, 24], ["None"], "methods", ["None"], ["", "def", "clear", "(", "self", ")", ":", "\n", "        ", "self", ".", "_storage", "=", "[", "]", "\n", "self", ".", "_next_idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.n_replay_buffer.ReplayBuffer.add": [[25, 33], ["len", "n_replay_buffer.ReplayBuffer._storage.append"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "obs_n", ",", "action_n", ",", "reward", ",", "obs_next_n", ",", "done", ")", ":", "\n", "        ", "data", "=", "(", "obs_n", ",", "action_n", ",", "reward", ",", "obs_next_n", ",", "done", ")", "\n", "\n", "if", "self", ".", "_next_idx", ">=", "len", "(", "self", ".", "_storage", ")", ":", "\n", "            ", "self", ".", "_storage", ".", "append", "(", "data", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_storage", "[", "self", ".", "_next_idx", "]", "=", "data", "\n", "", "self", ".", "_next_idx", "=", "(", "self", ".", "_next_idx", "+", "1", ")", "%", "self", ".", "_maxsize", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.n_replay_buffer.ReplayBuffer._encode_sample": [[34, 45], ["obs_ns.append", "action_ns.append", "rewards.append", "obs_next_ns.append", "dones.append", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "_encode_sample", "(", "self", ",", "idxes", ")", ":", "\n", "        ", "obs_ns", ",", "action_ns", ",", "rewards", ",", "obs_next_ns", ",", "dones", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "idxes", ":", "\n", "            ", "data", "=", "self", ".", "_storage", "[", "i", "]", "\n", "obs_n", ",", "action_n", ",", "reward", ",", "obs_next_n", ",", "done", "=", "data", "\n", "obs_ns", ".", "append", "(", "np", ".", "array", "(", "obs_n", ",", "copy", "=", "False", ")", ")", "\n", "action_ns", ".", "append", "(", "np", ".", "array", "(", "action_n", ",", "copy", "=", "False", ")", ")", "\n", "rewards", ".", "append", "(", "reward", ")", "\n", "obs_next_ns", ".", "append", "(", "np", ".", "array", "(", "obs_next_n", ",", "copy", "=", "False", ")", ")", "\n", "dones", ".", "append", "(", "done", ")", "\n", "", "return", "np", ".", "array", "(", "obs_ns", ")", ",", "np", ".", "array", "(", "action_ns", ")", ",", "np", ".", "array", "(", "rewards", ")", ",", "np", ".", "array", "(", "obs_next_ns", ")", ",", "np", ".", "array", "(", "dones", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.n_replay_buffer.ReplayBuffer.make_index": [[46, 48], ["random.randint", "range", "len"], "methods", ["None"], ["", "def", "make_index", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "return", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_storage", ")", "-", "1", ")", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.n_replay_buffer.ReplayBuffer.make_latest_index": [[49, 53], ["numpy.random.shuffle", "range"], "methods", ["None"], ["", "def", "make_latest_index", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "idx", "=", "[", "(", "self", ".", "_next_idx", "-", "1", "-", "i", ")", "%", "self", ".", "_maxsize", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "np", ".", "random", ".", "shuffle", "(", "idx", ")", "\n", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.n_replay_buffer.ReplayBuffer.sample_index": [[54, 56], ["n_replay_buffer.ReplayBuffer._encode_sample"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer._encode_sample"], ["", "def", "sample_index", "(", "self", ",", "idxes", ")", ":", "\n", "        ", "return", "self", ".", "_encode_sample", "(", "idxes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.n_replay_buffer.ReplayBuffer.sample": [[57, 84], ["n_replay_buffer.ReplayBuffer._encode_sample", "n_replay_buffer.ReplayBuffer.make_index", "range", "len"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer._encode_sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.make_index"], ["", "def", "sample", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"Sample a batch of experiences.\n\n        Parameters\n        ----------\n        batch_size: int\n            How many transitions to sample.\n\n        Returns\n        -------\n        obs_batch: np.array\n            batch of observations\n        act_batch: np.array\n            batch of actions executed given obs_batch\n        rew_batch: np.array\n            rewards received as results of executing act_batch\n        next_obs_batch: np.array\n            next set of observations seen after executing act_batch\n        done_mask: np.array\n            done_mask[i] = 1 if executing act_batch[i] resulted in\n            the end of an episode and 0 otherwise.\n        \"\"\"", "\n", "if", "batch_size", ">", "0", ":", "\n", "            ", "idxes", "=", "self", ".", "make_index", "(", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "idxes", "=", "range", "(", "0", ",", "len", "(", "self", ".", "_storage", ")", ")", "\n", "", "return", "self", ".", "_encode_sample", "(", "idxes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.n_replay_buffer.ReplayBuffer.collect": [[85, 87], ["n_replay_buffer.ReplayBuffer.sample"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample"], ["", "def", "collect", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sample", "(", "-", "1", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_small_observation.MADDPGAgentTrainer.__init__": [[226, 263], ["len", "range", "maddpg_small_observation.q_train", "maddpg_small_observation.p_train", "maddpg_local.trainer.replay_buffer.ReplayBuffer", "obs_ph_n.append", "maddpg_local.BatchInput().get", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer", "maddpg_local.BatchInput", "str"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.q_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.Uint8Input.get"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "model", ",", "obs_shape_n", ",", "act_space_n", ",", "agent_index", ",", "args", ",", "local_q_func", "=", "False", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "n", "=", "len", "(", "obs_shape_n", ")", "\n", "self", ".", "agent_index", "=", "agent_index", "\n", "self", ".", "args", "=", "args", "\n", "obs_ph_n", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "            ", "obs_ph_n", ".", "append", "(", "U", ".", "BatchInput", "(", "obs_shape_n", "[", "i", "]", ",", "name", "=", "\"observation\"", "+", "str", "(", "i", ")", ")", ".", "get", "(", ")", ")", "\n", "\n", "# Create all the functions necessary to train the model", "\n", "", "self", ".", "q_train", ",", "self", ".", "q_update", ",", "self", ".", "q_debug", "=", "q_train", "(", "\n", "scope", "=", "self", ".", "name", ",", "\n", "make_obs_ph_n", "=", "obs_ph_n", ",", "\n", "act_space_n", "=", "act_space_n", ",", "\n", "q_index", "=", "agent_index", ",", "\n", "q_func", "=", "model", ",", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "args", ".", "lr", ")", ",", "\n", "grad_norm_clipping", "=", "0.5", ",", "\n", "local_q_func", "=", "local_q_func", ",", "\n", "num_units", "=", "args", ".", "num_units", "\n", ")", "\n", "self", ".", "act", ",", "self", ".", "p_train", ",", "self", ".", "p_update", ",", "self", ".", "p_debug", "=", "p_train", "(", "\n", "scope", "=", "self", ".", "name", ",", "\n", "make_obs_ph_n", "=", "obs_ph_n", ",", "\n", "act_space_n", "=", "act_space_n", ",", "\n", "p_index", "=", "agent_index", ",", "\n", "p_func", "=", "model", ",", "\n", "q_func", "=", "model", ",", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "args", ".", "lr", ")", ",", "\n", "grad_norm_clipping", "=", "0.5", ",", "\n", "local_q_func", "=", "local_q_func", ",", "\n", "num_units", "=", "args", ".", "num_units", "\n", ")", "\n", "# Create experience buffer", "\n", "self", ".", "replay_buffer", "=", "ReplayBuffer", "(", "1e6", ")", "\n", "self", ".", "max_replay_buffer_len", "=", "args", ".", "batch_size", "*", "args", ".", "max_episode_len", "\n", "self", ".", "replay_sample_index", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_small_observation.MADDPGAgentTrainer.action": [[264, 267], ["print", "maddpg_small_observation.MADDPGAgentTrainer.act"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "obs", ")", ":", "\n", "        ", "print", "(", "obs", "[", "None", "]", ".", "shape", ")", "\n", "return", "self", ".", "act", "(", "obs", "[", "None", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_small_observation.MADDPGAgentTrainer.experience": [[268, 271], ["maddpg_small_observation.MADDPGAgentTrainer.replay_buffer.add", "float"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.add"], ["", "def", "experience", "(", "self", ",", "obs", ",", "act", ",", "rew", ",", "new_obs", ",", "done", ",", "terminal", ")", ":", "\n", "# Store transition in the replay buffer.", "\n", "        ", "self", ".", "replay_buffer", ".", "add", "(", "obs", ",", "act", ",", "rew", ",", "new_obs", ",", "float", "(", "done", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_small_observation.MADDPGAgentTrainer.preupdate": [[272, 274], ["None"], "methods", ["None"], ["", "def", "preupdate", "(", "self", ")", ":", "\n", "        ", "self", ".", "replay_sample_index", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_small_observation.MADDPGAgentTrainer.update": [[275, 311], ["maddpg_small_observation.MADDPGAgentTrainer.replay_buffer.make_index", "range", "maddpg_small_observation.MADDPGAgentTrainer.replay_buffer.sample_index", "range", "maddpg_small_observation.MADDPGAgentTrainer.q_train", "maddpg_small_observation.MADDPGAgentTrainer.p_train", "maddpg_small_observation.MADDPGAgentTrainer.p_update", "maddpg_small_observation.MADDPGAgentTrainer.q_update", "len", "agents[].replay_buffer.sample_index", "obs_n.append", "obs_next_n.append", "act_n.append", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.std", "range"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.make_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.q_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.std"], ["", "def", "update", "(", "self", ",", "agents", ",", "t", ",", "group_train", "=", "False", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "replay_buffer", ")", "<", "self", ".", "max_replay_buffer_len", ":", "# replay buffer is not large enough", "\n", "            ", "return", "\n", "", "if", "not", "t", "%", "100", "==", "0", ":", "# only update every 100 steps", "\n", "            ", "return", "\n", "\n", "", "self", ".", "replay_sample_index", "=", "self", ".", "replay_buffer", ".", "make_index", "(", "self", ".", "args", ".", "batch_size", ")", "\n", "# collect replay sample from all agents", "\n", "obs_n", "=", "[", "]", "\n", "obs_next_n", "=", "[", "]", "\n", "act_n", "=", "[", "]", "\n", "index", "=", "self", ".", "replay_sample_index", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "            ", "obs", ",", "act", ",", "rew", ",", "obs_next", ",", "done", "=", "agents", "[", "i", "]", ".", "replay_buffer", ".", "sample_index", "(", "index", ")", "\n", "obs_n", ".", "append", "(", "obs", ")", "\n", "obs_next_n", ".", "append", "(", "obs_next", ")", "\n", "act_n", ".", "append", "(", "act", ")", "\n", "", "obs", ",", "act", ",", "rew", ",", "obs_next", ",", "done", "=", "self", ".", "replay_buffer", ".", "sample_index", "(", "index", ")", "\n", "\n", "# train q network", "\n", "num_sample", "=", "1", "\n", "target_q", "=", "0.0", "\n", "for", "i", "in", "range", "(", "num_sample", ")", ":", "\n", "            ", "target_act_next_n", "=", "[", "agents", "[", "i", "]", ".", "p_debug", "[", "'target_act'", "]", "(", "obs_next_n", "[", "i", "]", ")", "for", "i", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "target_q_next", "=", "self", ".", "q_debug", "[", "'target_q_values'", "]", "(", "*", "(", "obs_next_n", "+", "target_act_next_n", ")", ")", "\n", "target_q", "+=", "rew", "+", "self", ".", "args", ".", "gamma", "*", "(", "1.0", "-", "done", ")", "*", "target_q_next", "\n", "", "target_q", "/=", "num_sample", "\n", "q_loss", "=", "self", ".", "q_train", "(", "*", "(", "obs_n", "+", "act_n", "+", "[", "target_q", "]", ")", ")", "\n", "\n", "# train p network", "\n", "p_loss", "=", "self", ".", "p_train", "(", "*", "(", "obs_n", "+", "act_n", ")", ")", "\n", "\n", "self", ".", "p_update", "(", ")", "\n", "self", ".", "q_update", "(", ")", "\n", "\n", "return", "[", "q_loss", ",", "p_loss", ",", "np", ".", "mean", "(", "target_q", ")", ",", "np", ".", "mean", "(", "rew", ")", ",", "np", ".", "mean", "(", "target_q_next", ")", ",", "np", ".", "std", "(", "target_q", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_small_observation.MADDPGAgentSharedTrainer.__init__": [[313, 355], ["len", "range", "maddpg_small_observation.q_train", "maddpg_small_observation.group_p_train", "maddpg_local.trainer.replay_buffer.ReplayBuffer", "obs_ph_n.append", "maddpg_local.BatchInput().get", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer", "maddpg_local.BatchInput", "str"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.q_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.group_p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.Uint8Input.get"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "model", ",", "obs_shape_n", ",", "act_space_n", ",", "agent_index", ",", "num_adversaries", ",", "args", ",", "local_q_func", "=", "False", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "n", "=", "len", "(", "obs_shape_n", ")", "\n", "self", ".", "agent_index", "=", "agent_index", "\n", "self", ".", "num_adversaries", "=", "num_adversaries", "\n", "self", ".", "args", "=", "args", "\n", "obs_ph_n", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "            ", "obs_ph_n", ".", "append", "(", "U", ".", "BatchInput", "(", "obs_shape_n", "[", "i", "]", ",", "name", "=", "\"observation\"", "+", "str", "(", "i", ")", ")", ".", "get", "(", ")", ")", "\n", "\n", "# Create all the functions necessary to train the model", "\n", "", "self", ".", "q_train", ",", "self", ".", "q_update", ",", "self", ".", "q_debug", "=", "q_train", "(", "\n", "scope", "=", "self", ".", "name", ",", "\n", "make_obs_ph_n", "=", "obs_ph_n", ",", "\n", "act_space_n", "=", "act_space_n", ",", "\n", "q_index", "=", "agent_index", ",", "\n", "q_func", "=", "model", ",", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "args", ".", "lr", ")", ",", "\n", "grad_norm_clipping", "=", "0.5", ",", "\n", "local_q_func", "=", "local_q_func", ",", "\n", "num_units", "=", "args", ".", "num_units", ",", "\n", "reuse", "=", "tf", ".", "AUTO_REUSE", "\n", ")", "\n", "self", ".", "act", ",", "self", ".", "p_train", ",", "self", ".", "p_update", ",", "self", ".", "p_debug", "=", "group_p_train", "(", "\n", "scope", "=", "self", ".", "name", ",", "\n", "make_obs_ph_n", "=", "obs_ph_n", ",", "\n", "act_space_n", "=", "act_space_n", ",", "\n", "p_index", "=", "agent_index", ",", "\n", "num_adversaries", "=", "num_adversaries", ",", "\n", "p_func", "=", "model", ",", "\n", "q_func", "=", "model", ",", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "args", ".", "lr", ")", ",", "\n", "grad_norm_clipping", "=", "0.5", ",", "\n", "local_q_func", "=", "local_q_func", ",", "\n", "num_units", "=", "args", ".", "num_units", ",", "\n", "reuse", "=", "tf", ".", "AUTO_REUSE", "\n", ")", "\n", "\n", "# Create experience buffer", "\n", "self", ".", "replay_buffer", "=", "ReplayBuffer", "(", "1e6", ")", "\n", "self", ".", "max_replay_buffer_len", "=", "args", ".", "batch_size", "*", "args", ".", "max_episode_len", "\n", "self", ".", "replay_sample_index", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_small_observation.MADDPGAgentSharedTrainer.action": [[356, 359], ["maddpg_small_observation.MADDPGAgentSharedTrainer.act"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "obs", ")", ":", "\n", "\n", "        ", "return", "self", ".", "act", "(", "obs", "[", "None", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_small_observation.MADDPGAgentSharedTrainer.experience": [[360, 363], ["maddpg_small_observation.MADDPGAgentSharedTrainer.replay_buffer.add", "float"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.add"], ["", "def", "experience", "(", "self", ",", "obs", ",", "act", ",", "rew", ",", "new_obs", ",", "done", ",", "terminal", ")", ":", "\n", "# Store transition in the replay buffer.", "\n", "        ", "self", ".", "replay_buffer", ".", "add", "(", "obs", ",", "act", ",", "rew", ",", "new_obs", ",", "float", "(", "done", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_small_observation.MADDPGAgentSharedTrainer.preupdate": [[364, 366], ["None"], "methods", ["None"], ["", "def", "preupdate", "(", "self", ")", ":", "\n", "        ", "self", ".", "replay_sample_index", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_small_observation.MADDPGAgentSharedTrainer.update": [[367, 406], ["maddpg_small_observation.MADDPGAgentSharedTrainer.replay_buffer.make_index", "range", "maddpg_small_observation.MADDPGAgentSharedTrainer.replay_buffer.sample_index", "range", "maddpg_small_observation.MADDPGAgentSharedTrainer.q_train", "maddpg_small_observation.MADDPGAgentSharedTrainer.p_update", "maddpg_small_observation.MADDPGAgentSharedTrainer.q_update", "len", "agents[].replay_buffer.sample_index", "obs_n.append", "obs_next_n.append", "act_n.append", "maddpg_small_observation.MADDPGAgentSharedTrainer.group_p_train", "maddpg_small_observation.MADDPGAgentSharedTrainer.p_train", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.std", "range"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.make_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.q_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.group_p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.std"], ["", "def", "update", "(", "self", ",", "agents", ",", "t", ",", "group_train", "=", "False", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "replay_buffer", ")", "<", "self", ".", "max_replay_buffer_len", ":", "# replay buffer is not large enough", "\n", "            ", "return", "\n", "", "if", "not", "t", "%", "100", "==", "0", ":", "# only update every 100 steps", "\n", "            ", "return", "\n", "\n", "", "self", ".", "replay_sample_index", "=", "self", ".", "replay_buffer", ".", "make_index", "(", "self", ".", "args", ".", "batch_size", ")", "\n", "# collect replay sample from all agents", "\n", "obs_n", "=", "[", "]", "\n", "obs_next_n", "=", "[", "]", "\n", "act_n", "=", "[", "]", "\n", "index", "=", "self", ".", "replay_sample_index", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "            ", "obs", ",", "act", ",", "rew", ",", "obs_next", ",", "done", "=", "agents", "[", "i", "]", ".", "replay_buffer", ".", "sample_index", "(", "index", ")", "\n", "obs_n", ".", "append", "(", "obs", ")", "\n", "obs_next_n", ".", "append", "(", "obs_next", ")", "\n", "act_n", ".", "append", "(", "act", ")", "\n", "", "obs", ",", "act", ",", "rew", ",", "obs_next", ",", "done", "=", "self", ".", "replay_buffer", ".", "sample_index", "(", "index", ")", "\n", "\n", "# train q network", "\n", "num_sample", "=", "1", "\n", "target_q", "=", "0.0", "\n", "for", "i", "in", "range", "(", "num_sample", ")", ":", "\n", "            ", "target_act_next_n", "=", "[", "agents", "[", "i", "]", ".", "p_debug", "[", "'target_act'", "]", "(", "obs_next_n", "[", "i", "]", ")", "for", "i", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "target_q_next", "=", "self", ".", "q_debug", "[", "'target_q_values'", "]", "(", "*", "(", "obs_next_n", "+", "target_act_next_n", ")", ")", "\n", "target_q", "+=", "rew", "+", "self", ".", "args", ".", "gamma", "*", "(", "1.0", "-", "done", ")", "*", "target_q_next", "\n", "", "target_q", "/=", "num_sample", "\n", "q_loss", "=", "self", ".", "q_train", "(", "*", "(", "obs_n", "+", "act_n", "+", "[", "target_q", "]", ")", ")", "\n", "\n", "# train p network", "\n", "if", "(", "group_train", ")", ":", "\n", "            ", "p_loss", "=", "self", ".", "group_p_train", "(", "*", "(", "obs_n", "+", "act_n", ")", ")", "\n", "", "else", ":", "\n", "            ", "p_loss", "=", "self", ".", "p_train", "(", "*", "(", "obs_n", "+", "act_n", ")", ")", "\n", "\n", "", "self", ".", "p_update", "(", ")", "\n", "self", ".", "q_update", "(", ")", "\n", "\n", "return", "[", "q_loss", ",", "p_loss", ",", "np", ".", "mean", "(", "target_q", ")", ",", "np", ".", "mean", "(", "rew", ")", ",", "np", ".", "mean", "(", "target_q_next", ")", ",", "np", ".", "std", "(", "target_q", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_small_observation.MADDPGAgentMicroSharedTrainer.__init__": [[408, 445], ["len", "range", "maddpg_small_observation.q_train", "maddpg_small_observation.p_train", "maddpg_local.trainer.replay_buffer.ReplayBuffer", "obs_ph_n.append", "maddpg_local.BatchInput().get", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer", "maddpg_local.BatchInput", "str"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.q_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.Uint8Input.get"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "model_p", ",", "model_q", ",", "obs_shape_n", ",", "act_space_n", ",", "agent_index", ",", "args", ",", "local_q_func", "=", "False", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "n", "=", "len", "(", "obs_shape_n", ")", "\n", "self", ".", "agent_index", "=", "agent_index", "\n", "self", ".", "args", "=", "args", "\n", "obs_ph_n", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "            ", "obs_ph_n", ".", "append", "(", "U", ".", "BatchInput", "(", "obs_shape_n", "[", "i", "]", ",", "name", "=", "\"observation\"", "+", "str", "(", "i", ")", ")", ".", "get", "(", ")", ")", "\n", "\n", "# Create all the functions necessary to train the model", "\n", "", "self", ".", "q_train", ",", "self", ".", "q_update", ",", "self", ".", "q_debug", "=", "q_train", "(", "\n", "scope", "=", "self", ".", "name", ",", "\n", "make_obs_ph_n", "=", "obs_ph_n", ",", "\n", "act_space_n", "=", "act_space_n", ",", "\n", "q_index", "=", "agent_index", ",", "\n", "q_func", "=", "model_q", ",", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "args", ".", "lr", ")", ",", "\n", "grad_norm_clipping", "=", "0.5", ",", "\n", "local_q_func", "=", "local_q_func", ",", "\n", "num_units", "=", "args", ".", "num_units", "\n", ")", "\n", "self", ".", "act", ",", "self", ".", "p_train", ",", "self", ".", "p_update", ",", "self", ".", "p_debug", "=", "p_train", "(", "\n", "scope", "=", "self", ".", "name", ",", "\n", "make_obs_ph_n", "=", "obs_ph_n", ",", "\n", "act_space_n", "=", "act_space_n", ",", "\n", "p_index", "=", "agent_index", ",", "\n", "p_func", "=", "model_p", ",", "\n", "q_func", "=", "model_q", ",", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "args", ".", "lr", ")", ",", "\n", "grad_norm_clipping", "=", "0.5", ",", "\n", "local_q_func", "=", "local_q_func", ",", "\n", "num_units", "=", "args", ".", "num_units", "\n", ")", "\n", "# Create experience buffer", "\n", "self", ".", "replay_buffer", "=", "ReplayBuffer", "(", "1e6", ")", "\n", "self", ".", "max_replay_buffer_len", "=", "args", ".", "batch_size", "*", "args", ".", "max_episode_len", "\n", "self", ".", "replay_sample_index", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_small_observation.MADDPGAgentMicroSharedTrainer.action": [[446, 449], ["maddpg_small_observation.MADDPGAgentMicroSharedTrainer.act"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "obs", ")", ":", "\n", "#print(obs[None].shape)", "\n", "        ", "return", "self", ".", "act", "(", "obs", "[", "None", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_small_observation.MADDPGAgentMicroSharedTrainer.experience": [[450, 453], ["maddpg_small_observation.MADDPGAgentMicroSharedTrainer.replay_buffer.add", "float"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.add"], ["", "def", "experience", "(", "self", ",", "obs", ",", "act", ",", "rew", ",", "new_obs", ",", "done", ",", "terminal", ")", ":", "\n", "# Store transition in the replay buffer.", "\n", "        ", "self", ".", "replay_buffer", ".", "add", "(", "obs", ",", "act", ",", "rew", ",", "new_obs", ",", "float", "(", "done", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_small_observation.MADDPGAgentMicroSharedTrainer.preupdate": [[454, 456], ["None"], "methods", ["None"], ["", "def", "preupdate", "(", "self", ")", ":", "\n", "        ", "self", ".", "replay_sample_index", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_small_observation.MADDPGAgentMicroSharedTrainer.update": [[457, 493], ["maddpg_small_observation.MADDPGAgentMicroSharedTrainer.replay_buffer.make_index", "range", "maddpg_small_observation.MADDPGAgentMicroSharedTrainer.replay_buffer.sample_index", "range", "maddpg_small_observation.MADDPGAgentMicroSharedTrainer.q_train", "maddpg_small_observation.MADDPGAgentMicroSharedTrainer.p_train", "maddpg_small_observation.MADDPGAgentMicroSharedTrainer.p_update", "maddpg_small_observation.MADDPGAgentMicroSharedTrainer.q_update", "len", "agents[].replay_buffer.sample_index", "obs_n.append", "obs_next_n.append", "act_n.append", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.std", "range"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.make_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.q_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.std"], ["", "def", "update", "(", "self", ",", "agents", ",", "t", ",", "group_train", "=", "False", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "replay_buffer", ")", "<", "self", ".", "max_replay_buffer_len", ":", "# replay buffer is not large enough", "\n", "            ", "return", "\n", "", "if", "not", "t", "%", "100", "==", "0", ":", "# only update every 100 steps", "\n", "            ", "return", "\n", "\n", "", "self", ".", "replay_sample_index", "=", "self", ".", "replay_buffer", ".", "make_index", "(", "self", ".", "args", ".", "batch_size", ")", "\n", "# collect replay sample from all agents", "\n", "obs_n", "=", "[", "]", "\n", "obs_next_n", "=", "[", "]", "\n", "act_n", "=", "[", "]", "\n", "index", "=", "self", ".", "replay_sample_index", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "            ", "obs", ",", "act", ",", "rew", ",", "obs_next", ",", "done", "=", "agents", "[", "i", "]", ".", "replay_buffer", ".", "sample_index", "(", "index", ")", "\n", "obs_n", ".", "append", "(", "obs", ")", "\n", "obs_next_n", ".", "append", "(", "obs_next", ")", "\n", "act_n", ".", "append", "(", "act", ")", "\n", "", "obs", ",", "act", ",", "rew", ",", "obs_next", ",", "done", "=", "self", ".", "replay_buffer", ".", "sample_index", "(", "index", ")", "\n", "\n", "# train q network", "\n", "num_sample", "=", "1", "\n", "target_q", "=", "0.0", "\n", "for", "i", "in", "range", "(", "num_sample", ")", ":", "\n", "            ", "target_act_next_n", "=", "[", "agents", "[", "i", "]", ".", "p_debug", "[", "'target_act'", "]", "(", "obs_next_n", "[", "i", "]", ")", "for", "i", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "target_q_next", "=", "self", ".", "q_debug", "[", "'target_q_values'", "]", "(", "*", "(", "obs_next_n", "+", "target_act_next_n", ")", ")", "\n", "target_q", "+=", "rew", "+", "self", ".", "args", ".", "gamma", "*", "(", "1.0", "-", "done", ")", "*", "target_q_next", "\n", "", "target_q", "/=", "num_sample", "\n", "q_loss", "=", "self", ".", "q_train", "(", "*", "(", "obs_n", "+", "act_n", "+", "[", "target_q", "]", ")", ")", "\n", "\n", "# train p network", "\n", "p_loss", "=", "self", ".", "p_train", "(", "*", "(", "obs_n", "+", "act_n", ")", ")", "\n", "\n", "self", ".", "p_update", "(", ")", "\n", "self", ".", "q_update", "(", ")", "\n", "\n", "return", "[", "q_loss", ",", "p_loss", ",", "np", ".", "mean", "(", "target_q", ")", ",", "np", ".", "mean", "(", "rew", ")", ",", "np", ".", "mean", "(", "target_q_next", ")", ",", "np", ".", "std", "(", "target_q", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_small_observation.discount_with_dones": [[12, 20], ["zip", "discounted.append"], "function", ["None"], ["def", "discount_with_dones", "(", "rewards", ",", "dones", ",", "gamma", ")", ":", "\n", "    ", "discounted", "=", "[", "]", "\n", "r", "=", "0", "\n", "for", "reward", ",", "done", "in", "zip", "(", "rewards", "[", ":", ":", "-", "1", "]", ",", "dones", "[", ":", ":", "-", "1", "]", ")", ":", "\n", "        ", "r", "=", "reward", "+", "gamma", "*", "r", "\n", "r", "=", "r", "*", "(", "1.", "-", "done", ")", "\n", "discounted", ".", "append", "(", "r", ")", "\n", "", "return", "discounted", "[", ":", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_small_observation.make_update_exp": [[21, 28], ["zip", "tensorflow.group", "maddpg_local.function", "sorted", "sorted", "tf.group.append", "var_target.assign"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function"], ["", "def", "make_update_exp", "(", "vals", ",", "target_vals", ")", ":", "\n", "    ", "polyak", "=", "1.0", "-", "1e-2", "\n", "expression", "=", "[", "]", "\n", "for", "var", ",", "var_target", "in", "zip", "(", "sorted", "(", "vals", ",", "key", "=", "lambda", "v", ":", "v", ".", "name", ")", ",", "sorted", "(", "target_vals", ",", "key", "=", "lambda", "v", ":", "v", ".", "name", ")", ")", ":", "\n", "        ", "expression", ".", "append", "(", "var_target", ".", "assign", "(", "polyak", "*", "var_target", "+", "(", "1.0", "-", "polyak", ")", "*", "var", ")", ")", "\n", "", "expression", "=", "tf", ".", "group", "(", "*", "expression", ")", "\n", "return", "U", ".", "function", "(", "[", "]", ",", "[", "]", ",", "updates", "=", "[", "expression", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_small_observation.p_train": [[29, 76], ["tensorflow.variable_scope", "p_func", "maddpg_local.scope_vars", "act_pdtype_n[].pdfromflat", "act_pdtype_n[].pdfromflat.sample", "tensorflow.reduce_mean", "act_pdtype_n[].pdfromflat.sample", "tensorflow.concat", "maddpg_local.minimize_and_clip", "maddpg_local.function", "maddpg_local.function", "maddpg_local.function", "print", "p_func", "maddpg_local.scope_vars", "maddpg_small_observation.make_update_exp", "act_pdtype_n[].pdfromflat().sample", "maddpg_local.function", "maddpg_local.common.distributions.make_pdtype", "act_pdtype_n[].sample_placeholder", "int", "maddpg_local.absolute_scope_name", "tensorflow.square", "tensorflow.concat", "q_func", "tensorflow.reduce_mean", "int", "maddpg_local.absolute_scope_name", "range", "act_pdtype_n[].pdfromflat.flatparam", "act_pdtype_n[].pdfromflat", "len", "act_pdtype_n[].param_shape", "act_pdtype_n[].param_shape", "str"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.minimize_and_clip", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.make_update_exp", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.make_pdtype", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.flatparam", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape"], ["", "def", "p_train", "(", "make_obs_ph_n", ",", "act_space_n", ",", "p_index", ",", "p_func", ",", "q_func", ",", "optimizer", ",", "grad_norm_clipping", "=", "None", ",", "local_q_func", "=", "False", ",", "num_units", "=", "64", ",", "scope", "=", "\"trainer\"", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "# create distribtuions", "\n", "        ", "act_pdtype_n", "=", "[", "make_pdtype", "(", "act_space", ")", "for", "act_space", "in", "act_space_n", "]", "\n", "\n", "# set up placeholders", "\n", "obs_ph_n", "=", "make_obs_ph_n", "\n", "act_ph_n", "=", "[", "act_pdtype_n", "[", "i", "]", ".", "sample_placeholder", "(", "[", "None", "]", ",", "name", "=", "\"action\"", "+", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "act_space_n", ")", ")", "]", "\n", "\n", "p_input", "=", "obs_ph_n", "[", "p_index", "]", "\n", "\n", "p", "=", "p_func", "(", "p_input", ",", "int", "(", "act_pdtype_n", "[", "p_index", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "p_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"p_func\"", ")", ")", "\n", "\n", "# wrap parameters in distribution", "\n", "act_pd", "=", "act_pdtype_n", "[", "p_index", "]", ".", "pdfromflat", "(", "p", ")", "\n", "\n", "act_sample", "=", "act_pd", ".", "sample", "(", ")", "\n", "p_reg", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "act_pd", ".", "flatparam", "(", ")", ")", ")", "\n", "\n", "act_input_n", "=", "act_ph_n", "+", "[", "]", "\n", "act_input_n", "[", "p_index", "]", "=", "act_pd", ".", "sample", "(", ")", "\n", "q_input", "=", "tf", ".", "concat", "(", "obs_ph_n", "+", "act_input_n", ",", "1", ")", "\n", "if", "local_q_func", ":", "\n", "            ", "q_input", "=", "tf", ".", "concat", "(", "[", "obs_ph_n", "[", "p_index", "]", ",", "act_input_n", "[", "p_index", "]", "]", ",", "1", ")", "\n", "", "q", "=", "q_func", "(", "q_input", ",", "1", ",", "scope", "=", "\"q_func\"", ",", "reuse", "=", "True", ",", "num_units", "=", "num_units", ")", "[", ":", ",", "0", "]", "\n", "pg_loss", "=", "-", "tf", ".", "reduce_mean", "(", "q", ")", "\n", "\n", "loss", "=", "pg_loss", "+", "p_reg", "*", "1e-3", "\n", "\n", "optimize_expr", "=", "U", ".", "minimize_and_clip", "(", "optimizer", ",", "loss", ",", "p_func_vars", ",", "grad_norm_clipping", ")", "\n", "\n", "# Create callable functions", "\n", "train", "=", "U", ".", "function", "(", "inputs", "=", "obs_ph_n", "+", "act_ph_n", ",", "outputs", "=", "loss", ",", "updates", "=", "[", "optimize_expr", "]", ")", "\n", "act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "outputs", "=", "act_sample", ")", "\n", "p_values", "=", "U", ".", "function", "(", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "p", ")", "\n", "print", "(", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "act_sample", ")", "\n", "\n", "# target network", "\n", "target_p", "=", "p_func", "(", "p_input", ",", "int", "(", "act_pdtype_n", "[", "p_index", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"target_p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "target_p_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_p_func\"", ")", ")", "\n", "update_target_p", "=", "make_update_exp", "(", "p_func_vars", ",", "target_p_func_vars", ")", "\n", "\n", "target_act_sample", "=", "act_pdtype_n", "[", "p_index", "]", ".", "pdfromflat", "(", "target_p", ")", ".", "sample", "(", ")", "\n", "target_act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "outputs", "=", "target_act_sample", ")", "\n", "\n", "return", "act", ",", "train", ",", "update_target_p", ",", "{", "'p_values'", ":", "p_values", ",", "'target_act'", ":", "target_act", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_small_observation.group_p_train": [[77, 187], ["tensorflow.variable_scope", "len", "list", "p_func", "maddpg_local.scope_vars", "tensorflow.reduce_mean", "maddpg_local.minimize_and_clip", "maddpg_local.function", "maddpg_local.scope_vars", "maddpg_small_observation.make_update_exp", "act_pdtype_n[].pdfromflat().sample", "maddpg_local.function", "maddpg_local.common.distributions.make_pdtype", "itertools.chain.from_iterable", "tensorflow.concat", "tensorflow.reshape", "tensorflow.concat", "tensorflow.reshape", "int", "maddpg_local.absolute_scope_name", "tensorflow.reshape", "tensorflow.split", "tensorflow.reshape", "tensorflow.split", "tensorflow.square", "range", "tensorflow.concat", "range", "tensorflow.concat", "q_func", "tensorflow.reduce_mean", "print", "maddpg_local.function", "maddpg_local.function", "print", "maddpg_local.function", "maddpg_local.function", "tensorflow.reshape", "tensorflow.split", "p_func", "tensorflow.reshape", "tensorflow.split", "p_func", "maddpg_local.absolute_scope_name", "act_pdtype_n[].pdfromflat", "act_pds[].sample", "act_pdtype_n[].pdfromflat", "act_pds[].sample", "tensorflow.concat", "act_pds[].sample", "q_inputs.append", "act_pds[].sample", "q_inputs.append", "int", "int", "act_pdtype_n[].pdfromflat", "act_pdtype_n[].sample_placeholder", "range", "act_pdtype_n[].sample_placeholder", "range", "act_pdtype_n[].param_shape", "range", "range", "range", "range", "tensorflow.concat", "tensorflow.concat", "range", "range", "act_pd.flatparam", "act_pdtype_n[].param_shape", "act_pdtype_n[].param_shape", "len", "len", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.minimize_and_clip", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.make_update_exp", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.make_pdtype", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.flatparam", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape"], ["", "", "def", "group_p_train", "(", "make_obs_ph_n", ",", "act_space_n", ",", "p_index", ",", "num_adversaries", ",", "p_func", ",", "q_func", ",", "optimizer", ",", "grad_norm_clipping", "=", "None", ",", "local_q_func", "=", "False", ",", "num_units", "=", "64", ",", "scope", "=", "\"trainer\"", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "# create distribtuions", "\n", "        ", "act_pdtype_n", "=", "[", "make_pdtype", "(", "act_space", ")", "for", "act_space", "in", "act_space_n", "]", "\n", "\n", "# set up placeholders for a group", "\n", "obs_ph_n", "=", "make_obs_ph_n", "\n", "n_agents", "=", "len", "(", "obs_ph_n", ")", "\n", "\n", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "\n", "            ", "act_ph_ns", "=", "[", "[", "act_pdtype_n", "[", "i", "]", ".", "sample_placeholder", "(", "[", "None", "]", ",", "name", "=", "\"action\"", "+", "str", "(", "n", ")", "+", "'_'", "+", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "act_space_n", ")", ")", "]", "for", "n", "in", "range", "(", "num_adversaries", ")", "]", "\n", "", "else", ":", "\n", "            ", "act_ph_ns", "=", "[", "[", "act_pdtype_n", "[", "i", "]", ".", "sample_placeholder", "(", "[", "None", "]", ",", "name", "=", "\"action\"", "+", "str", "(", "n", ")", "+", "'_'", "+", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "act_space_n", ")", ")", "]", "for", "n", "in", "range", "(", "n_agents", "-", "num_adversaries", ")", "]", "\n", "", "act_ph_ns_flatten", "=", "list", "(", "chain", ".", "from_iterable", "(", "act_ph_ns", ")", ")", "\n", "\n", "# p_input = obs_ph_n[p_index] # one obs for a certain p_index", "\n", "# batchify obs for all agents in a group", "\n", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "# adv", "\n", "            ", "p_input", "=", "tf", ".", "concat", "(", "obs_ph_n", "[", ":", "num_adversaries", "]", ",", "1", ")", "\n", "p_input", "=", "tf", ".", "reshape", "(", "p_input", ",", "[", "-", "1", ",", "p_input", ".", "shape", "[", "-", "1", "]", ".", "value", "//", "num_adversaries", "]", ")", "\n", "", "else", ":", "# good agent", "\n", "            ", "p_input", "=", "tf", ".", "concat", "(", "obs_ph_n", "[", "num_adversaries", ":", "]", ",", "1", ")", "\n", "p_input", "=", "tf", ".", "reshape", "(", "p_input", ",", "[", "-", "1", ",", "p_input", ".", "shape", "[", "-", "1", "]", ".", "value", "//", "(", "n_agents", "-", "num_adversaries", ")", "]", ")", "\n", "\n", "# get all actions from a group", "\n", "", "p", "=", "p_func", "(", "p_input", ",", "int", "(", "act_pdtype_n", "[", "p_index", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "p_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"p_func\"", ")", ")", "\n", "\n", "# wrap parameters in distribution", "\n", "# un-batchify actions from a group", "\n", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "\n", "            ", "p", "=", "tf", ".", "reshape", "(", "p", ",", "[", "-", "1", ",", "p", ".", "shape", "[", "-", "1", "]", "*", "num_adversaries", "]", ")", "\n", "ps", "=", "tf", ".", "split", "(", "p", ",", "num_or_size_splits", "=", "num_adversaries", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "p", "=", "tf", ".", "reshape", "(", "p", ",", "[", "-", "1", ",", "p", ".", "shape", "[", "-", "1", "]", "*", "(", "n_agents", "-", "num_adversaries", ")", "]", ")", "\n", "ps", "=", "tf", ".", "split", "(", "p", ",", "num_or_size_splits", "=", "(", "n_agents", "-", "num_adversaries", ")", ",", "axis", "=", "1", ")", "\n", "\n", "# get probability distributions and action samples for a group", "\n", "", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "\n", "            ", "act_pds", "=", "[", "act_pdtype_n", "[", "i", "]", ".", "pdfromflat", "(", "ps", "[", "i", "]", ")", "for", "i", "in", "range", "(", "num_adversaries", ")", "]", "\n", "act_samples", "=", "[", "act_pds", "[", "i", "]", ".", "sample", "(", ")", "for", "i", "in", "range", "(", "num_adversaries", ")", "]", "\n", "", "else", ":", "\n", "            ", "act_pds", "=", "[", "act_pdtype_n", "[", "i", "]", ".", "pdfromflat", "(", "ps", "[", "i", "-", "num_adversaries", "]", ")", "for", "i", "in", "range", "(", "num_adversaries", ",", "n_agents", ")", "]", "\n", "act_samples", "=", "[", "act_pds", "[", "i", "]", ".", "sample", "(", ")", "for", "i", "in", "range", "(", "n_agents", "-", "num_adversaries", ")", "]", "\n", "# act_pd = act_pdtype_n[p_index].pdfromflat(p)", "\n", "# act_sample = act_pd.sample()", "\n", "\n", "# p_reg = tf.reduce_mean(tf.square(act_pd.flatparam()))", "\n", "# get average p_reg for a group", "\n", "", "p_reg", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "tf", ".", "concat", "(", "[", "act_pd", ".", "flatparam", "(", ")", "for", "act_pd", "in", "act_pds", "]", ",", "-", "1", ")", ")", ")", "\n", "\n", "\n", "# act_input_n = act_ph_n + []", "\n", "act_input_ns", "=", "act_ph_ns", "\n", "# act_input_n[p_index] = act_pd.sample()", "\n", "# q_input = tf.concat(obs_ph_n + act_input_n, 1)", "\n", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "\n", "            ", "q_inputs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_adversaries", ")", ":", "\n", "                ", "act_input_ns", "[", "i", "]", "[", "i", "]", "=", "act_pds", "[", "i", "]", ".", "sample", "(", ")", "\n", "q_inputs", ".", "append", "(", "tf", ".", "concat", "(", "obs_ph_n", "+", "act_input_ns", "[", "i", "]", ",", "1", ")", ")", "\n", "# batchify q_input", "\n", "", "q_input", "=", "tf", ".", "concat", "(", "q_inputs", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "q_inputs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_agents", "-", "num_adversaries", ")", ":", "\n", "                ", "act_input_ns", "[", "i", "]", "[", "i", "+", "num_adversaries", "]", "=", "act_pds", "[", "i", "]", ".", "sample", "(", ")", "\n", "q_inputs", ".", "append", "(", "tf", ".", "concat", "(", "obs_ph_n", "+", "act_input_ns", "[", "i", "]", ",", "1", ")", ")", "\n", "# batchify q_input", "\n", "", "q_input", "=", "tf", ".", "concat", "(", "q_inputs", ",", "0", ")", "\n", "\n", "# if local_q_func:", "\n", "#     q_input = tf.concat([obs_ph_n[p_index], act_input_n[p_index]], 1)", "\n", "\n", "# input group of q_input into q_func", "\n", "", "q", "=", "q_func", "(", "q_input", ",", "1", ",", "scope", "=", "\"q_func\"", ",", "reuse", "=", "True", ",", "num_units", "=", "num_units", ")", "[", ":", ",", "0", "]", "\n", "pg_loss", "=", "-", "tf", ".", "reduce_mean", "(", "q", ")", "\n", "\n", "loss", "=", "pg_loss", "+", "p_reg", "*", "1e-3", "\n", "\n", "optimize_expr", "=", "U", ".", "minimize_and_clip", "(", "optimizer", ",", "loss", ",", "p_func_vars", ",", "grad_norm_clipping", ")", "\n", "\n", "# Create callable functions", "\n", "train", "=", "U", ".", "function", "(", "inputs", "=", "obs_ph_n", "+", "act_ph_ns_flatten", ",", "outputs", "=", "loss", ",", "updates", "=", "[", "optimize_expr", "]", ")", "\n", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "\n", "            ", "print", "(", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "act_samples", "[", "p_index", "]", ")", "\n", "act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "outputs", "=", "act_samples", "[", "p_index", "]", ")", "\n", "p_values", "=", "U", ".", "function", "(", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "ps", "[", "p_index", "]", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "act_samples", "[", "p_index", "-", "num_adversaries", "]", ")", "\n", "act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "outputs", "=", "act_samples", "[", "p_index", "-", "num_adversaries", "]", ")", "\n", "p_values", "=", "U", ".", "function", "(", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "ps", "[", "p_index", "-", "num_adversaries", "]", ")", "\n", "\n", "# target network for a group", "\n", "", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "\n", "            ", "p_input", "=", "tf", ".", "reshape", "(", "p_input", ",", "[", "-", "1", ",", "p_input", ".", "shape", "[", "-", "1", "]", "*", "num_adversaries", "]", ")", "\n", "p_inputs", "=", "tf", ".", "split", "(", "p_input", ",", "num_or_size_splits", "=", "num_adversaries", ",", "axis", "=", "1", ")", "\n", "target_p", "=", "p_func", "(", "p_inputs", "[", "p_index", "]", ",", "int", "(", "act_pdtype_n", "[", "p_index", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"target_p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "", "else", ":", "\n", "            ", "p_input", "=", "tf", ".", "reshape", "(", "p_input", ",", "[", "-", "1", ",", "p_input", ".", "shape", "[", "-", "1", "]", "*", "(", "n_agents", "-", "num_adversaries", ")", "]", ")", "\n", "p_inputs", "=", "tf", ".", "split", "(", "p_input", ",", "num_or_size_splits", "=", "(", "n_agents", "-", "num_adversaries", ")", ",", "axis", "=", "1", ")", "\n", "target_p", "=", "p_func", "(", "p_inputs", "[", "p_index", "-", "num_adversaries", "]", ",", "int", "(", "act_pdtype_n", "[", "p_index", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"target_p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "# target_p = p_func(p_input, int(act_pdtype_n[p_index].param_shape()[0]), scope=\"target_p_func\", num_units=num_units)", "\n", "", "target_p_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_p_func\"", ")", ")", "\n", "update_target_p", "=", "make_update_exp", "(", "p_func_vars", ",", "target_p_func_vars", ")", "\n", "\n", "target_act_sample", "=", "act_pdtype_n", "[", "p_index", "]", ".", "pdfromflat", "(", "target_p", ")", ".", "sample", "(", ")", "\n", "target_act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "outputs", "=", "target_act_sample", ")", "\n", "\n", "return", "act", ",", "train", ",", "update_target_p", ",", "{", "'p_values'", ":", "p_values", ",", "'target_act'", ":", "target_act", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_small_observation.q_train": [[188, 224], ["tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.concat", "maddpg_local.scope_vars", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "maddpg_local.minimize_and_clip", "maddpg_local.function", "maddpg_local.function", "maddpg_local.scope_vars", "maddpg_small_observation.make_update_exp", "maddpg_local.function", "maddpg_local.common.distributions.make_pdtype", "act_pdtype_n[].sample_placeholder", "tensorflow.concat", "q_func", "maddpg_local.absolute_scope_name", "tensorflow.square", "tensorflow.square", "q_func", "maddpg_local.absolute_scope_name", "range", "len", "str"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.minimize_and_clip", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.make_update_exp", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.make_pdtype", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name"], ["", "", "def", "q_train", "(", "make_obs_ph_n", ",", "act_space_n", ",", "q_index", ",", "q_func", ",", "optimizer", ",", "grad_norm_clipping", "=", "None", ",", "local_q_func", "=", "False", ",", "scope", "=", "\"trainer\"", ",", "reuse", "=", "None", ",", "num_units", "=", "64", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "# create distribtuions", "\n", "        ", "act_pdtype_n", "=", "[", "make_pdtype", "(", "act_space", ")", "for", "act_space", "in", "act_space_n", "]", "\n", "\n", "# set up placeholders", "\n", "obs_ph_n", "=", "make_obs_ph_n", "\n", "act_ph_n", "=", "[", "act_pdtype_n", "[", "i", "]", ".", "sample_placeholder", "(", "[", "None", "]", ",", "name", "=", "\"action\"", "+", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "act_space_n", ")", ")", "]", "\n", "target_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ",", "name", "=", "\"target\"", ")", "\n", "#print(act_ph_n)", "\n", "q_input", "=", "tf", ".", "concat", "(", "obs_ph_n", "+", "act_ph_n", ",", "1", ")", "\n", "if", "local_q_func", ":", "\n", "            ", "q_input", "=", "tf", ".", "concat", "(", "[", "obs_ph_n", "[", "q_index", "]", ",", "act_ph_n", "[", "q_index", "]", "]", ",", "1", ")", "\n", "", "q", "=", "q_func", "(", "q_input", ",", "1", ",", "scope", "=", "\"q_func\"", ",", "num_units", "=", "num_units", ")", "[", ":", ",", "0", "]", "\n", "q_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"q_func\"", ")", ")", "\n", "\n", "q_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "q", "-", "target_ph", ")", ")", "\n", "\n", "# viscosity solution to Bellman differential equation in place of an initial condition", "\n", "q_reg", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "q", ")", ")", "\n", "loss", "=", "q_loss", "#+ 1e-3 * q_reg", "\n", "\n", "optimize_expr", "=", "U", ".", "minimize_and_clip", "(", "optimizer", ",", "loss", ",", "q_func_vars", ",", "grad_norm_clipping", ")", "\n", "\n", "# Create callable functions", "\n", "train", "=", "U", ".", "function", "(", "inputs", "=", "obs_ph_n", "+", "act_ph_n", "+", "[", "target_ph", "]", ",", "outputs", "=", "loss", ",", "updates", "=", "[", "optimize_expr", "]", ")", "\n", "q_values", "=", "U", ".", "function", "(", "obs_ph_n", "+", "act_ph_n", ",", "q", ")", "\n", "\n", "# target network", "\n", "target_q", "=", "q_func", "(", "q_input", ",", "1", ",", "scope", "=", "\"target_q_func\"", ",", "num_units", "=", "num_units", ")", "[", ":", ",", "0", "]", "\n", "target_q_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_q_func\"", ")", ")", "\n", "update_target_q", "=", "make_update_exp", "(", "q_func_vars", ",", "target_q_func_vars", ")", "\n", "\n", "target_q_values", "=", "U", ".", "function", "(", "obs_ph_n", "+", "act_ph_n", ",", "target_q", ")", "\n", "\n", "return", "train", ",", "update_target_q", ",", "{", "'q_values'", ":", "q_values", ",", "'target_q_values'", ":", "target_q_values", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTrainer.__init__": [[32, 55], ["len", "maddpg_o.BatchInput().get", "policy_target_policy.p_train", "policy_target_policy.PolicyTrainer.get_p_variables", "policy_target_policy.PolicyTrainer.assign_weight", "maddpg_o.BatchInput", "str"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.Uint8Input.get", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTargetPolicyTrainer.get_p_variables", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.PolicyTrainer.assign_weight"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "model", ",", "obs_shape_n", ",", "session", ",", "act_space_n", ",", "agent_index", ",", "args", ",", "local_q_func", "=", "False", ")", ":", "\n", "        ", "self", ".", "session", "=", "session", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "n", "=", "len", "(", "obs_shape_n", ")", "\n", "self", ".", "num_agents", "=", "args", ".", "num_agents", "\n", "self", ".", "agent_index", "=", "agent_index", "\n", "self", ".", "args", "=", "args", "\n", "obs_ph", "=", "U", ".", "BatchInput", "(", "obs_shape_n", "[", "self", ".", "agent_index", "]", ",", "name", "=", "\"observation\"", "+", "str", "(", "self", ".", "agent_index", ")", ")", ".", "get", "(", ")", "\n", "\n", "\n", "self", ".", "act", ",", "self", ".", "target_act", "=", "p_train", "(", "\n", "scope", "=", "self", ".", "name", ",", "\n", "make_obs_ph", "=", "obs_ph", ",", "\n", "act_space_n", "=", "act_space_n", ",", "\n", "p_index", "=", "agent_index", ",", "\n", "p_func", "=", "model", ",", "\n", "grad_norm_clipping", "=", "0.5", ",", "\n", "local_q_func", "=", "local_q_func", ",", "\n", "num_units", "=", "args", ".", "num_units", "\n", ")", "\n", "\n", "self", ".", "get_p_variables", "(", ")", "\n", "self", ".", "assign_weight", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTrainer.action": [[56, 59], ["policy_target_policy.PolicyTrainer.act"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "obs", ")", ":", "\n", "\n", "        ", "return", "self", ".", "act", "(", "obs", "[", "None", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTrainer.batch_action": [[60, 62], ["policy_target_policy.PolicyTrainer.act"], "methods", ["None"], ["", "def", "batch_action", "(", "self", ",", "obs", ")", ":", "\n", "        ", "return", "self", ".", "act", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTrainer.batch_target_action": [[63, 65], ["policy_target_policy.PolicyTrainer.target_act"], "methods", ["None"], ["", "def", "batch_target_action", "(", "self", ",", "obs", ")", ":", "\n", "        ", "return", "self", ".", "target_act", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTrainer.target_action": [[66, 68], ["policy_target_policy.PolicyTrainer.target_act"], "methods", ["None"], ["", "def", "target_action", "(", "self", ",", "obs", ")", ":", "\n", "        ", "return", "self", ".", "target_act", "(", "obs", "[", "None", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTrainer.get_p_variables": [[69, 72], ["tensorflow.variable_scope", "maddpg_o.scope_vars", "maddpg_o.absolute_scope_name"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name"], ["", "def", "get_p_variables", "(", "self", ",", "reuse", "=", "True", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "name", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "self", ".", "p_variables", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"p_func\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTrainer.get_weigths": [[74, 78], ["dict", "policy_target_policy.PolicyTrainer.session.run"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run"], ["", "", "def", "get_weigths", "(", "self", ")", ":", "\n", "        ", "weigths_dict", "=", "dict", "(", ")", "\n", "weigths_dict", "[", "'p_variables'", "]", "=", "self", ".", "session", ".", "run", "(", "self", ".", "p_variables", ")", "\n", "return", "weigths_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTrainer.assign_weight": [[79, 87], ["dict", "len", "range", "policy_target_policy.PolicyTrainer.x.append", "policy_target_policy.PolicyTrainer.assign_op[].append", "tensorflow.placeholder", "policy_target_policy.PolicyTrainer.p_variables[].assign", "policy_target_policy.PolicyTrainer.p_variables[].get_shape"], "methods", ["None"], ["", "def", "assign_weight", "(", "self", ")", ":", "\n", "        ", "self", ".", "assign_op", "=", "dict", "(", ")", "\n", "self", ".", "assign_op", "[", "'p_variables'", "]", "=", "[", "]", "\n", "k1", "=", "len", "(", "self", ".", "p_variables", ")", "\n", "self", ".", "x", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k1", ")", ":", "\n", "            ", "self", ".", "x", ".", "append", "(", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "self", ".", "p_variables", "[", "i", "]", ".", "get_shape", "(", ")", ")", ")", "\n", "self", ".", "assign_op", "[", "'p_variables'", "]", ".", "append", "(", "self", ".", "p_variables", "[", "i", "]", ".", "assign", "(", "self", ".", "x", "[", "i", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTrainer.set_weigths": [[88, 91], ["enumerate", "policy_target_policy.PolicyTrainer.session.run"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run"], ["", "", "def", "set_weigths", "(", "self", ",", "weight_dict", ")", ":", "\n", "        ", "for", "i", ",", "weight", "in", "enumerate", "(", "weight_dict", "[", "'p_variables'", "]", ")", ":", "\n", "            ", "self", ".", "session", ".", "run", "(", "self", ".", "assign_op", "[", "'p_variables'", "]", "[", "i", "]", ",", "feed_dict", "=", "{", "self", ".", "x", "[", "i", "]", ":", "weight", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTrainer.set_all_weights": [[92, 95], ["enumerate", "policy_target_policy.PolicyTrainer.session.run"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run"], ["", "", "def", "set_all_weights", "(", "self", ",", "weight_dict", ")", ":", "\n", "        ", "for", "i", ",", "weight", "in", "enumerate", "(", "weight_dict", "[", "'p_variables'", "]", ")", ":", "\n", "            ", "self", ".", "session", ".", "run", "(", "self", ".", "assign_op", "[", "'p_variables'", "]", "[", "i", "]", ",", "feed_dict", "=", "{", "self", ".", "x", "[", "i", "]", ":", "weight", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTargetPolicyTrainer.__init__": [[97, 119], ["len", "maddpg_o.BatchInput().get", "policy_target_policy.p_train", "policy_target_policy.PolicyTargetPolicyTrainer.get_p_variables", "policy_target_policy.PolicyTargetPolicyTrainer.assign_weight", "maddpg_o.BatchInput", "str"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.Uint8Input.get", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTargetPolicyTrainer.get_p_variables", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.PolicyTrainer.assign_weight"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "model", ",", "obs_shape_n", ",", "session", ",", "act_space_n", ",", "agent_index", ",", "args", ",", "local_q_func", "=", "False", ")", ":", "\n", "        ", "self", ".", "session", "=", "session", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "n", "=", "len", "(", "obs_shape_n", ")", "\n", "self", ".", "num_agents", "=", "args", ".", "num_agents", "\n", "self", ".", "agent_index", "=", "agent_index", "\n", "self", ".", "args", "=", "args", "\n", "obs_ph", "=", "U", ".", "BatchInput", "(", "obs_shape_n", "[", "self", ".", "agent_index", "]", ",", "name", "=", "\"observation\"", "+", "str", "(", "self", ".", "agent_index", ")", ")", ".", "get", "(", ")", "\n", "\n", "self", ".", "act", ",", "self", ".", "target_act", "=", "p_train", "(", "\n", "scope", "=", "self", ".", "name", ",", "\n", "make_obs_ph", "=", "obs_ph", ",", "\n", "act_space_n", "=", "act_space_n", ",", "\n", "p_index", "=", "agent_index", ",", "\n", "p_func", "=", "model", ",", "\n", "grad_norm_clipping", "=", "0.5", ",", "\n", "local_q_func", "=", "local_q_func", ",", "\n", "num_units", "=", "args", ".", "num_units", "\n", ")", "\n", "\n", "self", ".", "get_p_variables", "(", ")", "\n", "self", ".", "assign_weight", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTargetPolicyTrainer.action": [[120, 122], ["policy_target_policy.PolicyTargetPolicyTrainer.act"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "obs", ")", ":", "\n", "        ", "return", "self", ".", "act", "(", "obs", "[", "None", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTargetPolicyTrainer.batch_action": [[123, 125], ["policy_target_policy.PolicyTargetPolicyTrainer.act"], "methods", ["None"], ["", "def", "batch_action", "(", "self", ",", "obs", ")", ":", "\n", "        ", "return", "self", ".", "act", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTargetPolicyTrainer.batch_target_action": [[126, 128], ["policy_target_policy.PolicyTargetPolicyTrainer.target_act"], "methods", ["None"], ["", "def", "batch_target_action", "(", "self", ",", "obs", ")", ":", "\n", "        ", "return", "self", ".", "target_act", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTargetPolicyTrainer.target_action": [[129, 131], ["policy_target_policy.PolicyTargetPolicyTrainer.target_act"], "methods", ["None"], ["", "def", "target_action", "(", "self", ",", "obs", ")", ":", "\n", "        ", "return", "self", ".", "target_act", "(", "obs", "[", "None", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTargetPolicyTrainer.get_p_variables": [[132, 136], ["tensorflow.variable_scope", "maddpg_o.scope_vars", "maddpg_o.scope_vars", "maddpg_o.absolute_scope_name", "maddpg_o.absolute_scope_name"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name"], ["", "def", "get_p_variables", "(", "self", ",", "reuse", "=", "True", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "name", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "self", ".", "p_variables", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"p_func\"", ")", ")", "\n", "self", ".", "target_p_variables", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_p_func\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTargetPolicyTrainer.get_weigths": [[137, 142], ["dict", "policy_target_policy.PolicyTargetPolicyTrainer.session.run", "policy_target_policy.PolicyTargetPolicyTrainer.session.run"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run"], ["", "", "def", "get_weigths", "(", "self", ")", ":", "\n", "        ", "weigths_dict", "=", "dict", "(", ")", "\n", "weigths_dict", "[", "'p_variables'", "]", "=", "self", ".", "session", ".", "run", "(", "self", ".", "p_variables", ")", "\n", "weigths_dict", "[", "'target_p_variables'", "]", "=", "self", ".", "session", ".", "run", "(", "self", ".", "target_p_variables", ")", "\n", "return", "weigths_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTargetPolicyTrainer.assign_weight": [[143, 159], ["dict", "len", "range", "range", "policy_target_policy.PolicyTargetPolicyTrainer.x.append", "policy_target_policy.PolicyTargetPolicyTrainer.assign_op[].append", "policy_target_policy.PolicyTargetPolicyTrainer.y.append", "policy_target_policy.PolicyTargetPolicyTrainer.assign_op[].append", "tensorflow.placeholder", "policy_target_policy.PolicyTargetPolicyTrainer.p_variables[].assign", "tensorflow.placeholder", "policy_target_policy.PolicyTargetPolicyTrainer.target_p_variables[].assign", "policy_target_policy.PolicyTargetPolicyTrainer.p_variables[].get_shape", "policy_target_policy.PolicyTargetPolicyTrainer.target_p_variables[].get_shape"], "methods", ["None"], ["", "def", "assign_weight", "(", "self", ")", ":", "\n", "        ", "self", ".", "assign_op", "=", "dict", "(", ")", "\n", "self", ".", "assign_op", "[", "'p_variables'", "]", "=", "[", "]", "\n", "self", ".", "assign_op", "[", "'target_p_variables'", "]", "=", "[", "]", "\n", "\n", "k1", "=", "len", "(", "self", ".", "p_variables", ")", "\n", "\n", "self", ".", "x", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k1", ")", ":", "\n", "            ", "self", ".", "x", ".", "append", "(", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "self", ".", "p_variables", "[", "i", "]", ".", "get_shape", "(", ")", ")", ")", "\n", "self", ".", "assign_op", "[", "'p_variables'", "]", ".", "append", "(", "self", ".", "p_variables", "[", "i", "]", ".", "assign", "(", "self", ".", "x", "[", "i", "]", ")", ")", "\n", "\n", "", "self", ".", "y", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k1", ")", ":", "\n", "            ", "self", ".", "y", ".", "append", "(", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "self", ".", "target_p_variables", "[", "i", "]", ".", "get_shape", "(", ")", ")", ")", "\n", "self", ".", "assign_op", "[", "'target_p_variables'", "]", ".", "append", "(", "self", ".", "target_p_variables", "[", "i", "]", ".", "assign", "(", "self", ".", "y", "[", "i", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTargetPolicyTrainer.set_weigths": [[161, 167], ["enumerate", "enumerate", "policy_target_policy.PolicyTargetPolicyTrainer.session.run", "policy_target_policy.PolicyTargetPolicyTrainer.session.run"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run"], ["", "", "def", "set_weigths", "(", "self", ",", "weight_dict", ")", ":", "\n", "        ", "for", "i", ",", "weight", "in", "enumerate", "(", "weight_dict", "[", "'p_variables'", "]", ")", ":", "\n", "            ", "self", ".", "session", ".", "run", "(", "self", ".", "assign_op", "[", "'p_variables'", "]", "[", "i", "]", ",", "feed_dict", "=", "{", "self", ".", "x", "[", "i", "]", ":", "weight", "}", ")", "\n", "\n", "", "for", "i", ",", "weight", "in", "enumerate", "(", "weight_dict", "[", "'target_p_variables'", "]", ")", ":", "\n", "            ", "self", ".", "session", ".", "run", "(", "self", ".", "assign_op", "[", "'target_p_variables'", "]", "[", "i", "]", ",", "feed_dict", "=", "{", "self", ".", "y", "[", "i", "]", ":", "weight", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTargetPolicyTrainer.set_all_weights": [[168, 174], ["enumerate", "enumerate", "policy_target_policy.PolicyTargetPolicyTrainer.session.run", "policy_target_policy.PolicyTargetPolicyTrainer.session.run"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run"], ["", "", "def", "set_all_weights", "(", "self", ",", "weight_dict", ")", ":", "\n", "        ", "for", "i", ",", "weight", "in", "enumerate", "(", "weight_dict", "[", "'p_variables'", "]", ")", ":", "\n", "            ", "self", ".", "session", ".", "run", "(", "self", ".", "assign_op", "[", "'p_variables'", "]", "[", "i", "]", ",", "feed_dict", "=", "{", "self", ".", "x", "[", "i", "]", ":", "weight", "}", ")", "\n", "\n", "", "for", "i", ",", "weight", "in", "enumerate", "(", "weight_dict", "[", "'target_p_variables'", "]", ")", ":", "\n", "            ", "self", ".", "session", ".", "run", "(", "self", ".", "assign_op", "[", "'target_p_variables'", "]", "[", "i", "]", ",", "feed_dict", "=", "{", "self", ".", "y", "[", "i", "]", ":", "weight", "}", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.p_train": [[10, 30], ["tensorflow.variable_scope", "p_func", "maddpg_o.scope_vars", "act_pdtype_n[].pdfromflat", "act_pdtype_n[].pdfromflat.sample", "maddpg_o.function", "p_func", "maddpg_o.scope_vars", "act_pdtype_n[].pdfromflat().sample", "maddpg_o.function", "maddpg_o.maddpg_local.common.distributions.make_pdtype", "act_pdtype_n[].sample_placeholder", "int", "maddpg_o.absolute_scope_name", "int", "maddpg_o.absolute_scope_name", "range", "act_pdtype_n[].pdfromflat", "len", "act_pdtype_n[].param_shape", "act_pdtype_n[].param_shape", "str"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.make_pdtype", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape"], ["def", "p_train", "(", "make_obs_ph", ",", "act_space_n", ",", "p_index", ",", "p_func", ",", "grad_norm_clipping", "=", "None", ",", "local_q_func", "=", "False", ",", "num_units", "=", "64", ",", "scope", "=", "\"trainer\"", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "# create distribtuions", "\n", "        ", "act_pdtype_n", "=", "[", "make_pdtype", "(", "act_space", ")", "for", "act_space", "in", "act_space_n", "]", "\n", "# set up placeholders", "\n", "obs_ph", "=", "make_obs_ph", "\n", "act_ph_n", "=", "[", "act_pdtype_n", "[", "i", "]", ".", "sample_placeholder", "(", "[", "None", "]", ",", "name", "=", "\"action\"", "+", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "act_space_n", ")", ")", "]", "\n", "p_input", "=", "obs_ph", "\n", "p", "=", "p_func", "(", "p_input", ",", "int", "(", "act_pdtype_n", "[", "0", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "p_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"p_func\"", ")", ")", "\n", "# wrap parameters in distribution", "\n", "act_pd", "=", "act_pdtype_n", "[", "0", "]", ".", "pdfromflat", "(", "p", ")", "\n", "act_sample", "=", "act_pd", ".", "sample", "(", ")", "\n", "act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph", "]", ",", "outputs", "=", "act_sample", ")", "\n", "# target network", "\n", "target_p", "=", "p_func", "(", "p_input", ",", "int", "(", "act_pdtype_n", "[", "0", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"target_p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "target_p_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_p_func\"", ")", ")", "\n", "target_act_sample", "=", "act_pdtype_n", "[", "0", "]", ".", "pdfromflat", "(", "target_p", ")", ".", "sample", "(", ")", "\n", "target_act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph", "]", ",", "outputs", "=", "target_act_sample", ")", "\n", "return", "act", ",", "target_act", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_normal.MADDPGAgentTrainer.__init__": [[127, 167], ["len", "range", "maddpg_normal.q_train", "maddpg_normal.p_train", "maddpg_o.maddpg_local.micro.n_replay_buffer.ReplayBuffer", "maddpg_normal.MADDPGAgentTrainer.get_p_q_variables", "maddpg_normal.MADDPGAgentTrainer.assign_weight", "obs_ph_n.append", "maddpg_o.BatchInput().get", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer", "maddpg_o.BatchInput", "str"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.q_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.PolicyTrainer.get_p_q_variables", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.PolicyTrainer.assign_weight", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.Uint8Input.get"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "model_p", ",", "model_q", ",", "obs_shape_n", ",", "act_space_n", ",", "agent_index", ",", "args", ",", "num_units", ",", "sess", ",", "local_q_func", "=", "False", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "n", "=", "len", "(", "obs_shape_n", ")", "\n", "self", ".", "agent_index", "=", "agent_index", "\n", "self", ".", "session", "=", "sess", "\n", "self", ".", "args", "=", "args", "\n", "obs_ph_n", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "            ", "obs_ph_n", ".", "append", "(", "U", ".", "BatchInput", "(", "obs_shape_n", "[", "i", "]", ",", "name", "=", "\"observation\"", "+", "str", "(", "i", ")", ")", ".", "get", "(", ")", ")", "\n", "\n", "# Create all the functions necessary to train the model", "\n", "", "self", ".", "q_train", ",", "self", ".", "q_update", ",", "self", ".", "q_debug", "=", "q_train", "(", "\n", "scope", "=", "self", ".", "name", ",", "\n", "make_obs_ph_n", "=", "obs_ph_n", ",", "\n", "act_space_n", "=", "act_space_n", ",", "\n", "q_index", "=", "agent_index", ",", "\n", "q_func", "=", "model_q", ",", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "args", ".", "lr", ")", ",", "\n", "grad_norm_clipping", "=", "0.5", ",", "\n", "local_q_func", "=", "local_q_func", ",", "\n", "num_units", "=", "args", ".", "num_units", "\n", ")", "\n", "self", ".", "act", ",", "self", ".", "p_train", ",", "self", ".", "p_update", ",", "self", ".", "p_debug", "=", "p_train", "(", "\n", "scope", "=", "self", ".", "name", ",", "\n", "make_obs_ph_n", "=", "obs_ph_n", ",", "\n", "act_space_n", "=", "act_space_n", ",", "\n", "p_index", "=", "agent_index", ",", "\n", "p_func", "=", "model_p", ",", "\n", "q_func", "=", "model_q", ",", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "args", ".", "lr", ")", ",", "\n", "grad_norm_clipping", "=", "0.5", ",", "\n", "local_q_func", "=", "local_q_func", ",", "\n", "num_units", "=", "args", ".", "num_units", "\n", ")", "\n", "# Create experience buffer", "\n", "self", ".", "replay_buffer", "=", "ReplayBuffer", "(", "1e6", ")", "\n", "self", ".", "max_replay_buffer_len", "=", "args", ".", "batch_size", "*", "args", ".", "max_episode_len", "\n", "self", ".", "replay_sample_index", "=", "None", "\n", "self", ".", "get_p_q_variables", "(", ")", "\n", "self", ".", "assign_weight", "(", ")", "\n", "# self.get_p_q_variables()", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_normal.MADDPGAgentTrainer.action": [[170, 173], ["maddpg_normal.MADDPGAgentTrainer.act"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "obs", ")", ":", "\n", "# print(obs[None].shape)", "\n", "        ", "return", "self", ".", "act", "(", "obs", "[", "None", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_normal.MADDPGAgentTrainer.experience": [[174, 177], ["maddpg_normal.MADDPGAgentTrainer.replay_buffer.add", "float"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.add"], ["", "def", "experience", "(", "self", ",", "obs", ",", "act", ",", "rew", ",", "new_obs", ",", "done", ")", ":", "\n", "# Store transition in the replay buffer.", "\n", "        ", "self", ".", "replay_buffer", ".", "add", "(", "obs", ",", "act", ",", "rew", ",", "new_obs", ",", "float", "(", "done", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_normal.MADDPGAgentTrainer.preupdate": [[178, 180], ["None"], "methods", ["None"], ["", "def", "preupdate", "(", "self", ")", ":", "\n", "        ", "self", ".", "replay_sample_index", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_normal.MADDPGAgentTrainer.get_p_q_variables": [[181, 187], ["tensorflow.variable_scope", "maddpg_o.scope_vars", "maddpg_o.scope_vars", "maddpg_o.scope_vars", "maddpg_o.scope_vars", "maddpg_o.absolute_scope_name", "maddpg_o.absolute_scope_name", "maddpg_o.absolute_scope_name", "maddpg_o.absolute_scope_name"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name"], ["", "def", "get_p_q_variables", "(", "self", ",", "reuse", "=", "True", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "name", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "self", ".", "p_variables", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"p_func\"", ")", ")", "\n", "self", ".", "target_p_variables", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_p_func\"", ")", ")", "\n", "self", ".", "q_variables", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"q_func\"", ")", ")", "\n", "self", ".", "target_q_variables", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_q_func\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_normal.MADDPGAgentTrainer.get_weigths": [[188, 195], ["dict", "maddpg_normal.MADDPGAgentTrainer.session.run", "maddpg_normal.MADDPGAgentTrainer.session.run", "maddpg_normal.MADDPGAgentTrainer.session.run", "maddpg_normal.MADDPGAgentTrainer.session.run"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run"], ["", "", "def", "get_weigths", "(", "self", ")", ":", "\n", "        ", "weigths_dict", "=", "dict", "(", ")", "\n", "weigths_dict", "[", "'p_variables'", "]", "=", "self", ".", "session", ".", "run", "(", "self", ".", "p_variables", ")", "\n", "weigths_dict", "[", "'target_p_variables'", "]", "=", "self", ".", "session", ".", "run", "(", "self", ".", "target_p_variables", ")", "\n", "weigths_dict", "[", "'q_variables'", "]", "=", "self", ".", "session", ".", "run", "(", "self", ".", "q_variables", ")", "\n", "weigths_dict", "[", "'target_q_variables'", "]", "=", "self", ".", "session", ".", "run", "(", "self", ".", "target_q_variables", ")", "\n", "return", "weigths_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_normal.MADDPGAgentTrainer.assign_weight": [[204, 234], ["dict", "len", "len", "range", "range", "range", "range", "maddpg_normal.MADDPGAgentTrainer.x.append", "maddpg_normal.MADDPGAgentTrainer.assign_op[].append", "maddpg_normal.MADDPGAgentTrainer.y.append", "maddpg_normal.MADDPGAgentTrainer.assign_op[].append", "maddpg_normal.MADDPGAgentTrainer.z.append", "maddpg_normal.MADDPGAgentTrainer.assign_op[].append", "maddpg_normal.MADDPGAgentTrainer.w.append", "maddpg_normal.MADDPGAgentTrainer.assign_op[].append", "tensorflow.placeholder", "maddpg_normal.MADDPGAgentTrainer.p_variables[].assign", "tensorflow.placeholder", "maddpg_normal.MADDPGAgentTrainer.target_p_variables[].assign", "tensorflow.placeholder", "maddpg_normal.MADDPGAgentTrainer.q_variables[].assign", "tensorflow.placeholder", "maddpg_normal.MADDPGAgentTrainer.target_q_variables[].assign", "maddpg_normal.MADDPGAgentTrainer.p_variables[].get_shape", "maddpg_normal.MADDPGAgentTrainer.target_p_variables[].get_shape", "maddpg_normal.MADDPGAgentTrainer.q_variables[].get_shape", "maddpg_normal.MADDPGAgentTrainer.target_q_variables[].get_shape"], "methods", ["None"], ["", "def", "assign_weight", "(", "self", ")", ":", "\n", "        ", "self", ".", "assign_op", "=", "dict", "(", ")", "\n", "self", ".", "assign_op", "[", "'p_variables'", "]", "=", "[", "]", "\n", "self", ".", "assign_op", "[", "'target_p_variables'", "]", "=", "[", "]", "\n", "self", ".", "assign_op", "[", "'q_variables'", "]", "=", "[", "]", "\n", "self", ".", "assign_op", "[", "'target_q_variables'", "]", "=", "[", "]", "\n", "\n", "k1", "=", "len", "(", "self", ".", "p_variables", ")", "\n", "k2", "=", "len", "(", "self", ".", "q_variables", ")", "\n", "\n", "self", ".", "x", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k1", ")", ":", "\n", "            ", "self", ".", "x", ".", "append", "(", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "self", ".", "p_variables", "[", "i", "]", ".", "get_shape", "(", ")", ")", ")", "\n", "self", ".", "assign_op", "[", "'p_variables'", "]", ".", "append", "(", "self", ".", "p_variables", "[", "i", "]", ".", "assign", "(", "self", ".", "x", "[", "i", "]", ")", ")", "\n", "\n", "", "self", ".", "y", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k1", ")", ":", "\n", "            ", "self", ".", "y", ".", "append", "(", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "self", ".", "target_p_variables", "[", "i", "]", ".", "get_shape", "(", ")", ")", ")", "\n", "self", ".", "assign_op", "[", "'target_p_variables'", "]", ".", "append", "(", "self", ".", "target_p_variables", "[", "i", "]", ".", "assign", "(", "self", ".", "y", "[", "i", "]", ")", ")", "\n", "\n", "\n", "", "self", ".", "z", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k2", ")", ":", "\n", "            ", "self", ".", "z", ".", "append", "(", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "self", ".", "q_variables", "[", "i", "]", ".", "get_shape", "(", ")", ")", ")", "\n", "self", ".", "assign_op", "[", "'q_variables'", "]", ".", "append", "(", "self", ".", "q_variables", "[", "i", "]", ".", "assign", "(", "self", ".", "z", "[", "i", "]", ")", ")", "\n", "\n", "", "self", ".", "w", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k2", ")", ":", "\n", "            ", "self", ".", "w", ".", "append", "(", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "self", ".", "target_q_variables", "[", "i", "]", ".", "get_shape", "(", ")", ")", ")", "\n", "self", ".", "assign_op", "[", "'target_q_variables'", "]", ".", "append", "(", "self", ".", "target_q_variables", "[", "i", "]", ".", "assign", "(", "self", ".", "w", "[", "i", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_normal.MADDPGAgentTrainer.set_weigths": [[291, 304], ["enumerate", "enumerate", "maddpg_normal.MADDPGAgentTrainer.session.run", "maddpg_normal.MADDPGAgentTrainer.session.run", "enumerate", "enumerate", "maddpg_normal.MADDPGAgentTrainer.session.run", "maddpg_normal.MADDPGAgentTrainer.session.run"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run"], ["", "", "def", "set_weigths", "(", "self", ",", "weight_dict", ",", "only_policy", "=", "False", ")", ":", "\n", "        ", "for", "i", ",", "weight", "in", "enumerate", "(", "weight_dict", "[", "'p_variables'", "]", ")", ":", "\n", "            ", "self", ".", "session", ".", "run", "(", "self", ".", "assign_op", "[", "'p_variables'", "]", "[", "i", "]", ",", "feed_dict", "=", "{", "self", ".", "x", "[", "i", "]", ":", "weight", "}", ")", "\n", "\n", "", "for", "i", ",", "weight", "in", "enumerate", "(", "weight_dict", "[", "'target_p_variables'", "]", ")", ":", "\n", "            ", "self", ".", "session", ".", "run", "(", "self", ".", "assign_op", "[", "'target_p_variables'", "]", "[", "i", "]", ",", "feed_dict", "=", "{", "self", ".", "y", "[", "i", "]", ":", "weight", "}", ")", "\n", "\n", "", "if", "not", "only_policy", ":", "\n", "            ", "for", "i", ",", "weight", "in", "enumerate", "(", "weight_dict", "[", "'q_variables'", "]", ")", ":", "\n", "                ", "self", ".", "session", ".", "run", "(", "self", ".", "assign_op", "[", "'q_variables'", "]", "[", "i", "]", ",", "feed_dict", "=", "{", "self", ".", "z", "[", "i", "]", ":", "weight", "}", ")", "\n", "\n", "", "for", "i", ",", "weight", "in", "enumerate", "(", "weight_dict", "[", "'target_q_variables'", "]", ")", ":", "\n", "                ", "self", ".", "session", ".", "run", "(", "self", ".", "assign_op", "[", "'target_q_variables'", "]", "[", "i", "]", ",", "feed_dict", "=", "{", "self", ".", "w", "[", "i", "]", ":", "weight", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_normal.MADDPGAgentTrainer.update": [[306, 338], ["maddpg_normal.MADDPGAgentTrainer.replay_buffer.make_index", "range", "maddpg_normal.MADDPGAgentTrainer.replay_buffer.sample_index", "range", "maddpg_normal.MADDPGAgentTrainer.q_train", "maddpg_normal.MADDPGAgentTrainer.p_train", "maddpg_normal.MADDPGAgentTrainer.p_update", "maddpg_normal.MADDPGAgentTrainer.q_update", "agents[].replay_buffer.sample_index", "obs_n.append", "obs_next_n.append", "act_n.append", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.std", "range"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.make_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.q_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.std"], ["", "", "", "def", "update", "(", "self", ",", "agents", ")", ":", "\n", "\n", "        ", "self", ".", "replay_sample_index", "=", "self", ".", "replay_buffer", ".", "make_index", "(", "self", ".", "args", ".", "batch_size", ")", "\n", "# collect replay sample from all agents", "\n", "obs_n", "=", "[", "]", "\n", "obs_next_n", "=", "[", "]", "\n", "act_n", "=", "[", "]", "\n", "index", "=", "self", ".", "replay_sample_index", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "            ", "obs", ",", "act", ",", "rew", ",", "obs_next", ",", "done", "=", "agents", "[", "i", "]", ".", "replay_buffer", ".", "sample_index", "(", "index", ")", "\n", "obs_n", ".", "append", "(", "obs", ")", "\n", "obs_next_n", ".", "append", "(", "obs_next", ")", "\n", "act_n", ".", "append", "(", "act", ")", "\n", "", "obs", ",", "act", ",", "rew", ",", "obs_next", ",", "done", "=", "self", ".", "replay_buffer", ".", "sample_index", "(", "index", ")", "\n", "\n", "# train q network", "\n", "num_sample", "=", "1", "\n", "target_q", "=", "0.0", "\n", "for", "i", "in", "range", "(", "num_sample", ")", ":", "\n", "            ", "target_act_next_n", "=", "[", "agents", "[", "i", "]", ".", "p_debug", "[", "'target_act'", "]", "(", "obs_next_n", "[", "i", "]", ")", "for", "i", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "target_q_next", "=", "self", ".", "q_debug", "[", "'target_q_values'", "]", "(", "*", "(", "obs_next_n", "+", "target_act_next_n", ")", ")", "\n", "target_q", "+=", "rew", "+", "self", ".", "args", ".", "gamma", "*", "(", "1.0", "-", "done", ")", "*", "target_q_next", "\n", "", "target_q", "/=", "num_sample", "\n", "q_loss", "=", "self", ".", "q_train", "(", "*", "(", "obs_n", "+", "act_n", "+", "[", "target_q", "]", ")", ")", "\n", "\n", "# train p network", "\n", "p_loss", "=", "self", ".", "p_train", "(", "*", "(", "obs_n", "+", "act_n", ")", ")", "\n", "\n", "self", ".", "p_update", "(", ")", "\n", "self", ".", "q_update", "(", ")", "\n", "\n", "return", "[", "q_loss", ",", "p_loss", ",", "np", ".", "mean", "(", "target_q", ")", ",", "np", ".", "mean", "(", "rew", ")", ",", "np", ".", "mean", "(", "target_q_next", ")", ",", "np", ".", "std", "(", "target_q", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_normal.discount_with_dones": [[14, 22], ["zip", "discounted.append"], "function", ["None"], ["def", "discount_with_dones", "(", "rewards", ",", "dones", ",", "gamma", ")", ":", "\n", "    ", "discounted", "=", "[", "]", "\n", "r", "=", "0", "\n", "for", "reward", ",", "done", "in", "zip", "(", "rewards", "[", ":", ":", "-", "1", "]", ",", "dones", "[", ":", ":", "-", "1", "]", ")", ":", "\n", "        ", "r", "=", "reward", "+", "gamma", "*", "r", "\n", "r", "=", "r", "*", "(", "1.", "-", "done", ")", "\n", "discounted", ".", "append", "(", "r", ")", "\n", "", "return", "discounted", "[", ":", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_normal.make_update_exp": [[24, 31], ["zip", "tensorflow.group", "maddpg_o.function", "sorted", "sorted", "tf.group.append", "var_target.assign"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function"], ["", "def", "make_update_exp", "(", "vals", ",", "target_vals", ")", ":", "\n", "    ", "polyak", "=", "1.0", "-", "1e-2", "\n", "expression", "=", "[", "]", "\n", "for", "var", ",", "var_target", "in", "zip", "(", "sorted", "(", "vals", ",", "key", "=", "lambda", "v", ":", "v", ".", "name", ")", ",", "sorted", "(", "target_vals", ",", "key", "=", "lambda", "v", ":", "v", ".", "name", ")", ")", ":", "\n", "        ", "expression", ".", "append", "(", "var_target", ".", "assign", "(", "polyak", "*", "var_target", "+", "(", "1.0", "-", "polyak", ")", "*", "var", ")", ")", "\n", "", "expression", "=", "tf", ".", "group", "(", "*", "expression", ")", "\n", "return", "U", ".", "function", "(", "[", "]", ",", "[", "]", ",", "updates", "=", "[", "expression", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_normal.p_train": [[33, 82], ["tensorflow.variable_scope", "p_func", "maddpg_o.scope_vars", "act_pdtype_n[].pdfromflat", "act_pdtype_n[].pdfromflat.sample", "tensorflow.reduce_mean", "act_pdtype_n[].pdfromflat.sample", "tensorflow.concat", "maddpg_o.minimize_and_clip", "maddpg_o.function", "maddpg_o.function", "maddpg_o.function", "p_func", "maddpg_o.scope_vars", "maddpg_normal.make_update_exp", "act_pdtype_n[].pdfromflat().sample", "maddpg_o.function", "maddpg_o.maddpg_local.common.distributions.make_pdtype", "act_pdtype_n[].sample_placeholder", "int", "maddpg_o.absolute_scope_name", "tensorflow.square", "tensorflow.concat", "q_func", "tensorflow.reduce_mean", "int", "maddpg_o.absolute_scope_name", "range", "act_pdtype_n[].pdfromflat.flatparam", "act_pdtype_n[].pdfromflat", "len", "act_pdtype_n[].param_shape", "act_pdtype_n[].param_shape", "str"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.minimize_and_clip", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.make_update_exp", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.make_pdtype", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.flatparam", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape"], ["", "def", "p_train", "(", "make_obs_ph_n", ",", "act_space_n", ",", "p_index", ",", "p_func", ",", "q_func", ",", "optimizer", ",", "grad_norm_clipping", "=", "None", ",", "local_q_func", "=", "False", ",", "num_units", "=", "64", ",", "scope", "=", "\"trainer\"", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "\n", "        ", "act_pdtype_n", "=", "[", "make_pdtype", "(", "act_space", ")", "for", "act_space", "in", "act_space_n", "]", "\n", "\n", "# set up placeholders", "\n", "obs_ph_n", "=", "make_obs_ph_n", "\n", "act_ph_n", "=", "[", "act_pdtype_n", "[", "i", "]", ".", "sample_placeholder", "(", "[", "None", "]", ",", "name", "=", "\"action\"", "+", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "act_space_n", ")", ")", "]", "\n", "\n", "p_input", "=", "obs_ph_n", "[", "p_index", "]", "\n", "\n", "# print(\"p_train/p_func:\", scope)", "\n", "p", "=", "p_func", "(", "p_input", ",", "int", "(", "act_pdtype_n", "[", "p_index", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "p_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"p_func\"", ")", ")", "\n", "\n", "# wrap parameters in distribution", "\n", "act_pd", "=", "act_pdtype_n", "[", "p_index", "]", ".", "pdfromflat", "(", "p", ")", "\n", "\n", "act_sample", "=", "act_pd", ".", "sample", "(", ")", "\n", "p_reg", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "act_pd", ".", "flatparam", "(", ")", ")", ")", "\n", "\n", "act_input_n", "=", "act_ph_n", "+", "[", "]", "\n", "act_input_n", "[", "p_index", "]", "=", "act_pd", ".", "sample", "(", ")", "\n", "q_input", "=", "tf", ".", "concat", "(", "obs_ph_n", "+", "act_input_n", ",", "1", ")", "\n", "if", "local_q_func", ":", "\n", "            ", "q_input", "=", "tf", ".", "concat", "(", "[", "obs_ph_n", "[", "p_index", "]", ",", "act_input_n", "[", "p_index", "]", "]", ",", "1", ")", "\n", "", "q", "=", "q_func", "(", "q_input", ",", "1", ",", "scope", "=", "\"q_func\"", ",", "reuse", "=", "True", ",", "num_units", "=", "num_units", ")", "[", ":", ",", "0", "]", "\n", "pg_loss", "=", "-", "tf", ".", "reduce_mean", "(", "q", ")", "\n", "\n", "loss", "=", "pg_loss", "+", "p_reg", "*", "1e-3", "\n", "\n", "optimize_expr", "=", "U", ".", "minimize_and_clip", "(", "optimizer", ",", "loss", ",", "p_func_vars", ",", "grad_norm_clipping", ")", "\n", "\n", "# Create callable functions", "\n", "train", "=", "U", ".", "function", "(", "inputs", "=", "obs_ph_n", "+", "act_ph_n", ",", "outputs", "=", "loss", ",", "updates", "=", "[", "optimize_expr", "]", ")", "\n", "act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "outputs", "=", "act_sample", ")", "\n", "# attention = U.function(inputs=[obs_ph_n[p_index]], outputs=[attn.good_attn, attn.adv_attn])", "\n", "p_values", "=", "U", ".", "function", "(", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "p", ")", "\n", "# print([obs_ph_n[p_index]], act_sample)", "\n", "\n", "# target network", "\n", "target_p", "=", "p_func", "(", "p_input", ",", "int", "(", "act_pdtype_n", "[", "p_index", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"target_p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "target_p_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_p_func\"", ")", ")", "\n", "update_target_p", "=", "make_update_exp", "(", "p_func_vars", ",", "target_p_func_vars", ")", "\n", "\n", "target_act_sample", "=", "act_pdtype_n", "[", "p_index", "]", ".", "pdfromflat", "(", "target_p", ")", ".", "sample", "(", ")", "\n", "target_act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "outputs", "=", "target_act_sample", ")", "\n", "\n", "return", "act", ",", "train", ",", "update_target_p", ",", "{", "'p_values'", ":", "p_values", ",", "'target_act'", ":", "target_act", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_normal.q_train": [[84, 124], ["tensorflow.variable_scope", "len", "tensorflow.placeholder", "tensorflow.concat", "maddpg_o.scope_vars", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "maddpg_o.minimize_and_clip", "maddpg_o.function", "maddpg_o.function", "maddpg_o.scope_vars", "maddpg_normal.make_update_exp", "maddpg_o.function", "maddpg_o.maddpg_local.common.distributions.make_pdtype", "act_pdtype_n[].sample_placeholder", "tensorflow.concat", "q_func", "maddpg_o.absolute_scope_name", "tensorflow.square", "tensorflow.square", "q_func", "maddpg_o.absolute_scope_name", "range", "str"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.minimize_and_clip", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.make_update_exp", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.make_pdtype", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name"], ["", "", "def", "q_train", "(", "make_obs_ph_n", ",", "act_space_n", ",", "q_index", ",", "q_func", ",", "optimizer", ",", "grad_norm_clipping", "=", "None", ",", "local_q_func", "=", "False", ",", "scope", "=", "\"trainer\"", ",", "reuse", "=", "None", ",", "num_units", "=", "64", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "# create distribtuions", "\n", "        ", "act_pdtype_n", "=", "[", "make_pdtype", "(", "act_space", ")", "for", "act_space", "in", "act_space_n", "]", "\n", "\n", "# set up placeholders", "\n", "n", "=", "len", "(", "act_space_n", ")", "\n", "obs_ph_n", "=", "make_obs_ph_n", "\n", "act_ph_n", "=", "[", "act_pdtype_n", "[", "i", "]", ".", "sample_placeholder", "(", "[", "None", "]", ",", "name", "=", "\"action\"", "+", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "n", ")", "]", "\n", "# exclude_i = list(filter(lambda i: i != q_index, range(n)))", "\n", "# mean_act = [act_ph_n[q_index], tf.reduce_mean([act_ph_n[i] for i in exclude_i])]", "\n", "target_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ",", "name", "=", "\"target\"", ")", "\n", "#print(act_ph_n)", "\n", "q_input", "=", "tf", ".", "concat", "(", "obs_ph_n", "+", "act_ph_n", ",", "1", ")", "\n", "if", "local_q_func", ":", "\n", "            ", "q_input", "=", "tf", ".", "concat", "(", "[", "obs_ph_n", "[", "q_index", "]", ",", "act_ph_n", "[", "q_index", "]", "]", ",", "1", ")", "\n", "", "q", "=", "q_func", "(", "q_input", ",", "1", ",", "scope", "=", "\"q_func\"", ",", "num_units", "=", "num_units", ")", "[", ":", ",", "0", "]", "\n", "q_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"q_func\"", ")", ")", "\n", "\n", "q_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "q", "-", "target_ph", ")", ")", "\n", "\n", "# viscosity solution to Bellman differential equation in place of an initial condition", "\n", "q_reg", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "q", ")", ")", "\n", "loss", "=", "q_loss", "#+ 1e-3 * q_reg", "\n", "\n", "# print(reuse)", "\n", "optimize_expr", "=", "U", ".", "minimize_and_clip", "(", "optimizer", ",", "loss", ",", "q_func_vars", ",", "grad_norm_clipping", ")", "\n", "\n", "# Create callable functions", "\n", "train", "=", "U", ".", "function", "(", "inputs", "=", "obs_ph_n", "+", "act_ph_n", "+", "[", "target_ph", "]", ",", "outputs", "=", "loss", ",", "updates", "=", "[", "optimize_expr", "]", ")", "\n", "q_values", "=", "U", ".", "function", "(", "obs_ph_n", "+", "act_ph_n", ",", "q", ")", "\n", "\n", "# target network", "\n", "target_q", "=", "q_func", "(", "q_input", ",", "1", ",", "scope", "=", "\"target_q_func\"", ",", "num_units", "=", "num_units", ")", "[", ":", ",", "0", "]", "\n", "target_q_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_q_func\"", ")", ")", "\n", "update_target_q", "=", "make_update_exp", "(", "q_func_vars", ",", "target_q_func_vars", ")", "\n", "\n", "target_q_values", "=", "U", ".", "function", "(", "obs_ph_n", "+", "act_ph_n", ",", "target_q", ")", "\n", "\n", "return", "train", ",", "update_target_q", ",", "{", "'q_values'", ":", "q_values", ",", "'target_q_values'", ":", "target_q_values", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentTrainer.__init__": [[234, 271], ["len", "range", "maddpg.q_train", "maddpg.p_train", "maddpg_o.maddpg_local.micro.n_replay_buffer.ReplayBuffer", "obs_ph_n.append", "maddpg_o.BatchInput().get", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer", "maddpg_o.BatchInput", "str"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.q_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.Uint8Input.get"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "model", ",", "obs_shape_n", ",", "act_space_n", ",", "agent_index", ",", "args", ",", "local_q_func", "=", "False", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "n", "=", "len", "(", "obs_shape_n", ")", "\n", "self", ".", "agent_index", "=", "agent_index", "\n", "self", ".", "args", "=", "args", "\n", "obs_ph_n", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "            ", "obs_ph_n", ".", "append", "(", "U", ".", "BatchInput", "(", "obs_shape_n", "[", "i", "]", ",", "name", "=", "\"observation\"", "+", "str", "(", "i", ")", ")", ".", "get", "(", ")", ")", "\n", "\n", "# Create all the functions necessary to train the model", "\n", "", "self", ".", "q_train", ",", "self", ".", "q_update", ",", "self", ".", "q_debug", "=", "q_train", "(", "\n", "scope", "=", "self", ".", "name", ",", "\n", "make_obs_ph_n", "=", "obs_ph_n", ",", "\n", "act_space_n", "=", "act_space_n", ",", "\n", "q_index", "=", "agent_index", ",", "\n", "q_func", "=", "model", ",", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "args", ".", "lr", ")", ",", "\n", "grad_norm_clipping", "=", "0.5", ",", "\n", "local_q_func", "=", "local_q_func", ",", "\n", "num_units", "=", "args", ".", "num_units", "\n", ")", "\n", "self", ".", "act", ",", "self", ".", "p_train", ",", "self", ".", "p_update", ",", "self", ".", "p_debug", "=", "p_train", "(", "\n", "scope", "=", "self", ".", "name", ",", "\n", "make_obs_ph_n", "=", "obs_ph_n", ",", "\n", "act_space_n", "=", "act_space_n", ",", "\n", "p_index", "=", "agent_index", ",", "\n", "p_func", "=", "model", ",", "\n", "q_func", "=", "model", ",", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "args", ".", "lr", ")", ",", "\n", "grad_norm_clipping", "=", "0.5", ",", "\n", "local_q_func", "=", "local_q_func", ",", "\n", "num_units", "=", "args", ".", "num_units", "\n", ")", "\n", "# Create experience buffer", "\n", "self", ".", "replay_buffer", "=", "ReplayBuffer", "(", "1e6", ")", "\n", "self", ".", "max_replay_buffer_len", "=", "args", ".", "batch_size", "*", "args", ".", "max_episode_len", "\n", "self", ".", "replay_sample_index", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentTrainer.action": [[272, 275], ["maddpg.MADDPGAgentTrainer.act"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "obs", ")", ":", "\n", "# print(obs[None].shape)", "\n", "        ", "return", "self", ".", "act", "(", "obs", "[", "None", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentTrainer.experience": [[276, 279], ["maddpg.MADDPGAgentTrainer.replay_buffer.add", "float"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.add"], ["", "def", "experience", "(", "self", ",", "obs", ",", "act", ",", "rew", ",", "new_obs", ",", "done", ",", "terminal", ")", ":", "\n", "# Store transition in the replay buffer.", "\n", "        ", "self", ".", "replay_buffer", ".", "add", "(", "obs", ",", "act", ",", "rew", ",", "new_obs", ",", "float", "(", "done", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentTrainer.preupdate": [[280, 282], ["None"], "methods", ["None"], ["", "def", "preupdate", "(", "self", ")", ":", "\n", "        ", "self", ".", "replay_sample_index", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentTrainer.update": [[283, 319], ["maddpg.MADDPGAgentTrainer.replay_buffer.make_index", "range", "maddpg.MADDPGAgentTrainer.replay_buffer.sample_index", "range", "maddpg.MADDPGAgentTrainer.q_train", "maddpg.MADDPGAgentTrainer.p_train", "maddpg.MADDPGAgentTrainer.p_update", "maddpg.MADDPGAgentTrainer.q_update", "len", "agents[].replay_buffer.sample_index", "obs_n.append", "obs_next_n.append", "act_n.append", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.std", "range"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.make_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.q_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.std"], ["", "def", "update", "(", "self", ",", "agents", ",", "t", ",", "group_train", "=", "False", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "replay_buffer", ")", "<", "self", ".", "max_replay_buffer_len", ":", "# replay buffer is not large enough", "\n", "            ", "return", "\n", "", "if", "not", "t", "%", "100", "==", "0", ":", "# only update every 100 steps", "\n", "            ", "return", "\n", "\n", "", "self", ".", "replay_sample_index", "=", "self", ".", "replay_buffer", ".", "make_index", "(", "self", ".", "args", ".", "batch_size", ")", "\n", "# collect replay sample from all agents", "\n", "obs_n", "=", "[", "]", "\n", "obs_next_n", "=", "[", "]", "\n", "act_n", "=", "[", "]", "\n", "index", "=", "self", ".", "replay_sample_index", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "            ", "obs", ",", "act", ",", "rew", ",", "obs_next", ",", "done", "=", "agents", "[", "i", "]", ".", "replay_buffer", ".", "sample_index", "(", "index", ")", "\n", "obs_n", ".", "append", "(", "obs", ")", "\n", "obs_next_n", ".", "append", "(", "obs_next", ")", "\n", "act_n", ".", "append", "(", "act", ")", "\n", "", "obs", ",", "act", ",", "rew", ",", "obs_next", ",", "done", "=", "self", ".", "replay_buffer", ".", "sample_index", "(", "index", ")", "\n", "\n", "# train q network", "\n", "num_sample", "=", "1", "\n", "target_q", "=", "0.0", "\n", "for", "i", "in", "range", "(", "num_sample", ")", ":", "\n", "            ", "target_act_next_n", "=", "[", "agents", "[", "i", "]", ".", "p_debug", "[", "'target_act'", "]", "(", "obs_next_n", "[", "i", "]", ")", "for", "i", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "target_q_next", "=", "self", ".", "q_debug", "[", "'target_q_values'", "]", "(", "*", "(", "obs_next_n", "+", "target_act_next_n", ")", ")", "\n", "target_q", "+=", "rew", "+", "self", ".", "args", ".", "gamma", "*", "(", "1.0", "-", "done", ")", "*", "target_q_next", "\n", "", "target_q", "/=", "num_sample", "\n", "q_loss", "=", "self", ".", "q_train", "(", "*", "(", "obs_n", "+", "act_n", "+", "[", "target_q", "]", ")", ")", "\n", "\n", "# train p network", "\n", "p_loss", "=", "self", ".", "p_train", "(", "*", "(", "obs_n", "+", "act_n", ")", ")", "\n", "\n", "self", ".", "p_update", "(", ")", "\n", "self", ".", "q_update", "(", ")", "\n", "\n", "return", "[", "q_loss", ",", "p_loss", ",", "np", ".", "mean", "(", "target_q", ")", ",", "np", ".", "mean", "(", "rew", ")", ",", "np", ".", "mean", "(", "target_q_next", ")", ",", "np", ".", "std", "(", "target_q", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentSharedTrainer.__init__": [[321, 365], ["len", "range", "maddpg.q_train", "maddpg.group_p_train", "maddpg_o.maddpg_local.micro.n_replay_buffer.ReplayBuffer", "obs_ph_n.append", "maddpg_o.BatchInput().get", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer", "maddpg_o.BatchInput", "str"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.q_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.group_p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.Uint8Input.get"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "model", ",", "obs_shape_n", ",", "act_space_n", ",", "agent_index", ",", "num_adversaries", ",", "args", ",", "local_q_func", "=", "False", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "n", "=", "len", "(", "obs_shape_n", ")", "\n", "self", ".", "agent_index", "=", "agent_index", "\n", "self", ".", "num_adversaries", "=", "num_adversaries", "\n", "self", ".", "args", "=", "args", "\n", "obs_ph_n", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "            ", "obs_ph_n", ".", "append", "(", "U", ".", "BatchInput", "(", "obs_shape_n", "[", "i", "]", ",", "name", "=", "\"observation\"", "+", "str", "(", "i", ")", ")", ".", "get", "(", ")", ")", "\n", "\n", "\n", "# Create all the functions necessary to train the model", "\n", "# print(\"!#12\")", "\n", "", "self", ".", "q_train", ",", "self", ".", "q_update", ",", "self", ".", "q_debug", "=", "q_train", "(", "\n", "scope", "=", "self", ".", "name", ",", "\n", "make_obs_ph_n", "=", "obs_ph_n", ",", "\n", "act_space_n", "=", "act_space_n", ",", "\n", "q_index", "=", "agent_index", ",", "\n", "q_func", "=", "model", ",", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "args", ".", "lr", ")", ",", "\n", "grad_norm_clipping", "=", "0.5", ",", "\n", "local_q_func", "=", "local_q_func", ",", "\n", "num_units", "=", "args", ".", "num_units", ",", "\n", "reuse", "=", "tf", ".", "AUTO_REUSE", "\n", ")", "\n", "self", ".", "act", ",", "self", ".", "p_train", ",", "self", ".", "p_update", ",", "self", ".", "p_debug", "=", "group_p_train", "(", "\n", "scope", "=", "self", ".", "name", ",", "\n", "make_obs_ph_n", "=", "obs_ph_n", ",", "\n", "act_space_n", "=", "act_space_n", ",", "\n", "p_index", "=", "agent_index", ",", "\n", "num_adversaries", "=", "num_adversaries", ",", "\n", "p_func", "=", "model", ",", "\n", "q_func", "=", "model", ",", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "args", ".", "lr", ")", ",", "\n", "grad_norm_clipping", "=", "0.5", ",", "\n", "local_q_func", "=", "local_q_func", ",", "\n", "num_units", "=", "args", ".", "num_units", ",", "\n", "reuse", "=", "tf", ".", "AUTO_REUSE", "\n", ")", "\n", "\n", "# Create experience buffer", "\n", "self", ".", "replay_buffer", "=", "ReplayBuffer", "(", "1e6", ")", "\n", "self", ".", "max_replay_buffer_len", "=", "args", ".", "batch_size", "*", "args", ".", "max_episode_len", "\n", "self", ".", "replay_sample_index", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentSharedTrainer.action": [[366, 369], ["maddpg.MADDPGAgentSharedTrainer.act"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "obs", ")", ":", "\n", "\n", "        ", "return", "self", ".", "act", "(", "obs", "[", "None", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentSharedTrainer.experience": [[370, 373], ["maddpg.MADDPGAgentSharedTrainer.replay_buffer.add", "float"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.add"], ["", "def", "experience", "(", "self", ",", "obs", ",", "act", ",", "rew", ",", "new_obs", ",", "done", ",", "terminal", ")", ":", "\n", "# Store transition in the replay buffer.", "\n", "        ", "self", ".", "replay_buffer", ".", "add", "(", "obs", ",", "act", ",", "rew", ",", "new_obs", ",", "float", "(", "done", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentSharedTrainer.preupdate": [[374, 376], ["None"], "methods", ["None"], ["", "def", "preupdate", "(", "self", ")", ":", "\n", "        ", "self", ".", "replay_sample_index", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentSharedTrainer.update": [[377, 416], ["maddpg.MADDPGAgentSharedTrainer.replay_buffer.make_index", "range", "maddpg.MADDPGAgentSharedTrainer.replay_buffer.sample_index", "range", "maddpg.MADDPGAgentSharedTrainer.q_train", "maddpg.MADDPGAgentSharedTrainer.p_update", "maddpg.MADDPGAgentSharedTrainer.q_update", "len", "agents[].replay_buffer.sample_index", "obs_n.append", "obs_next_n.append", "act_n.append", "maddpg.MADDPGAgentSharedTrainer.group_p_train", "maddpg.MADDPGAgentSharedTrainer.p_train", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.std", "range"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.make_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.q_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.group_p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.std"], ["", "def", "update", "(", "self", ",", "agents", ",", "t", ",", "group_train", "=", "False", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "replay_buffer", ")", "<", "self", ".", "max_replay_buffer_len", ":", "# replay buffer is not large enough", "\n", "            ", "return", "\n", "", "if", "not", "t", "%", "100", "==", "0", ":", "# only update every 100 steps", "\n", "            ", "return", "\n", "\n", "", "self", ".", "replay_sample_index", "=", "self", ".", "replay_buffer", ".", "make_index", "(", "self", ".", "args", ".", "batch_size", ")", "\n", "# collect replay sample from all agents", "\n", "obs_n", "=", "[", "]", "\n", "obs_next_n", "=", "[", "]", "\n", "act_n", "=", "[", "]", "\n", "index", "=", "self", ".", "replay_sample_index", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "            ", "obs", ",", "act", ",", "rew", ",", "obs_next", ",", "done", "=", "agents", "[", "i", "]", ".", "replay_buffer", ".", "sample_index", "(", "index", ")", "\n", "obs_n", ".", "append", "(", "obs", ")", "\n", "obs_next_n", ".", "append", "(", "obs_next", ")", "\n", "act_n", ".", "append", "(", "act", ")", "\n", "", "obs", ",", "act", ",", "rew", ",", "obs_next", ",", "done", "=", "self", ".", "replay_buffer", ".", "sample_index", "(", "index", ")", "\n", "\n", "# train q network", "\n", "num_sample", "=", "1", "\n", "target_q", "=", "0.0", "\n", "for", "i", "in", "range", "(", "num_sample", ")", ":", "\n", "            ", "target_act_next_n", "=", "[", "agents", "[", "i", "]", ".", "p_debug", "[", "'target_act'", "]", "(", "obs_next_n", "[", "i", "]", ")", "for", "i", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "target_q_next", "=", "self", ".", "q_debug", "[", "'target_q_values'", "]", "(", "*", "(", "obs_next_n", "+", "target_act_next_n", ")", ")", "\n", "target_q", "+=", "rew", "+", "self", ".", "args", ".", "gamma", "*", "(", "1.0", "-", "done", ")", "*", "target_q_next", "\n", "", "target_q", "/=", "num_sample", "\n", "q_loss", "=", "self", ".", "q_train", "(", "*", "(", "obs_n", "+", "act_n", "+", "[", "target_q", "]", ")", ")", "\n", "\n", "# train p network", "\n", "if", "(", "group_train", ")", ":", "\n", "            ", "p_loss", "=", "self", ".", "group_p_train", "(", "*", "(", "obs_n", "+", "act_n", ")", ")", "\n", "", "else", ":", "\n", "            ", "p_loss", "=", "self", ".", "p_train", "(", "*", "(", "obs_n", "+", "act_n", ")", ")", "\n", "\n", "", "self", ".", "p_update", "(", ")", "\n", "self", ".", "q_update", "(", ")", "\n", "\n", "return", "[", "q_loss", ",", "p_loss", ",", "np", ".", "mean", "(", "target_q", ")", ",", "np", ".", "mean", "(", "rew", ")", ",", "np", ".", "mean", "(", "target_q_next", ")", ",", "np", ".", "std", "(", "target_q", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentMicroSharedTrainer.__init__": [[418, 462], ["len", "range", "maddpg.q_train", "maddpg.p_train", "maddpg_o.maddpg_local.micro.n_replay_buffer.ReplayBuffer", "maddpg.MADDPGAgentMicroSharedTrainer.get_p_q_variables", "obs_ph_n.append", "maddpg_o.BatchInput().get", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer", "maddpg_o.BatchInput", "str"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.q_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.PolicyTrainer.get_p_q_variables", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.Uint8Input.get"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "model_p", ",", "model_q", ",", "obs_shape_n", ",", "act_space_n", ",", "agent_index", ",", "args", ",", "num_units", ",", "local_q_func", "=", "False", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "n", "=", "len", "(", "obs_shape_n", ")", "\n", "self", ".", "agent_index", "=", "agent_index", "\n", "# self.args = args", "\n", "obs_ph_n", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "            ", "obs_ph_n", ".", "append", "(", "U", ".", "BatchInput", "(", "obs_shape_n", "[", "i", "]", ",", "name", "=", "\"observation\"", "+", "str", "(", "i", ")", ")", ".", "get", "(", ")", ")", "\n", "# import dill", "\n", "# dill.dump(obs_ph_n, open(\"tmp\", \"wb\"))", "\n", "\n", "# Create all the functions necessary to train the model", "\n", "# print(num_units)", "\n", "", "self", ".", "q_train", ",", "self", ".", "q_update", ",", "self", ".", "q_debug", "=", "q_train", "(", "\n", "scope", "=", "self", ".", "name", ",", "\n", "make_obs_ph_n", "=", "obs_ph_n", ",", "\n", "act_space_n", "=", "act_space_n", ",", "\n", "q_index", "=", "agent_index", ",", "\n", "q_func", "=", "model_q", ",", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "args", ".", "lr", ")", ",", "\n", "grad_norm_clipping", "=", "0.5", ",", "\n", "local_q_func", "=", "local_q_func", ",", "\n", "num_units", "=", "num_units", ",", "\n", "reuse", "=", "tf", ".", "AUTO_REUSE", "\n", ")", "\n", "self", ".", "act", ",", "self", ".", "p_train", ",", "self", ".", "p_update", ",", "self", ".", "p_debug", "=", "p_train", "(", "\n", "scope", "=", "self", ".", "name", ",", "\n", "make_obs_ph_n", "=", "obs_ph_n", ",", "\n", "act_space_n", "=", "act_space_n", ",", "\n", "p_index", "=", "agent_index", ",", "\n", "p_func", "=", "model_p", ",", "\n", "q_func", "=", "model_q", ",", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "args", ".", "lr", ")", ",", "\n", "grad_norm_clipping", "=", "0.5", ",", "\n", "local_q_func", "=", "local_q_func", ",", "\n", "num_units", "=", "num_units", ",", "\n", "reuse", "=", "tf", ".", "AUTO_REUSE", "\n", ")", "\n", "# Create experience buffer", "\n", "self", ".", "replay_buffer", "=", "ReplayBuffer", "(", "1e6", ")", "\n", "self", ".", "max_replay_buffer_len", "=", "args", ".", "batch_size", "*", "args", ".", "max_episode_len", "\n", "self", ".", "replay_sample_index", "=", "None", "\n", "self", ".", "gamma", "=", "args", ".", "gamma", "\n", "self", ".", "get_p_q_variables", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentMicroSharedTrainer.get_attn": [[464, 467], ["maddpg.MADDPGAgentMicroSharedTrainer.attention"], "methods", ["None"], ["", "def", "get_attn", "(", "self", ",", "obs", ")", ":", "\n", "        ", "attn", "=", "self", ".", "attention", "(", "obs", "[", "None", "]", ")", "\n", "return", "attn", "[", "0", "]", "[", "0", "]", ",", "attn", "[", "1", "]", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentMicroSharedTrainer.batch_attn": [[468, 470], ["maddpg.MADDPGAgentMicroSharedTrainer.attention"], "methods", ["None"], ["", "def", "batch_attn", "(", "self", ",", "obs", ")", ":", "\n", "        ", "return", "self", ".", "attention", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentMicroSharedTrainer.action": [[471, 474], ["maddpg.MADDPGAgentMicroSharedTrainer.act"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "obs", ")", ":", "\n", "#print(obs[None].shape)", "\n", "        ", "return", "self", ".", "act", "(", "obs", "[", "None", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentMicroSharedTrainer.batch_action": [[475, 477], ["maddpg.MADDPGAgentMicroSharedTrainer.act"], "methods", ["None"], ["", "def", "batch_action", "(", "self", ",", "obs", ")", ":", "\n", "        ", "return", "self", ".", "act", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentMicroSharedTrainer.experience": [[482, 485], ["maddpg.MADDPGAgentMicroSharedTrainer.replay_buffer.add", "float"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.add"], ["", "def", "experience", "(", "self", ",", "obs", ",", "act", ",", "rew", ",", "new_obs", ",", "done", ",", "terminal", ")", ":", "\n", "# Store transition in the replay buffer.", "\n", "        ", "self", ".", "replay_buffer", ".", "add", "(", "obs", ",", "act", ",", "rew", ",", "new_obs", ",", "float", "(", "done", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentMicroSharedTrainer.preupdate": [[486, 488], ["None"], "methods", ["None"], ["", "def", "preupdate", "(", "self", ")", ":", "\n", "        ", "self", ".", "replay_sample_index", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentMicroSharedTrainer.target_action": [[489, 491], ["None"], "methods", ["None"], ["", "def", "target_action", "(", "self", ",", "batch_obs", ")", ":", "\n", "        ", "return", "self", ".", "p_debug", "[", "'target_act'", "]", "(", "batch_obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentMicroSharedTrainer.get_p_q_variables": [[492, 499], ["tensorflow.variable_scope", "maddpg_o.scope_vars", "maddpg_o.scope_vars", "maddpg_o.scope_vars", "maddpg_o.scope_vars", "maddpg_o.absolute_scope_name", "maddpg_o.absolute_scope_name", "maddpg_o.absolute_scope_name", "maddpg_o.absolute_scope_name"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name"], ["", "def", "get_p_q_variables", "(", "self", ",", "reuse", "=", "True", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "name", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "self", ".", "p_variables", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"p_func\"", ")", ")", "\n", "#print(self.p_variables[1].name)", "\n", "self", ".", "target_p_variables", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_p_func\"", ")", ")", "\n", "self", ".", "q_variables", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"q_func\"", ")", ")", "\n", "self", ".", "target_q_variables", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_q_func\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentMicroSharedTrainer.set_weigths": [[500, 513], ["enumerate", "enumerate", "enumerate", "enumerate", "print", "tensorflow.keras.backend.set_value", "tensorflow.keras.backend.set_value", "tensorflow.keras.backend.set_value", "tensorflow.keras.backend.set_value"], "methods", ["None"], ["", "", "def", "set_weigths", "(", "self", ",", "weight_dict", ")", ":", "\n", "        ", "for", "i", ",", "v1", "in", "enumerate", "(", "self", ".", "p_variables", ")", ":", "\n", "            ", "print", "(", "v1", ")", "\n", "tf", ".", "keras", ".", "backend", ".", "set_value", "(", "v1", ",", "weight_dict", "[", "v1", ".", "name", "]", ")", "\n", "\n", "", "for", "i", ",", "v2", "in", "enumerate", "(", "self", ".", "target_p_variables", ")", ":", "\n", "            ", "tf", ".", "keras", ".", "backend", ".", "set_value", "(", "v2", ",", "weight_dict", "[", "v2", ".", "name", "]", ")", "\n", "\n", "", "for", "i", ",", "v3", "in", "enumerate", "(", "self", ".", "q_variables", ")", ":", "\n", "            ", "tf", ".", "keras", ".", "backend", ".", "set_value", "(", "v3", ",", "weight_dict", "[", "v3", ".", "name", "]", ")", "\n", "\n", "", "for", "i", ",", "v4", "in", "enumerate", "(", "self", ".", "target_q_variables", ")", ":", "\n", "            ", "tf", ".", "keras", ".", "backend", ".", "set_value", "(", "v4", ",", "weight_dict", "[", "v4", ".", "name", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentMicroSharedTrainer.update": [[514, 555], ["list", "list", "list", "range", "time.time", "maddpg.MADDPGAgentMicroSharedTrainer.q_train", "times.append", "time.time", "maddpg.MADDPGAgentMicroSharedTrainer.p_train", "times.append", "time.time", "maddpg.MADDPGAgentMicroSharedTrainer.p_update", "times.append", "time.time", "maddpg.MADDPGAgentMicroSharedTrainer.q_update", "times.append", "time.time", "times.append", "time.time", "time.time", "time.time", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.q_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.p_train"], ["", "", "def", "update", "(", "self", ",", "data", ",", "target_act_next_n", ",", "group_train", "=", "False", ")", ":", "\n", "        ", "times", "=", "[", "]", "\n", "obs_n", ",", "act_n", ",", "rew", ",", "obs_next_n", ",", "done", "=", "data", "\n", "obs_n", "=", "list", "(", "obs_n", ")", "\n", "act_n", "=", "list", "(", "act_n", ")", "\n", "obs_next_n", "=", "list", "(", "obs_next_n", ")", "\n", "# done = np.array(done)", "\n", "# target_act_next_n = copy.deepcopy(target_act_next_n)", "\n", "\n", "# train q network", "\n", "num_sample", "=", "1", "\n", "target_q", "=", "0.0", "\n", "for", "i", "in", "range", "(", "num_sample", ")", ":", "\n", "# target_act_next_n = [agents[i].p_debug['target_act'](obs_next_n[i]) for i in range(self.n)]", "\n", "            ", "tmp0", "=", "time", ".", "time", "(", ")", "\n", "# print(type(obs_next_n))", "\n", "# print(type(target_act_next_n))", "\n", "target_q_next", "=", "self", ".", "q_debug", "[", "'target_q_values'", "]", "(", "*", "(", "obs_next_n", "+", "target_act_next_n", ")", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", "-", "tmp0", ")", "# 62s", "\n", "target_q", "+=", "rew", "+", "self", ".", "gamma", "*", "(", "1.0", "-", "done", ")", "*", "target_q_next", "\n", "", "target_q", "/=", "num_sample", "\n", "\n", "tmp0", "=", "time", ".", "time", "(", ")", "\n", "q_loss", "=", "self", ".", "q_train", "(", "*", "(", "obs_n", "+", "act_n", "+", "[", "target_q", "]", ")", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", "-", "tmp0", ")", "# 161s", "\n", "\n", "# train p network", "\n", "tmp0", "=", "time", ".", "time", "(", ")", "\n", "p_loss", "=", "self", ".", "p_train", "(", "*", "(", "obs_n", "+", "act_n", ")", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", "-", "tmp0", ")", "# 166s", "\n", "\n", "tmp0", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "p_update", "(", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", "-", "tmp0", ")", "# 4s", "\n", "\n", "tmp0", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "q_update", "(", ")", "\n", "times", ".", "append", "(", "time", ".", "time", "(", ")", "-", "tmp0", ")", "# 10s", "\n", "\n", "# return [q_loss, p_loss, np.mean(target_q), np.mean(rew), np.mean(target_q_next), np.std(target_q), times]", "\n", "return", "[", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.discount_with_dones": [[14, 22], ["zip", "discounted.append"], "function", ["None"], ["def", "discount_with_dones", "(", "rewards", ",", "dones", ",", "gamma", ")", ":", "\n", "    ", "discounted", "=", "[", "]", "\n", "r", "=", "0", "\n", "for", "reward", ",", "done", "in", "zip", "(", "rewards", "[", ":", ":", "-", "1", "]", ",", "dones", "[", ":", ":", "-", "1", "]", ")", ":", "\n", "        ", "r", "=", "reward", "+", "gamma", "*", "r", "\n", "r", "=", "r", "*", "(", "1.", "-", "done", ")", "\n", "discounted", ".", "append", "(", "r", ")", "\n", "", "return", "discounted", "[", ":", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.make_update_exp": [[23, 30], ["zip", "tensorflow.group", "maddpg_o.function", "sorted", "sorted", "tf.group.append", "var_target.assign"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function"], ["", "def", "make_update_exp", "(", "vals", ",", "target_vals", ")", ":", "\n", "    ", "polyak", "=", "1.0", "-", "1e-2", "\n", "expression", "=", "[", "]", "\n", "for", "var", ",", "var_target", "in", "zip", "(", "sorted", "(", "vals", ",", "key", "=", "lambda", "v", ":", "v", ".", "name", ")", ",", "sorted", "(", "target_vals", ",", "key", "=", "lambda", "v", ":", "v", ".", "name", ")", ")", ":", "\n", "        ", "expression", ".", "append", "(", "var_target", ".", "assign", "(", "polyak", "*", "var_target", "+", "(", "1.0", "-", "polyak", ")", "*", "var", ")", ")", "\n", "", "expression", "=", "tf", ".", "group", "(", "*", "expression", ")", "\n", "return", "U", ".", "function", "(", "[", "]", ",", "[", "]", ",", "updates", "=", "[", "expression", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.p_train": [[31, 80], ["tensorflow.variable_scope", "p_func", "maddpg_o.scope_vars", "act_pdtype_n[].pdfromflat", "act_pdtype_n[].pdfromflat.sample", "tensorflow.reduce_mean", "act_pdtype_n[].pdfromflat.sample", "tensorflow.concat", "maddpg_o.minimize_and_clip", "maddpg_o.function", "maddpg_o.function", "maddpg_o.function", "p_func", "maddpg_o.scope_vars", "maddpg.make_update_exp", "act_pdtype_n[].pdfromflat().sample", "maddpg_o.function", "maddpg_o.maddpg_local.common.distributions.make_pdtype", "act_pdtype_n[].sample_placeholder", "int", "maddpg_o.absolute_scope_name", "tensorflow.square", "tensorflow.concat", "q_func", "tensorflow.reduce_mean", "int", "maddpg_o.absolute_scope_name", "range", "act_pdtype_n[].pdfromflat.flatparam", "act_pdtype_n[].pdfromflat", "len", "act_pdtype_n[].param_shape", "act_pdtype_n[].param_shape", "str"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.minimize_and_clip", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.make_update_exp", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.make_pdtype", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.flatparam", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape"], ["", "def", "p_train", "(", "make_obs_ph_n", ",", "act_space_n", ",", "p_index", ",", "p_func", ",", "q_func", ",", "optimizer", ",", "grad_norm_clipping", "=", "None", ",", "local_q_func", "=", "False", ",", "num_units", "=", "64", ",", "scope", "=", "\"trainer\"", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "\n", "        ", "act_pdtype_n", "=", "[", "make_pdtype", "(", "act_space", ")", "for", "act_space", "in", "act_space_n", "]", "\n", "\n", "# set up placeholders", "\n", "obs_ph_n", "=", "make_obs_ph_n", "\n", "act_ph_n", "=", "[", "act_pdtype_n", "[", "i", "]", ".", "sample_placeholder", "(", "[", "None", "]", ",", "name", "=", "\"action\"", "+", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "act_space_n", ")", ")", "]", "\n", "\n", "p_input", "=", "obs_ph_n", "[", "p_index", "]", "\n", "\n", "# print(\"p_train/p_func:\", scope)", "\n", "p", "=", "p_func", "(", "p_input", ",", "int", "(", "act_pdtype_n", "[", "p_index", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "p_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"p_func\"", ")", ")", "\n", "\n", "# wrap parameters in distribution", "\n", "act_pd", "=", "act_pdtype_n", "[", "p_index", "]", ".", "pdfromflat", "(", "p", ")", "\n", "\n", "act_sample", "=", "act_pd", ".", "sample", "(", ")", "\n", "p_reg", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "act_pd", ".", "flatparam", "(", ")", ")", ")", "\n", "\n", "act_input_n", "=", "act_ph_n", "+", "[", "]", "\n", "act_input_n", "[", "p_index", "]", "=", "act_pd", ".", "sample", "(", ")", "\n", "q_input", "=", "tf", ".", "concat", "(", "obs_ph_n", "+", "act_input_n", ",", "1", ")", "\n", "if", "local_q_func", ":", "\n", "            ", "q_input", "=", "tf", ".", "concat", "(", "[", "obs_ph_n", "[", "p_index", "]", ",", "act_input_n", "[", "p_index", "]", "]", ",", "1", ")", "\n", "", "q", "=", "q_func", "(", "q_input", ",", "1", ",", "scope", "=", "\"q_func\"", ",", "reuse", "=", "True", ",", "num_units", "=", "num_units", ")", "[", ":", ",", "0", "]", "\n", "pg_loss", "=", "-", "tf", ".", "reduce_mean", "(", "q", ")", "\n", "\n", "loss", "=", "pg_loss", "+", "p_reg", "*", "1e-3", "\n", "\n", "optimize_expr", "=", "U", ".", "minimize_and_clip", "(", "optimizer", ",", "loss", ",", "p_func_vars", ",", "grad_norm_clipping", ")", "\n", "\n", "# Create callable functions", "\n", "train", "=", "U", ".", "function", "(", "inputs", "=", "obs_ph_n", "+", "act_ph_n", ",", "outputs", "=", "loss", ",", "updates", "=", "[", "optimize_expr", "]", ")", "\n", "act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "outputs", "=", "act_sample", ")", "\n", "# attention = U.function(inputs=[obs_ph_n[p_index]], outputs=[attn.good_attn, attn.adv_attn])", "\n", "p_values", "=", "U", ".", "function", "(", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "p", ")", "\n", "# print([obs_ph_n[p_index]], act_sample)", "\n", "\n", "# target network", "\n", "target_p", "=", "p_func", "(", "p_input", ",", "int", "(", "act_pdtype_n", "[", "p_index", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"target_p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "target_p_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_p_func\"", ")", ")", "\n", "update_target_p", "=", "make_update_exp", "(", "p_func_vars", ",", "target_p_func_vars", ")", "\n", "\n", "target_act_sample", "=", "act_pdtype_n", "[", "p_index", "]", ".", "pdfromflat", "(", "target_p", ")", ".", "sample", "(", ")", "\n", "target_act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "outputs", "=", "target_act_sample", ")", "\n", "\n", "return", "act", ",", "train", ",", "update_target_p", ",", "{", "'p_values'", ":", "p_values", ",", "'target_act'", ":", "target_act", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.group_p_train": [[81, 191], ["tensorflow.variable_scope", "len", "list", "p_func", "maddpg_o.scope_vars", "tensorflow.reduce_mean", "maddpg_o.minimize_and_clip", "maddpg_o.function", "maddpg_o.scope_vars", "maddpg.make_update_exp", "act_pdtype_n[].pdfromflat().sample", "maddpg_o.function", "maddpg_o.maddpg_local.common.distributions.make_pdtype", "itertools.chain.from_iterable", "tensorflow.concat", "tensorflow.reshape", "tensorflow.concat", "tensorflow.reshape", "int", "maddpg_o.absolute_scope_name", "tensorflow.reshape", "tensorflow.split", "tensorflow.reshape", "tensorflow.split", "tensorflow.square", "range", "tensorflow.concat", "range", "tensorflow.concat", "q_func", "tensorflow.reduce_mean", "maddpg_o.function", "maddpg_o.function", "maddpg_o.function", "maddpg_o.function", "tensorflow.reshape", "tensorflow.split", "p_func", "tensorflow.reshape", "tensorflow.split", "p_func", "maddpg_o.absolute_scope_name", "act_pdtype_n[].pdfromflat", "act_pds[].sample", "act_pdtype_n[].pdfromflat", "act_pds[].sample", "tensorflow.concat", "act_pds[].sample", "q_inputs.append", "act_pds[].sample", "q_inputs.append", "int", "int", "act_pdtype_n[].pdfromflat", "act_pdtype_n[].sample_placeholder", "range", "act_pdtype_n[].sample_placeholder", "range", "act_pdtype_n[].param_shape", "range", "range", "range", "range", "tensorflow.concat", "tensorflow.concat", "range", "range", "act_pd.flatparam", "act_pdtype_n[].param_shape", "act_pdtype_n[].param_shape", "len", "len", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.minimize_and_clip", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.make_update_exp", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.make_pdtype", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.flatparam", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape"], ["", "", "def", "group_p_train", "(", "make_obs_ph_n", ",", "act_space_n", ",", "p_index", ",", "num_adversaries", ",", "p_func", ",", "q_func", ",", "optimizer", ",", "grad_norm_clipping", "=", "None", ",", "local_q_func", "=", "False", ",", "num_units", "=", "64", ",", "scope", "=", "\"trainer\"", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "# create distribtuions", "\n", "        ", "act_pdtype_n", "=", "[", "make_pdtype", "(", "act_space", ")", "for", "act_space", "in", "act_space_n", "]", "\n", "\n", "# set up placeholders for a group", "\n", "obs_ph_n", "=", "make_obs_ph_n", "\n", "n_agents", "=", "len", "(", "obs_ph_n", ")", "\n", "\n", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "\n", "            ", "act_ph_ns", "=", "[", "[", "act_pdtype_n", "[", "i", "]", ".", "sample_placeholder", "(", "[", "None", "]", ",", "name", "=", "\"action\"", "+", "str", "(", "n", ")", "+", "'_'", "+", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "act_space_n", ")", ")", "]", "for", "n", "in", "range", "(", "num_adversaries", ")", "]", "\n", "", "else", ":", "\n", "            ", "act_ph_ns", "=", "[", "[", "act_pdtype_n", "[", "i", "]", ".", "sample_placeholder", "(", "[", "None", "]", ",", "name", "=", "\"action\"", "+", "str", "(", "n", ")", "+", "'_'", "+", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "act_space_n", ")", ")", "]", "for", "n", "in", "range", "(", "n_agents", "-", "num_adversaries", ")", "]", "\n", "", "act_ph_ns_flatten", "=", "list", "(", "chain", ".", "from_iterable", "(", "act_ph_ns", ")", ")", "\n", "\n", "# p_input = obs_ph_n[p_index] # one obs for a certain p_index", "\n", "# batchify obs for all agents in a group", "\n", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "# adv", "\n", "            ", "p_input", "=", "tf", ".", "concat", "(", "obs_ph_n", "[", ":", "num_adversaries", "]", ",", "1", ")", "\n", "p_input", "=", "tf", ".", "reshape", "(", "p_input", ",", "[", "-", "1", ",", "p_input", ".", "shape", "[", "-", "1", "]", ".", "value", "//", "num_adversaries", "]", ")", "\n", "", "else", ":", "# good agent", "\n", "            ", "p_input", "=", "tf", ".", "concat", "(", "obs_ph_n", "[", "num_adversaries", ":", "]", ",", "1", ")", "\n", "p_input", "=", "tf", ".", "reshape", "(", "p_input", ",", "[", "-", "1", ",", "p_input", ".", "shape", "[", "-", "1", "]", ".", "value", "//", "(", "n_agents", "-", "num_adversaries", ")", "]", ")", "\n", "\n", "# get all actions from a group", "\n", "", "p", "=", "p_func", "(", "p_input", ",", "int", "(", "act_pdtype_n", "[", "p_index", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "p_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"p_func\"", ")", ")", "\n", "\n", "# wrap parameters in distribution", "\n", "# un-batchify actions from a group", "\n", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "\n", "            ", "p", "=", "tf", ".", "reshape", "(", "p", ",", "[", "-", "1", ",", "p", ".", "shape", "[", "-", "1", "]", "*", "num_adversaries", "]", ")", "\n", "ps", "=", "tf", ".", "split", "(", "p", ",", "num_or_size_splits", "=", "num_adversaries", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "p", "=", "tf", ".", "reshape", "(", "p", ",", "[", "-", "1", ",", "p", ".", "shape", "[", "-", "1", "]", "*", "(", "n_agents", "-", "num_adversaries", ")", "]", ")", "\n", "ps", "=", "tf", ".", "split", "(", "p", ",", "num_or_size_splits", "=", "(", "n_agents", "-", "num_adversaries", ")", ",", "axis", "=", "1", ")", "\n", "\n", "# get probability distributions and action samples for a group", "\n", "", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "\n", "            ", "act_pds", "=", "[", "act_pdtype_n", "[", "i", "]", ".", "pdfromflat", "(", "ps", "[", "i", "]", ")", "for", "i", "in", "range", "(", "num_adversaries", ")", "]", "\n", "act_samples", "=", "[", "act_pds", "[", "i", "]", ".", "sample", "(", ")", "for", "i", "in", "range", "(", "num_adversaries", ")", "]", "\n", "", "else", ":", "\n", "            ", "act_pds", "=", "[", "act_pdtype_n", "[", "i", "]", ".", "pdfromflat", "(", "ps", "[", "i", "-", "num_adversaries", "]", ")", "for", "i", "in", "range", "(", "num_adversaries", ",", "n_agents", ")", "]", "\n", "act_samples", "=", "[", "act_pds", "[", "i", "]", ".", "sample", "(", ")", "for", "i", "in", "range", "(", "n_agents", "-", "num_adversaries", ")", "]", "\n", "# act_pd = act_pdtype_n[p_index].pdfromflat(p)", "\n", "# act_sample = act_pd.sample()", "\n", "\n", "# p_reg = tf.reduce_mean(tf.square(act_pd.flatparam()))", "\n", "# get average p_reg for a group", "\n", "", "p_reg", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "tf", ".", "concat", "(", "[", "act_pd", ".", "flatparam", "(", ")", "for", "act_pd", "in", "act_pds", "]", ",", "-", "1", ")", ")", ")", "\n", "\n", "\n", "# act_input_n = act_ph_n + []", "\n", "act_input_ns", "=", "act_ph_ns", "\n", "# act_input_n[p_index] = act_pd.sample()", "\n", "# q_input = tf.concat(obs_ph_n + act_input_n, 1)", "\n", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "\n", "            ", "q_inputs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_adversaries", ")", ":", "\n", "                ", "act_input_ns", "[", "i", "]", "[", "i", "]", "=", "act_pds", "[", "i", "]", ".", "sample", "(", ")", "\n", "q_inputs", ".", "append", "(", "tf", ".", "concat", "(", "obs_ph_n", "+", "act_input_ns", "[", "i", "]", ",", "1", ")", ")", "\n", "# batchify q_input", "\n", "", "q_input", "=", "tf", ".", "concat", "(", "q_inputs", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "q_inputs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_agents", "-", "num_adversaries", ")", ":", "\n", "                ", "act_input_ns", "[", "i", "]", "[", "i", "+", "num_adversaries", "]", "=", "act_pds", "[", "i", "]", ".", "sample", "(", ")", "\n", "q_inputs", ".", "append", "(", "tf", ".", "concat", "(", "obs_ph_n", "+", "act_input_ns", "[", "i", "]", ",", "1", ")", ")", "\n", "# batchify q_input", "\n", "", "q_input", "=", "tf", ".", "concat", "(", "q_inputs", ",", "0", ")", "\n", "\n", "# if local_q_func:", "\n", "#     q_input = tf.concat([obs_ph_n[p_index], act_input_n[p_index]], 1)", "\n", "\n", "# input group of q_input into q_func", "\n", "", "q", "=", "q_func", "(", "q_input", ",", "1", ",", "scope", "=", "\"q_func\"", ",", "reuse", "=", "True", ",", "num_units", "=", "num_units", ")", "[", ":", ",", "0", "]", "\n", "pg_loss", "=", "-", "tf", ".", "reduce_mean", "(", "q", ")", "\n", "\n", "loss", "=", "pg_loss", "+", "p_reg", "*", "1e-3", "\n", "\n", "optimize_expr", "=", "U", ".", "minimize_and_clip", "(", "optimizer", ",", "loss", ",", "p_func_vars", ",", "grad_norm_clipping", ")", "\n", "\n", "# Create callable functions", "\n", "train", "=", "U", ".", "function", "(", "inputs", "=", "obs_ph_n", "+", "act_ph_ns_flatten", ",", "outputs", "=", "loss", ",", "updates", "=", "[", "optimize_expr", "]", ")", "\n", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "\n", "# print([obs_ph_n[p_index]], act_samples[p_index])", "\n", "            ", "act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "outputs", "=", "act_samples", "[", "p_index", "]", ")", "\n", "p_values", "=", "U", ".", "function", "(", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "ps", "[", "p_index", "]", ")", "\n", "", "else", ":", "\n", "# print([obs_ph_n[p_index]], act_samples[p_index-num_adversaries])", "\n", "            ", "act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "outputs", "=", "act_samples", "[", "p_index", "-", "num_adversaries", "]", ")", "\n", "p_values", "=", "U", ".", "function", "(", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "ps", "[", "p_index", "-", "num_adversaries", "]", ")", "\n", "\n", "# target network for a group", "\n", "", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "\n", "            ", "p_input", "=", "tf", ".", "reshape", "(", "p_input", ",", "[", "-", "1", ",", "p_input", ".", "shape", "[", "-", "1", "]", "*", "num_adversaries", "]", ")", "\n", "p_inputs", "=", "tf", ".", "split", "(", "p_input", ",", "num_or_size_splits", "=", "num_adversaries", ",", "axis", "=", "1", ")", "\n", "target_p", "=", "p_func", "(", "p_inputs", "[", "p_index", "]", ",", "int", "(", "act_pdtype_n", "[", "p_index", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"target_p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "", "else", ":", "\n", "            ", "p_input", "=", "tf", ".", "reshape", "(", "p_input", ",", "[", "-", "1", ",", "p_input", ".", "shape", "[", "-", "1", "]", "*", "(", "n_agents", "-", "num_adversaries", ")", "]", ")", "\n", "p_inputs", "=", "tf", ".", "split", "(", "p_input", ",", "num_or_size_splits", "=", "(", "n_agents", "-", "num_adversaries", ")", ",", "axis", "=", "1", ")", "\n", "target_p", "=", "p_func", "(", "p_inputs", "[", "p_index", "-", "num_adversaries", "]", ",", "int", "(", "act_pdtype_n", "[", "p_index", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"target_p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "# target_p = p_func(p_input, int(act_pdtype_n[p_index].param_shape()[0]), scope=\"target_p_func\", num_units=num_units)", "\n", "", "target_p_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_p_func\"", ")", ")", "\n", "update_target_p", "=", "make_update_exp", "(", "p_func_vars", ",", "target_p_func_vars", ")", "\n", "\n", "target_act_sample", "=", "act_pdtype_n", "[", "p_index", "]", ".", "pdfromflat", "(", "target_p", ")", ".", "sample", "(", ")", "\n", "target_act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "outputs", "=", "target_act_sample", ")", "\n", "\n", "return", "act", ",", "train", ",", "update_target_p", ",", "{", "'p_values'", ":", "p_values", ",", "'target_act'", ":", "target_act", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.q_train": [[192, 232], ["tensorflow.variable_scope", "len", "tensorflow.placeholder", "tensorflow.concat", "maddpg_o.scope_vars", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "maddpg_o.minimize_and_clip", "maddpg_o.function", "maddpg_o.function", "maddpg_o.scope_vars", "maddpg.make_update_exp", "maddpg_o.function", "maddpg_o.maddpg_local.common.distributions.make_pdtype", "act_pdtype_n[].sample_placeholder", "tensorflow.concat", "q_func", "maddpg_o.absolute_scope_name", "tensorflow.square", "tensorflow.square", "q_func", "maddpg_o.absolute_scope_name", "range", "str"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.minimize_and_clip", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.make_update_exp", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.make_pdtype", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name"], ["", "", "def", "q_train", "(", "make_obs_ph_n", ",", "act_space_n", ",", "q_index", ",", "q_func", ",", "optimizer", ",", "grad_norm_clipping", "=", "None", ",", "local_q_func", "=", "False", ",", "scope", "=", "\"trainer\"", ",", "reuse", "=", "None", ",", "num_units", "=", "64", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "# create distribtuions", "\n", "        ", "act_pdtype_n", "=", "[", "make_pdtype", "(", "act_space", ")", "for", "act_space", "in", "act_space_n", "]", "\n", "\n", "# set up placeholders", "\n", "n", "=", "len", "(", "act_space_n", ")", "\n", "obs_ph_n", "=", "make_obs_ph_n", "\n", "act_ph_n", "=", "[", "act_pdtype_n", "[", "i", "]", ".", "sample_placeholder", "(", "[", "None", "]", ",", "name", "=", "\"action\"", "+", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "n", ")", "]", "\n", "# exclude_i = list(filter(lambda i: i != q_index, range(n)))", "\n", "# mean_act = [act_ph_n[q_index], tf.reduce_mean([act_ph_n[i] for i in exclude_i])]", "\n", "target_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ",", "name", "=", "\"target\"", ")", "\n", "#print(act_ph_n)", "\n", "q_input", "=", "tf", ".", "concat", "(", "obs_ph_n", "+", "act_ph_n", ",", "1", ")", "\n", "if", "local_q_func", ":", "\n", "            ", "q_input", "=", "tf", ".", "concat", "(", "[", "obs_ph_n", "[", "q_index", "]", ",", "act_ph_n", "[", "q_index", "]", "]", ",", "1", ")", "\n", "", "q", "=", "q_func", "(", "q_input", ",", "1", ",", "scope", "=", "\"q_func\"", ",", "num_units", "=", "num_units", ")", "[", ":", ",", "0", "]", "\n", "q_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"q_func\"", ")", ")", "\n", "\n", "q_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "q", "-", "target_ph", ")", ")", "\n", "\n", "# viscosity solution to Bellman differential equation in place of an initial condition", "\n", "q_reg", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "q", ")", ")", "\n", "loss", "=", "q_loss", "#+ 1e-3 * q_reg", "\n", "\n", "# print(reuse)", "\n", "optimize_expr", "=", "U", ".", "minimize_and_clip", "(", "optimizer", ",", "loss", ",", "q_func_vars", ",", "grad_norm_clipping", ")", "\n", "\n", "# Create callable functions", "\n", "train", "=", "U", ".", "function", "(", "inputs", "=", "obs_ph_n", "+", "act_ph_n", "+", "[", "target_ph", "]", ",", "outputs", "=", "loss", ",", "updates", "=", "[", "optimize_expr", "]", ")", "\n", "q_values", "=", "U", ".", "function", "(", "obs_ph_n", "+", "act_ph_n", ",", "q", ")", "\n", "\n", "# target network", "\n", "target_q", "=", "q_func", "(", "q_input", ",", "1", ",", "scope", "=", "\"target_q_func\"", ",", "num_units", "=", "num_units", ")", "[", ":", ",", "0", "]", "\n", "target_q_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_q_func\"", ")", ")", "\n", "update_target_q", "=", "make_update_exp", "(", "q_func_vars", ",", "target_q_func_vars", ")", "\n", "\n", "target_q_values", "=", "U", ".", "function", "(", "obs_ph_n", "+", "act_ph_n", ",", "target_q", ")", "\n", "\n", "return", "train", ",", "update_target_q", ",", "{", "'q_values'", ":", "q_values", ",", "'target_q_values'", ":", "target_q_values", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.PolicyTrainer.__init__": [[35, 58], ["len", "range", "policy_normal.p_train", "policy_normal.PolicyTrainer.get_p_q_variables", "policy_normal.PolicyTrainer.assign_weight", "obs_ph_n.append", "maddpg_o.BatchInput().get", "maddpg_o.BatchInput", "str"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.PolicyTrainer.get_p_q_variables", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.PolicyTrainer.assign_weight", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.Uint8Input.get"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "model_p", ",", "model_q", ",", "obs_shape_n", ",", "act_space_n", ",", "agent_index", ",", "args", ",", "num_units", ",", "sess", ",", "local_q_func", "=", "False", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "n", "=", "len", "(", "obs_shape_n", ")", "\n", "self", ".", "agent_index", "=", "agent_index", "\n", "self", ".", "session", "=", "sess", "\n", "self", ".", "args", "=", "args", "\n", "obs_ph_n", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "            ", "obs_ph_n", ".", "append", "(", "U", ".", "BatchInput", "(", "obs_shape_n", "[", "i", "]", ",", "name", "=", "\"observation\"", "+", "str", "(", "i", ")", ")", ".", "get", "(", ")", ")", "\n", "\n", "# Create all the functions necessary to train the model", "\n", "", "self", ".", "act", ",", "self", ".", "target_act", "=", "p_train", "(", "\n", "scope", "=", "self", ".", "name", ",", "\n", "make_obs_ph_n", "=", "obs_ph_n", ",", "\n", "act_space_n", "=", "act_space_n", ",", "\n", "p_index", "=", "agent_index", ",", "\n", "p_func", "=", "model_p", ",", "\n", "grad_norm_clipping", "=", "0.5", ",", "\n", "local_q_func", "=", "local_q_func", ",", "\n", "num_units", "=", "args", ".", "num_units", "\n", ")", "\n", "self", ".", "get_p_q_variables", "(", ")", "\n", "self", ".", "assign_weight", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.PolicyTrainer.action": [[59, 61], ["policy_normal.PolicyTrainer.act"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "obs", ")", ":", "\n", "        ", "return", "self", ".", "act", "(", "obs", "[", "None", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.PolicyTrainer.target_action": [[62, 64], ["policy_normal.PolicyTrainer.target_act"], "methods", ["None"], ["", "def", "target_action", "(", "self", ",", "obs", ")", ":", "\n", "        ", "return", "self", ".", "target_act", "(", "obs", "[", "None", "]", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.PolicyTrainer.get_p_q_variables": [[65, 68], ["tensorflow.variable_scope", "maddpg_o.scope_vars", "maddpg_o.absolute_scope_name"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name"], ["", "def", "get_p_q_variables", "(", "self", ",", "reuse", "=", "True", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "name", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "self", ".", "p_variables", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"p_func\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.PolicyTrainer.get_weigths": [[69, 73], ["dict", "policy_normal.PolicyTrainer.session.run"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run"], ["", "", "def", "get_weigths", "(", "self", ")", ":", "\n", "        ", "weigths_dict", "=", "dict", "(", ")", "\n", "weigths_dict", "[", "'p_variables'", "]", "=", "self", ".", "session", ".", "run", "(", "self", ".", "p_variables", ")", "\n", "return", "weigths_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.PolicyTrainer.assign_weight": [[74, 82], ["dict", "len", "range", "policy_normal.PolicyTrainer.x.append", "policy_normal.PolicyTrainer.assign_op[].append", "tensorflow.placeholder", "policy_normal.PolicyTrainer.p_variables[].assign", "policy_normal.PolicyTrainer.p_variables[].get_shape"], "methods", ["None"], ["", "def", "assign_weight", "(", "self", ")", ":", "\n", "        ", "self", ".", "assign_op", "=", "dict", "(", ")", "\n", "self", ".", "assign_op", "[", "'p_variables'", "]", "=", "[", "]", "\n", "k1", "=", "len", "(", "self", ".", "p_variables", ")", "\n", "self", ".", "x", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k1", ")", ":", "\n", "            ", "self", ".", "x", ".", "append", "(", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "self", ".", "p_variables", "[", "i", "]", ".", "get_shape", "(", ")", ")", ")", "\n", "self", ".", "assign_op", "[", "'p_variables'", "]", ".", "append", "(", "self", ".", "p_variables", "[", "i", "]", ".", "assign", "(", "self", ".", "x", "[", "i", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.PolicyTrainer.set_weigths": [[83, 86], ["enumerate", "policy_normal.PolicyTrainer.session.run"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run"], ["", "", "def", "set_weigths", "(", "self", ",", "weight_dict", ")", ":", "\n", "        ", "for", "i", ",", "weight", "in", "enumerate", "(", "weight_dict", "[", "'p_variables'", "]", ")", ":", "\n", "            ", "self", ".", "session", ".", "run", "(", "self", ".", "assign_op", "[", "'p_variables'", "]", "[", "i", "]", ",", "feed_dict", "=", "{", "self", ".", "x", "[", "i", "]", ":", "weight", "}", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.p_train": [[12, 33], ["tensorflow.variable_scope", "p_func", "maddpg_o.scope_vars", "act_pdtype_n[].pdfromflat", "act_pdtype_n[].pdfromflat.sample", "tensorflow.reduce_mean", "act_pdtype_n[].pdfromflat.sample", "maddpg_o.function", "p_func", "maddpg_o.scope_vars", "act_pdtype_n[].pdfromflat().sample", "maddpg_o.function", "maddpg_o.maddpg_local.common.distributions.make_pdtype", "act_pdtype_n[].sample_placeholder", "int", "maddpg_o.absolute_scope_name", "tensorflow.square", "int", "maddpg_o.absolute_scope_name", "range", "act_pdtype_n[].pdfromflat.flatparam", "act_pdtype_n[].pdfromflat", "len", "act_pdtype_n[].param_shape", "act_pdtype_n[].param_shape", "str"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.make_pdtype", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.flatparam", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape"], ["def", "p_train", "(", "make_obs_ph_n", ",", "act_space_n", ",", "p_index", ",", "p_func", ",", "grad_norm_clipping", "=", "None", ",", "local_q_func", "=", "False", ",", "num_units", "=", "64", ",", "scope", "=", "\"trainer\"", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "act_pdtype_n", "=", "[", "make_pdtype", "(", "act_space", ")", "for", "act_space", "in", "act_space_n", "]", "\n", "# set up placeholders", "\n", "obs_ph_n", "=", "make_obs_ph_n", "\n", "act_ph_n", "=", "[", "act_pdtype_n", "[", "i", "]", ".", "sample_placeholder", "(", "[", "None", "]", ",", "name", "=", "\"action\"", "+", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "act_space_n", ")", ")", "]", "\n", "p_input", "=", "obs_ph_n", "[", "p_index", "]", "\n", "p", "=", "p_func", "(", "p_input", ",", "int", "(", "act_pdtype_n", "[", "p_index", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "p_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"p_func\"", ")", ")", "\n", "# wrap parameters in distribution", "\n", "act_pd", "=", "act_pdtype_n", "[", "p_index", "]", ".", "pdfromflat", "(", "p", ")", "\n", "act_sample", "=", "act_pd", ".", "sample", "(", ")", "\n", "p_reg", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "act_pd", ".", "flatparam", "(", ")", ")", ")", "\n", "act_input_n", "=", "act_ph_n", "+", "[", "]", "\n", "act_input_n", "[", "p_index", "]", "=", "act_pd", ".", "sample", "(", ")", "\n", "act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "outputs", "=", "act_sample", ")", "\n", "target_p", "=", "p_func", "(", "p_input", ",", "int", "(", "act_pdtype_n", "[", "p_index", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"target_p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "target_p_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_p_func\"", ")", ")", "\n", "target_act_sample", "=", "act_pdtype_n", "[", "p_index", "]", ".", "pdfromflat", "(", "target_p", ")", ".", "sample", "(", ")", "\n", "target_act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "outputs", "=", "target_act_sample", ")", "\n", "return", "act", ",", "target_act", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.replay_buffer.ReplayBuffer.__init__": [[5, 17], ["int"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "\"\"\"Create Prioritized Replay buffer.\n\n        Parameters\n        ----------\n        size: int\n            Max number of transitions to store in the buffer. When the buffer\n            overflows the old memories are dropped.\n        \"\"\"", "\n", "self", ".", "_storage", "=", "[", "]", "\n", "self", ".", "_maxsize", "=", "int", "(", "size", ")", "\n", "self", ".", "_next_idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.replay_buffer.ReplayBuffer.__len__": [[18, 20], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_storage", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.replay_buffer.ReplayBuffer.clear": [[21, 24], ["None"], "methods", ["None"], ["", "def", "clear", "(", "self", ")", ":", "\n", "        ", "self", ".", "_storage", "=", "[", "]", "\n", "self", ".", "_next_idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.replay_buffer.ReplayBuffer.add": [[25, 33], ["len", "replay_buffer.ReplayBuffer._storage.append"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "obs_t", ",", "action", ",", "reward", ",", "obs_tp1", ",", "done", ")", ":", "\n", "        ", "data", "=", "(", "obs_t", ",", "action", ",", "reward", ",", "obs_tp1", ",", "done", ")", "\n", "\n", "if", "self", ".", "_next_idx", ">=", "len", "(", "self", ".", "_storage", ")", ":", "\n", "            ", "self", ".", "_storage", ".", "append", "(", "data", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_storage", "[", "self", ".", "_next_idx", "]", "=", "data", "\n", "", "self", ".", "_next_idx", "=", "(", "self", ".", "_next_idx", "+", "1", ")", "%", "self", ".", "_maxsize", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.replay_buffer.ReplayBuffer._encode_sample": [[34, 45], ["obses_t.append", "actions.append", "rewards.append", "obses_tp1.append", "dones.append", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "_encode_sample", "(", "self", ",", "idxes", ")", ":", "\n", "        ", "obses_t", ",", "actions", ",", "rewards", ",", "obses_tp1", ",", "dones", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "idxes", ":", "\n", "            ", "data", "=", "self", ".", "_storage", "[", "i", "]", "\n", "obs_t", ",", "action", ",", "reward", ",", "obs_tp1", ",", "done", "=", "data", "\n", "obses_t", ".", "append", "(", "np", ".", "array", "(", "obs_t", ",", "copy", "=", "False", ")", ")", "\n", "actions", ".", "append", "(", "np", ".", "array", "(", "action", ",", "copy", "=", "False", ")", ")", "\n", "rewards", ".", "append", "(", "reward", ")", "\n", "obses_tp1", ".", "append", "(", "np", ".", "array", "(", "obs_tp1", ",", "copy", "=", "False", ")", ")", "\n", "dones", ".", "append", "(", "done", ")", "\n", "", "return", "np", ".", "array", "(", "obses_t", ")", ",", "np", ".", "array", "(", "actions", ")", ",", "np", ".", "array", "(", "rewards", ")", ",", "np", ".", "array", "(", "obses_tp1", ")", ",", "np", ".", "array", "(", "dones", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.replay_buffer.ReplayBuffer._encode_sample_simple": [[46, 57], ["obses_t.append", "actions.append", "rewards.append", "obses_tp1.append", "dones.append"], "methods", ["None"], ["", "def", "_encode_sample_simple", "(", "self", ",", "idxes", ")", ":", "\n", "        ", "obses_t", ",", "actions", ",", "rewards", ",", "obses_tp1", ",", "dones", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "idxes", ":", "\n", "            ", "data", "=", "self", ".", "_storage", "[", "i", "]", "\n", "obs_t", ",", "action", ",", "reward", ",", "obs_tp1", ",", "done", "=", "data", "\n", "obses_t", ".", "append", "(", "obs_t", ")", "\n", "actions", ".", "append", "(", "action", ")", "\n", "rewards", ".", "append", "(", "reward", ")", "\n", "obses_tp1", ".", "append", "(", "obs_tp1", ")", "\n", "dones", ".", "append", "(", "done", ")", "\n", "", "return", "obses_t", ",", "actions", ",", "rewards", ",", "obses_tp1", ",", "dones", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.replay_buffer.ReplayBuffer.make_index": [[58, 60], ["random.randint", "range", "len"], "methods", ["None"], ["", "def", "make_index", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "return", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_storage", ")", "-", "1", ")", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.replay_buffer.ReplayBuffer.make_latest_index": [[61, 65], ["numpy.random.shuffle", "range"], "methods", ["None"], ["", "def", "make_latest_index", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "idx", "=", "[", "(", "self", ".", "_next_idx", "-", "1", "-", "i", ")", "%", "self", ".", "_maxsize", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "np", ".", "random", ".", "shuffle", "(", "idx", ")", "\n", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.replay_buffer.ReplayBuffer.sample_index": [[66, 71], ["replay_buffer.ReplayBuffer._encode_sample_simple", "replay_buffer.ReplayBuffer._encode_sample"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.replay_buffer.ReplayBuffer._encode_sample_simple", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer._encode_sample"], ["", "def", "sample_index", "(", "self", ",", "idxes", ",", "simple", "=", "False", ")", ":", "\n", "        ", "if", "simple", ":", "\n", "            ", "return", "self", ".", "_encode_sample_simple", "(", "idxes", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "_encode_sample", "(", "idxes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.replay_buffer.ReplayBuffer.sample": [[72, 99], ["replay_buffer.ReplayBuffer._encode_sample", "replay_buffer.ReplayBuffer.make_index", "range", "len"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer._encode_sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.make_index"], ["", "", "def", "sample", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"Sample a batch of experiences.\n\n        Parameters\n        ----------\n        batch_size: int\n            How many transitions to sample.\n\n        Returns\n        -------\n        obs_batch: np.array\n            batch of observations\n        act_batch: np.array\n            batch of actions executed given obs_batch\n        rew_batch: np.array\n            rewards received as results of executing act_batch\n        next_obs_batch: np.array\n            next set of observations seen after executing act_batch\n        done_mask: np.array\n            done_mask[i] = 1 if executing act_batch[i] resulted in\n            the end of an episode and 0 otherwise.\n        \"\"\"", "\n", "if", "batch_size", ">", "0", ":", "\n", "            ", "idxes", "=", "self", ".", "make_index", "(", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "idxes", "=", "range", "(", "0", ",", "len", "(", "self", ".", "_storage", ")", ")", "\n", "", "return", "self", ".", "_encode_sample", "(", "idxes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.replay_buffer.ReplayBuffer.collect": [[100, 102], ["replay_buffer.ReplayBuffer.sample"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample"], ["", "def", "collect", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sample", "(", "-", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.MADDPGAgentTrainer.__init__": [[123, 163], ["len", "range", "maddpg.q_train", "maddpg.p_train", "maddpg_local.trainer.replay_buffer.ReplayBuffer", "obs_ph_n.append", "maddpg_local.BatchInput().get", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer", "maddpg_local.BatchInput", "str"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.q_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.Uint8Input.get"], ["            ", "act_pds", "=", "[", "act_pdtype_n", "[", "i", "]", ".", "pdfromflat", "(", "ps", "[", "i", "-", "num_adversaries", "]", ")", "for", "i", "in", "range", "(", "num_adversaries", ",", "n_agents", ")", "]", "\n", "act_samples", "=", "[", "act_pds", "[", "i", "]", ".", "sample", "(", ")", "for", "i", "in", "range", "(", "n_agents", "-", "num_adversaries", ")", "]", "\n", "# act_pd = act_pdtype_n[p_index].pdfromflat(p)", "\n", "# act_sample = act_pd.sample()", "\n", "\n", "# p_reg = tf.reduce_mean(tf.square(act_pd.flatparam()))", "\n", "# get average p_reg for a group", "\n", "", "p_reg", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "tf", ".", "concat", "(", "[", "act_pd", ".", "flatparam", "(", ")", "for", "act_pd", "in", "act_pds", "]", ",", "-", "1", ")", ")", ")", "\n", "\n", "\n", "# act_input_n = act_ph_n + []", "\n", "act_input_ns", "=", "act_ph_ns", "\n", "# act_input_n[p_index] = act_pd.sample()", "\n", "# q_input = tf.concat(obs_ph_n + act_input_n, 1)", "\n", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "\n", "            ", "q_inputs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "num_adversaries", ")", ":", "\n", "                ", "act_input_ns", "[", "i", "]", "[", "i", "]", "=", "act_pds", "[", "i", "]", ".", "sample", "(", ")", "\n", "q_inputs", ".", "append", "(", "tf", ".", "concat", "(", "obs_ph_n", "+", "act_input_ns", "[", "i", "]", ",", "1", ")", ")", "\n", "# batchify q_input", "\n", "", "q_input", "=", "tf", ".", "concat", "(", "q_inputs", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "q_inputs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_agents", "-", "num_adversaries", ")", ":", "\n", "                ", "act_input_ns", "[", "i", "]", "[", "i", "+", "num_adversaries", "]", "=", "act_pds", "[", "i", "]", ".", "sample", "(", ")", "\n", "q_inputs", ".", "append", "(", "tf", ".", "concat", "(", "obs_ph_n", "+", "act_input_ns", "[", "i", "]", ",", "1", ")", ")", "\n", "# batchify q_input", "\n", "", "q_input", "=", "tf", ".", "concat", "(", "q_inputs", ",", "0", ")", "\n", "\n", "# if local_q_func:", "\n", "#     q_input = tf.concat([obs_ph_n[p_index], act_input_n[p_index]], 1)", "\n", "\n", "# input group of q_input into q_func", "\n", "", "q", "=", "q_func", "(", "q_input", ",", "1", ",", "scope", "=", "\"q_func\"", ",", "reuse", "=", "True", ",", "num_units", "=", "num_units", ")", "[", ":", ",", "0", "]", "\n", "pg_loss", "=", "-", "tf", ".", "reduce_mean", "(", "q", ")", "\n", "\n", "loss", "=", "pg_loss", "+", "p_reg", "*", "1e-3", "\n", "\n", "optimize_expr", "=", "U", ".", "minimize_and_clip", "(", "optimizer", ",", "loss", ",", "p_func_vars", ",", "grad_norm_clipping", ")", "\n", "\n", "# Create callable functions", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.MADDPGAgentTrainer.action": [[164, 166], ["maddpg.MADDPGAgentTrainer.act"], "methods", ["None"], ["train", "=", "U", ".", "function", "(", "inputs", "=", "obs_ph_n", "+", "act_ph_ns_flatten", ",", "outputs", "=", "loss", ",", "updates", "=", "[", "optimize_expr", "]", ")", "\n", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "\n", "# print([obs_ph_n[p_index]], act_samples[p_index])", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.MADDPGAgentTrainer.experience": [[167, 170], ["maddpg.MADDPGAgentTrainer.replay_buffer.add", "float"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.add"], ["            ", "act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "outputs", "=", "act_samples", "[", "p_index", "]", ")", "\n", "p_values", "=", "U", ".", "function", "(", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "ps", "[", "p_index", "]", ")", "\n", "", "else", ":", "\n", "# print([obs_ph_n[p_index]], act_samples[p_index-num_adversaries])", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.MADDPGAgentTrainer.preupdate": [[171, 173], ["None"], "methods", ["None"], ["            ", "act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "outputs", "=", "act_samples", "[", "p_index", "-", "num_adversaries", "]", ")", "\n", "p_values", "=", "U", ".", "function", "(", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "ps", "[", "p_index", "-", "num_adversaries", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.MADDPGAgentTrainer.update": [[174, 213], ["maddpg.MADDPGAgentTrainer.replay_buffer.make_index", "range", "maddpg.MADDPGAgentTrainer.replay_buffer.sample_index", "range", "maddpg.MADDPGAgentTrainer.q_train", "maddpg.MADDPGAgentTrainer.p_train", "maddpg.MADDPGAgentTrainer.p_update", "maddpg.MADDPGAgentTrainer.q_update", "len", "agents[].replay_buffer.sample_index", "obs_n.append", "obs_next_n.append", "act_n.append", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.std", "range"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.make_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.q_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.p_train", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample_index", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.std"], ["# target network for a group", "\n", "", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "\n", "            ", "p_input", "=", "tf", ".", "reshape", "(", "p_input", ",", "[", "-", "1", ",", "p_input", ".", "shape", "[", "-", "1", "]", "*", "num_adversaries", "]", ")", "\n", "p_inputs", "=", "tf", ".", "split", "(", "p_input", ",", "num_or_size_splits", "=", "num_adversaries", ",", "axis", "=", "1", ")", "\n", "target_p", "=", "p_func", "(", "p_inputs", "[", "p_index", "]", ",", "int", "(", "act_pdtype_n", "[", "p_index", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"target_p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "", "else", ":", "\n", "            ", "p_input", "=", "tf", ".", "reshape", "(", "p_input", ",", "[", "-", "1", ",", "p_input", ".", "shape", "[", "-", "1", "]", "*", "(", "n_agents", "-", "num_adversaries", ")", "]", ")", "\n", "p_inputs", "=", "tf", ".", "split", "(", "p_input", ",", "num_or_size_splits", "=", "(", "n_agents", "-", "num_adversaries", ")", ",", "axis", "=", "1", ")", "\n", "target_p", "=", "p_func", "(", "p_inputs", "[", "p_index", "-", "num_adversaries", "]", ",", "int", "(", "act_pdtype_n", "[", "p_index", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"target_p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "# target_p = p_func(p_input, int(act_pdtype_n[p_index].param_shape()[0]), scope=\"target_p_func\", num_units=num_units)", "\n", "", "target_p_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_p_func\"", ")", ")", "\n", "update_target_p", "=", "make_update_exp", "(", "p_func_vars", ",", "target_p_func_vars", ")", "\n", "\n", "target_act_sample", "=", "act_pdtype_n", "[", "p_index", "]", ".", "pdfromflat", "(", "target_p", ")", ".", "sample", "(", ")", "\n", "target_act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "outputs", "=", "target_act_sample", ")", "\n", "\n", "return", "act", ",", "train", ",", "update_target_p", ",", "{", "'p_values'", ":", "p_values", ",", "'target_act'", ":", "target_act", "}", "\n", "\n", "", "", "def", "q_train", "(", "make_obs_ph_n", ",", "act_space_n", ",", "q_index", ",", "q_func", ",", "optimizer", ",", "grad_norm_clipping", "=", "None", ",", "local_q_func", "=", "False", ",", "scope", "=", "\"trainer\"", ",", "reuse", "=", "None", ",", "num_units", "=", "64", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "# create distribtuions", "\n", "        ", "act_pdtype_n", "=", "[", "make_pdtype", "(", "act_space", ")", "for", "act_space", "in", "act_space_n", "]", "\n", "\n", "# set up placeholders", "\n", "n", "=", "len", "(", "act_space_n", ")", "\n", "obs_ph_n", "=", "make_obs_ph_n", "\n", "act_ph_n", "=", "[", "act_pdtype_n", "[", "i", "]", ".", "sample_placeholder", "(", "[", "None", "]", ",", "name", "=", "\"action\"", "+", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "n", ")", "]", "\n", "# exclude_i = list(filter(lambda i: i != q_index, range(n)))", "\n", "# mean_act = [act_ph_n[q_index], tf.reduce_mean([act_ph_n[i] for i in exclude_i])]", "\n", "target_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ",", "name", "=", "\"target\"", ")", "\n", "#print(act_ph_n)", "\n", "q_input", "=", "tf", ".", "concat", "(", "obs_ph_n", "+", "act_ph_n", ",", "1", ")", "\n", "if", "local_q_func", ":", "\n", "            ", "q_input", "=", "tf", ".", "concat", "(", "[", "obs_ph_n", "[", "q_index", "]", ",", "act_ph_n", "[", "q_index", "]", "]", ",", "1", ")", "\n", "", "q", "=", "q_func", "(", "q_input", ",", "1", ",", "scope", "=", "\"q_func\"", ",", "num_units", "=", "num_units", ")", "[", ":", ",", "0", "]", "\n", "q_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"q_func\"", ")", ")", "\n", "\n", "q_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "q", "-", "target_ph", ")", ")", "\n", "\n", "# viscosity solution to Bellman differential equation in place of an initial condition", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.discount_with_dones": [[11, 19], ["zip", "discounted.append"], "function", ["None"], ["import", "copy", "\n", "\n", "\n", "def", "discount_with_dones", "(", "rewards", ",", "dones", ",", "gamma", ")", ":", "\n", "    ", "discounted", "=", "[", "]", "\n", "r", "=", "0", "\n", "for", "reward", ",", "done", "in", "zip", "(", "rewards", "[", ":", ":", "-", "1", "]", ",", "dones", "[", ":", ":", "-", "1", "]", ")", ":", "\n", "        ", "r", "=", "reward", "+", "gamma", "*", "r", "\n", "r", "=", "r", "*", "(", "1.", "-", "done", ")", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.make_update_exp": [[20, 27], ["zip", "tensorflow.group", "maddpg_local.function", "sorted", "sorted", "tf.group.append", "var_target.assign"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function"], ["discounted", ".", "append", "(", "r", ")", "\n", "", "return", "discounted", "[", ":", ":", "-", "1", "]", "\n", "\n", "", "def", "make_update_exp", "(", "vals", ",", "target_vals", ")", ":", "\n", "    ", "polyak", "=", "1.0", "-", "1e-2", "\n", "expression", "=", "[", "]", "\n", "for", "var", ",", "var_target", "in", "zip", "(", "sorted", "(", "vals", ",", "key", "=", "lambda", "v", ":", "v", ".", "name", ")", ",", "sorted", "(", "target_vals", ",", "key", "=", "lambda", "v", ":", "v", ".", "name", ")", ")", ":", "\n", "        ", "expression", ".", "append", "(", "var_target", ".", "assign", "(", "polyak", "*", "var_target", "+", "(", "1.0", "-", "polyak", ")", "*", "var", ")", ")", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.p_train": [[28, 84], ["tensorflow.variable_scope", "p_func", "maddpg_local.scope_vars", "act_pdtype_n[].pdfromflat", "act_pdtype_n[].pdfromflat.sample", "tensorflow.reduce_mean", "act_pdtype_n[].pdfromflat.sample", "tensorflow.concat", "maddpg_local.minimize_and_clip", "maddpg_local.function", "maddpg_local.function", "maddpg_local.function", "p_func", "maddpg_local.scope_vars", "maddpg.make_update_exp", "act_pdtype_n[].pdfromflat().sample", "maddpg_local.function", "maddpg_local.common.distributions.make_pdtype", "act_pdtype_n[].sample_placeholder", "int", "maddpg_local.absolute_scope_name", "tensorflow.square", "tensorflow.concat", "print", "q_func", "tensorflow.reduce_mean", "int", "maddpg_local.absolute_scope_name", "range", "act_pdtype_n[].pdfromflat.flatparam", "tensorflow.shape", "act_pdtype_n[].pdfromflat", "len", "act_pdtype_n[].param_shape", "act_pdtype_n[].param_shape", "str"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.minimize_and_clip", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.make_update_exp", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.make_pdtype", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.flatparam", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.multi_discrete.MultiDiscrete.shape", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape"], ["", "expression", "=", "tf", ".", "group", "(", "*", "expression", ")", "\n", "return", "U", ".", "function", "(", "[", "]", ",", "[", "]", ",", "updates", "=", "[", "expression", "]", ")", "\n", "\n", "", "def", "p_train", "(", "make_obs_ph_n", ",", "act_space_n", ",", "p_index", ",", "p_func", ",", "q_func", ",", "optimizer", ",", "grad_norm_clipping", "=", "None", ",", "local_q_func", "=", "False", ",", "num_units", "=", "64", ",", "scope", "=", "\"trainer\"", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "\n", "        ", "act_pdtype_n", "=", "[", "make_pdtype", "(", "act_space", ")", "for", "act_space", "in", "act_space_n", "]", "\n", "\n", "# set up placeholders", "\n", "obs_ph_n", "=", "make_obs_ph_n", "\n", "act_ph_n", "=", "[", "act_pdtype_n", "[", "i", "]", ".", "sample_placeholder", "(", "[", "None", "]", ",", "name", "=", "\"action\"", "+", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "act_space_n", ")", ")", "]", "\n", "\n", "p_input", "=", "obs_ph_n", "[", "p_index", "]", "\n", "\n", "# print(\"p_train/p_func:\", scope)", "\n", "p", "=", "p_func", "(", "p_input", ",", "int", "(", "act_pdtype_n", "[", "p_index", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "p_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"p_func\"", ")", ")", "\n", "\n", "# wrap parameters in distribution", "\n", "act_pd", "=", "act_pdtype_n", "[", "p_index", "]", ".", "pdfromflat", "(", "p", ")", "\n", "\n", "act_sample", "=", "act_pd", ".", "sample", "(", ")", "\n", "p_reg", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "act_pd", ".", "flatparam", "(", ")", ")", ")", "\n", "\n", "act_input_n", "=", "act_ph_n", "+", "[", "]", "\n", "act_input_n", "[", "p_index", "]", "=", "act_pd", ".", "sample", "(", ")", "\n", "q_input", "=", "tf", ".", "concat", "(", "obs_ph_n", "+", "act_input_n", ",", "1", ")", "\n", "if", "local_q_func", ":", "\n", "            ", "q_input", "=", "tf", ".", "concat", "(", "[", "obs_ph_n", "[", "p_index", "]", ",", "act_input_n", "[", "p_index", "]", "]", ",", "1", ")", "\n", "", "q", "=", "q_func", "(", "q_input", ",", "1", ",", "scope", "=", "\"q_func\"", ",", "reuse", "=", "True", ",", "num_units", "=", "num_units", ")", "[", ":", ",", "0", "]", "\n", "pg_loss", "=", "-", "tf", ".", "reduce_mean", "(", "q", ")", "\n", "\n", "loss", "=", "pg_loss", "+", "p_reg", "*", "1e-3", "\n", "\n", "optimize_expr", "=", "U", ".", "minimize_and_clip", "(", "optimizer", ",", "loss", ",", "p_func_vars", ",", "grad_norm_clipping", ")", "\n", "\n", "# Create callable functions", "\n", "train", "=", "U", ".", "function", "(", "inputs", "=", "obs_ph_n", "+", "act_ph_n", ",", "outputs", "=", "loss", ",", "updates", "=", "[", "optimize_expr", "]", ")", "\n", "act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "outputs", "=", "act_sample", ")", "\n", "# attention = U.function(inputs=[obs_ph_n[p_index]], outputs=[attn.good_attn, attn.adv_attn])", "\n", "p_values", "=", "U", ".", "function", "(", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "p", ")", "\n", "# print([obs_ph_n[p_index]], act_sample)", "\n", "\n", "# target network", "\n", "target_p", "=", "p_func", "(", "p_input", ",", "int", "(", "act_pdtype_n", "[", "p_index", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"target_p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "target_p_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"target_p_func\"", ")", ")", "\n", "update_target_p", "=", "make_update_exp", "(", "p_func_vars", ",", "target_p_func_vars", ")", "\n", "\n", "target_act_sample", "=", "act_pdtype_n", "[", "p_index", "]", ".", "pdfromflat", "(", "target_p", ")", ".", "sample", "(", ")", "\n", "target_act", "=", "U", ".", "function", "(", "inputs", "=", "[", "obs_ph_n", "[", "p_index", "]", "]", ",", "outputs", "=", "target_act_sample", ")", "\n", "\n", "return", "act", ",", "train", ",", "update_target_p", ",", "{", "'p_values'", ":", "p_values", ",", "'target_act'", ":", "target_act", "}", "\n", "\n", "", "", "def", "group_p_train", "(", "make_obs_ph_n", ",", "act_space_n", ",", "p_index", ",", "num_adversaries", ",", "p_func", ",", "q_func", ",", "optimizer", ",", "grad_norm_clipping", "=", "None", ",", "local_q_func", "=", "False", ",", "num_units", "=", "64", ",", "scope", "=", "\"trainer\"", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "# create distribtuions", "\n", "        ", "act_pdtype_n", "=", "[", "make_pdtype", "(", "act_space", ")", "for", "act_space", "in", "act_space_n", "]", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.q_train": [[85, 121], ["tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.concat", "maddpg_local.scope_vars", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "maddpg_local.minimize_and_clip", "maddpg_local.function", "maddpg_local.function", "maddpg_local.scope_vars", "maddpg.make_update_exp", "maddpg_local.function", "maddpg_local.common.distributions.make_pdtype", "act_pdtype_n[].sample_placeholder", "tensorflow.concat", "q_func", "maddpg_local.absolute_scope_name", "tensorflow.square", "tensorflow.square", "q_func", "maddpg_local.absolute_scope_name", "range", "len", "str"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.minimize_and_clip", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.make_update_exp", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.make_pdtype", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name"], ["\n", "# set up placeholders for a group", "\n", "obs_ph_n", "=", "make_obs_ph_n", "\n", "n_agents", "=", "len", "(", "obs_ph_n", ")", "\n", "\n", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "\n", "            ", "act_ph_ns", "=", "[", "[", "act_pdtype_n", "[", "i", "]", ".", "sample_placeholder", "(", "[", "None", "]", ",", "name", "=", "\"action\"", "+", "str", "(", "n", ")", "+", "'_'", "+", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "act_space_n", ")", ")", "]", "for", "n", "in", "range", "(", "num_adversaries", ")", "]", "\n", "", "else", ":", "\n", "            ", "act_ph_ns", "=", "[", "[", "act_pdtype_n", "[", "i", "]", ".", "sample_placeholder", "(", "[", "None", "]", ",", "name", "=", "\"action\"", "+", "str", "(", "n", ")", "+", "'_'", "+", "str", "(", "i", ")", ")", "for", "i", "in", "range", "(", "len", "(", "act_space_n", ")", ")", "]", "for", "n", "in", "range", "(", "n_agents", "-", "num_adversaries", ")", "]", "\n", "", "act_ph_ns_flatten", "=", "list", "(", "chain", ".", "from_iterable", "(", "act_ph_ns", ")", ")", "\n", "\n", "# p_input = obs_ph_n[p_index] # one obs for a certain p_index", "\n", "# batchify obs for all agents in a group", "\n", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "# adv", "\n", "            ", "p_input", "=", "tf", ".", "concat", "(", "obs_ph_n", "[", ":", "num_adversaries", "]", ",", "1", ")", "\n", "p_input", "=", "tf", ".", "reshape", "(", "p_input", ",", "[", "-", "1", ",", "p_input", ".", "shape", "[", "-", "1", "]", ".", "value", "//", "num_adversaries", "]", ")", "\n", "", "else", ":", "# good agent", "\n", "            ", "p_input", "=", "tf", ".", "concat", "(", "obs_ph_n", "[", "num_adversaries", ":", "]", ",", "1", ")", "\n", "p_input", "=", "tf", ".", "reshape", "(", "p_input", ",", "[", "-", "1", ",", "p_input", ".", "shape", "[", "-", "1", "]", ".", "value", "//", "(", "n_agents", "-", "num_adversaries", ")", "]", ")", "\n", "\n", "# get all actions from a group", "\n", "", "p", "=", "p_func", "(", "p_input", ",", "int", "(", "act_pdtype_n", "[", "p_index", "]", ".", "param_shape", "(", ")", "[", "0", "]", ")", ",", "scope", "=", "\"p_func\"", ",", "num_units", "=", "num_units", ")", "\n", "p_func_vars", "=", "U", ".", "scope_vars", "(", "U", ".", "absolute_scope_name", "(", "\"p_func\"", ")", ")", "\n", "\n", "# wrap parameters in distribution", "\n", "# un-batchify actions from a group", "\n", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "\n", "            ", "p", "=", "tf", ".", "reshape", "(", "p", ",", "[", "-", "1", ",", "p", ".", "shape", "[", "-", "1", "]", "*", "num_adversaries", "]", ")", "\n", "ps", "=", "tf", ".", "split", "(", "p", ",", "num_or_size_splits", "=", "num_adversaries", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "p", "=", "tf", ".", "reshape", "(", "p", ",", "[", "-", "1", ",", "p", ".", "shape", "[", "-", "1", "]", "*", "(", "n_agents", "-", "num_adversaries", ")", "]", ")", "\n", "ps", "=", "tf", ".", "split", "(", "p", ",", "num_or_size_splits", "=", "(", "n_agents", "-", "num_adversaries", ")", ",", "axis", "=", "1", ")", "\n", "\n", "# get probability distributions and action samples for a group", "\n", "", "if", "(", "p_index", "<", "num_adversaries", ")", ":", "\n", "            ", "act_pds", "=", "[", "act_pdtype_n", "[", "i", "]", ".", "pdfromflat", "(", "ps", "[", "i", "]", ")", "for", "i", "in", "range", "(", "num_adversaries", ")", "]", "\n", "act_samples", "=", "[", "act_pds", "[", "i", "]", ".", "sample", "(", ")", "for", "i", "in", "range", "(", "num_adversaries", ")", "]", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.Pd.flatparam": [[12, 14], ["None"], "methods", ["None"], ["def", "flatparam", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "mode", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.Pd.mode": [[14, 16], ["None"], "methods", ["None"], ["", "def", "mode", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "logp", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.Pd.logp": [[16, 18], ["None"], "methods", ["None"], ["", "def", "logp", "(", "self", ",", "x", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "kl", "(", "self", ",", "other", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.Pd.kl": [[18, 20], ["None"], "methods", ["None"], ["", "def", "kl", "(", "self", ",", "other", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "entropy", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.Pd.entropy": [[20, 22], ["None"], "methods", ["None"], ["", "def", "entropy", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "sample", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.Pd.sample": [[22, 24], ["None"], "methods", ["None"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.pdclass": [[29, 31], ["None"], "methods", ["None"], ["def", "pdclass", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "pdfromflat", "(", "self", ",", "flat", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.pdfromflat": [[31, 33], ["distributions.PdType.pdclass"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.pdclass"], ["", "def", "pdfromflat", "(", "self", ",", "flat", ")", ":", "\n", "        ", "return", "self", ".", "pdclass", "(", ")", "(", "flat", ")", "\n", "", "def", "param_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.param_shape": [[33, 35], ["None"], "methods", ["None"], ["", "def", "param_shape", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "sample_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.sample_shape": [[35, 37], ["None"], "methods", ["None"], ["", "def", "sample_shape", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "sample_dtype", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.sample_dtype": [[37, 39], ["None"], "methods", ["None"], ["", "def", "sample_dtype", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.param_placeholder": [[40, 42], ["tensorflow.placeholder", "distributions.PdType.param_shape"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape"], ["", "def", "param_placeholder", "(", "self", ",", "prepend_shape", ",", "name", "=", "None", ")", ":", "\n", "        ", "return", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "prepend_shape", "+", "self", ".", "param_shape", "(", ")", ",", "name", "=", "name", ")", "\n", "", "def", "sample_placeholder", "(", "self", ",", "prepend_shape", ",", "name", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.PdType.sample_placeholder": [[42, 44], ["tensorflow.placeholder", "distributions.PdType.sample_dtype", "distributions.PdType.sample_shape"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.sample_dtype", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.sample_shape"], ["", "def", "sample_placeholder", "(", "self", ",", "prepend_shape", ",", "name", "=", "None", ")", ":", "\n", "        ", "return", "tf", ".", "placeholder", "(", "dtype", "=", "self", ".", "sample_dtype", "(", ")", ",", "shape", "=", "prepend_shape", "+", "self", ".", "sample_shape", "(", ")", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.CategoricalPdType.__init__": [[46, 48], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "ncat", ")", ":", "\n", "        ", "self", ".", "ncat", "=", "ncat", "\n", "", "def", "pdclass", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.CategoricalPdType.pdclass": [[48, 50], ["None"], "methods", ["None"], ["", "def", "pdclass", "(", "self", ")", ":", "\n", "        ", "return", "CategoricalPd", "\n", "", "def", "param_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.CategoricalPdType.param_shape": [[50, 52], ["None"], "methods", ["None"], ["", "def", "param_shape", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "ncat", "]", "\n", "", "def", "sample_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.CategoricalPdType.sample_shape": [[52, 54], ["None"], "methods", ["None"], ["", "def", "sample_shape", "(", "self", ")", ":", "\n", "        ", "return", "[", "]", "\n", "", "def", "sample_dtype", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.CategoricalPdType.sample_dtype": [[54, 56], ["None"], "methods", ["None"], ["", "def", "sample_dtype", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "int32", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftCategoricalPdType.__init__": [[58, 60], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "ncat", ")", ":", "\n", "        ", "self", ".", "ncat", "=", "ncat", "\n", "", "def", "pdclass", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftCategoricalPdType.pdclass": [[60, 62], ["None"], "methods", ["None"], ["", "def", "pdclass", "(", "self", ")", ":", "\n", "        ", "return", "SoftCategoricalPd", "\n", "", "def", "param_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftCategoricalPdType.param_shape": [[62, 64], ["None"], "methods", ["None"], ["", "def", "param_shape", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "ncat", "]", "\n", "", "def", "sample_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftCategoricalPdType.sample_shape": [[64, 66], ["None"], "methods", ["None"], ["", "def", "sample_shape", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "ncat", "]", "\n", "", "def", "sample_dtype", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftCategoricalPdType.sample_dtype": [[66, 68], ["None"], "methods", ["None"], ["", "def", "sample_dtype", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "float32", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.MultiCategoricalPdType.__init__": [[70, 74], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "low", ",", "high", ")", ":", "\n", "        ", "self", ".", "low", "=", "low", "\n", "self", ".", "high", "=", "high", "\n", "self", ".", "ncats", "=", "high", "-", "low", "+", "1", "\n", "", "def", "pdclass", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.MultiCategoricalPdType.pdclass": [[74, 76], ["None"], "methods", ["None"], ["", "def", "pdclass", "(", "self", ")", ":", "\n", "        ", "return", "MultiCategoricalPd", "\n", "", "def", "pdfromflat", "(", "self", ",", "flat", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.MultiCategoricalPdType.pdfromflat": [[76, 78], ["distributions.MultiCategoricalPd"], "methods", ["None"], ["", "def", "pdfromflat", "(", "self", ",", "flat", ")", ":", "\n", "        ", "return", "MultiCategoricalPd", "(", "self", ".", "low", ",", "self", ".", "high", ",", "flat", ")", "\n", "", "def", "param_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.MultiCategoricalPdType.param_shape": [[78, 80], ["sum"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "param_shape", "(", "self", ")", ":", "\n", "        ", "return", "[", "sum", "(", "self", ".", "ncats", ")", "]", "\n", "", "def", "sample_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.MultiCategoricalPdType.sample_shape": [[80, 82], ["len"], "methods", ["None"], ["", "def", "sample_shape", "(", "self", ")", ":", "\n", "        ", "return", "[", "len", "(", "self", ".", "ncats", ")", "]", "\n", "", "def", "sample_dtype", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.MultiCategoricalPdType.sample_dtype": [[82, 84], ["None"], "methods", ["None"], ["", "def", "sample_dtype", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "int32", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.__init__": [[86, 90], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "low", ",", "high", ")", ":", "\n", "        ", "self", ".", "low", "=", "low", "\n", "self", ".", "high", "=", "high", "\n", "self", ".", "ncats", "=", "high", "-", "low", "+", "1", "\n", "", "def", "pdclass", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdclass": [[90, 92], ["None"], "methods", ["None"], ["", "def", "pdclass", "(", "self", ")", ":", "\n", "        ", "return", "SoftMultiCategoricalPd", "\n", "", "def", "pdfromflat", "(", "self", ",", "flat", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.pdfromflat": [[92, 94], ["distributions.SoftMultiCategoricalPd"], "methods", ["None"], ["", "def", "pdfromflat", "(", "self", ",", "flat", ")", ":", "\n", "        ", "return", "SoftMultiCategoricalPd", "(", "self", ".", "low", ",", "self", ".", "high", ",", "flat", ")", "\n", "", "def", "param_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.param_shape": [[94, 96], ["sum"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "param_shape", "(", "self", ")", ":", "\n", "        ", "return", "[", "sum", "(", "self", ".", "ncats", ")", "]", "\n", "", "def", "sample_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.sample_shape": [[96, 98], ["sum"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "sample_shape", "(", "self", ")", ":", "\n", "        ", "return", "[", "sum", "(", "self", ".", "ncats", ")", "]", "\n", "", "def", "sample_dtype", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPdType.sample_dtype": [[98, 100], ["None"], "methods", ["None"], ["", "def", "sample_dtype", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "float32", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.DiagGaussianPdType.__init__": [[102, 104], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "", "def", "pdclass", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.DiagGaussianPdType.pdclass": [[104, 106], ["None"], "methods", ["None"], ["", "def", "pdclass", "(", "self", ")", ":", "\n", "        ", "return", "DiagGaussianPd", "\n", "", "def", "param_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.DiagGaussianPdType.param_shape": [[106, 108], ["None"], "methods", ["None"], ["", "def", "param_shape", "(", "self", ")", ":", "\n", "        ", "return", "[", "2", "*", "self", ".", "size", "]", "\n", "", "def", "sample_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.DiagGaussianPdType.sample_shape": [[108, 110], ["None"], "methods", ["None"], ["", "def", "sample_shape", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "size", "]", "\n", "", "def", "sample_dtype", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.DiagGaussianPdType.sample_dtype": [[110, 112], ["None"], "methods", ["None"], ["", "def", "sample_dtype", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "float32", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.__init__": [[114, 116], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "", "def", "pdclass", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.pdclass": [[116, 118], ["None"], "methods", ["None"], ["", "def", "pdclass", "(", "self", ")", ":", "\n", "        ", "return", "BernoulliPd", "\n", "", "def", "param_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.param_shape": [[118, 120], ["None"], "methods", ["None"], ["", "def", "param_shape", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "size", "]", "\n", "", "def", "sample_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.sample_shape": [[120, 122], ["None"], "methods", ["None"], ["", "def", "sample_shape", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "size", "]", "\n", "", "def", "sample_dtype", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPdType.sample_dtype": [[122, 124], ["None"], "methods", ["None"], ["", "def", "sample_dtype", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "int32", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.CategoricalPd.__init__": [[149, 151], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "logits", ")", ":", "\n", "        ", "self", ".", "logits", "=", "logits", "\n", "", "def", "flatparam", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.CategoricalPd.flatparam": [[151, 153], ["None"], "methods", ["None"], ["", "def", "flatparam", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "logits", "\n", "", "def", "mode", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.CategoricalPd.mode": [[153, 155], ["maddpg_o.argmax"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.argmax"], ["", "def", "mode", "(", "self", ")", ":", "\n", "        ", "return", "U", ".", "argmax", "(", "self", ".", "logits", ",", "axis", "=", "1", ")", "\n", "", "def", "logp", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.CategoricalPd.logp": [[155, 157], ["tensorflow.nn.sparse_softmax_cross_entropy_with_logits"], "methods", ["None"], ["", "def", "logp", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "-", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "logits", "=", "self", ".", "logits", ",", "labels", "=", "x", ")", "\n", "", "def", "kl", "(", "self", ",", "other", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.CategoricalPd.kl": [[157, 166], ["tensorflow.exp", "tensorflow.exp", "maddpg_o.sum", "maddpg_o.sum", "maddpg_o.sum", "maddpg_o.max", "maddpg_o.max", "tensorflow.log", "tensorflow.log"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.max", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.max"], ["", "def", "kl", "(", "self", ",", "other", ")", ":", "\n", "        ", "a0", "=", "self", ".", "logits", "-", "U", ".", "max", "(", "self", ".", "logits", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "a1", "=", "other", ".", "logits", "-", "U", ".", "max", "(", "other", ".", "logits", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "ea0", "=", "tf", ".", "exp", "(", "a0", ")", "\n", "ea1", "=", "tf", ".", "exp", "(", "a1", ")", "\n", "z0", "=", "U", ".", "sum", "(", "ea0", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "z1", "=", "U", ".", "sum", "(", "ea1", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "p0", "=", "ea0", "/", "z0", "\n", "return", "U", ".", "sum", "(", "p0", "*", "(", "a0", "-", "tf", ".", "log", "(", "z0", ")", "-", "a1", "+", "tf", ".", "log", "(", "z1", ")", ")", ",", "axis", "=", "1", ")", "\n", "", "def", "entropy", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.CategoricalPd.entropy": [[166, 172], ["tensorflow.exp", "maddpg_o.sum", "maddpg_o.sum", "maddpg_o.max", "tensorflow.log"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.max"], ["", "def", "entropy", "(", "self", ")", ":", "\n", "        ", "a0", "=", "self", ".", "logits", "-", "U", ".", "max", "(", "self", ".", "logits", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "ea0", "=", "tf", ".", "exp", "(", "a0", ")", "\n", "z0", "=", "U", ".", "sum", "(", "ea0", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "p0", "=", "ea0", "/", "z0", "\n", "return", "U", ".", "sum", "(", "p0", "*", "(", "tf", ".", "log", "(", "z0", ")", "-", "a0", ")", ",", "axis", "=", "1", ")", "\n", "", "def", "sample", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.CategoricalPd.sample": [[172, 175], ["tensorflow.random_uniform", "maddpg_o.argmax", "tensorflow.shape", "tensorflow.log", "tensorflow.log"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.argmax", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.multi_discrete.MultiDiscrete.shape"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "u", "=", "tf", ".", "random_uniform", "(", "tf", ".", "shape", "(", "self", ".", "logits", ")", ")", "\n", "return", "U", ".", "argmax", "(", "self", ".", "logits", "-", "tf", ".", "log", "(", "-", "tf", ".", "log", "(", "u", ")", ")", ",", "axis", "=", "1", ")", "\n", "", "@", "classmethod", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.CategoricalPd.fromflat": [[175, 178], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "fromflat", "(", "cls", ",", "flat", ")", ":", "\n", "        ", "return", "cls", "(", "flat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftCategoricalPd.__init__": [[180, 182], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "logits", ")", ":", "\n", "        ", "self", ".", "logits", "=", "logits", "\n", "", "def", "flatparam", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftCategoricalPd.flatparam": [[182, 184], ["None"], "methods", ["None"], ["", "def", "flatparam", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "logits", "\n", "", "def", "mode", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftCategoricalPd.mode": [[184, 186], ["maddpg_o.softmax"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.softmax"], ["", "def", "mode", "(", "self", ")", ":", "\n", "        ", "return", "U", ".", "softmax", "(", "self", ".", "logits", ",", "axis", "=", "-", "1", ")", "\n", "", "def", "logp", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftCategoricalPd.logp": [[186, 188], ["tensorflow.nn.softmax_cross_entropy_with_logits"], "methods", ["None"], ["", "def", "logp", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "-", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits", "(", "logits", "=", "self", ".", "logits", ",", "labels", "=", "x", ")", "\n", "", "def", "kl", "(", "self", ",", "other", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftCategoricalPd.kl": [[188, 197], ["tensorflow.exp", "tensorflow.exp", "maddpg_o.sum", "maddpg_o.sum", "maddpg_o.sum", "maddpg_o.max", "maddpg_o.max", "tensorflow.log", "tensorflow.log"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.max", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.max"], ["", "def", "kl", "(", "self", ",", "other", ")", ":", "\n", "        ", "a0", "=", "self", ".", "logits", "-", "U", ".", "max", "(", "self", ".", "logits", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "a1", "=", "other", ".", "logits", "-", "U", ".", "max", "(", "other", ".", "logits", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "ea0", "=", "tf", ".", "exp", "(", "a0", ")", "\n", "ea1", "=", "tf", ".", "exp", "(", "a1", ")", "\n", "z0", "=", "U", ".", "sum", "(", "ea0", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "z1", "=", "U", ".", "sum", "(", "ea1", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "p0", "=", "ea0", "/", "z0", "\n", "return", "U", ".", "sum", "(", "p0", "*", "(", "a0", "-", "tf", ".", "log", "(", "z0", ")", "-", "a1", "+", "tf", ".", "log", "(", "z1", ")", ")", ",", "axis", "=", "1", ")", "\n", "", "def", "entropy", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftCategoricalPd.entropy": [[197, 203], ["tensorflow.exp", "maddpg_o.sum", "maddpg_o.sum", "maddpg_o.max", "tensorflow.log"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.max"], ["", "def", "entropy", "(", "self", ")", ":", "\n", "        ", "a0", "=", "self", ".", "logits", "-", "U", ".", "max", "(", "self", ".", "logits", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "ea0", "=", "tf", ".", "exp", "(", "a0", ")", "\n", "z0", "=", "U", ".", "sum", "(", "ea0", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "p0", "=", "ea0", "/", "z0", "\n", "return", "U", ".", "sum", "(", "p0", "*", "(", "tf", ".", "log", "(", "z0", ")", "-", "a0", ")", ",", "axis", "=", "1", ")", "\n", "", "def", "sample", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftCategoricalPd.sample": [[203, 206], ["tensorflow.random_uniform", "maddpg_o.softmax", "tensorflow.shape", "tensorflow.log", "tensorflow.log"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.softmax", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.multi_discrete.MultiDiscrete.shape"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "u", "=", "tf", ".", "random_uniform", "(", "tf", ".", "shape", "(", "self", ".", "logits", ")", ")", "\n", "return", "U", ".", "softmax", "(", "self", ".", "logits", "-", "tf", ".", "log", "(", "-", "tf", ".", "log", "(", "u", ")", ")", ",", "axis", "=", "-", "1", ")", "\n", "", "@", "classmethod", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftCategoricalPd.fromflat": [[206, 209], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "fromflat", "(", "cls", ",", "flat", ")", ":", "\n", "        ", "return", "cls", "(", "flat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.MultiCategoricalPd.__init__": [[211, 215], ["tensorflow.constant", "list", "map", "tensorflow.split", "len", "flat.get_shape"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "low", ",", "high", ",", "flat", ")", ":", "\n", "        ", "self", ".", "flat", "=", "flat", "\n", "self", ".", "low", "=", "tf", ".", "constant", "(", "low", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "self", ".", "categoricals", "=", "list", "(", "map", "(", "CategoricalPd", ",", "tf", ".", "split", "(", "flat", ",", "high", "-", "low", "+", "1", ",", "axis", "=", "len", "(", "flat", ".", "get_shape", "(", ")", ")", "-", "1", ")", ")", ")", "\n", "", "def", "flatparam", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.MultiCategoricalPd.flatparam": [[215, 217], ["None"], "methods", ["None"], ["", "def", "flatparam", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "flat", "\n", "", "def", "mode", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.MultiCategoricalPd.mode": [[217, 219], ["tensorflow.cast", "tensorflow.stack", "p.mode"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.mode"], ["", "def", "mode", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "low", "+", "tf", ".", "cast", "(", "tf", ".", "stack", "(", "[", "p", ".", "mode", "(", ")", "for", "p", "in", "self", ".", "categoricals", "]", ",", "axis", "=", "-", "1", ")", ",", "tf", ".", "int32", ")", "\n", "", "def", "logp", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.MultiCategoricalPd.logp": [[219, 221], ["tensorflow.add_n", "p.logp", "zip", "tensorflow.unstack", "len", "x.get_shape"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.logp"], ["", "def", "logp", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "tf", ".", "add_n", "(", "[", "p", ".", "logp", "(", "px", ")", "for", "p", ",", "px", "in", "zip", "(", "self", ".", "categoricals", ",", "tf", ".", "unstack", "(", "x", "-", "self", ".", "low", ",", "axis", "=", "len", "(", "x", ".", "get_shape", "(", ")", ")", "-", "1", ")", ")", "]", ")", "\n", "", "def", "kl", "(", "self", ",", "other", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.MultiCategoricalPd.kl": [[221, 224], ["tensorflow.add_n", "p.kl", "zip"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.kl"], ["", "def", "kl", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "tf", ".", "add_n", "(", "[", "\n", "p", ".", "kl", "(", "q", ")", "for", "p", ",", "q", "in", "zip", "(", "self", ".", "categoricals", ",", "other", ".", "categoricals", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.MultiCategoricalPd.entropy": [[225, 227], ["tensorflow.add_n", "p.entropy"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.entropy"], ["", "def", "entropy", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "add_n", "(", "[", "p", ".", "entropy", "(", ")", "for", "p", "in", "self", ".", "categoricals", "]", ")", "\n", "", "def", "sample", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.MultiCategoricalPd.sample": [[227, 229], ["tensorflow.cast", "tensorflow.stack", "p.sample"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "low", "+", "tf", ".", "cast", "(", "tf", ".", "stack", "(", "[", "p", ".", "sample", "(", ")", "for", "p", "in", "self", ".", "categoricals", "]", ",", "axis", "=", "-", "1", ")", ",", "tf", ".", "int32", ")", "\n", "", "@", "classmethod", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.MultiCategoricalPd.fromflat": [[229, 232], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "fromflat", "(", "cls", ",", "flat", ")", ":", "\n", "        ", "return", "cls", "(", "flat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPd.__init__": [[234, 238], ["tensorflow.constant", "list", "map", "tensorflow.split", "len", "flat.get_shape"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "low", ",", "high", ",", "flat", ")", ":", "\n", "        ", "self", ".", "flat", "=", "flat", "\n", "self", ".", "low", "=", "tf", ".", "constant", "(", "low", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "categoricals", "=", "list", "(", "map", "(", "SoftCategoricalPd", ",", "tf", ".", "split", "(", "flat", ",", "high", "-", "low", "+", "1", ",", "axis", "=", "len", "(", "flat", ".", "get_shape", "(", ")", ")", "-", "1", ")", ")", ")", "\n", "", "def", "flatparam", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPd.flatparam": [[238, 240], ["None"], "methods", ["None"], ["", "def", "flatparam", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "flat", "\n", "", "def", "mode", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPd.mode": [[240, 245], ["range", "tensorflow.concat", "len", "x.append", "distributions.SoftMultiCategoricalPd.categoricals[].mode"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.mode"], ["", "def", "mode", "(", "self", ")", ":", "\n", "        ", "x", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "categoricals", ")", ")", ":", "\n", "            ", "x", ".", "append", "(", "self", ".", "low", "[", "i", "]", "+", "self", ".", "categoricals", "[", "i", "]", ".", "mode", "(", ")", ")", "\n", "", "return", "tf", ".", "concat", "(", "x", ",", "axis", "=", "-", "1", ")", "\n", "", "def", "logp", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPd.logp": [[245, 247], ["tensorflow.add_n", "p.logp", "zip", "tensorflow.unstack", "len", "x.get_shape"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.logp"], ["", "def", "logp", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "tf", ".", "add_n", "(", "[", "p", ".", "logp", "(", "px", ")", "for", "p", ",", "px", "in", "zip", "(", "self", ".", "categoricals", ",", "tf", ".", "unstack", "(", "x", "-", "self", ".", "low", ",", "axis", "=", "len", "(", "x", ".", "get_shape", "(", ")", ")", "-", "1", ")", ")", "]", ")", "\n", "", "def", "kl", "(", "self", ",", "other", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPd.kl": [[247, 250], ["tensorflow.add_n", "p.kl", "zip"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.kl"], ["", "def", "kl", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "tf", ".", "add_n", "(", "[", "\n", "p", ".", "kl", "(", "q", ")", "for", "p", ",", "q", "in", "zip", "(", "self", ".", "categoricals", ",", "other", ".", "categoricals", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPd.entropy": [[251, 253], ["tensorflow.add_n", "p.entropy"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.entropy"], ["", "def", "entropy", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "add_n", "(", "[", "p", ".", "entropy", "(", ")", "for", "p", "in", "self", ".", "categoricals", "]", ")", "\n", "", "def", "sample", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPd.sample": [[253, 258], ["range", "tensorflow.concat", "len", "x.append", "distributions.SoftMultiCategoricalPd.categoricals[].sample"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "x", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "categoricals", ")", ")", ":", "\n", "            ", "x", ".", "append", "(", "self", ".", "low", "[", "i", "]", "+", "self", ".", "categoricals", "[", "i", "]", ".", "sample", "(", ")", ")", "\n", "", "return", "tf", ".", "concat", "(", "x", ",", "axis", "=", "-", "1", ")", "\n", "", "@", "classmethod", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.SoftMultiCategoricalPd.fromflat": [[258, 261], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "fromflat", "(", "cls", ",", "flat", ")", ":", "\n", "        ", "return", "cls", "(", "flat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.DiagGaussianPd.__init__": [[263, 269], ["tensorflow.split", "tensorflow.exp"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "flat", ")", ":", "\n", "        ", "self", ".", "flat", "=", "flat", "\n", "mean", ",", "logstd", "=", "tf", ".", "split", "(", "axis", "=", "1", ",", "num_or_size_splits", "=", "2", ",", "value", "=", "flat", ")", "\n", "self", ".", "mean", "=", "mean", "\n", "self", ".", "logstd", "=", "logstd", "\n", "self", ".", "std", "=", "tf", ".", "exp", "(", "logstd", ")", "\n", "", "def", "flatparam", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.DiagGaussianPd.flatparam": [[269, 271], ["None"], "methods", ["None"], ["", "def", "flatparam", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "flat", "\n", "", "def", "mode", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.DiagGaussianPd.mode": [[271, 273], ["None"], "methods", ["None"], ["", "def", "mode", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "mean", "\n", "", "def", "logp", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.DiagGaussianPd.logp": [[273, 277], ["maddpg_o.sum", "maddpg_o.sum", "tensorflow.to_float", "tensorflow.square", "numpy.log", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.multi_discrete.MultiDiscrete.shape"], ["", "def", "logp", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "-", "0.5", "*", "U", ".", "sum", "(", "tf", ".", "square", "(", "(", "x", "-", "self", ".", "mean", ")", "/", "self", ".", "std", ")", ",", "axis", "=", "1", ")", "-", "0.5", "*", "np", ".", "log", "(", "2.0", "*", "np", ".", "pi", ")", "*", "tf", ".", "to_float", "(", "tf", ".", "shape", "(", "x", ")", "[", "1", "]", ")", "-", "U", ".", "sum", "(", "self", ".", "logstd", ",", "axis", "=", "1", ")", "\n", "", "def", "kl", "(", "self", ",", "other", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.DiagGaussianPd.kl": [[277, 280], ["isinstance", "maddpg_o.sum", "tensorflow.square", "tensorflow.square", "tensorflow.square"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "kl", "(", "self", ",", "other", ")", ":", "\n", "        ", "assert", "isinstance", "(", "other", ",", "DiagGaussianPd", ")", "\n", "return", "U", ".", "sum", "(", "other", ".", "logstd", "-", "self", ".", "logstd", "+", "(", "tf", ".", "square", "(", "self", ".", "std", ")", "+", "tf", ".", "square", "(", "self", ".", "mean", "-", "other", ".", "mean", ")", ")", "/", "(", "2.0", "*", "tf", ".", "square", "(", "other", ".", "std", ")", ")", "-", "0.5", ",", "axis", "=", "1", ")", "\n", "", "def", "entropy", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.DiagGaussianPd.entropy": [[280, 282], ["maddpg_o.sum", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "entropy", "(", "self", ")", ":", "\n", "        ", "return", "U", ".", "sum", "(", "self", ".", "logstd", "+", ".5", "*", "np", ".", "log", "(", "2.0", "*", "np", ".", "pi", "*", "np", ".", "e", ")", ",", "1", ")", "\n", "", "def", "sample", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.DiagGaussianPd.sample": [[282, 284], ["tensorflow.random_normal", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.multi_discrete.MultiDiscrete.shape"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "mean", "+", "self", ".", "std", "*", "tf", ".", "random_normal", "(", "tf", ".", "shape", "(", "self", ".", "mean", ")", ")", "\n", "", "@", "classmethod", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.DiagGaussianPd.fromflat": [[284, 287], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "fromflat", "(", "cls", ",", "flat", ")", ":", "\n", "        ", "return", "cls", "(", "flat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.__init__": [[289, 292], ["tensorflow.sigmoid"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "logits", ")", ":", "\n", "        ", "self", ".", "logits", "=", "logits", "\n", "self", ".", "ps", "=", "tf", ".", "sigmoid", "(", "logits", ")", "\n", "", "def", "flatparam", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.flatparam": [[292, 294], ["None"], "methods", ["None"], ["", "def", "flatparam", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "logits", "\n", "", "def", "mode", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.mode": [[294, 296], ["tensorflow.round"], "methods", ["None"], ["", "def", "mode", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "round", "(", "self", ".", "ps", ")", "\n", "", "def", "logp", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.logp": [[296, 298], ["maddpg_o.sum", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.to_float"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "logp", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "-", "U", ".", "sum", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "self", ".", "logits", ",", "labels", "=", "tf", ".", "to_float", "(", "x", ")", ")", ",", "axis", "=", "1", ")", "\n", "", "def", "kl", "(", "self", ",", "other", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.kl": [[298, 300], ["maddpg_o.sum", "maddpg_o.sum", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "kl", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "U", ".", "sum", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "other", ".", "logits", ",", "labels", "=", "self", ".", "ps", ")", ",", "axis", "=", "1", ")", "-", "U", ".", "sum", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "self", ".", "logits", ",", "labels", "=", "self", ".", "ps", ")", ",", "axis", "=", "1", ")", "\n", "", "def", "entropy", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.entropy": [[300, 302], ["maddpg_o.sum", "tensorflow.nn.sigmoid_cross_entropy_with_logits"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "entropy", "(", "self", ")", ":", "\n", "        ", "return", "U", ".", "sum", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "self", ".", "logits", ",", "labels", "=", "self", ".", "ps", ")", ",", "axis", "=", "1", ")", "\n", "", "def", "sample", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.sample": [[302, 306], ["tensorflow.sigmoid", "tensorflow.random_uniform", "tensorflow.to_float", "tensorflow.shape", "tensorflow.python.ops.math_ops.less"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.multi_discrete.MultiDiscrete.shape"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "p", "=", "tf", ".", "sigmoid", "(", "self", ".", "logits", ")", "\n", "u", "=", "tf", ".", "random_uniform", "(", "tf", ".", "shape", "(", "p", ")", ")", "\n", "return", "tf", ".", "to_float", "(", "math_ops", ".", "less", "(", "u", ",", "p", ")", ")", "\n", "", "@", "classmethod", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.BernoulliPd.fromflat": [[306, 309], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "fromflat", "(", "cls", ",", "flat", ")", ":", "\n", "        ", "return", "cls", "(", "flat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.make_pdtype": [[310, 325], ["isinstance", "distributions.DiagGaussianPdType", "isinstance", "len", "distributions.SoftCategoricalPdType", "isinstance", "distributions.SoftMultiCategoricalPdType", "isinstance", "distributions.BernoulliPdType"], "function", ["None"], ["", "", "def", "make_pdtype", "(", "ac_space", ")", ":", "\n", "    ", "from", "gym", "import", "spaces", "\n", "if", "isinstance", "(", "ac_space", ",", "spaces", ".", "Box", ")", ":", "\n", "        ", "assert", "len", "(", "ac_space", ".", "shape", ")", "==", "1", "\n", "return", "DiagGaussianPdType", "(", "ac_space", ".", "shape", "[", "0", "]", ")", "\n", "", "elif", "isinstance", "(", "ac_space", ",", "spaces", ".", "Discrete", ")", ":", "\n", "# return CategoricalPdType(ac_space.n)", "\n", "        ", "return", "SoftCategoricalPdType", "(", "ac_space", ".", "n", ")", "\n", "", "elif", "isinstance", "(", "ac_space", ",", "MultiDiscrete", ")", ":", "\n", "#return MultiCategoricalPdType(ac_space.low, ac_space.high)", "\n", "        ", "return", "SoftMultiCategoricalPdType", "(", "ac_space", ".", "low", ",", "ac_space", ".", "high", ")", "\n", "", "elif", "isinstance", "(", "ac_space", ",", "spaces", ".", "MultiBinary", ")", ":", "\n", "        ", "return", "BernoulliPdType", "(", "ac_space", ".", "n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.distributions.shape_el": [[326, 332], ["v.get_shape", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.multi_discrete.MultiDiscrete.shape"], ["", "", "def", "shape_el", "(", "v", ",", "i", ")", ":", "\n", "    ", "maybe", "=", "v", ".", "get_shape", "(", ")", "[", "i", "]", "\n", "if", "maybe", "is", "not", "None", ":", "\n", "        ", "return", "maybe", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "shape", "(", "v", ")", "[", "i", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.TfInput.__init__": [[40, 46], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "\"(unnamed)\"", ")", ":", "\n", "        ", "\"\"\"Generalized Tensorflow placeholder. The main differences are:\n            - possibly uses multiple placeholders internally and returns multiple values\n            - can apply light postprocessing to the value feed to placeholder.\n        \"\"\"", "\n", "self", ".", "name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.TfInput.get": [[47, 52], ["NotImplemented"], "methods", ["None"], ["", "def", "get", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the tf variable(s) representing the possibly postprocessed value\n        of placeholder(s).\n        \"\"\"", "\n", "raise", "NotImplemented", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.TfInput.make_feed_dict": [[53, 56], ["NotImplemented"], "methods", ["None"], ["", "def", "make_feed_dict", "(", "data", ")", ":", "\n", "        ", "\"\"\"Given data input it to the placeholder(s).\"\"\"", "\n", "raise", "NotImplemented", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.PlacholderTfInput.__init__": [[59, 63], ["tf_util.TfInput.__init__"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "placeholder", ")", ":", "\n", "        ", "\"\"\"Wrapper for regular tensorflow placeholder.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "placeholder", ".", "name", ")", "\n", "self", ".", "_placeholder", "=", "placeholder", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.PlacholderTfInput.get": [[64, 66], ["None"], "methods", ["None"], ["", "def", "get", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_placeholder", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.PlacholderTfInput.make_feed_dict": [[67, 69], ["None"], "methods", ["None"], ["", "def", "make_feed_dict", "(", "self", ",", "data", ")", ":", "\n", "        ", "return", "{", "self", ".", "_placeholder", ":", "data", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.BatchInput.__init__": [[72, 85], ["tf_util.PlacholderTfInput.__init__", "tensorflow.placeholder", "list"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "shape", ",", "dtype", "=", "tf", ".", "float32", ",", "name", "=", "None", ")", ":", "\n", "        ", "\"\"\"Creates a placeholder for a batch of tensors of a given shape and dtype\n\n        Parameters\n        ----------\n        shape: [int]\n            shape of a single elemenet of the batch\n        dtype: tf.dtype\n            number representation used for tensor contents\n        name: str\n            name of the underlying placeholder\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "tf", ".", "placeholder", "(", "dtype", ",", "[", "None", "]", "+", "list", "(", "shape", ")", ",", "name", "=", "name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.Uint8Input.__init__": [[88, 105], ["tf_util.PlacholderTfInput.__init__", "tensorflow.placeholder", "tensorflow.cast", "tf_util.PlacholderTfInput.get", "list"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.Uint8Input.get"], ["    ", "def", "__init__", "(", "self", ",", "shape", ",", "name", "=", "None", ")", ":", "\n", "        ", "\"\"\"Takes input in uint8 format which is cast to float32 and divided by 255\n        before passing it to the model.\n\n        On GPU this ensures lower data transfer times.\n\n        Parameters\n        ----------\n        shape: [int]\n            shape of the tensor.\n        name: str\n            name of the underlying placeholder\n        \"\"\"", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "tf", ".", "placeholder", "(", "tf", ".", "uint8", ",", "[", "None", "]", "+", "list", "(", "shape", ")", ",", "name", "=", "name", ")", ")", "\n", "self", ".", "_shape", "=", "shape", "\n", "self", ".", "_output", "=", "tf", ".", "cast", "(", "super", "(", ")", ".", "get", "(", ")", ",", "tf", ".", "float32", ")", "/", "255.0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.Uint8Input.get": [[106, 108], ["None"], "methods", ["None"], ["", "def", "get", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_output", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util._Function.__init__": [[336, 347], ["tensorflow.group", "tf_util.get_session", "list", "issubclass", "type", "len"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.get_session"], ["    ", "def", "__init__", "(", "self", ",", "inputs", ",", "outputs", ",", "updates", ",", "givens", ",", "check_nan", "=", "False", ")", ":", "\n", "        ", "for", "inpt", "in", "inputs", ":", "\n", "            ", "if", "not", "issubclass", "(", "type", "(", "inpt", ")", ",", "TfInput", ")", ":", "\n", "                ", "assert", "len", "(", "inpt", ".", "op", ".", "inputs", ")", "==", "0", ",", "\"inputs should all be placeholders of rl_algs.common.TfInput\"", "\n", "", "", "self", ".", "inputs", "=", "inputs", "\n", "updates", "=", "updates", "or", "[", "]", "\n", "self", ".", "update_group", "=", "tf", ".", "group", "(", "*", "updates", ")", "\n", "self", ".", "outputs_update", "=", "list", "(", "outputs", ")", "+", "[", "self", ".", "update_group", "]", "\n", "self", ".", "givens", "=", "{", "}", "if", "givens", "is", "None", "else", "givens", "\n", "self", ".", "check_nan", "=", "check_nan", "\n", "self", ".", "sess", "=", "get_session", "(", ")", "\n", "# print(self.sess)", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util._Function._feed_input": [[349, 354], ["issubclass", "type", "feed_dict.update", "tf_util.is_placeholder", "inpt.make_feed_dict"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.update", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.is_placeholder", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.PlacholderTfInput.make_feed_dict"], ["", "def", "_feed_input", "(", "self", ",", "feed_dict", ",", "inpt", ",", "value", ")", ":", "\n", "        ", "if", "issubclass", "(", "type", "(", "inpt", ")", ",", "TfInput", ")", ":", "\n", "            ", "feed_dict", ".", "update", "(", "inpt", ".", "make_feed_dict", "(", "value", ")", ")", "\n", "", "elif", "is_placeholder", "(", "inpt", ")", ":", "\n", "            ", "feed_dict", "[", "inpt", "]", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util._Function.__call__": [[355, 386], ["zip", "set", "len", "len", "tf_util._Function._feed_input", "len", "str", "feed_dict.get", "tf_util._Function.sess.run", "any", "len", "inpt.name.split", "inpt_name.split", "set.add", "tf_util._Function._feed_input", "list", "RuntimeError", "kwargs.pop", "kwargs.keys", "numpy.isnan().any", "numpy.isnan"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util._Function._feed_input", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.Uint8Input.get", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.add", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util._Function._feed_input"], ["", "", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# return 0", "\n", "        ", "assert", "len", "(", "args", ")", "<=", "len", "(", "self", ".", "inputs", ")", ",", "\"Too many arguments provided\"", "\n", "feed_dict", "=", "{", "}", "\n", "# Update the args", "\n", "for", "inpt", ",", "value", "in", "zip", "(", "self", ".", "inputs", ",", "args", ")", ":", "\n", "            ", "self", ".", "_feed_input", "(", "feed_dict", ",", "inpt", ",", "value", ")", "\n", "# Update the kwargs", "\n", "", "kwargs_passed_inpt_names", "=", "set", "(", ")", "\n", "for", "inpt", "in", "self", ".", "inputs", "[", "len", "(", "args", ")", ":", "]", ":", "\n", "            ", "inpt_name", "=", "inpt", ".", "name", ".", "split", "(", "':'", ")", "[", "0", "]", "\n", "inpt_name", "=", "inpt_name", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "\n", "assert", "inpt_name", "not", "in", "kwargs_passed_inpt_names", ",", "\"this function has two arguments with the same name \\\"{}\\\", so kwargs cannot be used.\"", ".", "format", "(", "inpt_name", ")", "\n", "if", "inpt_name", "in", "kwargs", ":", "\n", "                ", "kwargs_passed_inpt_names", ".", "add", "(", "inpt_name", ")", "\n", "self", ".", "_feed_input", "(", "feed_dict", ",", "inpt", ",", "kwargs", ".", "pop", "(", "inpt_name", ")", ")", "\n", "", "else", ":", "\n", "                ", "assert", "inpt", "in", "self", ".", "givens", ",", "\"Missing argument \"", "+", "inpt_name", "\n", "", "", "assert", "len", "(", "kwargs", ")", "==", "0", ",", "\"Function got extra arguments \"", "+", "str", "(", "list", "(", "kwargs", ".", "keys", "(", ")", ")", ")", "\n", "# Update feed dict with givens.", "\n", "for", "inpt", "in", "self", ".", "givens", ":", "\n", "            ", "feed_dict", "[", "inpt", "]", "=", "feed_dict", ".", "get", "(", "inpt", ",", "self", ".", "givens", "[", "inpt", "]", ")", "\n", "# print(\"AA\", self.sess, self.sess.graph, self.outputs_update)", "\n", "", "results", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "outputs_update", ",", "feed_dict", "=", "feed_dict", ")", "[", ":", "-", "1", "]", "\n", "# print(\"BB\")", "\n", "# results = []", "\n", "if", "self", ".", "check_nan", ":", "\n", "            ", "if", "any", "(", "np", ".", "isnan", "(", "r", ")", ".", "any", "(", ")", "for", "r", "in", "results", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"Nan detected\"", ")", "\n", "", "", "return", "results", "", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum": [[6, 8], ["tensorflow.reduce_sum"], "function", ["None"], ["def", "sum", "(", "x", ",", "axis", "=", "None", ",", "keepdims", "=", "False", ")", ":", "\n", "    ", "return", "tf", ".", "reduce_sum", "(", "x", ",", "axis", "=", "None", "if", "axis", "is", "None", "else", "[", "axis", "]", ",", "keep_dims", "=", "keepdims", ")", "\n", "", "def", "mean", "(", "x", ",", "axis", "=", "None", ",", "keepdims", "=", "False", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean": [[8, 10], ["tensorflow.reduce_mean"], "function", ["None"], ["", "def", "mean", "(", "x", ",", "axis", "=", "None", ",", "keepdims", "=", "False", ")", ":", "\n", "    ", "return", "tf", ".", "reduce_mean", "(", "x", ",", "axis", "=", "None", "if", "axis", "is", "None", "else", "[", "axis", "]", ",", "keep_dims", "=", "keepdims", ")", "\n", "", "def", "var", "(", "x", ",", "axis", "=", "None", ",", "keepdims", "=", "False", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.var": [[10, 13], ["tf_util.mean", "tf_util.mean", "tensorflow.square"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean"], ["", "def", "var", "(", "x", ",", "axis", "=", "None", ",", "keepdims", "=", "False", ")", ":", "\n", "    ", "meanx", "=", "mean", "(", "x", ",", "axis", "=", "axis", ",", "keepdims", "=", "keepdims", ")", "\n", "return", "mean", "(", "tf", ".", "square", "(", "x", "-", "meanx", ")", ",", "axis", "=", "axis", ",", "keepdims", "=", "keepdims", ")", "\n", "", "def", "std", "(", "x", ",", "axis", "=", "None", ",", "keepdims", "=", "False", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.std": [[13, 15], ["tensorflow.sqrt", "tf_util.var"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.var"], ["", "def", "std", "(", "x", ",", "axis", "=", "None", ",", "keepdims", "=", "False", ")", ":", "\n", "    ", "return", "tf", ".", "sqrt", "(", "var", "(", "x", ",", "axis", "=", "axis", ",", "keepdims", "=", "keepdims", ")", ")", "\n", "", "def", "max", "(", "x", ",", "axis", "=", "None", ",", "keepdims", "=", "False", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.max": [[15, 17], ["tensorflow.reduce_max"], "function", ["None"], ["", "def", "max", "(", "x", ",", "axis", "=", "None", ",", "keepdims", "=", "False", ")", ":", "\n", "    ", "return", "tf", ".", "reduce_max", "(", "x", ",", "axis", "=", "None", "if", "axis", "is", "None", "else", "[", "axis", "]", ",", "keep_dims", "=", "keepdims", ")", "\n", "", "def", "min", "(", "x", ",", "axis", "=", "None", ",", "keepdims", "=", "False", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.min": [[17, 19], ["tensorflow.reduce_min"], "function", ["None"], ["", "def", "min", "(", "x", ",", "axis", "=", "None", ",", "keepdims", "=", "False", ")", ":", "\n", "    ", "return", "tf", ".", "reduce_min", "(", "x", ",", "axis", "=", "None", "if", "axis", "is", "None", "else", "[", "axis", "]", ",", "keep_dims", "=", "keepdims", ")", "\n", "", "def", "concatenate", "(", "arrs", ",", "axis", "=", "0", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.concatenate": [[19, 21], ["tensorflow.concat"], "function", ["None"], ["", "def", "concatenate", "(", "arrs", ",", "axis", "=", "0", ")", ":", "\n", "    ", "return", "tf", ".", "concat", "(", "axis", "=", "axis", ",", "values", "=", "arrs", ")", "\n", "", "def", "argmax", "(", "x", ",", "axis", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.argmax": [[21, 23], ["tensorflow.argmax"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.argmax"], ["", "def", "argmax", "(", "x", ",", "axis", "=", "None", ")", ":", "\n", "    ", "return", "tf", ".", "argmax", "(", "x", ",", "axis", "=", "axis", ")", "\n", "", "def", "softmax", "(", "x", ",", "axis", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.softmax": [[23, 25], ["tensorflow.nn.softmax"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.softmax"], ["", "def", "softmax", "(", "x", ",", "axis", "=", "None", ")", ":", "\n", "    ", "return", "tf", ".", "nn", ".", "softmax", "(", "x", ",", "axis", "=", "axis", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.is_placeholder": [[31, 33], ["type", "len"], "function", ["None"], ["", "def", "is_placeholder", "(", "x", ")", ":", "\n", "    ", "return", "type", "(", "x", ")", "is", "tf", ".", "Tensor", "and", "len", "(", "x", ".", "op", ".", "inputs", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.ensure_tf_input": [[110, 118], ["isinstance", "tf_util.is_placeholder", "tf_util.PlacholderTfInput", "ValueError"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.is_placeholder"], ["", "", "def", "ensure_tf_input", "(", "thing", ")", ":", "\n", "    ", "\"\"\"Takes either tf.placeholder of TfInput and outputs equivalent TfInput\"\"\"", "\n", "if", "isinstance", "(", "thing", ",", "TfInput", ")", ":", "\n", "        ", "return", "thing", "\n", "", "elif", "is_placeholder", "(", "thing", ")", ":", "\n", "        ", "return", "PlacholderTfInput", "(", "thing", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Must be a placeholder or TfInput\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.huber_loss": [[124, 130], ["tensorflow.where", "tensorflow.abs", "tensorflow.square", "tensorflow.abs"], "function", ["None"], ["", "", "def", "huber_loss", "(", "x", ",", "delta", "=", "1.0", ")", ":", "\n", "    ", "\"\"\"Reference: https://en.wikipedia.org/wiki/Huber_loss\"\"\"", "\n", "return", "tf", ".", "where", "(", "\n", "tf", ".", "abs", "(", "x", ")", "<", "delta", ",", "\n", "tf", ".", "square", "(", "x", ")", "*", "0.5", ",", "\n", "delta", "*", "(", "tf", ".", "abs", "(", "x", ")", "-", "0.5", "*", "delta", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.minimize_and_clip": [[137, 150], ["optimizer.minimize", "optimizer.compute_gradients", "enumerate", "optimizer.apply_gradients", "tensorflow.clip_by_norm"], "function", ["None"], ["", "def", "minimize_and_clip", "(", "optimizer", ",", "objective", ",", "var_list", ",", "clip_val", "=", "10", ")", ":", "\n", "    ", "\"\"\"Minimized `objective` using `optimizer` w.r.t. variables in\n    `var_list` while ensure the norm of the gradients for each\n    variable is clipped to `clip_val`\n    \"\"\"", "\n", "if", "clip_val", "is", "None", ":", "\n", "        ", "return", "optimizer", ".", "minimize", "(", "objective", ",", "var_list", "=", "var_list", ")", "\n", "", "else", ":", "\n", "        ", "gradients", "=", "optimizer", ".", "compute_gradients", "(", "objective", ",", "var_list", "=", "var_list", ")", "\n", "for", "i", ",", "(", "grad", ",", "var", ")", "in", "enumerate", "(", "gradients", ")", ":", "\n", "            ", "if", "grad", "is", "not", "None", ":", "\n", "                ", "gradients", "[", "i", "]", "=", "(", "tf", ".", "clip_by_norm", "(", "grad", ",", "clip_val", ")", ",", "var", ")", "\n", "", "", "return", "optimizer", ".", "apply_gradients", "(", "gradients", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.get_session": [[158, 161], ["tensorflow.get_default_session"], "function", ["None"], ["def", "get_session", "(", ")", ":", "\n", "    ", "\"\"\"Returns recently made Tensorflow session\"\"\"", "\n", "return", "SESS", "or", "tf", ".", "get_default_session", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.make_session": [[163, 171], ["tensorflow.ConfigProto", "tensorflow.Session"], "function", ["None"], ["", "def", "make_session", "(", "num_cpu", ")", ":", "\n", "    ", "\"\"\"Returns a session that will use <num_cpu> CPU's only\"\"\"", "\n", "# print(\"num_cpu:\", num_cpu)", "\n", "tf_config", "=", "tf", ".", "ConfigProto", "(", "\n", "device_count", "=", "{", "\"CPU\"", ":", "1", "}", ",", "\n", "inter_op_parallelism_threads", "=", "num_cpu", ",", "\n", "intra_op_parallelism_threads", "=", "num_cpu", ")", "\n", "return", "tf", ".", "Session", "(", "config", "=", "tf_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.set_session": [[173, 176], ["None"], "function", ["None"], ["", "def", "set_session", "(", "sess", ")", ":", "\n", "    ", "global", "SESS", "\n", "SESS", "=", "sess", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.single_threaded_session": [[178, 181], ["tf_util.make_session"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.make_session"], ["", "def", "single_threaded_session", "(", ")", ":", "\n", "    ", "\"\"\"Returns a session which will only use a single CPU\"\"\"", "\n", "return", "make_session", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.initialize": [[186, 191], ["get_session().run", "ALREADY_INITIALIZED.update", "set", "tensorflow.variables_initializer", "tensorflow.global_variables", "tf_util.get_session"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.update", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.get_session"], ["def", "initialize", "(", ")", ":", "\n", "    ", "\"\"\"Initialize all the uninitialized variables in the global scope.\"\"\"", "\n", "new_variables", "=", "set", "(", "tf", ".", "global_variables", "(", ")", ")", "-", "ALREADY_INITIALIZED", "\n", "get_session", "(", ")", ".", "run", "(", "tf", ".", "variables_initializer", "(", "new_variables", ")", ")", "\n", "ALREADY_INITIALIZED", ".", "update", "(", "new_variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars": [[198, 218], ["tensorflow.get_collection", "isinstance"], "function", ["None"], ["", "def", "scope_vars", "(", "scope", ",", "trainable_only", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Get variables inside a scope\n    The scope can be specified as a string\n\n    Parameters\n    ----------\n    scope: str or VariableScope\n        scope in which the variables reside.\n    trainable_only: bool\n        whether or not to return only the variables that were marked as trainable.\n\n    Returns\n    -------\n    vars: [tf.Variable]\n        list of variables in `scope`.\n    \"\"\"", "\n", "return", "tf", ".", "get_collection", "(", "\n", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", "if", "trainable_only", "else", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "\n", "scope", "=", "scope", "if", "isinstance", "(", "scope", ",", "str", ")", "else", "scope", ".", "name", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_name": [[221, 224], ["tensorflow.get_variable_scope"], "function", ["None"], ["", "def", "scope_name", "(", ")", ":", "\n", "    ", "\"\"\"Returns the name of current scope as a string, e.g. deepq/q_func\"\"\"", "\n", "return", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.absolute_scope_name": [[226, 229], ["tf_util.scope_name"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_name"], ["", "def", "absolute_scope_name", "(", "relative_scope_name", ")", ":", "\n", "    ", "\"\"\"Appends parent scope name to `relative_scope_name`\"\"\"", "\n", "return", "scope_name", "(", ")", "+", "\"/\"", "+", "relative_scope_name", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.load_state": [[235, 241], ["tf.train.Saver.restore", "tensorflow.train.Saver", "tf_util.get_session"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.get_session"], ["", "def", "load_state", "(", "fname", ",", "saver", "=", "None", ")", ":", "\n", "    ", "\"\"\"Load all the variables to the current session from the location <fname>\"\"\"", "\n", "if", "saver", "is", "None", ":", "\n", "        ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "", "saver", ".", "restore", "(", "get_session", "(", ")", ",", "fname", "+", "\"model.ckpt\"", ")", "\n", "return", "saver", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.load_params_from": [[242, 248], ["tf_util.scope_vars", "tensorflow.train.Saver", "tf.train.Saver.restore", "tf_util.get_session", "os.path.join"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.scope_vars", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.get_session"], ["", "def", "load_params_from", "(", "fname", ",", "scope", ")", ":", "\n", "    ", "import", "os", "\n", "vars", "=", "scope_vars", "(", "scope", ")", "\n", "# vars_dict = {var.name.split(\":\")[0]: var for var in vars}", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "vars", ")", "\n", "saver", ".", "restore", "(", "get_session", "(", ")", ",", "os", ".", "path", ".", "join", "(", "fname", ",", "\"model.ckpt\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.save_state": [[250, 258], ["os.makedirs", "tf.train.Saver.save", "os.path.dirname", "tensorflow.train.Saver", "tf_util.get_session"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.save", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.get_session"], ["", "def", "save_state", "(", "fname", ",", "saver", "=", "None", ")", ":", "\n", "    ", "\"\"\"Save all the variables in the current session to the location <fname>\"\"\"", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "fname", ")", ",", "exist_ok", "=", "True", ")", "\n", "# print('shabi')", "\n", "if", "saver", "is", "None", ":", "\n", "        ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "", "saver", ".", "save", "(", "get_session", "(", ")", ",", "fname", "+", "\"model.ckpt\"", ",", "meta_graph_suffix", "=", "'meta'", ",", "write_meta_graph", "=", "True", ",", "write_state", "=", "True", ")", "\n", "return", "saver", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.save_variables": [[259, 270], ["sess.run", "os.path.dirname", "any", "joblib.dump", "tf_util.get_session", "tensorflow.get_collection", "os.makedirs", "zip"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.get_session"], ["", "def", "save_variables", "(", "save_path", ",", "variables", "=", "None", ",", "sess", "=", "None", ")", ":", "\n", "    ", "import", "joblib", "\n", "sess", "=", "sess", "or", "get_session", "(", ")", "\n", "variables", "=", "variables", "or", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ")", "\n", "\n", "ps", "=", "sess", ".", "run", "(", "variables", ")", "\n", "save_dict", "=", "{", "v", ".", "name", ":", "value", "for", "v", ",", "value", "in", "zip", "(", "variables", ",", "ps", ")", "}", "\n", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "save_path", ")", "\n", "if", "any", "(", "dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirname", ",", "exist_ok", "=", "True", ")", "\n", "", "joblib", ".", "dump", "(", "save_dict", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.load_variables": [[271, 287], ["joblib.load", "isinstance", "sess.run", "tf_util.get_session", "tensorflow.get_collection", "os.path.expanduser", "zip", "len", "len", "restores.append", "restores.append", "v.assign", "v.assign"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.load", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.get_session"], ["", "def", "load_variables", "(", "load_path", ",", "variables", "=", "None", ",", "sess", "=", "None", ")", ":", "\n", "    ", "import", "joblib", "\n", "sess", "=", "sess", "or", "get_session", "(", ")", "\n", "variables", "=", "variables", "or", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ")", "\n", "\n", "loaded_params", "=", "joblib", ".", "load", "(", "os", ".", "path", ".", "expanduser", "(", "load_path", ")", ")", "\n", "restores", "=", "[", "]", "\n", "if", "isinstance", "(", "loaded_params", ",", "list", ")", ":", "\n", "        ", "assert", "len", "(", "loaded_params", ")", "==", "len", "(", "variables", ")", ",", "'number of variables loaded mismatches len(variables)'", "\n", "for", "d", ",", "v", "in", "zip", "(", "loaded_params", ",", "variables", ")", ":", "\n", "            ", "restores", ".", "append", "(", "v", ".", "assign", "(", "d", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "for", "v", "in", "variables", ":", "\n", "            ", "restores", ".", "append", "(", "v", ".", "assign", "(", "loaded_params", "[", "v", ".", "name", "]", ")", ")", "\n", "\n", "", "", "sess", ".", "run", "(", "restores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.function": [[293, 333], ["isinstance", "tf_util._Function", "isinstance", "tf_util._Function", "tf_util._Function", "outputs.values", "type", "zip", "_Function.", "outputs.keys", "_Function."], "function", ["None"], ["", "def", "function", "(", "inputs", ",", "outputs", ",", "updates", "=", "None", ",", "givens", "=", "None", ")", ":", "\n", "    ", "\"\"\"Just like Theano function. Take a bunch of tensorflow placeholders and expersions\n    computed based on those placeholders and produces f(inputs) -> outputs. Function f takes\n    values to be feed to the inputs placeholders and produces the values of the experessions\n    in outputs.\n\n    Input values can be passed in the same order as inputs or can be provided as kwargs based\n    on placeholder name (passed to constructor or accessible via placeholder.op.name).\n\n    Example:\n        x = tf.placeholder(tf.int32, (), name=\"x\")\n        y = tf.placeholder(tf.int32, (), name=\"y\")\n        z = 3 * x + 2 * y\n        lin = function([x, y], z, givens={y: 0})\n\n        with single_threaded_session():\n            initialize()\n\n            assert lin(2) == 6\n            assert lin(x=3) == 9\n            assert lin(2, 2) == 10\n            assert lin(x=2, y=3) == 12\n\n    Parameters\n    ----------\n    inputs: [tf.placeholder or TfInput]\n        list of input arguments\n    outputs: [tf.Variable] or tf.Variable\n        list of outputs or a single output to be returned from function. Returned\n        value will also have the same shape.\n    \"\"\"", "\n", "# return None", "\n", "if", "isinstance", "(", "outputs", ",", "list", ")", ":", "\n", "        ", "return", "_Function", "(", "inputs", ",", "outputs", ",", "updates", ",", "givens", "=", "givens", ")", "\n", "", "elif", "isinstance", "(", "outputs", ",", "(", "dict", ",", "collections", ".", "OrderedDict", ")", ")", ":", "\n", "        ", "f", "=", "_Function", "(", "inputs", ",", "outputs", ".", "values", "(", ")", ",", "updates", ",", "givens", "=", "givens", ")", "\n", "return", "lambda", "*", "args", ",", "**", "kwargs", ":", "type", "(", "outputs", ")", "(", "zip", "(", "outputs", ".", "keys", "(", ")", ",", "f", "(", "*", "args", ",", "**", "kwargs", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "f", "=", "_Function", "(", "inputs", ",", "[", "outputs", "]", ",", "updates", ",", "givens", "=", "givens", ")", "\n", "return", "lambda", "*", "args", ",", "**", "kwargs", ":", "f", "(", "*", "args", ",", "**", "kwargs", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_epc_select.show_group_statistics": [[9, 15], ["numpy.sum", "print", "print", "numpy.mean", "numpy.var", "numpy.mean", "numpy.var"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.var", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.var"], ["def", "show_group_statistics", "(", "rewards", ",", "category", ")", ":", "\n", "    ", "sum_rewards", "=", "np", ".", "sum", "(", "rewards", ",", "axis", "=", "0", ")", "\n", "print", "(", "\"mean:\"", ",", "np", ".", "mean", "(", "sum_rewards", ")", ")", "\n", "print", "(", "\"var:\"", ",", "np", ".", "var", "(", "sum_rewards", ")", ")", "\n", "\n", "return", "np", ".", "mean", "(", "sum_rewards", ")", ",", "np", ".", "var", "(", "sum_rewards", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_epc_select.add_extra_flags": [[16, 39], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["", "def", "add_extra_flags", "(", "parser", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "\"Reinforcement Learning experiments for multiagent environments\"", ")", "\n", "# Environment", "\n", "parser", ".", "add_argument", "(", "\"--scenario\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"grassland\"", ",", "\n", "help", "=", "\"name of the scenario script\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-adversaries\"", ",", "type", "=", "int", ",", "\n", "default", "=", "2", ",", "help", "=", "\"number of adversaries\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-good\"", ",", "type", "=", "int", ",", "\n", "default", "=", "2", ",", "help", "=", "\"number of good\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-selection\"", ",", "type", "=", "int", ",", "\n", "default", "=", "2", ",", "help", "=", "\"number of selection\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-agents\"", ",", "type", "=", "int", ",", "\n", "default", "=", "2", ",", "help", "=", "\"number of good\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"./test/\"", ",", "\n", "help", "=", "\"directory in which training state and model should be saved\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-load-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"./test/\"", ",", "\n", "help", "=", "\"directory in which training state and model are loaded\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-load-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"./test/\"", ",", "\n", "help", "=", "\"directory in which training state and model are loaded\"", ")", "\n", "parser", ".", "add_argument", "(", "'--dir-ids'", ",", "type", "=", "int", ",", "nargs", "=", "\"+\"", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_epc_select.compete": [[40, 75], ["len", "numpy.zeros", "range", "numpy.average", "[].tolist", "print", "json.dump", "print", "results.append", "print", "train_epc_select.show_group_statistics", "open", "open", "json.load", "os.path.join", "np.average.argsort"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_epc_select.show_group_statistics", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.load"], ["", "def", "compete", "(", "arglist", ")", ":", "\n", "    ", "import", "copy", "\n", "dir_ids", "=", "arglist", ".", "dir_ids", "\n", "n_competitors", "=", "len", "(", "dir_ids", ")", "\n", "n_good", "=", "arglist", ".", "num_good", "\n", "n_adv", "=", "arglist", ".", "num_adversaries", "\n", "n", "=", "n_good", "+", "n_adv", "\n", "k", "=", "arglist", ".", "num_selection", "\n", "results", "=", "[", "]", "\n", "for", "id", "in", "dir_ids", ":", "\n", "        ", "print", "(", "'learning id %d'", "%", "id", ")", "\n", "load_dir", "=", "arglist", ".", "good_load_dir", "+", "'_%d/'", "%", "id", "+", "'report.json'", "\n", "with", "open", "(", "load_dir", ")", "as", "f", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "f", ")", "\n", "", "results", ".", "append", "(", "data", ")", "\n", "\n", "", "good_scores", "=", "np", ".", "zeros", "(", "(", "n_competitors", ",", "1", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_competitors", ")", ":", "\n", "        ", "result", "=", "results", "[", "i", "]", "\n", "agent_rewards", "=", "result", "[", "\"agent_rewards\"", "]", "\n", "print", "(", "\"\\n\\n-- Good agents from directory {}\"", ".", "format", "(", "i", ")", ")", "\n", "good_score", ",", "good_var", "=", "show_group_statistics", "(", "agent_rewards", "[", "n_adv", ":", "]", ",", "\"rewards\"", ")", "\n", "good_scores", "[", "i", "]", "[", "0", "]", "=", "good_score", "\n", "\n", "", "avg_good_scores", "=", "np", ".", "average", "(", "good_scores", ",", "axis", "=", "-", "1", ")", "\n", "\n", "top_indices", "=", "avg_good_scores", ".", "argsort", "(", ")", "[", "-", "k", ":", "]", "[", ":", ":", "-", "1", "]", ".", "tolist", "(", ")", "\n", "print", "(", "'top_indices'", ",", "top_indices", ")", "\n", "selection_summary", "=", "{", "\"scenario\"", ":", "arglist", ".", "scenario", ",", "\n", "\"num agents\"", ":", "n", ",", "\n", "\"weights directory\"", ":", "arglist", ".", "good_load_dir", ",", "\n", "\"top K ids\"", ":", "top_indices", "}", "\n", "json", ".", "dump", "(", "selection_summary", ",", "open", "(", "os", ".", "path", ".", "join", "(", "arglist", ".", "save_dir", ",", "\"selection_summary.json\"", ")", ",", "\"w\"", ")", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_normal.parse_args": [[17, 60], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\"Reinforcement Learning experiments for multiagent environments\"", ")", "\n", "# Environment", "\n", "parser", ".", "add_argument", "(", "\"--scenario\"", ",", "type", "=", "str", ",", "default", "=", "\"simple\"", ",", "help", "=", "\"name of the scenario script\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max-episode-len\"", ",", "type", "=", "int", ",", "default", "=", "25", ",", "help", "=", "\"maximum episode length\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-episodes\"", ",", "type", "=", "int", ",", "default", "=", "20000", ",", "help", "=", "\"number of episodes\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train-period\"", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "\"frequency of updating parameters\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train\"", ",", "type", "=", "int", ",", "default", "=", "2000", ",", "help", "=", "\"number of train\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-adversaries\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"number of adversaries\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-policy\"", ",", "type", "=", "str", ",", "default", "=", "\"maddpg\"", ",", "help", "=", "\"policy for good agents\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-policy\"", ",", "type", "=", "str", ",", "default", "=", "\"maddpg\"", ",", "help", "=", "\"policy of adversaries\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max-num-train\"", ",", "type", "=", "int", ",", "default", "=", "2000", ",", "help", "=", "\"number of train\"", ")", "\n", "# Core training parameters", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "type", "=", "float", ",", "default", "=", "1e-2", ",", "help", "=", "\"learning rate for Adam optimizer\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gamma\"", ",", "type", "=", "float", ",", "default", "=", "0.95", ",", "help", "=", "\"discount factor\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch-size\"", ",", "type", "=", "int", ",", "default", "=", "1024", ",", "help", "=", "\"number of episodes to optimize at the same time\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-units\"", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "\"number of units in the mlp\"", ")", "\n", "# Checkpointing", "\n", "parser", ".", "add_argument", "(", "\"--save-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"../trained_policy/\"", ",", "help", "=", "\"directory in which training state and model should be saved\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save-rate\"", ",", "type", "=", "int", ",", "default", "=", "20", ",", "help", "=", "\"save model once every time this number of train are completed\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train-rate\"", ",", "type", "=", "int", ",", "default", "=", "20", ",", "help", "=", "\"train model once every time this many episodes are completed\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-load-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"directory in which training state and model are loaded\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-load-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"directory in which training state and model are loaded\"", ")", "\n", "# Evaluation", "\n", "parser", ".", "add_argument", "(", "\"--restore\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--display\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--plots-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"../learning_curves/\"", ",", "help", "=", "\"directory where plot data is saved\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-good\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"num good\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-landmarks\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"num landmarks\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-agents\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"num agents\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-food\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"num food\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-forests\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"num foresets\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--prosp-dist\"", ",", "type", "=", "float", ",", "default", "=", "\"0.6\"", ",", "help", "=", "\"prospective neighbor distance\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-sight\"", ",", "type", "=", "float", ",", "default", "=", "\"1\"", ",", "help", "=", "\"neighbor distance\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-sight\"", ",", "type", "=", "float", ",", "default", "=", "\"1\"", ",", "help", "=", "\"neighbor distance\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--ratio\"", ",", "type", "=", "float", ",", "default", "=", "\"1\"", ",", "help", "=", "\"neighbor distance\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no-wheel\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--benchmark\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-max-num-neighbors\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"maximum number of  agents in neighbors area\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-max-num-neighbors\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"maximum number of  agents in neighbors area\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "\"1\"", ",", "help", "=", "\"seed for random number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--load-one-side\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_normal.make_env": [[61, 72], ["scenario_class", "scenario_class.make_world", "MultiAgentEnv", "importlib.import_module"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.make_world"], ["", "def", "make_env", "(", "scenario_name", ",", "arglist", ",", "evaluate", "=", "False", ")", ":", "###################", "\n", "    ", "import", "importlib", "\n", "from", "mpe_local", ".", "multiagent", ".", "environment", "import", "MultiAgentEnv", "\n", "module_name", "=", "\"mpe_local.multiagent.scenarios.{}\"", ".", "format", "(", "scenario_name", ")", "\n", "scenario_class", "=", "importlib", ".", "import_module", "(", "module_name", ")", ".", "Scenario", "\n", "scenario", "=", "scenario_class", "(", "n_good", "=", "arglist", ".", "num_agents", "-", "arglist", ".", "num_adversaries", ",", "n_adv", "=", "arglist", ".", "num_adversaries", ",", "n_landmarks", "=", "arglist", ".", "num_landmarks", ",", "n_food", "=", "arglist", ".", "num_food", ",", "n_forests", "=", "arglist", ".", "num_forests", ",", "\n", "no_wheel", "=", "arglist", ".", "no_wheel", ",", "good_sight", "=", "arglist", ".", "good_sight", ",", "adv_sight", "=", "arglist", ".", "adv_sight", ",", "alpha", "=", "0", ",", "ratio", "=", "arglist", ".", "ratio", ",", "max_good_neighbor", "=", "arglist", ".", "good_max_num_neighbors", ",", "max_adv_neighbor", "=", "arglist", ".", "adv_max_num_neighbors", ")", "\n", "world", "=", "scenario", ".", "make_world", "(", ")", "\n", "# create multiagent environment", "\n", "env", "=", "MultiAgentEnv", "(", "world", ",", "scenario", ".", "reset_world", ",", "scenario", ".", "reward", ",", "scenario", ".", "observation", ")", "\n", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_normal.get_trainer": [[73, 88], ["trainer", "functools.partial"], "function", ["None"], ["", "def", "get_trainer", "(", "side", ",", "i", ",", "scope", ",", "env", ",", "obs_shape_n", ",", "sess", ")", ":", "\n", "    ", "trainer", "=", "MADDPGAgentTrainer", "\n", "policy", "=", "arglist", ".", "adv_policy", "if", "side", "==", "\"adv\"", "else", "arglist", ".", "good_policy", "\n", "if", "policy", "==", "\"maddpg\"", ":", "\n", "        ", "model_p", "=", "mlp_model", "\n", "model_q", "=", "mlp_model", "\n", "", "elif", "policy", "==", "\"mean_field\"", ":", "\n", "        ", "model_p", "=", "mlp_model", "\n", "model_q", "=", "partial", "(", "mean_field_adv_q_model", "if", "side", "==", "\"adv\"", "else", "mean_field_agent_q_model", ",", "n_good", "=", "arglist", ".", "num_agents", "-", "arglist", ".", "num_adversaries", ",", "\n", "n_adv", "=", "arglist", ".", "num_adversaries", ",", "n_land", "=", "arglist", ".", "num_food", ",", "index", "=", "i", ",", "scenario", "=", "arglist", ".", "scenario", ",", "n_act", "=", "env", ".", "action_space", "[", "0", "]", ".", "n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "# print(obs_shape_n)", "\n", "", "num_units", "=", "arglist", ".", "num_units", "\n", "return", "trainer", "(", "scope", ",", "model_p", ",", "model_q", ",", "obs_shape_n", ",", "env", ".", "action_space", ",", "i", ",", "arglist", ",", "num_units", ",", "sess", ",", "local_q_func", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_normal.get_adv_trainer": [[90, 92], ["train_normal.get_trainer"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.get_trainer"], ["", "def", "get_adv_trainer", "(", "i", ",", "scope", ",", "env", ",", "obs_shape_n", ",", "sess", ")", ":", "\n", "    ", "return", "get_trainer", "(", "\"adv\"", ",", "i", ",", "scope", ",", "env", ",", "obs_shape_n", ",", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_normal.get_good_trainer": [[94, 96], ["train_normal.get_trainer"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.get_trainer"], ["", "def", "get_good_trainer", "(", "i", ",", "scope", ",", "env", ",", "obs_shape_n", ",", "sess", ")", ":", "\n", "    ", "return", "get_trainer", "(", "\"good\"", ",", "i", ",", "scope", ",", "env", ",", "obs_shape_n", ",", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_normal.interact_with_environments": [[98, 160], ["env.reset", "env.step", "enumerate", "numpy.mean", "numpy.mean", "agent.action", "enumerate", "time.sleep", "frames.append", "print", "env.reset", "good_episode_rewards.append", "adv_episode_rewards.append", "zip", "agent.experience", "imageio.mimsave", "print", "env.render"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.reset", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.step", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.action", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.reset", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.MADDPGAgentTrainer.experience", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.render"], ["", "def", "interact_with_environments", "(", "env", ",", "trainers", ",", "size_transitions", ",", "train_data", "=", "True", ",", "num_episode", "=", "None", ")", ":", "\n", "    ", "obs_n", "=", "env", ".", "reset", "(", ")", "\n", "good_episode_rewards", "=", "[", "0.0", "]", "\n", "adv_episode_rewards", "=", "[", "0.0", "]", "\n", "step", "=", "0", "\n", "episode", "=", "0", "\n", "num_transitions", "=", "0", "\n", "frames", "=", "[", "]", "\n", "while", "True", ":", "\n", "        ", "action_n", "=", "[", "agent", ".", "action", "(", "obs", ")", "for", "agent", ",", "obs", "in", "zip", "(", "trainers", ",", "obs_n", ")", "]", "\n", "# for i in range(env.n):", "\n", "#     if np.all(np.isnan(action_n[i])):", "\n", "#         print('weights....', trainers[i].get_weigths())", "\n", "\n", "new_obs_n", ",", "rew_n", ",", "done_n", ",", "info_n", "=", "env", ".", "step", "(", "action_n", ")", "\n", "# print('train_data', train_data)", "\n", "# print('interact action', action_n)", "\n", "# print('interact obs', obs_n)", "\n", "# print('interact next obs',new_obs_n)", "\n", "\n", "step", "+=", "1", "\n", "terminal", "=", "(", "step", ">", "arglist", ".", "max_episode_len", ")", "\n", "\n", "# collect experience", "\n", "if", "(", "train_data", ")", ":", "\n", "            ", "for", "i", ",", "agent", "in", "enumerate", "(", "trainers", ")", ":", "\n", "                ", "agent", ".", "experience", "(", "obs_n", "[", "i", "]", ",", "action_n", "[", "i", "]", ",", "rew_n", "[", "i", "]", ",", "new_obs_n", "[", "i", "]", ",", "done_n", "[", "i", "]", ")", "\n", "\n", "", "", "obs_n", "=", "new_obs_n", "\n", "if", "arglist", ".", "display", ":", "\n", "            ", "time", ".", "sleep", "(", "0.1", ")", "\n", "frames", ".", "append", "(", "env", ".", "render", "(", "'rgb_array'", ")", "[", "0", "]", ")", "\n", "print", "(", "'The step is'", ",", "step", ")", "\n", "if", "(", "terminal", ")", ":", "\n", "                ", "imageio", ".", "mimsave", "(", "'demo_num_agents_%d_%d.gif'", "%", "(", "arglist", ".", "num_agents", ",", "episode", ")", ",", "frames", ",", "duration", "=", "0.15", ")", "\n", "frames", "=", "[", "]", "\n", "print", "(", "'demo_num_agents_%d_%d.gif'", "%", "(", "arglist", ".", "num_agents", ",", "episode", ")", ")", "\n", "\n", "", "", "for", "i", ",", "rew", "in", "enumerate", "(", "rew_n", ")", ":", "\n", "            ", "if", "i", "<", "arglist", ".", "num_adversaries", ":", "\n", "                ", "adv_episode_rewards", "[", "-", "1", "]", "+=", "rew", "\n", "", "else", ":", "\n", "                ", "good_episode_rewards", "[", "-", "1", "]", "+=", "rew", "\n", "\n", "", "", "if", "terminal", ":", "\n", "            ", "episode", "+=", "1", "\n", "if", "not", "train_data", ":", "\n", "                ", "if", "episode", ">=", "num_episode", ":", "\n", "                    ", "break", "\n", "", "", "obs_n", "=", "env", ".", "reset", "(", ")", "\n", "good_episode_rewards", ".", "append", "(", "0", ")", "\n", "adv_episode_rewards", ".", "append", "(", "0", ")", "\n", "step", "=", "0", "\n", "\n", "", "num_transitions", "+=", "1", "\n", "\n", "if", "train_data", ":", "\n", "            ", "if", "num_transitions", ">", "size_transitions", ":", "\n", "                ", "break", "\n", "\n", "\n", "", "", "", "return", "np", ".", "mean", "(", "good_episode_rewards", ")", ",", "np", ".", "mean", "(", "adv_episode_rewards", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_normal.touch_path": [[161, 165], ["os.path.dirname", "any", "os.makedirs"], "function", ["None"], ["", "def", "touch_path", "(", "path", ")", ":", "\n", "    ", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "path", ")", "\n", "if", "any", "(", "dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirname", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_normal.save_weights": [[166, 172], ["range", "len", "os.path.join", "train_normal.touch_path", "trainers[].get_weigths", "joblib.dump"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.touch_path", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.PolicyTrainer.get_weigths"], ["", "", "def", "save_weights", "(", "trainers", ")", ":", "\n", "    ", "for", "i", "in", "range", "(", "len", "(", "trainers", ")", ")", ":", "\n", "        ", "weight_file_name", "=", "os", ".", "path", ".", "join", "(", "arglist", ".", "save_dir", ",", "'agent%d.weights'", "%", "i", ")", "\n", "touch_path", "(", "weight_file_name", ")", "\n", "weight_dict", "=", "trainers", "[", "i", "]", ".", "get_weigths", "(", ")", "\n", "joblib", ".", "dump", "(", "weight_dict", ",", "weight_file_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_normal.load_weights": [[176, 190], ["joblib.load", "trainers[].set_weigths", "joblib.load", "trainers[].set_weigths", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.load", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.PolicyTrainer.set_weigths", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.load", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.PolicyTrainer.set_weigths"], ["", "", "def", "load_weights", "(", "trainers", ",", "index", ")", ":", "\n", "#for i in range(len(trainers)):", "\n", "# with open(arglist.save_dir + 'agent%d.weights' %i,'rb') as f:", "\n", "#     weight_dict=pickle.load(f)", "\n", "    ", "if", "index", "<", "arglist", ".", "num_adversaries", ":", "\n", "        ", "if", "arglist", ".", "load_one_side", ":", "\n", "            ", "only_policy", "=", "True", "\n", "", "else", ":", "\n", "            ", "only_policy", "=", "False", "\n", "", "weight_dict", "=", "joblib", ".", "load", "(", "os", ".", "path", ".", "join", "(", "arglist", ".", "adv_load_dir", ",", "'agent%d.weights'", "%", "index", ")", ")", "\n", "trainers", "[", "index", "]", ".", "set_weigths", "(", "weight_dict", ",", "only_policy", ")", "\n", "", "else", ":", "\n", "        ", "weight_dict", "=", "joblib", ".", "load", "(", "os", ".", "path", ".", "join", "(", "arglist", ".", "good_load_dir", ",", "'agent%d.weights'", "%", "index", ")", ")", "\n", "trainers", "[", "index", "]", ".", "set_weigths", "(", "weight_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_normal.train": [[193, 333], ["tensorflow.Session", "time.time", "tensorflow.set_random_seed", "random.seed", "numpy.random.seed", "train_normal.make_env", "range", "range", "print", "maddpg_o.initialize", "train_normal.touch_path", "tensorflow.train.Saver", "make_env.reset", "time.time", "print", "print", "print", "time.time", "train_normal.get_adv_trainer", "trainers.append", "train_normal.get_good_trainer", "trainers.append", "print", "range", "print", "range", "print", "time.time", "train_normal.interact_with_environments", "time.time", "print", "train_normal.interact_with_environments", "print", "range", "train_normal.load_weights", "train_normal.load_weights", "range", "train_normal.interact_with_environments", "time.time", "time.time", "agent.preupdate", "enumerate", "train_normal.interact_with_environments", "time.time", "print", "global_train_time.append", "train_time.append", "time.time", "final_good_rewards.append", "final_adv_rewards.append", "train_normal.save_weights", "time.time", "print", "print", "agent.update", "round", "round", "open", "pickle.dump", "open", "pickle.dump", "open", "pickle.dump", "open", "pickle.dump", "numpy.mean", "agent.update", "round", "round"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.make_env", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.initialize", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.touch_path", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.reset", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.get_adv_trainer", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.get_good_trainer", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_darl1n.interact_with_environments", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_darl1n.interact_with_environments", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.load_weights", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.load_weights", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_darl1n.interact_with_environments", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.preupdate", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_darl1n.interact_with_environments", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.save_weights", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.update", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.update"], ["", "", "def", "train", "(", "arglist", ")", ":", "\n", "    ", "with", "tf", ".", "Session", "(", ")", "as", "session", ":", "\n", "        ", "train_start_time", "=", "time", ".", "time", "(", ")", "\n", "seed", "=", "arglist", ".", "seed", "\n", "tf", ".", "set_random_seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "num_agents", "=", "arglist", ".", "num_agents", "\n", "# Create environment", "\n", "env", "=", "make_env", "(", "arglist", ".", "scenario", ",", "arglist", ",", "arglist", ".", "benchmark", ")", "\n", "# print(env.n)", "\n", "# Create agent trainers", "\n", "obs_shape_n", "=", "[", "env", ".", "observation_space", "[", "i", "]", ".", "shape", "for", "i", "in", "range", "(", "env", ".", "n", ")", "]", "\n", "#num_adversaries = min(env.n, 1)", "\n", "trainers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "arglist", ".", "num_adversaries", ")", ":", "\n", "            ", "trainer", "=", "get_adv_trainer", "(", "i", ",", "\"adv{}\"", ".", "format", "(", "i", ")", ",", "env", ",", "obs_shape_n", ",", "session", ")", "\n", "trainers", ".", "append", "(", "trainer", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "arglist", ".", "num_adversaries", ",", "env", ".", "n", ")", ":", "\n", "            ", "trainer", "=", "get_good_trainer", "(", "i", ",", "\"good{}\"", ".", "format", "(", "i", ")", ",", "env", ",", "obs_shape_n", ",", "session", ")", "\n", "trainers", ".", "append", "(", "trainer", ")", "\n", "\n", "#trainers = get_trainers(env, arglist.num_adversaries, obs_shape_n, arglist)", "\n", "", "print", "(", "'Using good policy {} and adv policy {}'", ".", "format", "(", "arglist", ".", "good_policy", ",", "arglist", ".", "adv_policy", ")", ")", "\n", "\n", "# Initialize", "\n", "U", ".", "initialize", "(", ")", "\n", "\n", "# Load previous results, if necessary", "\n", "# if arglist.load_dir == \"\":", "\n", "#     arglist.load_dir = arglist.save_dir", "\n", "touch_path", "(", "arglist", ".", "save_dir", ")", "\n", "if", "arglist", ".", "display", "or", "arglist", ".", "restore", ":", "\n", "            ", "print", "(", "'Loading previous state ...'", ")", "\n", "for", "i", "in", "range", "(", "num_agents", ")", ":", "\n", "                ", "load_weights", "(", "trainers", ",", "i", ")", "\n", "\n", "", "", "if", "arglist", ".", "load_one_side", ":", "\n", "            ", "print", "(", "'Loading state of one side ...'", ")", "\n", "for", "i", "in", "range", "(", "arglist", ".", "num_adversaries", ")", ":", "\n", "                ", "load_weights", "(", "trainers", ",", "i", ")", "\n", "\n", "", "", "episode_rewards", "=", "[", "0.0", "]", "# sum of rewards for all agents", "\n", "agent_rewards", "=", "[", "[", "0.0", "]", "for", "_", "in", "range", "(", "env", ".", "n", ")", "]", "# individual agent reward", "\n", "final_adv_rewards", "=", "[", "]", "# sum of rewards for training curve", "\n", "final_good_rewards", "=", "[", "]", "\n", "agent_info", "=", "[", "[", "[", "]", "]", "]", "# placeholder for benchmarking info", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "obs_n", "=", "env", ".", "reset", "(", ")", "\n", "episode_step", "=", "0", "\n", "train_step", "=", "0", "\n", "ground_global_time", "=", "time", ".", "time", "(", ")", "\n", "train_time", "=", "[", "]", "\n", "global_train_time", "=", "[", "]", "\n", "num_train", "=", "0", "\n", "print", "(", "'Scenario: '", ",", "arglist", ".", "scenario", ")", "\n", "print", "(", "'Number of agents: '", ",", "arglist", ".", "num_agents", ")", "\n", "print", "(", "'Starting iterations...'", ")", "\n", "\n", "if", "arglist", ".", "display", "or", "arglist", ".", "restore", ":", "\n", "            ", "print", "(", "'Displaying or Restoring'", ")", "\n", "", "else", ":", "\n", "            ", "env_time1", "=", "time", ".", "time", "(", ")", "\n", "interact_with_environments", "(", "env", ",", "trainers", ",", "5", "*", "arglist", ".", "batch_size", ")", "\n", "env_time2", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'Environment interactation time: '", ",", "env_time2", "-", "env_time1", ")", "\n", "\n", "", "t_start", "=", "time", ".", "time", "(", ")", "\n", "comp_time", "=", "0", "\n", "if", "arglist", ".", "display", ":", "\n", "            ", "good_reward", ",", "adv_reward", "=", "interact_with_environments", "(", "env", ",", "trainers", ",", "10", "*", "arglist", ".", "max_episode_len", ",", "False", ",", "5", ")", "\n", "print", "(", "'Good Reward is'", ",", "good_reward", ",", "'Adv Reward is'", ",", "adv_reward", ")", "\n", "", "else", ":", "\n", "            ", "while", "True", ":", "\n", "# get action", "\n", "                ", "interact_with_environments", "(", "env", ",", "trainers", ",", "4", "*", "arglist", ".", "max_episode_len", ")", "\n", "\n", "# for displaying learned policies", "\n", "#print('Iteration', num_train)", "\n", "loss", "=", "None", "\n", "com_time_start", "=", "time", ".", "time", "(", ")", "\n", "for", "agent", "in", "trainers", ":", "\n", "                    ", "agent", ".", "preupdate", "(", ")", "\n", "\n", "", "if", "arglist", ".", "load_one_side", ":", "\n", "                    ", "for", "i", ",", "agent", "in", "enumerate", "(", "trainers", ")", ":", "\n", "                        ", "if", "i", ">=", "arglist", ".", "num_adversaries", ":", "# Update good agents", "\n", "                            ", "loss", "=", "agent", ".", "update", "(", "trainers", ")", "\n", "", "", "", "else", ":", "\n", "                    ", "for", "agent", "in", "trainers", ":", "\n", "                        ", "loss", "=", "agent", ".", "update", "(", "trainers", ")", "\n", "\n", "\n", "", "", "com_time_end", "=", "time", ".", "time", "(", ")", "\n", "comp_time", "+=", "com_time_end", "-", "com_time_start", "\n", "if", "(", "num_train", "%", "arglist", ".", "save_rate", "==", "0", ")", ":", "\n", "                    ", "comp_time", "=", "0", "\n", "good_reward", ",", "adv_reward", "=", "interact_with_environments", "(", "env", ",", "trainers", ",", "10", "*", "arglist", ".", "max_episode_len", ",", "False", ",", "5", ")", "\n", "t_end", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"steps: {},  good_reward: {}, adv_reward:{}, interval time: {}, global time: {}\"", ".", "format", "(", "\n", "num_train", ",", "good_reward", ",", "adv_reward", ",", "round", "(", "t_end", "-", "t_start", ",", "3", ")", ",", "round", "(", "t_end", "-", "ground_global_time", ",", "3", ")", ")", ")", "\n", "\n", "global_train_time", ".", "append", "(", "round", "(", "t_end", "-", "ground_global_time", ",", "3", ")", ")", "\n", "train_time", ".", "append", "(", "round", "(", "t_end", "-", "t_start", ",", "3", ")", ")", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "# Keep track of final episode reward", "\n", "final_good_rewards", ".", "append", "(", "good_reward", ")", "\n", "final_adv_rewards", ".", "append", "(", "adv_reward", ")", "\n", "", "num_train", "+=", "1", "\n", "# saves final episode reward for plotting training curve later", "\n", "if", "num_train", ">", "arglist", ".", "max_num_train", ":", "\n", "                    ", "save_weights", "(", "trainers", ")", "\n", "if", "arglist", ".", "restore", ":", "\n", "                        ", "good_file_name", "=", "arglist", ".", "save_dir", "+", "'good_agent_restore.pkl'", "\n", "adv_file_name", "=", "arglist", ".", "save_dir", "+", "'adv_agent_restore.pkl'", "\n", "time_file_name", "=", "arglist", ".", "save_dir", "+", "'train_time_restore.pkl'", "\n", "global_time_file", "=", "arglist", ".", "save_dir", "+", "'global_time_restore.pkl'", "\n", "", "else", ":", "\n", "                        ", "good_file_name", "=", "arglist", ".", "save_dir", "+", "'good_agent.pkl'", "\n", "adv_file_name", "=", "arglist", ".", "save_dir", "+", "'adv_agent.pkl'", "\n", "time_file_name", "=", "arglist", ".", "save_dir", "+", "'train_time.pkl'", "\n", "global_time_file", "=", "arglist", ".", "save_dir", "+", "'global_time.pkl'", "\n", "\n", "", "with", "open", "(", "good_file_name", ",", "'wb'", ")", "as", "fp", ":", "\n", "                        ", "pickle", ".", "dump", "(", "final_good_rewards", ",", "fp", ")", "\n", "\n", "", "with", "open", "(", "adv_file_name", ",", "'wb'", ")", "as", "fp", ":", "\n", "                        ", "pickle", ".", "dump", "(", "final_adv_rewards", ",", "fp", ")", "\n", "\n", "", "with", "open", "(", "time_file_name", ",", "'wb'", ")", "as", "fp", ":", "\n", "                        ", "pickle", ".", "dump", "(", "train_time", ",", "fp", ")", "\n", "\n", "", "with", "open", "(", "global_time_file", ",", "'wb'", ")", "as", "fp", ":", "\n", "                        ", "pickle", ".", "dump", "(", "global_train_time", ",", "fp", ")", "\n", "\n", "", "train_end_time", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'The total training time:'", ",", "train_end_time", "-", "train_start_time", ")", "\n", "print", "(", "'Average train time'", ",", "np", ".", "mean", "(", "train_time", ")", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.evaluate_epc.register_environment": [[65, 75], ["None"], "function", ["None"], ["def", "register_environment", "(", "n_good", ",", "n_adv", ",", "n_landmarks", ",", "n_food", ",", "n_forests", ",", "init_weights", ",", "id_mapping", "=", "None", ")", ":", "\n", "    ", "global", "N_GOOD", ",", "N_ADV", ",", "N_LAND", ",", "N_LANDMARKS", ",", "N_FOOD", ",", "N_FORESTS", ",", "ID_MAPPING", ",", "INIT_WEIGHTS", "\n", "N_GOOD", "=", "n_good", "\n", "N_ADV", "=", "n_adv", "\n", "N_LANDMARKS", "=", "n_landmarks", "\n", "N_FOOD", "=", "n_food", "\n", "N_FORESTS", "=", "n_forests", "\n", "N_LAND", "=", "N_LANDMARKS", "+", "N_FOOD", "+", "N_FORESTS", "\n", "INIT_WEIGHTS", "=", "init_weights", "\n", "ID_MAPPING", "=", "id_mapping", "\n", "# print(\"SHARE_WEIGHTS\", SHARE_WEIGHTS)", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.evaluate_epc.make_env": [[78, 94], ["scenario_class", "scenario_class.make_world", "MultiAgentEnv", "importlib.import_module"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.make_world"], ["", "def", "make_env", "(", "scenario_name", ",", "arglist", ",", "benchmark", "=", "False", ")", ":", "\n", "    ", "import", "importlib", "\n", "from", "mpe_local", ".", "multiagent", ".", "environment", "import", "MultiAgentEnv", "\n", "module_name", "=", "\"mpe_local.multiagent.scenarios.{}\"", ".", "format", "(", "scenario_name", ")", "\n", "scenario_class", "=", "importlib", ".", "import_module", "(", "module_name", ")", ".", "Scenario", "\n", "# load scenario from script", "\n", "# print(Scenario.__module__.__file__)", "\n", "scenario", "=", "scenario_class", "(", "n_good", "=", "N_GOOD", ",", "n_adv", "=", "N_ADV", ",", "n_landmarks", "=", "N_LANDMARKS", ",", "n_food", "=", "N_FOOD", ",", "n_forests", "=", "N_FORESTS", ",", "\n", "no_wheel", "=", "FLAGS", ".", "no_wheel", ",", "good_sight", "=", "FLAGS", ".", "good_sight", ",", "alpha", "=", "FLAGS", ".", "alpha", ",", "adv_sight", "=", "FLAGS", ".", "adv_sight", ",", "ratio", "=", "FLAGS", ".", "ratio", ",", "max_good_neighbor", "=", "N_GOOD", "+", "N_ADV", ",", "max_adv_neighbor", "=", "N_GOOD", "+", "N_ADV", ")", "\n", "# create world", "\n", "world", "=", "scenario", ".", "make_world", "(", ")", "\n", "# create multiagent environment", "\n", "env", "=", "MultiAgentEnv", "(", "world", ",", "scenario", ".", "reset_world", ",", "scenario", ".", "reward", ",", "\n", "scenario", ".", "observation", ",", "done_callback", "=", "scenario", ".", "done", ",", "info_callback", "=", "scenario", ".", "info", ",", "\n", "export_episode", "=", "FLAGS", ".", "save_gif_data", ")", "\n", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.evaluate_epc.make_session": [[96, 105], ["tensorflow.ConfigProto", "tensorflow.Session"], "function", ["None"], ["", "def", "make_session", "(", "graph", ",", "num_cpu", ")", ":", "\n", "# print(\"num_cpu:\", num_cpu)", "\n", "    ", "tf_config", "=", "tf", ".", "ConfigProto", "(", "\n", "# device_count={\"CPU\": num_cpu},", "\n", "inter_op_parallelism_threads", "=", "num_cpu", ",", "\n", "intra_op_parallelism_threads", "=", "num_cpu", ",", "\n", "log_device_placement", "=", "False", ")", "\n", "tf_config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "return", "tf", ".", "Session", "(", "graph", "=", "graph", ",", "config", "=", "tf_config", ")", "\n", "# return tf.Session(target=server.target, graph=graph, config=tf_config)", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.evaluate_epc.get_trainer": [[108, 137], ["trainer", "functools.partial", "functools.partial", "functools.partial", "functools.partial", "functools.partial"], "function", ["None"], ["", "def", "get_trainer", "(", "side", ",", "i", ",", "scope", ",", "env", ",", "obs_shape_n", ")", ":", "\n", "    ", "trainer", "=", "MADDPGAgentMicroSharedTrainer", "\n", "policy", "=", "FLAGS", ".", "adv_policy", "if", "side", "==", "\"adv\"", "else", "FLAGS", ".", "good_policy", "\n", "share_weights", "=", "FLAGS", ".", "adv_share_weights", "if", "side", "==", "\"adv\"", "else", "FLAGS", ".", "good_share_weights", "\n", "if", "policy", "==", "\"att-maddpg\"", ":", "\n", "\n", "        ", "if", "FLAGS", ".", "scenario", "==", "'ising'", ":", "\n", "            ", "model_p", "=", "partial", "(", "mlp_model_agent_p_ising", ",", "n_good", "=", "N_GOOD", ",", "n_adv", "=", "N_ADV", ",", "\n", "n_land", "=", "N_LAND", ",", "index", "=", "i", ",", "share_weights", "=", "share_weights", ")", "\n", "model_q", "=", "partial", "(", "mlp_model_agent_q_ising", ",", "n_good", "=", "N_GOOD", ",", "n_adv", "=", "N_ADV", ",", "\n", "n_land", "=", "N_LAND", ",", "index", "=", "i", ",", "share_weights", "=", "share_weights", ")", "\n", "", "else", ":", "\n", "            ", "model_p", "=", "partial", "(", "mlp_model_adv_p", "if", "side", "==", "\"adv\"", "else", "mlp_model_agent_p", ",", "n_good", "=", "N_GOOD", ",", "n_adv", "=", "N_ADV", ",", "\n", "n_land", "=", "N_LAND", ",", "index", "=", "i", ",", "share_weights", "=", "share_weights", ")", "\n", "model_q", "=", "partial", "(", "mlp_model_adv_q", "if", "side", "==", "\"adv\"", "else", "mlp_model_agent_q", ",", "n_good", "=", "N_GOOD", ",", "n_adv", "=", "N_ADV", ",", "\n", "n_land", "=", "N_LAND", ",", "index", "=", "i", ",", "share_weights", "=", "share_weights", ")", "\n", "\n", "", "", "elif", "policy", "==", "\"maddpg\"", ":", "\n", "        ", "model_p", "=", "mlp_model", "\n", "model_q", "=", "mlp_model", "\n", "", "elif", "policy", "==", "\"mean_field\"", ":", "\n", "        ", "model_p", "=", "mlp_model", "\n", "model_q", "=", "partial", "(", "mean_field_adv_q_model", "if", "side", "==", "\"adv\"", "else", "mean_field_agent_q_model", ",", "n_good", "=", "N_GOOD", ",", "\n", "n_adv", "=", "N_ADV", ",", "n_land", "=", "N_LAND", ",", "index", "=", "i", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "# print(obs_shape_n)", "\n", "", "num_units", "=", "(", "FLAGS", ".", "adv_num_units", "if", "side", "==", "\"adv\"", "else", "FLAGS", ".", "good_num_units", ")", "or", "FLAGS", ".", "num_units", "\n", "return", "trainer", "(", "scope", ",", "model_p", ",", "model_q", ",", "obs_shape_n", ",", "env", ".", "action_space", ",", "i", ",", "FLAGS", ",", "num_units", ",", "local_q_func", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.evaluate_epc.get_adv_trainer": [[139, 141], ["evaluate_epc.get_trainer"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.get_trainer"], ["", "def", "get_adv_trainer", "(", "i", ",", "scope", ",", "env", ",", "obs_shape_n", ")", ":", "\n", "    ", "return", "get_trainer", "(", "\"adv\"", ",", "i", ",", "scope", ",", "env", ",", "obs_shape_n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.evaluate_epc.get_one_side_trainer": [[142, 145], ["trainer"], "function", ["None"], ["", "def", "get_one_side_trainer", "(", "i", ",", "scope", ",", "env", ",", "obs_shape_n", ")", ":", "\n", "    ", "trainer", "=", "PolicyTrainer", "\n", "return", "trainer", "(", "scope", ",", "mlp_model", ",", "obs_shape_n", ",", "None", ",", "env", ".", "action_space", ",", "i", ",", "FLAGS", ",", "local_q_func", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.evaluate_epc.get_good_trainer": [[146, 148], ["evaluate_epc.get_trainer"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.get_trainer"], ["", "def", "get_good_trainer", "(", "i", ",", "scope", ",", "env", ",", "obs_shape_n", ")", ":", "\n", "    ", "return", "get_trainer", "(", "\"good\"", ",", "i", ",", "scope", ",", "env", ",", "obs_shape_n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.evaluate_epc.show_size": [[150, 158], ["tensorflow.trainable_variables", "var.get_shape"], "function", ["None"], ["", "def", "show_size", "(", ")", ":", "\n", "    ", "s", "=", "0", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "        ", "shape", "=", "var", ".", "get_shape", "(", ")", "\n", "tot", "=", "1", "\n", "for", "dim", "in", "shape", ":", "\n", "            ", "tot", "*=", "dim", "\n", "", "s", "+=", "tot", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.evaluate_epc.touch_path": [[160, 164], ["os.path.dirname", "any", "os.makedirs"], "function", ["None"], ["", "", "def", "touch_path", "(", "path", ")", ":", "\n", "    ", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "path", ")", "\n", "if", "any", "(", "dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirname", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.evaluate_epc.load_weights": [[166, 171], ["CACHED_WEIGHTS.update", "joblib.load"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.update", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.load"], ["", "", "def", "load_weights", "(", "load_path", ")", ":", "\n", "    ", "import", "joblib", "\n", "global", "CACHED_WEIGHTS", "\n", "\n", "CACHED_WEIGHTS", ".", "update", "(", "joblib", ".", "load", "(", "load_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.evaluate_epc.clean": [[173, 183], ["d.items", "type"], "function", ["None"], ["", "def", "clean", "(", "d", ")", ":", "\n", "    ", "rd", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "d", ".", "items", "(", ")", ":", "\n", "# if v.shape[0] == 456 or v.shape[0] == 1552:", "\n", "#     print(k, v.shape)", "\n", "        ", "if", "type", "(", "k", ")", "==", "tuple", ":", "\n", "            ", "rd", "[", "k", "[", "0", "]", "]", "=", "v", "\n", "", "else", ":", "\n", "            ", "rd", "[", "k", "]", "=", "v", "\n", "", "", "return", "rd", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.evaluate_epc.load_all_weights": [[185, 193], ["range", "evaluate_epc.clean", "evaluate_epc.load_weights", "os.path.join"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.clean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.load_weights"], ["", "def", "load_all_weights", "(", "load_dir", ",", "n", ")", ":", "\n", "    ", "global", "CACHED_WEIGHTS", "\n", "CACHED_WEIGHTS", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "# print(os.path.join(load_dir[i], \"agent{}.trainable-weights\".format(i)))", "\n", "        ", "load_weights", "(", "os", ".", "path", ".", "join", "(", "load_dir", "[", "i", "]", ",", "\"agent{}.trainable-weights\"", ".", "format", "(", "i", ")", ")", ")", "\n", "# print(CACHED_WEIGHTS)", "\n", "", "CACHED_WEIGHTS", "=", "clean", "(", "CACHED_WEIGHTS", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.evaluate_epc.parse_args": [[195, 271], ["argparse.ArgumentParser", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.parse_args", "add_extra_flags"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.parse_args", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_epc_select.add_extra_flags"], ["", "def", "parse_args", "(", "add_extra_flags", "=", "None", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "\"Reinforcement Learning experiments for multiagent environments\"", ")", "\n", "# Environment", "\n", "parser", ".", "add_argument", "(", "\"--scenario\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"grassland\"", ",", "\n", "help", "=", "\"name of the scenario script\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--map-size\"", ",", "type", "=", "str", ",", "default", "=", "\"normal\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-sight\"", ",", "type", "=", "float", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-sight\"", ",", "type", "=", "float", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "\"--no-wheel\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--alpha\"", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "\"--show-attention\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--max-episode-len\"", ",", "type", "=", "int", ",", "\n", "default", "=", "25", ",", "help", "=", "\"maximum episode length\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-episodes\"", ",", "type", "=", "int", ",", "\n", "default", "=", "200000", ",", "help", "=", "\"number of episodes\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-adversaries\"", ",", "type", "=", "int", ",", "\n", "default", "=", "2", ",", "help", "=", "\"number of adversaries\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-good\"", ",", "type", "=", "int", ",", "\n", "default", "=", "2", ",", "help", "=", "\"number of good\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-agents\"", ",", "type", "=", "int", ",", "\n", "default", "=", "2", ",", "help", "=", "\"number of agents\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-food\"", ",", "type", "=", "int", ",", "\n", "default", "=", "4", ",", "help", "=", "\"number of food\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-policy\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"maddpg\"", ",", "help", "=", "\"policy for good agents\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-policy\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"maddpg\"", ",", "help", "=", "\"policy of adversaries\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-load-one-side\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-load-one-side\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "# Core training parameters", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "type", "=", "float", ",", "default", "=", "1e-2", ",", "\n", "help", "=", "\"learning rate for Adam optimizer\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gamma\"", ",", "type", "=", "float", ",", "\n", "default", "=", "0.95", ",", "help", "=", "\"discount factor\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch-size\"", ",", "type", "=", "int", ",", "default", "=", "1024", ",", "\n", "help", "=", "\"number of episodes to optimize at the same time\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-units\"", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "\"number of units in the mlp\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-num-units\"", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-num-units\"", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--n-cpu-per-agent\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-share-weights\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-share-weights\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--use-gpu\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "# Checkpointing", "\n", "parser", ".", "add_argument", "(", "\"--good-save-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"./test/\"", ",", "\n", "help", "=", "\"directory in which training state and model should be saved\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-save-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"./test/\"", ",", "\n", "help", "=", "\"directory in which training state and model should be saved\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train-rate\"", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "\"save model once every time this many episodes are completed\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save-rate\"", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "\n", "help", "=", "\"save model once every time this many episodes are completed\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoint-rate\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--load-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"./test/\"", ",", "\n", "help", "=", "\"directory in which training state and model are loaded\"", ")", "\n", "# Evaluation", "\n", "parser", ".", "add_argument", "(", "\"--restore\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--display\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--save-gif-data\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--render-gif\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--benchmark\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--benchmark-iters\"", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "\"number of iterations run for benchmarking\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--n-envs\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "\"--ratio\"", ",", "type", "=", "float", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--save-summary\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--timeout\"", ",", "type", "=", "float", ",", "default", "=", "0.02", ")", "\n", "\n", "if", "add_extra_flags", "is", "not", "None", ":", "\n", "        ", "parser", "=", "add_extra_flags", "(", "parser", ")", "\n", "\n", "", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_epc.train_epc": [[9, 11], ["train_helper.proxy_train.proxy_train"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.proxy_train.proxy_train"], ["def", "train_epc", "(", "arglist", ")", ":", "\n", "    ", "proxy_train", "(", "{", "\"arglist\"", ":", "arglist", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.evaluate_normal.parse_args": [[18, 59], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\"Reinforcement Learning experiments for multiagent environments\"", ")", "\n", "# Environment", "\n", "parser", ".", "add_argument", "(", "\"--scenario\"", ",", "type", "=", "str", ",", "default", "=", "\"simple\"", ",", "help", "=", "\"name of the scenario script\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max-episode-len\"", ",", "type", "=", "int", ",", "default", "=", "25", ",", "help", "=", "\"maximum episode length\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-episodes\"", ",", "type", "=", "int", ",", "default", "=", "20000", ",", "help", "=", "\"number of episodes\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train-period\"", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "\"frequency of updating parameters\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train\"", ",", "type", "=", "int", ",", "default", "=", "2000", ",", "help", "=", "\"number of train\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-adversaries\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"number of adversaries\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-policy\"", ",", "type", "=", "str", ",", "default", "=", "\"maddpg\"", ",", "help", "=", "\"policy for good agents\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-policy\"", ",", "type", "=", "str", ",", "default", "=", "\"maddpg\"", ",", "help", "=", "\"policy of adversaries\"", ")", "\n", "# Core training parameters", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "type", "=", "float", ",", "default", "=", "1e-2", ",", "help", "=", "\"learning rate for Adam optimizer\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gamma\"", ",", "type", "=", "float", ",", "default", "=", "0.95", ",", "help", "=", "\"discount factor\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch-size\"", ",", "type", "=", "int", ",", "default", "=", "1024", ",", "help", "=", "\"number of episodes to optimize at the same time\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-units\"", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "\"number of units in the mlp\"", ")", "\n", "# Checkpointing", "\n", "parser", ".", "add_argument", "(", "\"--good-save-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"../trained_policy/\"", ",", "help", "=", "\"directory in which training state and model should be saved\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-save-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"../trained_policy/\"", ",", "help", "=", "\"directory in which training state and model should be saved\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save-rate\"", ",", "type", "=", "int", ",", "default", "=", "20", ",", "help", "=", "\"save model once every time this number of train are completed\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train-rate\"", ",", "type", "=", "int", ",", "default", "=", "20", ",", "help", "=", "\"train model once every time this many episodes are completed\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--load-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"directory in which training state and model are loaded\"", ")", "\n", "# Evaluation", "\n", "parser", ".", "add_argument", "(", "\"--restore\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--display\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--plots-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"../learning_curves/\"", ",", "help", "=", "\"directory where plot data is saved\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-good\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"num good\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-landmarks\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"num landmarks\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-agents\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"num agents\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--last-stage-num\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"num agents from last stage\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-max-num-neighbors\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"maximum number of  agents in neighbors area\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-max-num-neighbors\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"maximum number of  agents in neighbors area\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-food\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"num food\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-forests\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"num foresets\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--prosp-dist\"", ",", "type", "=", "float", ",", "default", "=", "\"0.6\"", ",", "help", "=", "\"prospective neighbor distance\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-sight\"", ",", "type", "=", "float", ",", "default", "=", "\"1\"", ",", "help", "=", "\"neighbor distance\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-sight\"", ",", "type", "=", "float", ",", "default", "=", "\"1\"", ",", "help", "=", "\"neighbor distance\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--ratio\"", ",", "type", "=", "float", ",", "default", "=", "\"1\"", ",", "help", "=", "\"size map\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no-wheel\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--method\"", ",", "type", "=", "str", ",", "default", "=", "\"darl1n\"", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.evaluate_normal.touch_path": [[60, 64], ["os.path.dirname", "any", "os.makedirs"], "function", ["None"], ["", "def", "touch_path", "(", "path", ")", ":", "\n", "    ", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "path", ")", "\n", "if", "any", "(", "dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirname", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.evaluate_normal.mlp_model": [[66, 74], ["tensorflow.variable_scope", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected"], "function", ["None"], ["", "", "def", "mlp_model", "(", "input", ",", "num_outputs", ",", "scope", ",", "reuse", "=", "False", ",", "num_units", "=", "64", ",", "rnn_cell", "=", "None", ")", ":", "\n", "# This model takes as input an observation and returns values of all actions", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "out", "=", "input", "\n", "out", "=", "layers", ".", "fully_connected", "(", "out", ",", "num_outputs", "=", "num_units", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "out", "=", "layers", ".", "fully_connected", "(", "out", ",", "num_outputs", "=", "num_units", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "out", "=", "layers", ".", "fully_connected", "(", "out", ",", "num_outputs", "=", "num_outputs", ",", "activation_fn", "=", "None", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.evaluate_normal.make_env": [[75, 86], ["scenario_class", "scenario_class.make_world", "MultiAgentEnv", "importlib.import_module"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.make_world"], ["", "", "def", "make_env", "(", "scenario_name", ",", "arglist", ",", "evaluate", "=", "False", ")", ":", "###################", "\n", "    ", "import", "importlib", "\n", "from", "mpe_local", ".", "multiagent", ".", "environment", "import", "MultiAgentEnv", "\n", "module_name", "=", "\"mpe_local.multiagent.scenarios.{}\"", ".", "format", "(", "scenario_name", ")", "\n", "scenario_class", "=", "importlib", ".", "import_module", "(", "module_name", ")", ".", "Scenario", "\n", "scenario", "=", "scenario_class", "(", "n_good", "=", "arglist", ".", "num_agents", "-", "arglist", ".", "num_adversaries", ",", "n_adv", "=", "arglist", ".", "num_adversaries", ",", "n_landmarks", "=", "arglist", ".", "num_landmarks", ",", "n_food", "=", "arglist", ".", "num_food", ",", "n_forests", "=", "arglist", ".", "num_forests", ",", "\n", "no_wheel", "=", "arglist", ".", "no_wheel", ",", "good_sight", "=", "arglist", ".", "good_sight", ",", "adv_sight", "=", "arglist", ".", "adv_sight", ",", "alpha", "=", "0", ",", "ratio", "=", "arglist", ".", "ratio", ",", "max_good_neighbor", "=", "arglist", ".", "good_max_num_neighbors", ",", "max_adv_neighbor", "=", "arglist", ".", "adv_max_num_neighbors", ")", "\n", "world", "=", "scenario", ".", "make_world", "(", ")", "\n", "# create multiagent environment", "\n", "env", "=", "MultiAgentEnv", "(", "world", ",", "scenario", ".", "reset_world", ",", "scenario", ".", "reward", ",", "scenario", ".", "observation", ")", "\n", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.evaluate_normal.get_trainers": [[87, 115], ["range", "range", "range", "trainers.append", "trainers.append", "trainers.append", "PolicyTrainer", "functools.partial", "PolicyTrainer", "functools.partial", "PolicyTrainer"], "function", ["None"], ["", "def", "get_trainers", "(", "env", ",", "num_agents", ",", "name", ",", "obs_shape_n", ",", "arglist", ",", "session", ")", ":", "\n", "    ", "trainers", "=", "[", "]", "\n", "model", "=", "mlp_model", "\n", "if", "arglist", ".", "method", "==", "'darl1n'", ":", "\n", "        ", "from", "maddpg_o", ".", "maddpg_local", ".", "micro", ".", "policy_target_policy", "import", "PolicyTrainer", "\n", "for", "i", "in", "range", "(", "num_agents", ")", ":", "\n", "            ", "trainers", ".", "append", "(", "PolicyTrainer", "(", "\n", "\"actor\"", "+", "\"agent_%d\"", "%", "i", ",", "model", ",", "obs_shape_n", ",", "session", ",", "env", ".", "action_space", ",", "i", ",", "arglist", ",", "\n", "False", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "from", "maddpg_o", ".", "maddpg_local", ".", "micro", ".", "policy_normal", "import", "PolicyTrainer", "\n", "num_units", "=", "arglist", ".", "num_units", "\n", "for", "i", "in", "range", "(", "arglist", ".", "num_adversaries", ")", ":", "\n", "            ", "model_p", "=", "mlp_model", "\n", "if", "arglist", ".", "adv_policy", "==", "\"mean_field\"", ":", "\n", "                ", "model_q", "=", "partial", "(", "mean_field_adv_q_model", ",", "n_good", "=", "arglist", ".", "num_agents", "-", "arglist", ".", "num_adversaries", ",", "\n", "n_adv", "=", "arglist", ".", "num_adversaries", ",", "n_land", "=", "arglist", ".", "num_food", ",", "index", "=", "i", ",", "scenario", "=", "arglist", ".", "scenario", ",", "n_act", "=", "env", ".", "action_space", "[", "0", "]", ".", "n", ")", "\n", "", "else", ":", "\n", "                ", "model_q", "=", "mlp_model", "\n", "", "trainers", ".", "append", "(", "PolicyTrainer", "(", "\"adv{}\"", ".", "format", "(", "i", ")", ",", "model_p", ",", "model_q", ",", "obs_shape_n", ",", "env", ".", "action_space", ",", "i", ",", "arglist", ",", "num_units", ",", "session", ",", "local_q_func", "=", "False", ")", ")", "\n", "", "for", "i", "in", "range", "(", "arglist", ".", "num_adversaries", ",", "env", ".", "n", ")", ":", "\n", "            ", "model_p", "=", "mlp_model", "\n", "if", "arglist", ".", "good_policy", "==", "\"mean_field\"", ":", "\n", "                ", "model_q", "=", "partial", "(", "mean_field_agent_q_model", ",", "n_good", "=", "arglist", ".", "num_agents", "-", "arglist", ".", "num_adversaries", ",", "n_adv", "=", "arglist", ".", "num_adversaries", ",", "n_land", "=", "arglist", ".", "num_food", ",", "index", "=", "i", ",", "scenario", "=", "arglist", ".", "scenario", ",", "n_act", "=", "env", ".", "action_space", "[", "0", "]", ".", "n", ")", "\n", "", "else", ":", "\n", "                ", "model_q", "=", "mlp_model", "\n", "", "trainers", ".", "append", "(", "PolicyTrainer", "(", "\"good{}\"", ".", "format", "(", "i", ")", ",", "model_p", ",", "model_q", ",", "obs_shape_n", ",", "env", ".", "action_space", ",", "i", ",", "arglist", ",", "num_units", ",", "session", ",", "local_q_func", "=", "False", ")", ")", "\n", "", "", "return", "trainers", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.evaluate_normal.evaluate_policy": [[116, 185], ["env.reset", "print", "action_history.append", "env.step", "print", "enumerate", "all", "numpy.mean", "numpy.mean", "initial.append", "agent.action", "good_episode_rewards.append", "adv_episode_rewards.append", "env.reset", "print", "zip", "time.sleep", "frames.append", "print", "evaluate_normal.touch_path", "imageio.mimsave", "matplotlib.imshow", "matplotlib.savefig", "initial.append", "open", "pickle.dump", "open", "pickle.dump", "env.render", "matplotlib.xticks", "matplotlib.yticks"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.reset", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.step", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.action", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.reset", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.touch_path", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.rendering.SimpleImageViewer.imshow", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.render"], ["", "def", "evaluate_policy", "(", "env", ",", "trainers", ",", "size_transitions", ",", "display", "=", "False", ")", ":", "\n", "    ", "good_episode_rewards", "=", "[", "0.0", "]", "\n", "adv_episode_rewards", "=", "[", "0.0", "]", "\n", "step", "=", "0", "\n", "num_transitions", "=", "0", "\n", "frames", "=", "[", "]", "\n", "initial", "=", "[", "]", "\n", "obs_n", "=", "env", ".", "reset", "(", ")", "\n", "if", "arglist", ".", "scenario", "==", "'ising'", ":", "\n", "        ", "for", "agent", "in", "env", ".", "world", ".", "agents", ":", "\n", "            ", "initial", ".", "append", "(", "agent", ".", "state", ".", "spin", ")", "\n", "", "", "print", "(", "initial", ")", "\n", "action_history", "=", "[", "]", "\n", "\n", "while", "True", ":", "\n", "        ", "action_n", "=", "[", "agent", ".", "action", "(", "obs", ")", "for", "agent", ",", "obs", "in", "zip", "(", "trainers", ",", "obs_n", ")", "]", "\n", "action_history", ".", "append", "(", "action_n", ")", "\n", "\n", "new_obs_n", ",", "rew_n", ",", "done_n", ",", "next_info_n", "=", "env", ".", "step", "(", "action_n", ")", "\n", "print", "(", "rew_n", ")", "\n", "num_transitions", "+=", "1", "\n", "for", "i", ",", "rew", "in", "enumerate", "(", "rew_n", ")", ":", "\n", "            ", "if", "i", "<", "arglist", ".", "num_adversaries", ":", "\n", "                ", "adv_episode_rewards", "[", "-", "1", "]", "+=", "rew", "\n", "", "else", ":", "\n", "                ", "good_episode_rewards", "[", "-", "1", "]", "+=", "rew", "\n", "", "", "step", "+=", "1", "\n", "done", "=", "all", "(", "done_n", ")", "\n", "terminal", "=", "(", "step", ">", "(", "arglist", ".", "max_episode_len", ")", ")", "\n", "obs_n", "=", "new_obs_n", "\n", "info_n", "=", "next_info_n", "\n", "if", "display", ":", "\n", "            ", "if", "arglist", ".", "scenario", "==", "'ising'", ":", "\n", "                ", "if", "(", "terminal", "or", "done", ")", ":", "\n", "                    ", "action_file", "=", "arglist", ".", "good_save_dir", "+", "'history_action%d.pkl'", "%", "num_transitions", "\n", "with", "open", "(", "action_file", ",", "'wb'", ")", "as", "fp", ":", "\n", "                        ", "pickle", ".", "dump", "(", "action_history", ",", "fp", ")", "\n", "", "initial_file", "=", "arglist", ".", "good_save_dir", "+", "'initial%d.pkl'", "%", "num_transitions", "\n", "with", "open", "(", "initial_file", ",", "'wb'", ")", "as", "fp", ":", "\n", "                        ", "pickle", ".", "dump", "(", "initial", ",", "fp", ")", "\n", "", "initial", "=", "[", "]", "\n", "action_history", "=", "[", "]", "\n", "", "", "else", ":", "\n", "                ", "time", ".", "sleep", "(", "0.1", ")", "\n", "frames", ".", "append", "(", "env", ".", "render", "(", "'rgb_array'", ")", "[", "0", "]", ")", "\n", "print", "(", "'The step is'", ",", "step", ")", "\n", "if", "(", "terminal", "or", "done", ")", ":", "\n", "                    ", "gif_path", "=", "'../visualize/'", "+", "arglist", ".", "scenario", "+", "'/'", "+", "arglist", ".", "method", "+", "'/%dagents/gifs/'", "%", "arglist", ".", "num_agents", "\n", "touch_path", "(", "gif_path", ")", "\n", "imageio", ".", "mimsave", "(", "gif_path", "+", "'%d.gif'", "%", "num_transitions", ",", "frames", ",", "duration", "=", "0.15", ")", "\n", "plt", ".", "imshow", "(", "frames", "[", "-", "1", "]", ")", "\n", "plt", ".", "xticks", "(", "[", "]", ")", ",", "plt", ".", "yticks", "(", "[", "]", ")", "\n", "plt", ".", "savefig", "(", "gif_path", "+", "'%d.png'", "%", "num_transitions", ",", "transparent", "=", "True", ")", "\n", "frames", "=", "[", "]", "\n", "\n", "", "", "", "if", "done", "or", "terminal", ":", "\n", "            ", "good_episode_rewards", ".", "append", "(", "0", ")", "\n", "adv_episode_rewards", ".", "append", "(", "0", ")", "\n", "obs_n", "=", "env", ".", "reset", "(", ")", "\n", "if", "arglist", ".", "scenario", "==", "'ising'", ":", "\n", "                ", "for", "agent", "in", "env", ".", "world", ".", "agents", ":", "\n", "                    ", "initial", ".", "append", "(", "agent", ".", "state", ".", "spin", ")", "\n", "", "", "step", "=", "0", "\n", "\n", "", "if", "num_transitions", ">=", "size_transitions", ":", "\n", "            ", "print", "(", "'good'", ",", "good_episode_rewards", ",", "'adv'", ",", "adv_episode_rewards", ")", "\n", "break", "\n", "\n", "", "", "return", "np", ".", "mean", "(", "good_episode_rewards", ")", ",", "np", ".", "mean", "(", "adv_episode_rewards", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.evaluate_normal.load_weights": [[186, 193], ["trainers[].set_weigths", "joblib.load", "joblib.load", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_normal.PolicyTrainer.set_weigths", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.load", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.load"], ["", "def", "load_weights", "(", "trainers", ",", "index", ")", ":", "\n", "    ", "if", "index", "<", "arglist", ".", "num_adversaries", ":", "\n", "        ", "weight_dict", "=", "joblib", ".", "load", "(", "os", ".", "path", ".", "join", "(", "arglist", ".", "adv_save_dir", ",", "'agent%d.weights'", "%", "index", ")", ")", "\n", "", "else", ":", "\n", "        ", "weight_dict", "=", "joblib", ".", "load", "(", "os", ".", "path", ".", "join", "(", "arglist", ".", "good_save_dir", ",", "'agent%d.weights'", "%", "index", ")", ")", "\n", "\n", "", "trainers", "[", "index", "]", ".", "set_weigths", "(", "weight_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_darl1n.parse_args": [[18, 60], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\"Reinforcement Learning experiments for multiagent environments\"", ")", "\n", "# Environment", "\n", "parser", ".", "add_argument", "(", "\"--scenario\"", ",", "type", "=", "str", ",", "default", "=", "\"simple\"", ",", "help", "=", "\"name of the scenario script\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max-episode-len\"", ",", "type", "=", "int", ",", "default", "=", "25", ",", "help", "=", "\"maximum episode length\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eva-max-episode-len\"", ",", "type", "=", "int", ",", "default", "=", "25", ",", "help", "=", "\"maximum episode length\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max-num-train\"", ",", "type", "=", "int", ",", "default", "=", "2000", ",", "help", "=", "\"number of train\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-adversaries\"", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "\"number of adversaries\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-policy\"", ",", "type", "=", "str", ",", "default", "=", "\"maddpg\"", ",", "help", "=", "\"policy for good agents\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-policy\"", ",", "type", "=", "str", ",", "default", "=", "\"maddpg\"", ",", "help", "=", "\"policy of adversaries\"", ")", "\n", "# Core training parameters", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "type", "=", "float", ",", "default", "=", "1e-2", ",", "help", "=", "\"learning rate for Adam optimizer\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gamma\"", ",", "type", "=", "float", ",", "default", "=", "0.95", ",", "help", "=", "\"discount factor\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch-size\"", ",", "type", "=", "int", ",", "default", "=", "1024", ",", "help", "=", "\"number of episodes to optimize at the same time\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-units\"", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "\"number of units in the mlp\"", ")", "\n", "# Checkpointing", "\n", "parser", ".", "add_argument", "(", "\"--save-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"../trained_policy/\"", ",", "help", "=", "\"directory in which training state and model should be saved\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save-rate\"", ",", "type", "=", "int", ",", "default", "=", "20", ",", "help", "=", "\"save model once every time this number of train are completed\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-load-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"directory in which training state and model are loaded\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-load-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"directory in which training state and model are loaded\"", ")", "\n", "# Evaluation", "\n", "parser", ".", "add_argument", "(", "\"--restore\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--display\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--plots-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"../learning_curves/\"", ",", "help", "=", "\"directory where plot data is saved\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-good\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"num good\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-landmarks\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"num landmarks\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-agents\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"num agents\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-learners\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"num learners\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--last-good\"", ",", "type", "=", "int", ",", "default", "=", "\"2\"", ",", "help", "=", "\"num good agents from last stage\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--last-adv\"", ",", "type", "=", "int", ",", "default", "=", "\"2\"", ",", "help", "=", "\"num adv agents from last stage\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-max-num-neighbors\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"maximum number of  agents in neighbors area\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-max-num-neighbors\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"maximum number of  agents in neighbors area\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-food\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"num food\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-forests\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"num foresets\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--prosp-dist\"", ",", "type", "=", "float", ",", "default", "=", "\"0.6\"", ",", "help", "=", "\"prospective neighbor distance\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-sight\"", ",", "type", "=", "float", ",", "default", "=", "\"1\"", ",", "help", "=", "\"neighbor distance\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-sight\"", ",", "type", "=", "float", ",", "default", "=", "\"1\"", ",", "help", "=", "\"neighbor distance\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--ratio\"", ",", "type", "=", "float", ",", "default", "=", "\"1\"", ",", "help", "=", "\"size of the map\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "\"1\"", ",", "help", "=", "\"seed for random number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no-wheel\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--load-one-side\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_darl1n.mlp_model": [[62, 70], ["tensorflow.variable_scope", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected"], "function", ["None"], ["", "def", "mlp_model", "(", "input", ",", "num_outputs", ",", "scope", ",", "reuse", "=", "False", ",", "num_units", "=", "64", ",", "rnn_cell", "=", "None", ")", ":", "\n", "# This model takes as input an observation and returns values of all actions", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "out", "=", "input", "\n", "out", "=", "layers", ".", "fully_connected", "(", "out", ",", "num_outputs", "=", "num_units", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "out", "=", "layers", ".", "fully_connected", "(", "out", ",", "num_outputs", "=", "num_units", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "out", "=", "layers", ".", "fully_connected", "(", "out", ",", "num_outputs", "=", "num_outputs", ",", "activation_fn", "=", "None", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_darl1n.make_env": [[72, 91], ["scenario_class.make_world", "MultiAgentEnv", "scenario_class", "scenario_class", "importlib.import_module", "importlib.import_module"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.make_world"], ["", "", "def", "make_env", "(", "scenario_name", ",", "arglist", ",", "evaluate", "=", "False", ")", ":", "###################", "\n", "    ", "import", "importlib", "\n", "if", "evaluate", ":", "\n", "        ", "from", "mpe_local", ".", "multiagent", ".", "environment", "import", "MultiAgentEnv", "\n", "module_name", "=", "\"mpe_local.multiagent.scenarios.{}\"", ".", "format", "(", "scenario_name", ")", "\n", "scenario_class", "=", "importlib", ".", "import_module", "(", "module_name", ")", ".", "Scenario", "\n", "scenario", "=", "scenario_class", "(", "n_good", "=", "arglist", ".", "num_agents", "-", "arglist", ".", "num_adversaries", ",", "n_adv", "=", "arglist", ".", "num_adversaries", ",", "n_landmarks", "=", "arglist", ".", "num_landmarks", ",", "n_food", "=", "arglist", ".", "num_food", ",", "n_forests", "=", "arglist", ".", "num_forests", ",", "\n", "no_wheel", "=", "arglist", ".", "no_wheel", ",", "good_sight", "=", "arglist", ".", "good_sight", ",", "adv_sight", "=", "arglist", ".", "adv_sight", ",", "alpha", "=", "0", ",", "ratio", "=", "arglist", ".", "ratio", ",", "max_good_neighbor", "=", "arglist", ".", "good_max_num_neighbors", ",", "max_adv_neighbor", "=", "arglist", ".", "adv_max_num_neighbors", ")", "\n", "", "else", ":", "\n", "        ", "from", "mpe_local", ".", "multiagent", ".", "environment_neighbor", "import", "MultiAgentEnv", "\n", "module_name", "=", "\"mpe_local.multiagent.scenarios.{}_neighbor\"", ".", "format", "(", "scenario_name", ")", "\n", "scenario_class", "=", "importlib", ".", "import_module", "(", "module_name", ")", ".", "Scenario", "\n", "scenario", "=", "scenario_class", "(", "n_good", "=", "arglist", ".", "num_agents", "-", "arglist", ".", "num_adversaries", ",", "n_adv", "=", "arglist", ".", "num_adversaries", ",", "n_landmarks", "=", "arglist", ".", "num_landmarks", ",", "n_food", "=", "arglist", ".", "num_food", ",", "n_forests", "=", "arglist", ".", "num_forests", ",", "\n", "no_wheel", "=", "arglist", ".", "no_wheel", ",", "good_sight", "=", "arglist", ".", "good_sight", ",", "adv_sight", "=", "arglist", ".", "adv_sight", ",", "alpha", "=", "0", ",", "ratio", "=", "arglist", ".", "ratio", ",", "prosp", "=", "arglist", ".", "prosp_dist", ",", "max_good_neighbor", "=", "arglist", ".", "good_max_num_neighbors", ",", "max_adv_neighbor", "=", "arglist", ".", "adv_max_num_neighbors", ")", "\n", "\n", "", "world", "=", "scenario", ".", "make_world", "(", ")", "\n", "# create multiagent environment", "\n", "env", "=", "MultiAgentEnv", "(", "world", ",", "scenario", ".", "reset_world", ",", "scenario", ".", "reward", ",", "scenario", ".", "observation", ")", "\n", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_darl1n.get_trainers": [[93, 102], ["range", "trainers.append", "trainer"], "function", ["None"], ["", "def", "get_trainers", "(", "env", ",", "num_agents", ",", "name", ",", "obs_shape_n", ",", "arglist", ",", "session", ")", ":", "\n", "    ", "trainers", "=", "[", "]", "\n", "model", "=", "mlp_model", "\n", "trainer", "=", "MADDPGAgentTrainer", "\n", "for", "i", "in", "range", "(", "num_agents", ")", ":", "\n", "        ", "trainers", ".", "append", "(", "trainer", "(", "\n", "name", "+", "\"agent_%d\"", "%", "i", ",", "model", ",", "obs_shape_n", ",", "session", ",", "env", ".", "action_space", ",", "i", ",", "arglist", ",", "\n", "local_q_func", "=", "(", "arglist", ".", "good_policy", "==", "'ddpg'", ")", ")", ")", "\n", "", "return", "trainers", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_darl1n.evaluate_policy": [[104, 151], ["evaluate_env.reset", "evaluate_env.step", "enumerate", "all", "numpy.mean", "numpy.mean", "agent.action", "time.sleep", "frames.append", "print", "good_episode_rewards.append", "adv_episode_rewards.append", "evaluate_env.reset", "zip", "imageio.mimsave", "print", "evaluate_env.render"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.reset", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.step", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.action", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.reset", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.render"], ["", "def", "evaluate_policy", "(", "evaluate_env", ",", "trainers", ",", "num_episode", ",", "display", "=", "False", ")", ":", "\n", "    ", "good_episode_rewards", "=", "[", "0.0", "]", "\n", "adv_episode_rewards", "=", "[", "0.0", "]", "\n", "step", "=", "0", "\n", "episode", "=", "0", "\n", "frames", "=", "[", "]", "\n", "obs_n", "=", "evaluate_env", ".", "reset", "(", ")", "\n", "while", "True", ":", "\n", "        ", "action_n", "=", "[", "agent", ".", "action", "(", "obs", ")", "for", "agent", ",", "obs", "in", "zip", "(", "trainers", ",", "obs_n", ")", "]", "\n", "\n", "new_obs_n", ",", "rew_n", ",", "done_n", ",", "next_info_n", "=", "evaluate_env", ".", "step", "(", "action_n", ")", "\n", "#print(rew_n)", "\n", "for", "i", ",", "rew", "in", "enumerate", "(", "rew_n", ")", ":", "\n", "            ", "if", "i", "<", "arglist", ".", "num_adversaries", ":", "\n", "                ", "adv_episode_rewards", "[", "-", "1", "]", "+=", "rew", "\n", "", "else", ":", "\n", "                ", "good_episode_rewards", "[", "-", "1", "]", "+=", "rew", "\n", "\n", "", "", "step", "+=", "1", "\n", "done", "=", "all", "(", "done_n", ")", "\n", "terminal", "=", "(", "step", ">", "(", "arglist", ".", "eva_max_episode_len", ")", ")", "\n", "\n", "obs_n", "=", "new_obs_n", "\n", "info_n", "=", "next_info_n", "\n", "\n", "if", "arglist", ".", "display", ":", "\n", "            ", "time", ".", "sleep", "(", "0.1", ")", "\n", "frames", ".", "append", "(", "evaluate_env", ".", "render", "(", "'rgb_array'", ")", "[", "0", "]", ")", "\n", "print", "(", "'The step is'", ",", "step", ")", "\n", "if", "(", "terminal", "or", "done", ")", ":", "\n", "                ", "imageio", ".", "mimsave", "(", "'demo_num_agents_%d_%d.gif'", "%", "(", "arglist", ".", "num_agents", ",", "episode", ")", ",", "frames", ",", "duration", "=", "0.15", ")", "\n", "frames", "=", "[", "]", "\n", "print", "(", "'demo_num_agents_%d_%d.gif'", "%", "(", "arglist", ".", "num_agents", ",", "episode", ")", ")", "\n", "\n", "", "", "if", "done", "or", "terminal", ":", "\n", "            ", "episode", "+=", "1", "\n", "if", "episode", ">=", "num_episode", ":", "\n", "                ", "break", "\n", "#print(good_episode_rewards[-1])", "\n", "#print(adv_episode_rewards[-1])", "\n", "", "good_episode_rewards", ".", "append", "(", "0", ")", "\n", "\n", "adv_episode_rewards", ".", "append", "(", "0", ")", "\n", "obs_n", "=", "evaluate_env", ".", "reset", "(", ")", "\n", "step", "=", "0", "\n", "\n", "", "", "return", "np", ".", "mean", "(", "good_episode_rewards", ")", ",", "np", ".", "mean", "(", "adv_episode_rewards", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_darl1n.interact_with_environments": [[153, 194], ["range", "env.reset", "trainers[].action", "enumerate", "env.step", "trainers[].target_action", "enumerate", "trainers[].experience", "numpy.zeros", "numpy.zeros", "numpy.zeros", "len", "trainers[].action", "trainers[].target_action", "len"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.reset", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.action", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.step", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.target_action", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.maddpg.MADDPGAgentTrainer.experience", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.action", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.target_action"], ["", "def", "interact_with_environments", "(", "env", ",", "trainers", ",", "node_id", ",", "steps", ")", ":", "\n", "    ", "act_d", "=", "env", ".", "action_space", "[", "0", "]", ".", "n", "\n", "for", "k", "in", "range", "(", "steps", ")", ":", "\n", "        ", "obs_pot", ",", "neighbor", "=", "env", ".", "reset", "(", "node_id", ")", "# Neighbor does not include agent itself", "\n", "\n", "action_n", "=", "[", "np", ".", "zeros", "(", "(", "act_d", ")", ")", "]", "*", "env", ".", "n", "# Actions for transition", "\n", "\n", "action_neighbor", "=", "[", "np", ".", "zeros", "(", "(", "act_d", ")", ")", "]", "*", "arglist", ".", "good_max_num_neighbors", "#The neighbors include the agent itself", "\n", "target_action_neighbor", "=", "[", "np", ".", "zeros", "(", "(", "act_d", ")", ")", "]", "*", "arglist", ".", "good_max_num_neighbors", "\n", "\n", "self_action", "=", "trainers", "[", "node_id", "]", ".", "action", "(", "obs_pot", "[", "node_id", "]", ")", "\n", "\n", "action_n", "[", "node_id", "]", "=", "self_action", "\n", "action_neighbor", "[", "0", "]", "=", "self_action", "\n", "\n", "valid_neighbor", "=", "1", "\n", "for", "i", ",", "obs", "in", "enumerate", "(", "obs_pot", ")", ":", "\n", "            ", "if", "i", "==", "node_id", ":", "continue", "\n", "if", "len", "(", "obs", ")", "!=", "0", ":", "\n", "#print(obs)", "\n", "                ", "other_action", "=", "trainers", "[", "i", "]", ".", "action", "(", "obs", ")", "\n", "action_n", "[", "i", "]", "=", "other_action", "\n", "if", "neighbor", "and", "i", "in", "neighbor", "and", "valid_neighbor", "<", "arglist", ".", "good_max_num_neighbors", ":", "\n", "                    ", "action_neighbor", "[", "valid_neighbor", "]", "=", "other_action", "\n", "valid_neighbor", "+=", "1", "\n", "#print(action_n)", "\n", "", "", "", "new_obs_neighbor", ",", "rew", ",", "done_n", ",", "next_info_n", "=", "env", ".", "step", "(", "action_n", ")", "# Interaction within the neighbor area", "\n", "\n", "valid_neighbor", "=", "1", "\n", "target_action_neighbor", "[", "0", "]", "=", "trainers", "[", "node_id", "]", ".", "target_action", "(", "new_obs_neighbor", "[", "node_id", "]", ")", "\n", "\n", "for", "k", ",", "next", "in", "enumerate", "(", "new_obs_neighbor", ")", ":", "\n", "            ", "if", "k", "==", "node_id", ":", "continue", "\n", "if", "len", "(", "next", ")", "!=", "0", "and", "valid_neighbor", "<", "arglist", ".", "good_max_num_neighbors", ":", "\n", "                ", "target_action_neighbor", "[", "valid_neighbor", "]", "=", "trainers", "[", "k", "]", ".", "target_action", "(", "next", ")", "\n", "valid_neighbor", "+=", "1", "\n", "\n", "", "", "info_n", "=", "0.1", "\n", "trainers", "[", "node_id", "]", ".", "experience", "(", "obs_pot", "[", "node_id", "]", ",", "action_neighbor", ",", "new_obs_neighbor", "[", "node_id", "]", ",", "target_action_neighbor", ",", "rew", ")", "\n", "\n", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_darl1n.touch_path": [[196, 200], ["os.path.dirname", "any", "os.makedirs"], "function", ["None"], ["", "def", "touch_path", "(", "path", ")", ":", "\n", "    ", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "path", ")", "\n", "if", "any", "(", "dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirname", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_darl1n.save_weights": [[202, 207], ["os.path.join", "train_darl1n.touch_path", "trainers[].get_all_weights", "joblib.dump"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.touch_path", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg_neighbor.MADDPGAgentTrainer.get_all_weights"], ["", "", "def", "save_weights", "(", "trainers", ",", "index", ")", ":", "\n", "    ", "weight_file_name", "=", "os", ".", "path", ".", "join", "(", "arglist", ".", "save_dir", ",", "'agent%d.weights'", "%", "index", ")", "\n", "touch_path", "(", "weight_file_name", ")", "\n", "weight_dict", "=", "trainers", "[", "index", "]", ".", "get_all_weights", "(", ")", "\n", "joblib", ".", "dump", "(", "weight_dict", ",", "weight_file_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_darl1n.load_weights": [[209, 220], ["joblib.load", "trainers[].set_all_weights", "joblib.load", "trainers[].set_all_weights", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.load", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTargetPolicyTrainer.set_all_weights", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.load", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTargetPolicyTrainer.set_all_weights"], ["", "def", "load_weights", "(", "trainers", ",", "index", ")", ":", "\n", "# with open(arglist.save_dir + 'agent%d.weights' %i,'rb') as f:", "\n", "#     weight_dict=pickle.load(f)", "\n", "\n", "# Attention here", "\n", "    ", "if", "index", ">=", "arglist", ".", "num_adversaries", ":", "\n", "        ", "weight_dict", "=", "joblib", ".", "load", "(", "os", ".", "path", ".", "join", "(", "arglist", ".", "good_load_dir", ",", "'agent%d.weights'", "%", "(", "(", "index", "-", "arglist", ".", "num_adversaries", ")", "%", "arglist", ".", "last_good", "+", "arglist", ".", "last_adv", ")", ")", ")", "\n", "trainers", "[", "index", "]", ".", "set_all_weights", "(", "weight_dict", ")", "\n", "", "else", ":", "\n", "        ", "weight_dict", "=", "joblib", ".", "load", "(", "os", ".", "path", ".", "join", "(", "arglist", ".", "adv_load_dir", ",", "'agent%d.weights'", "%", "(", "index", "%", "arglist", ".", "last_adv", ")", ")", ")", "\n", "trainers", "[", "index", "]", ".", "set_all_weights", "(", "weight_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.proxy_train.TrainProxy.__init__": [[6, 11], ["multiprocessing.Process.__init__"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "kwargs", ",", "conn", ")", ":", "\n", "        ", "Process", ".", "__init__", "(", "self", ",", "daemon", "=", "False", ")", "\n", "\n", "self", ".", "kwargs", "=", "kwargs", "\n", "self", ".", "conn", "=", "conn", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.proxy_train.TrainProxy.run": [[12, 14], ["proxy_train.TrainProxy.conn.send", "train_helpers.train"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.train"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "self", ".", "conn", ".", "send", "(", "train", "(", "**", "self", ".", "kwargs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.proxy_train.proxy_train": [[16, 40], ["type", "multiprocessing.Pipe", "train_proxies.append", "conns.append", "train_proxy.start", "result.append", "train_proxy.join", "proxy_train.TrainProxy", "conn.recv"], "function", ["None"], ["", "", "def", "proxy_train", "(", "kwargs_list", ")", ":", "\n", "    ", "not_list", "=", "False", "\n", "if", "type", "(", "kwargs_list", ")", "!=", "list", ":", "\n", "        ", "not_list", "=", "True", "\n", "kwargs_list", "=", "[", "kwargs_list", "]", "\n", "\n", "", "train_proxies", "=", "[", "]", "\n", "conns", "=", "[", "]", "\n", "for", "kwargs", "in", "kwargs_list", ":", "\n", "        ", "conn_pair", "=", "Pipe", "(", ")", "\n", "train_proxies", ".", "append", "(", "TrainProxy", "(", "kwargs", ",", "conn_pair", "[", "0", "]", ")", ")", "\n", "conns", ".", "append", "(", "conn_pair", "[", "1", "]", ")", "\n", "\n", "", "for", "train_proxy", "in", "train_proxies", ":", "\n", "        ", "train_proxy", ".", "start", "(", ")", "\n", "\n", "", "result", "=", "[", "]", "\n", "for", "conn", "in", "conns", ":", "\n", "        ", "result", ".", "append", "(", "conn", ".", "recv", "(", ")", ")", "\n", "\n", "", "for", "train_proxy", "in", "train_proxies", ":", "\n", "        ", "train_proxy", ".", "join", "(", ")", "\n", "\n", "", "return", "result", "[", "0", "]", "if", "not_list", "else", "result", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.__init__": [[348, 386], ["multiprocessing.Process.__init__", "open"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "index", ",", "n", ",", "obs_batch_size", ",", "obs_shape", ",", "update_event", ",", "save_event", ",", "save_dir", ",", "load_dir", ",", "\n", "cached_weights", ",", "num_cpu", ",", "get_trainer", ",", "main_conn", ",", "obs_queue", ",", "env_conns", ",", "use_gpu", ",", "timeout", ",", "\n", "attention_mode", ",", "agent_sends", ",", "agent_recvs", ",", "tmp_file", ",", "obs_len", ",", "act_len", ",", "batch_size", ",", "train", ",", "load_one_side", ")", ":", "\n", "        ", "multiprocessing", ".", "Process", ".", "__init__", "(", "self", ",", "daemon", "=", "True", ")", "\n", "# self.sess = SESSIONS[i]", "\n", "# self.graph = GRAPHS[i]", "\n", "self", ".", "index", "=", "index", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "obs_batch_size", "=", "obs_batch_size", "\n", "self", ".", "obs_shape", "=", "obs_shape", "\n", "self", ".", "scope", "=", "\"agent_runner_{}\"", ".", "format", "(", "index", ")", "\n", "self", ".", "num_cpu", "=", "num_cpu", "\n", "self", ".", "get_trainer", "=", "get_trainer", "\n", "self", ".", "main_conn", "=", "main_conn", "\n", "self", ".", "obs_queue", "=", "obs_queue", "\n", "self", ".", "env_conns", "=", "env_conns", "\n", "self", ".", "save_dir", "=", "save_dir", "\n", "self", ".", "load_dir", "=", "load_dir", "\n", "self", ".", "trainer", "=", "None", "\n", "self", ".", "sess", "=", "None", "\n", "self", ".", "graph", "=", "None", "\n", "self", ".", "var_list", "=", "None", "\n", "self", ".", "cached_weights", "=", "cached_weights", "\n", "self", ".", "use_gpu", "=", "use_gpu", "\n", "self", ".", "update_event", "=", "update_event", "\n", "self", ".", "save_event", "=", "save_event", "\n", "self", ".", "sum_batch_size", "=", "None", "\n", "self", ".", "tot_batch", "=", "None", "\n", "self", ".", "timeout", "=", "timeout", "\n", "self", ".", "attention_mode", "=", "attention_mode", "\n", "self", ".", "agent_sends", "=", "agent_sends", "\n", "self", ".", "agent_recvs", "=", "agent_recvs", "\n", "self", ".", "tmp_file", "=", "open", "(", "tmp_file", ",", "\"rb\"", ")", "\n", "self", ".", "obs_len", "=", "obs_len", "\n", "self", ".", "act_len", "=", "act_len", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "load_one_side", "=", "load_one_side", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.build": [[389, 394], ["train_helpers.Agent.get_trainer", "tensorflow.get_collection", "tensorflow.get_collection"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.get_trainer"], ["", "def", "build", "(", "self", ")", ":", "\n", "        ", "self", ".", "trainer", "=", "self", ".", "get_trainer", "(", ")", "\n", "self", ".", "var_list", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ")", "\n", "self", ".", "trainable_var_list", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.restore_trainable_weights": [[395, 405], ["print", "train_helpers.Agent.sess.run", "train_helpers.name_encode", "restores.append", "v.assign"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.name_encode"], ["", "def", "restore_trainable_weights", "(", "self", ",", "weights", ")", ":", "\n", "        ", "print", "(", "'restore weights...................'", ")", "\n", "restores", "=", "[", "]", "\n", "for", "v", "in", "self", ".", "trainable_var_list", ":", "\n", "            ", "name", ",", "is_new", "=", "name_encode", "(", "v", ".", "name", ",", "convert", "=", "False", ")", "\n", "if", "name", "is", "None", ":", "\n", "                ", "continue", "\n", "", "w", "=", "weights", "[", "name", "]", "\n", "restores", ".", "append", "(", "v", ".", "assign", "(", "w", ")", ")", "\n", "", "self", ".", "sess", ".", "run", "(", "restores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.load_one_side_weight": [[406, 410], ["joblib.load", "train_helpers.Agent.trainer.set_all_weights", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.load", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTargetPolicyTrainer.set_all_weights"], ["", "def", "load_one_side_weight", "(", "self", ")", ":", "\n", "        ", "weight_dict", "=", "joblib", ".", "load", "(", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "adv_load_dir", ",", "'agent%d.weights'", "%", "self", ".", "index", ")", ")", "\n", "#print('load weight')", "\n", "self", ".", "trainer", ".", "set_all_weights", "(", "weight_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.action": [[412, 414], ["train_helpers.Agent.trainer.batch_action"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentMicroSharedTrainer.batch_action"], ["", "def", "action", "(", "self", ",", "obs", ")", ":", "\n", "        ", "return", "self", ".", "trainer", ".", "batch_action", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.get_attn": [[415, 417], ["train_helpers.Agent.trainer.batch_attn"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.maddpg.MADDPGAgentMicroSharedTrainer.batch_attn"], ["", "def", "get_attn", "(", "self", ",", "obs", ")", ":", "\n", "        ", "return", "self", ".", "trainer", ".", "batch_attn", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.target_action": [[418, 423], ["train_helpers.Agent.trainer.target_action", "train_helpers.Agent.trainer.batch_target_action"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.target_action", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.micro.policy_target_policy.PolicyTargetPolicyTrainer.batch_target_action"], ["", "def", "target_action", "(", "self", ",", "batch_obs", ")", ":", "\n", "# print(batch_obs)", "\n", "        ", "if", "self", ".", "load_one_side", ":", "\n", "            ", "return", "self", ".", "trainer", ".", "batch_target_action", "(", "batch_obs", ")", "\n", "", "return", "self", ".", "trainer", ".", "target_action", "(", "batch_obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent._run": [[425, 548], ["tensorflow.Graph", "tensorflow.Graph.as_default", "train_helpers.make_session", "train_helpers.Agent.build", "tensorflow.set_random_seed", "make_session.run", "train_helpers.Agent.main_conn.send", "train_helpers.Agent.main_conn.recv", "tensorflow.variables_initializer", "train_helpers.Agent.load_one_side_weight", "numpy.zeros", "train_helpers.Agent.save_event.is_set", "train_helpers.Agent.update_event.is_set", "train_helpers.Agent.restore_trainable_weights", "train_helpers.Agent.action", "range", "train_helpers.Agent.main_conn.send", "train_helpers.Agent.main_conn.recv", "train_helpers.Agent.main_conn.recv", "numpy.zeros", "numpy.zeros", "enumerate", "range", "train_helpers.Agent.target_action", "range", "train_helpers.Agent.update", "train_helpers.Agent.main_conn.send", "train_helpers.Agent.main_conn.recv", "range", "train_helpers.Agent.obs_queue.get", "train_helpers.Agent.get_attn", "train_helpers.Agent.save_weights", "print", "numpy.zeros", "numpy.zeros", "numpy.zeros", "train_helpers.Agent.tmp_file.seek", "train_helpers.bytes_to_exp", "range", "range", "range", "numpy.concatenate", "train_helpers.Agent.env_conns[].send", "train_helpers.Agent.env_conns[].send", "sum", "range", "range", "range", "target_obs.append", "train_helpers.Agent.agent_sends[].send", "range", "train_helpers.Agent.agent_recvs[].recv", "train_helpers.Agent.agent_sends[].send", "train_helpers.Agent.agent_recvs[].recv", "target_obs.append", "train_helpers.Agent.agent_sends[].send", "target_obs.append", "train_helpers.Agent.agent_sends[].send", "train_helpers.Agent.agent_recvs[].recv", "sum", "sum", "train_helpers.Agent.agent_recvs[].recv"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.make_session", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.build", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.load_one_side_weight", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.restore_trainable_weights", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.action", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.target_action", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.update", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.Uint8Input.get", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.get_attn", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.save_weights", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.bytes_to_exp", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.concatenate", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum"], ["", "def", "_run", "(", "self", ")", ":", "\n", "        ", "self", ".", "sum_batch_size", "=", "0", "\n", "self", ".", "tot_batch", "=", "0", "\n", "warned", "=", "False", "\n", "self", ".", "graph", "=", "graph", "=", "tf", ".", "Graph", "(", ")", "\n", "# n_envs = len(self.env_conns)", "\n", "with", "graph", ".", "as_default", "(", ")", ":", "\n", "            ", "self", ".", "sess", "=", "sess", "=", "make_session", "(", "graph", ",", "self", ".", "num_cpu", ")", "\n", "\n", "with", "sess", ":", "\n", "                ", "self", ".", "build", "(", ")", "\n", "if", "self", ".", "load_one_side", ":", "\n", "                    ", "self", ".", "trainer", ".", "session", "=", "sess", "\n", "", "tf", ".", "set_random_seed", "(", "self", ".", "index", ")", "\n", "sess", ".", "run", "(", "tf", ".", "variables_initializer", "(", "self", ".", "var_list", ")", ")", "\n", "#print(self.index, sess.run(self.var_list[0]))", "\n", "\n", "if", "self", ".", "load_one_side", ":", "\n", "                    ", "self", ".", "load_one_side_weight", "(", ")", "\n", "", "else", ":", "\n", "                    ", "if", "self", ".", "cached_weights", "is", "not", "None", ":", "\n", "                        ", "self", ".", "restore_trainable_weights", "(", "self", ".", "cached_weights", ")", "\n", "del", "self", ".", "cached_weights", "\n", "\n", "", "", "self", ".", "main_conn", ".", "send", "(", "None", ")", "\n", "self", ".", "main_conn", ".", "recv", "(", ")", "\n", "attention_mode", "=", "self", ".", "attention_mode", "\n", "agent_num_train", "=", "1", "\n", "while", "True", ":", "\n", "                    ", "obs_batch", "=", "np", ".", "zeros", "(", "shape", "=", "(", "self", ".", "obs_batch_size", ",", "*", "self", ".", "obs_shape", ")", ")", "\n", "receiver", "=", "[", "None", "for", "_", "in", "range", "(", "self", ".", "obs_batch_size", ")", "]", "\n", "cnt", "=", "0", "\n", "while", "cnt", "<", "self", ".", "obs_batch_size", ":", "\n", "                        ", "try", ":", "\n", "                            ", "obs_batch", "[", "cnt", "]", ",", "receiver", "[", "cnt", "]", "=", "self", ".", "obs_queue", ".", "get", "(", "block", "=", "True", ",", "timeout", "=", "self", ".", "timeout", ")", "\n", "cnt", "+=", "1", "\n", "", "except", "queue", ".", "Empty", ":", "\n", "                            ", "break", "\n", "\n", "", "", "self", ".", "sum_batch_size", "+=", "cnt", "\n", "self", ".", "tot_batch", "+=", "1", "\n", "if", "cnt", ">", "0", ":", "\n", "                        ", "action", "=", "self", ".", "action", "(", "obs_batch", "[", ":", "cnt", "]", ")", "\n", "if", "attention_mode", ":", "\n", "                            ", "good_attn", ",", "adv_attn", "=", "self", ".", "get_attn", "(", "obs_batch", "[", ":", "cnt", "]", ")", "\n", "", "for", "i", "in", "range", "(", "cnt", ")", ":", "\n", "                            ", "if", "attention_mode", ":", "\n", "                                ", "self", ".", "env_conns", "[", "receiver", "[", "i", "]", "]", ".", "send", "(", "(", "action", "[", "i", "]", ",", "good_attn", "[", "i", "]", ",", "adv_attn", "[", "i", "]", ")", ")", "\n", "", "else", ":", "\n", "                                ", "self", ".", "env_conns", "[", "receiver", "[", "i", "]", "]", ".", "send", "(", "action", "[", "i", "]", ")", "\n", "\n", "", "", "", "if", "self", ".", "save_event", ".", "is_set", "(", ")", ":", "\n", "                        ", "save_dirs", "=", "[", "self", ".", "save_dir", "]", "\n", "self", ".", "main_conn", ".", "send", "(", "self", ".", "save_weights", "(", "save_dirs", ")", ")", "\n", "self", ".", "main_conn", ".", "recv", "(", ")", "\n", "\n", "", "if", "self", ".", "update_event", ".", "is_set", "(", ")", ":", "\n", "                        ", "if", "self", ".", "sum_batch_size", "/", "self", ".", "tot_batch", "/", "self", ".", "obs_batch_size", "<", ".5", "and", "not", "warned", ":", "\n", "                            ", "warned", "=", "True", "\n", "print", "(", "\"Batch load insufficient ({:.2%})! Consider higher timeout!\"", ".", "format", "(", "self", ".", "sum_batch_size", "/", "self", ".", "tot_batch", "/", "self", ".", "obs_batch_size", ")", ")", "\n", "", "sampled_index", ",", "data_length", "=", "self", ".", "main_conn", ".", "recv", "(", ")", "\n", "total_numbers", "=", "sum", "(", "self", ".", "obs_len", ")", "+", "sum", "(", "self", ".", "act_len", ")", "+", "self", ".", "n", "+", "sum", "(", "self", ".", "obs_len", ")", "+", "self", ".", "n", "\n", "float_length", "=", "4", "\n", "assert", "total_numbers", "*", "float_length", "==", "data_length", "\n", "obs_n", "=", "[", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "obs_len", "[", "i", "]", ")", ")", "for", "i", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "action_n", "=", "[", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "act_len", "[", "i", "]", ")", ")", "for", "i", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "reward", "=", "np", ".", "zeros", "(", "self", ".", "batch_size", ")", "\n", "obs_next_n", "=", "[", "np", ".", "zeros", "(", "(", "self", ".", "batch_size", ",", "self", ".", "obs_len", "[", "i", "]", ")", ")", "for", "i", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "done", "=", "np", ".", "zeros", "(", "self", ".", "batch_size", ")", "\n", "\n", "for", "i", ",", "index", "in", "enumerate", "(", "sampled_index", ")", ":", "\n", "                            ", "self", ".", "tmp_file", ".", "seek", "(", "index", "*", "data_length", ")", "\n", "flat_data", "=", "bytes_to_exp", "(", "self", ".", "tmp_file", ",", "total_numbers", ")", "\n", "\n", "last", "=", "0", "\n", "for", "j", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "                                ", "l", "=", "self", ".", "obs_len", "[", "j", "]", "\n", "obs_n", "[", "j", "]", "[", "i", "]", ",", "last", "=", "flat_data", "[", "last", ":", "last", "+", "l", "]", ",", "last", "+", "l", "\n", "\n", "", "for", "j", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "                                ", "l", "=", "self", ".", "act_len", "[", "j", "]", "\n", "action_n", "[", "j", "]", "[", "i", "]", ",", "last", "=", "flat_data", "[", "last", ":", "last", "+", "l", "]", ",", "last", "+", "l", "\n", "\n", "", "reward", "[", "i", "]", "=", "flat_data", "[", "last", "+", "self", ".", "index", "]", "\n", "last", "+=", "self", ".", "n", "\n", "\n", "for", "j", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "                                ", "l", "=", "self", ".", "obs_len", "[", "j", "]", "\n", "obs_next_n", "[", "j", "]", "[", "i", "]", ",", "last", "=", "flat_data", "[", "last", ":", "last", "+", "l", "]", ",", "last", "+", "l", "\n", "\n", "", "done", "[", "i", "]", "=", "flat_data", "[", "last", "+", "self", ".", "index", "]", "\n", "assert", "last", "+", "self", ".", "n", "==", "total_numbers", "\n", "\n", "", "target_obs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "                            ", "if", "i", "<", "self", ".", "index", ":", "\n", "                                ", "target_obs", ".", "append", "(", "self", ".", "agent_recvs", "[", "i", "]", ".", "recv", "(", ")", ")", "\n", "self", ".", "agent_sends", "[", "i", "]", ".", "send", "(", "obs_next_n", "[", "i", "]", ")", "\n", "", "elif", "i", "==", "self", ".", "index", ":", "\n", "                                ", "target_obs", ".", "append", "(", "obs_next_n", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                                ", "self", ".", "agent_sends", "[", "i", "]", ".", "send", "(", "obs_next_n", "[", "i", "]", ")", "\n", "target_obs", ".", "append", "(", "self", ".", "agent_recvs", "[", "i", "]", ".", "recv", "(", ")", ")", "\n", "\n", "", "", "target_actions", "=", "self", ".", "target_action", "(", "np", ".", "concatenate", "(", "target_obs", ",", "axis", "=", "0", ")", ")", "\n", "\n", "target_action_n", "=", "[", "None", "for", "_", "in", "range", "(", "self", ".", "n", ")", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "                            ", "ta", "=", "target_actions", "[", "i", "*", "self", ".", "batch_size", ":", "(", "i", "+", "1", ")", "*", "self", ".", "batch_size", "]", "\n", "if", "i", "<", "self", ".", "index", ":", "\n", "                                ", "target_action_n", "[", "i", "]", "=", "self", ".", "agent_recvs", "[", "i", "]", ".", "recv", "(", ")", "\n", "self", ".", "agent_sends", "[", "i", "]", ".", "send", "(", "ta", ")", "\n", "", "elif", "i", "==", "self", ".", "index", ":", "\n", "                                ", "target_action_n", "[", "i", "]", "=", "ta", "\n", "", "else", ":", "\n", "                                ", "self", ".", "agent_sends", "[", "i", "]", ".", "send", "(", "ta", ")", "\n", "target_action_n", "[", "i", "]", "=", "self", ".", "agent_recvs", "[", "i", "]", ".", "recv", "(", ")", "\n", "\n", "", "", "self", ".", "update", "(", "(", "(", "obs_n", ",", "action_n", ",", "reward", ",", "obs_next_n", ",", "done", ")", ",", "target_action_n", ")", ")", "\n", "agent_num_train", "+=", "1", "\n", "\n", "self", ".", "main_conn", ".", "send", "(", "None", ")", "\n", "self", ".", "main_conn", ".", "recv", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.run": [[549, 553], ["tensorflow.device", "train_helpers.Agent._run"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent._run"], ["", "", "", "", "", "def", "run", "(", "self", ")", ":", "\n", "# self.server = tf.train.Server(CLUSTER, job_name=\"local%d\" % self.index, task_index=0)", "\n", "        ", "with", "tf", ".", "device", "(", "\"/cpu:0\"", ")", ":", "\n", "            ", "self", ".", "_run", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.save_weights": [[554, 568], ["train_helpers.Agent.sess.run", "os.path.join", "train_helpers.touch_path", "joblib.dump", "zip", "train_helpers.name_encode"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.touch_path", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.name_encode"], ["", "", "def", "save_weights", "(", "self", ",", "save_dirs", ")", ":", "\n", "        ", "import", "joblib", "\n", "if", "self", ".", "load_one_side", ":", "\n", "            ", "return", "\n", "", "all_vars", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "var_list", ")", "\n", "all_save_dict", "=", "{", "v", ".", "name", ":", "value", "for", "v", ",", "value", "in", "zip", "(", "self", ".", "var_list", ",", "all_vars", ")", "}", "\n", "trainable_save_dict", "=", "{", "name_encode", "(", "v", ".", "name", ",", "convert", "=", "False", ")", "[", "0", "]", ":", "all_save_dict", "[", "v", ".", "name", "]", "\n", "for", "v", "in", "self", ".", "trainable_var_list", "}", "\n", "for", "save_dir", "in", "save_dirs", ":", "\n", "            ", "trainable_save_path", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"agent{}.trainable-weights\"", ".", "format", "(", "self", ".", "index", ")", ")", "\n", "touch_path", "(", "trainable_save_path", ")", "\n", "joblib", ".", "dump", "(", "trainable_save_dict", ",", "trainable_save_path", ")", "\n", "\n", "", "return", "trainable_save_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.preupdate": [[569, 574], ["train_helpers.Agent.trainer.preupdate"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.preupdate"], ["", "def", "preupdate", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "load_one_side", ":", "\n", "            ", "return", "\n", "", "self", ".", "trainer", ".", "preupdate", "(", ")", "\n", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.update": [[575, 582], ["train_helpers.Agent.trainer.update"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.update"], ["", "def", "update", "(", "self", ",", "args", ")", ":", "\n", "# No update", "\n", "        ", "if", "self", ".", "load_one_side", ":", "\n", "            ", "return", "\n", "", "data", ",", "target_act_next_n", "=", "args", "\n", "# _obs_n, _action_n, _rewards, _obs_next_n, _dones = data", "\n", "self", ".", "trainer", ".", "update", "(", "data", ",", "target_act_next_n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.__init__": [[584, 595], ["multiprocessing.Process.__init__"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "index", ",", "max_len", ",", "actor_queues", ",", "actor_conns", ",", "main_conn", ",", "experience_queue", ",", "attention_mode", ")", ":", "\n", "        ", "multiprocessing", ".", "Process", ".", "__init__", "(", "self", ",", "daemon", "=", "True", ")", "\n", "self", ".", "env", "=", "env", "\n", "self", ".", "index", "=", "index", "\n", "self", ".", "n", "=", "env", ".", "n", "\n", "self", ".", "max_len", "=", "max_len", "\n", "self", ".", "actor_queues", "=", "actor_queues", "\n", "self", ".", "actor_conns", "=", "actor_conns", "\n", "self", ".", "main_conn", "=", "main_conn", "\n", "self", ".", "experience_queue", "=", "experience_queue", "\n", "self", ".", "attention_mode", "=", "attention_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run": [[597, 650], ["tensorflow.set_random_seed", "random.seed", "numpy.random.seed", "env.reset", "range", "range", "env.step", "range", "experience_queue.put", "train_helpers.Environment.main_conn.recv", "actor_queues[].put", "actor_conns[].recv", "action_n.append", "numpy.array", "numpy.array", "all", "train_helpers.Environment.main_conn.recv", "train_helpers.Environment.main_conn.recv", "good_attn_n.append", "adv_attn_n.append", "env.export_memory", "joblib.dump", "train_helpers.Environment.main_conn.send", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.reset", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.BatchMultiAgentEnv.step", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.multiagent.environment.MultiAgentEnv.export_memory"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "tf", ".", "set_random_seed", "(", "self", ".", "index", ")", "\n", "random", ".", "seed", "(", "self", ".", "index", ")", "\n", "np", ".", "random", ".", "seed", "(", "self", ".", "index", ")", "\n", "env", ",", "n", ",", "actor_queues", ",", "actor_conns", ",", "experience_queue", "=", "self", ".", "env", ",", "self", ".", "n", ",", "self", ".", "actor_queues", ",", "self", ".", "actor_conns", ",", "self", ".", "experience_queue", "\n", "num_epi", "=", "0", "\n", "attention_mode", "=", "self", ".", "attention_mode", "\n", "while", "True", ":", "\n", "            ", "obs_n", "=", "env", ".", "reset", "(", ")", "\n", "steps", "=", "0", "\n", "sum_reward_n", "=", "[", "0.", "]", "*", "n", "\n", "#print('Environment Reset')", "\n", "num_epi", "+=", "1", "\n", "while", "True", ":", "\n", "                ", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                    ", "actor_queues", "[", "i", "]", ".", "put", "(", "(", "obs_n", "[", "i", "]", ",", "self", ".", "index", ")", ")", "\n", "\n", "", "action_n", "=", "[", "]", "\n", "good_attn_n", "=", "[", "]", "\n", "adv_attn_n", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                    ", "recv", "=", "actor_conns", "[", "i", "]", ".", "recv", "(", ")", "\n", "if", "attention_mode", ":", "\n", "                        ", "action", ",", "good_attn", ",", "adv_attn", "=", "recv", "\n", "good_attn_n", ".", "append", "(", "good_attn", ")", "\n", "adv_attn_n", ".", "append", "(", "adv_attn", ")", "\n", "", "else", ":", "\n", "                        ", "action", "=", "recv", "\n", "", "action_n", ".", "append", "(", "action", ")", "\n", "", "new_obs_n", ",", "reward_n", ",", "done_n", ",", "info_n", "=", "env", ".", "step", "(", "action_n", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                    ", "sum_reward_n", "[", "i", "]", "+=", "reward_n", "[", "i", "]", "\n", "reward_n", "[", "i", "]", "=", "np", ".", "array", "(", "reward_n", "[", "i", "]", ")", "\n", "done_n", "[", "i", "]", "=", "np", ".", "array", "(", "done_n", "[", "i", "]", ")", "\n", "", "steps", "+=", "1", "\n", "end_of_episode", "=", "steps", ">", "self", ".", "max_len", "or", "all", "(", "done_n", ")", "\n", "#print(self.max_len)", "\n", "experience_queue", ".", "put", "(", "[", "self", ".", "index", ",", "obs_n", ",", "action_n", ",", "reward_n", ",", "new_obs_n", ",", "done_n", ",", "end_of_episode", ",", "sum_reward_n", ",", "info_n", ",", "good_attn_n", ",", "adv_attn_n", "]", ")", "\n", "if", "end_of_episode", ":", "\n", "                    ", "num_episodes", "=", "self", ".", "main_conn", ".", "recv", "(", ")", "\n", "if", "num_episodes", "is", "not", "None", ":", "\n", "                        ", "memory", "=", "env", ".", "export_memory", "(", ")", "\n", "joblib", ".", "dump", "(", "memory", ",", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "save_dir", ",", "\"episode-{}.gif-data\"", ".", "format", "(", "num_episodes", ")", ")", ")", "\n", "self", ".", "main_conn", ".", "send", "(", "None", ")", "\n", "\n", "", "", "pause", "=", "self", ".", "main_conn", ".", "recv", "(", ")", "\n", "if", "pause", ":", "\n", "                    ", "self", ".", "main_conn", ".", "recv", "(", ")", "\n", "", "if", "end_of_episode", ":", "\n", "                    ", "break", "\n", "", "else", ":", "\n", "                    ", "obs_n", "=", "new_obs_n", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.exp_to_bytes": [[54, 68], ["numpy.concatenate().astype", "np.concatenate().astype.tobytes", "len", "f.write", "type", "np.concatenate().astype.append", "numpy.concatenate", "np.concatenate().astype.append", "data_n.flatten", "data.flatten"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.concatenate"], ["def", "exp_to_bytes", "(", "f", ",", "all_data", ")", ":", "\n", "    ", "flat_data", "=", "[", "]", "\n", "for", "data_n", "in", "all_data", ":", "\n", "        ", "if", "type", "(", "data_n", ")", "==", "list", ":", "\n", "            ", "for", "data", "in", "data_n", ":", "\n", "                ", "flat_data", ".", "append", "(", "data", ".", "flatten", "(", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "flat_data", ".", "append", "(", "data_n", ".", "flatten", "(", ")", ")", "\n", "", "", "total_length", "=", "0", "\n", "flat_data", "=", "np", ".", "concatenate", "(", "flat_data", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "b", "=", "flat_data", ".", "tobytes", "(", ")", "\n", "total_length", "=", "len", "(", "b", ")", "\n", "f", ".", "write", "(", "b", ")", "\n", "return", "total_length", ",", "flat_data", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.bytes_to_exp": [[69, 72], ["numpy.fromfile"], "function", ["None"], ["", "def", "bytes_to_exp", "(", "f", ",", "n", ")", ":", "\n", "    ", "flat_data", "=", "np", ".", "fromfile", "(", "f", ",", "dtype", "=", "np", ".", "float32", ",", "count", "=", "n", ")", "\n", "return", "flat_data", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.format_time": [[73, 78], ["divmod", "divmod", "divmod", "int", "int", "int", "int"], "function", ["None"], ["", "def", "format_time", "(", "ti", ")", ":", "\n", "    ", "h", ",", "m", "=", "divmod", "(", "ti", ",", "3600", ")", "\n", "m", ",", "s", "=", "divmod", "(", "m", ",", "60", ")", "\n", "s", ",", "ms", "=", "divmod", "(", "s", ",", "1", ")", "\n", "return", "\"{:2d}h{:2d}m{:2d}s.{:3d}\"", ".", "format", "(", "int", "(", "h", ")", ",", "int", "(", "m", ")", ",", "int", "(", "s", ")", ",", "int", "(", "ms", "*", "1000", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.register_environment": [[79, 89], ["None"], "function", ["None"], ["", "def", "register_environment", "(", "n_good", ",", "n_adv", ",", "n_landmarks", ",", "n_food", ",", "n_forests", ",", "init_weights", ",", "id_mapping", "=", "None", ")", ":", "\n", "    ", "global", "N_GOOD", ",", "N_ADV", ",", "N_LAND", ",", "N_LANDMARKS", ",", "N_FOOD", ",", "N_FORESTS", ",", "ID_MAPPING", ",", "INIT_WEIGHTS", "\n", "N_GOOD", "=", "n_good", "\n", "N_ADV", "=", "n_adv", "\n", "N_LANDMARKS", "=", "n_landmarks", "\n", "N_FOOD", "=", "n_food", "\n", "N_FORESTS", "=", "n_forests", "\n", "N_LAND", "=", "N_LANDMARKS", "+", "N_FOOD", "+", "N_FORESTS", "\n", "INIT_WEIGHTS", "=", "init_weights", "\n", "ID_MAPPING", "=", "id_mapping", "\n", "# print(\"SHARE_WEIGHTS\", SHARE_WEIGHTS)", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.name_encode": [[90, 131], ["name.split", "range", "re.match", "re.match", "re.match", "train_helpers.name_encode.agent_decode"], "function", ["None"], ["", "def", "name_encode", "(", "name", ",", "convert", ")", ":", "\n", "# print(name)", "\n", "\n", "    ", "def", "agent_decode", "(", "name", ")", ":", "\n", "# if name == \"self\":", "\n", "#     return last", "\n", "        ", "match", "=", "re", ".", "match", "(", "r'agent_(\\d+)'", ",", "name", ")", "\n", "if", "match", ":", "\n", "            ", "return", "int", "(", "match", ".", "group", "(", "1", ")", ")", "\n", "", "match", "=", "re", ".", "match", "(", "r'good(\\d+)'", ",", "name", ")", "\n", "if", "match", ":", "\n", "            ", "return", "int", "(", "match", ".", "group", "(", "1", ")", ")", "+", "N_ADV", "\n", "", "match", "=", "re", ".", "match", "(", "r'adv(\\d+)'", ",", "name", ")", "\n", "if", "match", ":", "\n", "            ", "return", "int", "(", "match", ".", "group", "(", "1", ")", ")", "\n", "", "return", "name", "\n", "\n", "", "names", "=", "name", ".", "split", "(", "'/'", ")", "\n", "ret", "=", "[", "]", "\n", "for", "name", "in", "names", ":", "\n", "        ", "decoded", "=", "agent_decode", "(", "name", ")", "\n", "ret", ".", "append", "(", "decoded", ")", "\n", "", "last", "=", "None", "\n", "\n", "is_new", "=", "None", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "ret", ")", ")", ":", "\n", "        ", "if", "type", "(", "ret", "[", "i", "]", ")", "==", "int", ":", "\n", "            ", "if", "is_new", "is", "None", ":", "\n", "                ", "is_new", "=", "ret", "[", "i", "]", "in", "NEW_IDS", "\n", "", "if", "convert", ":", "\n", "                ", "ret", "[", "i", "]", "=", "ID_MAPPING", "[", "ret", "[", "i", "]", "]", "\n", "", "if", "last", "==", "ret", "[", "i", "]", ":", "\n", "# if last == ret[i]:", "\n", "                ", "return", "None", ",", "None", "\n", "", "else", ":", "\n", "                ", "last", "=", "ret", "[", "i", "]", "\n", "", "ret", "[", "i", "]", "=", "str", "(", "ret", "[", "i", "]", ")", "\n", "\n", "#print('/'.join(ret))", "\n", "", "", "return", "'/'", ".", "join", "(", "ret", ")", ",", "is_new", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.make_env": [[132, 149], ["scenario_class", "scenario_class.make_world", "MultiAgentEnv", "importlib.import_module"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.scenarios.simple_spread.Scenario.make_world"], ["", "def", "make_env", "(", "scenario_name", ",", "arglist", ",", "benchmark", "=", "False", ")", ":", "\n", "    ", "import", "importlib", "\n", "from", "mpe_local", ".", "multiagent", ".", "environment", "import", "MultiAgentEnv", "\n", "\n", "module_name", "=", "\"mpe_local.multiagent.scenarios.{}\"", ".", "format", "(", "scenario_name", ")", "\n", "scenario_class", "=", "importlib", ".", "import_module", "(", "module_name", ")", ".", "Scenario", "\n", "# load scenario from script", "\n", "# print(Scenario.__module__.__file__)", "\n", "scenario", "=", "scenario_class", "(", "n_good", "=", "N_GOOD", ",", "n_adv", "=", "N_ADV", ",", "n_landmarks", "=", "N_LANDMARKS", ",", "n_food", "=", "N_FOOD", ",", "n_forests", "=", "N_FORESTS", ",", "\n", "no_wheel", "=", "FLAGS", ".", "no_wheel", ",", "good_sight", "=", "FLAGS", ".", "good_sight", ",", "adv_sight", "=", "FLAGS", ".", "adv_sight", ",", "alpha", "=", "FLAGS", ".", "alpha", ",", "ratio", "=", "FLAGS", ".", "ratio", ",", "max_good_neighbor", "=", "N_GOOD", "+", "N_ADV", ",", "max_adv_neighbor", "=", "N_GOOD", "+", "N_ADV", ")", "\n", "# create world", "\n", "world", "=", "scenario", ".", "make_world", "(", ")", "\n", "# create multiagent environment", "\n", "env", "=", "MultiAgentEnv", "(", "world", ",", "scenario", ".", "reset_world", ",", "scenario", ".", "reward", ",", "\n", "scenario", ".", "observation", ",", "done_callback", "=", "scenario", ".", "done", ",", "info_callback", "=", "scenario", ".", "info", ",", "\n", "export_episode", "=", "FLAGS", ".", "save_gif_data", ")", "\n", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.make_session": [[150, 159], ["tensorflow.ConfigProto", "tensorflow.Session"], "function", ["None"], ["", "def", "make_session", "(", "graph", ",", "num_cpu", ")", ":", "\n", "# print(\"num_cpu:\", num_cpu)", "\n", "    ", "tf_config", "=", "tf", ".", "ConfigProto", "(", "\n", "# device_count={\"CPU\": num_cpu},", "\n", "inter_op_parallelism_threads", "=", "num_cpu", ",", "\n", "intra_op_parallelism_threads", "=", "num_cpu", ",", "\n", "log_device_placement", "=", "False", ")", "\n", "tf_config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "return", "tf", ".", "Session", "(", "graph", "=", "graph", ",", "config", "=", "tf_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.get_trainer": [[160, 188], ["trainer", "functools.partial", "functools.partial", "functools.partial", "functools.partial", "functools.partial"], "function", ["None"], ["", "def", "get_trainer", "(", "side", ",", "i", ",", "scope", ",", "env", ",", "obs_shape_n", ")", ":", "\n", "    ", "trainer", "=", "MADDPGAgentMicroSharedTrainer", "\n", "policy", "=", "FLAGS", ".", "adv_policy", "if", "side", "==", "\"adv\"", "else", "FLAGS", ".", "good_policy", "\n", "share_weights", "=", "FLAGS", ".", "adv_share_weights", "if", "side", "==", "\"adv\"", "else", "FLAGS", ".", "good_share_weights", "\n", "if", "policy", "==", "\"att-maddpg\"", ":", "\n", "        ", "if", "FLAGS", ".", "scenario", "==", "'ising'", ":", "\n", "            ", "model_p", "=", "partial", "(", "mlp_model_agent_p_ising", ",", "n_good", "=", "N_GOOD", ",", "n_adv", "=", "N_ADV", ",", "\n", "n_land", "=", "N_LAND", ",", "index", "=", "i", ",", "share_weights", "=", "share_weights", ")", "\n", "model_q", "=", "partial", "(", "mlp_model_agent_q_ising", ",", "n_good", "=", "N_GOOD", ",", "n_adv", "=", "N_ADV", ",", "\n", "n_land", "=", "N_LAND", ",", "index", "=", "i", ",", "share_weights", "=", "share_weights", ")", "\n", "", "else", ":", "\n", "            ", "model_p", "=", "partial", "(", "mlp_model_adv_p", "if", "side", "==", "\"adv\"", "else", "mlp_model_agent_p", ",", "n_good", "=", "N_GOOD", ",", "n_adv", "=", "N_ADV", ",", "\n", "n_land", "=", "N_LAND", ",", "index", "=", "i", ",", "share_weights", "=", "share_weights", ")", "\n", "model_q", "=", "partial", "(", "mlp_model_adv_q", "if", "side", "==", "\"adv\"", "else", "mlp_model_agent_q", ",", "n_good", "=", "N_GOOD", ",", "n_adv", "=", "N_ADV", ",", "\n", "n_land", "=", "N_LAND", ",", "index", "=", "i", ",", "share_weights", "=", "share_weights", ")", "\n", "\n", "", "", "elif", "policy", "==", "\"maddpg\"", ":", "\n", "        ", "model_p", "=", "mlp_model", "\n", "model_q", "=", "mlp_model", "\n", "", "elif", "policy", "==", "\"mean_field\"", ":", "\n", "        ", "model_p", "=", "mlp_model", "\n", "model_q", "=", "partial", "(", "mean_field_adv_q_model", "if", "side", "==", "\"adv\"", "else", "mean_field_agent_q_model", ",", "n_good", "=", "N_GOOD", ",", "\n", "n_adv", "=", "N_ADV", ",", "n_land", "=", "N_LAND", ",", "index", "=", "i", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "# print(obs_shape_n)", "\n", "", "num_units", "=", "(", "FLAGS", ".", "adv_num_units", "if", "side", "==", "\"adv\"", "else", "FLAGS", ".", "good_num_units", ")", "or", "FLAGS", ".", "num_units", "\n", "return", "trainer", "(", "scope", ",", "model_p", ",", "model_q", ",", "obs_shape_n", ",", "env", ".", "action_space", ",", "i", ",", "FLAGS", ",", "num_units", ",", "local_q_func", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.get_adv_trainer": [[189, 191], ["train_helpers.get_trainer"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.get_trainer"], ["", "def", "get_adv_trainer", "(", "i", ",", "scope", ",", "env", ",", "obs_shape_n", ")", ":", "\n", "    ", "return", "get_trainer", "(", "\"adv\"", ",", "i", ",", "scope", ",", "env", ",", "obs_shape_n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.get_good_trainer": [[192, 194], ["train_helpers.get_trainer"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.get_trainer"], ["", "def", "get_good_trainer", "(", "i", ",", "scope", ",", "env", ",", "obs_shape_n", ")", ":", "\n", "    ", "return", "get_trainer", "(", "\"good\"", ",", "i", ",", "scope", ",", "env", ",", "obs_shape_n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.get_one_side_trainer": [[195, 198], ["trainer"], "function", ["None"], ["", "def", "get_one_side_trainer", "(", "i", ",", "scope", ",", "env", ",", "obs_shape_n", ")", ":", "\n", "    ", "trainer", "=", "PolicyTargetPolicyTrainer", "\n", "return", "trainer", "(", "scope", ",", "mlp_model", ",", "obs_shape_n", ",", "None", ",", "env", ".", "action_space", ",", "i", ",", "FLAGS", ",", "local_q_func", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.show_size": [[199, 207], ["tensorflow.trainable_variables", "var.get_shape"], "function", ["None"], ["", "def", "show_size", "(", ")", ":", "\n", "    ", "s", "=", "0", "\n", "for", "var", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "        ", "shape", "=", "var", ".", "get_shape", "(", ")", "\n", "tot", "=", "1", "\n", "for", "dim", "in", "shape", ":", "\n", "            ", "tot", "*=", "dim", "\n", "", "s", "+=", "tot", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.touch_path": [[208, 212], ["os.path.dirname", "any", "os.makedirs"], "function", ["None"], ["", "", "def", "touch_path", "(", "path", ")", ":", "\n", "    ", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "path", ")", "\n", "if", "any", "(", "dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirname", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.load_weights": [[213, 217], ["CACHED_WEIGHTS.update", "joblib.load"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.update", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.load"], ["", "", "def", "load_weights", "(", "load_path", ")", ":", "\n", "    ", "import", "joblib", "\n", "global", "CACHED_WEIGHTS", "\n", "CACHED_WEIGHTS", ".", "update", "(", "joblib", ".", "load", "(", "load_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.clean": [[218, 226], ["d.items", "type"], "function", ["None"], ["", "def", "clean", "(", "d", ")", ":", "\n", "    ", "rd", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "d", ".", "items", "(", ")", ":", "\n", "        ", "if", "type", "(", "k", ")", "==", "tuple", ":", "\n", "            ", "rd", "[", "k", "[", "0", "]", "]", "=", "v", "\n", "", "else", ":", "\n", "            ", "rd", "[", "k", "]", "=", "v", "\n", "", "", "return", "rd", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.read_and_renumber": [[227, 236], ["joblib.load", "dict", "joblib.load.items", "name.split", "str", "str"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.load"], ["", "def", "read_and_renumber", "(", "path", ",", "i", ",", "j", ")", ":", "\n", "    ", "weights", "=", "joblib", ".", "load", "(", "path", ")", "\n", "new_weights", "=", "dict", "(", ")", "\n", "for", "name", ",", "v", "in", "weights", ".", "items", "(", ")", ":", "\n", "        ", "dname", "=", "name", ".", "split", "(", "'/'", ")", "\n", "assert", "dname", "[", "0", "]", "==", "str", "(", "i", ")", "\n", "dname", "[", "0", "]", "=", "str", "(", "j", ")", "\n", "new_weights", "[", "'/'", ".", "join", "(", "dname", ")", "]", "=", "v", "\n", "", "return", "new_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.load_all_weights": [[237, 252], ["int", "range", "range", "train_helpers.clean", "train_helpers.read_and_renumber", "clean.update", "train_helpers.read_and_renumber", "clean.update", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.clean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.read_and_renumber", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.update", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.read_and_renumber", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Agent.update"], ["", "def", "load_all_weights", "(", "load_dir1", ",", "load_dir2", ",", "n_adv", ",", "n_good", ",", "last_n_adv", ",", "last_n_good", ")", ":", "\n", "    ", "global", "CACHED_WEIGHTS", "\n", "CACHED_WEIGHTS", "=", "{", "}", "\n", "half_good", "=", "int", "(", "n_good", "/", "2", ")", "\n", "for", "j", "in", "range", "(", "n_adv", ",", "half_good", "+", "n_adv", ")", ":", "\n", "        ", "index", "=", "(", "j", "-", "n_adv", ")", "%", "(", "last_n_good", ")", "+", "last_n_adv", "\n", "new_weights", "=", "read_and_renumber", "(", "os", ".", "path", ".", "join", "(", "load_dir1", ",", "\"agent{}.trainable-weights\"", ".", "format", "(", "index", ")", ")", ",", "index", ",", "j", ")", "\n", "CACHED_WEIGHTS", ".", "update", "(", "new_weights", ")", "\n", "\n", "", "for", "j", "in", "range", "(", "n_adv", "+", "half_good", ",", "n_good", "+", "n_adv", ")", ":", "\n", "        ", "index", "=", "(", "j", "-", "n_adv", "-", "half_good", ")", "%", "(", "last_n_good", ")", "+", "last_n_adv", "\n", "new_weights", "=", "read_and_renumber", "(", "os", ".", "path", ".", "join", "(", "load_dir2", ",", "\"agent{}.trainable-weights\"", ".", "format", "(", "index", ")", ")", ",", "index", ",", "j", ")", "\n", "CACHED_WEIGHTS", ".", "update", "(", "new_weights", ")", "\n", "\n", "", "CACHED_WEIGHTS", "=", "clean", "(", "CACHED_WEIGHTS", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.parse_args": [[253, 336], ["argparse.ArgumentParser", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.add_argument", "add_extra_flags.parse_args", "add_extra_flags"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.parse_args", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.experiments.train_epc_select.add_extra_flags"], ["", "def", "parse_args", "(", "add_extra_flags", "=", "None", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "\"Reinforcement Learning experiments for multiagent environments\"", ")", "\n", "# Environment", "\n", "parser", ".", "add_argument", "(", "\"--scenario\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"grassland\"", ",", "\n", "help", "=", "\"name of the scenario script\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--map-size\"", ",", "type", "=", "str", ",", "default", "=", "\"normal\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-sight\"", ",", "type", "=", "float", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-sight\"", ",", "type", "=", "float", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "\"--no-wheel\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--alpha\"", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "\"--show-attention\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--max-episode-len\"", ",", "type", "=", "int", ",", "\n", "default", "=", "25", ",", "help", "=", "\"maximum episode length\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max-num-train\"", ",", "type", "=", "int", ",", "\n", "default", "=", "1000", ",", "help", "=", "\"maximum episode length\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-episodes\"", ",", "type", "=", "int", ",", "\n", "default", "=", "200000", ",", "help", "=", "\"number of episodes\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-adversaries\"", ",", "type", "=", "int", ",", "\n", "default", "=", "2", ",", "help", "=", "\"number of adversaries\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-good\"", ",", "type", "=", "int", ",", "\n", "default", "=", "2", ",", "help", "=", "\"number of good\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-agents\"", ",", "type", "=", "int", ",", "\n", "default", "=", "2", ",", "help", "=", "\"number of good\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-food\"", ",", "type", "=", "int", ",", "\n", "default", "=", "4", ",", "help", "=", "\"number of food\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-policy\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"maddpg\"", ",", "help", "=", "\"policy for good agents\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-policy\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"maddpg\"", ",", "help", "=", "\"policy of adversaries\"", ")", "\n", "# Core training parameters", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "type", "=", "float", ",", "default", "=", "1e-2", ",", "\n", "help", "=", "\"learning rate for Adam optimizer\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gamma\"", ",", "type", "=", "float", ",", "\n", "default", "=", "0.95", ",", "help", "=", "\"discount factor\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch-size\"", ",", "type", "=", "int", ",", "default", "=", "1024", ",", "\n", "help", "=", "\"number of episodes to optimize at the same time\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-units\"", ",", "type", "=", "int", ",", "default", "=", "64", ",", "\n", "help", "=", "\"number of units in the mlp\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-num-units\"", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-num-units\"", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--n-cpu-per-agent\"", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-share-weights\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-share-weights\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--use-gpu\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "# Checkpointing", "\n", "parser", ".", "add_argument", "(", "\"--save-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"./test/\"", ",", "\n", "help", "=", "\"directory in which training state and model should be saved\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train-rate\"", ",", "type", "=", "int", ",", "default", "=", "100", ",", "\n", "help", "=", "\"save model once every time this many episodes are completed\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save-rate\"", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "\n", "help", "=", "\"save model once every time this many episodes are completed\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoint-rate\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-load-dir1\"", ",", "type", "=", "str", ",", "default", "=", "\"./test/\"", ",", "\n", "help", "=", "\"directory in which training state and model are loaded\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-load-dir2\"", ",", "type", "=", "str", ",", "default", "=", "\"./test/\"", ",", "\n", "help", "=", "\"directory in which training state and model are loaded\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-load-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"./test/\"", ",", "\n", "help", "=", "\"directory in which training state and model are loaded\"", ")", "\n", "# Evaluation", "\n", "parser", ".", "add_argument", "(", "\"--restore\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--good-load-one-side\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--adv-load-one-side\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--display\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--save-gif-data\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--render-gif\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--benchmark\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--benchmark-iters\"", ",", "type", "=", "int", ",", "default", "=", "10000", ",", "\n", "help", "=", "\"number of iterations run for benchmarking\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--ratio\"", ",", "type", "=", "float", ",", "default", "=", "1", ")", "\n", "parser", ".", "add_argument", "(", "\"--n-envs\"", ",", "type", "=", "int", ",", "default", "=", "4", ")", "\n", "parser", ".", "add_argument", "(", "\"--save-summary\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--timeout\"", ",", "type", "=", "float", ",", "default", "=", "0.02", ")", "\n", "parser", ".", "add_argument", "(", "\"--max-num-neighbors\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"maximum number of  agents in neighbors area\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--last-adv\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"number of adv agents in the last stage\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--last-good\"", ",", "type", "=", "int", ",", "default", "=", "\"0\"", ",", "help", "=", "\"number of good agents in the last stage\"", ")", "\n", "\n", "if", "add_extra_flags", "is", "not", "None", ":", "\n", "        ", "parser", "=", "add_extra_flags", "(", "parser", ")", "\n", "\n", "", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.calc_size": [[337, 346], ["var.get_shape"], "function", ["None"], ["", "def", "calc_size", "(", "var_list", ")", ":", "\n", "    ", "s", "=", "0", "\n", "for", "var", "in", "var_list", ":", "\n", "        ", "shape", "=", "var", ".", "get_shape", "(", ")", "\n", "tot", "=", "1", "\n", "for", "dim", "in", "shape", ":", "\n", "            ", "tot", "*=", "dim", "\n", "", "s", "+=", "tot", "\n", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.train": [[651, 986], ["os.makedirs", "numpy.random.seed", "tensorflow.set_random_seed", "random.seed", "train_helpers.register_environment", "min", "train_helpers.make_env", "min", "multiprocessing.Queue", "multiprocessing.Event", "multiprocessing.Event", "range", "range", "print", "time.time", "print", "train_helpers.load_all_weights", "multiprocessing.Pipe", "multiprocessing.Pipe", "multiprocessing.Queue", "tempfile.TemporaryDirectory", "os.path.join", "open", "range", "range", "range", "time.time", "print", "range", "range", "print", "range", "range", "time.time", "time.time", "time.time", "print", "tensorflow.Session", "time.time", "int", "open", "time.time", "agents[].terminate", "agents[].join", "envs[].terminate", "envs[].join", "open", "pickle.dump", "open", "pickle.dump", "open", "pickle.dump", "open", "pickle.dump", "open", "pickle.dump", "json.dump", "range", "range", "multiprocessing.Pipe", "range", "range", "range", "multiprocessing.Pipe", "range", "range", "range", "range", "agents.append", "agents.append", "envs.append", "agents[].start", "[].recv", "envs[].start", "[].send", "tf.Session.as_default", "tensorflow.summary.merge_all", "tensorflow.summary.FileWriter", "tensorflow.variables_initializer().run", "numpy.zeros", "numpy.zeros", "time.time", "open.flush", "multiprocessing.Event.set", "time.time", "time.time", "range", "range", "multiprocessing.Event.clear", "range", "range", "train_helpers.format_time", "open", "range", "range", "train_helpers.Agent", "train_helpers.Agent", "train_helpers.Environment", "range", "tensorflow.name_scope", "range", "range", "range", "range", "range", "range", "multiprocessing.Queue.get", "good_attn[].append", "adv_attn[].append", "time.time", "multiprocessing.Event.set", "range", "multiprocessing.Event.clear", "range", "numpy.sum", "numpy.sum", "print", "global_train_time.append", "good_reward.append", "adv_reward.append", "train_time.append", "train_index.append", "time.time", "time.time", "random.sample", "[].send", "[].recv", "time.time", "[].send", "[].send", "time.time", "os.path.join", "time.time", "tensorflow.variables_initializer", "list", "list", "train_helpers.exp_to_bytes", "open.flush", "range", "[].send", "[].send", "[].send", "[].recv", "[].send", "time.time", "numpy.mean", "round", "range", "time.time", "functools.partial", "functools.partial", "train_helpers.make_env", "tensorflow.name_scope", "tensorflow.placeholder", "tensorflow.summary.scalar", "reward_phs.append", "tensorflow.name_scope", "tensorflow.placeholder", "tensorflow.summary.scalar", "reward_phs.append", "map", "map", "open.seek", "agent_rewards[].append", "numpy.array", "range", "min", "tensorflow.get_collection", "range", "range", "time.time", "time.time", "len", "range", "range", "range", "len", "range", "range", "range", "range", "x.tolist", "x.tolist"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.register_environment", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.min", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.make_env", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.min", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.load_all_weights", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.Environment.run", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.clear", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.format_time", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.Uint8Input.get", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.clear", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.sum", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.exp_to_bytes", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.mean", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.train_helpers.make_env", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.min"], ["", "", "", "", "", "def", "train", "(", "arglist", ",", "init_weight_config", "=", "None", ",", "cached_weights", "=", "None", ")", ":", "\n", "    ", "global", "FLAGS", ",", "CACHED_WEIGHTS", "\n", "if", "cached_weights", "is", "not", "None", ":", "\n", "        ", "CACHED_WEIGHTS", "=", "cached_weights", "\n", "", "FLAGS", "=", "arglist", "\n", "os", ".", "makedirs", "(", "FLAGS", ".", "save_dir", ",", "exist_ok", "=", "True", ")", "\n", "seed", "=", "arglist", ".", "seed", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "tf", ".", "set_random_seed", "(", "seed", ")", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "# assert FLAGS.train_rate % FLAGS.n_envs ==  0", "\n", "frames", "=", "[", "]", "\n", "n", "=", "FLAGS", ".", "num_adversaries", "+", "FLAGS", ".", "num_good", "\n", "old_n", "=", "None", "\n", "id_mapping", "=", "None", "\n", "old_load_dir", "=", "None", "\n", "curriculum", "=", "init_weight_config", "is", "not", "None", "\n", "\n", "if", "FLAGS", ".", "restore", ":", "\n", "        ", "print", "(", "'Loading weights from last stage...'", ")", "\n", "load_all_weights", "(", "FLAGS", ".", "good_load_dir1", ",", "FLAGS", ".", "good_load_dir2", ",", "FLAGS", ".", "num_adversaries", ",", "FLAGS", ".", "num_good", ",", "FLAGS", ".", "last_adv", ",", "FLAGS", ".", "last_good", ")", "\n", "\n", "", "register_environment", "(", "n_good", "=", "FLAGS", ".", "num_good", ",", "n_adv", "=", "FLAGS", ".", "num_adversaries", ",", "n_landmarks", "=", "0", ",", "n_food", "=", "FLAGS", ".", "num_food", ",", "\n", "n_forests", "=", "0", ",", "init_weights", "=", "curriculum", ",", "id_mapping", "=", "id_mapping", ")", "\n", "\n", "n_envs", "=", "min", "(", "FLAGS", ".", "n_envs", ",", "FLAGS", ".", "num_episodes", ")", "\n", "env", "=", "make_env", "(", "FLAGS", ".", "scenario", ",", "FLAGS", ",", "FLAGS", ".", "benchmark", ")", "\n", "assert", "n", "==", "N_ADV", "+", "N_GOOD", "\n", "\n", "obs_shape_n", "=", "[", "env", ".", "observation_space", "[", "i", "]", ".", "shape", "for", "i", "in", "range", "(", "n", ")", "]", "\n", "action_shape_n", "=", "[", "env", ".", "action_space", "[", "i", "]", ".", "n", "for", "i", "in", "range", "(", "n", ")", "]", "\n", "num_adversaries", "=", "min", "(", "n", ",", "FLAGS", ".", "num_adversaries", ")", "\n", "\n", "agents", "=", "[", "]", "\n", "envs", "=", "[", "]", "\n", "\n", "agent_env_conns", "=", "[", "[", "multiprocessing", ".", "Pipe", "(", ")", "for", "_", "in", "range", "(", "n_envs", ")", "]", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "main_agent_conns", "=", "[", "multiprocessing", ".", "Pipe", "(", ")", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "main_env_conns", "=", "[", "multiprocessing", ".", "Pipe", "(", ")", "for", "_", "in", "range", "(", "n_envs", ")", "]", "\n", "agent_agent_conns", "=", "[", "[", "multiprocessing", ".", "Pipe", "(", ")", "for", "_", "in", "range", "(", "n", ")", "]", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "experience_queue", "=", "multiprocessing", ".", "Queue", "(", ")", "\n", "obs_queues", "=", "[", "multiprocessing", ".", "Queue", "(", ")", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "update_event", "=", "multiprocessing", ".", "Event", "(", ")", "\n", "save_event", "=", "multiprocessing", ".", "Event", "(", ")", "\n", "update_cnt", "=", "0", "\n", "\n", "assert", "GOOD_SHARE_WEIGHTS", "==", "False", "\n", "assert", "ADV_SHARE_WEIGHTS", "==", "False", "\n", "\n", "obs_len", "=", "[", "obs_shape_n", "[", "i", "]", "[", "0", "]", "for", "i", "in", "range", "(", "n", ")", "]", "\n", "act_len", "=", "[", "action_shape_n", "[", "i", "]", "for", "i", "in", "range", "(", "n", ")", "]", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "tmp_dir", ":", "\n", "        ", "tmp_file_name", "=", "os", ".", "path", ".", "join", "(", "tmp_dir", ",", "\"buffer\"", ")", "\n", "tmp_file", "=", "open", "(", "tmp_file_name", ",", "\"w+b\"", ")", "\n", "\n", "for", "i", "in", "range", "(", "num_adversaries", ")", ":", "\n", "            ", "agents", ".", "append", "(", "Agent", "(", "index", "=", "i", ",", "\n", "n", "=", "n", ",", "\n", "obs_batch_size", "=", "FLAGS", ".", "n_envs", ",", "\n", "obs_shape", "=", "obs_shape_n", "[", "i", "]", ",", "\n", "update_event", "=", "update_event", ",", "\n", "save_event", "=", "save_event", ",", "\n", "save_dir", "=", "FLAGS", ".", "save_dir", ",", "\n", "load_dir", "=", "FLAGS", ".", "adv_load_dir", "if", "FLAGS", ".", "restore", "else", "None", ",", "\n", "cached_weights", "=", "CACHED_WEIGHTS", "if", "len", "(", "CACHED_WEIGHTS", ")", ">", "0", "else", "None", ",", "\n", "main_conn", "=", "main_agent_conns", "[", "i", "]", "[", "1", "]", ",", "\n", "obs_queue", "=", "obs_queues", "[", "i", "]", ",", "\n", "env_conns", "=", "[", "agent_env_conns", "[", "i", "]", "[", "j", "]", "[", "0", "]", "for", "j", "in", "range", "(", "n_envs", ")", "]", ",", "\n", "num_cpu", "=", "FLAGS", ".", "n_cpu_per_agent", ",", "\n", "get_trainer", "=", "partial", "(", "get_one_side_trainer", ",", "i", "=", "i", ",", "scope", "=", "\"adv{}\"", ".", "format", "(", "i", ")", ",", "\n", "env", "=", "env", ",", "obs_shape_n", "=", "obs_shape_n", ")", ",", "\n", "use_gpu", "=", "FLAGS", ".", "use_gpu", ",", "\n", "timeout", "=", "FLAGS", ".", "timeout", ",", "\n", "attention_mode", "=", "FLAGS", ".", "show_attention", ",", "\n", "agent_sends", "=", "[", "agent_agent_conns", "[", "i", "]", "[", "j", "]", "[", "0", "]", "for", "j", "in", "range", "(", "n", ")", "]", ",", "\n", "agent_recvs", "=", "[", "agent_agent_conns", "[", "j", "]", "[", "i", "]", "[", "1", "]", "for", "j", "in", "range", "(", "n", ")", "]", ",", "\n", "tmp_file", "=", "tmp_file_name", ",", "\n", "obs_len", "=", "obs_len", ",", "\n", "act_len", "=", "act_len", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "\n", "train", "=", "FLAGS", ".", "train_rate", ">", "0", ",", "\n", "load_one_side", "=", "FLAGS", ".", "adv_load_one_side", "\n", ")", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "num_adversaries", ",", "n", ")", ":", "\n", "            ", "agents", ".", "append", "(", "Agent", "(", "index", "=", "i", ",", "\n", "n", "=", "n", ",", "\n", "obs_batch_size", "=", "FLAGS", ".", "n_envs", ",", "\n", "obs_shape", "=", "obs_shape_n", "[", "i", "]", ",", "\n", "update_event", "=", "update_event", ",", "\n", "save_event", "=", "save_event", ",", "\n", "save_dir", "=", "FLAGS", ".", "save_dir", ",", "\n", "load_dir", "=", "FLAGS", ".", "good_load_dir1", "if", "FLAGS", ".", "restore", "else", "None", ",", "\n", "cached_weights", "=", "CACHED_WEIGHTS", "if", "len", "(", "CACHED_WEIGHTS", ")", ">", "0", "else", "None", ",", "\n", "main_conn", "=", "main_agent_conns", "[", "i", "]", "[", "1", "]", ",", "\n", "obs_queue", "=", "obs_queues", "[", "i", "]", ",", "\n", "env_conns", "=", "[", "agent_env_conns", "[", "i", "]", "[", "j", "]", "[", "0", "]", "for", "j", "in", "range", "(", "n_envs", ")", "]", ",", "\n", "num_cpu", "=", "FLAGS", ".", "n_cpu_per_agent", ",", "\n", "get_trainer", "=", "partial", "(", "get_good_trainer", ",", "i", "=", "i", ",", "scope", "=", "\"good{}\"", ".", "format", "(", "i", "-", "num_adversaries", ")", ",", "\n", "env", "=", "env", ",", "obs_shape_n", "=", "obs_shape_n", ")", ",", "\n", "use_gpu", "=", "FLAGS", ".", "use_gpu", ",", "\n", "timeout", "=", "FLAGS", ".", "timeout", ",", "\n", "attention_mode", "=", "FLAGS", ".", "show_attention", ",", "\n", "agent_sends", "=", "[", "agent_agent_conns", "[", "i", "]", "[", "j", "]", "[", "0", "]", "for", "j", "in", "range", "(", "n", ")", "]", ",", "\n", "agent_recvs", "=", "[", "agent_agent_conns", "[", "j", "]", "[", "i", "]", "[", "1", "]", "for", "j", "in", "range", "(", "n", ")", "]", ",", "\n", "tmp_file", "=", "tmp_file_name", ",", "\n", "obs_len", "=", "obs_len", ",", "\n", "act_len", "=", "act_len", ",", "\n", "batch_size", "=", "FLAGS", ".", "batch_size", ",", "\n", "train", "=", "FLAGS", ".", "train_rate", ">", "0", ",", "\n", "load_one_side", "=", "FLAGS", ".", "good_load_one_side", "\n", ")", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "n_envs", ")", ":", "\n", "            ", "envs", ".", "append", "(", "Environment", "(", "env", "=", "make_env", "(", "FLAGS", ".", "scenario", ",", "FLAGS", ",", "FLAGS", ".", "benchmark", ")", ",", "\n", "index", "=", "i", ",", "\n", "max_len", "=", "FLAGS", ".", "max_episode_len", ",", "\n", "actor_queues", "=", "obs_queues", ",", "\n", "actor_conns", "=", "[", "agent_env_conns", "[", "j", "]", "[", "i", "]", "[", "1", "]", "for", "j", "in", "range", "(", "n", ")", "]", ",", "\n", "main_conn", "=", "main_env_conns", "[", "i", "]", "[", "1", "]", ",", "\n", "experience_queue", "=", "experience_queue", ",", "\n", "attention_mode", "=", "FLAGS", ".", "show_attention", ")", ")", "\n", "\n", "", "tmp0", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"Starting building graph & initialization & restoring...\"", ")", "\n", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "agents", "[", "i", "]", ".", "start", "(", ")", "\n", "", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "main_agent_conns", "[", "i", "]", "[", "0", "]", ".", "recv", "(", ")", "\n", "\n", "", "print", "(", "\"Building graph & initialization & restoring done in {0:.2f} seconds\"", ".", "format", "(", "time", ".", "time", "(", ")", "-", "tmp0", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_envs", ")", ":", "\n", "            ", "envs", "[", "i", "]", ".", "start", "(", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "            ", "main_agent_conns", "[", "i", "]", "[", "0", "]", ".", "send", "(", "None", ")", "\n", "\n", "", "action_time", "=", "0.0", "\n", "target_action_time", "=", "0.0", "\n", "env_time", "=", "0.0", "\n", "experience_time", "=", "0.0", "\n", "sample_time", "=", "0.0", "\n", "preupdate_time", "=", "0.0", "\n", "update_time", "=", "0.0", "\n", "pure_update_time", "=", "0.0", "\n", "real_train_time", "=", "[", "0.0", "]", "*", "5", "\n", "ground_global_time", "=", "time", ".", "time", "(", ")", "\n", "global_train_time", "=", "[", "]", "\n", "good_reward", "=", "[", "]", "\n", "adv_reward", "=", "[", "]", "\n", "train_time", "=", "[", "]", "\n", "train_index", "=", "[", "]", "\n", "episode_step", "=", "0", "\n", "num_episodes", "=", "0", "\n", "train_step", "=", "0", "\n", "\n", "t_start", "=", "time", ".", "time", "(", ")", "\n", "\n", "agent_rewards", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n", ")", "]", "\n", "\n", "train_start_time", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"Start training!\"", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "\n", "last_update_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "with", "sess", ".", "as_default", "(", ")", ":", "\n", "            ", "with", "tf", ".", "name_scope", "(", "'summaries'", ")", ":", "\n", "                ", "reward_phs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "FLAGS", ".", "num_adversaries", ")", ":", "\n", "                    ", "with", "tf", ".", "name_scope", "(", "'adv%d'", "%", "i", ")", ":", "\n", "                        ", "reward_ph", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "]", ",", "name", "=", "'reward'", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'reward'", ",", "reward_ph", ")", "\n", "reward_phs", ".", "append", "(", "reward_ph", ")", "\n", "", "", "for", "i", "in", "range", "(", "FLAGS", ".", "num_adversaries", ",", "n", ")", ":", "\n", "                    ", "with", "tf", ".", "name_scope", "(", "'good%d'", "%", "(", "i", "-", "FLAGS", ".", "num_adversaries", ")", ")", ":", "\n", "                        ", "reward_ph", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "]", ",", "name", "=", "'reward'", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'reward'", ",", "reward_ph", ")", "\n", "reward_phs", ".", "append", "(", "reward_ph", ")", "\n", "\n", "", "", "", "summaries", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "FLAGS", ".", "save_dir", "+", "'/summaries'", ",", "sess", ".", "graph", ")", "\n", "tf", ".", "variables_initializer", "(", "var_list", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "'summaries'", ")", ")", ".", "run", "(", ")", "\n", "\n", "", "num_steps_ahead", "=", "n_envs", "\n", "num_steps", "=", "0", "\n", "\n", "time_grass", "=", "[", "np", ".", "zeros", "(", "n", ")", "for", "_", "in", "range", "(", "n_envs", ")", "]", "\n", "time_live", "=", "[", "np", ".", "zeros", "(", "n", ")", "for", "_", "in", "range", "(", "n_envs", ")", "]", "\n", "\n", "good_attn", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_envs", ")", "]", "\n", "adv_attn", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_envs", ")", "]", "\n", "\n", "time_grass_all", "=", "[", "]", "\n", "time_live_all", "=", "[", "]", "\n", "\n", "exp_len", "=", "None", "\n", "BUFFER_SIZE", "=", "int", "(", "1e6", ")", "\n", "buffer_len", "=", "0", "\n", "\n", "test_tmp_file", "=", "open", "(", "tmp_file_name", ",", "\"rb\"", ")", "\n", "\n", "record", "=", "True", "\n", "train_num", "=", "0", "\n", "t_ep", "=", "time", ".", "time", "(", ")", "\n", "while", "True", ":", "\n", "            ", "cnt", "=", "0", "\n", "stop", "=", "False", "\n", "c_env", "=", "0", "\n", "while", "cnt", "<", "n_envs", ":", "\n", "                ", "index", ",", "obs_n", ",", "action_n", ",", "reward_n", ",", "new_obs_n", ",", "done_n", ",", "end_of_episode", ",", "sum_reward_n", ",", "info_n", ",", "good_attn_n", ",", "adv_attn_n", "=", "experience_queue", ".", "get", "(", ")", "\n", "good_attn", "[", "index", "]", ".", "append", "(", "list", "(", "map", "(", "lambda", "x", ":", "x", ".", "tolist", "(", ")", ",", "good_attn_n", ")", ")", ")", "\n", "adv_attn", "[", "index", "]", ".", "append", "(", "list", "(", "map", "(", "lambda", "x", ":", "x", ".", "tolist", "(", ")", ",", "adv_attn_n", ")", ")", ")", "\n", "no_grass", "=", "1", "\n", "if", "FLAGS", ".", "train_rate", ">", "0", ":", "\n", "                    ", "exp_len", ",", "flat_data", "=", "exp_to_bytes", "(", "tmp_file", ",", "[", "obs_n", ",", "action_n", ",", "reward_n", ",", "new_obs_n", ",", "done_n", "]", ")", "\n", "tmp_file", ".", "flush", "(", ")", "\n", "buffer_len", "+=", "1", "\n", "if", "buffer_len", "%", "BUFFER_SIZE", "==", "0", ":", "\n", "                        ", "tmp_file", ".", "seek", "(", "0", ")", "\n", "\n", "", "", "num_steps", "+=", "1", "\n", "if", "end_of_episode", ":", "\n", "                    ", "num_episodes", "+=", "1", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                        ", "agent_rewards", "[", "i", "]", ".", "append", "(", "sum_reward_n", "[", "i", "]", ")", "\n", "", "good_attn", "[", "index", "]", "=", "[", "]", "\n", "adv_attn", "[", "index", "]", "=", "[", "]", "\n", "# episode_rewards.append(sum(sum_reward_n[i]))", "\n", "main_env_conns", "[", "index", "]", "[", "0", "]", ".", "send", "(", "None", ")", "\n", "\n", "if", "FLAGS", ".", "train_rate", "==", "0", ":", "\n", "                        ", "if", "num_episodes", ">=", "FLAGS", ".", "num_episodes", ":", "\n", "                            ", "stop", "=", "True", "\n", "break", "\n", "\n", "", "", "if", "train_num", ">", "FLAGS", ".", "max_num_train", ":", "\n", "                        ", "stop", "=", "True", "\n", "break", "\n", "\n", "# print(num_steps_ahead, len(replay_buffer))", "\n", "", "", "if", "FLAGS", ".", "train_rate", ">", "0", "and", "num_steps_ahead", "%", "FLAGS", ".", "train_rate", "==", "0", "and", "buffer_len", ">=", "FLAGS", ".", "batch_size", "*", "5", ":", "\n", "# print(\"Ready to train for env {}\".format(i))", "\n", "                    ", "main_env_conns", "[", "index", "]", "[", "0", "]", ".", "send", "(", "True", ")", "\n", "cnt", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "main_env_conns", "[", "index", "]", "[", "0", "]", ".", "send", "(", "False", ")", "\n", "num_steps_ahead", "+=", "1", "\n", "\n", "", "", "if", "stop", ":", "\n", "                ", "break", "\n", "\n", "", "assert", "num_steps", "==", "num_steps_ahead", "\n", "\n", "if", "FLAGS", ".", "save_rate", ">", "0", "and", "train_num", ">", "0", "and", "train_num", "%", "FLAGS", ".", "save_rate", "==", "0", ":", "\n", "                ", "tmp0", "=", "time", ".", "time", "(", ")", "\n", "save_event", ".", "set", "(", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                    ", "main_agent_conns", "[", "i", "]", "[", "0", "]", ".", "recv", "(", ")", "\n", "", "save_event", ".", "clear", "(", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                    ", "main_agent_conns", "[", "i", "]", "[", "0", "]", ".", "send", "(", "None", ")", "\n", "\n", "", "this_time", "=", "time", ".", "time", "(", ")", "-", "t_ep", "\n", "agent_mean_rew", "=", "[", "np", ".", "mean", "(", "np", ".", "array", "(", "agent_rewards", "[", "i", "]", "[", "-", "10", ":", "]", ")", ")", "for", "i", "in", "range", "(", "n", ")", "]", "\n", "good", "=", "np", ".", "sum", "(", "[", "agent_mean_rew", "[", "i", "]", "for", "i", "in", "range", "(", "FLAGS", ".", "num_adversaries", ",", "n", ")", "]", ")", "\n", "adv", "=", "np", ".", "sum", "(", "[", "agent_mean_rew", "[", "i", "]", "for", "i", "in", "range", "(", "FLAGS", ".", "num_adversaries", ")", "]", ")", "\n", "print", "(", "\"{} train, interval time: {:.2f}, global time: {:.2f}\"", ".", "format", "(", "train_num", ",", "this_time", ",", "time", ".", "time", "(", ")", "-", "ground_global_time", ")", ",", "\"good reward:\"", ",", "good", ",", "\"adv reward\"", ",", "adv", ")", "\n", "global_train_time", ".", "append", "(", "round", "(", "time", ".", "time", "(", ")", "-", "ground_global_time", ",", "3", ")", ")", "\n", "good_reward", ".", "append", "(", "good", ")", "\n", "adv_reward", ".", "append", "(", "adv", ")", "\n", "train_time", ".", "append", "(", "this_time", ")", "\n", "train_index", ".", "append", "(", "train_num", ")", "\n", "t_ep", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "t_update", "=", "time", ".", "time", "(", ")", "\n", "tmp_file", ".", "flush", "(", ")", "\n", "update_event", ".", "set", "(", ")", "\n", "train_num", "+=", "1", "\n", "tmp0", "=", "time", ".", "time", "(", ")", "\n", "sample_time", "+=", "time", ".", "time", "(", ")", "-", "tmp0", "\n", "tmp0", "=", "time", ".", "time", "(", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                ", "indices", "=", "random", ".", "sample", "(", "range", "(", "min", "(", "buffer_len", ",", "BUFFER_SIZE", ")", ")", ",", "FLAGS", ".", "batch_size", ")", "\n", "main_agent_conns", "[", "i", "]", "[", "0", "]", ".", "send", "(", "(", "indices", ",", "exp_len", ")", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                ", "main_agent_conns", "[", "i", "]", "[", "0", "]", ".", "recv", "(", ")", "\n", "", "pure_update_time", "+=", "time", ".", "time", "(", ")", "-", "tmp0", "\n", "update_event", ".", "clear", "(", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "                ", "main_agent_conns", "[", "i", "]", "[", "0", "]", ".", "send", "(", "None", ")", "\n", "", "for", "i", "in", "range", "(", "n_envs", ")", ":", "\n", "                ", "main_env_conns", "[", "i", "]", "[", "0", "]", ".", "send", "(", "None", ")", "\n", "", "num_steps_ahead", "+=", "n_envs", "\n", "update_time", "+=", "time", ".", "time", "(", ")", "-", "t_update", "\n", "\n", "", "", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "        ", "agents", "[", "i", "]", ".", "terminate", "(", ")", "\n", "agents", "[", "i", "]", ".", "join", "(", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "n_envs", ")", ":", "\n", "        ", "envs", "[", "i", "]", ".", "terminate", "(", ")", "\n", "envs", "[", "i", "]", ".", "join", "(", ")", "\n", "\n", "", "good_file_name", "=", "FLAGS", ".", "save_dir", "+", "'/good_agent.pkl'", "\n", "with", "open", "(", "good_file_name", ",", "'wb'", ")", "as", "fp", ":", "\n", "        ", "pickle", ".", "dump", "(", "good_reward", ",", "fp", ")", "\n", "\n", "", "adv_file_name", "=", "FLAGS", ".", "save_dir", "+", "'/adv_agent.pkl'", "\n", "with", "open", "(", "adv_file_name", ",", "'wb'", ")", "as", "fp", ":", "\n", "        ", "pickle", ".", "dump", "(", "adv_reward", ",", "fp", ")", "\n", "\n", "", "time_file_name", "=", "FLAGS", ".", "save_dir", "+", "'/train_time.pkl'", "\n", "with", "open", "(", "time_file_name", ",", "'wb'", ")", "as", "fp", ":", "\n", "        ", "pickle", ".", "dump", "(", "train_time", ",", "fp", ")", "\n", "\n", "", "train_index_file_name", "=", "FLAGS", ".", "save_dir", "+", "'/train_index.pkl'", "\n", "with", "open", "(", "train_index_file_name", ",", "'wb'", ")", "as", "fp", ":", "\n", "        ", "pickle", ".", "dump", "(", "train_index", ",", "fp", ")", "\n", "\n", "", "global_time_file", "=", "arglist", ".", "save_dir", "+", "'/global_time.pkl'", "\n", "with", "open", "(", "global_time_file", ",", "'wb'", ")", "as", "fp", ":", "\n", "        ", "pickle", ".", "dump", "(", "global_train_time", ",", "fp", ")", "\n", "\n", "", "print", "(", "\"Total training time: {}.\"", ".", "format", "(", "format_time", "(", "time", ".", "time", "(", ")", "-", "t_start", ")", ")", ")", "\n", "report", "=", "{", "\"agent_rewards\"", ":", "agent_rewards", "}", "\n", "train_end_time", "=", "time", ".", "time", "(", ")", "\n", "if", "FLAGS", ".", "train_rate", "==", "0", ":", "\n", "        ", "json", ".", "dump", "(", "report", ",", "open", "(", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "save_dir", ",", "\"report.json\"", ")", ",", "\"w\"", ")", ")", "\n", "", "return", "report", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.__init__": [[7, 23], ["int", "range", "range"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "n_items", ",", "n_agents", ")", ":", "\n", "        ", "\"\"\"Create Prioritized Replay buffer.\n\n        Parameters\n        ----------\n        size: int\n            Max number of transitions to store in the buffer. When the buffer\n            overflows the old memories are dropped.\n        \"\"\"", "\n", "self", ".", "_storage", "=", "[", "[", "None", "for", "_", "in", "range", "(", "n_agents", ")", "]", "for", "_", "in", "range", "(", "n_items", ")", "]", "\n", "self", ".", "_maxsize", "=", "int", "(", "size", ")", "\n", "self", ".", "_next_idx", "=", "0", "\n", "self", ".", "n_items", "=", "n_items", "\n", "self", ".", "n_agents", "=", "n_agents", "\n", "self", ".", "len", "=", "0", "\n", "self", ".", "first", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.__len__": [[24, 26], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "len", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.save": [[27, 30], ["os.path.join", "joblib.dump"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "save_dir", ")", ":", "\n", "        ", "save_path", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"union_buffer.data\"", ")", "\n", "joblib", ".", "dump", "(", "(", "self", ".", "_storage", ",", "self", ".", "_next_idx", ",", "self", ".", "len", ",", "self", ".", "first", ")", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.load": [[31, 34], ["os.path.join", "joblib.load"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.load"], ["", "def", "load", "(", "self", ",", "load_dir", ")", ":", "\n", "        ", "load_path", "=", "os", ".", "path", ".", "join", "(", "load_dir", ",", "\"union_buffer.data\"", ")", "\n", "self", ".", "_storage", ",", "self", ".", "_next_idx", ",", "self", ".", "len", ",", "self", ".", "first", "=", "joblib", ".", "load", "(", "load_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.clear": [[35, 40], ["range", "range"], "methods", ["None"], ["", "def", "clear", "(", "self", ")", ":", "\n", "        ", "self", ".", "_storage", "=", "[", "[", "None", "for", "_", "in", "range", "(", "self", ".", "n_agents", ")", "]", "for", "_", "in", "range", "(", "self", ".", "n_items", ")", "]", "\n", "self", ".", "_next_idx", "=", "0", "\n", "self", ".", "first", "=", "True", "\n", "self", ".", "len", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.add": [[41, 61], ["range", "range", "range", "range", "numpy.zeros"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "data", ")", ":", "\n", "# data : (m, n, shape)", "\n", "\n", "        ", "if", "self", ".", "_next_idx", ">=", "self", ".", "len", ":", "\n", "            ", "if", "self", ".", "first", ":", "\n", "                ", "for", "i", "in", "range", "(", "self", ".", "n_items", ")", ":", "\n", "                    ", "for", "j", "in", "range", "(", "self", ".", "n_agents", ")", ":", "\n", "                        ", "s", "=", "data", "[", "i", "]", "[", "j", "]", ".", "shape", "\n", "self", ".", "_storage", "[", "i", "]", "[", "j", "]", "=", "np", ".", "zeros", "(", "shape", "=", "(", "self", ".", "_maxsize", ",", "*", "s", ")", ")", "\n", "", "", "self", ".", "first", "=", "False", "\n", "# else:", "\n", "# for i in range(self.m):", "\n", "#     for j in range(self.n):", "\n", "#         self._storage[i][j] = self._storage[i][j] + [data[i][j]]", "\n", "", "self", ".", "len", "+=", "1", "\n", "# else:", "\n", "", "for", "i", "in", "range", "(", "self", ".", "n_items", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "n_agents", ")", ":", "\n", "                ", "self", ".", "_storage", "[", "i", "]", "[", "j", "]", "[", "self", ".", "_next_idx", "]", "=", "data", "[", "i", "]", "[", "j", "]", "\n", "", "", "self", ".", "_next_idx", "=", "(", "self", ".", "_next_idx", "+", "1", ")", "%", "self", ".", "_maxsize", "\n", "#", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.make_index": [[98, 100], ["numpy.random.randint"], "methods", ["None"], ["", "def", "make_index", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "return", "np", ".", "random", ".", "randint", "(", "self", ".", "len", ",", "size", "=", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.union_replay_buffer.UnionReplayBuffer.sample_index": [[101, 109], ["range", "range"], "methods", ["None"], ["", "def", "sample_index", "(", "self", ",", "idxes", ")", ":", "\n", "# ret = [[[] for _ in range(self.n)] for _ in range(self.m)]", "\n", "# for i in range(self.m):", "\n", "#     for j in range(self.n):", "\n", "#         for k in idxes:", "\n", "#             ret[i][j].append(self._storage[i][j][k])", "\n", "#         ret[i][j] = np.array(ret[i][j])", "\n", "        ", "return", "[", "[", "self", ".", "_storage", "[", "i", "]", "[", "j", "]", "[", "idxes", "]", "for", "j", "in", "range", "(", "self", ".", "n_agents", ")", "]", "for", "i", "in", "range", "(", "self", ".", "n_items", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.model_v3_test3.register_fc": [[8, 11], ["None"], "function", ["None"], ["def", "register_fc", "(", "fully_connected", ")", ":", "\n", "    ", "global", "FULLY_CONNECTED", "\n", "FULLY_CONNECTED", "=", "fully_connected", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.model_v3_test3.mlp_model_agent_q_ising": [[12, 122], ["tensorflow.variable_scope", "tensorflow.concat", "tensorflow.concat", "theta_out.append", "phi_out.append", "g_out.append", "enumerate", "tensorflow.stack", "tensorflow.stack", "tensorflow.stack", "tensorflow.nn.softmax", "tensorflow.matmul", "range", "tensorflow.stack", "tensorflow.nn.relu", "tensorflow.nn.softmax", "tensorflow.squeeze", "tensorflow.contrib.layers.layer_norm", "tensorflow.nn.relu", "tensorflow.concat", "FULLY_CONNECTED", "FULLY_CONNECTED", "FULLY_CONNECTED", "tensorflow.variable_scope", "model_v3_test3.mlp_model_agent_p_ising", "range", "FULLY_CONNECTED", "FULLY_CONNECTED", "FULLY_CONNECTED", "theta_out.append", "phi_out.append", "g_out.append", "input_all_new.append", "tensorflow.matmul", "tensorflow.concat", "other_good_ins.append", "tensorflow.concat", "tensorflow.concat", "FULLY_CONNECTED", "FULLY_CONNECTED", "FULLY_CONNECTED", "tensorflow.matmul", "math.sqrt", "tensorflow.contrib.layers.layer_norm", "tensorflow.matmul", "math.sqrt", "tensorflow.transpose", "tensorflow.variable_scope", "model_v3_test3.mlp_model_agent_p_ising", "tensorflow.split", "tensorflow.transpose", "tensorflow.expand_dims"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.softmax", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.softmax", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.model_v3_test3.mlp_model_agent_p_ising", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.model_v3_test3.mlp_model_agent_p_ising"], ["", "def", "mlp_model_agent_q_ising", "(", "input", ",", "num_outputs", ",", "scope", ",", "index", ",", "n_adv", "=", "3", ",", "n_good", "=", "5", ",", "n_land", "=", "6", ",", "num_units", "=", "64", ",", "share_weights", "=", "False", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "if", "reuse", "is", "None", ":", "\n", "        ", "reuse", "=", "tf", ".", "AUTO_REUSE", "if", "share_weights", "else", "False", "\n", "\n", "# This model takes as input an observation and returns values of all actions", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "basic", "=", "0", "\n", "shorton", "=", "1", "\n", "# split actions", "\n", "num_test", "=", "num_units", "//", "2", "\n", "\n", "\n", "batch_size", "=", "input", ".", "shape", "[", "0", "]", ".", "value", "\n", "input_action", "=", "input", "[", ":", ",", "-", "2", "*", "(", "n_adv", "+", "n_good", ")", ":", "]", "\n", "self_action", "=", "input_action", "[", ":", ",", "index", "*", "2", ":", "(", "index", "+", "1", ")", "*", "2", "]", "\n", "good_action", "=", "input_action", "[", ":", ",", "n_adv", "*", "2", ":", "]", "\n", "other_good_action", "=", "tf", ".", "concat", "(", "[", "input_action", "[", ":", ",", "2", "*", "n_adv", ":", "2", "*", "index", "]", ",", "input_action", "[", ":", ",", "2", "*", "(", "index", "+", "1", ")", ":", "]", "]", ",", "1", ")", "\n", "other_adv_action", "=", "input_action", "[", ":", ",", ":", "n_adv", "*", "2", "]", "\n", "\n", "# split self obs", "\n", "length_wolf", "=", "5", "\n", "length_sheep", "=", "5", "\n", "self_start", "=", "n_adv", "*", "length_wolf", "+", "(", "index", "-", "n_adv", ")", "*", "length_sheep", "\n", "\n", "self_dim", "=", "length_sheep", "\n", "\n", "# self mlp", "\n", "\n", "input_obs_self", "=", "input", "[", ":", ",", "self_start", ":", "self_start", "+", "length_sheep", "]", "\n", "self_in", "=", "input_obs_self", "\n", "self_in", "=", "tf", ".", "concat", "(", "[", "self_in", ",", "self_action", "]", ",", "1", ")", "\n", "with", "tf", ".", "variable_scope", "(", "\"self\"", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "self_out", "=", "mlp_model_agent_p_ising", "(", "self_in", ",", "num_test", ",", "'mlp'", ",", "index", ",", "n_adv", "=", "n_adv", ",", "n_good", "=", "n_good", ",", "n_land", "=", "n_land", ",", "\n", "share_weights", "=", "share_weights", ",", "num_units", "=", "num_units", ",", "with_action", "=", "True", ",", "reuse", "=", "reuse", ")", "\n", "\n", "# sheep mlp", "\n", "", "if", "n_good", "!=", "1", ":", "\n", "            ", "other_good_ins", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_good", ")", ":", "\n", "                ", "if", "i", "==", "index", "-", "n_adv", ":", "\n", "                    ", "continue", "\n", "", "other_good_beg", "=", "n_adv", "*", "length_wolf", "+", "i", "*", "length_sheep", "\n", "other_good_in", "=", "input", "[", ":", ",", "other_good_beg", ":", "other_good_beg", "+", "length_sheep", "]", "\n", "tmp", "=", "tf", ".", "concat", "(", "[", "other_good_in", ",", "good_action", "[", ":", ",", "i", "*", "2", ":", "(", "i", "+", "1", ")", "*", "2", "]", "]", ",", "1", ")", "\n", "other_good_ins", ".", "append", "(", "tmp", ")", "\n", "", "other_good_outs", "=", "[", "]", "\n", "\n", "if", "basic", ":", "\n", "                ", "other_good_out", "=", "tf", ".", "concat", "(", "[", "i", "for", "i", "in", "other_good_ins", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "                ", "batch_other_good_ins", "=", "tf", ".", "concat", "(", "other_good_ins", ",", "axis", "=", "0", ")", "\n", "with", "tf", ".", "variable_scope", "(", "(", "\"good0\"", "if", "NUMBERED", "else", "\"good\"", ")", ",", "reuse", "=", "reuse", ")", ":", "\n", "                    ", "out", "=", "mlp_model_agent_p_ising", "(", "batch_other_good_ins", ",", "num_test", ",", "'mlp'", ",", "0", ",", "n_adv", "=", "n_adv", ",", "\n", "n_good", "=", "n_good", ",", "n_land", "=", "n_land", ",", "share_weights", "=", "share_weights", ",", "num_units", "=", "num_units", ",", "\n", "with_action", "=", "True", ",", "reuse", "=", "reuse", ")", "\n", "other_good_outs", "=", "tf", ".", "split", "(", "out", ",", "n_good", "-", "1", ",", "axis", "=", "0", ")", "\n", "", "", "", "else", ":", "\n", "            ", "other_good_outs", "=", "[", "]", "\n", "\n", "\n", "", "theta_out", "=", "[", "]", "\n", "phi_out", "=", "[", "]", "\n", "g_out", "=", "[", "]", "\n", "\n", "theta_out", ".", "append", "(", "FULLY_CONNECTED", "(", "self_out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'theta_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "phi_out", ".", "append", "(", "FULLY_CONNECTED", "(", "self_out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'phi_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "g_out", ".", "append", "(", "FULLY_CONNECTED", "(", "self_out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'g_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "for", "i", ",", "out", "in", "enumerate", "(", "other_good_outs", ")", ":", "\n", "            ", "theta_out", ".", "append", "(", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'theta_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "phi_out", ".", "append", "(", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'phi_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "g_out", ".", "append", "(", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'g_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "\n", "\n", "", "theta_outs", "=", "tf", ".", "stack", "(", "theta_out", ",", "2", ")", "\n", "# print(theta_outs.get_shape(),'theta_outs')", "\n", "# print(theta_out[0].get_shape(),'theta')", "\n", "phi_outs", "=", "tf", ".", "stack", "(", "phi_out", ",", "2", ")", "\n", "g_outs", "=", "tf", ".", "stack", "(", "g_out", ",", "2", ")", "\n", "self_attention", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "matmul", "(", "theta_outs", ",", "tf", ".", "transpose", "(", "phi_outs", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", "/", "math", ".", "sqrt", "(", "num_test", ")", ")", "\n", "# print(self_attention.get_shape(),'self_attention')", "\n", "input_all", "=", "tf", ".", "matmul", "(", "self_attention", ",", "g_outs", ")", "\n", "input_all_new", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_adv", "+", "n_good", ")", ":", "\n", "            ", "input_all_new", ".", "append", "(", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "input_all", "[", ":", ",", ":", ",", "i", "]", ",", "scope", "=", "'qlayernorm1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ")", "\n", "", "input_all", "=", "tf", ".", "stack", "(", "input_all_new", ",", "2", ")", "\n", "# input_all = tf.contrib.layers.layer_norm(input_all)", "\n", "input_all", "=", "tf", ".", "nn", ".", "relu", "(", "input_all", ")", "\n", "\n", "\n", "self_out_new", "=", "input_all", "[", ":", ",", ":", ",", "0", "]", "\n", "good_out_new", "=", "input_all", "[", ":", ",", ":", ",", "1", ":", "n_good", "]", "\n", "\n", "\n", "other_good_out_attn", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "matmul", "(", "tf", ".", "expand_dims", "(", "self_out_new", ",", "1", ")", ",", "good_out_new", ")", "/", "math", ".", "sqrt", "(", "num_test", ")", ")", "\n", "other_good_out", "=", "tf", ".", "squeeze", "(", "tf", ".", "matmul", "(", "other_good_out_attn", ",", "tf", ".", "transpose", "(", "good_out_new", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", ",", "1", ")", "\n", "other_good_out", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "other_good_out", ")", "\n", "other_good_out", "=", "tf", ".", "nn", ".", "relu", "(", "other_good_out", ")", "\n", "# merge layer for all", "\n", "\n", "input_merge", "=", "tf", ".", "concat", "(", "[", "self_out", ",", "other_good_out", "]", ",", "1", ")", "\n", "\n", "\n", "out", "=", "FULLY_CONNECTED", "(", "input_merge", ",", "num_outputs", "=", "num_units", ",", "scope", "=", "'last_1'", ",", "activation_fn", "=", "tf", ".", "nn", ".", "leaky_relu", ")", "\n", "out", "=", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_units", ",", "scope", "=", "'last_11'", ",", "activation_fn", "=", "tf", ".", "nn", ".", "leaky_relu", ")", "\n", "out", "=", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_outputs", ",", "scope", "=", "'last_2'", ",", "activation_fn", "=", "None", ")", "\n", "\n", "# print(\"mlp_model_agent_q\",", "\n", "#       len(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=tf.get_variable_scope().name)))", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.model_v3_test3.mlp_model_agent_p_ising": [[123, 188], ["tensorflow.variable_scope", "range", "tensorflow.transpose", "tensorflow.nn.softmax", "tensorflow.squeeze", "tensorflow.contrib.layers.layer_norm", "tensorflow.nn.relu", "tensorflow.concat", "FULLY_CONNECTED", "FULLY_CONNECTED", "FULLY_CONNECTED", "tensorflow.concat", "tensorflow.variable_scope", "FULLY_CONNECTED", "FULLY_CONNECTED", "other_good_ins.append", "tensorflow.variable_scope", "FULLY_CONNECTED", "FULLY_CONNECTED", "tensorflow.matmul", "tensorflow.matmul", "math.sqrt", "tensorflow.transpose", "tensorflow.expand_dims"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.softmax"], ["", "", "def", "mlp_model_agent_p_ising", "(", "input", ",", "num_outputs", ",", "scope", ",", "index", ",", "n_adv", "=", "2", ",", "n_good", "=", "5", ",", "n_land", "=", "6", ",", "num_units", "=", "64", ",", "with_action", "=", "False", ",", "share_weights", "=", "False", ",", "reuse", "=", "None", ")", ":", "\n", "# This model takes as input an observation and returns values of all actions", "\n", "#print('input ....................................', input)", "\n", "    ", "num_neighbor", "=", "4", "\n", "if", "reuse", "is", "None", ":", "\n", "        ", "reuse", "=", "(", "tf", ".", "AUTO_REUSE", "if", "share_weights", "else", "False", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "num_test", "=", "num_units", "//", "2", "\n", "batch_size", "=", "input", ".", "shape", "[", "0", "]", ".", "value", "\n", "\n", "if", "with_action", ":", "\n", "            ", "self_action", "=", "input", "[", ":", ",", "-", "2", ":", "]", "\n", "", "else", ":", "\n", "            ", "self_action", "=", "None", "\n", "\n", "# self mlp", "\n", "", "self_dim", "=", "1", "\n", "self_in", "=", "input", "[", ":", ",", ":", "1", "]", "\n", "if", "with_action", ":", "\n", "            ", "self_in", "=", "tf", ".", "concat", "(", "[", "self_in", ",", "self_action", "]", ",", "axis", "=", "1", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"self\"", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "self_out", "=", "FULLY_CONNECTED", "(", "\n", "self_in", ",", "num_outputs", "=", "num_units", ",", "scope", "=", "'l1'", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "self_out", "=", "FULLY_CONNECTED", "(", "\n", "self_out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'l2'", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "\n", "# sheep mlp", "\n", "\n", "", "other_good_dim", "=", "1", "\n", "other_good_in", "=", "input", "[", ":", ",", "self_dim", ":", "]", "\n", "other_good_ins", "=", "[", "]", "\n", "#print('othe good...................', other_good_in)", "\n", "for", "i", "in", "range", "(", "num_neighbor", ")", ":", "\n", "            ", "pos", "=", "other_good_in", "[", ":", ",", "i", ":", "i", "+", "1", "]", "\n", "#print('othere pos ..................', pos)", "\n", "#tmp = tf.concat([pos], axis=1)", "\n", "other_good_ins", ".", "append", "(", "pos", ")", "\n", "\n", "#print('other_good_input..................', other_good_ins)", "\n", "#print('input .......................................................................................................', input, with_action)", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "(", "\"good0\"", "if", "NUMBERED", "else", "\"good\"", ")", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "fc1_good", "=", "FULLY_CONNECTED", "(", "\n", "other_good_ins", ",", "num_outputs", "=", "num_units", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "scope", "=", "\"l1\"", ",", "reuse", "=", "reuse", ")", "\n", "other_good_outs", "=", "(", "FULLY_CONNECTED", "(", "\n", "fc1_good", ",", "num_outputs", "=", "num_test", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "scope", "=", "\"l2\"", ",", "reuse", "=", "reuse", ")", ")", "\n", "", "other_good_out", "=", "tf", ".", "transpose", "(", "other_good_outs", ",", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "# other_good_out = tf.reduce_mean(tf.stack(other_good_outs, 2), 2)", "\n", "#other_good_out = tf.concat([i for i in other_good_outs],1)", "\n", "\n", "other_good_out_attn", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "matmul", "(", "tf", ".", "expand_dims", "(", "self_out", ",", "1", ")", ",", "other_good_out", ")", "/", "math", ".", "sqrt", "(", "num_test", ")", ")", "\n", "# print(\"attn:\", other_good_out_attn)", "\n", "other_good_out", "=", "tf", ".", "squeeze", "(", "tf", ".", "matmul", "(", "other_good_out_attn", ",", "tf", ".", "transpose", "(", "other_good_out", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", ",", "1", ")", "\n", "other_good_out", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "other_good_out", ")", "\n", "other_good_out", "=", "tf", ".", "nn", ".", "relu", "(", "other_good_out", ")", "\n", "\n", "input_merge", "=", "tf", ".", "concat", "(", "[", "self_out", ",", "other_good_out", "]", ",", "1", ")", "\n", "out", "=", "FULLY_CONNECTED", "(", "input_merge", ",", "num_outputs", "=", "num_units", ",", "scope", "=", "'last_1'", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", "if", "with_action", "else", "tf", ".", "nn", ".", "leaky_relu", ")", "\n", "out", "=", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_units", ",", "scope", "=", "'last_11'", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", "if", "with_action", "else", "tf", ".", "nn", ".", "leaky_relu", ")", "\n", "out", "=", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_outputs", ",", "scope", "=", "'last_2'", ",", "activation_fn", "=", "None", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.model_v3_test3.mlp_model_agent_p": [[189, 316], ["tensorflow.variable_scope", "tensorflow.split", "tensorflow.transpose", "tensorflow.nn.softmax", "tensorflow.squeeze", "tensorflow.contrib.layers.layer_norm", "tensorflow.nn.relu", "range", "FULLY_CONNECTED", "FULLY_CONNECTED", "FULLY_CONNECTED", "tensorflow.concat", "tensorflow.variable_scope", "FULLY_CONNECTED", "FULLY_CONNECTED", "tensorflow.variable_scope", "FULLY_CONNECTED", "FULLY_CONNECTED", "tensorflow.matmul", "range", "tensorflow.transpose", "tensorflow.nn.softmax", "tensorflow.squeeze", "tensorflow.contrib.layers.layer_norm", "tensorflow.nn.relu", "other_adv_ins.append", "tensorflow.transpose", "tensorflow.nn.softmax", "tensorflow.squeeze", "tensorflow.contrib.layers.layer_norm", "tensorflow.nn.relu", "tensorflow.concat", "tensorflow.matmul", "math.sqrt", "tensorflow.transpose", "other_good_ins.append", "tensorflow.variable_scope", "FULLY_CONNECTED", "FULLY_CONNECTED", "tensorflow.matmul", "tensorflow.concat", "tensorflow.concat", "tensorflow.variable_scope", "FULLY_CONNECTED", "FULLY_CONNECTED", "tensorflow.matmul", "tensorflow.concat", "tensorflow.concat", "tensorflow.expand_dims", "tensorflow.concat", "tensorflow.concat", "tensorflow.matmul", "math.sqrt", "tensorflow.transpose", "tensorflow.matmul", "math.sqrt", "tensorflow.transpose", "tensorflow.expand_dims", "tensorflow.expand_dims"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.softmax", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.softmax", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.softmax"], ["", "", "def", "mlp_model_agent_p", "(", "input", ",", "num_outputs", ",", "scope", ",", "index", ",", "n_adv", "=", "2", ",", "n_good", "=", "5", ",", "n_land", "=", "6", ",", "num_units", "=", "64", ",", "with_action", "=", "False", ",", "share_weights", "=", "False", ",", "reuse", "=", "None", ")", ":", "\n", "# This model takes as input an observation and returns values of all actions", "\n", "#print(input)", "\n", "    ", "if", "reuse", "is", "None", ":", "\n", "        ", "reuse", "=", "(", "tf", ".", "AUTO_REUSE", "if", "share_weights", "else", "False", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "num_test", "=", "num_units", "//", "2", "\n", "batch_size", "=", "input", ".", "shape", "[", "0", "]", ".", "value", "\n", "self_land", "=", "input", "[", ":", ",", "5", ":", "5", "+", "3", "*", "n_land", "]", "# Need modification", "\n", "\n", "if", "with_action", ":", "\n", "            ", "self_action", "=", "input", "[", ":", ",", "-", "5", ":", "]", "\n", "", "else", ":", "\n", "            ", "self_action", "=", "None", "\n", "\n", "# self mlp", "\n", "", "self_dim", "=", "5", "+", "3", "*", "n_land", "\n", "#print('number of land',n_land)", "\n", "self_in", "=", "input", "[", ":", ",", ":", "5", "]", "\n", "if", "with_action", ":", "\n", "            ", "self_in", "=", "tf", ".", "concat", "(", "[", "self_in", ",", "self_action", "]", ",", "axis", "=", "1", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"self\"", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "self_out", "=", "FULLY_CONNECTED", "(", "\n", "self_in", ",", "num_outputs", "=", "num_units", ",", "scope", "=", "'l1'", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "self_out", "=", "FULLY_CONNECTED", "(", "\n", "self_out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'l2'", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "\n", "\n", "# land mark mlp", "\n", "", "land_mark_input", "=", "input", "[", ":", ",", "5", ":", "5", "+", "3", "*", "n_land", "]", "\n", "land_mark_input", "=", "tf", ".", "split", "(", "land_mark_input", ",", "n_land", ",", "axis", "=", "1", ")", "\n", "with", "tf", ".", "variable_scope", "(", "\"landmark\"", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "fc1_out", "=", "FULLY_CONNECTED", "(", "\n", "land_mark_input", ",", "num_outputs", "=", "num_units", ",", "scope", "=", "'l1'", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "# print(fc1_out)", "\n", "land_outs", "=", "(", "FULLY_CONNECTED", "(", "\n", "fc1_out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'l2'", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ")", ")", "\n", "# print(land_outs)", "\n", "", "land_out", "=", "tf", ".", "transpose", "(", "land_outs", ",", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "land_out_attn", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "matmul", "(", "tf", ".", "expand_dims", "(", "self_out", ",", "1", ")", ",", "land_out", ")", "/", "math", ".", "sqrt", "(", "num_test", ")", ")", "\n", "land_out", "=", "tf", ".", "squeeze", "(", "tf", ".", "matmul", "(", "land_out_attn", ",", "tf", ".", "transpose", "(", "land_out", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", ",", "1", ")", "\n", "land_out", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "land_out", ")", "\n", "land_out", "=", "tf", ".", "nn", ".", "relu", "(", "land_out", ")", "\n", "\n", "\n", "# sheep mlp", "\n", "if", "n_good", "!=", "1", ":", "# n_good should be larger than 1", "\n", "            ", "other_good_dim", "=", "(", "2", "+", "2", "+", "1", ")", "*", "(", "n_good", "-", "1", ")", "\n", "other_good_in", "=", "input", "[", ":", ",", "self_dim", ":", "]", "\n", "other_good_ins", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_good", "-", "1", ")", ":", "\n", "                ", "pos", "=", "other_good_in", "[", ":", ",", "2", "*", "n_adv", "+", "i", "*", "2", ":", "2", "*", "n_adv", "+", "(", "i", "+", "1", ")", "*", "2", "]", "\n", "vel", "=", "other_good_in", "[", ":", ",", "2", "*", "n_adv", "+", "2", "*", "(", "n_good", "-", "1", ")", "+", "2", "*", "n_adv", "+", "i", "*", "2", ":", "2", "*", "n_adv", "+", "2", "*", "(", "n_good", "-", "1", ")", "+", "2", "*", "n_adv", "+", "(", "i", "+", "1", ")", "*", "2", "]", "\n", "is_live", "=", "other_good_in", "[", ":", ",", "5", "*", "n_adv", "+", "4", "*", "(", "n_good", "-", "1", ")", "+", "i", ":", "5", "*", "n_adv", "+", "4", "*", "(", "n_good", "-", "1", ")", "+", "i", "+", "1", "]", "\n", "if", "with_action", ":", "\n", "                    ", "tmp", "=", "tf", ".", "concat", "(", "[", "pos", ",", "vel", ",", "is_live", "]", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "                    ", "tmp", "=", "tf", ".", "concat", "(", "[", "pos", ",", "vel", ",", "is_live", "]", ",", "axis", "=", "1", ")", "\n", "", "other_good_ins", ".", "append", "(", "tmp", ")", "\n", "#print('benchmark ............', other_good_ins)", "\n", "# other_good_ins = tf.split(other_good_ins, n_good - 1, axis=1)", "\n", "# other_good_outs = []", "\n", "\n", "# for i in range(n_good-1):", "\n", "#     true_id = i if i < index - n_adv else i + 1", "\n", "", "with", "tf", ".", "variable_scope", "(", "(", "\"good0\"", "if", "NUMBERED", "else", "\"good\"", ")", ",", "reuse", "=", "reuse", ")", ":", "\n", "                ", "fc1_good", "=", "FULLY_CONNECTED", "(", "\n", "other_good_ins", ",", "num_outputs", "=", "num_units", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "scope", "=", "\"l1\"", ",", "reuse", "=", "reuse", ")", "\n", "other_good_outs", "=", "(", "FULLY_CONNECTED", "(", "\n", "fc1_good", ",", "num_outputs", "=", "num_test", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "scope", "=", "\"l2\"", ",", "reuse", "=", "reuse", ")", ")", "\n", "", "other_good_out", "=", "tf", ".", "transpose", "(", "other_good_outs", ",", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "# other_good_out = tf.reduce_mean(tf.stack(other_good_outs, 2), 2)", "\n", "#other_good_out = tf.concat([i for i in other_good_outs],1)", "\n", "\n", "other_good_out_attn", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "matmul", "(", "tf", ".", "expand_dims", "(", "self_out", ",", "1", ")", ",", "other_good_out", ")", "/", "math", ".", "sqrt", "(", "num_test", ")", ")", "\n", "# print(\"attn:\", other_good_out_attn)", "\n", "other_good_out", "=", "tf", ".", "squeeze", "(", "tf", ".", "matmul", "(", "other_good_out_attn", ",", "tf", ".", "transpose", "(", "other_good_out", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", ",", "1", ")", "\n", "other_good_out", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "other_good_out", ")", "\n", "other_good_out", "=", "tf", ".", "nn", ".", "relu", "(", "other_good_out", ")", "\n", "\n", "#wolf_mlp", "\n", "", "other_adv_dim", "=", "5", "*", "(", "n_adv", ")", "\n", "other_adv_beg", "=", "self_dim", "\n", "other_adv_in", "=", "input", "[", ":", ",", "other_adv_beg", ":", "]", "\n", "\n", "other_adv_ins", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_adv", ")", ":", "\n", "            ", "pos", "=", "other_adv_in", "[", ":", ",", "i", "*", "2", ":", "(", "i", "+", "1", ")", "*", "2", "]", "\n", "vel", "=", "other_adv_in", "[", ":", ",", "2", "*", "n_adv", "+", "2", "*", "(", "n_good", "-", "1", ")", "+", "i", "*", "2", ":", "2", "*", "n_adv", "+", "2", "*", "(", "n_good", "-", "1", ")", "+", "(", "i", "+", "1", ")", "*", "2", "]", "\n", "is_live", "=", "other_adv_in", "[", ":", ",", "4", "*", "n_adv", "+", "4", "*", "(", "n_good", "-", "1", ")", "+", "i", ":", "4", "*", "n_adv", "+", "4", "*", "(", "n_good", "-", "1", ")", "+", "i", "+", "1", "]", "\n", "if", "not", "with_action", ":", "\n", "                ", "tmp", "=", "tf", ".", "concat", "(", "[", "pos", ",", "vel", ",", "is_live", "]", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "tmp", "=", "tf", ".", "concat", "(", "[", "pos", ",", "vel", ",", "is_live", "]", ",", "axis", "=", "1", ")", "\n", "", "other_adv_ins", ".", "append", "(", "tmp", ")", "\n", "\n", "# other_adv_outs = []", "\n", "# for i in range(n_adv):", "\n", "", "if", "(", "n_adv", ">", "0", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "(", "\"adv0\"", "if", "NUMBERED", "else", "\"adv\"", ")", ",", "reuse", "=", "reuse", ")", ":", "\n", "                ", "fc1_adv", "=", "FULLY_CONNECTED", "(", "\n", "other_adv_ins", ",", "num_outputs", "=", "num_units", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "scope", "=", "\"l1\"", ",", "reuse", "=", "reuse", ")", "\n", "other_adv_outs", "=", "(", "FULLY_CONNECTED", "(", "\n", "fc1_adv", ",", "num_outputs", "=", "num_test", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "scope", "=", "\"l2\"", ",", "reuse", "=", "reuse", ")", ")", "\n", "", "other_adv_out", "=", "tf", ".", "transpose", "(", "other_adv_outs", ",", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "other_adv_out_attn", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "matmul", "(", "tf", ".", "expand_dims", "(", "self_out", ",", "1", ")", ",", "other_adv_out", ")", "/", "math", ".", "sqrt", "(", "num_test", ")", ")", "\n", "other_adv_out", "=", "tf", ".", "squeeze", "(", "tf", ".", "matmul", "(", "other_adv_out_attn", ",", "tf", ".", "transpose", "(", "other_adv_out", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", ",", "1", ")", "\n", "other_adv_out", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "other_adv_out", ")", "\n", "other_adv_out", "=", "tf", ".", "nn", ".", "relu", "(", "other_adv_out", ")", "\n", "", "else", ":", "\n", "            ", "other_adv_out", "=", "None", "\n", "\n", "# other_adv_out = tf.concat([i for i in other_adv_outs],1)", "\n", "# merge layer for all", "\n", "", "if", "n_good", "==", "1", ":", "\n", "            ", "input_merge", "=", "tf", ".", "concat", "(", "[", "self_out", ",", "land_out", ",", "other_adv_out", "]", ",", "1", ")", "\n", "", "elif", "(", "n_adv", "<=", "0", ")", ":", "\n", "            ", "input_merge", "=", "tf", ".", "concat", "(", "[", "self_out", ",", "land_out", ",", "other_good_out", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "input_merge", "=", "tf", ".", "concat", "(", "[", "self_out", ",", "land_out", ",", "other_good_out", ",", "other_adv_out", "]", ",", "1", ")", "\n", "", "out", "=", "FULLY_CONNECTED", "(", "input_merge", ",", "num_outputs", "=", "num_units", ",", "scope", "=", "'last_1'", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", "if", "with_action", "else", "tf", ".", "nn", ".", "leaky_relu", ")", "\n", "out", "=", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_units", ",", "scope", "=", "'last_11'", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", "if", "with_action", "else", "tf", ".", "nn", ".", "leaky_relu", ")", "\n", "out", "=", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_outputs", ",", "scope", "=", "'last_2'", ",", "activation_fn", "=", "None", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.model_v3_test3.mean_field_adv_q_model": [[317, 370], ["tensorflow.variable_scope", "range", "range", "tensorflow.reduce_sum", "tensorflow.concat", "model_v3_test3.mlp_model", "tensorflow.reduce_sum", "tensorflow.einsum", "range", "other_cnt.append", "tf.einsum.append", "tf.einsum.append", "range", "range", "other_cnt.append", "tf.einsum.append", "tf.einsum.append", "tensorflow.einsum", "tensorflow.einsum"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.model_v3_test3.mlp_model"], ["", "", "def", "mean_field_adv_q_model", "(", "inputs", ",", "num_outputs", ",", "scope", ",", "index", ",", "scenario", ",", "n_act", "=", "5", ",", "n_adv", "=", "3", ",", "n_good", "=", "5", ",", "n_land", "=", "6", ",", "reuse", "=", "False", ",", "num_units", "=", "64", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "#if scenario == 'grassland' or scenario == 'adversarial':", "\n", "        ", "input_action", "=", "inputs", "[", ":", ",", "-", "n_act", "*", "(", "n_adv", "+", "n_good", ")", ":", "]", "\n", "actions", "=", "[", "input_action", "[", ":", ",", "n_act", "*", "i", ":", "n_act", "*", "(", "i", "+", "1", ")", "]", "for", "i", "in", "range", "(", "n_adv", "+", "n_good", ")", "]", "\n", "wolf_actions", "=", "actions", "[", ":", "n_adv", "]", "\n", "sheep_actions", "=", "actions", "[", "n_adv", ":", "]", "\n", "self_action", "=", "actions", "[", "index", "]", "\n", "input_obs", "=", "inputs", "[", ":", ",", ":", "-", "n_act", "*", "(", "n_adv", "+", "n_good", ")", "]", "\n", "\n", "if", "scenario", "==", "'grassland'", "or", "scenario", "==", "'adversarial'", ":", "\n", "            ", "length_wolf", "=", "(", "n_land", ")", "*", "3", "+", "(", "n_good", "+", "n_adv", ")", "*", "5", "\n", "length_sheep", "=", "length_wolf", "\n", "assert", "(", "length_wolf", "*", "n_adv", "+", "length_sheep", "*", "n_good", "+", "5", "*", "(", "n_adv", "+", "n_good", ")", "==", "inputs", ".", "shape", "[", "1", "]", ")", "\n", "input_wolf_obs", "=", "inputs", "[", ":", ",", ":", "length_wolf", "*", "n_adv", "]", "\n", "input_sheep_obs", "=", "inputs", "[", ":", ",", "length_wolf", "*", "n_adv", ":", "length_wolf", "*", "n_adv", "+", "length_sheep", "*", "n_good", "]", "\n", "wolf_obs", "=", "[", "input_wolf_obs", "[", ":", ",", "length_wolf", "*", "i", ":", "length_wolf", "*", "(", "i", "+", "1", ")", "]", "for", "i", "in", "range", "(", "n_adv", ")", "]", "\n", "sheep_obs", "=", "[", "input_sheep_obs", "[", ":", ",", "length_sheep", "*", "i", ":", "length_sheep", "*", "(", "i", "+", "1", ")", "]", "for", "i", "in", "range", "(", "n_good", ")", "]", "\n", "\n", "# there is at least 1 other survivor, due to the game rule.", "\n", "", "other_action", "=", "[", "]", "\n", "other_cnt", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_adv", ")", ":", "\n", "            ", "if", "i", "!=", "index", ":", "\n", "                ", "if", "scenario", "==", "'grassland'", "or", "scenario", "==", "'adversarial'", ":", "\n", "                    ", "live", "=", "wolf_obs", "[", "i", "]", "[", ":", ",", "4", "]", "\n", "other_cnt", ".", "append", "(", "live", ")", "\n", "other_action", ".", "append", "(", "tf", ".", "einsum", "(", "'ij,i->ij'", ",", "wolf_actions", "[", "i", "]", ",", "live", ")", ")", "\n", "", "else", ":", "\n", "                    ", "other_action", ".", "append", "(", "wolf_actions", "[", "i", "]", ")", "\n", "\n", "\n", "", "", "", "for", "i", "in", "range", "(", "n_good", ")", ":", "\n", "            ", "if", "scenario", "==", "'grassland'", "or", "scenario", "==", "'adversarial'", ":", "\n", "                ", "live", "=", "sheep_obs", "[", "i", "]", "[", ":", ",", "4", "]", "\n", "other_cnt", ".", "append", "(", "live", ")", "\n", "other_action", ".", "append", "(", "tf", ".", "einsum", "(", "'ij,i->ij'", ",", "sheep_actions", "[", "i", "]", ",", "live", ")", ")", "\n", "", "else", ":", "\n", "                ", "other_action", ".", "append", "(", "sheep_actions", "[", "i", "]", ")", "\n", "\n", "", "", "other_action_sum", "=", "tf", ".", "reduce_sum", "(", "other_action", ",", "axis", "=", "0", ")", "\n", "if", "scenario", "==", "'grassland'", "or", "scenario", "==", "'adversarial'", ":", "\n", "            ", "other_cnt_sum", "=", "tf", ".", "reduce_sum", "(", "other_cnt", ",", "axis", "=", "0", ")", "\n", "#print(other_cnt_sum)", "\n", "if", "other_cnt_sum", "==", "0", ":", "\n", "                ", "other_cnt_sum", "=", "1", "\n", "", "other_cnt_sum_r", "=", "1.", "/", "other_cnt_sum", "\n", "other_action", "=", "tf", ".", "einsum", "(", "'ij,i->ij'", ",", "other_action_sum", ",", "other_cnt_sum_r", ")", "\n", "", "else", ":", "\n", "            ", "other_action", "=", "other_action_sum", "/", "(", "n_good", "+", "n_adv", "-", "1", ")", "\n", "\n", "", "q_input", "=", "tf", ".", "concat", "(", "[", "input_obs", ",", "self_action", ",", "other_action", "]", ",", "axis", "=", "1", ")", "\n", "return", "mlp_model", "(", "q_input", ",", "num_outputs", ",", "\"mlp\"", ",", "reuse", ",", "num_units", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.model_v3_test3.mean_field_agent_q_model": [[371, 426], ["tensorflow.variable_scope", "range", "range", "tensorflow.reduce_sum", "tensorflow.concat", "model_v3_test3.mlp_model", "tensorflow.reduce_sum", "range", "other_cnt.append", "other_action.append", "other_action.append", "range", "range", "tensorflow.einsum", "other_cnt.append", "other_action.append", "other_action.append", "tensorflow.einsum"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.model_v3_test3.mlp_model"], ["", "", "def", "mean_field_agent_q_model", "(", "inputs", ",", "num_outputs", ",", "scope", ",", "index", ",", "scenario", ",", "n_act", "=", "5", ",", "n_adv", "=", "3", ",", "n_good", "=", "5", ",", "n_land", "=", "6", ",", "reuse", "=", "False", ",", "num_units", "=", "64", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "input_action", "=", "inputs", "[", ":", ",", "-", "n_act", "*", "(", "n_adv", "+", "n_good", ")", ":", "]", "\n", "actions", "=", "[", "input_action", "[", ":", ",", "n_act", "*", "i", ":", "n_act", "*", "(", "i", "+", "1", ")", "]", "for", "i", "in", "range", "(", "n_adv", "+", "n_good", ")", "]", "\n", "wolf_actions", "=", "actions", "[", ":", "n_adv", "]", "\n", "sheep_actions", "=", "actions", "[", "n_adv", ":", "]", "\n", "self_action", "=", "actions", "[", "index", "]", "\n", "input_obs", "=", "inputs", "[", ":", ",", ":", "-", "n_act", "*", "(", "n_adv", "+", "n_good", ")", "]", "\n", "if", "scenario", "==", "'grassland'", "or", "scenario", "==", "'adversarial'", ":", "\n", "            ", "length_wolf", "=", "(", "n_land", ")", "*", "3", "+", "(", "n_good", "+", "n_adv", ")", "*", "5", "\n", "length_sheep", "=", "length_wolf", "\n", "assert", "(", "length_wolf", "*", "n_adv", "+", "length_sheep", "*", "n_good", "+", "5", "*", "(", "n_adv", "+", "n_good", ")", "==", "inputs", ".", "shape", "[", "1", "]", ")", "\n", "input_wolf_obs", "=", "inputs", "[", ":", ",", ":", "length_wolf", "*", "n_adv", "]", "\n", "input_sheep_obs", "=", "inputs", "[", ":", ",", "length_wolf", "*", "n_adv", ":", "length_wolf", "*", "n_adv", "+", "length_sheep", "*", "n_good", "]", "\n", "wolf_obs", "=", "[", "input_wolf_obs", "[", ":", ",", "length_wolf", "*", "i", ":", "length_wolf", "*", "(", "i", "+", "1", ")", "]", "for", "i", "in", "range", "(", "n_adv", ")", "]", "\n", "sheep_obs", "=", "[", "input_sheep_obs", "[", ":", ",", "length_sheep", "*", "i", ":", "length_sheep", "*", "(", "i", "+", "1", ")", "]", "for", "i", "in", "range", "(", "n_good", ")", "]", "\n", "\n", "# there is at least 1 other survivor, due to the game rule.", "\n", "", "other_action", "=", "[", "]", "\n", "other_cnt", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_adv", ")", ":", "\n", "            ", "if", "scenario", "==", "'grassland'", "or", "scenario", "==", "'adversarial'", ":", "\n", "                ", "live", "=", "wolf_obs", "[", "i", "]", "[", ":", ",", "4", "]", "\n", "other_cnt", ".", "append", "(", "live", ")", "\n", "other_action", ".", "append", "(", "tf", ".", "einsum", "(", "'ij,i->ij'", ",", "wolf_actions", "[", "i", "]", ",", "live", ")", ")", "\n", "#print(live)", "\n", "", "else", ":", "\n", "#live = 1", "\n", "                ", "other_action", ".", "append", "(", "wolf_actions", "[", "i", "]", ")", "\n", "\n", "", "", "for", "i", "in", "range", "(", "n_good", ")", ":", "\n", "            ", "if", "i", "+", "n_adv", "!=", "index", ":", "\n", "                ", "if", "scenario", "==", "'grassland'", "or", "scenario", "==", "'adversarial'", ":", "\n", "                    ", "live", "=", "sheep_obs", "[", "i", "]", "[", ":", ",", "4", "]", "\n", "other_cnt", ".", "append", "(", "live", ")", "\n", "other_action", ".", "append", "(", "tf", ".", "einsum", "(", "'ij,i->ij'", ",", "sheep_actions", "[", "i", "]", ",", "live", ")", ")", "\n", "", "else", ":", "\n", "                    ", "other_action", ".", "append", "(", "sheep_actions", "[", "i", "]", ")", "\n", "\n", "", "", "", "other_action_sum", "=", "tf", ".", "reduce_sum", "(", "other_action", ",", "axis", "=", "0", ")", "\n", "\n", "if", "scenario", "==", "'grassland'", "or", "scenario", "==", "'adversarial'", ":", "\n", "            ", "other_cnt_sum", "=", "tf", ".", "reduce_sum", "(", "other_cnt", ",", "axis", "=", "0", ")", "\n", "#print(other_cnt_sum)", "\n", "# if other_cnt_sum == 0:", "\n", "#     other_cnt_sum = 1", "\n", "#other_cnt_sum_r = 1. / (n_good+n_adv -1)", "\n", "other_action", "=", "other_action_sum", "/", "(", "n_good", "+", "n_adv", "-", "1", ")", "\n", "#other_action = tf.einsum('ij,i->ij', other_action_sum, other_cnt_sum_r)", "\n", "", "else", ":", "\n", "            ", "other_action", "=", "other_action_sum", "/", "(", "n_good", "+", "n_adv", "-", "1", ")", "\n", "\n", "\n", "", "q_input", "=", "tf", ".", "concat", "(", "[", "input_obs", ",", "self_action", ",", "other_action", "]", ",", "axis", "=", "1", ")", "\n", "return", "mlp_model", "(", "q_input", ",", "num_outputs", ",", "\"mlp\"", ",", "reuse", ",", "num_units", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.model_v3_test3.mlp_model_adv_p": [[427, 557], ["tensorflow.variable_scope", "tensorflow.split", "tensorflow.transpose", "tensorflow.nn.softmax", "tensorflow.squeeze", "tensorflow.contrib.layers.layer_norm", "tensorflow.nn.relu", "range", "tensorflow.transpose", "tensorflow.nn.softmax", "tensorflow.squeeze", "tensorflow.contrib.layers.layer_norm", "tensorflow.nn.relu", "range", "FULLY_CONNECTED", "FULLY_CONNECTED", "tensorflow.concat", "tensorflow.variable_scope", "FULLY_CONNECTED", "FULLY_CONNECTED", "tensorflow.variable_scope", "FULLY_CONNECTED", "FULLY_CONNECTED", "tensorflow.matmul", "other_good_ins.append", "tensorflow.variable_scope", "FULLY_CONNECTED", "FULLY_CONNECTED", "tensorflow.matmul", "tensorflow.concat", "FULLY_CONNECTED", "FULLY_CONNECTED", "other_adv_ins.append", "tensorflow.variable_scope", "FULLY_CONNECTED", "FULLY_CONNECTED", "tensorflow.transpose", "tensorflow.nn.softmax", "tensorflow.squeeze", "tensorflow.contrib.layers.layer_norm", "tensorflow.nn.relu", "tensorflow.concat", "tensorflow.concat", "tensorflow.matmul", "math.sqrt", "tensorflow.transpose", "tensorflow.concat", "tensorflow.concat", "tensorflow.matmul", "math.sqrt", "tensorflow.transpose", "tensorflow.concat", "tensorflow.concat", "tensorflow.matmul", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.matmul", "math.sqrt", "tensorflow.transpose", "tensorflow.expand_dims"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.softmax", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.softmax", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.softmax"], ["", "", "def", "mlp_model_adv_p", "(", "input", ",", "num_outputs", ",", "scope", ",", "index", ",", "n_adv", "=", "2", ",", "n_good", "=", "5", ",", "n_land", "=", "6", ",", "num_units", "=", "64", ",", "with_action", "=", "False", ",", "share_weights", "=", "False", ",", "reuse", "=", "None", ")", ":", "\n", "# This model takes as input an observation and returns values of all actions", "\n", "    ", "if", "reuse", "is", "None", ":", "\n", "        ", "reuse", "=", "tf", ".", "AUTO_REUSE", "if", "share_weights", "else", "False", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "# self input mlp", "\n", "        ", "num_test", "=", "num_units", "//", "2", "\n", "batch_size", "=", "input", ".", "shape", "[", "0", "]", ".", "value", "\n", "self_dim", "=", "5", "+", "3", "*", "n_land", "\n", "self_land", "=", "input", "[", ":", ",", "5", ":", "5", "+", "3", "*", "n_land", "]", "\n", "\n", "if", "with_action", ":", "\n", "            ", "self_action", "=", "input", "[", ":", ",", "-", "5", ":", "]", "\n", "", "else", ":", "\n", "            ", "self_action", "=", "None", "\n", "\n", "", "self_in", "=", "input", "[", ":", ",", ":", "5", "]", "\n", "if", "with_action", ":", "\n", "            ", "self_in", "=", "tf", ".", "concat", "(", "[", "self_in", ",", "self_action", "]", ",", "axis", "=", "1", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"self\"", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "self_out", "=", "FULLY_CONNECTED", "(", "\n", "self_in", ",", "num_outputs", "=", "num_units", ",", "scope", "=", "'l1'", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "# print(\"GOT\")", "\n", "self_out", "=", "FULLY_CONNECTED", "(", "\n", "self_out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'l2'", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "# print(\"GOT2\")", "\n", "\n", "# land mark mlp", "\n", "", "land_mark_input", "=", "input", "[", ":", ",", "5", ":", "5", "+", "3", "*", "n_land", "]", "\n", "land_mark_input", "=", "tf", ".", "split", "(", "land_mark_input", ",", "n_land", ",", "axis", "=", "1", ")", "\n", "land_info", "=", "[", "]", "\n", "land_outs", "=", "[", "]", "\n", "# for i in range(n_land):", "\n", "with", "tf", ".", "variable_scope", "(", "\"landmark\"", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "fc1_out", "=", "FULLY_CONNECTED", "(", "\n", "land_mark_input", ",", "num_outputs", "=", "num_units", ",", "scope", "=", "'l1'", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "land_outs", "=", "(", "FULLY_CONNECTED", "(", "\n", "fc1_out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'l2'", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ")", ")", "\n", "", "land_out", "=", "tf", ".", "transpose", "(", "land_outs", ",", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "land_out_attn", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "matmul", "(", "tf", ".", "expand_dims", "(", "self_out", ",", "1", ")", ",", "land_out", ")", "/", "math", ".", "sqrt", "(", "num_test", ")", ")", "\n", "land_out", "=", "tf", ".", "squeeze", "(", "tf", ".", "matmul", "(", "land_out_attn", ",", "tf", ".", "transpose", "(", "land_out", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", ",", "1", ")", "\n", "land_out", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "land_out", ")", "\n", "land_out", "=", "tf", ".", "nn", ".", "relu", "(", "land_out", ")", "\n", "\n", "# other sheep mlp", "\n", "other_good_in", "=", "input", "[", ":", ",", "self_dim", ":", "]", "\n", "other_good_ins", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_good", ")", ":", "\n", "            ", "pos", "=", "other_good_in", "[", ":", ",", "2", "*", "(", "n_adv", "-", "1", ")", "+", "i", "*", "2", ":", "2", "*", "(", "n_adv", "-", "1", ")", "+", "(", "i", "+", "1", ")", "*", "2", "]", "\n", "vel", "=", "other_good_in", "[", ":", ",", "4", "*", "(", "n_adv", "-", "1", ")", "+", "2", "*", "n_good", "+", "i", "*", "2", ":", "4", "*", "(", "n_adv", "-", "1", ")", "+", "2", "*", "n_good", "+", "(", "i", "+", "1", ")", "*", "2", "]", "\n", "is_live", "=", "other_good_in", "[", ":", ",", "5", "*", "(", "n_adv", "-", "1", ")", "+", "4", "*", "n_good", "+", "i", ":", "5", "*", "(", "n_adv", "-", "1", ")", "+", "4", "*", "n_good", "+", "i", "+", "1", "]", "\n", "if", "with_action", ":", "\n", "                ", "tmp", "=", "tf", ".", "concat", "(", "[", "pos", ",", "vel", ",", "is_live", "]", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "tmp", "=", "tf", ".", "concat", "(", "[", "pos", ",", "vel", ",", "is_live", "]", ",", "axis", "=", "1", ")", "\n", "", "other_good_ins", ".", "append", "(", "tmp", ")", "\n", "\n", "# other_good_outs = []", "\n", "\n", "# for i in range(n_good):", "\n", "", "with", "tf", ".", "variable_scope", "(", "(", "\"good0\"", "if", "NUMBERED", "else", "\"good\"", ")", ",", "reuse", "=", "reuse", ")", ":", "\n", "# print(num_units)", "\n", "# print(other_good_ins[i])", "\n", "            ", "fc1_good", "=", "FULLY_CONNECTED", "(", "\n", "other_good_ins", ",", "num_outputs", "=", "num_units", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "scope", "=", "\"l1\"", ",", "reuse", "=", "reuse", ")", "\n", "other_good_outs", "=", "(", "FULLY_CONNECTED", "(", "\n", "fc1_good", ",", "num_outputs", "=", "num_test", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "scope", "=", "\"l2\"", ",", "reuse", "=", "reuse", ")", ")", "\n", "# other_good_out = tf.reduce_mean(tf.stack(other_good_outs, 2), 2)", "\n", "\n", "", "other_good_out", "=", "tf", ".", "transpose", "(", "other_good_outs", ",", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "other_good_out_attn", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "matmul", "(", "tf", ".", "expand_dims", "(", "self_out", ",", "1", ")", ",", "other_good_out", ")", "/", "math", ".", "sqrt", "(", "num_test", ")", ")", "\n", "other_good_out", "=", "tf", ".", "squeeze", "(", "tf", ".", "matmul", "(", "other_good_out_attn", ",", "tf", ".", "transpose", "(", "other_good_out", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", ",", "1", ")", "\n", "other_good_out", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "other_good_out", ")", "\n", "other_good_out", "=", "tf", ".", "nn", ".", "relu", "(", "other_good_out", ")", "\n", "\n", "# other_good_out = tf.concat([i for i in other_good_outs],1)", "\n", "\n", "# other wolf mlp", "\n", "if", "n_adv", "==", "1", ":", "\n", "            ", "input_merge", "=", "tf", ".", "concat", "(", "[", "self_out", ",", "other_good_out", "]", ",", "1", ")", "\n", "out", "=", "FULLY_CONNECTED", "(", "input_merge", ",", "num_outputs", "=", "num_units", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "out", "=", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_outputs", ",", "activation_fn", "=", "None", ")", "\n", "return", "out", "\n", "\n", "", "other_adv_beg", "=", "self_dim", "\n", "other_adv_in", "=", "input", "[", ":", ",", "self_dim", ":", "]", "\n", "\n", "other_adv_ins", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_adv", "-", "1", ")", ":", "\n", "            ", "pos", "=", "other_adv_in", "[", ":", ",", "i", "*", "2", ":", "(", "i", "+", "1", ")", "*", "2", "]", "\n", "vel", "=", "other_adv_in", "[", ":", ",", "2", "*", "(", "n_adv", "-", "1", ")", "+", "2", "*", "n_good", "+", "i", "*", "2", ":", "2", "*", "(", "n_adv", "-", "1", ")", "+", "2", "*", "n_good", "+", "(", "i", "+", "1", ")", "*", "2", "]", "\n", "is_live", "=", "other_adv_in", "[", ":", ",", "4", "*", "(", "n_adv", "-", "1", ")", "+", "4", "*", "n_good", "+", "i", ":", "4", "*", "(", "n_adv", "-", "1", ")", "+", "4", "*", "n_good", "+", "i", "+", "1", "]", "\n", "if", "not", "with_action", ":", "\n", "                ", "tmp", "=", "tf", ".", "concat", "(", "[", "pos", ",", "vel", ",", "is_live", "]", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "tmp", "=", "tf", ".", "concat", "(", "[", "pos", ",", "vel", ",", "is_live", "]", ",", "axis", "=", "1", ")", "\n", "", "other_adv_ins", ".", "append", "(", "tmp", ")", "\n", "\n", "", "other_adv_outs", "=", "[", "]", "\n", "# true_id = i if i < index else i + 1", "\n", "with", "tf", ".", "variable_scope", "(", "(", "\"adv0\"", "if", "NUMBERED", "else", "\"adv\"", ")", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "fc1_adv", "=", "FULLY_CONNECTED", "(", "\n", "other_adv_ins", ",", "num_outputs", "=", "num_units", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "scope", "=", "\"l1\"", ",", "reuse", "=", "reuse", ")", "\n", "other_adv_outs", "=", "(", "FULLY_CONNECTED", "(", "\n", "fc1_adv", ",", "num_outputs", "=", "num_test", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ",", "scope", "=", "\"l2\"", ",", "reuse", "=", "reuse", ")", ")", "\n", "# other_adv_out = tf.reduce_mean(tf.stack(other_adv_outs, 2), 2)", "\n", "\n", "other_adv_out", "=", "tf", ".", "transpose", "(", "other_adv_outs", ",", "[", "1", ",", "2", ",", "0", "]", ")", "\n", "", "if", "(", "n_adv", ">", "0", ")", ":", "\n", "\n", "            ", "other_adv_out_attn", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "matmul", "(", "tf", ".", "expand_dims", "(", "self_out", ",", "1", ")", ",", "other_adv_out", ")", "/", "math", ".", "sqrt", "(", "num_test", ")", ")", "\n", "other_adv_out", "=", "tf", ".", "squeeze", "(", "tf", ".", "matmul", "(", "other_adv_out_attn", ",", "tf", ".", "transpose", "(", "other_adv_out", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", ",", "1", ")", "\n", "other_adv_out", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "other_adv_out", ")", "\n", "other_adv_out", "=", "tf", ".", "nn", ".", "relu", "(", "other_adv_out", ")", "\n", "", "else", ":", "\n", "            ", "other_adv_out", "=", "None", "\n", "\n", "# other_adv_out = tf.concat([i for i in other_adv_outs],1)", "\n", "\n", "# merge layer for all", "\n", "", "if", "(", "n_adv", "<=", "0", ")", ":", "\n", "            ", "input_merge", "=", "tf", ".", "concat", "(", "[", "self_out", ",", "land_out", ",", "other_good_out", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "input_merge", "=", "tf", ".", "concat", "(", "[", "self_out", ",", "land_out", ",", "other_good_out", ",", "other_adv_out", "]", ",", "1", ")", "\n", "\n", "", "out", "=", "FULLY_CONNECTED", "(", "input_merge", ",", "num_outputs", "=", "num_units", ",", "scope", "=", "'last_1'", ",", "\n", "activation_fn", "=", "tf", ".", "nn", ".", "relu", "if", "with_action", "else", "tf", ".", "nn", ".", "leaky_relu", ")", "\n", "# out = FULLY_CONNECTED(out, num_outputs=num_units, scope='last_11', activation_fn=tf.nn.leaky_relu)", "\n", "out", "=", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_outputs", ",", "scope", "=", "'last_2'", ",", "activation_fn", "=", "None", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.model_v3_test3.mlp_model_agent_q": [[558, 696], ["tensorflow.variable_scope", "tensorflow.concat", "tensorflow.concat", "range", "theta_out.append", "phi_out.append", "g_out.append", "enumerate", "enumerate", "tensorflow.stack", "tensorflow.stack", "tensorflow.stack", "tensorflow.nn.softmax", "tensorflow.matmul", "range", "tensorflow.stack", "tensorflow.nn.relu", "tensorflow.nn.softmax", "tensorflow.squeeze", "tensorflow.contrib.layers.layer_norm", "tensorflow.nn.relu", "FULLY_CONNECTED", "FULLY_CONNECTED", "FULLY_CONNECTED", "tensorflow.variable_scope", "model_v3_test3.mlp_model_agent_p", "range", "tensorflow.concat", "other_adv_ins.append", "tensorflow.concat", "FULLY_CONNECTED", "FULLY_CONNECTED", "FULLY_CONNECTED", "theta_out.append", "phi_out.append", "g_out.append", "theta_out.append", "phi_out.append", "g_out.append", "input_all_new.append", "tensorflow.nn.softmax", "tensorflow.squeeze", "tensorflow.contrib.layers.layer_norm", "tensorflow.nn.relu", "tensorflow.matmul", "tensorflow.concat", "tensorflow.concat", "other_good_ins.append", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "FULLY_CONNECTED", "FULLY_CONNECTED", "FULLY_CONNECTED", "FULLY_CONNECTED", "FULLY_CONNECTED", "FULLY_CONNECTED", "tensorflow.matmul", "math.sqrt", "tensorflow.contrib.layers.layer_norm", "tensorflow.matmul", "tensorflow.matmul", "math.sqrt", "tensorflow.transpose", "tensorflow.concat", "tensorflow.concat", "tensorflow.variable_scope", "model_v3_test3.mlp_model_agent_p", "tensorflow.split", "tensorflow.variable_scope", "model_v3_test3.mlp_model_adv_p", "tensorflow.split", "tensorflow.transpose", "tensorflow.matmul", "math.sqrt", "tensorflow.transpose", "tensorflow.expand_dims", "tensorflow.expand_dims"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.softmax", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.softmax", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.model_v3_test3.mlp_model_agent_p", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.softmax", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.model_v3_test3.mlp_model_agent_p", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.model_v3_test3.mlp_model_adv_p"], ["", "", "def", "mlp_model_agent_q", "(", "input", ",", "num_outputs", ",", "scope", ",", "index", ",", "n_adv", "=", "3", ",", "n_good", "=", "5", ",", "n_land", "=", "6", ",", "num_units", "=", "64", ",", "share_weights", "=", "False", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "if", "reuse", "is", "None", ":", "\n", "        ", "reuse", "=", "tf", ".", "AUTO_REUSE", "if", "share_weights", "else", "False", "\n", "# This model takes as input an observation and returns values of all actions", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "basic", "=", "0", "\n", "shorton", "=", "1", "\n", "# split actions", "\n", "num_test", "=", "num_units", "//", "2", "\n", "\n", "\n", "batch_size", "=", "input", ".", "shape", "[", "0", "]", ".", "value", "\n", "input_action", "=", "input", "[", ":", ",", "-", "5", "*", "(", "n_adv", "+", "n_good", ")", ":", "]", "\n", "self_action", "=", "input_action", "[", ":", ",", "index", "*", "5", ":", "(", "index", "+", "1", ")", "*", "5", "]", "\n", "good_action", "=", "input_action", "[", ":", ",", "n_adv", "*", "5", ":", "]", "\n", "other_good_action", "=", "tf", ".", "concat", "(", "[", "input_action", "[", ":", ",", "5", "*", "n_adv", ":", "5", "*", "index", "]", ",", "input_action", "[", ":", ",", "5", "*", "(", "index", "+", "1", ")", ":", "]", "]", ",", "1", ")", "\n", "other_adv_action", "=", "input_action", "[", ":", ",", ":", "n_adv", "*", "5", "]", "\n", "\n", "# split self obs", "\n", "length_wolf", "=", "(", "n_land", ")", "*", "3", "+", "(", "n_good", "+", "n_adv", ")", "*", "5", "\n", "length_sheep", "=", "length_wolf", "\n", "self_start", "=", "n_adv", "*", "length_wolf", "+", "(", "index", "-", "n_adv", ")", "*", "length_sheep", "\n", "\n", "self_dim", "=", "length_sheep", "\n", "\n", "# self mlp", "\n", "\n", "input_obs_self", "=", "input", "[", ":", ",", "self_start", ":", "self_start", "+", "length_sheep", "]", "\n", "self_in", "=", "input_obs_self", "\n", "self_in", "=", "tf", ".", "concat", "(", "[", "self_in", ",", "self_action", "]", ",", "1", ")", "\n", "with", "tf", ".", "variable_scope", "(", "\"self\"", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "self_out", "=", "mlp_model_agent_p", "(", "self_in", ",", "num_test", ",", "'mlp'", ",", "index", ",", "n_adv", "=", "n_adv", ",", "n_good", "=", "n_good", ",", "n_land", "=", "n_land", ",", "\n", "share_weights", "=", "share_weights", ",", "num_units", "=", "num_units", ",", "with_action", "=", "True", ",", "reuse", "=", "reuse", ")", "\n", "\n", "# sheep mlp", "\n", "", "if", "n_good", "!=", "1", ":", "\n", "            ", "other_good_ins", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_good", ")", ":", "\n", "                ", "if", "i", "==", "index", "-", "n_adv", ":", "\n", "                    ", "continue", "\n", "", "other_good_beg", "=", "n_adv", "*", "length_wolf", "+", "i", "*", "length_sheep", "\n", "other_good_in", "=", "input", "[", ":", ",", "other_good_beg", ":", "other_good_beg", "+", "length_sheep", "]", "\n", "tmp", "=", "tf", ".", "concat", "(", "[", "other_good_in", ",", "good_action", "[", ":", ",", "i", "*", "5", ":", "(", "i", "+", "1", ")", "*", "5", "]", "]", ",", "1", ")", "\n", "other_good_ins", ".", "append", "(", "tmp", ")", "\n", "", "other_good_outs", "=", "[", "]", "\n", "\n", "if", "basic", ":", "\n", "                ", "other_good_out", "=", "tf", ".", "concat", "(", "[", "i", "for", "i", "in", "other_good_ins", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "                ", "batch_other_good_ins", "=", "tf", ".", "concat", "(", "other_good_ins", ",", "axis", "=", "0", ")", "\n", "with", "tf", ".", "variable_scope", "(", "(", "\"good0\"", "if", "NUMBERED", "else", "\"good\"", ")", ",", "reuse", "=", "reuse", ")", ":", "\n", "                    ", "out", "=", "mlp_model_agent_p", "(", "batch_other_good_ins", ",", "num_test", ",", "'mlp'", ",", "0", ",", "n_adv", "=", "n_adv", ",", "\n", "n_good", "=", "n_good", ",", "n_land", "=", "n_land", ",", "share_weights", "=", "share_weights", ",", "num_units", "=", "num_units", ",", "\n", "with_action", "=", "True", ",", "reuse", "=", "reuse", ")", "\n", "other_good_outs", "=", "tf", ".", "split", "(", "out", ",", "n_good", "-", "1", ",", "axis", "=", "0", ")", "\n", "", "", "", "else", ":", "\n", "            ", "other_good_outs", "=", "[", "]", "\n", "\n", "\n", "#wolf_mlp", "\n", "", "other_adv_ins", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_adv", ")", ":", "\n", "            ", "other_adv_beg", "=", "length_wolf", "*", "i", "\n", "other_adv_in", "=", "input", "[", ":", ",", "other_adv_beg", ":", "other_adv_beg", "+", "length_wolf", "]", "\n", "tmp", "=", "tf", ".", "concat", "(", "[", "other_adv_in", ",", "other_adv_action", "[", ":", ",", "i", "*", "5", ":", "(", "i", "+", "1", ")", "*", "5", "]", "]", ",", "1", ")", "\n", "other_adv_ins", ".", "append", "(", "tmp", ")", "\n", "\n", "", "other_adv_outs", "=", "[", "]", "\n", "if", "basic", ":", "\n", "            ", "other_adv_out", "=", "tf", ".", "concat", "(", "[", "i", "for", "i", "in", "other_adv_ins", "]", ",", "1", ")", "\n", "", "elif", "n_adv", ">", "0", ":", "\n", "            ", "batch_other_adv_ins", "=", "tf", ".", "concat", "(", "other_adv_ins", ",", "axis", "=", "0", ")", "\n", "with", "tf", ".", "variable_scope", "(", "(", "\"adv0\"", "if", "NUMBERED", "else", "\"adv\"", ")", ",", "reuse", "=", "reuse", ")", ":", "\n", "                ", "out", "=", "mlp_model_adv_p", "(", "batch_other_adv_ins", ",", "num_test", ",", "'mlp'", ",", "0", ",", "n_adv", "=", "n_adv", ",", "n_good", "=", "n_good", ",", "\n", "n_land", "=", "n_land", ",", "reuse", "=", "reuse", ",", "num_units", "=", "num_units", ",", "with_action", "=", "True", ",", "share_weights", "=", "share_weights", ")", "\n", "other_adv_outs", "=", "tf", ".", "split", "(", "out", ",", "n_adv", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "theta_out", "=", "[", "]", "\n", "phi_out", "=", "[", "]", "\n", "g_out", "=", "[", "]", "\n", "\n", "theta_out", ".", "append", "(", "FULLY_CONNECTED", "(", "self_out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'theta_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "phi_out", ".", "append", "(", "FULLY_CONNECTED", "(", "self_out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'phi_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "g_out", ".", "append", "(", "FULLY_CONNECTED", "(", "self_out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'g_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "for", "i", ",", "out", "in", "enumerate", "(", "other_good_outs", ")", ":", "\n", "            ", "theta_out", ".", "append", "(", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'theta_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "phi_out", ".", "append", "(", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'phi_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "g_out", ".", "append", "(", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'g_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "", "for", "i", ",", "out", "in", "enumerate", "(", "other_adv_outs", ")", ":", "\n", "            ", "theta_out", ".", "append", "(", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'theta_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "phi_out", ".", "append", "(", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'phi_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "g_out", ".", "append", "(", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'g_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "\n", "", "theta_outs", "=", "tf", ".", "stack", "(", "theta_out", ",", "2", ")", "\n", "# print(theta_outs.get_shape(),'theta_outs')", "\n", "# print(theta_out[0].get_shape(),'theta')", "\n", "phi_outs", "=", "tf", ".", "stack", "(", "phi_out", ",", "2", ")", "\n", "g_outs", "=", "tf", ".", "stack", "(", "g_out", ",", "2", ")", "\n", "self_attention", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "matmul", "(", "theta_outs", ",", "tf", ".", "transpose", "(", "phi_outs", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", "/", "math", ".", "sqrt", "(", "num_test", ")", ")", "\n", "# print(self_attention.get_shape(),'self_attention')", "\n", "input_all", "=", "tf", ".", "matmul", "(", "self_attention", ",", "g_outs", ")", "\n", "input_all_new", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_adv", "+", "n_good", ")", ":", "\n", "            ", "input_all_new", ".", "append", "(", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "input_all", "[", ":", ",", ":", ",", "i", "]", ",", "scope", "=", "'qlayernorm1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ")", "\n", "", "input_all", "=", "tf", ".", "stack", "(", "input_all_new", ",", "2", ")", "\n", "# input_all = tf.contrib.layers.layer_norm(input_all)", "\n", "input_all", "=", "tf", ".", "nn", ".", "relu", "(", "input_all", ")", "\n", "\n", "\n", "self_out_new", "=", "input_all", "[", ":", ",", ":", ",", "0", "]", "\n", "good_out_new", "=", "input_all", "[", ":", ",", ":", ",", "1", ":", "n_good", "]", "\n", "adv_out_new", "=", "input_all", "[", ":", ",", ":", ",", "n_good", ":", "]", "\n", "if", "(", "n_adv", ">", "0", ")", ":", "\n", "            ", "other_adv_out_attn", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "matmul", "(", "tf", ".", "expand_dims", "(", "self_out_new", ",", "1", ")", ",", "adv_out_new", ")", "/", "math", ".", "sqrt", "(", "num_test", ")", ")", "\n", "other_adv_out", "=", "tf", ".", "squeeze", "(", "tf", ".", "matmul", "(", "other_adv_out_attn", ",", "tf", ".", "transpose", "(", "adv_out_new", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", ",", "1", ")", "\n", "other_adv_out", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "other_adv_out", ")", "\n", "other_adv_out", "=", "tf", ".", "nn", ".", "relu", "(", "other_adv_out", ")", "\n", "\n", "", "other_good_out_attn", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "matmul", "(", "tf", ".", "expand_dims", "(", "self_out_new", ",", "1", ")", ",", "good_out_new", ")", "/", "math", ".", "sqrt", "(", "num_test", ")", ")", "\n", "other_good_out", "=", "tf", ".", "squeeze", "(", "tf", ".", "matmul", "(", "other_good_out_attn", ",", "tf", ".", "transpose", "(", "good_out_new", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", ",", "1", ")", "\n", "other_good_out", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "other_good_out", ")", "\n", "other_good_out", "=", "tf", ".", "nn", ".", "relu", "(", "other_good_out", ")", "\n", "# merge layer for all", "\n", "if", "n_good", "==", "1", ":", "\n", "            ", "input_merge", "=", "tf", ".", "concat", "(", "[", "self_out", ",", "other_adv_out", "]", ",", "1", ")", "\n", "", "elif", "(", "n_adv", "<=", "0", ")", ":", "\n", "            ", "input_merge", "=", "tf", ".", "concat", "(", "[", "self_out", ",", "other_good_out", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "input_merge", "=", "tf", ".", "concat", "(", "[", "self_out", ",", "other_good_out", ",", "other_adv_out", "]", ",", "1", ")", "\n", "\n", "", "out", "=", "FULLY_CONNECTED", "(", "input_merge", ",", "num_outputs", "=", "num_units", ",", "scope", "=", "'last_1'", ",", "activation_fn", "=", "tf", ".", "nn", ".", "leaky_relu", ")", "\n", "out", "=", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_units", ",", "scope", "=", "'last_11'", ",", "activation_fn", "=", "tf", ".", "nn", ".", "leaky_relu", ")", "\n", "out", "=", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_outputs", ",", "scope", "=", "'last_2'", ",", "activation_fn", "=", "None", ")", "\n", "\n", "# print(\"mlp_model_agent_q\",", "\n", "#       len(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=tf.get_variable_scope().name)))", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.model_v3_test3.mlp_model_adv_q": [[697, 839], ["tensorflow.variable_scope", "tensorflow.concat", "tensorflow.concat", "range", "theta_out.append", "phi_out.append", "g_out.append", "enumerate", "enumerate", "tensorflow.stack", "tensorflow.stack", "tensorflow.stack", "tensorflow.nn.softmax", "tensorflow.matmul", "range", "tensorflow.stack", "tensorflow.nn.relu", "tensorflow.nn.softmax", "tensorflow.squeeze", "tensorflow.contrib.layers.layer_norm", "tensorflow.nn.relu", "FULLY_CONNECTED", "FULLY_CONNECTED", "FULLY_CONNECTED", "tensorflow.variable_scope", "model_v3_test3.mlp_model_adv_p", "tensorflow.concat", "other_good_ins.append", "tensorflow.concat", "tensorflow.concat", "range", "FULLY_CONNECTED", "FULLY_CONNECTED", "FULLY_CONNECTED", "theta_out.append", "phi_out.append", "g_out.append", "theta_out.append", "phi_out.append", "g_out.append", "input_all_new.append", "tensorflow.nn.softmax", "tensorflow.squeeze", "tensorflow.contrib.layers.layer_norm", "tensorflow.nn.relu", "tensorflow.matmul", "tensorflow.concat", "tensorflow.variable_scope", "model_v3_test3.mlp_model_agent_p", "tensorflow.split", "tensorflow.concat", "other_adv_ins.append", "tensorflow.concat", "tensorflow.concat", "FULLY_CONNECTED", "FULLY_CONNECTED", "FULLY_CONNECTED", "FULLY_CONNECTED", "FULLY_CONNECTED", "FULLY_CONNECTED", "tensorflow.matmul", "math.sqrt", "tensorflow.contrib.layers.layer_norm", "tensorflow.matmul", "tensorflow.matmul", "math.sqrt", "tensorflow.transpose", "tensorflow.concat", "tensorflow.concat", "tensorflow.variable_scope", "model_v3_test3.mlp_model_adv_p", "tensorflow.split", "tensorflow.transpose", "tensorflow.matmul", "math.sqrt", "tensorflow.transpose", "tensorflow.expand_dims", "tensorflow.expand_dims"], "function", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.softmax", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.softmax", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.model_v3_test3.mlp_model_adv_p", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.common.tf_util.softmax", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.model_v3_test3.mlp_model_agent_p", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.model_v3_test3.mlp_model_adv_p"], ["", "", "def", "mlp_model_adv_q", "(", "input", ",", "num_outputs", ",", "scope", ",", "index", ",", "n_adv", "=", "3", ",", "n_good", "=", "5", ",", "n_land", "=", "6", ",", "share_weights", "=", "False", ",", "num_units", "=", "64", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "if", "reuse", "is", "None", ":", "\n", "        ", "reuse", "=", "tf", ".", "AUTO_REUSE", "if", "share_weights", "else", "False", "\n", "# This model takes as input an observation and returns values of all actions", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "# split actions", "\n", "        ", "basic", "=", "0", "\n", "self_dim", "=", "n_land", "*", "3", "+", "5", "\n", "shorton", "=", "1", "\n", "num_test", "=", "num_units", "//", "2", "\n", "input_action", "=", "input", "[", ":", ",", "-", "5", "*", "(", "n_adv", "+", "n_good", ")", ":", "]", "\n", "self_action", "=", "input_action", "[", ":", ",", "index", "*", "5", ":", "(", "index", "+", "1", ")", "*", "5", "]", "\n", "other_good_action", "=", "input_action", "[", ":", ",", "5", "*", "n_adv", ":", "]", "\n", "adv_action", "=", "input_action", "[", ":", ",", ":", "5", "*", "n_adv", "]", "\n", "other_adv_action", "=", "tf", ".", "concat", "(", "[", "input_action", "[", ":", ",", ":", "5", "*", "index", "]", ",", "input_action", "[", ":", ",", "5", "*", "(", "index", "+", "1", ")", ":", "5", "*", "n_adv", "]", "]", ",", "1", ")", "\n", "\n", "# split self obs", "\n", "length_wolf", "=", "(", "n_land", ")", "*", "3", "+", "(", "n_good", "+", "n_adv", ")", "*", "5", "\n", "length_sheep", "=", "length_wolf", "\n", "\n", "## self input mlp", "\n", "self_start", "=", "index", "*", "length_wolf", "\n", "input_obs_self", "=", "input", "[", ":", ",", "self_start", ":", "self_start", "+", "length_wolf", "]", "\n", "batch_size", "=", "input", ".", "shape", "[", "0", "]", ".", "value", "\n", "self_in", "=", "tf", ".", "concat", "(", "[", "input_obs_self", ",", "self_action", "]", ",", "1", ")", "\n", "with", "tf", ".", "variable_scope", "(", "\"self\"", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "self_out", "=", "mlp_model_adv_p", "(", "self_in", ",", "num_test", ",", "'mlp'", ",", "index", ",", "n_adv", "=", "n_adv", ",", "n_good", "=", "n_good", ",", "n_land", "=", "n_land", ",", "\n", "share_weights", "=", "share_weights", ",", "num_units", "=", "num_units", ",", "with_action", "=", "True", ",", "reuse", "=", "reuse", ")", "\n", "\n", "# other sheep mlp", "\n", "", "other_good_ins", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_good", ")", ":", "\n", "            ", "other_good_beg", "=", "n_adv", "*", "length_wolf", "+", "i", "*", "length_sheep", "\n", "other_good_in", "=", "input", "[", ":", ",", "other_good_beg", ":", "other_good_beg", "+", "length_sheep", "]", "\n", "tmp", "=", "tf", ".", "concat", "(", "[", "other_good_in", ",", "other_good_action", "[", ":", ",", "i", "*", "5", ":", "(", "i", "+", "1", ")", "*", "5", "]", "]", ",", "axis", "=", "1", ")", "\n", "other_good_ins", ".", "append", "(", "tmp", ")", "\n", "\n", "", "other_good_outs", "=", "[", "]", "\n", "if", "basic", ":", "\n", "            ", "other_good_out", "=", "tf", ".", "concat", "(", "[", "i", "for", "i", "in", "other_good_ins", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "batch_other_good_ins", "=", "tf", ".", "concat", "(", "other_good_ins", ",", "axis", "=", "0", ")", "\n", "# for i in range(n_good):", "\n", "with", "tf", ".", "variable_scope", "(", "(", "\"good0\"", "if", "NUMBERED", "else", "\"good\"", ")", ",", "reuse", "=", "reuse", ")", ":", "\n", "                ", "out", "=", "mlp_model_agent_p", "(", "batch_other_good_ins", ",", "num_test", ",", "'mlp'", ",", "0", ",", "n_adv", "=", "n_adv", ",", "n_good", "=", "n_good", ",", "\n", "n_land", "=", "n_land", ",", "share_weights", "=", "share_weights", ",", "num_units", "=", "num_units", ",", "with_action", "=", "True", ",", "reuse", "=", "reuse", ")", "\n", "other_good_outs", "=", "tf", ".", "split", "(", "out", ",", "n_good", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "if", "n_adv", "!=", "1", ":", "\n", "\n", "            ", "other_adv_ins", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_adv", ")", ":", "\n", "                ", "if", "i", "==", "index", ":", "\n", "                    ", "continue", "\n", "", "other_adv_beg", "=", "length_wolf", "*", "i", "\n", "other_adv_in", "=", "input", "[", ":", ",", "other_adv_beg", ":", "other_adv_beg", "+", "length_wolf", "]", "\n", "tmp", "=", "tf", ".", "concat", "(", "[", "other_adv_in", ",", "adv_action", "[", ":", ",", "i", "*", "5", ":", "(", "i", "+", "1", ")", "*", "5", "]", "]", ",", "1", ")", "\n", "other_adv_ins", ".", "append", "(", "tmp", ")", "\n", "\n", "", "other_adv_outs", "=", "[", "]", "\n", "if", "basic", ":", "\n", "                ", "other_adv_out", "=", "tf", ".", "concat", "(", "[", "i", "for", "i", "in", "other_adv_ins", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "                ", "batch_other_adv_ins", "=", "tf", ".", "concat", "(", "other_adv_ins", ",", "axis", "=", "0", ")", "\n", "# for i in range(n_adv-1):", "\n", "#     true_id = i if i < index else i + 1", "\n", "with", "tf", ".", "variable_scope", "(", "(", "\"adv0\"", "if", "NUMBERED", "else", "\"adv\"", ")", ",", "reuse", "=", "reuse", ")", ":", "\n", "                    ", "out", "=", "mlp_model_adv_p", "(", "batch_other_adv_ins", ",", "num_test", ",", "'mlp'", ",", "0", ",", "n_adv", "=", "n_adv", ",", "n_good", "=", "n_good", ",", "\n", "n_land", "=", "n_land", ",", "share_weights", "=", "share_weights", ",", "num_units", "=", "num_units", ",", "with_action", "=", "True", ",", "reuse", "=", "reuse", ")", "\n", "other_adv_outs", "=", "tf", ".", "split", "(", "out", ",", "n_adv", "-", "1", ",", "axis", "=", "0", ")", "\n", "", "", "", "else", ":", "\n", "            ", "other_adv_outs", "=", "[", "]", "\n", "\n", "", "theta_out", "=", "[", "]", "\n", "phi_out", "=", "[", "]", "\n", "g_out", "=", "[", "]", "\n", "\n", "theta_out", ".", "append", "(", "FULLY_CONNECTED", "(", "self_out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'theta_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "phi_out", ".", "append", "(", "FULLY_CONNECTED", "(", "self_out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'phi_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "g_out", ".", "append", "(", "FULLY_CONNECTED", "(", "self_out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'g_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "for", "i", ",", "out", "in", "enumerate", "(", "other_good_outs", ")", ":", "\n", "            ", "theta_out", ".", "append", "(", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'theta_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "phi_out", ".", "append", "(", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'phi_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "g_out", ".", "append", "(", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'g_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "", "for", "i", ",", "out", "in", "enumerate", "(", "other_adv_outs", ")", ":", "\n", "            ", "theta_out", ".", "append", "(", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'theta_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "phi_out", ".", "append", "(", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'phi_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "g_out", ".", "append", "(", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_test", ",", "scope", "=", "'g_f'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "activation_fn", "=", "None", ")", ")", "\n", "\n", "", "theta_outs", "=", "tf", ".", "stack", "(", "theta_out", ",", "2", ")", "\n", "# print(theta_outs.get_shape(),'theta_outs')", "\n", "# print(theta_out[0].get_shape(),'theta')", "\n", "phi_outs", "=", "tf", ".", "stack", "(", "phi_out", ",", "2", ")", "\n", "g_outs", "=", "tf", ".", "stack", "(", "g_out", ",", "2", ")", "\n", "self_attention", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "matmul", "(", "theta_outs", ",", "tf", ".", "transpose", "(", "phi_outs", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", "/", "math", ".", "sqrt", "(", "num_test", ")", ")", "\n", "# print(self_attention.get_shape(),'self_attention')", "\n", "input_all", "=", "tf", ".", "matmul", "(", "self_attention", ",", "g_outs", ")", "\n", "input_all_new", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_adv", "+", "n_good", ")", ":", "\n", "            ", "input_all_new", ".", "append", "(", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "input_all", "[", ":", ",", ":", ",", "i", "]", ",", "scope", "=", "'qlayernorm1'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ")", "\n", "", "input_all", "=", "tf", ".", "stack", "(", "input_all_new", ",", "2", ")", "\n", "'''\n        input_all = tf.contrib.layers.layer_norm(input_all)\n        '''", "\n", "# input_all_new2 = tf.stack(input_all_new1, 2)", "\n", "input_all", "=", "tf", ".", "nn", ".", "relu", "(", "input_all", ")", "\n", "\n", "\n", "self_out_new", "=", "input_all", "[", ":", ",", ":", ",", "0", "]", "\n", "good_out_new", "=", "input_all", "[", ":", ",", ":", ",", "1", ":", "1", "+", "n_good", "]", "\n", "adv_out_new", "=", "input_all", "[", ":", ",", ":", ",", "1", "+", "n_good", ":", "]", "\n", "\n", "if", "(", "n_adv", ">", "0", ")", ":", "\n", "            ", "other_adv_out_attn", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "matmul", "(", "tf", ".", "expand_dims", "(", "self_out_new", ",", "1", ")", ",", "adv_out_new", ")", "/", "math", ".", "sqrt", "(", "num_test", ")", ")", "\n", "other_adv_out", "=", "tf", ".", "squeeze", "(", "tf", ".", "matmul", "(", "other_adv_out_attn", ",", "tf", ".", "transpose", "(", "adv_out_new", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", ",", "1", ")", "\n", "other_adv_out", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "other_adv_out", ")", "\n", "other_adv_out", "=", "tf", ".", "nn", ".", "relu", "(", "other_adv_out", ")", "\n", "\n", "", "other_good_out_attn", "=", "tf", ".", "nn", ".", "softmax", "(", "tf", ".", "matmul", "(", "tf", ".", "expand_dims", "(", "self_out_new", ",", "1", ")", ",", "good_out_new", ")", "/", "math", ".", "sqrt", "(", "num_test", ")", ")", "\n", "other_good_out", "=", "tf", ".", "squeeze", "(", "tf", ".", "matmul", "(", "other_good_out_attn", ",", "tf", ".", "transpose", "(", "good_out_new", ",", "[", "0", ",", "2", ",", "1", "]", ")", ")", ",", "1", ")", "\n", "other_good_out", "=", "tf", ".", "contrib", ".", "layers", ".", "layer_norm", "(", "other_good_out", ")", "\n", "other_good_out", "=", "tf", ".", "nn", ".", "relu", "(", "other_good_out", ")", "\n", "\n", "\n", "# merge layer for all", "\n", "\n", "if", "n_adv", "==", "1", ":", "\n", "            ", "input_merge", "=", "tf", ".", "concat", "(", "[", "self_out", ",", "other_good_out", "]", ",", "1", ")", "\n", "", "elif", "n_adv", "<=", "0", ":", "\n", "            ", "input_merge", "=", "tf", ".", "concat", "(", "[", "self_out", ",", "other_good_out", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "input_merge", "=", "tf", ".", "concat", "(", "[", "self_out", ",", "other_good_out", ",", "other_adv_out", "]", ",", "1", ")", "\n", "\n", "\n", "", "out", "=", "FULLY_CONNECTED", "(", "input_merge", ",", "num_outputs", "=", "num_units", ",", "scope", "=", "'last_1'", ",", "activation_fn", "=", "tf", ".", "nn", ".", "leaky_relu", ")", "\n", "out", "=", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_units", ",", "scope", "=", "'last_11'", ",", "activation_fn", "=", "tf", ".", "nn", ".", "leaky_relu", ")", "\n", "out", "=", "FULLY_CONNECTED", "(", "out", ",", "num_outputs", "=", "num_outputs", ",", "scope", "=", "'last_2'", ",", "activation_fn", "=", "None", ")", "\n", "\n", "# print(\"mlp_model_adv_q\",", "\n", "#       len(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope=tf.get_variable_scope().name)))", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.model_v3_test3.mlp_model": [[840, 849], ["tensorflow.variable_scope", "tensorflow.contrib.layers.fully_connected", "tensorflow.contrib.layers.fully_connected", "tensorflow.contrib.layers.fully_connected"], "function", ["None"], ["", "", "def", "mlp_model", "(", "input", ",", "num_outputs", ",", "scope", ",", "reuse", "=", "False", ",", "num_units", "=", "64", ",", "rnn_cell", "=", "None", ")", ":", "\n", "# This model takes as input an observation and returns values of all actions", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "out", "=", "input", "\n", "out", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "out", ",", "num_outputs", "=", "num_units", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "out", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "out", ",", "num_outputs", "=", "num_units", ",", "activation_fn", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "out", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "out", ",", "num_outputs", "=", "num_outputs", ",", "activation_fn", "=", "None", ")", "\n", "# print(tf.shape(out))", "\n", "return", "out", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__init__": [[5, 17], ["int"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "\"\"\"Create Prioritized Replay buffer.\n\n        Parameters\n        ----------\n        size: int\n            Max number of transitions to store in the buffer. When the buffer\n            overflows the old memories are dropped.\n        \"\"\"", "\n", "self", ".", "_storage", "=", "[", "]", "\n", "self", ".", "_maxsize", "=", "int", "(", "size", ")", "\n", "self", ".", "_next_idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.__len__": [[18, 20], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_storage", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.clear": [[21, 24], ["None"], "methods", ["None"], ["", "def", "clear", "(", "self", ")", ":", "\n", "        ", "self", ".", "_storage", "=", "[", "]", "\n", "self", ".", "_next_idx", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.add": [[25, 33], ["len", "replay_buffer.ReplayBuffer._storage.append"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "obs_t", ",", "action", ",", "reward", ",", "obs_tp1", ",", "done", ")", ":", "\n", "        ", "data", "=", "(", "obs_t", ",", "action", ",", "reward", ",", "obs_tp1", ",", "done", ")", "\n", "\n", "if", "self", ".", "_next_idx", ">=", "len", "(", "self", ".", "_storage", ")", ":", "\n", "            ", "self", ".", "_storage", ".", "append", "(", "data", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_storage", "[", "self", ".", "_next_idx", "]", "=", "data", "\n", "", "self", ".", "_next_idx", "=", "(", "self", ".", "_next_idx", "+", "1", ")", "%", "self", ".", "_maxsize", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer._encode_sample": [[34, 45], ["obses_t.append", "actions.append", "rewards.append", "obses_tp1.append", "dones.append", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "_encode_sample", "(", "self", ",", "idxes", ")", ":", "\n", "        ", "obses_t", ",", "actions", ",", "rewards", ",", "obses_tp1", ",", "dones", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "idxes", ":", "\n", "            ", "data", "=", "self", ".", "_storage", "[", "i", "]", "\n", "obs_t", ",", "action", ",", "reward", ",", "obs_tp1", ",", "done", "=", "data", "\n", "obses_t", ".", "append", "(", "np", ".", "array", "(", "obs_t", ",", "copy", "=", "False", ")", ")", "\n", "actions", ".", "append", "(", "np", ".", "array", "(", "action", ",", "copy", "=", "False", ")", ")", "\n", "rewards", ".", "append", "(", "reward", ")", "\n", "obses_tp1", ".", "append", "(", "np", ".", "array", "(", "obs_tp1", ",", "copy", "=", "False", ")", ")", "\n", "dones", ".", "append", "(", "done", ")", "\n", "", "return", "np", ".", "array", "(", "obses_t", ")", ",", "np", ".", "array", "(", "actions", ")", ",", "np", ".", "array", "(", "rewards", ")", ",", "np", ".", "array", "(", "obses_tp1", ")", ",", "np", ".", "array", "(", "dones", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.encode_sample_simple": [[46, 69], ["range", "range", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "obses_t[].append", "actions[].append", "obses_tp1[].append", "rewards[].append", "dones[].append", "range", "range", "range", "range", "range"], "methods", ["None"], ["", "def", "_encode_sample_simple", "(", "self", ",", "idxes", ")", ":", "\n", "        ", "obses_t", ",", "actions", ",", "rewards", ",", "obses_tp1", ",", "dones", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "idxes", ":", "\n", "            ", "data", "=", "self", ".", "_storage", "[", "i", "]", "\n", "obs_t", ",", "action", ",", "reward", ",", "obs_tp1", ",", "done", "=", "data", "\n", "obses_t", ".", "append", "(", "obs_t", ")", "\n", "actions", ".", "append", "(", "action", ")", "\n", "rewards", ".", "append", "(", "reward", ")", "\n", "obses_tp1", ".", "append", "(", "obs_tp1", ")", "\n", "dones", ".", "append", "(", "done", ")", "\n", "", "return", "obses_t", ",", "actions", ",", "rewards", ",", "obses_tp1", ",", "dones", "\n", "\n", "", "def", "make_index", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "return", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "_storage", ")", "-", "1", ")", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "", "def", "make_latest_index", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "idx", "=", "[", "(", "self", ".", "_next_idx", "-", "1", "-", "i", ")", "%", "self", ".", "_maxsize", "for", "i", "in", "range", "(", "batch_size", ")", "]", "\n", "np", ".", "random", ".", "shuffle", "(", "idx", ")", "\n", "return", "idx", "\n", "\n", "", "def", "sample_index", "(", "self", ",", "idxes", ",", "simple", "=", "False", ")", ":", "\n", "        ", "if", "simple", ":", "\n", "            ", "return", "self", ".", "_encode_sample_simple", "(", "idxes", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.make_index": [[70, 72], ["random.randint", "range", "len"], "methods", ["None"], ["            ", "return", "self", ".", "_encode_sample", "(", "idxes", ")", "\n", "\n", "", "", "def", "sample", "(", "self", ",", "batch_size", ")", ":", "\n"]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.make_latest_index": [[73, 77], ["numpy.random.shuffle", "range"], "methods", ["None"], ["        "]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample_index": [[78, 80], ["replay_buffer.ReplayBuffer._encode_sample_simple"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.trainer.replay_buffer.ReplayBuffer._encode_sample_simple"], []], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample": [[81, 108], ["replay_buffer.ReplayBuffer._encode_sample", "replay_buffer.ReplayBuffer.make_index", "range", "len"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer._encode_sample", "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.make_index"], ["\n", "if", "batch_size", ">", "0", ":", "\n", "            ", "idxes", "=", "self", ".", "make_index", "(", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "idxes", "=", "range", "(", "0", ",", "len", "(", "self", ".", "_storage", ")", ")", "\n", "", "return", "self", ".", "_encode_sample", "(", "idxes", ")", "\n", "\n", "", "def", "collect", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sample", "(", "-", "1", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.collect": [[109, 111], ["replay_buffer.ReplayBuffer.sample"], "methods", ["home.repos.pwc.inspect_result.baoqianwang_iros22_darl1n.train_helper.replay_buffer.ReplayBuffer.sample"], []]}