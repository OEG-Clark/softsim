{"home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.get_validset_feeds": [[9, 22], ["ops.pad_seqs"], "function", ["home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.pad_seqs"], ["def", "get_validset_feeds", "(", "model", ",", "x", ",", "y", ",", "h_dim", ")", ":", "\n", "    ", "x_new", ",", "v_seq_lengths", "=", "pad_seqs", "(", "x", ")", "\n", "\n", "input_feed", "=", "{", "model", ".", "x", ":", "x_new", ",", "\n", "model", ".", "y", ":", "y", ",", "\n", "model", ".", "seq_lens", ":", "v_seq_lengths", ",", "\n", "model", ".", "training", ":", "True", ",", "\n", "model", ".", "keep_prob", ":", "1.0", ",", "\n", "}", "\n", "\n", "output_feed", "=", "[", "model", ".", "loss_nowd", ",", "model", ".", "output_probs", "]", "\n", "\n", "return", "input_feed", ",", "output_feed", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.save_config_dict": [[24, 48], ["zip", "open", "json.dump", "type", "list", "type", "val.astype"], "function", ["None"], ["", "def", "save_config_dict", "(", "config", ",", "path", ",", "tags", "=", "None", ",", "values", "=", "None", ")", ":", "\n", "    ", "'''\n    Save a dictionary (config) to a json file in path\n\n    Input:\n    config  - A dictionary to save\n    path    - String specifying the path\n    tags    - (optional) The keys to add to the dict\n    values  - (optional) The values to add to the dict\n    '''", "\n", "if", "'.json'", "not", "in", "path", ":", "\n", "        ", "path", "=", "path", "+", "'config.json'", "\n", "\n", "", "if", "tags", "is", "not", "None", "and", "values", "is", "not", "None", ":", "\n", "        ", "for", "tag", ",", "val", "in", "zip", "(", "tags", ",", "values", ")", ":", "\n", "            ", "if", "type", "(", "val", ")", "is", "np", ".", "ndarray", ":", "\n", "                ", "config", "[", "tag", "]", "=", "list", "(", "val", ")", "\n", "", "else", ":", "\n", "                ", "config", "[", "tag", "]", "=", "val", "\n", "if", "type", "(", "val", ")", "==", "np", ".", "float32", ":", "\n", "                    ", "config", "[", "tag", "]", "=", "val", ".", "astype", "(", "np", ".", "float64", ")", "\n", "\n", "", "", "", "", "with", "open", "(", "path", ",", "'w'", ")", "as", "fp", ":", "\n", "        ", "json", ".", "dump", "(", "config", ",", "fp", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.create_conf_dict": [[50, 62], ["copy.deepcopy", "vars"], "function", ["None"], ["", "", "def", "create_conf_dict", "(", "args", ")", ":", "\n", "    ", "'''\n    Create the config dictionary from tensorflow flags.\n    '''", "\n", "d", "=", "copy", ".", "deepcopy", "(", "vars", "(", "args", ")", ")", "# Important to copy the dict,", "\n", "# otherwise the original args", "\n", "# dictionary will be mutated.", "\n", "del", "d", "[", "'logdir'", "]", "\n", "del", "d", "[", "'test'", "]", "\n", "del", "d", "[", "'gpu'", "]", "\n", "\n", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.calculate_metrics": [[64, 95], ["numpy.average", "sklearn.metrics.f1_score", "numpy.array", "len", "numpy.argmax", "len", "numpy.argmax", "numpy.equal", "len", "numpy.reshape", "numpy.argmax", "len", "numpy.reshape", "numpy.argmax"], "function", ["None"], ["", "def", "calculate_metrics", "(", "y_true", ",", "y_pred", ",", "labels", "=", "None", ")", ":", "\n", "    ", "'''\n    A function to compute the accuracy, F1 score.\n    The 'macro' F1 score is computed; meaning the F1 score is computed for each\n    class and then the unwieghted average is returned.\n\n    Input:\n    y_true - a numpy array of true labels.\n    y_pred - a numpy array of predicted labels.\n    labels - the labels for each class in y_true with shape (max(y_true)+1).\n\n    Returns:\n    A numpy array of Accuracy and F1\n    '''", "\n", "if", "len", "(", "y_true", ".", "shape", ")", "==", "2", ":", "\n", "        ", "y_true", "=", "np", ".", "argmax", "(", "y_true", ",", "axis", "=", "1", ")", "\n", "", "elif", "len", "(", "y_true", ".", "shape", ")", "==", "3", ":", "\n", "        ", "y_flat", "=", "np", ".", "reshape", "(", "y_true", ",", "(", "-", "1", ",", "y_true", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "y_true", "=", "np", ".", "argmax", "(", "y_flat", ",", "axis", "=", "1", ")", "\n", "\n", "", "if", "len", "(", "y_pred", ".", "shape", ")", "==", "2", ":", "\n", "        ", "y_pred", "=", "np", ".", "argmax", "(", "y_pred", ",", "axis", "=", "1", ")", "\n", "", "elif", "len", "(", "y_pred", ".", "shape", ")", "==", "3", ":", "\n", "        ", "y_flat", "=", "np", ".", "reshape", "(", "y_pred", ",", "(", "-", "1", ",", "y_pred", ".", "shape", "[", "-", "1", "]", ")", ")", "\n", "y_pred", "=", "np", ".", "argmax", "(", "y_flat", ",", "axis", "=", "1", ")", "\n", "\n", "", "acc", "=", "np", ".", "average", "(", "np", ".", "equal", "(", "y_true", ",", "y_pred", ")", ")", "\n", "\n", "F1", "=", "metrics", ".", "f1_score", "(", "y_true", ",", "y_pred", ",", "labels", ",", "average", "=", "'macro'", ")", "\n", "\n", "return", "np", ".", "array", "(", "[", "acc", ",", "F1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.get_max_length": [[97, 108], ["len", "max", "len"], "function", ["None"], ["", "def", "get_max_length", "(", "var", ")", ":", "\n", "    ", "'''\n    A function that returns the largest length of an array in a list of arrays.\n\n    Input:\n    var - A list of numpy arrays\n\n    Returns:\n    The largest length (int)\n    '''", "\n", "return", "len", "(", "max", "(", "var", ",", "key", "=", "lambda", "v", ":", "len", "(", "v", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.print_metrics": [[110, 124], ["range", "print", "print", "len", "tags[].rjust"], "function", ["None"], ["", "def", "print_metrics", "(", "tags", ",", "values", ")", ":", "\n", "    ", "'''\n    Prints the tags and values column-wise\n    The columns have a width of 13 characters and tags should not be\n    longer than 10 characters\n    '''", "\n", "label_str", "=", "\"\"", "\n", "value_str", "=", "''", "\n", "for", "i", "in", "range", "(", "len", "(", "tags", ")", ")", ":", "\n", "        ", "label_str", "+=", "tags", "[", "i", "]", ".", "rjust", "(", "13", ")", "\n", "value_str", "+=", "'{:13.4}'", ".", "format", "(", "values", "[", "i", "]", ")", "\n", "\n", "", "print", "(", "label_str", ")", "\n", "print", "(", "value_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.get_minibatches_indices": [[126, 161], ["numpy.arange", "range", "numpy.random.shuffle", "minibatches.append", "random.shuffle", "minibatches.append"], "function", ["None"], ["", "def", "get_minibatches_indices", "(", "n", ",", "minibatch_size", ",", "shuffle", "=", "True", ",", "\n", "shuffleBatches", "=", "True", ",", "\n", "allow_smaller_final_batch", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Inputs:\n    n - An integer corresponding to the total number of data points\n\n    Returns:\n    minibatches - a list of lists with indices in the lowest dimension\n    \"\"\"", "\n", "idx_list", "=", "np", ".", "arange", "(", "n", ",", "dtype", "=", "\"int32\"", ")", "\n", "\n", "if", "shuffle", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "idx_list", ")", "\n", "\n", "", "if", "n", "<=", "minibatch_size", ":", "\n", "        ", "return", "[", "idx_list", "]", "\n", "\n", "", "minibatches", "=", "[", "]", "\n", "minibatch_start", "=", "0", "\n", "\n", "for", "i", "in", "range", "(", "n", "//", "minibatch_size", ")", ":", "\n", "        ", "minibatches", ".", "append", "(", "idx_list", "[", "minibatch_start", ":", "\n", "minibatch_start", "+", "minibatch_size", "]", ")", "\n", "minibatch_start", "+=", "minibatch_size", "\n", "", "if", "allow_smaller_final_batch", ":", "\n", "        ", "if", "(", "minibatch_start", "!=", "n", ")", ":", "\n", "# Make a minibatch out of what is left", "\n", "            ", "minibatches", ".", "append", "(", "idx_list", "[", "minibatch_start", ":", "]", ")", "\n", "\n", "", "", "if", "shuffleBatches", "is", "True", ":", "\n", "# minibatches here is a list of list indexes", "\n", "        ", "random", ".", "shuffle", "(", "minibatches", ")", "\n", "\n", "", "return", "minibatches", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.random_split": [[163, 170], ["numpy.arange", "numpy.setdiff1d", "numpy.all", "numpy.random.choice", "numpy.sort", "int", "numpy.hstack", "numpy.ceil"], "function", ["None"], ["", "def", "random_split", "(", "n", ",", "test_frac", "=", "0.1", ")", ":", "\n", "    ", "all_idx", "=", "np", ".", "arange", "(", "n", ")", "\n", "test_idx", "=", "all_idx", "[", "np", ".", "random", ".", "choice", "(", "\n", "n", ",", "int", "(", "np", ".", "ceil", "(", "test_frac", "*", "n", ")", ")", ",", "replace", "=", "False", ")", "]", "\n", "train_idx", "=", "np", ".", "setdiff1d", "(", "all_idx", ",", "test_idx", ")", "\n", "assert", "(", "np", ".", "all", "(", "np", ".", "sort", "(", "np", ".", "hstack", "(", "[", "train_idx", ",", "test_idx", "]", ")", ")", "==", "all_idx", ")", ")", "\n", "return", "train_idx", ",", "test_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.randomly_split_data": [[172, 240], ["min", "len", "print", "ops.one_hot_encoder", "one_hot_encoder.sum", "ops.random_split", "numpy.all", "numpy.all", "print", "print", "print", "print", "print", "print", "print", "y[].sum", "y[].sum", "print", "y[].sum", "y[].sum", "ops.random_split", "numpy.all", "numpy.all", "numpy.sort", "numpy.sort", "len", "len", "len", "len", "len", "print", "print", "print", "print", "print", "print", "[].sum", "[].sum", "numpy.sort", "numpy.sort", "numpy.sort", "[].sum", "[].sum"], "function", ["home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.one_hot_encoder", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.random_split", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.random_split"], ["", "def", "randomly_split_data", "(", "y", ",", "test_frac", "=", "0.5", ",", "valid_frac", "=", "0", ")", ":", "\n", "    ", "'''\n    Split the data into 3 sets:\n\n    Returns a tuple with:\n        train-idx       - A list of the train indices.\n        valid-idx       - A list of the validation indices.\n        test-idx        - A list of the testing indices.\n    '''", "\n", "if", "len", "(", "y", ".", "shape", ")", "==", "1", ":", "\n", "        ", "print", "(", "'Warning: are you sure Y contains all the classes?'", ")", "\n", "y", "=", "one_hot_encoder", "(", "y", ")", "\n", "\n", "", "split", "=", "None", "\n", "smallest_class", "=", "min", "(", "y", ".", "sum", "(", "axis", "=", "0", ")", ")", "\n", "\n", "while", "split", "is", "None", ":", "\n", "        ", "not_test_idx", ",", "test_idx", "=", "random_split", "(", "\n", "y", ".", "shape", "[", "0", "]", ",", "test_frac", "=", "test_frac", "+", "valid_frac", ")", "\n", "\n", "cond1", "=", "np", ".", "all", "(", "y", "[", "not_test_idx", ",", ":", "]", ".", "sum", "(", "axis", "=", "0", ")", ">=", "\n", "0.8", "*", "(", "1", "-", "test_frac", "-", "valid_frac", ")", "*", "smallest_class", ")", "\n", "cond2", "=", "np", ".", "all", "(", "y", "[", "test_idx", ",", ":", "]", ".", "sum", "(", "axis", "=", "0", ")", ">=", "\n", "0.8", "*", "(", "test_frac", "+", "valid_frac", ")", "*", "smallest_class", ")", "\n", "\n", "if", "cond1", "and", "cond2", ":", "\n", "            ", "if", "valid_frac", "!=", "0", ":", "\n", "                ", "while", "split", "is", "None", ":", "\n", "                    ", "final_test_idx", ",", "valid_idx", "=", "random_split", "(", "\n", "y", "[", "test_idx", "]", ".", "shape", "[", "0", "]", ",", "\n", "test_frac", "=", "valid_frac", "/", "(", "test_frac", "+", "valid_frac", ")", ")", "\n", "\n", "cond1", "=", "np", ".", "all", "(", "\n", "y", "[", "test_idx", ",", ":", "]", "[", "final_test_idx", ",", ":", "]", ".", "sum", "(", "axis", "=", "0", ")", ">=", "\n", "0.6", "*", "test_frac", "*", "smallest_class", ")", "\n", "cond2", "=", "np", ".", "all", "(", "\n", "y", "[", "test_idx", ",", ":", "]", "[", "valid_idx", ",", ":", "]", ".", "sum", "(", "axis", "=", "0", ")", ">=", "\n", "0.6", "*", "valid_frac", "*", "smallest_class", ")", "\n", "if", "cond1", "and", "cond2", ":", "\n", "                        ", "split", "=", "(", "np", ".", "sort", "(", "not_test_idx", ")", ",", "\n", "np", ".", "sort", "(", "test_idx", "[", "valid_idx", "]", ")", ",", "\n", "np", ".", "sort", "(", "test_idx", "[", "final_test_idx", "]", ")", ")", "\n", "print", "(", "'Split completed.\\n'", ")", "\n", "break", "\n", "", "else", ":", "\n", "                        ", "print", "(", "'Valid labels unevenly split, resplitting...\\n'", ")", "\n", "print", "(", "y", "[", "test_idx", ",", ":", "]", "[", "final_test_idx", ",", ":", "]", ".", "sum", "(", "axis", "=", "0", ")", ")", "\n", "print", "(", "0.6", "*", "test_frac", "*", "smallest_class", ")", "\n", "print", "(", "y", "[", "test_idx", ",", ":", "]", "[", "valid_idx", ",", ":", "]", ".", "sum", "(", "axis", "=", "0", ")", ")", "\n", "print", "(", "0.6", "*", "valid_frac", "*", "smallest_class", ")", "\n", "", "", "", "else", ":", "\n", "                ", "split", "=", "(", "np", ".", "sort", "(", "not_test_idx", ")", ",", "None", ",", "np", ".", "sort", "(", "test_idx", ")", ")", "\n", "print", "(", "'Split completed.\\n'", ")", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "'Test labels unevenly split, resplitting...\\n'", ")", "\n", "print", "(", "y", "[", "not_test_idx", ",", ":", "]", ".", "sum", "(", "axis", "=", "0", ")", ")", "\n", "print", "(", "0.7", "*", "(", "1", "-", "test_frac", ")", "*", "smallest_class", ")", "\n", "print", "(", "y", "[", "test_idx", ",", ":", "]", ".", "sum", "(", "axis", "=", "0", ")", ")", "\n", "print", "(", "0.7", "*", "test_frac", "*", "smallest_class", ")", "\n", "\n", "", "", "if", "valid_frac", "!=", "0", ":", "\n", "        ", "print", "(", "\"Train:Validation:Testing - %d:%d:%d\"", "%", "(", "len", "(", "split", "[", "0", "]", ")", ",", "\n", "len", "(", "split", "[", "1", "]", ")", ",", "\n", "len", "(", "split", "[", "2", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Train:Testing - %d:%d\"", "%", "(", "len", "(", "split", "[", "0", "]", ")", ",", "len", "(", "split", "[", "2", "]", ")", ")", ")", "\n", "\n", "", "return", "split", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.one_hot_sequence": [[242, 253], ["numpy.zeros", "range", "int", "range", "x.max", "int"], "function", ["None"], ["", "def", "one_hot_sequence", "(", "x", ",", "depth", "=", "None", ")", ":", "\n", "    ", "if", "depth", "is", "None", ":", "\n", "        ", "depth", "=", "int", "(", "x", ".", "max", "(", ")", "+", "1", ")", "\n", "\n", "", "one_hot", "=", "np", ".", "zeros", "(", "x", ".", "shape", "+", "(", "depth", ",", ")", ")", "\n", "# TODO: speed up this operation its super slow.", "\n", "for", "i", "in", "range", "(", "x", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "x", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "one_hot", "[", "i", ",", "j", ",", "int", "(", "x", "[", "i", ",", "j", "]", ")", "]", "=", "1", "\n", "\n", "", "", "return", "one_hot", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.one_hot_encoder": [[255, 273], ["numpy.zeros", "int", "labels.max", "numpy.arange", "labels.astype"], "function", ["None"], ["", "def", "one_hot_encoder", "(", "labels", ",", "n_classes", "=", "None", ")", ":", "\n", "    ", "'''\n    A function that converts an array of integers, representing the labels\n    of data, into an array of one-hot encoded vectors.\n\n    Inputs:\n    Labels      - a numpy array of integers (nsamples)\n    n_classes   - (int) the number of classes if labels does not contain all\n\n    Returns:\n    A numpy array of one-hot encoded vectors with size [nsamples, n_classes]\n    '''", "\n", "if", "n_classes", "is", "None", ":", "\n", "        ", "n_classes", "=", "int", "(", "labels", ".", "max", "(", ")", "+", "1", ")", "\n", "\n", "", "one_hot", "=", "np", ".", "zeros", "(", "(", "labels", ".", "shape", "[", "0", "]", ",", "n_classes", ")", ")", "\n", "one_hot", "[", "np", ".", "arange", "(", "labels", ".", "shape", "[", "0", "]", ")", ",", "labels", ".", "astype", "(", "int", ")", "]", "=", "1", "\n", "return", "one_hot", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.pad_seqs": [[275, 298], ["len", "numpy.max", "numpy.zeros", "enumerate", "len", "numpy.array"], "function", ["None"], ["", "def", "pad_seqs", "(", "seqs", ")", ":", "\n", "    ", "\"\"\"Create the matrices from the datasets.\n\n    This pad each sequence to the same length: the length of the\n    longest sequence.\n\n    Output:\n    x -- a numpy array with shape (batch_size, max_time_steps, num_features)\n    lengths -- an array of the sequence lengths\n\n    \"\"\"", "\n", "lengths", "=", "[", "len", "(", "s", ")", "for", "s", "in", "seqs", "]", "\n", "\n", "n_samples", "=", "len", "(", "seqs", ")", "\n", "maxlen", "=", "np", ".", "max", "(", "lengths", ")", "\n", "inputDimSize", "=", "seqs", "[", "0", "]", ".", "shape", "[", "1", "]", "\n", "\n", "x", "=", "np", ".", "zeros", "(", "(", "n_samples", ",", "maxlen", ",", "inputDimSize", ")", ")", "\n", "\n", "for", "idx", ",", "s", "in", "enumerate", "(", "seqs", ")", ":", "\n", "        ", "x", "[", "idx", ",", ":", "lengths", "[", "idx", "]", ",", ":", "]", "=", "s", "\n", "\n", "", "return", "x", ",", "np", ".", "array", "(", "lengths", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.main.parse_args": [[11, 84], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.main.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "'''\n        parsing and configuration\n    '''", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--name\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"standard\"", ",", "\n", "help", "=", "\"[%(default)s] A string to describe this model\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--data\"", ",", "type", "=", "str", ",", "\n", "default", "=", "'pmnist'", ",", "\n", "choices", "=", "[", "'pmnist'", ",", "'mnist'", ",", "'add'", ",", "'copy'", "]", ",", "\n", "help", "=", "\"[%(default)s] Path to the dataset.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--layers\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"128\"", ",", "\n", "help", "=", "\"[%(default)s] A comma-separated list\"", "\n", "\" of the layer sizes\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--stack\"", ",", "type", "=", "int", ",", "\n", "default", "=", "4", ",", "\n", "help", "=", "\"[%(default)s] The batch size to train with\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch_size\"", ",", "type", "=", "int", ",", "\n", "default", "=", "200", ",", "\n", "help", "=", "\"[%(default)s] The batch size to train with\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--keep_prob\"", ",", "type", "=", "float", ",", "\n", "default", "=", "0.9", ",", "\n", "help", "=", "'[%(default)s] The keep probability to use'", "\n", "' for training'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_grad_norm'", ",", "type", "=", "float", ",", "\n", "default", "=", "5.0", ",", "\n", "help", "=", "'[%(default)s] The maximum grad norm to clip by'", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate'", ",", "type", "=", "float", ",", "\n", "default", "=", "0.001", ",", "\n", "help", "=", "'[%(default)s] The learning rate to train with'", ")", "\n", "parser", ".", "add_argument", "(", "'--optimizer'", ",", "type", "=", "str", ",", "\n", "default", "=", "'adam'", ",", "\n", "choices", "=", "[", "'momentum'", ",", "'rms'", ",", "'adam'", "]", ",", "\n", "help", "=", "'[%(default)s] The optimizer to train with'", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "type", "=", "int", ",", "\n", "default", "=", "100", ",", "\n", "help", "=", "\"[%(default)s] The number of epochs to train for\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"[False] If True, the model \"", "\n", "\"is only tested and not trained.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--logdir\"", ",", "type", "=", "str", ",", "\n", "default", "=", "\"log\"", ",", "\n", "help", "=", "\"[%(default)s] The directory to write\"", "\n", "\" tensoboard logs to\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--gpu\"", ",", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"[%(default)s] The specific GPU to train on.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--wd'", ",", "type", "=", "float", ",", "\n", "default", "=", "0.0", ",", "\n", "help", "=", "'[%(default)s] weight decay importance'", ")", "\n", "parser", ".", "add_argument", "(", "'--results_file'", ",", "type", "=", "str", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "'[%(default)s] The file to append results to. '", "\n", "' If set, nothing else will be logged or saved.'", ")", "\n", "parser", ".", "add_argument", "(", "'--chrono'", ",", "type", "=", "bool", ",", "default", "=", "True", ",", "\n", "help", "=", "'[False] If set, chrono-initialization is used.'", ")", "\n", "parser", ".", "add_argument", "(", "'--log_test'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'[False] Log test data metrics on TB.'", ")", "\n", "parser", ".", "add_argument", "(", "'--cell'", ",", "type", "=", "str", ",", "\n", "default", "=", "'bn-star'", ",", "\n", "choices", "=", "[", "'rnn'", ",", "'lstm'", ",", "'star'", ",", "'bn-star'", "]", ",", "\n", "help", "=", "'[%(default)s] The type of cell to use.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--T\"", ",", "type", "=", "int", ",", "\n", "default", "=", "200", ",", "\n", "help", "=", "\"[%(default)s] Sequence length for add/copy.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--log_every\"", ",", "type", "=", "int", ",", "\n", "default", "=", "200000", ",", "\n", "help", "=", "\"[%(default)s] How often to log highres loss.\"", ")", "\n", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.main.test_wrapper": [[86, 92], ["print", "prepare_data.load_data", "test_agent.test"], "function", ["home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.prepare_data.load_data", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.test_agent.TestAgent.test"], ["", "def", "test_wrapper", "(", "test_agent", ",", "args", ")", ":", "\n", "    ", "print", "(", "'test score'", ")", "\n", "data_list", "=", "load_data", "(", "args", ".", "data", ")", "\n", "x_test", "=", "data_list", "[", "4", "]", "\n", "y_test", "=", "data_list", "[", "5", "]", "\n", "test_agent", ".", "test", "(", "x_test", ",", "y_test", ",", "'models/'", "+", "args", ".", "name", "+", "'/'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.main.test_valid_wrapper": [[93, 99], ["print", "prepare_data.load_data", "test_agent.test"], "function", ["home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.prepare_data.load_data", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.test_agent.TestAgent.test"], ["", "def", "test_valid_wrapper", "(", "test_agent", ",", "args", ")", ":", "\n", "    ", "print", "(", "'validation score'", ")", "\n", "data_list", "=", "load_data", "(", "args", ".", "data", ")", "\n", "x_test", "=", "data_list", "[", "2", "]", "\n", "y_test", "=", "data_list", "[", "3", "]", "\n", "test_agent", ".", "test", "(", "x_test", ",", "y_test", ",", "'models/'", "+", "args", ".", "name", "+", "'/'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.main.main": [[100, 135], ["vars", "vars.update", "test_agent.TestAgent", "main.test_wrapper", "test_agent.TestAgent", "main.test_valid_wrapper", "train_agent.TrainAgent", "test_agent.TestAgent", "test_agent.TestAgent", "py3nvml.grab_gpus", "open", "json.load", "train_agent.TrainAgent.train", "main.test_valid_wrapper", "print", "os.path.join", "main.test_valid_wrapper", "main.test_wrapper"], "function", ["home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.main.test_wrapper", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.main.test_valid_wrapper", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.train_agent.TrainAgent.train", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.main.test_valid_wrapper", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.main.test_valid_wrapper", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.main.test_wrapper"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "gpu", "is", "not", "None", ":", "\n", "        ", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "args", ".", "gpu", "\n", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "py3nvml", "\n", "py3nvml", ".", "grab_gpus", "(", "1", ",", "gpu_fraction", "=", "0.95", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "print", "(", "\"Could not import py3nvml\"", ")", "\n", "\n", "", "", "if", "args", ".", "test", ":", "\n", "# Get the config", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "'models'", ",", "args", ".", "name", ",", "'config.json'", ")", ")", "as", "fp", ":", "\n", "            ", "config_dict", "=", "json", ".", "load", "(", "fp", ")", "\n", "", "args_dict", "=", "vars", "(", "args", ")", "\n", "args_dict", ".", "update", "(", "config_dict", ")", "\n", "\n", "test_agent", "=", "TestAgent", "(", "args", ")", "\n", "test_wrapper", "(", "test_agent", ",", "args", ")", "\n", "valid_agent", "=", "TestAgent", "(", "args", ")", "\n", "test_valid_wrapper", "(", "valid_agent", ",", "args", ")", "\n", "\n", "\n", "", "else", ":", "\n", "        ", "agent", "=", "TrainAgent", "(", "args", ")", "\n", "test_agent", "=", "TestAgent", "(", "args", ")", "\n", "valid_agent", "=", "TestAgent", "(", "args", ")", "\n", "try", ":", "\n", "            ", "agent", ".", "train", "(", "args", ".", "data", ",", "args", ".", "max_grad_norm", ",", "args", ".", "wd", ",", "\n", "test_agent", ",", "args", "=", "args", ")", "\n", "test_valid_wrapper", "(", "valid_agent", ",", "args", ")", "\n", "#test_wrapper(test_agent, args)", "\n", "", "except", "KeyboardInterrupt", ":", "\n", "            ", "test_valid_wrapper", "(", "valid_agent", ",", "args", ")", "\n", "test_wrapper", "(", "test_agent", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.model_file.RNN_Model.__init__": [[84, 101], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "n_features", ",", "n_classes", ",", "h_dim", ",", "max_sequence_length", ",", "\n", "is_test", "=", "False", ",", "max_gradient_norm", "=", "None", ",", "opt_method", "=", "'adam'", ",", "\n", "learning_rate", "=", "0.001", ",", "weight_decay", "=", "0", ",", "\n", "cell_type", "=", "'star'", ",", "chrono", "=", "False", ",", "mse", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "n_features", "=", "n_features", "\n", "self", ".", "n_classes", "=", "n_classes", "\n", "self", ".", "h_dim", "=", "h_dim", "\n", "self", ".", "max_sequence_length", "=", "max_sequence_length", "\n", "self", ".", "opt_method", "=", "opt_method", "\n", "#self.learning_rate = learning_rate", "\n", "self", ".", "max_gradient_norm", "=", "max_gradient_norm", "\n", "self", ".", "is_test", "=", "is_test", "\n", "self", ".", "weight_decay", "=", "weight_decay", "\n", "self", ".", "cell_type", "=", "cell_type", "\n", "self", ".", "chrono", "=", "chrono", "\n", "self", ".", "mse", "=", "mse", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.model_file.RNN_Model.build_inputs": [[102, 117], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder"], "methods", ["None"], ["", "def", "build_inputs", "(", "self", ")", ":", "\n", "        ", "self", ".", "keep_prob", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "name", "=", "'keep_prob'", ")", "\n", "self", ".", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "None", ",", "self", ".", "n_features", "]", ",", "\n", "name", "=", "'x'", ")", "\n", "if", "self", ".", "output_seq", ":", "\n", "            ", "self", ".", "y", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "None", ",", "self", ".", "n_classes", "]", ",", "\n", "name", "=", "'y'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "y", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "self", ".", "n_classes", "]", ",", "\n", "name", "=", "'y'", ")", "\n", "", "self", ".", "seq_lens", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "\n", "name", "=", "\"sequence_lengths\"", ")", "\n", "self", ".", "training", "=", "tf", ".", "placeholder", "(", "tf", ".", "bool", ")", "\n", "\n", "self", ".", "learning_rate", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.model_file.RNN_Model.build_loss": [[119, 146], ["tensorflow.summary.scalar", "tensorflow.losses.mean_squared_error", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.reduce_mean", "tensorflow.add_n", "tensorflow.reduce_mean", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.nn.softmax_cross_entropy_with_logits", "tensorflow.nn.softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.nn.l2_loss", "tensorflow.trainable_variables", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "def", "build_loss", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "if", "self", ".", "mse", ":", "\n", "            ", "mean_squared_error", "=", "tf", ".", "losses", ".", "mean_squared_error", "(", "\n", "labels", "=", "self", ".", "y", ",", "predictions", "=", "outputs", ")", "\n", "self", ".", "loss_nowd", "=", "tf", ".", "reduce_mean", "(", "mean_squared_error", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'mean_squared_error'", ",", "\n", "tf", ".", "reduce_mean", "(", "mean_squared_error", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "output_seq", ":", "\n", "                ", "flat_out", "=", "tf", ".", "reshape", "(", "outputs", ",", "(", "-", "1", ",", "tf", ".", "shape", "(", "outputs", ")", "[", "-", "1", "]", ")", ")", "\n", "flat_y", "=", "tf", ".", "reshape", "(", "self", ".", "y", ",", "(", "-", "1", ",", "tf", ".", "shape", "(", "self", ".", "y", ")", "[", "-", "1", "]", ")", ")", "\n", "sample_cross_entropy", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits", "(", "\n", "labels", "=", "flat_y", ",", "logits", "=", "flat_out", ")", "\n", "\n", "", "else", ":", "\n", "                ", "sample_cross_entropy", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits", "(", "\n", "labels", "=", "self", ".", "y", ",", "logits", "=", "outputs", ")", "\n", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "'cross_entropy'", ",", "\n", "tf", ".", "reduce_mean", "(", "sample_cross_entropy", ")", ")", "\n", "self", ".", "loss_nowd", "=", "tf", ".", "reduce_mean", "(", "sample_cross_entropy", ")", "\n", "\n", "", "weight_decay", "=", "self", ".", "weight_decay", "*", "tf", ".", "add_n", "(", "[", "tf", ".", "nn", ".", "l2_loss", "(", "v", ")", "for", "v", "in", "\n", "tf", ".", "trainable_variables", "(", ")", "\n", "if", "'bias'", "not", "in", "v", ".", "name", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'weight_decay'", ",", "weight_decay", ")", "\n", "self", ".", "loss", "=", "self", ".", "loss_nowd", "+", "weight_decay", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.model_file.RNN_Model.build_optimizer": [[147, 167], ["tensorflow.trainable_variables", "tensorflow.gradients", "tensorflow.clip_by_global_norm", "tensorflow.summary.scalar", "tensorflow.train.MomentumOptimizer.apply_gradients", "print", "tensorflow.train.AdamOptimizer", "zip", "print", "tensorflow.train.RMSPropOptimizer", "print", "tensorflow.train.MomentumOptimizer"], "methods", ["None"], ["", "def", "build_optimizer", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "opt_method", "==", "'adam'", ":", "\n", "            ", "print", "(", "'Optimizing with Adam'", ")", "\n", "opt", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "learning_rate", ")", "\n", "", "elif", "self", ".", "opt_method", "==", "'rms'", ":", "\n", "            ", "print", "(", "'Optimizing with RMSProp'", ")", "\n", "opt", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "self", ".", "learning_rate", ")", "\n", "", "elif", "self", ".", "opt_method", "==", "'momentum'", ":", "\n", "            ", "print", "(", "'Optimizing with Nesterov momentum SGD'", ")", "\n", "opt", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "self", ".", "learning_rate", ",", "\n", "momentum", "=", "0.9", ",", "\n", "use_nesterov", "=", "True", ")", "\n", "\n", "", "params", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "gradients", "=", "tf", ".", "gradients", "(", "self", ".", "loss", ",", "params", ")", "\n", "clipped_gradients", ",", "norm", "=", "tf", ".", "clip_by_global_norm", "(", "gradients", ",", "\n", "self", ".", "max_gradient_norm", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'gradients_norm'", ",", "norm", ")", "\n", "\n", "self", ".", "train_opt", "=", "opt", ".", "apply_gradients", "(", "zip", "(", "clipped_gradients", ",", "params", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.model_file.RNN_Model.build": [[168, 197], ["print", "model_file.RNN_Model.build_inputs", "model_file.rnn", "model_file.RNN_Model.build_loss", "tensorflow.nn.softmax", "tensorflow.summary.merge_all", "tensorflow.reshape", "print", "model_file.RNN_Model.build_optimizer", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.model_file.RNN_Model.build_inputs", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.model_file.rnn", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.model_file.RNN_Model.build_loss", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.model_file.RNN_Model.build_optimizer"], ["", "def", "build", "(", "self", ",", "output_format", "=", "'last'", ")", ":", "\n", "        ", "print", "(", "\"Building model ...\"", ")", "\n", "self", ".", "output_seq", "=", "False", "\n", "if", "output_format", "==", "'all'", ":", "\n", "            ", "self", ".", "output_seq", "=", "True", "\n", "", "self", ".", "build_inputs", "(", ")", "\n", "\n", "t_max", "=", "None", "\n", "if", "self", ".", "chrono", ":", "\n", "            ", "t_max", "=", "self", ".", "max_sequence_length", "\n", "\n", "", "outputs", "=", "rnn", "(", "self", ".", "x", ",", "self", ".", "h_dim", ",", "self", ".", "n_classes", ",", "self", ".", "keep_prob", ",", "\n", "sequence_lengths", "=", "self", ".", "seq_lens", ",", "\n", "training", "=", "self", ".", "training", ",", "output_format", "=", "output_format", ",", "\n", "cell_type", "=", "self", ".", "cell_type", ",", "t_max", "=", "t_max", ",", "\n", ")", "\n", "\n", "self", ".", "build_loss", "(", "outputs", ")", "\n", "\n", "self", ".", "output_probs", "=", "tf", ".", "nn", ".", "softmax", "(", "outputs", ")", "\n", "if", "self", ".", "output_seq", ":", "\n", "            ", "self", ".", "output_probs", "=", "tf", ".", "reshape", "(", "\n", "self", ".", "output_probs", ",", "(", "-", "1", ",", "tf", ".", "shape", "(", "self", ".", "output_probs", ")", "[", "-", "1", "]", ")", ")", "\n", "\n", "", "if", "not", "self", ".", "is_test", ":", "\n", "            ", "print", "(", "\"Adding training operations\"", ")", "\n", "self", ".", "build_optimizer", "(", ")", "\n", "\n", "", "self", ".", "summary_op", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.model_file.rnn": [[7, 80], ["tensorflow.contrib.rnn.DropoutWrapper", "len", "print", "tensorflow.contrib.rnn.MultiRNNCell", "model_file.rnn.single_cell"], "function", ["None"], ["def", "rnn", "(", "x", ",", "h_dim", ",", "y_dim", ",", "keep_prob", ",", "sequence_lengths", ",", "\n", "training", ",", "output_format", ",", "cell_type", "=", "'star'", ",", "\n", "t_max", "=", "784", ")", ":", "\n", "    ", "'''\n    Inputs:\n    x - The input data.\n        Tensor shape (batch_size, max_sequence_length, n_features)\n    h_dim - A list with the number of neurons in each hidden layer\n    keep_prob - The percentage of weights to keep in each iteration\n                 (1-drop_prob)\n\n    Returns:\n    The non-softmaxed output of the RNN.\n    '''", "\n", "\n", "def", "single_cell", "(", "dim", ",", "output_projection", "=", "None", ",", "training", "=", "True", ")", ":", "\n", "        ", "if", "cell_type", "==", "'rnn'", ":", "\n", "            ", "print", "(", "'Using the standard RNN cell'", ")", "\n", "cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "BasicRNNCell", "(", "dim", ")", "\n", "", "elif", "cell_type", "==", "'lstm'", ":", "\n", "            ", "cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "LSTMCell", "(", "dim", ")", "\n", "print", "(", "'Using LSTM cell'", ")", "\n", "", "elif", "cell_type", "==", "'star'", ":", "\n", "            ", "cell", "=", "STARCell", "(", "dim", ",", "t_max", "=", "t_max", ")", "\n", "print", "(", "'Using STAR cell'", ")", "\n", "", "elif", "cell_type", "==", "'bn-star'", ":", "\n", "            ", "cell", "=", "BNSTAR_cell", "(", "dim", ",", "t_max", "=", "t_max", ",", "training", "=", "training", ")", "\n", "print", "(", "'Using BN-STAR cell'", ")", "\n", "\n", "\n", "", "drop_cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "DropoutWrapper", "(", "\n", "cell", ",", "\n", "input_keep_prob", "=", "1", ",", "\n", "output_keep_prob", "=", "keep_prob", ")", "\n", "return", "drop_cell", "\n", "\n", "", "if", "len", "(", "h_dim", ")", ">", "1", ":", "\n", "# Multilayer RNN        ", "\n", "        ", "cells", "=", "[", "single_cell", "(", "dim", ",", "training", "=", "training", ")", "for", "dim", "in", "h_dim", "]", "\n", "\n", "print", "(", "'Num cells: '", "+", "str", "(", "len", "(", "cells", ")", ")", ")", "\n", "cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "MultiRNNCell", "(", "cells", ")", "\n", "", "else", ":", "\n", "        ", "cell", "=", "single_cell", "(", "h_dim", "[", "0", "]", ",", "training", "=", "training", ")", "\n", "\n", "", "if", "output_format", "==", "'last'", ":", "\n", "        ", "out", ",", "final_state", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "\n", "cell", ",", "x", ",", "sequence_length", "=", "sequence_lengths", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "\n", "# self.final_state is a tuple with", "\n", "# (state.c, state.h)", "\n", "if", "len", "(", "h_dim", ")", ">", "1", ":", "\n", "# If we have a multi-layer rnn, get the top layer state", "\n", "            ", "out", "=", "final_state", "[", "-", "1", "]", "\n", "out", "=", "out", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "out", "=", "final_state", "\n", "out", "=", "out", "[", "1", "]", "\n", "\n", "", "proj_out", "=", "linear", "(", "out", ",", "y_dim", ",", "scope", "=", "'output_mapping'", ")", "\n", "\n", "", "elif", "output_format", "==", "'all'", ":", "\n", "        ", "out", ",", "_", "=", "tf", ".", "nn", ".", "dynamic_rnn", "(", "\n", "cell", ",", "x", ",", "sequence_length", "=", "sequence_lengths", ",", "\n", "dtype", "=", "tf", ".", "float32", ")", "\n", "flat_out", "=", "tf", ".", "reshape", "(", "out", ",", "(", "-", "1", ",", "out", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", ")", "\n", "proj_out", "=", "linear", "(", "flat_out", ",", "y_dim", ",", "scope", "=", "'output_mapping'", ")", "\n", "proj_out", "=", "tf", ".", "reshape", "(", "proj_out", ",", "\n", "(", "tf", ".", "shape", "(", "out", ")", "[", "0", "]", ",", "tf", ".", "shape", "(", "out", ")", "[", "1", "]", ",", "y_dim", ")", ")", "\n", "\n", "", "return", "proj_out", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.bn_star.BNSTAR_cell.__init__": [[9, 19], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.test_agent.TestAgent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_units", ",", "t_max", "=", "784", ",", "training", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "'''\n        t_max should be a float value corresponding to the longest possible\n        time dependency in the input.\n        '''", "\n", "self", ".", "num_units", "=", "num_units", "\n", "self", ".", "t_max", "=", "784", "\n", "self", ".", "training", "=", "training", "\n", "super", "(", "BNSTAR_cell", ",", "self", ")", ".", "__init__", "(", "num_units", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.bn_star.BNSTAR_cell.__call__": [[20, 78], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.matmul", "bn_star.batch_norm", "tensorflow.nn.bias_add", "tensorflow.nn.bias_add", "tensorflow.tanh", "tensorflow.split", "x.get_shape().as_list", "print", "tensorflow.get_variable", "print", "tensorflow.get_variable", "bn_star.batch_norm", "bn_star.batch_norm", "tensorflow.contrib.rnn.LSTMStateTuple", "tensorflow.concat", "tensorflow.python.keras.initializers.get", "tensorflow.python.keras.initializers.get", "tensorflow.python.keras.initializers.get", "tensorflow.sigmoid", "tensorflow.tanh", "type", "x.get_shape", "bn_star.bias_initializer", "bn_star.chrono_init", "tensorflow.sigmoid"], "methods", ["home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.bn_star.batch_norm", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.bn_star.batch_norm", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.bn_star.batch_norm", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.star.bias_initializer", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.star.chrono_init"], ["", "def", "__call__", "(", "self", ",", "x", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "        ", "\"\"\"BN-STAR.\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", "or", "type", "(", "self", ")", ".", "__name__", ")", ":", "\n", "            ", "if", "self", ".", "_state_is_tuple", ":", "\n", "                ", "h", ",", "_", "=", "state", "\n", "", "else", ":", "\n", "                ", "h", ",", "_", "=", "tf", ".", "split", "(", "value", "=", "state", ",", "num_or_size_splits", "=", "2", ",", "axis", "=", "1", ")", "\n", "\n", "\n", "", "x_size", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "\n", "W_zx", "=", "tf", ".", "get_variable", "(", "'W_xh_z'", ",", "\n", "[", "x_size", ",", "1", "*", "self", ".", "num_units", "]", ",", "initializer", "=", "initializers", ".", "get", "(", "'orthogonal'", ")", ")", "\n", "W_Kx", "=", "tf", ".", "get_variable", "(", "'W_xh_K'", ",", "\n", "[", "x_size", ",", "1", "*", "self", ".", "num_units", "]", ",", "initializer", "=", "initializers", ".", "get", "(", "'orthogonal'", ")", ")", "\n", "W_Kh", "=", "tf", ".", "get_variable", "(", "'W_hh'", ",", "\n", "[", "self", ".", "num_units", ",", "1", "*", "self", ".", "num_units", "]", ",", "initializer", "=", "initializers", ".", "get", "(", "'orthogonal'", ")", ")", "\n", "\n", "\n", "if", "self", ".", "t_max", "is", "None", ":", "\n", "                ", "print", "(", "'Zero initializer '", ")", "\n", "bias", "=", "tf", ".", "get_variable", "(", "'bias'", ",", "[", "2", "*", "self", ".", "num_units", "]", ",", "\n", "initializer", "=", "bias_initializer", "(", "2", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Using chrono initializer ...'", ")", "\n", "bias", "=", "tf", ".", "get_variable", "(", "'bias'", ",", "[", "2", "*", "self", ".", "num_units", "]", ",", "\n", "initializer", "=", "chrono_init", "(", "self", ".", "t_max", ",", "\n", "2", ")", ")", "\n", "\n", "", "bias_f", "=", "bias", "[", "self", ".", "num_units", ":", ",", "...", "]", "\n", "bias_j", "=", "bias", "[", ":", "self", ".", "num_units", ",", "...", "]", "\n", "\n", "fx", "=", "tf", ".", "matmul", "(", "x", ",", "W_Kx", ")", "\n", "fh", "=", "tf", ".", "matmul", "(", "h", ",", "W_Kh", ")", "\n", "\n", "j", "=", "tf", ".", "matmul", "(", "x", ",", "W_zx", ")", "\n", "\n", "\n", "bn_f", "=", "batch_norm", "(", "fx", ",", "'fx'", ",", "self", ".", "training", ")", "+", "batch_norm", "(", "fh", ",", "'fh'", ",", "self", ".", "training", ")", "\n", "bn_j", "=", "batch_norm", "(", "j", ",", "'j'", ",", "self", ".", "training", ")", "\n", "\n", "\n", "bn_f", "=", "tf", ".", "nn", ".", "bias_add", "(", "bn_f", ",", "bias_f", ")", "\n", "bn_j", "=", "tf", ".", "nn", ".", "bias_add", "(", "bn_j", ",", "bias_j", ")", "\n", "\n", "beta", "=", "1", "\n", "new_h", "=", "tf", ".", "sigmoid", "(", "bn_f", ")", "*", "h", "+", "(", "1", "-", "tf", ".", "sigmoid", "(", "bn_f", "-", "beta", ")", ")", "*", "tf", ".", "tanh", "(", "bn_j", ")", "\n", "\n", "#            bn_f = tf.sigmoid(bn_f)", "\n", "#            bn_j = tf.tanh(bn_j)", "\n", "#            new_h = bn_f * h + (1-bn_f) * bn_j", "\n", "new_h", "=", "tf", ".", "tanh", "(", "new_h", ")", "\n", "\n", "if", "self", ".", "_state_is_tuple", ":", "\n", "                ", "new_state", "=", "LSTMStateTuple", "(", "new_h", ",", "new_h", ")", "\n", "", "else", ":", "\n", "                ", "new_state", "=", "tf", ".", "concat", "(", "[", "new_h", ",", "new_h", "]", ",", "1", ")", "\n", "", "return", "new_h", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.bn_star.chrono_init": [[80, 93], ["tensorflow.log", "tensorflow.zeros", "tensorflow.concat", "tensorflow.python.ops.random_ops.random_uniform"], "function", ["None"], ["", "", "", "def", "chrono_init", "(", "t_max", ",", "num_gates", ")", ":", "\n", "    ", "def", "_initializer", "(", "shape", ",", "dtype", "=", "tf", ".", "float32", ",", "partition_info", "=", "None", ")", ":", "\n", "        ", "num_units", "=", "shape", "[", "0", "]", "//", "num_gates", "\n", "uni_vals", "=", "tf", ".", "log", "(", "random_ops", ".", "random_uniform", "(", "[", "num_units", "]", ",", "minval", "=", "1.0", ",", "\n", "maxval", "=", "t_max", ",", "dtype", "=", "dtype", ",", "\n", "seed", "=", "42", ")", ")", "\n", "\n", "bias_j", "=", "tf", ".", "zeros", "(", "num_units", ")", "\n", "bias_f", "=", "uni_vals", "\n", "\n", "return", "tf", ".", "concat", "(", "[", "bias_j", ",", "bias_f", "]", ",", "0", ")", "\n", "\n", "", "return", "_initializer", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.bn_star.bias_initializer": [[95, 106], ["numpy.zeros", "int", "numpy.ones", "tensorflow.constant"], "function", ["None"], ["", "def", "bias_initializer", "(", "num_gates", ")", ":", "\n", "    ", "def", "_initializer", "(", "shape", ",", "dtype", "=", "tf", ".", "float32", ",", "partition_info", "=", "None", ")", ":", "\n", "        ", "p", "=", "np", ".", "zeros", "(", "shape", ")", "\n", "num_units", "=", "int", "(", "shape", "[", "0", "]", "//", "num_gates", ")", "\n", "# i, j, o, f", "\n", "# f:", "\n", "p", "[", "-", "num_units", ":", "]", "=", "np", ".", "ones", "(", "num_units", ")", "\n", "\n", "return", "tf", ".", "constant", "(", "p", ",", "dtype", ")", "\n", "\n", "", "return", "_initializer", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.bn_star.batch_norm": [[108, 132], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.moments", "tensorflow.assign", "tensorflow.assign", "tensorflow.cond", "x.get_shape().as_list", "tensorflow.nn.batch_normalization", "tensorflow.constant_initializer", "tensorflow.control_dependencies", "tensorflow.nn.batch_normalization", "x.get_shape"], "function", ["None"], ["", "def", "batch_norm", "(", "x", ",", "name_scope", ",", "training", ",", "epsilon", "=", "1e-3", ",", "decay", "=", "0.999", ")", ":", "\n", "    ", "'''Assume 2d [batch, values] tensor'''", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "name_scope", ")", ":", "\n", "        ", "size", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "\n", "scale", "=", "tf", ".", "get_variable", "(", "'scale'", ",", "[", "size", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.1", ")", ")", "\n", "offset", "=", "tf", ".", "get_variable", "(", "'offset'", ",", "[", "size", "]", ")", "\n", "\n", "pop_mean", "=", "tf", ".", "get_variable", "(", "'pop_mean'", ",", "[", "size", "]", ",", "initializer", "=", "tf", ".", "zeros_initializer", ",", "trainable", "=", "False", ")", "\n", "pop_var", "=", "tf", ".", "get_variable", "(", "'pop_var'", ",", "[", "size", "]", ",", "initializer", "=", "tf", ".", "ones_initializer", ",", "trainable", "=", "False", ")", "\n", "batch_mean", ",", "batch_var", "=", "tf", ".", "nn", ".", "moments", "(", "x", ",", "[", "0", "]", ")", "\n", "\n", "train_mean_op", "=", "tf", ".", "assign", "(", "pop_mean", ",", "pop_mean", "*", "decay", "+", "batch_mean", "*", "(", "1", "-", "decay", ")", ")", "\n", "train_var_op", "=", "tf", ".", "assign", "(", "pop_var", ",", "pop_var", "*", "decay", "+", "batch_var", "*", "(", "1", "-", "decay", ")", ")", "\n", "\n", "def", "batch_statistics", "(", ")", ":", "\n", "            ", "with", "tf", ".", "control_dependencies", "(", "[", "train_mean_op", ",", "train_var_op", "]", ")", ":", "\n", "                ", "return", "tf", ".", "nn", ".", "batch_normalization", "(", "x", ",", "batch_mean", ",", "batch_var", ",", "offset", ",", "scale", ",", "epsilon", ")", "\n", "\n", "", "", "def", "population_statistics", "(", ")", ":", "\n", "            ", "return", "tf", ".", "nn", ".", "batch_normalization", "(", "x", ",", "pop_mean", ",", "pop_var", ",", "offset", ",", "scale", ",", "epsilon", ")", "\n", "\n", "", "return", "tf", ".", "cond", "(", "training", ",", "batch_statistics", ",", "population_statistics", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.train_agent.TrainAgent.__init__": [[18, 45], ["ops.create_conf_dict", "os.path.join", "os.path.exists", "list", "list", "shutil.rmtree", "map", "os.path.exists", "os.makedirs", "args.layers.split", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.create_conf_dict"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "# Create the config dictionary", "\n", "        ", "self", ".", "config", "=", "create_conf_dict", "(", "args", ")", "\n", "\n", "self", ".", "logdir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "logdir", ",", "args", ".", "name", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "logdir", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "self", ".", "logdir", ")", "\n", "\n", "", "self", ".", "h_dim", "=", "list", "(", "map", "(", "int", ",", "args", ".", "layers", ".", "split", "(", "','", ")", ")", ")", "\n", "self", ".", "h_dim", "=", "list", "(", "(", "self", ".", "h_dim", "[", "0", "]", "*", "np", ".", "ones", "(", "[", "args", ".", "stack", "]", ")", ")", ".", "astype", "(", "int", ")", ")", "\n", "\n", "# Create the save path", "\n", "self", ".", "save_path", "=", "'models/'", "+", "args", ".", "name", "+", "'/'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "save_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "save_path", ")", "\n", "\n", "", "self", ".", "mse", "=", "False", "\n", "if", "args", ".", "data", "==", "'add'", ":", "\n", "            ", "self", ".", "mse", "=", "True", "\n", "\n", "", "self", ".", "output_format", "=", "'last'", "\n", "if", "args", ".", "data", "==", "'copy'", ":", "\n", "            ", "self", ".", "output_format", "=", "'all'", "\n", "\n", "", "self", ".", "log_test", "=", "False", "\n", "if", "args", ".", "log_test", "or", "args", ".", "data", "==", "'copy'", "or", "args", ".", "data", "==", "'add'", ":", "\n", "            ", "self", ".", "log_test", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.train_agent.TrainAgent.train": [[46, 210], ["prepare_data.load_data", "ops.get_max_length", "model_file.RNN_Model", "model_file.RNN_Model.build", "tensorflow.train.Saver", "ops.get_validset_feeds", "ops.get_validset_feeds", "tf_ops.create_sess", "sess.run", "tensorflow.summary.FileWriter", "print", "range", "test_agent.test", "ops.get_minibatches_indices", "numpy.zeros", "time.time", "enumerate", "tensorflow.global_variables_initializer", "tensorflow.local_variables_initializer", "print", "print", "len", "len", "ops.pad_seqs", "sess.run", "numpy.isnan", "sess.run", "ops.calculate_metrics", "tf_ops.create_scalar_summaries", "tensorflow.summary.FileWriter.add_summary", "print", "print", "ops.print_metrics", "ops.save_config_dict", "print", "print", "print", "print", "sys.exit", "float", "tf_ops.create_scalar_summaries", "tensorflow.summary.FileWriter.add_summary", "tensorflow.summary.FileWriter.flush", "ops.calculate_metrics", "float", "numpy.argmax", "time.time", "sess.run", "ops.calculate_metrics", "numpy.concatenate", "tensorflow.train.Saver.save", "ops.save_config_dict", "len", "numpy.argmax", "len", "numpy.argmax", "len", "len", "len", "len", "len", "list", "len", "len"], "methods", ["home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.prepare_data.load_data", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.get_max_length", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.model_file.RNN_Model.build", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.get_validset_feeds", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.get_validset_feeds", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.tf_ops.create_sess", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.test_agent.TestAgent.test", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.get_minibatches_indices", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.pad_seqs", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.calculate_metrics", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.tf_ops.create_scalar_summaries", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.print_metrics", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.save_config_dict", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.tf_ops.create_scalar_summaries", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.calculate_metrics", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.calculate_metrics", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.save_config_dict"], ["", "", "def", "train", "(", "self", ",", "data_path", ",", "max_gradient_norm", ",", "weight_decay", ",", "test_agent", ",", "\n", "args", ")", ":", "\n", "        ", "data_list", "=", "load_data", "(", "data_path", ",", "seq_len", "=", "args", ".", "T", ")", "\n", "x_train", ",", "y_train", ",", "x_valid", ",", "y_valid", ",", "x_test", ",", "y_test", "=", "data_list", "\n", "\n", "max_len", "=", "get_max_length", "(", "x_train", "+", "x_valid", ")", "\n", "\n", "# Create the model", "\n", "model", "=", "RNN_Model", "(", "x_train", "[", "0", "]", ".", "shape", "[", "-", "1", "]", ",", "y_train", ".", "shape", "[", "-", "1", "]", ",", "\n", "h_dim", "=", "self", ".", "h_dim", ",", "\n", "max_sequence_length", "=", "max_len", ",", "\n", "max_gradient_norm", "=", "max_gradient_norm", ",", "\n", "opt_method", "=", "args", ".", "optimizer", ",", "\n", "weight_decay", "=", "weight_decay", ",", "\n", "cell_type", "=", "args", ".", "cell", ",", "\n", "chrono", "=", "args", ".", "chrono", ",", "\n", "mse", "=", "self", ".", "mse", ",", "\n", ")", "\n", "model", ".", "build", "(", "self", ".", "output_format", ")", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "# Prepare validation and test data", "\n", "v_input_feed", ",", "v_output_feed", "=", "get_validset_feeds", "(", "\n", "model", ",", "x_valid", ",", "y_valid", ",", "self", ".", "h_dim", ")", "\n", "t_input_feed", ",", "t_output_feed", "=", "get_validset_feeds", "(", "\n", "model", ",", "x_test", ",", "y_test", ",", "self", ".", "h_dim", ")", "\n", "\n", "train_tags", "=", "[", "'Train Loss'", ",", "'Train Acc'", ",", "'Train F1'", "]", "\n", "metric_tags", "=", "train_tags", "+", "[", "'Valid Loss'", ",", "'Valid Acc'", ",", "'Valid F1'", "]", "\n", "\n", "if", "self", ".", "log_test", ":", "\n", "            ", "metric_tags", "+=", "[", "'Test Loss'", ",", "'Test Acc'", ",", "'Test F1'", "]", "\n", "\n", "", "with", "create_sess", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "[", "tf", ".", "global_variables_initializer", "(", ")", ",", "\n", "tf", ".", "local_variables_initializer", "(", ")", "]", ")", "\n", "best_loss", "=", "1e8", "\n", "best_epoch", "=", "0", "\n", "\n", "tb_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "self", ".", "logdir", ",", "sess", ".", "graph", ")", "\n", "\n", "#Load pretrained params", "\n", "#saver.restore(sess, \"./models/pmnist_bn_8_debug/model\")", "\n", "\n", "\n", "print", "(", "\"Training model ...\"", ")", "\n", "tb_step", "=", "0", "\n", "learning_rate", "=", "args", ".", "learning_rate", "\n", "for", "e", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "                ", "if", "e", "%", "50", "==", "0", "and", "e", ">", "1", ":", "\n", "                    ", "learning_rate", "=", "learning_rate", "/", "10.", "\n", "print", "(", "'Learning rate: '", ",", "learning_rate", ")", "\n", "", "if", "e", "==", "0", ":", "\n", "                    ", "print", "(", "'Learning rate: '", ",", "learning_rate", ")", "\n", "\n", "\n", "", "minibatch_indices", "=", "get_minibatches_indices", "(", "\n", "len", "(", "x_train", ")", ",", "args", ".", "batch_size", ")", "\n", "\n", "eval_metrics", "=", "np", ".", "zeros", "(", "len", "(", "metric_tags", ")", ")", "\n", "\n", "# Time each epoch", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Loop over minibatches", "\n", "for", "b_num", ",", "b_indices", "in", "enumerate", "(", "minibatch_indices", ")", ":", "\n", "#print('\\rProcessing batch {}/{}'.format(b_num, len(minibatch_indices)), end='', flush=True)", "\n", "\n", "                    ", "x", "=", "[", "x_train", "[", "i", "]", "for", "i", "in", "b_indices", "]", "\n", "y", "=", "y_train", "[", "b_indices", "]", "\n", "\n", "x", ",", "seq_lengths", "=", "pad_seqs", "(", "x", ")", "\n", "\n", "input_feed", "=", "{", "model", ".", "x", ":", "x", ",", "\n", "model", ".", "y", ":", "y", ",", "\n", "model", ".", "seq_lens", ":", "seq_lengths", ",", "\n", "model", ".", "training", ":", "True", ",", "\n", "model", ".", "learning_rate", ":", "learning_rate", ",", "\n", "model", ".", "keep_prob", ":", "args", ".", "keep_prob", ",", "\n", "}", "\n", "_", ",", "loss", ",", "output_probs", "=", "sess", ".", "run", "(", "\n", "[", "model", ".", "train_opt", ",", "model", ".", "loss_nowd", ",", "\n", "model", ".", "output_probs", "]", ",", "\n", "input_feed", ")", "\n", "\n", "if", "np", ".", "isnan", "(", "loss", ")", ":", "\n", "                        ", "print", "(", "'!'", "*", "70", ")", "\n", "print", "(", "'Nan loss value'", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n", "# Update the training loss", "\n", "", "eval_metrics", "[", "0", "]", "+=", "loss", "/", "float", "(", "len", "(", "minibatch_indices", ")", ")", "\n", "\n", "if", "b_num", "%", "args", ".", "log_every", "==", "0", ":", "\n", "                        ", "summary", "=", "create_scalar_summaries", "(", "\n", "[", "'high_res_train_loss'", "]", ",", "\n", "[", "loss", "]", ",", "\n", ")", "\n", "\n", "tb_writer", ".", "add_summary", "(", "summary", ",", "tb_step", ")", "\n", "tb_writer", ".", "flush", "(", ")", "\n", "tb_step", "+=", "1", "\n", "\n", "# Update the remaining metrics", "\n", "", "eval_metrics", "[", "1", ":", "3", "]", "+=", "calculate_metrics", "(", "\n", "y", ",", "np", ".", "argmax", "(", "output_probs", ",", "axis", "=", "1", ")", ")", "/", "float", "(", "len", "(", "minibatch_indices", ")", ")", "\n", "\n", "", "if", "'mnist'", "in", "args", ".", "data", ":", "\n", "# Compute validation loss and accuracy", "\n", "                    ", "eval_metrics", "[", "len", "(", "train_tags", ")", "]", ",", "output_probs", "=", "sess", ".", "run", "(", "\n", "v_output_feed", ",", "v_input_feed", ")", "\n", "eval_metrics", "[", "len", "(", "train_tags", ")", "+", "1", ":", "2", "*", "len", "(", "train_tags", ")", "]", "+=", "calculate_metrics", "(", "y_valid", ",", "\n", "np", ".", "argmax", "(", "output_probs", ",", "axis", "=", "1", ")", ")", "\n", "\n", "epoch_duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "\n", "if", "self", ".", "log_test", ":", "\n", "# Compute test dataset metrics", "\n", "                        ", "eval_metrics", "[", "2", "*", "len", "(", "train_tags", ")", "]", ",", "output_probs", "=", "sess", ".", "run", "(", "t_output_feed", ",", "t_input_feed", ")", "\n", "eval_metrics", "[", "2", "*", "len", "(", "train_tags", ")", "+", "1", ":", "]", "+=", "calculate_metrics", "(", "\n", "y_test", ",", "np", ".", "argmax", "(", "output_probs", ",", "axis", "=", "1", ")", ")", "\n", "\n", "# Log the metrics on tensorboard", "\n", "", "summary", "=", "create_scalar_summaries", "(", "\n", "metric_tags", "+", "[", "'Epoch_duration'", "]", ",", "\n", "np", ".", "concatenate", "(", "(", "eval_metrics", ",", "[", "epoch_duration", "]", ")", ")", ")", "\n", "\n", "tb_writer", ".", "add_summary", "(", "summary", ",", "e", ")", "\n", "\n", "# Save model if it yields the best validation loss", "\n", "if", "best_loss", ">=", "eval_metrics", "[", "len", "(", "train_tags", ")", "]", ":", "\n", "                        ", "best_loss", "=", "eval_metrics", "[", "len", "(", "train_tags", ")", "]", "\n", "best_epoch", "=", "e", "\n", "saver", ".", "save", "(", "sess", ",", "self", ".", "save_path", "+", "'model'", ")", "\n", "\n", "# Save the config to json", "\n", "save_config_dict", "(", "self", ".", "config", ",", "self", ".", "save_path", ",", "\n", "tags", "=", "[", "'best_epoch'", ",", "\n", "'max_sequence_length'", "]", "+", "\n", "metric_tags", ",", "\n", "values", "=", "[", "best_epoch", ",", "max_len", "]", "+", "\n", "list", "(", "eval_metrics", ")", ")", "\n", "\n", "", "print", "(", ")", "\n", "print", "(", "args", ".", "name", "+", "\": Epoch {}/{}  |  best epoch: {}\"", "\n", "\"  |  epoch duration: {:.1f}\"", ".", "format", "(", "\n", "e", ",", "args", ".", "epochs", ",", "best_epoch", ",", "epoch_duration", ")", ")", "\n", "print_metrics", "(", "metric_tags", ",", "eval_metrics", ")", "\n", "\n", "", "else", ":", "\n", "                    ", "save_config_dict", "(", "self", ".", "config", ",", "self", ".", "save_path", ",", "\n", "tags", "=", "[", "'placeholder'", "]", ",", "\n", "values", "=", "[", "0", "]", ",", "\n", ")", "\n", "\n", "print", "(", ")", "\n", "print", "(", "args", ".", "name", "+", "\": Epoch {}/{}\"", ".", "format", "(", "e", ",", "args", ".", "epochs", ")", ")", "\n", "\n", "", "", "", "if", "'mnist'", "in", "args", ".", "data", ":", "\n", "            ", "test_agent", ".", "test", "(", "x_test", ",", "y_test", ",", "self", ".", "save_path", ",", "self", ".", "config", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.rnn_cells.CustomLSTMCell.__init__": [[9, 19], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.test_agent.TestAgent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_units", ",", "t_max", "=", "784", ",", "forget_only", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "'''\n        t_max should be a float value corresponding to the longest possible\n        time dependency in the input.\n        '''", "\n", "self", ".", "num_units", "=", "num_units", "\n", "self", ".", "t_max", "=", "t_max", "\n", "self", ".", "forget_only", "=", "forget_only", "\n", "super", "(", "CustomLSTMCell", ",", "self", ")", ".", "__init__", "(", "num_units", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.rnn_cells.CustomLSTMCell.__call__": [[20, 75], ["tensorflow.variable_scope", "tensorflow.concat", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.concat", "tensorflow.nn.bias_add", "tensorflow.split", "print", "x.get_shape().as_list", "tensorflow.get_variable", "print", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.split", "tensorflow.contrib.rnn.LSTMStateTuple", "tensorflow.concat", "tensorflow.python.keras.initializers.get", "tensorflow.python.keras.initializers.get", "rnn_cells.CustomLSTMCell._activation", "tensorflow.sigmoid", "tensorflow.split", "rnn_cells.CustomLSTMCell._activation", "type", "x.get_shape", "rnn_cells.bias_initializer", "rnn_cells.chrono_init", "tensorflow.sigmoid", "tensorflow.sigmoid", "rnn_cells.CustomLSTMCell._activation", "tensorflow.sigmoid", "tensorflow.tanh", "tensorflow.sigmoid"], "methods", ["home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.star.bias_initializer", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.star.chrono_init"], ["", "def", "__call__", "(", "self", ",", "x", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "        ", "\"\"\"Long short-term memory cell (LSTM).\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", "or", "type", "(", "self", ")", ".", "__name__", ")", ":", "\n", "            ", "if", "self", ".", "_state_is_tuple", ":", "\n", "                ", "c", ",", "h", "=", "state", "\n", "", "else", ":", "\n", "                ", "c", ",", "h", "=", "tf", ".", "split", "(", "value", "=", "state", ",", "num_or_size_splits", "=", "2", ",", "axis", "=", "1", ")", "\n", "\n", "", "all_inputs", "=", "tf", ".", "concat", "(", "[", "x", ",", "h", "]", ",", "1", ")", "\n", "\n", "num_gates", "=", "4", "\n", "if", "self", ".", "forget_only", ":", "\n", "                ", "print", "(", "'Forget-only'", ")", "\n", "num_gates", "=", "2", "\n", "\n", "", "x_size", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "W_xh", "=", "tf", ".", "get_variable", "(", "'W_xh'", ",", "\n", "[", "x_size", ",", "num_gates", "*", "self", ".", "num_units", "]", ",", "initializer", "=", "initializers", ".", "get", "(", "'orthogonal'", ")", ")", "\n", "W_hh", "=", "tf", ".", "get_variable", "(", "'W_hh'", ",", "\n", "[", "self", ".", "num_units", ",", "num_gates", "*", "self", ".", "num_units", "]", ",", "initializer", "=", "initializers", ".", "get", "(", "'orthogonal'", ")", ")", "\n", "if", "self", ".", "t_max", "is", "None", ":", "\n", "                ", "bias", "=", "tf", ".", "get_variable", "(", "'bias'", ",", "[", "num_gates", "*", "self", ".", "num_units", "]", ",", "\n", "initializer", "=", "bias_initializer", "(", "num_gates", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Using chrono initializer ...'", ")", "\n", "bias", "=", "tf", ".", "get_variable", "(", "'bias'", ",", "[", "num_gates", "*", "self", ".", "num_units", "]", ",", "\n", "initializer", "=", "chrono_init", "(", "self", ".", "t_max", ",", "\n", "num_gates", ")", ")", "\n", "\n", "", "weights", "=", "tf", ".", "concat", "(", "[", "W_xh", ",", "W_hh", "]", ",", "0", ")", "\n", "\n", "concat", "=", "tf", ".", "nn", ".", "bias_add", "(", "tf", ".", "matmul", "(", "all_inputs", ",", "weights", ")", ",", "bias", ")", "\n", "\n", "if", "num_gates", "==", "4", ":", "\n", "# i=input_gate, j=new_input, o=output_gate, f=forget_gate", "\n", "                ", "i", ",", "j", ",", "o", ",", "f", "=", "tf", ".", "split", "(", "value", "=", "concat", ",", "\n", "num_or_size_splits", "=", "num_gates", ",", "\n", "axis", "=", "1", ")", "\n", "new_c", "=", "(", "c", "*", "tf", ".", "sigmoid", "(", "f", ")", "+", "tf", ".", "sigmoid", "(", "i", ")", "*", "\n", "self", ".", "_activation", "(", "j", ")", ")", "\n", "new_h", "=", "self", ".", "_activation", "(", "new_c", ")", "*", "tf", ".", "sigmoid", "(", "o", ")", "\n", "", "elif", "num_gates", "==", "2", ":", "\n", "                ", "j", ",", "f", "=", "tf", ".", "split", "(", "value", "=", "concat", ",", "num_or_size_splits", "=", "num_gates", ",", "\n", "axis", "=", "1", ")", "\n", "beta", "=", "1", "\n", "new_c", "=", "tf", ".", "sigmoid", "(", "f", ")", "*", "c", "+", "(", "1", "-", "tf", ".", "sigmoid", "(", "f", "-", "beta", ")", ")", "*", "tf", ".", "tanh", "(", "j", ")", "\n", "new_h", "=", "self", ".", "_activation", "(", "new_c", ")", "\n", "#new_h = new_c", "\n", "\n", "\n", "", "if", "self", ".", "_state_is_tuple", ":", "\n", "                ", "new_state", "=", "LSTMStateTuple", "(", "new_c", ",", "new_h", ")", "\n", "", "else", ":", "\n", "                ", "new_state", "=", "tf", ".", "concat", "(", "[", "new_c", ",", "new_h", "]", ",", "1", ")", "\n", "", "return", "new_h", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.rnn_cells.chrono_init": [[77, 97], ["tensorflow.log", "tensorflow.python.ops.random_ops.random_uniform", "tensorflow.zeros", "tensorflow.concat", "tensorflow.zeros", "tensorflow.concat"], "function", ["None"], ["", "", "", "def", "chrono_init", "(", "t_max", ",", "num_gates", ")", ":", "\n", "    ", "def", "_initializer", "(", "shape", ",", "dtype", "=", "tf", ".", "float32", ",", "partition_info", "=", "None", ")", ":", "\n", "        ", "num_units", "=", "shape", "[", "0", "]", "//", "num_gates", "\n", "uni_vals", "=", "tf", ".", "log", "(", "random_ops", ".", "random_uniform", "(", "[", "num_units", "]", ",", "minval", "=", "1.0", ",", "\n", "maxval", "=", "t_max", ",", "dtype", "=", "dtype", ",", "\n", "seed", "=", "42", ")", ")", "\n", "if", "num_gates", "==", "4", ":", "\n", "# i, j, o, f", "\n", "            ", "bias_i", "=", "-", "uni_vals", "\n", "j_o", "=", "tf", ".", "zeros", "(", "2", "*", "num_units", ")", "\n", "bias_f", "=", "uni_vals", "\n", "return", "tf", ".", "concat", "(", "[", "bias_i", ",", "j_o", ",", "bias_f", "]", ",", "0", ")", "\n", "\n", "", "elif", "num_gates", "==", "2", ":", "\n", "            ", "bias_j", "=", "tf", ".", "zeros", "(", "num_units", ")", "\n", "bias_f", "=", "uni_vals", "\n", "\n", "return", "tf", ".", "concat", "(", "[", "bias_j", ",", "bias_f", "]", ",", "0", ")", "\n", "\n", "", "", "return", "_initializer", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.rnn_cells.bias_initializer": [[99, 110], ["numpy.zeros", "int", "numpy.ones", "tensorflow.constant"], "function", ["None"], ["", "def", "bias_initializer", "(", "num_gates", ")", ":", "\n", "    ", "def", "_initializer", "(", "shape", ",", "dtype", "=", "tf", ".", "float32", ",", "partition_info", "=", "None", ")", ":", "\n", "        ", "p", "=", "np", ".", "zeros", "(", "shape", ")", "\n", "num_units", "=", "int", "(", "shape", "[", "0", "]", "//", "num_gates", ")", "\n", "# i, j, o, f", "\n", "# f:", "\n", "p", "[", "-", "num_units", ":", "]", "=", "np", ".", "ones", "(", "num_units", ")", "\n", "\n", "return", "tf", ".", "constant", "(", "p", ",", "dtype", ")", "\n", "\n", "", "return", "_initializer", "\n", "", ""]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.prepare_data.load_data": [[7, 47], ["print", "ops.randomly_split_data", "list", "numpy.random.randint", "prepare_data.get_mnist", "prepare_data.get_mnist", "prepare_data.get_add", "prepare_data.get_copy", "numpy.random.rand"], "function", ["home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.randomly_split_data", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.prepare_data.get_mnist", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.prepare_data.get_mnist", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.prepare_data.get_add", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.prepare_data.get_copy"], ["def", "load_data", "(", "dataset_name", ",", "seq_len", "=", "200", ")", ":", "\n", "    ", "'''\n    Returns:\n    x - a n_samples long list containing arrays of shape (sequence_length,\n                                                          n_features)\n    y - an array of the labels with shape (n_samples, n_classes)\n    '''", "\n", "print", "(", "\"Loading \"", "+", "dataset_name", "+", "\" dataset ...\"", ")", "\n", "\n", "if", "dataset_name", "==", "'test'", ":", "\n", "        ", "n_data_points", "=", "5000", "\n", "sequence_length", "=", "100", "\n", "n_features", "=", "1", "\n", "x", "=", "list", "(", "np", ".", "random", ".", "rand", "(", "n_data_points", ",", "sequence_length", ",", "n_features", ")", ")", "\n", "n_classes", "=", "4", "\n", "y", "=", "np", ".", "random", ".", "randint", "(", "low", "=", "0", ",", "high", "=", "n_classes", ",", "size", "=", "n_data_points", ")", "\n", "\n", "", "if", "dataset_name", "==", "'mnist'", ":", "\n", "        ", "return", "get_mnist", "(", "permute", "=", "False", ")", "\n", "\n", "", "if", "dataset_name", "==", "'pmnist'", ":", "\n", "        ", "return", "get_mnist", "(", "permute", "=", "True", ")", "\n", "\n", "", "if", "dataset_name", "==", "'add'", ":", "\n", "        ", "x", ",", "y", "=", "get_add", "(", "n_data", "=", "150000", ",", "seq_len", "=", "seq_len", ")", "\n", "\n", "", "if", "dataset_name", "==", "'copy'", ":", "\n", "        ", "return", "get_copy", "(", "n_data", "=", "150000", ",", "seq_len", "=", "seq_len", ")", "\n", "\n", "", "train_idx", ",", "valid_idx", ",", "test_idx", "=", "randomly_split_data", "(", "\n", "y", ",", "test_frac", "=", "0.2", ",", "valid_frac", "=", "0.1", ")", "\n", "\n", "x_train", "=", "[", "x", "[", "i", "]", "for", "i", "in", "train_idx", "]", "\n", "y_train", "=", "y", "[", "train_idx", "]", "\n", "x_valid", "=", "[", "x", "[", "i", "]", "for", "i", "in", "valid_idx", "]", "\n", "y_valid", "=", "y", "[", "valid_idx", "]", "\n", "x_test", "=", "[", "x", "[", "i", "]", "for", "i", "in", "test_idx", "]", "\n", "y_test", "=", "y", "[", "test_idx", "]", "\n", "\n", "return", "x_train", ",", "y_train", ",", "x_valid", ",", "y_valid", ",", "x_test", ",", "y_test", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.prepare_data.get_add": [[49, 61], ["numpy.zeros", "numpy.random.uniform", "numpy.random.randint", "range", "numpy.reshape"], "function", ["None"], ["", "def", "get_add", "(", "n_data", ",", "seq_len", ")", ":", "\n", "    ", "x", "=", "np", ".", "zeros", "(", "(", "n_data", ",", "seq_len", ",", "2", ")", ")", "\n", "x", "[", ":", ",", ":", ",", "0", "]", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.", ",", "high", "=", "1.", ",", "size", "=", "(", "n_data", ",", "seq_len", ")", ")", "\n", "inds", "=", "np", ".", "random", ".", "randint", "(", "seq_len", "/", "2", ",", "size", "=", "(", "n_data", ",", "2", ")", ")", "\n", "inds", "[", ":", ",", "1", "]", "+=", "seq_len", "//", "2", "\n", "for", "i", "in", "range", "(", "n_data", ")", ":", "\n", "        ", "x", "[", "i", ",", "inds", "[", "i", ",", "0", "]", ",", "1", "]", "=", "1.0", "\n", "x", "[", "i", ",", "inds", "[", "i", ",", "1", "]", ",", "1", "]", "=", "1.0", "\n", "\n", "", "y", "=", "(", "x", "[", ":", ",", ":", ",", "0", "]", "*", "x", "[", ":", ",", ":", ",", "1", "]", ")", ".", "sum", "(", "axis", "=", "1", ")", "\n", "y", "=", "np", ".", "reshape", "(", "y", ",", "(", "n_data", ",", "1", ")", ")", "\n", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.prepare_data.get_copy": [[63, 84], ["numpy.zeros", "numpy.random.randint", "numpy.zeros_like", "ops.one_hot_sequence", "ops.one_hot_sequence", "list", "list", "list", "numpy.ones"], "function", ["home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.one_hot_sequence", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.one_hot_sequence"], ["", "def", "get_copy", "(", "n_data", ",", "seq_len", ")", ":", "\n", "    ", "x", "=", "np", ".", "zeros", "(", "(", "n_data", ",", "seq_len", "+", "1", "+", "2", "*", "10", ")", ")", "\n", "info", "=", "np", ".", "random", ".", "randint", "(", "1", ",", "high", "=", "9", ",", "size", "=", "(", "n_data", ",", "10", ")", ")", "\n", "\n", "x", "[", ":", ",", ":", "10", "]", "=", "info", "\n", "x", "[", ":", ",", "seq_len", "+", "10", "]", "=", "9", "*", "np", ".", "ones", "(", "n_data", ")", "\n", "\n", "y", "=", "np", ".", "zeros_like", "(", "x", ")", "\n", "y", "[", ":", ",", "-", "10", ":", "]", "=", "info", "\n", "\n", "x", "=", "one_hot_sequence", "(", "x", ")", "\n", "y", "=", "one_hot_sequence", "(", "y", ")", "\n", "\n", "n_train", ",", "n_valid", ",", "n_test", "=", "[", "100000", ",", "10000", ",", "40000", "]", "\n", "x_train", "=", "list", "(", "x", "[", ":", "n_train", "]", ")", "\n", "y_train", "=", "y", "[", ":", "n_train", "]", "\n", "x_valid", "=", "list", "(", "x", "[", "n_train", ":", "n_train", "+", "n_valid", "]", ")", "\n", "y_valid", "=", "y", "[", "n_train", ":", "n_train", "+", "n_valid", "]", "\n", "x_test", "=", "list", "(", "x", "[", "-", "n_test", ":", "]", ")", "\n", "y_test", "=", "y", "[", "-", "n_test", ":", "]", "\n", "return", "x_train", ",", "y_train", ",", "x_valid", ",", "y_valid", ",", "x_test", ",", "y_test", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.prepare_data.get_mnist": [[86, 106], ["input_data.read_data_sets", "list", "list", "list", "print", "numpy.load", "numpy.arange", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "len", "len", "len"], "function", ["None"], ["", "def", "get_mnist", "(", "permute", "=", "False", ")", ":", "\n", "    ", "from", "tensorflow", ".", "examples", ".", "tutorials", ".", "mnist", "import", "input_data", "\n", "mnist", "=", "input_data", ".", "read_data_sets", "(", "\"MNIST\"", ",", "one_hot", "=", "True", ")", "\n", "\n", "if", "permute", ":", "\n", "        ", "perm_mask", "=", "np", ".", "load", "(", "'pmnist_permutation_mask.npy'", ")", "\n", "", "else", ":", "\n", "        ", "perm_mask", "=", "np", ".", "arange", "(", "784", ")", "\n", "\n", "", "x_train", "=", "list", "(", "np", ".", "expand_dims", "(", "mnist", ".", "train", ".", "images", "[", ":", ",", "perm_mask", "]", ",", "-", "1", ")", ")", "\n", "y_train", "=", "mnist", ".", "train", ".", "labels", "\n", "x_valid", "=", "list", "(", "np", ".", "expand_dims", "(", "mnist", ".", "validation", ".", "images", "[", ":", ",", "perm_mask", "]", ",", "-", "1", ")", ")", "\n", "y_valid", "=", "mnist", ".", "validation", ".", "labels", "\n", "x_test", "=", "list", "(", "np", ".", "expand_dims", "(", "mnist", ".", "test", ".", "images", "[", ":", ",", "perm_mask", "]", ",", "-", "1", ")", ")", "\n", "y_test", "=", "mnist", ".", "test", ".", "labels", "\n", "\n", "print", "(", "\"Train:Validation:Testing - %d:%d:%d\"", "%", "(", "len", "(", "y_train", ")", ",", "len", "(", "y_valid", ")", ",", "\n", "len", "(", "y_test", ")", ")", ")", "\n", "\n", "return", "x_train", ",", "y_train", ",", "x_valid", ",", "y_valid", ",", "x_test", ",", "y_test", "\n", "", ""]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.star.STARCell.__init__": [[9, 18], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.test_agent.TestAgent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_units", ",", "t_max", "=", "784", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "'''\n        t_max should be a float value corresponding to the longest possible\n        time dependency in the input.\n        '''", "\n", "self", ".", "num_units", "=", "num_units", "\n", "self", ".", "t_max", "=", "784", "\n", "super", "(", "STARCell", ",", "self", ")", ".", "__init__", "(", "num_units", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.star.STARCell.__call__": [[19, 67], ["tensorflow.variable_scope", "tensorflow.concat", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.concat", "tensorflow.nn.bias_add", "tensorflow.nn.bias_add", "tensorflow.tanh", "tensorflow.split", "x.get_shape().as_list", "print", "tensorflow.get_variable", "print", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.contrib.rnn.LSTMStateTuple", "tensorflow.concat", "tensorflow.python.keras.initializers.get", "tensorflow.python.keras.initializers.get", "tensorflow.python.keras.initializers.get", "tensorflow.sigmoid", "tensorflow.tanh", "type", "x.get_shape", "star.bias_initializer", "star.chrono_init", "tensorflow.sigmoid"], "methods", ["home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.star.bias_initializer", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.star.chrono_init"], ["", "def", "__call__", "(", "self", ",", "x", ",", "state", ",", "scope", "=", "None", ")", ":", "\n", "        ", "\"\"\"STAR cell.\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", "or", "type", "(", "self", ")", ".", "__name__", ")", ":", "\n", "            ", "if", "self", ".", "_state_is_tuple", ":", "\n", "                ", "h", ",", "_", "=", "state", "\n", "", "else", ":", "\n", "                ", "h", ",", "_", "=", "tf", ".", "split", "(", "value", "=", "state", ",", "num_or_size_splits", "=", "2", ",", "axis", "=", "1", ")", "\n", "\n", "", "all_inputs", "=", "tf", ".", "concat", "(", "[", "x", ",", "h", "]", ",", "1", ")", "\n", "\n", "x_size", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", "]", "\n", "\n", "weights_OBS", "=", "tf", ".", "get_variable", "(", "'W_xh_z'", ",", "\n", "[", "x_size", ",", "1", "*", "self", ".", "num_units", "]", ",", "initializer", "=", "initializers", ".", "get", "(", "'orthogonal'", ")", ")", "\n", "W_xh", "=", "tf", ".", "get_variable", "(", "'W_xh_K'", ",", "\n", "[", "x_size", ",", "1", "*", "self", ".", "num_units", "]", ",", "initializer", "=", "initializers", ".", "get", "(", "'orthogonal'", ")", ")", "\n", "W_hh", "=", "tf", ".", "get_variable", "(", "'W_hh'", ",", "\n", "[", "self", ".", "num_units", ",", "1", "*", "self", ".", "num_units", "]", ",", "initializer", "=", "initializers", ".", "get", "(", "'orthogonal'", ")", ")", "\n", "\n", "\n", "if", "self", ".", "t_max", "is", "None", ":", "\n", "                ", "print", "(", "'Zero initializer '", ")", "\n", "bias", "=", "tf", ".", "get_variable", "(", "'bias'", ",", "[", "2", "*", "self", ".", "num_units", "]", ",", "\n", "initializer", "=", "bias_initializer", "(", "2", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Using chrono initializer ...'", ")", "\n", "bias", "=", "tf", ".", "get_variable", "(", "'bias'", ",", "[", "2", "*", "self", ".", "num_units", "]", ",", "\n", "initializer", "=", "chrono_init", "(", "self", ".", "t_max", ",", "\n", "2", ")", ")", "\n", "\n", "", "weights_K", "=", "tf", ".", "concat", "(", "[", "W_xh", ",", "W_hh", "]", ",", "0", ")", "\n", "\n", "bias_K", "=", "bias", "[", "self", ".", "num_units", ":", ",", "...", "]", "\n", "bias_OBS", "=", "bias", "[", ":", "self", ".", "num_units", ",", "...", "]", "\n", "\n", "\n", "f", "=", "tf", ".", "nn", ".", "bias_add", "(", "tf", ".", "matmul", "(", "all_inputs", ",", "weights_K", ")", ",", "bias_K", ")", "\n", "j", "=", "tf", ".", "nn", ".", "bias_add", "(", "tf", ".", "matmul", "(", "x", ",", "weights_OBS", ")", ",", "bias_OBS", ")", "\n", "\n", "beta", "=", "1", "\n", "new_h", "=", "tf", ".", "sigmoid", "(", "f", ")", "*", "h", "+", "(", "1", "-", "tf", ".", "sigmoid", "(", "f", "-", "beta", ")", ")", "*", "tf", ".", "tanh", "(", "j", ")", "\n", "new_h", "=", "tf", ".", "tanh", "(", "new_h", ")", "\n", "\n", "if", "self", ".", "_state_is_tuple", ":", "\n", "                ", "new_state", "=", "LSTMStateTuple", "(", "new_h", ",", "new_h", ")", "\n", "", "else", ":", "\n", "                ", "new_state", "=", "tf", ".", "concat", "(", "[", "new_h", ",", "new_h", "]", ",", "1", ")", "\n", "", "return", "new_h", ",", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.star.chrono_init": [[69, 82], ["tensorflow.log", "tensorflow.zeros", "tensorflow.concat", "tensorflow.python.ops.random_ops.random_uniform"], "function", ["None"], ["", "", "", "def", "chrono_init", "(", "t_max", ",", "num_gates", ")", ":", "\n", "    ", "def", "_initializer", "(", "shape", ",", "dtype", "=", "tf", ".", "float32", ",", "partition_info", "=", "None", ")", ":", "\n", "        ", "num_units", "=", "shape", "[", "0", "]", "//", "num_gates", "\n", "uni_vals", "=", "tf", ".", "log", "(", "random_ops", ".", "random_uniform", "(", "[", "num_units", "]", ",", "minval", "=", "1.0", ",", "\n", "maxval", "=", "t_max", ",", "dtype", "=", "dtype", ",", "\n", "seed", "=", "42", ")", ")", "\n", "\n", "bias_j", "=", "tf", ".", "zeros", "(", "num_units", ")", "\n", "bias_f", "=", "uni_vals", "\n", "\n", "return", "tf", ".", "concat", "(", "[", "bias_j", ",", "bias_f", "]", ",", "0", ")", "\n", "\n", "", "return", "_initializer", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.star.bias_initializer": [[84, 95], ["numpy.zeros", "int", "numpy.ones", "tensorflow.constant"], "function", ["None"], ["", "def", "bias_initializer", "(", "num_gates", ")", ":", "\n", "    ", "def", "_initializer", "(", "shape", ",", "dtype", "=", "tf", ".", "float32", ",", "partition_info", "=", "None", ")", ":", "\n", "        ", "p", "=", "np", ".", "zeros", "(", "shape", ")", "\n", "num_units", "=", "int", "(", "shape", "[", "0", "]", "//", "num_gates", ")", "\n", "# i, j, o, f", "\n", "# f:", "\n", "p", "[", "-", "num_units", ":", "]", "=", "np", ".", "ones", "(", "num_units", ")", "\n", "\n", "return", "tf", ".", "constant", "(", "p", ",", "dtype", ")", "\n", "\n", "", "return", "_initializer", "\n", "", ""]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.tf_ops.create_sess": [[4, 9], ["tensorflow.ConfigProto", "tensorflow.Session"], "function", ["None"], ["def", "create_sess", "(", ")", ":", "\n", "    ", "sess_config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ")", "\n", "sess_config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "\n", "return", "tf", ".", "Session", "(", "config", "=", "sess_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.tf_ops.create_scalar_summaries": [[11, 25], ["range", "tensorflow.Summary", "len", "summary_value_list.append", "tensorflow.Summary.Value"], "function", ["None"], ["", "def", "create_scalar_summaries", "(", "tags", ",", "values", ")", ":", "\n", "    ", "'''\n    Input:\n    tags - the tag names to use in the summary\n    values - the values to log\n\n    Returns:\n    A tensorflow summary to be used in wrtier.add_summary(summary, steps)\n    '''", "\n", "summary_value_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "tags", ")", ")", ":", "\n", "        ", "summary_value_list", ".", "append", "(", "tf", ".", "Summary", ".", "Value", "(", "tag", "=", "tags", "[", "i", "]", ",", "\n", "simple_value", "=", "values", "[", "i", "]", ")", ")", "\n", "", "return", "tf", ".", "Summary", "(", "value", "=", "summary_value_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.tf_ops.linear": [[27, 39], ["tensorflow.constant_initializer", "tensorflow.random_normal_initializer", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "input_data.get_shape"], "function", ["None"], ["", "def", "linear", "(", "input_data", ",", "output_dim", ",", "scope", "=", "None", ",", "stddev", "=", "1.0", ",", "init_func", "=", "None", ")", ":", "\n", "    ", "if", "init_func", "==", "'norm'", ":", "\n", "        ", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "stddev", ")", "\n", "", "elif", "init_func", "is", "None", ":", "\n", "        ", "initializer", "=", "None", "\n", "", "const", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", "\n", "with", "tf", ".", "variable_scope", "(", "scope", "or", "'linear'", ")", ":", "\n", "        ", "w", "=", "tf", ".", "get_variable", "(", "\n", "'weights'", ",", "[", "input_data", ".", "get_shape", "(", ")", "[", "-", "1", "]", ",", "output_dim", "]", ",", "\n", "initializer", "=", "initializer", ")", "\n", "b", "=", "tf", ".", "get_variable", "(", "'bias'", ",", "[", "output_dim", "]", ",", "initializer", "=", "const", ")", "\n", "return", "tf", ".", "matmul", "(", "input_data", ",", "w", ")", "+", "b", "\n", "", "", ""]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.test_agent.TestAgent.__init__": [[16, 35], ["list", "list", "vars", "map", "args.layers.split", "numpy.ones"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "#self.h_dim = list(map(int, args.layers.split(',')))", "\n", "        ", "self", ".", "h_dim", "=", "list", "(", "map", "(", "int", ",", "args", ".", "layers", ".", "split", "(", "','", ")", ")", ")", "\n", "self", ".", "h_dim", "=", "list", "(", "(", "self", ".", "h_dim", "[", "0", "]", "*", "np", ".", "ones", "(", "[", "args", ".", "stack", "]", ")", ")", ".", "astype", "(", "int", ")", ")", "\n", "\n", "self", ".", "batch_size", "=", "args", ".", "batch_size", "\n", "self", ".", "keep_prob", "=", "args", ".", "keep_prob", "\n", "\n", "self", ".", "name", "=", "args", ".", "name", "\n", "\n", "self", ".", "args", "=", "vars", "(", "args", ")", "\n", "\n", "self", ".", "mse", "=", "False", "\n", "if", "args", ".", "data", "==", "'add'", ":", "\n", "            ", "self", ".", "mse", "=", "True", "\n", "\n", "", "self", ".", "output_format", "=", "'last'", "\n", "if", "args", ".", "data", "==", "'copy'", ":", "\n", "            ", "self", ".", "output_format", "=", "'all'", "\n", "\n"]], "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.test_agent.TestAgent.test": [[36, 97], ["tensorflow.reset_default_graph", "ops.get_max_length", "model_file.RNN_Model", "model_file.RNN_Model.build", "print", "tensorflow.trainable_variables", "ops.get_validset_feeds", "print", "tf_ops.create_sess", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "print", "numpy.zeros", "time.time", "sess.run", "ops.calculate_metrics", "print", "print", "ops.print_metrics", "tensorflow.train.latest_checkpoint", "len", "time.time", "numpy.argmax", "ops.save_config_dict", "os.path.isfile", "open", "csv.writer", "list", "csv.writer.writerow", "list", "open", "csv.writer", "csv.writer.writerow"], "methods", ["home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.get_max_length", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.model_file.RNN_Model.build", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.get_validset_feeds", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.tf_ops.create_sess", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.calculate_metrics", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.print_metrics", "home.repos.pwc.inspect_result.0zgur0_STAR_Network.None.ops.save_config_dict"], ["", "", "def", "test", "(", "self", ",", "x", ",", "y", ",", "model_path", ",", "conf_dict", "=", "None", ")", ":", "\n", "        ", "tf", ".", "reset_default_graph", "(", ")", "\n", "max_len", "=", "get_max_length", "(", "x", ")", "\n", "\n", "# Create the model", "\n", "model", "=", "RNN_Model", "(", "x", "[", "0", "]", ".", "shape", "[", "-", "1", "]", ",", "y", ".", "shape", "[", "-", "1", "]", ",", "\n", "h_dim", "=", "self", ".", "h_dim", ",", "\n", "max_sequence_length", "=", "max_len", ",", "\n", "is_test", "=", "True", ",", "\n", "cell_type", "=", "self", ".", "args", "[", "'cell'", "]", ",", "\n", "mse", "=", "self", ".", "mse", ",", "\n", ")", "\n", "model", ".", "build", "(", "self", ".", "output_format", ")", "\n", "\n", "print", "(", "'Variables to be loaded'", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "            ", "print", "(", "v", ")", "\n", "\n", "# Prepare the test data", "\n", "", "input_feed", ",", "output_feed", "=", "get_validset_feeds", "(", "\n", "model", ",", "x", ",", "y", ",", "self", ".", "h_dim", ")", "\n", "\n", "metric_tags", "=", "[", "'Test Loss'", ",", "'Test Acc'", ",", "'Test F1'", "]", "\n", "\n", "with", "create_sess", "(", ")", "as", "sess", ":", "\n", "            ", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "sess", ",", "\n", "tf", ".", "train", ".", "latest_checkpoint", "(", "model_path", ")", ")", "\n", "\n", "print", "(", "\"Testing model ...\"", ")", "\n", "eval_metrics", "=", "np", ".", "zeros", "(", "len", "(", "metric_tags", ")", ")", "\n", "\n", "# Time the testing", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "eval_metrics", "[", "0", "]", ",", "output_probs", "=", "sess", ".", "run", "(", "output_feed", ",", "\n", "input_feed", ")", "\n", "duration", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "eval_metrics", "[", "1", ":", "]", "+=", "calculate_metrics", "(", "\n", "y", ",", "np", ".", "argmax", "(", "output_probs", ",", "axis", "=", "1", ")", ")", "\n", "\n", "if", "self", ".", "args", "[", "'results_file'", "]", "is", "None", ":", "\n", "                ", "if", "conf_dict", "is", "not", "None", ":", "\n", "# Save the config to json", "\n", "                    ", "save_config_dict", "(", "conf_dict", ",", "model_path", ",", "\n", "metric_tags", "[", ":", "-", "1", "]", ",", "\n", "list", "(", "eval_metrics", "[", ":", "-", "1", "]", ")", ")", "\n", "", "", "else", ":", "\n", "# Create the file with headers if it doesn't exist", "\n", "                ", "if", "not", "os", ".", "path", ".", "isfile", "(", "self", ".", "args", "[", "'results_file'", "]", ")", ":", "\n", "                    ", "with", "open", "(", "self", ".", "args", "[", "'results_file'", "]", ",", "'w'", ")", "as", "fd", ":", "\n", "                        ", "writer", "=", "csv", ".", "writer", "(", "fd", ")", "\n", "writer", ".", "writerow", "(", "metric_tags", "[", ":", "-", "1", "]", ")", "\n", "", "", "with", "open", "(", "self", ".", "args", "[", "'results_file'", "]", ",", "'a'", ")", "as", "fd", ":", "\n", "                    ", "writer", "=", "csv", ".", "writer", "(", "fd", ")", "\n", "row", "=", "list", "(", "eval_metrics", "[", ":", "-", "1", "]", ")", "\n", "writer", ".", "writerow", "(", "row", ")", "\n", "\n", "", "", "print", "(", ")", "\n", "print", "(", "self", ".", "name", "+", "\":\"", "\n", "\"  |  test duration: {}\"", ".", "format", "(", "duration", ")", ")", "\n", "print_metrics", "(", "metric_tags", "[", ":", "-", "1", "]", ",", "eval_metrics", "[", ":", "-", "1", "]", ")", "\n", "", "", "", ""]]}