{"home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.dataset.tlfm_dataset.TFLMDatasetGAN.__init__": [[21, 111], ["torchvision.transforms.Compose", "os.listdir", "torchvision.transforms.RandomHorizontalFlip", "os.path.isdir", "os.path.join", "range", "os.path.join", "bf_images.append", "bf_images[].sort", "gfp_images.append", "gfp_images[].sort", "rfp_images.append", "rfp_images[].sort", "len", "range", "os.listdir", "tlfm_dataset.TFLMDatasetGAN._check_if_same_trap", "os.path.join", "tlfm_dataset.TFLMDatasetGAN.paths_to_dataset_samples.append", "len", "[].replace", "[].replace", "[].replace", "tuple", "tuple", "tuple", "item.split", "item.split", "item.split", "[].split", "[].split", "[].split", "item.split", "item.split", "item.split"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.dataset.tlfm_dataset.TFLMDatasetGAN._check_if_same_trap"], ["def", "__init__", "(", "self", ",", "path", ":", "str", ",", "\n", "sequence_length", ":", "int", "=", "3", ",", "\n", "overlap", ":", "bool", "=", "True", ",", "\n", "transformations", ":", "transforms", ".", "Compose", "=", "transforms", ".", "Compose", "(", "\n", "[", "transforms", ".", "RandomHorizontalFlip", "(", "p", "=", "0.5", ")", "]", ")", ",", "\n", "z_position_indications", ":", "Tuple", "[", "str", "]", "=", "(", "\"_000_\"", ",", "\"_001_\"", ",", "\"_002_\"", ")", ",", "\n", "gfp_min", ":", "Union", "[", "float", ",", "int", "]", "=", "150.0", ",", "\n", "gfp_max", ":", "Union", "[", "float", ",", "int", "]", "=", "2200.0", ",", "\n", "rfp_min", ":", "Union", "[", "float", ",", "int", "]", "=", "20.0", ",", "\n", "rfp_max", ":", "Union", "[", "float", ",", "int", "]", "=", "2000.0", ",", "\n", "flip", ":", "bool", "=", "True", ",", "\n", "positions", ":", "Optional", "[", "Tuple", "[", "str", ",", "...", "]", "]", "=", "None", ",", "\n", "no_rfp", ":", "bool", "=", "False", ",", "\n", "no_gfp", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param path: (str) Path to dataset\n        :param sequence_length: (int) Length of sequence to be returned\n        :param overlap: (bool) If true sequences can overlap\n        :param transformations: (transforms.Compose) Transformations and augmentations to be applied\n        :param z_position_indications: (Tuple[str]) String to indicate each z position\n        :param gfp_min: (Union[float, int]) Minimal value assumed gfp value\n        :param gfp_max: (Union[float, int]) Maximal value assumed gfp value\n        :param rfp_min: (Union[float, int]) Minimal value assumed rfp value\n        :param rfp_max: (Union[float, int]) Maximal value assumed rfp value\n        :param flip: (bool) If true images are flipped vertically\n        :param positions: (Optional[Tuple[str, ...]]) If given only positions which are given are loaded\n        :param no_rfp: (bool) If true no rfp channel is utilized\n        :param no_rfp: (bool) If true nogfp channel is utilized\n        \"\"\"", "\n", "# Save parameters", "\n", "self", ".", "transformations", "=", "transformations", "\n", "self", ".", "gfp_min", "=", "gfp_min", "\n", "self", ".", "gfp_max", "=", "gfp_max", "\n", "self", ".", "rfp_min", "=", "rfp_min", "\n", "self", ".", "rfp_max", "=", "rfp_max", "\n", "self", ".", "flip", "=", "flip", "\n", "self", ".", "no_rfp", "=", "no_rfp", "\n", "self", ".", "no_gfp", "=", "no_gfp", "\n", "# Load data sample paths", "\n", "self", ".", "paths_to_dataset_samples", "=", "[", "]", "\n", "# Iterate over all position folders", "\n", "for", "position_folder", "in", "os", ".", "listdir", "(", "path", "=", "path", ")", ":", "\n", "            ", "if", "(", "positions", "is", "None", ")", "or", "(", "position_folder", "in", "positions", ")", ":", "\n", "# Check that current folder is really a folder", "\n", "                ", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "path", ",", "position_folder", ")", ")", ":", "\n", "# Load images all in folder", "\n", "                    ", "all_images", "=", "[", "os", ".", "path", ".", "join", "(", "path", ",", "position_folder", ",", "image_file", ")", "for", "image_file", "in", "\n", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "path", ",", "position_folder", ")", ")", "if", "\"tif\"", "in", "image_file", "]", "\n", "# Get all BF images", "\n", "all_bf_images", "=", "[", "image_file", "for", "image_file", "in", "all_images", "if", "\"-BF0_\"", "in", "image_file", "]", "\n", "# Get all GFP images", "\n", "all_gfp_images", "=", "[", "image_file", "for", "image_file", "in", "all_images", "if", "\"-GFP\"", "in", "image_file", "]", "\n", "# Get all RFP images", "\n", "all_rfp_images", "=", "[", "image_file", "for", "image_file", "in", "all_images", "if", "\"-RFP\"", "in", "image_file", "]", "\n", "# Convert list of images to list of z positions including images", "\n", "bf_images", "=", "[", "]", "\n", "for", "z_position_indication", "in", "z_position_indications", ":", "\n", "                        ", "bf_images", ".", "append", "(", "\n", "[", "image_file", "for", "image_file", "in", "all_bf_images", "if", "z_position_indication", "in", "image_file", "]", ")", "\n", "# Sort images by time steps and trap number", "\n", "bf_images", "[", "-", "1", "]", ".", "sort", "(", "key", "=", "lambda", "item", ":", "\n", "item", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", ".", "replace", "(", "\".tif\"", ",", "\"\"", ")", "+", "\n", "item", ".", "split", "(", "\"_\"", ")", "[", "-", "5", "]", ")", "\n", "", "gfp_images", "=", "[", "]", "\n", "for", "z_position_indication", "in", "z_position_indications", ":", "\n", "                        ", "gfp_images", ".", "append", "(", "\n", "[", "image_file", "for", "image_file", "in", "all_gfp_images", "if", "z_position_indication", "in", "image_file", "]", ")", "\n", "# Sort images by time steps and trap number", "\n", "gfp_images", "[", "-", "1", "]", ".", "sort", "(", "key", "=", "lambda", "item", ":", "\n", "item", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", ".", "replace", "(", "\".tif\"", ",", "\"\"", ")", "+", "\n", "item", ".", "split", "(", "\"_\"", ")", "[", "-", "5", "]", ")", "\n", "", "rfp_images", "=", "[", "]", "\n", "for", "z_position_indication", "in", "z_position_indications", ":", "\n", "                        ", "rfp_images", ".", "append", "(", "\n", "[", "image_file", "for", "image_file", "in", "all_rfp_images", "if", "z_position_indication", "in", "image_file", "]", ")", "\n", "# Sort images by time steps and trap number", "\n", "rfp_images", "[", "-", "1", "]", ".", "sort", "(", "key", "=", "lambda", "item", ":", "\n", "item", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", ".", "replace", "(", "\".tif\"", ",", "\"\"", ")", "+", "\n", "item", ".", "split", "(", "\"_\"", ")", "[", "-", "5", "]", ")", "\n", "# Construct image sequences", "\n", "", "for", "z_position", "in", "range", "(", "len", "(", "z_position_indications", ")", ")", ":", "\n", "                        ", "for", "index", "in", "range", "(", "0", ",", "len", "(", "bf_images", "[", "z_position", "]", ")", "-", "sequence_length", "+", "1", ",", "\n", "1", "if", "overlap", "else", "sequence_length", ")", ":", "\n", "                            ", "if", "self", ".", "_check_if_same_trap", "(", "bf_images", "[", "z_position", "]", "[", "index", ":", "index", "+", "sequence_length", "]", ")", ":", "\n", "# Save paths", "\n", "                                ", "self", ".", "paths_to_dataset_samples", ".", "append", "(", "\n", "(", "tuple", "(", "bf_images", "[", "z_position", "]", "[", "index", ":", "index", "+", "sequence_length", "]", ")", ",", "\n", "tuple", "(", "gfp_images", "[", "z_position", "]", "[", "index", ":", "index", "+", "sequence_length", "]", ")", ",", "\n", "tuple", "(", "rfp_images", "[", "z_position", "]", "[", "index", ":", "index", "+", "sequence_length", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.dataset.tlfm_dataset.TFLMDatasetGAN._check_if_same_trap": [[112, 120], ["all", "path.find", "path.find"], "methods", ["None"], ["", "", "", "", "", "", "", "def", "_check_if_same_trap", "(", "self", ",", "path_list", ":", "List", "[", "str", "]", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Method checks of a sequence of images paths include the same trap.\n        :param path_list: (List[str]) List of strings\n        :return: (bool) If same trap true else false\n        \"\"\"", "\n", "traps", "=", "[", "path", "[", "path", ".", "find", "(", "\"trap\"", ")", ":", "path", ".", "find", "(", "\"trap\"", ")", "+", "8", "]", "for", "path", "in", "path_list", "]", "\n", "return", "all", "(", "trap", "==", "traps", "[", "0", "]", "for", "trap", "in", "traps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.dataset.tlfm_dataset.TFLMDatasetGAN.__len__": [[121, 127], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Returns the length of the dataset.\n        :return: (int) Length of the dataset.\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "paths_to_dataset_samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.dataset.tlfm_dataset.TFLMDatasetGAN.__getitem__": [[128, 199], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "dataset.utils.normalize_0_1", "cv2.imread().astype", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.stack.append", "torch.stack.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "tlfm_dataset.TFLMDatasetGAN.transformations", "torch.stack.unsqueeze", "torch.stack.unsqueeze", "torch.stack.flip", "torch.stack.flip", "cv2.imread().astype", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.stack.append", "torch.stack.append", "cv2.imread().astype", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.stack.append", "torch.stack.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "tlfm_dataset.TFLMDatasetGAN.transformations", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "tlfm_dataset.TFLMDatasetGAN.transformations", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "cv2.imread", "torch.stack.ndimension", "torch.stack.ndimension", "torch.stack.split", "torch.stack.split", "torch.stack.split", "torch.stack.split", "cv2.imread", "cv2.imread", "torch.stack.ndimension", "torch.stack.ndimension", "torch.stack.ndimension", "torch.stack.ndimension"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.dataset.utils.normalize_0_1"], ["", "def", "__getitem__", "(", "self", ",", "item", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Method returns one instance with the index item of the dataset.\n        :param item: (int) Index of the dataset element to be returned\n        :return: (torch.Tensor) Image sequence of n images\n        \"\"\"", "\n", "# Get paths", "\n", "path_bf_images", ",", "path_gfp_images", ",", "path_rfp_images", "=", "self", ".", "paths_to_dataset_samples", "[", "item", "]", "\n", "# Load bf images", "\n", "bf_images", "=", "[", "]", "\n", "for", "path_bf_image", "in", "path_bf_images", ":", "\n", "            ", "image", "=", "cv2", ".", "imread", "(", "path_bf_image", ",", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "image", "=", "torch", ".", "from_numpy", "(", "image", ")", "\n", "bf_images", ".", "append", "(", "image", ")", "\n", "", "bf_images", "=", "torch", ".", "stack", "(", "bf_images", ",", "dim", "=", "0", ")", "\n", "# Load gfp images", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "            ", "gfp_images", "=", "[", "]", "\n", "for", "path_gfp_image", "in", "path_gfp_images", ":", "\n", "                ", "image", "=", "cv2", ".", "imread", "(", "path_gfp_image", ",", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "image", "=", "torch", ".", "from_numpy", "(", "image", ")", "\n", "gfp_images", ".", "append", "(", "image", ")", "\n", "", "gfp_images", "=", "torch", ".", "stack", "(", "gfp_images", ",", "dim", "=", "0", ")", "\n", "# Load rfp images", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "            ", "rfp_images", "=", "[", "]", "\n", "for", "path_rfp_image", "in", "path_rfp_images", ":", "\n", "                ", "image", "=", "cv2", ".", "imread", "(", "path_rfp_image", ",", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "image", "=", "torch", ".", "from_numpy", "(", "image", ")", "\n", "rfp_images", ".", "append", "(", "image", ")", "\n", "", "rfp_images", "=", "torch", ".", "stack", "(", "rfp_images", ",", "dim", "=", "0", ")", "\n", "", "if", "self", ".", "no_gfp", ":", "\n", "# Concat images", "\n", "            ", "images", "=", "torch", ".", "cat", "(", "[", "bf_images", "]", ",", "dim", "=", "0", ")", "\n", "# Perform transformations", "\n", "images", "=", "self", ".", "transformations", "(", "images", ")", "\n", "# Remove batch dimension", "\n", "images", "=", "images", "[", "0", "]", "if", "images", ".", "ndimension", "(", ")", "==", "4", "else", "images", "\n", "# Reshape images to [1, sequence length, height, width]", "\n", "images", "=", "images", ".", "unsqueeze", "(", "dim", "=", "0", ")", "\n", "", "elif", "self", ".", "no_rfp", ":", "\n", "# Concat images", "\n", "            ", "images", "=", "torch", ".", "cat", "(", "[", "bf_images", ",", "gfp_images", "]", ",", "dim", "=", "0", ")", "\n", "# Perform transformations", "\n", "images", ":", "torch", ".", "Tensor", "=", "self", ".", "transformations", "(", "images", ")", "\n", "# Remove batch dimension", "\n", "images", "=", "images", "[", "0", "]", "if", "images", ".", "ndimension", "(", ")", "==", "4", "else", "images", "\n", "# Reshape images to [2, sequence length, height, width]", "\n", "images", "=", "torch", ".", "stack", "(", "images", ".", "split", "(", "split_size", "=", "images", ".", "shape", "[", "0", "]", "//", "2", ",", "dim", "=", "0", ")", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "# Concat images", "\n", "            ", "images", "=", "torch", ".", "cat", "(", "[", "bf_images", ",", "gfp_images", ",", "rfp_images", "]", ",", "dim", "=", "0", ")", "\n", "# Perform transformations", "\n", "images", "=", "self", ".", "transformations", "(", "images", ")", "\n", "# Remove batch dimension", "\n", "images", "=", "images", "[", "0", "]", "if", "images", ".", "ndimension", "(", ")", "==", "4", "else", "images", "\n", "# Reshape images to [3, sequence length, height, width]", "\n", "images", "=", "torch", ".", "stack", "(", "images", ".", "split", "(", "split_size", "=", "images", ".", "shape", "[", "0", "]", "//", "3", ",", "dim", "=", "0", ")", ",", "dim", "=", "0", ")", "\n", "# Normalized bf images", "\n", "", "images", "[", "0", "]", "=", "utils", ".", "normalize_0_1", "(", "images", "[", "0", "]", ")", "\n", "# Normalize gfp images", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "# images[1] = utils.normalize_0_1(images[1])", "\n", "            ", "images", "[", "1", "]", "=", "(", "(", "images", "[", "1", "]", "-", "self", ".", "gfp_min", ")", ".", "clamp", "(", "min", "=", "0.0", ")", "/", "self", ".", "gfp_max", ")", ".", "clamp", "(", "max", "=", "1.0", ")", "\n", "# Normalize rfp images", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "# images[2] = utils.normalize_0_1(images[2])", "\n", "            ", "images", "[", "2", "]", "=", "(", "(", "images", "[", "2", "]", "-", "self", ".", "rfp_min", ")", ".", "clamp", "(", "min", "=", "0.0", ")", "/", "self", ".", "rfp_max", ")", ".", "clamp", "(", "max", "=", "1.0", ")", "\n", "# Flip images if utilized", "\n", "", "images", "=", "images", ".", "flip", "(", "dims", "=", "(", "-", "2", ",", ")", ")", "if", "self", ".", "flip", "else", "images", "\n", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.dataset.tlfm_dataset.ElasticDeformation.__init__": [[206, 220], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ",", "sample_mode", ":", "str", "=", "\"bilinear\"", ",", "alpha", ":", "int", "=", "80", ",", "\n", "sigma", ":", "int", "=", "16", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param sample_mode: (str) Resmapling mode\n        :param alpha: (int) Scale factor of the deformation\n        :param sigma: (int) Standard deviation of the gaussian kernel to be applied\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "ElasticDeformation", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Save parameters", "\n", "self", ".", "sample_mode", "=", "sample_mode", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "sigma", "=", "sigma", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.dataset.tlfm_dataset.ElasticDeformation.forward": [[221, 228], ["tlfm_dataset.elastic_deformation"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.dataset.tlfm_dataset.elastic_deformation"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass applies random elastic deformation\n        :param input: (torch.Tensor) Input tensor\n        :return: (torch.Tensor) Augmented output tensor\n        \"\"\"", "\n", "return", "elastic_deformation", "(", "img", "=", "input", ",", "sample_mode", "=", "self", ".", "sample_mode", ",", "alpha", "=", "self", ".", "alpha", ",", "sigma", "=", "self", ".", "sigma", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.dataset.tlfm_dataset.elastic_deformation": [[230, 276], ["torch.arange", "torch.arange", "torch.arange.repeat().view", "x_cord.repeat().view.t", "torch.stack", "torch.stack", "gaussian_kernel.repeat.view", "gaussian_kernel.repeat.repeat", "torch.stack().unsqueeze().flip", "torch.stack().unsqueeze().flip", "torch.exp", "torch.exp", "torch.nn.functional.conv2d().squeeze", "torch.nn.functional.conv2d().squeeze", "torch.nn.functional.grid_sample", "torch.nn.functional.grid_sample", "torch.arange.repeat", "torch.stack().unsqueeze", "torch.stack().unsqueeze", "torch.nn.functional.conv2d", "torch.nn.functional.conv2d", "torch.sum", "torch.sum", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.meshgrid", "torch.meshgrid", "img.ndimension", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "function", ["None"], ["", "", "def", "elastic_deformation", "(", "img", ":", "torch", ".", "Tensor", ",", "sample_mode", ":", "str", "=", "\"bilinear\"", ",", "alpha", ":", "int", "=", "50", ",", "\n", "sigma", ":", "int", "=", "12", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Performs random elastic deformation to the given Tensor image\n    :param img: (torch.Tensor) Input image\n    :param sample_mode: (str) Resmapling mode\n    :param alpha: (int) Scale factor of the deformation\n    :param sigma: (int) Standard deviation of the gaussian kernel to be applied\n    \"\"\"", "\n", "# Get image shape", "\n", "height", ",", "width", "=", "img", ".", "shape", "[", "-", "2", ":", "]", "\n", "# Get kernel size", "\n", "kernel_size", "=", "(", "sigma", "*", "4", ")", "+", "1", "\n", "# Get mean of gaussian kernel", "\n", "mean", "=", "(", "kernel_size", "-", "1", ")", "/", "2.", "\n", "# Make gaussian kernel", "\n", "# https://discuss.pytorch.org/t/is-there-anyway-to-do-gaussian-filtering-for-an-image-2d-3d-in-pytorch/12351/7", "\n", "x_cord", "=", "torch", ".", "arange", "(", "kernel_size", ",", "device", "=", "img", ".", "device", ")", "\n", "x_grid", "=", "x_cord", ".", "repeat", "(", "kernel_size", ")", ".", "view", "(", "kernel_size", ",", "kernel_size", ")", "\n", "y_grid", "=", "x_grid", ".", "t", "(", ")", "\n", "xy_grid", "=", "torch", ".", "stack", "(", "[", "x_grid", ",", "y_grid", "]", ",", "dim", "=", "-", "1", ")", "\n", "gaussian_kernel", "=", "(", "1.", "/", "(", "2.", "*", "math", ".", "pi", "*", "sigma", "**", "2", ")", ")", "*", "torch", ".", "exp", "(", "-", "torch", ".", "sum", "(", "(", "xy_grid", "-", "mean", ")", "**", "2.", ",", "dim", "=", "-", "1", ")", "/", "(", "2.", "*", "sigma", "**", "2", ")", ")", "\n", "gaussian_kernel", "=", "gaussian_kernel", ".", "view", "(", "1", ",", "1", ",", "kernel_size", ",", "kernel_size", ")", "\n", "gaussian_kernel", "=", "gaussian_kernel", ".", "repeat", "(", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "gaussian_kernel", ".", "requires_grad", "=", "False", "\n", "# Make random deformations in the range of [-1, 1]", "\n", "dx", "=", "(", "torch", ".", "rand", "(", "(", "height", ",", "width", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "img", ".", "device", ")", "*", "2.", "-", "1.", ")", ".", "view", "(", "1", ",", "1", ",", "height", ",", "width", ")", "\n", "dy", "=", "(", "torch", ".", "rand", "(", "(", "height", ",", "width", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "img", ".", "device", ")", "*", "2.", "-", "1.", ")", ".", "view", "(", "1", ",", "1", ",", "height", ",", "width", ")", "\n", "# Apply gaussian filter to deformations", "\n", "dx", ",", "dy", "=", "torch", ".", "nn", ".", "functional", ".", "conv2d", "(", "input", "=", "torch", ".", "cat", "(", "[", "dx", ",", "dy", "]", ",", "dim", "=", "0", ")", ",", "weight", "=", "gaussian_kernel", ",", "stride", "=", "1", ",", "\n", "padding", "=", "kernel_size", "//", "2", ")", ".", "squeeze", "(", "dim", "=", "0", ")", "*", "alpha", "\n", "# Add deformations to coordinate grid", "\n", "grid", "=", "torch", ".", "stack", "(", "torch", ".", "meshgrid", "(", "[", "torch", ".", "arange", "(", "height", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "img", ".", "device", ")", ",", "\n", "torch", ".", "arange", "(", "width", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "img", ".", "device", ")", "]", ")", ",", "\n", "dim", "=", "-", "1", ")", ".", "unsqueeze", "(", "dim", "=", "0", ")", ".", "flip", "(", "dims", "=", "(", "-", "1", ",", ")", ")", "\n", "grid", "[", "...", ",", "0", "]", "+=", "dx", "\n", "grid", "[", "...", ",", "1", "]", "+=", "dy", "\n", "# Convert grid to relative sampling location in the range of [-1, 1]", "\n", "grid", "[", "...", ",", "0", "]", "=", "2", "*", "(", "grid", "[", "...", ",", "0", "]", "-", "(", "height", "//", "2", ")", ")", "/", "height", "\n", "grid", "[", "...", ",", "1", "]", "=", "2", "*", "(", "grid", "[", "...", ",", "1", "]", "-", "(", "width", "//", "2", ")", ")", "/", "width", "\n", "# Resample image", "\n", "img_deformed", "=", "torch", ".", "nn", ".", "functional", ".", "grid_sample", "(", "input", "=", "img", "[", "None", "]", "if", "img", ".", "ndimension", "(", ")", "==", "3", "else", "img", ",", "\n", "grid", "=", "grid", ",", "mode", "=", "sample_mode", ",", "padding_mode", "=", "'border'", ",", "\n", "align_corners", "=", "False", ")", "[", "0", "]", "\n", "return", "img_deformed", "\n", "", ""]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.dataset.utils.normalize_0_1": [[4, 24], ["tensor.reshape.flatten", "tensor.reshape.reshape", "[].float", "torch.tensor", "[].float", "torch.tensor", "tensor.reshape.min", "tensor.reshape.max"], "function", ["None"], ["def", "normalize_0_1", "(", "tensor", ":", "torch", ".", "Tensor", ",", "max", ":", "float", "=", "None", ",", "min", ":", "float", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Function normalizes a given input tensor channel-wise to a rage between zero and one.\n    :param tensor: (torch.Tensor) Input tensor of the shape [channels, height, width]\n    :param max: (float) Max value utilized in the normalization\n    :param min: (float) Min value of the normalization\n    :return: (torch.Tensor) Normalized input tensor of the same shape as the input\n    \"\"\"", "\n", "# Save shape", "\n", "channels", ",", "height", ",", "width", "=", "tensor", ".", "shape", "\n", "# Flatten input tensor to the shape [channels, height * width]", "\n", "tensor", "=", "tensor", ".", "flatten", "(", "start_dim", "=", "1", ")", "\n", "# Get channel wise min and max", "\n", "tensor_min", "=", "tensor", ".", "min", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "[", "0", "]", ".", "float", "(", ")", "if", "min", "is", "None", "else", "torch", ".", "tensor", "(", "min", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "tensor_max", "=", "tensor", ".", "max", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "[", "0", "]", ".", "float", "(", ")", "if", "max", "is", "None", "else", "torch", ".", "tensor", "(", "max", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "# Normalize tensor", "\n", "tensor", "=", "(", "tensor", "-", "tensor_min", ")", "/", "(", "tensor_max", "-", "tensor_min", ")", "\n", "# Reshape tensor to original shape", "\n", "tensor", "=", "tensor", ".", "reshape", "(", "channels", ",", "height", ",", "width", ")", "\n", "return", "tensor", "\n", "", ""]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.Generator.__init__": [[20, 96], ["torch.Module.__init__", "multi_stylegan_generator.StyleMapping", "multi_stylegan_generator.ConstantInput", "multi_stylegan_generator.ConstantInput", "multi_stylegan_generator.StyledConv2d", "multi_stylegan_generator.StyledConv2d", "multi_stylegan_generator.OutputBlock", "multi_stylegan_generator.OutputBlock", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "torch.Module", "torch.Module", "torch.Module", "multi_stylegan_generator.Generator.noises.register_buffer", "range", "multi_stylegan_generator.Generator.main_convolutions_1.append", "multi_stylegan_generator.Generator.main_convolutions_1.append", "multi_stylegan_generator.Generator.output_blocks_1.append", "multi_stylegan_generator.Generator.main_convolutions_2.append", "multi_stylegan_generator.Generator.main_convolutions_2.append", "multi_stylegan_generator.Generator.output_blocks_2.append", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "multi_stylegan_generator.Generator.noises.register_buffer", "multi_stylegan_generator.Generator.noises.register_buffer", "int", "int", "int", "int", "int", "int", "int", "int", "len", "multi_stylegan_generator.StyledConv2d", "multi_stylegan_generator.StyledConv2d", "multi_stylegan_generator.OutputBlock", "multi_stylegan_generator.StyledConv2d", "multi_stylegan_generator.StyledConv2d", "multi_stylegan_generator.OutputBlock", "len", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "int", "int", "int", "int", "int", "int", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param config: (Dict[str, Any]) Dict with network configurations\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "Generator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Save parameter", "\n", "channels", ":", "Tuple", "[", "int", ",", "...", "]", "=", "config", "[", "\"channels\"", "]", "\n", "channel_factor", ":", "Union", "[", "int", ",", "float", "]", "=", "config", "[", "\"channel_factor\"", "]", "\n", "self", ".", "out_channels", ":", "int", "=", "3", "\n", "self", ".", "latent_dimensions", ":", "int", "=", "config", "[", "\"latent_dimensions\"", "]", "\n", "depth_style_mapping", ":", "int", "=", "config", "[", "\"depth_style_mapping\"", "]", "\n", "self", ".", "starting_resolution", ":", "Tuple", "[", "int", ",", "int", "]", "=", "config", "[", "\"starting_resolution\"", "]", "\n", "# Init style mapping", "\n", "self", ".", "style_mapping", "=", "StyleMapping", "(", "latent_dimensions", "=", "self", ".", "latent_dimensions", ",", "depth", "=", "depth_style_mapping", ")", "\n", "# Init constant input module", "\n", "self", ".", "constant_input_1", "=", "ConstantInput", "(", "channel", "=", "int", "(", "channels", "[", "0", "]", "//", "channel_factor", ")", ",", "size", "=", "self", ".", "starting_resolution", ")", "\n", "self", ".", "constant_input_2", "=", "ConstantInput", "(", "channel", "=", "int", "(", "channels", "[", "0", "]", "//", "channel_factor", ")", ",", "size", "=", "self", ".", "starting_resolution", ")", "\n", "# Init first styled convolution", "\n", "self", ".", "starting_convolution_1", "=", "StyledConv2d", "(", "in_channels", "=", "int", "(", "channels", "[", "0", "]", "//", "channel_factor", ")", ",", "\n", "out_channels", "=", "int", "(", "channels", "[", "0", "]", "//", "channel_factor", ")", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "style_dimension", "=", "self", ".", "latent_dimensions", ",", "upsampling", "=", "False", ",", "\n", "demodulate", "=", "True", ")", "\n", "self", ".", "starting_convolution_2", "=", "StyledConv2d", "(", "in_channels", "=", "int", "(", "channels", "[", "0", "]", "//", "channel_factor", ")", ",", "\n", "out_channels", "=", "int", "(", "channels", "[", "0", "]", "//", "channel_factor", ")", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "style_dimension", "=", "self", ".", "latent_dimensions", ",", "upsampling", "=", "False", ",", "\n", "demodulate", "=", "True", ",", "modulation_mapping", "=", "False", ")", "\n", "# Init first output mapping", "\n", "self", ".", "starting_output_block_1", "=", "OutputBlock", "(", "in_channels", "=", "int", "(", "channels", "[", "0", "]", "//", "channel_factor", ")", ",", "\n", "out_channels", "=", "self", ".", "out_channels", ",", "\n", "style_dimension", "=", "self", ".", "latent_dimensions", ",", "upsampling", "=", "False", ")", "\n", "self", ".", "starting_output_block_2", "=", "OutputBlock", "(", "in_channels", "=", "int", "(", "channels", "[", "0", "]", "//", "channel_factor", ")", ",", "\n", "out_channels", "=", "self", ".", "out_channels", ",", "\n", "style_dimension", "=", "self", ".", "latent_dimensions", ",", "upsampling", "=", "False", ",", "\n", "modulation_mapping", "=", "False", ")", "\n", "# Init main styled convolutions and output blocks", "\n", "self", ".", "main_convolutions_1", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "output_blocks_1", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "main_convolutions_2", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "output_blocks_2", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "index", "in", "range", "(", "len", "(", "channels", ")", "-", "1", ")", ":", "\n", "            ", "self", ".", "main_convolutions_1", ".", "append", "(", "\n", "StyledConv2d", "(", "in_channels", "=", "int", "(", "channels", "[", "index", "]", "//", "channel_factor", ")", ",", "\n", "out_channels", "=", "int", "(", "channels", "[", "index", "+", "1", "]", "//", "channel_factor", ")", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "\n", "style_dimension", "=", "self", ".", "latent_dimensions", ",", "upsampling", "=", "True", ",", "demodulate", "=", "True", ")", ")", "\n", "self", ".", "main_convolutions_1", ".", "append", "(", "\n", "StyledConv2d", "(", "in_channels", "=", "int", "(", "channels", "[", "index", "+", "1", "]", "//", "channel_factor", ")", ",", "\n", "out_channels", "=", "int", "(", "channels", "[", "index", "+", "1", "]", "//", "channel_factor", ")", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "style_dimension", "=", "self", ".", "latent_dimensions", ",", "upsampling", "=", "False", ",", "demodulate", "=", "True", ")", ")", "\n", "self", ".", "output_blocks_1", ".", "append", "(", "OutputBlock", "(", "in_channels", "=", "int", "(", "channels", "[", "index", "+", "1", "]", "//", "channel_factor", ")", ",", "\n", "out_channels", "=", "self", ".", "out_channels", ",", "\n", "style_dimension", "=", "self", ".", "latent_dimensions", ",", "upsampling", "=", "True", ")", ")", "\n", "self", ".", "main_convolutions_2", ".", "append", "(", "\n", "StyledConv2d", "(", "in_channels", "=", "int", "(", "channels", "[", "index", "]", "//", "channel_factor", ")", ",", "\n", "out_channels", "=", "int", "(", "channels", "[", "index", "+", "1", "]", "//", "channel_factor", ")", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "\n", "style_dimension", "=", "self", ".", "latent_dimensions", ",", "upsampling", "=", "True", ",", "demodulate", "=", "True", ",", "\n", "modulation_mapping", "=", "False", ")", ")", "\n", "self", ".", "main_convolutions_2", ".", "append", "(", "\n", "StyledConv2d", "(", "in_channels", "=", "int", "(", "channels", "[", "index", "+", "1", "]", "//", "channel_factor", ")", ",", "\n", "out_channels", "=", "int", "(", "channels", "[", "index", "+", "1", "]", "//", "channel_factor", ")", ",", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "\n", "style_dimension", "=", "self", ".", "latent_dimensions", ",", "upsampling", "=", "False", ",", "demodulate", "=", "True", ",", "\n", "modulation_mapping", "=", "False", ")", ")", "\n", "self", ".", "output_blocks_2", ".", "append", "(", "OutputBlock", "(", "in_channels", "=", "int", "(", "channels", "[", "index", "+", "1", "]", "//", "channel_factor", ")", ",", "\n", "out_channels", "=", "self", ".", "out_channels", ",", "\n", "style_dimension", "=", "self", ".", "latent_dimensions", ",", "upsampling", "=", "True", ",", "\n", "modulation_mapping", "=", "False", ")", ")", "\n", "# Init noises as a nn.Module to store each tensor", "\n", "", "self", ".", "noises", "=", "nn", ".", "Module", "(", ")", "\n", "self", ".", "noises", ".", "register_buffer", "(", "'noise_start'", ",", "\n", "torch", ".", "randn", "(", "1", ",", "1", ",", "self", ".", "starting_resolution", "[", "0", "]", ",", "self", ".", "starting_resolution", "[", "1", "]", ")", ")", "\n", "for", "index", "in", "range", "(", "len", "(", "channels", ")", "-", "1", ")", ":", "\n", "            ", "self", ".", "noises", ".", "register_buffer", "(", "'noise_{}'", ".", "format", "(", "(", "2", "*", "index", ")", ")", ",", "\n", "torch", ".", "randn", "(", "1", ",", "1", ",", "2", "**", "(", "index", "+", "3", ")", ",", "2", "**", "(", "index", "+", "3", ")", ")", ")", "\n", "self", ".", "noises", ".", "register_buffer", "(", "'noise_{}'", ".", "format", "(", "(", "2", "*", "index", ")", "+", "1", ")", ",", "\n", "torch", ".", "randn", "(", "1", ",", "1", ",", "2", "**", "(", "index", "+", "3", ")", ",", "2", "**", "(", "index", "+", "3", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.Generator.get_parameters": [[97, 113], ["multi_stylegan_generator.Generator.constant_input_1.parameters", "multi_stylegan_generator.Generator.starting_convolution_1.parameters", "multi_stylegan_generator.Generator.starting_output_block_1.parameters", "multi_stylegan_generator.Generator.main_convolutions_1.parameters", "multi_stylegan_generator.Generator.output_blocks_1.parameters", "multi_stylegan_generator.Generator.constant_input_2.parameters", "multi_stylegan_generator.Generator.starting_convolution_2.parameters", "multi_stylegan_generator.Generator.starting_output_block_2.parameters", "multi_stylegan_generator.Generator.main_convolutions_2.parameters", "multi_stylegan_generator.Generator.output_blocks_2.parameters", "multi_stylegan_generator.Generator.style_mapping.parameters"], "methods", ["None"], ["", "", "def", "get_parameters", "(", "self", ",", "lr_main", ":", "float", "=", "1e-03", ",", "lr_style", ":", "float", "=", "1e-05", ")", "->", "Iterable", ":", "\n", "        ", "\"\"\"\n        Method returns all parameters of the model with different learning rates\n        :return: (Iterable) Iterable object including the main parameters of the generator network\n        \"\"\"", "\n", "return", "[", "{", "'params'", ":", "self", ".", "constant_input_1", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr_main", "}", ",", "\n", "{", "'params'", ":", "self", ".", "starting_convolution_1", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr_main", "}", ",", "\n", "{", "'params'", ":", "self", ".", "starting_output_block_1", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr_main", "}", ",", "\n", "{", "'params'", ":", "self", ".", "main_convolutions_1", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr_main", "}", ",", "\n", "{", "'params'", ":", "self", ".", "output_blocks_1", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr_main", "}", ",", "\n", "{", "'params'", ":", "self", ".", "constant_input_2", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr_main", "}", ",", "\n", "{", "'params'", ":", "self", ".", "starting_convolution_2", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr_main", "}", ",", "\n", "{", "'params'", ":", "self", ".", "starting_output_block_2", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr_main", "}", ",", "\n", "{", "'params'", ":", "self", ".", "main_convolutions_2", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr_main", "}", ",", "\n", "{", "'params'", ":", "self", ".", "output_blocks_2", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr_main", "}", ",", "\n", "{", "'params'", ":", "self", ".", "style_mapping", ".", "parameters", "(", ")", ",", "'lr'", ":", "lr_style", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.Generator.forward": [[114, 206], ["multi_stylegan_generator.Generator.constant_input_1", "multi_stylegan_generator.Generator.constant_input_2", "multi_stylegan_generator.Generator.starting_convolution_1", "multi_stylegan_generator.Generator.starting_convolution_2", "multi_stylegan_generator.Generator.starting_output_block_1", "multi_stylegan_generator.Generator.starting_output_block_2", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "isinstance", "isinstance", "multi_stylegan_generator.Generator.style_mapping", "getattr", "styles[].unsqueeze().repeat", "styles[].unsqueeze().repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "multi_stylegan_generator.Generator.unsqueeze().repeat", "input.unsqueeze().repeat", "len", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "math.sqrt", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "multi_stylegan_generator.Generator.style_mapping", "len", "getattr", "numpy.random.randint", "input.repeat", "range", "range", "styles[].unsqueeze", "styles[].unsqueeze", "multi_stylegan_generator.Generator.unsqueeze", "len", "input.unsqueeze", "len", "len", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "\n", "input", ":", "Union", "[", "List", "[", "torch", ".", "Tensor", "]", ",", "torch", ".", "Tensor", "]", ",", "\n", "return_main_style_vectors", ":", "bool", "=", "False", ",", "\n", "noise", ":", "Optional", "[", "List", "[", "torch", ".", "Tensor", "]", "]", "=", "None", ",", "\n", "randomize_noise", ":", "bool", "=", "True", ",", "\n", "inject_index", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "input_is_latent", ":", "bool", "=", "False", ",", "\n", "return_path_length_grads", ":", "bool", "=", "False", ")", "->", "Union", "[", "\n", "torch", ".", "Tensor", ",", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param input: (List[torch.Tensor], torch.Tensor) Input noise tensor\n        :param return_main_style_vectors: (bool) If true latent style vectors will be returned\n        :param noise: (Optional[List[torch.Tensor]]) List of noise vectors for noisy bias\n        :param randomize_noise: (bool) If true random noisy bias will be produced, otherwise fixed noise is used\n        :param inject_index: (Optional[int]) Index to inject two style tensors to styled convolutions\n        :param input_is_latent: (bool) If input is in latent space set to true\n        :return: (torch.Tensor, Tuple[torch.Tensor, torch.Tensor]) Generated image and optimal latent style vectors\n        \"\"\"", "\n", "# Make style vectors if not latent input", "\n", "if", "not", "input_is_latent", ":", "\n", "            ", "if", "isinstance", "(", "input", ",", "list", ")", ":", "\n", "                ", "styles", "=", "[", "self", ".", "style_mapping", "(", "input", "[", "index", "]", ")", "for", "index", "in", "range", "(", "len", "(", "input", ")", ")", "]", "\n", "", "else", ":", "\n", "                ", "styles", "=", "self", ".", "style_mapping", "(", "input", ")", "\n", "# Init or generate noise", "\n", "", "", "if", "noise", "is", "None", ":", "\n", "            ", "if", "randomize_noise", ":", "\n", "                ", "noise_start", "=", "None", "\n", "noise", "=", "[", "None", "]", "*", "len", "(", "self", ".", "main_convolutions_1", ")", "\n", "", "else", ":", "\n", "                ", "noise_start", "=", "getattr", "(", "self", ".", "noises", ",", "'noise_start'", ")", "\n", "noise", "=", "[", "getattr", "(", "self", ".", "noises", ",", "'noise_{}'", ".", "format", "(", "index", ")", ")", "for", "index", "in", "\n", "range", "(", "len", "(", "self", ".", "main_convolutions_1", ")", ")", "]", "\n", "", "", "else", ":", "\n", "            ", "noise_start", "=", "noise", "[", "0", "]", "\n", "noise", "=", "noise", "[", "1", ":", "]", "\n", "# Construct style tensors", "\n", "", "if", "not", "input_is_latent", ":", "\n", "            ", "if", "isinstance", "(", "styles", ",", "list", ")", ":", "\n", "                ", "if", "inject_index", "is", "None", ":", "\n", "                    ", "inject_index", "=", "np", ".", "random", ".", "randint", "(", "1", ",", "len", "(", "self", ".", "main_convolutions_1", ")", "+", "2", "-", "1", ")", "\n", "", "latent_1", "=", "styles", "[", "0", "]", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "inject_index", ",", "1", ")", "\n", "latent_2", "=", "styles", "[", "1", "]", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "len", "(", "self", ".", "main_convolutions_1", ")", "+", "2", "-", "inject_index", ",", "1", ")", "\n", "latent", "=", "torch", ".", "cat", "(", "(", "latent_1", ",", "latent_2", ")", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "latent", "=", "styles", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "len", "(", "self", ".", "main_convolutions_1", ")", "+", "2", ",", "1", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "input", ".", "ndim", "<", "3", ":", "\n", "# Add third dim and repeat to match styled convolutions", "\n", "                ", "latent", "=", "input", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "len", "(", "self", ".", "main_convolutions_1", ")", "+", "2", ",", "1", ")", "\n", "", "elif", "input", ".", "shape", "[", "1", "]", "!=", "len", "(", "self", ".", "main_convolutions_1", ")", "+", "2", ":", "\n", "# Check that dim 1 has the shape of one", "\n", "                ", "assert", "input", ".", "shape", "[", "1", "]", "==", "0", "\n", "# Repeat input latent vector to match styled convolutions", "\n", "latent", "=", "input", ".", "repeat", "(", "1", ",", "len", "(", "self", ".", "main_convolutions_1", ")", "+", "2", ",", "1", ")", "\n", "", "else", ":", "\n", "# Set input as latent vector", "\n", "                ", "latent", "=", "input", "\n", "# Perform starting operations", "\n", "", "", "output_1", "=", "self", ".", "constant_input_1", "(", "latent", ")", "\n", "output_2", "=", "self", ".", "constant_input_2", "(", "latent", ")", "\n", "output_1", ",", "style", "=", "self", ".", "starting_convolution_1", "(", "output_1", ",", "latent", "[", ":", ",", "0", "]", ",", "noise", "=", "noise_start", ")", "\n", "output_2", "=", "self", ".", "starting_convolution_2", "(", "output_2", ",", "style", ",", "noise", "=", "noise_start", ")", "\n", "skip_1", ",", "style", "=", "self", ".", "starting_output_block_1", "(", "output_1", ",", "latent", "[", ":", ",", "1", "]", ")", "\n", "skip_2", "=", "self", ".", "starting_output_block_2", "(", "output_2", ",", "style", ")", "\n", "# Perform main path", "\n", "for", "index", "in", "range", "(", "len", "(", "self", ".", "main_convolutions_1", ")", "//", "2", ")", ":", "\n", "            ", "output_1", ",", "style", "=", "self", ".", "main_convolutions_1", "[", "index", "*", "2", "]", "(", "output_1", ",", "latent", "[", ":", ",", "index", "*", "2", "+", "1", "]", ",", "\n", "noise", "=", "noise", "[", "index", "*", "2", "]", ")", "\n", "output_2", "=", "self", ".", "main_convolutions_2", "[", "index", "*", "2", "]", "(", "output_2", ",", "style", ",", "noise", "=", "noise", "[", "index", "*", "2", "]", ")", "\n", "output_1", ",", "style", "=", "self", ".", "main_convolutions_1", "[", "index", "*", "2", "+", "1", "]", "(", "output_1", ",", "latent", "[", ":", ",", "index", "*", "2", "+", "2", "]", ",", "\n", "noise", "=", "noise", "[", "index", "*", "2", "+", "1", "]", ")", "\n", "output_2", "=", "self", ".", "main_convolutions_2", "[", "index", "*", "2", "+", "1", "]", "(", "output_2", ",", "style", ",", "noise", "=", "noise", "[", "index", "*", "2", "+", "1", "]", ")", "\n", "skip_1", ",", "style", "=", "self", ".", "output_blocks_1", "[", "index", "]", "(", "output_1", ",", "latent", "[", ":", ",", "index", "*", "2", "+", "3", "]", ",", "skip", "=", "skip_1", ")", "\n", "skip_2", "=", "self", ".", "output_blocks_2", "[", "index", "]", "(", "output_1", ",", "style", ",", "skip", "=", "skip_2", ")", "\n", "# Get final image", "\n", "", "image", "=", "torch", ".", "stack", "(", "[", "skip_1", ",", "skip_2", "]", ",", "dim", "=", "1", ")", "\n", "# Return path length grads if utilized", "\n", "if", "return_path_length_grads", ":", "\n", "# Make noise tensor", "\n", "            ", "noise", "=", "torch", ".", "randn", "(", "image", ".", "shape", ",", "device", "=", "image", ".", "device", ",", "dtype", "=", "torch", ".", "float32", ",", "requires_grad", "=", "True", ")", "/", "math", ".", "sqrt", "(", "image", ".", "shape", "[", "2", "]", "*", "image", ".", "shape", "[", "3", "]", "*", "image", ".", "shape", "[", "4", "]", ")", "\n", "# Calc gradient", "\n", "grad", "=", "autograd", ".", "grad", "(", "outputs", "=", "(", "image", "*", "noise", ")", ".", "sum", "(", ")", ",", "inputs", "=", "latent", ",", "create_graph", "=", "True", ",", "\n", "retain_graph", "=", "True", ",", "only_inputs", "=", "True", ")", "[", "0", "]", "\n", "return", "grad", "\n", "# Return also the latent vector if needed", "\n", "", "if", "return_main_style_vectors", ":", "\n", "            ", "return", "image", ",", "latent", "\n", "", "else", ":", "\n", "            ", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.StyleMapping.__init__": [[213, 227], ["torch.Module.__init__", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "equalized_layer.PixelwiseNormalization", "layers.extend", "equalized_layer.EqualizedLinear", "op_static.FusedLeakyReLU"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ",", "latent_dimensions", ":", "int", "=", "512", ",", "depth", ":", "int", "=", "8", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param latent_dimensions: (int) Dimension of latent tensor\n        :param depth: (int) Number if linear layers used in mapping path\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "StyleMapping", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Init layers", "\n", "layers", "=", "[", "equalized_layer", ".", "PixelwiseNormalization", "(", ")", "]", "\n", "for", "_", "in", "range", "(", "depth", ")", ":", "\n", "            ", "layers", ".", "extend", "(", "[", "equalized_layer", ".", "EqualizedLinear", "(", "latent_dimensions", ",", "latent_dimensions", ",", "bias", "=", "False", ")", ",", "\n", "FusedLeakyReLU", "(", "latent_dimensions", ")", "]", ")", "\n", "", "self", ".", "layers", "=", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.StyleMapping.forward": [[228, 236], ["multi_stylegan_generator.StyleMapping.layers"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "noise", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param noise: (torch.Tensor) Noise input tensor\n        :return: (torch.Tensor) Mapped latent vector\n        \"\"\"", "\n", "output", "=", "self", ".", "layers", "(", "noise", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.ConstantInput.__init__": [[243, 253], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ",", "channel", ":", "int", ",", "size", ":", "Tuple", "[", "int", ",", "int", "]", "=", "(", "4", ",", "4", ")", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param channel: (int) Number of channels utilized in constant variable\n        :param size: (Tuple[int, int]) Width and height of the constant variable\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "ConstantInput", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Init constant variable", "\n", "self", ".", "input", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ",", "channel", ",", "size", "[", "0", "]", ",", "size", "[", "1", "]", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.ConstantInput.forward": [[254, 265], ["multi_stylegan_generator.ConstantInput.input.repeat_interleave"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param input: (torch.Tensor) Input tensor of latent path only to get batch size dimension\n        :return: (torch.Tensor) Constant tensor\n        \"\"\"", "\n", "# Get batch size", "\n", "batch_size", "=", "input", ".", "shape", "[", "0", "]", "\n", "# Repeat input tensor to match batch size", "\n", "output", "=", "self", ".", "input", ".", "repeat_interleave", "(", "dim", "=", "0", ",", "repeats", "=", "batch_size", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.NoiseInjection.__init__": [[272, 280], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "NoiseInjection", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Init bias weights", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.NoiseInjection.forward": [[281, 293], ["torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ",", "noise", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param input: (torch.Tensor) Input tensor\n        :param noise: (Optional[torch.Tensor]) Noise tensor\n        :return: (torch.Tensor) Output tensor\n        \"\"\"", "\n", "if", "noise", "is", "None", ":", "\n", "            ", "noise", "=", "torch", ".", "randn", "(", "input", ".", "shape", "[", "0", "]", ",", "1", ",", "input", ".", "shape", "[", "2", "]", ",", "input", ".", "shape", "[", "3", "]", ",", "device", "=", "input", ".", "device", ",", "\n", "dtype", "=", "torch", ".", "float32", ")", "\n", "\n", "", "return", "input", "+", "self", ".", "weight", "*", "noise", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.ModulatedConv2d.__init__": [[301, 347], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "isinstance", "multi_stylegan_generator.Blur", "math.sqrt", "math.sqrt", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "equalized_layer.EqualizedLinear", "multi_stylegan_generator.ModulatedConv2d.modulation_mapping.bias.data.fill_"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ":", "int", ",", "out_channels", ":", "int", ",", "style_dimension", ":", "int", ",", "\n", "kernel_size", ":", "Union", "[", "int", ",", "Tuple", "[", "int", ",", "int", "]", "]", "=", "(", "3", ",", "3", ")", ",", "\n", "demodulate", ":", "bool", "=", "True", ",", "upsampling", ":", "bool", "=", "True", ",", "\n", "blur_kernel", ":", "List", "[", "int", "]", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "modulation_mapping", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param in_channels: (int) Number of input channels to be utilized\n        :param out_channels: (int) Number of output channels to be utilized\n        :param style_dimension: (int) Number of style dimensions\n        :param kernel_size: (Union[int, Tuple[int, int]]) Kernel size of the convolution filter\n        :param demodulate: (bool) True if weights should be demodulated\n        :param upsampling: (bool) True if output should be downscaled\n        :param blur_kernel: (List[int]) List of weights for the blur kernel to be used\n        :param modulation_mapping: (bool) If true modulation mapping is utilized\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "ModulatedConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Save parameters", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "demodulate", "=", "demodulate", "\n", "self", ".", "upsampling", "=", "upsampling", "\n", "self", ".", "kernel_size", "=", "kernel_size", "if", "isinstance", "(", "kernel_size", ",", "tuple", ")", "else", "(", "kernel_size", ",", "kernel_size", ")", "\n", "# Init blur upsampling", "\n", "self", ".", "blur", "=", "Blur", "(", "kernel", "=", "blur_kernel", ",", "sampling_factor", "=", "2", ",", "sampling_factor_padding", "=", "2", ",", "\n", "kernel_size", "=", "kernel_size", "[", "0", "]", ")", "if", "upsampling", "else", "None", "\n", "# If upsampling is utilized perform no parring in convolution if not perform same padding in convolution", "\n", "if", "upsampling", ":", "\n", "            ", "self", ".", "padding", "=", "(", "0", ",", "0", ")", "\n", "self", ".", "stride", "=", "(", "2", ",", "2", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "padding", "=", "(", "self", ".", "kernel_size", "[", "0", "]", "//", "2", ",", "self", ".", "kernel_size", "[", "1", "]", "//", "2", ")", "\n", "self", ".", "stride", "=", "(", "1", ",", "1", ")", "\n", "# Init scaling factor", "\n", "", "self", ".", "scale", "=", "math", ".", "sqrt", "(", "2", ")", "/", "math", ".", "sqrt", "(", "in_channels", "*", "self", ".", "kernel_size", "[", "0", "]", "*", "self", ".", "kernel_size", "[", "1", "]", ")", "\n", "# Init convolution weights", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "randn", "(", "1", ",", "out_channels", ",", "in_channels", ",", "self", ".", "kernel_size", "[", "0", "]", ",", "self", ".", "kernel_size", "[", "1", "]", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "\n", "requires_grad", "=", "True", ")", "\n", "# Init linear layer for modulation", "\n", "self", ".", "modulation_mapping", "=", "equalized_layer", ".", "EqualizedLinear", "(", "in_channels", "=", "style_dimension", ",", "\n", "out_channels", "=", "in_channels", ",", "\n", "bias", "=", "True", ")", "if", "modulation_mapping", "else", "None", "\n", "# Reset bias of linear layer to ones", "\n", "if", "modulation_mapping", ":", "\n", "            ", "self", ".", "modulation_mapping", ".", "bias", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.ModulatedConv2d.__repr__": [[348, 364], ["None"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        Method to return info about the object\n        :return: (str) String including information about module\n        \"\"\"", "\n", "return", "(", "'{}({}, {}, kernel_size=({}, {}), stride=({}, {}), padding=({}, {}), upsampling={})'", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "\n", "self", ".", "in_channels", ",", "\n", "self", ".", "out_channels", ",", "\n", "self", ".", "kernel_size", "[", "0", "]", ",", "\n", "self", ".", "kernel_size", "[", "1", "]", ",", "\n", "self", ".", "stride", "[", "0", "]", ",", "\n", "self", ".", "stride", "[", "1", "]", ",", "\n", "self", ".", "padding", "[", "0", "]", ",", "\n", "self", ".", "padding", "[", "1", "]", ",", "\n", "self", ".", "upsampling", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.ModulatedConv2d.forward": [[365, 415], ["input.view.view.view", "multi_stylegan_generator.ModulatedConv2d.modulation_mapping().view", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "torch.rsqrt", "weight.view.view.view", "weight.view.view.transpose().reshape", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "output.view.view.view", "multi_stylegan_generator.ModulatedConv2d.blur", "weight.view.view.view", "torch.conv2d", "torch.conv2d", "torch.conv2d", "output.view.view.view", "torch.rsqrt.view", "torch.rsqrt.view", "torch.rsqrt.view", "multi_stylegan_generator.ModulatedConv2d.modulation_mapping", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "weight.view.view.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ",", "style", ":", "torch", ".", "Tensor", ")", "->", "Union", "[", "\n", "torch", ".", "Tensor", ",", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param input: (torch.Tensor) Input tensor\n        :param style: (torch.Tensor) Style tensor\n        :return: (torch.Tensor) Output tensor and if modulation mapping is utilized also modulated style is returned\n        \"\"\"", "\n", "# Save shape of input", "\n", "batch_size", ",", "features", ",", "height", ",", "width", "=", "input", ".", "shape", "\n", "# Check input shape", "\n", "assert", "features", "==", "self", ".", "in_channels", ",", "'Expect input feature shape of {} but get {}.'", ".", "format", "(", "self", ".", "in_channels", ",", "features", ")", "\n", "# Get modulated style from linear layer", "\n", "if", "self", ".", "modulation_mapping", "is", "not", "None", ":", "\n", "            ", "modulated_style", "=", "self", ".", "modulation_mapping", "(", "style", ")", ".", "view", "(", "batch_size", ",", "1", ",", "self", ".", "in_channels", ",", "1", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "modulated_style", "=", "style", "\n", "# Scale weights of convolution", "\n", "", "weight", "=", "self", ".", "scale", "*", "self", ".", "weight", "*", "modulated_style", "\n", "# Demodulate weights if utilized", "\n", "if", "self", ".", "demodulate", ":", "\n", "            ", "demodulation_factor", "=", "torch", ".", "rsqrt", "(", "torch", ".", "sum", "(", "weight", "**", "2", ",", "dim", "=", "[", "2", ",", "3", ",", "4", "]", ")", "+", "1e-08", ")", "\n", "weight", "=", "weight", "*", "demodulation_factor", ".", "view", "(", "batch_size", ",", "self", ".", "out_channels", ",", "1", ",", "1", ",", "1", ")", "\n", "# Reshape input", "\n", "", "input", "=", "input", ".", "view", "(", "1", ",", "batch_size", "*", "features", ",", "height", ",", "width", ")", "\n", "if", "self", ".", "upsampling", ":", "\n", "# Reshape weights to perform transposed convolution", "\n", "            ", "weight", "=", "weight", ".", "view", "(", "batch_size", ",", "self", ".", "out_channels", ",", "self", ".", "in_channels", ",", "self", ".", "kernel_size", "[", "0", "]", ",", "\n", "self", ".", "kernel_size", "[", "1", "]", ")", "\n", "weight", "=", "weight", ".", "transpose", "(", "1", ",", "2", ")", ".", "reshape", "(", "batch_size", "*", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "\n", "self", ".", "kernel_size", "[", "0", "]", ",", "self", ".", "kernel_size", "[", "1", "]", ")", "\n", "# Perform transposed convolution", "\n", "output", "=", "F", ".", "conv_transpose2d", "(", "input", "=", "input", ",", "weight", "=", "weight", ",", "padding", "=", "self", ".", "padding", ",", "stride", "=", "self", ".", "stride", ",", "\n", "groups", "=", "batch_size", ")", "\n", "# Reshape output", "\n", "output", "=", "output", ".", "view", "(", "batch_size", ",", "self", ".", "out_channels", ",", "output", ".", "shape", "[", "2", "]", ",", "output", ".", "shape", "[", "3", "]", ")", "\n", "# Perform blur operation", "\n", "output", "=", "self", ".", "blur", "(", "output", ")", "\n", "", "else", ":", "\n", "# Reshape weights to perform convolution", "\n", "            ", "weight", "=", "weight", ".", "view", "(", "batch_size", "*", "self", ".", "out_channels", ",", "self", ".", "in_channels", ",", "self", ".", "kernel_size", "[", "0", "]", ",", "\n", "self", ".", "kernel_size", "[", "1", "]", ")", "\n", "# Perform convolution", "\n", "output", "=", "F", ".", "conv2d", "(", "input", "=", "input", ",", "weight", "=", "weight", ",", "padding", "=", "self", ".", "padding", ",", "stride", "=", "self", ".", "stride", ",", "groups", "=", "batch_size", ")", "\n", "# Reshape output", "\n", "output", "=", "output", ".", "view", "(", "batch_size", ",", "self", ".", "out_channels", ",", "output", ".", "shape", "[", "2", "]", ",", "output", ".", "shape", "[", "3", "]", ")", "\n", "", "if", "self", ".", "modulation_mapping", "is", "not", "None", ":", "\n", "            ", "return", "output", ",", "modulated_style", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.StyledConv2d.__init__": [[424, 451], ["torch.Module.__init__", "multi_stylegan_generator.ModulatedConv2d", "multi_stylegan_generator.NoiseInjection", "op_static.FusedLeakyReLU"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ":", "int", ",", "out_channels", ":", "int", ",", "kernel_size", ":", "Union", "[", "int", ",", "Tuple", "[", "int", ",", "int", "]", "]", ",", "\n", "style_dimension", ":", "int", ",", "demodulate", ":", "bool", "=", "True", ",", "upsampling", ":", "bool", "=", "False", ",", "\n", "blur_kernel", ":", "List", "[", "int", "]", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "modulation_mapping", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param in_channels: (int) Number of input channels to be utilized\n        :param out_channels: (int) Number of output channels to be utilized\n        :param style_dimension: (int) Number of style dimensions\n        :param kernel_size: (int, Tuple[int, int]) Kernel size of the convolution filter\n        :param demodulate: (bool) True if weights should be demodulated\n        :param upsampling: (bool) True if output should be downscaled\n        :param blur_kernel: (List[int]) List of weights for the blur kernel to be used\n        :param modulation_mapping: (bool) If true modulation mapping is utilized\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "StyledConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Save parameters", "\n", "self", ".", "modulation_mapping", "=", "modulation_mapping", "\n", "# Init modulated convolution", "\n", "self", ".", "modulated_convolution", "=", "ModulatedConv2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "out_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "style_dimension", "=", "style_dimension", ",", "\n", "demodulate", "=", "demodulate", ",", "upsampling", "=", "upsampling", ",", "\n", "blur_kernel", "=", "blur_kernel", ",", "modulation_mapping", "=", "modulation_mapping", ")", "\n", "# Init noisy bias injection", "\n", "self", ".", "noise_injection", "=", "NoiseInjection", "(", ")", "\n", "# Init activation including bias", "\n", "self", ".", "activation", "=", "FusedLeakyReLU", "(", "out_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.StyledConv2d.forward": [[452, 470], ["multi_stylegan_generator.StyledConv2d.noise_injection", "multi_stylegan_generator.StyledConv2d.activation", "multi_stylegan_generator.StyledConv2d.modulated_convolution", "multi_stylegan_generator.StyledConv2d.modulated_convolution"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ",", "style", ":", "torch", ".", "Tensor", ",", "\n", "noise", ":", "torch", ".", "Tensor", "=", "None", ")", "->", "Union", "[", "torch", ".", "Tensor", ",", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param input: (torch.Tensor) Input tensor\n        :param style: (torch.Tensor) Style tensor\n        :param noise: (torch.Tensor) Noise tensor\n        :return: (torch.Tensor) Output tensor and if modulation mapping is utilized style vector is returned\n        \"\"\"", "\n", "if", "self", ".", "modulation_mapping", ":", "\n", "            ", "output", ",", "style", "=", "self", ".", "modulated_convolution", "(", "input", ",", "style", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "modulated_convolution", "(", "input", ",", "style", ")", "\n", "", "output", "=", "self", ".", "noise_injection", "(", "output", ",", "noise", "=", "noise", ")", "\n", "output", "=", "self", ".", "activation", "(", "output", ")", "\n", "if", "self", ".", "modulation_mapping", ":", "\n", "            ", "return", "output", ",", "style", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.OutputBlock.__init__": [[478, 503], ["torch.Module.__init__", "multi_stylegan_generator.ModulatedConv2d", "torch.Parameter", "torch.Parameter", "torch.Parameter", "multi_stylegan_generator.Upsample", "torch.Identity", "torch.Identity", "torch.Identity", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ":", "int", ",", "style_dimension", ":", "int", ",", "out_channels", ":", "int", "=", "1", ",", "\n", "upsampling", ":", "bool", "=", "False", ",", "blur_kernel", ":", "List", "[", "int", "]", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "\n", "modulation_mapping", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param in_channels: (int) Number of input channels\n        :param style_dimension: (int) Style vector dimension\n        :param out_channels: (int) Number of output channels\n        :param upsampling: (bool) If true 2x upsampling is utilized\n        :param blur_kernel: (List[int]) List of kernel weights\n        :param modulation_mapping: (bool) If true modulation mapping is utilized\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "OutputBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Save parameters", "\n", "self", ".", "modulation_mapping", "=", "modulation_mapping", "\n", "# Init upsampling operation", "\n", "self", ".", "upsampling", "=", "Upsample", "(", "blur_kernel", "=", "blur_kernel", ",", "factor", "=", "2", ")", "if", "upsampling", "else", "nn", ".", "Identity", "(", ")", "\n", "# Init modulated convolution", "\n", "self", ".", "modulated_convolution", "=", "ModulatedConv2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "out_channels", ",", "\n", "style_dimension", "=", "style_dimension", ",", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "\n", "upsampling", "=", "False", ",", "demodulate", "=", "False", ",", "\n", "modulation_mapping", "=", "modulation_mapping", ")", "\n", "# Init bias parameter", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "1", ",", "1", ",", "1", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "requires_grad", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.OutputBlock.forward": [[504, 527], ["multi_stylegan_generator.OutputBlock.modulated_convolution", "multi_stylegan_generator.OutputBlock.modulated_convolution", "multi_stylegan_generator.OutputBlock.upsampling"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ",", "style", ":", "torch", ".", "Tensor", ",", "\n", "skip", ":", "torch", ".", "Tensor", "=", "None", ")", "->", "Union", "[", "torch", ".", "Tensor", ",", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param input: (torch.Tensor) Input tensor\n        :param style: (torch.Tensor) Output tensor\n        :param skip: (torch.Tensor) Tensor for skip connection\n        :return: (torch.Tensor) Output tensor\n        \"\"\"", "\n", "# Perform convolution", "\n", "if", "self", ".", "modulation_mapping", ":", "\n", "            ", "output", ",", "style", "=", "self", ".", "modulated_convolution", "(", "input", ",", "style", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "modulated_convolution", "(", "input", ",", "style", ")", "\n", "# Add bias", "\n", "", "output", "=", "output", "+", "self", ".", "bias", "\n", "# Map skip tensor", "\n", "if", "skip", "is", "not", "None", ":", "\n", "            ", "skip", "=", "self", ".", "upsampling", "(", "skip", ")", "\n", "output", "=", "output", "+", "skip", "\n", "", "if", "self", ".", "modulation_mapping", ":", "\n", "            ", "return", "output", ",", "style", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.Upsample.__init__": [[534, 552], ["torch.Module.__init__", "multi_stylegan_generator.Upsample.make_kernel", "multi_stylegan_generator.Upsample.register_buffer"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.Blur.make_kernel"], ["def", "__init__", "(", "self", ",", "blur_kernel", ":", "List", "[", "int", "]", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "factor", ":", "int", "=", "2", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param blur_kernel: (List[int]) List of weights for the blur kernel to be used\n        :param factor: (int) Upscale factor\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "Upsample", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Save parameter", "\n", "self", ".", "factor", "=", "factor", "\n", "# Make kernel", "\n", "kernel", "=", "self", ".", "make_kernel", "(", "kernel", "=", "blur_kernel", ")", "\n", "# Save kernel", "\n", "self", ".", "register_buffer", "(", "'kernel'", ",", "kernel", ")", "\n", "# Calc padding factor", "\n", "padding_factor", "=", "kernel", ".", "shape", "[", "0", "]", "-", "factor", "\n", "# Calc padding", "\n", "self", ".", "padding", "=", "(", "(", "(", "padding_factor", "+", "1", ")", "//", "2", ")", "+", "factor", "-", "1", ",", "padding_factor", "//", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.Upsample.make_kernel": [[553, 567], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.sum", "torch.tensor.sum", "torch.tensor.sum", "torch.tensor.float", "torch.tensor.float", "torch.tensor.float"], "methods", ["None"], ["", "def", "make_kernel", "(", "self", ",", "kernel", ":", "List", "[", "int", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Method generates a kernel matrix for a given input list of weights\n        :param kernel: (List[int]) List of weights for the blur kernel to be used\n        :return: (torch.Tensor) Kernel tensor\n        \"\"\"", "\n", "# Kernel into list", "\n", "kernel", "=", "torch", ".", "tensor", "(", "kernel", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "# Change dim of tensor if list list is 1d", "\n", "if", "kernel", ".", "ndim", "==", "1", ":", "\n", "            ", "kernel", "=", "kernel", "[", "None", ",", ":", "]", "*", "kernel", "[", ":", ",", "None", "]", "\n", "# Normalize kernel", "\n", "", "kernel", "/=", "kernel", ".", "sum", "(", ")", "\n", "return", "kernel", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.Upsample.forward": [[568, 576], ["op_static.upfirdn2d"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.upfirdn2d.upfirdn2d"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param input: (torch.Tensor) Input tensor\n        :return: (torch.Tensor) Upscaled output tensor\n        \"\"\"", "\n", "output", "=", "upfirdn2d", "(", "input", "=", "input", ",", "kernel", "=", "self", ".", "kernel", ",", "up", "=", "self", ".", "factor", ",", "pad", "=", "self", ".", "padding", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.Blur.__init__": [[583, 605], ["torch.Module.__init__", "multi_stylegan_generator.Blur.calc_padding", "multi_stylegan_generator.Blur.make_kernel", "multi_stylegan_generator.Blur.register_buffer"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.Blur.calc_padding", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.Blur.make_kernel"], ["def", "__init__", "(", "self", ",", "kernel", ":", "List", "[", "int", "]", ",", "sampling_factor", ":", "int", "=", "1", ",", "\n", "sampling_factor_padding", ":", "int", "=", "2", ",", "\n", "kernel_size", ":", "int", "=", "3", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param kernel: (List[int]) List of kernel weights\n        :param sampling_factor: (int) Scaling factor\n        :param sampling_factor_padding: (int) Scaling factor for padding\n        :param kernel_size: (int) Blur kernel size\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "Blur", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Save padding factor", "\n", "self", ".", "padding", "=", "self", ".", "calc_padding", "(", "kernel", ",", "sampling_factor_padding", "=", "sampling_factor_padding", ",", "\n", "kernel_size", "=", "kernel_size", ")", "\n", "# Init kernel", "\n", "kernel", "=", "self", ".", "make_kernel", "(", "kernel", ")", "\n", "# Rescale kernel if sampling factor is bigger than one", "\n", "if", "sampling_factor", ">", "1", ":", "\n", "            ", "kernel", "=", "kernel", "*", "(", "sampling_factor", "**", "2", ")", "\n", "# Save kernel", "\n", "", "self", ".", "register_buffer", "(", "'kernel'", ",", "kernel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.Blur.calc_padding": [[606, 618], ["len"], "methods", ["None"], ["", "def", "calc_padding", "(", "self", ",", "kernel", ":", "List", "[", "int", "]", ",", "sampling_factor_padding", ":", "int", "=", "2", ",", "\n", "kernel_size", ":", "int", "=", "3", ")", "->", "Tuple", "[", "int", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Method estimates the padding factor\n        :param kernel: (List[int]) List of kernel weights\n        :param sampling_factor: (int) Factor used in scaling\n        :param kernel_size: (int) Kernel size of convolution afterwards\n        :return: (Tuple[int, int]) Padding in x and y direction\n        \"\"\"", "\n", "padding_factor", "=", "(", "len", "(", "kernel", ")", "-", "sampling_factor_padding", ")", "+", "(", "kernel_size", "-", "1", ")", "\n", "padding", "=", "(", "(", "padding_factor", "+", "1", ")", "//", "2", ",", "padding_factor", "//", "2", ")", "\n", "return", "padding", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.Blur.make_kernel": [[619, 633], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.sum", "torch.tensor.sum", "torch.tensor.sum"], "methods", ["None"], ["", "def", "make_kernel", "(", "self", ",", "kernel", ":", "List", "[", "int", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Method generates a kernel matrix for a given input list of weights\n        :param kernel: (List[int]) List of weights for the blur kernel to be used\n        :return: (torch.Tensor) Kernel tensor\n        \"\"\"", "\n", "# Kernel into list", "\n", "kernel", "=", "torch", ".", "tensor", "(", "kernel", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "# Change dim of tensor if list list is 1d", "\n", "if", "kernel", ".", "ndim", "==", "1", ":", "\n", "            ", "kernel", "=", "kernel", "[", "None", ",", ":", "]", "*", "kernel", "[", ":", ",", "None", "]", "\n", "# Normalize kernel", "\n", "", "kernel", "=", "kernel", "/", "kernel", ".", "sum", "(", ")", "\n", "return", "kernel", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.multi_stylegan_generator.Blur.forward": [[634, 642], ["op_static.upfirdn2d"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.upfirdn2d.upfirdn2d"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param input: (torch.Tensor) Input tensor\n        :return: (torch.Tensor) Output tensor\n        \"\"\"", "\n", "output", "=", "upfirdn2d", "(", "input", ",", "self", ".", "kernel", ",", "pad", "=", "self", ".", "padding", ")", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.adaptive_discriminator_augmentation.AdaptiveDiscriminatorAugmentation.__init__": [[18, 42], ["torch.Module.__init__", "adaptive_discriminator_augmentation.AugmentationPipeline"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ",", "discriminator", ":", "Union", "[", "nn", ".", "Module", ",", "nn", ".", "DataParallel", "]", ",", "r_target", ":", "float", "=", "0.6", ",", "\n", "p_step", ":", "float", "=", "5e-03", ",", "r_update", ":", "int", "=", "8", ",", "p_max", ":", "float", "=", "0.8", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param discriminator: (Union[nn.Module, nn.DataParallel]) Discriminator network\n        :param r_target: (float) Target value for r\n        :param p_step: (float) Step size of p\n        :param r_update: (int) Update frequency of r\n        :param p_max: (float) Global max value of p\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "AdaptiveDiscriminatorAugmentation", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Save parameters", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "r_target", "=", "r_target", "\n", "self", ".", "p_step", "=", "p_step", "\n", "self", ".", "r_update", "=", "r_update", "\n", "self", ".", "p_max", "=", "p_max", "\n", "# Init augmentation variables", "\n", "self", ".", "r", "=", "[", "]", "\n", "self", ".", "p", "=", "0.05", "\n", "self", ".", "r_history", "=", "[", "]", "\n", "# Init augmentation pipeline", "\n", "self", ".", "augmentation_pipeline", "=", "AugmentationPipeline", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.adaptive_discriminator_augmentation.AdaptiveDiscriminatorAugmentation.__calc_r": [[43, 53], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "torch.sign", "prediction_pixel_wise.mean"], "methods", ["None"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "__calc_r", "(", "self", ",", "prediction_scalar", ":", "torch", ".", "Tensor", ",", "prediction_pixel_wise", ":", "torch", ".", "Tensor", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        Method computes the overfitting heuristic r.\n        :param prediction_scalar: (torch.Tensor) Scalar prediction [batch size, 1]\n        :param prediction_pixel_wise: (torch.Tensor) Pixel-wise prediction [batch size, 1, height, width]\n        :return: (float) Value of the overfitting heuristic r\n        \"\"\"", "\n", "return", "(", "0.5", "*", "torch", ".", "mean", "(", "torch", ".", "sign", "(", "prediction_scalar", ")", ")", "\n", "+", "0.5", "*", "torch", ".", "mean", "(", "torch", ".", "sign", "(", "prediction_pixel_wise", ".", "mean", "(", "dim", "=", "(", "-", "1", ",", "-", "2", ")", ")", ")", ")", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.adaptive_discriminator_augmentation.AdaptiveDiscriminatorAugmentation.forward": [[54, 97], ["images.view.view.flatten", "adaptive_discriminator_augmentation.AdaptiveDiscriminatorAugmentation.augmentation_pipeline", "images.view.view.view", "adaptive_discriminator_augmentation.AdaptiveDiscriminatorAugmentation.discriminator", "adaptive_discriminator_augmentation.AdaptiveDiscriminatorAugmentation.discriminator", "adaptive_discriminator_augmentation.AdaptiveDiscriminatorAugmentation.r.append", "len", "numpy.mean", "adaptive_discriminator_augmentation.AdaptiveDiscriminatorAugmentation.r_history.append", "adaptive_discriminator_augmentation.AdaptiveDiscriminatorAugmentation.__calc_r", "prediction_scalar.detach", "prediction_pixel_wise.detach"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.adaptive_discriminator_augmentation.AdaptiveDiscriminatorAugmentation.__calc_r"], ["", "def", "forward", "(", "self", ",", "images", ":", "torch", ".", "Tensor", ",", "is_real", ":", "bool", "=", "False", ",", "\n", "is_cut_mix", ":", "bool", "=", "False", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param images: (torch.Tensor) Mini batch of images (real or fake) [batch size, channels, time steps, height, width]\n        :param is_real: (bool) If true real images are utilized as the input\n        :param is_cut_mix: (bool) If true cut mix is utilized and no augmentation is performed\n        :return: (Tuple[torch.Tensor, torch.Tensor]) Scalar and pixel-wise real/fake prediction of the discriminator\n        \"\"\"", "\n", "# Case if cut mix is utilized", "\n", "if", "is_cut_mix", ":", "\n", "            ", "return", "self", ".", "discriminator", "(", "images", ")", "\n", "# Reshape images to [batch size, channels * time steps, height, width]", "\n", "", "original_shape", "=", "images", ".", "shape", "\n", "images", "=", "images", ".", "flatten", "(", "start_dim", "=", "1", ",", "end_dim", "=", "2", ")", "\n", "# Apply augmentations", "\n", "images", ":", "torch", ".", "Tensor", "=", "self", ".", "augmentation_pipeline", "(", "images", ",", "self", ".", "p", ")", "\n", "# Reshape images again to original shape", "\n", "images", "=", "images", ".", "view", "(", "original_shape", ")", "\n", "# Discriminator prediction", "\n", "prediction_scalar", ",", "prediction_pixel_wise", "=", "self", ".", "discriminator", "(", "images", ")", "\n", "# If fake images are given compute overfitting heuristic", "\n", "if", "not", "is_real", ":", "\n", "            ", "self", ".", "r", ".", "append", "(", "self", ".", "__calc_r", "(", "prediction_scalar", "=", "prediction_scalar", ".", "detach", "(", ")", ",", "\n", "prediction_pixel_wise", "=", "prediction_pixel_wise", ".", "detach", "(", ")", ")", ")", "\n", "# Update p", "\n", "", "if", "len", "(", "self", ".", "r", ")", ">=", "self", ".", "r_update", ":", "\n", "# Calc r over the last epochs", "\n", "            ", "r", "=", "np", ".", "mean", "(", "self", ".", "r", ")", "\n", "# If r above target value increment p else reduce", "\n", "if", "r", ">", "self", ".", "r_target", ":", "\n", "                ", "self", ".", "p", "+=", "self", ".", "p_step", "\n", "", "else", ":", "\n", "                ", "self", ".", "p", "-=", "self", ".", "p_step", "\n", "# Check if p is negative", "\n", "", "self", ".", "p", "=", "self", ".", "p", "if", "self", ".", "p", ">=", "0.", "else", "0.", "\n", "# Check if p is larger than 1", "\n", "self", ".", "p", "=", "self", ".", "p", "if", "self", ".", "p", "<", "self", ".", "p_max", "else", "self", ".", "p_max", "\n", "# Reset r", "\n", "self", ".", "r", "=", "[", "]", "\n", "# Save current r in history", "\n", "self", ".", "r_history", ".", "append", "(", "r", ")", "\n", "", "return", "prediction_scalar", ",", "prediction_pixel_wise", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.adaptive_discriminator_augmentation.AugmentationPipeline.__init__": [[104, 107], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "# Call super constructor", "\n", "        ", "super", "(", "AugmentationPipeline", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.adaptive_discriminator_augmentation.AugmentationPipeline.forward": [[108, 201], ["len", "images[].flip", "len", "random.choice", "angle.to.to.to", "kornia.rotate", "len", "adaptive_discriminator_augmentation.integer_translation", "len", "kornia.apply_affine", "len", "kornia.apply_affine", "len", "kornia.apply_affine", "len", "kornia.apply_affine", "enumerate", "enumerate", "images.to", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "len", "len", "math.sqrt", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "len", "len", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "len", "len", "math.sqrt", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "len", "len", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "len", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "len", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "len", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "numpy.random.uniform", "len", "len", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "numpy.random.uniform", "len", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "len", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "len", "numpy.random.lognormal", "numpy.random.lognormal", "len", "len", "math.log", "math.log"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.adaptive_discriminator_augmentation.integer_translation"], ["", "def", "forward", "(", "self", ",", "images", ":", "torch", ".", "Tensor", ",", "p", ":", "float", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass applies augmentation to mini-batch of given images\n        :param images: (torch.Tensor) Mini-batch images [batch size, channels, height, width]\n        :param p: (float) Probability of augmentation to be applied\n        :return: (torch.Tensor) Augmented images [batch size, channels, height, width]\n        \"\"\"", "\n", "# Perform vertical flip", "\n", "images_flipped", "=", "[", "index", "for", "index", ",", "value", "in", "enumerate", "(", "torch", ".", "rand", "(", "images", ".", "shape", "[", "0", "]", ")", "<=", "p", ")", "if", "value", "==", "True", "]", "\n", "if", "len", "(", "images_flipped", ")", ">", "0", ":", "\n", "            ", "images", "[", "images_flipped", "]", "=", "images", "[", "images_flipped", "]", ".", "flip", "(", "dims", "=", "(", "-", "1", ",", ")", ")", "\n", "# Perform rotation", "\n", "", "images_rotated", "=", "[", "index", "for", "index", ",", "value", "in", "enumerate", "(", "torch", ".", "rand", "(", "images", ".", "shape", "[", "0", "]", ")", "<=", "p", ")", "if", "value", "==", "True", "]", "\n", "if", "len", "(", "images_rotated", ")", ">", "0", ":", "\n", "            ", "angle", "=", "random", ".", "choice", "(", "[", "torch", ".", "tensor", "(", "0.", ")", ",", "torch", ".", "tensor", "(", "-", "90.", ")", ",", "torch", ".", "tensor", "(", "90.", ")", ",", "torch", ".", "tensor", "(", "180.", ")", "]", ")", "\n", "angle", "=", "angle", ".", "to", "(", "images", ".", "to", "(", "images", ".", "device", ")", ")", "\n", "images", "[", "images_rotated", "]", "=", "kaf", ".", "rotate", "(", "images", "[", "images_rotated", "]", ",", "\n", "angle", "=", "angle", ")", "\n", "# Perform integer translation", "\n", "", "images_translated", "=", "[", "index", "for", "index", ",", "value", "in", "enumerate", "(", "torch", ".", "rand", "(", "images", ".", "shape", "[", "0", "]", ")", "<=", "p", ")", "if", "value", "==", "True", "]", "\n", "if", "len", "(", "images_translated", ")", ">", "0", ":", "\n", "            ", "images", "[", "images_translated", "]", "=", "integer_translation", "(", "images", "[", "images_translated", "]", ")", "\n", "# Perform isotropic scaling", "\n", "", "images_scaling", "=", "[", "index", "for", "index", ",", "value", "in", "enumerate", "(", "torch", ".", "rand", "(", "images", ".", "shape", "[", "0", "]", ")", "<=", "p", ")", "if", "value", "==", "True", "]", "\n", "if", "len", "(", "images_scaling", ")", ">", "0", ":", "\n", "            ", "images", "[", "images_scaling", "]", "=", "kaf", ".", "apply_affine", "(", "\n", "images", "[", "images_scaling", "]", ",", "\n", "params", "=", "{", "\"angle\"", ":", "torch", ".", "zeros", "(", "len", "(", "images_scaling", ")", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"translations\"", ":", "torch", ".", "zeros", "(", "len", "(", "images_scaling", ")", ",", "2", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"center\"", ":", "torch", ".", "ones", "(", "len", "(", "images_scaling", ")", ",", "2", ",", "device", "=", "images", ".", "device", ")", "\n", "*", "0.5", "*", "torch", ".", "tensor", "(", "images", ".", "shape", "[", "2", ":", "]", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"scale\"", ":", "torch", ".", "ones", "(", "len", "(", "images_scaling", ")", ",", "2", ",", "device", "=", "images", ".", "device", ")", "*", "\n", "torch", ".", "from_numpy", "(", "\n", "np", ".", "random", ".", "lognormal", "(", "mean", "=", "0", ",", "sigma", "=", "(", "0.2", "*", "math", ".", "log", "(", "2", ")", ")", "**", "2", ",", "\n", "size", "=", "(", "len", "(", "images_scaling", ")", ",", "1", ")", ")", ")", ".", "float", "(", ")", ".", "to", "(", "images", ".", "device", ")", ",", "\n", "\"sx\"", ":", "torch", ".", "zeros", "(", "len", "(", "images_scaling", ")", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"sy\"", ":", "torch", ".", "zeros", "(", "len", "(", "images_scaling", ")", ",", "device", "=", "images", ".", "device", ")", "}", ",", "\n", "flags", "=", "{", "\"resample\"", ":", "torch", ".", "tensor", "(", "1", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"padding_mode\"", ":", "torch", ".", "tensor", "(", "2", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"align_corners\"", ":", "torch", ".", "tensor", "(", "True", ",", "device", "=", "images", ".", "device", ")", "}", ")", "\n", "# Perform rotation", "\n", "", "images_rotated", "=", "[", "index", "for", "index", ",", "value", "in", "enumerate", "(", "torch", ".", "rand", "(", "images", ".", "shape", "[", "0", "]", ")", "<=", "(", "1", "-", "math", ".", "sqrt", "(", "1", "-", "p", ")", ")", ")", "\n", "if", "value", "==", "True", "]", "\n", "if", "len", "(", "images_rotated", ")", ">", "0", ":", "\n", "            ", "images", "[", "images_rotated", "]", "=", "kaf", ".", "apply_affine", "(", "\n", "images", "[", "images_rotated", "]", ",", "\n", "params", "=", "{", "\"angle\"", ":", "torch", ".", "from_numpy", "(", "\n", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "180", ",", "high", "=", "180", ",", "size", "=", "len", "(", "images_rotated", ")", ")", ")", ".", "to", "(", "images", ".", "device", ")", ",", "\n", "\"translations\"", ":", "torch", ".", "zeros", "(", "len", "(", "images_rotated", ")", ",", "2", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"center\"", ":", "torch", ".", "ones", "(", "len", "(", "images_rotated", ")", ",", "2", ",", "device", "=", "images", ".", "device", ")", "\n", "*", "0.5", "*", "torch", ".", "tensor", "(", "images", ".", "shape", "[", "2", ":", "]", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"scale\"", ":", "torch", ".", "ones", "(", "len", "(", "images_rotated", ")", ",", "2", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"sx\"", ":", "torch", ".", "zeros", "(", "len", "(", "images_rotated", ")", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"sy\"", ":", "torch", ".", "zeros", "(", "len", "(", "images_rotated", ")", ",", "device", "=", "images", ".", "device", ")", "}", ",", "\n", "flags", "=", "{", "\"resample\"", ":", "torch", ".", "tensor", "(", "1", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"padding_mode\"", ":", "torch", ".", "tensor", "(", "2", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"align_corners\"", ":", "torch", ".", "tensor", "(", "True", ",", "device", "=", "images", ".", "device", ")", "}", ")", "\n", "# Perform anisotropic scaling", "\n", "", "images_scaling", "=", "[", "index", "for", "index", ",", "value", "in", "enumerate", "(", "torch", ".", "rand", "(", "images", ".", "shape", "[", "0", "]", ")", "<=", "p", ")", "if", "value", "==", "True", "]", "\n", "if", "len", "(", "images_scaling", ")", ">", "0", ":", "\n", "            ", "images", "[", "images_scaling", "]", "=", "kaf", ".", "apply_affine", "(", "\n", "images", "[", "images_scaling", "]", ",", "\n", "params", "=", "{", "\"angle\"", ":", "torch", ".", "zeros", "(", "len", "(", "images_scaling", ")", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"translations\"", ":", "torch", ".", "zeros", "(", "len", "(", "images_scaling", ")", ",", "2", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"center\"", ":", "torch", ".", "ones", "(", "len", "(", "images_scaling", ")", ",", "2", ",", "device", "=", "images", ".", "device", ")", "\n", "*", "0.5", "*", "torch", ".", "tensor", "(", "images", ".", "shape", "[", "2", ":", "]", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"scale\"", ":", "torch", ".", "ones", "(", "len", "(", "images_scaling", ")", ",", "2", ",", "device", "=", "images", ".", "device", ")", "*", "\n", "torch", ".", "from_numpy", "(", "\n", "np", ".", "random", ".", "lognormal", "(", "mean", "=", "0", ",", "sigma", "=", "(", "0.2", "*", "math", ".", "log", "(", "2", ")", ")", "**", "2", ",", "\n", "size", "=", "(", "len", "(", "images_scaling", ")", ",", "2", ")", ")", ")", ".", "float", "(", ")", ".", "to", "(", "images", ".", "device", ")", ",", "\n", "\"sx\"", ":", "torch", ".", "zeros", "(", "len", "(", "images_scaling", ")", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"sy\"", ":", "torch", ".", "zeros", "(", "len", "(", "images_scaling", ")", ",", "device", "=", "images", ".", "device", ")", "}", ",", "\n", "flags", "=", "{", "\"resample\"", ":", "torch", ".", "tensor", "(", "1", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"padding_mode\"", ":", "torch", ".", "tensor", "(", "2", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"align_corners\"", ":", "torch", ".", "tensor", "(", "True", ",", "device", "=", "images", ".", "device", ")", "}", ")", "\n", "# Perform rotation", "\n", "", "images_rotated", "=", "[", "index", "for", "index", ",", "value", "in", "enumerate", "(", "torch", ".", "rand", "(", "images", ".", "shape", "[", "0", "]", ")", "<=", "(", "1", "-", "math", ".", "sqrt", "(", "1", "-", "p", ")", ")", ")", "\n", "if", "value", "==", "True", "]", "\n", "if", "len", "(", "images_rotated", ")", ">", "0", ":", "\n", "            ", "images", "[", "images_rotated", "]", "=", "kaf", ".", "apply_affine", "(", "\n", "images", "[", "images_rotated", "]", ",", "\n", "params", "=", "{", "\"angle\"", ":", "torch", ".", "from_numpy", "(", "\n", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "180", ",", "high", "=", "180", ",", "size", "=", "len", "(", "images_rotated", ")", ")", ")", ".", "to", "(", "images", ".", "device", ")", ",", "\n", "\"translations\"", ":", "torch", ".", "zeros", "(", "len", "(", "images_rotated", ")", ",", "2", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"center\"", ":", "torch", ".", "ones", "(", "len", "(", "images_rotated", ")", ",", "2", ",", "device", "=", "images", ".", "device", ")", "\n", "*", "0.5", "*", "torch", ".", "tensor", "(", "images", ".", "shape", "[", "2", ":", "]", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"scale\"", ":", "torch", ".", "ones", "(", "len", "(", "images_rotated", ")", ",", "2", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"sx\"", ":", "torch", ".", "zeros", "(", "len", "(", "images_rotated", ")", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"sy\"", ":", "torch", ".", "zeros", "(", "len", "(", "images_rotated", ")", ",", "device", "=", "images", ".", "device", ")", "}", ",", "\n", "flags", "=", "{", "\"resample\"", ":", "torch", ".", "tensor", "(", "1", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"padding_mode\"", ":", "torch", ".", "tensor", "(", "2", ",", "device", "=", "images", ".", "device", ")", ",", "\n", "\"align_corners\"", ":", "torch", ".", "tensor", "(", "True", ",", "device", "=", "images", ".", "device", ")", "}", ")", "\n", "", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.adaptive_discriminator_augmentation.integer_translation": [[203, 214], ["torch.roll", "torch.roll", "int", "int", "random.uniform", "random.uniform"], "function", ["None"], ["", "", "def", "integer_translation", "(", "images", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Function implements integer translation augmentation\n    :param images: (torch.Tensor) Input images\n    :return: (torch.Tensor) Augmented images\n    \"\"\"", "\n", "# Get translation index", "\n", "translation_index", "=", "(", "int", "(", "images", ".", "shape", "[", "-", "2", "]", "*", "random", ".", "uniform", "(", "-", "0.125", ",", "0.125", ")", ")", ",", "\n", "int", "(", "images", ".", "shape", "[", "-", "1", "]", "*", "random", ".", "uniform", "(", "-", "0.125", ",", "0.125", ")", ")", ")", "\n", "# Apply translation", "\n", "return", "torch", ".", "roll", "(", "images", ",", "shifts", "=", "translation_index", ",", "dims", "=", "(", "-", "2", ",", "-", "1", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.WassersteinDiscriminatorLoss.__init__": [[14, 20], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "WassersteinDiscriminatorLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.WassersteinDiscriminatorLoss.forward": [[21, 41], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "weight.view().to", "weight.view().to", "weight.view", "weight.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prediction_real", ":", "torch", ".", "Tensor", ",", "\n", "prediction_fake", ":", "torch", ".", "Tensor", ",", "weight", ":", "torch", ".", "Tensor", "=", "None", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass of the loss module\n        :param prediction_real: (torch.Tensor) Prediction for real samples\n        :param prediction_fake: (torch.Tensor) Prediction for fake samples\n        :param weight: (torch.Tensor) Weights map to be applied\n        :return: (Tuple[torch.Tensor, torch.Tensor]) Scalar loss value\n        \"\"\"", "\n", "# Compute loss", "\n", "if", "weight", "is", "not", "None", ":", "\n", "            ", "loss_real", "=", "-", "torch", ".", "mean", "(", "\n", "prediction_real", "*", "weight", ".", "view", "(", "1", ",", "1", ",", "1", ",", "weight", ".", "shape", "[", "-", "2", "]", ",", "weight", ".", "shape", "[", "-", "1", "]", ")", ".", "to", "(", "prediction_real", ".", "device", ")", ")", "\n", "loss_fake", "=", "torch", ".", "mean", "(", "\n", "prediction_fake", "*", "weight", ".", "view", "(", "1", ",", "1", ",", "1", ",", "weight", ".", "shape", "[", "-", "2", "]", ",", "weight", ".", "shape", "[", "-", "1", "]", ")", ".", "to", "(", "prediction_fake", ".", "device", ")", ")", "\n", "return", "loss_real", ",", "loss_fake", "\n", "", "else", ":", "\n", "            ", "loss_real", "=", "-", "torch", ".", "mean", "(", "prediction_real", ")", "\n", "loss_fake", "=", "torch", ".", "mean", "(", "prediction_fake", ")", "\n", "return", "loss_real", ",", "loss_fake", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.WassersteinDiscriminatorLossCutMix.__init__": [[48, 54], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "WassersteinDiscriminatorLossCutMix", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.WassersteinDiscriminatorLossCutMix.forward": [[55, 66], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prediction", ":", "torch", ".", "Tensor", ",", "\n", "label", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass. Loss parts are not summed up to not retain the whole backward graph later.\n        :param prediction: (torch.Tensor)\n        :return: (Tuple[torch.Tensor, torch.Tensor]) Loss values for real and fake part\n        \"\"\"", "\n", "# Compute loss", "\n", "loss_real", "=", "-", "torch", ".", "mean", "(", "prediction", "*", "label", ")", "\n", "loss_fake", "=", "torch", ".", "mean", "(", "prediction", "*", "(", "-", "label", "+", "1.", ")", ")", "\n", "return", "loss_real", ",", "loss_fake", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.WassersteinGeneratorLoss.__init__": [[73, 79], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "WassersteinGeneratorLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.WassersteinGeneratorLoss.forward": [[80, 95], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "weight.view().to", "weight.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prediction_fake", ":", "torch", ".", "Tensor", ",", "weight", ":", "torch", ".", "Tensor", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass of the loss module\n        :param prediction_fake: (torch.Tensor) Prediction for fake samples\n        :param weight: (torch.Tensor) Weights map to be applied\n        :return: (torch.Tensor) Scalar loss value\n        \"\"\"", "\n", "# Compute loss", "\n", "if", "weight", "is", "not", "None", ":", "\n", "            ", "loss", "=", "-", "torch", ".", "mean", "(", "\n", "prediction_fake", "*", "weight", ".", "view", "(", "1", ",", "1", ",", "1", ",", "weight", ".", "shape", "[", "-", "2", "]", ",", "weight", ".", "shape", "[", "-", "1", "]", ")", ".", "to", "(", "prediction_fake", ".", "device", ")", ")", "\n", "return", "loss", "\n", "", "else", ":", "\n", "            ", "loss", "=", "-", "torch", ".", "mean", "(", "prediction_fake", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.NonSaturatingLogisticGeneratorLoss.__init__": [[102, 108], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "NonSaturatingLogisticGeneratorLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.NonSaturatingLogisticGeneratorLoss.__repr__": [[109, 115], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get representation of the loss module\n        :return: (str) String including information\n        \"\"\"", "\n", "return", "'{}'", ".", "format", "(", "self", ".", "__class__", ".", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.NonSaturatingLogisticGeneratorLoss.forward": [[116, 132], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.softplus", "torch.softplus", "torch.softplus", "torch.softplus", "torch.softplus", "torch.softplus", "weight.view().to", "weight.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prediction_fake", ":", "torch", ".", "Tensor", ",", "weight", ":", "torch", ".", "Tensor", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass to compute the generator loss\n        :param prediction_fake: (torch.Tensor) Prediction of the discriminator for fake samples\n        :param weight: (torch.Tensor) Weights map to be applied\n        :return: (torch.Tensor) Loss value\n        \"\"\"", "\n", "# Calc loss", "\n", "if", "weight", "is", "not", "None", ":", "\n", "            ", "loss", "=", "torch", ".", "mean", "(", "\n", "F", ".", "softplus", "(", "-", "prediction_fake", ")", "*", "weight", ".", "view", "(", "1", ",", "1", ",", "1", ",", "weight", ".", "shape", "[", "-", "2", "]", ",", "weight", ".", "shape", "[", "-", "1", "]", ")", ".", "to", "(", "\n", "prediction_fake", ".", "device", ")", ")", "\n", "return", "loss", "\n", "", "else", ":", "\n", "            ", "loss", "=", "torch", ".", "mean", "(", "F", ".", "softplus", "(", "-", "prediction_fake", ")", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.NonSaturatingLogisticDiscriminatorLoss.__init__": [[139, 145], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "NonSaturatingLogisticDiscriminatorLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.NonSaturatingLogisticDiscriminatorLoss.forward": [[146, 171], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.softplus", "torch.softplus", "torch.softplus", "torch.softplus", "torch.softplus", "torch.softplus", "torch.softplus", "torch.softplus", "torch.softplus", "weight.view().to", "torch.softplus", "torch.softplus", "torch.softplus", "weight.view().to", "weight.view", "weight.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prediction_real", ":", "torch", ".", "Tensor", ",", "\n", "prediction_fake", ":", "torch", ".", "Tensor", ",", "weight", ":", "torch", ".", "Tensor", "=", "None", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass. Loss parts are not summed up to not retain the whole backward graph later.\n        :param prediction_real: (torch.Tensor) Prediction of the discriminator for real images\n        :param prediction_fake: (torch.Tensor) Prediction of the discriminator for fake images\n        :param weight: (torch.Tensor) Weights map to be applied\n        :return: (Tuple[torch.Tensor, torch.Tensor]) Loss values for real and fake part\n        \"\"\"", "\n", "if", "weight", "is", "not", "None", ":", "\n", "# Calc real loss part", "\n", "            ", "loss_real", "=", "torch", ".", "mean", "(", "\n", "F", ".", "softplus", "(", "-", "prediction_real", ")", "*", "weight", ".", "view", "(", "1", ",", "1", ",", "1", ",", "weight", ".", "shape", "[", "-", "2", "]", ",", "weight", ".", "shape", "[", "-", "1", "]", ")", ".", "to", "(", "\n", "prediction_real", ".", "device", ")", ")", "\n", "# Calc fake loss part", "\n", "loss_fake", "=", "torch", ".", "mean", "(", "\n", "F", ".", "softplus", "(", "prediction_fake", ")", "*", "weight", ".", "view", "(", "1", ",", "1", ",", "1", ",", "weight", ".", "shape", "[", "-", "2", "]", ",", "weight", ".", "shape", "[", "-", "1", "]", ")", ".", "to", "(", "\n", "prediction_fake", ".", "device", ")", ")", "\n", "return", "loss_real", ",", "loss_fake", "\n", "", "else", ":", "\n", "# Calc real loss part", "\n", "            ", "loss_real", "=", "torch", ".", "mean", "(", "F", ".", "softplus", "(", "-", "prediction_real", ")", ")", "\n", "# Calc fake loss part", "\n", "loss_fake", "=", "torch", ".", "mean", "(", "F", ".", "softplus", "(", "prediction_fake", ")", ")", "\n", "return", "loss_real", ",", "loss_fake", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.NonSaturatingLogisticDiscriminatorLossCutMix.__init__": [[178, 184], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "NonSaturatingLogisticDiscriminatorLossCutMix", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.NonSaturatingLogisticDiscriminatorLossCutMix.forward": [[185, 196], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.softplus", "torch.softplus", "torch.softplus", "torch.softplus", "torch.softplus", "torch.softplus"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prediction", ":", "torch", ".", "Tensor", ",", "label", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass. Loss parts are not summed up to not retain the whole backward graph later.\n        :param prediction: (torch.Tensor)\n        :return: (Tuple[torch.Tensor, torch.Tensor]) Loss values for real and fake part\n        \"\"\"", "\n", "# Calc real loss part", "\n", "loss_real", "=", "torch", ".", "mean", "(", "F", ".", "softplus", "(", "-", "prediction", ")", "*", "label", ")", "\n", "# Calc fake loss part", "\n", "loss_fake", "=", "torch", ".", "mean", "(", "F", ".", "softplus", "(", "prediction", ")", "*", "(", "-", "label", "+", "1.", ")", ")", "\n", "return", "loss_real", ",", "loss_fake", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.HingeGeneratorLoss.__init__": [[204, 210], ["loss.WassersteinGeneratorLoss.__init__"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "HingeGeneratorLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.HingeDiscriminatorLoss.__init__": [[217, 223], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "HingeDiscriminatorLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.HingeDiscriminatorLoss.forward": [[224, 253], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "weight.view().to", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "weight.view().to", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "weight.view", "weight.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prediction_real", ":", "torch", ".", "Tensor", ",", "prediction_fake", ":", "torch", ".", "Tensor", ",", "\n", "weight", ":", "torch", ".", "Tensor", "=", "None", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass. Loss parts are not summed up to not retain the whole backward graph later.\n        :param prediction_real: (torch.Tensor) Prediction of the discriminator for real images\n        :param prediction_fake: (torch.Tensor) Prediction of the discriminator for fake images\n        :param weight: (torch.Tensor) Weights map to be applied\n        :return: (Tuple[torch.Tensor, torch.Tensor]) Loss values for real and fake part\n        \"\"\"", "\n", "if", "weight", "is", "not", "None", ":", "\n", "# Calc loss for real prediction", "\n", "            ", "loss_real", "=", "-", "torch", ".", "mean", "(", "torch", ".", "minimum", "(", "torch", ".", "tensor", "(", "0.", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "prediction_real", ".", "device", ")", ",", "\n", "prediction_real", "-", "1.", ")", "*", "weight", ".", "view", "(", "1", ",", "1", ",", "1", ",", "weight", ".", "shape", "[", "-", "2", "]", ",", "\n", "weight", ".", "shape", "[", "-", "1", "]", ")", ".", "to", "(", "\n", "prediction_real", ".", "device", ")", ")", "\n", "# Calc loss for fake prediction", "\n", "loss_fake", "=", "-", "torch", ".", "mean", "(", "torch", ".", "minimum", "(", "torch", ".", "tensor", "(", "0.", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "prediction_real", ".", "device", ")", ",", "\n", "-", "prediction_fake", "-", "1.", ")", "*", "weight", ".", "view", "(", "1", ",", "1", ",", "1", ",", "weight", ".", "shape", "[", "-", "2", "]", ",", "\n", "weight", ".", "shape", "[", "-", "1", "]", ")", ".", "to", "(", "\n", "prediction_fake", ".", "device", ")", ")", "\n", "return", "loss_real", ",", "loss_fake", "\n", "", "else", ":", "\n", "# Calc loss for real prediction", "\n", "            ", "loss_real", "=", "-", "torch", ".", "mean", "(", "torch", ".", "minimum", "(", "torch", ".", "tensor", "(", "0.", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "prediction_real", ".", "device", ")", ",", "\n", "prediction_real", "-", "1.", ")", ")", "\n", "# Calc loss for fake prediction", "\n", "loss_fake", "=", "-", "torch", ".", "mean", "(", "torch", ".", "minimum", "(", "torch", ".", "tensor", "(", "0.", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "prediction_real", ".", "device", ")", ",", "\n", "-", "prediction_fake", "-", "1.", ")", ")", "\n", "return", "loss_real", ",", "loss_fake", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.HingeDiscriminatorLossCutMix.__init__": [[260, 266], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "HingeDiscriminatorLossCutMix", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.HingeDiscriminatorLossCutMix.forward": [[267, 281], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.minimum", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prediction", ":", "torch", ".", "Tensor", ",", "\n", "label", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass. Loss parts are not summed up to not retain the whole backward graph later.\n        :param prediction: (torch.Tensor)\n        :return: (Tuple[torch.Tensor, torch.Tensor]) Loss values for real and fake part\n        \"\"\"", "\n", "# Calc loss for real prediction", "\n", "loss_real", "=", "-", "torch", ".", "mean", "(", "torch", ".", "minimum", "(", "torch", ".", "tensor", "(", "0.", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "prediction", ".", "device", ")", ",", "\n", "prediction", "-", "1.", ")", "*", "label", ")", "\n", "# Calc loss for fake prediction", "\n", "loss_fake", "=", "-", "torch", ".", "mean", "(", "torch", ".", "minimum", "(", "torch", ".", "tensor", "(", "0.", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "prediction", ".", "device", ")", ",", "\n", "-", "prediction", "-", "1.", ")", "*", "(", "-", "label", "+", "1.", ")", ")", "\n", "return", "loss_real", ",", "loss_fake", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.R1Regularization.__init__": [[288, 294], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "R1Regularization", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.R1Regularization.__repr__": [[295, 301], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get representation of the loss module\n        :return: (str) String including information\n        \"\"\"", "\n", "return", "'{}'", ".", "format", "(", "self", ".", "__class__", ".", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.R1Regularization.forward": [[302, 318], ["torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "grad_real.pow().view().sum().mean", "prediction_real.sum", "grad_real.pow().view().sum", "prediction_real.sum", "prediction_real_pixel_wise.sum", "grad_real.pow().view", "grad_real.pow"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prediction_real", ":", "torch", ".", "Tensor", ",", "image_real", ":", "torch", ".", "Tensor", ",", "\n", "prediction_real_pixel_wise", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass to compute the regularization\n        :param prediction_real: (torch.Tensor) Prediction of the discriminator for a batch of real images\n        :param image_real: (torch.Tensor) Batch of the corresponding real images\n        :return: (torch.Tensor) Loss value\n        \"\"\"", "\n", "# Calc gradient", "\n", "grad_real", ",", "=", "autograd", ".", "grad", "(", "\n", "outputs", "=", "(", "prediction_real", ".", "sum", "(", ")", ",", "prediction_real_pixel_wise", ".", "sum", "(", ")", ")", "\n", "if", "prediction_real_pixel_wise", "is", "not", "None", "else", "prediction_real", ".", "sum", "(", ")", ",", "\n", "inputs", "=", "image_real", ",", "create_graph", "=", "True", ")", "\n", "# Calc regularization", "\n", "regularization_loss", "=", "0.5", "*", "grad_real", ".", "pow", "(", "2", ")", ".", "view", "(", "grad_real", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ".", "sum", "(", "1", ")", ".", "mean", "(", ")", "\n", "return", "regularization_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.R2Regularization.__init__": [[325, 331], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "R2Regularization", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.R2Regularization.__repr__": [[332, 338], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get representation of the loss module\n        :return: (str) String including information\n        \"\"\"", "\n", "return", "'{}'", ".", "format", "(", "self", ".", "__class__", ".", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.R2Regularization.forward": [[339, 351], ["torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad.pow().view().sum().mean", "prediction_fake.sum", "torch.autograd.grad.pow().view().sum", "torch.autograd.grad.pow().view", "torch.autograd.grad.pow"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prediction_fake", ":", "torch", ".", "Tensor", ",", "image_fake", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass to compute the regularization\n        :param prediction_real: (torch.Tensor) Prediction of the discriminator for a batch of real images\n        :param image_real: (torch.Tensor) Batch of the corresponding real images\n        :return: (torch.Tensor) Loss value\n        \"\"\"", "\n", "# Calc gradient", "\n", "grad_real", "=", "autograd", ".", "grad", "(", "outputs", "=", "prediction_fake", ".", "sum", "(", ")", ",", "inputs", "=", "image_fake", ",", "create_graph", "=", "True", ")", "\n", "# Calc regularization", "\n", "regularization_loss", "=", "0.5", "*", "grad_real", ".", "pow", "(", "2", ")", ".", "view", "(", "grad_real", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ".", "sum", "(", "1", ")", ".", "mean", "(", ")", "\n", "return", "regularization_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.PathLengthRegularization.__init__": [[358, 370], ["torch.Module.__init__", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ",", "decay", ":", "float", "=", "0.01", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param decay: (float) Decay of the current mean path length\n        :param weight: (float) Weight factor\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "PathLengthRegularization", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Save parameter", "\n", "self", ".", "decay", "=", "decay", "\n", "# Init mean path length", "\n", "self", ".", "mean_path_length", "=", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "float", ",", "requires_grad", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.PathLengthRegularization.__repr__": [[371, 377], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get representation of the loss module\n        :return: (str) String including information\n        \"\"\"", "\n", "return", "'{}'", ".", "format", "(", "self", ".", "__class__", ".", "__name__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.PathLengthRegularization.forward": [[378, 396], ["loss.PathLengthRegularization.mean_path_length.detach_", "torch.sqrt().mean", "torch.sqrt().mean", "torch.sqrt().mean", "torch.sqrt().mean", "torch.sqrt().mean", "torch.sqrt().mean", "torch.sqrt().mean", "torch.sqrt().mean", "torch.sqrt().mean", "loss.PathLengthRegularization.mean_path_length.to", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt().mean.mean", "torch.sqrt().mean.mean", "torch.sqrt().mean.mean", "grad.pow().sum().mean", "grad.pow().sum", "grad.pow"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "grad", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param grad: (torch.Tensor) Patch length grads\n        :return: (Tuple[torch.Tensor, torch.Tensor]) Path length penalty and path lengths\n        \"\"\"", "\n", "# Reduce dims", "\n", "# Detach mean path length", "\n", "self", ".", "mean_path_length", ".", "detach_", "(", ")", "\n", "# Get new path lengths", "\n", "path_lengths", "=", "torch", ".", "sqrt", "(", "grad", ".", "pow", "(", "2", ")", ".", "sum", "(", "2", ")", ".", "mean", "(", "1", ")", "+", "1e-08", ")", ".", "mean", "(", ")", "\n", "# Mean path length to device", "\n", "self", ".", "mean_path_length", "=", "self", ".", "mean_path_length", ".", "to", "(", "grad", ".", "device", ")", "\n", "# Calc path length mean", "\n", "self", ".", "mean_path_length", "=", "self", ".", "mean_path_length", "+", "self", ".", "decay", "*", "(", "path_lengths", ".", "mean", "(", ")", "-", "self", ".", "mean_path_length", ")", "\n", "# Get path length penalty", "\n", "path_length_penalty", "=", "torch", ".", "mean", "(", "(", "path_lengths", "-", "self", ".", "mean_path_length", ")", "**", "2", ")", "\n", "return", "path_length_penalty", ",", "path_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.TopK.__init__": [[404, 416], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ",", "starting_iteration", ":", "int", ",", "final_iteration", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param starting_iteration: (bool) Number of iteration when to start with top-k training\n        :param final_iteration: (bool) Number of iteration when to stop top-k training decrease\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "TopK", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Save parameters", "\n", "self", ".", "starting_iteration", "=", "starting_iteration", "\n", "self", ".", "final_iteration", "=", "final_iteration", "\n", "self", ".", "iterations", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.TopK.calc_v": [[417, 431], ["float", "float"], "methods", ["None"], ["", "def", "calc_v", "(", "self", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        Method tracks the iterations and estimates v.\n        :return: (float) v factor\n        \"\"\"", "\n", "# Update iterations", "\n", "self", ".", "iterations", "+=", "1", "\n", "if", "self", ".", "iterations", "<=", "self", ".", "starting_iteration", ":", "\n", "            ", "return", "1.", "\n", "", "elif", "self", ".", "iterations", ">=", "self", ".", "final_iteration", ":", "\n", "            ", "return", "0.5", "\n", "", "else", ":", "\n", "            ", "return", "0.5", "*", "(", "1.", "-", "float", "(", "self", ".", "iterations", "-", "self", ".", "starting_iteration", ")", "\n", "/", "float", "(", "self", ".", "final_iteration", "-", "self", ".", "starting_iteration", ")", ")", "+", "0.5", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.TopK.forward": [[432, 445], ["loss.TopK.calc_v", "input.view.view.view", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "max", "int"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.loss.TopK.calc_v"], ["", "", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param input: (torch.Tensor) Input tensor\n        :return: (torch.Tensor) Output tensor filtered by top-k\n        \"\"\"", "\n", "# Calc v", "\n", "v", "=", "self", ".", "calc_v", "(", ")", "\n", "# Flatten input", "\n", "input", "=", "input", ".", "view", "(", "-", "1", ")", "\n", "# Apply top k", "\n", "output", "=", "torch", ".", "topk", "(", "input", ",", "k", "=", "max", "(", "1", ",", "int", "(", "input", ".", "shape", "[", "0", "]", "*", "v", ")", ")", ")", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.IS.__init__": [[21, 43], ["torchvision.models.inception_v3().cpu", "torchvision.models.inception_v3"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "device", ":", "Union", "[", "str", ",", "torch", ".", "device", "]", "=", "\"cuda\"", ",", "\n", "data_parallel", ":", "bool", "=", "True", ",", "batch_size", ":", "int", "=", "1", ",", "\n", "data_samples", ":", "int", "=", "5000", ",", "no_rfp", ":", "bool", "=", "False", ",", "\n", "no_gfp", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param device: (Union[str, torch.device]) Device to be utilized\n        :param data_parallel: (bool) If true data parallel is used\n        :param batch_size: (bool) Batch size to be utilized\n        :param data_samples: (int) Number of real and fake sample to be utilized during evaluation\n        :param no_rfp: (bool) If true no RFP channel is utilized\n        :param no_rfp: (bool) If true no GFP channel is utilized\n        \"\"\"", "\n", "# Save parameters", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "data_parallel", "=", "data_parallel", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "data_samples", "=", "data_samples", "\n", "self", ".", "no_rfp", "=", "no_rfp", "\n", "self", ".", "no_gfp", "=", "no_gfp", "\n", "# Init inception net", "\n", "self", ".", "inception_net", "=", "torchvision", ".", "models", ".", "inception_v3", "(", "pretrained", "=", "True", ")", ".", "cpu", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.IS.__preprocessing": [[44, 53], ["kornia.resize", "misc.normalize_m1_1_batch"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.normalize_m1_1_batch"], ["", "def", "__preprocessing", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Preprocessing\n        :param input: (torch.Tensor) Input tensor\n        :return: (torch.Tensor) Output tensor\n        \"\"\"", "\n", "input", "=", "kornia", ".", "resize", "(", "input", "[", ":", ",", ":", ",", "0", "]", ",", "size", "=", "(", "299", ",", "299", ")", ",", "interpolation", "=", "'bilinear'", ",", "antialias", "=", "True", ")", "\n", "output", "=", "misc", ".", "normalize_m1_1_batch", "(", "input", "[", ":", ",", ":", ",", "None", "]", ")", "[", ":", ",", ":", ",", "0", "]", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.IS.__call__": [[54, 155], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "copy.deepcopy.to", "copy.deepcopy.eval", "generator.to", "generator.eval", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack.mean", "torch.stack.mean", "torch.stack.mean", "torch.stack.mean", "torch.stack.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum.mean().exp", "torch.sum.mean().exp", "torch.sum.mean().exp", "torch.sum.mean().exp", "torch.sum.mean().exp", "copy.deepcopy.cpu", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.sum.mean().exp.item", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "copy.deepcopy", "math.ceil", "misc.get_noise", "generator", "fake_images[].unsqueeze().repeat_interleave", "copy.deepcopy.softmax().cpu().unbind", "torch.stack.extend", "torch.stack.extend", "torch.stack.extend", "torch.stack.extend", "torch.stack.extend", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack.mean", "torch.stack.mean", "torch.stack.mean", "torch.stack.mean", "torch.stack.mean", "torch.stack.mean", "torch.stack.mean", "torch.stack.mean", "torch.stack.mean", "torch.stack.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum.mean().exp", "torch.sum.mean().exp", "torch.sum.mean().exp", "torch.sum.mean().exp", "torch.sum.mean().exp", "torch.sum.mean().exp", "torch.sum.mean().exp", "torch.sum.mean().exp", "torch.sum.mean().exp", "torch.sum.mean().exp", "copy.deepcopy", "fake_images[].unsqueeze().repeat_interleave", "fake_images[].unsqueeze().repeat_interleave", "copy.deepcopy.softmax().cpu().unbind", "torch.stack.extend", "torch.stack.extend", "torch.stack.extend", "torch.stack.extend", "torch.stack.extend", "copy.deepcopy.softmax().cpu().unbind", "torch.stack.extend", "torch.stack.extend", "torch.stack.extend", "torch.stack.extend", "torch.stack.extend", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.sum.mean", "torch.sum.mean", "torch.sum.mean", "torch.sum.mean", "torch.sum.mean", "torch.sum.mean().exp.item", "torch.sum.mean().exp.item", "torch.sum.mean().exp.item", "torch.sum.mean().exp.item", "torch.sum.mean().exp.item", "fake_images[].unsqueeze", "copy.deepcopy.softmax().cpu", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.sum.mean", "torch.sum.mean", "torch.sum.mean", "torch.sum.mean", "torch.sum.mean", "torch.sum.mean", "torch.sum.mean", "torch.sum.mean", "torch.sum.mean", "torch.sum.mean", "isinstance", "fake_images[].unsqueeze", "fake_images[].unsqueeze", "copy.deepcopy.softmax().cpu", "copy.deepcopy.softmax().cpu", "copy.deepcopy.softmax", "copy.deepcopy.softmax", "copy.deepcopy.softmax", "copy.deepcopy.", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "validation_metrics.IS.__preprocessing", "copy.deepcopy.", "copy.deepcopy.", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "validation_metrics.IS.__preprocessing", "validation_metrics.IS.__preprocessing"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.get_noise", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.IS.__preprocessing", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.IS.__preprocessing", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.IS.__preprocessing"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "__call__", "(", "self", ",", "generator", ":", "Union", "[", "nn", ".", "Module", ",", "nn", ".", "DataParallel", "]", ",", "\n", "**", "kwargs", ")", "->", "Union", "[", "Tuple", "[", "float", ",", "float", ",", "float", "]", ",", "Tuple", "[", "float", ",", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        Method to compute FID score\n        :param generator: (Union[nn.Module, nn.DataParallel]) Generator network\n        :param **kwargs: Not used\n        :return: (Union[Tuple[float, float, float], Tuple[float, float]]) IS scores of bf, gfp and rfp (optional)\n        \"\"\"", "\n", "# Apply data parallel if utilized", "\n", "if", "self", ".", "data_parallel", ":", "\n", "            ", "inception_net", "=", "nn", ".", "DataParallel", "(", "copy", ".", "deepcopy", "(", "self", ".", "inception_net", ")", ")", "\n", "", "else", ":", "\n", "            ", "inception_net", "=", "copy", ".", "deepcopy", "(", "self", ".", "inception_net", ")", "\n", "# Inception net to device", "\n", "", "inception_net", "=", "inception_net", ".", "to", "(", "self", ".", "device", ")", "\n", "# Ensure eval mode is present", "\n", "inception_net", ".", "eval", "(", ")", "\n", "# Generator to device", "\n", "generator", ".", "to", "(", "self", ".", "device", ")", "\n", "# Generator into eval mode", "\n", "generator", ".", "eval", "(", ")", "\n", "# Generate activation of real samples", "\n", "predictions_fake_bf", "=", "[", "]", "\n", "predictions_fake_gfp", "=", "[", "]", "\n", "if", "not", "self", ".", "no_rfp", ":", "\n", "            ", "predictions_fake_rfp", "=", "[", "]", "\n", "", "for", "_", "in", "range", "(", "math", ".", "ceil", "(", "self", ".", "data_samples", "/", "self", ".", "batch_size", ")", ")", ":", "\n", "# Generate noise input", "\n", "            ", "noise_input", "=", "misc", ".", "get_noise", "(", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "latent_dimension", "=", "generator", ".", "module", ".", "latent_dimensions", "\n", "if", "isinstance", "(", "generator", ",", "nn", ".", "DataParallel", ")", "else", "generator", ".", "latent_dimensions", ",", "\n", "p_mixed_noise", "=", "0.0", ",", "\n", "device", "=", "self", ".", "device", "\n", ")", "\n", "# Predict fake images", "\n", "fake_images", "=", "generator", "(", "input", "=", "noise_input", ")", "\n", "# Get random bf images [batch size, 3, height, width]", "\n", "fake_images_bf", "=", "fake_images", "[", ":", ",", "0", ",", "torch", ".", "randint", "(", "0", ",", "fake_images", ".", "shape", "[", "2", "]", ",", "(", "1", ",", ")", ")", "]", ".", "unsqueeze", "(", "\n", "dim", "=", "1", ")", ".", "repeat_interleave", "(", "dim", "=", "1", ",", "repeats", "=", "3", ")", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "# Get random gfp images [batch size, 3, height, width]", "\n", "                ", "fake_images_gfp", "=", "fake_images", "[", ":", ",", "1", ",", "torch", ".", "randint", "(", "0", ",", "fake_images", ".", "shape", "[", "2", "]", ",", "(", "1", ",", ")", ")", "]", ".", "unsqueeze", "(", "\n", "dim", "=", "1", ")", ".", "repeat_interleave", "(", "dim", "=", "1", ",", "repeats", "=", "3", ")", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "# Get random rfp images [batch size, 3, height, width]", "\n", "                ", "fake_images_rfp", "=", "fake_images", "[", ":", ",", "2", ",", "torch", ".", "randint", "(", "0", ",", "fake_images", ".", "shape", "[", "2", "]", ",", "(", "1", ",", ")", ")", "]", ".", "unsqueeze", "(", "\n", "dim", "=", "1", ")", ".", "repeat_interleave", "(", "dim", "=", "1", ",", "repeats", "=", "3", ")", "\n", "# Make predictions for bf images", "\n", "", "prediction_fake_bf", "=", "inception_net", "(", "self", ".", "__preprocessing", "(", "fake_images_bf", ")", ")", ".", "softmax", "(", "dim", "=", "1", ")", ".", "cpu", "(", ")", ".", "unbind", "(", "dim", "=", "0", ")", "\n", "# Save bf activation", "\n", "predictions_fake_bf", ".", "extend", "(", "prediction_fake_bf", ")", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "# Make predictions for gfp images", "\n", "                ", "prediction_fake_gfp", "=", "inception_net", "(", "self", ".", "__preprocessing", "(", "fake_images_gfp", ")", ")", ".", "softmax", "(", "dim", "=", "1", ")", ".", "cpu", "(", ")", ".", "unbind", "(", "dim", "=", "0", ")", "\n", "# Save bf activation", "\n", "predictions_fake_gfp", ".", "extend", "(", "prediction_fake_gfp", ")", "\n", "# Make predictions for rfp images", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "                ", "prediction_fake_rfp", "=", "inception_net", "(", "self", ".", "__preprocessing", "(", "fake_images_rfp", ")", ")", ".", "softmax", "(", "dim", "=", "1", ")", ".", "cpu", "(", ")", ".", "unbind", "(", "dim", "=", "0", ")", "\n", "# Save bf activation", "\n", "predictions_fake_rfp", ".", "extend", "(", "prediction_fake_rfp", ")", "\n", "# Remove to many activations", "\n", "", "", "predictions_fake_bf", "=", "torch", ".", "stack", "(", "predictions_fake_bf", "[", ":", "self", ".", "data_samples", "]", ",", "dim", "=", "0", ")", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "            ", "predictions_fake_gfp", "=", "torch", ".", "stack", "(", "predictions_fake_gfp", "[", ":", "self", ".", "data_samples", "]", ",", "dim", "=", "0", ")", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "            ", "predictions_fake_rfp", "=", "torch", ".", "stack", "(", "predictions_fake_rfp", "[", ":", "self", ".", "data_samples", "]", ",", "dim", "=", "0", ")", "\n", "# Calc inception score", "\n", "", "p_y_bf", "=", "predictions_fake_bf", ".", "mean", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "            ", "p_y_gfp", "=", "predictions_fake_gfp", ".", "mean", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "            ", "p_y_rfp", "=", "predictions_fake_rfp", ".", "mean", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "# Calc kl divergence", "\n", "", "kl_bf", "=", "torch", ".", "sum", "(", "predictions_fake_bf", "*", "torch", ".", "log", "(", "predictions_fake_bf", "/", "p_y_bf", ")", ",", "dim", "=", "-", "1", ")", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "            ", "kl_gfp", "=", "torch", ".", "sum", "(", "predictions_fake_gfp", "*", "torch", ".", "log", "(", "predictions_fake_gfp", "/", "p_y_gfp", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "            ", "kl_rfp", "=", "torch", ".", "sum", "(", "predictions_fake_rfp", "*", "torch", ".", "log", "(", "predictions_fake_rfp", "/", "p_y_rfp", ")", ",", "dim", "=", "-", "1", ")", "\n", "# Calc inception score", "\n", "", "inception_score_bf", "=", "kl_bf", ".", "mean", "(", ")", ".", "exp", "(", ")", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "            ", "inception_score_gfp", "=", "kl_gfp", ".", "mean", "(", ")", ".", "exp", "(", ")", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "            ", "inception_score_rfp", "=", "kl_rfp", ".", "mean", "(", ")", ".", "exp", "(", ")", "\n", "# Model to cpu", "\n", "", "inception_net", ".", "cpu", "(", ")", "\n", "# Remove model", "\n", "del", "inception_net", "\n", "# Empty cuda cache", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "            ", "return", "inception_score_bf", ".", "item", "(", ")", ",", "inception_score_gfp", ".", "item", "(", ")", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "            ", "return", "inception_score_bf", ".", "item", "(", ")", ",", "inception_score_gfp", ".", "item", "(", ")", ",", "inception_score_rfp", ".", "item", "(", ")", "\n", "", "return", "inception_score_bf", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.FID.__init__": [[162, 190], ["InceptionNetworkFID().cpu", "validation_metrics.InceptionNetworkFID"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "device", ":", "Union", "[", "str", ",", "torch", ".", "device", "]", "=", "\"cuda\"", ",", "\n", "data_parallel", ":", "bool", "=", "True", ",", "batch_size", ":", "int", "=", "1", ",", "\n", "data_samples", ":", "int", "=", "5000", ",", "no_rfp", ":", "bool", "=", "False", ",", "\n", "no_gfp", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param device: (Union[str, torch.device]) Device to be utilized\n        :param data_parallel: (bool) If true data parallel is used\n        :param batch_size: (bool) Batch size to be utilized\n        :param data_samples: (int) Number of real and fake sample to be utilized during evaluation\n        :param no_rfp: (bool) If true no RFP channel is utilized\n        :param no_rfp: (bool) If true no GFP channel is utilized\n        \"\"\"", "\n", "# Save parameters", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "data_parallel", "=", "data_parallel", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "data_samples", "=", "data_samples", "\n", "self", ".", "no_rfp", "=", "no_rfp", "\n", "self", ".", "no_gfp", "=", "no_gfp", "\n", "# Init inception net", "\n", "self", ".", "model", "=", "InceptionNetworkFID", "(", ")", ".", "cpu", "(", ")", "\n", "# Init activations", "\n", "self", ".", "activations_real_bf", ":", "np", ".", "ndarray", "=", "None", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "            ", "self", ".", "activations_real_gfp", ":", "np", ".", "ndarray", "=", "None", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "            ", "self", ".", "activations_real_rfp", ":", "np", ".", "ndarray", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.FID._calc_fid": [[191, 220], ["numpy.mean", "numpy.mean", "numpy.cov", "numpy.cov", "numpy.mean", "numpy.mean", "numpy.cov", "numpy.cov", "scipy.linalg.sqrtm", "numpy.iscomplexobj", "numpy.iscomplexobj", "numpy.trace", "numpy.trace", "numpy.trace", "numpy.trace", "numpy.trace", "numpy.trace"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_calc_fid", "(", "real_activations", ":", "np", ".", "ndarray", ",", "fake_activations", ":", "np", ".", "ndarray", ")", ":", "\n", "        ", "\"\"\"\n        Method to compute fid score\n        :param real_activations: (np.ndarray) Real activation of the shape [samples, 2048]\n        :param fake_activations: (np.ndarray) Fake activation of the shape [samples, 2048]\n        :return: (float) FID score\n        \"\"\"", "\n", "# Calc statistics of real activations", "\n", "real_mu", "=", "np", ".", "mean", "(", "real_activations", ",", "axis", "=", "0", ")", "\n", "real_cov", "=", "np", ".", "cov", "(", "real_activations", ",", "rowvar", "=", "False", ")", "\n", "# Calc statistics of fake activations", "\n", "fake_mu", "=", "np", ".", "mean", "(", "fake_activations", ",", "axis", "=", "0", ")", "\n", "fake_cov", "=", "np", ".", "cov", "(", "fake_activations", ",", "rowvar", "=", "False", ")", "\n", "# Check that mu and cov arrays of real and fake have the same shapes", "\n", "assert", "real_mu", ".", "shape", "==", "fake_mu", ".", "shape", "\n", "assert", "real_cov", ".", "shape", "==", "fake_cov", ".", "shape", "\n", "# Calc diff of mu real and fake", "\n", "diff", "=", "real_mu", "-", "fake_mu", "\n", "# Square diff", "\n", "diff_squared", "=", "diff", "@", "diff", "\n", "# Calc cov mean of fake and real cov", "\n", "cov_mean", ",", "_", "=", "sqrtm", "(", "real_cov", "@", "fake_cov", ",", "disp", "=", "False", ")", "\n", "# Remove imaginary path of cov mean", "\n", "if", "np", ".", "iscomplexobj", "(", "cov_mean", ")", ":", "\n", "            ", "cov_mean", "=", "cov_mean", ".", "real", "\n", "# Calc FID", "\n", "", "fid", "=", "diff_squared", "+", "np", ".", "trace", "(", "real_cov", ")", "+", "np", ".", "trace", "(", "fake_cov", ")", "-", "2", "*", "np", ".", "trace", "(", "cov_mean", ")", "\n", "return", "fid", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.FID.__call__": [[221, 359], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "copy.deepcopy.to", "copy.deepcopy.eval", "generator.to", "generator.eval", "range", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "copy.deepcopy.cpu", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "validation_metrics.FID._calc_fid", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "copy.deepcopy", "math.ceil", "misc.get_noise", "generator", "fake_images[].unsqueeze().repeat_interleave", "copy.deepcopy.cpu().unbind", "activations_fake_bf.extend", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "copy.deepcopy", "real_images[].unsqueeze().repeat_interleave", "copy.deepcopy.cpu().unbind", "activations_real_bf.extend", "fake_images[].unsqueeze().repeat_interleave", "fake_images[].unsqueeze().repeat_interleave", "copy.deepcopy.cpu().unbind", "activations_fake_gfp.extend", "copy.deepcopy.cpu().unbind", "activations_fake_rfp.extend", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "validation_metrics.FID._calc_fid", "validation_metrics.FID._calc_fid", "validation_metrics.FID._calc_fid", "validation_metrics.FID._calc_fid", "validation_metrics.FID._calc_fid", "real_images[].unsqueeze().repeat_interleave", "real_images[].unsqueeze().repeat_interleave", "copy.deepcopy.cpu().unbind", "activations_real_gfp.extend", "copy.deepcopy.cpu().unbind", "activations_real_rfp.extend", "len", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "fake_images[].unsqueeze", "copy.deepcopy.cpu", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "real_images[].unsqueeze", "copy.deepcopy.cpu", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "isinstance", "fake_images[].unsqueeze", "fake_images[].unsqueeze", "copy.deepcopy.cpu", "copy.deepcopy.cpu", "real_images[].unsqueeze", "real_images[].unsqueeze", "copy.deepcopy.cpu", "copy.deepcopy.cpu", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "copy.deepcopy.", "copy.deepcopy.", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "copy.deepcopy.", "copy.deepcopy.", "copy.deepcopy.", "copy.deepcopy.", "misc.normalize_m1_1_batch", "misc.normalize_m1_1_batch", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "misc.normalize_m1_1_batch", "misc.normalize_m1_1_batch", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "misc.normalize_m1_1_batch", "misc.normalize_m1_1_batch", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.FID._calc_fid", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.get_noise", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.FID._calc_fid", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.FID._calc_fid", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.FID._calc_fid", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.FID._calc_fid", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.FID._calc_fid", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.normalize_m1_1_batch", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.normalize_m1_1_batch", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.normalize_m1_1_batch", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.normalize_m1_1_batch", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.normalize_m1_1_batch", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.normalize_m1_1_batch"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "__call__", "(", "self", ",", "generator", ":", "Union", "[", "nn", ".", "Module", ",", "nn", ".", "DataParallel", "]", ",", "\n", "dataset", ":", "DataLoader", ")", "->", "Union", "[", "Tuple", "[", "float", ",", "float", ",", "float", "]", ",", "Tuple", "[", "float", ",", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        Method to compute FID score\n        :param generator: (Union[nn.Module, nn.DataParallel]) Generator network\n        :return: (Union[Tuple[float, float, float], Tuple[float, float]]) FID scores of bf, gfp and rfp (optional)\n        \"\"\"", "\n", "# Apply data parallel if utilized", "\n", "if", "self", ".", "data_parallel", ":", "\n", "            ", "inception_net", "=", "nn", ".", "DataParallel", "(", "copy", ".", "deepcopy", "(", "self", ".", "model", ")", ")", "\n", "", "else", ":", "\n", "            ", "inception_net", "=", "copy", ".", "deepcopy", "(", "self", ".", "model", ")", "\n", "# Inception net to device", "\n", "", "inception_net", "=", "inception_net", ".", "to", "(", "self", ".", "device", ")", "\n", "# Ensure eval mode is present", "\n", "inception_net", ".", "eval", "(", ")", "\n", "# Generate activation of real samples if not already computed!", "\n", "if", "self", ".", "activations_real_bf", "is", "None", ":", "\n", "            ", "activations_real_bf", "=", "[", "]", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "                ", "activations_real_gfp", "=", "[", "]", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "                ", "activations_real_rfp", "=", "[", "]", "\n", "", "for", "real_images", "in", "dataset", ":", "\n", "# Get random bf images [batch size, 3, height, width]", "\n", "                ", "real_images_bf", "=", "real_images", "[", ":", ",", "0", ",", "torch", ".", "randint", "(", "0", ",", "real_images", ".", "shape", "[", "2", "]", ",", "(", "1", ",", ")", ")", "]", ".", "unsqueeze", "(", "\n", "dim", "=", "1", ")", ".", "repeat_interleave", "(", "dim", "=", "1", ",", "repeats", "=", "3", ")", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "# Get random gfp images [batch size, 3, height, width]", "\n", "                    ", "real_images_gfp", "=", "real_images", "[", ":", ",", "1", ",", "torch", ".", "randint", "(", "0", ",", "real_images", ".", "shape", "[", "2", "]", ",", "(", "1", ",", ")", ")", "]", ".", "unsqueeze", "(", "\n", "dim", "=", "1", ")", ".", "repeat_interleave", "(", "dim", "=", "1", ",", "repeats", "=", "3", ")", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "# Get random rfp images [batch size, 3, height, width]", "\n", "                    ", "real_images_rfp", "=", "real_images", "[", ":", ",", "2", ",", "torch", ".", "randint", "(", "0", ",", "real_images", ".", "shape", "[", "2", "]", ",", "(", "1", ",", ")", ")", "]", ".", "unsqueeze", "(", "\n", "dim", "=", "1", ")", ".", "repeat_interleave", "(", "dim", "=", "1", ",", "repeats", "=", "3", ")", "\n", "# Make predictions for bf images", "\n", "", "activation_real_bf", "=", "inception_net", "(", "misc", ".", "normalize_m1_1_batch", "(", "real_images_bf", ")", "[", ":", ",", ":", ",", "0", "]", ")", ".", "cpu", "(", ")", ".", "unbind", "(", "\n", "dim", "=", "0", ")", "\n", "# Save bf activation", "\n", "activations_real_bf", ".", "extend", "(", "activation_real_bf", ")", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "# Make predictions for gfp images", "\n", "                    ", "activation_real_gfp", "=", "inception_net", "(", "\n", "misc", ".", "normalize_m1_1_batch", "(", "real_images_gfp", ")", "[", ":", ",", ":", ",", "0", "]", ")", ".", "cpu", "(", ")", ".", "unbind", "(", "\n", "dim", "=", "0", ")", "\n", "# Save bf activation", "\n", "activations_real_gfp", ".", "extend", "(", "activation_real_gfp", ")", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "# Make predictions for rfp images", "\n", "                    ", "activation_real_rfp", "=", "inception_net", "(", "\n", "misc", ".", "normalize_m1_1_batch", "(", "real_images_rfp", ")", "[", ":", ",", ":", ",", "0", "]", ")", ".", "cpu", "(", ")", ".", "unbind", "(", "dim", "=", "0", ")", "\n", "# Save bf activation", "\n", "activations_real_rfp", ".", "extend", "(", "activation_real_rfp", ")", "\n", "# Check if number of samples is reached", "\n", "", "if", "len", "(", "activations_real_bf", ")", ">=", "self", ".", "data_samples", ":", "\n", "# Remove to many activations", "\n", "                    ", "self", ".", "activations_real_bf", ":", "np", ".", "ndarray", "=", "torch", ".", "stack", "(", "activations_real_bf", "[", ":", "self", ".", "data_samples", "]", ",", "\n", "dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "                        ", "self", ".", "activations_real_gfp", ":", "np", ".", "ndarray", "=", "torch", ".", "stack", "(", "activations_real_gfp", "[", ":", "self", ".", "data_samples", "]", ",", "\n", "dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "                        ", "self", ".", "activations_real_rfp", ":", "np", ".", "ndarray", "=", "torch", ".", "stack", "(", "activations_real_rfp", "[", ":", "self", ".", "data_samples", "]", ",", "\n", "dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "# Break for loop", "\n", "", "break", "\n", "# Generator to device", "\n", "", "", "", "generator", ".", "to", "(", "self", ".", "device", ")", "\n", "# Generator into eval mode", "\n", "generator", ".", "eval", "(", ")", "\n", "# Generate activation of real samples", "\n", "activations_fake_bf", "=", "[", "]", "\n", "activations_fake_gfp", "=", "[", "]", "\n", "if", "not", "self", ".", "no_rfp", ":", "\n", "            ", "activations_fake_rfp", "=", "[", "]", "\n", "", "for", "_", "in", "range", "(", "math", ".", "ceil", "(", "self", ".", "data_samples", "/", "self", ".", "batch_size", ")", ")", ":", "\n", "# Generate noise input", "\n", "            ", "noise_input", "=", "misc", ".", "get_noise", "(", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "latent_dimension", "=", "generator", ".", "module", ".", "latent_dimensions", "\n", "if", "isinstance", "(", "generator", ",", "nn", ".", "DataParallel", ")", "else", "generator", ".", "latent_dimensions", ",", "\n", "p_mixed_noise", "=", "0.0", ",", "\n", "device", "=", "self", ".", "device", "\n", ")", "\n", "# Predict fake images", "\n", "fake_images", "=", "generator", "(", "input", "=", "noise_input", ")", "\n", "# Get random bf images [batch size, 3, height, width]", "\n", "fake_images_bf", "=", "fake_images", "[", ":", ",", "0", ",", "torch", ".", "randint", "(", "0", ",", "fake_images", ".", "shape", "[", "2", "]", ",", "(", "1", ",", ")", ")", "]", ".", "unsqueeze", "(", "\n", "dim", "=", "1", ")", ".", "repeat_interleave", "(", "dim", "=", "1", ",", "repeats", "=", "3", ")", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "# Get random gfp images [batch size, 3, height, width]", "\n", "                ", "fake_images_gfp", "=", "fake_images", "[", ":", ",", "1", ",", "torch", ".", "randint", "(", "0", ",", "fake_images", ".", "shape", "[", "2", "]", ",", "(", "1", ",", ")", ")", "]", ".", "unsqueeze", "(", "\n", "dim", "=", "1", ")", ".", "repeat_interleave", "(", "dim", "=", "1", ",", "repeats", "=", "3", ")", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "# Get random rfp images [batch size, 3, height, width]", "\n", "                ", "fake_images_rfp", "=", "fake_images", "[", ":", ",", "2", ",", "torch", ".", "randint", "(", "0", ",", "fake_images", ".", "shape", "[", "2", "]", ",", "(", "1", ",", ")", ")", "]", ".", "unsqueeze", "(", "\n", "dim", "=", "1", ")", ".", "repeat_interleave", "(", "dim", "=", "1", ",", "repeats", "=", "3", ")", "\n", "# Make predictions for bf images", "\n", "", "activation_fake_bf", "=", "inception_net", "(", "misc", ".", "normalize_m1_1_batch", "(", "fake_images_bf", ")", "[", ":", ",", ":", ",", "0", "]", ")", ".", "cpu", "(", ")", ".", "unbind", "(", "dim", "=", "0", ")", "\n", "# Save bf activation", "\n", "activations_fake_bf", ".", "extend", "(", "activation_fake_bf", ")", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "# Make predictions for gfp images", "\n", "                ", "activation_fake_gfp", "=", "inception_net", "(", "misc", ".", "normalize_m1_1_batch", "(", "fake_images_gfp", ")", "[", ":", ",", ":", ",", "0", "]", ")", ".", "cpu", "(", ")", ".", "unbind", "(", "\n", "dim", "=", "0", ")", "\n", "# Save bf activation", "\n", "activations_fake_gfp", ".", "extend", "(", "activation_fake_gfp", ")", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "# Make predictions for rfp images", "\n", "                ", "activation_fake_rfp", "=", "inception_net", "(", "misc", ".", "normalize_m1_1_batch", "(", "fake_images_rfp", ")", "[", ":", ",", ":", ",", "0", "]", ")", ".", "cpu", "(", ")", ".", "unbind", "(", "\n", "dim", "=", "0", ")", "\n", "# Save bf activation", "\n", "activations_fake_rfp", ".", "extend", "(", "activation_fake_rfp", ")", "\n", "# Remove to many activations", "\n", "", "", "activations_fake_bf", ":", "np", ".", "ndarray", "=", "torch", ".", "stack", "(", "activations_fake_bf", "[", ":", "self", ".", "data_samples", "]", ",", "\n", "dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "            ", "activations_fake_gfp", ":", "np", ".", "ndarray", "=", "torch", ".", "stack", "(", "activations_fake_gfp", "[", ":", "self", ".", "data_samples", "]", ",", "\n", "dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "            ", "activations_fake_rfp", ":", "np", ".", "ndarray", "=", "torch", ".", "stack", "(", "activations_fake_rfp", "[", ":", "self", ".", "data_samples", "]", ",", "\n", "dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "# Model to cpu", "\n", "", "inception_net", ".", "cpu", "(", ")", "\n", "# Remove model", "\n", "del", "inception_net", "\n", "# Empty cuda cache", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "# Calc fid score for bf and gfp", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "            ", "return", "self", ".", "_calc_fid", "(", "self", ".", "activations_real_bf", ",", "activations_fake_bf", ")", ",", "self", ".", "_calc_fid", "(", "self", ".", "activations_real_gfp", ",", "activations_fake_gfp", ")", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "            ", "return", "self", ".", "_calc_fid", "(", "self", ".", "activations_real_bf", ",", "activations_fake_bf", ")", ",", "self", ".", "_calc_fid", "(", "self", ".", "activations_real_gfp", ",", "activations_fake_gfp", ")", ",", "self", ".", "_calc_fid", "(", "self", ".", "activations_real_rfp", ",", "activations_fake_rfp", ")", "\n", "", "return", "self", ".", "_calc_fid", "(", "self", ".", "activations_real_bf", ",", "activations_fake_bf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.FVD.__init__": [[367, 399], ["InceptionI3d().cpu", "validation_metrics.FVD.model.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "validation_metrics.InceptionI3d"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "device", ":", "Union", "[", "str", ",", "torch", ".", "device", "]", "=", "\"cuda\"", ",", "\n", "data_parallel", ":", "bool", "=", "True", ",", "batch_size", ":", "int", "=", "1", ",", "\n", "data_samples", ":", "int", "=", "5000", ",", "no_rfp", ":", "bool", "=", "False", ",", "\n", "no_gfp", ":", "bool", "=", "False", ",", "\n", "network_path", ":", "str", "=", "\"multi_stylegan/pretrained_i3d/rgb_imagenet.pt\"", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param device: (Union[str, torch.device]) Device to be utilized\n        :param data_parallel: (bool) If true data parallel is used\n        :param batch_size: (bool) Batch size to be utilized\n        :param data_samples: (int) Number of real and fake sample to be utilized during evaluation\n        :param no_rfp: (bool) If true no RFP channel is utilized\n        :param no_rfp: (bool) If true no GFP channel is utilized\n        :param network_path: (str) Path to trained 3D incrption net\n        \"\"\"", "\n", "# Save parameters", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "data_parallel", "=", "data_parallel", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "data_samples", "=", "data_samples", "\n", "self", ".", "no_rfp", "=", "no_rfp", "\n", "self", ".", "no_gfp", "=", "no_gfp", "\n", "# Init inception net", "\n", "self", ".", "model", "=", "InceptionI3d", "(", "num_classes", "=", "400", ",", "in_channels", "=", "3", ")", ".", "cpu", "(", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "network_path", ")", ")", "\n", "self", ".", "model", ".", "VALID_ENDPOINTS", "=", "self", ".", "model", ".", "VALID_ENDPOINTS", "[", ":", "-", "2", "]", "\n", "# Init activations", "\n", "self", ".", "activations_real_bf", ":", "np", ".", "ndarray", "=", "None", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "            ", "self", ".", "activations_real_gfp", ":", "np", ".", "ndarray", "=", "None", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "            ", "self", ".", "activations_real_rfp", ":", "np", ".", "ndarray", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.FVD._calc_fvd": [[400, 429], ["numpy.mean", "numpy.mean", "numpy.cov", "numpy.cov", "numpy.mean", "numpy.mean", "numpy.cov", "numpy.cov", "scipy.linalg.sqrtm", "numpy.iscomplexobj", "numpy.iscomplexobj", "numpy.trace", "numpy.trace", "numpy.trace", "numpy.trace", "numpy.trace", "numpy.trace"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_calc_fvd", "(", "real_activations", ":", "np", ".", "ndarray", ",", "fake_activations", ":", "np", ".", "ndarray", ")", ":", "\n", "        ", "\"\"\"\n        Method to compute fvd score\n        :param real_activations: (np.ndarray) Real activation of the shape [samples, 2048]\n        :param fake_activations: (np.ndarray) Fake activation of the shape [samples, 2048]\n        :return: (float) FID score\n        \"\"\"", "\n", "# Calc statistics of real activations", "\n", "real_mu", "=", "np", ".", "mean", "(", "real_activations", ",", "axis", "=", "0", ")", "\n", "real_cov", "=", "np", ".", "cov", "(", "real_activations", ",", "rowvar", "=", "False", ")", "\n", "# Calc statistics of fake activations", "\n", "fake_mu", "=", "np", ".", "mean", "(", "fake_activations", ",", "axis", "=", "0", ")", "\n", "fake_cov", "=", "np", ".", "cov", "(", "fake_activations", ",", "rowvar", "=", "False", ")", "\n", "# Check that mu and cov arrays of real and fake have the same shapes", "\n", "assert", "real_mu", ".", "shape", "==", "fake_mu", ".", "shape", "\n", "assert", "real_cov", ".", "shape", "==", "fake_cov", ".", "shape", "\n", "# Calc diff of mu real and fake", "\n", "diff", "=", "real_mu", "-", "fake_mu", "\n", "# Square diff", "\n", "diff_squared", "=", "diff", "@", "diff", "\n", "# Calc cov mean of fake and real cov", "\n", "cov_mean", ",", "_", "=", "sqrtm", "(", "real_cov", "@", "fake_cov", ",", "disp", "=", "False", ")", "\n", "# Remove imaginary path of cov mean", "\n", "if", "np", ".", "iscomplexobj", "(", "cov_mean", ")", ":", "\n", "            ", "cov_mean", "=", "cov_mean", ".", "real", "\n", "# Calc FID", "\n", "", "fid", "=", "diff_squared", "+", "np", ".", "trace", "(", "real_cov", ")", "+", "np", ".", "trace", "(", "fake_cov", ")", "-", "2", "*", "np", ".", "trace", "(", "cov_mean", ")", "\n", "return", "fid", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.FVD.__call__": [[430, 569], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "copy.deepcopy.to", "copy.deepcopy.eval", "generator.to", "generator.eval", "range", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "copy.deepcopy.cpu", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "validation_metrics.FVD._calc_fvd", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "copy.deepcopy", "math.ceil", "misc.get_noise", "generator", "fake_images[].unsqueeze().repeat_interleave", "copy.deepcopy.cpu().flatten().unbind", "activations_fake_bf.extend", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "copy.deepcopy", "real_images[].unsqueeze().repeat_interleave", "copy.deepcopy.cpu().flatten().unbind", "activations_real_bf.extend", "fake_images[].unsqueeze().repeat_interleave", "fake_images[].unsqueeze().repeat_interleave", "copy.deepcopy.cpu().flatten().unbind", "activations_fake_gfp.extend", "copy.deepcopy.cpu().flatten().unbind", "activations_fake_rfp.extend", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "validation_metrics.FVD._calc_fvd", "validation_metrics.FVD._calc_fvd", "validation_metrics.FVD._calc_fvd", "validation_metrics.FVD._calc_fvd", "validation_metrics.FVD._calc_fvd", "real_images[].unsqueeze().repeat_interleave", "real_images[].unsqueeze().repeat_interleave", "copy.deepcopy.cpu().flatten().unbind", "activations_real_gfp.extend", "copy.deepcopy.cpu().flatten().unbind", "activations_real_rfp.extend", "len", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "fake_images[].unsqueeze", "copy.deepcopy.cpu().flatten", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "real_images[].unsqueeze", "copy.deepcopy.cpu().flatten", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "torch.stack().numpy", "isinstance", "fake_images[].unsqueeze", "fake_images[].unsqueeze", "copy.deepcopy.cpu().flatten", "copy.deepcopy.cpu().flatten", "real_images[].unsqueeze", "real_images[].unsqueeze", "copy.deepcopy.cpu().flatten", "copy.deepcopy.cpu().flatten", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "copy.deepcopy.cpu", "copy.deepcopy.cpu", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "copy.deepcopy.cpu", "copy.deepcopy.cpu", "copy.deepcopy.cpu", "copy.deepcopy.cpu", "copy.deepcopy.", "copy.deepcopy.", "misc.normalize_m1_1_batch", "copy.deepcopy.", "copy.deepcopy.", "misc.normalize_m1_1_batch", "copy.deepcopy.", "copy.deepcopy.", "misc.normalize_m1_1_batch", "misc.normalize_m1_1_batch", "misc.normalize_m1_1_batch", "misc.normalize_m1_1_batch"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.FVD._calc_fvd", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.get_noise", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.FVD._calc_fvd", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.FVD._calc_fvd", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.FVD._calc_fvd", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.FVD._calc_fvd", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.FVD._calc_fvd", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.normalize_m1_1_batch", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.normalize_m1_1_batch", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.normalize_m1_1_batch", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.normalize_m1_1_batch", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.normalize_m1_1_batch", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.normalize_m1_1_batch"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "__call__", "(", "self", ",", "generator", ":", "Union", "[", "nn", ".", "Module", ",", "nn", ".", "DataParallel", "]", ",", "dataset", ":", "DataLoader", ")", "->", "Union", "[", "\n", "float", ",", "Tuple", "[", "float", ",", "float", "]", ",", "Tuple", "[", "float", ",", "float", ",", "float", "]", "]", ":", "\n", "        ", "\"\"\"\n        Method to compute FID score\n        :param generator: (Union[nn.Module, nn.DataParallel]) Generator network\n        :return: (Tuple[float, float, float]) FID scores for bf, gfp and rfp\n        \"\"\"", "\n", "# Apply data parallel if utilized", "\n", "if", "self", ".", "data_parallel", ":", "\n", "            ", "inception_net", "=", "nn", ".", "DataParallel", "(", "copy", ".", "deepcopy", "(", "self", ".", "model", ")", ")", "\n", "", "else", ":", "\n", "            ", "inception_net", "=", "copy", ".", "deepcopy", "(", "self", ".", "model", ")", "\n", "# Inception net to device", "\n", "", "inception_net", "=", "inception_net", ".", "to", "(", "self", ".", "device", ")", "\n", "# Ensure eval mode is present", "\n", "inception_net", ".", "eval", "(", ")", "\n", "# Generate activation of real samples if not already computed!", "\n", "if", "self", ".", "activations_real_bf", "is", "None", ":", "\n", "            ", "activations_real_bf", "=", "[", "]", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "                ", "activations_real_gfp", "=", "[", "]", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "                ", "activations_real_rfp", "=", "[", "]", "\n", "", "for", "real_images", "in", "dataset", ":", "\n", "# Get random bf images [batch size, 3, time steps, height, width]", "\n", "                ", "real_images_bf", "=", "real_images", "[", ":", ",", "0", "]", ".", "unsqueeze", "(", "\n", "dim", "=", "1", ")", ".", "repeat_interleave", "(", "dim", "=", "1", ",", "repeats", "=", "3", ")", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "# Get random gfp images [batch size, 3, time steps, height, width]", "\n", "                    ", "real_images_gfp", "=", "real_images", "[", ":", ",", "1", "]", ".", "unsqueeze", "(", "\n", "dim", "=", "1", ")", ".", "repeat_interleave", "(", "dim", "=", "1", ",", "repeats", "=", "3", ")", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "# Get random rfp images [batch size, 3, time steps, height, width]", "\n", "                    ", "real_images_rfp", "=", "real_images", "[", ":", ",", "2", "]", ".", "unsqueeze", "(", "\n", "dim", "=", "1", ")", ".", "repeat_interleave", "(", "dim", "=", "1", ",", "repeats", "=", "3", ")", "\n", "# Make predictions for bf images", "\n", "", "activation_real_bf", "=", "inception_net", "(", "\n", "misc", ".", "normalize_m1_1_batch", "(", "real_images_bf", ")", ")", ".", "cpu", "(", ")", ".", "flatten", "(", "start_dim", "=", "1", ")", ".", "unbind", "(", "dim", "=", "0", ")", "\n", "# Save bf activation", "\n", "activations_real_bf", ".", "extend", "(", "activation_real_bf", ")", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "# Make predictions for gfp images", "\n", "                    ", "activation_real_gfp", "=", "inception_net", "(", "\n", "misc", ".", "normalize_m1_1_batch", "(", "real_images_gfp", ")", ")", ".", "cpu", "(", ")", ".", "flatten", "(", "start_dim", "=", "1", ")", ".", "unbind", "(", "dim", "=", "0", ")", "\n", "# Save bf activation", "\n", "activations_real_gfp", ".", "extend", "(", "activation_real_gfp", ")", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "# Make predictions for rfp images", "\n", "                    ", "activation_real_rfp", "=", "inception_net", "(", "\n", "misc", ".", "normalize_m1_1_batch", "(", "real_images_rfp", ")", ")", ".", "cpu", "(", ")", ".", "flatten", "(", "start_dim", "=", "1", ")", ".", "unbind", "(", "dim", "=", "0", ")", "\n", "# Save bf activation", "\n", "activations_real_rfp", ".", "extend", "(", "activation_real_rfp", ")", "\n", "# Check if number of samples is reached", "\n", "", "if", "len", "(", "activations_real_bf", ")", ">=", "self", ".", "data_samples", ":", "\n", "# Remove to many activations", "\n", "                    ", "self", ".", "activations_real_bf", ":", "np", ".", "ndarray", "=", "torch", ".", "stack", "(", "activations_real_bf", "[", ":", "self", ".", "data_samples", "]", ",", "\n", "dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "                        ", "self", ".", "activations_real_gfp", ":", "np", ".", "ndarray", "=", "torch", ".", "stack", "(", "activations_real_gfp", "[", ":", "self", ".", "data_samples", "]", ",", "\n", "dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "                        ", "self", ".", "activations_real_rfp", ":", "np", ".", "ndarray", "=", "torch", ".", "stack", "(", "activations_real_rfp", "[", ":", "self", ".", "data_samples", "]", ",", "\n", "dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "# Break for loop", "\n", "", "break", "\n", "# Generator to device", "\n", "", "", "", "generator", ".", "to", "(", "self", ".", "device", ")", "\n", "# Generator into eval mode", "\n", "generator", ".", "eval", "(", ")", "\n", "# Generate activation of real samples", "\n", "activations_fake_bf", "=", "[", "]", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "            ", "activations_fake_gfp", "=", "[", "]", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "            ", "activations_fake_rfp", "=", "[", "]", "\n", "", "for", "_", "in", "range", "(", "math", ".", "ceil", "(", "self", ".", "data_samples", "/", "self", ".", "batch_size", ")", ")", ":", "\n", "# Generate noise input", "\n", "            ", "noise_input", "=", "misc", ".", "get_noise", "(", "\n", "batch_size", "=", "self", ".", "batch_size", ",", "\n", "latent_dimension", "=", "generator", ".", "module", ".", "latent_dimensions", "\n", "if", "isinstance", "(", "generator", ",", "nn", ".", "DataParallel", ")", "else", "generator", ".", "latent_dimensions", ",", "\n", "p_mixed_noise", "=", "0.0", ",", "\n", "device", "=", "self", ".", "device", "\n", ")", "\n", "# Predict fake images", "\n", "fake_images", "=", "generator", "(", "input", "=", "noise_input", ")", "\n", "# Get random bf images [batch size, 3, height, width]", "\n", "fake_images_bf", "=", "fake_images", "[", ":", ",", "0", "]", ".", "unsqueeze", "(", "\n", "dim", "=", "1", ")", ".", "repeat_interleave", "(", "dim", "=", "1", ",", "repeats", "=", "3", ")", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "# Get random gfp images [batch size, 3, height, width]", "\n", "                ", "fake_images_gfp", "=", "fake_images", "[", ":", ",", "1", "]", ".", "unsqueeze", "(", "\n", "dim", "=", "1", ")", ".", "repeat_interleave", "(", "dim", "=", "1", ",", "repeats", "=", "3", ")", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "# Get random rfp images [batch size, 3, height, width]", "\n", "                ", "fake_images_rfp", "=", "fake_images", "[", ":", ",", "2", "]", ".", "unsqueeze", "(", "\n", "dim", "=", "1", ")", ".", "repeat_interleave", "(", "dim", "=", "1", ",", "repeats", "=", "3", ")", "\n", "# Make predictions for bf images", "\n", "", "activation_fake_bf", "=", "inception_net", "(", "\n", "(", "misc", ".", "normalize_m1_1_batch", "(", "fake_images_bf", ")", ")", ")", ".", "cpu", "(", ")", ".", "flatten", "(", "start_dim", "=", "1", ")", ".", "unbind", "(", "dim", "=", "0", ")", "\n", "# Save bf activation", "\n", "activations_fake_bf", ".", "extend", "(", "activation_fake_bf", ")", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "# Make predictions for gfp images", "\n", "                ", "activation_fake_gfp", "=", "inception_net", "(", "\n", "(", "misc", ".", "normalize_m1_1_batch", "(", "fake_images_gfp", ")", ")", ")", ".", "cpu", "(", ")", ".", "flatten", "(", "start_dim", "=", "1", ")", ".", "unbind", "(", "dim", "=", "0", ")", "\n", "# Save bf activation", "\n", "activations_fake_gfp", ".", "extend", "(", "activation_fake_gfp", ")", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "# Make predictions for gfp images", "\n", "                ", "activation_fake_rfp", "=", "inception_net", "(", "\n", "(", "misc", ".", "normalize_m1_1_batch", "(", "fake_images_rfp", ")", ")", ")", ".", "cpu", "(", ")", ".", "flatten", "(", "start_dim", "=", "1", ")", ".", "unbind", "(", "dim", "=", "0", ")", "\n", "# Save bf activation", "\n", "activations_fake_rfp", ".", "extend", "(", "activation_fake_rfp", ")", "\n", "# Remove to many activations", "\n", "", "", "activations_fake_bf", ":", "np", ".", "ndarray", "=", "torch", ".", "stack", "(", "activations_fake_bf", "[", ":", "self", ".", "data_samples", "]", ",", "\n", "dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "            ", "activations_fake_gfp", ":", "np", ".", "ndarray", "=", "torch", ".", "stack", "(", "activations_fake_gfp", "[", ":", "self", ".", "data_samples", "]", ",", "\n", "dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "            ", "activations_fake_rfp", ":", "np", ".", "ndarray", "=", "torch", ".", "stack", "(", "activations_fake_rfp", "[", ":", "self", ".", "data_samples", "]", ",", "\n", "dim", "=", "0", ")", ".", "numpy", "(", ")", "\n", "# Model to cpu", "\n", "", "inception_net", ".", "cpu", "(", ")", "\n", "# Remove model", "\n", "del", "inception_net", "\n", "# Empty cuda cache", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "# Calc fid score for bf and gfp", "\n", "if", "not", "self", ".", "no_gfp", ":", "\n", "            ", "return", "self", ".", "_calc_fvd", "(", "self", ".", "activations_real_bf", ",", "activations_fake_bf", ")", ",", "self", ".", "_calc_fvd", "(", "self", ".", "activations_real_gfp", ",", "activations_fake_gfp", ")", "\n", "", "if", "not", "self", ".", "no_rfp", ":", "\n", "            ", "return", "self", ".", "_calc_fvd", "(", "self", ".", "activations_real_bf", ",", "activations_fake_bf", ")", ",", "self", ".", "_calc_fvd", "(", "self", ".", "activations_real_gfp", ",", "activations_fake_gfp", ")", ",", "self", ".", "_calc_fvd", "(", "self", ".", "activations_real_rfp", ",", "activations_fake_rfp", ")", "\n", "", "return", "self", ".", "_calc_fvd", "(", "self", ".", "activations_real_bf", ",", "activations_fake_bf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.InceptionNetworkFID.__init__": [[576, 581], ["torch.Module.__init__", "torchvision.models.inception_v3"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "# Call super constructor", "\n", "        ", "super", "(", "InceptionNetworkFID", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Init pre trained inception net", "\n", "self", ".", "inception_net", "=", "torchvision", ".", "models", ".", "inception_v3", "(", "pretrained", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.InceptionNetworkFID.forward": [[582, 616], ["validation_metrics.InceptionNetworkFID.inception_net.Conv2d_1a_3x3", "validation_metrics.InceptionNetworkFID.inception_net.Conv2d_2a_3x3", "validation_metrics.InceptionNetworkFID.inception_net.Conv2d_2b_3x3", "validation_metrics.InceptionNetworkFID.inception_net.maxpool1", "validation_metrics.InceptionNetworkFID.inception_net.Conv2d_3b_1x1", "validation_metrics.InceptionNetworkFID.inception_net.Conv2d_4a_3x3", "validation_metrics.InceptionNetworkFID.inception_net.maxpool2", "validation_metrics.InceptionNetworkFID.inception_net.Mixed_5b", "validation_metrics.InceptionNetworkFID.inception_net.Mixed_5c", "validation_metrics.InceptionNetworkFID.inception_net.Mixed_5d", "validation_metrics.InceptionNetworkFID.inception_net.Mixed_6a", "validation_metrics.InceptionNetworkFID.inception_net.Mixed_6b", "validation_metrics.InceptionNetworkFID.inception_net.Mixed_6c", "validation_metrics.InceptionNetworkFID.inception_net.Mixed_6d", "validation_metrics.InceptionNetworkFID.inception_net.Mixed_6e", "validation_metrics.InceptionNetworkFID.inception_net.Mixed_7a", "validation_metrics.InceptionNetworkFID.inception_net.Mixed_7b", "validation_metrics.InceptionNetworkFID.inception_net.Mixed_7c", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "torch.adaptive_avg_pool2d", "output.view.view.view", "kornia.resize"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward method\n        :param input: (torch.Tensor) Input tensor normalized to a range of [-1, 1]\n        :return: (torch.Tensor) Rescaled intermediate output of layer 7c of the inception net\n        \"\"\"", "\n", "# Reshape input if needed", "\n", "if", "input", ".", "shape", "[", "-", "1", "]", "!=", "299", "or", "input", ".", "shape", "[", "-", "2", "]", "!=", "299", ":", "\n", "            ", "input", "=", "kornia", ".", "resize", "(", "input", ",", "size", "=", "(", "299", ",", "299", ")", ",", "interpolation", "=", "'bilinear'", ",", "antialias", "=", "True", ")", "\n", "# input = nn.functional.interpolate(input, size=(299, 299), mode='bilinear', align_corners=False)", "\n", "# Forward pass of inception to get produce output", "\n", "", "x", "=", "self", ".", "inception_net", ".", "Conv2d_1a_3x3", "(", "input", ")", "\n", "x", "=", "self", ".", "inception_net", ".", "Conv2d_2a_3x3", "(", "x", ")", "\n", "x", "=", "self", ".", "inception_net", ".", "Conv2d_2b_3x3", "(", "x", ")", "\n", "x", "=", "self", ".", "inception_net", ".", "maxpool1", "(", "x", ")", "\n", "x", "=", "self", ".", "inception_net", ".", "Conv2d_3b_1x1", "(", "x", ")", "\n", "x", "=", "self", ".", "inception_net", ".", "Conv2d_4a_3x3", "(", "x", ")", "\n", "x", "=", "self", ".", "inception_net", ".", "maxpool2", "(", "x", ")", "\n", "x", "=", "self", ".", "inception_net", ".", "Mixed_5b", "(", "x", ")", "\n", "x", "=", "self", ".", "inception_net", ".", "Mixed_5c", "(", "x", ")", "\n", "x", "=", "self", ".", "inception_net", ".", "Mixed_5d", "(", "x", ")", "\n", "x", "=", "self", ".", "inception_net", ".", "Mixed_6a", "(", "x", ")", "\n", "x", "=", "self", ".", "inception_net", ".", "Mixed_6b", "(", "x", ")", "\n", "x", "=", "self", ".", "inception_net", ".", "Mixed_6c", "(", "x", ")", "\n", "x", "=", "self", ".", "inception_net", ".", "Mixed_6d", "(", "x", ")", "\n", "x", "=", "self", ".", "inception_net", ".", "Mixed_6e", "(", "x", ")", "\n", "x", "=", "self", ".", "inception_net", ".", "Mixed_7a", "(", "x", ")", "\n", "x", "=", "self", ".", "inception_net", ".", "Mixed_7b", "(", "x", ")", "\n", "x", "=", "self", ".", "inception_net", ".", "Mixed_7c", "(", "x", ")", "\n", "# Get intermediate output and downscale tensor to get a tensor of shape (batch size, 2024, 1, 1)", "\n", "output", "=", "F", ".", "adaptive_avg_pool2d", "(", "x", ",", "(", "1", ",", "1", ")", ")", "\n", "# Reshape output to shape (batch size, 2024)", "\n", "output", "=", "output", ".", "view", "(", "input", ".", "shape", "[", "0", "]", ",", "2048", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.MaxPool3dSamePadding.compute_pad": [[633, 638], ["max", "max"], "methods", ["None"], ["    ", "def", "compute_pad", "(", "self", ",", "dim", ",", "s", ")", ":", "\n", "        ", "if", "s", "%", "self", ".", "stride", "[", "dim", "]", "==", "0", ":", "\n", "            ", "return", "max", "(", "self", ".", "kernel_size", "[", "dim", "]", "-", "self", ".", "stride", "[", "dim", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "return", "max", "(", "self", ".", "kernel_size", "[", "dim", "]", "-", "(", "s", "%", "self", ".", "stride", "[", "dim", "]", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.MaxPool3dSamePadding.forward": [[639, 664], ["torch.pad.size", "numpy.ceil", "numpy.ceil", "numpy.ceil", "numpy.ceil", "numpy.ceil", "numpy.ceil", "validation_metrics.MaxPool3dSamePadding.compute_pad", "validation_metrics.MaxPool3dSamePadding.compute_pad", "validation_metrics.MaxPool3dSamePadding.compute_pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "super().forward", "float", "float", "float", "float", "float", "float"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.Unit3D.compute_pad", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.Unit3D.compute_pad", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.Unit3D.compute_pad", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.upfirdn2d.UpFirDn2d.forward"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# compute 'same' padding", "\n", "        ", "(", "batch", ",", "channel", ",", "t", ",", "h", ",", "w", ")", "=", "x", ".", "size", "(", ")", "\n", "# print t,h,w", "\n", "out_t", "=", "np", ".", "ceil", "(", "float", "(", "t", ")", "/", "float", "(", "self", ".", "stride", "[", "0", "]", ")", ")", "\n", "out_h", "=", "np", ".", "ceil", "(", "float", "(", "h", ")", "/", "float", "(", "self", ".", "stride", "[", "1", "]", ")", ")", "\n", "out_w", "=", "np", ".", "ceil", "(", "float", "(", "w", ")", "/", "float", "(", "self", ".", "stride", "[", "2", "]", ")", ")", "\n", "# print out_t, out_h, out_w", "\n", "pad_t", "=", "self", ".", "compute_pad", "(", "0", ",", "t", ")", "\n", "pad_h", "=", "self", ".", "compute_pad", "(", "1", ",", "h", ")", "\n", "pad_w", "=", "self", ".", "compute_pad", "(", "2", ",", "w", ")", "\n", "# print pad_t, pad_h, pad_w", "\n", "\n", "pad_t_f", "=", "pad_t", "//", "2", "\n", "pad_t_b", "=", "pad_t", "-", "pad_t_f", "\n", "pad_h_f", "=", "pad_h", "//", "2", "\n", "pad_h_b", "=", "pad_h", "-", "pad_h_f", "\n", "pad_w_f", "=", "pad_w", "//", "2", "\n", "pad_w_b", "=", "pad_w", "-", "pad_w_f", "\n", "\n", "pad", "=", "(", "pad_w_f", ",", "pad_w_b", ",", "pad_h_f", ",", "pad_h_b", ",", "pad_t_f", ",", "pad_t_b", ")", "\n", "# print x.size()", "\n", "# print pad", "\n", "x", "=", "F", ".", "pad", "(", "x", ",", "pad", ")", "\n", "return", "super", "(", "MaxPool3dSamePadding", ",", "self", ")", ".", "forward", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.Unit3D.__init__": [[668, 700], ["torch.Module.__init__", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "\n", "output_channels", ",", "\n", "kernel_shape", "=", "(", "1", ",", "1", ",", "1", ")", ",", "\n", "stride", "=", "(", "1", ",", "1", ",", "1", ")", ",", "\n", "padding", "=", "0", ",", "\n", "activation_fn", "=", "F", ".", "relu", ",", "\n", "use_batch_norm", "=", "True", ",", "\n", "use_bias", "=", "False", ",", "\n", "name", "=", "'unit_3d'", ")", ":", "\n", "\n", "        ", "\"\"\"Initializes Unit3D module.\"\"\"", "\n", "super", "(", "Unit3D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "_output_channels", "=", "output_channels", "\n", "self", ".", "_kernel_shape", "=", "kernel_shape", "\n", "self", ".", "_stride", "=", "stride", "\n", "self", ".", "_use_batch_norm", "=", "use_batch_norm", "\n", "self", ".", "_activation_fn", "=", "activation_fn", "\n", "self", ".", "_use_bias", "=", "use_bias", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "padding", "=", "padding", "\n", "\n", "self", ".", "conv3d", "=", "nn", ".", "Conv3d", "(", "in_channels", "=", "in_channels", ",", "\n", "out_channels", "=", "self", ".", "_output_channels", ",", "\n", "kernel_size", "=", "self", ".", "_kernel_shape", ",", "\n", "stride", "=", "self", ".", "_stride", ",", "\n", "padding", "=", "0", ",", "\n", "# we always want padding to be 0 here. We will dynamically pad based on input size in forward function", "\n", "bias", "=", "self", ".", "_use_bias", ")", "\n", "\n", "if", "self", ".", "_use_batch_norm", ":", "\n", "            ", "self", ".", "bn", "=", "nn", ".", "BatchNorm3d", "(", "self", ".", "_output_channels", ",", "eps", "=", "0.001", ",", "momentum", "=", "0.01", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.Unit3D.compute_pad": [[701, 706], ["max", "max"], "methods", ["None"], ["", "", "def", "compute_pad", "(", "self", ",", "dim", ",", "s", ")", ":", "\n", "        ", "if", "s", "%", "self", ".", "_stride", "[", "dim", "]", "==", "0", ":", "\n", "            ", "return", "max", "(", "self", ".", "_kernel_shape", "[", "dim", "]", "-", "self", ".", "_stride", "[", "dim", "]", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "return", "max", "(", "self", ".", "_kernel_shape", "[", "dim", "]", "-", "(", "s", "%", "self", ".", "_stride", "[", "dim", "]", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.Unit3D.forward": [[707, 739], ["validation_metrics.Unit3D.size", "numpy.ceil", "numpy.ceil", "numpy.ceil", "numpy.ceil", "numpy.ceil", "numpy.ceil", "validation_metrics.Unit3D.compute_pad", "validation_metrics.Unit3D.compute_pad", "validation_metrics.Unit3D.compute_pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "validation_metrics.Unit3D.conv3d", "validation_metrics.Unit3D.bn", "validation_metrics.Unit3D._activation_fn", "float", "float", "float", "float", "float", "float"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.Unit3D.compute_pad", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.Unit3D.compute_pad", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.Unit3D.compute_pad"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# compute 'same' padding", "\n", "        ", "(", "batch", ",", "channel", ",", "t", ",", "h", ",", "w", ")", "=", "x", ".", "size", "(", ")", "\n", "# print t,h,w", "\n", "out_t", "=", "np", ".", "ceil", "(", "float", "(", "t", ")", "/", "float", "(", "self", ".", "_stride", "[", "0", "]", ")", ")", "\n", "out_h", "=", "np", ".", "ceil", "(", "float", "(", "h", ")", "/", "float", "(", "self", ".", "_stride", "[", "1", "]", ")", ")", "\n", "out_w", "=", "np", ".", "ceil", "(", "float", "(", "w", ")", "/", "float", "(", "self", ".", "_stride", "[", "2", "]", ")", ")", "\n", "# print out_t, out_h, out_w", "\n", "pad_t", "=", "self", ".", "compute_pad", "(", "0", ",", "t", ")", "\n", "pad_h", "=", "self", ".", "compute_pad", "(", "1", ",", "h", ")", "\n", "pad_w", "=", "self", ".", "compute_pad", "(", "2", ",", "w", ")", "\n", "# print pad_t, pad_h, pad_w", "\n", "\n", "pad_t_f", "=", "pad_t", "//", "2", "\n", "pad_t_b", "=", "pad_t", "-", "pad_t_f", "\n", "pad_h_f", "=", "pad_h", "//", "2", "\n", "pad_h_b", "=", "pad_h", "-", "pad_h_f", "\n", "pad_w_f", "=", "pad_w", "//", "2", "\n", "pad_w_b", "=", "pad_w", "-", "pad_w_f", "\n", "\n", "pad", "=", "(", "pad_w_f", ",", "pad_w_b", ",", "pad_h_f", ",", "pad_h_b", ",", "pad_t_f", ",", "pad_t_b", ")", "\n", "# print x.size()", "\n", "# print pad", "\n", "x", "=", "F", ".", "pad", "(", "x", ",", "pad", ")", "\n", "# print x.size()", "\n", "\n", "x", "=", "self", ".", "conv3d", "(", "x", ")", "\n", "if", "self", ".", "_use_batch_norm", ":", "\n", "            ", "x", "=", "self", ".", "bn", "(", "x", ")", "\n", "", "if", "self", ".", "_activation_fn", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "_activation_fn", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.InceptionModule.__init__": [[742, 760], ["torch.Module.__init__", "validation_metrics.Unit3D", "validation_metrics.Unit3D", "validation_metrics.Unit3D", "validation_metrics.Unit3D", "validation_metrics.Unit3D", "validation_metrics.MaxPool3dSamePadding", "validation_metrics.Unit3D"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "name", ")", ":", "\n", "        ", "super", "(", "InceptionModule", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "b0", "=", "Unit3D", "(", "in_channels", "=", "in_channels", ",", "output_channels", "=", "out_channels", "[", "0", "]", ",", "kernel_shape", "=", "[", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "0", ",", "\n", "name", "=", "name", "+", "'/Branch_0/Conv3d_0a_1x1'", ")", "\n", "self", ".", "b1a", "=", "Unit3D", "(", "in_channels", "=", "in_channels", ",", "output_channels", "=", "out_channels", "[", "1", "]", ",", "kernel_shape", "=", "[", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "0", ",", "\n", "name", "=", "name", "+", "'/Branch_1/Conv3d_0a_1x1'", ")", "\n", "self", ".", "b1b", "=", "Unit3D", "(", "in_channels", "=", "out_channels", "[", "1", "]", ",", "output_channels", "=", "out_channels", "[", "2", "]", ",", "kernel_shape", "=", "[", "3", ",", "3", ",", "3", "]", ",", "\n", "name", "=", "name", "+", "'/Branch_1/Conv3d_0b_3x3'", ")", "\n", "self", ".", "b2a", "=", "Unit3D", "(", "in_channels", "=", "in_channels", ",", "output_channels", "=", "out_channels", "[", "3", "]", ",", "kernel_shape", "=", "[", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "0", ",", "\n", "name", "=", "name", "+", "'/Branch_2/Conv3d_0a_1x1'", ")", "\n", "self", ".", "b2b", "=", "Unit3D", "(", "in_channels", "=", "out_channels", "[", "3", "]", ",", "output_channels", "=", "out_channels", "[", "4", "]", ",", "kernel_shape", "=", "[", "3", ",", "3", ",", "3", "]", ",", "\n", "name", "=", "name", "+", "'/Branch_2/Conv3d_0b_3x3'", ")", "\n", "self", ".", "b3a", "=", "MaxPool3dSamePadding", "(", "kernel_size", "=", "[", "3", ",", "3", ",", "3", "]", ",", "\n", "stride", "=", "(", "1", ",", "1", ",", "1", ")", ",", "padding", "=", "0", ")", "\n", "self", ".", "b3b", "=", "Unit3D", "(", "in_channels", "=", "in_channels", ",", "output_channels", "=", "out_channels", "[", "5", "]", ",", "kernel_shape", "=", "[", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "0", ",", "\n", "name", "=", "name", "+", "'/Branch_3/Conv3d_0b_1x1'", ")", "\n", "self", ".", "name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.InceptionModule.forward": [[761, 767], ["validation_metrics.InceptionModule.b0", "validation_metrics.InceptionModule.b1b", "validation_metrics.InceptionModule.b2b", "validation_metrics.InceptionModule.b3b", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "validation_metrics.InceptionModule.b1a", "validation_metrics.InceptionModule.b2a", "validation_metrics.InceptionModule.b3a"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "b0", "=", "self", ".", "b0", "(", "x", ")", "\n", "b1", "=", "self", ".", "b1b", "(", "self", ".", "b1a", "(", "x", ")", ")", "\n", "b2", "=", "self", ".", "b2b", "(", "self", ".", "b2a", "(", "x", ")", ")", "\n", "b3", "=", "self", ".", "b3b", "(", "self", ".", "b3a", "(", "x", ")", ")", "\n", "return", "torch", ".", "cat", "(", "[", "b0", ",", "b1", ",", "b2", ",", "b3", "]", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.InceptionI3d.__init__": [[806, 925], ["torch.Module.__init__", "validation_metrics.Unit3D", "validation_metrics.MaxPool3dSamePadding", "validation_metrics.Unit3D", "validation_metrics.Unit3D", "validation_metrics.MaxPool3dSamePadding", "validation_metrics.InceptionModule", "validation_metrics.InceptionModule", "validation_metrics.MaxPool3dSamePadding", "validation_metrics.InceptionModule", "validation_metrics.InceptionModule", "validation_metrics.InceptionModule", "validation_metrics.InceptionModule", "validation_metrics.InceptionModule", "validation_metrics.MaxPool3dSamePadding", "validation_metrics.InceptionModule", "validation_metrics.InceptionModule", "torch.AvgPool3d", "torch.AvgPool3d", "torch.AvgPool3d", "torch.AvgPool3d", "torch.AvgPool3d", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "validation_metrics.Unit3D", "validation_metrics.InceptionI3d.build", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.InceptionI3d.build"], ["def", "__init__", "(", "self", ",", "num_classes", "=", "400", ",", "spatial_squeeze", "=", "True", ",", "\n", "final_endpoint", "=", "'Logits'", ",", "name", "=", "'inception_i3d'", ",", "in_channels", "=", "3", ",", "dropout_keep_prob", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"Initializes I3D model instance.\n        Args:\n          num_classes: The number of outputs in the logit layer (default 400, which\n              matches the Kinetics dataset).\n          spatial_squeeze: Whether to squeeze the spatial dimensions for the logits\n              before returning (default True).\n          final_endpoint: The model contains many possible endpoints.\n              `final_endpoint` specifies the last endpoint for the model to be built\n              up to. In addition to the output at `final_endpoint`, all the outputs\n              at endpoints up to `final_endpoint` will also be returned, in a\n              dictionary. `final_endpoint` must be one of\n              InceptionI3d.VALID_ENDPOINTS (default 'Logits').\n          name: A string (optional). The name of this module.\n        Raises:\n          ValueError: if `final_endpoint` is not recognized.\n        \"\"\"", "\n", "\n", "if", "final_endpoint", "not", "in", "self", ".", "VALID_ENDPOINTS", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown final endpoint %s'", "%", "final_endpoint", ")", "\n", "\n", "", "super", "(", "InceptionI3d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "_num_classes", "=", "num_classes", "\n", "self", ".", "_spatial_squeeze", "=", "spatial_squeeze", "\n", "self", ".", "_final_endpoint", "=", "final_endpoint", "\n", "self", ".", "logits", "=", "None", "\n", "\n", "if", "self", ".", "_final_endpoint", "not", "in", "self", ".", "VALID_ENDPOINTS", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown final endpoint %s'", "%", "self", ".", "_final_endpoint", ")", "\n", "\n", "", "self", ".", "end_points", "=", "{", "}", "\n", "end_point", "=", "'Conv3d_1a_7x7'", "\n", "self", ".", "end_points", "[", "end_point", "]", "=", "Unit3D", "(", "in_channels", "=", "in_channels", ",", "output_channels", "=", "64", ",", "kernel_shape", "=", "[", "7", ",", "7", ",", "7", "]", ",", "\n", "stride", "=", "(", "2", ",", "2", ",", "2", ")", ",", "padding", "=", "(", "3", ",", "3", ",", "3", ")", ",", "name", "=", "name", "+", "end_point", ")", "\n", "if", "self", ".", "_final_endpoint", "==", "end_point", ":", "return", "\n", "\n", "end_point", "=", "'MaxPool3d_2a_3x3'", "\n", "self", ".", "end_points", "[", "end_point", "]", "=", "MaxPool3dSamePadding", "(", "kernel_size", "=", "[", "1", ",", "3", ",", "3", "]", ",", "stride", "=", "(", "1", ",", "2", ",", "2", ")", ",", "\n", "padding", "=", "0", ")", "\n", "if", "self", ".", "_final_endpoint", "==", "end_point", ":", "return", "\n", "\n", "end_point", "=", "'Conv3d_2b_1x1'", "\n", "self", ".", "end_points", "[", "end_point", "]", "=", "Unit3D", "(", "in_channels", "=", "64", ",", "output_channels", "=", "64", ",", "kernel_shape", "=", "[", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "0", ",", "\n", "name", "=", "name", "+", "end_point", ")", "\n", "if", "self", ".", "_final_endpoint", "==", "end_point", ":", "return", "\n", "\n", "end_point", "=", "'Conv3d_2c_3x3'", "\n", "self", ".", "end_points", "[", "end_point", "]", "=", "Unit3D", "(", "in_channels", "=", "64", ",", "output_channels", "=", "192", ",", "kernel_shape", "=", "[", "3", ",", "3", ",", "3", "]", ",", "padding", "=", "1", ",", "\n", "name", "=", "name", "+", "end_point", ")", "\n", "if", "self", ".", "_final_endpoint", "==", "end_point", ":", "return", "\n", "\n", "end_point", "=", "'MaxPool3d_3a_3x3'", "\n", "self", ".", "end_points", "[", "end_point", "]", "=", "MaxPool3dSamePadding", "(", "kernel_size", "=", "[", "1", ",", "3", ",", "3", "]", ",", "stride", "=", "(", "1", ",", "2", ",", "2", ")", ",", "\n", "padding", "=", "0", ")", "\n", "if", "self", ".", "_final_endpoint", "==", "end_point", ":", "return", "\n", "\n", "end_point", "=", "'Mixed_3b'", "\n", "self", ".", "end_points", "[", "end_point", "]", "=", "InceptionModule", "(", "192", ",", "[", "64", ",", "96", ",", "128", ",", "16", ",", "32", ",", "32", "]", ",", "name", "+", "end_point", ")", "\n", "if", "self", ".", "_final_endpoint", "==", "end_point", ":", "return", "\n", "\n", "end_point", "=", "'Mixed_3c'", "\n", "self", ".", "end_points", "[", "end_point", "]", "=", "InceptionModule", "(", "256", ",", "[", "128", ",", "128", ",", "192", ",", "32", ",", "96", ",", "64", "]", ",", "name", "+", "end_point", ")", "\n", "if", "self", ".", "_final_endpoint", "==", "end_point", ":", "return", "\n", "\n", "end_point", "=", "'MaxPool3d_4a_3x3'", "\n", "self", ".", "end_points", "[", "end_point", "]", "=", "MaxPool3dSamePadding", "(", "kernel_size", "=", "[", "3", ",", "3", ",", "3", "]", ",", "stride", "=", "(", "2", ",", "2", ",", "2", ")", ",", "\n", "padding", "=", "0", ")", "\n", "if", "self", ".", "_final_endpoint", "==", "end_point", ":", "return", "\n", "\n", "end_point", "=", "'Mixed_4b'", "\n", "self", ".", "end_points", "[", "end_point", "]", "=", "InceptionModule", "(", "128", "+", "192", "+", "96", "+", "64", ",", "[", "192", ",", "96", ",", "208", ",", "16", ",", "48", ",", "64", "]", ",", "name", "+", "end_point", ")", "\n", "if", "self", ".", "_final_endpoint", "==", "end_point", ":", "return", "\n", "\n", "end_point", "=", "'Mixed_4c'", "\n", "self", ".", "end_points", "[", "end_point", "]", "=", "InceptionModule", "(", "192", "+", "208", "+", "48", "+", "64", ",", "[", "160", ",", "112", ",", "224", ",", "24", ",", "64", ",", "64", "]", ",", "name", "+", "end_point", ")", "\n", "if", "self", ".", "_final_endpoint", "==", "end_point", ":", "return", "\n", "\n", "end_point", "=", "'Mixed_4d'", "\n", "self", ".", "end_points", "[", "end_point", "]", "=", "InceptionModule", "(", "160", "+", "224", "+", "64", "+", "64", ",", "[", "128", ",", "128", ",", "256", ",", "24", ",", "64", ",", "64", "]", ",", "name", "+", "end_point", ")", "\n", "if", "self", ".", "_final_endpoint", "==", "end_point", ":", "return", "\n", "\n", "end_point", "=", "'Mixed_4e'", "\n", "self", ".", "end_points", "[", "end_point", "]", "=", "InceptionModule", "(", "128", "+", "256", "+", "64", "+", "64", ",", "[", "112", ",", "144", ",", "288", ",", "32", ",", "64", ",", "64", "]", ",", "name", "+", "end_point", ")", "\n", "if", "self", ".", "_final_endpoint", "==", "end_point", ":", "return", "\n", "\n", "end_point", "=", "'Mixed_4f'", "\n", "self", ".", "end_points", "[", "end_point", "]", "=", "InceptionModule", "(", "112", "+", "288", "+", "64", "+", "64", ",", "[", "256", ",", "160", ",", "320", ",", "32", ",", "128", ",", "128", "]", ",", "\n", "name", "+", "end_point", ")", "\n", "if", "self", ".", "_final_endpoint", "==", "end_point", ":", "return", "\n", "\n", "end_point", "=", "'MaxPool3d_5a_2x2'", "\n", "self", ".", "end_points", "[", "end_point", "]", "=", "MaxPool3dSamePadding", "(", "kernel_size", "=", "[", "2", ",", "2", ",", "2", "]", ",", "stride", "=", "(", "2", ",", "2", ",", "2", ")", ",", "\n", "padding", "=", "0", ")", "\n", "if", "self", ".", "_final_endpoint", "==", "end_point", ":", "return", "\n", "\n", "end_point", "=", "'Mixed_5b'", "\n", "self", ".", "end_points", "[", "end_point", "]", "=", "InceptionModule", "(", "256", "+", "320", "+", "128", "+", "128", ",", "[", "256", ",", "160", ",", "320", ",", "32", ",", "128", ",", "128", "]", ",", "\n", "name", "+", "end_point", ")", "\n", "if", "self", ".", "_final_endpoint", "==", "end_point", ":", "return", "\n", "\n", "end_point", "=", "'Mixed_5c'", "\n", "self", ".", "end_points", "[", "end_point", "]", "=", "InceptionModule", "(", "256", "+", "320", "+", "128", "+", "128", ",", "[", "384", ",", "192", ",", "384", ",", "48", ",", "128", ",", "128", "]", ",", "\n", "name", "+", "end_point", ")", "\n", "if", "self", ".", "_final_endpoint", "==", "end_point", ":", "return", "\n", "\n", "end_point", "=", "'Logits'", "\n", "self", ".", "avg_pool", "=", "nn", ".", "AvgPool3d", "(", "kernel_size", "=", "[", "2", ",", "7", ",", "7", "]", ",", "\n", "stride", "=", "(", "1", ",", "1", ",", "1", ")", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout_keep_prob", ")", "\n", "self", ".", "logits", "=", "Unit3D", "(", "in_channels", "=", "384", "+", "384", "+", "128", "+", "128", ",", "output_channels", "=", "self", ".", "_num_classes", ",", "\n", "kernel_shape", "=", "[", "1", ",", "1", ",", "1", "]", ",", "\n", "padding", "=", "0", ",", "\n", "activation_fn", "=", "None", ",", "\n", "use_batch_norm", "=", "False", ",", "\n", "use_bias", "=", "True", ",", "\n", "name", "=", "'logits'", ")", "\n", "\n", "self", ".", "build", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.InceptionI3d.replace_logits": [[926, 935], ["validation_metrics.Unit3D"], "methods", ["None"], ["", "def", "replace_logits", "(", "self", ",", "num_classes", ")", ":", "\n", "        ", "self", ".", "_num_classes", "=", "num_classes", "\n", "self", ".", "logits", "=", "Unit3D", "(", "in_channels", "=", "384", "+", "384", "+", "128", "+", "128", ",", "output_channels", "=", "self", ".", "_num_classes", ",", "\n", "kernel_shape", "=", "[", "1", ",", "1", ",", "1", "]", ",", "\n", "padding", "=", "0", ",", "\n", "activation_fn", "=", "None", ",", "\n", "use_batch_norm", "=", "False", ",", "\n", "use_bias", "=", "True", ",", "\n", "name", "=", "'logits'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.InceptionI3d.build": [[936, 939], ["validation_metrics.InceptionI3d.end_points.keys", "validation_metrics.InceptionI3d.add_module"], "methods", ["None"], ["", "def", "build", "(", "self", ")", ":", "\n", "        ", "for", "k", "in", "self", ".", "end_points", ".", "keys", "(", ")", ":", "\n", "            ", "self", ".", "add_module", "(", "k", ",", "self", ".", "end_points", "[", "k", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.InceptionI3d.forward": [[940, 945], ["kornia.resize", "x.reshape.reshape.reshape", "validation_metrics.InceptionI3d.extract_features", "x.reshape.reshape.flatten"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.InceptionI3d.extract_features"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "batch_size", ",", "channels", ",", "time_steps", "=", "x", ".", "shape", "[", ":", "3", "]", "\n", "x", "=", "kornia", ".", "resize", "(", "x", ".", "flatten", "(", "start_dim", "=", "1", ",", "end_dim", "=", "2", ")", ",", "size", "=", "(", "224", ",", "224", ")", ",", "interpolation", "=", "'bilinear'", ",", "antialias", "=", "True", ")", "\n", "x", "=", "x", ".", "reshape", "(", "batch_size", ",", "channels", ",", "time_steps", ",", "224", ",", "224", ")", "\n", "return", "self", ".", "extract_features", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.validation_metrics.InceptionI3d.extract_features": [[946, 952], ["torch.adaptive_avg_pool3d().flatten", "torch.adaptive_avg_pool3d().flatten", "torch.adaptive_avg_pool3d().flatten", "torch.adaptive_avg_pool3d().flatten", "torch.adaptive_avg_pool3d().flatten", "torch.adaptive_avg_pool3d", "torch.adaptive_avg_pool3d", "torch.adaptive_avg_pool3d", "torch.adaptive_avg_pool3d", "torch.adaptive_avg_pool3d"], "methods", ["None"], ["", "def", "extract_features", "(", "self", ",", "x", ")", ":", "\n", "        ", "for", "end_point", "in", "self", ".", "VALID_ENDPOINTS", ":", "\n", "            ", "if", "end_point", "in", "self", ".", "end_points", ":", "\n", "                ", "x", "=", "self", ".", "_modules", "[", "end_point", "]", "(", "x", ")", "\n", "", "", "output", "=", "F", ".", "adaptive_avg_pool3d", "(", "x", ",", "output_size", "=", "(", "1", ",", "1", ",", "1", ")", ")", ".", "flatten", "(", "start_dim", "=", "1", ")", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.Discriminator.__init__": [[20, 98], ["torch.Module.__init__", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "enumerate", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "enumerate", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "zip", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Flatten", "torch.Flatten", "torch.Flatten", "equalized_layer.EqualizedLinear", "op_static.FusedLeakyReLU", "equalized_layer.EqualizedLinear", "reversed", "reversed", "u_net_2d_discriminator.Discriminator.transposed_convolutions.append", "op_static.FusedLeakyReLU", "equalized_layer.EqualizedConv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "u_net_2d_discriminator.Discriminator.decoder_blocks.append", "u_net_2d_discriminator.Discriminator.decoder_blocks.append", "torch.Sequential", "torch.Sequential", "torch.Sequential", "u_net_2d_discriminator.Discriminator.encoder_blocks.append", "u_net_2d_discriminator.Discriminator.encoder_blocks.append", "u_net_2d_discriminator.Discriminator.encoder_blocks.append", "u_net_2d_discriminator.Discriminator.encoder_blocks.append", "equalized_layer.EqualizedConv2d", "u_net_2d_discriminator.Blur", "u_net_2d_discriminator.NonLocalBlock", "u_net_2d_discriminator.ResNetBlock", "u_net_2d_discriminator.Upsample", "equalized_layer.EqualizedConv2d", "u_net_2d_discriminator.ResNetBlock", "u_net_2d_discriminator.ResNetBlock", "u_net_2d_discriminator.NonLocalBlock", "u_net_2d_discriminator.ResNetBlock", "len"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "Dict", "[", "str", ",", "Any", "]", ",", "no_rfp", ":", "bool", "=", "False", ",", "no_gfp", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param config: (Dict[str, Any]) Dict with network configurations\n        :param no_rfp: (bool) If true no rfp channels if predicted\n        :param no_gfp: (bool) If true no gfp channels if predicted\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "Discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Get parameters from config dict", "\n", "encoder_channels", ":", "Tuple", "[", "Tuple", "[", "int", ",", "int", "]", ",", "...", "]", "=", "config", "[", "\"encoder_channels\"", "]", "\n", "decoder_channels", ":", "Tuple", "[", "Tuple", "[", "int", ",", "int", "]", ",", "...", "]", "=", "config", "[", "\"decoder_channels\"", "]", "\n", "self", ".", "fft", ":", "bool", "=", "config", "[", "\"fft\"", "]", "\n", "# Init encoder blocks", "\n", "self", ".", "encoder_blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "index", ",", "encoder_channel", "in", "enumerate", "(", "encoder_channels", ")", ":", "\n", "            ", "if", "index", "==", "0", ":", "\n", "                ", "if", "no_gfp", ":", "\n", "                    ", "input_channels", ":", "int", "=", "3", "\n", "", "elif", "no_rfp", ":", "\n", "                    ", "input_channels", ":", "int", "=", "6", "\n", "", "else", ":", "\n", "                    ", "input_channels", ":", "int", "=", "9", "\n", "", "if", "self", ".", "fft", ":", "\n", "                    ", "self", ".", "encoder_blocks", ".", "append", "(", "\n", "ResNetBlock", "(", "in_channels", "=", "input_channels", "+", "(", "input_channels", "*", "2", ")", ",", "\n", "out_channels", "=", "encoder_channel", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "encoder_blocks", ".", "append", "(", "\n", "ResNetBlock", "(", "in_channels", "=", "input_channels", ",", "\n", "out_channels", "=", "encoder_channel", "[", "1", "]", ")", ")", "\n", "", "", "elif", "index", "==", "2", ":", "\n", "                ", "self", ".", "encoder_blocks", ".", "append", "(", "\n", "NonLocalBlock", "(", "in_channels", "=", "encoder_channel", "[", "0", "]", ",", "out_channels", "=", "encoder_channel", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "encoder_blocks", ".", "append", "(", "\n", "ResNetBlock", "(", "in_channels", "=", "encoder_channel", "[", "0", "]", ",", "out_channels", "=", "encoder_channel", "[", "1", "]", ",", "\n", "mini_batch_std_dev", "=", "index", ">=", "(", "len", "(", "encoder_channels", ")", "-", "2", ")", ")", ")", "\n", "# Init downscale convolutions", "\n", "", "", "self", ".", "downscale_convolutions", "=", "nn", ".", "ModuleList", "(", "\n", "[", "nn", ".", "Sequential", "(", "\n", "equalized_layer", ".", "EqualizedConv2d", "(", "in_channels", "=", "encoder_channel", "[", "1", "]", ",", "out_channels", "=", "encoder_channel", "[", "1", "]", ",", "\n", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "(", "0", ",", "0", ")", ")", ",", "Blur", "(", ")", ")", "for", "\n", "encoder_channel", "in", "encoder_channels", "[", ":", "-", "1", "]", "]", ")", "\n", "# Init classification head", "\n", "self", ".", "classification_head", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "AdaptiveAvgPool2d", "(", "output_size", "=", "(", "1", ",", "1", ")", ")", ",", "\n", "nn", ".", "Flatten", "(", "start_dim", "=", "1", ")", ",", "\n", "equalized_layer", ".", "EqualizedLinear", "(", "in_channels", "=", "encoder_channels", "[", "-", "1", "]", "[", "-", "1", "]", ",", "out_channels", "=", "128", ",", "bias", "=", "False", ")", ",", "\n", "FusedLeakyReLU", "(", "channel", "=", "128", ")", ",", "\n", "equalized_layer", ".", "EqualizedLinear", "(", "in_channels", "=", "128", ",", "out_channels", "=", "1", ",", "bias", "=", "False", ")", "\n", ")", "\n", "# Init decoder blocks", "\n", "self", ".", "decoder_blocks", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "index", ",", "decoder_channel", "in", "enumerate", "(", "decoder_channels", ")", ":", "\n", "            ", "if", "index", "==", "1", ":", "\n", "                ", "self", ".", "decoder_blocks", ".", "append", "(", "\n", "NonLocalBlock", "(", "in_channels", "=", "decoder_channel", "[", "0", "]", ",", "out_channels", "=", "decoder_channel", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "decoder_blocks", ".", "append", "(", "ResNetBlock", "(", "in_channels", "=", "decoder_channel", "[", "0", "]", ",", "out_channels", "=", "decoder_channel", "[", "1", "]", ")", ")", "\n", "# Init transposed convolutions", "\n", "", "", "self", ".", "transposed_convolutions", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "current_channel", ",", "past_channel", ",", "decoder_channel", "in", "zip", "(", "reversed", "(", "encoder_channels", "[", "1", ":", "]", ")", ",", "\n", "reversed", "(", "encoder_channels", "[", ":", "-", "1", "]", ")", ",", "\n", "decoder_channels", ")", ":", "\n", "            ", "self", ".", "transposed_convolutions", ".", "append", "(", "\n", "nn", ".", "Sequential", "(", "\n", "Upsample", "(", ")", ",", "\n", "equalized_layer", ".", "EqualizedConv2d", "(", "in_channels", "=", "current_channel", "[", "-", "1", "]", ",", "\n", "out_channels", "=", "decoder_channel", "[", "0", "]", "-", "past_channel", "[", "-", "1", "]", ",", "\n", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "(", "0", ",", "0", ")", ",", "\n", "bias", "=", "False", ")", "\n", ")", ")", "\n", "# Init final mapping", "\n", "", "self", ".", "final_mapping", "=", "nn", ".", "Sequential", "(", "\n", "FusedLeakyReLU", "(", "channel", "=", "decoder_channels", "[", "-", "1", "]", "[", "-", "1", "]", ")", ",", "\n", "equalized_layer", ".", "EqualizedConv2d", "(", "in_channels", "=", "decoder_channels", "[", "-", "1", "]", "[", "-", "1", "]", ",", "out_channels", "=", "1", ",", "\n", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "(", "0", ",", "0", ")", ",", "bias", "=", "False", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.Discriminator.forward": [[99, 141], ["torch.cat.flatten", "torch.cat.flatten", "torch.cat.flatten", "enumerate", "u_net_2d_discriminator.Discriminator.classification_head", "zip", "u_net_2d_discriminator.Discriminator.final_mapping().unsqueeze", "encoder_block", "reversed", "decoder_block", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "encoder_features.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "u_net_2d_discriminator.Discriminator.final_mapping", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.rfft().permute", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "transposed_convolution", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft", "torch.rfft"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ",", "**", "kwargs", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass of the 3D U-Net discriminator\n        :param input: (torch.Tensor) Input tensor of the shape [batch size, channels, time steps, width, height]\n        :return: (Tuple[torch.Tensor, torch.Tensor]) Scalar classification prediction and pixel wise prediction without\n        time steps dimension\n        \"\"\"", "\n", "# Perform 3D fft on input", "\n", "if", "self", ".", "fft", ":", "\n", "            ", "if", "input", ".", "shape", "[", "1", "]", "==", "3", ":", "\n", "                ", "bf_fft", "=", "torch", ".", "rfft", "(", "input", "[", ":", ",", "0", "]", ",", "signal_ndim", "=", "3", ",", "normalized", "=", "True", ",", "onesided", "=", "False", ")", ".", "permute", "(", "0", ",", "4", ",", "1", ",", "2", ",", "3", ")", "\n", "gfp_fft", "=", "torch", ".", "rfft", "(", "input", "[", ":", ",", "1", "]", ",", "signal_ndim", "=", "3", ",", "normalized", "=", "True", ",", "onesided", "=", "False", ")", ".", "permute", "(", "0", ",", "4", ",", "1", ",", "2", ",", "3", ")", "\n", "rfp_fft", "=", "torch", ".", "rfft", "(", "input", "[", ":", ",", "2", "]", ",", "signal_ndim", "=", "3", ",", "normalized", "=", "True", ",", "onesided", "=", "False", ")", ".", "permute", "(", "0", ",", "4", ",", "1", ",", "2", ",", "3", ")", "\n", "# Make input", "\n", "input", "=", "torch", ".", "cat", "(", "[", "input", ",", "bf_fft", ",", "gfp_fft", ",", "rfp_fft", "]", ",", "dim", "=", "1", ")", "\n", "", "elif", "input", ".", "shape", "[", "1", "]", "==", "2", ":", "\n", "                ", "bf_fft", "=", "torch", ".", "rfft", "(", "input", "[", ":", ",", "0", "]", ",", "signal_ndim", "=", "3", ",", "normalized", "=", "True", ",", "onesided", "=", "False", ")", ".", "permute", "(", "0", ",", "4", ",", "1", ",", "2", ",", "3", ")", "\n", "gfp_fft", "=", "torch", ".", "rfft", "(", "input", "[", ":", ",", "1", "]", ",", "signal_ndim", "=", "3", ",", "normalized", "=", "True", ",", "onesided", "=", "False", ")", ".", "permute", "(", "0", ",", "4", ",", "1", ",", "2", ",", "3", ")", "\n", "# Make input", "\n", "input", "=", "torch", ".", "cat", "(", "[", "input", ",", "bf_fft", ",", "gfp_fft", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "bf_fft", "=", "torch", ".", "rfft", "(", "input", "[", ":", ",", "0", "]", ",", "signal_ndim", "=", "3", ",", "normalized", "=", "True", ",", "onesided", "=", "False", ")", ".", "permute", "(", "0", ",", "4", ",", "1", ",", "2", ",", "3", ")", "\n", "# Make input", "\n", "input", "=", "torch", ".", "cat", "(", "[", "input", ",", "bf_fft", "]", ",", "dim", "=", "1", ")", "\n", "# Flatten input", "\n", "", "", "input", "=", "input", ".", "flatten", "(", "start_dim", "=", "1", ",", "end_dim", "=", "2", ")", "\n", "# Perform decoder mapping and store features", "\n", "encoder_features", "=", "[", "]", "\n", "for", "index", ",", "encoder_block", "in", "enumerate", "(", "self", ".", "encoder_blocks", ")", ":", "\n", "            ", "input", "=", "encoder_block", "(", "input", ")", "\n", "if", "index", "!=", "(", "len", "(", "self", ".", "encoder_blocks", ")", "-", "1", ")", ":", "\n", "                ", "encoder_features", ".", "append", "(", "input", ")", "\n", "input", "=", "self", ".", "downscale_convolutions", "[", "index", "]", "(", "input", ")", "\n", "# Predict classification", "\n", "", "", "classification", "=", "self", ".", "classification_head", "(", "input", ")", "\n", "# Decoder forward pass", "\n", "for", "decoder_block", ",", "transposed_convolution", ",", "encoder_feature", "in", "zip", "(", "self", ".", "decoder_blocks", ",", "self", ".", "transposed_convolutions", ",", "reversed", "(", "encoder_features", ")", ")", ":", "\n", "            ", "input", "=", "decoder_block", "(", "torch", ".", "cat", "(", "[", "transposed_convolution", "(", "input", ")", ",", "encoder_feature", "]", ",", "dim", "=", "1", ")", ")", "\n", "# Perform final mapping", "\n", "", "classification_pixel_wise", "=", "self", ".", "final_mapping", "(", "input", ")", ".", "unsqueeze", "(", "dim", "=", "2", ")", "\n", "return", "classification", ",", "classification_pixel_wise", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.ResNetBlock.__init__": [[148, 173], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "u_net_2d_discriminator.MinibatchStdDev", "torch.Identity", "torch.Identity", "torch.Identity", "equalized_layer.EqualizedConv2d", "op_static.FusedLeakyReLU", "equalized_layer.EqualizedConv2d", "op_static.FusedLeakyReLU", "equalized_layer.EqualizedConv2d", "torch.Identity", "torch.Identity", "torch.Identity"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ":", "int", ",", "out_channels", ":", "int", ",", "mini_batch_std_dev", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param in_channels: (int) Number of input channels\n        :param out_channels: (int) Number of output channels\n        :param mini_batch_std_dev: (bool) If true mini batch std dev is utilized\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "ResNetBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Init mini batch std dev if needed", "\n", "self", ".", "mini_batch_std_dev", "=", "MinibatchStdDev", "(", ")", "if", "mini_batch_std_dev", "else", "nn", ".", "Identity", "(", ")", "\n", "# Init main mapping", "\n", "self", ".", "main_mapping", "=", "nn", ".", "Sequential", "(", "\n", "equalized_layer", ".", "EqualizedConv2d", "(", "in_channels", "=", "in_channels", "+", "1", "if", "mini_batch_std_dev", "else", "in_channels", ",", "\n", "out_channels", "=", "out_channels", ",", "\n", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "(", "1", ",", "1", ")", ",", "bias", "=", "False", ")", ",", "\n", "FusedLeakyReLU", "(", "out_channels", ")", ",", "\n", "equalized_layer", ".", "EqualizedConv2d", "(", "in_channels", "=", "out_channels", ",", "out_channels", "=", "out_channels", ",", "\n", "kernel_size", "=", "(", "3", ",", "3", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "(", "1", ",", "1", ")", ",", "bias", "=", "False", ")", ",", "\n", "FusedLeakyReLU", "(", "out_channels", ")", "\n", ")", "\n", "# Init residual mapping", "\n", "self", ".", "residual_mapping", "=", "equalized_layer", ".", "EqualizedConv2d", "(", "\n", "in_channels", "=", "in_channels", ",", "out_channels", "=", "out_channels", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "\n", "bias", "=", "False", ")", "if", "in_channels", "!=", "out_channels", "else", "nn", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.ResNetBlock.forward": [[174, 187], ["u_net_2d_discriminator.ResNetBlock.mini_batch_std_dev", "u_net_2d_discriminator.ResNetBlock.main_mapping", "math.sqrt", "u_net_2d_discriminator.ResNetBlock.residual_mapping"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass of the residual block\n        :param input: (torch.Tensor) Input tensor 5D\n        :return: (torch.Tensor) Output tensor 5d\n        \"\"\"", "\n", "# Perform mini batch std dev", "\n", "output", "=", "self", ".", "mini_batch_std_dev", "(", "input", ")", "\n", "# Perform main mapping", "\n", "output", "=", "self", ".", "main_mapping", "(", "output", ")", "\n", "# Perform residual mapping", "\n", "output", "=", "(", "output", "+", "self", ".", "residual_mapping", "(", "input", ")", ")", "/", "math", ".", "sqrt", "(", "2", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.MinibatchStdDev.__init__": [[195, 204], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ",", "alpha", ":", "float", "=", "1e-8", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param alpha: (float) Small constant for numeric stability\n        \"\"\"", "\n", "# Constructor method", "\n", "super", "(", "MinibatchStdDev", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Save parameters", "\n", "self", ".", "alpha", "=", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.MinibatchStdDev.forward": [[205, 218], ["torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.mean().view", "torch.cat.repeat", "torch.cat.repeat", "torch.cat.repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean().clamp", "torch.mean().clamp", "torch.mean().clamp", "torch.mean().clamp", "torch.mean().clamp", "torch.mean().clamp", "torch.mean().clamp", "torch.mean().clamp", "torch.mean().clamp", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param input: (Torch Tensor) Input tensor [batch size, channels,, height, width]\n        :return: (Torch Tensor) Output tensor [batch size, channels, height, width]\n        \"\"\"", "\n", "# Calc stddev", "\n", "output", "=", "input", "-", "torch", ".", "mean", "(", "input", ",", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "output", "=", "torch", ".", "sqrt", "(", "torch", ".", "mean", "(", "output", "**", "2", ",", "dim", "=", "0", ",", "keepdim", "=", "False", ")", ".", "clamp", "(", "min", "=", "self", ".", "alpha", ")", ")", "\n", "output", "=", "torch", ".", "mean", "(", "output", ")", ".", "view", "(", "1", ",", "1", ",", "1", ")", "\n", "output", "=", "output", ".", "repeat", "(", "input", ".", "shape", "[", "0", "]", ",", "1", ",", "input", ".", "shape", "[", "2", "]", ",", "input", ".", "shape", "[", "3", "]", ")", "\n", "output", "=", "torch", ".", "cat", "(", "(", "input", ",", "output", ")", ",", "1", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.Upsample.__init__": [[225, 243], ["torch.Module.__init__", "u_net_2d_discriminator.Upsample.make_kernel", "u_net_2d_discriminator.Upsample.register_buffer"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.Blur.make_kernel"], ["def", "__init__", "(", "self", ",", "blur_kernel", ":", "List", "[", "int", "]", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "factor", ":", "int", "=", "2", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param blur_kernel: (List[int]) List of weights for the blur kernel to be used\n        :param factor: (int) Upscale factor\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "Upsample", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Save parameter", "\n", "self", ".", "factor", "=", "factor", "\n", "# Make kernel", "\n", "kernel", "=", "self", ".", "make_kernel", "(", "kernel", "=", "blur_kernel", ")", "\n", "# Save kernel", "\n", "self", ".", "register_buffer", "(", "'kernel'", ",", "kernel", ")", "\n", "# Calc padding factor", "\n", "padding_factor", "=", "kernel", ".", "shape", "[", "0", "]", "-", "factor", "\n", "# Calc padding", "\n", "self", ".", "padding", "=", "(", "(", "(", "padding_factor", "+", "1", ")", "//", "2", ")", "+", "factor", "-", "1", ",", "padding_factor", "//", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.Upsample.make_kernel": [[244, 258], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.sum", "torch.tensor.sum", "torch.tensor.sum", "torch.tensor.float", "torch.tensor.float", "torch.tensor.float"], "methods", ["None"], ["", "def", "make_kernel", "(", "self", ",", "kernel", ":", "List", "[", "int", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Method generates a kernel matrix for a given input list of weights\n        :param kernel: (List[int]) List of weights for the blur kernel to be used\n        :return: (torch.Tensor) Kernel tensor\n        \"\"\"", "\n", "# Kernel into list", "\n", "kernel", "=", "torch", ".", "tensor", "(", "kernel", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "# Change dim of tensor if list list is 1d", "\n", "if", "kernel", ".", "ndim", "==", "1", ":", "\n", "            ", "kernel", "=", "kernel", "[", "None", ",", ":", "]", "*", "kernel", "[", ":", ",", "None", "]", "\n", "# Normalize kernel", "\n", "", "kernel", "/=", "kernel", ".", "sum", "(", ")", "\n", "return", "kernel", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.Upsample.forward": [[259, 267], ["op_static.upfirdn2d"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.upfirdn2d.upfirdn2d"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param input: (torch.Tensor) Input tensor\n        :return: (torch.Tensor) Upscaled output tensor\n        \"\"\"", "\n", "output", "=", "upfirdn2d", "(", "input", "=", "input", ",", "kernel", "=", "self", ".", "kernel", ",", "up", "=", "self", ".", "factor", ",", "pad", "=", "self", ".", "padding", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.Blur.__init__": [[274, 296], ["torch.Module.__init__", "u_net_2d_discriminator.Blur.calc_padding", "u_net_2d_discriminator.Blur.make_kernel", "u_net_2d_discriminator.Blur.register_buffer"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.Blur.calc_padding", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.Blur.make_kernel"], ["def", "__init__", "(", "self", ",", "kernel", ":", "List", "[", "int", "]", "=", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "sampling_factor", ":", "int", "=", "1", ",", "\n", "sampling_factor_padding", ":", "int", "=", "2", ",", "\n", "kernel_size", ":", "int", "=", "3", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param kernel: (List[int]) List of kernel weights\n        :param sampling_factor: (int) Scaling factor\n        :param sampling_factor_padding: (int) Scaling factor for padding\n        :param kernel_size: (int) Blur kernel size\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "Blur", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Save padding factor", "\n", "self", ".", "padding", "=", "self", ".", "calc_padding", "(", "kernel", ",", "sampling_factor_padding", "=", "sampling_factor_padding", ",", "\n", "kernel_size", "=", "kernel_size", ")", "\n", "# Init kernel", "\n", "kernel", "=", "self", ".", "make_kernel", "(", "kernel", ")", "\n", "# Rescale kernel if sampling factor is bigger than one", "\n", "if", "sampling_factor", ">", "1", ":", "\n", "            ", "kernel", "=", "kernel", "*", "(", "sampling_factor", "**", "2", ")", "\n", "# Save kernel", "\n", "", "self", ".", "register_buffer", "(", "'kernel'", ",", "kernel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.Blur.calc_padding": [[297, 309], ["len"], "methods", ["None"], ["", "def", "calc_padding", "(", "self", ",", "kernel", ":", "List", "[", "int", "]", ",", "sampling_factor_padding", ":", "int", "=", "2", ",", "\n", "kernel_size", ":", "int", "=", "3", ")", "->", "Tuple", "[", "int", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Method estimates the padding factor\n        :param kernel: (List[int]) List of kernel weights\n        :param sampling_factor: (int) Factor used in scaling\n        :param kernel_size: (int) Kernel size of convolution afterwards\n        :return: (Tuple[int, int]) Padding in x and y direction\n        \"\"\"", "\n", "padding_factor", "=", "(", "len", "(", "kernel", ")", "-", "sampling_factor_padding", ")", "+", "(", "kernel_size", "-", "1", ")", "\n", "padding", "=", "(", "(", "padding_factor", "+", "1", ")", "//", "2", ",", "padding_factor", "//", "2", ")", "\n", "return", "padding", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.Blur.make_kernel": [[310, 324], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor.sum", "torch.tensor.sum", "torch.tensor.sum"], "methods", ["None"], ["", "def", "make_kernel", "(", "self", ",", "kernel", ":", "List", "[", "int", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Method generates a kernel matrix for a given input list of weights\n        :param kernel: (List[int]) List of weights for the blur kernel to be used\n        :return: (torch.Tensor) Kernel tensor\n        \"\"\"", "\n", "# Kernel into list", "\n", "kernel", "=", "torch", ".", "tensor", "(", "kernel", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "# Change dim of tensor if list list is 1d", "\n", "if", "kernel", ".", "ndim", "==", "1", ":", "\n", "            ", "kernel", "=", "kernel", "[", "None", ",", ":", "]", "*", "kernel", "[", ":", ",", "None", "]", "\n", "# Normalize kernel", "\n", "", "kernel", "=", "kernel", "/", "kernel", ".", "sum", "(", ")", "\n", "return", "kernel", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.Blur.forward": [[325, 333], ["op_static.upfirdn2d"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.upfirdn2d.upfirdn2d"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param input: (torch.Tensor) Input tensor\n        :return: (torch.Tensor) Output tensor\n        \"\"\"", "\n", "output", "=", "upfirdn2d", "(", "input", ",", "self", ".", "kernel", ",", "pad", "=", "self", ".", "padding", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.NonLocalBlock.__init__": [[340, 358], ["torch.Module.__init__", "equalized_layer.EqualizedConv2d", "equalized_layer.EqualizedConv2d", "equalized_layer.EqualizedConv2d", "equalized_layer.EqualizedConv2d", "u_net_2d_discriminator.NonLocalBlock.register_parameter", "equalized_layer.EqualizedConv2d", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ":", "int", ",", "out_channels", ":", "int", ")", "->", "None", ":", "\n", "# Call super constructor", "\n", "        ", "super", "(", "NonLocalBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Init convolutions", "\n", "self", ".", "theta", "=", "equalized_layer", ".", "EqualizedConv2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "out_channels", "//", "8", ",", "\n", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "(", "0", ",", "0", ")", ",", "bias", "=", "False", ")", "\n", "self", ".", "phi", "=", "equalized_layer", ".", "EqualizedConv2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "out_channels", "//", "8", ",", "\n", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "(", "0", ",", "0", ")", ",", "bias", "=", "False", ")", "\n", "self", ".", "g", "=", "equalized_layer", ".", "EqualizedConv2d", "(", "in_channels", "=", "in_channels", ",", "out_channels", "=", "out_channels", "//", "2", ",", "\n", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "(", "0", ",", "0", ")", ",", "bias", "=", "False", ")", "\n", "self", ".", "o", "=", "equalized_layer", ".", "EqualizedConv2d", "(", "in_channels", "=", "out_channels", "//", "2", ",", "out_channels", "=", "out_channels", ",", "\n", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "(", "0", ",", "0", ")", ",", "bias", "=", "False", ")", "\n", "# Init residual mapping", "\n", "self", ".", "residual_mapping", "=", "equalized_layer", ".", "EqualizedConv2d", "(", "\n", "in_channels", "=", "in_channels", ",", "out_channels", "=", "out_channels", ",", "kernel_size", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "(", "0", ",", "0", ")", ",", "\n", "bias", "=", "False", ")", "if", "in_channels", "!=", "out_channels", "else", "nn", ".", "Identity", "(", ")", "\n", "# Init gain parameter", "\n", "self", ".", "register_parameter", "(", "name", "=", "\"gamma\"", ",", "param", "=", "nn", ".", "Parameter", "(", "torch", ".", "tensor", "(", "0.", ")", ",", "requires_grad", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.NonLocalBlock.forward": [[359, 382], ["u_net_2d_discriminator.NonLocalBlock.theta", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "theta.flatten.flatten.flatten", "phi.flatten.flatten.flatten", "g.flatten.flatten.flatten", "torch.softmax", "torch.softmax", "torch.softmax", "u_net_2d_discriminator.NonLocalBlock.o", "u_net_2d_discriminator.NonLocalBlock.phi", "u_net_2d_discriminator.NonLocalBlock.g", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "torch.bmm().view", "math.sqrt", "theta.flatten.flatten.transpose", "u_net_2d_discriminator.NonLocalBlock.residual_mapping", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param input: (torch.Tensor) Input tensor\n        :return: (torch.Tensor) Output tensor\n        \"\"\"", "\n", "# Save input shape", "\n", "batch_size", ",", "_", ",", "height", ",", "width", "=", "input", ".", "shape", "\n", "# Perform convolutional mappings [batch size, out channels // 8, height, width]", "\n", "theta", "=", "self", ".", "theta", "(", "input", ")", "\n", "# [batch size, out channels // 8, height // 2, width // 2]", "\n", "phi", "=", "F", ".", "max_pool2d", "(", "self", ".", "phi", "(", "input", ")", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "# [batch size, out channels // 2, height // 2, width // 2]", "\n", "g", "=", "F", ".", "max_pool2d", "(", "self", ".", "g", "(", "input", ")", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ")", "\n", "# Flatten spatial dimensions", "\n", "theta", "=", "theta", ".", "flatten", "(", "start_dim", "=", "2", ")", "# [batch size, out channels // 8, height * width]", "\n", "phi", "=", "phi", ".", "flatten", "(", "start_dim", "=", "2", ")", "# [batch size, out channels // 8, height // 2 * width // 2]", "\n", "g", "=", "g", ".", "flatten", "(", "start_dim", "=", "2", ")", "# [batch size, out channels // 2, height // 2 * width // 2]", "\n", "# Perform matrix multiplication and softmax [batch size, out channels // 8, out channels // 2]", "\n", "beta", "=", "F", ".", "softmax", "(", "torch", ".", "bmm", "(", "theta", ".", "transpose", "(", "1", ",", "2", ")", ",", "phi", ")", ",", "-", "1", ")", "\n", "# Final matrix multiplication and convolution [batch size, out channels, height, width]", "\n", "output", "=", "self", ".", "o", "(", "torch", ".", "bmm", "(", "g", ",", "beta", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "view", "(", "batch_size", ",", "-", "1", ",", "height", ",", "width", ")", ")", "\n", "return", "(", "self", ".", "gamma", "*", "output", "+", "self", ".", "residual_mapping", "(", "input", ")", ")", "/", "math", ".", "sqrt", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.generate_cut_mix_augmentation_data": [[384, 400], ["u_net_2d_discriminator._generate_binary_cut_mix_map"], "function", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator._generate_binary_cut_mix_map"], ["", "", "def", "generate_cut_mix_augmentation_data", "(", "image_real", ":", "torch", ".", "Tensor", ",", "\n", "image_fake", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    This functions generates the input image and target real fake image for CutMix augmentation.\n    :param image_real: (torch.Tensor) Real image\n    :param image_fake: (torch.Tensor) Fake image\n    :return: (torch.Tensor) Combined input image and corresponding real/fake label\n    \"\"\"", "\n", "# Ensure same dim", "\n", "image_fake", "=", "image_fake", "[", ":", "image_real", ".", "shape", "[", "0", "]", "]", "\n", "# Get target map", "\n", "target", "=", "_generate_binary_cut_mix_map", "(", "height", "=", "image_real", ".", "shape", "[", "-", "2", "]", ",", "width", "=", "image_fake", ".", "shape", "[", "-", "1", "]", ",", "\n", "device", "=", "image_real", ".", "device", ")", "\n", "# Construct input image", "\n", "input_image", "=", "image_real", "*", "target", "+", "image_fake", "*", "(", "-", "target", "+", "1.", ")", "\n", "return", "input_image", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.generate_cut_mix_transformation_data": [[402, 424], ["u_net_2d_discriminator._generate_binary_cut_mix_map"], "function", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator._generate_binary_cut_mix_map"], ["", "def", "generate_cut_mix_transformation_data", "(", "image_real", ":", "torch", ".", "Tensor", ",", "image_fake", ":", "torch", ".", "Tensor", ",", "\n", "prediction_real", ":", "torch", ".", "Tensor", ",", "\n", "prediction_fake", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "    ", "\"\"\"\n    Function generates the input and target for cut mix transformation consistency.\n    :param image_real: (torch.Tensor) Real image\n    :param image_fake: (torch.Tensor) Fake image\n    :param prediction_real: (torch.Tensor) Pixel-wise prediction of discriminator for real image\n    :param prediction_fake: (torch.Tensor) Pixel-wise prediction of discriminator for fake image\n    :return: (torch.Tensor) Combined input image and corresponding combined soft real/fake label\n    \"\"\"", "\n", "# Ensure same dim", "\n", "image_fake", "=", "image_fake", "[", ":", "image_real", ".", "shape", "[", "0", "]", "]", "\n", "prediction_fake", "=", "prediction_fake", "[", ":", "image_real", ".", "shape", "[", "0", "]", "]", "\n", "# Get binary map", "\n", "binary_map", "=", "_generate_binary_cut_mix_map", "(", "height", "=", "image_real", ".", "shape", "[", "-", "2", "]", ",", "width", "=", "image_fake", ".", "shape", "[", "-", "1", "]", ",", "\n", "device", "=", "image_real", ".", "device", ")", "\n", "# Construct input image", "\n", "input_image", "=", "image_real", "*", "binary_map", "+", "image_fake", "*", "(", "-", "binary_map", "+", "1.", ")", "\n", "# Construct target", "\n", "target", "=", "prediction_real", "*", "binary_map", "+", "prediction_fake", "*", "(", "-", "binary_map", "+", "1.", ")", "\n", "return", "input_image", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator._generate_binary_cut_mix_map": [[426, 449], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "torch.randint", "int", "int", "int", "int", "random.random", "random.random"], "function", ["None"], ["", "def", "_generate_binary_cut_mix_map", "(", "height", ":", "int", ",", "width", ":", "int", ",", "\n", "device", ":", "Union", "[", "str", ",", "torch", ".", "device", "]", "=", "\"cpu\"", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    This function generate a random binary map with two areas for cut mix augmentation of consistency regularization.\n    :param height: (int) Height of the map\n    :param width: (int) Width of the map\n    :param device: (Union[str, torch.device]) Device to utilize\n    :return: (torch.Tensor) Binary map\n    \"\"\"", "\n", "# Make target", "\n", "binary_map", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "1", ",", "height", ",", "width", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "# Generate a random coordinates to perform cut", "\n", "cut_coordinates_height", "=", "torch", ".", "randint", "(", "int", "(", "0.1", "*", "height", ")", ",", "int", "(", "0.9", "*", "height", ")", ",", "size", "=", "(", "1", ",", ")", ")", "\n", "cut_coordinates_width", "=", "torch", ".", "randint", "(", "int", "(", "0.1", "*", "width", ")", ",", "int", "(", "0.9", "*", "width", ")", ",", "size", "=", "(", "1", ",", ")", ")", "\n", "# Apply coordinates", "\n", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "binary_map", "[", "...", ",", "cut_coordinates_height", ":", ",", "cut_coordinates_width", ":", "]", "=", "1.0", "\n", "", "else", ":", "\n", "        ", "binary_map", "[", "...", ",", ":", "cut_coordinates_height", ",", ":", "cut_coordinates_width", "]", "=", "1.0", "\n", "# Invert target randomly", "\n", "", "if", "random", ".", "random", "(", ")", ">", "0.5", ":", "\n", "        ", "binary_map", "=", "-", "binary_map", "+", "1.", "\n", "", "return", "binary_map", "\n", "", ""]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.__init__": [[18, 49], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "dict", "dict", "dict", "os.getcwd", "datetime.datetime.datetime.now().strftime", "datetime.datetime.datetime.now"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "experiment_path", ":", "str", "=", "\n", "os", ".", "path", ".", "join", "(", "os", ".", "getcwd", "(", ")", ",", "\"experiments\"", ",", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%d_%m_%Y__%H_%M_%S\"", ")", ")", ",", "\n", "experiment_path_extension", ":", "str", "=", "\"\"", ",", "\n", "path_metrics", ":", "str", "=", "\"metrics\"", ",", "\n", "path_hyperparameters", ":", "str", "=", "\"hyperparameters\"", ",", "\n", "path_plots", ":", "str", "=", "\"plots\"", ",", "\n", "path_models", ":", "str", "=", "\"models\"", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param path_metrics: (str) Path to folder in which all metrics are stored\n        :param experiment_path_extension: (str) Extension to experiment folder\n        :param path_hyperparameters: (str)  Path to folder in which all hyperparameters are stored\n        :param path_plots: (str)  Path to folder in which all plots are stored\n        :param path_models: (str)  Path to folder in which all models are stored\n        \"\"\"", "\n", "experiment_path", "=", "experiment_path", "+", "experiment_path_extension", "\n", "# Save parameters", "\n", "self", ".", "path_metrics", "=", "os", ".", "path", ".", "join", "(", "experiment_path", ",", "path_metrics", ")", "\n", "self", ".", "path_hyperparameters", "=", "os", ".", "path", ".", "join", "(", "experiment_path", ",", "path_hyperparameters", ")", "\n", "self", ".", "path_plots", "=", "os", ".", "path", ".", "join", "(", "experiment_path", ",", "path_plots", ")", "\n", "self", ".", "path_models", "=", "os", ".", "path", ".", "join", "(", "experiment_path", ",", "path_models", ")", "\n", "# Init folders", "\n", "os", ".", "makedirs", "(", "self", ".", "path_metrics", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "path_hyperparameters", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "path_plots", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "path_models", ",", "exist_ok", "=", "True", ")", "\n", "# Init dicts to store the metrics and hyperparameters", "\n", "self", ".", "metrics", "=", "dict", "(", ")", "\n", "self", ".", "temp_metrics", "=", "dict", "(", ")", "\n", "self", ".", "hyperparameters", "=", "dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_metric": [[50, 60], ["misc.Logger.metrics[].append", "float", "float"], "methods", ["None"], ["", "def", "log_metric", "(", "self", ",", "metric_name", ":", "str", ",", "value", ":", "Any", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Method writes a given metric value into a dict including list for every metric.\n        :param metric_name: (str) Name of the metric\n        :param value: (float) Value of the metric\n        \"\"\"", "\n", "if", "metric_name", "in", "self", ".", "metrics", ":", "\n", "            ", "self", ".", "metrics", "[", "metric_name", "]", ".", "append", "(", "float", "(", "value", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "metrics", "[", "metric_name", "]", "=", "[", "float", "(", "value", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_temp_metric": [[61, 71], ["misc.Logger.temp_metrics[].append", "float", "float"], "methods", ["None"], ["", "", "def", "log_temp_metric", "(", "self", ",", "metric_name", ":", "str", ",", "value", ":", "Any", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Method writes a given metric value into a dict including temporal metrics.\n        :param metric_name: (str) Name of the metric\n        :param value: (float) Value of the metric\n        \"\"\"", "\n", "if", "metric_name", "in", "self", ".", "temp_metrics", ":", "\n", "            ", "self", ".", "temp_metrics", "[", "metric_name", "]", ".", "append", "(", "float", "(", "value", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "temp_metrics", "[", "metric_name", "]", "=", "[", "float", "(", "value", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.save_temp_metric": [[72, 100], ["dict", "isinstance", "dict", "misc.Logger.save", "float", "misc.Logger.log_metric", "torch.tensor().mean", "torch.tensor().mean", "torch.tensor().mean", "torch.tensor().mean", "float", "misc.Logger.log_metric", "torch.tensor().mean", "torch.tensor().mean", "torch.tensor().mean", "torch.tensor().mean", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.save", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_metric", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_metric"], ["", "", "def", "save_temp_metric", "(", "self", ",", "metric_name", ":", "Union", "[", "Iterable", "[", "str", "]", ",", "str", "]", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "\"\"\"\n        Method writes temporal metrics into the metrics dict by averaging.\n        :param metric_name: (Union[Iterable[str], str]) One temporal metric name ore a list of names\n        \"\"\"", "\n", "averaged_temp_dict", "=", "dict", "(", ")", "\n", "# Case if only one metric is given", "\n", "if", "isinstance", "(", "metric_name", ",", "str", ")", ":", "\n", "# Calc average", "\n", "            ", "value", "=", "float", "(", "torch", ".", "tensor", "(", "self", ".", "temp_metrics", "[", "metric_name", "]", ")", ".", "mean", "(", ")", ")", "\n", "# Save metric in log dict", "\n", "self", ".", "log_metric", "(", "metric_name", "=", "metric_name", ",", "value", "=", "value", ")", "\n", "# Put metric also in dict to be returned", "\n", "averaged_temp_dict", "[", "metric_name", "]", "=", "value", "\n", "# Case if multiple metrics are given", "\n", "", "else", ":", "\n", "            ", "for", "name", "in", "metric_name", ":", "\n", "# Calc average", "\n", "                ", "value", "=", "float", "(", "torch", ".", "tensor", "(", "self", ".", "temp_metrics", "[", "name", "]", ")", ".", "mean", "(", ")", ")", "\n", "# Save metric in log dict", "\n", "self", ".", "log_metric", "(", "metric_name", "=", "name", ",", "value", "=", "value", ")", "\n", "# Put metric also in dict to be returned", "\n", "averaged_temp_dict", "[", "name", "]", "=", "value", "\n", "# Reset temp metrics", "\n", "", "", "self", ".", "temp_metrics", "=", "dict", "(", ")", "\n", "# Save logs", "\n", "self", ".", "save", "(", ")", "\n", "return", "averaged_temp_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_hyperparameter": [[101, 123], ["hyperparameter_dict.keys", "misc.Logger.hyperparameters[].append", "str", "str", "misc.Logger.hyperparameters.keys", "misc.Logger.hyperparameters[].append", "str", "str"], "methods", ["None"], ["", "def", "log_hyperparameter", "(", "self", ",", "hyperparameter_name", ":", "str", "=", "None", ",", "value", ":", "Any", "=", "None", ",", "\n", "hyperparameter_dict", ":", "Dict", "[", "str", ",", "Any", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Method writes a given hyperparameter into a dict including all other hyperparameters.\n        :param hyperparameter_name: (str) Name of the hyperparameter\n        :param value: (Any) Value of the hyperparameter, must by convertible to str\n        :param hyperparameter_dict: (Dict[str, Any]) Dict of multiple hyperparameter to be saved\n        \"\"\"", "\n", "# Case if name and value are given", "\n", "if", "(", "hyperparameter_name", "is", "not", "None", ")", "and", "(", "value", "is", "not", "None", ")", ":", "\n", "            ", "if", "hyperparameter_name", "in", "self", ".", "hyperparameters", ":", "\n", "                ", "self", ".", "hyperparameters", "[", "hyperparameter_name", "]", ".", "append", "(", "str", "(", "value", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "hyperparameters", "[", "hyperparameter_name", "]", "=", "[", "str", "(", "value", ")", "]", "\n", "# Case if dict of hyperparameters is given", "\n", "", "", "if", "hyperparameter_dict", "is", "not", "None", ":", "\n", "# Iterate over given dict, cast data and store in internal hyperparameters dict", "\n", "            ", "for", "key", "in", "hyperparameter_dict", ".", "keys", "(", ")", ":", "\n", "                ", "if", "key", "in", "self", ".", "hyperparameters", ".", "keys", "(", ")", ":", "\n", "                    ", "self", ".", "hyperparameters", "[", "key", "]", ".", "append", "(", "str", "(", "hyperparameter_dict", "[", "key", "]", ")", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "hyperparameters", "[", "key", "]", "=", "[", "str", "(", "hyperparameter_dict", "[", "key", "]", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.save_checkpoint": [[124, 131], ["torch.save", "torch.save", "torch.save", "torch.save", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.save", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.save", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.save", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.save"], ["", "", "", "", "def", "save_checkpoint", "(", "self", ",", "file_name", ":", "str", ",", "checkpoint_dict", ":", "Dict", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        This method saves a given checkpoint.\n        :param name: (str) File name with file format\n        :param model: (Dict) Dict including all modules\n        \"\"\"", "\n", "torch", ".", "save", "(", "checkpoint_dict", ",", "os", ".", "path", ".", "join", "(", "self", ".", "path_models", ",", "file_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.save_prediction": [[132, 167], ["range", "bf_images.repeat_interleave.repeat_interleave.repeat_interleave", "torchvision.utils.save_image", "gfp_images.repeat_interleave.repeat_interleave.repeat_interleave", "rfp_images.repeat_interleave.repeat_interleave.repeat_interleave", "torchvision.utils.save_image", "torchvision.utils.save_image", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "save_prediction", "(", "self", ",", "prediction", ":", "torch", ".", "Tensor", ",", "name", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        This method saves the image predictions as an png image\n        :param prediction: (torch.Tensor) Prediction of the shape [batch size, 2, time steps, height, width]\n        :param name: (torch.Tensor) Name of the images without ending!\n        \"\"\"", "\n", "for", "batch_index", "in", "range", "(", "prediction", ".", "shape", "[", "0", "]", ")", ":", "\n", "# Get images and normalize shape [time steps, 1, height, width]", "\n", "            ", "bf_images", "=", "prediction", "[", "batch_index", ",", "0", "]", "[", ":", ",", "None", "]", "\n", "# Make bf to rgb", "\n", "bf_images", "=", "bf_images", ".", "repeat_interleave", "(", "3", ",", "dim", "=", "1", ")", "\n", "if", "prediction", ".", "shape", "[", "1", "]", ">", "1", ":", "\n", "                ", "gfp_images", "=", "prediction", "[", "batch_index", ",", "1", "]", "[", ":", ",", "None", "]", "\n", "# Make gfp to rgb only green shades", "\n", "gfp_images", "=", "gfp_images", ".", "repeat_interleave", "(", "3", ",", "dim", "=", "1", ")", "\n", "gfp_images", "[", ":", ",", "0", "]", "=", "0.0", "\n", "gfp_images", "[", ":", ",", "2", "]", "=", "0.0", "\n", "", "if", "prediction", ".", "shape", "[", "1", "]", ">", "2", ":", "\n", "                ", "rfp_images", "=", "prediction", "[", "batch_index", ",", "2", "]", "[", ":", ",", "None", "]", "\n", "# Make rfp to rgb only red shades", "\n", "rfp_images", "=", "rfp_images", ".", "repeat_interleave", "(", "3", ",", "dim", "=", "1", ")", "\n", "rfp_images", "[", ":", ",", "1", "]", "=", "0.0", "\n", "rfp_images", "[", ":", ",", "2", "]", "=", "0.0", "\n", "# Save images", "\n", "", "torchvision", ".", "utils", ".", "save_image", "(", "tensor", "=", "bf_images", ",", "\n", "fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "path_plots", ",", "name", "+", "\"_bf_{}.png\"", ".", "format", "(", "batch_index", ")", ")", ",", "\n", "nrow", "=", "bf_images", ".", "shape", "[", "0", "]", ",", "padding", "=", "0", ")", "\n", "if", "prediction", ".", "shape", "[", "1", "]", ">", "1", ":", "\n", "                ", "torchvision", ".", "utils", ".", "save_image", "(", "tensor", "=", "gfp_images", ",", "\n", "fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "path_plots", ",", "name", "+", "\"_gfp_{}.png\"", ".", "format", "(", "batch_index", ")", ")", ",", "\n", "nrow", "=", "gfp_images", ".", "shape", "[", "0", "]", ",", "padding", "=", "0", ")", "\n", "", "if", "prediction", ".", "shape", "[", "1", "]", ">", "2", ":", "\n", "                ", "torchvision", ".", "utils", ".", "save_image", "(", "tensor", "=", "rfp_images", ",", "\n", "fp", "=", "os", ".", "path", ".", "join", "(", "self", ".", "path_plots", ",", "name", "+", "\"_rfp_{}.png\"", ".", "format", "(", "batch_index", ")", ")", ",", "\n", "nrow", "=", "gfp_images", ".", "shape", "[", "0", "]", ",", "padding", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.save": [[168, 181], ["misc.Logger.metrics.items", "open", "json.dump", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.save", "torch.save", "torch.save", "torch.save", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.save", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.save", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.save", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.save"], ["", "", "", "def", "save", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Method saves all current logs (metrics and hyperparameters). Plots are saved directly.\n        \"\"\"", "\n", "# Save dict of hyperparameter as json file", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_hyperparameters", ",", "'hyperparameter.txt'", ")", ",", "'w'", ")", "as", "json_file", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "hyperparameters", ",", "json_file", ")", "\n", "# Iterate items in metrics dict", "\n", "", "for", "metric_name", ",", "values", "in", "self", ".", "metrics", ".", "items", "(", ")", ":", "\n", "# Convert list of values to torch tensor to use build in save method from torch", "\n", "            ", "values", "=", "torch", ".", "tensor", "(", "values", ")", "\n", "# Save values", "\n", "torch", ".", "save", "(", "values", ",", "os", ".", "path", ".", "join", "(", "self", ".", "path_metrics", ",", "'{}.pt'", ".", "format", "(", "metric_name", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.exponential_moving_average": [[183, 200], ["torch.no_grad", "torch.no_grad", "dict", "dict", "dict.keys", "type", "type", "model_ema.named_parameters", "model_train.named_parameters", "model_ema_dict[].data.mul_().add_", "model_ema_dict[].data.mul_"], "function", ["None"], ["", "", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "exponential_moving_average", "(", "model_ema", ":", "Union", "[", "torch", ".", "nn", ".", "Module", ",", "nn", ".", "DataParallel", "]", ",", "\n", "model_train", ":", "Union", "[", "torch", ".", "nn", ".", "Module", ",", "nn", ".", "DataParallel", "]", ",", "decay", ":", "float", "=", "0.999", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Function apples one exponential moving average step to a given model to be accumulated and a given training model\n    :param model_ema: (Union[torch.nn.Module, nn.DataParallel]) Model to be accumulated\n    :param model_train: (Union[torch.nn.Module, nn.DataParallel]) Training model\n    :param decay: (float) Decay factor\n    \"\"\"", "\n", "# Check types", "\n", "assert", "type", "(", "model_ema", ")", "is", "type", "(", "model_train", ")", ",", "'EMA can only be performed on networks of the same type!'", "\n", "# Get parameter dicts", "\n", "model_ema_dict", "=", "dict", "(", "model_ema", ".", "named_parameters", "(", ")", ")", "\n", "model_train_dict", "=", "dict", "(", "model_train", ".", "named_parameters", "(", ")", ")", "\n", "# Apply ema", "\n", "for", "key", "in", "model_ema_dict", ".", "keys", "(", ")", ":", "\n", "        ", "model_ema_dict", "[", "key", "]", ".", "data", ".", "mul_", "(", "decay", ")", ".", "add_", "(", "1", "-", "decay", ",", "model_train_dict", "[", "key", "]", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.random_permutation": [[202, 214], ["torch.from_numpy", "torch.from_numpy", "torch.equal", "torch.equal", "numpy.random.choice", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "range"], "function", ["None"], ["", "", "def", "random_permutation", "(", "n", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Function generates a random permutation without current permutation ([0, 1, 2, ...]).\n    :param n: (int) Number of elements\n    :return: (torch.Tensor) Permutation tensor\n    \"\"\"", "\n", "# Get random permutation", "\n", "permutation", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "choice", "(", "range", "(", "n", ")", ",", "size", "=", "n", ")", ")", "\n", "# Check of default permutation is present", "\n", "if", "torch", ".", "equal", "(", "permutation", ",", "torch", ".", "arange", "(", "n", ")", ")", ":", "\n", "        ", "permutation", "=", "torch", ".", "arange", "(", "start", "=", "n", "-", "1", ",", "end", "=", "-", "1", ",", "step", "=", "-", "1", ")", "\n", "", "return", "permutation", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.normalize_0_1_batch": [[216, 226], ["input.view", "torch.min", "torch.min", "torch.max", "torch.max", "torch.min", "torch.min"], "function", ["None"], ["", "def", "normalize_0_1_batch", "(", "input", ":", "torch", ".", "tensor", ")", "->", "torch", ".", "tensor", ":", "\n", "    ", "\"\"\"\n    Normalize a given tensor batch wise to a range of [0, 1]\n    :param input: (Torch tensor) Input tensor\n    :return: (Torch tensor) Normalized output tensor\n    \"\"\"", "\n", "input_flatten", "=", "input", ".", "view", "(", "input", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "return", "(", "(", "input", "-", "torch", ".", "min", "(", "input_flatten", ",", "dim", "=", "1", ")", "[", "0", "]", "[", ":", ",", "None", ",", "None", ",", "None", ",", "None", "]", ")", "/", "(", "\n", "torch", ".", "max", "(", "input_flatten", ",", "dim", "=", "1", ")", "[", "0", "]", "[", ":", ",", "None", ",", "None", ",", "None", ",", "None", "]", "-", "\n", "torch", ".", "min", "(", "input_flatten", ",", "dim", "=", "1", ")", "[", "0", "]", "[", ":", ",", "None", ",", "None", ",", "None", ",", "None", "]", ")", ")", ".", "clamp", "(", "min", "=", "1e-03", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.normalize_m1_1_batch": [[228, 236], ["misc.normalize_0_1_batch"], "function", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.normalize_0_1_batch"], ["", "def", "normalize_m1_1_batch", "(", "input", ":", "torch", ".", "tensor", ")", "->", "torch", ".", "tensor", ":", "\n", "    ", "\"\"\"\n    Normalize a given tensor batch wise to a range of [-1, 1]\n    :param input: (Torch tensor) Input tensor\n    :return: (Torch tensor) Normalized output tensor\n    \"\"\"", "\n", "output", "=", "2.", "*", "normalize_0_1_batch", "(", "input", ")", "-", "1.", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.get_noise": [[238, 253], ["list", "torch.randn", "torch.randn", "random.random", "torch.randn().unbind", "torch.randn().unbind", "torch.randn", "torch.randn"], "function", ["None"], ["", "def", "get_noise", "(", "batch_size", ":", "int", ",", "latent_dimension", ",", "p_mixed_noise", ":", "float", "=", "0.9", ",", "device", ":", "str", "=", "'cuda'", ")", "->", "Union", "[", "\n", "torch", ".", "Tensor", ",", "List", "]", ":", "\n", "    ", "\"\"\"\n    Function returns an input noise for the style gan 2 generator.\n    Iter a list of two noise vectors or one noise vector will be returned.\n    :param batch_size: (int) Batch size to be used\n    :param latent_dimension: (int) Latent dimensions to be utilized\n    :param p_mixed_noise: (int) Probability that a mixed noise will be returned\n    :param device: (str) Device to be utilized\n    :return: List of noise tensors or single noise tensor\n    \"\"\"", "\n", "if", "(", "p_mixed_noise", ">", "0", ")", "and", "(", "random", ".", "random", "(", ")", "<", "p_mixed_noise", ")", ":", "\n", "        ", "return", "list", "(", "torch", ".", "randn", "(", "2", ",", "batch_size", ",", "latent_dimension", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", ".", "unbind", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "torch", ".", "randn", "(", "batch_size", ",", "latent_dimension", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.model_wrapper.ModelWrapper.__init__": [[22, 103], ["loss.NonSaturatingLogisticGeneratorLoss", "loss.NonSaturatingLogisticDiscriminatorLoss", "loss.R1Regularization", "loss.NonSaturatingLogisticDiscriminatorLossCutMix", "torch.MSELoss", "torch.MSELoss", "loss.PathLengthRegularization", "model_wrapper.ModelWrapper.generator_ema.eval", "isinstance", "misc.get_noise", "isinstance", "copy.deepcopy().to", "torch.DataParallel", "torch.DataParallel", "copy.deepcopy().to", "copy.deepcopy", "copy.deepcopy", "model_wrapper.ModelWrapper.generator.module.cpu", "model_wrapper.ModelWrapper.generator.cpu"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.get_noise"], ["def", "__init__", "(", "self", ",", "\n", "generator", ":", "Union", "[", "nn", ".", "Module", ",", "nn", ".", "DataParallel", "]", ",", "\n", "discriminator", ":", "Union", "[", "nn", ".", "Module", ",", "nn", ".", "DataParallel", "]", ",", "\n", "generator_optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "\n", "discriminator_optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "\n", "training_dataset", ":", "DataLoader", ",", "\n", "data_logger", ":", "misc", ".", "Logger", ",", "\n", "validation_metrics", ":", "Tuple", "[", "Callable", ",", "...", "]", ",", "\n", "hyperparameters", ":", "Dict", "[", "str", ",", "Any", "]", ",", "\n", "trap_weights_map", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "generator_loss", ":", "nn", ".", "Module", "=", "loss", ".", "NonSaturatingLogisticGeneratorLoss", "(", ")", ",", "\n", "discriminator_loss", ":", "nn", ".", "Module", "=", "loss", ".", "NonSaturatingLogisticDiscriminatorLoss", "(", ")", ",", "\n", "discriminator_regularization_loss", ":", "nn", ".", "Module", "=", "loss", ".", "R1Regularization", "(", ")", ",", "\n", "cut_mix_augmentation_loss", ":", "nn", ".", "Module", "=", "loss", ".", "NonSaturatingLogisticDiscriminatorLossCutMix", "(", ")", ",", "\n", "cut_mix_regularization_loss", ":", "nn", ".", "Module", "=", "nn", ".", "MSELoss", "(", "reduction", "=", "\"mean\"", ")", ",", "\n", "path_length_regularization", ":", "nn", ".", "Module", "=", "loss", ".", "PathLengthRegularization", "(", ")", ",", "\n", "generator_ema", ":", "Optional", "[", "Union", "[", "nn", ".", "Module", ",", "nn", ".", "DataParallel", "]", "]", "=", "None", ",", "\n", "device", ":", "str", "=", "\"cuda\"", ",", "\n", "discriminator_learning_rate_schedule", ":", "Optional", "[", "object", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param generator: (Union[nn.Module, nn.DataParallel]) Generator network\n        :param discriminator: (Union[nn.Module, nn.DataParallel]) Generator network\n        :param generator_optimizer: (torch.optim.Optimizer) Generator optimizer\n        :param discriminator_optimizer: (torch.optim.Optimizer) Discriminator optimizer\n        :param training_dataset: (DataLoader) Training dataset\n        :param data_logger: (misc.Logger) Custom data logger\n        :param validation_metrics: (Tuple[Callable, ...]) Tuple of validation metrics to be utilized\n        :param hyperparameters: (Dict[str, Any]) Hyperparameter dict\n        :param trap_weights_map: (Optional[torch.Tensor]) Optional weights map for trap region\n        :param generator_loss: (nn.Module) Generator loss function\n        :param discriminator_loss: (nn.Module) Discriminator loss function\n        :param discriminator_regularization_loss: (nn.Module) Dis. regularization loss\n        :param cut_mix_augmentation_loss: (nn.Module) Cut mix augmentation loss\n        :param cut_mix_regularization_loss: (nn.Module) Cut mix regularization loss\n        :param path_length_regularization: (nn.Module) Path length regularization loss\n        :param generator_ema: (Optional[Union[nn.Module, nn.DataParallel]]) Generator for EMA\n        :param device: (str) Device to be utilized (only cuda supported!)\n        :param discriminator_learning_rate_schedule: (Optional[object]) Optional discriminator lr schedule\n        \"\"\"", "\n", "# Save parameters", "\n", "self", ".", "generator", "=", "generator", "\n", "self", ".", "discriminator", "=", "discriminator", "\n", "self", ".", "generator_optimizer", "=", "generator_optimizer", "\n", "self", ".", "discriminator_optimizer", "=", "discriminator_optimizer", "\n", "self", ".", "training_dataset", "=", "training_dataset", "\n", "self", ".", "data_logger", "=", "data_logger", "\n", "self", ".", "validation_metrics", "=", "validation_metrics", "\n", "self", ".", "trap_weights_map", "=", "trap_weights_map", "\n", "self", ".", "generator_loss", "=", "generator_loss", "\n", "self", ".", "discriminator_loss", "=", "discriminator_loss", "\n", "self", ".", "discriminator_regularization_loss", "=", "discriminator_regularization_loss", "\n", "self", ".", "cut_mix_augmentation_loss", "=", "cut_mix_augmentation_loss", "\n", "self", ".", "cut_mix_regularization_loss", "=", "cut_mix_regularization_loss", "\n", "self", ".", "path_length_regularization", "=", "path_length_regularization", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "hyperparameters", "=", "hyperparameters", "\n", "self", ".", "discriminator_learning_rate_schedule", "=", "discriminator_learning_rate_schedule", "\n", "# Make copy of generator to perform ema", "\n", "if", "generator_ema", "is", "None", ":", "\n", "            ", "if", "isinstance", "(", "self", ".", "generator", ",", "nn", ".", "DataParallel", ")", ":", "\n", "                ", "self", ".", "generator_ema", "=", "copy", ".", "deepcopy", "(", "self", ".", "generator", ".", "module", ".", "cpu", "(", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "generator_ema", "=", "nn", ".", "DataParallel", "(", "self", ".", "generator_ema", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "generator_ema", "=", "copy", ".", "deepcopy", "(", "self", ".", "generator", ".", "cpu", "(", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "generator_ema", "=", "generator_ema", "\n", "# Model into eval mode", "\n", "", "self", ".", "generator_ema", ".", "eval", "(", ")", "\n", "# Get latent dimensions", "\n", "if", "isinstance", "(", "self", ".", "generator", ",", "nn", ".", "DataParallel", ")", ":", "\n", "            ", "self", ".", "latent_dimensions", "=", "self", ".", "generator", ".", "module", ".", "latent_dimensions", "\n", "", "else", ":", "\n", "            ", "self", ".", "latent_dimensions", "=", "self", ".", "generator", ".", "latent_dimensions", "\n", "# Init best fid", "\n", "", "self", ".", "best_fvd", "=", "np", ".", "inf", "\n", "# Init validation input noise", "\n", "self", ".", "validation_input_noise", "=", "misc", ".", "get_noise", "(", "batch_size", "=", "15", ",", "\n", "latent_dimension", "=", "self", ".", "latent_dimensions", ",", "\n", "p_mixed_noise", "=", "1.0", ",", "\n", "device", "=", "\"cuda\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.model_wrapper.ModelWrapper.train": [[104, 196], ["rtpt.rtpt.RTPT.rtpt.RTPT", "rtpt.rtpt.RTPT.rtpt.RTPT.start", "model_wrapper.ModelWrapper.generator.to", "model_wrapper.ModelWrapper.discriminator.to", "tqdm.tqdm.tqdm", "range", "loss.TopK", "torch.Identity", "torch.Identity", "model_wrapper.ModelWrapper.generator.train", "model_wrapper.ModelWrapper.discriminator.train", "rtpt.rtpt.RTPT.rtpt.RTPT.step", "model_wrapper.ModelWrapper._gan_training", "model_wrapper.ModelWrapper.data_logger.save", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model_wrapper.ModelWrapper.generator.eval", "model_wrapper.ModelWrapper.generator_ema.eval", "isinstance", "isinstance", "model_wrapper.ModelWrapper.data_logger.save_prediction", "model_wrapper.ModelWrapper.data_logger.save_prediction", "model_wrapper.ModelWrapper.data_logger.save_prediction", "model_wrapper.ModelWrapper.data_logger.save_prediction", "model_wrapper.ModelWrapper.validation", "model_wrapper.ModelWrapper.data_logger.save_checkpoint", "model_wrapper.ModelWrapper.discriminator_learning_rate_schedule.step", "int", "int", "len", "model_wrapper.ModelWrapper.generator_ema.module", "model_wrapper.ModelWrapper.generator_ema.module", "model_wrapper.ModelWrapper.generator_ema", "model_wrapper.ModelWrapper.generator_ema", "model_wrapper.ModelWrapper.generator.module", "model_wrapper.ModelWrapper.generator.module", "model_wrapper.ModelWrapper.generator", "model_wrapper.ModelWrapper.generator", "len", "len", "model_wrapper.ModelWrapper.generator_ema.state_dict", "model_wrapper.ModelWrapper.generator.state_dict", "model_wrapper.ModelWrapper.generator_optimizer.state_dict", "model_wrapper.ModelWrapper.discriminator.state_dict", "model_wrapper.ModelWrapper.discriminator_optimizer.state_dict", "model_wrapper.ModelWrapper.path_length_regularization.state_dict"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.model_wrapper.ModelWrapper.train", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.model_wrapper.ModelWrapper.train", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.model_wrapper.ModelWrapper._gan_training", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.save", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.save_prediction", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.save_prediction", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.save_prediction", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.save_prediction", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.model_wrapper.ModelWrapper.validation", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.save_checkpoint"], ["", "def", "train", "(", "self", ",", "epochs", ":", "int", "=", "20", ",", "validate_after_n_epochs", ":", "int", "=", "10", ",", "\n", "save_model_after_n_epochs", ":", "int", "=", "5", ",", "resume_training", ":", "bool", "=", "False", ",", "\n", "top_k", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Training method\n        :param epochs: (int) Epochs to perform\n        :param validate_after_n_epochs: (int) Validate generator after given number of epochs\n        :param save_model_after_n_epochs: (int) Save models after a given number of epochs\n        :param resume_training: (bool) If true training is resumed and cut mix and wrong order reg/aug used\n        :param top_k: (bool) If true top-k is utilized\n        \"\"\"", "\n", "# Init top-k", "\n", "if", "top_k", ":", "\n", "            ", "top_k", "=", "loss", ".", "TopK", "(", "\n", "starting_iteration", "=", "int", "(", "self", ".", "hyperparameters", "[", "\"top_k_start\"", "]", "*", "epochs", "*", "len", "(", "self", ".", "training_dataset", ")", ")", ",", "\n", "final_iteration", "=", "int", "(", "self", ".", "hyperparameters", "[", "\"top_k_finish\"", "]", "*", "epochs", "\n", "*", "len", "(", "self", ".", "training_dataset", ")", ")", ")", "\n", "if", "resume_training", ":", "\n", "                ", "top_k", ".", "starting_iteration", "=", "0", "\n", "top_k", ".", "final_iteration", "=", "1", "\n", "", "", "else", ":", "\n", "            ", "top_k", "=", "nn", ".", "Identity", "(", ")", "\n", "# Save parameters", "\n", "", "self", ".", "epochs", "=", "epochs", "\n", "# Init RTPT", "\n", "rtpt", "=", "RTPT", "(", "name_initials", "=", "\"CR\"", ",", "experiment_name", "=", "\"DeepFovea++\"", ",", "max_iterations", "=", "epochs", ")", "\n", "# Start RTPT", "\n", "rtpt", ".", "start", "(", ")", "\n", "# Models to device", "\n", "self", ".", "generator", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "discriminator", ".", "to", "(", "self", ".", "device", ")", "\n", "# Init progress bar", "\n", "self", ".", "progress_bar", "=", "tqdm", "(", "total", "=", "epochs", "*", "len", "(", "self", ".", "training_dataset", ")", ")", "\n", "# Main loop", "\n", "for", "self", ".", "epoch", "in", "range", "(", "epochs", ")", ":", "\n", "# Models into training mode", "\n", "            ", "self", ".", "generator", ".", "train", "(", ")", "\n", "self", ".", "discriminator", ".", "train", "(", ")", "\n", "# Update RTPT", "\n", "rtpt", ".", "step", "(", ")", "\n", "# Perform gan training", "\n", "self", ".", "_gan_training", "(", "resume_training", "=", "resume_training", ",", "top_k", "=", "top_k", ")", "\n", "# Make validation plots", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Models into eval mode", "\n", "                ", "self", ".", "generator", ".", "eval", "(", ")", "\n", "self", ".", "generator_ema", ".", "eval", "(", ")", "\n", "# Make predictions", "\n", "if", "isinstance", "(", "self", ".", "generator_ema", ",", "nn", ".", "DataParallel", ")", ":", "\n", "                    ", "predictions_ema", "=", "self", ".", "generator_ema", ".", "module", "(", "input", "=", "self", ".", "validation_input_noise", ",", "\n", "randomize_noise", "=", "False", ")", "\n", "predictions_ema_rand", "=", "self", ".", "generator_ema", ".", "module", "(", "input", "=", "self", ".", "validation_input_noise", ",", "\n", "randomize_noise", "=", "True", ")", "\n", "", "else", ":", "\n", "                    ", "predictions_ema", "=", "self", ".", "generator_ema", "(", "input", "=", "self", ".", "validation_input_noise", ",", "randomize_noise", "=", "False", ")", "\n", "predictions_ema_rand", "=", "self", ".", "generator_ema", "(", "input", "=", "self", ".", "validation_input_noise", ",", "randomize_noise", "=", "True", ")", "\n", "", "if", "isinstance", "(", "self", ".", "generator", ",", "nn", ".", "DataParallel", ")", ":", "\n", "                    ", "predictions", "=", "self", ".", "generator", ".", "module", "(", "input", "=", "self", ".", "validation_input_noise", ",", "randomize_noise", "=", "False", ")", "\n", "predictions_rand", "=", "self", ".", "generator", ".", "module", "(", "input", "=", "self", ".", "validation_input_noise", ",", "randomize_noise", "=", "True", ")", "\n", "", "else", ":", "\n", "                    ", "predictions", "=", "self", ".", "generator", "(", "input", "=", "self", ".", "validation_input_noise", ",", "randomize_noise", "=", "False", ")", "\n", "predictions_rand", "=", "self", ".", "generator", "(", "input", "=", "self", ".", "validation_input_noise", ",", "randomize_noise", "=", "True", ")", "\n", "# Save predictions", "\n", "", "self", ".", "data_logger", ".", "save_prediction", "(", "prediction", "=", "predictions_ema", ",", "\n", "name", "=", "\"prediction_ema_{}\"", ".", "format", "(", "self", ".", "epoch", "+", "1", ")", ")", "\n", "self", ".", "data_logger", ".", "save_prediction", "(", "prediction", "=", "predictions_ema_rand", ",", "\n", "name", "=", "\"prediction_ema_rand_{}\"", ".", "format", "(", "self", ".", "epoch", "+", "1", ")", ")", "\n", "self", ".", "data_logger", ".", "save_prediction", "(", "prediction", "=", "predictions", ",", "\n", "name", "=", "\"prediction_{}\"", ".", "format", "(", "self", ".", "epoch", "+", "1", ")", ")", "\n", "self", ".", "data_logger", ".", "save_prediction", "(", "prediction", "=", "predictions_rand", ",", "\n", "name", "=", "\"prediction_rand_{}\"", ".", "format", "(", "self", ".", "epoch", "+", "1", ")", ")", "\n", "# Perform gan validation", "\n", "", "if", "(", "(", "self", ".", "epoch", "+", "1", ")", "%", "validate_after_n_epochs", "==", "0", ")", ":", "\n", "                ", "self", ".", "validation", "(", ")", "\n", "# Save logs", "\n", "", "self", ".", "data_logger", ".", "save", "(", ")", "\n", "# Save models and optimizers", "\n", "if", "(", "(", "self", ".", "epoch", "+", "1", ")", "%", "save_model_after_n_epochs", ")", "==", "0", ":", "\n", "                ", "self", ".", "data_logger", ".", "save_checkpoint", "(", "\n", "file_name", "=", "\"checkpoint_{}.pt\"", ".", "format", "(", "self", ".", "epoch", "+", "1", ")", ",", "\n", "checkpoint_dict", "=", "{", "\n", "\"generator_ema\"", ":", "self", ".", "generator_ema", ".", "state_dict", "(", ")", ",", "\n", "\"generator\"", ":", "self", ".", "generator", ".", "state_dict", "(", ")", ",", "\n", "\"generator_optimizer\"", ":", "self", ".", "generator_optimizer", ".", "state_dict", "(", ")", ",", "\n", "\"discriminator\"", ":", "self", ".", "discriminator", ".", "state_dict", "(", ")", ",", "\n", "\"discriminator_optimizer\"", ":", "self", ".", "discriminator_optimizer", ".", "state_dict", "(", ")", ",", "\n", "\"path_length_regularization\"", ":", "self", ".", "path_length_regularization", ".", "state_dict", "(", ")", ",", "\n", "}", "\n", ")", "\n", "# Perform learning rate schedule if utilized", "\n", "", "if", "self", ".", "discriminator_learning_rate_schedule", "is", "not", "None", ":", "\n", "                ", "self", ".", "discriminator_learning_rate_schedule", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.model_wrapper.ModelWrapper.validation": [[197, 244], ["torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "model_wrapper.ModelWrapper.generator_ema.eval", "model_wrapper.ModelWrapper.generator_ema.to", "model_wrapper.ModelWrapper.progress_bar.set_description", "validation_metric", "print", "isinstance", "isinstance", "model_wrapper.ModelWrapper.data_logger.log_metric", "len", "model_wrapper.ModelWrapper.data_logger.log_metric", "model_wrapper.ModelWrapper.data_logger.log_metric", "model_wrapper.ModelWrapper.data_logger.log_metric", "model_wrapper.ModelWrapper.data_logger.log_metric", "model_wrapper.ModelWrapper.data_logger.log_metric"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_metric", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_metric", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_metric", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_metric", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_metric", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_metric"], ["", "", "", "def", "validation", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        GAN validation\n        \"\"\"", "\n", "# Clean cuda cache", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "# Set progress bar", "\n", "try", ":", "\n", "            ", "self", ".", "progress_bar", ".", "set_description", "(", "\"Validation\"", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "print", "(", "\"Validation\"", ")", "\n", "# Model into eval mode", "\n", "", "self", ".", "generator_ema", ".", "eval", "(", ")", "\n", "# Model to device", "\n", "self", ".", "generator_ema", ".", "to", "(", "self", ".", "device", ")", "\n", "# Perform validation", "\n", "for", "validation_metric", "in", "self", ".", "validation_metrics", ":", "\n", "# Get scores", "\n", "            ", "scores", "=", "validation_metric", "(", "generator", "=", "self", ".", "generator_ema", ",", "dataset", "=", "self", ".", "training_dataset", ")", "\n", "if", "isinstance", "(", "scores", ",", "np", ".", "float64", ")", "or", "isinstance", "(", "scores", ",", "float", ")", ":", "\n", "                ", "score_bf", "=", "scores", "\n", "# Log scores", "\n", "self", ".", "data_logger", ".", "log_metric", "(", "metric_name", "=", "validation_metric", ".", "__class__", ".", "__name__", "+", "\"_bf\"", ",", "value", "=", "score_bf", ")", "\n", "", "else", ":", "\n", "                ", "if", "len", "(", "scores", ")", "==", "3", ":", "\n", "                    ", "score_bf", ",", "score_gfp", ",", "score_rfp", "=", "scores", "\n", "# Log scores", "\n", "self", ".", "data_logger", ".", "log_metric", "(", "metric_name", "=", "validation_metric", ".", "__class__", ".", "__name__", "+", "\"_bf\"", ",", "\n", "value", "=", "score_bf", ")", "\n", "self", ".", "data_logger", ".", "log_metric", "(", "metric_name", "=", "validation_metric", ".", "__class__", ".", "__name__", "+", "\"_gfp\"", ",", "\n", "value", "=", "score_gfp", ")", "\n", "self", ".", "data_logger", ".", "log_metric", "(", "metric_name", "=", "validation_metric", ".", "__class__", ".", "__name__", "+", "\"_rfp\"", ",", "\n", "value", "=", "score_rfp", ")", "\n", "", "else", ":", "\n", "                    ", "score_bf", ",", "score_gfp", "=", "scores", "\n", "# Log scores", "\n", "self", ".", "data_logger", ".", "log_metric", "(", "metric_name", "=", "validation_metric", ".", "__class__", ".", "__name__", "+", "\"_bf\"", ",", "\n", "value", "=", "score_bf", ")", "\n", "self", ".", "data_logger", ".", "log_metric", "(", "metric_name", "=", "validation_metric", ".", "__class__", ".", "__name__", "+", "\"_gfp\"", ",", "\n", "value", "=", "score_gfp", ")", "\n", "# Save best fid score", "\n", "", "", "if", "\"FVD\"", "in", "validation_metric", ".", "__class__", ".", "__name__", ":", "\n", "                ", "try", ":", "\n", "                    ", "if", "self", ".", "best_fvd", ">", "score_bf", ":", "\n", "                        ", "self", ".", "best_fvd", "=", "score_bf", "\n", "", "", "except", "RuntimeError", ":", "\n", "                    ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.model_wrapper.ModelWrapper._gan_training": [[245, 452], ["torch.Identity", "torch.Identity", "model_wrapper.ModelWrapper.progress_bar.update", "real_images.to.to.to", "model_wrapper.ModelWrapper.discriminator_optimizer.zero_grad", "model_wrapper.ModelWrapper.generator_optimizer.zero_grad", "model_wrapper.ModelWrapper.discriminator", "model_wrapper.ModelWrapper.discriminator", "model_wrapper.ModelWrapper.discriminator_loss", "model_wrapper.ModelWrapper.discriminator_loss", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "model_wrapper.ModelWrapper.discriminator_optimizer.step", "model_wrapper.ModelWrapper.data_logger.log_metric", "model_wrapper.ModelWrapper.data_logger.log_metric", "model_wrapper.ModelWrapper.data_logger.log_metric", "model_wrapper.ModelWrapper.data_logger.log_metric", "model_wrapper.ModelWrapper.discriminator_optimizer.zero_grad", "model_wrapper.ModelWrapper.generator_optimizer.zero_grad", "misc.get_noise", "model_wrapper.ModelWrapper.generator", "model_wrapper.ModelWrapper.discriminator", "top_k", "isinstance", "model_wrapper.ModelWrapper.generator_loss", "model_wrapper.ModelWrapper.generator_loss", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "model_wrapper.ModelWrapper.generator_optimizer.step", "model_wrapper.ModelWrapper.data_logger.log_metric", "model_wrapper.ModelWrapper.data_logger.log_metric", "misc.exponential_moving_average", "model_wrapper.ModelWrapper.progress_bar.set_description", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "misc.get_noise", "model_wrapper.ModelWrapper.generator", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_wrapper.ModelWrapper.discriminator.parameters", "model_wrapper.ModelWrapper.discriminator_optimizer.zero_grad", "model_wrapper.ModelWrapper.generator_optimizer.zero_grad", "model_wrapper.ModelWrapper.discriminator", "model_wrapper.ModelWrapper.discriminator_regularization_loss", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "model_wrapper.ModelWrapper.discriminator_optimizer.step", "model_wrapper.ModelWrapper.data_logger.log_metric", "model_wrapper.ModelWrapper.discriminator_optimizer.zero_grad", "model_wrapper.ModelWrapper.generator_optimizer.zero_grad", "u_net_2d_discriminator.generate_cut_mix_augmentation_data", "model_wrapper.ModelWrapper.discriminator", "model_wrapper.ModelWrapper.cut_mix_augmentation_loss", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "model_wrapper.ModelWrapper.discriminator_optimizer.step", "model_wrapper.ModelWrapper.data_logger.log_metric", "model_wrapper.ModelWrapper.discriminator_optimizer.zero_grad", "u_net_2d_discriminator.generate_cut_mix_transformation_data", "model_wrapper.ModelWrapper.discriminator", "model_wrapper.ModelWrapper.cut_mix_regularization_loss", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "model_wrapper.ModelWrapper.discriminator_optimizer.step", "model_wrapper.ModelWrapper.data_logger.log_metric", "model_wrapper.ModelWrapper.generator.parameters", "model_wrapper.ModelWrapper.discriminator_optimizer.zero_grad", "model_wrapper.ModelWrapper.generator_optimizer.zero_grad", "misc.get_noise", "model_wrapper.ModelWrapper.generator", "model_wrapper.ModelWrapper.path_length_regularization", "loss_path_length_regularization_.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "model_wrapper.ModelWrapper.generator_optimizer.step", "model_wrapper.ModelWrapper.data_logger.log_metric", "model_wrapper.ModelWrapper.data_logger.log_metric", "loss_discriminator_real.item", "loss_discriminator_fake.item", "loss_discriminator_real_pixel_wise.item", "loss_discriminator_fake_pixel_wise.item", "model_wrapper.ModelWrapper.discriminator.parameters", "random.random", "model_wrapper.ModelWrapper.discriminator.parameters", "real_images.to.to.detach", "torch.cat.detach", "torch.cat.detach", "real_prediction_pixel_wise.detach", "fake_prediction_pixel_wise.detach", "model_wrapper.ModelWrapper.discriminator.parameters", "model_wrapper.ModelWrapper.item", "model_wrapper.ModelWrapper.item", "model_wrapper.ModelWrapper.generator.parameters", "model_wrapper.ModelWrapper.item", "float", "random.random", "model_wrapper.ModelWrapper.item", "max", "path_length.mean().item", "loss_path_length_regularization.item", "float", "int", "path_length.mean", "max", "misc.random_permutation", "int"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_metric", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_metric", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_metric", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_metric", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.get_noise", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_metric", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_metric", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.exponential_moving_average", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.get_noise", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_metric", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.generate_cut_mix_augmentation_data", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_metric", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.u_net_2d_discriminator.generate_cut_mix_transformation_data", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_metric", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.get_noise", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.upfirdn2d.UpFirDn2d.backward", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_metric", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.Logger.log_metric", "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.misc.random_permutation"], ["", "", "", "", "def", "_gan_training", "(", "self", ",", "resume_training", ":", "bool", "=", "False", ",", "\n", "top_k", ":", "nn", ".", "Module", "=", "nn", ".", "Identity", "(", ")", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Gan training\n        :param resume_training: (bool) If true training is resumed and cut mix and wrong order reg/aug used\n        :param top_k: (nn.Module) Top-k module\n        \"\"\"", "\n", "# Main loop", "\n", "for", "real_images", "in", "self", ".", "training_dataset", ":", "# type: torch.Tensor", "\n", "# Update progress bar", "\n", "            ", "self", ".", "progress_bar", ".", "update", "(", "n", "=", "1", ")", "\n", "# Data to device", "\n", "real_images", "=", "real_images", ".", "to", "(", "self", ".", "device", ")", "\n", "############## Discriminator training ##############", "\n", "# Reset gradients", "\n", "self", ".", "discriminator_optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "generator_optimizer", ".", "zero_grad", "(", ")", "\n", "# Utilize no gradients for generator prediction", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Get noise input vector", "\n", "                ", "noise_input", "=", "misc", ".", "get_noise", "(", "batch_size", "=", "real_images", ".", "shape", "[", "0", "]", ",", "\n", "latent_dimension", "=", "self", ".", "latent_dimensions", ",", "\n", "p_mixed_noise", "=", "self", ".", "hyperparameters", "[", "\"p_mixed_noise\"", "]", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "# Forward pass of generator", "\n", "fake_images", ":", "torch", ".", "Tensor", "=", "self", ".", "generator", "(", "input", "=", "noise_input", ")", "\n", "\n", "", "if", "self", ".", "epoch", ">=", "self", ".", "hyperparameters", "[", "\"wrong_order_start\"", "]", "*", "self", ".", "epochs", "or", "resume_training", ":", "\n", "# Add one real image of wrong permutation to fake images", "\n", "                ", "fake_images", "=", "torch", ".", "cat", "(", "\n", "[", "fake_images", ",", "\n", "real_images", "[", ":", "max", "(", "1", ",", "int", "(", "self", ".", "hyperparameters", "[", "\"batch_factor_wrong_order\"", "]", "*", "real_images", ".", "shape", "[", "0", "]", ")", ")", ",", "\n", ":", ",", "misc", ".", "random_permutation", "(", "real_images", ".", "shape", "[", "2", "]", ")", "]", "]", ",", "dim", "=", "0", ")", "\n", "# Forward pass discriminator with real images", "\n", "", "real_prediction", ",", "real_prediction_pixel_wise", "=", "self", ".", "discriminator", "(", "real_images", ",", "is_real", "=", "True", ",", "\n", "is_cut_mix", "=", "False", ")", "\n", "# Forward pass discriminator with fake images", "\n", "fake_prediction", ",", "fake_prediction_pixel_wise", "=", "self", ".", "discriminator", "(", "fake_images", ",", "is_real", "=", "False", ",", "\n", "is_cut_mix", "=", "False", ")", "\n", "# Calc discriminator loss", "\n", "loss_discriminator_real", ",", "loss_discriminator_fake", "=", "self", ".", "discriminator_loss", "(", "real_prediction", ",", "fake_prediction", ")", "\n", "# Calc discriminator loss", "\n", "loss_discriminator_real_pixel_wise", ",", "loss_discriminator_fake_pixel_wise", "=", "self", ".", "discriminator_loss", "(", "\n", "real_prediction_pixel_wise", ",", "fake_prediction_pixel_wise", ",", "\n", "weight", "=", "self", ".", "trap_weights_map", "\n", "if", "self", ".", "hyperparameters", "[", "\"trap_weight\"", "]", "*", "self", ".", "epochs", "<=", "self", ".", "epoch", "or", "resume_training", "else", "None", ")", "\n", "# Calc gradients", "\n", "(", "loss_discriminator_real", "+", "loss_discriminator_fake", "+", "\n", "loss_discriminator_real_pixel_wise", "+", "loss_discriminator_fake_pixel_wise", ")", ".", "backward", "(", ")", "\n", "# Clip discriminator gradients", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "discriminator", ".", "parameters", "(", ")", ",", "max_norm", "=", "5.", ")", "\n", "# Optimize discriminator", "\n", "self", ".", "discriminator_optimizer", ".", "step", "(", ")", "\n", "# Log losses", "\n", "self", ".", "data_logger", ".", "log_metric", "(", "metric_name", "=", "\"loss_discriminator_real\"", ",", "value", "=", "loss_discriminator_real", ".", "item", "(", ")", ")", "\n", "self", ".", "data_logger", ".", "log_metric", "(", "metric_name", "=", "\"loss_discriminator_fake\"", ",", "value", "=", "loss_discriminator_fake", ".", "item", "(", ")", ")", "\n", "self", ".", "data_logger", ".", "log_metric", "(", "metric_name", "=", "\"loss_discriminator_real_pixel_wise\"", ",", "\n", "value", "=", "loss_discriminator_real_pixel_wise", ".", "item", "(", ")", ")", "\n", "self", ".", "data_logger", ".", "log_metric", "(", "metric_name", "=", "\"loss_discriminator_fake_pixel_wise\"", ",", "\n", "value", "=", "loss_discriminator_fake_pixel_wise", ".", "item", "(", ")", ")", "\n", "# Perform regularization", "\n", "if", "(", "self", ".", "progress_bar", ".", "n", "%", "self", ".", "hyperparameters", "[", "\"lazy_discriminator_regularization\"", "]", ")", "==", "0", ":", "\n", "# Reset gradients", "\n", "                ", "self", ".", "discriminator_optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "generator_optimizer", ".", "zero_grad", "(", ")", "\n", "# Set requires grad", "\n", "real_images", ".", "requires_grad", "=", "True", "\n", "# Make prediction", "\n", "real_prediction", ",", "real_prediction_pixel_wise", "=", "self", ".", "discriminator", "(", "real_images", ",", "is_real", "=", "False", ",", "\n", "is_cut_mix", "=", "True", ")", "\n", "# Calc loss", "\n", "loss_discriminator_regularization", "=", "self", ".", "discriminator_regularization_loss", "(", "real_prediction", ",", "real_images", ",", "\n", "real_prediction_pixel_wise", ")", "\n", "# Calc gradients", "\n", "(", "self", ".", "hyperparameters", "[", "\n", "\"w_discriminator_regularization_r1\"", "]", "*", "loss_discriminator_regularization", ")", ".", "backward", "(", ")", "\n", "# Clip discriminator gradients", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "discriminator", ".", "parameters", "(", ")", ",", "max_norm", "=", "5.", ")", "\n", "# Optimize discriminator", "\n", "self", ".", "discriminator_optimizer", ".", "step", "(", ")", "\n", "# Log augmentation loss", "\n", "self", ".", "data_logger", ".", "log_metric", "(", "\n", "metric_name", "=", "\"loss_discriminator_regularization\"", ",", "\n", "value", "=", "(", "loss_discriminator_regularization", ")", ".", "item", "(", ")", ")", "\n", "# Perform cut mix regularization/augmentation", "\n", "", "if", "(", "random", ".", "random", "(", ")", "<=", "(", "(", "0.5", "/", "float", "(", "self", ".", "epochs", ")", ")", "*", "float", "(", "self", ".", "epoch", ")", ")", ")", "or", "(", "resume_training", "and", "random", ".", "random", "(", ")", "<=", "0.5", ")", ":", "\n", "# Reset gradients", "\n", "                ", "self", ".", "discriminator_optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "generator_optimizer", ".", "zero_grad", "(", ")", "\n", "# Init cut mix augmentation", "\n", "cut_mix_augmentation_images", ",", "cut_mix_augmentation_label", "=", "generate_cut_mix_augmentation_data", "(", "real_images", ",", "fake_images", ")", "\n", "# Make prediction", "\n", "_", ",", "cut_mix_augmentation_prediction", "=", "self", ".", "discriminator", "(", "cut_mix_augmentation_images", ",", "is_cut_mix", "=", "True", ")", "\n", "# Calc loss", "\n", "cut_mix_augmentation_loss_real", ",", "cut_mix_augmentation_loss_fake", "=", "self", ".", "cut_mix_augmentation_loss", "(", "cut_mix_augmentation_prediction", ",", "cut_mix_augmentation_label", ")", "\n", "# Calc gradients", "\n", "(", "self", ".", "hyperparameters", "[", "\"w_discriminator_regularization\"", "]", "*", "\n", "(", "cut_mix_augmentation_loss_real", "+", "cut_mix_augmentation_loss_fake", ")", ")", ".", "backward", "(", ")", "\n", "# Clip discriminator gradients", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "discriminator", ".", "parameters", "(", ")", ",", "max_norm", "=", "5.", ")", "\n", "# Optimize discriminator", "\n", "self", ".", "discriminator_optimizer", ".", "step", "(", ")", "\n", "# Log augmentation loss", "\n", "self", ".", "data_logger", ".", "log_metric", "(", "\n", "metric_name", "=", "\"loss_cut_mix_augmentation\"", ",", "\n", "value", "=", "(", "cut_mix_augmentation_loss_real", "+", "cut_mix_augmentation_loss_fake", ")", ".", "item", "(", ")", ")", "\n", "# Reset gradients", "\n", "self", ".", "discriminator_optimizer", ".", "zero_grad", "(", ")", "\n", "# Init cut mix regularization", "\n", "cut_mix_regularization_images", ",", "cut_mix_regularization_label", "=", "generate_cut_mix_transformation_data", "(", "real_images", ".", "detach", "(", ")", ",", "fake_images", ".", "detach", "(", ")", ",", "\n", "real_prediction_pixel_wise", ".", "detach", "(", ")", ",", "\n", "fake_prediction_pixel_wise", ".", "detach", "(", ")", ")", "\n", "# Make prediction", "\n", "_", ",", "cut_mix_regularization_prediction", "=", "self", ".", "discriminator", "(", "cut_mix_regularization_images", ",", "\n", "is_cut_mix", "=", "True", ")", "\n", "# Calc loss", "\n", "cut_mix_regularization_loss", "=", "self", ".", "cut_mix_regularization_loss", "(", "cut_mix_regularization_prediction", ",", "\n", "cut_mix_regularization_label", ")", "\n", "# Calc gradients", "\n", "(", "self", ".", "hyperparameters", "[", "\"w_discriminator_regularization\"", "]", "*", "cut_mix_regularization_loss", ")", ".", "backward", "(", ")", "\n", "# Clip discriminator gradients", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "discriminator", ".", "parameters", "(", ")", ",", "max_norm", "=", "5.", ")", "\n", "# Optimize discriminator", "\n", "self", ".", "discriminator_optimizer", ".", "step", "(", ")", "\n", "# Log regularization loss", "\n", "self", ".", "data_logger", ".", "log_metric", "(", "metric_name", "=", "\"loss_cut_mix_regularization\"", ",", "\n", "value", "=", "cut_mix_regularization_loss", ".", "item", "(", ")", ")", "\n", "############## Generator training ##############", "\n", "# Reset gradients", "\n", "", "self", ".", "discriminator_optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "generator_optimizer", ".", "zero_grad", "(", ")", "\n", "# Get noise input vector", "\n", "noise_input", "=", "misc", ".", "get_noise", "(", "batch_size", "=", "real_images", ".", "shape", "[", "0", "]", ",", "\n", "latent_dimension", "=", "self", ".", "latent_dimensions", ",", "\n", "p_mixed_noise", "=", "self", ".", "hyperparameters", "[", "\"p_mixed_noise\"", "]", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "# Forward pass of generator", "\n", "fake_images", "=", "self", ".", "generator", "(", "input", "=", "noise_input", ")", "\n", "# Discriminator prediction", "\n", "fake_prediction", ",", "fake_prediction_pixel_wise", "=", "self", ".", "discriminator", "(", "fake_images", ",", "is_real", "=", "False", ",", "\n", "is_cut_mix", "=", "False", ")", "\n", "# Apply top k", "\n", "output", "=", "top_k", "(", "fake_prediction", ")", "\n", "# Case if top k is utilized", "\n", "if", "isinstance", "(", "output", ",", "tuple", ")", ":", "\n", "# Unpack output", "\n", "                ", "fake_prediction", ",", "indexes", "=", "output", "\n", "# Apply indexes to pixel-wise prediction", "\n", "fake_prediction_pixel_wise", "=", "fake_prediction_pixel_wise", "[", "indexes", "]", "\n", "# Case if not top k is utilized", "\n", "", "else", ":", "\n", "                ", "fake_prediction", "=", "output", "\n", "# Calc generator loss", "\n", "", "loss_generator", "=", "self", ".", "generator_loss", "(", "fake_prediction", ")", "\n", "# Calc generator loss", "\n", "loss_generator_pixel_wise", "=", "self", ".", "generator_loss", "(", "fake_prediction_pixel_wise", ",", "weight", "=", "self", ".", "trap_weights_map", "\n", "if", "self", ".", "hyperparameters", "[", "\"trap_weight\"", "]", "*", "self", ".", "epochs", "<=", "self", ".", "epoch", "or", "resume_training", "else", "None", ")", "\n", "# Calc gradients", "\n", "(", "loss_generator", "+", "loss_generator_pixel_wise", ")", ".", "backward", "(", ")", "\n", "# Clip generator gradients", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "generator", ".", "parameters", "(", ")", ",", "max_norm", "=", "5.", ")", "\n", "# Optimize generator", "\n", "self", ".", "generator_optimizer", ".", "step", "(", ")", "\n", "# Log generator loss", "\n", "self", ".", "data_logger", ".", "log_metric", "(", "metric_name", "=", "\"loss_generator\"", ",", "value", "=", "loss_generator", ".", "item", "(", ")", ")", "\n", "# Log generator loss", "\n", "self", ".", "data_logger", ".", "log_metric", "(", "metric_name", "=", "\"loss_generator_pixel_wise\"", ",", "value", "=", "loss_generator_pixel_wise", ".", "item", "(", ")", ")", "\n", "# Perform regularization", "\n", "if", "(", "self", ".", "progress_bar", ".", "n", "%", "self", ".", "hyperparameters", "[", "\"lazy_generator_regularization\"", "]", ")", "==", "0", ":", "\n", "# Reset gradients", "\n", "                ", "self", ".", "discriminator_optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "generator_optimizer", ".", "zero_grad", "(", ")", "\n", "# Get input noise", "\n", "noise_input", "=", "misc", ".", "get_noise", "(", "\n", "batch_size", "=", "max", "(", "1", ",", "int", "(", "self", ".", "hyperparameters", "[", "\"batch_size_shrink_path_length_regularization\"", "]", "*", "\n", "real_images", ".", "shape", "[", "0", "]", ")", ")", ",", "\n", "latent_dimension", "=", "self", ".", "latent_dimensions", ",", "\n", "p_mixed_noise", "=", "self", ".", "hyperparameters", "[", "\"p_mixed_noise\"", "]", ",", "\n", "device", "=", "self", ".", "device", ")", "\n", "# Predict images and latents", "\n", "path_length_grads", "=", "self", ".", "generator", "(", "input", "=", "noise_input", ",", "return_path_length_grads", "=", "True", ")", "\n", "# Calc regularization loss", "\n", "loss_path_length_regularization", ",", "path_length", "=", "self", ".", "path_length_regularization", "(", "path_length_grads", ")", "\n", "# Calc gradients", "\n", "loss_path_length_regularization_", "=", "(", "\n", "self", ".", "hyperparameters", "[", "\"w_generator_regularization\"", "]", "*", "loss_path_length_regularization", ")", "\n", "loss_path_length_regularization_", ".", "backward", "(", ")", "\n", "# Clip gradients", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "generator", ".", "parameters", "(", ")", ",", "max_norm", "=", "5.", ")", "\n", "# Optimize", "\n", "self", ".", "generator_optimizer", ".", "step", "(", ")", "\n", "# Log regularization loss", "\n", "self", ".", "data_logger", ".", "log_metric", "(", "metric_name", "=", "\"path_length\"", ",", "value", "=", "path_length", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "self", ".", "data_logger", ".", "log_metric", "(", "metric_name", "=", "\"loss_path_length_regularization\"", ",", "\n", "value", "=", "loss_path_length_regularization", ".", "item", "(", ")", ")", "\n", "# Perform ema", "\n", "", "misc", ".", "exponential_moving_average", "(", "model_ema", "=", "self", ".", "generator_ema", ",", "model_train", "=", "self", ".", "generator", ")", "\n", "# Set progress bar description", "\n", "self", ".", "progress_bar", ".", "set_description", "(", "\"Loss D={:.3f}, Loss G={:.3f}, Best FVD={:.3f}\"", ".", "format", "(", "\n", "(", "loss_discriminator_fake", "+", "loss_discriminator_real", "+", "\n", "loss_discriminator_fake_pixel_wise", "+", "loss_discriminator_real_pixel_wise", ")", ".", "item", "(", ")", ",", "\n", "(", "loss_generator", "+", "loss_generator_pixel_wise", ")", ".", "item", "(", ")", ",", "self", ".", "best_fvd", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.equalized_layer.EqualizedConv2d.__init__": [[14, 45], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "isinstance", "isinstance", "isinstance", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ":", "int", ",", "out_channels", ":", "int", ",", "kernel_size", ":", "Union", "[", "int", ",", "Tuple", "[", "int", ",", "int", "]", "]", "=", "3", ",", "\n", "stride", ":", "Union", "[", "int", ",", "Tuple", "[", "int", ",", "int", "]", "]", "=", "1", ",", "padding", ":", "Union", "[", "int", ",", "Tuple", "[", "int", ",", "int", "]", "]", "=", "1", ",", "\n", "bias", ":", "bool", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param in_channels: (int) Number of input channels\n        :param out_channels: (int) Number of output channels\n        :param kernel_size: (Union[int, Tuple[int, int]]) Kernel size\n        :param stride: (Union[int, Tuple[int, int]]) Stride factor used in the convolution\n        :param padding: (Union[int, Tuple[int, int]]) Padding factor used in the convolution\n        :param bias: (bool) Use bias\n        \"\"\"", "\n", "# Init super constructor", "\n", "super", "(", "EqualizedConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Save parameters", "\n", "self", ".", "kernel_size", "=", "(", "kernel_size", ",", "kernel_size", ")", "if", "isinstance", "(", "kernel_size", ",", "int", ")", "else", "kernel_size", "\n", "self", ".", "stride", "=", "(", "stride", ",", "stride", ")", "if", "isinstance", "(", "stride", ",", "int", ")", "else", "stride", "\n", "self", ".", "padding", "=", "(", "padding", ",", "padding", ")", "if", "isinstance", "(", "padding", ",", "int", ")", "else", "padding", "\n", "# Init weights tensor for convolution", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "\n", "nn", ".", "init", ".", "normal_", "(", "torch", ".", "empty", "(", "out_channels", ",", "in_channels", ",", "*", "self", ".", "kernel_size", ",", "dtype", "=", "torch", ".", "float", ")", ")", ",", "\n", "requires_grad", "=", "True", ")", "\n", "# Init bias weight if needed", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "out_channels", ",", "dtype", "=", "torch", ".", "float", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", "=", "None", "\n", "# Init scale factor", "\n", "", "self", ".", "scale", "=", "torch", ".", "tensor", "(", "\n", "np", ".", "sqrt", "(", "2", ")", "/", "np", ".", "sqrt", "(", "in_channels", "*", "(", "self", ".", "kernel_size", "[", "0", "]", "*", "self", ".", "kernel_size", "[", "1", "]", ")", ")", ")", ".", "float", "(", ")", "\n", "self", ".", "scale_bias", "=", "torch", ".", "tensor", "(", "np", ".", "sqrt", "(", "2", ")", "/", "np", ".", "sqrt", "(", "out_channels", ")", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.equalized_layer.EqualizedConv2d.__repr__": [[46, 62], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        Method returns information about the module\n        :return: (str) Info string\n        \"\"\"", "\n", "return", "(", "'{}({}, {}, kernel_size=({}, {}), stride=({}, {}), padding=({}, {}), bias={})'", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "\n", "self", ".", "weight", ".", "shape", "[", "1", "]", ",", "\n", "self", ".", "weight", ".", "shape", "[", "0", "]", ",", "\n", "self", ".", "weight", ".", "shape", "[", "2", "]", ",", "\n", "self", ".", "weight", ".", "shape", "[", "3", "]", ",", "\n", "self", ".", "stride", "[", "0", "]", ",", "\n", "self", ".", "stride", "[", "1", "]", ",", "\n", "self", ".", "padding", "[", "0", "]", ",", "\n", "self", ".", "padding", "[", "1", "]", ",", "\n", "self", ".", "bias", "is", "not", "None", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.equalized_layer.EqualizedConv2d.forward": [[63, 75], ["torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d", "torch.conv2d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param input: (Torch Tensor) Input tensor 4D\n        :return: (Torch tensor) Output tensor 4D\n        \"\"\"", "\n", "if", "self", ".", "bias", "is", "None", ":", "\n", "            ", "output", "=", "F", ".", "conv2d", "(", "input", "=", "input", ",", "weight", "=", "self", ".", "weight", "*", "self", ".", "scale", ",", "stride", "=", "self", ".", "stride", ",", "padding", "=", "self", ".", "padding", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "F", ".", "conv2d", "(", "input", "=", "input", ",", "weight", "=", "self", ".", "weight", "*", "self", ".", "scale", ",", "bias", "=", "self", ".", "bias", "*", "self", ".", "scale_bias", ",", "\n", "stride", "=", "self", ".", "stride", ",", "padding", "=", "self", ".", "padding", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.equalized_layer.EqualizedTransposedConv2d.__init__": [[82, 113], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "isinstance", "isinstance", "isinstance", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ":", "int", ",", "out_channels", ":", "int", ",", "kernel_size", ":", "Union", "[", "int", ",", "Tuple", "[", "int", ",", "int", "]", "]", "=", "2", ",", "\n", "stride", ":", "Union", "[", "int", ",", "Tuple", "[", "int", ",", "int", "]", "]", "=", "2", ",", "padding", ":", "Union", "[", "int", ",", "Tuple", "[", "int", ",", "int", "]", "]", "=", "0", ",", "\n", "bias", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param in_channels: (int) Number of input channels\n        :param out_channels: (int) Number of output channels\n        :param kernel_size: (Union[int, Tuple[int, int]]) Kernel size\n        :param stride: (Union[int, Tuple[int, int]]) Stride factor used in the convolution\n        :param padding: (Union[int, Tuple[int, int]]) Padding factor used in the convolution\n        :param bias: (bool) Use bias\n        \"\"\"", "\n", "# Init super constructor", "\n", "super", "(", "EqualizedTransposedConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Save parameters", "\n", "self", ".", "kernel_size", "=", "(", "kernel_size", ",", "kernel_size", ")", "if", "isinstance", "(", "kernel_size", ",", "int", ")", "else", "kernel_size", "\n", "self", ".", "stride", "=", "(", "stride", ",", "stride", ")", "if", "isinstance", "(", "stride", ",", "int", ")", "else", "stride", "\n", "self", ".", "padding", "=", "(", "padding", ",", "padding", ")", "if", "isinstance", "(", "padding", ",", "int", ")", "else", "padding", "\n", "# Init weights tensor for convolution", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "\n", "nn", ".", "init", ".", "normal_", "(", "torch", ".", "empty", "(", "in_channels", ",", "out_channels", ",", "*", "self", ".", "kernel_size", ",", "dtype", "=", "torch", ".", "float", ")", ")", ",", "\n", "requires_grad", "=", "True", ")", "\n", "# Init bias weight if needed", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "out_channels", ",", "dtype", "=", "torch", ".", "float", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", "=", "None", "\n", "# Init scale factor", "\n", "", "self", ".", "scale", "=", "torch", ".", "tensor", "(", "\n", "np", ".", "sqrt", "(", "2", ")", "/", "np", ".", "sqrt", "(", "in_channels", "*", "(", "self", ".", "kernel_size", "[", "0", "]", "*", "self", ".", "kernel_size", "[", "1", "]", ")", ")", ")", ".", "float", "(", ")", "\n", "self", ".", "scale_bias", "=", "torch", ".", "tensor", "(", "np", ".", "sqrt", "(", "2", ")", "/", "np", ".", "sqrt", "(", "out_channels", ")", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.equalized_layer.EqualizedTransposedConv2d.__repr__": [[114, 130], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        Method returns information about the module\n        :return: (str) Info string\n        \"\"\"", "\n", "return", "(", "'{}({}, {}, kernel_size=({}, {}), stride=({}, {}), padding=({}, {}), bias={})'", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "\n", "self", ".", "weight", ".", "shape", "[", "1", "]", ",", "\n", "self", ".", "weight", ".", "shape", "[", "0", "]", ",", "\n", "self", ".", "weight", ".", "shape", "[", "2", "]", ",", "\n", "self", ".", "weight", ".", "shape", "[", "3", "]", ",", "\n", "self", ".", "stride", "[", "0", "]", ",", "\n", "self", ".", "stride", "[", "1", "]", ",", "\n", "self", ".", "padding", "[", "0", "]", ",", "\n", "self", ".", "padding", "[", "1", "]", ",", "\n", "self", ".", "bias", "is", "not", "None", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.equalized_layer.EqualizedTransposedConv2d.forward": [[131, 144], ["torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d", "torch.conv_transpose2d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param input: (Torch Tensor) Input tensor 4D\n        :return: (Torch tensor) Output tensor 4D\n        \"\"\"", "\n", "if", "self", ".", "bias", "is", "None", ":", "\n", "            ", "output", "=", "F", ".", "conv_transpose2d", "(", "input", "=", "input", ",", "weight", "=", "self", ".", "weight", "*", "self", ".", "scale", ",", "stride", "=", "self", ".", "stride", ",", "\n", "padding", "=", "self", ".", "padding", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "F", ".", "conv_transpose2d", "(", "input", "=", "input", ",", "weight", "=", "self", ".", "weight", "*", "self", ".", "scale", ",", "bias", "=", "self", ".", "bias", "*", "self", ".", "scale_bias", ",", "\n", "stride", "=", "self", ".", "stride", ",", "padding", "=", "self", ".", "padding", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.equalized_layer.EqualizedConv1d.__init__": [[151, 180], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ":", "int", ",", "out_channels", ":", "int", ",", "kernel_size", ":", "int", "=", "3", ",", "\n", "stride", ":", "int", "=", "1", ",", "padding", ":", "int", "=", "1", ",", "bias", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param in_channels: (int) Number of input channels\n        :param out_channels: (int) Number of output channels\n        :param kernel_size: (int) Kernel size\n        :param stride: (int) Stride factor used in the convolution\n        :param padding: (int) Padding factor used in the convolution\n        :param bias: (bool) Use bias\n        \"\"\"", "\n", "# Call super constructor", "\n", "super", "(", "EqualizedConv1d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Save parameters", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "# Init weight parameter", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "\n", "nn", ".", "init", ".", "normal_", "(", "torch", ".", "empty", "(", "out_channels", ",", "in_channels", ",", "kernel_size", ",", "dtype", "=", "torch", ".", "float", ")", ")", ",", "requires_grad", "=", "True", ")", "\n", "# Init bias if utilized", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "out_channels", ",", "dtype", "=", "torch", ".", "float", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", "=", "None", "\n", "# Init scale factor", "\n", "", "self", ".", "scale", "=", "torch", ".", "tensor", "(", "\n", "np", ".", "sqrt", "(", "2", ")", "/", "np", ".", "sqrt", "(", "in_channels", "*", "(", "self", ".", "kernel_size", ")", ")", ")", ".", "float", "(", ")", "\n", "self", ".", "scale_bias", "=", "torch", ".", "tensor", "(", "np", ".", "sqrt", "(", "2", ")", "/", "np", ".", "sqrt", "(", "out_channels", ")", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.equalized_layer.EqualizedConv1d.__repr__": [[181, 194], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        Method returns information about the module\n        :return: (str) Info string\n        \"\"\"", "\n", "return", "(", "'{}({}, {}, kernel_size={}, stride={}, padding={}, bias={})'", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "\n", "self", ".", "weight", ".", "shape", "[", "1", "]", ",", "\n", "self", ".", "weight", ".", "shape", "[", "0", "]", ",", "\n", "self", ".", "weight", ".", "shape", "[", "2", "]", ",", "\n", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "\n", "self", ".", "bias", "is", "not", "None", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.equalized_layer.EqualizedConv1d.forward": [[195, 208], ["torch.conv1d", "torch.conv1d", "torch.conv1d", "torch.conv1d", "torch.conv1d", "torch.conv1d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param input: (torch.Tensor) Input tensor 3D\n        :return: (torch.Tensor) Output tensor 3D\n        \"\"\"", "\n", "if", "self", ".", "bias", "is", "None", ":", "\n", "            ", "output", "=", "F", ".", "conv1d", "(", "input", "=", "input", ",", "weight", "=", "self", ".", "weight", "*", "self", ".", "scale", ",", "stride", "=", "self", ".", "stride", ",", "\n", "padding", "=", "self", ".", "padding", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "F", ".", "conv1d", "(", "input", "=", "input", ",", "weight", "=", "self", ".", "weight", "*", "self", ".", "scale", ",", "bias", "=", "self", ".", "bias", "*", "self", ".", "scale_bias", ",", "\n", "stride", "=", "self", ".", "stride", ",", "padding", "=", "self", ".", "padding", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.equalized_layer.EqualizedLinear.__init__": [[215, 235], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.init.normal_", "torch.init.normal_", "torch.init.normal_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ":", "int", ",", "out_channels", ":", "int", ",", "bias", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param in_channels: (int) Number of input channels\n        :param out_channels: (int) Number of output channels\n        :param use_bias: (bool) True if bias should be used\n        \"\"\"", "\n", "# Init super constructor", "\n", "super", "(", "EqualizedLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Init weights tensor for convolution", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "\n", "nn", ".", "init", ".", "normal_", "(", "torch", ".", "empty", "(", "out_channels", ",", "in_channels", ",", "dtype", "=", "torch", ".", "float", ")", ")", ",", "requires_grad", "=", "True", ")", "\n", "# Init bias weight if needed", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "out_channels", ")", ".", "fill_", "(", "0", ")", ",", "requires_grad", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", "=", "None", "\n", "# Init scale factor", "\n", "", "self", ".", "scale", "=", "np", ".", "sqrt", "(", "2", ")", "/", "np", ".", "sqrt", "(", "in_channels", ")", "\n", "self", ".", "scale_bias", "=", "np", ".", "sqrt", "(", "2", ")", "/", "np", ".", "sqrt", "(", "out_channels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.equalized_layer.EqualizedLinear.__repr__": [[236, 243], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        Method returns information about the module\n        :return: (str) Info string\n        \"\"\"", "\n", "return", "(", "'{}({}, {}, bias={})'", ".", "format", "(", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "weight", ".", "shape", "[", "1", "]", ",", "self", ".", "weight", ".", "shape", "[", "0", "]", ",", "\n", "self", ".", "bias", "is", "not", "None", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.equalized_layer.EqualizedLinear.forward": [[244, 255], ["torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param input: (torch.Tensor) Input tensor 2D or 3D\n        :return: (torch.Tensor) Output tensor 2D or 3D\n        \"\"\"", "\n", "if", "self", ".", "bias", "is", "None", ":", "\n", "            ", "output", "=", "F", ".", "linear", "(", "input", "=", "input", ",", "weight", "=", "self", ".", "weight", "*", "self", ".", "scale", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "F", ".", "linear", "(", "input", "=", "input", ",", "weight", "=", "self", ".", "weight", "*", "self", ".", "scale", ",", "bias", "=", "self", ".", "bias", "*", "self", ".", "scale_bias", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.equalized_layer.PixelwiseNormalization.__init__": [[262, 269], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["def", "__init__", "(", "self", ",", "alpha", ":", "float", "=", "1e-8", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Constructor method\n        :param alpha: (float) Small constants for numeric stability\n        \"\"\"", "\n", "super", "(", "PixelwiseNormalization", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "alpha", "=", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.multi_stylegan.equalized_layer.PixelwiseNormalization.forward": [[270, 278], ["torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Forward pass\n        :param input: (Torch Tensor) Input tensor\n        :return: (Torch Tensor) Normalized output tensor with same shape as input\n        \"\"\"", "\n", "output", "=", "input", "/", "torch", ".", "sqrt", "(", "torch", ".", "mean", "(", "input", "**", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "+", "self", ".", "alpha", ")", "\n", "return", "output", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLUFunctionBackward.forward": [[23, 43], ["ctx.save_for_backward", "grad_output.new_empty", "fused_act_cuda.fused_bias_act", "fused_act_cuda.fused_bias_act.sum().detach", "list", "range", "fused_act_cuda.fused_bias_act.sum"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "grad_output", ",", "out", ",", "negative_slope", ",", "scale", ")", ":", "\n", "        ", "ctx", ".", "save_for_backward", "(", "out", ")", "\n", "ctx", ".", "negative_slope", "=", "negative_slope", "\n", "ctx", ".", "scale", "=", "scale", "\n", "\n", "empty", "=", "grad_output", ".", "new_empty", "(", "0", ")", "\n", "\n", "grad_input", "=", "fused_act_cuda", ".", "fused_bias_act", "(", "\n", "grad_output", ",", "empty", ",", "out", ",", "3", ",", "1", ",", "negative_slope", ",", "scale", "\n", ")", "\n", "\n", "dim", "=", "[", "0", "]", "\n", "\n", "if", "grad_input", ".", "ndim", ">", "2", ":", "\n", "            ", "dim", "+=", "list", "(", "range", "(", "2", ",", "grad_input", ".", "ndim", ")", ")", "\n", "\n", "", "grad_bias", "=", "grad_input", ".", "sum", "(", "dim", ")", ".", "detach", "(", ")", "\n", "\n", "return", "grad_input", ",", "grad_bias", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLUFunctionBackward.backward": [[44, 52], ["fused_act_cuda.fused_bias_act"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "gradgrad_input", ",", "gradgrad_bias", ")", ":", "\n", "        ", "out", ",", "=", "ctx", ".", "saved_tensors", "\n", "gradgrad_out", "=", "fused_act_cuda", ".", "fused_bias_act", "(", "\n", "gradgrad_input", ",", "gradgrad_bias", ",", "out", ",", "3", ",", "1", ",", "ctx", ".", "negative_slope", ",", "ctx", ".", "scale", "\n", ")", "\n", "\n", "return", "gradgrad_out", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLUFunction.forward": [[55, 64], ["input.new_empty", "fused_act_cuda.fused_bias_act", "ctx.save_for_backward"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ",", "bias", ",", "negative_slope", ",", "scale", ")", ":", "\n", "        ", "empty", "=", "input", ".", "new_empty", "(", "0", ")", "\n", "out", "=", "fused_act_cuda", ".", "fused_bias_act", "(", "input", ",", "bias", ",", "empty", ",", "3", ",", "0", ",", "negative_slope", ",", "scale", ")", "\n", "ctx", ".", "save_for_backward", "(", "out", ")", "\n", "ctx", ".", "negative_slope", "=", "negative_slope", "\n", "ctx", ".", "scale", "=", "scale", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLUFunction.backward": [[65, 74], ["FusedLeakyReLUFunctionBackward.apply"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "out", ",", "=", "ctx", ".", "saved_tensors", "\n", "\n", "grad_input", ",", "grad_bias", "=", "FusedLeakyReLUFunctionBackward", ".", "apply", "(", "\n", "grad_output", ",", "out", ",", "ctx", ".", "negative_slope", ",", "ctx", ".", "scale", "\n", ")", "\n", "\n", "return", "grad_input", ",", "grad_bias", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__": [[77, 83], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channel", ",", "negative_slope", "=", "0.2", ",", "scale", "=", "1.", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "channel", ")", ")", "\n", "self", ".", "negative_slope", "=", "negative_slope", "\n", "self", ".", "scale", "=", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.FusedLeakyReLU.forward": [[84, 86], ["fused_act.fused_leaky_relu"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.fused_leaky_relu"], ["", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "fused_leaky_relu", "(", "input", ",", "self", ".", "bias", ",", "self", ".", "negative_slope", ",", "self", ".", "scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.fused_act.fused_leaky_relu": [[88, 90], ["FusedLeakyReLUFunction.apply"], "function", ["None"], ["", "", "def", "fused_leaky_relu", "(", "input", ",", "bias", ",", "negative_slope", "=", "0.2", ",", "scale", "=", "2", "**", "0.5", ")", ":", "\n", "    ", "return", "FusedLeakyReLUFunction", ".", "apply", "(", "input", ",", "bias", ",", "negative_slope", ",", "scale", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.upfirdn2d.UpFirDn2dBackward.forward": [[23, 64], ["grad_output.reshape.reshape.reshape", "upfirdn2d_cuda.upfirdn2d", "grad_input.view.view.view", "ctx.save_for_backward"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.upfirdn2d.upfirdn2d"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "\n", "ctx", ",", "grad_output", ",", "kernel", ",", "grad_kernel", ",", "up", ",", "down", ",", "pad", ",", "g_pad", ",", "in_size", ",", "out_size", "\n", ")", ":", "\n", "\n", "        ", "up_x", ",", "up_y", "=", "up", "\n", "down_x", ",", "down_y", "=", "down", "\n", "g_pad_x0", ",", "g_pad_x1", ",", "g_pad_y0", ",", "g_pad_y1", "=", "g_pad", "\n", "\n", "grad_output", "=", "grad_output", ".", "reshape", "(", "-", "1", ",", "out_size", "[", "0", "]", ",", "out_size", "[", "1", "]", ",", "1", ")", "\n", "\n", "grad_input", "=", "upfirdn2d_cuda", ".", "upfirdn2d", "(", "\n", "grad_output", ",", "\n", "grad_kernel", ",", "\n", "down_x", ",", "\n", "down_y", ",", "\n", "up_x", ",", "\n", "up_y", ",", "\n", "g_pad_x0", ",", "\n", "g_pad_x1", ",", "\n", "g_pad_y0", ",", "\n", "g_pad_y1", ",", "\n", ")", "\n", "grad_input", "=", "grad_input", ".", "view", "(", "in_size", "[", "0", "]", ",", "in_size", "[", "1", "]", ",", "in_size", "[", "2", "]", ",", "in_size", "[", "3", "]", ")", "\n", "\n", "ctx", ".", "save_for_backward", "(", "kernel", ")", "\n", "\n", "pad_x0", ",", "pad_x1", ",", "pad_y0", ",", "pad_y1", "=", "pad", "\n", "\n", "ctx", ".", "up_x", "=", "up_x", "\n", "ctx", ".", "up_y", "=", "up_y", "\n", "ctx", ".", "down_x", "=", "down_x", "\n", "ctx", ".", "down_y", "=", "down_y", "\n", "ctx", ".", "pad_x0", "=", "pad_x0", "\n", "ctx", ".", "pad_x1", "=", "pad_x1", "\n", "ctx", ".", "pad_y0", "=", "pad_y0", "\n", "ctx", ".", "pad_y1", "=", "pad_y1", "\n", "ctx", ".", "in_size", "=", "in_size", "\n", "ctx", ".", "out_size", "=", "out_size", "\n", "\n", "return", "grad_input", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.upfirdn2d.UpFirDn2dBackward.backward": [[65, 89], ["gradgrad_input.reshape.reshape.reshape", "upfirdn2d_cuda.upfirdn2d", "gradgrad_out.view.view.view"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.upfirdn2d.upfirdn2d"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "gradgrad_input", ")", ":", "\n", "        ", "kernel", ",", "=", "ctx", ".", "saved_tensors", "\n", "\n", "gradgrad_input", "=", "gradgrad_input", ".", "reshape", "(", "-", "1", ",", "ctx", ".", "in_size", "[", "2", "]", ",", "ctx", ".", "in_size", "[", "3", "]", ",", "1", ")", "\n", "\n", "gradgrad_out", "=", "upfirdn2d_cuda", ".", "upfirdn2d", "(", "\n", "gradgrad_input", ",", "\n", "kernel", ",", "\n", "ctx", ".", "up_x", ",", "\n", "ctx", ".", "up_y", ",", "\n", "ctx", ".", "down_x", ",", "\n", "ctx", ".", "down_y", ",", "\n", "ctx", ".", "pad_x0", ",", "\n", "ctx", ".", "pad_x1", ",", "\n", "ctx", ".", "pad_y0", ",", "\n", "ctx", ".", "pad_y1", ",", "\n", ")", "\n", "# gradgrad_out = gradgrad_out.view(ctx.in_size[0], ctx.out_size[0], ctx.out_size[1], ctx.in_size[3])", "\n", "gradgrad_out", "=", "gradgrad_out", ".", "view", "(", "\n", "ctx", ".", "in_size", "[", "0", "]", ",", "ctx", ".", "in_size", "[", "1", "]", ",", "ctx", ".", "out_size", "[", "0", "]", ",", "ctx", ".", "out_size", "[", "1", "]", "\n", ")", "\n", "\n", "return", "gradgrad_out", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.upfirdn2d.UpFirDn2d.forward": [[92, 128], ["input.reshape.reshape.reshape", "ctx.save_for_backward", "upfirdn2d_cuda.upfirdn2d", "out.view.view.view", "torch.flip", "torch.flip", "torch.flip", "torch.flip"], "methods", ["home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.upfirdn2d.upfirdn2d"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "input", ",", "kernel", ",", "up", ",", "down", ",", "pad", ")", ":", "\n", "        ", "up_x", ",", "up_y", "=", "up", "\n", "down_x", ",", "down_y", "=", "down", "\n", "pad_x0", ",", "pad_x1", ",", "pad_y0", ",", "pad_y1", "=", "pad", "\n", "\n", "kernel_h", ",", "kernel_w", "=", "kernel", ".", "shape", "\n", "batch", ",", "channel", ",", "in_h", ",", "in_w", "=", "input", ".", "shape", "\n", "ctx", ".", "in_size", "=", "input", ".", "shape", "\n", "\n", "input", "=", "input", ".", "reshape", "(", "-", "1", ",", "in_h", ",", "in_w", ",", "1", ")", "\n", "\n", "ctx", ".", "save_for_backward", "(", "kernel", ",", "torch", ".", "flip", "(", "kernel", ",", "[", "0", ",", "1", "]", ")", ")", "\n", "\n", "out_h", "=", "(", "in_h", "*", "up_y", "+", "pad_y0", "+", "pad_y1", "-", "kernel_h", ")", "//", "down_y", "+", "1", "\n", "out_w", "=", "(", "in_w", "*", "up_x", "+", "pad_x0", "+", "pad_x1", "-", "kernel_w", ")", "//", "down_x", "+", "1", "\n", "ctx", ".", "out_size", "=", "(", "out_h", ",", "out_w", ")", "\n", "\n", "ctx", ".", "up", "=", "(", "up_x", ",", "up_y", ")", "\n", "ctx", ".", "down", "=", "(", "down_x", ",", "down_y", ")", "\n", "ctx", ".", "pad", "=", "(", "pad_x0", ",", "pad_x1", ",", "pad_y0", ",", "pad_y1", ")", "\n", "\n", "g_pad_x0", "=", "kernel_w", "-", "pad_x0", "-", "1", "\n", "g_pad_y0", "=", "kernel_h", "-", "pad_y0", "-", "1", "\n", "g_pad_x1", "=", "in_w", "*", "up_x", "-", "out_w", "*", "down_x", "+", "pad_x0", "-", "up_x", "+", "1", "\n", "g_pad_y1", "=", "in_h", "*", "up_y", "-", "out_h", "*", "down_y", "+", "pad_y0", "-", "up_y", "+", "1", "\n", "\n", "ctx", ".", "g_pad", "=", "(", "g_pad_x0", ",", "g_pad_x1", ",", "g_pad_y0", ",", "g_pad_y1", ")", "\n", "\n", "out", "=", "upfirdn2d_cuda", ".", "upfirdn2d", "(", "\n", "input", ",", "kernel", ",", "up_x", ",", "up_y", ",", "down_x", ",", "down_y", ",", "pad_x0", ",", "pad_x1", ",", "pad_y0", ",", "pad_y1", "\n", ")", "\n", "# out = out.view(major, out_h, out_w, minor)", "\n", "out", "=", "out", ".", "view", "(", "-", "1", ",", "channel", ",", "out_h", ",", "out_w", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.upfirdn2d.UpFirDn2d.backward": [[129, 146], ["UpFirDn2dBackward.apply"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "kernel", ",", "grad_kernel", "=", "ctx", ".", "saved_tensors", "\n", "\n", "grad_input", "=", "UpFirDn2dBackward", ".", "apply", "(", "\n", "grad_output", ",", "\n", "kernel", ",", "\n", "grad_kernel", ",", "\n", "ctx", ".", "up", ",", "\n", "ctx", ".", "down", ",", "\n", "ctx", ".", "pad", ",", "\n", "ctx", ".", "g_pad", ",", "\n", "ctx", ".", "in_size", ",", "\n", "ctx", ".", "out_size", ",", "\n", ")", "\n", "\n", "return", "grad_input", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.upfirdn2d.upfirdn2d": [[148, 154], ["UpFirDn2d.apply"], "function", ["None"], ["", "", "def", "upfirdn2d", "(", "input", ",", "kernel", ",", "up", "=", "1", ",", "down", "=", "1", ",", "pad", "=", "(", "0", ",", "0", ")", ")", ":", "\n", "    ", "out", "=", "UpFirDn2d", ".", "apply", "(", "\n", "input", ",", "kernel", ",", "(", "up", ",", "up", ")", ",", "(", "down", ",", "down", ")", ",", "(", "pad", "[", "0", "]", ",", "pad", "[", "1", "]", ",", "pad", "[", "0", "]", ",", "pad", "[", "1", "]", ")", "\n", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.ChristophReich1996_Multi-StyleGAN.op_static.upfirdn2d.upfirdn2d_native": [[156, 191], ["input.view", "torch.pad", "out.permute.view", "torch.pad", "out.permute.permute", "out.permute.reshape", "torch.flip().view", "torch.flip().view", "torch.conv2d", "out.permute.reshape", "out.permute.permute", "max", "max", "max", "max", "torch.flip", "torch.flip", "max", "max", "max", "max"], "function", ["None"], ["", "def", "upfirdn2d_native", "(", "\n", "input", ",", "kernel", ",", "up_x", ",", "up_y", ",", "down_x", ",", "down_y", ",", "pad_x0", ",", "pad_x1", ",", "pad_y0", ",", "pad_y1", "\n", ")", ":", "\n", "    ", "_", ",", "in_h", ",", "in_w", ",", "minor", "=", "input", ".", "shape", "\n", "kernel_h", ",", "kernel_w", "=", "kernel", ".", "shape", "\n", "\n", "out", "=", "input", ".", "view", "(", "-", "1", ",", "in_h", ",", "1", ",", "in_w", ",", "1", ",", "minor", ")", "\n", "out", "=", "F", ".", "pad", "(", "out", ",", "[", "0", ",", "0", ",", "0", ",", "up_x", "-", "1", ",", "0", ",", "0", ",", "0", ",", "up_y", "-", "1", "]", ")", "\n", "out", "=", "out", ".", "view", "(", "-", "1", ",", "in_h", "*", "up_y", ",", "in_w", "*", "up_x", ",", "minor", ")", "\n", "\n", "out", "=", "F", ".", "pad", "(", "\n", "out", ",", "[", "0", ",", "0", ",", "max", "(", "pad_x0", ",", "0", ")", ",", "max", "(", "pad_x1", ",", "0", ")", ",", "max", "(", "pad_y0", ",", "0", ")", ",", "max", "(", "pad_y1", ",", "0", ")", "]", "\n", ")", "\n", "out", "=", "out", "[", "\n", ":", ",", "\n", "max", "(", "-", "pad_y0", ",", "0", ")", ":", "out", ".", "shape", "[", "1", "]", "-", "max", "(", "-", "pad_y1", ",", "0", ")", ",", "\n", "max", "(", "-", "pad_x0", ",", "0", ")", ":", "out", ".", "shape", "[", "2", "]", "-", "max", "(", "-", "pad_x1", ",", "0", ")", ",", "\n", ":", ",", "\n", "]", "\n", "\n", "out", "=", "out", ".", "permute", "(", "0", ",", "3", ",", "1", ",", "2", ")", "\n", "out", "=", "out", ".", "reshape", "(", "\n", "[", "-", "1", ",", "1", ",", "in_h", "*", "up_y", "+", "pad_y0", "+", "pad_y1", ",", "in_w", "*", "up_x", "+", "pad_x0", "+", "pad_x1", "]", "\n", ")", "\n", "w", "=", "torch", ".", "flip", "(", "kernel", ",", "[", "0", ",", "1", "]", ")", ".", "view", "(", "1", ",", "1", ",", "kernel_h", ",", "kernel_w", ")", "\n", "out", "=", "F", ".", "conv2d", "(", "out", ",", "w", ")", "\n", "out", "=", "out", ".", "reshape", "(", "\n", "-", "1", ",", "\n", "minor", ",", "\n", "in_h", "*", "up_y", "+", "pad_y0", "+", "pad_y1", "-", "kernel_h", "+", "1", ",", "\n", "in_w", "*", "up_x", "+", "pad_x0", "+", "pad_x1", "-", "kernel_w", "+", "1", ",", "\n", ")", "\n", "out", "=", "out", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "\n", "return", "out", "[", ":", ",", ":", ":", "down_y", ",", ":", ":", "down_x", ",", ":", "]", "\n", "\n"]]}