{"home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.maml_inner_loop.InnerLoop.__init__": [[26, 39], ["maml_inner_loop.InnerLoop.C.cuda"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "baseComposer", ",", "module_list", ",", "loss_fn", ",", "\n", "num_updates", ",", "step_size", ")", ":", "\n", "# super(InnerLoop, self).__init__(composer=baseComposer.composer,", "\n", "#     module_list=module_list, loss_fn=loss_fn)", "\n", "#Composer, already initialized", "\n", "    ", "self", ".", "loss_fn", "=", "loss_fn", "\n", "self", ".", "C", "=", "baseComposer", "\n", "self", ".", "C", ".", "cuda", "(", ")", "\n", "#Number of updates to be taken", "\n", "self", ".", "num_updates", "=", "num_updates", "\n", "#Step size for the updates", "\n", "self", ".", "step_size", "=", "step_size", "\n", "self", ".", "meta_batch_size", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.maml_inner_loop.InnerLoop.net_forward": [[40, 42], ["maml_inner_loop.InnerLoop.C.forward"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.forward"], ["", "def", "net_forward", "(", "self", ",", "x", ",", "weights", "=", "None", ")", ":", "\n", "    ", "return", "self", ".", "C", ".", "forward", "(", "x", ",", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.maml_inner_loop.InnerLoop.forward": [[43, 78], ["collections.OrderedDict", "range", "maml_inner_loop.InnerLoop.evaluate", "maml_inner_loop.InnerLoop.evaluate", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "collections.OrderedDict", "maml_inner_loop.InnerLoop.C.parameters", "maml_inner_loop.InnerLoop.forward_pass", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "maml_inner_loop.InnerLoop.forward_pass", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "zip", "maml_inner_loop.InnerLoop.C.named_parameters", "maml_inner_loop.InnerLoop.C.parameters", "collections.OrderedDict.values", "maml_inner_loop.InnerLoop.C.named_parameters", "zip", "collections.OrderedDict.items"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.evaluate", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.evaluate", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.maml_inner_loop.InnerLoop.forward_pass", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.maml_inner_loop.InnerLoop.forward_pass"], ["", "def", "forward", "(", "self", ",", "dataset", ")", ":", "\n", "# # Test net before training, should be random accuracy", "\n", "# tr_pre_loss, __ = self.evaluate(dataset.TrainInput, dataset.TrainOutput)", "\n", "# val_pre_loss, __ = self.evaluate(dataset.ValInput, dataset.ValOutput)", "\n", "    ", "fast_weights", "=", "OrderedDict", "(", "(", "name", ",", "param", ")", "for", "(", "name", ",", "param", ")", "\n", "in", "self", ".", "C", ".", "named_parameters", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_updates", ")", ":", "\n", "      ", "in_", ",", "target", "=", "dataset", ".", "TrainInput", ",", "dataset", ".", "TrainOutput", "\n", "if", "i", "==", "0", ":", "\n", "        ", "loss", ",", "_", "=", "self", ".", "forward_pass", "(", "in_", ",", "target", ")", "\n", "grads", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "self", ".", "C", ".", "parameters", "(", ")", ",", "\n", "create_graph", "=", "True", ",", "allow_unused", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "loss", ",", "_", "=", "self", ".", "forward_pass", "(", "in_", ",", "target", ",", "fast_weights", ")", "\n", "grads", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "fast_weights", ".", "values", "(", ")", ",", "\n", "create_graph", "=", "True", ",", "allow_unused", "=", "True", ")", "\n", "", "fast_weights", "=", "OrderedDict", "(", "(", "name", ",", "param", "-", "self", ".", "step_size", "*", "grad", ")", "\n", "for", "(", "(", "name", ",", "param", ")", ",", "grad", ")", "in", "zip", "(", "fast_weights", ".", "items", "(", ")", ",", "grads", ")", "\n", "if", "grad", "is", "not", "None", ")", "\n", "# Test net after training, should be better than random", "\n", "", "tr_post_loss", ",", "train_ans", "=", "self", ".", "evaluate", "(", "dataset", ".", "TrainInput", ",", "\n", "dataset", ".", "TrainOutput", ",", "weights", "=", "fast_weights", ")", "\n", "val_post_loss", ",", "val_ans", "=", "self", ".", "evaluate", "(", "dataset", ".", "ValInput", ",", "dataset", ".", "ValOutput", ",", "\n", "weights", "=", "fast_weights", ")", "\n", "# import pdb; pdb.set_trace()", "\n", "\n", "# Compute the meta gradient and return it", "\n", "in_", ",", "target", "=", "dataset", ".", "ValInput", ",", "dataset", ".", "ValOutput", "\n", "loss", "=", "val_post_loss", "/", "self", ".", "meta_batch_size", "\n", "grads", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "\n", "self", ".", "C", ".", "parameters", "(", ")", ",", "allow_unused", "=", "True", ")", "\n", "meta_grads", "=", "{", "name", ":", "g", "for", "(", "(", "name", ",", "_", ")", ",", "g", ")", "\n", "in", "zip", "(", "self", ".", "C", ".", "named_parameters", "(", ")", ",", "grads", ")", "}", "\n", "metrics", "=", "(", "tr_post_loss", ",", "val_post_loss", ",", "train_ans", ",", "val_ans", ")", "\n", "return", "metrics", ",", "meta_grads", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.maml_inner_loop.InnerLoop.forward_pass": [[79, 87], ["torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "maml_inner_loop.InnerLoop.net_forward", "maml_inner_loop.InnerLoop.loss_fn", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.net_forward"], ["", "def", "forward_pass", "(", "self", ",", "in_", ",", "target", ",", "weights", "=", "None", ")", ":", "\n", "    ", "''' Run data through net, return loss and output '''", "\n", "input_var", "=", "torch", ".", "autograd", ".", "Variable", "(", "in_", ")", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "target_var", "=", "torch", ".", "autograd", ".", "Variable", "(", "target", ")", ".", "cuda", "(", "non_blocking", "=", "True", ")", "\n", "# Run the batch through the net, compute loss", "\n", "out", "=", "self", ".", "net_forward", "(", "input_var", ",", "weights", ")", "\n", "loss", "=", "self", ".", "loss_fn", "(", "out", ",", "target_var", ")", "\n", "return", "loss", ",", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.maml_inner_loop.InnerLoop.evaluate": [[88, 92], ["maml_inner_loop.InnerLoop.forward_pass"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.maml_inner_loop.InnerLoop.forward_pass"], ["", "def", "evaluate", "(", "self", ",", "inp", ",", "out", ",", "weights", "=", "None", ")", ":", "\n", "    ", "'''evaluate the net on (inp, out)'''", "\n", "#Simpler than pytorch-maml/src/score.py bc I don't have acc nor batches", "\n", "return", "self", ".", "forward_pass", "(", "inp", ",", "out", ",", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.maml_inner_loop.InnerLoop.copy_weights": [[93, 101], ["enumerate", "zip", "isinstance", "maml_inner_loop.InnerLoop.C.module_list[].copy_weights", "isinstance", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.copy_weights"], ["", "def", "copy_weights", "(", "self", ",", "net", ")", ":", "\n", "    ", "'''Set this module's weights to be the same as those of 'net' '''", "\n", "for", "(", "i_m", ",", "(", "m_from", ",", "m_to", ")", ")", "in", "enumerate", "(", "\n", "zip", "(", "net", ".", "module_list", ",", "self", ".", "C", ".", "module_list", ")", ")", ":", "\n", "      ", "assert", "not", "(", "isinstance", "(", "m_to", ",", "nn", ".", "Linear", ")", "or", "isinstance", "(", "m_to", ",", "nn", ".", "Conv2d", ")", "\n", "or", "isinstance", "(", "m_to", ",", "nn", ".", "BatchNorm2d", ")", ")", "\n", "assert", "isinstance", "(", "m_to", ",", "torch_NN", ")", "\n", "self", ".", "C", ".", "module_list", "[", "i_m", "]", ".", "copy_weights", "(", "net", ".", "module_list", "[", "i_m", "]", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.create_functions_datasets.special_sine": [[26, 27], ["numpy.sin"], "function", ["None"], ["def", "special_sine", "(", "x", ",", "y", ",", "z", ")", ":", "return", "np", ".", "sin", "(", "np", ".", "pi", "*", "(", "y", "*", "x", "+", "z", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.create_functions_datasets.main": [[31, 132], ["numpy.reshape", "numpy.ones_like", "matplotlib.subplots", "print", "matplotlib.show", "h5py.File", "DATA.items", "range", "numpy.reshape", "range", "numpy.arange", "create_functions_datasets.main.run_sines_alet_etal"], "function", ["None"], ["def", "main", "(", "args", ")", ":", "\n", "  ", "def", "maybe_add_plot", "(", "ax_counter", ",", "x", ",", "y", ")", ":", "\n", "    ", "if", "random", ".", "random", "(", ")", "<", "0.025", "and", "ax_counter", "<", "9", ":", "\n", "      ", "ax", "[", "ax_counter", "//", "3", "]", "[", "ax_counter", "%", "3", "]", ".", "plot", "(", "x", ",", "y", ")", "\n", "ax", "[", "ax_counter", "//", "3", "]", "[", "ax_counter", "%", "3", "]", ".", "yaxis", ".", "set_ticks", "(", "[", "-", "1", ",", "0", ",", "1", "]", ")", "\n", "ax", "[", "ax_counter", "//", "3", "]", "[", "ax_counter", "%", "3", "]", ".", "xaxis", ".", "set_ticks", "(", "[", "-", "1", ",", "0", ",", "1", "]", ")", "\n", "ax", "[", "ax_counter", "//", "3", "]", "[", "ax_counter", "%", "3", "]", ".", "set_ylim", "(", "(", "-", "1.1", ",", "1.1", ")", ")", "\n", "return", "ax_counter", "+", "1", "\n", "", "else", ":", "return", "ax_counter", "\n", "\n", "", "def", "run_sines_alet_etal", "(", "args", ")", ":", "\n", "# As described in https://arxiv.org/abs/1806.10166", "\n", "# Varies frequency and phase", "\n", "    ", "ax_counter", "=", "0", "\n", "for", "dataset", "in", "range", "(", "args", ".", "meta_datasets", ")", ":", "\n", "      ", "freq", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.1", ",", "high", "=", "5.0", ")", "\n", "phase", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.", ",", "high", "=", "np", ".", "pi", ")", "\n", "y", "=", "special_sine", "(", "x", ",", "freq", ",", "phase", ")", "\n", "ori_name", "=", "(", "str", "(", "freq", ")", ".", "replace", "(", "'.'", ",", "'d'", ")", "+", "'_'", "+", "\n", "str", "(", "phase", ")", ".", "replace", "(", "'.'", ",", "'d'", ")", ")", "\n", "DATA", "[", "ori_name", "+", "'-IN'", "]", "=", "x", "\n", "DATA", "[", "ori_name", "+", "'-OUT'", "]", "=", "y", "\n", "ax_counter", "=", "maybe_add_plot", "(", "ax_counter", ",", "x", ",", "y", ")", "\n", "\n", "", "", "def", "run_sines_finn_etal", "(", "args", ")", ":", "\n", "# As described in https://arxiv.org/abs/1703.03400", "\n", "# Varies amplitude and phase", "\n", "# Not part of original experiments in https://arxiv.org/abs/1806.10166", "\n", "# because of a misunderstanding on our part.", "\n", "    ", "ax_counter", "=", "0", "\n", "x", "=", "np", ".", "reshape", "(", "np", ".", "arange", "(", "-", "5.", ",", "5.", ",", "2.", "/", "args", ".", "limit_data", ")", ",", "(", "-", "1", ",", "1", ")", ")", "\n", "for", "dataset", "in", "range", "(", "args", ".", "meta_datasets", ")", ":", "\n", "      ", "amplitude", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.1", ",", "high", "=", "5.0", ")", "\n", "phase", "=", "np", ".", "random", ".", "uniform", "(", "low", "=", "0.", ",", "high", "=", "np", ".", "pi", ")", "\n", "y", "=", "amplitude", "*", "special_sine", "(", "x", ",", "1.", ",", "phase", ")", "\n", "ori_name", "=", "(", "str", "(", "amplitude", ")", ".", "replace", "(", "'.'", ",", "'d'", ")", "+", "'_'", "+", "\n", "str", "(", "phase", ")", ".", "replace", "(", "'.'", ",", "'d'", ")", ")", "\n", "DATA", "[", "ori_name", "+", "'-IN'", "]", "=", "x", "\n", "DATA", "[", "ori_name", "+", "'-OUT'", "]", "=", "y", "\n", "ax_counter", "=", "maybe_add_plot", "(", "ax_counter", ",", "x", ",", "y", ")", "\n", "\n", "", "", "def", "run_functions", "(", "args", ")", ":", "\n", "    ", "ax_counter", "=", "0", "\n", "c", "=", "4.", "\n", "for", "a", "in", "LIST_OPS", ":", "\n", "      ", "for", "b", "in", "LIST_OPS", ":", "\n", "        ", "if", "b", "<", "a", ":", "continue", "#sum is commutative", "\n", "if", "args", ".", "not_alone", "and", "b", "==", "a", ":", "continue", "\n", "print", "(", "a", ",", "b", ")", "\n", "ori_name", "=", "a", "+", "'_'", "+", "b", "\n", "y", "=", "(", "OPS", "[", "a", "]", "(", "x", ",", "c", "*", "o", ")", "+", "OPS", "[", "b", "]", "(", "x", ",", "c", "*", "o", ")", ")", "/", "2.", "\n", "DATA", "[", "ori_name", "+", "'-IN'", "]", "=", "x", "\n", "DATA", "[", "ori_name", "+", "'-OUT'", "]", "=", "y", "\n", "ax_counter", "=", "maybe_add_plot", "(", "ax_counter", ",", "x", ",", "y", ")", "\n", "\n", "", "", "", "DATA", "=", "{", "}", "\n", "x", "=", "np", ".", "reshape", "(", "np", ".", "arange", "(", "-", "1.", ",", "1.", ",", "2.", "/", "args", ".", "limit_data", ")", ",", "(", "-", "1", ",", "1", ")", ")", "\n", "o", "=", "np", ".", "ones_like", "(", "x", ")", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "3", ",", "ncols", "=", "3", ")", "\n", "\n", "if", "args", ".", "mode", "==", "'sines'", ":", "run_sines_alet_etal", "(", "args", ")", "\n", "elif", "args", ".", "mode", "==", "'sines-finn'", ":", "run_sines_finn_etal", "(", "args", ")", "\n", "elif", "args", ".", "mode", "==", "'sum'", ":", "run_functions", "(", "args", ")", "\n", "else", ":", "raise", "NotImplementedError", "\n", "\n", "print", "(", "len", "(", "DATA", ")", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "# Plots 2 images visualizing a few sumed functions.", "\n", "if", "args", ".", "plot_metalearning_slide", ":", "\n", "#Plot 4 meta-training", "\n", "    ", "funs", "=", "[", "[", "'abs'", ",", "'cos'", "]", ",", "[", "'sign'", ",", "'square'", "]", ",", "\n", "[", "'id'", ",", "'exp2'", "]", ",", "[", "'id'", ",", "'cos'", "]", "]", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "4", ")", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "      ", "x", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ",", "8", ")", "\n", "y", "=", "np", ".", "ones_like", "(", "x", ")", "*", "4.", "\n", "ax", "[", "i", "]", ".", "scatter", "(", "x", ",", "(", "OPS", "[", "funs", "[", "i", "]", "[", "0", "]", "]", "(", "x", ",", "y", ")", "+", "OPS", "[", "funs", "[", "i", "]", "[", "1", "]", "]", "(", "x", ",", "y", ")", ")", "/", "2.", ")", "\n", "ax", "[", "i", "]", ".", "set_ylim", "(", "[", "-", "1.2", ",", "1.2", "]", ")", "\n", "ax", "[", "i", "]", ".", "set_xlim", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "ax", "[", "i", "]", ".", "set_xticks", "(", "[", "]", ")", "\n", "ax", "[", "i", "]", ".", "set_yticks", "(", "[", "]", ")", "\n", "ax", "[", "i", "]", ".", "set_aspect", "(", "1.", ")", "\n", "", "plt", ".", "savefig", "(", "'meta-train.png'", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "4", ")", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "      ", "x", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ",", "100", ")", "\n", "y", "=", "np", ".", "ones_like", "(", "x", ")", "*", "4.", "\n", "ax", "[", "i", "]", ".", "scatter", "(", "x", ",", "(", "OPS", "[", "funs", "[", "i", "]", "[", "0", "]", "]", "(", "x", ",", "y", ")", "+", "OPS", "[", "funs", "[", "i", "]", "[", "1", "]", "]", "(", "x", ",", "y", ")", ")", "/", "2.", ")", "\n", "ax", "[", "i", "]", ".", "set_ylim", "(", "[", "-", "1.2", ",", "1.2", "]", ")", "\n", "ax", "[", "i", "]", ".", "set_xlim", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "ax", "[", "i", "]", ".", "set_xticks", "(", "[", "]", ")", "\n", "ax", "[", "i", "]", ".", "set_yticks", "(", "[", "]", ")", "\n", "ax", "[", "i", "]", ".", "set_aspect", "(", "1.", ")", "\n", "", "plt", ".", "savefig", "(", "'meta-test.png'", ")", "\n", "\n", "# Saves to file", "\n", "", "h", "=", "h5py", ".", "File", "(", "args", ".", "out_file", ")", "\n", "for", "k", ",", "v", "in", "DATA", ".", "items", "(", ")", ":", "\n", "    ", "h", ".", "create_dataset", "(", "k", ",", "data", "=", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.__init__": [[8, 34], ["len", "sum", "torch.nn.ParameterList", "hasattr", "type", "type", "list", "len", "type", "type", "args.type_modules.split", "map", "type", "type", "type", "type", "str", "type", "type", "type", "type", "args.num_modules.split", "str"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "#Assert module specifications are consistent.", "\n", "    ", "if", "not", "hasattr", "(", "self", ",", "'type_modules'", ")", ":", "self", ".", "type_modules", "=", "[", "]", "\n", "if", "self", ".", "type_modules", "!=", "[", "]", ":", "\n", "      ", "pass", "\n", "", "elif", "type", "(", "args", ".", "type_modules", ")", "==", "type", "(", "''", ")", ":", "\n", "      ", "self", ".", "type_modules", "=", "args", ".", "type_modules", ".", "split", "(", "','", ")", "\n", "", "else", ":", "\n", "      ", "assert", "type", "(", "args", ".", "type_modules", ")", "==", "type", "(", "[", "]", ")", "\n", "assert", "type", "(", "args", ".", "type_modules", "[", "0", "]", ")", "==", "type", "(", "'a'", ")", "\n", "self", ".", "type_modules", "=", "args", ".", "type_modules", "\n", "", "if", "type", "(", "args", ".", "num_modules", ")", "==", "type", "(", "''", ")", ":", "\n", "      ", "self", ".", "num_modules", "=", "list", "(", "map", "(", "int", ",", "\n", "args", ".", "num_modules", ".", "split", "(", "','", ")", ")", ")", "\n", "", "else", ":", "\n", "      ", "assert", "type", "(", "args", ".", "num_modules", ")", "==", "type", "(", "[", "]", ")", "\n", "assert", "type", "(", "args", ".", "num_modules", "[", "0", "]", ")", "==", "type", "(", "1", ")", "\n", "self", ".", "num_modules", "=", "args", ".", "num_modules", "\n", "", "self", ".", "num_types", "=", "len", "(", "self", ".", "num_modules", ")", "\n", "assert", "len", "(", "self", ".", "type_modules", ")", "==", "self", ".", "num_types", ",", "(", "str", "(", "self", ".", "type_modules", ")", "+", "' should have '", "+", "str", "(", "self", ".", "num_types", ")", "+", "' elts.'", ")", "\n", "self", ".", "tot_modules", "=", "sum", "(", "self", ".", "num_modules", ")", "\n", "\n", "self", ".", "usage_normalization", "=", "1e-9", "\n", "self", ".", "has_global_variable", "=", "False", "\n", "self", ".", "StructureParameters", "=", "ParameterList", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.initialize_structure": [[35, 40], ["None"], "methods", ["None"], ["", "def", "initialize_structure", "(", "self", ")", ":", "\n", "    ", "'''\n    Create a random structure\n    '''", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.propose_new_structure": [[41, 46], ["None"], "methods", ["None"], ["", "def", "propose_new_structure", "(", "self", ",", "new_structure", ")", ":", "\n", "    ", "'''\n    Given a structure, new_structure, make a modification\n    '''", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.update_structure": [[47, 53], ["None"], "methods", ["None"], ["", "def", "update_structure", "(", "self", ",", "structure", ",", "step", "=", "None", ")", ":", "\n", "    ", "'''\n    Optional function updating some aspects of the structure\n    for instance to adapt to some parameters that changed by SGD\n    '''", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.update_Usage_counters": [[54, 59], ["None"], "methods", ["None"], ["", "def", "update_Usage_counters", "(", "self", ",", "METRICS", ",", "T", ")", ":", "\n", "    ", "'''\n    Updates table of fraction of times module is used for each dataset.\n    '''", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.modules_given_structure": [[60, 62], ["None"], "methods", ["None"], ["", "def", "modules_given_structure", "(", "self", ",", "structure", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.propose_new_global_structure": [[66, 68], ["None"], "methods", ["None"], ["", "def", "propose_new_global_structure", "(", "self", ")", ":", "\n", "    ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.save_customized_files": [[69, 71], ["None"], "methods", ["None"], ["", "def", "save_customized_files", "(", "self", ",", "directory", ")", ":", "\n", "    ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.get_plot_name": [[72, 77], ["None"], "methods", ["None"], ["", "def", "get_plot_name", "(", "self", ",", "args", ",", "plot_name", ")", ":", "\n", "    ", "'''\n    Modifies the plot_name\n    '''", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.update_PosUsage_counters": [[78, 84], ["None"], "methods", ["None"], ["", "def", "update_PosUsage_counters", "(", "self", ",", "METRICS", ")", ":", "\n", "    ", "'''\n    Updates table of fraction of times module is used for each dataset.\n    and for each slot.\n    '''", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.update_customized_counters": [[85, 90], ["None"], "methods", ["None"], ["", "def", "update_customized_counters", "(", "self", ",", "METRICS", "=", "None", ")", ":", "\n", "    ", "'''\n    Updates tables depending on the pertinent structure.\n    '''", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.update_customized_stats": [[91, 96], ["None"], "methods", ["None"], ["", "def", "update_customized_stats", "(", "self", ",", "BG", "=", "None", ")", ":", "\n", "    ", "'''\n    Updates tables depending on the pertinent structure.\n    '''", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.plot_customized_usage_rate": [[97, 99], ["None"], "methods", ["None"], ["", "def", "plot_customized_usage_rate", "(", "self", ",", "directory", "=", "None", ")", ":", "\n", "    ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.plot_usage": [[104, 110], ["matplotlib.gca().matshow", "matplotlib.gcf().colorbar", "matplotlib.savefig", "matplotlib.clf", "os.path.join", "matplotlib.gca", "matplotlib.gcf"], "methods", ["None"], ["", "def", "plot_usage", "(", "self", ",", "directory", ")", ":", "\n", "    ", "if", "self", ".", "Usage", "is", "not", "None", ":", "\n", "      ", "cax", "=", "plt", ".", "gca", "(", ")", ".", "matshow", "(", "self", ".", "Usage", "/", "self", ".", "usage_normalization", ")", "\n", "plt", ".", "gcf", "(", ")", ".", "colorbar", "(", "cax", ")", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'usage-rate'", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.initialize_all_structures": [[111, 126], ["tqdm.tqdm.tqdm", "range", "range", "structure.Structure.initialize_structure", "len", "structure.Structure.initialize_structure", "range", "len"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.initialize_structure", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.initialize_structure"], ["", "", "def", "initialize_all_structures", "(", "self", ",", "T", ",", "mtrain_copies", "=", "1", ")", ":", "\n", "    ", "self", ".", "TrainStructures", "=", "[", "None", "for", "_", "in", "range", "(", "mtrain_copies", "*", "T", ".", "mtrain", ")", "]", "\n", "self", ".", "ValStructures", "=", "[", "None", "for", "_", "in", "T", ".", "MVAL", "]", "\n", "for", "i", "in", "Tqdm", "(", "range", "(", "len", "(", "self", ".", "TrainStructures", ")", ")", ")", ":", "\n", "      ", "self", ".", "TrainStructures", "[", "i", "]", "=", "self", ".", "initialize_structure", "(", ")", "\n", "self", ".", "TrainStructures", "[", "i", "]", "[", "'original_input_shape'", "]", "=", "(", "\n", "T", ".", "MTRAIN", "[", "i", "%", "T", ".", "mtrain", "]", ".", "original_input_shape", ")", "\n", "self", ".", "TrainStructures", "[", "i", "]", "[", "'original_output_shape'", "]", "=", "(", "\n", "T", ".", "MTRAIN", "[", "i", "%", "T", ".", "mtrain", "]", ".", "original_output_shape", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "self", ".", "ValStructures", ")", ")", ":", "\n", "      ", "self", ".", "ValStructures", "[", "i", "]", "=", "self", ".", "initialize_structure", "(", ")", "\n", "self", ".", "ValStructures", "[", "i", "]", "[", "'original_input_shape'", "]", "=", "(", "\n", "T", ".", "MVAL", "[", "i", "]", ".", "original_input_shape", ")", "\n", "self", ".", "ValStructures", "[", "i", "]", "[", "'original_output_shape'", "]", "=", "(", "\n", "T", ".", "MVAL", "[", "i", "]", ".", "original_output_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.default_update_Usage_counters": [[132, 149], ["enumerate", "list", "list.sort", "enumerate", "range", "range", "range", "len"], "methods", ["None"], ["", "", "def", "default_update_Usage_counters", "(", "self", ",", "METRICS", ",", "T", ")", ":", "\n", "    ", "'''\n    Updates table of fraction of times module is used for each dataset.\n    '''", "\n", "eps", "=", "1e-3", "\n", "self", ".", "Usage", "*=", "(", "1", "-", "eps", ")", "\n", "for", "i_s", ",", "structure", "in", "enumerate", "(", "self", ".", "TrainStructures", "+", "self", ".", "ValStructures", ")", ":", "\n", "      ", "for", "m", "in", "structure", "[", "'modules'", "]", ":", "\n", "        ", "self", ".", "Usage", "[", "i_s", "]", "[", "m", "]", "+=", "eps", "\n", "", "", "names", "=", "(", "[", "T", ".", "MTRAIN", "[", "i", "%", "T", ".", "mtrain", "]", ".", "name", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "TrainStructures", ")", ")", "]", "+", "[", "_", ".", "name", "for", "_", "in", "T", ".", "MVAL", "]", ")", "\n", "names", "=", "list", "(", "enumerate", "(", "names", ")", ")", "\n", "names", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "values", "=", "self", ".", "Usage", "[", "[", "_", "[", "0", "]", "for", "_", "in", "names", "]", ",", ":", "]", "\n", "METRICS", "[", "'Usage'", "]", "=", "[", "[", "values", "[", "i", "]", "[", "j", "]", "for", "j", "in", "range", "(", "values", ".", "shape", "[", "1", "]", ")", "]", "\n", "for", "i", "in", "range", "(", "values", ".", "shape", "[", "0", "]", ")", "]", "\n", "METRICS", "[", "'Usage-names'", "]", "=", "[", "_", "[", "1", "]", "for", "_", "in", "names", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.default_initialize_structure": [[150, 157], ["range", "numpy.random.randint", "numpy.random.randint", "structure[].append"], "methods", ["None"], ["", "def", "default_initialize_structure", "(", "self", ")", ":", "\n", "    ", "structure", "=", "{", "'modules'", ":", "[", "]", "}", "\n", "for", "i", "in", "range", "(", "self", ".", "structure_size", ")", ":", "\n", "      ", "act_type", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "structure_size", ")", "\n", "act_mod", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "num_modules", "[", "act_type", "]", ")", "\n", "structure", "[", "'modules'", "]", ".", "append", "(", "self", ".", "Modules", "[", "act_type", "]", "[", "act_mod", "]", ")", "\n", "", "return", "structure", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.default_initialize_fixed_structure": [[158, 167], ["range", "numpy.random.randint", "structure[].append"], "methods", ["None"], ["", "def", "default_initialize_fixed_structure", "(", "self", ")", ":", "\n", "#Position 'i' in the structure can only be filled by a node of type 'i'", "\n", "    ", "assert", "self", ".", "num_types", "==", "self", ".", "structure_size", "\n", "structure", "=", "{", "'modules'", ":", "[", "]", "}", "\n", "for", "i", "in", "range", "(", "self", ".", "num_types", ")", ":", "\n", "      ", "act_type", "=", "i", "\n", "act_mod", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "num_modules", "[", "act_type", "]", ")", "\n", "structure", "[", "'modules'", "]", ".", "append", "(", "self", ".", "Modules", "[", "act_type", "]", "[", "act_mod", "]", ")", "\n", "", "return", "structure", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.default_propose_new_structure": [[168, 173], ["numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "len"], "methods", ["None"], ["", "def", "default_propose_new_structure", "(", "self", ",", "new_structure", ")", ":", "\n", "    ", "pos", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "new_structure", "[", "'modules'", "]", ")", ")", "\n", "act_type", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "num_types", ")", "\n", "act_mod", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "num_modules", "[", "act_type", "]", ")", "\n", "new_structure", "[", "'modules'", "]", "[", "pos", "]", "=", "self", ".", "Modules", "[", "act_type", "]", "[", "act_mod", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.default_propose_new_fixed_structure": [[174, 180], ["numpy.random.randint", "numpy.random.randint", "len"], "methods", ["None"], ["", "def", "default_propose_new_fixed_structure", "(", "self", ",", "new_structure", ")", ":", "\n", "#Position 'i' in the structure can only be filled by a node of type 'i'", "\n", "    ", "pos", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "new_structure", "[", "'modules'", "]", ")", ")", "\n", "act_type", "=", "pos", "\n", "act_mod", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "num_modules", "[", "act_type", "]", ")", "\n", "new_structure", "[", "'modules'", "]", "[", "pos", "]", "=", "self", ".", "Modules", "[", "act_type", "]", "[", "act_mod", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_main.main": [[9, 117], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "tensorboardX.SummaryWriter", "composer.startswith", "modular_metalearning.BounceGrad", "modular_metalearning.BounceGrad.SAConfig_SGDModules", "composer.split", "int", "sum_composer.Sum_Structure", "composer.startswith", "composer.split", "int", "functioncomposition_composer.FunctionComposition_Structure", "str", "[].split", "str", "str", "parser.parse_args.data_desc.split"], "function", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.SAConfig_SGDModules"], ["def", "main", "(", ")", ":", "\n", "#########", "\n", "# Flags #", "\n", "#########", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "# Compute flags", "\n", "parser", ".", "add_argument", "(", "'--device'", ",", "dest", "=", "'nn_device'", ",", "default", "=", "'cuda:0'", ",", "\n", "help", "=", "'what device we want to run things in'", ")", "\n", "# Data flags", "\n", "parser", ".", "add_argument", "(", "'--data_desc'", ",", "dest", "=", "'data_desc'", ",", "\n", "help", "=", "'description of data source'", ")", "\n", "parser", ".", "add_argument", "(", "'--limit_data'", ",", "dest", "=", "'limit_data'", ",", "type", "=", "int", ",", "\n", "help", "=", "'maximum number of points per dataset'", ",", "default", "=", "10000", ")", "\n", "parser", ".", "add_argument", "(", "'--max_datasets'", ",", "dest", "=", "'max_datasets'", ",", "type", "=", "int", ",", "\n", "default", "=", "256", ",", "help", "=", "'maximum number of datasets'", ")", "\n", "parser", ".", "add_argument", "(", "'--data_split'", ",", "dest", "=", "'data_split'", ",", "default", "=", "'20,80,0'", ",", "\n", "help", "=", "'comma-separated distribution (in %) of train,val,test per dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--meta_split'", ",", "dest", "=", "'meta_split'", ",", "default", "=", "'90,10,0'", ",", "\n", "help", "=", "'comma-separated distribution (in %) of mtrain,mval,mtest'", ")", "\n", "parser", ".", "add_argument", "(", "'--split_by_file'", ",", "dest", "=", "'split_by_file'", ",", "\n", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--smaller_MVals'", ",", "dest", "=", "'smaller_MVals'", ",", "type", "=", "str", ",", "\n", "default", "=", "''", ",", "help", "=", "'List of extra smaller training sizes for MVal'", ")", "\n", "parser", ".", "add_argument", "(", "'--dont_normalize'", ",", "dest", "=", "'normalize_data'", ",", "\n", "action", "=", "'store_false'", ")", "\n", "\n", "# BounceGrad flags", "\n", "parser", ".", "add_argument", "(", "'--torch_seed'", ",", "dest", "=", "'torch_seed'", ",", "type", "=", "int", ",", "\n", "default", "=", "0", ",", "help", "=", "'random seed for pytorch'", ")", "\n", "parser", ".", "add_argument", "(", "'--mtrain_copies'", ",", "dest", "=", "'mtrain_copies'", ",", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "help", "=", "'number of copies of meta-train, searching multiple \\\n                  structures in parallel'", ")", "\n", "parser", ".", "add_argument", "(", "'--dont_bounce'", ",", "dest", "=", "'do_bounce'", ",", "action", "=", "'store_false'", ",", "\n", "help", "=", "'Skip Simulated Annealing and proposing structures; only Grad step'", ")", "\n", "parser", ".", "add_argument", "(", "'--meta_lr'", ",", "dest", "=", "'meta_lr'", ",", "type", "=", "float", ",", "default", "=", "'1e-3'", ",", "\n", "help", "=", "'learning rate for module parameters'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_modules'", ",", "dest", "=", "'num_modules'", ",", "\n", "help", "=", "'comma-separated list with size of each population of module type'", ")", "\n", "parser", ".", "add_argument", "(", "'--type_modules'", ",", "dest", "=", "'type_modules'", ",", "\n", "help", "=", "'comma-separated list describing the type of each module category'", ")", "\n", "parser", ".", "add_argument", "(", "'--composer'", ",", "dest", "=", "'composer'", ",", "default", "=", "'composition'", ",", "\n", "help", "=", "'Which type of composition to use; \\\n          for example \"compositon,sum,concatenate,gnn\"'", ")", "\n", "parser", ".", "add_argument", "(", "'--optimization_steps'", ",", "dest", "=", "'optimization_steps'", ",", "\n", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "'number of BounceGrad steps'", ")", "\n", "parser", ".", "add_argument", "(", "'--meta_batch_size'", ",", "dest", "=", "'meta_batch_size'", ",", "type", "=", "int", ",", "\n", "default", "=", "0", ",", "help", "=", "'Number of metatrain cases between gradient steps;\\\n          0 if all MTRAIN'", ")", "\n", "\n", "# MAML flags", "\n", "parser", ".", "add_argument", "(", "'--MAML'", ",", "dest", "=", "'MAML'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'MAML loss instead of conventional loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--MAML_inner_updates'", ",", "dest", "=", "'MAML_inner_updates'", ",", "\n", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'number of gradient steps in the inner loop'", ")", "\n", "parser", ".", "add_argument", "(", "'--MAML_step_size'", ",", "dest", "=", "'MAML_step_size'", ",", "type", "=", "float", ",", "\n", "default", "=", "1e-2", ",", "help", "=", "'step size in MAML gradient steps'", ")", "\n", "\n", "# Plotting flags", "\n", "parser", ".", "add_argument", "(", "'--plot_name'", ",", "dest", "=", "'plot_name'", ",", "\n", "default", "=", "'default'", ",", "help", "=", "'Name for error plot'", ")", "\n", "parser", ".", "add_argument", "(", "'--store_video'", ",", "dest", "=", "'store_video'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Store images every step into video folder'", ")", "\n", "parser", ".", "add_argument", "(", "'--plot_ymax'", ",", "dest", "=", "'plot_ymax'", ",", "type", "=", "float", ",", "\n", "default", "=", "-", "1.", ",", "help", "=", "'maximum y in zoomed loss plot'", ")", "\n", "parser", ".", "add_argument", "(", "'--plot_freq'", ",", "dest", "=", "'plot_freq'", ",", "type", "=", "int", ",", "\n", "default", "=", "5", ",", "help", "=", "'Number of optimization steps between plots'", ")", "\n", "\n", "# Flags mostly useful for restarting experiments", "\n", "parser", ".", "add_argument", "(", "'--load_modules'", ",", "dest", "=", "'load_modules'", ",", "type", "=", "str", ",", "\n", "default", "=", "''", ",", "help", "=", "'Filepath to load modules from self.L;\\\n          empty if dont want to load'", ")", "\n", "parser", ".", "add_argument", "(", "'--load_structures_and_metrics'", ",", "\n", "dest", "=", "'load_structures_and_metrics'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'Filepath to load structures and metrics;\\\n          empty if dont want to load'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_modules'", ",", "dest", "=", "'save_modules'", ",", "type", "=", "str", ",", "\n", "default", "=", "''", ",", "help", "=", "'Filepath to save modules from self.L;\\\n          if empty use plot_name'", ")", "\n", "parser", ".", "add_argument", "(", "'--initial_temp'", ",", "dest", "=", "'initial_temp'", ",", "type", "=", "float", ",", "\n", "default", "=", "0", ",", "help", "=", "'[log] initial temperature'", ")", "\n", "parser", ".", "add_argument", "(", "'--initial_acc'", ",", "dest", "=", "'initial_acc'", ",", "type", "=", "float", ",", "\n", "default", "=", "0", ",", "help", "=", "'[log] initial acceptance ratio'", ")", "\n", "\n", "# Parsing args", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Tensorboard writer", "\n", "tensorboardX_writer", "=", "SummaryWriter", "(", "\n", "comment", "=", "'composer='", "+", "args", ".", "composer", "+", "\n", "'_optsteps='", "+", "str", "(", "args", ".", "optimization_steps", ")", "+", "\n", "'_copies='", "+", "str", "(", "args", ".", "mtrain_copies", ")", "+", "\n", "'_data='", "+", "args", ".", "data_desc", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "+", "'_'", "+", "\n", "str", "(", "args", ".", "meta_lr", ")", ")", "\n", "\n", "# Finding composer", "\n", "composer", "=", "args", ".", "composer", "\n", "if", "composer", ".", "startswith", "(", "'sum'", ")", ":", "\n", "    ", "[", "composer", ",", "args", ".", "structure_size", "]", "=", "composer", ".", "split", "(", "'-'", ")", "\n", "args", ".", "structure_size", "=", "int", "(", "args", ".", "structure_size", ")", "\n", "S", "=", "Sum_Structure", "(", "args", "=", "args", ")", "\n", "", "elif", "composer", ".", "startswith", "(", "'functionComposition'", ")", ":", "\n", "    ", "[", "composer", ",", "args", ".", "structure_size", "]", "=", "composer", ".", "split", "(", "'-'", ")", "\n", "args", ".", "structure_size", "=", "int", "(", "args", ".", "structure_size", ")", "\n", "S", "=", "FunctionComposition_Structure", "(", "args", "=", "args", ")", "\n", "", "else", ":", "raise", "NotImplementedError", "\n", "\n", "bg", "=", "BounceGrad", "(", "S", "=", "S", ",", "args", "=", "args", ",", "tensorboardX_writer", "=", "tensorboardX_writer", ")", "\n", "bg", ".", "SAConfig_SGDModules", "(", "args", ".", "optimization_steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.__init__": [[23, 103], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "modular_metalearning.BounceGrad.create_dataset", "modular_metalearning.BounceGrad.create_modules", "modular_metalearning.BounceGrad.get_plot_name", "os.path.exists", "os.makedirs", "numpy.zeros", "modular_metalearning.BounceGrad.S.save_customized_files", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.set_default_tensor_type", "torch.set_default_tensor_type", "torch.set_default_tensor_type", "torch.set_default_tensor_type", "torch.set_default_tensor_type", "torch.set_default_tensor_type", "torch.set_default_tensor_type", "torch.set_default_tensor_type", "list", "print", "shutil.rmtree", "os.makedirs", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "map", "map", "map", "len", "range", "len", "args.smaller_MVals.split", "args.data_split.split", "args.meta_split.split", "range"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.create_dataset", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.create_modules", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.get_plot_name", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.save_customized_files"], ["  ", "def", "__init__", "(", "self", ",", "S", ",", "args", ",", "tensorboardX_writer", "=", "None", ")", ":", "\n", "##############################", "\n", "# Parse parameters from args #", "\n", "##############################", "\n", "    ", "self", ".", "S", "=", "S", "\n", "self", ".", "composer", "=", "args", ".", "composer", "\n", "#MAML parameters", "\n", "self", ".", "MAML", "=", "args", ".", "MAML", "\n", "self", ".", "MAML_loss_fn", "=", "(", "lambda", "x", ",", "y", ":", "torch", ".", "mean", "(", "(", "x", "-", "y", ")", "**", "2", ")", ")", "\n", "self", ".", "MAML_inner_updates", "=", "args", ".", "MAML_inner_updates", "\n", "self", ".", "MAML_step_size", "=", "args", ".", "MAML_step_size", "\n", "\n", "# Device", "\n", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", "or", "args", ".", "nn_device", "==", "'cpu'", ":", "\n", "      ", "self", ".", "nn_device", "=", "'cpu'", "\n", "torch", ".", "set_default_tensor_type", "(", "'torch.FloatTensor'", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "nn_device", "=", "args", ".", "nn_device", "\n", "torch", ".", "set_default_tensor_type", "(", "'torch.cuda.FloatTensor'", ")", "\n", "", "torch", ".", "device", "(", "self", ".", "nn_device", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "torch_seed", ")", "\n", "\n", "#Other parameters", "\n", "self", ".", "mtrain_copies", "=", "args", ".", "mtrain_copies", "\n", "self", ".", "normalize_data", "=", "args", ".", "normalize_data", "\n", "self", ".", "do_bounce", "=", "args", ".", "do_bounce", "\n", "self", ".", "meta_lr", "=", "args", ".", "meta_lr", "\n", "self", ".", "initial_temp", "=", "args", ".", "initial_temp", "\n", "self", ".", "initial_acc", "=", "args", ".", "initial_acc", "\n", "self", ".", "execute_gd_every", "=", "args", ".", "meta_batch_size", "\n", "self", ".", "smaller_MVals", "=", "(", "list", "(", "map", "(", "int", ",", "args", ".", "smaller_MVals", ".", "split", "(", "','", ")", ")", ")", "\n", "if", "args", ".", "smaller_MVals", "!=", "''", "else", "[", "]", ")", "\n", "self", ".", "split_by_file", "=", "args", ".", "split_by_file", "\n", "self", ".", "limit_data", "=", "args", ".", "limit_data", "\n", "self", ".", "max_datasets", "=", "args", ".", "max_datasets", "\n", "self", ".", "data_split", "=", "[", "x", "/", "100", "for", "x", "in", "map", "(", "int", ",", "args", ".", "data_split", ".", "split", "(", "','", ")", ")", "]", "\n", "self", ".", "meta_split", "=", "[", "x", "/", "100", "for", "x", "in", "map", "(", "int", ",", "args", ".", "meta_split", ".", "split", "(", "','", ")", ")", "]", "\n", "\n", "self", ".", "load_modules", "=", "args", ".", "load_modules", "\n", "self", ".", "load_structures_and_metrics", "=", "args", ".", "load_structures_and_metrics", "\n", "self", ".", "save_modules", "=", "args", ".", "save_modules", "\n", "if", "len", "(", "self", ".", "save_modules", ")", ">", "0", "and", "self", ".", "save_modules", "[", "-", "1", "]", "!=", "'/'", ":", "\n", "      ", "self", ".", "save_modules", "+=", "'/'", "#make it a folder", "\n", "\n", "#Create dataset and modules", "\n", "", "self", ".", "data_desc", "=", "args", ".", "data_desc", "\n", "self", ".", "create_dataset", "(", ")", "\n", "self", ".", "create_modules", "(", ")", "\n", "self", ".", "optimization_steps", "=", "args", ".", "optimization_steps", "#num. of BOUNCE-GRAD steps", "\n", "\n", "#Automatic plot_name", "\n", "self", ".", "get_plot_name", "(", "args", ")", "\n", "if", "self", ".", "save_modules", "==", "''", ":", "\n", "      ", "self", ".", "save_modules", "=", "self", ".", "plot_name", "\n", "print", "(", "'Saving modules to '", ",", "self", ".", "plot_name", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "plot_name", ")", ":", "shutil", ".", "rmtree", "(", "self", ".", "plot_name", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "plot_name", ")", "\n", "self", ".", "store_video", "=", "args", ".", "store_video", "\n", "if", "self", ".", "store_video", ":", "\n", "      ", "os", ".", "makedirs", "(", "self", ".", "plot_name", "+", "'/video'", ")", "\n", "#Metrics", "\n", "", "self", ".", "writer", "=", "tensorboardX_writer", "\n", "self", ".", "METRICS", "=", "{", "}", "\n", "keys_that_are_empty_lists", "=", "[", "'NumberToWords'", "]", "\n", "for", "k", "in", "keys_that_are_empty_lists", ":", "self", ".", "METRICS", "[", "k", "]", "=", "[", "]", "\n", "self", ".", "METRICS", "[", "'WordsToNumber'", "]", "=", "{", "}", "\n", "self", ".", "METRICS", "[", "'Sharing'", "]", "=", "[", "[", "0.", "for", "_", "in", "range", "(", "50", ")", "]", "for", "__", "in", "range", "(", "50", ")", "]", "\n", "self", ".", "last_comb", "=", "None", "\n", "self", ".", "last_comb_eval", "=", "None", "\n", "self", ".", "current", "=", "None", "\n", "self", ".", "current_Mtrain", "=", "None", "\n", "self", ".", "current_Meval", "=", "None", "\n", "self", ".", "perm_sample_modules", "=", "None", "\n", "self", ".", "perm_sample_fns", "=", "None", "\n", "self", ".", "plot_ymax", "=", "args", ".", "plot_ymax", "\n", "self", ".", "plot_freq", "=", "args", ".", "plot_freq", "\n", "\n", "#Structure params", "\n", "self", ".", "S", ".", "Usage", "=", "np", ".", "zeros", "(", "(", "self", ".", "mtrain_copies", "*", "self", ".", "T", ".", "mtrain", "+", "self", ".", "T", ".", "mval", ",", "len", "(", "self", ".", "L", ")", ")", ")", "\n", "self", ".", "S", ".", "save_customized_files", "(", "directory", "=", "self", ".", "plot_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.get_plot_name": [[104, 146], ["print", "args.plot_name.startswith", "modular_metalearning.BounceGrad.S.get_plot_name", "[].split", "len", "str", "net.split", "str", "str", "str", "str", "str", "print", "max", "max", "input", "str", "int", "args.plot_name.split", "input.lower", "print", "print", "input", "modular_metalearning.BounceGrad.data_desc.split"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.get_plot_name"], ["", "def", "get_plot_name", "(", "self", ",", "args", ")", ":", "\n", "    ", "shorter_data_desc", "=", "self", ".", "data_desc", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "if", "len", "(", "shorter_data_desc", ")", "<", "4", ":", "shorter_data_desc", "=", "self", ".", "data_desc", "[", "-", "4", ":", "]", "\n", "self", ".", "plot_name", "=", "shorter_data_desc", "+", "'_'", "\n", "self", ".", "plot_name", "+=", "self", ".", "S", ".", "composer_abbreviation", "+", "'_'", "\n", "if", "self", ".", "MAML", ":", "\n", "      ", "if", "max", "(", "self", ".", "S", ".", "num_modules", ")", ">", "1", ":", "self", ".", "plot_name", "+=", "'MOMA'", "\n", "else", ":", "self", ".", "plot_name", "+=", "'MAML'", "\n", "", "else", ":", "\n", "      ", "if", "max", "(", "self", ".", "S", ".", "num_modules", ")", ">", "1", ":", "self", ".", "plot_name", "+=", "'SA'", "\n", "else", ":", "self", ".", "plot_name", "+=", "'BIGNET'", "\n", "", "self", ".", "plot_name", "+=", "'_'", "+", "str", "(", "self", ".", "limit_data", ")", "+", "'_'", "+", "str", "(", "self", ".", "max_datasets", ")", "\n", "nn_size", "=", "0", "\n", "for", "net", "in", "self", ".", "S", ".", "type_modules", ":", "#dumb hash of module sizes", "\n", "      ", "aux", "=", "net", ".", "split", "(", "'-'", ")", "\n", "for", "num", "in", "aux", ":", "\n", "        ", "try", ":", "int_num", "=", "int", "(", "num", ")", "\n", "except", ":", "int_num", "=", "0", "\n", "nn_size", "+=", "int_num", "\n", "", "", "self", ".", "plot_name", "+=", "'_NNS'", "+", "str", "(", "nn_size", ")", "\n", "if", "self", ".", "split_by_file", ":", "\n", "      ", "self", ".", "plot_name", "+=", "'_split'", "\n", "", "else", ":", "self", ".", "plot_name", "+=", "'_file=shuffled'", "\n", "self", ".", "plot_name", "+=", "'_steps='", "+", "str", "(", "self", ".", "optimization_steps", ")", "\n", "self", ".", "plot_name", "+=", "'_lr='", "+", "str", "(", "self", ".", "meta_lr", ")", "\n", "self", ".", "plot_name", "+=", "'_Mupdt='", "+", "str", "(", "self", ".", "MAML_inner_updates", ")", "\n", "self", ".", "plot_name", "+=", "'_copies='", "+", "str", "(", "self", ".", "mtrain_copies", ")", "\n", "print", "(", "'plot_name: '", ",", "self", ".", "plot_name", ")", "\n", "if", "args", ".", "plot_name", ".", "startswith", "(", "'overwrite-'", ")", ":", "\n", "      ", "self", ".", "plot_name", "=", "'-'", ".", "join", "(", "args", ".", "plot_name", ".", "split", "(", "'-'", ")", "[", "1", ":", "]", ")", "\n", "print", "(", "'Args overwrote plot name to:'", ",", "self", ".", "plot_name", ")", "\n", "", "elif", "args", ".", "plot_name", "==", "'dummy'", ":", "\n", "      ", "ans", "=", "input", "(", "'Want to change plot_name to dummy?'", ")", "\n", "if", "ans", ".", "lower", "(", ")", "in", "[", "'y'", ",", "'yes'", "]", ":", "\n", "        ", "print", "(", "'Changed to dummy'", ")", "\n", "self", ".", "plot_name", "=", "'dummy'", "\n", "", "else", ":", "print", "(", "'Keeping automatic name'", ")", "\n", "", "elif", "args", ".", "plot_name", "==", "'default'", ":", "\n", "      ", "input", "(", "'I will not keep your name, see above'", ")", "\n", "", "else", ":", "self", ".", "plot_name", "=", "args", ".", "plot_name", "+", "'__'", "+", "self", ".", "plot_name", "\n", "self", ".", "S", ".", "get_plot_name", "(", "args", ",", "self", ".", "plot_name", ")", "\n", "if", "self", ".", "plot_name", "[", "-", "1", "]", "!=", "'/'", ":", "self", ".", "plot_name", "+=", "'/'", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.create_modules": [[147, 185], ["torch.nn.ModuleList", "torch.nn.ModuleList", "enumerate", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.ReduceLROnPlateau", "torch.optim.lr_scheduler.ReduceLROnPlateau", "zip", "typ.split", "range", "modular_metalearning.BounceGrad.nn_act.append", "modular_metalearning.BounceGrad.nn_inp.append", "modular_metalearning.BounceGrad.nn_hid.append", "modular_metalearning.BounceGrad.nn_out.append", "range", "modular_metalearning.BounceGrad.S.Modules.append", "modular_metalearning.BounceGrad.load_L", "modular_metalearning.BounceGrad.L.parameters", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "len", "custom_module.torch_NN().to", "l.append", "modular_metalearning.BounceGrad.L.append", "m.parameters", "int", "len", "custom_module.torch_NN"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.load_L"], ["", "def", "create_modules", "(", "self", ")", ":", "\n", "    ", "'''\n    Creates modules following num_modules and type_modules\n    '''", "\n", "self", ".", "L", "=", "nn", ".", "ModuleList", "(", ")", "#Library of PyTorch Modules", "\n", "self", ".", "S", ".", "Modules", "=", "[", "]", "\n", "self", ".", "nn_inp", "=", "[", "]", "\n", "self", ".", "nn_out", "=", "[", "]", "\n", "self", ".", "nn_hid", "=", "[", "]", "\n", "self", ".", "nn_act", "=", "[", "]", "\n", "for", "(", "t", ",", "(", "num", ",", "typ", ")", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "S", ".", "num_modules", ",", "self", ".", "S", ".", "type_modules", ")", ")", ":", "\n", "      ", "l", "=", "[", "]", "\n", "#'final_act'-#inp-#hid1-#hid2-...-#out", "\n", "#example: 'affine-123-64-64-42'", "\n", "typ_split", "=", "typ", ".", "split", "(", "'-'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "typ_split", ")", ")", ":", "\n", "        ", "try", ":", "\n", "          ", "typ_split", "[", "i", "]", "=", "int", "(", "typ_split", "[", "i", "]", ")", "\n", "", "except", ":", "pass", "\n", "", "self", ".", "nn_act", ".", "append", "(", "typ_split", "[", "0", "]", ")", "\n", "self", ".", "nn_inp", ".", "append", "(", "typ_split", "[", "1", "]", ")", "\n", "self", ".", "nn_hid", ".", "append", "(", "typ_split", "[", "2", ":", "-", "1", "]", ")", "\n", "self", ".", "nn_out", ".", "append", "(", "typ_split", "[", "-", "1", "]", ")", "\n", "for", "_", "in", "range", "(", "num", ")", ":", "\n", "        ", "aux_nn", "=", "torch_NN", "(", "inp", "=", "self", ".", "nn_inp", "[", "t", "]", ",", "out", "=", "self", ".", "nn_out", "[", "t", "]", ",", "\n", "hidden", "=", "self", ".", "nn_hid", "[", "t", "]", ",", "\n", "final_act", "=", "self", ".", "nn_act", "[", "t", "]", ")", ".", "to", "(", "device", "=", "self", ".", "nn_device", ")", "\n", "l", ".", "append", "(", "len", "(", "self", ".", "L", ")", ")", "\n", "self", ".", "L", ".", "append", "(", "aux_nn", ")", "\n", "", "self", ".", "S", ".", "Modules", ".", "append", "(", "l", ")", "\n", "", "if", "self", ".", "load_modules", "!=", "''", ":", "self", ".", "load_L", "(", "self", ".", "load_modules", ")", "\n", "self", ".", "SOpt", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "L", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "meta_lr", ")", "\n", "self", ".", "SOpt_scheduler", "=", "ReduceLROnPlateau", "(", "\n", "optimizer", "=", "self", ".", "SOpt", ",", "factor", "=", "1", "/", "2.", ",", "\n", "mode", "=", "'min'", ",", "patience", "=", "50", ",", "threshold", "=", "0", ",", "cooldown", "=", "300", ",", "verbose", "=", "True", ",", "\n", "min_lr", "=", "1e-4", ")", "\n", "self", ".", "LocalOpt", "=", "None", "#optimizes custom parameters --> uses Train, not Val", "\n", "self", ".", "initial_norms", "=", "[", "torch", ".", "norm", "(", "_", ")", "for", "m", "in", "self", ".", "L", "for", "_", "in", "m", ".", "parameters", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.create_dataset": [[186, 251], ["modular_metalearning.BounceGrad.data_desc.split", "modular_metalearning.BounceGrad.data_source.startswith", "len", "len", "len", "copy.deepcopy", "enumerate", "dataset.MetaHDFDataset", "modular_metalearning.BounceGrad.data_source.startswith", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "dataset.MetaNpySelfRegressDataset", "range", "range", "range", "range", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "modular_metalearning.BounceGrad.data_source.split", "len", "len", "len", "len", "modular_metalearning.BounceGrad.data_source.split", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "def", "create_dataset", "(", "self", ")", ":", "\n", "    ", "'''\n    Creates dataset by calling dataset.py and transforms it to pytorch tensors.\n    '''", "\n", "# Parsing", "\n", "self", ".", "parsed_data_desc", "=", "self", ".", "data_desc", ".", "split", "(", "'-'", ")", "\n", "self", ".", "data_source", "=", "self", ".", "parsed_data_desc", "[", "0", "]", "\n", "if", "self", ".", "data_source", ".", "startswith", "(", "'HDF5'", ")", ":", "\n", "      ", "self", ".", "D", "=", "MetaHDFDataset", "(", "\n", "mtrain", "=", "self", ".", "meta_split", "[", "0", "]", ",", "mval", "=", "self", ".", "meta_split", "[", "1", "]", ",", "\n", "mtest", "=", "self", ".", "meta_split", "[", "2", "]", ",", "\n", "train", "=", "self", ".", "data_split", "[", "0", "]", ",", "val", "=", "self", ".", "data_split", "[", "1", "]", ",", "\n", "test", "=", "self", ".", "data_split", "[", "2", "]", ",", "\n", "filename", "=", "self", ".", "data_source", ".", "split", "(", "'@'", ")", "[", "1", "]", ",", "\n", "limit_data", "=", "self", ".", "limit_data", ",", "\n", "max_datasets", "=", "self", ".", "max_datasets", ",", "\n", "split_by_file", "=", "self", ".", "split_by_file", ",", "\n", "smaller_MVals", "=", "self", ".", "smaller_MVals", ",", "\n", "normalize", "=", "self", ".", "normalize_data", ")", "\n", "self", ".", "function_depth", "=", "2", "\n", "", "elif", "self", ".", "data_source", ".", "startswith", "(", "'NPY_SR'", ")", ":", "\n", "      ", "self", ".", "D", "=", "MetaNpySelfRegressDataset", "(", "\n", "mtrain", "=", "self", ".", "meta_split", "[", "0", "]", ",", "mval", "=", "self", ".", "meta_split", "[", "1", "]", ",", "\n", "mtest", "=", "self", ".", "meta_split", "[", "2", "]", ",", "\n", "train", "=", "self", ".", "data_split", "[", "0", "]", ",", "val", "=", "self", ".", "data_split", "[", "1", "]", ",", "\n", "test", "=", "self", ".", "data_split", "[", "2", "]", ",", "\n", "filename", "=", "self", ".", "data_source", ".", "split", "(", "'@'", ")", "[", "1", "]", ",", "\n", "limit_data", "=", "self", ".", "limit_data", ",", "\n", "max_datasets", "=", "self", ".", "max_datasets", ",", "\n", "split_by_file", "=", "self", ".", "split_by_file", ",", "\n", "smaller_MVals", "=", "self", ".", "smaller_MVals", ",", "\n", "normalize", "=", "self", ".", "normalize_data", ")", "\n", "", "else", ":", "assert", "False", ",", "self", ".", "data_source", "+", "' hasnt been implemented yet'", "\n", "self", ".", "D_mtrain", "=", "len", "(", "self", ".", "D", ".", "MTRAIN", ")", "\n", "self", ".", "D_mval", "=", "len", "(", "self", ".", "D", ".", "MVAL", ")", "\n", "self", ".", "D_mtest", "=", "len", "(", "self", ".", "D", ".", "MTEST", ")", "\n", "# Convert to pytorch tensors", "\n", "self", ".", "T", "=", "copy", ".", "deepcopy", "(", "self", ".", "D", ")", "\n", "for", "i", ",", "dataset", "in", "enumerate", "(", "self", ".", "T", ".", "ALL", ")", ":", "\n", "      ", "self", ".", "T", ".", "ALL", "[", "i", "]", ".", "TrainInput", "=", "(", "\n", "torch", ".", "from_numpy", "(", "dataset", ".", "TrainInput", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "nn_device", ")", ")", "\n", "self", ".", "T", ".", "ALL", "[", "i", "]", ".", "TrainOutput", "=", "(", "\n", "torch", ".", "from_numpy", "(", "dataset", ".", "TrainOutput", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "nn_device", ")", ")", "\n", "self", ".", "T", ".", "ALL", "[", "i", "]", ".", "ValInput", "=", "(", "\n", "torch", ".", "from_numpy", "(", "dataset", ".", "ValInput", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "nn_device", ")", ")", "\n", "self", ".", "T", ".", "ALL", "[", "i", "]", ".", "ValOutput", "=", "(", "\n", "torch", ".", "from_numpy", "(", "dataset", ".", "ValOutput", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "nn_device", ")", ")", "\n", "self", ".", "T", ".", "ALL", "[", "i", "]", ".", "TestInput", "=", "(", "\n", "torch", ".", "from_numpy", "(", "dataset", ".", "TestInput", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "nn_device", ")", ")", "\n", "self", ".", "T", ".", "ALL", "[", "i", "]", ".", "TestOutput", "=", "(", "\n", "torch", ".", "from_numpy", "(", "dataset", ".", "TestOutput", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "nn_device", ")", ")", "\n", "\n", "# Create running answers  = search ensembles", "\n", "# They weren't used in the paper, but may be in the future,", "\n", "# as ensembles generally perform better than any single structure.", "\n", "", "self", ".", "answers_running_score", "=", "1e-5", "\n", "self", ".", "ans_eps", "=", "1e-1", "#3e-2", "\n", "self", ".", "MTrainAnswers", "=", "[", "[", "None", ",", "None", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "mtrain_copies", "*", "len", "(", "self", ".", "T", ".", "MTRAIN", ")", ")", "]", "\n", "self", ".", "MValAnswers", "=", "[", "[", "None", ",", "None", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "mtrain_copies", "*", "len", "(", "self", ".", "T", ".", "MTRAIN", ")", ")", "]", "\n", "self", ".", "MTestAnswers", "=", "[", "[", "None", ",", "None", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "mtrain_copies", "*", "len", "(", "self", ".", "T", ".", "MTRAIN", ")", ")", "]", "\n", "self", ".", "OldMTrainAnswers", "=", "[", "[", "None", ",", "None", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "mtrain_copies", "*", "len", "(", "self", ".", "T", ".", "MTRAIN", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.run_MAML": [[258, 277], ["modular_metalearning.BounceGrad.S.composer_class", "modular_metalearning.BounceGrad.S.composer_class", "maml_inner_loop.InnerLoop", "modular_metalearning.BounceGrad.slow_net.cuda", "modular_metalearning.BounceGrad.fast_net.copy_weights", "modular_metalearning.BounceGrad.fast_net.forward"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.copy_weights", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.forward"], ["", "def", "run_MAML", "(", "self", ",", "structure", ",", "dataset", ")", ":", "\n", "    ", "'''\n    Run MAML of structure 'structure' on 'dataset'.\n\n    Code inspired by a single iteration of:\n    https://github.com/katerakelly/pytorch-maml/blob/master/src/maml.py#L149\n    '''", "\n", "self", ".", "slow_net", "=", "self", ".", "S", ".", "composer_class", "(", "composer", "=", "self", ".", "composer", ",", "\n", "module_list", "=", "self", ".", "L", ",", "loss_fn", "=", "None", ",", "structure", "=", "structure", ")", "\n", "baseComposer", "=", "self", ".", "S", ".", "composer_class", "(", "composer", "=", "self", ".", "composer", ",", "\n", "module_list", "=", "self", ".", "L", ",", "loss_fn", "=", "None", ",", "structure", "=", "structure", ")", "\n", "self", ".", "fast_net", "=", "InnerLoop", "(", "baseComposer", "=", "baseComposer", ",", "module_list", "=", "self", ".", "L", ",", "\n", "loss_fn", "=", "self", ".", "MAML_loss_fn", ",", "num_updates", "=", "self", ".", "MAML_inner_updates", ",", "\n", "step_size", "=", "self", ".", "MAML_step_size", ")", "\n", "self", ".", "slow_net", ".", "cuda", "(", ")", "\n", "self", ".", "fast_net", ".", "copy_weights", "(", "self", ".", "slow_net", ")", "\n", "metrics", ",", "g", "=", "self", ".", "fast_net", ".", "forward", "(", "dataset", ")", "\n", "(", "train_loss", ",", "val_loss", ",", "train_ans", ",", "val_ans", ")", "=", "metrics", "\n", "return", "train_loss", ",", "val_loss", ",", "train_ans", ",", "val_ans", ",", "g", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.run_model": [[278, 286], ["len", "inp.unsqueeze.unsqueeze.unsqueeze", "modular_metalearning.BounceGrad.S.composer_class", "len"], "methods", ["None"], ["", "def", "run_model", "(", "self", ",", "structure", ",", "inp", ",", "instructions", "=", "{", "}", ")", ":", "\n", "    ", "'''\n    Returns the composition of several modules\n    '''", "\n", "if", "len", "(", "inp", ".", "shape", ")", "==", "0", "or", "inp", ".", "shape", "[", "0", "]", "==", "0", ":", "return", "inp", "#empty tensor", "\n", "if", "len", "(", "inp", ".", "shape", ")", "==", "1", ":", "inp", "=", "inp", ".", "unsqueeze", "(", "1", ")", "\n", "return", "self", ".", "S", ".", "composer_class", "(", "composer", "=", "self", ".", "composer", ",", "\n", "module_list", "=", "self", ".", "L", ",", "structure", "=", "structure", ",", "instructions", "=", "instructions", ")", "(", "inp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.evaluate": [[287, 297], ["modular_metalearning.BounceGrad.run_model", "torch.mse_loss", "torch.mse_loss", "len", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.run_model"], ["", "def", "evaluate", "(", "self", ",", "structure", ",", "dataset", ",", "mode", ")", ":", "\n", "    ", "'''\n    Evaluates the dataset according to the structure\n    '''", "\n", "inp", "=", "dataset", ".", "TrainInput", "if", "mode", "==", "'Train'", "else", "dataset", ".", "ValInput", "\n", "out", "=", "(", "dataset", ".", "TrainOutput", "if", "mode", "==", "'Train'", "else", "dataset", ".", "ValOutput", ")", "\n", "if", "len", "(", "inp", ".", "shape", ")", "==", "0", "or", "inp", ".", "shape", "[", "0", "]", "==", "0", ":", "#empty tensors", "\n", "      ", "return", "torch", ".", "FloatTensor", "(", "np", ".", "array", "(", "[", "0", "]", ")", ")", ",", "out", "\n", "", "pred", "=", "self", ".", "run_model", "(", "structure", ",", "inp", ")", "\n", "return", "F", ".", "mse_loss", "(", "pred", ",", "out", ")", ",", "pred", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.evaluate_several_structures": [[298, 311], ["numpy.random.choice", "modular_metalearning.BounceGrad.evaluate", "original_train.data.cpu().numpy", "len", "len", "original_train.data.cpu"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.evaluate"], ["", "def", "evaluate_several_structures", "(", "self", ",", "num", ",", "keep_last", "=", "False", ",", "mode", "=", "'Train'", ")", ":", "\n", "    ", "'''\n    Returns the mean loss for several random datasets\n    keep_last: evaluate same datasets as last time\n    '''", "\n", "if", "not", "keep_last", ":", "\n", "      ", "self", ".", "several_ds_to_eval", "=", "np", ".", "random", ".", "choice", "(", "num", ",", "size", "=", "len", "(", "self", ".", "T", ".", "MTRAIN", ")", ")", "\n", "", "res", "=", "0.", "\n", "for", "i", "in", "self", ".", "several_ds_to_eval", ":", "\n", "      ", "original_train", ",", "original_train_ans", "=", "self", ".", "evaluate", "(", "\n", "self", ".", "S", ".", "TrainStructures", "[", "i", "]", ",", "self", ".", "T", ".", "MTRAIN", "[", "i", "]", ",", "mode", ")", "\n", "res", "+=", "original_train", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "return", "res", "/", "len", "(", "self", ".", "several_ds_to_eval", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.bounce": [[312, 382], ["copy.deepcopy", "modular_metalearning.BounceGrad.S.propose_new_structure", "modular_metalearning.BounceGrad.run_MAML", "original_train.data.cpu().numpy", "modular_metalearning.BounceGrad.evaluate", "original_train.data.cpu().numpy", "min", "numpy.exp", "modular_metalearning.BounceGrad.run_MAML", "new_train.data.cpu().numpy", "modular_metalearning.BounceGrad.evaluate", "new_train.data.cpu().numpy", "modular_metalearning.BounceGrad.S.update_structure", "modular_metalearning.BounceGrad.evaluate", "new_train_ans.data.cpu().numpy", "new_val_ans.data.cpu().numpy", "modular_metalearning.BounceGrad.S.update_structure", "modular_metalearning.BounceGrad.evaluate", "original_train_ans.data.cpu().numpy", "original_val_ans.data.cpu().numpy", "original_train.data.cpu", "original_train.data.cpu", "numpy.random.rand", "new_train.backward", "new_val.backward", "original_train.backward", "original_val.backward", "new_train.data.cpu", "new_train.data.cpu", "new_train_ans.data.cpu", "new_val_ans.data.cpu", "original_train_ans.data.cpu", "original_val_ans.data.cpu"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.propose_new_structure", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.run_MAML", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.evaluate", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.run_MAML", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.evaluate", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.update_structure", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.evaluate", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.update_structure", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.evaluate"], ["", "def", "bounce", "(", "self", ",", "structure", ",", "dataset", ",", "temp", ",", "do_grad", ")", ":", "\n", "    ", "'''\n    Propose a modification to structure\n    Do a SA step depending on performance in Train\n    Backpropagate on Val\n    '''", "\n", "if", "self", ".", "do_bounce", ":", "\n", "      ", "new_structure", "=", "copy", ".", "deepcopy", "(", "structure", ")", "\n", "self", ".", "S", ".", "propose_new_structure", "(", "new_structure", ")", "\n", "##################################", "\n", "# Simulated Annealing comparison #", "\n", "##################################", "\n", "", "if", "self", ".", "MAML", ":", "\n", "      ", "(", "original_train", ",", "original_val", ",", "\n", "original_train_ans", ",", "original_val_ans", ",", "original_gradient", ")", "=", "(", "\n", "self", ".", "run_MAML", "(", "structure", ",", "dataset", ")", ")", "\n", "original_train_np", "=", "original_train", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "self", ".", "do_bounce", ":", "\n", "        ", "new_train", ",", "new_val", ",", "new_train_ans", ",", "new_val_ans", ",", "new_gradient", "=", "(", "\n", "self", ".", "run_MAML", "(", "new_structure", ",", "dataset", ")", ")", "\n", "new_train_np", "=", "new_train", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", "else", ":", "\n", "      ", "MAML_g", "=", "None", "\n", "original_train", ",", "original_train_ans", "=", "self", ".", "evaluate", "(", "structure", ",", "\n", "dataset", ",", "'Train'", ")", "\n", "original_train_np", "=", "original_train", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "self", ".", "do_bounce", ":", "\n", "        ", "new_train", ",", "new_train_ans", "=", "self", ".", "evaluate", "(", "new_structure", ",", "dataset", ",", "\n", "'Train'", ")", "\n", "new_train_np", "=", "new_train", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "", "if", "self", ".", "do_bounce", ":", "\n", "      ", "upt_factor", "=", "min", "(", "0.01", ",", "self", ".", "SA_running_acc_rate", "/", "self", ".", "SA_running_factor", ")", "\n", "prob_accept", "=", "np", ".", "exp", "(", "(", "original_train_np", "-", "new_train_np", ")", "/", "temp", ")", "\n", "", "if", "(", "self", ".", "do_bounce", "and", "(", "#Accept", "\n", "new_train_np", "<=", "original_train_np", "or", "np", ".", "random", ".", "rand", "(", ")", "<", "prob_accept", ")", ")", ":", "\n", "      ", "if", "original_train_np", "<", "new_train_np", ":", "#update running frac of worse accepts", "\n", "        ", "self", ".", "SA_running_factor", "=", "(", "(", "1", "-", "upt_factor", ")", "*", "self", ".", "SA_running_factor", "+", "\n", "upt_factor", ")", "\n", "self", ".", "SA_running_acc_rate", "=", "(", "(", "1", "-", "upt_factor", ")", "*", "self", ".", "SA_running_acc_rate", "+", "\n", "upt_factor", ")", "\n", "", "if", "self", ".", "MAML", ":", "MAML_g", "=", "new_gradient", "\n", "else", ":", "\n", "        ", "if", "self", ".", "LocalOpt", "is", "not", "None", ":", "new_train", ".", "backward", "(", ")", "\n", "# structure['node_positions'].requires_grad = False", "\n", "self", ".", "S", ".", "update_structure", "(", "structure", ")", "\n", "new_val", ",", "new_val_ans", "=", "self", ".", "evaluate", "(", "new_structure", ",", "dataset", ",", "'Val'", ")", "\n", "if", "do_grad", ":", "new_val", ".", "backward", "(", ")", "\n", "# structure['node_positions'].requires_grad = True", "\n", "", "return", "(", "new_structure", ",", "new_train", ",", "new_val", ",", "\n", "new_train_ans", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "new_val_ans", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "MAML_g", ")", "\n", "", "else", ":", "#Reject", "\n", "      ", "if", "self", ".", "do_bounce", "and", "original_train_np", "<", "new_train_np", ":", "\n", "#update running frac of worse accepts", "\n", "        ", "self", ".", "SA_running_factor", "=", "(", "(", "1", "-", "upt_factor", ")", "*", "self", ".", "SA_running_factor", "+", "\n", "upt_factor", ")", "\n", "self", ".", "SA_running_acc_rate", "=", "(", "1", "-", "upt_factor", ")", "*", "self", ".", "SA_running_acc_rate", "\n", "", "if", "self", ".", "MAML", ":", "MAML_g", "=", "original_gradient", "\n", "else", ":", "\n", "        ", "if", "self", ".", "LocalOpt", "is", "not", "None", ":", "original_train", ".", "backward", "(", ")", "\n", "# structure['node_positions'].requires_grad = False", "\n", "self", ".", "S", ".", "update_structure", "(", "structure", ")", "\n", "original_val", ",", "original_val_ans", "=", "self", ".", "evaluate", "(", "structure", ",", "dataset", ",", "\n", "'Val'", ")", "\n", "if", "do_grad", ":", "original_val", ".", "backward", "(", ")", "\n", "# structure['node_positions'].requires_grad = True", "\n", "", "return", "(", "structure", ",", "original_train", ",", "original_val", ",", "\n", "original_train_ans", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "original_val_ans", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "MAML_g", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.SAConfig_SGDModules": [[386, 582], ["numpy.exp", "torch.nn.CosineSimilarity", "torch.nn.CosineSimilarity", "modular_metalearning.BounceGrad.S.initialize_all_structures", "len", "tqdm.tqdm.tqdm", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.ReduceLROnPlateau", "torch.optim.lr_scheduler.ReduceLROnPlateau", "modular_metalearning.BounceGrad.load_strmet", "range", "modular_metalearning.BounceGrad.S.update_PosUsage_counters", "modular_metalearning.BounceGrad.S.update_Usage_counters", "modular_metalearning.BounceGrad.S.update_customized_counters", "modular_metalearning.BounceGrad.update_Sharing_counters", "numpy.exp", "tqdm.tqdm.tqdm", "enumerate", "modular_metalearning.BounceGrad.SOpt.zero_grad", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.update_stats", "modular_metalearning.BounceGrad.S.update_customized_stats", "modular_metalearning.BounceGrad.SOpt_scheduler.step", "enumerate", "modular_metalearning.BounceGrad.S.update_structure", "modular_metalearning.BounceGrad.bounce", "modular_metalearning.BounceGrad.current_train.append", "modular_metalearning.BounceGrad.current_val.append", "modular_metalearning.BounceGrad.S.update_structure", "modular_metalearning.BounceGrad.bounce", "modular_metalearning.BounceGrad.current_Mtrain.append", "modular_metalearning.BounceGrad.current_Meval.append", "numpy.mean.item", "numpy.mean.item", "numpy.mean.item", "numpy.mean.item", "numpy.log10().item", "numpy.log10().item", "modular_metalearning.BounceGrad.log_metrics", "modular_metalearning.BounceGrad.store_simple_metrics", "modular_metalearning.BounceGrad.LocalOpt_scheduler.step", "train_loss.data.cpu().numpy", "val_loss.data.cpu().numpy", "modular_metalearning.BounceGrad.MTrain_norm_diff.append", "modular_metalearning.BounceGrad.MTrain_cos_diff.append", "maml_gradients.append", "train_loss.data.cpu().numpy", "val_loss.data.cpu().numpy", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "modular_metalearning.BounceGrad.save_L", "numpy.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "modular_metalearning.BounceGrad.L.named_parameters", "modular_metalearning.BounceGrad.SOpt.zero_grad", "modular_metalearning.BounceGrad.SOpt.step", "modular_metalearning.BounceGrad.SOpt.step", "modular_metalearning.BounceGrad.SOpt.zero_grad", "range", "range", "range", "range", "numpy.log10", "numpy.log10", "len", "train_loss.data.cpu", "val_loss.data.cpu", "numpy.linalg.norm", "torch.nn.CosineSimilarity.", "len", "G.items", "hooks.append", "module.dummy_forward_pass", "module.dummy_forward_pass.backward", "h.remove", "modular_metalearning.BounceGrad.LocalOpt.step", "modular_metalearning.BounceGrad.LocalOpt.zero_grad", "len", "train_loss.data.cpu", "val_loss.data.cpu", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "v.register_hook", "modular_metalearning.BounceGrad.T.MTRAIN[].TrainOutput.data.cpu().numpy", "modular_metalearning.BounceGrad.T.MTRAIN[].ValOutput.data.cpu().numpy", "modular_metalearning.BounceGrad.T.MVAL[].TrainOutput.data.cpu().numpy", "modular_metalearning.BounceGrad.T.MVAL[].ValOutput.data.cpu().numpy", "modular_metalearning.BounceGrad.SAConfig_SGDModules.get_closure"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.initialize_all_structures", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.load_strmet", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.update_PosUsage_counters", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.update_Usage_counters", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.update_customized_counters", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.update_Sharing_counters", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.update_stats", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.structure.Structure.update_customized_stats", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.update_structure", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.bounce", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.update_structure", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.bounce", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.log_metrics", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.store_simple_metrics", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.save_L", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.dummy_forward_pass"], ["", "", "def", "SAConfig_SGDModules", "(", "self", ",", "optimization_steps", ")", ":", "\n", "    ", "'''\n    Optimization by Simulated Annealing on the module configurations\n    and SGD (Adam in our case) on the modules at every step.\n    '''", "\n", "# Cooling schedule decreases exponentially wrt the fraction of accepted", "\n", "# proposals with worse performance, starting at 1 (accept no matter what)", "\n", "# Therefore we have to keep a running estimate of fraction of accepts.", "\n", "self", ".", "SA_running_acc_rate", "=", "1e-9", "#initial counters for Simulated Annealing", "\n", "self", ".", "SA_running_factor", "=", "1e-9", "#normalizing constant", "\n", "temp", "=", "np", ".", "exp", "(", "self", ".", "initial_temp", ")", "#temperature in the SA formula", "\n", "temp_change", "=", "1.1", "\n", "CosDist", "=", "nn", ".", "CosineSimilarity", "(", "dim", "=", "1", ")", "\n", "#############################", "\n", "# Create initial structures #", "\n", "#############################", "\n", "self", ".", "S", ".", "initialize_all_structures", "(", "T", "=", "self", ".", "T", ",", "mtrain_copies", "=", "self", ".", "mtrain_copies", ")", "\n", "if", "len", "(", "self", ".", "S", ".", "StructureParameters", ")", ":", "\n", "      ", "self", ".", "LocalOpt", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "S", ".", "StructureParameters", ",", "\n", "lr", "=", "self", ".", "meta_lr", "/", "10", ")", "\n", "self", ".", "LocalOpt_scheduler", "=", "ReduceLROnPlateau", "(", "\n", "optimizer", "=", "self", ".", "SOpt", ",", "factor", "=", "1", "/", "2.", ",", "\n", "mode", "=", "'min'", ",", "patience", "=", "20", ",", "threshold", "=", "0", ",", "cooldown", "=", "100", ",", "\n", "verbose", "=", "True", ",", "min_lr", "=", "1e-4", ")", "\n", "", "if", "self", ".", "load_structures_and_metrics", "!=", "''", ":", "\n", "      ", "self", ".", "load_strmet", "(", "self", ".", "load_structures_and_metrics", ")", "\n", "\n", "# input('Check structure: '+ str( self.S.TrainStructures[0]))", "\n", "", "for", "step", "in", "Tqdm", "(", "range", "(", "optimization_steps", ")", ")", ":", "\n", "      ", "self", ".", "step", "=", "step", "*", "self", ".", "mtrain_copies", "\n", "if", "step", ":", "\n", "        ", "self", ".", "SOpt_scheduler", ".", "step", "(", "self", ".", "mean_current_val", ")", "#MTrain-Val", "\n", "if", "self", ".", "LocalOpt", "is", "not", "None", ":", "\n", "          ", "self", ".", "LocalOpt_scheduler", ".", "step", "(", "self", ".", "mean_current_val", ")", "#MTrain-Val", "\n", "", "", "self", ".", "METRICS", "[", "'TrainStructures'", "]", "=", "self", ".", "S", ".", "TrainStructures", "\n", "self", ".", "METRICS", "[", "'ValStructures'", "]", "=", "self", ".", "S", ".", "ValStructures", "\n", "self", ".", "S", ".", "update_PosUsage_counters", "(", "METRICS", "=", "self", ".", "METRICS", ")", "\n", "self", ".", "S", ".", "update_Usage_counters", "(", "METRICS", "=", "self", ".", "METRICS", ",", "T", "=", "self", ".", "T", ")", "\n", "self", ".", "S", ".", "update_customized_counters", "(", "METRICS", "=", "self", ".", "METRICS", ")", "\n", "self", ".", "update_Sharing_counters", "(", ")", "\n", "\n", "#with default values the midpoint @0.7%, end @0.005%", "\n", "acc_rate", "=", "np", ".", "exp", "(", "self", ".", "initial_acc", "-", "5.", "*", "step", "/", "optimization_steps", ")", "\n", "if", "self", ".", "SA_running_acc_rate", "/", "self", ".", "SA_running_factor", "<", "acc_rate", ":", "\n", "        ", "temp", "*=", "temp_change", "\n", "", "else", ":", "temp", "/=", "temp_change", "\n", "\n", "self", ".", "current_train", "=", "[", "]", "\n", "self", ".", "current_val", "=", "[", "]", "\n", "self", ".", "MTrain_norm_diff", "=", "[", "]", "\n", "self", ".", "MTrain_cos_diff", "=", "[", "]", "\n", "if", "self", ".", "MAML", ":", "maml_gradients", "=", "[", "]", "\n", "for", "i", ",", "structure", "in", "Tqdm", "(", "enumerate", "(", "self", ".", "S", ".", "TrainStructures", ")", ")", ":", "\n", "        ", "dataset", "=", "self", ".", "T", ".", "MTRAIN", "[", "i", "%", "len", "(", "self", ".", "T", ".", "MTRAIN", ")", "]", "#multiple structures per dataset", "\n", "#Update structure", "\n", "self", ".", "S", ".", "update_structure", "(", "self", ".", "S", ".", "TrainStructures", "[", "i", "]", ",", "step", "=", "self", ".", "step", ")", "\n", "#######################", "\n", "# Simulated Annealing #", "\n", "#######################", "\n", "(", "self", ".", "S", ".", "TrainStructures", "[", "i", "]", ",", "train_loss", ",", "val_loss", ",", "train_ans", ",", "val_ans", ",", "\n", "MAML_g", ")", "=", "self", ".", "bounce", "(", "structure", ",", "dataset", ",", "temp", ",", "do_grad", "=", "True", ")", "\n", "self", ".", "current_train", ".", "append", "(", "train_loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "self", ".", "current_val", ".", "append", "(", "val_loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "if", "self", ".", "MTrainAnswers", "[", "i", "]", "[", "0", "]", "is", "None", ":", "\n", "          ", "self", ".", "MTrainAnswers", "[", "i", "]", "[", "0", "]", "=", "train_ans", "*", "self", ".", "ans_eps", "\n", "", "else", ":", "self", ".", "MTrainAnswers", "[", "i", "]", "[", "0", "]", "=", "(", "\n", "(", "1", "-", "self", ".", "ans_eps", ")", "*", "self", ".", "MTrainAnswers", "[", "i", "]", "[", "0", "]", "+", "\n", "train_ans", "*", "self", ".", "ans_eps", ")", "\n", "if", "self", ".", "MTrainAnswers", "[", "i", "]", "[", "1", "]", "is", "None", ":", "\n", "          ", "self", ".", "MTrainAnswers", "[", "i", "]", "[", "1", "]", "=", "val_ans", "*", "self", ".", "ans_eps", "\n", "", "else", ":", "\n", "          ", "self", ".", "MTrainAnswers", "[", "i", "]", "[", "1", "]", "=", "(", "(", "1", "-", "self", ".", "ans_eps", ")", "\n", "*", "self", ".", "MTrainAnswers", "[", "i", "]", "[", "1", "]", "+", "val_ans", "*", "self", ".", "ans_eps", ")", "\n", "", "if", "self", ".", "OldMTrainAnswers", "[", "i", "]", "[", "0", "]", "is", "not", "None", ":", "\n", "          ", "self", ".", "MTrain_norm_diff", ".", "append", "(", "\n", "np", ".", "mean", "(", "np", ".", "linalg", ".", "norm", "(", "\n", "self", ".", "OldMTrainAnswers", "[", "i", "]", "[", "0", "]", "-", "train_ans", ",", "axis", "=", "1", ")", ")", ")", "\n", "self", ".", "MTrain_cos_diff", ".", "append", "(", "\n", "torch", ".", "mean", "(", "CosDist", "(", "torch", ".", "FloatTensor", "(", "\n", "self", ".", "OldMTrainAnswers", "[", "i", "]", "[", "0", "]", "-", "\n", "dataset", ".", "TrainOutput", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "torch", ".", "FloatTensor", "(", "\n", "train_ans", "-", "dataset", ".", "TrainOutput", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", ")", ")", "\n", "", "self", ".", "OldMTrainAnswers", "[", "i", "]", "[", "0", "]", "=", "train_ans", "\n", "\n", "####################", "\n", "# Gradient Descent #", "\n", "####################", "\n", "if", "self", ".", "MAML", ":", "maml_gradients", ".", "append", "(", "MAML_g", ")", "\n", "if", "(", "i", "==", "len", "(", "self", ".", "S", ".", "TrainStructures", ")", "-", "1", "or", "(", "self", ".", "execute_gd_every", ">", "0", "and", "\n", "i", "%", "self", ".", "execute_gd_every", "==", "self", ".", "execute_gd_every", "-", "1", ")", ")", ":", "\n", "          ", "if", "self", ".", "MAML", ":", "\n", "# Compute sum of maml_gradients to each module", "\n", "# Inspired by:", "\n", "# github.com/katerakelly/pytorch-maml/blob/master/src/maml.py#L66", "\n", "# but multiple changes because they have a single structure", "\n", "            ", "self", ".", "dict_gradients", "=", "{", "}", "\n", "for", "G", "in", "maml_gradients", ":", "\n", "              ", "for", "(", "key", ",", "value", ")", "in", "G", ".", "items", "(", ")", ":", "\n", "                ", "if", "value", "is", "None", ":", "continue", "\n", "name", "=", "'.'", ".", "join", "(", "key", ".", "split", "(", "'.'", ")", "[", "1", ":", "]", ")", "\n", "if", "name", "not", "in", "self", ".", "dict_gradients", ":", "\n", "                  ", "self", ".", "dict_gradients", "[", "name", "]", "=", "value", "\n", "", "else", ":", "self", ".", "dict_gradients", "[", "name", "]", "+=", "value", "\n", "\n", "", "", "hooks", "=", "[", "]", "\n", "for", "(", "k", ",", "v", ")", "in", "self", ".", "L", ".", "named_parameters", "(", ")", ":", "\n", "              ", "def", "get_closure", "(", ")", ":", "\n", "                ", "key", "=", "k", "\n", "value", "=", "v", "\n", "def", "replace_grad", "(", "grad", ")", ":", "\n", "                  ", "if", "key", "in", "self", ".", "dict_gradients", ":", "\n", "                    ", "return", "self", ".", "dict_gradients", "[", "key", "]", "\n", "", "else", ":", "return", "torch", ".", "zeros_like", "(", "value", ")", "\n", "", "return", "replace_grad", "\n", "", "hooks", ".", "append", "(", "v", ".", "register_hook", "(", "get_closure", "(", ")", ")", ")", "\n", "", "self", ".", "SOpt", ".", "zero_grad", "(", ")", "\n", "for", "module", "in", "self", ".", "L", ":", "\n", "              ", "dummy_loss", "=", "module", ".", "dummy_forward_pass", "(", ")", "\n", "dummy_loss", ".", "backward", "(", ")", "\n", "", "self", ".", "SOpt", ".", "step", "(", ")", "\n", "for", "h", "in", "hooks", ":", "h", ".", "remove", "(", ")", "\n", "\n", "maml_gradients", "=", "[", "]", "\n", "", "else", ":", "#No MAML --> use regular loss", "\n", "            ", "self", ".", "SOpt", ".", "step", "(", ")", "\n", "self", ".", "SOpt", ".", "zero_grad", "(", ")", "\n", "if", "self", ".", "LocalOpt", "is", "not", "None", ":", "\n", "              ", "self", ".", "LocalOpt", ".", "step", "(", ")", "\n", "self", ".", "LocalOpt", ".", "zero_grad", "(", ")", "\n", "\n", "#Simulated Annealing on MetaValidation data", "\n", "", "", "", "", "self", ".", "current_Mtrain", "=", "[", "]", "\n", "self", ".", "current_Meval", "=", "[", "]", "\n", "for", "i", ",", "structure", "in", "enumerate", "(", "self", ".", "S", ".", "ValStructures", ")", ":", "\n", "        ", "dataset", "=", "self", ".", "T", ".", "MVAL", "[", "i", "%", "len", "(", "self", ".", "T", ".", "MVAL", ")", "]", "\n", "#Update structure", "\n", "self", ".", "S", ".", "update_structure", "(", "self", ".", "S", ".", "ValStructures", "[", "i", "]", ",", "step", "=", "self", ".", "step", ")", "\n", "(", "self", ".", "S", ".", "ValStructures", "[", "i", "]", ",", "train_loss", ",", "val_loss", ",", "\n", "train_ans", ",", "val_ans", ",", "MAML_g", ")", "=", "(", "\n", "self", ".", "bounce", "(", "structure", ",", "dataset", ",", "temp", ",", "do_grad", "=", "False", ")", ")", "\n", "self", ".", "current_Mtrain", ".", "append", "(", "train_loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "self", ".", "current_Meval", ".", "append", "(", "val_loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "if", "self", ".", "MValAnswers", "[", "i", "]", "[", "0", "]", "is", "None", ":", "\n", "          ", "self", ".", "MValAnswers", "[", "i", "]", "[", "0", "]", "=", "train_ans", "*", "self", ".", "ans_eps", "\n", "", "else", ":", "\n", "          ", "self", ".", "MValAnswers", "[", "i", "]", "[", "0", "]", "=", "(", "\n", "(", "1", "-", "self", ".", "ans_eps", ")", "*", "self", ".", "MValAnswers", "[", "i", "]", "[", "0", "]", "+", "train_ans", "*", "self", ".", "ans_eps", ")", "\n", "", "if", "self", ".", "MValAnswers", "[", "i", "]", "[", "1", "]", "is", "None", ":", "\n", "          ", "self", ".", "MValAnswers", "[", "i", "]", "[", "1", "]", "=", "val_ans", "*", "self", ".", "ans_eps", "\n", "", "else", ":", "\n", "          ", "self", ".", "MValAnswers", "[", "i", "]", "[", "1", "]", "=", "(", "(", "1", "-", "self", ".", "ans_eps", ")", "*", "self", ".", "MValAnswers", "[", "i", "]", "[", "1", "]", "+", "\n", "val_ans", "*", "self", ".", "ans_eps", ")", "\n", "#Zero-out optimizers (step in MTRAIN performed + dont want step from MVAL)", "\n", "", "", "self", ".", "SOpt", ".", "zero_grad", "(", ")", "\n", "###################", "\n", "# Stats and plots #", "\n", "###################", "\n", "self", ".", "answers_running_score", "=", "(", "self", ".", "answers_running_score", "*", "\n", "(", "1.", "-", "self", ".", "ans_eps", ")", "+", "self", ".", "ans_eps", ")", "\n", "ensemble_train", "=", "np", ".", "mean", "(", "[", "np", ".", "mean", "(", "\n", "(", "self", ".", "MTrainAnswers", "[", "i", "]", "[", "0", "]", "/", "self", ".", "answers_running_score", "\n", "-", "self", ".", "T", ".", "MTRAIN", "[", "i", "]", ".", "TrainOutput", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "**", "2", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "T", ".", "mtrain", ")", "]", ")", "\n", "ensemble_val", "=", "np", ".", "mean", "(", "[", "np", ".", "mean", "(", "\n", "(", "self", ".", "MTrainAnswers", "[", "i", "]", "[", "1", "]", "/", "self", ".", "answers_running_score", "\n", "-", "self", ".", "T", ".", "MTRAIN", "[", "i", "]", ".", "ValOutput", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "**", "2", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "T", ".", "mtrain", ")", "]", ")", "\n", "ensemble_Mtrain", "=", "np", ".", "mean", "(", "[", "np", ".", "mean", "(", "\n", "(", "self", ".", "MValAnswers", "[", "i", "]", "[", "0", "]", "/", "self", ".", "answers_running_score", "\n", "-", "self", ".", "T", ".", "MVAL", "[", "i", "]", ".", "TrainOutput", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "**", "2", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "T", ".", "mval", ")", "]", ")", "\n", "ensemble_Mval", "=", "np", ".", "mean", "(", "[", "np", ".", "mean", "(", "\n", "(", "self", ".", "MValAnswers", "[", "i", "]", "[", "1", "]", "/", "self", ".", "answers_running_score", "\n", "-", "self", ".", "T", ".", "MVAL", "[", "i", "]", ".", "ValOutput", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "**", "2", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "T", ".", "mval", ")", "]", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'ensemble/train'", ",", "ensemble_train", ".", "item", "(", ")", ",", "\n", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'ensemble/val'", ",", "ensemble_val", ".", "item", "(", ")", ",", "\n", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'ensemble/Mtrain'", ",", "ensemble_Mtrain", ".", "item", "(", ")", ",", "\n", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'ensemble/Mval'", ",", "ensemble_Mval", ".", "item", "(", ")", ",", "\n", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'SA/temp'", ",", "np", ".", "log10", "(", "temp", ")", ".", "item", "(", ")", ",", "\n", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'SA/acc_rate'", ",", "\n", "np", ".", "log10", "(", "self", ".", "SA_running_acc_rate", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "update_stats", "(", ")", "\n", "self", ".", "S", ".", "update_customized_stats", "(", "self", ")", "\n", "if", "step", "%", "self", ".", "plot_freq", "==", "0", "or", "step", "==", "self", ".", "optimization_steps", "-", "1", ":", "\n", "#plot & store metrics to JSON", "\n", "        ", "self", ".", "log_metrics", "(", ")", "\n", "self", ".", "store_simple_metrics", "(", ")", "\n", "# self.store_metrics()", "\n", "if", "self", ".", "save_modules", "!=", "''", ":", "self", ".", "save_L", "(", "self", ".", "save_modules", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.save_L": [[586, 593], ["enumerate", "torch.save", "torch.save", "torch.save", "torch.save", "module.state_dict", "str"], "methods", ["None"], ["", "", "", "def", "save_L", "(", "self", ",", "filepath", "=", "None", ")", ":", "\n", "    ", "'''\n    Saves ModuleList\n    '''", "\n", "if", "filepath", "is", "None", ":", "filepath", "=", "'moduleList-'", "\n", "for", "i_m", ",", "module", "in", "enumerate", "(", "self", ".", "L", ")", ":", "\n", "      ", "torch", ".", "save", "(", "module", ".", "state_dict", "(", ")", ",", "filepath", "+", "str", "(", "i_m", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.load_L": [[594, 601], ["enumerate", "modular_metalearning.BounceGrad.L[].load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "str"], "methods", ["None"], ["", "", "def", "load_L", "(", "self", ",", "filepath", "=", "None", ")", ":", "\n", "    ", "'''\n    Loads ModuleList\n    '''", "\n", "if", "filepath", "is", "None", ":", "filepath", "=", "'moduleList-'", "\n", "for", "i_m", ",", "module", "in", "enumerate", "(", "self", ".", "L", ")", ":", "\n", "      ", "self", ".", "L", "[", "i_m", "]", ".", "load_state_dict", "(", "torch", ".", "load", "(", "filepath", "+", "str", "(", "i_m", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.load_strmet": [[602, 613], ["os.path.isdir", "os.path.join", "open", "json.load"], "methods", ["None"], ["", "", "def", "load_strmet", "(", "self", ",", "filepath", "=", "None", ")", ":", "\n", "    ", "'''\n    Loads structures and metrics\n    '''", "\n", "if", "filepath", "is", "None", ":", "filepath", "=", "'metrics/'", "\n", "if", "os", ".", "path", ".", "isdir", "(", "filepath", ")", ":", "\n", "      ", "filepath", "=", "os", ".", "path", ".", "join", "(", "filepath", ",", "'metrics.json'", ")", "\n", "", "with", "open", "(", "filepath", ",", "'r'", ")", "as", "infile", ":", "\n", "      ", "self", ".", "METRICS", "=", "json", ".", "load", "(", "infile", ")", "\n", "", "self", ".", "S", ".", "TrainStructures", "=", "self", ".", "METRICS", "[", "'TrainStructures'", "]", "\n", "self", ".", "S", ".", "ValStructures", "=", "self", ".", "METRICS", "[", "'ValStructures'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.update_stats": [[614, 666], ["modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "numpy.mean().item", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "len", "len", "len", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "numpy.mean().item", "numpy.std().item", "numpy.std().item", "numpy.min().item", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "numpy.percentile().item", "numpy.percentile().item", "numpy.percentile().item", "numpy.percentile().item", "m.parameters", "zip", "numpy.mean", "numpy.mean().item", "numpy.std().item", "numpy.min().item", "numpy.mean().item", "numpy.std().item", "numpy.min().item", "numpy.mean().item", "numpy.std().item", "numpy.min().item", "numpy.mean", "numpy.std", "numpy.std", "numpy.min", "numpy.percentile", "numpy.percentile", "numpy.percentile", "numpy.percentile", "numpy.mean", "numpy.std", "numpy.min", "numpy.mean", "numpy.std", "numpy.min", "numpy.mean", "numpy.std", "numpy.min"], "methods", ["None"], ["", "def", "update_stats", "(", "self", ")", ":", "\n", "    ", "'''\n    Updates several metrics after each step\n    '''", "\n", "#Differences between timesteps", "\n", "if", "self", ".", "MTrain_norm_diff", "!=", "[", "]", ":", "\n", "      ", "self", ".", "writer", ".", "add_scalar", "(", "'norm_diff/perc_10'", ",", "\n", "np", ".", "percentile", "(", "self", ".", "MTrain_norm_diff", ",", "10", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'norm_diff/perc_90'", ",", "\n", "np", ".", "percentile", "(", "self", ".", "MTrain_norm_diff", ",", "90", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'norm_diff/perc_10'", ",", "\n", "np", ".", "percentile", "(", "self", ".", "MTrain_cos_diff", ",", "10", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'norm_diff/perc_90'", ",", "\n", "np", ".", "percentile", "(", "self", ".", "MTrain_cos_diff", ",", "90", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "\n", "#Weight norms", "\n", "", "self", ".", "act_norms", "=", "[", "torch", ".", "norm", "(", "_", ")", "for", "m", "in", "self", ".", "L", "for", "_", "in", "m", ".", "parameters", "(", ")", "]", "\n", "self", ".", "norm_ratios", "=", "[", "(", "a", "/", "b", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "for", "(", "a", ",", "b", ")", "in", "zip", "(", "\n", "self", ".", "act_norms", ",", "self", ".", "initial_norms", ")", "]", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'norm_ratios/mean'", ",", "\n", "np", ".", "mean", "(", "self", ".", "norm_ratios", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'norm_ratios/std'", ",", "\n", "np", ".", "std", "(", "self", ".", "norm_ratios", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "#Error metrics", "\n", "self", ".", "mean_current_val", "=", "np", ".", "mean", "(", "self", ".", "current_val", ")", ".", "item", "(", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'mean_loss/T_val'", ",", "self", ".", "mean_current_val", ",", "\n", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'std_loss/T_val'", ",", "\n", "np", ".", "std", "(", "self", ".", "current_val", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'min_loss/T_val'", ",", "\n", "np", ".", "min", "(", "self", ".", "current_val", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "if", "len", "(", "self", ".", "current_train", ")", ":", "\n", "      ", "self", ".", "writer", ".", "add_scalar", "(", "'mean_loss/T_train'", ",", "\n", "np", ".", "mean", "(", "self", ".", "current_train", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'std_loss/T_train'", ",", "\n", "np", ".", "std", "(", "self", ".", "current_train", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'min_loss/T_train'", ",", "\n", "np", ".", "min", "(", "self", ".", "current_train", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "", "if", "len", "(", "self", ".", "current_Mtrain", ")", ":", "\n", "      ", "self", ".", "writer", ".", "add_scalar", "(", "'mean_loss/V_train'", ",", "\n", "np", ".", "mean", "(", "self", ".", "current_Mtrain", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'std_loss/V_train'", ",", "\n", "np", ".", "std", "(", "self", ".", "current_Mtrain", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'min_loss/V_train'", ",", "\n", "np", ".", "min", "(", "self", ".", "current_Mtrain", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "", "if", "len", "(", "self", ".", "current_Meval", ")", ":", "\n", "      ", "self", ".", "writer", ".", "add_scalar", "(", "'mean_loss/V_val'", ",", "\n", "np", ".", "mean", "(", "self", ".", "current_Meval", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'std_loss/V_val'", ",", "\n", "np", ".", "std", "(", "self", ".", "current_Meval", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'min_loss/V_val'", ",", "\n", "np", ".", "min", "(", "self", ".", "current_Meval", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.is_jsonable": [[667, 672], ["json.dumps"], "methods", ["None"], ["", "", "def", "is_jsonable", "(", "self", ",", "x", ")", ":", "\n", "    ", "try", ":", "\n", "      ", "json", ".", "dumps", "(", "x", ")", "\n", "return", "True", "\n", "", "except", ":", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.store_simple_metrics": [[673, 683], ["getattr", "open", "json.dump", "dir", "modular_metalearning.BounceGrad.is_jsonable", "os.path.join", "getattr", "modular_metalearning.BounceGrad.METRICS.items", "modular_metalearning.BounceGrad.is_jsonable"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.is_jsonable", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.is_jsonable"], ["", "def", "store_simple_metrics", "(", "self", ")", ":", "\n", "    ", "'''\n    Stores all metrics that can be JSON-ed to a JSON file\n    '''", "\n", "self", ".", "METRICS", "[", "'params'", "]", "=", "{", "attr", ":", "getattr", "(", "self", ",", "attr", ")", "for", "attr", "in", "\n", "dir", "(", "self", ")", "if", "self", ".", "is_jsonable", "(", "getattr", "(", "self", ",", "attr", ")", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "plot_name", ",", "\n", "'metrics.json'", ")", ",", "'w'", ")", "as", "outfile", ":", "\n", "      ", "json", ".", "dump", "(", "{", "k", ":", "v", "for", "k", ",", "v", "in", "self", ".", "METRICS", ".", "items", "(", ")", "\n", "if", "self", ".", "is_jsonable", "(", "v", ")", "}", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.store_metrics": [[684, 704], ["int", "time.time", "getattr", "open", "json.dump", "open", "json.dump", "dir", "type", "len", "getattr", "type", "type", "type", "type", "type", "type", "getattr", "type", "len", "callable", "attr.startswith", "getattr", "type", "type", "type", "type", "type", "type", "getattr", "type", "getattr", "getattr", "getattr", "type", "type", "type", "type", "getattr", "list", "getattr().keys", "getattr"], "methods", ["None"], ["", "", "def", "store_metrics", "(", "self", ")", ":", "\n", "    ", "'''\n    Stores all the metrics to a JSON file\n    '''", "\n", "self", ".", "METRICS", "[", "'time'", "]", "=", "int", "(", "time", ".", "time", "(", ")", ")", "\n", "self", ".", "METRICS", "[", "'params'", "]", "=", "{", "attr", ":", "getattr", "(", "self", ",", "attr", ")", "for", "attr", "in", "dir", "(", "self", ")", "\n", "if", "(", "type", "(", "getattr", "(", "self", ",", "attr", ")", ")", "in", "\n", "[", "type", "(", "1", ")", ",", "type", "(", "1.0", ")", ",", "type", "(", "'a'", ")", ",", "type", "(", "None", ")", "]", "\n", "or", "(", "type", "(", "getattr", "(", "self", ",", "attr", ")", ")", "==", "type", "(", "[", "]", ")", "and", "\n", "len", "(", "getattr", "(", "self", ",", "attr", ")", ")", "and", "type", "(", "getattr", "(", "self", ",", "attr", ")", "[", "0", "]", ")", "in", "\n", "[", "type", "(", "1", ")", ",", "type", "(", "1.0", ")", ",", "type", "(", "'a'", ")", ",", "type", "(", "None", ")", "]", ")", "\n", "or", "(", "type", "(", "getattr", "(", "self", ",", "attr", ")", ")", "==", "type", "(", "{", "}", ")", "and", "\n", "len", "(", "getattr", "(", "self", ",", "attr", ")", ")", "and", "\n", "type", "(", "getattr", "(", "self", ",", "attr", ")", "[", "list", "(", "getattr", "(", "self", ",", "attr", ")", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ")", "in", "\n", "[", "type", "(", "1", ")", ",", "type", "(", "1.0", ")", ",", "type", "(", "'a'", ")", ",", "type", "(", "None", ")", "]", ")", "\n", "and", "not", "callable", "(", "getattr", "(", "self", ",", "attr", ")", ")", "and", "not", "attr", ".", "startswith", "(", "'__'", ")", ")", "}", "\n", "with", "open", "(", "'metrics/'", "+", "self", ".", "plot_name", "[", ":", "-", "1", "]", "+", "'.json'", ",", "'w'", ")", "as", "outfile", ":", "\n", "      ", "json", ".", "dump", "(", "self", ".", "METRICS", ",", "outfile", ")", "\n", "", "with", "open", "(", "self", ".", "plot_name", "+", "'metrics.json'", ",", "'w'", ")", "as", "outfile", ":", "\n", "      ", "json", ".", "dump", "(", "self", ".", "METRICS", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.plot_sharing": [[705, 726], ["list", "list.sort", "matplotlib.gca().matshow", "matplotlib.gca().matshow", "matplotlib.gca().set_xticklabels", "matplotlib.gca().set_xticklabels", "matplotlib.gca().set_yticklabels", "matplotlib.gca().set_yticklabels", "matplotlib.gca().xaxis.set_major_locator", "matplotlib.gca().xaxis.set_major_locator", "matplotlib.gca().yaxis.set_major_locator", "matplotlib.gca().yaxis.set_major_locator", "matplotlib.gcf().colorbar", "matplotlib.gcf().colorbar", "matplotlib.savefig", "matplotlib.savefig", "matplotlib.clf", "matplotlib.clf", "numpy.max", "len", "enumerate", "matplotlib.MultipleLocator", "matplotlib.MultipleLocator", "matplotlib.MultipleLocator", "matplotlib.MultipleLocator", "matplotlib.savefig", "matplotlib.savefig", "os.path.join", "matplotlib.gca", "matplotlib.gca", "matplotlib.gca", "matplotlib.gca", "sorted", "matplotlib.gca", "matplotlib.gca", "sorted", "os.path.join", "matplotlib.gcf", "matplotlib.gcf", "matplotlib.gca", "matplotlib.gca", "matplotlib.gca", "matplotlib.gca", "numpy.array", "str"], "methods", ["None"], ["", "", "def", "plot_sharing", "(", "self", ")", ":", "\n", "    ", "if", "(", "self", ".", "METRICS", "[", "'Sharing'", "]", "is", "not", "None", "and", "\n", "np", ".", "max", "(", "self", ".", "METRICS", "[", "'Sharing'", "]", ")", ">", "1e-4", "and", "\n", "len", "(", "self", ".", "METRICS", "[", "'NumberToWords'", "]", ")", "<=", "50", ")", ":", "\n", "#Find ordering", "\n", "      ", "aux", "=", "list", "(", "enumerate", "(", "self", ".", "METRICS", "[", "'NumberToWords'", "]", ")", ")", "\n", "aux", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "sorted_order", "=", "[", "_", "[", "0", "]", "for", "_", "in", "aux", "]", "\n", "cax", "=", "plt", ".", "gca", "(", ")", ".", "matshow", "(", "np", ".", "array", "(", "\n", "self", ".", "METRICS", "[", "'Sharing'", "]", ")", "[", "sorted_order", ",", ":", "]", "[", ":", ",", "sorted_order", "]", "\n", "/", "self", ".", "S", ".", "usage_normalization", ")", "\n", "plt", ".", "gca", "(", ")", ".", "set_xticklabels", "(", "[", "''", "]", "+", "sorted", "(", "self", ".", "METRICS", "[", "'NumberToWords'", "]", ")", ")", "\n", "plt", ".", "gca", "(", ")", ".", "set_yticklabels", "(", "[", "''", "]", "+", "sorted", "(", "self", ".", "METRICS", "[", "'NumberToWords'", "]", ")", ")", "\n", "plt", ".", "gca", "(", ")", ".", "xaxis", ".", "set_major_locator", "(", "ticker", ".", "MultipleLocator", "(", "1", ")", ")", "\n", "plt", ".", "gca", "(", ")", ".", "yaxis", ".", "set_major_locator", "(", "ticker", ".", "MultipleLocator", "(", "1", ")", ")", "\n", "if", "self", ".", "store_video", ":", "\n", "        ", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "self", ".", "plot_name", ",", "'video/sharing-rate_'", "+", "\n", "str", "(", "self", ".", "step", ")", ")", ")", "\n", "", "plt", ".", "gcf", "(", ")", ".", "colorbar", "(", "cax", ")", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "self", ".", "plot_name", ",", "'sharing-rate'", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.log_metrics": [[727, 799], ["modular_metalearning.BounceGrad.S.plot_usage", "modular_metalearning.BounceGrad.S.plot_customized_usage_rate", "modular_metalearning.BounceGrad.plot_sharing", "numpy.linspace().reshape", "modular_metalearning.BounceGrad.T.normalize_input", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "matplotlib.subplots", "matplotlib.subplots", "range", "matplotlib.subplots", "matplotlib.subplots", "range", "matplotlib.savefig", "matplotlib.savefig", "matplotlib.clf", "matplotlib.clf", "numpy.random.choice", "min", "matplotlib.savefig", "matplotlib.savefig", "matplotlib.cla", "matplotlib.cla", "numpy.random.choice", "min", "ax[].scatter", "ax[].scatter", "ax[].set_xlim", "ax[].set_ylim", "ax[].set_xticks", "ax[].set_yticks", "os.path.join", "matplotlib.savefig", "matplotlib.savefig", "numpy.linspace", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "len", "min", "len", "ax[].plot", "ax[].set_ylim", "ax[].set_xlim", "ax[].set_xticks", "ax[].set_yticks", "os.path.join", "matplotlib.savefig", "matplotlib.savefig", "len", "min", "len", "ax[].scatter", "modular_metalearning.BounceGrad.T.denormalize_output", "ax[].plot", "numpy.array", "numpy.array", "os.path.join", "len", "numpy.array", "numpy.array", "os.path.join", "len", "modular_metalearning.BounceGrad.T.denormalize_output", "modular_metalearning.BounceGrad.run_model().data.cpu().numpy", "numpy.floor", "numpy.ceil", "modular_metalearning.BounceGrad.T.denormalize_output", "numpy.min", "numpy.max", "numpy.floor", "numpy.ceil", "str", "net().data.cpu().numpy", "str", "modular_metalearning.BounceGrad.run_model().data.cpu", "numpy.min", "numpy.max", "net().data.cpu", "modular_metalearning.BounceGrad.run_model", "net"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.plot_usage", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.plot_customized_usage_rate", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.plot_sharing", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaDataset.normalize_input", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaDataset.denormalize_output", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaDataset.denormalize_output", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaDataset.denormalize_output", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.run_model"], ["", "", "def", "log_metrics", "(", "self", ")", ":", "\n", "    ", "'''\n    Creates all plots based on self.METRICS.\n    '''", "\n", "# Plot Usage rate", "\n", "self", ".", "S", ".", "plot_usage", "(", "directory", "=", "self", ".", "plot_name", ")", "\n", "self", ".", "S", ".", "plot_customized_usage_rate", "(", "directory", "=", "self", ".", "plot_name", ")", "\n", "self", ".", "plot_sharing", "(", ")", "\n", "\n", "# Plot basic modules", "\n", "if", "self", ".", "T", ".", "MTRAIN", "[", "0", "]", ".", "TrainInput", ".", "shape", "[", "-", "1", "]", ">", "1", ":", "return", "\n", "print_plot", "=", "0", "\n", "input_range", "=", "np", ".", "linspace", "(", "-", "1", ",", "1", ")", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "\n", "norm_input_range", "=", "self", ".", "T", ".", "normalize_input", "(", "input_range", ")", "\n", "norm_input_torch", "=", "torch", ".", "FloatTensor", "(", "norm_input_range", ")", ".", "to", "(", "\n", "device", "=", "self", ".", "nn_device", ")", "\n", "if", "self", ".", "perm_sample_modules", "is", "None", ":", "\n", "      ", "self", ".", "perm_sample_modules", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "self", ".", "L", ")", ",", "\n", "min", "(", "len", "(", "self", ".", "L", ")", ",", "9", ")", ",", "replace", "=", "False", ")", "\n", "", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "3", ",", "ncols", "=", "3", ")", "\n", "for", "i", "in", "range", "(", "min", "(", "len", "(", "self", ".", "L", ")", ",", "9", ")", ")", ":", "\n", "      ", "net", "=", "self", ".", "L", "[", "self", ".", "perm_sample_modules", "[", "i", "]", "]", "\n", "color", "=", "'b'", "\n", "if", "net", ".", "inp", "==", "1", "and", "net", ".", "out", "==", "1", ":", "#plotable function", "\n", "        ", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "plot", "(", "input_range", ",", "\n", "2.", "*", "self", ".", "T", ".", "denormalize_output", "(", "\n", "net", "(", "norm_input_torch", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "c", "=", "color", ")", "\n", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "set_ylim", "(", "[", "-", "1.5", ",", "1.5", "]", ")", "\n", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "set_xlim", "(", "[", "-", "1", ",", "1", "]", ")", "\n", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "set_xticks", "(", "np", ".", "array", "(", "[", "-", "1", ",", "0", ",", "1", "]", ")", ")", "\n", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "set_yticks", "(", "np", ".", "array", "(", "[", "-", "1", ",", "0", ",", "1", "]", ")", ")", "\n", "print_plot", "+=", "1", "\n", "", "", "if", "print_plot", ">", "0", ":", "\n", "      ", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "self", ".", "plot_name", ",", "'sample-modules'", ")", ")", "\n", "if", "self", ".", "store_video", ":", "\n", "        ", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "self", ".", "plot_name", ",", "\n", "'video/modules_'", "+", "str", "(", "self", ".", "step", ")", ")", ")", "\n", "", "plt", ".", "cla", "(", ")", "\n", "# Plot basic comparisons", "\n", "", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "3", ",", "ncols", "=", "3", ")", "\n", "if", "self", ".", "perm_sample_fns", "is", "None", ":", "\n", "      ", "self", ".", "perm_sample_fns", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "self", ".", "T", ".", "MTRAIN", ")", ",", "\n", "min", "(", "len", "(", "self", ".", "T", ".", "MTRAIN", ")", ",", "9", ")", ",", "replace", "=", "False", ")", "\n", "", "for", "i", "in", "range", "(", "min", "(", "len", "(", "self", ".", "T", ".", "MTRAIN", ")", ",", "9", ")", ")", ":", "\n", "      ", "dataset", "=", "self", ".", "T", ".", "MTRAIN", "[", "self", ".", "perm_sample_fns", "[", "i", "]", "]", "\n", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "scatter", "(", "dataset", ".", "UValInput", ",", "\n", "dataset", ".", "UValOutput", ",", "c", "=", "'g'", ",", "label", "=", "'val'", ")", "\n", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "scatter", "(", "dataset", ".", "UTrainInput", ",", "\n", "dataset", ".", "UTrainOutput", ",", "c", "=", "'r'", ",", "label", "=", "'train'", ",", "\n", "s", "=", "18", ")", "\n", "if", "self", ".", "MAML", ":", "\n", "        ", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "scatter", "(", "self", ".", "T", ".", "MTRAIN", "[", "self", ".", "perm_sample_fns", "[", "i", "]", "]", ".", "UValInput", ",", "\n", "self", ".", "T", ".", "denormalize_output", "(", "\n", "self", ".", "MTrainAnswers", "[", "self", ".", "perm_sample_fns", "[", "i", "]", "]", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "structure", "=", "self", ".", "S", ".", "TrainStructures", "[", "self", ".", "perm_sample_fns", "[", "i", "]", "]", "\n", "structure_output", "=", "self", ".", "T", ".", "denormalize_output", "(", "self", ".", "run_model", "(", "structure", ",", "\n", "norm_input_torch", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "plot", "(", "input_range", ",", "structure_output", ")", "\n", "", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "set_xlim", "(", "[", "\n", "np", ".", "floor", "(", "np", ".", "min", "(", "self", ".", "T", ".", "MTRAIN", "[", "self", ".", "perm_sample_fns", "[", "i", "]", "]", ".", "UValInput", ")", ")", ",", "\n", "np", ".", "ceil", "(", "np", ".", "max", "(", "self", ".", "T", ".", "MTRAIN", "[", "self", ".", "perm_sample_fns", "[", "i", "]", "]", ".", "UValInput", ")", ")", "]", ")", "\n", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "set_ylim", "(", "[", "\n", "np", ".", "floor", "(", "np", ".", "min", "(", "self", ".", "T", ".", "MTRAIN", "[", "self", ".", "perm_sample_fns", "[", "i", "]", "]", ".", "UValOutput", ")", ")", "-", ".5", ",", "\n", "np", ".", "ceil", "(", "np", ".", "max", "(", "self", ".", "T", ".", "MTRAIN", "[", "self", ".", "perm_sample_fns", "[", "i", "]", "]", ".", "UValOutput", ")", ")", "+", ".5", "]", ")", "\n", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "set_xticks", "(", "np", ".", "array", "(", "[", "-", "1", ",", "0", ",", "1", "]", ")", ")", "\n", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "set_yticks", "(", "np", ".", "array", "(", "[", "-", "1", ",", "0", ",", "1", "]", ")", ")", "\n", "", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "self", ".", "plot_name", ",", "'comparisons'", ")", ")", "\n", "if", "self", ".", "store_video", ":", "\n", "      ", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "self", ".", "plot_name", ",", "\n", "'video/comparisons_'", "+", "str", "(", "self", ".", "step", ")", ")", ")", "\n", "", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.modular_metalearning.BounceGrad.update_Sharing_counters": [[800, 846], ["enumerate", "len", "enumerate", "print", "modular_metalearning.BounceGrad.S.modules_given_structure", "modular_metalearning.BounceGrad.S.modules_given_structure", "set", "len", "min", "modular_metalearning.BounceGrad.T.MTRAIN[].name.split", "modular_metalearning.BounceGrad.T.MVAL[].name.split", "modular_metalearning.BounceGrad.T.MTRAIN[].name.split", "modular_metalearning.BounceGrad.T.MVAL[].name.split", "modular_metalearning.BounceGrad.count", "modular_metalearning.BounceGrad.count", "len", "modular_metalearning.BounceGrad.METRICS[].append", "len"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.modules_given_structure", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.modules_given_structure"], ["", "def", "update_Sharing_counters", "(", "self", ")", ":", "\n", "    ", "'''\n    Updates table of E[# of modules shared by 2 keywords]\n    More precisely dataset names are a list of keywords A_B_C\n    the entries of the table are those keywords.\n\n    For example:\n     - square_plywood in the MIT dataset --> object=square,surface=plywood\n     - 1_4 in the Berkeley dataset --> action 1 actor 5\n    These plots show what structure the modules capture\n    '''", "\n", "if", "self", ".", "meta_lr", "==", "0", "or", "self", ".", "mtrain_copies", ">", "1", ":", "\n", "      ", "if", "self", ".", "step", "==", "0", ":", "print", "(", "'Not doing Sharing for now'", ")", "\n", "return", "\n", "", "if", "len", "(", "self", ".", "METRICS", "[", "'WordsToNumber'", "]", ")", ">", "50", ":", "return", "#too many keywords", "\n", "eps", "=", "1e-3", "\n", "self", ".", "S", ".", "usage_normalization", "=", "self", ".", "S", ".", "usage_normalization", "*", "(", "1", "-", "eps", ")", "+", "eps", "\n", "for", "i_s", ",", "i_structure", "in", "enumerate", "(", "\n", "self", ".", "S", ".", "TrainStructures", "+", "self", ".", "S", ".", "ValStructures", ")", ":", "\n", "      ", "for", "j_s", ",", "j_structure", "in", "enumerate", "(", "\n", "self", ".", "S", ".", "TrainStructures", "+", "self", ".", "S", ".", "ValStructures", ")", ":", "\n", "#count number of matches", "\n", "        ", "i_modules", "=", "self", ".", "S", ".", "modules_given_structure", "(", "i_structure", ")", "\n", "j_modules", "=", "self", ".", "S", ".", "modules_given_structure", "(", "j_structure", ")", "\n", "count", "=", "0", "\n", "for", "a", "in", "set", "(", "i_modules", ")", ":", "\n", "          ", "count", "+=", "min", "(", "i_modules", ".", "count", "(", "a", ")", ",", "j_modules", ".", "count", "(", "a", ")", ")", "\n", "", "count", "/=", "len", "(", "i_modules", ")", "\n", "if", "i_s", "<", "self", ".", "T", ".", "mtrain", ":", "i_words", "=", "self", ".", "T", ".", "MTRAIN", "[", "i_s", "]", ".", "name", ".", "split", "(", "'_'", ")", "\n", "else", ":", "i_words", "=", "self", ".", "T", ".", "MVAL", "[", "i_s", "-", "self", ".", "T", ".", "mtrain", "]", ".", "name", ".", "split", "(", "'_'", ")", "\n", "if", "j_s", "<", "self", ".", "T", ".", "mtrain", ":", "j_words", "=", "self", ".", "T", ".", "MTRAIN", "[", "j_s", "]", ".", "name", ".", "split", "(", "'_'", ")", "\n", "else", ":", "j_words", "=", "self", ".", "T", ".", "MVAL", "[", "j_s", "-", "self", ".", "T", ".", "mtrain", "]", ".", "name", ".", "split", "(", "'_'", ")", "\n", "for", "i_w", "in", "i_words", "+", "j_words", ":", "\n", "          ", "if", "i_w", "not", "in", "self", ".", "METRICS", "[", "'WordsToNumber'", "]", ":", "\n", "            ", "self", ".", "METRICS", "[", "'WordsToNumber'", "]", "[", "i_w", "]", "=", "(", "\n", "len", "(", "self", ".", "METRICS", "[", "'WordsToNumber'", "]", ")", ")", "\n", "self", ".", "METRICS", "[", "'NumberToWords'", "]", ".", "append", "(", "i_w", ")", "\n", "if", "len", "(", "self", ".", "METRICS", "[", "'WordsToNumber'", "]", ")", ">", "50", ":", "return", "#too many keywords", "\n", "", "", "for", "i_w", "in", "i_words", ":", "\n", "          ", "for", "j_w", "in", "j_words", ":", "\n", "            ", "(", "ni_w", ",", "nj_w", ")", "=", "(", "self", ".", "METRICS", "[", "'WordsToNumber'", "]", "[", "i_w", "]", ",", "\n", "self", ".", "METRICS", "[", "'WordsToNumber'", "]", "[", "j_w", "]", ")", "\n", "self", ".", "METRICS", "[", "'Sharing'", "]", "[", "ni_w", "]", "[", "nj_w", "]", "*=", "(", "1.", "-", "eps", ")", "\n", "self", ".", "METRICS", "[", "'Sharing'", "]", "[", "nj_w", "]", "[", "ni_w", "]", "*=", "(", "1.", "-", "eps", ")", "\n", "self", ".", "METRICS", "[", "'Sharing'", "]", "[", "ni_w", "]", "[", "nj_w", "]", "+=", "count", "*", "eps", "\n", "self", ".", "METRICS", "[", "'Sharing'", "]", "[", "nj_w", "]", "[", "ni_w", "]", "+=", "count", "*", "eps", "\n", "", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.sum_composer.Sum_Composer.__init__": [[17, 22], ["composition.Composer.__init__"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__"], ["  ", "def", "__init__", "(", "self", ",", "composer", ",", "module_list", ",", "loss_fn", "=", "None", ",", "structure", "=", "{", "}", ",", "\n", "instructions", "=", "{", "}", ")", ":", "\n", "    ", "super", "(", "Sum_Composer", ",", "self", ")", ".", "__init__", "(", "composer", "=", "composer", ",", "\n", "module_list", "=", "module_list", ",", "loss_fn", "=", "loss_fn", ",", "\n", "structure", "=", "structure", ",", "instructions", "=", "instructions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.sum_composer.Sum_Composer.forward_no_weights": [[23, 28], ["torch.sum", "res.append", "torch.stack"], "methods", ["None"], ["", "def", "forward_no_weights", "(", "self", ",", "x", ")", ":", "\n", "    ", "res", "=", "[", "]", "\n", "for", "mod", "in", "self", ".", "structure", "[", "'modules'", "]", ":", "res", ".", "append", "(", "self", ".", "module_list", "[", "mod", "]", "(", "x", ")", ")", "\n", "x", "=", "torch", ".", "sum", "(", "torch", ".", "stack", "(", "res", ")", ",", "0", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.sum_composer.Sum_Composer.forward_with_weights": [[29, 35], ["torch.sum", "res.append", "torch.stack", "str"], "methods", ["None"], ["", "def", "forward_with_weights", "(", "self", ",", "x", ",", "weights", ")", ":", "\n", "    ", "res", "=", "[", "]", "\n", "for", "mod", "in", "self", ".", "structure", "[", "'modules'", "]", ":", "\n", "      ", "res", ".", "append", "(", "self", ".", "module_list", "[", "mod", "]", "(", "x", ",", "\n", "weights", "=", "weights", ",", "prefix", "=", "'module_list.'", "+", "str", "(", "mod", ")", "+", "'.features.'", ")", ")", "\n", "", "return", "torch", ".", "sum", "(", "torch", ".", "stack", "(", "res", ")", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.sum_composer.Sum_Structure.__init__": [[37, 43], ["structure.Structure.__init__"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__"], ["  ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "    ", "self", ".", "composer", "=", "'sum'", "\n", "self", ".", "composer_class", "=", "Sum_Composer", "\n", "self", ".", "composer_abbreviation", "=", "'SUM'", "\n", "self", ".", "structure_size", "=", "args", ".", "structure_size", "\n", "super", "(", "Sum_Structure", ",", "self", ")", ".", "__init__", "(", "args", "=", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.sum_composer.Sum_Structure.propose_new_structure": [[44, 46], ["sum_composer.Sum_Structure.default_propose_new_structure"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.default_propose_new_structure"], ["", "def", "propose_new_structure", "(", "self", ",", "new_structure", ")", ":", "\n", "    ", "return", "self", ".", "default_propose_new_structure", "(", "new_structure", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.sum_composer.Sum_Structure.initialize_structure": [[47, 49], ["sum_composer.Sum_Structure.default_initialize_structure"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.default_initialize_structure"], ["", "def", "initialize_structure", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "default_initialize_structure", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.sum_composer.Sum_Structure.update_Usage_counters": [[50, 52], ["sum_composer.Sum_Structure.default_update_Usage_counters"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.default_update_Usage_counters"], ["", "def", "update_Usage_counters", "(", "self", ",", "METRICS", ",", "T", ")", ":", "\n", "    ", "return", "self", ".", "default_update_Usage_counters", "(", "METRICS", ",", "T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.sum_composer.Sum_Structure.modules_given_structure": [[53, 55], ["None"], "methods", ["None"], ["", "def", "modules_given_structure", "(", "self", ",", "structure", ")", ":", "\n", "    ", "return", "structure", "[", "'modules'", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.composition.Composer.__init__": [[37, 53], ["torch.nn.Module.__init__", "len", "type", "type", "torch.nn.ModuleList"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__"], ["def", "__init__", "(", "self", ",", "composer", ",", "module_list", ",", "loss_fn", "=", "None", ",", "structure", "=", "{", "}", ",", "\n", "instructions", "=", "{", "}", ")", ":", "\n", "    ", "'''\n    composer: string describing the composer type\n    structure: specifies how to compose which modules\n    loss_fn: loss function\n    instructions: can be left blank, customizable non-computation parameters\n    '''", "\n", "super", "(", "Composer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "module_list", "=", "module_list", "\n", "assert", "type", "(", "module_list", ")", "==", "type", "(", "torch", ".", "nn", ".", "ModuleList", "(", ")", ")", "\n", "self", ".", "num_modules", "=", "len", "(", "self", ".", "module_list", ")", "\n", "self", ".", "composer", "=", "composer", "\n", "self", ".", "loss_fn", "=", "loss_fn", "\n", "self", ".", "structure", "=", "structure", "\n", "self", ".", "instructions", "=", "instructions", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.composition.Composer.forward_no_weights": [[54, 60], ["None"], "methods", ["None"], ["", "def", "forward_no_weights", "(", "self", ",", "x", ")", ":", "\n", "    ", "\"\"\"\n    Specifies how to get the final result given structure and input\n    Method must be implemented in subclass.\n    \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.composition.Composer.forward_with_weights": [[61, 67], ["None"], "methods", ["None"], ["", "def", "forward_with_weights", "(", "self", ",", "x", ",", "weights", ")", ":", "\n", "    ", "\"\"\"\n    Similar to forward_no_weights, but fixing weights\n    Method must be implemented in subclass.\n    \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.composition.Composer.forward": [[68, 75], ["composition.Composer.forward_no_weights", "composition.Composer.forward_with_weights"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Composer.forward_no_weights", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.composition.Composer.forward_with_weights"], ["", "def", "forward", "(", "self", ",", "x", ",", "weights", "=", "None", ")", ":", "\n", "##  TODO: use the forward method of each method for weights!=None", "\n", "##  instead of manual code.", "\n", "    ", "if", "weights", "is", "None", ":", "\n", "      ", "return", "self", ".", "forward_no_weights", "(", "x", ")", "\n", "", "else", ":", "\n", "      ", "return", "self", ".", "forward_with_weights", "(", "x", ",", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.composition.Composer.net_forward": [[76, 78], ["composition.Composer.forward"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.forward"], ["", "", "def", "net_forward", "(", "self", ",", "x", ",", "weights", "=", "None", ")", ":", "\n", "    ", "return", "self", ".", "forward", "(", "x", ",", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.composition.Composer.copy_weights": [[79, 88], ["zip", "net.modules", "composition.Composer.modules", "isinstance", "isinstance", "isinstance", "m_from.weight.data.clone", "m_from.bias.data.clone"], "methods", ["None"], ["", "def", "copy_weights", "(", "self", ",", "net", ")", ":", "\n", "    ", "'''Set this module's weights to be the same as those of 'net' '''", "\n", "raise", "NotImplementedError", "\n", "for", "m_from", ",", "m_to", "in", "zip", "(", "net", ".", "modules", "(", ")", ",", "self", ".", "modules", "(", ")", ")", ":", "\n", "      ", "if", "(", "isinstance", "(", "m_to", ",", "nn", ".", "Linear", ")", "or", "isinstance", "(", "m_to", ",", "nn", ".", "Conv2d", ")", "\n", "or", "isinstance", "(", "m_to", ",", "nn", ".", "BatchNorm2d", ")", ")", ":", "\n", "        ", "m_to", ".", "weight", ".", "data", "=", "m_from", ".", "weight", ".", "data", ".", "clone", "(", ")", "\n", "if", "m_to", ".", "bias", "is", "not", "None", ":", "\n", "            ", "m_to", ".", "bias", ".", "data", "=", "m_from", ".", "bias", ".", "data", ".", "clone", "(", ")", "\n", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.dataset.Dataset.__init__": [[20, 30], ["numpy.random.RandomState", "type", "type", "numpy.random.RandomState"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "train", ",", "val", ",", "test", ",", "RS", "=", "None", ",", "shuffle", "=", "True", ",", "name", "=", "None", ")", ":", "\n", "#Random state", "\n", "    ", "if", "RS", "is", "None", ":", "self", ".", "RS", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "SEED", ")", "\n", "elif", "type", "(", "RS", ")", "==", "type", "(", "1", ")", ":", "self", ".", "RS", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "RS", ")", "\n", "else", ":", "self", ".", "RS", "=", "RS", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "val", "=", "val", "\n", "self", ".", "test", "=", "test", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.dataset.MetaDataset.__init__": [[35, 88], ["random.seed", "dataset.MetaDataset.create_datasets", "numpy.random.RandomState", "dataset.MetaDataset.apply_normalization", "len", "dataset.MetaDataset.MTRAIN.sort", "dataset.MetaDataset.MVAL.sort", "dataset.MetaDataset.MTEST.sort", "type", "type", "numpy.random.RandomState", "max", "str", "dataset.MetaDataset.add_smaller_cases", "str", "str", "max"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaHDFDataset.create_datasets", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaDataset.apply_normalization", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaDataset.add_smaller_cases"], ["  ", "def", "__init__", "(", "self", ",", "\n", "train", ",", "val", ",", "test", ",", "#Size of each dataset", "\n", "mtrain", ",", "mval", ",", "mtest", ",", "#Number of metacases", "\n", "shuffle", "=", "True", ",", "\n", "limit_data", "=", "-", "1", ",", "\n", "split_by_file", "=", "False", ",", "\n", "smaller_MVals", "=", "[", "]", ",", "\n", "max_datasets", "=", "1e9", ",", "\n", "RS", "=", "None", ",", "filename", "=", "None", ",", "normalize", "=", "False", ")", ":", "\n", "\n", "#Random state", "\n", "    ", "if", "RS", "is", "None", ":", "self", ".", "RS", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "SEED", ")", "\n", "elif", "type", "(", "RS", ")", "==", "type", "(", "1", ")", ":", "self", ".", "RS", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "RS", ")", "\n", "else", ":", "self", ".", "RS", "=", "RS", "#RandomState", "\n", "random", ".", "seed", "(", "SEED", ")", "\n", "\n", "#Parameters for each testcase", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "val", "=", "val", "\n", "self", ".", "test", "=", "test", "\n", "\n", "self", ".", "mtrain", "=", "mtrain", "#meta-train size", "\n", "self", ".", "mval", "=", "mval", "#meta-validation size", "\n", "self", ".", "mtest", "=", "mtest", "#meta-test size", "\n", "\n", "#Other customizations", "\n", "self", ".", "max_datasets", "=", "max_datasets", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "limit_data", "=", "limit_data", "\n", "self", ".", "normalize", "=", "normalize", "\n", "self", ".", "split_by_file", "=", "split_by_file", "\n", "self", ".", "smaller_MVals", "=", "smaller_MVals", "\n", "\n", "#Create data", "\n", "self", ".", "create_datasets", "(", "filename", ")", "\n", "if", "self", ".", "normalize", ":", "\n", "      ", "self", ".", "apply_normalization", "(", ")", "\n", "\n", "", "if", "self", ".", "smaller_MVals", "!=", "[", "]", ":", "\n", "      ", "assert", "max", "(", "self", ".", "smaller_MVals", ")", "<", "self", ".", "MVAL", "[", "0", "]", ".", "train", ",", "(", "\n", "'all smaller_MVals should be  smaller than train'", "+", "\n", "str", "(", "max", "(", "self", ".", "smaller_MVals", ")", ")", "+", "' vs '", "+", "str", "(", "self", ".", "MVAL", "[", "0", "]", ".", "train", ")", ")", "\n", "self", ".", "prev_mval", "=", "self", ".", "mval", "\n", "for", "dataset", "in", "self", ".", "MVAL", ":", "\n", "        ", "if", "dataset", ".", "name", "is", "not", "None", ":", "dataset", ".", "name", "+=", "'_'", "+", "str", "(", "dataset", ".", "train", ")", "\n", "", "for", "train_sz", "in", "self", ".", "smaller_MVals", ":", "\n", "        ", "self", ".", "add_smaller_cases", "(", "self", ".", "prev_mval", ",", "train_sz", ")", "\n", "", "self", ".", "mval", "=", "len", "(", "self", ".", "MVAL", ")", "\n", "\n", "", "if", "self", ".", "MTRAIN", "[", "0", "]", ".", "name", "is", "not", "None", ":", "\n", "      ", "self", ".", "MTRAIN", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", ".", "name", ")", "\n", "self", ".", "MVAL", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", ".", "name", ")", "\n", "self", ".", "MTEST", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.dataset.MetaDataset.add_smaller_cases": [[89, 102], ["range", "copy.deepcopy", "copy.deepcopy.name.split", "dataset.MetaDataset.ALL.append", "dataset.MetaDataset.MVAL.append", "str"], "methods", ["None"], ["", "", "def", "add_smaller_cases", "(", "self", ",", "old_idx", ",", "new_train", ")", ":", "\n", "    ", "'''\n    Creates new cases with smaller training and appends them to self.MVAL\n    '''", "\n", "for", "i", "in", "range", "(", "old_idx", ")", ":", "\n", "      ", "aux", "=", "copy", ".", "deepcopy", "(", "self", ".", "MVAL", "[", "i", "]", ")", "\n", "name", "=", "aux", ".", "name", ".", "split", "(", "'_'", ")", "\n", "aux", ".", "train", "=", "new_train", "\n", "aux", ".", "TrainInput", "=", "aux", ".", "TrainInput", "[", ":", "aux", ".", "train", "]", "\n", "aux", ".", "TrainOutput", "=", "aux", ".", "TrainOutput", "[", ":", "aux", ".", "train", "]", "\n", "aux", ".", "name", "=", "'_'", ".", "join", "(", "name", "[", ":", "-", "1", "]", "+", "[", "str", "(", "aux", ".", "train", ")", "]", ")", "\n", "self", ".", "ALL", ".", "append", "(", "aux", ")", "\n", "self", ".", "MVAL", ".", "append", "(", "self", ".", "ALL", "[", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.dataset.MetaDataset.apply_normalization": [[103, 151], ["numpy.concatenate", "numpy.concatenate", "numpy.mean", "numpy.maximum", "numpy.mean", "numpy.maximum", "print", "print", "print", "print", "numpy.concatenate", "numpy.concatenate", "numpy.mean", "numpy.maximum", "numpy.mean", "numpy.maximum", "print", "print", "print", "print", "numpy.std", "numpy.std", "numpy.std", "numpy.std", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy"], "methods", ["None"], ["", "", "def", "apply_normalization", "(", "self", ")", ":", "\n", "    ", "'''\n    Applies normalization to all inputs and all outputs in MetaDataset\n    at the same time\n    '''", "\n", "# Check all inputs and all outputs have the same size", "\n", "inp_shape", "=", "self", ".", "MTRAIN", "[", "0", "]", ".", "TrainInput", ".", "shape", "[", "1", "]", "\n", "out_shape", "=", "self", ".", "MTRAIN", "[", "0", "]", ".", "TrainOutput", ".", "shape", "[", "1", "]", "\n", "for", "dataset", "in", "self", ".", "ALL", ":", "\n", "      ", "assert", "dataset", ".", "TrainInput", ".", "shape", "[", "1", "]", "==", "inp_shape", "\n", "assert", "dataset", ".", "TestOutput", ".", "shape", "[", "1", "]", "==", "out_shape", "\n", "# Compute mean and std", "\n", "", "ALL_IN", "=", "np", ".", "concatenate", "(", "[", "dataset", ".", "ValInput", "for", "dataset", "in", "self", ".", "MVAL", "]", ",", "0", ")", "\n", "ALL_OUT", "=", "np", ".", "concatenate", "(", "[", "dataset", ".", "ValOutput", "for", "dataset", "in", "self", ".", "MVAL", "]", ",", "0", ")", "\n", "self", ".", "input_mean", "=", "np", ".", "mean", "(", "ALL_IN", ",", "0", ")", "\n", "self", ".", "input_std", "=", "np", ".", "maximum", "(", "EPS", ",", "np", ".", "std", "(", "ALL_IN", ",", "0", ")", ")", "\n", "self", ".", "output_mean", "=", "np", ".", "mean", "(", "ALL_OUT", ",", "0", ")", "\n", "self", ".", "output_std", "=", "np", ".", "maximum", "(", "EPS", ",", "np", ".", "std", "(", "ALL_OUT", ",", "0", ")", ")", "\n", "print", "(", "'MVAL Input mean: '", ",", "self", ".", "input_mean", ")", "\n", "print", "(", "'MVAL Input std: '", ",", "self", ".", "input_std", ")", "\n", "print", "(", "'MVAL Output mean: '", ",", "self", ".", "output_mean", ")", "\n", "print", "(", "'MVAL Output std: '", ",", "self", ".", "output_std", ")", "\n", "\n", "ALL_IN", "=", "np", ".", "concatenate", "(", "[", "dataset", ".", "ValInput", "for", "dataset", "in", "self", ".", "MTRAIN", "]", ",", "0", ")", "\n", "ALL_OUT", "=", "np", ".", "concatenate", "(", "[", "dataset", ".", "ValOutput", "for", "dataset", "in", "self", ".", "MTRAIN", "]", ",", "0", ")", "\n", "self", ".", "input_mean", "=", "np", ".", "mean", "(", "ALL_IN", ",", "0", ")", "\n", "self", ".", "input_std", "=", "np", ".", "maximum", "(", "EPS", ",", "np", ".", "std", "(", "ALL_IN", ",", "0", ")", ")", "\n", "self", ".", "output_mean", "=", "np", ".", "mean", "(", "ALL_OUT", ",", "0", ")", "\n", "self", ".", "output_std", "=", "np", ".", "maximum", "(", "EPS", ",", "np", ".", "std", "(", "ALL_OUT", ",", "0", ")", ")", "\n", "print", "(", "'Input mean: '", ",", "self", ".", "input_mean", ")", "\n", "print", "(", "'Input std: '", ",", "self", ".", "input_std", ")", "\n", "print", "(", "'Output mean: '", ",", "self", ".", "output_mean", ")", "\n", "print", "(", "'Output std: '", ",", "self", ".", "output_std", ")", "\n", "\n", "for", "dataset", "in", "self", ".", "ALL", ":", "\n", "#Copy unnormalized versions", "\n", "      ", "dataset", ".", "UTrainInput", "=", "copy", ".", "deepcopy", "(", "dataset", ".", "TrainInput", ")", "\n", "dataset", ".", "UTrainOutput", "=", "copy", ".", "deepcopy", "(", "dataset", ".", "TrainOutput", ")", "\n", "dataset", ".", "UValInput", "=", "copy", ".", "deepcopy", "(", "dataset", ".", "ValInput", ")", "\n", "dataset", ".", "UValOutput", "=", "copy", ".", "deepcopy", "(", "dataset", ".", "ValOutput", ")", "\n", "\n", "dataset", ".", "TrainInput", "=", "(", "dataset", ".", "TrainInput", "-", "self", ".", "input_mean", ")", "/", "self", ".", "input_std", "\n", "dataset", ".", "TrainOutput", "=", "(", "dataset", ".", "TrainOutput", "-", "\n", "self", ".", "output_mean", ")", "/", "self", ".", "output_std", "\n", "dataset", ".", "ValInput", "=", "(", "dataset", ".", "ValInput", "-", "self", ".", "input_mean", ")", "/", "self", ".", "input_std", "\n", "dataset", ".", "ValOutput", "=", "(", "dataset", ".", "ValOutput", "-", "self", ".", "output_mean", ")", "/", "self", ".", "output_std", "\n", "dataset", ".", "TestInput", "=", "(", "dataset", ".", "TestInput", "-", "self", ".", "input_mean", ")", "/", "self", ".", "input_std", "\n", "dataset", ".", "TestOutput", "=", "(", "dataset", ".", "TestOutput", "-", "self", ".", "output_mean", ")", "/", "self", ".", "output_std", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.dataset.MetaDataset.normalize_input": [[152, 154], ["None"], "methods", ["None"], ["", "", "def", "normalize_input", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "(", "x", "-", "self", ".", "input_mean", ")", "/", "self", ".", "input_std", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.dataset.MetaDataset.denormalize_input": [[155, 157], ["None"], "methods", ["None"], ["", "def", "denormalize_input", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "self", ".", "input_mean", "+", "self", ".", "input_std", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.dataset.MetaDataset.normalize_output": [[158, 160], ["None"], "methods", ["None"], ["", "def", "normalize_output", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "(", "x", "-", "self", ".", "output_mean", ")", "/", "self", ".", "output_std", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.dataset.MetaDataset.denormalize_output": [[161, 163], ["None"], "methods", ["None"], ["", "def", "denormalize_output", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "self", ".", "output_mean", "+", "self", ".", "output_std", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.dataset.MetaDataset.create_datasets": [[164, 167], ["None"], "methods", ["None"], ["", "def", "create_datasets", "(", "self", ",", "filename", "=", "None", ")", ":", "\n", "#Populates self.ALL, self.MTRAIN, self.MVAL, self.MTEST", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.dataset.NPDataset.__init__": [[172, 229], ["dataset.Dataset.__init__", "input_data.reshape.reshape.reshape", "output_data.reshape.reshape.reshape", "abs", "int", "int", "dataset.NPDataset.RS.get_state", "dataset.NPDataset.RS.shuffle", "dataset.NPDataset.RS.set_state", "dataset.NPDataset.RS.shuffle", "round", "round", "min"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__"], ["  ", "def", "__init__", "(", "self", ",", "\n", "input_data", ",", "output_data", ",", "\n", "train", ",", "val", ",", "test", ",", "\n", "name", "=", "None", ",", "limit", "=", "-", "1", ",", "\n", "RS", "=", "None", ",", "shuffle", "=", "True", ",", "\n", "train_val_are_all", "=", "False", ")", ":", "\n", "#input_data, output_data are np arrays", "\n", "    ", "super", "(", "NPDataset", ",", "self", ")", ".", "__init__", "(", "train", "=", "train", ",", "val", "=", "val", ",", "test", "=", "test", ",", "\n", "RS", "=", "RS", ",", "shuffle", "=", "shuffle", ",", "name", "=", "name", ")", "\n", "#Handle input/output with more than 2 dims,", "\n", "#compress to 2, but remember.", "\n", "self", ".", "original_input_shape", "=", "input_data", ".", "shape", "\n", "self", ".", "original_output_shape", "=", "output_data", ".", "shape", "\n", "input_data", "=", "input_data", ".", "reshape", "(", "input_data", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "output_data", "=", "output_data", ".", "reshape", "(", "output_data", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "assert", "input_data", ".", "shape", "[", "0", "]", "==", "output_data", ".", "shape", "[", "0", "]", "\n", "if", "limit", ">=", "0", ":", "\n", "      ", "input_data", "=", "input_data", "[", ":", "limit", ",", ":", "]", "\n", "output_data", "=", "output_data", "[", ":", "limit", ",", ":", "]", "\n", "", "len_data", "=", "input_data", ".", "shape", "[", "0", "]", "\n", "if", "abs", "(", "train", "+", "val", "+", "test", "-", "1.", ")", "<", "1e-6", ":", "\n", "      ", "self", ".", "train", "=", "int", "(", "round", "(", "len_data", "*", "train", ")", ")", "\n", "self", ".", "val", "=", "int", "(", "round", "(", "len_data", "*", "val", ")", ")", "\n", "self", ".", "test", "=", "len_data", "-", "self", ".", "train", "-", "self", ".", "val", "\n", "assert", "self", ".", "train", "+", "self", ".", "val", "+", "self", ".", "test", "==", "len_data", "\n", "assert", "min", "(", "[", "self", ".", "train", ",", "self", ".", "val", ",", "self", ".", "test", "]", ")", ">=", "0", "\n", "\n", "", "if", "self", ".", "shuffle", ":", "#Shuffle in unison", "\n", "      ", "rng_state", "=", "self", ".", "RS", ".", "get_state", "(", ")", "\n", "self", ".", "RS", ".", "shuffle", "(", "input_data", ")", "\n", "self", ".", "RS", ".", "set_state", "(", "rng_state", ")", "\n", "self", ".", "RS", ".", "shuffle", "(", "output_data", ")", "\n", "\n", "", "self", ".", "All", "=", "[", "input_data", ",", "output_data", "]", "\n", "\n", "if", "train_val_are_all", ":", "\n", "      ", "self", ".", "train", "=", "len_data", "\n", "self", ".", "val", "=", "len_data", "\n", "self", ".", "test", "=", "0", "\n", "self", ".", "TrainInput", "=", "input_data", "\n", "self", ".", "TrainOutput", "=", "output_data", "\n", "self", ".", "ValInput", "=", "input_data", "\n", "self", ".", "ValOutput", "=", "output_data", "\n", "self", ".", "TestInput", "=", "input_data", "[", ":", "0", "]", "\n", "self", ".", "TestOutput", "=", "output_data", "[", ":", "0", "]", "\n", "", "else", ":", "\n", "      ", "self", ".", "TrainInput", "=", "input_data", "[", ":", "self", ".", "train", "]", "\n", "self", ".", "TrainOutput", "=", "output_data", "[", ":", "self", ".", "train", "]", "\n", "self", ".", "ValInput", "=", "input_data", "[", "self", ".", "train", ":", "self", ".", "train", "+", "self", ".", "val", "]", "\n", "self", ".", "ValOutput", "=", "output_data", "[", "self", ".", "train", ":", "self", ".", "train", "+", "self", ".", "val", "]", "\n", "self", ".", "TestInput", "=", "input_data", "[", "self", ".", "train", "+", "self", ".", "val", ":", "]", "\n", "self", ".", "TestOutput", "=", "output_data", "[", "self", ".", "train", "+", "self", ".", "val", ":", "]", "\n", "\n", "", "self", ".", "Train", "=", "[", "self", ".", "TrainInput", ",", "self", ".", "TrainOutput", "]", "\n", "self", ".", "Val", "=", "[", "self", ".", "ValInput", ",", "self", ".", "ValOutput", "]", "\n", "self", ".", "Test", "=", "[", "self", ".", "TestInput", ",", "self", ".", "TestOutput", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.dataset.MetaHDFDataset.create_datasets": [[234, 311], ["h5py.File", "print", "print", "int", "int", "int", "list", "random.shuffle", "print", "print", "name.replace", "len", "len", "dataset.MetaHDFDataset.RS.choice", "min", "len", "round", "round", "zip", "min", "num_datasets_hist.append", "range", "dataset.MetaHDFDataset.RS.shuffle", "len", "len", "len", "sorted", "sorted", "len", "print", "dataset.MetaHDFDataset.RS.get_state", "dataset.MetaHDFDataset.RS.shuffle", "dataset.MetaHDFDataset.RS.set_state", "dataset.MetaHDFDataset.RS.shuffle", "input", "list_to_append.append", "list", "list", "enumerate", "enumerate", "len", "len", "len", "dataset.NPDataset", "key.replace", "h5py.File.keys", "h5py.File.keys", "len", "len"], "methods", ["None"], ["  ", "def", "create_datasets", "(", "self", ",", "filename", ")", ":", "\n", "    ", "'''\n    Populates self.ALL, self.MTRAIN, self.MVAL, self.MTEST\n    '''", "\n", "#Read HDF5", "\n", "f", "=", "h5py", ".", "File", "(", "filename", ",", "'r'", ")", "\n", "DATA", "=", "[", "[", "f", "[", "key", "]", ",", "f", "[", "key", ".", "replace", "(", "'IN'", ",", "'OUT'", ")", "]", "]", "\n", "for", "key", "in", "sorted", "(", "list", "(", "f", ".", "keys", "(", ")", ")", ")", "if", "'IN'", "in", "key", "]", "\n", "NAMES", "=", "[", "name", ".", "replace", "(", "'-IN'", ",", "''", ")", "\n", "for", "name", "in", "sorted", "(", "list", "(", "f", ".", "keys", "(", ")", ")", ")", "if", "'IN'", "in", "name", "]", "\n", "print", "(", "'Names = '", ",", "NAMES", "[", ":", "10", "]", ")", "\n", "print", "(", "'Num datasets = '", ",", "len", "(", "NAMES", ")", ")", "\n", "\n", "#DATA contains a list of 'object'=datasets", "\n", "self", ".", "mval_fraction", ",", "self", ".", "mtest_fraction", "=", "self", ".", "mval", ",", "self", ".", "mtest", "\n", "if", "self", ".", "max_datasets", "<", "len", "(", "DATA", ")", ":", "\n", "#Subsample DATA randomly", "\n", "      ", "subsampled_idx", "=", "self", ".", "RS", ".", "choice", "(", "len", "(", "DATA", ")", ",", "size", "=", "self", ".", "max_datasets", ",", "\n", "replace", "=", "False", ")", "\n", "DATA", "=", "[", "d", "for", "(", "i_d", ",", "d", ")", "in", "enumerate", "(", "DATA", ")", "if", "i_d", "in", "subsampled_idx", "]", "\n", "NAMES", "=", "[", "d", "for", "(", "i_d", ",", "d", ")", "in", "enumerate", "(", "NAMES", ")", "if", "i_d", "in", "subsampled_idx", "]", "\n", "\n", "", "tot_datasets", "=", "min", "(", "DATA", "[", "0", "]", "[", "0", "]", "[", "(", ")", "]", ".", "shape", "[", "0", "]", "//", "self", ".", "limit_data", ",", "\n", "self", ".", "max_datasets", "//", "len", "(", "DATA", ")", ")", "*", "len", "(", "DATA", ")", "\n", "self", ".", "mval", "=", "int", "(", "round", "(", "self", ".", "mval", "*", "tot_datasets", ")", ")", "\n", "self", ".", "mtest", "=", "int", "(", "round", "(", "self", ".", "mtest", "*", "tot_datasets", ")", ")", "\n", "self", ".", "mtrain", "=", "int", "(", "tot_datasets", "-", "self", ".", "mtest", "-", "self", ".", "mval", ")", "\n", "assert", "self", ".", "mtrain", ">", "0", "\n", "self", ".", "ALL", "=", "[", "]", "\n", "num_datasets_hist", "=", "[", "]", "\n", "\n", "self", ".", "MTRAIN", "=", "[", "]", "\n", "self", ".", "MVAL", "=", "[", "]", "\n", "self", ".", "MTEST", "=", "[", "]", "\n", "num_datasets_hist", "=", "[", "]", "\n", "shuffled_pairs", "=", "list", "(", "zip", "(", "NAMES", ",", "DATA", ")", ")", "\n", "random", ".", "shuffle", "(", "shuffled_pairs", ")", "\n", "for", "(", "name", ",", "data", ")", "in", "shuffled_pairs", ":", "\n", "      ", "input_data", "=", "data", "[", "0", "]", "[", "(", ")", "]", "\n", "output_data", "=", "data", "[", "1", "]", "[", "(", ")", "]", "\n", "num_datasets", "=", "min", "(", "input_data", ".", "shape", "[", "0", "]", "//", "self", ".", "limit_data", ",", "\n", "self", ".", "max_datasets", "//", "len", "(", "DATA", ")", ")", "\n", "num_datasets_hist", ".", "append", "(", "num_datasets", ")", "\n", "if", "num_datasets", "==", "0", ":", "\n", "        ", "print", "(", "name", "+", "' has no datasets'", ")", ";", "continue", "\n", "", "if", "self", ".", "shuffle", ":", "\n", "#Shuffle in unison", "\n", "        ", "rng_state", "=", "self", ".", "RS", ".", "get_state", "(", ")", "\n", "self", ".", "RS", ".", "shuffle", "(", "input_data", ")", "\n", "self", ".", "RS", ".", "set_state", "(", "rng_state", ")", "\n", "self", ".", "RS", ".", "shuffle", "(", "output_data", ")", "\n", "", "else", ":", "input", "(", "'Are you sure you dont want to shuffle?'", ")", "\n", "list_to_append", "=", "self", ".", "ALL", "#same for all datasets created from this file", "\n", "if", "self", ".", "split_by_file", ":", "\n", "        ", "if", "len", "(", "self", ".", "MTRAIN", ")", "<", "self", ".", "mtrain", ":", "list_to_append", "=", "self", ".", "MTRAIN", "\n", "elif", "len", "(", "self", ".", "MVAL", ")", "<", "self", ".", "mval", ":", "list_to_append", "=", "self", ".", "MVAL", "\n", "elif", "len", "(", "self", ".", "MTEST", ")", "<", "self", ".", "mtest", ":", "list_to_append", "=", "self", ".", "MTEST", "\n", "else", ":", "assert", "False", ",", "'something doesnt add up'", "\n", "# print(num_datasets)", "\n", "", "for", "k", "in", "range", "(", "num_datasets", ")", ":", "\n", "        ", "list_to_append", ".", "append", "(", "NPDataset", "(", "\n", "input_data", "=", "input_data", "[", "k", "*", "self", ".", "limit_data", ":", "(", "k", "+", "1", ")", "*", "self", ".", "limit_data", "]", ",", "\n", "output_data", "=", "output_data", "[", "k", "*", "self", ".", "limit_data", ":", "(", "k", "+", "1", ")", "*", "self", ".", "limit_data", "]", ",", "\n", "name", "=", "name", ",", "train", "=", "self", ".", "train", ",", "val", "=", "self", ".", "val", ",", "test", "=", "self", ".", "test", ")", ")", "\n", "", "", "if", "self", ".", "split_by_file", ":", "\n", "      ", "self", ".", "ALL", "=", "self", ".", "MTRAIN", "+", "self", ".", "MVAL", "+", "self", ".", "MTEST", "\n", "", "else", ":", "\n", "      ", "self", ".", "RS", ".", "shuffle", "(", "self", ".", "ALL", ")", "\n", "[", "self", ".", "MTRAIN", ",", "self", ".", "MTEST", ",", "self", ".", "MVAL", "]", "=", "[", "\n", "self", ".", "ALL", "[", ":", "self", ".", "mtrain", "]", ",", "\n", "self", ".", "ALL", "[", "self", ".", "mtrain", ":", "self", ".", "mtrain", "+", "self", ".", "mtest", "]", ",", "\n", "self", ".", "ALL", "[", "self", ".", "mtrain", "+", "self", ".", "mtest", ":", "]", "]", "\n", "", "print", "(", "'Goal meta sizes: '", ",", "self", ".", "mtrain", ",", "self", ".", "mval", ",", "self", ".", "mtest", ")", "\n", "(", "self", ".", "mtrain", ",", "self", ".", "mval", ",", "self", ".", "mtest", ")", "=", "(", "\n", "len", "(", "self", ".", "MTRAIN", ")", ",", "len", "(", "self", ".", "MVAL", ")", ",", "len", "(", "self", ".", "MTEST", ")", ")", "\n", "print", "(", "'Final meta sizes: '", ",", "self", ".", "mtrain", ",", "self", ".", "mval", ",", "self", ".", "mtest", ")", "\n", "return", "self", ".", "ALL", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.dataset.MetaNpySelfRegressDataset.create_meta_dataset": [[319, 333], ["min", "range", "min", "list_to_append.append", "dataset.NPDataset"], "methods", ["None"], ["def", "create_meta_dataset", "(", "self", ",", "array", ",", "names", ",", "hard_max_datasets", "=", "1e10", ")", ":", "\n", "    ", "'''\n    From an array of shape [n,...] creates many datasets\n    '''", "\n", "list_to_append", "=", "[", "]", "\n", "max_datasets", "=", "min", "(", "self", ".", "max_datasets", ",", "hard_max_datasets", ")", "\n", "for", "i", "in", "range", "(", "min", "(", "array", ".", "shape", "[", "0", "]", ",", "max_datasets", ")", ")", ":", "\n", "      ", "list_to_append", ".", "append", "(", "NPDataset", "(", "\n", "input_data", "=", "array", "[", "i", "]", ",", "\n", "output_data", "=", "array", "[", "i", "]", ",", "\n", "name", "=", "names", "[", "i", "]", ",", "train", "=", "self", ".", "train", ",", "val", "=", "self", ".", "val", ",", "test", "=", "self", ".", "test", ",", "\n", "shuffle", "=", "False", ",", "#dont shuffle", "\n", "train_val_are_all", "=", "True", ")", ")", "\n", "", "return", "list_to_append", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.dataset.MetaNpySelfRegressDataset.create_datasets": [[334, 360], ["numpy.load", "numpy.load", "numpy.load", "numpy.transpose", "numpy.transpose", "numpy.transpose", "pdb.set_trace", "dataset.MetaNpySelfRegressDataset.create_meta_dataset", "dataset.MetaNpySelfRegressDataset.create_meta_dataset", "dataset.MetaNpySelfRegressDataset.create_meta_dataset", "len", "len", "len", "str", "range", "str", "range", "str", "range"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.dataset.MetaNpySelfRegressDataset.create_meta_dataset", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.dataset.MetaNpySelfRegressDataset.create_meta_dataset", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.dataset.MetaNpySelfRegressDataset.create_meta_dataset"], ["", "def", "create_datasets", "(", "self", ",", "filename", ")", ":", "\n", "    ", "'''\n    Populates self.ALL, self.MTRAIN, self.MVAL, self.MTEST\n    '''", "\n", "#Read .npy", "\n", "MTrainArray", "=", "np", ".", "load", "(", "filename", "+", "'_train.npy'", ")", "\n", "MValArray", "=", "np", ".", "load", "(", "filename", "+", "'_val.npy'", ")", "\n", "MTestArray", "=", "np", ".", "load", "(", "filename", "+", "'_test.npy'", ")", "\n", "\n", "MTrainArray", "=", "np", ".", "transpose", "(", "MTrainArray", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "MValArray", "=", "np", ".", "transpose", "(", "MValArray", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "MTestArray", "=", "np", ".", "transpose", "(", "MTestArray", ",", "[", "0", ",", "2", ",", "1", ",", "3", "]", ")", "\n", "import", "pdb", ";", "pdb", ".", "set_trace", "(", ")", "\n", "MTrainNames", "=", "[", "'train_'", "+", "str", "(", "i", ")", "for", "i", "in", "range", "(", "MTrainArray", ".", "shape", "[", "0", "]", ")", "]", "\n", "MValNames", "=", "[", "'val_'", "+", "str", "(", "i", ")", "for", "i", "in", "range", "(", "MValArray", ".", "shape", "[", "0", "]", ")", "]", "\n", "MTestNames", "=", "[", "'test_'", "+", "str", "(", "i", ")", "for", "i", "in", "range", "(", "MTestArray", ".", "shape", "[", "0", "]", ")", "]", "\n", "\n", "self", ".", "MTRAIN", "=", "self", ".", "create_meta_dataset", "(", "MTrainArray", ",", "MTrainNames", ")", "\n", "self", ".", "MVAL", "=", "self", ".", "create_meta_dataset", "(", "MValArray", ",", "MValNames", ",", "\n", "hard_max_datasets", "=", "self", ".", "max_datasets", "//", "4", ")", "\n", "self", ".", "MTEST", "=", "self", ".", "create_meta_dataset", "(", "MTestArray", ",", "MTestNames", ")", "\n", "self", ".", "mtrain", "=", "len", "(", "self", ".", "MTRAIN", ")", "\n", "self", ".", "mval", "=", "len", "(", "self", ".", "MVAL", ")", "\n", "self", ".", "mtest", "=", "len", "(", "self", ".", "MTEST", ")", "\n", "self", ".", "ALL", "=", "self", ".", "MTRAIN", "+", "self", ".", "MVAL", "+", "self", ".", "MTEST", "\n", "return", "self", ".", "ALL", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.layers.exponential.__init__": [[46, 48], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "exponential", ",", "self", ")", ".", "__init__", "(", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.layers.exponential.forward": [[48, 50], ["torch.exp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "torch", ".", "exp", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.layers.Net.__init__": [[52, 58], ["super().__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_feature", ",", "n_hidden", ",", "n_output", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden", "=", "torch", ".", "nn", ".", "Linear", "(", "n_feature", ",", "n_hidden", ")", "# hidden layer", "\n", "self", ".", "hidden_two", "=", "torch", ".", "nn", ".", "Linear", "(", "n_hidden", ",", "n_hidden", ")", "# hidden layer", "\n", "self", ".", "hidden_3", "=", "torch", ".", "nn", ".", "Linear", "(", "n_hidden", ",", "n_hidden", ")", "# hidden layer", "\n", "self", ".", "predict", "=", "torch", ".", "nn", ".", "Linear", "(", "n_hidden", ",", "n_output", ")", "# output layer", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.layers.Net.forward": [[59, 65], ["torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "layers.Net.predict", "layers.Net.hidden", "layers.Net.hidden_two", "layers.Net.hidden_3"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.relu", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.relu", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "hidden", "(", "x", ")", ")", "# activation function for hidden layer", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "hidden_two", "(", "x", ")", ")", "# activation function for hidden layer", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "hidden_3", "(", "x", ")", ")", "# activation function for hidden layer", "\n", "x", "=", "self", ".", "predict", "(", "x", ")", "# linear output", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.layers.linear": [[16, 21], ["torch.nn.functional.linear", "torch.nn.functional.linear", "weight.cuda", "weight.cuda", "bias.cuda"], "function", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.linear", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.linear"], ["def", "linear", "(", "input", ",", "weight", ",", "bias", "=", "None", ")", ":", "\n", "    ", "if", "bias", "is", "None", ":", "\n", "        ", "return", "F", ".", "linear", "(", "input", ",", "weight", ".", "cuda", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "F", ".", "linear", "(", "input", ",", "weight", ".", "cuda", "(", ")", ",", "bias", ".", "cuda", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.layers.conv2d": [[22, 24], ["torch.nn.functional.conv2d", "weight.cuda", "bias.cuda"], "function", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.conv2d"], ["", "", "def", "conv2d", "(", "input", ",", "weight", ",", "bias", "=", "None", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "dilation", "=", "1", ",", "groups", "=", "1", ")", ":", "\n", "    ", "return", "F", ".", "conv2d", "(", "input", ",", "weight", ".", "cuda", "(", ")", ",", "bias", ".", "cuda", "(", ")", ",", "stride", ",", "padding", ",", "dilation", ",", "groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.layers.relu": [[25, 27], ["torch.nn.functional.threshold"], "function", ["None"], ["", "def", "relu", "(", "input", ")", ":", "\n", "    ", "return", "F", ".", "threshold", "(", "input", ",", "0", ",", "0", ",", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.layers.maxpool": [[28, 30], ["torch.nn.functional.max_pool2d"], "function", ["None"], ["", "def", "maxpool", "(", "input", ",", "kernel_size", ",", "stride", "=", "None", ")", ":", "\n", "    ", "return", "F", ".", "max_pool2d", "(", "input", ",", "kernel_size", ",", "stride", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.layers.batchnorm": [[31, 38], ["torch.zeros().cuda", "torch.ones().cuda", "torch.nn.functional.batch_norm", "torch.zeros", "torch.ones", "numpy.prod", "numpy.prod", "numpy.array", "numpy.array", "input.data.size", "input.data.size"], "function", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.MLP.batch_norm"], ["", "def", "batchnorm", "(", "input", ",", "weight", "=", "None", ",", "bias", "=", "None", ",", "running_mean", "=", "None", ",", "running_var", "=", "None", ",", "training", "=", "True", ",", "eps", "=", "1e-5", ",", "momentum", "=", "0.1", ")", ":", "\n", "    ", "''' momentum = 1 restricts stats to the current mini-batch '''", "\n", "# This hack only works when momentum is 1 and avoids needing to track running stats", "\n", "# by substuting dummy variables", "\n", "running_mean", "=", "torch", ".", "zeros", "(", "np", ".", "prod", "(", "np", ".", "array", "(", "input", ".", "data", ".", "size", "(", ")", "[", "1", "]", ")", ")", ")", ".", "cuda", "(", ")", "\n", "running_var", "=", "torch", ".", "ones", "(", "np", ".", "prod", "(", "np", ".", "array", "(", "input", ".", "data", ".", "size", "(", ")", "[", "1", "]", ")", ")", ")", ".", "cuda", "(", ")", "\n", "return", "F", ".", "batch_norm", "(", "input", ",", "running_mean", ",", "running_var", ",", "weight", ",", "bias", ",", "training", ",", "momentum", ",", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.layers.bilinear_upsample": [[39, 41], ["torch.nn.functional.upsample"], "function", ["None"], ["", "def", "bilinear_upsample", "(", "in_", ",", "factor", ")", ":", "\n", "    ", "return", "F", ".", "upsample", "(", "in_", ",", "None", ",", "factor", ",", "'bilinear'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.layers.log_softmax": [[42, 44], ["torch.nn.functional.log_softmax"], "function", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.log_softmax"], ["", "def", "log_softmax", "(", "input", ")", ":", "\n", "    ", "return", "F", ".", "log_softmax", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.functioncomposition_composer.FunctionComposition_Composer.__init__": [[18, 23], ["composition.Composer.__init__"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__"], ["  ", "def", "__init__", "(", "self", ",", "composer", ",", "module_list", ",", "loss_fn", "=", "None", ",", "structure", "=", "{", "}", ",", "\n", "instructions", "=", "{", "}", ")", ":", "\n", "    ", "super", "(", "FunctionComposition_Composer", ",", "self", ")", ".", "__init__", "(", "composer", "=", "composer", ",", "\n", "module_list", "=", "module_list", ",", "loss_fn", "=", "loss_fn", ",", "\n", "structure", "=", "structure", ",", "instructions", "=", "instructions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.functioncomposition_composer.FunctionComposition_Composer.forward_no_weights": [[24, 28], ["None"], "methods", ["None"], ["", "def", "forward_no_weights", "(", "self", ",", "x", ")", ":", "\n", "    ", "for", "mod", "in", "self", ".", "structure", "[", "'modules'", "]", ":", "\n", "      ", "x", "=", "self", ".", "module_list", "[", "mod", "]", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.functioncomposition_composer.FunctionComposition_Composer.forward_with_weights": [[29, 34], ["str"], "methods", ["None"], ["", "def", "forward_with_weights", "(", "self", ",", "x", ",", "weights", ")", ":", "\n", "    ", "for", "mod", "in", "self", ".", "structure", "[", "'modules'", "]", ":", "\n", "      ", "x", "=", "self", ".", "module_list", "[", "mod", "]", "(", "x", ",", "\n", "weights", "=", "weights", ",", "prefix", "=", "'module_list.'", "+", "str", "(", "mod", ")", "+", "'.features.'", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.functioncomposition_composer.FunctionComposition_Structure.__init__": [[36, 42], ["structure.Structure.__init__"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__"], ["  ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "    ", "self", ".", "composer", "=", "'functionCompostion'", "\n", "self", ".", "composer_class", "=", "FunctionComposition_Composer", "\n", "self", ".", "composer_abbreviation", "=", "'C'", "\n", "self", ".", "structure_size", "=", "args", ".", "structure_size", "\n", "super", "(", "FunctionComposition_Structure", ",", "self", ")", ".", "__init__", "(", "args", "=", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.functioncomposition_composer.FunctionComposition_Structure.propose_new_structure": [[43, 45], ["functioncomposition_composer.FunctionComposition_Structure.default_propose_new_structure"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.default_propose_new_structure"], ["", "def", "propose_new_structure", "(", "self", ",", "new_structure", ")", ":", "\n", "    ", "return", "self", ".", "default_propose_new_structure", "(", "new_structure", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.functioncomposition_composer.FunctionComposition_Structure.initialize_structure": [[46, 48], ["functioncomposition_composer.FunctionComposition_Structure.default_initialize_structure"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.default_initialize_structure"], ["", "def", "initialize_structure", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "default_initialize_structure", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.functioncomposition_composer.FunctionComposition_Structure.update_Usage_counters": [[49, 51], ["functioncomposition_composer.FunctionComposition_Structure.default_update_Usage_counters"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.default_update_Usage_counters"], ["", "def", "update_Usage_counters", "(", "self", ",", "METRICS", ",", "T", ")", ":", "\n", "    ", "return", "self", ".", "default_update_Usage_counters", "(", "METRICS", ",", "T", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.functioncomposition_composer.FunctionComposition_Structure.modules_given_structure": [[52, 54], ["None"], "methods", ["None"], ["", "def", "modules_given_structure", "(", "self", ",", "structure", ")", ":", "\n", "    ", "return", "structure", "[", "'modules'", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.custom_module.torch_NN.__init__": [[23, 58], ["torch.Module.__init__", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "range", "custom_module.torch_NN.add_module", "len", "key_words.append", "int", "torch.Sequential", "torch.Sequential", "custom_module.torch_NN.add_module", "key_words.append", "torch.Linear", "torch.Linear", "collections.OrderedDict", "torch.Sigmoid", "torch.Sigmoid", "custom_module.torch_NN.add_module", "str", "torch.ReLU", "torch.ReLU", "layers.exponential", "custom_module.torch_NN.add_module", "str", "torch.Sequential", "torch.Sequential", "custom_module.torch_NN.add_module", "custom_module.torch_NN.__init__.module_from_name"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__"], ["def", "__init__", "(", "self", ",", "inp", "=", "1", ",", "out", "=", "1", ",", "hidden", "=", "[", "]", ",", "final_act", "=", "'affine'", ",", "loss_fn", "=", "None", ")", ":", "\n", "    ", "super", "(", "torch_NN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "inp", "=", "inp", "\n", "self", ".", "dummy_inp", "=", "torch", ".", "randn", "(", "8", ",", "inp", ",", "device", "=", "nn_device", ")", "\n", "self", ".", "out", "=", "out", "\n", "self", ".", "num_layers", "=", "len", "(", "hidden", ")", "+", "1", "\n", "self", ".", "final_act", "=", "final_act", "\n", "key_words", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "      ", "key_words", ".", "append", "(", "'fc'", "+", "str", "(", "i", ")", ")", "\n", "if", "i", "<", "self", ".", "num_layers", "-", "1", ":", "#final_act may not be a relu", "\n", "        ", "key_words", ".", "append", "(", "'relu'", "+", "str", "(", "i", ")", ")", "\n", "\n", "", "", "def", "module_from_name", "(", "name", ")", ":", "\n", "      ", "if", "self", ".", "num_layers", ">", "10", ":", "raise", "NotImplementedError", "\n", "#TODO: allow more than 10 layers, put '_' and use split", "\n", "num", "=", "int", "(", "name", "[", "-", "1", "]", ")", "\n", "typ", "=", "name", "[", ":", "-", "1", "]", "\n", "if", "typ", "==", "'fc'", ":", "\n", "        ", "inp", "=", "self", ".", "inp", "if", "num", "==", "0", "else", "hidden", "[", "num", "-", "1", "]", "\n", "out", "=", "self", ".", "out", "if", "num", "+", "1", "==", "self", ".", "num_layers", "else", "hidden", "[", "num", "]", "\n", "return", "nn", ".", "Linear", "(", "inp", ",", "out", ")", "\n", "", "elif", "typ", "==", "'relu'", ":", "\n", "        ", "return", "nn", ".", "ReLU", "(", ")", "#removed inplace", "\n", "", "else", ":", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "add_module", "(", "'features'", ",", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "name", ",", "module_from_name", "(", "name", ")", ")", "for", "name", "in", "key_words", "]", ")", ")", ")", "\n", "\n", "if", "self", ".", "final_act", "==", "'sigmoid'", ":", "self", ".", "add_module", "(", "'fa'", ",", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "elif", "self", ".", "final_act", "==", "'exp'", ":", "self", ".", "add_module", "(", "'fa'", ",", "exponential", "(", ")", ")", "\n", "elif", "self", ".", "final_act", "==", "'affine'", ":", "self", ".", "add_module", "(", "'fa'", ",", "nn", ".", "Sequential", "(", ")", ")", "\n", "elif", "self", ".", "final_act", "==", "'relu'", ":", "self", ".", "add_module", "(", "'fa'", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "elif", "self", ".", "final_act", "==", "'tanh'", ":", "self", ".", "add_module", "(", "'fa'", ",", "nn", ".", "Tanh", "(", ")", ")", "\n", "else", ":", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.custom_module.torch_NN.dummy_forward_pass": [[59, 64], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "custom_module.torch_NN.forward"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.forward"], ["", "def", "dummy_forward_pass", "(", "self", ")", ":", "\n", "    ", "'''\n    Dummy forward pass to be able to backpropagate to activate gradient hooks\n    '''", "\n", "return", "torch", ".", "mean", "(", "self", ".", "forward", "(", "self", ".", "dummy_inp", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.custom_module.torch_NN.forward": [[65, 80], ["custom_module.torch_NN.features", "custom_module.torch_NN.fa", "range", "custom_module.torch_NN.fa", "layers.linear", "layers.relu", "str", "str"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.linear", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.relu"], ["", "def", "forward", "(", "self", ",", "x", ",", "weights", "=", "None", ",", "prefix", "=", "''", ")", ":", "\n", "    ", "'''\n    Runs the net forward; if weights are None it uses 'self' layers,\n    otherwise keeps the structure and uses 'weights' instead.\n    '''", "\n", "if", "weights", "is", "None", ":", "\n", "      ", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "x", "=", "self", ".", "fa", "(", "x", ")", "\n", "", "else", ":", "\n", "      ", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "        ", "x", "=", "linear", "(", "x", ",", "weights", "[", "prefix", "+", "'fc'", "+", "str", "(", "i", ")", "+", "'.weight'", "]", ",", "\n", "weights", "[", "prefix", "+", "'fc'", "+", "str", "(", "i", ")", "+", "'.bias'", "]", ")", "\n", "if", "i", "<", "self", ".", "num_layers", "-", "1", ":", "x", "=", "relu", "(", "x", ")", "\n", "", "x", "=", "self", ".", "fa", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.custom_module.torch_NN.net_forward": [[81, 83], ["custom_module.torch_NN.forward"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.forward"], ["", "def", "net_forward", "(", "self", ",", "x", ",", "weights", "=", "None", ")", ":", "\n", "    ", "return", "self", ".", "forward", "(", "x", ",", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.custom_module.torch_NN.copy_weights": [[86, 94], ["zip", "net.modules", "custom_module.torch_NN.modules", "isinstance", "isinstance", "isinstance", "m_from.weight.data.clone", "m_from.bias.data.clone"], "methods", ["None"], ["", "def", "copy_weights", "(", "self", ",", "net", ")", ":", "\n", "    ", "'''Set this module's weights to be the same as those of 'net' '''", "\n", "for", "m_from", ",", "m_to", "in", "zip", "(", "net", ".", "modules", "(", ")", ",", "self", ".", "modules", "(", ")", ")", ":", "\n", "      ", "if", "(", "isinstance", "(", "m_to", ",", "nn", ".", "Linear", ")", "or", "isinstance", "(", "m_to", ",", "nn", ".", "Conv2d", ")", "\n", "or", "isinstance", "(", "m_to", ",", "nn", ".", "BatchNorm2d", ")", ")", ":", "\n", "        ", "m_to", ".", "weight", ".", "data", "=", "m_from", ".", "weight", ".", "data", ".", "clone", "(", ")", "\n", "if", "m_to", ".", "bias", "is", "not", "None", ":", "\n", "            ", "m_to", ".", "bias", ".", "data", "=", "m_from", ".", "bias", ".", "data", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.None.custom_module.main": [[95, 99], ["custom_module.torch_NN", "torch.rand", "torch.rand", "print", "torch_NN."], "function", ["None"], ["", "", "", "", "", "def", "main", "(", ")", ":", "\n", "  ", "NN", "=", "torch_NN", "(", "hidden", "=", "[", "2", ",", "3", "]", ",", "final_act", "=", "'sigmoid'", ")", "\n", "x", "=", "torch", ".", "rand", "(", "1", ")", "\n", "print", "(", "NN", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.MLP.__init__": [[9, 17], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "encoder.MLP.init_weights"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.CNN.init_weights"], ["def", "__init__", "(", "self", ",", "n_in", ",", "n_hid", ",", "n_out", ",", "do_prob", "=", "0.", ")", ":", "\n", "    ", "super", "(", "MLP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "n_in", ",", "n_hid", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "n_hid", ",", "n_out", ")", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm1d", "(", "n_out", ")", "\n", "self", ".", "dropout_prob", "=", "do_prob", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.MLP.init_weights": [[18, 26], ["encoder.MLP.modules", "isinstance", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "m.bias.data.fill_", "isinstance", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "    ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "      ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_normal_", "(", "m", ".", "weight", ".", "data", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0.1", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm1d", ")", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.MLP.batch_norm": [[27, 35], ["len", "inputs.view", "encoder.MLP.bn", "encoder.MLP.view", "inputs.size", "inputs.size", "len", "encoder.MLP.bn", "inputs.size", "inputs.size"], "methods", ["None"], ["", "", "", "def", "batch_norm", "(", "self", ",", "inputs", ")", ":", "\n", "    ", "if", "len", "(", "inputs", ".", "shape", ")", "==", "3", ":", "\n", "      ", "x", "=", "inputs", ".", "view", "(", "inputs", ".", "size", "(", "0", ")", "*", "inputs", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "bn", "(", "x", ")", "\n", "return", "x", ".", "view", "(", "inputs", ".", "size", "(", "0", ")", ",", "inputs", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "", "elif", "len", "(", "inputs", ".", "shape", ")", "==", "2", ":", "\n", "      ", "return", "self", ".", "bn", "(", "inputs", ")", "\n", "", "else", ":", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.MLP.forward": [[36, 42], ["torch.elu", "torch.elu", "torch.elu", "torch.dropout", "torch.dropout", "torch.dropout", "torch.elu", "torch.elu", "torch.elu", "encoder.MLP.batch_norm", "encoder.MLP.fc1", "encoder.MLP.fc2"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.MLP.batch_norm"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "# Input shape: [num_sims, num_things, num_features]", "\n", "    ", "x", "=", "F", ".", "elu", "(", "self", ".", "fc1", "(", "inputs", ")", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "self", ".", "dropout_prob", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "F", ".", "elu", "(", "self", ".", "fc2", "(", "x", ")", ")", "\n", "return", "self", ".", "batch_norm", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.Encoder.__init__": [[45, 47], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__"], ["  ", "def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.Encoder.init_weights": [[48, 53], ["encoder.Encoder.modules", "isinstance", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "m.bias.data.fill_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "    ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "      ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "nn", ".", "init", ".", "xavier_normal_", "(", "m", ".", "weight", ".", "data", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.Encoder.edge2node": [[54, 58], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "rel_rec.t", "torch.matmul.size", "torch.matmul.size", "torch.matmul.size"], "methods", ["None"], ["", "", "", "def", "edge2node", "(", "self", ",", "x", ",", "rel_rec", ",", "rel_send", ")", ":", "\n", "# NOTE: Assumes that we have the same graph across all samples.", "\n", "    ", "incoming", "=", "torch", ".", "matmul", "(", "rel_rec", ".", "t", "(", ")", ",", "x", ")", "\n", "return", "incoming", "/", "incoming", ".", "size", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.Encoder.node2edge": [[59, 65], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "node2edge", "(", "self", ",", "x", ",", "rel_rec", ",", "rel_send", ")", ":", "\n", "# NOTE: Assumes that we have the same graph across all samples.", "\n", "    ", "receivers", "=", "torch", ".", "matmul", "(", "rel_rec", ",", "x", ")", "\n", "senders", "=", "torch", ".", "matmul", "(", "rel_send", ",", "x", ")", "\n", "edges", "=", "torch", ".", "cat", "(", "[", "receivers", ",", "senders", "]", ",", "dim", "=", "2", ")", "\n", "return", "edges", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.Encoder.forward": [[66, 68], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "rel_rec", ",", "rel_send", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.FullMLPStructureEncoder.__init__": [[71, 85], ["encoder.Encoder.__init__", "encoder.MLP", "encoder.MLP", "encoder.MLP", "encoder.MLP", "print", "torch.Linear", "torch.Linear", "torch.Linear", "encoder.FullMLPStructureEncoder.init_weights"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.CNN.init_weights"], ["  ", "def", "__init__", "(", "self", ",", "n_in", ",", "n_hid", ",", "n_out", ",", "n_nodes", "=", "5", ",", "do_prob", "=", "0.", ")", ":", "\n", "    ", "super", "(", "FullMLPStructureEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_e", "=", "8", "\n", "# self.n_hid = n_hid", "\n", "self", ".", "n_nodes", "=", "n_nodes", "\n", "self", ".", "n_edges", "=", "self", ".", "n_nodes", "*", "(", "self", ".", "n_nodes", "-", "1", ")", "\n", "self", ".", "feat", "=", "self", ".", "n_edges", "*", "self", ".", "n_e", "\n", "self", ".", "mlp1", "=", "MLP", "(", "n_in", ",", "self", ".", "n_e", ",", "self", ".", "n_e", ",", "do_prob", ")", "\n", "self", ".", "mlp2", "=", "MLP", "(", "self", ".", "feat", ",", "2", "*", "self", ".", "feat", ",", "self", ".", "feat", ",", "do_prob", ")", "\n", "self", ".", "mlp3", "=", "MLP", "(", "self", ".", "feat", ",", "2", "*", "self", ".", "feat", ",", "self", ".", "feat", ",", "do_prob", ")", "\n", "self", ".", "mlp4", "=", "MLP", "(", "self", ".", "feat", ",", "2", "*", "self", ".", "feat", ",", "self", ".", "feat", ",", "do_prob", ")", "\n", "print", "(", "\"Using structure encoder, hidden size {}.\"", ".", "format", "(", "n_hid", ")", ")", "\n", "self", ".", "fc_out", "=", "nn", ".", "Linear", "(", "self", ".", "n_e", ",", "n_out", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.FullMLPStructureEncoder.forward": [[86, 101], ["inputs.view", "encoder.FullMLPStructureEncoder.mlp1().reshape().contiguous", "encoder.FullMLPStructureEncoder.mlp2", "encoder.FullMLPStructureEncoder.mlp3", "encoder.FullMLPStructureEncoder.mlp4", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.size", "inputs.size", "encoder.FullMLPStructureEncoder.fc_out", "encoder.FullMLPStructureEncoder.mlp1().reshape", "encoder.FullMLPStructureEncoder.mlp1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "rel_rec", ",", "rel_send", ")", ":", "\n", "    ", "x", "=", "inputs", ".", "view", "(", "inputs", ".", "size", "(", "0", ")", ",", "inputs", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "# New shape: [num_sims, num_edges, num_edge_modules]", "\n", "bs", "=", "x", ".", "shape", "[", "0", "]", "\n", "x", "=", "self", ".", "mlp1", "(", "x", ")", ".", "reshape", "(", "bs", ",", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "after1", "=", "x", "\n", "x", "=", "self", ".", "mlp2", "(", "x", ")", "\n", "x", "=", "x", "+", "after1", "\n", "after2", "=", "x", "\n", "x", "=", "self", ".", "mlp3", "(", "x", ")", "\n", "x", "=", "x", "+", "after2", "\n", "after3", "=", "x", "\n", "x", "=", "self", ".", "mlp4", "(", "x", ")", "\n", "x", "=", "(", "x", "+", "after3", ")", ".", "reshape", "(", "bs", ",", "self", ".", "n_edges", ",", "self", ".", "n_e", ")", "\n", "return", "F", ".", "softmax", "(", "self", ".", "fc_out", "(", "x", ")", ",", "dim", "=", "2", ")", "# [:,:,1]", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.MLPStructureEncoder.__init__": [[103, 114], ["encoder.Encoder.__init__", "encoder.MLP", "encoder.MLP", "encoder.MLP", "encoder.MLP", "encoder.MLP", "print", "torch.Linear", "torch.Linear", "torch.Linear", "encoder.MLPStructureEncoder.init_weights"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.CNN.init_weights"], ["  ", "def", "__init__", "(", "self", ",", "n_in", ",", "n_hid", ",", "n_out", ",", "do_prob", "=", "0.", ")", ":", "\n", "    ", "super", "(", "MLPStructureEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "n_hid", "=", "32", "\n", "self", ".", "mlp1", "=", "MLP", "(", "n_in", ",", "n_hid", ",", "n_hid", ",", "do_prob", ")", "\n", "self", ".", "mlp15", "=", "MLP", "(", "n_hid", ",", "n_hid", ",", "n_hid", ",", "do_prob", ")", "\n", "self", ".", "mlp2", "=", "MLP", "(", "n_hid", "*", "2", ",", "n_hid", ",", "n_hid", ",", "do_prob", ")", "\n", "self", ".", "mlp3", "=", "MLP", "(", "n_hid", "*", "2", ",", "n_hid", ",", "n_hid", ",", "do_prob", ")", "\n", "self", ".", "mlp4", "=", "MLP", "(", "n_hid", "*", "4", ",", "n_hid", ",", "n_hid", ",", "do_prob", ")", "\n", "print", "(", "\"Using structure encoder, hidden size {}.\"", ".", "format", "(", "n_hid", ")", ")", "\n", "self", ".", "fc_out", "=", "nn", ".", "Linear", "(", "n_hid", ",", "n_out", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.MLPStructureEncoder.forward": [[115, 132], ["inputs.view", "encoder.MLPStructureEncoder.mlp1", "encoder.MLPStructureEncoder.edge2node", "encoder.MLPStructureEncoder.mlp15", "encoder.MLPStructureEncoder.node2edge", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "encoder.MLPStructureEncoder.edge2node", "encoder.MLPStructureEncoder.mlp3", "encoder.MLPStructureEncoder.node2edge", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "encoder.MLPStructureEncoder.mlp4", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.size", "inputs.size", "encoder.MLPStructureEncoder.fc_out", "encoder.MLPStructureEncoder.mlp2"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.Encoder.edge2node", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.Encoder.node2edge", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.Encoder.edge2node", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.Encoder.node2edge"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "rel_rec", ",", "rel_send", ")", ":", "\n", "    ", "x", "=", "inputs", ".", "view", "(", "inputs", ".", "size", "(", "0", ")", ",", "inputs", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "# New shape: [num_sims, num_edges, num_edge_modules]", "\n", "x", "=", "self", ".", "mlp1", "(", "x", ")", "# 2-layer ELU net per node", "\n", "first_edges", "=", "x", "\n", "x", "=", "self", ".", "edge2node", "(", "x", ",", "rel_rec", ",", "rel_send", ")", "\n", "x", "=", "self", ".", "mlp15", "(", "x", ")", "\n", "x", "=", "self", ".", "node2edge", "(", "x", ",", "rel_rec", ",", "rel_send", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "self", ".", "mlp2", "(", "x", ")", ",", "first_edges", ")", ",", "dim", "=", "2", ")", "\n", "x_skip", "=", "x", "\n", "x", "=", "self", ".", "edge2node", "(", "x", ",", "rel_rec", ",", "rel_send", ")", "\n", "x", "=", "self", ".", "mlp3", "(", "x", ")", "\n", "x", "=", "self", ".", "node2edge", "(", "x", ",", "rel_rec", ",", "rel_send", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "x_skip", ")", ",", "dim", "=", "2", ")", "# Skip connection", "\n", "x", "=", "self", ".", "mlp4", "(", "x", ")", "\n", "\n", "return", "F", ".", "softmax", "(", "self", ".", "fc_out", "(", "x", ")", ",", "dim", "=", "2", ")", "# [:,:,1]", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.MLPStateEncoder.__init__": [[135, 149], ["encoder.Encoder.__init__", "encoder.MLP", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "encoder.MLP", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "encoder.MLP", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "encoder.MLP", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "print", "torch.Linear", "torch.Linear", "torch.Linear", "encoder.MLPStateEncoder.init_weights"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.CNN.init_weights"], ["  ", "def", "__init__", "(", "self", ",", "n_in", ",", "n_hid", ",", "n_out", ",", "do_prob", "=", "0.", ")", ":", "\n", "    ", "super", "(", "MLPStateEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "mlp1", "=", "MLP", "(", "n_in", ",", "n_hid", ",", "n_hid", ",", "do_prob", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm1d", "(", "n_hid", ")", "\n", "self", ".", "mlp2", "=", "MLP", "(", "n_hid", "*", "2", ",", "n_hid", ",", "n_hid", ",", "do_prob", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm1d", "(", "n_hid", ")", "\n", "self", ".", "mlp3", "=", "MLP", "(", "n_hid", ",", "n_hid", ",", "n_hid", ",", "do_prob", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm1d", "(", "n_hid", ")", "\n", "self", ".", "mlp4", "=", "MLP", "(", "n_hid", "*", "3", ",", "n_hid", ",", "n_hid", ",", "do_prob", ")", "\n", "self", ".", "bn4", "=", "nn", ".", "BatchNorm1d", "(", "n_hid", ")", "\n", "print", "(", "\"Using state encoder, hidden size {}.\"", ".", "format", "(", "n_hid", ")", ")", "\n", "self", ".", "n_hid", "=", "n_hid", "\n", "self", ".", "fc_out", "=", "nn", ".", "Linear", "(", "n_hid", ",", "n_out", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.MLPStateEncoder.forward": [[150, 170], ["inputs.view", "encoder.MLPStateEncoder.mlp1", "encoder.MLPStateEncoder.bn1().reshape", "encoder.MLPStateEncoder.node2edge", "encoder.MLPStateEncoder.mlp2", "encoder.MLPStateEncoder.bn2().reshape", "encoder.MLPStateEncoder.edge2node", "encoder.MLPStateEncoder.mlp3", "encoder.MLPStateEncoder.bn3().reshape", "encoder.MLPStateEncoder.node2edge", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "encoder.MLPStateEncoder.mlp4", "encoder.MLPStateEncoder.bn4().reshape", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.size", "inputs.size", "encoder.MLPStateEncoder.fc_out", "encoder.MLPStateEncoder.bn1", "encoder.MLPStateEncoder.bn2", "encoder.MLPStateEncoder.bn3", "encoder.MLPStateEncoder.bn4", "encoder.MLPStateEncoder.reshape", "encoder.MLPStateEncoder.reshape", "encoder.MLPStateEncoder.reshape", "encoder.MLPStateEncoder.reshape"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.Encoder.node2edge", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.Encoder.edge2node", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.Encoder.node2edge"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "rel_rec", ",", "rel_send", ")", ":", "\n", "# Input shape: [num_sims, num_atoms, num_timesteps, num_dims]", "\n", "    ", "x", "=", "inputs", ".", "view", "(", "inputs", ".", "size", "(", "0", ")", ",", "inputs", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "# New shape: [num_sims, num_atoms, num_timesteps*num_dims]", "\n", "bs", "=", "x", ".", "shape", "[", "0", "]", "\n", "x", "=", "self", ".", "mlp1", "(", "x", ")", "# 2-layer ELU net per node", "\n", "x", "=", "self", ".", "bn1", "(", "x", ".", "reshape", "(", "-", "1", ",", "self", ".", "n_hid", ")", ")", ".", "reshape", "(", "bs", ",", "-", "1", ",", "self", ".", "n_hid", ")", "\n", "x", "=", "self", ".", "node2edge", "(", "x", ",", "rel_rec", ",", "rel_send", ")", "\n", "x", "=", "self", ".", "mlp2", "(", "x", ")", "\n", "x", "=", "self", ".", "bn2", "(", "x", ".", "reshape", "(", "-", "1", ",", "self", ".", "n_hid", ")", ")", ".", "reshape", "(", "bs", ",", "-", "1", ",", "self", ".", "n_hid", ")", "\n", "x_skip", "=", "x", "\n", "x", "=", "self", ".", "edge2node", "(", "x", ",", "rel_rec", ",", "rel_send", ")", "\n", "x", "=", "self", ".", "mlp3", "(", "x", ")", "\n", "x", "=", "self", ".", "bn3", "(", "x", ".", "reshape", "(", "-", "1", ",", "self", ".", "n_hid", ")", ")", ".", "reshape", "(", "bs", ",", "-", "1", ",", "self", ".", "n_hid", ")", "\n", "x", "=", "self", ".", "node2edge", "(", "x", ",", "rel_rec", ",", "rel_send", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "x_skip", ")", ",", "dim", "=", "2", ")", "# Skip connection", "\n", "x", "=", "self", ".", "mlp4", "(", "x", ")", "\n", "x", "=", "self", ".", "bn4", "(", "x", ".", "reshape", "(", "-", "1", ",", "self", ".", "n_hid", ")", ")", ".", "reshape", "(", "bs", ",", "-", "1", ",", "self", ".", "n_hid", ")", "\n", "\n", "return", "F", ".", "softmax", "(", "self", ".", "fc_out", "(", "x", ")", ",", "dim", "=", "2", ")", "#[:,:,1]", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.CNN.__init__": [[176, 191], ["torch.Module.__init__", "torch.MaxPool1d", "torch.MaxPool1d", "torch.MaxPool1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "encoder.CNN.init_weights"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.CNN.init_weights"], ["  ", "def", "__init__", "(", "self", ",", "n_in", ",", "n_hid", ",", "n_out", ",", "do_prob", "=", "0.", ")", ":", "\n", "    ", "super", "(", "CNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool1d", "(", "kernel_size", "=", "2", ",", "stride", "=", "None", ",", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "return_indices", "=", "False", ",", "\n", "ceil_mode", "=", "False", ")", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv1d", "(", "n_in", ",", "n_hid", ",", "kernel_size", "=", "5", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm1d", "(", "n_hid", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv1d", "(", "n_hid", ",", "n_hid", ",", "kernel_size", "=", "5", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm1d", "(", "n_hid", ")", "\n", "self", ".", "conv_predict", "=", "nn", ".", "Conv1d", "(", "n_hid", ",", "n_out", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "conv_attention", "=", "nn", ".", "Conv1d", "(", "n_hid", ",", "1", ",", "kernel_size", "=", "1", ")", "\n", "self", ".", "dropout_prob", "=", "do_prob", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.CNN.init_weights": [[192, 201], ["encoder.CNN.modules", "isinstance", "m.weight.data.normal_", "m.bias.data.fill_", "isinstance", "math.sqrt", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "    ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "      ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv1d", ")", ":", "\n", "        ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.", "/", "n", ")", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0.1", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm1d", ")", ":", "\n", "        ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.CNN.my_softmax": [[202, 207], ["input.transpose().contiguous", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax.transpose", "input.transpose"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "my_softmax", "(", "input", ",", "axis", "=", "1", ")", ":", "\n", "    ", "trans_input", "=", "input", ".", "transpose", "(", "axis", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "soft_max_1d", "=", "F", ".", "softmax", "(", "trans_input", ")", "\n", "return", "soft_max_1d", ".", "transpose", "(", "axis", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.CNN.forward": [[208, 221], ["torch.relu", "torch.relu", "torch.relu", "encoder.CNN.bn1", "torch.dropout", "torch.dropout", "torch.dropout", "encoder.CNN.pool", "torch.relu", "torch.relu", "torch.relu", "encoder.CNN.bn2", "encoder.CNN.conv_predict", "encoder.CNN.my_softmax", "encoder.CNN.conv1", "encoder.CNN.conv2", "encoder.CNN.conv_attention"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.relu", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.relu", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.relu", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.relu", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.relu", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.relu", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.CNN.my_softmax"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "# Input shape: [num_sims * num_edges, num_dims, num_timesteps]", "\n", "    ", "x", "=", "F", ".", "relu", "(", "self", ".", "conv1", "(", "inputs", ")", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "self", ".", "dropout_prob", ",", "training", "=", "self", ".", "training", ")", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv2", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "bn2", "(", "x", ")", "\n", "pred", "=", "self", ".", "conv_predict", "(", "x", ")", "\n", "attention", "=", "self", ".", "my_softmax", "(", "self", ".", "conv_attention", "(", "x", ")", ",", "axis", "=", "2", ")", "\n", "\n", "edge_prob", "=", "(", "pred", "*", "attention", ")", ".", "mean", "(", "dim", "=", "2", ")", "\n", "return", "edge_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.CNNStateEncoder.__init__": [[224, 241], ["encoder.Encoder.__init__", "encoder.CNN", "encoder.MLP", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "encoder.MLP", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "encoder.MLP", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.Linear", "print", "encoder.CNNStateEncoder.init_weights"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.CNN.init_weights"], ["  ", "def", "__init__", "(", "self", ",", "n_in", ",", "n_hid", ",", "n_out", ",", "do_prob", "=", "0.", ")", ":", "\n", "    ", "super", "(", "CNNStateEncoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout_prob", "=", "do_prob", "\n", "\n", "self", ".", "cnn", "=", "CNN", "(", "n_in", "*", "2", ",", "n_hid", ",", "n_hid", ",", "do_prob", ")", "\n", "self", ".", "mlp1", "=", "MLP", "(", "n_hid", ",", "n_hid", ",", "n_hid", ",", "do_prob", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm1d", "(", "n_hid", ")", "\n", "self", ".", "mlp2", "=", "MLP", "(", "n_hid", ",", "n_hid", ",", "n_hid", ",", "do_prob", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm1d", "(", "n_hid", ")", "\n", "self", ".", "mlp3", "=", "MLP", "(", "n_hid", "*", "3", ",", "n_hid", ",", "n_hid", ",", "do_prob", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm1d", "(", "n_hid", ")", "\n", "self", ".", "fc_out", "=", "nn", ".", "Linear", "(", "n_hid", ",", "n_out", ")", "\n", "self", ".", "n_hid", "=", "n_hid", "\n", "\n", "print", "(", "\"Using CNN state encoder, hidden size {}.\"", ".", "format", "(", "n_hid", ")", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.CNNStateEncoder.node2edge_temporal": [[242, 262], ["inputs.view", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "receivers.transpose.transpose.view", "receivers.transpose.transpose.transpose", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "senders.transpose.transpose.view", "senders.transpose.transpose.transpose", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "inputs.size", "inputs.size", "inputs.size", "inputs.size", "inputs.size", "inputs.size", "inputs.size", "receivers.transpose.transpose.size", "inputs.size", "senders.transpose.transpose.size"], "methods", ["None"], ["", "def", "node2edge_temporal", "(", "self", ",", "inputs", ",", "rel_rec", ",", "rel_send", ")", ":", "\n", "# NOTE: Assumes that we have the same graph across all samples.", "\n", "\n", "    ", "x", "=", "inputs", ".", "view", "(", "inputs", ".", "size", "(", "0", ")", ",", "inputs", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "\n", "receivers", "=", "torch", ".", "matmul", "(", "rel_rec", ",", "x", ")", "\n", "receivers", "=", "receivers", ".", "view", "(", "inputs", ".", "size", "(", "0", ")", "*", "receivers", ".", "size", "(", "1", ")", ",", "\n", "inputs", ".", "size", "(", "2", ")", ",", "inputs", ".", "size", "(", "3", ")", ")", "\n", "receivers", "=", "receivers", ".", "transpose", "(", "2", ",", "1", ")", "\n", "\n", "senders", "=", "torch", ".", "matmul", "(", "rel_send", ",", "x", ")", "\n", "senders", "=", "senders", ".", "view", "(", "inputs", ".", "size", "(", "0", ")", "*", "senders", ".", "size", "(", "1", ")", ",", "\n", "inputs", ".", "size", "(", "2", ")", ",", "\n", "inputs", ".", "size", "(", "3", ")", ")", "\n", "senders", "=", "senders", ".", "transpose", "(", "2", ",", "1", ")", "\n", "\n", "# receivers and senders have shape:", "\n", "# [num_sims * num_edges, num_dims, num_timesteps]", "\n", "edges", "=", "torch", ".", "cat", "(", "[", "receivers", ",", "senders", "]", ",", "dim", "=", "1", ")", "\n", "return", "edges", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.CNNStateEncoder.forward": [[263, 280], ["encoder.CNNStateEncoder.node2edge_temporal", "encoder.CNNStateEncoder.cnn", "encoder.CNNStateEncoder.view", "encoder.CNNStateEncoder.bn1().reshape", "encoder.CNNStateEncoder.edge2node", "encoder.CNNStateEncoder.bn2().reshape", "encoder.CNNStateEncoder.node2edge", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "encoder.CNNStateEncoder.bn3().reshape", "torch.softmax", "torch.softmax", "torch.softmax", "inputs.size", "encoder.CNNStateEncoder.fc_out", "inputs.size", "encoder.CNNStateEncoder.bn1", "encoder.CNNStateEncoder.bn2", "encoder.CNNStateEncoder.bn3", "inputs.size", "encoder.CNNStateEncoder.mlp1().reshape", "encoder.CNNStateEncoder.mlp2().reshape", "encoder.CNNStateEncoder.mlp3().reshape", "encoder.CNNStateEncoder.mlp1", "encoder.CNNStateEncoder.mlp2", "encoder.CNNStateEncoder.mlp3"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.CNNStateEncoder.node2edge_temporal", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.Encoder.edge2node", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.Encoder.node2edge"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "rel_rec", ",", "rel_send", ")", ":", "\n", "# Input now has shape: [num_sims, num_atoms, num_timesteps, num_dims]", "\n", "    ", "edges", "=", "self", ".", "node2edge_temporal", "(", "inputs", ",", "rel_rec", ",", "rel_send", ")", "\n", "x", "=", "self", ".", "cnn", "(", "edges", ")", "\n", "x", "=", "x", ".", "view", "(", "inputs", ".", "size", "(", "0", ")", ",", "(", "inputs", ".", "size", "(", "1", ")", "-", "1", ")", "*", "inputs", ".", "size", "(", "1", ")", ",", "-", "1", ")", "\n", "bs", "=", "x", ".", "shape", "[", "0", "]", "\n", "x", "=", "self", ".", "bn1", "(", "self", ".", "mlp1", "(", "x", ")", ".", "reshape", "(", "-", "1", ",", "self", ".", "n_hid", ")", ")", ".", "reshape", "(", "bs", ",", "-", "1", ",", "self", ".", "n_hid", ")", "\n", "x_skip", "=", "x", "\n", "\n", "x", "=", "self", ".", "edge2node", "(", "x", ",", "rel_rec", ",", "rel_send", ")", "\n", "x", "=", "self", ".", "bn2", "(", "self", ".", "mlp2", "(", "x", ")", ".", "reshape", "(", "-", "1", ",", "self", ".", "n_hid", ")", ")", ".", "reshape", "(", "bs", ",", "-", "1", ",", "self", ".", "n_hid", ")", "\n", "\n", "x", "=", "self", ".", "node2edge", "(", "x", ",", "rel_rec", ",", "rel_send", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "x_skip", ")", ",", "dim", "=", "2", ")", "# Skip connection", "\n", "x", "=", "self", ".", "bn3", "(", "self", ".", "mlp3", "(", "x", ")", ".", "reshape", "(", "-", "1", ",", "self", ".", "n_hid", ")", ")", ".", "reshape", "(", "bs", ",", "-", "1", ",", "self", ".", "n_hid", ")", "\n", "\n", "return", "F", ".", "softmax", "(", "self", ".", "fc_out", "(", "x", ")", ",", "dim", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.__init__": [[8, 34], ["len", "sum", "torch.nn.ParameterList", "hasattr", "type", "type", "list", "len", "type", "type", "args.type_modules.split", "map", "type", "type", "type", "type", "str", "type", "type", "type", "type", "args.num_modules.split", "str"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "#Assert module specifications are consistent.", "\n", "    ", "if", "not", "hasattr", "(", "self", ",", "'type_modules'", ")", ":", "self", ".", "type_modules", "=", "[", "]", "\n", "if", "self", ".", "type_modules", "!=", "[", "]", ":", "\n", "      ", "pass", "\n", "", "elif", "type", "(", "args", ".", "type_modules", ")", "==", "type", "(", "''", ")", ":", "\n", "      ", "self", ".", "type_modules", "=", "args", ".", "type_modules", ".", "split", "(", "','", ")", "\n", "", "else", ":", "\n", "      ", "assert", "type", "(", "args", ".", "type_modules", ")", "==", "type", "(", "[", "]", ")", "\n", "assert", "type", "(", "args", ".", "type_modules", "[", "0", "]", ")", "==", "type", "(", "'a'", ")", "\n", "self", ".", "type_modules", "=", "args", ".", "type_modules", "\n", "", "if", "type", "(", "args", ".", "num_modules", ")", "==", "type", "(", "''", ")", ":", "\n", "      ", "self", ".", "num_modules", "=", "list", "(", "map", "(", "int", ",", "\n", "args", ".", "num_modules", ".", "split", "(", "','", ")", ")", ")", "\n", "", "else", ":", "\n", "      ", "assert", "type", "(", "args", ".", "num_modules", ")", "==", "type", "(", "[", "]", ")", "\n", "assert", "type", "(", "args", ".", "num_modules", "[", "0", "]", ")", "==", "type", "(", "1", ")", "\n", "self", ".", "num_modules", "=", "args", ".", "num_modules", "\n", "", "self", ".", "num_types", "=", "len", "(", "self", ".", "num_modules", ")", "\n", "assert", "len", "(", "self", ".", "type_modules", ")", "==", "self", ".", "num_types", ",", "(", "str", "(", "self", ".", "type_modules", ")", "+", "' should have '", "+", "str", "(", "self", ".", "num_types", ")", "+", "' elts.'", ")", "\n", "self", ".", "tot_modules", "=", "sum", "(", "self", ".", "num_modules", ")", "\n", "\n", "self", ".", "usage_normalization", "=", "1e-9", "\n", "self", ".", "has_global_variable", "=", "False", "\n", "self", ".", "StructureParameters", "=", "ParameterList", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.initialize_structure": [[35, 40], ["None"], "methods", ["None"], ["", "def", "initialize_structure", "(", "self", ")", ":", "\n", "    ", "'''\n    Create a random structure\n    '''", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.propose_new_structure": [[41, 46], ["None"], "methods", ["None"], ["", "def", "propose_new_structure", "(", "self", ",", "new_structure", ")", ":", "\n", "    ", "'''\n    Given a structure, new_structure, make a modification\n    '''", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.update_structure": [[47, 53], ["None"], "methods", ["None"], ["", "def", "update_structure", "(", "self", ",", "structure", ",", "step", "=", "None", ")", ":", "\n", "    ", "'''\n    Optional function updating some aspects of the structure\n    for instance to adapt to some parameters that changed by SGD\n    '''", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.update_Usage_counters": [[54, 59], ["None"], "methods", ["None"], ["", "def", "update_Usage_counters", "(", "self", ",", "METRICS", ",", "T", ")", ":", "\n", "    ", "'''\n    Updates table of fraction of times module is used for each dataset.\n    '''", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.modules_given_structure": [[60, 62], ["None"], "methods", ["None"], ["", "def", "modules_given_structure", "(", "self", ",", "structure", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.save_structures": [[63, 70], ["open", "pickle.dump", "open.close", "open", "pickle.dump", "open.close", "os.path.join", "os.path.join"], "methods", ["None"], ["###########################", "\n", "##  Optional functions   ##", "\n", "###########################", "\n", "", "def", "propose_new_global_structure", "(", "self", ")", ":", "\n", "    ", "return", "None", "\n", "\n", "", "def", "save_customized_files", "(", "self", ",", "directory", ")", ":", "\n", "    ", "return", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.load_structures": [[71, 78], ["open", "pickle.load", "open.close", "open", "pickle.load", "open.close", "os.path.join", "os.path.join"], "methods", ["None"], ["\n", "", "def", "get_plot_name", "(", "self", ",", "args", ",", "plot_name", ")", ":", "\n", "    ", "'''\n    Modifies the plot_name\n    '''", "\n", "return", "\n", "\n", "", "def", "update_PosUsage_counters", "(", "self", ",", "METRICS", ")", ":", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.propose_new_global_structure": [[82, 84], ["None"], "methods", ["None"], ["\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.save_customized_files": [[85, 87], ["None"], "methods", ["None"], ["", "def", "update_customized_counters", "(", "self", ",", "METRICS", "=", "None", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.get_plot_name": [[88, 93], ["None"], "methods", ["None"], ["\n", "return", "\n", "\n", "", "def", "update_customized_stats", "(", "self", ",", "BG", "=", "None", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.update_PosUsage_counters": [[94, 100], ["None"], "methods", ["None"], ["\n", "return", "\n", "\n", "", "def", "plot_customized_usage_rate", "(", "self", ",", "directory", "=", "None", ")", ":", "\n", "    ", "return", "\n", "\n", "#####################################################", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.update_customized_counters": [[101, 106], ["None"], "methods", ["None"], ["## Common functions, not expected to be customized ##", "\n", "#####################################################", "\n", "\n", "", "def", "plot_usage", "(", "self", ",", "directory", ")", ":", "\n", "    ", "if", "self", ".", "Usage", "is", "not", "None", ":", "\n", "      ", "cax", "=", "plt", ".", "gca", "(", ")", ".", "matshow", "(", "self", ".", "Usage", "/", "self", ".", "usage_normalization", ")", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.plot_customized_usage_rate": [[107, 109], ["None"], "methods", ["None"], ["plt", ".", "gcf", "(", ")", ".", "colorbar", "(", "cax", ")", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'usage-rate'", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.plot_usage": [[114, 116], ["None"], "methods", ["None"], ["for", "i", "in", "Tqdm", "(", "range", "(", "len", "(", "self", ".", "TrainStructures", ")", ")", ")", ":", "\n", "      ", "self", ".", "TrainStructures", "[", "i", "]", "=", "self", ".", "initialize_structure", "(", ")", "\n", "self", ".", "TrainStructures", "[", "i", "]", "[", "'original_input_shape'", "]", "=", "(", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.initialize_all_structures": [[117, 132], ["tqdm.tqdm.tqdm", "range", "range", "structure.Structure.initialize_structure", "len", "structure.Structure.initialize_structure", "len"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.initialize_structure", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.initialize_structure"], ["T", ".", "MTRAIN", "[", "i", "%", "T", ".", "mtrain", "]", ".", "original_input_shape", ")", "\n", "self", ".", "TrainStructures", "[", "i", "]", "[", "'original_output_shape'", "]", "=", "(", "\n", "T", ".", "MTRAIN", "[", "i", "%", "T", ".", "mtrain", "]", ".", "original_output_shape", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "self", ".", "ValStructures", ")", ")", ":", "\n", "      ", "self", ".", "ValStructures", "[", "i", "]", "=", "self", ".", "initialize_structure", "(", ")", "\n", "self", ".", "ValStructures", "[", "i", "]", "[", "'original_input_shape'", "]", "=", "(", "\n", "T", ".", "MVAL", "[", "i", "]", ".", "original_input_shape", ")", "\n", "self", ".", "ValStructures", "[", "i", "]", "[", "'original_output_shape'", "]", "=", "(", "\n", "T", ".", "MVAL", "[", "i", "]", ".", "original_output_shape", ")", "\n", "\n", "###########################################################", "\n", "## Default functions                                     ##", "\n", "## For some functions, many structures use the same code ##", "\n", "###########################################################", "\n", "\n", "", "", "def", "default_update_Usage_counters", "(", "self", ",", "METRICS", ",", "T", ")", ":", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.default_update_Usage_counters": [[138, 155], ["enumerate", "list", "list.sort", "enumerate", "range", "range"], "methods", ["None"], ["for", "i_s", ",", "structure", "in", "enumerate", "(", "self", ".", "TrainStructures", "+", "self", ".", "ValStructures", ")", ":", "\n", "      ", "for", "m", "in", "structure", "[", "'modules'", "]", ":", "\n", "        ", "self", ".", "Usage", "[", "i_s", "]", "[", "m", "]", "+=", "eps", "\n", "", "", "names", "=", "(", "[", "T", ".", "MTRAIN", "[", "i", "%", "T", ".", "mtrain", "]", ".", "name", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "TrainStructures", ")", ")", "]", "+", "[", "_", ".", "name", "for", "_", "in", "T", ".", "MVAL", "]", ")", "\n", "names", "=", "list", "(", "enumerate", "(", "names", ")", ")", "\n", "names", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "values", "=", "self", ".", "Usage", "[", "[", "_", "[", "0", "]", "for", "_", "in", "names", "]", ",", ":", "]", "\n", "METRICS", "[", "'Usage'", "]", "=", "[", "[", "values", "[", "i", "]", "[", "j", "]", "for", "j", "in", "range", "(", "values", ".", "shape", "[", "1", "]", ")", "]", "\n", "for", "i", "in", "range", "(", "values", ".", "shape", "[", "0", "]", ")", "]", "\n", "METRICS", "[", "'Usage-names'", "]", "=", "[", "_", "[", "1", "]", "for", "_", "in", "names", "]", "\n", "\n", "", "def", "default_initialize_structure", "(", "self", ")", ":", "\n", "    ", "structure", "=", "{", "'modules'", ":", "[", "]", "}", "\n", "for", "i", "in", "range", "(", "self", ".", "structure_size", ")", ":", "\n", "      ", "act_type", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "structure_size", ")", "\n", "act_mod", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "num_modules", "[", "act_type", "]", ")", "\n", "structure", "[", "'modules'", "]", ".", "append", "(", "self", ".", "Modules", "[", "act_type", "]", "[", "act_mod", "]", ")", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.default_initialize_structure": [[156, 163], ["range", "numpy.random.randint", "numpy.random.randint", "structure[].append"], "methods", ["None"], ["", "return", "structure", "\n", "\n", "", "def", "default_initialize_fixed_structure", "(", "self", ")", ":", "\n", "#Position 'i' in the structure can only be filled by a node of type 'i'", "\n", "    ", "assert", "self", ".", "num_types", "==", "self", ".", "structure_size", "\n", "structure", "=", "{", "'modules'", ":", "[", "]", "}", "\n", "for", "i", "in", "range", "(", "self", ".", "num_types", ")", ":", "\n", "      ", "act_type", "=", "i", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.default_initialize_fixed_structure": [[164, 173], ["range", "numpy.random.randint", "structure[].append"], "methods", ["None"], ["act_mod", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "num_modules", "[", "act_type", "]", ")", "\n", "structure", "[", "'modules'", "]", ".", "append", "(", "self", ".", "Modules", "[", "act_type", "]", "[", "act_mod", "]", ")", "\n", "", "return", "structure", "\n", "\n", "", "def", "default_propose_new_structure", "(", "self", ",", "new_structure", ")", ":", "\n", "    ", "pos", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "new_structure", "[", "'modules'", "]", ")", ")", "\n", "act_type", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "num_types", ")", "\n", "act_mod", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "num_modules", "[", "act_type", "]", ")", "\n", "new_structure", "[", "'modules'", "]", "[", "pos", "]", "=", "self", ".", "Modules", "[", "act_type", "]", "[", "act_mod", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.default_propose_new_structure": [[174, 179], ["numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "len"], "methods", ["None"], ["", "def", "default_propose_new_fixed_structure", "(", "self", ",", "new_structure", ")", ":", "\n", "#Position 'i' in the structure can only be filled by a node of type 'i'", "\n", "    ", "pos", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "new_structure", "[", "'modules'", "]", ")", ")", "\n", "act_type", "=", "pos", "\n", "act_mod", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "num_modules", "[", "act_type", "]", ")", "\n", "new_structure", "[", "'modules'", "]", "[", "pos", "]", "=", "self", ".", "Modules", "[", "act_type", "]", "[", "act_mod", "]", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.default_propose_new_fixed_structure": [[180, 186], ["numpy.random.randint", "numpy.random.randint", "len"], "methods", ["None"], ["", "", ""]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_main.main": [[5, 151], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "composer.startswith", "modular_metalearning.BounceGrad", "modular_metalearning.BounceGrad.SAConfig_SGDModules", "GNN_Structure", "composer.startswith", "hgnn_composer.HGNN_Structure", "composer.startswith", "composer.split", "int", "Sum_Structure", "composer.startswith", "composer.split", "int", "FunctionComposition_Structure"], "function", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.SAConfig_SGDModules"], ["\n", "from", "sum_composer", "import", "Sum_Structure", "\n", "from", "functioncomposition_composer", "import", "FunctionComposition_Structure", "\n", "\n", "def", "main", "(", ")", ":", "\n", "#########", "\n", "# Flags #", "\n", "#########", "\n", "  ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "# Compute flags", "\n", "parser", ".", "add_argument", "(", "'--device'", ",", "dest", "=", "'nn_device'", ",", "default", "=", "'cuda:0'", ",", "\n", "help", "=", "'what device we want to run things in'", ")", "\n", "# Data flags", "\n", "parser", ".", "add_argument", "(", "'--data_desc'", ",", "dest", "=", "'data_desc'", ",", "\n", "help", "=", "'description of data source'", ")", "\n", "parser", ".", "add_argument", "(", "'--limit_data'", ",", "dest", "=", "'limit_data'", ",", "type", "=", "int", ",", "\n", "help", "=", "'maximum number of points per dataset'", ",", "default", "=", "10000", ")", "\n", "parser", ".", "add_argument", "(", "'--max_datasets'", ",", "dest", "=", "'max_datasets'", ",", "type", "=", "int", ",", "\n", "default", "=", "256", ",", "help", "=", "'maximum number of datasets'", ")", "\n", "parser", ".", "add_argument", "(", "'--data_split'", ",", "dest", "=", "'data_split'", ",", "default", "=", "'20,80,0'", ",", "\n", "help", "=", "'comma-separated distribution (in %) of train,val,test per dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--meta_split'", ",", "dest", "=", "'meta_split'", ",", "default", "=", "'90,10,0'", ",", "\n", "help", "=", "'comma-separated distribution (in %) of mtrain,mval,mtest'", ")", "\n", "parser", ".", "add_argument", "(", "'--split_by_file'", ",", "dest", "=", "'split_by_file'", ",", "\n", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--smaller_MVals'", ",", "dest", "=", "'smaller_MVals'", ",", "type", "=", "str", ",", "\n", "default", "=", "''", ",", "help", "=", "'List of extra smaller training sizes for MVal'", ")", "\n", "parser", ".", "add_argument", "(", "'--dont_normalize'", ",", "dest", "=", "'normalize_data'", ",", "\n", "action", "=", "'store_false'", ")", "\n", "\n", "# BounceGrad flags", "\n", "parser", ".", "add_argument", "(", "'--torch_seed'", ",", "dest", "=", "'torch_seed'", ",", "type", "=", "int", ",", "\n", "default", "=", "0", ",", "help", "=", "'random seed for pytorch'", ")", "\n", "parser", ".", "add_argument", "(", "'--mtrain_copies'", ",", "dest", "=", "'mtrain_copies'", ",", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "help", "=", "'number of copies of meta-train, searching multiple \\\n                  structures in parallel'", ")", "\n", "parser", ".", "add_argument", "(", "'--dont_bounce'", ",", "dest", "=", "'do_bounce'", ",", "action", "=", "'store_false'", ",", "\n", "help", "=", "'Skip Simulated Annealing and proposing structures; only Grad step'", ")", "\n", "parser", ".", "add_argument", "(", "'--meta_lr'", ",", "dest", "=", "'meta_lr'", ",", "type", "=", "float", ",", "default", "=", "'1e-3'", ",", "\n", "help", "=", "'learning rate for module parameters'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_modules'", ",", "dest", "=", "'num_modules'", ",", "\n", "help", "=", "'comma-separated list with size of each population of module type'", ")", "\n", "parser", ".", "add_argument", "(", "'--type_modules'", ",", "dest", "=", "'type_modules'", ",", "\n", "help", "=", "'comma-separated list describing the type of each module category'", ")", "\n", "parser", ".", "add_argument", "(", "'--composer'", ",", "dest", "=", "'composer'", ",", "default", "=", "'composition'", ",", "\n", "help", "=", "'Which type of composition to use; \\\n          for example \"compositon,sum,concatenate,gnn\"'", ")", "\n", "parser", ".", "add_argument", "(", "'--optimization_steps'", ",", "dest", "=", "'optimization_steps'", ",", "\n", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "'number of BounceGrad steps'", ")", "\n", "parser", ".", "add_argument", "(", "'--meta_batch_size'", ",", "dest", "=", "'meta_batch_size'", ",", "type", "=", "int", ",", "\n", "default", "=", "0", ",", "help", "=", "'Number of metatrain cases between gradient steps;\\\n          0 if all MTRAIN'", ")", "\n", "\n", "# MAML flags", "\n", "parser", ".", "add_argument", "(", "'--MAML'", ",", "dest", "=", "'MAML'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'MAML loss instead of conventional loss'", ")", "\n", "parser", ".", "add_argument", "(", "'--MAML_inner_updates'", ",", "dest", "=", "'MAML_inner_updates'", ",", "\n", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'number of gradient steps in the inner loop'", ")", "\n", "parser", ".", "add_argument", "(", "'--MAML_step_size'", ",", "dest", "=", "'MAML_step_size'", ",", "type", "=", "float", ",", "\n", "default", "=", "1e-2", ",", "help", "=", "'step size in MAML gradient steps'", ")", "\n", "\n", "# Plotting flags", "\n", "parser", ".", "add_argument", "(", "'--plot_name'", ",", "dest", "=", "'plot_name'", ",", "\n", "default", "=", "'default'", ",", "help", "=", "'Name for error plot'", ")", "\n", "parser", ".", "add_argument", "(", "'--store_video'", ",", "dest", "=", "'store_video'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'Store images every step into video folder'", ")", "\n", "parser", ".", "add_argument", "(", "'--plot_ymax'", ",", "dest", "=", "'plot_ymax'", ",", "type", "=", "float", ",", "\n", "default", "=", "-", "1.", ",", "help", "=", "'maximum y in zoomed loss plot'", ")", "\n", "parser", ".", "add_argument", "(", "'--plot_freq'", ",", "dest", "=", "'plot_freq'", ",", "type", "=", "int", ",", "\n", "default", "=", "5", ",", "help", "=", "'Number of optimization steps between plots'", ")", "\n", "\n", "# Flags mostly useful for restarting experiments", "\n", "parser", ".", "add_argument", "(", "'--load_modules'", ",", "dest", "=", "'load_modules'", ",", "type", "=", "str", ",", "\n", "default", "=", "''", ",", "help", "=", "'Filepath to load modules from self.L;\\\n          empty if dont want to load'", ")", "\n", "parser", ".", "add_argument", "(", "'--load_structures_and_metrics'", ",", "\n", "dest", "=", "'load_structures_and_metrics'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'Filepath to load structures and metrics;\\\n          empty if dont want to load'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_modules'", ",", "dest", "=", "'save_modules'", ",", "type", "=", "str", ",", "\n", "default", "=", "''", ",", "help", "=", "'Filepath to save modules from self.L;\\\n          if empty use plot_name'", ")", "\n", "parser", ".", "add_argument", "(", "'--initial_temp'", ",", "dest", "=", "'initial_temp'", ",", "type", "=", "float", ",", "\n", "default", "=", "0", ",", "help", "=", "'[log] initial temperature'", ")", "\n", "parser", ".", "add_argument", "(", "'--initial_acc'", ",", "dest", "=", "'initial_acc'", ",", "type", "=", "float", ",", "\n", "default", "=", "0", ",", "help", "=", "'[log] initial acceptance ratio'", ")", "\n", "\n", "# Parsing args", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# Tensorboard writer", "\n", "tensorboardX_writer", "=", "SummaryWriter", "(", "\n", "comment", "=", "'composer='", "+", "args", ".", "composer", "+", "\n", "'_optsteps='", "+", "str", "(", "args", ".", "optimization_steps", ")", "+", "\n", "'_copies='", "+", "str", "(", "args", ".", "mtrain_copies", ")", "+", "\n", "'_data='", "+", "args", ".", "data_desc", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "+", "'_'", "+", "\n", "str", "(", "args", ".", "meta_lr", ")", ")", "\n", "\n", "# Finding composer", "\n", "composer", "=", "args", ".", "composer", "\n", "if", "composer", ".", "startswith", "(", "'sum'", ")", ":", "\n", "    ", "[", "composer", ",", "args", ".", "structure_size", "]", "=", "composer", ".", "split", "(", "'-'", ")", "\n", "args", ".", "structure_size", "=", "int", "(", "args", ".", "structure_size", ")", "\n", "S", "=", "Sum_Structure", "(", "args", "=", "args", ")", "\n", "", "elif", "composer", ".", "startswith", "(", "'functionComposition'", ")", ":", "\n", "    ", "[", "composer", ",", "args", ".", "structure_size", "]", "=", "composer", ".", "split", "(", "'-'", ")", "\n", "args", ".", "structure_size", "=", "int", "(", "args", ".", "structure_size", ")", "\n", "S", "=", "FunctionComposition_Structure", "(", "args", "=", "args", ")", "\n", "", "else", ":", "raise", "NotImplementedError", "\n", "\n", "bg", "=", "BounceGrad", "(", "S", "=", "S", ",", "args", "=", "args", ",", "tensorboardX_writer", "=", "tensorboardX_writer", ")", "\n", "bg", ".", "SAConfig_SGDModules", "(", "args", ".", "optimization_steps", ")", "\n", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "  ", "main", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.Dataset.__init__": [[29, 34], ["None"], "methods", ["None"], ["  ", "def", "__init__", "(", "self", ",", "train", ",", "val", ",", "test", ",", "name", "=", "None", ")", ":", "\n", "    ", "self", ".", "train", "=", "train", "\n", "self", ".", "val", "=", "val", "\n", "self", ".", "test", "=", "test", "\n", "self", ".", "name", "=", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaDataset.__getitem__": [[42, 44], ["None"], "methods", ["None"], ["  ", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "    ", "return", "self", ".", "ALL", "[", "idx", "]", "#.data", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaDataset.__len__": [[45, 47], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "    ", "return", "len", "(", "self", ".", "ALL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaDataset.__init__": [[48, 104], ["data_loading.MetaDataset.create_datasets", "numpy.random.RandomState", "data_loading.MetaDataset.apply_normalization", "len", "data_loading.MetaDataset.MTRAIN.sort", "data_loading.MetaDataset.MVAL.sort", "data_loading.MetaDataset.MTEST.sort", "type", "type", "numpy.random.RandomState", "data_loading.MetaDataset.apply_output_normalization", "max", "str", "data_loading.MetaDataset.add_smaller_cases", "str", "str", "max"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaHDFDataset.create_datasets", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaDataset.apply_normalization", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaDataset.apply_output_normalization", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaDataset.add_smaller_cases"], ["", "def", "__init__", "(", "self", ",", "\n", "train", ",", "val", ",", "test", ",", "\n", "limit_data", "=", "-", "1", ",", "smaller_MVals", "=", "[", "]", ",", "max_datasets", "=", "1e9", ",", "\n", "train_val_are_all", "=", "False", ",", "\n", "filename", "=", "None", ",", "normalize_output", "=", "False", ",", "normalize", "=", "False", ",", "\n", "mtrain", "=", "None", ",", "mval", "=", "None", ",", "mtest", "=", "None", ",", "\n", "RS", "=", "None", ",", "split_by_file", "=", "None", ")", ":", "\n", "\n", "#Random state", "\n", "    ", "if", "RS", "is", "None", ":", "self", ".", "RS", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "SEED", ")", "\n", "elif", "type", "(", "RS", ")", "==", "type", "(", "1", ")", ":", "self", ".", "RS", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "RS", ")", "\n", "else", ":", "self", ".", "RS", "=", "RS", "\n", "# proportion of datasets in each split", "\n", "self", ".", "mtrain", "=", "mtrain", "\n", "self", ".", "mval", "=", "mval", "\n", "self", ".", "mtest", "=", "mtest", "\n", "# proportion of data in each split", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "val", "=", "val", "\n", "self", ".", "test", "=", "test", "\n", "\n", "# whether to make train data == val data and exclude test", "\n", "self", ".", "train_val_are_all", "=", "train_val_are_all", "\n", "\n", "# Other customizations", "\n", "self", ".", "max_datasets", "=", "max_datasets", "\n", "self", ".", "limit_data", "=", "limit_data", "\n", "self", ".", "normalize", "=", "normalize", "\n", "self", ".", "normalize_output", "=", "normalize_output", "\n", "self", ".", "smaller_MVals", "=", "smaller_MVals", "\n", "self", ".", "split_by_file", "=", "split_by_file", "\n", "\n", "# Create data", "\n", "self", ".", "create_datasets", "(", "filename", ")", "\n", "assert", "self", ".", "MTRAIN", "is", "not", "None", "and", "self", ".", "MVAL", "is", "not", "None", "and", "self", ".", "MTEST", "is", "not", "None", "and", "self", ".", "ALL", "is", "not", "None", "\n", "\n", "if", "self", ".", "normalize", ":", "\n", "      ", "self", ".", "apply_normalization", "(", ")", "\n", "", "elif", "self", ".", "normalize_output", ":", "\n", "      ", "self", ".", "apply_output_normalization", "(", ")", "\n", "\n", "", "if", "self", ".", "smaller_MVals", "!=", "[", "]", ":", "\n", "      ", "assert", "max", "(", "self", ".", "smaller_MVals", ")", "<", "self", ".", "MVAL", "[", "0", "]", ".", "train", ",", "(", "\n", "'all smaller_MVals should be  smaller than train'", "+", "\n", "str", "(", "max", "(", "self", ".", "smaller_MVals", ")", ")", "+", "' vs '", "+", "str", "(", "self", ".", "MVAL", "[", "0", "]", ".", "train", ")", ")", "\n", "self", ".", "prev_mval", "=", "self", ".", "mval", "\n", "for", "dataset", "in", "self", ".", "MVAL", ":", "\n", "        ", "if", "dataset", ".", "name", "is", "not", "None", ":", "dataset", ".", "name", "+=", "'_'", "+", "str", "(", "dataset", ".", "train", ")", "\n", "", "for", "train_sz", "in", "self", ".", "smaller_MVals", ":", "\n", "        ", "self", ".", "add_smaller_cases", "(", "self", ".", "prev_mval", ",", "train_sz", ")", "\n", "", "self", ".", "mval", "=", "len", "(", "self", ".", "MVAL", ")", "\n", "\n", "", "if", "self", ".", "MTRAIN", "[", "0", "]", ".", "name", "is", "not", "None", ":", "\n", "      ", "self", ".", "MTRAIN", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", ".", "name", ")", "\n", "self", ".", "MVAL", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", ".", "name", ")", "\n", "self", ".", "MTEST", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaDataset.add_smaller_cases": [[105, 118], ["range", "copy.deepcopy", "copy.deepcopy.name.split", "data_loading.MetaDataset.ALL.append", "data_loading.MetaDataset.MVAL.append", "str"], "methods", ["None"], ["", "", "def", "add_smaller_cases", "(", "self", ",", "old_idx", ",", "new_train", ")", ":", "\n", "    ", "'''\n    Creates new cases with smaller training and appends them to self.MVAL\n    '''", "\n", "for", "i", "in", "range", "(", "old_idx", ")", ":", "\n", "      ", "aux", "=", "copy", ".", "deepcopy", "(", "self", ".", "MVAL", "[", "i", "]", ")", "\n", "name", "=", "aux", ".", "name", ".", "split", "(", "'_'", ")", "\n", "aux", ".", "train", "=", "new_train", "\n", "aux", ".", "TrainInput", "=", "aux", ".", "TrainInput", "[", ":", "aux", ".", "train", "]", "\n", "aux", ".", "TrainOutput", "=", "aux", ".", "TrainOutput", "[", ":", "aux", ".", "train", "]", "\n", "aux", ".", "name", "=", "'_'", ".", "join", "(", "name", "[", ":", "-", "1", "]", "+", "[", "str", "(", "aux", ".", "train", ")", "]", ")", "\n", "self", ".", "ALL", ".", "append", "(", "aux", ")", "\n", "self", ".", "MVAL", ".", "append", "(", "self", ".", "ALL", "[", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaDataset.apply_output_normalization": [[119, 149], ["numpy.concatenate", "numpy.mean", "numpy.maximum", "print", "print", "numpy.concatenate", "numpy.mean", "numpy.maximum", "print", "print", "numpy.std", "numpy.std", "copy.deepcopy", "copy.deepcopy"], "methods", ["None"], ["", "", "def", "apply_output_normalization", "(", "self", ")", ":", "\n", "    ", "'''\n    Applies normalization to all inputs and all outputs in MetaDataset\n    at the same time\n    '''", "\n", "# Check all inputs and all outputs have the same size", "\n", "out_shape", "=", "self", ".", "MTRAIN", "[", "0", "]", ".", "TrainOutput", ".", "shape", "[", "1", "]", "\n", "for", "dataset", "in", "self", ".", "ALL", ":", "\n", "      ", "assert", "dataset", ".", "TestOutput", ".", "shape", "[", "1", "]", "==", "out_shape", "\n", "# Compute mean and std", "\n", "", "ALL_OUT", "=", "np", ".", "concatenate", "(", "[", "dataset", ".", "ValOutput", "for", "dataset", "in", "self", ".", "MVAL", "]", ",", "0", ")", "\n", "self", ".", "output_mean", "=", "np", ".", "mean", "(", "ALL_OUT", ",", "0", ")", "\n", "self", ".", "output_std", "=", "np", ".", "maximum", "(", "EPS", ",", "np", ".", "std", "(", "ALL_OUT", ",", "0", ")", ")", "\n", "print", "(", "'MVAL Output mean: '", ",", "self", ".", "output_mean", ")", "\n", "print", "(", "'MVAL Output std: '", ",", "self", ".", "output_std", ")", "\n", "\n", "ALL_OUT", "=", "np", ".", "concatenate", "(", "[", "dataset", ".", "ValOutput", "for", "dataset", "in", "self", ".", "MTRAIN", "]", ",", "0", ")", "\n", "self", ".", "output_mean", "=", "np", ".", "mean", "(", "ALL_OUT", ",", "0", ")", "\n", "self", ".", "output_std", "=", "np", ".", "maximum", "(", "EPS", ",", "np", ".", "std", "(", "ALL_OUT", ",", "0", ")", ")", "\n", "print", "(", "'Output mean: '", ",", "self", ".", "output_mean", ")", "\n", "print", "(", "'Output std: '", ",", "self", ".", "output_std", ")", "\n", "\n", "for", "dataset", "in", "self", ".", "ALL", ":", "\n", "# Copy unnormalized versions", "\n", "      ", "dataset", ".", "UTrainOutput", "=", "copy", ".", "deepcopy", "(", "dataset", ".", "TrainOutput", ")", "\n", "dataset", ".", "UValOutput", "=", "copy", ".", "deepcopy", "(", "dataset", ".", "ValOutput", ")", "\n", "\n", "dataset", ".", "TrainOutput", "=", "(", "dataset", ".", "TrainOutput", "-", "self", ".", "output_mean", ")", "/", "self", ".", "output_std", "\n", "dataset", ".", "ValOutput", "=", "(", "dataset", ".", "ValOutput", "-", "self", ".", "output_mean", ")", "/", "self", ".", "output_std", "\n", "dataset", ".", "TestOutput", "=", "(", "dataset", ".", "TestOutput", "-", "self", ".", "output_mean", ")", "/", "self", ".", "output_std", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaDataset.apply_normalization": [[150, 197], ["numpy.concatenate", "numpy.concatenate", "numpy.mean", "numpy.maximum", "numpy.mean", "numpy.maximum", "print", "print", "print", "print", "numpy.concatenate", "numpy.concatenate", "numpy.mean", "numpy.maximum", "numpy.mean", "numpy.maximum", "print", "print", "print", "print", "numpy.std", "numpy.std", "numpy.std", "numpy.std", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy"], "methods", ["None"], ["", "", "def", "apply_normalization", "(", "self", ")", ":", "\n", "    ", "'''\n    Applies normalization to all inputs and all outputs in MetaDataset\n    at the same time\n    '''", "\n", "# Check all inputs and all outputs have the same size", "\n", "inp_shape", "=", "self", ".", "MTRAIN", "[", "0", "]", ".", "TrainInput", ".", "shape", "[", "1", "]", "\n", "out_shape", "=", "self", ".", "MTRAIN", "[", "0", "]", ".", "TrainOutput", ".", "shape", "[", "1", "]", "\n", "for", "dataset", "in", "self", ".", "ALL", ":", "\n", "      ", "assert", "dataset", ".", "TrainInput", ".", "shape", "[", "1", "]", "==", "inp_shape", "\n", "assert", "dataset", ".", "TestOutput", ".", "shape", "[", "1", "]", "==", "out_shape", "\n", "# Compute mean and std", "\n", "", "ALL_IN", "=", "np", ".", "concatenate", "(", "[", "dataset", ".", "ValInput", "for", "dataset", "in", "self", ".", "MVAL", "]", ",", "0", ")", "\n", "ALL_OUT", "=", "np", ".", "concatenate", "(", "[", "dataset", ".", "ValOutput", "for", "dataset", "in", "self", ".", "MVAL", "]", ",", "0", ")", "\n", "self", ".", "input_mean", "=", "np", ".", "mean", "(", "ALL_IN", ",", "0", ")", "\n", "self", ".", "input_std", "=", "np", ".", "maximum", "(", "EPS", ",", "np", ".", "std", "(", "ALL_IN", ",", "0", ")", ")", "\n", "self", ".", "output_mean", "=", "np", ".", "mean", "(", "ALL_OUT", ",", "0", ")", "\n", "self", ".", "output_std", "=", "np", ".", "maximum", "(", "EPS", ",", "np", ".", "std", "(", "ALL_OUT", ",", "0", ")", ")", "\n", "print", "(", "'MVAL Input mean: '", ",", "self", ".", "input_mean", ")", "\n", "print", "(", "'MVAL Input std: '", ",", "self", ".", "input_std", ")", "\n", "print", "(", "'MVAL Output mean: '", ",", "self", ".", "output_mean", ")", "\n", "print", "(", "'MVAL Output std: '", ",", "self", ".", "output_std", ")", "\n", "\n", "ALL_IN", "=", "np", ".", "concatenate", "(", "[", "dataset", ".", "ValInput", "for", "dataset", "in", "self", ".", "MTRAIN", "]", ",", "0", ")", "\n", "ALL_OUT", "=", "np", ".", "concatenate", "(", "[", "dataset", ".", "ValOutput", "for", "dataset", "in", "self", ".", "MTRAIN", "]", ",", "0", ")", "\n", "self", ".", "input_mean", "=", "np", ".", "mean", "(", "ALL_IN", ",", "0", ")", "\n", "self", ".", "input_std", "=", "np", ".", "maximum", "(", "EPS", ",", "np", ".", "std", "(", "ALL_IN", ",", "0", ")", ")", "\n", "self", ".", "output_mean", "=", "np", ".", "mean", "(", "ALL_OUT", ",", "0", ")", "\n", "self", ".", "output_std", "=", "np", ".", "maximum", "(", "EPS", ",", "np", ".", "std", "(", "ALL_OUT", ",", "0", ")", ")", "\n", "print", "(", "'Input mean: '", ",", "self", ".", "input_mean", ")", "\n", "print", "(", "'Input std: '", ",", "self", ".", "input_std", ")", "\n", "print", "(", "'Output mean: '", ",", "self", ".", "output_mean", ")", "\n", "print", "(", "'Output std: '", ",", "self", ".", "output_std", ")", "\n", "\n", "for", "dataset", "in", "self", ".", "ALL", ":", "\n", "# Copy unnormalized versions", "\n", "      ", "dataset", ".", "UTrainInput", "=", "copy", ".", "deepcopy", "(", "dataset", ".", "TrainInput", ")", "\n", "dataset", ".", "UTrainOutput", "=", "copy", ".", "deepcopy", "(", "dataset", ".", "TrainOutput", ")", "\n", "dataset", ".", "UValInput", "=", "copy", ".", "deepcopy", "(", "dataset", ".", "ValInput", ")", "\n", "dataset", ".", "UValOutput", "=", "copy", ".", "deepcopy", "(", "dataset", ".", "ValOutput", ")", "\n", "\n", "dataset", ".", "TrainInput", "=", "(", "dataset", ".", "TrainInput", "-", "self", ".", "input_mean", ")", "/", "self", ".", "input_std", "\n", "dataset", ".", "TrainOutput", "=", "(", "dataset", ".", "TrainOutput", "-", "self", ".", "output_mean", ")", "/", "self", ".", "output_std", "\n", "dataset", ".", "ValInput", "=", "(", "dataset", ".", "ValInput", "-", "self", ".", "input_mean", ")", "/", "self", ".", "input_std", "\n", "dataset", ".", "ValOutput", "=", "(", "dataset", ".", "ValOutput", "-", "self", ".", "output_mean", ")", "/", "self", ".", "output_std", "\n", "dataset", ".", "TestInput", "=", "(", "dataset", ".", "TestInput", "-", "self", ".", "input_mean", ")", "/", "self", ".", "input_std", "\n", "dataset", ".", "TestOutput", "=", "(", "dataset", ".", "TestOutput", "-", "self", ".", "output_mean", ")", "/", "self", ".", "output_std", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaDataset.normalize_input": [[198, 200], ["None"], "methods", ["None"], ["", "", "def", "normalize_input", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "(", "x", "-", "self", ".", "input_mean", ")", "/", "self", ".", "input_std", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaDataset.denormalize_input": [[201, 203], ["None"], "methods", ["None"], ["", "def", "denormalize_input", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "self", ".", "input_mean", "+", "self", ".", "input_std", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaDataset.normalize_output": [[204, 206], ["None"], "methods", ["None"], ["", "def", "normalize_output", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "(", "x", "-", "self", ".", "output_mean", ")", "/", "self", ".", "output_std", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaDataset.denormalize_output": [[207, 209], ["None"], "methods", ["None"], ["", "def", "denormalize_output", "(", "self", ",", "x", ")", ":", "\n", "    ", "return", "self", ".", "output_mean", "+", "self", ".", "output_std", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaDataset.create_datasets": [[210, 213], ["NotImplementedError"], "methods", ["None"], ["", "def", "create_datasets", "(", "self", ",", "filename", ")", ":", "\n", "# Populates self.ALL, self.MTRAIN, self.MVAL, self.MTEST", "\n", "    ", "raise", "NotImplementedError", "(", "\"please subclass MetaDataset\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.NPDataset.__init__": [[216, 280], ["data_loading.Dataset.__init__", "numpy.array_equal", "abs", "int", "int", "round", "round", "min"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__"], ["  ", "def", "__init__", "(", "self", ",", "\n", "input_data", ",", "output_data", ",", "\n", "train", ",", "val", ",", "test", ",", "\n", "train_val_are_all", ",", "\n", "name", "=", "None", ",", "limit", "=", "-", "1", ",", "\n", "edge_data", "=", "None", ",", "structure_idx", "=", "None", ")", ":", "\n", "# input_data, output_data are np arrays", "\n", "    ", "super", "(", "NPDataset", ",", "self", ")", ".", "__init__", "(", "train", "=", "train", ",", "val", "=", "val", ",", "test", "=", "test", ",", "name", "=", "name", ")", "\n", "\n", "# Handle input/output with more than 2 dims,", "\n", "# compress to 2, but remember.", "\n", "self", ".", "original_input_shape", "=", "input_data", ".", "shape", "\n", "self", ".", "original_output_shape", "=", "output_data", ".", "shape", "\n", "\n", "# structure associated with this dataset", "\n", "self", ".", "structure_idx", "=", "structure_idx", "\n", "\n", "assert", "input_data", ".", "shape", "[", "0", "]", "==", "output_data", ".", "shape", "[", "0", "]", "\n", "if", "limit", ">=", "0", ":", "\n", "      ", "input_data", "=", "input_data", "[", ":", "limit", ",", ":", "]", "\n", "output_data", "=", "output_data", "[", ":", "limit", ",", ":", "]", "\n", "", "len_data", "=", "input_data", ".", "shape", "[", "0", "]", "\n", "if", "abs", "(", "train", "+", "val", "+", "test", "-", "1.", ")", "<", "1e-6", ":", "\n", "      ", "self", ".", "train", "=", "int", "(", "round", "(", "len_data", "*", "train", ")", ")", "\n", "self", ".", "val", "=", "int", "(", "round", "(", "len_data", "*", "val", ")", ")", "\n", "self", ".", "test", "=", "len_data", "-", "self", ".", "train", "-", "self", ".", "val", "\n", "assert", "self", ".", "train", "+", "self", ".", "val", "+", "self", ".", "test", "==", "len_data", "\n", "assert", "min", "(", "[", "self", ".", "train", ",", "self", ".", "val", ",", "self", ".", "test", "]", ")", ">=", "0", "\n", "\n", "", "if", "train_val_are_all", ":", "\n", "      ", "self", ".", "train", "=", "len_data", "\n", "self", ".", "val", "=", "len_data", "\n", "self", ".", "test", "=", "0", "\n", "self", ".", "TrainInput", "=", "input_data", "\n", "self", ".", "TrainOutput", "=", "output_data", "\n", "self", ".", "ValInput", "=", "input_data", "\n", "self", ".", "ValOutput", "=", "output_data", "\n", "self", ".", "TestInput", "=", "input_data", "[", ":", "0", "]", "\n", "self", ".", "TestOutput", "=", "output_data", "[", ":", "0", "]", "\n", "", "else", ":", "\n", "      ", "self", ".", "TrainInput", "=", "input_data", "[", ":", "self", ".", "train", "]", "\n", "self", ".", "TrainOutput", "=", "output_data", "[", ":", "self", ".", "train", "]", "\n", "self", ".", "ValInput", "=", "input_data", "[", "self", ".", "train", ":", "self", ".", "train", "+", "self", ".", "val", "]", "\n", "self", ".", "ValOutput", "=", "output_data", "[", "self", ".", "train", ":", "self", ".", "train", "+", "self", ".", "val", "]", "\n", "self", ".", "TestInput", "=", "input_data", "[", "self", ".", "train", "+", "self", ".", "val", ":", "]", "\n", "self", ".", "TestOutput", "=", "output_data", "[", "self", ".", "train", "+", "self", ".", "val", ":", "]", "\n", "\n", "", "self", ".", "Edges", "=", "edge_data", "\n", "\n", "if", "np", ".", "array_equal", "(", "self", ".", "TrainInput", ",", "self", ".", "TrainOutput", ")", ":", "\n", "# self.TrainInput = self.TrainInput[:-1]", "\n", "      ", "self", ".", "TrainOutput", "=", "self", ".", "TrainOutput", "[", "1", ":", "]", "\n", "# self.ValInput = self.ValInput[:-1]", "\n", "self", ".", "ValOutput", "=", "self", ".", "ValOutput", "[", "1", ":", "]", "\n", "# self.TestInput = self.TestInput[:-1]", "\n", "self", ".", "TestOutput", "=", "self", ".", "TestOutput", "[", "1", ":", "]", "\n", "self", ".", "train", "=", "self", ".", "TrainInput", ".", "shape", "[", "0", "]", "\n", "self", ".", "val", "=", "self", ".", "ValInput", ".", "shape", "[", "0", "]", "\n", "self", ".", "test", "=", "self", ".", "TestInput", ".", "shape", "[", "0", "]", "\n", "", "self", ".", "Train", "=", "[", "self", ".", "TrainInput", ",", "self", ".", "TrainOutput", "]", "\n", "self", ".", "Val", "=", "[", "self", ".", "ValInput", ",", "self", ".", "ValOutput", "]", "\n", "self", ".", "Test", "=", "[", "self", ".", "TestInput", ",", "self", ".", "TestOutput", "]", "\n", "\n", "self", ".", "All", "=", "[", "input_data", ",", "output_data", ",", "edge_data", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaNpySelfRegressDataset._create_meta_dataset": [[290, 304], ["min", "range", "min", "list_to_append.append", "data_loading.NPDataset"], "methods", ["None"], ["def", "_create_meta_dataset", "(", "self", ",", "array", ",", "edges", ",", "names", ",", "train_val_are_all", "=", "False", ",", "hard_max_datasets", "=", "1e10", ")", ":", "\n", "    ", "'''\n    From an array of shape [n,...] creates many datasets\n    '''", "\n", "list_to_append", "=", "[", "]", "\n", "max_datasets", "=", "min", "(", "self", ".", "max_datasets", ",", "hard_max_datasets", ")", "\n", "for", "i", "in", "range", "(", "min", "(", "array", ".", "shape", "[", "0", "]", ",", "max_datasets", ")", ")", ":", "\n", "      ", "list_to_append", ".", "append", "(", "NPDataset", "(", "\n", "input_data", "=", "array", "[", "i", "]", ",", "output_data", "=", "array", "[", "i", "]", ",", "edge_data", "=", "edges", "[", "i", "]", ",", "\n", "structure_idx", "=", "i", ",", "#limit=48,", "\n", "train", "=", "self", ".", "train", ",", "val", "=", "self", ".", "val", ",", "test", "=", "self", ".", "test", ",", "\n", "train_val_are_all", "=", "train_val_are_all", ",", "\n", "name", "=", "names", "[", "i", "]", ")", ")", "\n", "", "return", "list_to_append", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaNpySelfRegressDataset.create_datasets": [[305, 357], ["numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "data_loading.MetaNpySelfRegressDataset._create_meta_dataset", "data_loading.MetaNpySelfRegressDataset._create_meta_dataset", "data_loading.MetaNpySelfRegressDataset._create_meta_dataset", "len", "len", "len", "numpy.delete().reshape", "map", "numpy.stack().reshape", "len", "A.reshape", "numpy.split", "str", "range", "str", "range", "str", "range", "max", "numpy.delete", "x.squeeze", "numpy.stack", "range", "numpy.sqrt().astype", "list", "map", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaNpySelfRegressDataset._create_meta_dataset", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaNpySelfRegressDataset._create_meta_dataset", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaNpySelfRegressDataset._create_meta_dataset"], ["", "def", "create_datasets", "(", "self", ",", "filename", ")", ":", "\n", "    ", "'''\n    Populates self.ALL, self.MTRAIN, self.MVAL, self.MTEST\n    '''", "\n", "# (num_datasets, num_nodes, num_traj_steps, input_dims)", "\n", "MTrainArray", "=", "np", ".", "load", "(", "'data/state_'", "+", "filename", "+", "'_train.npy'", ")", "\n", "MValArray", "=", "np", ".", "load", "(", "'data/state_'", "+", "filename", "+", "'_val.npy'", ")", "\n", "MTestArray", "=", "np", ".", "load", "(", "'data/state_'", "+", "filename", "+", "'_test.npy'", ")", "\n", "\n", "# import ipdb; ipdb.set_trace()", "\n", "\n", "# (num datasets, num connections (minus diagonals)", "\n", "MTrainEdges", "=", "np", ".", "load", "(", "'data/edges_'", "+", "filename", "+", "'_train.npy'", ")", "\n", "MValEdges", "=", "np", ".", "load", "(", "'data/edges_'", "+", "filename", "+", "'_val.npy'", ")", "\n", "MTestEdges", "=", "np", ".", "load", "(", "'data/edges_'", "+", "filename", "+", "'_test.npy'", ")", "\n", "\n", "# get rid of self-edges from Edges labels", "\n", "def", "delete_single_diagonal", "(", "A", ")", ":", "\n", "      ", "''' deletes A's diagonal (removing self-edges)'''", "\n", "return", "np", ".", "delete", "(", "A", ",", "range", "(", "0", ",", "A", ".", "shape", "[", "0", "]", "**", "2", ",", "(", "A", ".", "shape", "[", "0", "]", "+", "1", ")", ")", ")", ".", "reshape", "(", "A", ".", "shape", "[", "0", "]", ",", "(", "A", ".", "shape", "[", "1", "]", "-", "1", ")", ")", "\n", "\n", "", "def", "delete_self_edges", "(", "A", ")", ":", "\n", "      ", "''' makes A into a list of square matrices representing the graph's adjacency\n      matrix of edge module types, then makes each square matrix into a n x (n-1) matrix\n      by deleting its diagonal (removing self-edges), then reshapes them to original shape[0]'''", "\n", "if", "len", "(", "A", ".", "shape", ")", "==", "2", ":", "\n", "        ", "adj_mat", "=", "A", ".", "reshape", "(", "(", "A", ".", "shape", "[", "0", "]", ",", "np", ".", "sqrt", "(", "A", ".", "shape", "[", "1", "]", ")", ".", "astype", "(", "int", ")", ",", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "        ", "adj_mat", "=", "A", "\n", "", "split_squeezed", "=", "map", "(", "lambda", "x", ":", "x", ".", "squeeze", "(", "0", ")", ",", "np", ".", "split", "(", "adj_mat", ",", "adj_mat", ".", "shape", "[", "0", "]", ")", ")", "\n", "return", "np", ".", "stack", "(", "list", "(", "map", "(", "delete_single_diagonal", ",", "split_squeezed", ")", ")", ")", ".", "reshape", "(", "A", ".", "shape", "[", "0", "]", ",", "-", "1", ")", "\n", "\n", "\n", "", "for", "edges_data", "in", "[", "MTrainEdges", ",", "MValEdges", ",", "MTestEdges", "]", ":", "\n", "      ", "edges_data", "[", "edges_data", "==", "-", "1", "]", "=", "0", ",", "\n", "\n", "\n", "", "MTrainNames", "=", "[", "'train_'", "+", "str", "(", "i", ")", "for", "i", "in", "range", "(", "MTrainArray", ".", "shape", "[", "0", "]", ")", "]", "\n", "MValNames", "=", "[", "'val_'", "+", "str", "(", "i", ")", "for", "i", "in", "range", "(", "MValArray", ".", "shape", "[", "0", "]", ")", "]", "\n", "MTestNames", "=", "[", "'test_'", "+", "str", "(", "i", ")", "for", "i", "in", "range", "(", "MTestArray", ".", "shape", "[", "0", "]", ")", "]", "\n", "\n", "self", ".", "MTRAIN", "=", "self", ".", "_create_meta_dataset", "(", "MTrainArray", ",", "MTrainEdges", ",", "MTrainNames", ",", "\n", "train_val_are_all", "=", "True", ")", "\n", "self", ".", "MTEST", "=", "self", ".", "_create_meta_dataset", "(", "MValArray", ",", "MValEdges", ",", "MValNames", ",", "\n", "hard_max_datasets", "=", "max", "(", "250", ",", "self", ".", "max_datasets", "//", "4", ")", ")", "\n", "self", ".", "MVAL", "=", "self", ".", "_create_meta_dataset", "(", "MTestArray", ",", "MTestEdges", ",", "MTestNames", ",", "\n", "hard_max_datasets", "=", "self", ".", "max_datasets", ")", "\n", "self", ".", "ALL", "=", "self", ".", "MTRAIN", "+", "self", ".", "MVAL", "+", "self", ".", "MTEST", "\n", "\n", "self", ".", "mtrain", "=", "len", "(", "self", ".", "MTRAIN", ")", "\n", "self", ".", "mtest", "=", "len", "(", "self", ".", "MVAL", ")", "\n", "self", ".", "mval", "=", "len", "(", "self", ".", "MTEST", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.MetaHDFDataset.create_datasets": [[361, 441], ["h5py.File", "print", "print", "min", "int", "int", "int", "list", "random.shuffle", "print", "print", "name.replace", "len", "len", "data_loading.MetaHDFDataset.RS.choice", "min", "len", "round", "round", "zip", "min", "num_datasets_hist.append", "range", "data_loading.MetaHDFDataset.RS.shuffle", "len", "len", "len", "sorted", "sorted", "len", "pdb.set_trace", "print", "data_loading.MetaHDFDataset.RS.get_state", "data_loading.MetaHDFDataset.RS.shuffle", "data_loading.MetaHDFDataset.RS.set_state", "data_loading.MetaHDFDataset.RS.shuffle", "list_to_append.append", "list", "list", "enumerate", "enumerate", "len", "len", "len", "data_loading.NPDataset", "key.replace", "h5py.File.keys", "h5py.File.keys", "len", "len"], "methods", ["None"], ["  ", "def", "create_datasets", "(", "self", ",", "filename", ")", ":", "\n", "    ", "'''\n    Populates self.ALL, self.MTRAIN, self.MVAL, self.MTEST\n    '''", "\n", "#Read HDF5", "\n", "f", "=", "h5py", ".", "File", "(", "filename", ",", "'r'", ")", "\n", "DATA", "=", "[", "[", "f", "[", "key", "]", ",", "f", "[", "key", ".", "replace", "(", "'IN'", ",", "'OUT'", ")", "]", "]", "\n", "for", "key", "in", "sorted", "(", "list", "(", "f", ".", "keys", "(", ")", ")", ")", "if", "'IN'", "in", "key", "]", "\n", "NAMES", "=", "[", "name", ".", "replace", "(", "'-IN'", ",", "''", ")", "\n", "for", "name", "in", "sorted", "(", "list", "(", "f", ".", "keys", "(", ")", ")", ")", "if", "'IN'", "in", "name", "]", "\n", "print", "(", "'Names = '", ",", "NAMES", "[", ":", "10", "]", ")", "\n", "print", "(", "'Num datasets = '", ",", "len", "(", "NAMES", ")", ")", "\n", "\n", "#DATA contains a list of 'object'=datasets", "\n", "self", ".", "mval_fraction", ",", "self", ".", "mtest_fraction", "=", "self", ".", "mval", ",", "self", ".", "mtest", "\n", "if", "self", ".", "max_datasets", "<", "len", "(", "DATA", ")", ":", "\n", "#Subsample DATA randomly", "\n", "      ", "subsampled_idx", "=", "self", ".", "RS", ".", "choice", "(", "len", "(", "DATA", ")", ",", "size", "=", "self", ".", "max_datasets", ",", "\n", "replace", "=", "False", ")", "\n", "DATA", "=", "[", "d", "for", "(", "i_d", ",", "d", ")", "in", "enumerate", "(", "DATA", ")", "if", "i_d", "in", "subsampled_idx", "]", "\n", "NAMES", "=", "[", "d", "for", "(", "i_d", ",", "d", ")", "in", "enumerate", "(", "NAMES", ")", "if", "i_d", "in", "subsampled_idx", "]", "\n", "\n", "", "self", ".", "limit_data", "=", "min", "(", "self", ".", "limit_data", ",", "DATA", "[", "0", "]", "[", "0", "]", "[", "(", ")", "]", ".", "shape", "[", "0", "]", ")", "\n", "tot_datasets", "=", "min", "(", "DATA", "[", "0", "]", "[", "0", "]", "[", "(", ")", "]", ".", "shape", "[", "0", "]", "//", "self", ".", "limit_data", ",", "\n", "self", ".", "max_datasets", "//", "len", "(", "DATA", ")", ")", "*", "len", "(", "DATA", ")", "\n", "self", ".", "mval", "=", "int", "(", "round", "(", "self", ".", "mval", "*", "tot_datasets", ")", ")", "\n", "self", ".", "mtest", "=", "int", "(", "round", "(", "self", ".", "mtest", "*", "tot_datasets", ")", ")", "\n", "self", ".", "mtrain", "=", "int", "(", "tot_datasets", "-", "self", ".", "mtest", "-", "self", ".", "mval", ")", "\n", "assert", "self", ".", "mtrain", ">", "0", "\n", "self", ".", "ALL", "=", "[", "]", "\n", "num_datasets_hist", "=", "[", "]", "\n", "\n", "self", ".", "MTRAIN", "=", "[", "]", "\n", "self", ".", "MVAL", "=", "[", "]", "\n", "self", ".", "MTEST", "=", "[", "]", "\n", "num_datasets_hist", "=", "[", "]", "\n", "shuffled_pairs", "=", "list", "(", "zip", "(", "NAMES", ",", "DATA", ")", ")", "\n", "random", ".", "shuffle", "(", "shuffled_pairs", ")", "\n", "for", "(", "name", ",", "data", ")", "in", "shuffled_pairs", ":", "\n", "      ", "input_data", "=", "data", "[", "0", "]", "[", "(", ")", "]", "\n", "output_data", "=", "data", "[", "1", "]", "[", "(", ")", "]", "\n", "num_datasets", "=", "min", "(", "input_data", ".", "shape", "[", "0", "]", "//", "self", ".", "limit_data", ",", "\n", "self", ".", "max_datasets", "//", "len", "(", "DATA", ")", ")", "\n", "num_datasets_hist", ".", "append", "(", "num_datasets", ")", "\n", "if", "num_datasets", "==", "0", ":", "\n", "        ", "import", "pdb", ";", "pdb", ".", "set_trace", "(", ")", "\n", "print", "(", "name", "+", "' has no datasets'", ")", ";", "continue", "\n", "", "if", "False", ":", "#self.shuffle:", "\n", "#Shuffle in unison", "\n", "        ", "rng_state", "=", "self", ".", "RS", ".", "get_state", "(", ")", "\n", "self", ".", "RS", ".", "shuffle", "(", "input_data", ")", "\n", "self", ".", "RS", ".", "set_state", "(", "rng_state", ")", "\n", "self", ".", "RS", ".", "shuffle", "(", "output_data", ")", "\n", "", "list_to_append", "=", "self", ".", "ALL", "#same for all datasets created from this file", "\n", "if", "self", ".", "split_by_file", ":", "\n", "        ", "if", "len", "(", "self", ".", "MTRAIN", ")", "<", "self", ".", "mtrain", ":", "list_to_append", "=", "self", ".", "MTRAIN", "\n", "elif", "len", "(", "self", ".", "MVAL", ")", "<", "self", ".", "mval", ":", "list_to_append", "=", "self", ".", "MVAL", "\n", "elif", "len", "(", "self", ".", "MTEST", ")", "<", "self", ".", "mtest", ":", "list_to_append", "=", "self", ".", "MTEST", "\n", "else", ":", "assert", "False", ",", "'something doesnt add up'", "\n", "# print(num_datasets)", "\n", "", "for", "k", "in", "range", "(", "num_datasets", ")", ":", "\n", "        ", "list_to_append", ".", "append", "(", "NPDataset", "(", "\n", "input_data", "=", "input_data", "[", "k", "*", "self", ".", "limit_data", ":", "(", "k", "+", "1", ")", "*", "self", ".", "limit_data", "]", ",", "\n", "output_data", "=", "output_data", "[", "k", "*", "self", ".", "limit_data", ":", "(", "k", "+", "1", ")", "*", "self", ".", "limit_data", "]", ",", "\n", "train_val_are_all", "=", "False", ",", "\n", "name", "=", "name", ",", "train", "=", "self", ".", "train", ",", "val", "=", "self", ".", "val", ",", "test", "=", "self", ".", "test", ",", "\n", "structure_idx", "=", "k", ")", ")", "\n", "", "", "if", "self", ".", "split_by_file", ":", "\n", "      ", "self", ".", "ALL", "=", "self", ".", "MTRAIN", "+", "self", ".", "MVAL", "+", "self", ".", "MTEST", "\n", "", "else", ":", "\n", "      ", "self", ".", "RS", ".", "shuffle", "(", "self", ".", "ALL", ")", "\n", "[", "self", ".", "MTRAIN", ",", "self", ".", "MTEST", ",", "self", ".", "MVAL", "]", "=", "[", "\n", "self", ".", "ALL", "[", ":", "self", ".", "mtrain", "]", ",", "\n", "self", ".", "ALL", "[", "self", ".", "mtrain", ":", "self", ".", "mtrain", "+", "self", ".", "mtest", "]", ",", "\n", "self", ".", "ALL", "[", "self", ".", "mtrain", "+", "self", ".", "mtest", ":", "]", "]", "\n", "", "print", "(", "'Goal meta sizes: '", ",", "self", ".", "mtrain", ",", "self", ".", "mval", ",", "self", ".", "mtest", ")", "\n", "(", "self", ".", "mtrain", ",", "self", ".", "mval", ",", "self", ".", "mtest", ")", "=", "(", "\n", "len", "(", "self", ".", "MTRAIN", ")", ",", "len", "(", "self", ".", "MVAL", ")", ",", "len", "(", "self", ".", "MTEST", ")", ")", "\n", "print", "(", "'Final meta sizes: '", ",", "self", ".", "mtrain", ",", "self", ".", "mval", ",", "self", ".", "mtest", ")", "\n", "return", "self", ".", "ALL", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.convert_to_torch_tensors": [[444, 460], ["copy.deepcopy", "enumerate", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "function", ["None"], ["", "", "def", "convert_to_torch_tensors", "(", "np_dataset", ",", "nn_device", ")", ":", "\n", "  ", "torch_dataset", "=", "copy", ".", "deepcopy", "(", "np_dataset", ")", "\n", "for", "i", ",", "dataset", "in", "enumerate", "(", "torch_dataset", ".", "ALL", ")", ":", "\n", "    ", "torch_dataset", ".", "ALL", "[", "i", "]", ".", "TrainInput", "=", "(", "\n", "torch", ".", "from_numpy", "(", "dataset", ".", "TrainInput", ")", ".", "float", "(", ")", ".", "to", "(", "nn_device", ")", ")", "\n", "torch_dataset", ".", "ALL", "[", "i", "]", ".", "TrainOutput", "=", "(", "\n", "torch", ".", "from_numpy", "(", "dataset", ".", "TrainOutput", ")", ".", "float", "(", ")", ".", "to", "(", "nn_device", ")", ")", "\n", "torch_dataset", ".", "ALL", "[", "i", "]", ".", "ValInput", "=", "(", "\n", "torch", ".", "from_numpy", "(", "dataset", ".", "ValInput", ")", ".", "float", "(", ")", ".", "to", "(", "nn_device", ")", ")", "\n", "torch_dataset", ".", "ALL", "[", "i", "]", ".", "ValOutput", "=", "(", "\n", "torch", ".", "from_numpy", "(", "dataset", ".", "ValOutput", ")", ".", "float", "(", ")", ".", "to", "(", "nn_device", ")", ")", "\n", "torch_dataset", ".", "ALL", "[", "i", "]", ".", "TestInput", "=", "(", "\n", "torch", ".", "from_numpy", "(", "dataset", ".", "TestInput", ")", ".", "float", "(", ")", ".", "to", "(", "nn_device", ")", ")", "\n", "torch_dataset", ".", "ALL", "[", "i", "]", ".", "TestOutput", "=", "(", "\n", "torch", ".", "from_numpy", "(", "dataset", ".", "TestOutput", ")", ".", "float", "(", ")", ".", "to", "(", "nn_device", ")", ")", "\n", "", "return", "torch_dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.get_data_loaders": [[462, 486], ["len", "list", "torch.utils.data.Subset", "torch.utils.data.Subset", "torch.utils.data.Subset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "len", "torch.utils.data.DataLoader"], "function", ["None"], ["", "def", "get_data_loaders", "(", "dataset", ",", "batch_size", "=", "32", ",", "shuffle", "=", "True", ")", ":", "\n", "\n", "# Creating data indices for training and validation splits:", "\n", "  ", "dataset_size", "=", "len", "(", "dataset", ")", "\n", "indices", "=", "list", "(", "range", "(", "dataset_size", ")", ")", "\n", "\n", "train_indices", ",", "val_indices", ",", "test_indices", "=", "indices", "[", ":", "dataset", ".", "mtrain", "]", ",", "indices", "[", "dataset", ".", "mtrain", ":", "dataset", ".", "mtrain", "+", "dataset", ".", "mval", "]", ",", "indices", "[", "dataset", ".", "mtrain", "+", "dataset", ".", "mval", ":", "]", "\n", "\n", "train_dataset", "=", "Subset", "(", "dataset", ",", "train_indices", ")", "\n", "val_dataset", "=", "Subset", "(", "dataset", ",", "val_indices", ")", "\n", "test_dataset", "=", "Subset", "(", "dataset", ",", "test_indices", ")", "\n", "\n", "def", "collate", "(", "batch", ")", ":", "\n", "    ", "return", "batch", "\n", "\n", "", "custom_collate", "=", "collate", "\n", "\n", "train_loader", "=", "DataLoader", "(", "train_dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "shuffle", ",", "collate_fn", "=", "custom_collate", ")", "\n", "val_loader", "=", "DataLoader", "(", "val_dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "shuffle", ",", "collate_fn", "=", "custom_collate", ")", "\n", "test_loader", "=", "DataLoader", "(", "test_dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "shuffle", ",", "collate_fn", "=", "custom_collate", ")", "if", "len", "(", "test_dataset", ".", "indices", ")", "else", "None", "\n", "\n", "return", "train_loader", ",", "val_loader", ",", "test_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.__init__": [[17, 104], ["torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.device", "torch.device", "torch.device", "torch.device", "print", "print", "numpy.exp", "modular_metalearning.BounceGrad.initialize_dataset", "modular_metalearning.BounceGrad.initialize_modules", "print", "tensorboardX.SummaryWriter", "os.path.join", "torch.set_default_tensor_type", "torch.set_default_tensor_type", "torch.set_default_tensor_type", "torch.set_default_tensor_type", "torch.set_default_tensor_type", "torch.set_default_tensor_type", "torch.set_default_tensor_type", "torch.set_default_tensor_type", "torch.get_num_threads", "torch.get_num_threads", "torch.get_num_threads", "torch.get_num_threads", "torch.set_num_threads", "torch.set_num_threads", "torch.set_num_threads", "torch.set_num_threads", "torch.get_num_threads", "torch.get_num_threads", "torch.get_num_threads", "torch.get_num_threads", "list", "modular_metalearning.BounceGrad.initialize_encoder", "modular_metalearning.BounceGrad.get_filename", "modular_metalearning.BounceGrad.get_filename", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "map", "map", "map", "modular_metalearning.BounceGrad.S.draw_new_edges_for_node", "args.smaller_MVals.split", "args.meta_split.split", "args.data_split.split", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.initialize_dataset", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.initialize_modules", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.initialize_encoder", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.get_filename", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.get_filename", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.draw_new_edges_for_node"], ["from", "tqdm", "import", "tqdm", "as", "Tqdm", "\n", "import", "os", "\n", "import", "shutil", "\n", "\n", "\n", "class", "BounceGrad", "(", "object", ")", ":", "\n", "  ", "def", "__init__", "(", "self", ",", "S", ",", "args", ",", "tensorboardX_writer", "=", "None", ")", ":", "\n", "##############################", "\n", "# Parse parameters from args #", "\n", "##############################", "\n", "    ", "self", ".", "S", "=", "S", "\n", "self", ".", "composer", "=", "args", ".", "composer", "\n", "#MAML parameters", "\n", "self", ".", "MAML", "=", "args", ".", "MAML", "\n", "self", ".", "MAML_loss_fn", "=", "(", "lambda", "x", ",", "y", ":", "torch", ".", "mean", "(", "(", "x", "-", "y", ")", "**", "2", ")", ")", "\n", "self", ".", "MAML_inner_updates", "=", "args", ".", "MAML_inner_updates", "\n", "self", ".", "MAML_step_size", "=", "args", ".", "MAML_step_size", "\n", "\n", "# Device", "\n", "if", "not", "torch", ".", "cuda", ".", "is_available", "(", ")", "or", "args", ".", "nn_device", "==", "'cpu'", ":", "\n", "      ", "self", ".", "nn_device", "=", "'cpu'", "\n", "torch", ".", "set_default_tensor_type", "(", "'torch.FloatTensor'", ")", "\n", "", "else", ":", "\n", "      ", "self", ".", "nn_device", "=", "args", ".", "nn_device", "\n", "torch", ".", "set_default_tensor_type", "(", "'torch.cuda.FloatTensor'", ")", "\n", "", "torch", ".", "device", "(", "self", ".", "nn_device", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "torch_seed", ")", "\n", "\n", "#Other parameters", "\n", "self", ".", "mtrain_copies", "=", "args", ".", "mtrain_copies", "\n", "self", ".", "normalize_data", "=", "args", ".", "normalize_data", "\n", "self", ".", "do_bounce", "=", "args", ".", "do_bounce", "\n", "self", ".", "meta_lr", "=", "args", ".", "meta_lr", "\n", "self", ".", "initial_temp", "=", "args", ".", "initial_temp", "\n", "self", ".", "initial_acc", "=", "args", ".", "initial_acc", "\n", "self", ".", "execute_gd_every", "=", "args", ".", "meta_batch_size", "\n", "self", ".", "smaller_MVals", "=", "(", "list", "(", "map", "(", "int", ",", "args", ".", "smaller_MVals", ".", "split", "(", "','", ")", ")", ")", "\n", "if", "args", ".", "smaller_MVals", "!=", "''", "else", "[", "]", ")", "\n", "self", ".", "split_by_file", "=", "args", ".", "split_by_file", "\n", "self", ".", "limit_data", "=", "args", ".", "limit_data", "\n", "self", ".", "max_datasets", "=", "args", ".", "max_datasets", "\n", "self", ".", "data_split", "=", "[", "x", "/", "100", "for", "x", "in", "map", "(", "int", ",", "args", ".", "data_split", ".", "split", "(", "','", ")", ")", "]", "\n", "self", ".", "meta_split", "=", "[", "x", "/", "100", "for", "x", "in", "map", "(", "int", ",", "args", ".", "meta_split", ".", "split", "(", "','", ")", ")", "]", "\n", "\n", "self", ".", "load_modules", "=", "args", ".", "load_modules", "\n", "self", ".", "load_structures_and_metrics", "=", "args", ".", "load_structures_and_metrics", "\n", "self", ".", "save_modules", "=", "args", ".", "save_modules", "\n", "if", "len", "(", "self", ".", "save_modules", ")", ">", "0", "and", "self", ".", "save_modules", "[", "-", "1", "]", "!=", "'/'", ":", "\n", "      ", "self", ".", "save_modules", "+=", "'/'", "#make it a folder", "\n", "\n", "#Create dataset and modules", "\n", "", "self", ".", "data_desc", "=", "args", ".", "data_desc", "\n", "self", ".", "create_dataset", "(", ")", "\n", "self", ".", "create_modules", "(", ")", "\n", "self", ".", "optimization_steps", "=", "args", ".", "optimization_steps", "#num. of BOUNCE-GRAD steps", "\n", "\n", "#Automatic plot_name", "\n", "self", ".", "get_plot_name", "(", "args", ")", "\n", "if", "self", ".", "save_modules", "==", "''", ":", "\n", "      ", "self", ".", "save_modules", "=", "self", ".", "plot_name", "\n", "print", "(", "'Saving modules to '", ",", "self", ".", "plot_name", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "plot_name", ")", ":", "shutil", ".", "rmtree", "(", "self", ".", "plot_name", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "plot_name", ")", "\n", "self", ".", "store_video", "=", "args", ".", "store_video", "\n", "if", "self", ".", "store_video", ":", "\n", "      ", "os", ".", "makedirs", "(", "self", ".", "plot_name", "+", "'/video'", ")", "\n", "#Metrics", "\n", "", "self", ".", "writer", "=", "tensorboardX_writer", "\n", "self", ".", "METRICS", "=", "{", "}", "\n", "keys_that_are_empty_lists", "=", "[", "'NumberToWords'", "]", "\n", "for", "k", "in", "keys_that_are_empty_lists", ":", "self", ".", "METRICS", "[", "k", "]", "=", "[", "]", "\n", "self", ".", "METRICS", "[", "'WordsToNumber'", "]", "=", "{", "}", "\n", "self", ".", "METRICS", "[", "'Sharing'", "]", "=", "[", "[", "0.", "for", "_", "in", "range", "(", "50", ")", "]", "for", "__", "in", "range", "(", "50", ")", "]", "\n", "self", ".", "last_comb", "=", "None", "\n", "self", ".", "last_comb_eval", "=", "None", "\n", "self", ".", "current", "=", "None", "\n", "self", ".", "current_Mtrain", "=", "None", "\n", "self", ".", "current_Meval", "=", "None", "\n", "self", ".", "perm_sample_modules", "=", "None", "\n", "self", ".", "perm_sample_fns", "=", "None", "\n", "self", ".", "plot_ymax", "=", "args", ".", "plot_ymax", "\n", "self", ".", "plot_freq", "=", "args", ".", "plot_freq", "\n", "\n", "#Structure params", "\n", "self", ".", "S", ".", "Usage", "=", "np", ".", "zeros", "(", "(", "self", ".", "mtrain_copies", "*", "self", ".", "T", ".", "mtrain", "+", "self", ".", "T", ".", "mval", ",", "len", "(", "self", ".", "L", ")", ")", ")", "\n", "self", ".", "S", ".", "save_customized_files", "(", "directory", "=", "self", ".", "plot_name", ")", "\n", "\n", "", "def", "get_plot_name", "(", "self", ",", "args", ")", ":", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.get_filename": [[105, 122], ["socket.gethostname", "time.strftime", "hasattr", "modular_metalearning.BounceGrad.data_source.split", "map"], "methods", ["None"], ["    ", "shorter_data_desc", "=", "self", ".", "data_desc", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "if", "len", "(", "shorter_data_desc", ")", "<", "4", ":", "shorter_data_desc", "=", "self", ".", "data_desc", "[", "-", "4", ":", "]", "\n", "self", ".", "plot_name", "=", "shorter_data_desc", "+", "'_'", "\n", "self", ".", "plot_name", "+=", "self", ".", "S", ".", "composer_abbreviation", "+", "'_'", "\n", "if", "self", ".", "MAML", ":", "\n", "      ", "if", "max", "(", "self", ".", "S", ".", "num_modules", ")", ">", "1", ":", "self", ".", "plot_name", "+=", "'MOMA'", "\n", "else", ":", "self", ".", "plot_name", "+=", "'MAML'", "\n", "", "else", ":", "\n", "      ", "if", "max", "(", "self", ".", "S", ".", "num_modules", ")", ">", "1", ":", "self", ".", "plot_name", "+=", "'SA'", "\n", "else", ":", "self", ".", "plot_name", "+=", "'BIGNET'", "\n", "", "self", ".", "plot_name", "+=", "'_'", "+", "str", "(", "self", ".", "limit_data", ")", "+", "'_'", "+", "str", "(", "self", ".", "max_datasets", ")", "\n", "nn_size", "=", "0", "\n", "for", "net", "in", "self", ".", "S", ".", "type_modules", ":", "#dumb hash of module sizes", "\n", "      ", "aux", "=", "net", ".", "split", "(", "'-'", ")", "\n", "for", "num", "in", "aux", ":", "\n", "        ", "try", ":", "int_num", "=", "int", "(", "num", ")", "\n", "except", ":", "int_num", "=", "0", "\n", "nn_size", "+=", "int_num", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad._encode_onehot": [[123, 134], ["len", "numpy.zeros", "len", "set", "numpy.arange"], "methods", ["None"], ["", "", "self", ".", "plot_name", "+=", "'_NNS'", "+", "str", "(", "nn_size", ")", "\n", "if", "self", ".", "split_by_file", ":", "\n", "      ", "self", ".", "plot_name", "+=", "'_split'", "\n", "", "else", ":", "self", ".", "plot_name", "+=", "'_file=shuffled'", "\n", "self", ".", "plot_name", "+=", "'_steps='", "+", "str", "(", "self", ".", "optimization_steps", ")", "\n", "self", ".", "plot_name", "+=", "'_lr='", "+", "str", "(", "self", ".", "meta_lr", ")", "\n", "self", ".", "plot_name", "+=", "'_Mupdt='", "+", "str", "(", "self", ".", "MAML_inner_updates", ")", "\n", "self", ".", "plot_name", "+=", "'_copies='", "+", "str", "(", "self", ".", "mtrain_copies", ")", "\n", "print", "(", "'plot_name: '", ",", "self", ".", "plot_name", ")", "\n", "if", "args", ".", "plot_name", ".", "startswith", "(", "'overwrite-'", ")", ":", "\n", "      ", "self", ".", "plot_name", "=", "'-'", ".", "join", "(", "args", ".", "plot_name", ".", "split", "(", "'-'", ")", "[", "1", ":", "]", ")", "\n", "print", "(", "'Args overwrote plot name to:'", ",", "self", ".", "plot_name", ")", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.initialize_encoder": [[135, 165], ["numpy.array", "numpy.array", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.BCELoss", "torch.nn.BCELoss", "torch.optim.SGD", "torch.optim.SGD", "encoder.MLPStateEncoder", "numpy.ones", "numpy.eye", "modular_metalearning.BounceGrad._encode_onehot", "modular_metalearning.BounceGrad._encode_onehot", "modular_metalearning.BounceGrad.encoder.parameters", "torch.nn.BCELoss", "torch.nn.BCELoss", "torch.optim.SGD", "torch.optim.SGD", "encoder.CNNStateEncoder", "modular_metalearning.BounceGrad.encoder2.parameters", "encoder.MLPStructureEncoder", "numpy.where", "numpy.where", "encoder.MLPStateEncoder", "encoder.MLPStructureEncoder", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad._encode_onehot", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad._encode_onehot"], ["", "elif", "args", ".", "plot_name", "==", "'dummy'", ":", "\n", "      ", "ans", "=", "input", "(", "'Want to change plot_name to dummy?'", ")", "\n", "if", "ans", ".", "lower", "(", ")", "in", "[", "'y'", ",", "'yes'", "]", ":", "\n", "        ", "print", "(", "'Changed to dummy'", ")", "\n", "self", ".", "plot_name", "=", "'dummy'", "\n", "", "else", ":", "print", "(", "'Keeping automatic name'", ")", "\n", "", "elif", "args", ".", "plot_name", "==", "'default'", ":", "\n", "      ", "input", "(", "'I will not keep your name, see above'", ")", "\n", "", "else", ":", "self", ".", "plot_name", "=", "args", ".", "plot_name", "+", "'__'", "+", "self", ".", "plot_name", "\n", "self", ".", "S", ".", "get_plot_name", "(", "args", ",", "self", ".", "plot_name", ")", "\n", "if", "self", ".", "plot_name", "[", "-", "1", "]", "!=", "'/'", ":", "self", ".", "plot_name", "+=", "'/'", "\n", "\n", "", "def", "create_modules", "(", "self", ")", ":", "\n", "    ", "'''\n    Creates modules following num_modules and type_modules\n    '''", "\n", "self", ".", "L", "=", "nn", ".", "ModuleList", "(", ")", "#Library of PyTorch Modules", "\n", "self", ".", "S", ".", "Modules", "=", "[", "]", "\n", "self", ".", "nn_inp", "=", "[", "]", "\n", "self", ".", "nn_out", "=", "[", "]", "\n", "self", ".", "nn_hid", "=", "[", "]", "\n", "self", ".", "nn_act", "=", "[", "]", "\n", "for", "(", "t", ",", "(", "num", ",", "typ", ")", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "S", ".", "num_modules", ",", "self", ".", "S", ".", "type_modules", ")", ")", ":", "\n", "      ", "l", "=", "[", "]", "\n", "#'final_act'-#inp-#hid1-#hid2-...-#out", "\n", "#example: 'affine-123-64-64-42'", "\n", "typ_split", "=", "typ", ".", "split", "(", "'-'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "typ_split", ")", ")", ":", "\n", "        ", "try", ":", "\n", "          ", "typ_split", "[", "i", "]", "=", "int", "(", "typ_split", "[", "i", "]", ")", "\n", "", "except", ":", "pass", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.initialize_modules": [[166, 204], ["torch.nn.ModuleList", "torch.nn.ModuleList", "enumerate", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.ReduceLROnPlateau", "torch.optim.lr_scheduler.ReduceLROnPlateau", "zip", "typ.split", "range", "modular_metalearning.BounceGrad.nn_act.append", "modular_metalearning.BounceGrad.nn_inp.append", "modular_metalearning.BounceGrad.nn_hid.append", "modular_metalearning.BounceGrad.nn_out.append", "range", "modular_metalearning.BounceGrad.S.Modules.append", "modular_metalearning.BounceGrad.load_L", "modular_metalearning.BounceGrad.L.parameters", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "len", "custom_module.torch_NN().to", "l.append", "modular_metalearning.BounceGrad.L.append", "m.parameters", "int", "len", "custom_module.torch_NN"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.load_L"], ["", "self", ".", "nn_act", ".", "append", "(", "typ_split", "[", "0", "]", ")", "\n", "self", ".", "nn_inp", ".", "append", "(", "typ_split", "[", "1", "]", ")", "\n", "self", ".", "nn_hid", ".", "append", "(", "typ_split", "[", "2", ":", "-", "1", "]", ")", "\n", "self", ".", "nn_out", ".", "append", "(", "typ_split", "[", "-", "1", "]", ")", "\n", "for", "_", "in", "range", "(", "num", ")", ":", "\n", "        ", "aux_nn", "=", "torch_NN", "(", "inp", "=", "self", ".", "nn_inp", "[", "t", "]", ",", "out", "=", "self", ".", "nn_out", "[", "t", "]", ",", "\n", "hidden", "=", "self", ".", "nn_hid", "[", "t", "]", ",", "\n", "final_act", "=", "self", ".", "nn_act", "[", "t", "]", ")", ".", "to", "(", "device", "=", "self", ".", "nn_device", ")", "\n", "l", ".", "append", "(", "len", "(", "self", ".", "L", ")", ")", "\n", "self", ".", "L", ".", "append", "(", "aux_nn", ")", "\n", "", "self", ".", "S", ".", "Modules", ".", "append", "(", "l", ")", "\n", "", "if", "self", ".", "load_modules", "!=", "''", ":", "self", ".", "load_L", "(", "self", ".", "load_modules", ")", "\n", "self", ".", "SOpt", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "L", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "meta_lr", ")", "\n", "self", ".", "SOpt_scheduler", "=", "ReduceLROnPlateau", "(", "\n", "optimizer", "=", "self", ".", "SOpt", ",", "factor", "=", "1", "/", "2.", ",", "\n", "mode", "=", "'min'", ",", "patience", "=", "50", ",", "threshold", "=", "0", ",", "cooldown", "=", "300", ",", "verbose", "=", "True", ",", "\n", "min_lr", "=", "1e-4", ")", "\n", "self", ".", "LocalOpt", "=", "None", "#optimizes custom parameters --> uses Train, not Val", "\n", "self", ".", "initial_norms", "=", "[", "torch", ".", "norm", "(", "_", ")", "for", "m", "in", "self", ".", "L", "for", "_", "in", "m", ".", "parameters", "(", ")", "]", "\n", "\n", "", "def", "create_dataset", "(", "self", ")", ":", "\n", "    ", "'''\n    Creates dataset by calling dataset.py and transforms it to pytorch tensors.\n    '''", "\n", "# Parsing", "\n", "self", ".", "parsed_data_desc", "=", "self", ".", "data_desc", ".", "split", "(", "'-'", ")", "\n", "self", ".", "data_source", "=", "self", ".", "parsed_data_desc", "[", "0", "]", "\n", "if", "self", ".", "data_source", ".", "startswith", "(", "'HDF5'", ")", ":", "\n", "      ", "self", ".", "D", "=", "MetaHDFDataset", "(", "\n", "mtrain", "=", "self", ".", "meta_split", "[", "0", "]", ",", "mval", "=", "self", ".", "meta_split", "[", "1", "]", ",", "\n", "mtest", "=", "self", ".", "meta_split", "[", "2", "]", ",", "\n", "train", "=", "self", ".", "data_split", "[", "0", "]", ",", "val", "=", "self", ".", "data_split", "[", "1", "]", ",", "\n", "test", "=", "self", ".", "data_split", "[", "2", "]", ",", "\n", "filename", "=", "self", ".", "data_source", ".", "split", "(", "'@'", ")", "[", "1", "]", ",", "\n", "limit_data", "=", "self", ".", "limit_data", ",", "\n", "max_datasets", "=", "self", ".", "max_datasets", ",", "\n", "split_by_file", "=", "self", ".", "split_by_file", ",", "\n", "smaller_MVals", "=", "self", ".", "smaller_MVals", ",", "\n", "normalize", "=", "self", ".", "normalize_data", ")", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.initialize_dataset": [[205, 257], ["data_desc.split", "modular_metalearning.BounceGrad.data_source.startswith", "data_loading.convert_to_torch_tensors", "modular_metalearning.BounceGrad.initialize_answers", "data_loading.MetaHDFDataset", "modular_metalearning.BounceGrad.data_source.startswith", "range", "data_loading.get_data_loaders", "data_loading.get_data_loaders", "data_loading.MetaNpySelfRegressDataset", "RuntimeError", "len", "modular_metalearning.BounceGrad.data_source.split", "modular_metalearning.BounceGrad.data_source.split"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.convert_to_torch_tensors", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.initialize_answers", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.get_data_loaders", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.data_loading.get_data_loaders"], ["self", ".", "function_depth", "=", "2", "\n", "", "elif", "self", ".", "data_source", ".", "startswith", "(", "'NPY_SR'", ")", ":", "\n", "      ", "self", ".", "D", "=", "MetaNpySelfRegressDataset", "(", "\n", "mtrain", "=", "self", ".", "meta_split", "[", "0", "]", ",", "mval", "=", "self", ".", "meta_split", "[", "1", "]", ",", "\n", "mtest", "=", "self", ".", "meta_split", "[", "2", "]", ",", "\n", "train", "=", "self", ".", "data_split", "[", "0", "]", ",", "val", "=", "self", ".", "data_split", "[", "1", "]", ",", "\n", "test", "=", "self", ".", "data_split", "[", "2", "]", ",", "\n", "filename", "=", "self", ".", "data_source", ".", "split", "(", "'@'", ")", "[", "1", "]", ",", "\n", "limit_data", "=", "self", ".", "limit_data", ",", "\n", "max_datasets", "=", "self", ".", "max_datasets", ",", "\n", "split_by_file", "=", "self", ".", "split_by_file", ",", "\n", "smaller_MVals", "=", "self", ".", "smaller_MVals", ",", "\n", "normalize", "=", "self", ".", "normalize_data", ")", "\n", "", "else", ":", "assert", "False", ",", "self", ".", "data_source", "+", "' hasnt been implemented yet'", "\n", "self", ".", "D_mtrain", "=", "len", "(", "self", ".", "D", ".", "MTRAIN", ")", "\n", "self", ".", "D_mval", "=", "len", "(", "self", ".", "D", ".", "MVAL", ")", "\n", "self", ".", "D_mtest", "=", "len", "(", "self", ".", "D", ".", "MTEST", ")", "\n", "# Convert to pytorch tensors", "\n", "self", ".", "T", "=", "copy", ".", "deepcopy", "(", "self", ".", "D", ")", "\n", "for", "i", ",", "dataset", "in", "enumerate", "(", "self", ".", "T", ".", "ALL", ")", ":", "\n", "      ", "self", ".", "T", ".", "ALL", "[", "i", "]", ".", "TrainInput", "=", "(", "\n", "torch", ".", "from_numpy", "(", "dataset", ".", "TrainInput", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "nn_device", ")", ")", "\n", "self", ".", "T", ".", "ALL", "[", "i", "]", ".", "TrainOutput", "=", "(", "\n", "torch", ".", "from_numpy", "(", "dataset", ".", "TrainOutput", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "nn_device", ")", ")", "\n", "self", ".", "T", ".", "ALL", "[", "i", "]", ".", "ValInput", "=", "(", "\n", "torch", ".", "from_numpy", "(", "dataset", ".", "ValInput", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "nn_device", ")", ")", "\n", "self", ".", "T", ".", "ALL", "[", "i", "]", ".", "ValOutput", "=", "(", "\n", "torch", ".", "from_numpy", "(", "dataset", ".", "ValOutput", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "nn_device", ")", ")", "\n", "self", ".", "T", ".", "ALL", "[", "i", "]", ".", "TestInput", "=", "(", "\n", "torch", ".", "from_numpy", "(", "dataset", ".", "TestInput", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "nn_device", ")", ")", "\n", "self", ".", "T", ".", "ALL", "[", "i", "]", ".", "TestOutput", "=", "(", "\n", "torch", ".", "from_numpy", "(", "dataset", ".", "TestOutput", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "nn_device", ")", ")", "\n", "\n", "# Create running answers  = search ensembles", "\n", "# They weren't used in the paper, but may be in the future,", "\n", "# as ensembles generally perform better than any single structure.", "\n", "", "self", ".", "answers_running_score", "=", "1e-5", "\n", "self", ".", "ans_eps", "=", "1e-1", "#3e-2", "\n", "self", ".", "MTrainAnswers", "=", "[", "[", "None", ",", "None", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "mtrain_copies", "*", "len", "(", "self", ".", "T", ".", "MTRAIN", ")", ")", "]", "\n", "self", ".", "MValAnswers", "=", "[", "[", "None", ",", "None", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "mtrain_copies", "*", "len", "(", "self", ".", "T", ".", "MTRAIN", ")", ")", "]", "\n", "self", ".", "MTestAnswers", "=", "[", "[", "None", ",", "None", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "mtrain_copies", "*", "len", "(", "self", ".", "T", ".", "MTRAIN", ")", ")", "]", "\n", "self", ".", "OldMTrainAnswers", "=", "[", "[", "None", ",", "None", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "mtrain_copies", "*", "len", "(", "self", ".", "T", ".", "MTRAIN", ")", ")", "]", "\n", "\n", "#######################################", "\n", "###                                 ###", "\n", "### BOUNCEGRAD: SAnnealing with SGD ###", "\n", "###                                 ###", "\n", "#######################################", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.run_model": [[264, 272], ["len", "inp.unsqueeze.unsqueeze.unsqueeze", "modular_metalearning.BounceGrad.S.composer_class", "len"], "methods", ["None"], ["\n", "self", ".", "slow_net", "=", "self", ".", "S", ".", "composer_class", "(", "composer", "=", "self", ".", "composer", ",", "\n", "module_list", "=", "self", ".", "L", ",", "loss_fn", "=", "None", ",", "structure", "=", "structure", ")", "\n", "baseComposer", "=", "self", ".", "S", ".", "composer_class", "(", "composer", "=", "self", ".", "composer", ",", "\n", "module_list", "=", "self", ".", "L", ",", "loss_fn", "=", "None", ",", "structure", "=", "structure", ")", "\n", "self", ".", "fast_net", "=", "InnerLoop", "(", "baseComposer", "=", "baseComposer", ",", "module_list", "=", "self", ".", "L", ",", "\n", "loss_fn", "=", "self", ".", "MAML_loss_fn", ",", "num_updates", "=", "self", ".", "MAML_inner_updates", ",", "\n", "step_size", "=", "self", ".", "MAML_step_size", ")", "\n", "self", ".", "slow_net", ".", "cuda", "(", ")", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.batched_evaluate": [[273, 374], ["modular_metalearning.BounceGrad.S.compose_multiple_structures", "modular_metalearning.BounceGrad.run_model", "list.reshape", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "modular_metalearning.BounceGrad.run_model().reshape", "list", "modular_metalearning.BounceGrad.run_model().reshape", "list", "enumerate", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "modular_metalearning.BounceGrad.run_model().reshape", "list", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "torch.mean().detach().cpu().numpy().item", "torch.mean().detach().cpu().numpy().item", "torch.mean().detach().cpu().numpy().item", "torch.mean().detach().cpu().numpy().item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "zip", "torch.cat().detach().cpu().numpy", "torch.cat().detach().cpu().numpy", "torch.cat().detach().cpu().numpy", "torch.cat().detach().cpu().numpy", "torch.split", "torch.split", "torch.split", "torch.split", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "torch.cat().contiguous", "modular_metalearning.BounceGrad.find_node_dist_rels[].append", "len", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.mse_loss", "torch.mse_loss", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modular_metalearning.BounceGrad.run_model", "modular_metalearning.BounceGrad.run_model", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modular_metalearning.BounceGrad.run_model", "zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "zip", "torch.mean().detach().cpu().numpy().item", "torch.mean().detach().cpu().numpy().item", "torch.mean().detach().cpu().numpy().item", "torch.mean().detach().cpu().numpy().item", "torch.mean().detach().cpu().numpy", "torch.mean().detach().cpu().numpy", "torch.mean().detach().cpu().numpy", "torch.mean().detach().cpu().numpy", "numpy.array", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "zip", "torch.mse_loss", "torch.mse_loss", "zip", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.mean().detach().cpu().numpy", "torch.mean().detach().cpu().numpy", "torch.mean().detach().cpu().numpy", "torch.mean().detach().cpu().numpy", "torch.mean().detach().cpu", "torch.mean().detach().cpu", "torch.mean().detach().cpu", "torch.mean().detach().cpu", "zip", "zip", "zip", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "zip", "zip", "numpy.sum().item", "torch.mean().detach().cpu", "torch.mean().detach().cpu", "torch.mean().detach().cpu", "torch.mean().detach().cpu", "torch.mean().detach", "torch.mean().detach", "torch.mean().detach", "torch.mean().detach", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "numpy.sum", "torch.mean().detach", "torch.mean().detach", "torch.mean().detach", "torch.mean().detach", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "numpy.arange", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.compose_multiple_structures", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.run_model", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.run_model", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.run_model", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.run_model"], ["self", ".", "fast_net", ".", "copy_weights", "(", "self", ".", "slow_net", ")", "\n", "metrics", ",", "g", "=", "self", ".", "fast_net", ".", "forward", "(", "dataset", ")", "\n", "(", "train_loss", ",", "val_loss", ",", "train_ans", ",", "val_ans", ")", "=", "metrics", "\n", "return", "train_loss", ",", "val_loss", ",", "train_ans", ",", "val_ans", ",", "g", "\n", "\n", "", "def", "run_model", "(", "self", ",", "structure", ",", "inp", ",", "instructions", "=", "{", "}", ")", ":", "\n", "    ", "'''\n    Returns the composition of several modules\n    '''", "\n", "if", "len", "(", "inp", ".", "shape", ")", "==", "0", "or", "inp", ".", "shape", "[", "0", "]", "==", "0", ":", "return", "inp", "#empty tensor", "\n", "if", "len", "(", "inp", ".", "shape", ")", "==", "1", ":", "inp", "=", "inp", ".", "unsqueeze", "(", "1", ")", "\n", "return", "self", ".", "S", ".", "composer_class", "(", "composer", "=", "self", ".", "composer", ",", "\n", "module_list", "=", "self", ".", "L", ",", "structure", "=", "structure", ",", "instructions", "=", "instructions", ")", "(", "inp", ")", "\n", "\n", "", "def", "evaluate", "(", "self", ",", "structure", ",", "dataset", ",", "mode", ")", ":", "\n", "    ", "'''\n    Evaluates the dataset according to the structure\n    '''", "\n", "inp", "=", "dataset", ".", "TrainInput", "if", "mode", "==", "'Train'", "else", "dataset", ".", "ValInput", "\n", "out", "=", "(", "dataset", ".", "TrainOutput", "if", "mode", "==", "'Train'", "else", "dataset", ".", "ValOutput", ")", "\n", "if", "len", "(", "inp", ".", "shape", ")", "==", "0", "or", "inp", ".", "shape", "[", "0", "]", "==", "0", ":", "#empty tensors", "\n", "      ", "return", "torch", ".", "FloatTensor", "(", "np", ".", "array", "(", "[", "0", "]", ")", ")", ",", "out", "\n", "", "pred", "=", "self", ".", "run_model", "(", "structure", ",", "inp", ")", "\n", "return", "F", ".", "mse_loss", "(", "pred", ",", "out", ")", ",", "pred", "\n", "\n", "", "def", "evaluate_several_structures", "(", "self", ",", "num", ",", "keep_last", "=", "False", ",", "mode", "=", "'Train'", ")", ":", "\n", "    ", "'''\n    Returns the mean loss for several random datasets\n    keep_last: evaluate same datasets as last time\n    '''", "\n", "if", "not", "keep_last", ":", "\n", "      ", "self", ".", "several_ds_to_eval", "=", "np", ".", "random", ".", "choice", "(", "num", ",", "size", "=", "len", "(", "self", ".", "T", ".", "MTRAIN", ")", ")", "\n", "", "res", "=", "0.", "\n", "for", "i", "in", "self", ".", "several_ds_to_eval", ":", "\n", "      ", "original_train", ",", "original_train_ans", "=", "self", ".", "evaluate", "(", "\n", "self", ".", "S", ".", "TrainStructures", "[", "i", "]", ",", "self", ".", "T", ".", "MTRAIN", "[", "i", "]", ",", "mode", ")", "\n", "res", "+=", "original_train", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "return", "res", "/", "len", "(", "self", ".", "several_ds_to_eval", ")", "\n", "\n", "", "def", "bounce", "(", "self", ",", "structure", ",", "dataset", ",", "temp", ",", "do_grad", ")", ":", "\n", "    ", "'''\n    Propose a modification to structure\n    Do a SA step depending on performance in Train\n    Backpropagate on Val\n    '''", "\n", "if", "self", ".", "do_bounce", ":", "\n", "      ", "new_structure", "=", "copy", ".", "deepcopy", "(", "structure", ")", "\n", "self", ".", "S", ".", "propose_new_structure", "(", "new_structure", ")", "\n", "##################################", "\n", "# Simulated Annealing comparison #", "\n", "##################################", "\n", "", "if", "self", ".", "MAML", ":", "\n", "      ", "(", "original_train", ",", "original_val", ",", "\n", "original_train_ans", ",", "original_val_ans", ",", "original_gradient", ")", "=", "(", "\n", "self", ".", "run_MAML", "(", "structure", ",", "dataset", ")", ")", "\n", "original_train_np", "=", "original_train", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "self", ".", "do_bounce", ":", "\n", "        ", "new_train", ",", "new_val", ",", "new_train_ans", ",", "new_val_ans", ",", "new_gradient", "=", "(", "\n", "self", ".", "run_MAML", "(", "new_structure", ",", "dataset", ")", ")", "\n", "new_train_np", "=", "new_train", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "", "else", ":", "\n", "      ", "MAML_g", "=", "None", "\n", "original_train", ",", "original_train_ans", "=", "self", ".", "evaluate", "(", "structure", ",", "\n", "dataset", ",", "'Train'", ")", "\n", "original_train_np", "=", "original_train", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "self", ".", "do_bounce", ":", "\n", "        ", "new_train", ",", "new_train_ans", "=", "self", ".", "evaluate", "(", "new_structure", ",", "dataset", ",", "\n", "'Train'", ")", "\n", "new_train_np", "=", "new_train", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "", "if", "self", ".", "do_bounce", ":", "\n", "      ", "upt_factor", "=", "min", "(", "0.01", ",", "self", ".", "SA_running_acc_rate", "/", "self", ".", "SA_running_factor", ")", "\n", "prob_accept", "=", "np", ".", "exp", "(", "(", "original_train_np", "-", "new_train_np", ")", "/", "temp", ")", "\n", "", "if", "(", "self", ".", "do_bounce", "and", "(", "#Accept", "\n", "new_train_np", "<=", "original_train_np", "or", "np", ".", "random", ".", "rand", "(", ")", "<", "prob_accept", ")", ")", ":", "\n", "      ", "if", "original_train_np", "<", "new_train_np", ":", "#update running frac of worse accepts", "\n", "        ", "self", ".", "SA_running_factor", "=", "(", "(", "1", "-", "upt_factor", ")", "*", "self", ".", "SA_running_factor", "+", "\n", "upt_factor", ")", "\n", "self", ".", "SA_running_acc_rate", "=", "(", "(", "1", "-", "upt_factor", ")", "*", "self", ".", "SA_running_acc_rate", "+", "\n", "upt_factor", ")", "\n", "", "if", "self", ".", "MAML", ":", "MAML_g", "=", "new_gradient", "\n", "else", ":", "\n", "        ", "if", "self", ".", "LocalOpt", "is", "not", "None", ":", "new_train", ".", "backward", "(", ")", "\n", "# structure['node_positions'].requires_grad = False", "\n", "self", ".", "S", ".", "update_structure", "(", "structure", ")", "\n", "new_val", ",", "new_val_ans", "=", "self", ".", "evaluate", "(", "new_structure", ",", "dataset", ",", "'Val'", ")", "\n", "if", "do_grad", ":", "new_val", ".", "backward", "(", ")", "\n", "# structure['node_positions'].requires_grad = True", "\n", "", "return", "(", "new_structure", ",", "new_train", ",", "new_val", ",", "\n", "new_train_ans", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "new_val_ans", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "MAML_g", ")", "\n", "", "else", ":", "#Reject", "\n", "      ", "if", "self", ".", "do_bounce", "and", "original_train_np", "<", "new_train_np", ":", "\n", "#update running frac of worse accepts", "\n", "        ", "self", ".", "SA_running_factor", "=", "(", "(", "1", "-", "upt_factor", ")", "*", "self", ".", "SA_running_factor", "+", "\n", "upt_factor", ")", "\n", "self", ".", "SA_running_acc_rate", "=", "(", "1", "-", "upt_factor", ")", "*", "self", ".", "SA_running_acc_rate", "\n", "", "if", "self", ".", "MAML", ":", "MAML_g", "=", "original_gradient", "\n", "else", ":", "\n", "        ", "if", "self", ".", "LocalOpt", "is", "not", "None", ":", "original_train", ".", "backward", "(", ")", "\n", "# structure['node_positions'].requires_grad = False", "\n", "self", ".", "S", ".", "update_structure", "(", "structure", ")", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad._update_frac_worse_accepts": [[375, 380], ["None"], "methods", ["None"], ["original_val", ",", "original_val_ans", "=", "self", ".", "evaluate", "(", "structure", ",", "dataset", ",", "\n", "'Val'", ")", "\n", "if", "do_grad", ":", "original_val", ".", "backward", "(", ")", "\n", "# structure['node_positions'].requires_grad = True", "\n", "", "return", "(", "structure", ",", "original_train", ",", "original_val", ",", "\n", "original_train_ans", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad._get_structure_encoder_input": [[381, 428], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "round", "numpy.random.choice", "array.astype.astype.astype", "modular_metalearning.BounceGrad._get_structure_encoder_input.select_indices"], "methods", ["None"], ["original_val_ans", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "MAML_g", ")", "\n", "\n", "##############################", "\n", "## MAIN BOUNCEGRAD FUNCTION ##", "\n", "##############################", "\n", "", "", "def", "SAConfig_SGDModules", "(", "self", ",", "optimization_steps", ")", ":", "\n", "    ", "'''\n    Optimization by Simulated Annealing on the module configurations\n    and SGD (Adam in our case) on the modules at every step.\n    '''", "\n", "# Cooling schedule decreases exponentially wrt the fraction of accepted", "\n", "# proposals with worse performance, starting at 1 (accept no matter what)", "\n", "# Therefore we have to keep a running estimate of fraction of accepts.", "\n", "self", ".", "SA_running_acc_rate", "=", "1e-9", "#initial counters for Simulated Annealing", "\n", "self", ".", "SA_running_factor", "=", "1e-9", "#normalizing constant", "\n", "temp", "=", "np", ".", "exp", "(", "self", ".", "initial_temp", ")", "#temperature in the SA formula", "\n", "temp_change", "=", "1.1", "\n", "CosDist", "=", "nn", ".", "CosineSimilarity", "(", "dim", "=", "1", ")", "\n", "#############################", "\n", "# Create initial structures #", "\n", "#############################", "\n", "self", ".", "S", ".", "initialize_all_structures", "(", "T", "=", "self", ".", "T", ",", "mtrain_copies", "=", "self", ".", "mtrain_copies", ")", "\n", "if", "len", "(", "self", ".", "S", ".", "StructureParameters", ")", ":", "\n", "      ", "self", ".", "LocalOpt", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "S", ".", "StructureParameters", ",", "\n", "lr", "=", "self", ".", "meta_lr", "/", "10", ")", "\n", "self", ".", "LocalOpt_scheduler", "=", "ReduceLROnPlateau", "(", "\n", "optimizer", "=", "self", ".", "SOpt", ",", "factor", "=", "1", "/", "2.", ",", "\n", "mode", "=", "'min'", ",", "patience", "=", "20", ",", "threshold", "=", "0", ",", "cooldown", "=", "100", ",", "\n", "verbose", "=", "True", ",", "min_lr", "=", "1e-4", ")", "\n", "", "if", "self", ".", "load_structures_and_metrics", "!=", "''", ":", "\n", "      ", "self", ".", "load_strmet", "(", "self", ".", "load_structures_and_metrics", ")", "\n", "\n", "# input('Check structure: '+ str( self.S.TrainStructures[0]))", "\n", "", "for", "step", "in", "Tqdm", "(", "range", "(", "optimization_steps", ")", ")", ":", "\n", "      ", "self", ".", "step", "=", "step", "*", "self", ".", "mtrain_copies", "\n", "if", "step", ":", "\n", "        ", "self", ".", "SOpt_scheduler", ".", "step", "(", "self", ".", "mean_current_val", ")", "#MTrain-Val", "\n", "if", "self", ".", "LocalOpt", "is", "not", "None", ":", "\n", "          ", "self", ".", "LocalOpt_scheduler", ".", "step", "(", "self", ".", "mean_current_val", ")", "#MTrain-Val", "\n", "", "", "self", ".", "METRICS", "[", "'TrainStructures'", "]", "=", "self", ".", "S", ".", "TrainStructures", "\n", "self", ".", "METRICS", "[", "'ValStructures'", "]", "=", "self", ".", "S", ".", "ValStructures", "\n", "self", ".", "S", ".", "update_PosUsage_counters", "(", "METRICS", "=", "self", ".", "METRICS", ")", "\n", "self", ".", "S", ".", "update_Usage_counters", "(", "METRICS", "=", "self", ".", "METRICS", ",", "T", "=", "self", ".", "T", ")", "\n", "self", ".", "S", ".", "update_customized_counters", "(", "METRICS", "=", "self", ".", "METRICS", ")", "\n", "self", ".", "update_Sharing_counters", "(", ")", "\n", "\n", "#with default values the midpoint @0.7%, end @0.005%", "\n", "acc_rate", "=", "np", ".", "exp", "(", "self", ".", "initial_acc", "-", "5.", "*", "step", "/", "optimization_steps", ")", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.batched_propose": [[429, 446], ["encoder", "encoder.detach().cpu().numpy", "zip", "copy.deepcopy", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "modular_metalearning.BounceGrad.proposal_fn", "modular_metalearning.BounceGrad._get_structure_encoder_input", "RuntimeError", "encoder.detach().cpu", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "encoder.detach"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad._get_structure_encoder_input"], ["if", "self", ".", "SA_running_acc_rate", "/", "self", ".", "SA_running_factor", "<", "acc_rate", ":", "\n", "        ", "temp", "*=", "temp_change", "\n", "", "else", ":", "temp", "/=", "temp_change", "\n", "\n", "self", ".", "current_train", "=", "[", "]", "\n", "self", ".", "current_val", "=", "[", "]", "\n", "self", ".", "MTrain_norm_diff", "=", "[", "]", "\n", "self", ".", "MTrain_cos_diff", "=", "[", "]", "\n", "if", "self", ".", "MAML", ":", "maml_gradients", "=", "[", "]", "\n", "for", "i", ",", "structure", "in", "Tqdm", "(", "enumerate", "(", "self", ".", "S", ".", "TrainStructures", ")", ")", ":", "\n", "        ", "dataset", "=", "self", ".", "T", ".", "MTRAIN", "[", "i", "%", "len", "(", "self", ".", "T", ".", "MTRAIN", ")", "]", "#multiple structures per dataset", "\n", "#Update structure", "\n", "self", ".", "S", ".", "update_structure", "(", "self", ".", "S", ".", "TrainStructures", "[", "i", "]", ",", "step", "=", "self", ".", "step", ")", "\n", "#######################", "\n", "# Simulated Annealing #", "\n", "#######################", "\n", "(", "self", ".", "S", ".", "TrainStructures", "[", "i", "]", ",", "train_loss", ",", "val_loss", ",", "train_ans", ",", "val_ans", ",", "\n", "MAML_g", ")", "=", "self", ".", "bounce", "(", "structure", ",", "dataset", ",", "temp", ",", "do_grad", "=", "True", ")", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.bidirectional_accuracy": [[447, 457], ["numpy.sum", "tuple", "[].index", "numpy.sum", "len", "modular_metalearning.BounceGrad.bidirectional_accuracy.get_other_edge"], "methods", ["None"], ["self", ".", "current_train", ".", "append", "(", "train_loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "self", ".", "current_val", ".", "append", "(", "val_loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "if", "self", ".", "MTrainAnswers", "[", "i", "]", "[", "0", "]", "is", "None", ":", "\n", "          ", "self", ".", "MTrainAnswers", "[", "i", "]", "[", "0", "]", "=", "train_ans", "*", "self", ".", "ans_eps", "\n", "", "else", ":", "self", ".", "MTrainAnswers", "[", "i", "]", "[", "0", "]", "=", "(", "\n", "(", "1", "-", "self", ".", "ans_eps", ")", "*", "self", ".", "MTrainAnswers", "[", "i", "]", "[", "0", "]", "+", "\n", "train_ans", "*", "self", ".", "ans_eps", ")", "\n", "if", "self", ".", "MTrainAnswers", "[", "i", "]", "[", "1", "]", "is", "None", ":", "\n", "          ", "self", ".", "MTrainAnswers", "[", "i", "]", "[", "1", "]", "=", "val_ans", "*", "self", ".", "ans_eps", "\n", "", "else", ":", "\n", "          ", "self", ".", "MTrainAnswers", "[", "i", "]", "[", "1", "]", "=", "(", "(", "1", "-", "self", ".", "ans_eps", ")", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.batched_bounce": [[458, 630], ["modular_metalearning.BounceGrad.batched_evaluate", "map", "min", "enumerate", "sum", "modular_metalearning.BounceGrad.bidirectional_accuracy", "zip", "map", "modular_metalearning.BounceGrad.batched_evaluate", "map", "torch.any", "torch.any", "torch.any", "torch.any", "modular_metalearning.BounceGrad.batched_evaluate", "zip", "numpy.exp", "modular_metalearning.BounceGrad._update_frac_worse_accepts", "list", "sum", "sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum.backward", "torch.sum.backward", "list", "list", "len", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "numpy.random.uniform", "modular_metalearning.BounceGrad.batched_propose", "modular_metalearning.BounceGrad.batched_propose", "zip", "torch.any", "torch.any", "torch.any", "torch.any", "modular_metalearning.BounceGrad.batched_evaluate", "x.data.cpu().numpy", "list", "list", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum.backward", "torch.sum.backward", "x.data.cpu().numpy", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "return_tuples.append", "return_tuples.append", "map", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "zip", "zip", "p.data.cpu().numpy", "p.data.cpu().numpy", "copy.deepcopy", "proposed_structs.append", "modular_metalearning.BounceGrad.batched_propose", "RuntimeError", "x.data.cpu().numpy", "zip", "zip", "p.data.cpu().numpy", "p.data.cpu().numpy", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "numpy.random.rand", "accepted_structs.append", "torch.Tensor.append", "torch.Tensor.append", "float", "zip", "numpy.split", "p.data.cpu().numpy", "modular_metalearning.BounceGrad.S.propose_new_structure", "x.data.cpu", "x.data.cpu", "numpy.sum", "x.squeeze", "numpy.where", "float", "zip", "float", "zip", "p.data.cpu", "p.data.cpu", "modular_metalearning.BounceGrad.S.update_structure_to", "x.data.cpu", "p.data.cpu", "p.data.cpu", "numpy.sum", "numpy.sum", "p.data.cpu", "dataset.Edges.tolist", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.batched_evaluate", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.bidirectional_accuracy", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.batched_evaluate", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.batched_evaluate", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad._update_frac_worse_accepts", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.batched_propose", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.batched_propose", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.batched_evaluate", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.batched_propose", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.propose_new_structure", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.update_structure_to"], ["*", "self", ".", "MTrainAnswers", "[", "i", "]", "[", "1", "]", "+", "val_ans", "*", "self", ".", "ans_eps", ")", "\n", "", "if", "self", ".", "OldMTrainAnswers", "[", "i", "]", "[", "0", "]", "is", "not", "None", ":", "\n", "          ", "self", ".", "MTrain_norm_diff", ".", "append", "(", "\n", "np", ".", "mean", "(", "np", ".", "linalg", ".", "norm", "(", "\n", "self", ".", "OldMTrainAnswers", "[", "i", "]", "[", "0", "]", "-", "train_ans", ",", "axis", "=", "1", ")", ")", ")", "\n", "self", ".", "MTrain_cos_diff", ".", "append", "(", "\n", "torch", ".", "mean", "(", "CosDist", "(", "torch", ".", "FloatTensor", "(", "\n", "self", ".", "OldMTrainAnswers", "[", "i", "]", "[", "0", "]", "-", "\n", "dataset", ".", "TrainOutput", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ",", "\n", "torch", ".", "FloatTensor", "(", "\n", "train_ans", "-", "dataset", ".", "TrainOutput", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", ")", ")", "\n", "", "self", ".", "OldMTrainAnswers", "[", "i", "]", "[", "0", "]", "=", "train_ans", "\n", "\n", "####################", "\n", "# Gradient Descent #", "\n", "####################", "\n", "if", "self", ".", "MAML", ":", "maml_gradients", ".", "append", "(", "MAML_g", ")", "\n", "if", "(", "i", "==", "len", "(", "self", ".", "S", ".", "TrainStructures", ")", "-", "1", "or", "(", "self", ".", "execute_gd_every", ">", "0", "and", "\n", "i", "%", "self", ".", "execute_gd_every", "==", "self", ".", "execute_gd_every", "-", "1", ")", ")", ":", "\n", "          ", "if", "self", ".", "MAML", ":", "\n", "# Compute sum of maml_gradients to each module", "\n", "# Inspired by:", "\n", "# github.com/katerakelly/pytorch-maml/blob/master/src/maml.py#L66", "\n", "# but multiple changes because they have a single structure", "\n", "            ", "self", ".", "dict_gradients", "=", "{", "}", "\n", "for", "G", "in", "maml_gradients", ":", "\n", "              ", "for", "(", "key", ",", "value", ")", "in", "G", ".", "items", "(", ")", ":", "\n", "                ", "if", "value", "is", "None", ":", "continue", "\n", "name", "=", "'.'", ".", "join", "(", "key", ".", "split", "(", "'.'", ")", "[", "1", ":", "]", ")", "\n", "if", "name", "not", "in", "self", ".", "dict_gradients", ":", "\n", "                  ", "self", ".", "dict_gradients", "[", "name", "]", "=", "value", "\n", "", "else", ":", "self", ".", "dict_gradients", "[", "name", "]", "+=", "value", "\n", "\n", "", "", "hooks", "=", "[", "]", "\n", "for", "(", "k", ",", "v", ")", "in", "self", ".", "L", ".", "named_parameters", "(", ")", ":", "\n", "              ", "def", "get_closure", "(", ")", ":", "\n", "                ", "key", "=", "k", "\n", "value", "=", "v", "\n", "def", "replace_grad", "(", "grad", ")", ":", "\n", "                  ", "if", "key", "in", "self", ".", "dict_gradients", ":", "\n", "                    ", "return", "self", ".", "dict_gradients", "[", "key", "]", "\n", "", "else", ":", "return", "torch", ".", "zeros_like", "(", "value", ")", "\n", "", "return", "replace_grad", "\n", "", "hooks", ".", "append", "(", "v", ".", "register_hook", "(", "get_closure", "(", ")", ")", ")", "\n", "", "self", ".", "SOpt", ".", "zero_grad", "(", ")", "\n", "for", "module", "in", "self", ".", "L", ":", "\n", "              ", "dummy_loss", "=", "module", ".", "dummy_forward_pass", "(", ")", "\n", "dummy_loss", ".", "backward", "(", ")", "\n", "", "self", ".", "SOpt", ".", "step", "(", ")", "\n", "for", "h", "in", "hooks", ":", "h", ".", "remove", "(", ")", "\n", "\n", "maml_gradients", "=", "[", "]", "\n", "", "else", ":", "#No MAML --> use regular loss", "\n", "            ", "self", ".", "SOpt", ".", "step", "(", ")", "\n", "self", ".", "SOpt", ".", "zero_grad", "(", ")", "\n", "if", "self", ".", "LocalOpt", "is", "not", "None", ":", "\n", "              ", "self", ".", "LocalOpt", ".", "step", "(", ")", "\n", "self", ".", "LocalOpt", ".", "zero_grad", "(", ")", "\n", "\n", "#Simulated Annealing on MetaValidation data", "\n", "", "", "", "", "self", ".", "current_Mtrain", "=", "[", "]", "\n", "self", ".", "current_Meval", "=", "[", "]", "\n", "for", "i", ",", "structure", "in", "enumerate", "(", "self", ".", "S", ".", "ValStructures", ")", ":", "\n", "        ", "dataset", "=", "self", ".", "T", ".", "MVAL", "[", "i", "%", "len", "(", "self", ".", "T", ".", "MVAL", ")", "]", "\n", "#Update structure", "\n", "self", ".", "S", ".", "update_structure", "(", "self", ".", "S", ".", "ValStructures", "[", "i", "]", ",", "step", "=", "self", ".", "step", ")", "\n", "(", "self", ".", "S", ".", "ValStructures", "[", "i", "]", ",", "train_loss", ",", "val_loss", ",", "\n", "train_ans", ",", "val_ans", ",", "MAML_g", ")", "=", "(", "\n", "self", ".", "bounce", "(", "structure", ",", "dataset", ",", "temp", ",", "do_grad", "=", "False", ")", ")", "\n", "self", ".", "current_Mtrain", ".", "append", "(", "train_loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "self", ".", "current_Meval", ".", "append", "(", "val_loss", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "if", "self", ".", "MValAnswers", "[", "i", "]", "[", "0", "]", "is", "None", ":", "\n", "          ", "self", ".", "MValAnswers", "[", "i", "]", "[", "0", "]", "=", "train_ans", "*", "self", ".", "ans_eps", "\n", "", "else", ":", "\n", "          ", "self", ".", "MValAnswers", "[", "i", "]", "[", "0", "]", "=", "(", "\n", "(", "1", "-", "self", ".", "ans_eps", ")", "*", "self", ".", "MValAnswers", "[", "i", "]", "[", "0", "]", "+", "train_ans", "*", "self", ".", "ans_eps", ")", "\n", "", "if", "self", ".", "MValAnswers", "[", "i", "]", "[", "1", "]", "is", "None", ":", "\n", "          ", "self", ".", "MValAnswers", "[", "i", "]", "[", "1", "]", "=", "val_ans", "*", "self", ".", "ans_eps", "\n", "", "else", ":", "\n", "          ", "self", ".", "MValAnswers", "[", "i", "]", "[", "1", "]", "=", "(", "(", "1", "-", "self", ".", "ans_eps", ")", "*", "self", ".", "MValAnswers", "[", "i", "]", "[", "1", "]", "+", "\n", "val_ans", "*", "self", ".", "ans_eps", ")", "\n", "#Zero-out optimizers (step in MTRAIN performed + dont want step from MVAL)", "\n", "", "", "self", ".", "SOpt", ".", "zero_grad", "(", ")", "\n", "###################", "\n", "# Stats and plots #", "\n", "###################", "\n", "self", ".", "answers_running_score", "=", "(", "self", ".", "answers_running_score", "*", "\n", "(", "1.", "-", "self", ".", "ans_eps", ")", "+", "self", ".", "ans_eps", ")", "\n", "ensemble_train", "=", "np", ".", "mean", "(", "[", "np", ".", "mean", "(", "\n", "(", "self", ".", "MTrainAnswers", "[", "i", "]", "[", "0", "]", "/", "self", ".", "answers_running_score", "\n", "-", "self", ".", "T", ".", "MTRAIN", "[", "i", "]", ".", "TrainOutput", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "**", "2", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "T", ".", "mtrain", ")", "]", ")", "\n", "ensemble_val", "=", "np", ".", "mean", "(", "[", "np", ".", "mean", "(", "\n", "(", "self", ".", "MTrainAnswers", "[", "i", "]", "[", "1", "]", "/", "self", ".", "answers_running_score", "\n", "-", "self", ".", "T", ".", "MTRAIN", "[", "i", "]", ".", "ValOutput", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "**", "2", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "T", ".", "mtrain", ")", "]", ")", "\n", "ensemble_Mtrain", "=", "np", ".", "mean", "(", "[", "np", ".", "mean", "(", "\n", "(", "self", ".", "MValAnswers", "[", "i", "]", "[", "0", "]", "/", "self", ".", "answers_running_score", "\n", "-", "self", ".", "T", ".", "MVAL", "[", "i", "]", ".", "TrainOutput", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "**", "2", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "T", ".", "mval", ")", "]", ")", "\n", "ensemble_Mval", "=", "np", ".", "mean", "(", "[", "np", ".", "mean", "(", "\n", "(", "self", ".", "MValAnswers", "[", "i", "]", "[", "1", "]", "/", "self", ".", "answers_running_score", "\n", "-", "self", ".", "T", ".", "MVAL", "[", "i", "]", ".", "ValOutput", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "**", "2", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "T", ".", "mval", ")", "]", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'ensemble/train'", ",", "ensemble_train", ".", "item", "(", ")", ",", "\n", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'ensemble/val'", ",", "ensemble_val", ".", "item", "(", ")", ",", "\n", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'ensemble/Mtrain'", ",", "ensemble_Mtrain", ".", "item", "(", ")", ",", "\n", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'ensemble/Mval'", ",", "ensemble_Mval", ".", "item", "(", ")", ",", "\n", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'SA/temp'", ",", "np", ".", "log10", "(", "temp", ")", ".", "item", "(", ")", ",", "\n", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'SA/acc_rate'", ",", "\n", "np", ".", "log10", "(", "self", ".", "SA_running_acc_rate", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "update_stats", "(", ")", "\n", "self", ".", "S", ".", "update_customized_stats", "(", "self", ")", "\n", "if", "step", "%", "self", ".", "plot_freq", "==", "0", "or", "step", "==", "self", ".", "optimization_steps", "-", "1", ":", "\n", "#plot & store metrics to JSON", "\n", "        ", "self", ".", "log_metrics", "(", ")", "\n", "self", ".", "store_simple_metrics", "(", ")", "\n", "# self.store_metrics()", "\n", "if", "self", ".", "save_modules", "!=", "''", ":", "self", ".", "save_L", "(", "self", ".", "save_modules", ")", "\n", "\n", "#########################################", "\n", "# Logistic functions of little interest #", "\n", "#########################################", "\n", "", "", "", "def", "save_L", "(", "self", ",", "filepath", "=", "None", ")", ":", "\n", "    ", "'''\n    Saves ModuleList\n    '''", "\n", "if", "filepath", "is", "None", ":", "filepath", "=", "'moduleList-'", "\n", "for", "i_m", ",", "module", "in", "enumerate", "(", "self", ".", "L", ")", ":", "\n", "      ", "torch", ".", "save", "(", "module", ".", "state_dict", "(", ")", ",", "filepath", "+", "str", "(", "i_m", ")", ")", "\n", "\n", "", "", "def", "load_L", "(", "self", ",", "filepath", "=", "None", ")", ":", "\n", "    ", "'''\n    Loads ModuleList\n    '''", "\n", "if", "filepath", "is", "None", ":", "filepath", "=", "'moduleList-'", "\n", "for", "i_m", ",", "module", "in", "enumerate", "(", "self", ".", "L", ")", ":", "\n", "      ", "self", ".", "L", "[", "i_m", "]", ".", "load_state_dict", "(", "torch", ".", "load", "(", "filepath", "+", "str", "(", "i_m", ")", ")", ")", "\n", "\n", "", "", "def", "load_strmet", "(", "self", ",", "filepath", "=", "None", ")", ":", "\n", "    ", "'''\n    Loads structures and metrics\n    '''", "\n", "if", "filepath", "is", "None", ":", "filepath", "=", "'metrics/'", "\n", "if", "os", ".", "path", ".", "isdir", "(", "filepath", ")", ":", "\n", "      ", "filepath", "=", "os", ".", "path", ".", "join", "(", "filepath", ",", "'metrics.json'", ")", "\n", "", "with", "open", "(", "filepath", ",", "'r'", ")", "as", "infile", ":", "\n", "      ", "self", ".", "METRICS", "=", "json", ".", "load", "(", "infile", ")", "\n", "", "self", ".", "S", ".", "TrainStructures", "=", "self", ".", "METRICS", "[", "'TrainStructures'", "]", "\n", "self", ".", "S", ".", "ValStructures", "=", "self", ".", "METRICS", "[", "'ValStructures'", "]", "\n", "\n", "", "def", "update_stats", "(", "self", ")", ":", "\n", "    ", "'''\n    Updates several metrics after each step\n    '''", "\n", "#Differences between timesteps", "\n", "if", "self", ".", "MTrain_norm_diff", "!=", "[", "]", ":", "\n", "      ", "self", ".", "writer", ".", "add_scalar", "(", "'norm_diff/perc_10'", ",", "\n", "np", ".", "percentile", "(", "self", ".", "MTrain_norm_diff", ",", "10", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'norm_diff/perc_90'", ",", "\n", "np", ".", "percentile", "(", "self", ".", "MTrain_norm_diff", ",", "90", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'norm_diff/perc_10'", ",", "\n", "np", ".", "percentile", "(", "self", ".", "MTrain_cos_diff", ",", "10", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'norm_diff/perc_90'", ",", "\n", "np", ".", "percentile", "(", "self", ".", "MTrain_cos_diff", ",", "90", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "\n", "#Weight norms", "\n", "", "self", ".", "act_norms", "=", "[", "torch", ".", "norm", "(", "_", ")", "for", "m", "in", "self", ".", "L", "for", "_", "in", "m", ".", "parameters", "(", ")", "]", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.encoder_loss": [[631, 639], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "modular_metalearning.BounceGrad.encoder_loss_fn", "len"], "methods", ["None"], ["self", ".", "norm_ratios", "=", "[", "(", "a", "/", "b", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "for", "(", "a", ",", "b", ")", "in", "zip", "(", "\n", "self", ".", "act_norms", ",", "self", ".", "initial_norms", ")", "]", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'norm_ratios/mean'", ",", "\n", "np", ".", "mean", "(", "self", ".", "norm_ratios", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'norm_ratios/std'", ",", "\n", "np", ".", "std", "(", "self", ".", "norm_ratios", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "#Error metrics", "\n", "self", ".", "mean_current_val", "=", "np", ".", "mean", "(", "self", ".", "current_val", ")", ".", "item", "(", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'mean_loss/T_val'", ",", "self", ".", "mean_current_val", ",", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.encoder_step": [[640, 653], ["modular_metalearning.BounceGrad.encoder_opt.zero_grad", "encoder_loss.backward", "modular_metalearning.BounceGrad.encoder_opt.step", "modular_metalearning.BounceGrad.encoder_opt.zero_grad", "modular_metalearning.BounceGrad.encoder_opt2.zero_grad", "encoder_loss.backward", "modular_metalearning.BounceGrad.encoder_opt2.step", "modular_metalearning.BounceGrad.encoder_opt2.zero_grad", "RuntimeError"], "methods", ["None"], ["self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'std_loss/T_val'", ",", "\n", "np", ".", "std", "(", "self", ".", "current_val", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'min_loss/T_val'", ",", "\n", "np", ".", "min", "(", "self", ".", "current_val", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "if", "len", "(", "self", ".", "current_train", ")", ":", "\n", "      ", "self", ".", "writer", ".", "add_scalar", "(", "'mean_loss/T_train'", ",", "\n", "np", ".", "mean", "(", "self", ".", "current_train", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'std_loss/T_train'", ",", "\n", "np", ".", "std", "(", "self", ".", "current_train", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'min_loss/T_train'", ",", "\n", "np", ".", "min", "(", "self", ".", "current_train", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "", "if", "len", "(", "self", ".", "current_Mtrain", ")", ":", "\n", "      ", "self", ".", "writer", ".", "add_scalar", "(", "'mean_loss/V_train'", ",", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.do_plot_with_without_node": [[654, 752], ["numpy.tile", "numpy.tile", "numpy.tile", "numpy.tile", "numpy.tile", "numpy.tile", "numpy.tile", "numpy.tile", "range", "modular_metalearning.BounceGrad.S.compose_multiple_structures", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modular_metalearning.BounceGrad.run_model().reshape", "list", "zip", "modular_metalearning.BounceGrad.run_model().reshape", "list", "enumerate", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "torch.split", "torch.split", "torch.split", "torch.split", "matplotlib.figure", "range", "matplotlib.xlim", "matplotlib.ylim", "modular_metalearning.BounceGrad.writer.add_figure", "matplotlib.figure", "range", "modular_metalearning.BounceGrad.writer.add_figure", "matplotlib.figure", "range", "modular_metalearning.BounceGrad.writer.add_figure", "torch.split", "torch.split", "torch.split", "torch.split", "zip", "matplotlib.figure", "range", "matplotlib.xlim", "matplotlib.ylim", "modular_metalearning.BounceGrad.writer.add_figure", "float", "float", "modular_metalearning.BounceGrad.run_model", "matplotlib.scatter", "matplotlib.scatter", "matplotlib.scatter", "matplotlib.scatter", "modular_metalearning.BounceGrad.run_model", "matplotlib.scatter", "dataset.TrainInput[].detach().cpu().numpy", "dataset.TrainInput[].detach().cpu().numpy", "str", "dataset.TrainInput[].detach().cpu().numpy", "dataset.TrainInput[].detach().cpu().numpy", "str", "dataset.TrainInput[].detach().cpu().numpy", "dataset.TrainInput[].detach().cpu().numpy", "pred[].detach().cpu().numpy", "pred[].detach().cpu().numpy", "str", "[].detach().cpu().numpy", "[].detach().cpu().numpy", "str", "dataset.TrainInput[].detach().cpu", "dataset.TrainInput[].detach().cpu", "dataset.TrainInput[].detach().cpu", "dataset.TrainInput[].detach().cpu", "dataset.TrainInput[].detach().cpu", "dataset.TrainInput[].detach().cpu", "pred[].detach().cpu", "pred[].detach().cpu", "[].detach().cpu", "[].detach().cpu", "dataset.TrainInput[].detach", "dataset.TrainInput[].detach", "dataset.TrainInput[].detach", "dataset.TrainInput[].detach", "dataset.TrainInput[].detach", "dataset.TrainInput[].detach", "pred[].detach", "pred[].detach", "[].detach", "[].detach"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.compose_multiple_structures", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.run_model", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.run_model"], ["np", ".", "mean", "(", "self", ".", "current_Mtrain", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'std_loss/V_train'", ",", "\n", "np", ".", "std", "(", "self", ".", "current_Mtrain", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'min_loss/V_train'", ",", "\n", "np", ".", "min", "(", "self", ".", "current_Mtrain", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "", "if", "len", "(", "self", ".", "current_Meval", ")", ":", "\n", "      ", "self", ".", "writer", ".", "add_scalar", "(", "'mean_loss/V_val'", ",", "\n", "np", ".", "mean", "(", "self", ".", "current_Meval", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'std_loss/V_val'", ",", "\n", "np", ".", "std", "(", "self", ".", "current_Meval", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'min_loss/V_val'", ",", "\n", "np", ".", "min", "(", "self", ".", "current_Meval", ")", ".", "item", "(", ")", ",", "self", ".", "step", ")", "\n", "\n", "", "", "def", "is_jsonable", "(", "self", ",", "x", ")", ":", "\n", "    ", "try", ":", "\n", "      ", "json", ".", "dumps", "(", "x", ")", "\n", "return", "True", "\n", "", "except", ":", "return", "False", "\n", "\n", "", "def", "store_simple_metrics", "(", "self", ")", ":", "\n", "    ", "'''\n    Stores all metrics that can be JSON-ed to a JSON file\n    '''", "\n", "self", ".", "METRICS", "[", "'params'", "]", "=", "{", "attr", ":", "getattr", "(", "self", ",", "attr", ")", "for", "attr", "in", "\n", "dir", "(", "self", ")", "if", "self", ".", "is_jsonable", "(", "getattr", "(", "self", ",", "attr", ")", ")", "}", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "plot_name", ",", "\n", "'metrics.json'", ")", ",", "'w'", ")", "as", "outfile", ":", "\n", "      ", "json", ".", "dump", "(", "{", "k", ":", "v", "for", "k", ",", "v", "in", "self", ".", "METRICS", ".", "items", "(", ")", "\n", "if", "self", ".", "is_jsonable", "(", "v", ")", "}", ",", "outfile", ")", "\n", "\n", "", "", "def", "store_metrics", "(", "self", ")", ":", "\n", "    ", "'''\n    Stores all the metrics to a JSON file\n    '''", "\n", "self", ".", "METRICS", "[", "'time'", "]", "=", "int", "(", "time", ".", "time", "(", ")", ")", "\n", "self", ".", "METRICS", "[", "'params'", "]", "=", "{", "attr", ":", "getattr", "(", "self", ",", "attr", ")", "for", "attr", "in", "dir", "(", "self", ")", "\n", "if", "(", "type", "(", "getattr", "(", "self", ",", "attr", ")", ")", "in", "\n", "[", "type", "(", "1", ")", ",", "type", "(", "1.0", ")", ",", "type", "(", "'a'", ")", ",", "type", "(", "None", ")", "]", "\n", "or", "(", "type", "(", "getattr", "(", "self", ",", "attr", ")", ")", "==", "type", "(", "[", "]", ")", "and", "\n", "len", "(", "getattr", "(", "self", ",", "attr", ")", ")", "and", "type", "(", "getattr", "(", "self", ",", "attr", ")", "[", "0", "]", ")", "in", "\n", "[", "type", "(", "1", ")", ",", "type", "(", "1.0", ")", ",", "type", "(", "'a'", ")", ",", "type", "(", "None", ")", "]", ")", "\n", "or", "(", "type", "(", "getattr", "(", "self", ",", "attr", ")", ")", "==", "type", "(", "{", "}", ")", "and", "\n", "len", "(", "getattr", "(", "self", ",", "attr", ")", ")", "and", "\n", "type", "(", "getattr", "(", "self", ",", "attr", ")", "[", "list", "(", "getattr", "(", "self", ",", "attr", ")", ".", "keys", "(", ")", ")", "[", "0", "]", "]", ")", "in", "\n", "[", "type", "(", "1", ")", ",", "type", "(", "1.0", ")", ",", "type", "(", "'a'", ")", ",", "type", "(", "None", ")", "]", ")", "\n", "and", "not", "callable", "(", "getattr", "(", "self", ",", "attr", ")", ")", "and", "not", "attr", ".", "startswith", "(", "'__'", ")", ")", "}", "\n", "with", "open", "(", "'metrics/'", "+", "self", ".", "plot_name", "[", ":", "-", "1", "]", "+", "'.json'", ",", "'w'", ")", "as", "outfile", ":", "\n", "      ", "json", ".", "dump", "(", "self", ".", "METRICS", ",", "outfile", ")", "\n", "", "with", "open", "(", "self", ".", "plot_name", "+", "'metrics.json'", ",", "'w'", ")", "as", "outfile", ":", "\n", "      ", "json", ".", "dump", "(", "self", ".", "METRICS", ",", "outfile", ")", "\n", "\n", "", "", "def", "plot_sharing", "(", "self", ")", ":", "\n", "    ", "if", "(", "self", ".", "METRICS", "[", "'Sharing'", "]", "is", "not", "None", "and", "\n", "np", ".", "max", "(", "self", ".", "METRICS", "[", "'Sharing'", "]", ")", ">", "1e-4", "and", "\n", "len", "(", "self", ".", "METRICS", "[", "'NumberToWords'", "]", ")", "<=", "50", ")", ":", "\n", "#Find ordering", "\n", "      ", "aux", "=", "list", "(", "enumerate", "(", "self", ".", "METRICS", "[", "'NumberToWords'", "]", ")", ")", "\n", "aux", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "sorted_order", "=", "[", "_", "[", "0", "]", "for", "_", "in", "aux", "]", "\n", "cax", "=", "plt", ".", "gca", "(", ")", ".", "matshow", "(", "np", ".", "array", "(", "\n", "self", ".", "METRICS", "[", "'Sharing'", "]", ")", "[", "sorted_order", ",", ":", "]", "[", ":", ",", "sorted_order", "]", "\n", "/", "self", ".", "S", ".", "usage_normalization", ")", "\n", "plt", ".", "gca", "(", ")", ".", "set_xticklabels", "(", "[", "''", "]", "+", "sorted", "(", "self", ".", "METRICS", "[", "'NumberToWords'", "]", ")", ")", "\n", "plt", ".", "gca", "(", ")", ".", "set_yticklabels", "(", "[", "''", "]", "+", "sorted", "(", "self", ".", "METRICS", "[", "'NumberToWords'", "]", ")", ")", "\n", "plt", ".", "gca", "(", ")", ".", "xaxis", ".", "set_major_locator", "(", "ticker", ".", "MultipleLocator", "(", "1", ")", ")", "\n", "plt", ".", "gca", "(", ")", ".", "yaxis", ".", "set_major_locator", "(", "ticker", ".", "MultipleLocator", "(", "1", ")", ")", "\n", "if", "self", ".", "store_video", ":", "\n", "        ", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "self", ".", "plot_name", ",", "'video/sharing-rate_'", "+", "\n", "str", "(", "self", ".", "step", ")", ")", ")", "\n", "", "plt", ".", "gcf", "(", ")", ".", "colorbar", "(", "cax", ")", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "self", ".", "plot_name", ",", "'sharing-rate'", ")", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "\n", "", "", "def", "log_metrics", "(", "self", ")", ":", "\n", "    ", "'''\n    Creates all plots based on self.METRICS.\n    '''", "\n", "# Plot Usage rate", "\n", "self", ".", "S", ".", "plot_usage", "(", "directory", "=", "self", ".", "plot_name", ")", "\n", "self", ".", "S", ".", "plot_customized_usage_rate", "(", "directory", "=", "self", ".", "plot_name", ")", "\n", "self", ".", "plot_sharing", "(", ")", "\n", "\n", "# Plot basic modules", "\n", "if", "self", ".", "T", ".", "MTRAIN", "[", "0", "]", ".", "TrainInput", ".", "shape", "[", "-", "1", "]", ">", "1", ":", "return", "\n", "print_plot", "=", "0", "\n", "input_range", "=", "np", ".", "linspace", "(", "-", "1", ",", "1", ")", ".", "reshape", "(", "(", "-", "1", ",", "1", ")", ")", "\n", "norm_input_range", "=", "self", ".", "T", ".", "normalize_input", "(", "input_range", ")", "\n", "norm_input_torch", "=", "torch", ".", "FloatTensor", "(", "norm_input_range", ")", ".", "to", "(", "\n", "device", "=", "self", ".", "nn_device", ")", "\n", "if", "self", ".", "perm_sample_modules", "is", "None", ":", "\n", "      ", "self", ".", "perm_sample_modules", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "self", ".", "L", ")", ",", "\n", "min", "(", "len", "(", "self", ".", "L", ")", ",", "9", ")", ",", "replace", "=", "False", ")", "\n", "", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "3", ",", "ncols", "=", "3", ")", "\n", "for", "i", "in", "range", "(", "min", "(", "len", "(", "self", ".", "L", ")", ",", "9", ")", ")", ":", "\n", "      ", "net", "=", "self", ".", "L", "[", "self", ".", "perm_sample_modules", "[", "i", "]", "]", "\n", "color", "=", "'b'", "\n", "if", "net", ".", "inp", "==", "1", "and", "net", ".", "out", "==", "1", ":", "#plotable function", "\n", "        ", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "plot", "(", "input_range", ",", "\n", "2.", "*", "self", ".", "T", ".", "denormalize_output", "(", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.SAConfig_SGDModules": [[758, 977], ["numpy.exp", "torch.nn.CosineSimilarity", "torch.nn.CosineSimilarity", "modular_metalearning.BounceGrad.S.initialize_all_structures", "print", "tqdm.tqdm.tqdm", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.ReduceLROnPlateau", "torch.optim.lr_scheduler.ReduceLROnPlateau", "modular_metalearning.BounceGrad.S.load_structures", "range", "numpy.exp", "modular_metalearning.BounceGrad.initialize_mtrain_metrics_tracking", "modular_metalearning.BounceGrad._initialize_mval_metrics_tracking", "enumerate", "modular_metalearning.BounceGrad.SOpt.zero_grad", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.update_metrics", "len", "modular_metalearning.BounceGrad.SOpt_scheduler.step", "print", "modular_metalearning.BounceGrad.encoder.train", "module.train", "enumerate", "modular_metalearning.BounceGrad.encoder.eval", "module.eval", "modular_metalearning.BounceGrad.batched_bounce", "zip", "modular_metalearning.BounceGrad._update_mval_perf_tracking", "numpy.log10().item", "numpy.log10().item", "modular_metalearning.BounceGrad.writer.add_scalar", "range", "range", "modular_metalearning.BounceGrad.temporal_acc_SA_truth_mval.keys", "modular_metalearning.BounceGrad.save_train_state", "max", "modular_metalearning.BounceGrad.batched_bounce", "zip", "modular_metalearning.BounceGrad._update_mtrain_perf_tracking", "modular_metalearning.BounceGrad.SOpt.step", "modular_metalearning.BounceGrad.SOpt.zero_grad", "modular_metalearning.BounceGrad.do_plot_with_without_node", "modular_metalearning.BounceGrad.encoder_loss().detach().cpu().numpy", "numpy.array", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "matplotlib.figure", "range", "range", "matplotlib.xlim", "matplotlib.ylim", "modular_metalearning.BounceGrad.writer.add_figure", "matplotlib.clf", "time.time", "modular_metalearning.BounceGrad.encoder_loss", "modular_metalearning.BounceGrad.encoder_step", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor.detach().cpu().numpy", "torch.Tensor.detach().cpu().numpy", "print", "modular_metalearning.BounceGrad.LocalOpt.step", "modular_metalearning.BounceGrad.LocalOpt.zero_grad", "numpy.log10", "numpy.log10", "numpy.mean", "numpy.median", "range", "matplotlib.scatter", "numpy.mean", "modular_metalearning.BounceGrad.T.MTRAIN[].TrainOutput.numel", "numpy.mean", "modular_metalearning.BounceGrad.T.MTRAIN[].TrainOutput.numel", "len", "modular_metalearning.BounceGrad.encoder_loss().detach().cpu", "str", "numpy.array", "str", "numpy.array", "matplotlib.scatter", "str", "torch.Tensor.detach().cpu", "torch.Tensor.detach().cpu", "sum", "numpy.sum", "dataset.TrainInput[].detach().cpu().numpy", "dataset.TrainInput[].detach().cpu().numpy", "modular_metalearning.BounceGrad.encoder_loss().detach", "torch.Tensor.detach", "torch.Tensor.detach", "p.norm().item", "dataset.TrainInput[].detach().cpu", "dataset.TrainInput[].detach().cpu", "modular_metalearning.BounceGrad.L.parameters", "modular_metalearning.BounceGrad.encoder_loss", "p.norm", "len", "dataset.TrainInput[].detach", "dataset.TrainInput[].detach"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.initialize_all_structures", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.load_structures", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.initialize_mtrain_metrics_tracking", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad._initialize_mval_metrics_tracking", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.update_metrics", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.batched_bounce", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad._update_mval_perf_tracking", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.save_train_state", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.batched_bounce", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad._update_mtrain_perf_tracking", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.do_plot_with_without_node", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.encoder_loss", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.encoder_step", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.encoder_loss"], ["print_plot", "+=", "1", "\n", "", "", "if", "print_plot", ">", "0", ":", "\n", "      ", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "self", ".", "plot_name", ",", "'sample-modules'", ")", ")", "\n", "if", "self", ".", "store_video", ":", "\n", "        ", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "self", ".", "plot_name", ",", "\n", "'video/modules_'", "+", "str", "(", "self", ".", "step", ")", ")", ")", "\n", "", "plt", ".", "cla", "(", ")", "\n", "# Plot basic comparisons", "\n", "", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "3", ",", "ncols", "=", "3", ")", "\n", "if", "self", ".", "perm_sample_fns", "is", "None", ":", "\n", "      ", "self", ".", "perm_sample_fns", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "self", ".", "T", ".", "MTRAIN", ")", ",", "\n", "min", "(", "len", "(", "self", ".", "T", ".", "MTRAIN", ")", ",", "9", ")", ",", "replace", "=", "False", ")", "\n", "", "for", "i", "in", "range", "(", "min", "(", "len", "(", "self", ".", "T", ".", "MTRAIN", ")", ",", "9", ")", ")", ":", "\n", "      ", "dataset", "=", "self", ".", "T", ".", "MTRAIN", "[", "self", ".", "perm_sample_fns", "[", "i", "]", "]", "\n", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "scatter", "(", "dataset", ".", "UValInput", ",", "\n", "dataset", ".", "UValOutput", ",", "c", "=", "'g'", ",", "label", "=", "'val'", ")", "\n", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "scatter", "(", "dataset", ".", "UTrainInput", ",", "\n", "dataset", ".", "UTrainOutput", ",", "c", "=", "'r'", ",", "label", "=", "'train'", ",", "\n", "s", "=", "18", ")", "\n", "if", "self", ".", "MAML", ":", "\n", "        ", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "scatter", "(", "self", ".", "T", ".", "MTRAIN", "[", "self", ".", "perm_sample_fns", "[", "i", "]", "]", ".", "UValInput", ",", "\n", "self", ".", "T", ".", "denormalize_output", "(", "\n", "self", ".", "MTrainAnswers", "[", "self", ".", "perm_sample_fns", "[", "i", "]", "]", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "structure", "=", "self", ".", "S", ".", "TrainStructures", "[", "self", ".", "perm_sample_fns", "[", "i", "]", "]", "\n", "structure_output", "=", "self", ".", "T", ".", "denormalize_output", "(", "self", ".", "run_model", "(", "structure", ",", "\n", "norm_input_torch", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "plot", "(", "input_range", ",", "structure_output", ")", "\n", "", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "set_xlim", "(", "[", "\n", "np", ".", "floor", "(", "np", ".", "min", "(", "self", ".", "T", ".", "MTRAIN", "[", "self", ".", "perm_sample_fns", "[", "i", "]", "]", ".", "UValInput", ")", ")", ",", "\n", "np", ".", "ceil", "(", "np", ".", "max", "(", "self", ".", "T", ".", "MTRAIN", "[", "self", ".", "perm_sample_fns", "[", "i", "]", "]", ".", "UValInput", ")", ")", "]", ")", "\n", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "set_ylim", "(", "[", "\n", "np", ".", "floor", "(", "np", ".", "min", "(", "self", ".", "T", ".", "MTRAIN", "[", "self", ".", "perm_sample_fns", "[", "i", "]", "]", ".", "UValOutput", ")", ")", "-", ".5", ",", "\n", "np", ".", "ceil", "(", "np", ".", "max", "(", "self", ".", "T", ".", "MTRAIN", "[", "self", ".", "perm_sample_fns", "[", "i", "]", "]", ".", "UValOutput", ")", ")", "+", ".5", "]", ")", "\n", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "set_xticks", "(", "np", ".", "array", "(", "[", "-", "1", ",", "0", ",", "1", "]", ")", ")", "\n", "ax", "[", "i", "//", "3", ",", "i", "%", "3", "]", ".", "set_yticks", "(", "np", ".", "array", "(", "[", "-", "1", ",", "0", ",", "1", "]", ")", ")", "\n", "", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "self", ".", "plot_name", ",", "'comparisons'", ")", ")", "\n", "if", "self", ".", "store_video", ":", "\n", "      ", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "self", ".", "plot_name", ",", "\n", "'video/comparisons_'", "+", "str", "(", "self", ".", "step", ")", ")", ")", "\n", "", "plt", ".", "clf", "(", ")", "\n", "\n", "", "def", "update_Sharing_counters", "(", "self", ")", ":", "\n", "    ", "'''\n    Updates table of E[# of modules shared by 2 keywords]\n    More precisely dataset names are a list of keywords A_B_C\n    the entries of the table are those keywords.\n\n    For example:\n     - square_plywood in the MIT dataset --> object=square,surface=plywood\n     - 1_4 in the Berkeley dataset --> action 1 actor 5\n    These plots show what structure the modules capture\n    '''", "\n", "if", "self", ".", "meta_lr", "==", "0", "or", "self", ".", "mtrain_copies", ">", "1", ":", "\n", "      ", "if", "self", ".", "step", "==", "0", ":", "print", "(", "'Not doing Sharing for now'", ")", "\n", "return", "\n", "", "if", "len", "(", "self", ".", "METRICS", "[", "'WordsToNumber'", "]", ")", ">", "50", ":", "return", "#too many keywords", "\n", "eps", "=", "1e-3", "\n", "self", ".", "S", ".", "usage_normalization", "=", "self", ".", "S", ".", "usage_normalization", "*", "(", "1", "-", "eps", ")", "+", "eps", "\n", "for", "i_s", ",", "i_structure", "in", "enumerate", "(", "\n", "self", ".", "S", ".", "TrainStructures", "+", "self", ".", "S", ".", "ValStructures", ")", ":", "\n", "      ", "for", "j_s", ",", "j_structure", "in", "enumerate", "(", "\n", "self", ".", "S", ".", "TrainStructures", "+", "self", ".", "S", ".", "ValStructures", ")", ":", "\n", "#count number of matches", "\n", "        ", "i_modules", "=", "self", ".", "S", ".", "modules_given_structure", "(", "i_structure", ")", "\n", "j_modules", "=", "self", ".", "S", ".", "modules_given_structure", "(", "j_structure", ")", "\n", "count", "=", "0", "\n", "for", "a", "in", "set", "(", "i_modules", ")", ":", "\n", "          ", "count", "+=", "min", "(", "i_modules", ".", "count", "(", "a", ")", ",", "j_modules", ".", "count", "(", "a", ")", ")", "\n", "", "count", "/=", "len", "(", "i_modules", ")", "\n", "if", "i_s", "<", "self", ".", "T", ".", "mtrain", ":", "i_words", "=", "self", ".", "T", ".", "MTRAIN", "[", "i_s", "]", ".", "name", ".", "split", "(", "'_'", ")", "\n", "else", ":", "i_words", "=", "self", ".", "T", ".", "MVAL", "[", "i_s", "-", "self", ".", "T", ".", "mtrain", "]", ".", "name", ".", "split", "(", "'_'", ")", "\n", "if", "j_s", "<", "self", ".", "T", ".", "mtrain", ":", "j_words", "=", "self", ".", "T", ".", "MTRAIN", "[", "j_s", "]", ".", "name", ".", "split", "(", "'_'", ")", "\n", "else", ":", "j_words", "=", "self", ".", "T", ".", "MVAL", "[", "j_s", "-", "self", ".", "T", ".", "mtrain", "]", ".", "name", ".", "split", "(", "'_'", ")", "\n", "for", "i_w", "in", "i_words", "+", "j_words", ":", "\n", "          ", "if", "i_w", "not", "in", "self", ".", "METRICS", "[", "'WordsToNumber'", "]", ":", "\n", "            ", "self", ".", "METRICS", "[", "'WordsToNumber'", "]", "[", "i_w", "]", "=", "(", "\n", "len", "(", "self", ".", "METRICS", "[", "'WordsToNumber'", "]", ")", ")", "\n", "self", ".", "METRICS", "[", "'NumberToWords'", "]", ".", "append", "(", "i_w", ")", "\n", "if", "len", "(", "self", ".", "METRICS", "[", "'WordsToNumber'", "]", ")", ">", "50", ":", "return", "#too many keywords", "\n", "", "", "for", "i_w", "in", "i_words", ":", "\n", "          ", "for", "j_w", "in", "j_words", ":", "\n", "            ", "(", "ni_w", ",", "nj_w", ")", "=", "(", "self", ".", "METRICS", "[", "'WordsToNumber'", "]", "[", "i_w", "]", ",", "\n", "self", ".", "METRICS", "[", "'WordsToNumber'", "]", "[", "j_w", "]", ")", "\n", "self", ".", "METRICS", "[", "'Sharing'", "]", "[", "ni_w", "]", "[", "nj_w", "]", "*=", "(", "1.", "-", "eps", ")", "\n", "self", ".", "METRICS", "[", "'Sharing'", "]", "[", "nj_w", "]", "[", "ni_w", "]", "*=", "(", "1.", "-", "eps", ")", "\n", "self", ".", "METRICS", "[", "'Sharing'", "]", "[", "ni_w", "]", "[", "nj_w", "]", "+=", "count", "*", "eps", "\n", "self", ".", "METRICS", "[", "'Sharing'", "]", "[", "nj_w", "]", "[", "ni_w", "]", "+=", "count", "*", "eps", "\n", "", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.save_train_state": [[980, 989], ["modular_metalearning.BounceGrad.save_L", "modular_metalearning.BounceGrad.S.save_structures", "os.path.exists", "os.makedirs"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.save_L", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.structure.Structure.save_structures"], []], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.initialize_mtrain_metrics_tracking": [[993, 1008], ["range"], "methods", ["None"], []], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad._initialize_mval_metrics_tracking": [[1009, 1019], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad._update_mtrain_perf_tracking": [[1020, 1037], ["enumerate", "modular_metalearning.BounceGrad.mtrain_encoder_losses.append", "modular_metalearning.BounceGrad.current_train.extend", "modular_metalearning.BounceGrad.current_val.extend", "zip", "modular_metalearning.BounceGrad.current_train_every[].extend", "modular_metalearning.BounceGrad.current_val_every[].extend"], "methods", ["None"], []], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad._update_mval_perf_tracking": [[1038, 1055], ["enumerate", "modular_metalearning.BounceGrad.mval_encoder_losses.append", "modular_metalearning.BounceGrad.current_Mtrain.extend", "modular_metalearning.BounceGrad.current_Meval.extend", "zip", "modular_metalearning.BounceGrad.current_Mtrain_every[].extend", "modular_metalearning.BounceGrad.current_Meval_every[].extend"], "methods", ["None"], []], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.update_metrics": [[1056, 1204], ["max", "modular_metalearning.BounceGrad.writer.add_scalar", "max", "modular_metalearning.BounceGrad.writer.add_scalar", "max", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "len", "len", "enumerate", "max", "modular_metalearning.BounceGrad.writer.add_scalar", "max", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "max", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "numpy.mean", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "numpy.mean().item", "numpy.std().item", "numpy.mean().item", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "len", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "len", "len", "time.time", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "numpy.mean", "numpy.percentile().item", "numpy.percentile().item", "numpy.percentile().item", "numpy.percentile().item", "m.parameters", "zip", "numpy.std().item", "numpy.min().item", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "numpy.mean().item", "numpy.std().item", "numpy.min().item", "numpy.mean().item", "numpy.std().item", "numpy.min().item", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "len", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "numpy.mean", "numpy.std", "numpy.mean", "numpy.mean().item", "numpy.std().item", "numpy.min().item", "numpy.mean().item", "numpy.std().item", "numpy.min().item", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "numpy.mean().item", "numpy.std().item", "numpy.min().item", "numpy.mean().item", "numpy.std().item", "numpy.min().item", "numpy.percentile", "numpy.percentile", "numpy.percentile", "numpy.percentile", "numpy.std", "numpy.min", "numpy.mean", "numpy.std", "numpy.min", "numpy.mean", "numpy.std", "numpy.min", "numpy.mean().item", "numpy.std().item", "numpy.min().item", "numpy.mean", "numpy.std", "numpy.min", "numpy.mean", "numpy.std", "numpy.min", "numpy.mean", "numpy.std", "numpy.min", "numpy.mean", "numpy.std", "numpy.min", "numpy.mean", "numpy.std", "numpy.min"], "methods", ["None"], []], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.initialize_answers": [[1209, 1222], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad._update_mtrain_answers": [[1223, 1244], ["enumerate", "modular_metalearning.BounceGrad.MTrain_norm_diff.append", "modular_metalearning.BounceGrad.MTrain_cos_diff.append", "numpy.mean", "torch.mean().data.cpu().numpy", "torch.mean().data.cpu().numpy", "torch.mean().data.cpu().numpy", "torch.mean().data.cpu().numpy", "numpy.linalg.norm", "torch.mean().data.cpu", "torch.mean().data.cpu", "torch.mean().data.cpu", "torch.mean().data.cpu", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "modular_metalearning.BounceGrad.CosDist", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "dataset.TrainOutput.cpu", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "dataset.TrainOutput.cpu"], "methods", ["None"], []], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad._update_mval_answers": [[1245, 1257], ["enumerate"], "methods", ["None"], []], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.update_answers": [[1258, 1280], ["numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "modular_metalearning.BounceGrad.writer.add_scalar", "numpy.mean.item", "numpy.mean.item", "numpy.mean.item", "numpy.mean.item", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "range", "range", "range", "range", "modular_metalearning.BounceGrad.T.MTRAIN[].TrainOutput.cpu().numpy", "modular_metalearning.BounceGrad.T.MTRAIN[].ValOutput.cpu().numpy", "modular_metalearning.BounceGrad.T.MVAL[].TrainOutput.cpu().numpy", "modular_metalearning.BounceGrad.T.MVAL[].ValOutput.cpu().numpy", "modular_metalearning.BounceGrad.T.MTRAIN[].TrainOutput.cpu", "modular_metalearning.BounceGrad.T.MTRAIN[].ValOutput.cpu", "modular_metalearning.BounceGrad.T.MVAL[].TrainOutput.cpu", "modular_metalearning.BounceGrad.T.MVAL[].ValOutput.cpu"], "methods", ["None"], []], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.save_L": [[1285, 1297], ["enumerate", "os.path.exists", "os.makedirs", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "module.state_dict", "os.path.join", "modular_metalearning.BounceGrad.encoder.state_dict", "os.path.join", "str"], "methods", ["None"], []], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.modular_metalearning.BounceGrad.load_L": [[1299, 1310], ["enumerate", "modular_metalearning.BounceGrad.L[].load_state_dict", "modular_metalearning.BounceGrad.encoder.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "os.path.join", "os.path.join", "str"], "methods", ["None"], []], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.composition.Composer.__init__": [[33, 49], ["torch.nn.Module.__init__", "len", "type", "type", "torch.nn.ModuleList"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__"], ["class", "Composer", "(", "nn", ".", "Module", ")", ":", "\n", "  ", "'''\n  Composes multiple modules into a single net.\n  '''", "\n", "def", "__init__", "(", "self", ",", "composer", ",", "module_list", ",", "loss_fn", "=", "None", ",", "structure", "=", "{", "}", ",", "\n", "instructions", "=", "{", "}", ")", ":", "\n", "    ", "'''\n    composer: string describing the composer type\n    structure: specifies how to compose which modules\n    loss_fn: loss function\n    instructions: can be left blank, customizable non-computation parameters\n    '''", "\n", "super", "(", "Composer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "module_list", "=", "module_list", "\n", "assert", "type", "(", "module_list", ")", "==", "type", "(", "torch", ".", "nn", ".", "ModuleList", "(", ")", ")", "\n", "self", ".", "num_modules", "=", "len", "(", "self", ".", "module_list", ")", "\n", "self", ".", "composer", "=", "composer", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.composition.Composer.forward_no_weights": [[50, 56], ["None"], "methods", ["None"], ["self", ".", "loss_fn", "=", "loss_fn", "\n", "self", ".", "structure", "=", "structure", "\n", "self", ".", "instructions", "=", "instructions", "\n", "\n", "", "def", "forward_no_weights", "(", "self", ",", "x", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.composition.Composer.forward_with_weights": [[57, 63], ["None"], "methods", ["None"], ["\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "forward_with_weights", "(", "self", ",", "x", ",", "weights", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.composition.Composer.forward": [[64, 71], ["composition.Composer.forward_no_weights", "composition.Composer.forward_with_weights"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Composer.forward_no_weights", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.composition.Composer.forward_with_weights"], ["\n", "raise", "NotImplementedError", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "weights", "=", "None", ")", ":", "\n", "##  TODO: use the forward method of each method for weights!=None", "\n", "##  instead of manual code.", "\n", "    ", "if", "weights", "is", "None", ":", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.composition.Composer.net_forward": [[72, 74], ["composition.Composer.forward"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.forward"], ["      ", "return", "self", ".", "forward_no_weights", "(", "x", ")", "\n", "", "else", ":", "\n", "      ", "return", "self", ".", "forward_with_weights", "(", "x", ",", "weights", ")", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.composition.Composer.copy_weights": [[75, 84], ["zip", "net.modules", "composition.Composer.modules", "isinstance", "isinstance", "isinstance", "m_from.weight.data.clone", "m_from.bias.data.clone"], "methods", ["None"], ["\n", "", "", "def", "net_forward", "(", "self", ",", "x", ",", "weights", "=", "None", ")", ":", "\n", "    ", "return", "self", ".", "forward", "(", "x", ",", "weights", ")", "\n", "\n", "", "def", "copy_weights", "(", "self", ",", "net", ")", ":", "\n", "    ", "'''Set this module's weights to be the same as those of 'net' '''", "\n", "raise", "NotImplementedError", "\n", "for", "m_from", ",", "m_to", "in", "zip", "(", "net", ".", "modules", "(", ")", ",", "self", ".", "modules", "(", ")", ")", ":", "\n", "      ", "if", "(", "isinstance", "(", "m_to", ",", "nn", ".", "Linear", ")", "or", "isinstance", "(", "m_to", ",", "nn", ".", "Conv2d", ")", "\n", "or", "isinstance", "(", "m_to", ",", "nn", ".", "BatchNorm2d", ")", ")", ":", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Composer.__init__": [[20, 39], ["composition.Composer.__init__"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__"], ["  ", "def", "__init__", "(", "self", ",", "composer", ",", "module_list", ",", "loss_fn", "=", "None", ",", "structure", "=", "{", "}", ",", "\n", "instructions", "=", "{", "}", ")", ":", "\n", "    ", "super", "(", "HGNN_Composer", ",", "self", ")", ".", "__init__", "(", "composer", "=", "composer", ",", "\n", "module_list", "=", "module_list", ",", "\n", "loss_fn", "=", "loss_fn", ",", "structure", "=", "structure", ",", "instructions", "=", "instructions", ")", "\n", "self", ".", "graph", "=", "self", ".", "structure", "[", "'graph'", "]", "\n", "#Order must be:", "\n", "# a) Nodes", "\n", "# b) Edges", "\n", "end_nodes", "=", "self", ".", "structure", "[", "'end_nodes'", "]", "\n", "end_edges", "=", "self", ".", "structure", "[", "'end_edges'", "]", "\n", "\n", "self", ".", "node_modules", "=", "self", ".", "module_list", "[", ":", "end_nodes", "]", "\n", "self", ".", "edge_modules", "=", "self", ".", "module_list", "[", "end_nodes", ":", "end_edges", "]", "\n", "self", ".", "msg_sz", "=", "self", ".", "structure", "[", "'msg_sz'", "]", "\n", "self", ".", "node_dim", "=", "self", ".", "structure", "[", "'node_dim'", "]", "\n", "self", ".", "update_sz", "=", "self", ".", "structure", "[", "'update_sz'", "]", "\n", "self", ".", "visualize", "=", "(", "'visualize'", "in", "self", ".", "instructions", "\n", "and", "self", ".", "instructions", "[", "'visualize'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Composer.visualize_graph": [[40, 47], ["networkx.Graph", "networkx.Graph.add_nodes_from", "enumerate", "list", "map", "networkx.Graph.add_edge", "range"], "methods", ["None"], ["", "def", "visualize_graph", "(", "self", ")", ":", "\n", "# import networkx as nx", "\n", "    ", "G", "=", "nx", ".", "Graph", "(", ")", "\n", "G", ".", "add_nodes_from", "(", "list", "(", "range", "(", "1", ",", "self", ".", "structure", "[", "\"num_nodes\"", "]", ")", ")", ")", "\n", "for", "i", ",", "edge", "in", "enumerate", "(", "map", "(", "tuple", ",", "self", ".", "structure", "[", "'graph'", "]", "[", "\"edges\"", "]", ")", ")", ":", "\n", "      ", "type", "=", "'r'", "if", "self", ".", "structure", "[", "\"edge_idx_inv\"", "]", "[", "i", "]", "else", "'b'", "\n", "G", ".", "add_edge", "(", "*", "edge", ",", "color", "=", "type", ",", "weight", "=", "5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Composer.forward_no_weights": [[57, 118], ["hgnn_composer.HGNN_Composer.inp_to_graph_inp", "range", "torch.zeros().cuda", "torch.zeros().cuda", "torch.cuda.LongTensor().reshape", "hgnn_composer.HGNN_Composer.structure[].append", "enumerate", "enumerate", "node_hist.append", "hgnn_composer.HGNN_Composer.graph_out_to_out", "range", "hgnn_composer.HGNN_Composer.structure[].append", "len", "torch.zeros().cuda.scatter_().cuda", "nodes[].clone", "nodes[].clone", "torch.cat", "module().view", "[].clone", "nodes[].clone", "torch.cat().view", "module().view", "hgnn_composer.HGNN_Composer.clone", "hgnn_composer.HGNN_Composer.graph_out_to_out", "torch.zeros", "torch.zeros", "torch.cuda.LongTensor", "len", "torch.matmul", "len", "nodes[].clone", "_.data.cpu().numpy", "len", "numpy.array", "torch.zeros().cuda.scatter_", "module", "torch.cat", "module", "torch.cat.view", "_.data.cpu"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Composer.inp_to_graph_inp", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Composer.graph_out_to_out", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Composer.graph_out_to_out"], ["", "", "def", "forward_no_weights", "(", "self", ",", "x", ")", ":", "\n", "    ", "nodes", "=", "self", ".", "inp_to_graph_inp", "(", "x", ")", "\n", "# number of steps to predict: -1 because the first one is input", "\n", "# self.visualize_graph()", "\n", "steps", "=", "self", ".", "structure", "[", "'self_regress_steps'", "]", "\n", "self", ".", "bs", "=", "nodes", ".", "shape", "[", "0", "]", "# batch_size", "\n", "self", ".", "n", "=", "nodes", ".", "shape", "[", "1", "]", "# number of nodes", "\n", "# incoming messages?", "\n", "incoming", "=", "[", "torch", ".", "zeros", "(", "self", ".", "bs", ",", "self", ".", "n", ",", "self", ".", "msg_sz", ")", ".", "cuda", "(", ")", "for", "_", "in", "range", "(", "steps", "+", "1", ")", "]", "\n", "## Pointing tensors ##", "\n", "edge_sources", "=", "self", ".", "structure", "[", "'edge_sources'", "]", "# module->[list of nodes]", "\n", "edge_sinks", "=", "self", ".", "structure", "[", "'edge_sinks'", "]", "# module->[list of nodes]", "\n", "node_idx", "=", "self", ".", "structure", "[", "'node_idx'", "]", "# module->[list of nodes]", "\n", "node_hist", "=", "[", "]", "\n", "# node_hist.append(nodes.clone())", "\n", "#Sinks", "\n", "self", ".", "structure", "[", "'sinks_one_hot'", "]", "=", "[", "]", "\n", "# import ipdb; ipdb.set_trace()", "\n", "\n", "# create one-hot feature embedding of edge sinks?", "\n", "for", "sinks", "in", "self", ".", "structure", "[", "'edge_sinks'", "]", ":", "\n", "      ", "if", "sinks", "==", "[", "]", ":", "\n", "        ", "self", ".", "structure", "[", "'sinks_one_hot'", "]", ".", "append", "(", "None", ")", "\n", "continue", "\n", "", "z", "=", "torch", ".", "zeros", "(", "self", ".", "structure", "[", "'num_nodes'", "]", ",", "len", "(", "sinks", ")", ")", ".", "cuda", "(", ")", "\n", "aux_idx", "=", "torch", ".", "cuda", ".", "LongTensor", "(", "np", ".", "array", "(", "sinks", ")", ")", ".", "reshape", "(", "-", "1", ",", "len", "(", "sinks", ")", ")", "\n", "self", ".", "structure", "[", "'sinks_one_hot'", "]", ".", "append", "(", "z", ".", "scatter_", "(", "dim", "=", "0", ",", "index", "=", "aux_idx", ",", "value", "=", "1.", ")", ".", "cuda", "(", ")", ")", "\n", "# print('1-hot: ', self.structure['sinks_one_hot'][-1])", "\n", "\n", "", "for", "step", "in", "range", "(", "steps", ")", ":", "\n", "# Edge modules: concat input from sources and sinks and feed through edge module", "\n", "      ", "for", "i", ",", "module", "in", "enumerate", "(", "self", ".", "edge_modules", ")", ":", "\n", "        ", "if", "len", "(", "edge_sources", "[", "i", "]", ")", "==", "0", ":", "continue", "\n", "sources", "=", "nodes", "[", ":", ",", "edge_sources", "[", "i", "]", ",", ":", "]", ".", "clone", "(", ")", "\n", "sinks", "=", "nodes", "[", ":", ",", "edge_sinks", "[", "i", "]", ",", ":", "]", ".", "clone", "(", ")", "\n", "# concat messages from source and sink to form edge state", "\n", "inp", "=", "torch", ".", "cat", "(", "[", "sources", ",", "sinks", "]", ",", "dim", "=", "2", ")", "\n", "# feed through edge module", "\n", "out", "=", "module", "(", "inp", ".", "view", "(", "-", "1", ",", "inp", ".", "shape", "[", "2", "]", ")", ")", ".", "view", "(", "self", ".", "bs", ",", "-", "1", ",", "self", ".", "msg_sz", ")", "\n", "incoming", "[", "step", "]", "=", "(", "incoming", "[", "step", "]", "+", "torch", ".", "matmul", "(", "self", ".", "structure", "[", "'sinks_one_hot'", "]", "[", "i", "]", ",", "out", ")", ")", "\n", "# for (j, sink) in enumerate(edge_sinks[i]): # TODO: vectorize", "\n", "#   incoming[step][:, sink, :] = (incoming[step][:, sink, :].clone() + out[:, j, :])", "\n", "\n", "# Node modules: pick added messages and old value -> put new", "\n", "", "for", "(", "i", ",", "module", ")", "in", "enumerate", "(", "self", ".", "node_modules", ")", ":", "\n", "        ", "if", "len", "(", "node_idx", "[", "i", "]", ")", "==", "0", ":", "continue", "\n", "msg", "=", "incoming", "[", "step", "]", "[", ":", ",", "node_idx", "[", "i", "]", ",", ":", "]", ".", "clone", "(", ")", "\n", "old", "=", "nodes", "[", ":", ",", "node_idx", "[", "i", "]", ",", ":", "]", ".", "clone", "(", ")", "\n", "# Updates node's value; no worries about updating too early since each node only affects itself.", "\n", "aux", "=", "torch", ".", "cat", "(", "[", "msg", ",", "old", "]", ",", "dim", "=", "2", ")", ".", "view", "(", "-", "1", ",", "self", ".", "node_dim", "+", "self", ".", "msg_sz", ")", "\n", "aux", "=", "module", "(", "aux", ")", ".", "view", "(", "self", ".", "bs", ",", "-", "1", ",", "self", ".", "update_sz", ")", "\n", "nodes", "[", ":", ",", "node_idx", "[", "i", "]", ",", "-", "self", ".", "update_sz", ":", "]", "=", "nodes", "[", ":", ",", "node_idx", "[", "i", "]", ",", "-", "self", ".", "update_sz", ":", "]", ".", "clone", "(", ")", "+", "aux", "\n", "\n", "", "node_hist", ".", "append", "(", "nodes", ".", "clone", "(", ")", ")", "\n", "\n", "", "del", "self", ".", "structure", "[", "'sinks_one_hot'", "]", "\n", "# if np.random.rand() < 1./2500:", "\n", "#   import pdb; pdb.set_trace()", "\n", "if", "self", ".", "visualize", ":", "\n", "      ", "return", "self", ".", "graph_out_to_out", "(", "node_hist", ")", ",", "[", "_", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "for", "_", "in", "node_hist", "]", "\n", "", "else", ":", "return", "self", ".", "graph_out_to_out", "(", "node_hist", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Composer.inp_to_graph_inp": [[119, 132], ["x[].clone"], "methods", ["None"], ["", "def", "inp_to_graph_inp", "(", "self", ",", "x", ")", ":", "\n", "    ", "'''\n    Goes from input tensor to tensor in graph space\n    '''", "\n", "# graph_type = self.graph['type']", "\n", "# if 'original_input_shape' in self.structure:", "\n", "#   x = x.reshape(tuple([-1]+list(self.structure['original_input_shape'][1:])))", "\n", "self", ".", "initial_inp", "=", "x", "#maybe clone()?", "\n", "if", "'self_regress_steps'", "in", "self", ".", "structure", ":", "\n", "# taking only the first step of every self_regress_step steps as input upon which we will make predictions", "\n", "      ", "x", "=", "x", "[", "0", ":", ":", "self", ".", "structure", "[", "'self_regress_steps'", "]", ",", ":", ",", ":", "]", ".", "clone", "(", ")", "\n", "", "else", ":", "raise", "NotImplementedError", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Composer.graph_out_to_out": [[133, 153], ["range", "torch.zeros", "len", "node_hist[].reshape", "range", "node_hist[].reshape", "node_hist[].clone", "len"], "methods", ["None"], ["", "def", "graph_out_to_out", "(", "self", ",", "node_hist", ")", ":", "\n", "    ", "'''\n    Goes from output in graph space to final output\n    '''", "\n", "# graph_type = self.graph['type']", "\n", "for", "i", "in", "range", "(", "len", "(", "node_hist", ")", ")", ":", "\n", "# import ipdb; ipdb.set_trace()", "\n", "      ", "node_hist", "[", "i", "]", "=", "node_hist", "[", "i", "]", ".", "reshape", "(", "(", "node_hist", "[", "i", "]", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "", "out", "=", "torch", ".", "zeros", "(", "[", "node_hist", "[", "0", "]", ".", "shape", "[", "0", "]", "*", "len", "(", "node_hist", ")", ",", "node_hist", "[", "0", "]", ".", "shape", "[", "1", "]", "]", ")", "\n", "if", "'self_regress_steps'", "in", "self", ".", "structure", ":", "\n", "      ", "for", "i", "in", "range", "(", "self", ".", "structure", "[", "'self_regress_steps'", "]", ")", ":", "\n", "        ", "out", "[", "i", ":", ":", "self", ".", "structure", "[", "'self_regress_steps'", "]", "]", "=", "node_hist", "[", "i", "]", ".", "clone", "(", ")", "\n", "# out = out.reshape((out.shape[0], -1))", "\n", "# make_dot(out).save('help.dot')", "\n", "# print('Saved figure!')", "\n", "# import pdb; pdb.set_trace()", "\n", "", "return", "out", "[", ":", "self", ".", "initial_inp", ".", "shape", "[", "0", "]", "-", "1", "]", "\n", "", "else", ":", "\n", "      ", "raise", "NotImplementedError", "\n", "return", "node_hist", "[", "-", "1", "]", ".", "reshape", "(", "(", "node_hist", "[", "-", "1", "]", ".", "shape", "[", "0", "]", ",", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.__init__": [[155, 178], ["hgnn_composer.HGNN_Structure.composer.split", "len", "len", "copy.deepcopy", "hgnn_composer.HGNN_Structure.graph[].split", "structure.Structure.__init__", "numpy.zeros", "len", "open", "json.load", "hgnn_composer.HGNN_Structure.composer.split", "max", "len", "len"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__"], ["  ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "    ", "self", ".", "composer_class", "=", "HGNN_Composer", "\n", "self", ".", "composer_abbreviation", "=", "'H_GRAPH'", "\n", "#Loads configuration file for graph composer", "\n", "self", ".", "composer", "=", "args", ".", "composer", "\n", "assert", "len", "(", "self", ".", "composer", ".", "split", "(", "'@'", ")", ")", "==", "2", "\n", "[", "self", ".", "composer", ",", "self", ".", "composer_file", "]", "=", "self", ".", "composer", ".", "split", "(", "'@'", ")", "\n", "with", "open", "(", "self", ".", "composer_file", ",", "'r'", ")", "as", "infile", ":", "\n", "      ", "self", ".", "graph", "=", "json", ".", "load", "(", "infile", ")", "\n", "", "self", ".", "graph", "[", "'num_nodes'", "]", "=", "len", "(", "self", ".", "graph", "[", "'nodes'", "]", ")", "\n", "self", ".", "graph", "[", "'num_edges'", "]", "=", "len", "(", "self", ".", "graph", "[", "'edges'", "]", ")", "\n", "self", ".", "graph", "[", "'num_slots'", "]", "=", "self", ".", "graph", "[", "'num_nodes'", "]", "+", "self", ".", "graph", "[", "'num_edges'", "]", "\n", "self", ".", "loaded_graph", "=", "copy", ".", "deepcopy", "(", "self", ".", "graph", ")", "\n", "self", ".", "composer", "=", "'gnn'", "\n", "self", ".", "type_modules", "=", "self", ".", "graph", "[", "'type_modules'", "]", ".", "split", "(", "','", ")", "\n", "self", ".", "num_steps", "=", "self", ".", "graph", "[", "'num_steps'", "]", "\n", "super", "(", "HGNN_Structure", ",", "self", ")", ".", "__init__", "(", "args", "=", "args", ")", "\n", "\n", "self", ".", "has_global_variable", "=", "False", "\n", "self", ".", "PosUsage", "=", "None", "\n", "self", ".", "GNNUsage", "=", "np", ".", "zeros", "(", "(", "\n", "max", "(", "len", "(", "self", ".", "graph", "[", "'nodes'", "]", ")", ",", "len", "(", "self", ".", "graph", "[", "'edges'", "]", ")", ")", ",", "self", ".", "tot_modules", ")", ")", "\n", "self", ".", "StructureParameters", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.save_customized_files": [[179, 182], ["open", "json.dump", "os.path.join"], "methods", ["None"], ["", "def", "save_customized_files", "(", "self", ",", "directory", ")", ":", "\n", "    ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "'graph.json'", ")", ",", "'w'", ")", "as", "outfile", ":", "\n", "      ", "json", ".", "dump", "(", "self", ".", "loaded_graph", ",", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.get_plot_name": [[183, 196], ["args.plot_name.startswith", "plot_name.replace.replace.replace", "print", "input", "len", "str", "str", "args.data_desc.split"], "methods", ["None"], ["", "", "def", "get_plot_name", "(", "self", ",", "args", ",", "plot_name", ")", ":", "\n", "    ", "if", "args", ".", "plot_name", ".", "startswith", "(", "'wf'", ")", ":", "\n", "      ", "extra", "=", "args", ".", "plot_name", "[", "2", ":", "]", "\n", "if", "len", "(", "extra", ")", "and", "extra", "[", "0", "]", "in", "[", "'-'", ",", "'_'", "]", ":", "extra", "=", "extra", "[", "1", ":", "]", "\n", "plot_name", "=", "self", ".", "composer_file", "[", ":", "-", "5", "]", "#remove json", "\n", "plot_name", "+=", "'nm='", "+", "args", ".", "num_modules", "+", "'lr='", "+", "str", "(", "args", ".", "adam_lr", ")", "\n", "plot_name", "+=", "'opt='", "+", "str", "(", "args", ".", "optimization_steps", ")", "\n", "plot_name", "+=", "'data='", "+", "args", ".", "data_desc", ".", "split", "(", "'@'", ")", "[", "1", "]", "[", ":", "5", "]", "\n", "plot_name", "=", "plot_name", ".", "replace", "(", "'/'", ",", "''", ")", "\n", "plot_name", "+=", "'name='", "+", "extra", "\n", "plot_name", "+=", "'/'", "\n", "print", "(", "'Plot name: '", ",", "plot_name", ")", "\n", "input", "(", "'press enter to continue'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.initialize_all_structures": [[197, 226], ["tqdm.tqdm.tqdm", "range", "torch.nn.ParameterList", "numpy.ones", "numpy.ones", "range", "hgnn_composer.HGNN_Structure.initialize_structure", "len", "hgnn_composer.HGNN_Structure.initialize_structure", "len"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.initialize_structure", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.initialize_structure"], ["", "", "def", "initialize_all_structures", "(", "self", ",", "T", ")", ":", "\n", "#Initialize node x node -> edge", "\n", "    ", "find_node", "=", "self", ".", "find_node", "\n", "if", "find_node", ":", "self", ".", "StructureParameters", "=", "nn", ".", "ParameterList", "(", ")", "\n", "if", "'num_types'", "in", "self", ".", "graph", ":", "\n", "      ", "self", ".", "num_types", "=", "self", ".", "graph", "[", "'num_types'", "]", "\n", "", "else", ":", "self", ".", "num_types", "=", "2", "\n", "C", "=", "5", "\n", "self", ".", "TypeTypeToEdge", "=", "C", "*", "np", ".", "ones", "(", "(", "self", ".", "num_types", ",", "self", ".", "num_types", ",", "\n", "self", ".", "num_modules", "[", "1", "]", ")", ")", "\n", "self", ".", "TypeTypeNode", "=", "C", "*", "np", ".", "ones", "(", "(", "self", ".", "num_types", ",", "self", ".", "num_types", ",", "\n", "self", ".", "num_modules", "[", "0", "]", ")", ")", "\n", "assert", "self", ".", "num_modules", "[", "0", "]", "==", "1", "\n", "self", ".", "TrainStructures", "=", "[", "None", "for", "_", "in", "T", ".", "MTRAIN", "]", "\n", "self", ".", "ValStructures", "=", "[", "None", "for", "_", "in", "T", ".", "MVAL", "]", "\n", "for", "i", "in", "Tqdm", "(", "range", "(", "len", "(", "self", ".", "TrainStructures", ")", ")", ")", ":", "\n", "      ", "self", ".", "TrainStructures", "[", "i", "]", "=", "self", ".", "initialize_structure", "(", "\n", "find_node", "=", "find_node", ",", "dataset", "=", "T", ".", "MTRAIN", "[", "i", "]", ")", "\n", "self", ".", "TrainStructures", "[", "i", "]", "[", "'original_input_shape'", "]", "=", "(", "\n", "T", ".", "MTRAIN", "[", "i", "]", ".", "original_input_shape", ")", "\n", "self", ".", "TrainStructures", "[", "i", "]", "[", "'original_output_shape'", "]", "=", "(", "\n", "T", ".", "MTRAIN", "[", "i", "]", ".", "original_output_shape", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "self", ".", "ValStructures", ")", ")", ":", "\n", "      ", "self", ".", "ValStructures", "[", "i", "]", "=", "self", ".", "initialize_structure", "(", "\n", "find_node", "=", "find_node", ",", "dataset", "=", "T", ".", "MVAL", "[", "i", "]", ")", "\n", "self", ".", "ValStructures", "[", "i", "]", "[", "'original_input_shape'", "]", "=", "(", "\n", "T", ".", "MVAL", "[", "i", "]", ".", "original_input_shape", ")", "\n", "self", ".", "ValStructures", "[", "i", "]", "[", "'original_output_shape'", "]", "=", "(", "\n", "T", ".", "MVAL", "[", "i", "]", ".", "original_output_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.edges_from_node_types": [[227, 231], ["None"], "methods", ["None"], ["", "", "def", "edges_from_node_types", "(", "self", ",", "node_types", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "return", "[", "self", ".", "NodeNodeToEdge", "[", "node_types", "[", "s", "]", "]", "[", "node_types", "[", "t", "]", "]", "\n", "for", "(", "s", ",", "t", ")", "in", "self", ".", "graph", "[", "'edges'", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.initialize_structure": [[232, 284], ["len", "len", "list", "list", "range", "list", "hgnn_composer.HGNN_Structure.update_edge_variables", "map", "map", "len", "[].append", "map", "hgnn_composer.HGNN_Structure.StructureParameters.extend", "range", "list", "list", "range", "list", "len", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "torch.nn.Parameter", "len", "len", "len", "len", "torch.rand_like"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.update_edge_variables"], ["", "def", "initialize_structure", "(", "self", ",", "find_node", "=", "False", ",", "dataset", "=", "None", ")", ":", "\n", "    ", "structure", "=", "{", "}", "\n", "structure", "[", "'graph'", "]", "=", "self", ".", "graph", "\n", "structure", "[", "'num_node_modules'", "]", "=", "self", ".", "num_modules", "[", "0", "]", "\n", "structure", "[", "'num_edge_modules'", "]", "=", "self", ".", "num_modules", "[", "1", "]", "\n", "structure", "[", "'num_nodes'", "]", "=", "len", "(", "self", ".", "graph", "[", "'nodes'", "]", ")", "\n", "structure", "[", "'num_edges'", "]", "=", "len", "(", "self", ".", "graph", "[", "'edges'", "]", ")", "\n", "structure", "[", "'num_steps'", "]", "=", "self", ".", "graph", "[", "'num_steps'", "]", "\n", "if", "'self_regress'", "in", "self", ".", "graph", "and", "self", ".", "graph", "[", "'self_regress'", "]", ":", "\n", "      ", "structure", "[", "'self_regress'", "]", "=", "True", "\n", "structure", "[", "'self_regress_steps'", "]", "=", "structure", "[", "'num_steps'", "]", "\n", "", "structure", "[", "'msg_sz'", "]", "=", "self", ".", "graph", "[", "'msg_sz'", "]", "\n", "structure", "[", "'update_sz'", "]", "=", "self", ".", "graph", "[", "'update_sz'", "]", "\n", "structure", "[", "'node_dim'", "]", "=", "self", ".", "graph", "[", "'node_dim'", "]", "\n", "structure", "[", "'initial_input'", "]", "=", "self", ".", "graph", "[", "'initial_input'", "]", "\n", "structure", "[", "'num_types'", "]", "=", "self", ".", "num_types", "\n", "## Limits ##", "\n", "structure", "[", "'end_nodes'", "]", "=", "structure", "[", "'num_node_modules'", "]", "\n", "structure", "[", "'end_edges'", "]", "=", "(", "structure", "[", "'end_nodes'", "]", "+", "\n", "structure", "[", "'num_edge_modules'", "]", ")", "\n", "structure", "[", "'end_final'", "]", "=", "structure", "[", "'end_edges'", "]", "\n", "## Types ##", "\n", "structure", "[", "'types'", "]", "=", "list", "(", "map", "(", "int", ",", "list", "(", "\n", "np", ".", "random", ".", "choice", "(", "structure", "[", "'num_types'", "]", ",", "len", "(", "self", ".", "graph", "[", "'nodes'", "]", ")", ")", ")", ")", ")", "\n", "## Nodes ##", "\n", "structure", "[", "'node_idx_inv'", "]", "=", "list", "(", "map", "(", "int", ",", "list", "(", "\n", "np", ".", "random", ".", "choice", "(", "structure", "[", "'num_node_modules'", "]", ",", "\n", "len", "(", "self", ".", "graph", "[", "'nodes'", "]", ")", ")", ")", ")", ")", "#node->mod", "\n", "structure", "[", "'node_idx'", "]", "=", "[", "[", "]", "for", "_", "in", "\n", "range", "(", "structure", "[", "'num_node_modules'", "]", ")", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "structure", "[", "'node_idx_inv'", "]", ")", ")", ":", "\n", "      ", "idx", "=", "structure", "[", "'node_idx_inv'", "]", "[", "i", "]", "\n", "structure", "[", "'node_idx'", "]", "[", "idx", "]", ".", "append", "(", "i", ")", "#module->[list of nodes]", "\n", "## Edges ##", "\n", "", "structure", "[", "'edge_idx_inv'", "]", "=", "list", "(", "map", "(", "int", ",", "list", "(", "np", ".", "random", ".", "choice", "(", "\n", "self", ".", "num_modules", "[", "1", "]", ",", "len", "(", "self", ".", "graph", "[", "'edges'", "]", ")", ")", ")", ")", ")", "#edge->mod", "\n", "\n", "## to make sure they are undirected", "\n", "# for idx, module in enumerate(structure['edge_idx_inv']):", "\n", "#   r, c = tuple(structure['graph']['edges'][idx])", "\n", "#   other_idx = structure['graph']['edges'].index([c, r])", "\n", "#   structure['edge_idx_inv'][other_idx] = module", "\n", "\n", "self", ".", "update_edge_variables", "(", "structure", ")", "\n", "\n", "# Find node variables", "\n", "if", "find_node", ":", "\n", "       ", "self", ".", "StructureParameters", ".", "extend", "(", "[", "torch", ".", "nn", ".", "Parameter", "(", "\n", "torch", ".", "rand_like", "(", "dataset", ".", "TrainInput", "[", ":", ",", ":", "1", ",", ":", "]", ")", "*", "2.", "-", "1.", ")", "]", ")", "\n", "structure", "[", "'parameters'", "]", "=", "range", "(", "len", "(", "self", ".", "StructureParameters", ")", "-", "1", ",", "\n", "len", "(", "self", ".", "StructureParameters", ")", ")", "\n", "", "return", "structure", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.update_edges_from_nodes_all_structures": [[285, 290], ["range", "range", "len", "hgnn_composer.HGNN_Structure.update_edges_from_nodes", "len", "hgnn_composer.HGNN_Structure.update_edges_from_nodes"], "methods", ["None"], ["", "def", "update_edges_from_nodes_all_structures", "(", "self", ")", ":", "\n", "    ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "TrainStructures", ")", ")", ":", "\n", "      ", "self", ".", "update_edges_from_nodes", "(", "self", ".", "TrainStructures", "[", "i", "]", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "self", ".", "ValStructures", ")", ")", ":", "\n", "      ", "self", ".", "update_edges_from_nodes", "(", "self", ".", "ValStructures", "[", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.update_edge_variables": [[291, 311], ["range", "len", "[].append", "[].append", "[].append", "[].append", "range", "range", "range", "range"], "methods", ["None"], ["", "", "def", "update_edge_variables", "(", "self", ",", "structure", ")", ":", "\n", "# structure['edge_idx_inv'] = (", "\n", "#     self.edges_from_node_types(structure['node_idx_inv']))", "\n", "    ", "structure", "[", "'edge_sources'", "]", "=", "[", "[", "]", "for", "_", "in", "\n", "range", "(", "structure", "[", "'num_edge_modules'", "]", ")", "]", "\n", "structure", "[", "'edge_sinks'", "]", "=", "[", "[", "]", "for", "_", "in", "\n", "range", "(", "structure", "[", "'num_edge_modules'", "]", ")", "]", "\n", "structure", "[", "'edge_idx'", "]", "=", "[", "[", "]", "for", "_", "in", "\n", "range", "(", "structure", "[", "'num_edge_modules'", "]", ")", "]", "\n", "structure", "[", "'node_receives'", "]", "=", "[", "[", "]", "for", "_", "in", "range", "(", "structure", "[", "'num_nodes'", "]", ")", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "structure", "[", "'edge_idx_inv'", "]", ")", ")", ":", "\n", "      ", "idx", "=", "structure", "[", "'edge_idx_inv'", "]", "[", "i", "]", "\n", "#module->[list of edge indices]", "\n", "structure", "[", "'edge_idx'", "]", "[", "idx", "]", ".", "append", "(", "i", ")", "\n", "#module->[list of node indices]", "\n", "structure", "[", "'edge_sources'", "]", "[", "idx", "]", ".", "append", "(", "self", ".", "graph", "[", "'edges'", "]", "[", "i", "]", "[", "0", "]", ")", "\n", "#module->[list of node indices]", "\n", "structure", "[", "'edge_sinks'", "]", "[", "idx", "]", ".", "append", "(", "self", ".", "graph", "[", "'edges'", "]", "[", "i", "]", "[", "1", "]", ")", "\n", "#'inverse' from edge_sinks", "\n", "structure", "[", "'node_receives'", "]", "[", "self", ".", "graph", "[", "'edges'", "]", "[", "i", "]", "[", "1", "]", "]", ".", "append", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.reset_global_variable": [[312, 314], ["None"], "methods", ["None"], ["", "", "def", "reset_global_variable", "(", "self", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.set_new_global_variable": [[315, 320], ["None"], "methods", ["None"], ["", "def", "set_new_global_variable", "(", "self", ")", ":", "\n", "    ", "'''\n    Mutates global variables\n    '''", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure._zero_out_current_probs": [[321, 325], ["enumerate"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_zero_out_current_probs", "(", "curr_edge_idx_inv", ",", "probs", ")", ":", "\n", "    ", "for", "edge", ",", "module", "in", "enumerate", "(", "curr_edge_idx_inv", ")", ":", "\n", "      ", "probs", "[", "edge", ",", "module", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure._normalize_probabilities": [[326, 330], ["numpy.sum", "numpy.divide"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_normalize_probabilities", "(", "probs", ",", "axis", "=", "None", ")", ":", "\n", "    ", "dividend", "=", "np", ".", "sum", "(", "probs", ",", "axis", "=", "axis", ",", "keepdims", "=", "True", ")", "\n", "np", ".", "divide", "(", "probs", ",", "dividend", ",", "out", "=", "probs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.draw_new_edges_for_node": [[331, 360], ["numpy.random.choice", "numpy.array", "copy.deepcopy", "range", "numpy.where", "hgnn_composer.HGNN_Structure.update_edge_variables", "RuntimeError", "hgnn_composer.HGNN_Structure._zero_out_current_probs", "hgnn_composer.HGNN_Structure._normalize_probabilities", "numpy.random.choice", "range"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.update_edge_variables", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure._zero_out_current_probs", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure._normalize_probabilities"], ["", "def", "draw_new_edges_for_node", "(", "self", ",", "flip", "=", "False", ")", ":", "\n", "    ", "'''\n    given a current structure and an array (of the same dimensions)\n    of probabilitys of changing each value, and whether to flip\n    or sample, draws new edges for a randomly chosen node\n    '''", "\n", "def", "f", "(", "new_struct", ",", "probs", ")", ":", "\n", "# pick a node to change edges for", "\n", "      ", "node", "=", "np", ".", "random", ".", "choice", "(", "range", "(", "new_struct", "[", "'num_nodes'", "]", ")", ")", "\n", "np_edges_array", "=", "np", ".", "array", "(", "new_struct", "[", "'graph'", "]", "[", "'edges'", "]", ")", "\n", "# get first item, because where returns a tuple", "\n", "indices_for_node", "=", "np", ".", "where", "(", "np_edges_array", "[", ":", ",", "1", "]", "==", "node", ")", "[", "0", "]", "\n", "probabilities", "=", "copy", ".", "deepcopy", "(", "probs", ")", "\n", "if", "new_struct", "[", "'num_edge_modules'", "]", ">", "1", ":", "\n", "        ", "if", "flip", ":", "\n", "          ", "self", ".", "_zero_out_current_probs", "(", "new_struct", "[", "'edge_idx_inv'", "]", ",", "\n", "probabilities", ")", "\n", "self", ".", "_normalize_probabilities", "(", "probabilities", ",", "axis", "=", "1", ")", "\n", "", "for", "idx", "in", "indices_for_node", ":", "\n", "          ", "new_module", "=", "np", ".", "random", ".", "choice", "(", "\n", "range", "(", "new_struct", "[", "'num_edge_modules'", "]", ")", ",", "p", "=", "probabilities", "[", "idx", "]", ")", "\n", "new_struct", "[", "'edge_idx_inv'", "]", "[", "idx", "]", "=", "new_module", "\n", "", "self", ".", "update_edge_variables", "(", "new_struct", ")", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"please check to make sure \\\n            either node or edge modules > 1\"", ")", "\n", "", "return", "new_struct", "\n", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.draw_new_structure": [[361, 386], ["copy.deepcopy", "hgnn_composer.HGNN_Structure._zero_out_current_probs", "hgnn_composer.HGNN_Structure._normalize_probabilities", "probabilities.flatten.flatten.flatten", "list", "numpy.random.choice", "hgnn_composer.HGNN_Structure.update_edge_variables", "RuntimeError", "itertools.product", "range", "range", "range", "len"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure._zero_out_current_probs", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure._normalize_probabilities", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.update_edge_variables"], ["", "def", "draw_new_structure", "(", "self", ",", "new_struct", ",", "probs", ")", ":", "\n", "      ", "'''given a current structure and an array (of the same dimensions)\n      of probabilities of changing each value, draws a value to change'''", "\n", "probabilities", "=", "copy", ".", "deepcopy", "(", "probs", ")", "\n", "self", ".", "_zero_out_current_probs", "(", "new_struct", "[", "'edge_idx_inv'", "]", ",", "probabilities", ")", "\n", "self", ".", "_normalize_probabilities", "(", "probabilities", ")", "\n", "probabilities", "=", "probabilities", ".", "flatten", "(", ")", "\n", "\n", "if", "new_struct", "[", "'num_edge_modules'", "]", ">", "1", ":", "\n", "        ", "import", "itertools", "\n", "choices_to_change", "=", "list", "(", "itertools", ".", "product", "(", "range", "(", "new_struct", "[", "'num_edges'", "]", ")", ",", "\n", "range", "(", "self", ".", "num_modules", "[", "1", "]", ")", ")", ")", "# edge, module", "\n", "choice_idx", "=", "np", ".", "random", ".", "choice", "(", "range", "(", "len", "(", "choices_to_change", ")", ")", ",", "p", "=", "probabilities", ")", "\n", "idx", ",", "new_module", "=", "choices_to_change", "[", "choice_idx", "]", "# edge, new module to change to", "\n", "new_struct", "[", "'edge_idx_inv'", "]", "[", "idx", "]", "=", "new_module", "\n", "\n", "# undirected graph: change corresponding edge going the other way", "\n", "# r, c = tuple(new_struct['graph']['edges'][idx])", "\n", "# other_idx = new_struct['graph']['edges'].index([c, r])", "\n", "# new_struct['edge_idx_inv'][other_idx] = new_module", "\n", "\n", "self", ".", "update_edge_variables", "(", "new_struct", ")", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "\"please check to make sure either node or edge modules > 1\"", ")", "\n", "", "return", "new_struct", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.update_structure_to": [[387, 390], ["hgnn_composer.HGNN_Structure.update_edge_variables"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.update_edge_variables"], ["", "def", "update_structure_to", "(", "self", ",", "structure", ",", "new_edges", ")", ":", "\n", "    ", "structure", "[", "'edge_idx_inv'", "]", "=", "new_edges", "\n", "self", ".", "update_edge_variables", "(", "structure", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.propose_new_structure": [[391, 431], ["numpy.random.rand", "[].index", "[].append", "numpy.random.randint", "numpy.random.randint", "numpy.random.randint", "hgnn_composer.HGNN_Structure.update_edge_variables", "RuntimeError", "len", "numpy.random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.update_edge_variables"], ["", "def", "propose_new_structure", "(", "self", ",", "new_structure", ")", ":", "\n", "#Pick either a node or an edge and try switching module", "\n", "    ", "change_node", "=", "(", "np", ".", "random", ".", "rand", "(", ")", ">", "0.5", ")", "\n", "if", "new_structure", "[", "'num_node_modules'", "]", "==", "1", ":", "change_node", "=", "False", "\n", "if", "new_structure", "[", "'num_edge_modules'", "]", "==", "1", ":", "change_node", "=", "True", "\n", "if", "change_node", "and", "new_structure", "[", "'num_node_modules'", "]", ">", "1", ":", "\n", "      ", "idx", "=", "-", "1", "\n", "while", "(", "idx", "==", "-", "1", "or", "#don't modify nodes w/ no assigned module", "\n", "new_structure", "[", "'node_idx_inv'", "]", "[", "idx", "]", ">=", "\n", "new_structure", "[", "'num_node_modules'", "]", ")", ":", "\n", "        ", "idx", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "new_structure", "[", "'node_idx_inv'", "]", ")", ")", "\n", "#Remove from old", "\n", "", "old_module", "=", "new_structure", "[", "'node_idx_inv'", "]", "[", "idx", "]", "\n", "pos_in_old", "=", "new_structure", "[", "'node_idx'", "]", "[", "old_module", "]", ".", "index", "(", "idx", ")", "\n", "del", "new_structure", "[", "'node_idx'", "]", "[", "old_module", "]", "[", "pos_in_old", "]", "\n", "#Add to new", "\n", "new_module", "=", "old_module", "\n", "while", "new_module", "==", "old_module", ":", "\n", "        ", "new_module", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "num_modules", "[", "0", "]", ")", "\n", "", "new_structure", "[", "'node_idx_inv'", "]", "[", "idx", "]", "=", "new_module", "\n", "new_structure", "[", "'node_idx'", "]", "[", "new_module", "]", ".", "append", "(", "idx", ")", "\n", "", "elif", "new_structure", "[", "'num_edge_modules'", "]", ">", "1", ":", "\n", "      ", "idx", "=", "-", "1", "\n", "while", "(", "idx", "==", "-", "1", "or", "#don't modify edges w/ no assigned module", "\n", "new_structure", "[", "'edge_idx_inv'", "]", "[", "idx", "]", ">=", "\n", "new_structure", "[", "'num_edge_modules'", "]", ")", ":", "\n", "        ", "idx", "=", "np", ".", "random", ".", "randint", "(", "len", "(", "new_structure", "[", "'edge_idx_inv'", "]", ")", "//", "2", ")", "\n", "#Add to new", "\n", "", "new_module", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "num_modules", "[", "1", "]", ")", "\n", "new_structure", "[", "'edge_idx_inv'", "]", "[", "idx", "]", "=", "new_module", "\n", "\n", "# undirected graph: change corresponding edge going the other way", "\n", "# r, c = tuple(new_structure['graph']['edges'][idx])", "\n", "# other_idx = new_structure['graph']['edges'].index([c, r])", "\n", "# new_structure['edge_idx_inv'][other_idx] = new_module", "\n", "\n", "self", ".", "update_edge_variables", "(", "new_structure", ")", "\n", "", "else", ":", "\n", "      ", "raise", "RuntimeError", "(", "\"please check to make sure either node or edge modules > 1\"", ")", "\n", "", "return", "new_structure", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.update_PosUsage_counters": [[432, 453], ["range", "enumerate", "len", "enumerate", "enumerate", "numpy.zeros", "range", "b.item", "len", "len"], "methods", ["None"], ["", "def", "update_PosUsage_counters", "(", "self", ",", "METRICS", ")", ":", "\n", "    ", "'''\n    Updates table of fraction of times module is used for each dataset.\n    and for each slot.\n    '''", "\n", "eps", "=", "1.", "/", "30", "\n", "if", "self", ".", "PosUsage", "is", "None", ":", "\n", "      ", "self", ".", "PosUsage", "=", "[", "np", ".", "zeros", "(", "(", "self", ".", "graph", "[", "'num_slots'", "]", ",", "self", ".", "tot_modules", ")", ")", "\n", "for", "_", "in", "range", "(", "len", "(", "self", ".", "TrainStructures", ")", "+", "len", "(", "self", ".", "ValStructures", ")", ")", "]", "\n", "", "for", "i", "in", "range", "(", "len", "(", "self", ".", "PosUsage", ")", ")", ":", "\n", "      ", "self", ".", "PosUsage", "[", "i", "]", "*=", "(", "1", "-", "eps", ")", "\n", "", "for", "i", ",", "structure", "in", "enumerate", "(", "self", ".", "TrainStructures", "+", "self", ".", "ValStructures", ")", ":", "\n", "      ", "for", "j", ",", "node", "in", "enumerate", "(", "structure", "[", "'node_idx_inv'", "]", ")", ":", "\n", "        ", "if", "node", ">=", "0", "and", "node", "<", "self", ".", "num_modules", "[", "0", "]", ":", "\n", "          ", "self", ".", "PosUsage", "[", "i", "]", "[", "j", "]", "[", "node", "]", "+=", "eps", "\n", "", "", "for", "j", ",", "node", "in", "enumerate", "(", "structure", "[", "'edge_idx_inv'", "]", ")", ":", "\n", "        ", "if", "(", "node", ">=", "self", ".", "num_modules", "[", "0", "]", "and", "\n", "node", "<", "self", ".", "num_modules", "[", "0", "]", "+", "self", ".", "num_modules", "[", "1", "]", ")", ":", "\n", "          ", "self", ".", "PosUsage", "[", "i", "]", "[", "j", "]", "[", "node", "+", "self", ".", "num_modules", "[", "0", "]", "]", "+=", "eps", "\n", "", "", "", "METRICS", "[", "'PosUsage'", "]", "=", "[", "\n", "[", "[", "b", ".", "item", "(", ")", "for", "b", "in", "a", "]", "for", "a", "in", "_", "]", "for", "_", "in", "self", ".", "PosUsage", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.update_customized_counters": [[454, 456], ["None"], "methods", ["None"], ["", "def", "update_customized_counters", "(", "self", ",", "METRICS", "=", "None", ")", ":", "\n", "    ", "return", "#TODO: implement, but not critical, just debugging", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.update_Usage_counters": [[457, 478], ["enumerate", "list", "list.sort", "enumerate", "enumerate", "enumerate", "range", "range", "len", "len"], "methods", ["None"], ["", "def", "update_Usage_counters", "(", "self", ",", "METRICS", ",", "T", ")", ":", "\n", "    ", "'''\n    Updates table of fraction of times module is used for each dataset.\n    '''", "\n", "eps", "=", "1e-3", "\n", "self", ".", "Usage", "*=", "(", "1", "-", "eps", ")", "\n", "for", "i_s", ",", "structure", "in", "enumerate", "(", "self", ".", "TrainStructures", "+", "self", ".", "ValStructures", ")", ":", "\n", "      ", "for", "i", ",", "l", "in", "enumerate", "(", "structure", "[", "'node_idx'", "]", ")", ":", "\n", "        ", "self", ".", "Usage", "[", "i_s", "]", "[", "self", ".", "Modules", "[", "0", "]", "[", "i", "]", "]", "+=", "(", "\n", "eps", "*", "len", "(", "l", ")", "/", "structure", "[", "'num_nodes'", "]", ")", "\n", "", "for", "i", ",", "l", "in", "enumerate", "(", "structure", "[", "'edge_idx'", "]", ")", ":", "\n", "        ", "self", ".", "Usage", "[", "i_s", "]", "[", "self", ".", "Modules", "[", "1", "]", "[", "i", "]", "]", "+=", "(", "\n", "eps", "*", "len", "(", "l", ")", "/", "structure", "[", "'num_edges'", "]", ")", "\n", "", "", "names", "=", "(", "\n", "[", "_", ".", "name", "for", "_", "in", "T", ".", "MTRAIN", "]", "+", "[", "_", ".", "name", "for", "_", "in", "T", ".", "MVAL", "]", ")", "\n", "names", "=", "list", "(", "enumerate", "(", "names", ")", ")", "\n", "names", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "values", "=", "self", ".", "Usage", "[", "[", "_", "[", "0", "]", "for", "_", "in", "names", "]", ",", ":", "]", "\n", "METRICS", "[", "'Usage'", "]", "=", "[", "[", "values", "[", "i", "]", "[", "j", "]", "for", "j", "in", "range", "(", "values", ".", "shape", "[", "1", "]", ")", "]", "\n", "for", "i", "in", "range", "(", "values", ".", "shape", "[", "0", "]", ")", "]", "\n", "METRICS", "[", "'Usage-names'", "]", "=", "[", "_", "[", "1", "]", "for", "_", "in", "names", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.modules_given_structure": [[479, 482], ["int"], "methods", ["None"], ["", "def", "modules_given_structure", "(", "self", ",", "structure", ")", ":", "\n", "    ", "return", "(", "[", "m", "for", "m", "in", "structure", "[", "'node_idx_inv'", "]", "]", "+", "\n", "[", "int", "(", "m", ")", "+", "structure", "[", "'end_nodes'", "]", "for", "m", "in", "structure", "[", "'edge_idx_inv'", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.plot_customized_usage_rate": [[483, 485], ["None"], "methods", ["None"], ["", "def", "plot_customized_usage_rate", "(", "self", ",", "directory", ")", ":", "\n", "    ", "return", "#TODO: implement, but not critical, just debugging", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.hgnn_composer.HGNN_Structure.compose_multiple_structures": [[486, 528], ["copy.deepcopy", "len", "enumerate", "enumerate", "enumerate", "enumerate"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "compose_multiple_structures", "(", "structures", ")", ":", "\n", "    ", "'''\n    :return: dictionary representing a mega-graph made of several structure propositions,\n     which can be fed into a composer class to be composed into an NN\n    '''", "\n", "mega_structure", "=", "copy", ".", "deepcopy", "(", "structures", "[", "0", "]", ")", "\n", "if", "len", "(", "structures", ")", ">", "1", ":", "\n", "      ", "for", "structure", "in", "structures", "[", "1", ":", "]", ":", "\n", "# add each structure to mega-composition", "\n", "\n", "# store for use in calculating updated indices", "\n", "        ", "prev_num_nodes", "=", "mega_structure", "[", "'num_nodes'", "]", "\n", "prev_num_edges", "=", "mega_structure", "[", "'num_edges'", "]", "\n", "\n", "# num nodes, num edges", "\n", "mega_structure", "[", "'num_nodes'", "]", "+=", "structure", "[", "'num_nodes'", "]", "\n", "mega_structure", "[", "'num_edges'", "]", "+=", "structure", "[", "'num_edges'", "]", "\n", "mega_structure", "[", "'graph'", "]", "[", "'num_nodes'", "]", "+=", "structure", "[", "'graph'", "]", "[", "'num_nodes'", "]", "\n", "mega_structure", "[", "'graph'", "]", "[", "'num_edges'", "]", "+=", "structure", "[", "'graph'", "]", "[", "'num_edges'", "]", "\n", "\n", "# create the mega graph", "\n", "mega_structure", "[", "'graph'", "]", "[", "'nodes'", "]", "+=", "structure", "[", "'graph'", "]", "[", "'nodes'", "]", "\n", "mega_structure", "[", "'graph'", "]", "[", "'edges'", "]", "+=", "[", "[", "node_idx", "+", "prev_num_nodes", "for", "node_idx", "in", "edge", "]", "\n", "for", "edge", "in", "structure", "[", "'graph'", "]", "[", "'edges'", "]", "]", "\n", "\n", "for", "i", ",", "edge_type_list", "in", "enumerate", "(", "structure", "[", "'edge_sources'", "]", ")", ":", "\n", "            ", "mega_structure", "[", "'edge_sources'", "]", "[", "i", "]", "+=", "[", "node_idx", "+", "prev_num_nodes", "for", "node_idx", "in", "edge_type_list", "]", "\n", "", "for", "i", ",", "edge_type_list", "in", "enumerate", "(", "structure", "[", "'edge_sinks'", "]", ")", ":", "\n", "            ", "mega_structure", "[", "'edge_sinks'", "]", "[", "i", "]", "+=", "[", "node_idx", "+", "prev_num_nodes", "for", "node_idx", "in", "edge_type_list", "]", "\n", "\n", "# node to type_idx", "\n", "", "for", "i", ",", "node_type_list", "in", "enumerate", "(", "structure", "[", "'node_idx'", "]", ")", ":", "\n", "            ", "mega_structure", "[", "'node_idx'", "]", "[", "i", "]", "+=", "[", "node_idx", "+", "prev_num_nodes", "for", "node_idx", "in", "node_type_list", "]", "\n", "", "for", "i", ",", "edge_type_list", "in", "enumerate", "(", "structure", "[", "'edge_idx'", "]", ")", ":", "\n", "            ", "mega_structure", "[", "'edge_idx'", "]", "[", "i", "]", "+=", "[", "edge_idx", "+", "prev_num_edges", "for", "edge_idx", "in", "edge_type_list", "]", "\n", "\n", "# type_list to node_idx", "\n", "", "mega_structure", "[", "'node_idx_inv'", "]", "+=", "structure", "[", "'node_idx_inv'", "]", "\n", "mega_structure", "[", "'edge_idx_inv'", "]", "+=", "structure", "[", "'edge_idx_inv'", "]", "\n", "\n", "", "", "return", "mega_structure", "\n", "", "", ""]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.exponential.__init__": [[46, 48], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "exponential", ",", "self", ")", ".", "__init__", "(", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.exponential.forward": [[48, 50], ["torch.exp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "torch", ".", "exp", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.Net.__init__": [[52, 58], ["super().__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_feature", ",", "n_hidden", ",", "n_output", ")", ":", "\n", "        ", "super", "(", "Net", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden", "=", "torch", ".", "nn", ".", "Linear", "(", "n_feature", ",", "n_hidden", ")", "# hidden layer", "\n", "self", ".", "hidden_two", "=", "torch", ".", "nn", ".", "Linear", "(", "n_hidden", ",", "n_hidden", ")", "# hidden layer", "\n", "self", ".", "hidden_3", "=", "torch", ".", "nn", ".", "Linear", "(", "n_hidden", ",", "n_hidden", ")", "# hidden layer", "\n", "self", ".", "predict", "=", "torch", ".", "nn", ".", "Linear", "(", "n_hidden", ",", "n_output", ")", "# output layer", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.Net.forward": [[59, 65], ["torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.relu", "layers.Net.predict", "layers.Net.hidden", "layers.Net.hidden_two", "layers.Net.hidden_3"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.relu", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.relu", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.relu"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "hidden", "(", "x", ")", ")", "# activation function for hidden layer", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "hidden_two", "(", "x", ")", ")", "# activation function for hidden layer", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "hidden_3", "(", "x", ")", ")", "# activation function for hidden layer", "\n", "x", "=", "self", ".", "predict", "(", "x", ")", "# linear output", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.linear": [[16, 21], ["torch.nn.functional.linear", "torch.nn.functional.linear", "weight.cuda", "weight.cuda", "bias.cuda"], "function", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.linear", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.linear"], ["def", "linear", "(", "input", ",", "weight", ",", "bias", "=", "None", ")", ":", "\n", "    ", "if", "bias", "is", "None", ":", "\n", "        ", "return", "F", ".", "linear", "(", "input", ",", "weight", ".", "cuda", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "F", ".", "linear", "(", "input", ",", "weight", ".", "cuda", "(", ")", ",", "bias", ".", "cuda", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.conv2d": [[22, 24], ["torch.nn.functional.conv2d", "weight.cuda", "bias.cuda"], "function", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.conv2d"], ["", "", "def", "conv2d", "(", "input", ",", "weight", ",", "bias", "=", "None", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "dilation", "=", "1", ",", "groups", "=", "1", ")", ":", "\n", "    ", "return", "F", ".", "conv2d", "(", "input", ",", "weight", ".", "cuda", "(", ")", ",", "bias", ".", "cuda", "(", ")", ",", "stride", ",", "padding", ",", "dilation", ",", "groups", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.relu": [[25, 27], ["torch.nn.functional.threshold"], "function", ["None"], ["", "def", "relu", "(", "input", ")", ":", "\n", "    ", "return", "F", ".", "threshold", "(", "input", ",", "0", ",", "0", ",", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.maxpool": [[28, 30], ["torch.nn.functional.max_pool2d"], "function", ["None"], ["", "def", "maxpool", "(", "input", ",", "kernel_size", ",", "stride", "=", "None", ")", ":", "\n", "    ", "return", "F", ".", "max_pool2d", "(", "input", ",", "kernel_size", ",", "stride", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.batchnorm": [[31, 38], ["torch.zeros().cuda", "torch.ones().cuda", "torch.nn.functional.batch_norm", "torch.zeros", "torch.ones", "numpy.prod", "numpy.prod", "numpy.array", "numpy.array", "input.data.size", "input.data.size"], "function", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.encoder.MLP.batch_norm"], ["", "def", "batchnorm", "(", "input", ",", "weight", "=", "None", ",", "bias", "=", "None", ",", "running_mean", "=", "None", ",", "running_var", "=", "None", ",", "training", "=", "True", ",", "eps", "=", "1e-5", ",", "momentum", "=", "0.1", ")", ":", "\n", "    ", "''' momentum = 1 restricts stats to the current mini-batch '''", "\n", "# This hack only works when momentum is 1 and avoids needing to track running stats", "\n", "# by substuting dummy variables", "\n", "running_mean", "=", "torch", ".", "zeros", "(", "np", ".", "prod", "(", "np", ".", "array", "(", "input", ".", "data", ".", "size", "(", ")", "[", "1", "]", ")", ")", ")", ".", "cuda", "(", ")", "\n", "running_var", "=", "torch", ".", "ones", "(", "np", ".", "prod", "(", "np", ".", "array", "(", "input", ".", "data", ".", "size", "(", ")", "[", "1", "]", ")", ")", ")", ".", "cuda", "(", ")", "\n", "return", "F", ".", "batch_norm", "(", "input", ",", "running_mean", ",", "running_var", ",", "weight", ",", "bias", ",", "training", ",", "momentum", ",", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.bilinear_upsample": [[39, 41], ["torch.nn.functional.upsample"], "function", ["None"], ["", "def", "bilinear_upsample", "(", "in_", ",", "factor", ")", ":", "\n", "    ", "return", "F", ".", "upsample", "(", "in_", ",", "None", ",", "factor", ",", "'bilinear'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.log_softmax": [[42, 44], ["torch.nn.functional.log_softmax"], "function", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.log_softmax"], ["", "def", "log_softmax", "(", "input", ")", ":", "\n", "    ", "return", "F", ".", "log_softmax", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__": [[20, 56], ["torch.Module.__init__", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "range", "custom_module.torch_NN.add_module", "len", "key_words.append", "int", "torch.Sequential", "torch.Sequential", "torch.Sequential", "custom_module.torch_NN.add_module", "key_words.append", "torch.Linear", "torch.Linear", "torch.Linear", "collections.OrderedDict", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "custom_module.torch_NN.add_module", "str", "torch.ReLU", "torch.ReLU", "torch.ReLU", "layers.exponential", "custom_module.torch_NN.add_module", "str", "torch.Sequential", "torch.Sequential", "torch.Sequential", "custom_module.torch_NN.add_module", "custom_module.torch_NN.__init__.module_from_name"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.__init__"], ["  ", "'''\n  Mimic the pytorch-maml/src/ominglot_net.py structure\n  '''", "\n", "def", "__init__", "(", "self", ",", "inp", "=", "1", ",", "out", "=", "1", ",", "hidden", "=", "[", "]", ",", "final_act", "=", "'affine'", ",", "loss_fn", "=", "None", ")", ":", "\n", "    ", "super", "(", "torch_NN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "inp", "=", "inp", "\n", "self", ".", "dummy_inp", "=", "torch", ".", "randn", "(", "8", ",", "inp", ",", "device", "=", "nn_device", ")", "\n", "self", ".", "out", "=", "out", "\n", "self", ".", "num_layers", "=", "len", "(", "hidden", ")", "+", "1", "\n", "self", ".", "final_act", "=", "final_act", "\n", "key_words", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "      ", "key_words", ".", "append", "(", "'fc'", "+", "str", "(", "i", ")", ")", "\n", "if", "i", "<", "self", ".", "num_layers", "-", "1", ":", "#final_act may not be a relu", "\n", "        ", "key_words", ".", "append", "(", "'relu'", "+", "str", "(", "i", ")", ")", "\n", "\n", "", "", "def", "module_from_name", "(", "name", ")", ":", "\n", "      ", "if", "self", ".", "num_layers", ">", "10", ":", "raise", "NotImplementedError", "\n", "#TODO: allow more than 10 layers, put '_' and use split", "\n", "num", "=", "int", "(", "name", "[", "-", "1", "]", ")", "\n", "typ", "=", "name", "[", ":", "-", "1", "]", "\n", "if", "typ", "==", "'fc'", ":", "\n", "        ", "inp", "=", "self", ".", "inp", "if", "num", "==", "0", "else", "hidden", "[", "num", "-", "1", "]", "\n", "out", "=", "self", ".", "out", "if", "num", "+", "1", "==", "self", ".", "num_layers", "else", "hidden", "[", "num", "]", "\n", "return", "nn", ".", "Linear", "(", "inp", ",", "out", ")", "\n", "", "elif", "typ", "==", "'relu'", ":", "\n", "        ", "return", "nn", ".", "ReLU", "(", ")", "#removed inplace", "\n", "", "else", ":", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "add_module", "(", "'features'", ",", "nn", ".", "Sequential", "(", "OrderedDict", "(", "[", "\n", "(", "name", ",", "module_from_name", "(", "name", ")", ")", "for", "name", "in", "key_words", "]", ")", ")", ")", "\n", "\n", "if", "self", ".", "final_act", "==", "'sigmoid'", ":", "self", ".", "add_module", "(", "'fa'", ",", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "elif", "self", ".", "final_act", "==", "'exp'", ":", "self", ".", "add_module", "(", "'fa'", ",", "exponential", "(", ")", ")", "\n", "elif", "self", ".", "final_act", "==", "'affine'", ":", "self", ".", "add_module", "(", "'fa'", ",", "nn", ".", "Sequential", "(", ")", ")", "\n", "elif", "self", ".", "final_act", "==", "'relu'", ":", "self", ".", "add_module", "(", "'fa'", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "elif", "self", ".", "final_act", "==", "'tanh'", ":", "self", ".", "add_module", "(", "'fa'", ",", "nn", ".", "Tanh", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.dummy_forward_pass": [[57, 62], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "custom_module.torch_NN.forward"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.forward"], ["else", ":", "raise", "NotImplementedError", "\n", "\n", "", "def", "dummy_forward_pass", "(", "self", ")", ":", "\n", "    ", "'''\n    Dummy forward pass to be able to backpropagate to activate gradient hooks\n    '''", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.forward": [[63, 80], ["custom_module.torch_NN.features", "custom_module.torch_NN.fa", "range", "custom_module.torch_NN.fa", "layers.linear", "torch.dropout", "torch.dropout", "torch.dropout", "layers.relu", "str", "str"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.linear", "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.layers.relu"], ["return", "torch", ".", "mean", "(", "self", ".", "forward", "(", "self", ".", "dummy_inp", ")", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "weights", "=", "None", ",", "prefix", "=", "''", ")", ":", "\n", "    ", "'''\n    Runs the net forward; if weights are None it uses 'self' layers,\n    otherwise keeps the structure and uses 'weights' instead.\n    '''", "\n", "if", "weights", "is", "None", ":", "\n", "      ", "x", "=", "self", ".", "features", "(", "x", ")", "\n", "x", "=", "self", ".", "fa", "(", "x", ")", "\n", "", "else", ":", "\n", "      ", "for", "i", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "        ", "x", "=", "linear", "(", "x", ",", "weights", "[", "prefix", "+", "'fc'", "+", "str", "(", "i", ")", "+", "'.weight'", "]", ",", "\n", "weights", "[", "prefix", "+", "'fc'", "+", "str", "(", "i", ")", "+", "'.bias'", "]", ")", "\n", "if", "i", "<", "self", ".", "num_layers", "-", "1", ":", "x", "=", "relu", "(", "x", ")", "\n", "", "x", "=", "self", ".", "fa", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.net_forward": [[81, 83], ["custom_module.torch_NN.forward"], "methods", ["home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.forward"], ["", "def", "net_forward", "(", "self", ",", "x", ",", "weights", "=", "None", ")", ":", "\n", "    ", "return", "self", ".", "forward", "(", "x", ",", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.torch_NN.copy_weights": [[86, 94], ["zip", "net.modules", "custom_module.torch_NN.modules", "isinstance", "isinstance", "isinstance", "m_from.weight.data.clone", "m_from.bias.data.clone"], "methods", ["None"], ["", "def", "copy_weights", "(", "self", ",", "net", ")", ":", "\n", "    ", "'''Set this module's weights to be the same as those of 'net' '''", "\n", "for", "m_from", ",", "m_to", "in", "zip", "(", "net", ".", "modules", "(", ")", ",", "self", ".", "modules", "(", ")", ")", ":", "\n", "      ", "if", "(", "isinstance", "(", "m_to", ",", "nn", ".", "Linear", ")", "or", "isinstance", "(", "m_to", ",", "nn", ".", "Conv2d", ")", "\n", "or", "isinstance", "(", "m_to", ",", "nn", ".", "BatchNorm2d", ")", ")", ":", "\n", "        ", "m_to", ".", "weight", ".", "data", "=", "m_from", ".", "weight", ".", "data", ".", "clone", "(", ")", "\n", "if", "m_to", ".", "bias", "is", "not", "None", ":", "\n", "            ", "m_to", ".", "bias", ".", "data", "=", "m_from", ".", "bias", ".", "data", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.FerranAlet_modular-metalearning.neurips2019.custom_module.main": [[95, 99], ["custom_module.torch_NN", "torch.rand", "torch.rand", "torch.rand", "print", "torch_NN."], "function", ["None"], ["", "", "", "", "", "def", "main", "(", ")", ":", "\n", "  ", "NN", "=", "torch_NN", "(", "hidden", "=", "[", "2", ",", "3", "]", ",", "final_act", "=", "'sigmoid'", ")", "\n", "x", "=", "torch", ".", "rand", "(", "1", ")", "\n", "print", "(", "NN", "(", "x", ")", ")", "\n", "\n"]]}