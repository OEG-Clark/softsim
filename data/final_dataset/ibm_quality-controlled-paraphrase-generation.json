{"home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.None.data.DatasetArguments.__post_init__": [[105, 116], ["datasets.GenerateMode", "ValueError", "data.extract_suffix", "data.extract_suffix"], "methods", ["home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.None.data.extract_suffix", "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.None.data.extract_suffix"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "dataset_generate_mode", "=", "GenerateMode", "(", "self", ".", "dataset_generate_mode", ")", "\n", "if", "self", ".", "dataset_name", "is", "None", "and", "self", ".", "train_file", "is", "None", "and", "self", ".", "validation_file", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Need either a dataset name or a training/validation file.\"", ")", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "train_file", "is", "not", "None", ":", "\n", "                ", "extension", ",", "compression", "=", "extract_suffix", "(", "self", ".", "train_file", ")", "\n", "assert", "extension", "is", "not", "None", ",", "\"`train_file` should be a csv or a json file.\"", "\n", "", "if", "self", ".", "validation_file", "is", "not", "None", ":", "\n", "                ", "extension", ",", "compression", "=", "extract_suffix", "(", "self", ".", "validation_file", ")", "\n", "assert", "extension", "is", "not", "None", ",", "\"`validation_file` should be a csv or a json file.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.None.data.extract_suffix": [[10, 19], ["file_name.split", "file_name.split.pop", "file_name.split.pop"], "function", ["None"], ["def", "extract_suffix", "(", "file_name", ")", ":", "\n", "    ", "compression", "=", "None", "\n", "extension", "=", "None", "\n", "parts", "=", "file_name", ".", "split", "(", "'.'", ")", "\n", "if", "parts", "[", "-", "1", "]", "in", "[", "'gz'", "]", ":", "\n", "        ", "compression", "=", "parts", ".", "pop", "(", ")", "\n", "", "if", "parts", "[", "-", "1", "]", "in", "[", "'csv'", ",", "'json'", "]", ":", "\n", "        ", "extension", "=", "parts", ".", "pop", "(", ")", "\n", "", "return", "extension", ",", "compression", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.None.data.remove_non_printables": [[22, 24], ["text.translate"], "function", ["None"], ["def", "remove_non_printables", "(", "text", ")", ":", "\n", "    ", "return", "text", ".", "translate", "(", "nonprintable_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.None.data.bad_chars_filter": [[25, 30], ["isinstance", "data.remove_non_printables", "dictionary.items"], "function", ["home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.None.data.remove_non_printables"], ["", "def", "bad_chars_filter", "(", "dictionary", ")", ":", "\n", "    ", "result", "=", "{", "\n", "k", ":", "remove_non_printables", "(", "v", ")", "if", "isinstance", "(", "v", ",", "str", ")", "else", "v", "for", "k", ",", "v", "in", "dictionary", ".", "items", "(", ")", "\n", "}", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.None.data.prepare_dataset": [[118, 207], ["datasets.load_dataset", "datasets.load_dataset", "datasets.map.map", "datasets[].select", "datasets[].select", "datasets[].select", "datasets.map.filter", "datasets.map.map", "eval", "logger.info", "data.extract_suffix", "data.extract_suffix", "data.extract_suffix", "range", "range", "range", "logger.info", "logger.info", "str", "eval", "eval", "logger.warning"], "function", ["home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.None.data.extract_suffix", "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.None.data.extract_suffix", "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.None.data.extract_suffix"], ["", "", "", "", "def", "prepare_dataset", "(", "dataset_args", ",", "logger", "=", "None", ")", ":", "\n", "\n", "\n", "    ", "if", "dataset_args", ".", "dataset_split", "is", "not", "None", ":", "\n", "        ", "try", ":", "\n", "            ", "dataset_split", "=", "eval", "(", "dataset_args", ".", "dataset_split", ")", "\n", "", "except", ":", "\n", "            ", "dataset_split", "=", "str", "(", "dataset_args", ".", "dataset_split", ")", "\n", "if", "logger", "is", "not", "None", ":", "\n", "                ", "logger", ".", "warning", "(", "f\"Dataset split name: '{dataset_split}' treated as string. if you want to use json make sure it can be parsed proprly.\"", ")", "\n", "\n", "\n", "", "", "if", "logger", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Dataset is splitted by '{dataset_split}'\"", ")", "\n", "", "", "else", ":", "\n", "        ", "dataset_split", "=", "None", "\n", "\n", "", "if", "dataset_args", ".", "dataset_name", "is", "not", "None", ":", "\n", "\n", "        ", "datasets", "=", "load_dataset", "(", "\n", "dataset_args", ".", "dataset_name", ",", "\n", "dataset_args", ".", "dataset_config_name", ",", "\n", "split", "=", "dataset_split", ",", "\n", "keep_in_memory", "=", "dataset_args", ".", "dataset_keep_in_memory", ",", "\n", "cache_dir", "=", "dataset_args", ".", "dataset_cache_dir", ",", "\n", "download_mode", "=", "dataset_args", ".", "dataset_generate_mode", ",", "\n", "ignore_verifications", "=", "True", ",", "\n", ")", "\n", "\n", "", "else", ":", "\n", "        ", "data_files", "=", "{", "}", "\n", "if", "dataset_args", ".", "train_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"train\"", "]", "=", "dataset_args", ".", "train_file", "\n", "extension", ",", "compression", "=", "extract_suffix", "(", "dataset_args", ".", "train_file", ")", "\n", "# if compression:", "\n", "#     print(f'loading dataset from compressed file: {dataset_args.train_file}')", "\n", "#     datasets = Dataset.from_pandas(pd.read_csv(dataset_args.train_file, na_filter=False), split=dataset_args.dataset_split)", "\n", "", "if", "dataset_args", ".", "validation_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"validation\"", "]", "=", "dataset_args", ".", "validation_file", "\n", "extension", ",", "compression", "=", "extract_suffix", "(", "dataset_args", ".", "validation_file", ")", "\n", "", "if", "dataset_args", ".", "test_file", "is", "not", "None", ":", "\n", "            ", "data_files", "[", "\"test\"", "]", "=", "dataset_args", ".", "test_file", "\n", "extension", ",", "compression", "=", "extract_suffix", "(", "dataset_args", ".", "test_file", ")", "\n", "\n", "# if compression:", "\n", "#     pass", "\n", "# else:", "\n", "", "datasets", "=", "load_dataset", "(", "extension", ",", "data_files", "=", "data_files", ",", "\n", "split", "=", "dataset_split", ",", "\n", "keep_in_memory", "=", "dataset_args", ".", "dataset_keep_in_memory", ",", "\n", "cache_dir", "=", "dataset_args", ".", "dataset_cache_dir", ",", "\n", "na_filter", "=", "False", ",", "\n", "download_mode", "=", "dataset_args", ".", "dataset_generate_mode", ",", "\n", "ignore_verifications", "=", "True", ",", "\n", ")", "\n", "\n", "", "if", "dataset_args", ".", "remove_bad_chars", ":", "\n", "        ", "datasets", "=", "datasets", ".", "map", "(", "bad_chars_filter", ",", "load_from_cache_file", "=", "False", ")", "\n", "\n", "", "if", "dataset_args", ".", "max_train_samples", "is", "not", "None", "and", "'train'", "in", "datasets", ":", "\n", "        ", "datasets", "[", "'train'", "]", "=", "datasets", "[", "'train'", "]", ".", "select", "(", "range", "(", "dataset_args", ".", "max_train_samples", ")", ")", "\n", "\n", "", "if", "dataset_args", ".", "max_validation_samples", "is", "not", "None", "and", "'validation'", "in", "datasets", ":", "\n", "        ", "datasets", "[", "'validation'", "]", "=", "datasets", "[", "'validation'", "]", ".", "select", "(", "range", "(", "dataset_args", ".", "max_validation_samples", ")", ")", "\n", "\n", "", "if", "dataset_args", ".", "max_test_samples", "is", "not", "None", "and", "'test'", "in", "datasets", ":", "\n", "        ", "datasets", "[", "'test'", "]", "=", "datasets", "[", "'test'", "]", ".", "select", "(", "range", "(", "dataset_args", ".", "max_test_samples", ")", ")", "\n", "\n", "", "if", "dataset_args", ".", "dataset_filter", ":", "\n", "        ", "datasets", "=", "datasets", ".", "filter", "(", "\n", "lambda", "x", ":", "eval", "(", "dataset_args", ".", "dataset_filter", ",", "None", ",", "x", ")", ",", "\n", "keep_in_memory", "=", "dataset_args", ".", "dataset_keep_in_memory", ",", "\n", "load_from_cache", "=", "False", "\n", ")", "\n", "if", "logger", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Dataset was filtered by '{dataset_args.dataset_filter}'\"", ")", "\n", "\n", "", "", "if", "dataset_args", ".", "dataset_map", ":", "\n", "        ", "datasets", "=", "datasets", ".", "map", "(", "\n", "lambda", "x", ":", "eval", "(", "f\"\"\"locals() if not exec('{dataset_args.dataset_map}') else None\"\"\"", ",", "None", ",", "x", ")", ",", "\n", "keep_in_memory", "=", "dataset_args", ".", "dataset_keep_in_memory", ",", "\n", "load_from_cache_file", "=", "False", ",", "\n", ")", "\n", "if", "logger", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Dataset was mapped with '{dataset_args.dataset_filter}'\"", ")", "\n", "\n", "\n", "\n", "", "", "return", "datasets", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QP.train.parse_args": [[124, 132], ["sys.argv[].endswith", "Args", "Args", "len", "parser.parse_json_file", "parser.parse_args_into_dataclasses", "os.path.abspath"], "function", ["None"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "# If we pass only one argument to the script and it's the path to a json file,", "\n", "# let's parse it to get our arguments.", "\n", "        ", "args", "=", "Args", "(", "*", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "args", "=", "Args", "(", "*", "parser", ".", "parse_args_into_dataclasses", "(", ")", ")", "\n", "", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QP.train.main": [[133, 302], ["set_caching_enabled", "train.parse_args", "print", "data.prepare_dataset", "logger.warning", "transformers.trainer_utils.is_main_process", "logger.info", "transformers.set_seed", "print", "json.loads", "json.loads.sort", "print", "json.loads", "json.loads.sort", "print", "len", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "min", "datasets.map.map", "transformers.Trainer", "clearml.Task.init", "clearml.Task.init.set_resource_monitor_iteration_timeout", "train.parse_args", "os.path.isdir", "transformers.trainer_utils.get_last_checkpoint", "transformers.utils.logging.set_verbosity_info", "transformers.utils.logging.enable_default_handler", "transformers.utils.logging.enable_explicit_format", "logger.warning", "tuple", "AutoTokenizer.from_pretrained.", "list", "random.sample", "transformers.Trainer.train", "len", "transformers.Trainer.save_model", "transformers.Trainer.log_metrics", "transformers.Trainer.save_metrics", "transformers.Trainer.save_state", "logger.info", "transformers.Trainer.evaluate", "transformers.Trainer.log_metrics", "transformers.Trainer.save_metrics", "logger.info", "predict_dataset.remove_columns", "zip", "os.path.join", "pandas.DataFrame().to_csv", "ValueError", "bool", "zip", "range", "logger.info", "isinstance", "numpy.squeeze", "numpy.argmax", "transformers.DataCollatorWithPadding", "transformers.Trainer.predict", "numpy.squeeze", "numpy.argmax", "results.append", "len", "logger.info", "len", "pandas.DataFrame", "os.listdir", "bool", "tuple", "zip", "parse_args.task.run_tags.replace().split", "parse_args.task.run_tags.replace"], "function", ["home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QCPG.train.parse_args", "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.None.data.prepare_dataset", "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QCPG.train.parse_args"], ["", "def", "main", "(", ")", ":", "\n", "\n", "    ", "from", "datasets", "import", "set_caching_enabled", "\n", "set_caching_enabled", "(", "False", ")", "\n", "\n", "config", "=", "parse_args", "(", ")", "\n", "print", "(", "config", ".", "train", ".", "run_name", ")", "\n", "if", "config", ".", "train", ".", "run_name", "and", "config", ".", "train", ".", "run_name", "!=", "config", ".", "train", ".", "output_dir", ":", "\n", "        ", "import", "clearml", "\n", "task", "=", "clearml", ".", "Task", ".", "init", "(", "project_name", "=", "\"tslm/tslm-gen\"", ",", "task_name", "=", "f\"{config.train.run_name}\"", ",", "tags", "=", "[", "tag", "for", "tag", "in", "config", ".", "task", ".", "run_tags", ".", "replace", "(", "' '", ",", "''", ")", ".", "split", "(", "','", ")", "if", "tag", "]", ")", "\n", "task", ".", "set_resource_monitor_iteration_timeout", "(", "0", ")", "\n", "parse_args", "(", ")", "\n", "\n", "# Detecting last checkpoint.", "\n", "", "checkpoint", "=", "None", "\n", "if", "os", ".", "path", ".", "isdir", "(", "config", ".", "train", ".", "output_dir", ")", "and", "config", ".", "train", ".", "do_train", "and", "not", "config", ".", "train", ".", "overwrite_output_dir", ":", "\n", "        ", "last_checkpoint", "=", "get_last_checkpoint", "(", "config", ".", "train", ".", "output_dir", ")", "\n", "if", "last_checkpoint", "is", "None", "and", "len", "(", "os", ".", "listdir", "(", "config", ".", "train", ".", "output_dir", ")", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Output directory ({config.train.output_dir}) already exists and is not empty. \"", "\n", "\"Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "", "elif", "last_checkpoint", "is", "not", "None", "and", "config", ".", "train", ".", "resume_from_checkpoint", "is", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"", "\n", "\"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"", "\n", ")", "\n", "checkpoint", "=", "last_checkpoint", "\n", "", "else", ":", "\n", "            ", "checkpoint", "=", "config", ".", "train", ".", "resume_from_checkpoint", "\n", "\n", "\n", "", "", "datasets", "=", "prepare_dataset", "(", "config", ".", "data", ",", "logger", ")", "\n", "# Log on each process the small summary:", "\n", "logger", ".", "warning", "(", "\n", "f\"Process rank: {config.train.local_rank}, device: {config.train.device}, n_gpu: {config.train.n_gpu}\"", "\n", "+", "f\"distributed training: {bool(config.train.local_rank != -1)}, 16-bits training: {config.train.fp16}\"", "\n", ")", "\n", "# Set the verbosity to info of the Transformers logger (on main process only):", "\n", "if", "is_main_process", "(", "config", ".", "train", ".", "local_rank", ")", ":", "\n", "        ", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity_info", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_explicit_format", "(", ")", "\n", "\n", "", "logger", ".", "info", "(", "f\"Training/evaluation parameters {config.train}\"", ")", "\n", "\n", "set_seed", "(", "config", ".", "train", ".", "seed", ")", "\n", "print", "(", "config", ".", "task", ".", "input_columns", ")", "\n", "inputs", "=", "json", ".", "loads", "(", "config", ".", "task", ".", "input_columns", ")", "\n", "inputs", ".", "sort", "(", ")", "\n", "print", "(", "'Input Columns:'", ",", "inputs", ")", "\n", "\n", "labels", "=", "json", ".", "loads", "(", "config", ".", "task", ".", "label_columns", ")", "\n", "labels", ".", "sort", "(", ")", "\n", "print", "(", "'Label Columns:'", ",", "labels", ")", "\n", "\n", "num_labels", "=", "len", "(", "labels", ")", "\n", "is_regression", "=", "True", "\n", "\n", "model_config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "config", ".", "model", ".", "config_name", "if", "config", ".", "model", ".", "config_name", "else", "config", ".", "model", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "problem_type", "=", "'regression'", ",", "\n", "finetuning_task", "=", "'custom'", ",", "\n", "cache_dir", "=", "config", ".", "model", ".", "cache_dir", ",", "\n", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "config", ".", "model", ".", "tokenizer_name", "if", "config", ".", "model", ".", "tokenizer_name", "else", "config", ".", "model", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "config", ".", "model", ".", "cache_dir", ",", "\n", "use_fast", "=", "config", ".", "model", ".", "use_fast_tokenizer", ",", "\n", ")", "\n", "\n", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "\n", "config", ".", "model", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "config", ".", "model", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "model_config", ",", "\n", "cache_dir", "=", "config", ".", "model", ".", "cache_dir", ",", "\n", ")", "\n", "\n", "\n", "if", "config", ".", "task", ".", "pad_to_max_length", ":", "\n", "        ", "padding", "=", "\"max_length\"", "\n", "", "else", ":", "\n", "        ", "padding", "=", "False", "\n", "\n", "\n", "", "if", "config", ".", "task", ".", "max_seq_length", ">", "tokenizer", ".", "model_max_length", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "f\"The max_seq_length passed ({config.task.max_seq_length}) is larger than the maximum length for the\"", "\n", "f\"model ({tokenizer.model_max_length}). Using max_seq_length={tokenizer.model_max_length}.\"", "\n", ")", "\n", "\n", "", "max_seq_length", "=", "min", "(", "config", ".", "task", ".", "max_seq_length", ",", "tokenizer", ".", "model_max_length", ")", "\n", "\n", "def", "preprocess_function", "(", "examples", ")", ":", "\n", "# Tokenize the texts", "\n", "        ", "args", "=", "(", "\n", "tuple", "(", "examples", "[", "col", "]", "for", "col", "in", "inputs", ")", "\n", ")", "\n", "result", "=", "tokenizer", "(", "*", "args", ",", "padding", "=", "padding", ",", "max_length", "=", "max_seq_length", ",", "truncation", "=", "True", ")", "\n", "\n", "result", "[", "\"label\"", "]", "=", "list", "(", "zip", "(", "*", "tuple", "(", "examples", "[", "col", "]", "for", "col", "in", "labels", ")", ")", ")", "\n", "return", "result", "\n", "\n", "", "if", "config", ".", "train", ".", "do_predict", ":", "\n", "        ", "predict_dataset", "=", "datasets", "[", "'validation'", "]", "\n", "", "datasets", "=", "datasets", ".", "map", "(", "preprocess_function", ",", "batched", "=", "True", ",", "load_from_cache_file", "=", "not", "config", ".", "task", ".", "overwrite_cache", ")", "\n", "\n", "# Log a few random samples from the training set:", "\n", "if", "config", ".", "train", ".", "do_train", ":", "\n", "        ", "for", "index", "in", "random", ".", "sample", "(", "range", "(", "len", "(", "datasets", "[", "'train'", "]", ")", ")", ",", "3", ")", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Sample {index} of the training set: {datasets['train'][index]}.\"", ")", "\n", "\n", "", "", "def", "compute_metrics", "(", "p", ":", "EvalPrediction", ")", ":", "\n", "        ", "preds", "=", "p", ".", "predictions", "[", "0", "]", "if", "isinstance", "(", "p", ".", "predictions", ",", "tuple", ")", "else", "p", ".", "predictions", "\n", "preds", "=", "np", ".", "squeeze", "(", "preds", ")", "if", "is_regression", "else", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "return", "{", "\"mse\"", ":", "(", "(", "preds", "-", "p", ".", "label_ids", ")", "**", "2", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "}", "\n", "\n", "# Data collator will default to DataCollatorWithPadding, so we change it if we already did the padding.", "\n", "", "if", "config", ".", "task", ".", "pad_to_max_length", ":", "\n", "        ", "data_collator", "=", "default_data_collator", "\n", "", "elif", "config", ".", "train", ".", "fp16", ":", "\n", "        ", "data_collator", "=", "DataCollatorWithPadding", "(", "tokenizer", ",", "pad_to_multiple_of", "=", "8", ")", "\n", "", "else", ":", "\n", "        ", "data_collator", "=", "None", "\n", "\n", "# Initialize our Trainer", "\n", "", "trainer", "=", "Trainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "config", ".", "train", ",", "\n", "train_dataset", "=", "datasets", "[", "'train'", "]", "if", "config", ".", "train", ".", "do_train", "else", "None", ",", "\n", "eval_dataset", "=", "datasets", "[", "'validation'", "]", "if", "config", ".", "train", ".", "do_eval", "else", "None", ",", "\n", "compute_metrics", "=", "compute_metrics", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "data_collator", "=", "data_collator", ",", "\n", ")", "\n", "\n", "# Training", "\n", "if", "config", ".", "train", ".", "do_train", ":", "\n", "        ", "train_result", "=", "trainer", ".", "train", "(", "resume_from_checkpoint", "=", "checkpoint", ")", "\n", "metrics", "=", "train_result", ".", "metrics", "\n", "\n", "metrics", "[", "\"train_samples\"", "]", "=", "len", "(", "datasets", "[", "'train'", "]", ")", "\n", "\n", "trainer", ".", "save_model", "(", ")", "# Saves the tokenizer too for easy upload", "\n", "\n", "trainer", ".", "log_metrics", "(", "\"train\"", ",", "metrics", ")", "\n", "trainer", ".", "save_metrics", "(", "\"train\"", ",", "metrics", ")", "\n", "trainer", ".", "save_state", "(", ")", "\n", "\n", "# Evaluation", "\n", "", "if", "config", ".", "train", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Evaluate ***\"", ")", "\n", "metrics", "=", "trainer", ".", "evaluate", "(", "eval_dataset", "=", "datasets", "[", "'validation'", "]", ")", "\n", "trainer", ".", "log_metrics", "(", "\"eval\"", ",", "metrics", ")", "\n", "trainer", ".", "save_metrics", "(", "\"eval\"", ",", "metrics", ")", "\n", "\n", "", "if", "config", ".", "train", ".", "do_predict", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Predict ***\"", ")", "\n", "predict_dataset", ".", "remove_columns", "(", "labels", ")", "\n", "predictions", "=", "trainer", ".", "predict", "(", "datasets", "[", "'validation'", "]", ",", "metric_key_prefix", "=", "\"predict\"", ")", ".", "predictions", "\n", "predictions", "=", "np", ".", "squeeze", "(", "predictions", ")", "if", "is_regression", "else", "np", ".", "argmax", "(", "predictions", ",", "axis", "=", "1", ")", "\n", "results", "=", "[", "]", "\n", "for", "orig", ",", "pred", "in", "zip", "(", "predict_dataset", ",", "predictions", ")", ":", "\n", "            ", "input_data", "=", "{", "col", ":", "orig", "[", "col", "]", "for", "col", "in", "inputs", "}", "\n", "pred_data", "=", "{", "col", ":", "p", "for", "col", ",", "p", "in", "zip", "(", "labels", ",", "pred", ")", "}", "\n", "results", ".", "append", "(", "{", "**", "input_data", ",", "**", "pred_data", "}", ")", "\n", "", "results_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "train", ".", "output_dir", ",", "f\"predict_results.csv.gz\"", ")", "\n", "pd", ".", "DataFrame", "(", "results", ")", ".", "to_csv", "(", "results_file", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QP.train._mp_fn": [[305, 308], ["train.main"], "function", ["home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QCPG.train.main"], ["", "", "def", "_mp_fn", "(", "index", ")", ":", "\n", "# For xla_spawn (TPUs)", "\n", "    ", "main", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QCPG.predict.DataTrainingArguments.__post_init__": [[150, 153], ["None"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "val_max_target_length", "is", "None", ":", "\n", "            ", "self", ".", "val_max_target_length", "=", "self", ".", "max_target_length", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QCPG.predict.normalize_condition": [[154, 157], ["cond.replace().upper", "str", "str", "cond.replace"], "function", ["None"], ["", "", "", "def", "normalize_condition", "(", "cond", ",", "cls", ")", ":", "\n", "    ", "cond", "=", "'_'", ".", "join", "(", "[", "'COND'", ",", "str", "(", "cls", ")", ",", "str", "(", "cond", ")", "]", ")", "\n", "return", "cond", ".", "replace", "(", "' '", ",", "'_'", ")", ".", "upper", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QCPG.predict.main": [[158, 345], ["set_caching_enabled", "transformers.HfArgumentParser", "logging.basicConfig", "logger.setLevel", "logger.warning", "transformers.trainer_utils.is_main_process", "logger.info", "transformers.set_seed", "data.prepare_dataset", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoConfig.from_pretrained", "dataset.map", "transformers.DataCollatorForSeq2Seq", "transformers.Seq2SeqTrainer", "logger.info", "transformers.Seq2SeqTrainer.predict", "transformers.Seq2SeqTrainer.is_world_process_zero", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "clearml.Task.init", "Task.init.set_resource_monitor_iteration_timeout", "transformers.utils.logging.set_verbosity_info", "json.loads", "sorted", "logger.info", "transformers.AutoModelForSeq2SeqLM.from_config", "ValueError", "logger.warning", "AutoTokenizer.from_pretrained.", "len", "transformers.trainer_utils.is_main_process", "list", "dataset.unique", "transformers.AutoModelForSeq2SeqLM.from_pretrained", "ValueError", "ValueError", "ValueError", "hasattr", "list", "AutoTokenizer.from_pretrained.as_target_tokenizer", "AutoTokenizer.from_pretrained.", "AutoTokenizer.from_pretrained.batch_decode", "os.path.join", "pandas.DataFrame", "pd.DataFrame.to_csv", "os.path.abspath", "logging.StreamHandler", "data.prepare_dataset.values", "predict.normalize_condition", "zip", "pred.strip", "bool", "zip", "predict.normalize_condition", "zip"], "function", ["home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.None.data.prepare_dataset", "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QCPG.train.normalize_condition", "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QCPG.train.normalize_condition"], ["", "def", "main", "(", ")", ":", "\n", "\n", "    ", "from", "datasets", "import", "set_caching_enabled", "\n", "set_caching_enabled", "(", "False", ")", "\n", "\n", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DatasetArguments", ",", "DataTrainingArguments", ",", "Seq2SeqTrainingArguments", ")", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "        ", "model_args", ",", "dataset_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_args", ",", "dataset_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "", "if", "False", ":", "\n", "        ", "task", "=", "Task", ".", "init", "(", "project_name", "=", "\"tslm/tslm-gen-eval\"", ",", "task_name", "=", "f\"{training_args.run_name}\"", ")", "\n", "task", ".", "set_resource_monitor_iteration_timeout", "(", "1", ")", "\n", "\n", "", "training_args", ".", "do_train", "=", "False", "\n", "training_args", ".", "do_evaluate", "=", "False", "\n", "training_args", ".", "do_predict", "=", "True", "\n", "training_args", ".", "predict_with_generate", "=", "True", "\n", "# Detecting last checkpoint.", "\n", "last_checkpoint", "=", "None", "\n", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "]", ",", "\n", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", "else", "logging", ".", "WARN", ")", "\n", "\n", "# Log on each process the small summary:", "\n", "logger", ".", "warning", "(", "\n", "f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"", "\n", "+", "f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"", "\n", ")", "\n", "# Set the verbosity to info of the Transformers logger (on main process only):", "\n", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", ":", "\n", "        ", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity_info", "(", ")", "\n", "", "logger", ".", "info", "(", "f\"Training/evaluation parameters {training_args}\"", ")", "\n", "\n", "# Set seed before initializing model.", "\n", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "datasets", "=", "prepare_dataset", "(", "dataset_args", ",", "logger", ")", "\n", "\n", "try", ":", "\n", "        ", "dataset", "=", "list", "(", "datasets", ".", "values", "(", ")", ")", "[", "-", "1", "]", "\n", "", "except", ":", "\n", "        ", "dataset", "=", "datasets", "\n", "\n", "", "conditions_columns", "=", "data_args", ".", "conditions_columns", "\n", "if", "conditions_columns", "is", "not", "None", ":", "\n", "        ", "conditions_columns", "=", "json", ".", "loads", "(", "conditions_columns", ")", "\n", "all_conditions", "=", "[", "]", "\n", "for", "column", "in", "conditions_columns", ":", "\n", "            ", "conditions", "=", "dataset", ".", "unique", "(", "column", ")", "\n", "conditions", "=", "[", "normalize_condition", "(", "c", ",", "column", ")", "for", "c", "in", "conditions", "]", "\n", "all_conditions", "+=", "conditions", "\n", "", "all_conditions", "=", "sorted", "(", "all_conditions", ")", "\n", "logger", ".", "info", "(", "f\"Full conditions list: {all_conditions}\"", ")", "\n", "\n", "", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "model_args", ".", "tokenizer_name", "if", "model_args", ".", "tokenizer_name", "else", "model_args", ".", "model_name_or_path", "\n", ")", "\n", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "model_args", ".", "config_name", "if", "model_args", ".", "config_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "if", "model_args", ".", "config_name", "is", "not", "None", ":", "\n", "        ", "model", "=", "AutoModelForSeq2SeqLM", ".", "from_config", "(", "config", ")", "\n", "", "elif", "model_args", ".", "model_name_or_path", "is", "not", "None", ":", "\n", "        ", "model", "=", "AutoModelForSeq2SeqLM", ".", "from_pretrained", "(", "model_args", ".", "model_name_or_path", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"You must specify model_name_or_path or config_name\"", ")", "\n", "\n", "\n", "", "if", "model", ".", "config", ".", "decoder_start_token_id", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"Make sure that `config.decoder_start_token_id` is correctly defined\"", ")", "\n", "\n", "", "prefix", "=", "data_args", ".", "source_prefix", "if", "data_args", ".", "source_prefix", "is", "not", "None", "else", "\"\"", "\n", "\n", "# Preprocessing the datasets.", "\n", "# We need to tokenize inputs and targets.", "\n", "column_names", "=", "dataset", ".", "column_names", "\n", "\n", "\n", "# Get the column names for input/target.", "\n", "if", "data_args", ".", "source_column", "is", "None", ":", "\n", "        ", "source_column", "=", "column_names", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "source_column", "=", "data_args", ".", "source_column", "\n", "if", "source_column", "not", "in", "column_names", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"--source_column' value '{data_args.source_column}' needs to be one of: {', '.join(column_names)}\"", "\n", ")", "\n", "", "", "if", "data_args", ".", "target_column", "is", "None", ":", "\n", "        ", "target_column", "=", "column_names", "[", "1", "]", "\n", "", "else", ":", "\n", "        ", "target_column", "=", "data_args", ".", "target_column", "\n", "if", "target_column", "not", "in", "column_names", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"--target_column' value '{data_args.target_column}' needs to be one of: {', '.join(column_names)}\"", "\n", ")", "\n", "\n", "# Temporarily set max_target_length for training.", "\n", "", "", "max_target_length", "=", "data_args", ".", "max_target_length", "\n", "padding", "=", "\"max_length\"", "if", "data_args", ".", "pad_to_max_length", "else", "False", "\n", "\n", "if", "training_args", ".", "label_smoothing_factor", ">", "0", "and", "not", "hasattr", "(", "model", ",", "\"prepare_decoder_input_ids_from_labels\"", ")", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "\"label_smoothing is enabled but the `prepare_decoder_input_ids_from_labels` method is not defined for\"", "\n", "f\"`{model.__class__.__name__}`. This will lead to loss being calculated twice and will take up more memory\"", "\n", ")", "\n", "\n", "", "def", "preprocess_function", "(", "examples", ")", ":", "\n", "        ", "inputs", "=", "examples", "[", "source_column", "]", "\n", "targets", "=", "examples", "[", "target_column", "]", "\n", "\n", "if", "conditions_columns", ":", "\n", "            ", "conditions", "=", "[", "examples", "[", "column", "]", "for", "column", "in", "conditions_columns", "]", "\n", "conditions", "=", "list", "(", "zip", "(", "*", "conditions", ")", ")", "\n", "conditions", "=", "[", "' '", ".", "join", "(", "normalize_condition", "(", "cond", ",", "col", ")", "for", "cond", ",", "col", "in", "zip", "(", "conds", ",", "conditions_columns", ")", ")", "for", "conds", "in", "conditions", "]", "\n", "inputs", "=", "[", "conds", "+", "prefix", "+", "inp", "for", "inp", ",", "conds", "in", "zip", "(", "inputs", ",", "conditions", ")", "]", "\n", "", "else", ":", "\n", "            ", "inputs", "=", "[", "prefix", "+", "inp", "for", "inp", "in", "inputs", "]", "\n", "\n", "", "model_inputs", "=", "tokenizer", "(", "inputs", ",", "max_length", "=", "data_args", ".", "max_source_length", ",", "padding", "=", "padding", ",", "truncation", "=", "True", ")", "\n", "\n", "# Setup the tokenizer for targets", "\n", "with", "tokenizer", ".", "as_target_tokenizer", "(", ")", ":", "\n", "            ", "labels", "=", "tokenizer", "(", "targets", ",", "max_length", "=", "max_target_length", ",", "padding", "=", "padding", ",", "truncation", "=", "True", ")", "\n", "\n", "# If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore", "\n", "# padding in the loss.", "\n", "", "if", "padding", "==", "\"max_length\"", "and", "data_args", ".", "ignore_pad_token_for_loss", ":", "\n", "            ", "labels", "[", "\"input_ids\"", "]", "=", "[", "\n", "[", "(", "l", "if", "l", "!=", "tokenizer", ".", "pad_token_id", "else", "-", "100", ")", "for", "l", "in", "label", "]", "for", "label", "in", "labels", "[", "\"input_ids\"", "]", "\n", "]", "\n", "\n", "", "model_inputs", "[", "\"labels\"", "]", "=", "labels", "[", "\"input_ids\"", "]", "\n", "return", "model_inputs", "\n", "\n", "", "input_dataset", "=", "dataset", ".", "map", "(", "\n", "preprocess_function", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "remove_columns", "=", "column_names", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", ")", "\n", "\n", "# Data collator", "\n", "label_pad_token_id", "=", "-", "100", "if", "data_args", ".", "ignore_pad_token_for_loss", "else", "tokenizer", ".", "pad_token_id", "\n", "data_collator", "=", "DataCollatorForSeq2Seq", "(", "\n", "tokenizer", ",", "\n", "model", "=", "model", ",", "\n", "label_pad_token_id", "=", "label_pad_token_id", ",", "\n", "pad_to_multiple_of", "=", "8", "if", "training_args", ".", "fp16", "else", "None", ",", "\n", ")", "\n", "\n", "trainer", "=", "Seq2SeqTrainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "data_collator", "=", "data_collator", ",", "\n", "# compute_metrics=compute_metrics if training_args.predict_with_generate else None,", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "\"*** Predict ***\"", ")", "\n", "\n", "predict_results", "=", "trainer", ".", "predict", "(", "\n", "input_dataset", ",", "\n", "max_length", "=", "data_args", ".", "val_max_target_length", ",", "\n", "num_beams", "=", "data_args", ".", "num_beams", ",", "\n", ")", "\n", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "        ", "if", "training_args", ".", "predict_with_generate", ":", "\n", "            ", "predictions", "=", "tokenizer", ".", "batch_decode", "(", "\n", "predict_results", ".", "predictions", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "True", "\n", ")", "\n", "predictions", "=", "[", "pred", ".", "strip", "(", ")", "for", "pred", "in", "predictions", "]", "\n", "output_prediction_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "data_args", ".", "output_file_name", ")", "\n", "result", "=", "pd", ".", "DataFrame", "(", "{", "'source'", ":", "dataset", "[", "source_column", "]", ",", "'target'", ":", "dataset", "[", "target_column", "]", ",", "'prediction'", ":", "predictions", "}", ")", "\n", "result", ".", "to_csv", "(", "output_prediction_file", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QCPG.predict._mp_fn": [[348, 351], ["predict.main"], "function", ["home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QCPG.train.main"], ["", "", "", "def", "_mp_fn", "(", "index", ")", ":", "\n", "# For xla_spawn (TPUs)", "\n", "    ", "main", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QCPG.evaluate.main": [[30, 66], ["set_caching_enabled", "transformers.HfArgumentParser", "os.makedirs", "data.prepare_dataset", "datasets.load_metric", "print", "datasets.load_metric.compute", "pd.DataFrame.to_csv", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "os.path.abspath", "pandas.DataFrame", "len", "os.path.dirname", "os.getpid", "print", "os.path.abspath"], "function", ["home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.None.data.prepare_dataset"], ["", "def", "main", "(", ")", ":", "\n", "\n", "    ", "from", "datasets", "import", "set_caching_enabled", "\n", "set_caching_enabled", "(", "False", ")", "\n", "\n", "parser", "=", "HfArgumentParser", "(", "(", "DatasetArguments", ",", "EvalArguments", ")", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "        ", "dataset_args", ",", "eval_args", "=", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "dataset_args", ",", "eval_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "\n", "", "os", ".", "makedirs", "(", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "dirname", "(", "eval_args", ".", "output_path", ")", ")", ",", "exist_ok", "=", "True", ")", "\n", "\n", "dataset", "=", "prepare_dataset", "(", "dataset_args", ")", "\n", "column_names", "=", "dataset", ".", "column_names", "\n", "\n", "predictions", "=", "dataset", "[", "column_names", "[", "1", "]", "]", "if", "eval_args", ".", "predictions_column", "is", "None", "else", "dataset", "[", "eval_args", ".", "predictions_column", "]", "\n", "references", "=", "dataset", "[", "column_names", "[", "0", "]", "]", "if", "eval_args", ".", "references_column", "is", "None", "else", "dataset", "[", "eval_args", ".", "references_column", "]", "\n", "\n", "metric", "=", "load_metric", "(", "eval_args", ".", "metric_name_or_path", ",", "experiment_id", "=", "os", ".", "getpid", "(", ")", ")", "\n", "\n", "print", "(", "'Computing metric...'", ")", "\n", "result", "=", "metric", ".", "compute", "(", "predictions", "=", "predictions", ",", "references", "=", "references", ")", "\n", "\n", "result", "[", "'prediction'", "]", "=", "predictions", "\n", "result", "[", "'reference'", "]", "=", "references", "\n", "\n", "try", ":", "\n", "        ", "df", "=", "pd", ".", "DataFrame", "(", "result", ")", "\n", "", "except", ":", "\n", "        ", "print", "(", "result", ")", "\n", "raise", "NotImplementedError", "\n", "\n", "", "df", ".", "to_csv", "(", "eval_args", ".", "output_path", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QCPG.train.DataTrainingArguments.__post_init__": [[171, 174], ["None"], "methods", ["None"], ["# Set the verbosity to info of the Transformers logger (on main process only):", "\n", "if", "is_main_process", "(", "config", ".", "train", ".", "local_rank", ")", ":", "\n", "        ", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity_info", "(", ")", "\n", "transformers", ".", "utils", ".", "logging", ".", "enable_default_handler", "(", ")", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QCPG.train.normalize_condition": [[175, 178], ["cond.replace().upper", "str", "str", "cond.replace"], "function", ["None"], ["transformers", ".", "utils", ".", "logging", ".", "enable_explicit_format", "(", ")", "\n", "\n", "", "logger", ".", "info", "(", "f\"Training/evaluation parameters {config.train}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QCPG.train.parse_args": [[179, 191], ["transformers.HfArgumentParser", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "len", "os.path.abspath"], "function", ["None"], ["set_seed", "(", "config", ".", "train", ".", "seed", ")", "\n", "print", "(", "config", ".", "task", ".", "input_columns", ")", "\n", "inputs", "=", "json", ".", "loads", "(", "config", ".", "task", ".", "input_columns", ")", "\n", "inputs", ".", "sort", "(", ")", "\n", "print", "(", "'Input Columns:'", ",", "inputs", ")", "\n", "\n", "labels", "=", "json", ".", "loads", "(", "config", ".", "task", ".", "label_columns", ")", "\n", "labels", ".", "sort", "(", ")", "\n", "print", "(", "'Label Columns:'", ",", "labels", ")", "\n", "\n", "num_labels", "=", "len", "(", "labels", ")", "\n", "is_regression", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QCPG.train.main": [[192, 509], ["train.parse_args", "logging.basicConfig", "logger.setLevel", "logger.warning", "transformers.trainer_utils.is_main_process", "logger.info", "transformers.set_seed", "data.prepare_dataset", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoConfig.from_pretrained", "AutoModelForSeq2SeqLM.from_pretrained.resize_token_embeddings", "transformers.DataCollatorForSeq2Seq", "datasets.load_metric", "transformers.Seq2SeqTrainer", "clearml.Task.init", "clearml.Task.init.set_resource_monitor_iteration_timeout", "train.parse_args", "logger.warning", "os.path.isdir", "transformers.trainer_utils.get_last_checkpoint", "transformers.utils.logging.set_verbosity_info", "json.loads", "sorted", "logger.info", "transformers.AutoModelForSeq2SeqLM.from_config", "len", "ValueError", "logger.warning", "AutoTokenizer.from_pretrained.", "train_dataset.map.map", "eval_dataset.map.map", "predict_dataset.map.map", "print", "isinstance", "AutoTokenizer.from_pretrained.batch_decode", "AutoTokenizer.from_pretrained.batch_decode", "train.main.postprocess_text"], "function", ["home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QCPG.train.parse_args", "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.None.data.prepare_dataset", "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QCPG.train.parse_args"], ["model_config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "config", ".", "model", ".", "config_name", "if", "config", ".", "model", ".", "config_name", "else", "config", ".", "model", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "problem_type", "=", "'regression'", ",", "\n", "finetuning_task", "=", "'custom'", ",", "\n", "cache_dir", "=", "config", ".", "model", ".", "cache_dir", ",", "\n", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "config", ".", "model", ".", "tokenizer_name", "if", "config", ".", "model", ".", "tokenizer_name", "else", "config", ".", "model", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "config", ".", "model", ".", "cache_dir", ",", "\n", "use_fast", "=", "config", ".", "model", ".", "use_fast_tokenizer", ",", "\n", ")", "\n", "\n", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "\n", "config", ".", "model", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "config", ".", "model", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "model_config", ",", "\n", "cache_dir", "=", "config", ".", "model", ".", "cache_dir", ",", "\n", ")", "\n", "\n", "\n", "if", "config", ".", "task", ".", "pad_to_max_length", ":", "\n", "        ", "padding", "=", "\"max_length\"", "\n", "", "else", ":", "\n", "        ", "padding", "=", "False", "\n", "\n", "\n", "", "if", "config", ".", "task", ".", "max_seq_length", ">", "tokenizer", ".", "model_max_length", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "f\"The max_seq_length passed ({config.task.max_seq_length}) is larger than the maximum length for the\"", "\n", "f\"model ({tokenizer.model_max_length}). Using max_seq_length={tokenizer.model_max_length}.\"", "\n", ")", "\n", "\n", "", "max_seq_length", "=", "min", "(", "config", ".", "task", ".", "max_seq_length", ",", "tokenizer", ".", "model_max_length", ")", "\n", "\n", "def", "preprocess_function", "(", "examples", ")", ":", "\n", "# Tokenize the texts", "\n", "        ", "args", "=", "(", "\n", "tuple", "(", "examples", "[", "col", "]", "for", "col", "in", "inputs", ")", "\n", ")", "\n", "result", "=", "tokenizer", "(", "*", "args", ",", "padding", "=", "padding", ",", "max_length", "=", "max_seq_length", ",", "truncation", "=", "True", ")", "\n", "\n", "result", "[", "\"label\"", "]", "=", "list", "(", "zip", "(", "*", "tuple", "(", "examples", "[", "col", "]", "for", "col", "in", "labels", ")", ")", ")", "\n", "return", "result", "\n", "\n", "", "if", "config", ".", "train", ".", "do_predict", ":", "\n", "        ", "predict_dataset", "=", "datasets", "[", "'validation'", "]", "\n", "", "datasets", "=", "datasets", ".", "map", "(", "preprocess_function", ",", "batched", "=", "True", ",", "load_from_cache_file", "=", "not", "config", ".", "task", ".", "overwrite_cache", ")", "\n", "\n", "# Log a few random samples from the training set:", "\n", "if", "config", ".", "train", ".", "do_train", ":", "\n", "        ", "for", "index", "in", "random", ".", "sample", "(", "range", "(", "len", "(", "datasets", "[", "'train'", "]", ")", ")", ",", "3", ")", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Sample {index} of the training set: {datasets['train'][index]}.\"", ")", "\n", "\n", "", "", "def", "compute_metrics", "(", "p", ":", "EvalPrediction", ")", ":", "\n", "        ", "preds", "=", "p", ".", "predictions", "[", "0", "]", "if", "isinstance", "(", "p", ".", "predictions", ",", "tuple", ")", "else", "p", ".", "predictions", "\n", "preds", "=", "np", ".", "squeeze", "(", "preds", ")", "if", "is_regression", "else", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "return", "{", "\"mse\"", ":", "(", "(", "preds", "-", "p", ".", "label_ids", ")", "**", "2", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "}", "\n", "\n", "# Data collator will default to DataCollatorWithPadding, so we change it if we already did the padding.", "\n", "", "if", "config", ".", "task", ".", "pad_to_max_length", ":", "\n", "        ", "data_collator", "=", "default_data_collator", "\n", "", "elif", "config", ".", "train", ".", "fp16", ":", "\n", "        ", "data_collator", "=", "DataCollatorWithPadding", "(", "tokenizer", ",", "pad_to_multiple_of", "=", "8", ")", "\n", "", "else", ":", "\n", "        ", "data_collator", "=", "None", "\n", "\n", "# Initialize our Trainer", "\n", "", "trainer", "=", "Trainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "config", ".", "train", ",", "\n", "train_dataset", "=", "datasets", "[", "'train'", "]", "if", "config", ".", "train", ".", "do_train", "else", "None", ",", "\n", "eval_dataset", "=", "datasets", "[", "'validation'", "]", "if", "config", ".", "train", ".", "do_eval", "else", "None", ",", "\n", "compute_metrics", "=", "compute_metrics", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "data_collator", "=", "data_collator", ",", "\n", ")", "\n", "\n", "# Training", "\n", "if", "config", ".", "train", ".", "do_train", ":", "\n", "        ", "train_result", "=", "trainer", ".", "train", "(", "resume_from_checkpoint", "=", "checkpoint", ")", "\n", "metrics", "=", "train_result", ".", "metrics", "\n", "\n", "metrics", "[", "\"train_samples\"", "]", "=", "len", "(", "datasets", "[", "'train'", "]", ")", "\n", "\n", "trainer", ".", "save_model", "(", ")", "# Saves the tokenizer too for easy upload", "\n", "\n", "trainer", ".", "log_metrics", "(", "\"train\"", ",", "metrics", ")", "\n", "trainer", ".", "save_metrics", "(", "\"train\"", ",", "metrics", ")", "\n", "trainer", ".", "save_state", "(", ")", "\n", "\n", "# Evaluation", "\n", "", "if", "config", ".", "train", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Evaluate ***\"", ")", "\n", "metrics", "=", "trainer", ".", "evaluate", "(", "eval_dataset", "=", "datasets", "[", "'validation'", "]", ")", "\n", "trainer", ".", "log_metrics", "(", "\"eval\"", ",", "metrics", ")", "\n", "trainer", ".", "save_metrics", "(", "\"eval\"", ",", "metrics", ")", "\n", "\n", "", "if", "config", ".", "train", ".", "do_predict", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Predict ***\"", ")", "\n", "predict_dataset", ".", "remove_columns", "(", "labels", ")", "\n", "predictions", "=", "trainer", ".", "predict", "(", "datasets", "[", "'validation'", "]", ",", "metric_key_prefix", "=", "\"predict\"", ")", ".", "predictions", "\n", "predictions", "=", "np", ".", "squeeze", "(", "predictions", ")", "if", "is_regression", "else", "np", ".", "argmax", "(", "predictions", ",", "axis", "=", "1", ")", "\n", "results", "=", "[", "]", "\n", "for", "orig", ",", "pred", "in", "zip", "(", "predict_dataset", ",", "predictions", ")", ":", "\n", "            ", "input_data", "=", "{", "col", ":", "orig", "[", "col", "]", "for", "col", "in", "inputs", "}", "\n", "pred_data", "=", "{", "col", ":", "p", "for", "col", ",", "p", "in", "zip", "(", "labels", ",", "pred", ")", "}", "\n", "results", ".", "append", "(", "{", "**", "input_data", ",", "**", "pred_data", "}", ")", "\n", "", "results_file", "=", "os", ".", "path", ".", "join", "(", "config", ".", "train", ".", "output_dir", ",", "f\"predict_results.csv.gz\"", ")", "\n", "pd", ".", "DataFrame", "(", "results", ")", ".", "to_csv", "(", "results_file", ",", "index", "=", "False", ")", "\n", "\n", "\n", "\n", "", "", "def", "_mp_fn", "(", "index", ")", ":", "\n", "# For xla_spawn (TPUs)", "\n", "    ", "main", "(", ")", "\n", "\n", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "main", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QCPG.train._mp_fn": [[511, 514], ["train.main"], "function", ["home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.QCPG.train.main"], []], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.cross_metric.cross_metric.CrossMetric._info": [[55, 72], ["datasets.MetricInfo", "datasets.Features", "datasets.Value", "datasets.Value"], "methods", ["None"], ["def", "_info", "(", "self", ")", ":", "\n", "# TODO: Specifies the datasets.MetricInfo object", "\n", "        ", "return", "datasets", ".", "MetricInfo", "(", "\n", "# This is the description that will appear on the metrics page.", "\n", "description", "=", "_DESCRIPTION", ",", "\n", "citation", "=", "_CITATION", ",", "\n", "inputs_description", "=", "_KWARGS_DESCRIPTION", ",", "\n", "# This defines the format of each prediction and reference", "\n", "features", "=", "datasets", ".", "Features", "(", "{", "\n", "'predictions'", ":", "datasets", ".", "Value", "(", "'string'", ")", ",", "\n", "'references'", ":", "datasets", ".", "Value", "(", "'string'", ")", ",", "\n", "}", ")", ",", "\n", "# Homepage of the metric for documentation", "\n", "homepage", "=", "\"http://metric.homepage\"", ",", "\n", "# Additional links to the codebase or references", "\n", "codebase_urls", "=", "[", "\"http://github.com/path/to/codebase/of/new_metric\"", "]", ",", "\n", "reference_urls", "=", "[", "\"http://path.to.reference.url/new_metric\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.cross_metric.cross_metric.CrossMetric._download_and_prepare": [[74, 84], ["transformers.AutoTokenizer.from_pretrained", "transformers.AutoModel.from_pretrained", "cross_metric.CrossMetric.model.eval", "cross_metric.CrossMetric.set_device", "torch.cuda.is_available"], "methods", ["home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.bleurt.bleurt.BLEURT.set_device"], ["", "def", "_download_and_prepare", "(", "self", ",", "dl_manager", ")", ":", "\n", "        ", "\"\"\"Optional: download external resources useful to compute the scores\"\"\"", "\n", "if", "self", ".", "config_name", "==", "'default'", ":", "\n", "            ", "model_name", "=", "'sentence-transformers/paraphrase-mpnet-base-v2'", "\n", "", "else", ":", "\n", "            ", "model_name", "=", "self", ".", "config_name", "\n", "", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "model", "=", "AutoModel", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "set_device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.cross_metric.cross_metric.CrossMetric.set_device": [[85, 88], ["cross_metric.CrossMetric.model.to", "torch.device"], "methods", ["None"], ["", "def", "set_device", "(", "self", ",", "device", ")", ":", "\n", "        ", "self", ".", "model", ".", "to", "(", "torch", ".", "device", "(", "device", ")", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.cross_metric.cross_metric.CrossMetric.mean_pooling": [[89, 93], ["attention_mask.unsqueeze().expand().float", "torch.sum", "torch.clamp", "attention_mask.unsqueeze().expand", "attention_mask.unsqueeze().expand().float.sum", "token_embeddings.size", "attention_mask.unsqueeze"], "methods", ["None"], ["", "def", "mean_pooling", "(", "self", ",", "model_output", ",", "attention_mask", ")", ":", "\n", "        ", "token_embeddings", "=", "model_output", "[", "0", "]", "#First element of model_output contains all token embeddings", "\n", "input_mask_expanded", "=", "attention_mask", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "token_embeddings", ".", "size", "(", ")", ")", ".", "float", "(", ")", "\n", "return", "torch", ".", "sum", "(", "token_embeddings", "*", "input_mask_expanded", ",", "1", ")", "/", "torch", ".", "clamp", "(", "input_mask_expanded", ".", "sum", "(", "1", ")", ",", "min", "=", "1e-9", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.cross_metric.cross_metric.CrossMetric.embed": [[94, 105], ["cross_metric.CrossMetric.tokenizer", "cross_metric.CrossMetric.mean_pooling", "cross_metric.CrossMetric.cpu().detach", "list", "torch.no_grad", "cross_metric.CrossMetric.model", "isinstance", "tensor.to", "cross_metric.CrossMetric.items", "cross_metric.CrossMetric.cpu", "torch.device"], "methods", ["home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.cross_metric.cross_metric.CrossMetric.mean_pooling"], ["", "def", "embed", "(", "self", ",", "sentences", ")", ":", "\n", "\n", "        ", "inputs", "=", "self", ".", "tokenizer", "(", "list", "(", "sentences", ")", ",", "padding", "=", "True", ",", "truncation", "=", "True", ",", "return_tensors", "=", "'pt'", ")", "\n", "inputs", "=", "{", "\n", "name", ":", "tensor", ".", "to", "(", "torch", ".", "device", "(", "self", ".", "device", ")", ")", "if", "isinstance", "(", "tensor", ",", "torch", ".", "Tensor", ")", "else", "tensor", "\n", "for", "name", ",", "tensor", "in", "inputs", ".", "items", "(", ")", "\n", "}", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "model_output", "=", "self", ".", "model", "(", "**", "inputs", ")", "\n", "", "sentence_embeddings", "=", "self", ".", "mean_pooling", "(", "model_output", ",", "inputs", "[", "'attention_mask'", "]", ")", "\n", "return", "sentence_embeddings", ".", "cpu", "(", ")", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.cross_metric.cross_metric.CrossMetric._compute": [[106, 127], ["tqdm.auto.tqdm.auto.tqdm", "torch.cat", "torch.cat", "torch.nn.functional.cosine_similarity", "cross_metric.CrossMetric.set_device", "zip", "preds_embeds.append", "refs_embeds.append", "torch.nn.functional.cosine_similarity.tolist", "cross_metric.to_batches", "cross_metric.to_batches", "int", "cross_metric.CrossMetric.embed", "cross_metric.CrossMetric.embed", "math.ceil", "min", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.bleurt.bleurt.BLEURT.set_device", "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.bleurt.bleurt.to_batches", "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.bleurt.bleurt.to_batches", "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.cross_metric.cross_metric.CrossMetric.embed", "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.cross_metric.cross_metric.CrossMetric.embed"], ["", "def", "_compute", "(", "self", ",", "predictions", ",", "references", ",", "batch_size", "=", "64", ",", "device", "=", "None", ")", ":", "\n", "        ", "\"\"\"Returns the scores\"\"\"", "\n", "if", "device", "!=", "self", ".", "device", "and", "device", "is", "not", "None", ":", "\n", "            ", "self", ".", "set_device", "(", "device", ")", "\n", "\n", "", "preds_embeds", "=", "[", "]", "\n", "refs_embeds", "=", "[", "]", "\n", "for", "preds", ",", "refs", "in", "tqdm", "(", "zip", "(", "to_batches", "(", "predictions", ",", "batch_size", ")", ",", "to_batches", "(", "references", ",", "batch_size", ")", ")", ",", "total", "=", "int", "(", "ceil", "(", "min", "(", "len", "(", "predictions", ")", ",", "len", "(", "references", ")", ")", "/", "batch_size", ")", ")", ",", "desc", "=", "\"cross_metric\"", ")", ":", "\n", "\n", "            ", "preds_embeds", ".", "append", "(", "self", ".", "embed", "(", "preds", ")", ")", "\n", "refs_embeds", ".", "append", "(", "self", ".", "embed", "(", "refs", ")", ")", "\n", "\n", "", "preds", "=", "torch", ".", "cat", "(", "preds_embeds", ")", "\n", "refs", "=", "torch", ".", "cat", "(", "refs_embeds", ")", "\n", "\n", "scores", "=", "torch", ".", "nn", ".", "functional", ".", "cosine_similarity", "(", "preds", ",", "refs", ",", "dim", "=", "1", ")", "\n", "\n", "scores", "=", "(", "scores", "+", "1", ")", "/", "2", "\n", "\n", "return", "{", "\n", "\"scores\"", ":", "scores", ".", "tolist", "(", ")", ",", "\n", "}", ""]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.cross_metric.cross_metric.to_batches": [[9, 11], ["range", "len"], "function", ["None"], ["def", "to_batches", "(", "seq", ",", "size", ")", ":", "\n", "    ", "return", "(", "seq", "[", "pos", ":", "pos", "+", "size", "]", "for", "pos", "in", "range", "(", "0", ",", "len", "(", "seq", ")", ",", "size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.syntdiv_metric.syntdiv_metric.CrossMetric._info": [[107, 124], ["datasets.MetricInfo", "datasets.Features", "datasets.Value", "datasets.Value"], "methods", ["None"], ["def", "_info", "(", "self", ")", ":", "\n", "# TODO: Specifies the datasets.MetricInfo object", "\n", "        ", "return", "datasets", ".", "MetricInfo", "(", "\n", "# This is the description that will appear on the metrics page.", "\n", "description", "=", "_DESCRIPTION", ",", "\n", "citation", "=", "_CITATION", ",", "\n", "inputs_description", "=", "_KWARGS_DESCRIPTION", ",", "\n", "# This defines the format of each prediction and reference", "\n", "features", "=", "datasets", ".", "Features", "(", "{", "\n", "'predictions'", ":", "datasets", ".", "Value", "(", "'string'", ")", ",", "\n", "'references'", ":", "datasets", ".", "Value", "(", "'string'", ")", ",", "\n", "}", ")", ",", "\n", "# Homepage of the metric for documentation", "\n", "homepage", "=", "\"http://metric.homepage\"", ",", "\n", "# Additional links to the codebase or references", "\n", "codebase_urls", "=", "[", "\"http://github.com/path/to/codebase/of/new_metric\"", "]", ",", "\n", "reference_urls", "=", "[", "\"http://path.to.reference.url/new_metric\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.syntdiv_metric.syntdiv_metric.CrossMetric._download_and_prepare": [[126, 135], ["benepar.download", "spacy.prefer_gpu", "spacy.load", "spacy.__version__.startswith", "syntdiv_metric.CrossMetric.nlp.add_pipe", "syntdiv_metric.CrossMetric.nlp.add_pipe", "benepar.BeneparComponent"], "methods", ["None"], ["", "def", "_download_and_prepare", "(", "self", ",", "dl_manager", ")", ":", "\n", "        ", "\"\"\"Optional: download external resources useful to compute the scores\"\"\"", "\n", "benepar", ".", "download", "(", "'benepar_en3'", ")", "\n", "spacy", ".", "prefer_gpu", "(", ")", "\n", "self", ".", "nlp", "=", "spacy", ".", "load", "(", "'en_core_web_sm'", ")", "\n", "if", "spacy", ".", "__version__", ".", "startswith", "(", "'2'", ")", ":", "\n", "            ", "self", ".", "nlp", ".", "add_pipe", "(", "benepar", ".", "BeneparComponent", "(", "\"benepar_en3\"", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "nlp", ".", "add_pipe", "(", "\"benepar\"", ",", "config", "=", "{", "\"model\"", ":", "\"benepar_en3\"", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.syntdiv_metric.syntdiv_metric.CrossMetric._compute": [[140, 152], ["list", "syntdiv_metric.CrossMetric.nlp.select_pipes", "list", "list", "list", "list", "tqdm.auto.tqdm.auto.tqdm", "tqdm.auto.tqdm.auto.tqdm", "map", "tqdm.auto.tqdm.auto.tqdm", "map", "map", "syntdiv_metric.CrossMetric.nlp.pipe", "syntdiv_metric.CrossMetric.nlp.pipe", "zip", "len", "len", "len"], "methods", ["None"], ["", "", "def", "_compute", "(", "self", ",", "predictions", ",", "references", ",", "batch_size", "=", "64", ",", "workers", "=", "16", ")", ":", "\n", "        ", "\"\"\"Returns the scores\"\"\"", "\n", "with", "self", ".", "nlp", ".", "select_pipes", "(", "enable", "=", "[", "\"parser\"", ",", "\"benepar\"", "]", ")", ":", "\n", "            ", "preds", "=", "list", "(", "tqdm", "(", "self", ".", "nlp", ".", "pipe", "(", "predictions", ",", "batch_size", "=", "batch_size", ")", ",", "total", "=", "len", "(", "predictions", ")", ",", "desc", "=", "\"syntdiv:parse_preds\"", ",", "disable", "=", "True", ")", ")", "\n", "preds", "=", "list", "(", "map", "(", "get_tree_string", ",", "preds", ")", ")", "\n", "refs", "=", "list", "(", "tqdm", "(", "self", ".", "nlp", ".", "pipe", "(", "references", ",", "batch_size", "=", "batch_size", ")", ",", "total", "=", "len", "(", "references", ")", ",", "desc", "=", "\"syntdiv:parse_refs\"", ",", "disable", "=", "True", ")", ")", "\n", "refs", "=", "list", "(", "map", "(", "get_tree_string", ",", "refs", ")", ")", "\n", "\n", "", "scores", "=", "list", "(", "tqdm", "(", "map", "(", "dist", ",", "zip", "(", "preds", ",", "refs", ")", ")", ",", "total", "=", "len", "(", "preds", ")", ",", "desc", "=", "\"syntdiv:calc_dist\"", ")", ")", "\n", "\n", "return", "{", "\n", "\"scores\"", ":", "scores", ",", "\n", "}", ""]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.syntdiv_metric.syntdiv_metric.to_batches": [[9, 11], ["range", "len"], "function", ["None"], ["def", "to_batches", "(", "seq", ",", "size", ")", ":", "\n", "    ", "return", "(", "seq", "[", "pos", ":", "pos", "+", "size", "]", "for", "pos", "in", "range", "(", "0", ",", "len", "(", "seq", ")", ",", "size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.syntdiv_metric.syntdiv_metric.normalize_tree": [[13, 39], ["res.append", "res.append"], "function", ["None"], ["", "def", "normalize_tree", "(", "tree_string", ",", "max_depth", "=", "3", ")", ":", "\n", "    ", "res", "=", "[", "]", "\n", "depth", "=", "-", "1", "\n", "leaf", "=", "False", "\n", "for", "c", "in", "tree_string", ":", "\n", "        ", "if", "c", "in", "[", "'{'", ",", "'}'", "]", ":", "\n", "            ", "continue", "\n", "", "if", "c", "==", "'('", ":", "\n", "            ", "leaf", "=", "False", "\n", "depth", "+=", "1", "\n", "\n", "", "elif", "c", "==", "')'", ":", "\n", "            ", "leaf", "=", "False", "\n", "depth", "-=", "1", "\n", "if", "depth", "<", "max_depth", ":", "\n", "                ", "res", ".", "append", "(", "'}'", ")", "\n", "continue", "\n", "\n", "", "", "elif", "c", "==", "' '", ":", "\n", "            ", "leaf", "=", "True", "\n", "continue", "\n", "\n", "", "if", "depth", "<=", "max_depth", "and", "not", "leaf", "and", "c", "!=", "')'", ":", "\n", "            ", "res", ".", "append", "(", "c", "if", "c", "!=", "'('", "else", "'{'", ")", "\n", "\n", "", "", "return", "''", ".", "join", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.syntdiv_metric.syntdiv_metric.tree_edit_distance": [[40, 50], ["apted.helpers.Tree.from_text", "apted.helpers.Tree.from_text", "lintree1.count", "lintree2.count", "apted.APTED", "apted.APTED.compute_edit_distance"], "function", ["None"], ["", "def", "tree_edit_distance", "(", "lintree1", ",", "lintree2", ")", ":", "\n", "\n", "    ", "tree1", "=", "Tree", ".", "from_text", "(", "lintree1", ")", "\n", "tree2", "=", "Tree", ".", "from_text", "(", "lintree2", ")", "\n", "n_nodes_t1", "=", "lintree1", ".", "count", "(", "'{'", ")", "\n", "n_nodes_t2", "=", "lintree2", ".", "count", "(", "'{'", ")", "\n", "\n", "apted", "=", "APTED", "(", "tree1", ",", "tree2", ")", "\n", "ted", "=", "apted", ".", "compute_edit_distance", "(", ")", "\n", "return", "ted", "/", "(", "n_nodes_t1", "+", "n_nodes_t2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.syntdiv_metric.syntdiv_metric.get_tree_string": [[51, 53], ["next", "iter"], "function", ["None"], ["", "def", "get_tree_string", "(", "doc", ")", ":", "\n", "    ", "return", "next", "(", "iter", "(", "doc", ".", "sents", ")", ")", ".", "_", ".", "parse_string", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.syntdiv_metric.syntdiv_metric.dist": [[54, 62], ["syntdiv_metric.normalize_tree", "syntdiv_metric.normalize_tree", "syntdiv_metric.tree_edit_distance"], "function", ["home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.syntdiv_metric.syntdiv_metric.normalize_tree", "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.syntdiv_metric.syntdiv_metric.normalize_tree", "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.syntdiv_metric.syntdiv_metric.tree_edit_distance"], ["", "def", "dist", "(", "pair", ")", ":", "\n", "\n", "    ", "p_tree_n", "=", "normalize_tree", "(", "pair", "[", "0", "]", ",", "max_depth", "=", "3", ")", "\n", "r_tree_n", "=", "normalize_tree", "(", "pair", "[", "1", "]", ",", "max_depth", "=", "3", ")", "\n", "\n", "ted", "=", "tree_edit_distance", "(", "p_tree_n", ",", "r_tree_n", ")", "\n", "\n", "return", "ted", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.para_metric.para_metric.ModelBasedMetric._info": [[53, 70], ["datasets.MetricInfo", "datasets.Features", "datasets.Value", "datasets.Value"], "methods", ["None"], ["def", "_info", "(", "self", ")", ":", "\n", "# TODO: Specifies the datasets.MetricInfo object", "\n", "        ", "return", "datasets", ".", "MetricInfo", "(", "\n", "# This is the description that will appear on the metrics page.", "\n", "description", "=", "_DESCRIPTION", ",", "\n", "citation", "=", "_CITATION", ",", "\n", "inputs_description", "=", "_KWARGS_DESCRIPTION", ",", "\n", "# This defines the format of each prediction and reference", "\n", "features", "=", "datasets", ".", "Features", "(", "{", "\n", "'predictions'", ":", "datasets", ".", "Value", "(", "'string'", ")", ",", "\n", "'references'", ":", "datasets", ".", "Value", "(", "'string'", ")", ",", "\n", "}", ")", ",", "\n", "# Homepage of the metric for documentation", "\n", "homepage", "=", "\"http://metric.homepage\"", ",", "\n", "# Additional links to the codebase or references", "\n", "codebase_urls", "=", "[", "\"http://github.com/path/to/codebase/of/new_metric\"", "]", ",", "\n", "reference_urls", "=", "[", "\"http://path.to.reference.url/new_metric\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.para_metric.para_metric.ModelBasedMetric._download_and_prepare": [[72, 78], ["datasets.load_metric", "datasets.load_metric", "datasets.load_metric", "datasets.load_metric", "datasets.load_metric"], "methods", ["None"], ["", "def", "_download_and_prepare", "(", "self", ",", "dl_manager", ")", ":", "\n", "        ", "self", ".", "bertscore", "=", "load_metric", "(", "\"bertscore\"", ",", "experiment_id", "=", "self", ".", "experiment_id", ")", "\n", "self", ".", "bleu", "=", "load_metric", "(", "\"sacrebleu\"", ",", "experiment_id", "=", "self", ".", "experiment_id", ")", "\n", "self", ".", "sbert", "=", "load_metric", "(", "\"metrics/cross_metric\"", ",", "experiment_id", "=", "self", ".", "experiment_id", ")", "\n", "self", ".", "syntdiv", "=", "load_metric", "(", "\"metrics/syntdiv_metric\"", ",", "experiment_id", "=", "self", ".", "experiment_id", ")", "\n", "self", ".", "bleurt", "=", "load_metric", "(", "\"metrics/bleurt\"", ",", "experiment_id", "=", "self", ".", "experiment_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.para_metric.para_metric.ModelBasedMetric._compute": [[79, 108], ["len", "tqdm.auto.tqdm.auto.tqdm", "zip", "set_diversities.append", "seq_diversities.append", "diversity_scores.append", "para_metric.ModelBasedMetric.bleurt.compute", "para_metric.ModelBasedMetric.syntdiv.compute", "Levenshtein.setratio", "Levenshtein.seqratio", "para_metric.ModelBasedMetric.bleu.compute", "tqdm.auto.tqdm.auto.tqdm", "zip", "zip"], "methods", ["None"], ["", "def", "_compute", "(", "self", ",", "predictions", ",", "references", ",", "batch_size", "=", "100", ")", ":", "\n", "        ", "\"\"\"Returns the scores\"\"\"", "\n", "set_diversities", "=", "[", "]", "\n", "seq_diversities", "=", "[", "]", "\n", "diversity_scores", "=", "[", "]", "\n", "total", "=", "len", "(", "predictions", ")", "\n", "for", "pred", ",", "ref", "in", "tqdm", "(", "zip", "(", "predictions", ",", "references", ")", ",", "total", "=", "total", ",", "desc", "=", "\"edit_distance\"", ",", "disable", "=", "True", ")", ":", "\n", "            ", "set_diversity", "=", "1", "-", "setratio", "(", "pred", ",", "ref", ")", "\n", "seq_diversity", "=", "1", "-", "seqratio", "(", "pred", ",", "ref", ")", "\n", "diversity_score", "=", "(", "set_diversity", "+", "seq_diversity", ")", "/", "2", "\n", "set_diversities", ".", "append", "(", "set_diversity", ")", "\n", "seq_diversities", ".", "append", "(", "seq_diversity", ")", "\n", "diversity_scores", ".", "append", "(", "diversity_score", ")", "\n", "", "bleu_scores", "=", "[", "self", ".", "bleu", ".", "compute", "(", "predictions", "=", "[", "pred", "]", ",", "references", "=", "[", "[", "ref", "]", "]", ")", "[", "'score'", "]", "for", "pred", ",", "ref", "in", "tqdm", "(", "zip", "(", "predictions", ",", "references", ")", ",", "total", "=", "total", ",", "desc", "=", "\"bleu\"", ")", "]", "\n", "bleurt_score", "=", "self", ".", "bleurt", ".", "compute", "(", "predictions", "=", "predictions", ",", "references", "=", "references", ")", "[", "'scores'", "]", "\n", "# bertscore_score = self.bertscore.compute(predictions=predictions, references=references, lang='en')[\"f1\"]", "\n", "# semantic_scores = self.sbert.compute(predictions=predictions, references=references)[\"scores\"]", "\n", "syntactic_diversity", "=", "self", ".", "syntdiv", ".", "compute", "(", "predictions", "=", "predictions", ",", "references", "=", "references", ")", "[", "\"scores\"", "]", "\n", "\n", "\n", "diversity_scores", "=", "[", "(", "lex", "+", "syn", ")", "/", "2", "for", "lex", ",", "syn", "in", "zip", "(", "syntactic_diversity", ",", "set_diversities", ")", "]", "\n", "\n", "return", "{", "\n", "\"set_diversity\"", ":", "set_diversities", ",", "\n", "\"seq_diversity\"", ":", "seq_diversities", ",", "\n", "\"syn_diversity\"", ":", "syntactic_diversity", ",", "\n", "\"diversity_score\"", ":", "diversity_scores", ",", "\n", "\"bleu_score\"", ":", "bleu_scores", ",", "\n", "\"bleurt_score\"", ":", "bleurt_score", ",", "\n", "# \"bertscore_score\": bertscore_score,", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.para_metric.para_metric.to_batches": [[7, 9], ["range", "len"], "function", ["None"], ["def", "to_batches", "(", "seq", ",", "size", ")", ":", "\n", "    ", "return", "(", "seq", "[", "pos", ":", "pos", "+", "size", "]", "for", "pos", "in", "range", "(", "0", ",", "len", "(", "seq", ")", ",", "size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.bleurt.bleurt.BLEURT._info": [[53, 70], ["datasets.MetricInfo", "datasets.Features", "datasets.Value", "datasets.Value"], "methods", ["None"], ["def", "_info", "(", "self", ")", ":", "\n", "# TODO: Specifies the datasets.MetricInfo object", "\n", "        ", "return", "datasets", ".", "MetricInfo", "(", "\n", "# This is the description that will appear on the metrics page.", "\n", "description", "=", "_DESCRIPTION", ",", "\n", "citation", "=", "_CITATION", ",", "\n", "inputs_description", "=", "_KWARGS_DESCRIPTION", ",", "\n", "# This defines the format of each prediction and reference", "\n", "features", "=", "datasets", ".", "Features", "(", "{", "\n", "'predictions'", ":", "datasets", ".", "Value", "(", "'string'", ")", ",", "\n", "'references'", ":", "datasets", ".", "Value", "(", "'string'", ")", ",", "\n", "}", ")", ",", "\n", "# Homepage of the metric for documentation", "\n", "homepage", "=", "\"http://metric.homepage\"", ",", "\n", "# Additional links to the codebase or references", "\n", "codebase_urls", "=", "[", "\"http://github.com/path/to/codebase/of/new_metric\"", "]", ",", "\n", "reference_urls", "=", "[", "\"http://path.to.reference.url/new_metric\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.bleurt.bleurt.BLEURT._download_and_prepare": [[72, 82], ["transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSequenceClassification.from_pretrained", "bleurt.BLEURT.model.eval", "bleurt.BLEURT.set_device", "torch.cuda.is_available"], "methods", ["home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.bleurt.bleurt.BLEURT.set_device"], ["", "def", "_download_and_prepare", "(", "self", ",", "dl_manager", ")", ":", "\n", "        ", "\"\"\"Optional: download external resources useful to compute the scores\"\"\"", "\n", "if", "self", ".", "config_name", "==", "'default'", ":", "\n", "            ", "model_name", "=", "'Elron/bleurt-large-512'", "\n", "", "else", ":", "\n", "            ", "model_name", "=", "self", ".", "config_name", "\n", "", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "set_device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.bleurt.bleurt.BLEURT.set_device": [[83, 86], ["bleurt.BLEURT.model.to", "torch.device"], "methods", ["None"], ["", "def", "set_device", "(", "self", ",", "device", ")", ":", "\n", "        ", "self", ".", "model", ".", "to", "(", "torch", ".", "device", "(", "device", ")", ")", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.bleurt.bleurt.BLEURT._compute": [[88, 112], ["tqdm.auto.tqdm.auto.tqdm", "bleurt.BLEURT.set_device", "zip", "bleurt.BLEURT.tokenizer", "[].squeeze.tolist", "bleurt.to_batches", "bleurt.to_batches", "int", "torch.no_grad", "[].squeeze", "math.ceil", "isinstance", "tensor.to", "bleurt.BLEURT.items", "torch.device", "min", "bleurt.BLEURT.model", "len", "len"], "methods", ["home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.bleurt.bleurt.BLEURT.set_device", "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.bleurt.bleurt.to_batches", "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.bleurt.bleurt.to_batches"], ["def", "_compute", "(", "self", ",", "predictions", ",", "references", ",", "batch_size", "=", "64", ",", "device", "=", "None", ",", "adjusted", "=", "True", ")", ":", "\n", "        ", "\"\"\"Returns the scores\"\"\"", "\n", "if", "device", "!=", "self", ".", "device", "and", "device", "is", "not", "None", ":", "\n", "            ", "self", ".", "set_device", "(", "device", ")", "\n", "\n", "", "scores", "=", "[", "]", "\n", "for", "preds", ",", "refs", "in", "tqdm", "(", "zip", "(", "to_batches", "(", "predictions", ",", "batch_size", ")", ",", "to_batches", "(", "references", ",", "batch_size", ")", ")", ",", "total", "=", "int", "(", "ceil", "(", "min", "(", "len", "(", "predictions", ")", ",", "len", "(", "references", ")", ")", "/", "batch_size", ")", ")", ",", "desc", "=", "\"bleurt\"", ",", "disable", "=", "True", ")", ":", "\n", "\n", "            ", "inputs", "=", "self", ".", "tokenizer", "(", "preds", ",", "refs", ",", "return_tensors", "=", "'pt'", ",", "padding", "=", "'longest'", ")", "\n", "inputs", "=", "{", "\n", "name", ":", "tensor", ".", "to", "(", "torch", ".", "device", "(", "self", ".", "device", ")", ")", "if", "isinstance", "(", "tensor", ",", "torch", ".", "Tensor", ")", "else", "tensor", "\n", "for", "name", ",", "tensor", "in", "inputs", ".", "items", "(", ")", "\n", "}", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "outputs", "=", "self", ".", "model", "(", "**", "inputs", ")", "[", "'logits'", "]", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "", "if", "adjusted", ":", "\n", "                ", "outputs", "=", "1", "/", "(", "1", "+", "2", "**", "(", "-", "4", "*", "outputs", ")", ")", "# scaled sigmoid", "\n", "\n", "", "scores", "+=", "outputs", ".", "tolist", "(", ")", "\n", "\n", "", "return", "{", "\n", "\"scores\"", ":", "scores", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.ibm_quality-controlled-paraphrase-generation.bleurt.bleurt.to_batches": [[7, 9], ["range", "len"], "function", ["None"], ["def", "to_batches", "(", "seq", ",", "size", ")", ":", "\n", "    ", "return", "(", "seq", "[", "pos", ":", "pos", "+", "size", "]", "for", "pos", "in", "range", "(", "0", ",", "len", "(", "seq", ")", ",", "size", ")", ")", "\n", "\n"]]}