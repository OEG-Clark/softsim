{"home.repos.pwc.inspect_result.eladsar_rbi.None.ape_agent.ApeAgent.__init__": [[28, 76], ["print", "agent.Agent.__init__", "model.DuelNet", "model.DuelNet", "ape_agent.ApeAgent.value_net.to", "ape_agent.ApeAgent.target_net.to", "ape_agent.ApeAgent.target_net.load_state_dict", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.SmoothL1Loss", "torch.SmoothL1Loss", "torch.SmoothL1Loss", "torch.SmoothL1Loss", "torch.SmoothL1Loss", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "ape_agent.ApeAgent.value_net.state_dict", "numpy.ones", "environment.Env", "numpy.arange", "memory.Memory", "memory.ReplayBatchSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "ape_agent.ApeAgent.value_net.parameters", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.memory.ReplayBatchSampler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "root_dir", ",", "player", "=", "False", ",", "choose", "=", "False", ",", "checkpoint", "=", "None", ")", ":", "\n", "\n", "        ", "print", "(", "\"Learning with Ape Agent\"", ")", "\n", "super", "(", "ApeAgent", ",", "self", ")", ".", "__init__", "(", "root_dir", ",", "checkpoint", ",", "player", ")", "\n", "\n", "self", ".", "value_net", "=", "DuelNet", "(", ")", "\n", "self", ".", "target_net", "=", "DuelNet", "(", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", ":", "\n", "            ", "self", ".", "value_net", "=", "nn", ".", "DataParallel", "(", "self", ".", "value_net", ")", "\n", "self", ".", "target_net", "=", "nn", ".", "DataParallel", "(", "self", ".", "target_net", ")", "\n", "\n", "", "self", ".", "value_net", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "target_net", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "target_net", ".", "load_state_dict", "(", "self", ".", "value_net", ".", "state_dict", "(", ")", ")", "\n", "\n", "self", ".", "a_zeros", "=", "torch", ".", "zeros", "(", "1", ",", "1", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "pi_rand", "=", "np", ".", "ones", "(", "self", ".", "action_space", ")", "/", "self", ".", "action_space", "\n", "self", ".", "pi_rand_batch", "=", "torch", ".", "FloatTensor", "(", "self", ".", "pi_rand", ")", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "self", ".", "batch", ",", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "q_loss", "=", "nn", ".", "SmoothL1Loss", "(", "reduction", "=", "'none'", ")", "\n", "\n", "if", "player", ":", "\n", "\n", "# play variables", "\n", "            ", "self", ".", "env", "=", "Env", "(", ")", "\n", "self", ".", "trajectory", "=", "[", "]", "\n", "self", ".", "images", "=", "[", "]", "\n", "self", ".", "choices", "=", "np", ".", "arange", "(", "self", ".", "action_space", ",", "dtype", "=", "np", ".", "int", ")", "\n", "self", ".", "n_replay_saved", "=", "1", "\n", "self", ".", "frame", "=", "0", "\n", "self", ".", "states", "=", "0", "\n", "\n", "", "else", ":", "\n", "\n", "# datasets", "\n", "            ", "self", ".", "train_dataset", "=", "Memory", "(", "root_dir", ")", "\n", "self", ".", "train_sampler", "=", "ReplayBatchSampler", "(", "root_dir", ")", "\n", "self", ".", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "self", ".", "train_dataset", ",", "batch_sampler", "=", "self", ".", "train_sampler", ",", "\n", "collate_fn", "=", "collate", ",", "num_workers", "=", "args", ".", "cpu_workers", ",", "\n", "pin_memory", "=", "True", ",", "drop_last", "=", "False", ")", "\n", "\n", "# configure learning", "\n", "\n", "# IT IS IMPORTANT TO ASSIGN MODEL TO CUDA/PARALLEL BEFORE DEFINING OPTIMIZER", "\n", "", "self", ".", "optimizer_value", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "value_net", ".", "parameters", "(", ")", ",", "lr", "=", "0.00025", "/", "4", ",", "eps", "=", "1.5e-4", ",", "weight_decay", "=", "0", ")", "\n", "self", ".", "n_offset", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.ape_agent.ApeAgent.save_checkpoint": [[77, 91], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "ape_agent.ApeAgent.value_net.module.state_dict", "ape_agent.ApeAgent.target_net.module.state_dict", "ape_agent.ApeAgent.optimizer_value.state_dict", "ape_agent.ApeAgent.value_net.state_dict", "ape_agent.ApeAgent.target_net.state_dict", "ape_agent.ApeAgent.optimizer_value.state_dict"], "methods", ["None"], ["", "def", "save_checkpoint", "(", "self", ",", "path", ",", "aux", "=", "None", ")", ":", "\n", "\n", "        ", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", ":", "\n", "            ", "state", "=", "{", "'value_net'", ":", "self", ".", "value_net", ".", "module", ".", "state_dict", "(", ")", ",", "\n", "'target_net'", ":", "self", ".", "target_net", ".", "module", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_value'", ":", "self", ".", "optimizer_value", ".", "state_dict", "(", ")", ",", "\n", "'aux'", ":", "aux", "}", "\n", "", "else", ":", "\n", "            ", "state", "=", "{", "'value_net'", ":", "self", ".", "value_net", ".", "state_dict", "(", ")", ",", "\n", "'target_net'", ":", "self", ".", "target_net", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_value'", ":", "self", ".", "optimizer_value", ".", "state_dict", "(", ")", ",", "\n", "'aux'", ":", "aux", "}", "\n", "\n", "", "torch", ".", "save", "(", "state", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.ape_agent.ApeAgent.load_checkpoint": [[92, 107], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "ape_agent.ApeAgent.optimizer_value.load_state_dict", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "ape_agent.ApeAgent.value_net.module.load_state_dict", "ape_agent.ApeAgent.target_net.module.load_state_dict", "ape_agent.ApeAgent.value_net.load_state_dict", "ape_agent.ApeAgent.target_net.load_state_dict"], "methods", ["None"], ["", "def", "load_checkpoint", "(", "self", ",", "path", ")", ":", "\n", "\n", "        ", "state", "=", "torch", ".", "load", "(", "path", ",", "map_location", "=", "\"cuda:%d\"", "%", "self", ".", "cuda_id", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", ":", "\n", "            ", "self", ".", "value_net", ".", "module", ".", "load_state_dict", "(", "state", "[", "'value_net'", "]", ")", "\n", "self", ".", "target_net", ".", "module", ".", "load_state_dict", "(", "state", "[", "'target_net'", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "value_net", ".", "load_state_dict", "(", "state", "[", "'value_net'", "]", ")", "\n", "self", ".", "target_net", ".", "load_state_dict", "(", "state", "[", "'target_net'", "]", ")", "\n", "\n", "", "self", ".", "optimizer_value", ".", "load_state_dict", "(", "state", "[", "'optimizer_value'", "]", ")", "\n", "self", ".", "n_offset", "=", "state", "[", "'aux'", "]", "[", "'n'", "]", "\n", "\n", "return", "state", "[", "'aux'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.ape_agent.ApeAgent.learn": [[108, 202], ["ape_agent.ApeAgent.value_net.train", "ape_agent.ApeAgent.target_net.eval", "tqdm.tqdm.tqdm", "enumerate", "sample[].to", "sample[].to().unsqueeze_", "sample[].to", "sample[].to", "sample[].to", "sample[].to", "ape_agent.ApeAgent.value_net", "q_tag_eval.detach.detach.detach", "ape_agent.ApeAgent.target_net", "q_tag_target.detach.detach.detach", "ape_agent.ApeAgent.value_net", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "torch.argmax().unsqueeze", "preprocess.h_torch", "ape_agent.ApeAgent.optimizer_value.zero_grad", "loss_value.backward", "ape_agent.ApeAgent.optimizer_value.step", "is_value.max", "sample[].to().unsqueeze_.squeeze().data.cpu().numpy", "q_a.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "r.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "q.data.cpu().max", "beta_index.numpy.numpy.numpy", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "sample[].to", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "loss_value.data.cpu().numpy", "ape_agent.ApeAgent.save_checkpoint", "ape_agent.ApeAgent.target_net.load_state_dict", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "s[].data.cpu", "ape_agent.ApeAgent.value_net.train", "preprocess.hinv_torch", "ape_agent.ApeAgent.q_loss", "sample[].to().unsqueeze_.squeeze().data.cpu", "q_a.data.cpu().numpy.data.cpu().numpy.data.cpu", "r.data.cpu().numpy.data.cpu().numpy.data.cpu", "q.data.cpu", "ape_agent.ApeAgent.value_net.state_dict", "q_tag_target.detach.detach.gather().squeeze", "loss_value.data.cpu", "q_tag_target.detach.detach.gather", "sample[].to().unsqueeze_.squeeze"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.train", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.save_checkpoint", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.train"], ["", "def", "learn", "(", "self", ",", "n_interval", ",", "n_tot", ")", ":", "\n", "\n", "        ", "self", ".", "value_net", ".", "train", "(", ")", "\n", "self", ".", "target_net", ".", "eval", "(", ")", "\n", "\n", "results", "=", "{", "'n'", ":", "[", "]", ",", "'loss_value'", ":", "[", "]", ",", "'loss_beta'", ":", "[", "]", ",", "'act_diff'", ":", "[", "]", ",", "'a_agent'", ":", "[", "]", ",", "\n", "'a_player'", ":", "[", "]", ",", "'loss_std'", ":", "[", "]", ",", "'mc_val'", ":", "[", "]", ",", "\"Hbeta\"", ":", "[", "]", ",", "\"Hpi\"", ":", "[", "]", ",", "\n", "\"adv_a\"", ":", "[", "]", ",", "\"q_a\"", ":", "[", "]", ",", "'image'", ":", "[", "]", "}", "\n", "\n", "for", "n", ",", "sample", "in", "tqdm", "(", "enumerate", "(", "self", ".", "train_loader", ")", ")", ":", "\n", "\n", "            ", "n", "=", "self", ".", "n_offset", "+", "n", "+", "1", "\n", "\n", "s", "=", "sample", "[", "'s'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "a", "=", "sample", "[", "'a'", "]", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze_", "(", "1", ")", "\n", "r", "=", "sample", "[", "'r'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "t", "=", "sample", "[", "'t'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "s_tag", "=", "sample", "[", "'s_tag'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "tde", "=", "sample", "[", "'tde'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "_", ",", "_", ",", "_", ",", "q_tag_eval", ",", "_", "=", "self", ".", "value_net", "(", "s_tag", ",", "a", ",", "self", ".", "pi_rand_batch", ")", "\n", "q_tag_eval", "=", "q_tag_eval", ".", "detach", "(", ")", "\n", "\n", "_", ",", "_", ",", "_", ",", "q_tag_target", ",", "_", "=", "self", ".", "target_net", "(", "s_tag", ",", "a", ",", "self", ".", "pi_rand_batch", ")", "\n", "q_tag_target", "=", "q_tag_target", ".", "detach", "(", ")", "\n", "\n", "_", ",", "_", ",", "_", ",", "q", ",", "q_a", "=", "self", ".", "value_net", "(", "s", ",", "a", ",", "self", ".", "pi_rand_batch", ")", "\n", "\n", "a_tag", "=", "torch", ".", "argmax", "(", "q_tag_eval", ",", "dim", "=", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "r", "=", "h_torch", "(", "r", "+", "self", ".", "discount", "**", "self", ".", "n_steps", "*", "(", "1", "-", "t", ")", "*", "hinv_torch", "(", "q_tag_target", ".", "gather", "(", "1", ",", "a_tag", ")", ".", "squeeze", "(", "1", ")", ")", ")", "\n", "\n", "is_value", "=", "tde", "**", "(", "-", "self", ".", "priority_beta", ")", "\n", "is_value", "=", "is_value", "/", "is_value", ".", "max", "(", ")", "\n", "loss_value", "=", "(", "self", ".", "q_loss", "(", "q_a", ",", "r", ")", "*", "is_value", ")", ".", "mean", "(", ")", "\n", "\n", "# Learning part", "\n", "\n", "self", ".", "optimizer_value", ".", "zero_grad", "(", ")", "\n", "loss_value", ".", "backward", "(", ")", "\n", "self", ".", "optimizer_value", ".", "step", "(", ")", "\n", "\n", "# collect actions statistics", "\n", "\n", "if", "not", "n", "%", "50", ":", "\n", "\n", "                ", "a_index_np", "=", "a", ".", "squeeze", "(", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "q_a", "=", "q_a", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "r", "=", "r", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "_", ",", "beta_index", "=", "q", ".", "data", ".", "cpu", "(", ")", ".", "max", "(", "1", ")", "\n", "beta_index", "=", "beta_index", ".", "numpy", "(", ")", "\n", "act_diff", "=", "(", "a_index_np", "!=", "beta_index", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "# add results", "\n", "\n", "results", "[", "'act_diff'", "]", ".", "append", "(", "act_diff", ")", "\n", "results", "[", "'a_agent'", "]", ".", "append", "(", "beta_index", ")", "\n", "results", "[", "'adv_a'", "]", ".", "append", "(", "q_a", ")", "\n", "results", "[", "'q_a'", "]", ".", "append", "(", "q_a", ")", "\n", "results", "[", "'a_player'", "]", ".", "append", "(", "a_index_np", ")", "\n", "results", "[", "'Hbeta'", "]", ".", "append", "(", "0", ")", "\n", "results", "[", "'Hpi'", "]", ".", "append", "(", "0", ")", "\n", "results", "[", "'mc_val'", "]", ".", "append", "(", "r", ")", "\n", "\n", "# add results", "\n", "results", "[", "'loss_beta'", "]", ".", "append", "(", "0", ")", "\n", "results", "[", "'loss_value'", "]", ".", "append", "(", "loss_value", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "results", "[", "'loss_std'", "]", ".", "append", "(", "0", ")", "\n", "results", "[", "'n'", "]", ".", "append", "(", "n", ")", "\n", "\n", "if", "not", "n", "%", "self", ".", "update_memory_interval", ":", "\n", "# save agent state", "\n", "                    ", "self", ".", "save_checkpoint", "(", "self", ".", "snapshot_path", ",", "{", "'n'", ":", "self", ".", "n_offset", "+", "n", "+", "1", "}", ")", "\n", "\n", "", "if", "not", "n", "%", "self", ".", "update_target_interval", ":", "\n", "# save agent state", "\n", "                    ", "self", ".", "target_net", ".", "load_state_dict", "(", "self", ".", "value_net", ".", "state_dict", "(", ")", ")", "\n", "\n", "", "if", "not", "n", "%", "n_interval", ":", "\n", "                    ", "results", "[", "'act_diff'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'act_diff'", "]", ")", "\n", "results", "[", "'a_agent'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'a_agent'", "]", ")", "\n", "results", "[", "'adv_a'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'adv_a'", "]", ")", "\n", "results", "[", "'q_a'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'q_a'", "]", ")", "\n", "results", "[", "'a_player'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'a_player'", "]", ")", "\n", "results", "[", "'mc_val'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'mc_val'", "]", ")", "\n", "results", "[", "'image'", "]", "=", "s", "[", "0", ",", ":", "-", "1", ",", ":", ",", ":", "]", ".", "data", ".", "cpu", "(", ")", "\n", "\n", "yield", "results", "\n", "self", ".", "value_net", ".", "train", "(", ")", "\n", "results", "=", "{", "key", ":", "[", "]", "for", "key", "in", "results", "}", "\n", "\n", "if", "n", ">=", "n_tot", ":", "\n", "                        ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.ape_agent.ApeAgent.play": [[203, 278], ["torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "range", "numpy.ones", "ape_agent.ApeAgent.env.reset", "ape_agent.ApeAgent.value_net.eval", "preprocess.get_mc_value", "numpy.array", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "ape_agent.ApeAgent.env.s.to", "ape_agent.ApeAgent.value_net", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy", "pi_mix.clip.clip.clip", "numpy.random.choice", "ape_agent.ApeAgent.env.step", "ape_agent.ApeAgent.load_checkpoint", "ape_agent.ApeAgent.value_net.eval", "numpy.zeros", "pi_mix.clip.clip.sum", "rewards[].append", "numpy.array.append", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "time.sleep", "ape_agent.ApeAgent.load_checkpoint", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu", "rewards.append", "numpy.argmax", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_mc_value", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.load_checkpoint", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.load_checkpoint"], ["", "", "", "", "", "def", "play", "(", "self", ",", "n_tot", ",", "save", "=", "True", ",", "load", "=", "True", ",", "fix", "=", "False", ")", ":", "\n", "\n", "        ", "pi_rand", "=", "np", ".", "ones", "(", "self", ".", "action_space", ")", "/", "self", ".", "action_space", "\n", "pi_rand", "=", "torch", ".", "FloatTensor", "(", "pi_rand", ")", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_tot", ")", ":", "\n", "\n", "            ", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n", "rewards", "=", "[", "[", "]", "]", "\n", "q_val", "=", "[", "]", "\n", "lives", "=", "self", ".", "env", ".", "lives", "\n", "\n", "while", "not", "fix", ":", "\n", "                ", "try", ":", "\n", "                    ", "self", ".", "load_checkpoint", "(", "self", ".", "snapshot_path", ")", "\n", "break", "\n", "", "except", ":", "\n", "                    ", "time", ".", "sleep", "(", "0.5", ")", "\n", "\n", "", "", "self", ".", "value_net", ".", "eval", "(", ")", "\n", "\n", "while", "not", "self", ".", "env", ".", "t", ":", "\n", "\n", "                ", "if", "load", "and", "not", "(", "self", ".", "states", "%", "self", ".", "load_memory_interval", ")", ":", "\n", "                    ", "try", ":", "\n", "                        ", "self", ".", "load_checkpoint", "(", "self", ".", "snapshot_path", ")", "\n", "", "except", ":", "\n", "                        ", "pass", "\n", "\n", "", "self", ".", "value_net", ".", "eval", "(", ")", "\n", "\n", "", "s", "=", "self", ".", "env", ".", "s", ".", "to", "(", "self", ".", "device", ")", "\n", "# get aux data", "\n", "_", ",", "_", ",", "_", ",", "q", ",", "_", "=", "self", ".", "value_net", "(", "s", ",", "self", ".", "a_zeros", ",", "pi_rand", ")", "\n", "\n", "q", "=", "q", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "self", ".", "n_offset", ">=", "self", ".", "random_initialization", ":", "\n", "\n", "                    ", "pi", "=", "np", ".", "zeros", "(", "self", ".", "action_space", ")", "\n", "pi", "[", "np", ".", "argmax", "(", "q", ")", "]", "=", "1", "\n", "\n", "", "else", ":", "\n", "\n", "                    ", "pi", "=", "self", ".", "pi_rand", "\n", "\n", "", "pi_mix", "=", "self", ".", "epsilon", "*", "self", ".", "pi_rand", "+", "(", "1", "-", "self", ".", "epsilon", ")", "*", "pi", "\n", "\n", "pi_mix", "=", "pi_mix", ".", "clip", "(", "0", ",", "1", ")", "\n", "pi_mix", "=", "pi_mix", "/", "pi_mix", ".", "sum", "(", ")", "\n", "a", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "choices", ",", "p", "=", "pi_mix", ")", "\n", "self", ".", "env", ".", "step", "(", "a", ")", "\n", "\n", "if", "self", ".", "env", ".", "k", ">=", "self", ".", "history_length", ":", "\n", "\n", "                    ", "if", "lives", ">", "self", ".", "env", ".", "lives", ":", "\n", "                        ", "rewards", ".", "append", "(", "[", "]", ")", "\n", "", "lives", "=", "self", ".", "env", ".", "lives", "\n", "\n", "rewards", "[", "-", "1", "]", ".", "append", "(", "self", ".", "env", ".", "r", ")", "\n", "q_val", ".", "append", "(", "q", "[", "a", "]", ")", "\n", "\n", "", "self", ".", "frame", "+=", "1", "\n", "\n", "", "mc_val", "=", "get_mc_value", "(", "rewards", ",", "None", ",", "self", ".", "discount", ",", "None", ")", "\n", "q_val", "=", "np", ".", "array", "(", "q_val", ")", "\n", "\n", "yield", "{", "'score'", ":", "self", ".", "env", ".", "score", ",", "\n", "'frames'", ":", "self", ".", "env", ".", "k", ",", "\"n\"", ":", "self", ".", "n_offset", ",", "\"mc\"", ":", "mc_val", ",", "\"q\"", ":", "q_val", "}", "\n", "\n", "if", "self", ".", "n_offset", ">=", "self", ".", "n_tot", "and", "not", "fix", ":", "\n", "                ", "break", "\n", "\n", "", "", "raise", "StopIteration", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.ape_agent.ApeAgent.multiplay": [[279, 454], ["numpy.zeros", "ape_agent.ApeAgent.a_zeros.repeat", "numpy.repeat", "numpy.arange", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "range", "numpy.arange", "environment.Env", "numpy.expand_dims", "mp_env[].reset", "preprocess.lock_file", "numpy.load().item", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "os.path.join", "os.mkdir", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "ape_agent.ApeAgent.value_net", "q.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "numpy.logical_and", "numpy.repeat", "pi_mix.clip.clip.clip", "range", "range", "range", "range", "range", "range", "range", "range", "os.path.join", "os.path.join", "os.path.join", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "str", "range", "ape_agent.ApeAgent.value_net.eval", "numpy.expand_dims", "numpy.zeros", "numpy.repeat", "numpy.random.choice", "cv2.imwrite", "episode[].append", "env.step", "[].append", "[].append", "q_a[].append", "numpy.load", "ape_agent.ApeAgent.load_checkpoint", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "q.data.cpu().numpy.data.cpu().numpy.data.cpu", "numpy.array", "numpy.expand_dims", "os.path.join", "numpy.array", "rewards[].append", "v_target[].append", "preprocess.get_tde_value", "numpy.abs", "numpy.concatenate", "numpy.stack", "trajectory[].append", "print", "env.reset", "preprocess.lock_file", "numpy.load().item", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "os.path.join", "os.mkdir", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "pi_mix.clip.clip.sum", "str", "sum", "numpy.argmax", "str", "numpy.array", "preprocess.get_td_value", "numpy.load", "preprocess.lock_file", "numpy.load().item", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "numpy.concatenate", "os.path.join", "numpy.save", "preprocess.lock_file", "numpy.load", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "numpy.abs", "numpy.sign", "len", "psutil.virtual_memory", "numpy.append", "time.time", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.load_checkpoint", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_tde_value", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_td_value", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file"], ["", "def", "multiplay", "(", "self", ")", ":", "\n", "\n", "        ", "n_players", "=", "self", ".", "n_players", "\n", "\n", "player_i", "=", "np", ".", "arange", "(", "self", ".", "actor_index", ",", "self", ".", "actor_index", "+", "self", ".", "n_actors", "*", "n_players", ",", "self", ".", "n_actors", ")", "/", "(", "self", ".", "n_actors", "*", "n_players", "-", "1", ")", "\n", "mp_explore", "=", "0.4", "**", "(", "1", "+", "7", "*", "player_i", ")", "\n", "explore_threshold", "=", "player_i", "\n", "\n", "mp_env", "=", "[", "Env", "(", ")", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "self", ".", "frame", "=", "0", "\n", "episode_num", "=", "np", ".", "zeros", "(", "n_players", ",", "dtype", "=", "np", ".", "int", ")", "\n", "a_zeros_mp", "=", "self", ".", "a_zeros", ".", "repeat", "(", "n_players", ",", "1", ")", "\n", "mp_pi_rand", "=", "np", ".", "repeat", "(", "np", ".", "expand_dims", "(", "self", ".", "pi_rand", ",", "axis", "=", "0", ")", ",", "n_players", ",", "axis", "=", "0", ")", "\n", "range_players", "=", "np", ".", "arange", "(", "n_players", ")", "\n", "rewards", "=", "[", "[", "[", "]", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "v_target", "=", "[", "[", "[", "]", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "episode", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "q_a", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "image_dir", "=", "[", "''", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "trajectory", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "\n", "screen_dir", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"screen\"", ")", "]", "*", "n_players", "\n", "trajectory_dir", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"trajectory\"", ")", "]", "*", "n_players", "\n", "readlock", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "list_dir", ",", "\"readlock_explore.npy\"", ")", "]", "*", "n_players", "\n", "\n", "pi_rand_batch", "=", "torch", ".", "FloatTensor", "(", "self", ".", "pi_rand", ")", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "n_players", ",", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_players", ")", ":", "\n", "            ", "mp_env", "[", "i", "]", ".", "reset", "(", ")", "\n", "\n", "# set initial episodes number", "\n", "# lock read", "\n", "fwrite", "=", "lock_file", "(", "self", ".", "episodelock", ")", "\n", "episode_num", "[", "i", "]", "=", "np", ".", "load", "(", "fwrite", ")", ".", "item", "(", ")", "\n", "fwrite", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fwrite", ",", "episode_num", "[", "i", "]", "+", "1", ")", "\n", "# unlock file", "\n", "release_file", "(", "fwrite", ")", "\n", "\n", "image_dir", "[", "i", "]", "=", "os", ".", "path", ".", "join", "(", "screen_dir", "[", "i", "]", ",", "str", "(", "episode_num", "[", "i", "]", ")", ")", "\n", "os", ".", "mkdir", "(", "image_dir", "[", "i", "]", ")", "\n", "\n", "", "lives", "=", "[", "mp_env", "[", "i", "]", ".", "lives", "for", "i", "in", "range", "(", "n_players", ")", "]", "\n", "\n", "while", "True", ":", "\n", "\n", "            ", "if", "not", "(", "self", ".", "frame", "%", "self", ".", "load_memory_interval", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "self", ".", "load_checkpoint", "(", "self", ".", "snapshot_path", ")", "\n", "", "except", ":", "\n", "                    ", "pass", "\n", "\n", "", "self", ".", "value_net", ".", "eval", "(", ")", "\n", "\n", "", "s", "=", "torch", ".", "cat", "(", "[", "env", ".", "s", "for", "env", "in", "mp_env", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "_", ",", "_", ",", "_", ",", "q", ",", "_", "=", "self", ".", "value_net", "(", "s", ",", "a_zeros_mp", ",", "pi_rand_batch", ")", "\n", "\n", "q", "=", "q", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "mp_trigger", "=", "np", ".", "logical_and", "(", "\n", "np", ".", "array", "(", "[", "env", ".", "score", "for", "env", "in", "mp_env", "]", ")", ">=", "self", ".", "behavioral_avg_score", "*", "explore_threshold", ",", "\n", "explore_threshold", ">=", "0", ")", "\n", "exploration", "=", "np", ".", "repeat", "(", "np", ".", "expand_dims", "(", "mp_explore", "*", "mp_trigger", ",", "axis", "=", "1", ")", ",", "self", ".", "action_space", ",", "axis", "=", "1", ")", "\n", "\n", "if", "self", ".", "n_offset", ">=", "self", ".", "random_initialization", ":", "\n", "\n", "                ", "pi", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_players", ",", "self", ".", "action_space", ")", ")", "\n", "pi", "[", "range_players", ",", "np", ".", "argmax", "(", "q", ",", "axis", "=", "1", ")", "]", "=", "1", "\n", "\n", "", "else", ":", "\n", "                ", "pi", "=", "mp_pi_rand", "\n", "\n", "", "pi_mix", "=", "pi", "*", "(", "1", "-", "exploration", ")", "+", "exploration", "*", "mp_pi_rand", "\n", "pi_mix", "=", "pi_mix", ".", "clip", "(", "0", ",", "1", ")", "\n", "pi_mix", "=", "pi_mix", "/", "np", ".", "repeat", "(", "np", ".", "expand_dims", "(", "pi_mix", ".", "sum", "(", "axis", "=", "1", ")", ",", "axis", "=", "1", ")", ",", "self", ".", "action_space", ",", "axis", "=", "1", ")", "\n", "\n", "v_expected", "=", "(", "q", "*", "pi", ")", ".", "sum", "(", "axis", "=", "1", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_players", ")", ":", "\n", "\n", "                ", "a", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "choices", ",", "p", "=", "pi_mix", "[", "i", "]", ")", "\n", "\n", "env", "=", "mp_env", "[", "i", "]", "\n", "cv2", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "image_dir", "[", "i", "]", ",", "\"%s.png\"", "%", "str", "(", "self", ".", "frame", ")", ")", ",", "mp_env", "[", "i", "]", ".", "image", ",", "[", "imcompress", ",", "compress_level", "]", ")", "\n", "\n", "episode", "[", "i", "]", ".", "append", "(", "np", ".", "array", "(", "(", "self", ".", "frame", ",", "a", ",", "pi", "[", "i", "]", ",", "\n", "None", ",", "None", ",", "\n", "episode_num", "[", "i", "]", ",", "0.", ",", "0", ",", "0", ",", "\n", "0.", ",", "1.", ",", "1.", ",", "0", ",", "1.", ",", "0", ")", ",", "dtype", "=", "self", ".", "rec_type", ")", ")", "\n", "\n", "env", ".", "step", "(", "a", ")", "\n", "\n", "if", "lives", "[", "i", "]", ">", "env", ".", "lives", ":", "\n", "                    ", "rewards", "[", "i", "]", ".", "append", "(", "[", "]", ")", "\n", "v_target", "[", "i", "]", ".", "append", "(", "[", "]", ")", "\n", "", "lives", "[", "i", "]", "=", "env", ".", "lives", "\n", "\n", "rewards", "[", "i", "]", "[", "-", "1", "]", ".", "append", "(", "env", ".", "r", ")", "\n", "v_target", "[", "i", "]", "[", "-", "1", "]", ".", "append", "(", "v_expected", "[", "i", "]", ")", "\n", "q_a", "[", "i", "]", ".", "append", "(", "q", "[", "i", "]", "[", "a", "]", ")", "\n", "\n", "if", "env", ".", "t", ":", "\n", "\n", "                    ", "td_val", ",", "t_val", "=", "get_tde_value", "(", "rewards", "[", "i", "]", ",", "self", ".", "discount", ",", "self", ".", "n_steps", ")", "\n", "tde", "=", "np", ".", "abs", "(", "np", ".", "array", "(", "q_a", "[", "i", "]", ")", "-", "get_td_value", "(", "rewards", "[", "i", "]", ",", "v_target", "[", "i", "]", ",", "self", ".", "discount", ",", "self", ".", "n_steps", ")", ")", "\n", "v_scale", "=", "np", ".", "concatenate", "(", "v_target", "[", "i", "]", ")", "\n", "\n", "tde", "=", "(", "(", "tde", "+", "0.01", ")", "/", "(", "np", ".", "abs", "(", "v_scale", ")", "+", "0.01", ")", ")", "**", "self", ".", "priority_alpha", "\n", "\n", "episode_df", "=", "np", ".", "stack", "(", "episode", "[", "i", "]", "[", "self", ".", "history_length", "-", "1", ":", "self", ".", "max_length", "]", ")", "\n", "episode_df", "[", "'r'", "]", "=", "td_val", "[", "self", ".", "history_length", "-", "1", ":", "self", ".", "max_length", "]", "\n", "episode_df", "[", "'t'", "]", "=", "t_val", "[", "self", ".", "history_length", "-", "1", ":", "self", ".", "max_length", "]", "\n", "episode_df", "[", "'tde'", "]", "=", "tde", "[", "self", ".", "history_length", "-", "1", ":", "self", ".", "max_length", "]", "\n", "\n", "trajectory", "[", "i", "]", ".", "append", "(", "episode_df", ")", "\n", "\n", "print", "(", "\"ape | st: %d\\t| sc: %d\\t| f: %d\\t| e: %7g\\t| typ: %2d | trg: %d | t: %d\\t| n %d\\t| avg_r: %g\\t| avg_f: %g\"", "%", "\n", "(", "self", ".", "frame", ",", "env", ".", "score", ",", "env", ".", "k", ",", "mp_explore", "[", "i", "]", ",", "np", ".", "sign", "(", "explore_threshold", "[", "i", "]", ")", ",", "mp_trigger", "[", "i", "]", ",", "\n", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", ",", "self", ".", "n_offset", ",", "self", ".", "behavioral_avg_score", ",", "\n", "self", ".", "behavioral_avg_frame", ")", ")", "\n", "\n", "env", ".", "reset", "(", ")", "\n", "episode", "[", "i", "]", "=", "[", "]", "\n", "q_a", "[", "i", "]", "=", "[", "]", "\n", "rewards", "[", "i", "]", "=", "[", "[", "]", "]", "\n", "v_target", "[", "i", "]", "=", "[", "[", "]", "]", "\n", "lives", "[", "i", "]", "=", "env", ".", "lives", "\n", "\n", "# get new episode number", "\n", "\n", "# lock read", "\n", "fwrite", "=", "lock_file", "(", "self", ".", "episodelock", ")", "\n", "episode_num", "[", "i", "]", "=", "np", ".", "load", "(", "fwrite", ")", ".", "item", "(", ")", "\n", "fwrite", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fwrite", ",", "episode_num", "[", "i", "]", "+", "1", ")", "\n", "# unlock file", "\n", "release_file", "(", "fwrite", ")", "\n", "\n", "image_dir", "[", "i", "]", "=", "os", ".", "path", ".", "join", "(", "screen_dir", "[", "i", "]", ",", "str", "(", "episode_num", "[", "i", "]", ")", ")", "\n", "os", ".", "mkdir", "(", "image_dir", "[", "i", "]", ")", "\n", "\n", "if", "sum", "(", "[", "len", "(", "j", ")", "for", "j", "in", "trajectory", "[", "i", "]", "]", ")", ">=", "self", ".", "player_replay_size", ":", "\n", "\n", "# write if enough space is available", "\n", "                        ", "if", "psutil", ".", "virtual_memory", "(", ")", ".", "available", ">=", "mem_threshold", ":", "\n", "\n", "# lock read", "\n", "                            ", "fwrite", "=", "lock_file", "(", "self", ".", "writelock", ")", "\n", "traj_num", "=", "np", ".", "load", "(", "fwrite", ")", ".", "item", "(", ")", "\n", "fwrite", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fwrite", ",", "traj_num", "+", "1", ")", "\n", "# unlock file", "\n", "release_file", "(", "fwrite", ")", "\n", "\n", "traj_to_save", "=", "np", ".", "concatenate", "(", "trajectory", "[", "i", "]", ")", "\n", "traj_to_save", "[", "'traj'", "]", "=", "traj_num", "\n", "\n", "traj_file", "=", "os", ".", "path", ".", "join", "(", "trajectory_dir", "[", "i", "]", ",", "\"%d.npy\"", "%", "traj_num", ")", "\n", "np", ".", "save", "(", "traj_file", ",", "traj_to_save", ")", "\n", "\n", "fread", "=", "lock_file", "(", "readlock", "[", "i", "]", ")", "\n", "traj_list", "=", "np", ".", "load", "(", "fread", ")", "\n", "fread", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fread", ",", "np", ".", "append", "(", "traj_list", ",", "traj_num", ")", ")", "\n", "release_file", "(", "fread", ")", "\n", "\n", "", "trajectory", "[", "i", "]", "=", "[", "]", "\n", "\n", "", "", "", "self", ".", "frame", "+=", "1", "\n", "if", "not", "self", ".", "frame", "%", "self", ".", "player_replay_size", ":", "\n", "                ", "yield", "True", "\n", "\n", "", "if", "self", ".", "n_offset", ">=", "self", ".", "n_tot", ":", "\n", "                ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.ape_agent.ApeAgent.demonstrate": [[455, 494], ["ape_agent.ApeAgent.value_net.eval", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "torch.FloatTensor().unsqueeze().to", "range", "numpy.ones", "ape_agent.ApeAgent.env.reset", "numpy.arange", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "ape_agent.ApeAgent.env.s.to", "ape_agent.ApeAgent.value_net", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy", "numpy.zeros", "pi.clip.clip.clip", "numpy.random.choice", "ape_agent.ApeAgent.env.step", "preprocess.state_to_img", "pi.clip.clip.sum", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu", "numpy.argmax", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.state_to_img"], ["", "", "", "def", "demonstrate", "(", "self", ",", "n_tot", ")", ":", "\n", "\n", "        ", "self", ".", "value_net", ".", "eval", "(", ")", "\n", "pi_rand", "=", "np", ".", "ones", "(", "self", ".", "action_space", ")", "/", "self", ".", "action_space", "\n", "pi_rand", "=", "torch", ".", "FloatTensor", "(", "pi_rand", ")", ".", "unsqueeze", "(", "0", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_tot", ")", ":", "\n", "\n", "            ", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n", "choices", "=", "np", ".", "arange", "(", "self", ".", "action_space", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "while", "not", "self", ".", "env", ".", "t", ":", "\n", "\n", "                ", "s", "=", "self", ".", "env", ".", "s", ".", "to", "(", "self", ".", "device", ")", "\n", "_", ",", "_", ",", "_", ",", "q", ",", "_", "=", "self", ".", "value_net", "(", "s", ",", "self", ".", "a_zeros", ",", "pi_rand", ")", "\n", "\n", "q", "=", "q", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "pi_greed", "=", "np", ".", "zeros", "(", "self", ".", "action_space", ")", "\n", "pi_greed", "[", "np", ".", "argmax", "(", "q", ")", "]", "=", "1", "\n", "pi", "=", "self", ".", "epsilon", "*", "self", ".", "pi_rand", "+", "(", "1", "-", "self", ".", "epsilon", ")", "*", "pi_greed", "\n", "\n", "pi", "=", "pi", ".", "clip", "(", "0", ",", "1", ")", "\n", "pi", "=", "pi", "/", "pi", ".", "sum", "(", ")", "\n", "\n", "a", "=", "np", ".", "random", ".", "choice", "(", "choices", ",", "p", "=", "pi", ")", "\n", "self", ".", "env", ".", "step", "(", "a", ")", "\n", "\n", "img", "=", "state_to_img", "(", "s", ")", "\n", "\n", "v", "=", "(", "pi", "*", "q", ")", ".", "sum", "(", ")", "\n", "adv", "=", "q", "-", "v", "\n", "\n", "yield", "{", "'score'", ":", "self", ".", "env", ".", "score", ",", "\"beta\"", ":", "pi", ",", "\"v\"", ":", "v", ",", "\"q\"", ":", "q", ",", "\"adv\"", ":", "adv", ",", "\"s\"", ":", "img", ",", "'frames'", ":", "self", ".", "env", ".", "k", ",", "\n", "\"actions\"", ":", "self", ".", "env", ".", "action_meanings", ",", "\"a\"", ":", "a", "\n", "}", "\n", "\n", "", "", "raise", "StopIteration", "\n", "", "", ""]], "home.repos.pwc.inspect_result.eladsar_rbi.None.config.boolean_feature": [[19, 27], ["feature.replace", "parser.add_mutually_exclusive_group", "parser.add_mutually_exclusive_group.add_argument", "parser.add_mutually_exclusive_group.add_argument", "parser.set_defaults"], "function", ["None"], ["", "def", "boolean_feature", "(", "feature", ",", "default", ",", "help", ")", ":", "\n", "\n", "    ", "global", "parser", "\n", "featurename", "=", "feature", ".", "replace", "(", "\"-\"", ",", "\"_\"", ")", "\n", "feature_parser", "=", "parser", ".", "add_mutually_exclusive_group", "(", "required", "=", "False", ")", "\n", "feature_parser", ".", "add_argument", "(", "'--%s'", "%", "feature", ",", "dest", "=", "featurename", ",", "action", "=", "'store_true'", ",", "help", "=", "help", ")", "\n", "feature_parser", ".", "add_argument", "(", "'--no-%s'", "%", "feature", ",", "dest", "=", "featurename", ",", "action", "=", "'store_false'", ",", "help", "=", "help", ")", "\n", "parser", ".", "set_defaults", "(", "**", "{", "featurename", ":", "default", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.r2d2_agent.R2D2Agent.__init__": [[34, 78], ["print", "agent.Agent.__init__", "model.DuelRNN", "r2d2_agent.R2D2Agent.value_net.to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.SmoothL1Loss", "torch.SmoothL1Loss", "torch.SmoothL1Loss", "torch.SmoothL1Loss", "torch.SmoothL1Loss", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "numpy.ones", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "environment.Env", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "numpy.arange", "memory_rnn.ObservationsRNNMemory", "memory_rnn.ObservationsRNNBatchSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "r2d2_agent.R2D2Agent.value_net.parameters", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.memory.ReplayBatchSampler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "root_dir", ",", "player", "=", "False", ",", "choose", "=", "False", ",", "checkpoint", "=", "None", ")", ":", "\n", "\n", "        ", "print", "(", "\"Learning with RBIRNNAgent\"", ")", "\n", "super", "(", "R2D2Agent", ",", "self", ")", ".", "__init__", "(", "root_dir", ",", "checkpoint", ")", "\n", "\n", "self", ".", "value_net", "=", "DuelRNN", "(", ")", "\n", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", ":", "\n", "            ", "self", ".", "value_net", "=", "nn", ".", "DataParallel", "(", "self", ".", "value_net", ")", "\n", "", "self", ".", "value_net", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "pi_rand", "=", "np", ".", "ones", "(", "self", ".", "action_space", ")", "/", "self", ".", "action_space", "\n", "self", ".", "pi_rand_seq", "=", "torch", ".", "ones", "(", "self", ".", "batch", ",", "self", ".", "seq_length", ",", "self", ".", "action_space", ",", "dtype", "=", "torch", ".", "float", ")", ".", "to", "(", "self", ".", "device", ")", "/", "self", ".", "action_space", "\n", "self", ".", "pi_rand_bi", "=", "torch", ".", "ones", "(", "self", ".", "batch", ",", "self", ".", "burn_in", ",", "self", ".", "action_space", ",", "dtype", "=", "torch", ".", "float", ")", ".", "to", "(", "self", ".", "device", ")", "/", "self", ".", "action_space", "\n", "\n", "self", ".", "a_zeros", "=", "torch", ".", "zeros", "(", "1", ",", "1", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "a_zeros_bi", "=", "torch", ".", "zeros", "(", "self", ".", "batch", ",", "self", ".", "burn_in", ",", "1", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "q_loss", "=", "nn", ".", "SmoothL1Loss", "(", "reduction", "=", "'none'", ")", "\n", "\n", "if", "player", ":", "\n", "\n", "# play variables", "\n", "            ", "self", ".", "env", "=", "Env", "(", ")", "\n", "self", ".", "a_zeros", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "1", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "trajectory", "=", "[", "]", "\n", "self", ".", "images", "=", "[", "]", "\n", "self", ".", "choices", "=", "np", ".", "arange", "(", "self", ".", "action_space", ",", "dtype", "=", "np", ".", "int", ")", "\n", "self", ".", "n_replay_saved", "=", "1", "\n", "self", ".", "frame", "=", "0", "\n", "self", ".", "states", "=", "0", "\n", "\n", "", "else", ":", "\n", "\n", "# datasets", "\n", "            ", "self", ".", "train_dataset", "=", "ObservationsRNNMemory", "(", "root_dir", ")", "\n", "self", ".", "train_sampler", "=", "ObservationsRNNBatchSampler", "(", "root_dir", ")", "\n", "self", ".", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "self", ".", "train_dataset", ",", "batch_sampler", "=", "self", ".", "train_sampler", ",", "collate_fn", "=", "collate", ",", "\n", "num_workers", "=", "args", ".", "cpu_workers", ",", "pin_memory", "=", "True", ",", "drop_last", "=", "False", ")", "\n", "\n", "# configure learning", "\n", "\n", "# IT IS IMPORTANT TO ASSIGN MODEL TO CUDA/PARALLEL BEFORE DEFINING OPTIMIZER", "\n", "", "self", ".", "optimizer_value", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "value_net", ".", "parameters", "(", ")", ",", "lr", "=", "0.001", ",", "eps", "=", "1e-3", ",", "weight_decay", "=", "0", ")", "\n", "self", ".", "n_offset", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.r2d2_agent.R2D2Agent.save_checkpoint": [[79, 91], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "r2d2_agent.R2D2Agent.value_net.module.state_dict", "r2d2_agent.R2D2Agent.optimizer_value.state_dict", "r2d2_agent.R2D2Agent.value_net.state_dict", "r2d2_agent.R2D2Agent.optimizer_value.state_dict"], "methods", ["None"], ["", "def", "save_checkpoint", "(", "self", ",", "path", ",", "aux", "=", "None", ")", ":", "\n", "\n", "        ", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", ":", "\n", "            ", "state", "=", "{", "'value_net'", ":", "self", ".", "value_net", ".", "module", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_value'", ":", "self", ".", "optimizer_value", ".", "state_dict", "(", ")", ",", "\n", "'aux'", ":", "aux", "}", "\n", "", "else", ":", "\n", "            ", "state", "=", "{", "'value_net'", ":", "self", ".", "value_net", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_value'", ":", "self", ".", "optimizer_value", ".", "state_dict", "(", ")", ",", "\n", "'aux'", ":", "aux", "}", "\n", "\n", "", "torch", ".", "save", "(", "state", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.r2d2_agent.R2D2Agent.load_checkpoint": [[92, 105], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "r2d2_agent.R2D2Agent.value_net.module.load_state_dict", "r2d2_agent.R2D2Agent.optimizer_value.load_state_dict", "r2d2_agent.R2D2Agent.value_net.load_state_dict", "r2d2_agent.R2D2Agent.optimizer_value.load_state_dict"], "methods", ["None"], ["", "def", "load_checkpoint", "(", "self", ",", "path", ")", ":", "\n", "\n", "        ", "state", "=", "torch", ".", "load", "(", "path", ",", "map_location", "=", "\"cuda:%d\"", "%", "self", ".", "cuda_id", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", ":", "\n", "            ", "self", ".", "value_net", ".", "module", ".", "load_state_dict", "(", "state", "[", "'value_net'", "]", ")", "\n", "self", ".", "optimizer_value", ".", "load_state_dict", "(", "state", "[", "'optimizer_value'", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "value_net", ".", "load_state_dict", "(", "state", "[", "'value_net'", "]", ")", "\n", "self", ".", "optimizer_value", ".", "load_state_dict", "(", "state", "[", "'optimizer_value'", "]", ")", "\n", "\n", "", "self", ".", "n_offset", "=", "state", "[", "'aux'", "]", "[", "'n'", "]", "\n", "return", "state", "[", "'aux'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.r2d2_agent.R2D2Agent.learn": [[106, 214], ["model.DuelRNN", "torch.DataParallel.to", "torch.DataParallel.load_state_dict", "r2d2_agent.R2D2Agent.value_net.train", "torch.DataParallel.eval", "tqdm.tqdm.tqdm", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "r2d2_agent.R2D2Agent.value_net.state_dict", "enumerate", "sample[].to", "sample[].to().unsqueeze_", "sample[].to", "sample[].to", "sample[].to", "sample[].to", "sample[].to", "sample[].to", "r2d2_agent.R2D2Agent.value_net", "r2d2_agent.R2D2Agent.value_net", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.argmax().detach().unsqueeze", "torch.DataParallel.", "q_target.detach.detach.detach", "preprocess.h_torch", "is_value.unsqueeze().repeat.unsqueeze().repeat.unsqueeze().repeat", "r2d2_agent.R2D2Agent.optimizer_value.zero_grad", "loss_value.backward", "r2d2_agent.R2D2Agent.optimizer_value.step", "is_value.unsqueeze().repeat.unsqueeze().repeat.max", "sample[].to", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "is_value.unsqueeze().repeat.unsqueeze().repeat.unsqueeze", "a[].contiguous().view().data.cpu().numpy", "q_a[].contiguous().view().data.cpu().numpy", "r.view().data.cpu().numpy.view().data.cpu().numpy.view().data.cpu().numpy", "q[].contiguous().view().data.cpu().max", "beta_index.numpy.numpy.numpy", "R.view().data.cpu().numpy.view().data.cpu().numpy.view().data.cpu().numpy", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "torch.DataParallel.load_state_dict", "r2d2_agent.R2D2Agent.save_checkpoint", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "s[].data.cpu", "r2d2_agent.R2D2Agent.value_net.train", "preprocess.hinv_torch", "loss_value.data.cpu().numpy", "r2d2_agent.R2D2Agent.value_net.state_dict", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "r2d2_agent.R2D2Agent.q_loss", "a[].contiguous().view().data.cpu", "q_a[].contiguous().view().data.cpu", "r.view().data.cpu().numpy.view().data.cpu().numpy.view().data.cpu", "q[].contiguous().view().data.cpu", "R.view().data.cpu().numpy.view().data.cpu().numpy.view().data.cpu", "loss_value.data.cpu", "a[].contiguous().view", "q_a[].contiguous().view", "r.view().data.cpu().numpy.view().data.cpu().numpy.view", "q[].contiguous().view", "R.view().data.cpu().numpy.view().data.cpu().numpy.view", "a[].contiguous", "q_a[].contiguous", "q[].contiguous"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.train", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.save_checkpoint", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.train"], ["", "def", "learn", "(", "self", ",", "n_interval", ",", "n_tot", ")", ":", "\n", "\n", "        ", "target_net", "=", "DuelRNN", "(", ")", "\n", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", ":", "\n", "            ", "target_net", "=", "nn", ".", "DataParallel", "(", "target_net", ")", "\n", "", "target_net", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "target_net", ".", "load_state_dict", "(", "self", ".", "value_net", ".", "state_dict", "(", ")", ")", "\n", "\n", "self", ".", "value_net", ".", "train", "(", ")", "\n", "target_net", ".", "eval", "(", ")", "\n", "\n", "results", "=", "{", "'n'", ":", "[", "]", ",", "'loss_value'", ":", "[", "]", ",", "'loss_beta'", ":", "[", "]", ",", "'act_diff'", ":", "[", "]", ",", "'a_agent'", ":", "[", "]", ",", "\n", "'a_player'", ":", "[", "]", ",", "'loss_std'", ":", "[", "]", ",", "'mc_val'", ":", "[", "]", ",", "\"Hbeta\"", ":", "[", "]", ",", "\"Hpi\"", ":", "[", "]", ",", "\"adv_a\"", ":", "[", "]", ",", "\"q_a\"", ":", "[", "]", ",", "'image'", ":", "[", "]", "}", "\n", "\n", "for", "n", ",", "sample", "in", "tqdm", "(", "enumerate", "(", "self", ".", "train_loader", ")", ")", ":", "\n", "\n", "            ", "s", "=", "sample", "[", "'s'", "]", ".", "to", "(", "self", ".", "device", ",", "non_blocking", "=", "True", ")", "\n", "a", "=", "sample", "[", "'a'", "]", ".", "to", "(", "self", ".", "device", ",", "non_blocking", "=", "True", ")", ".", "unsqueeze_", "(", "2", ")", "\n", "# burn in", "\n", "h_q", "=", "sample", "[", "'h_q'", "]", ".", "to", "(", "self", ".", "device", ",", "non_blocking", "=", "True", ")", "\n", "s_bi", "=", "sample", "[", "'s_bi'", "]", ".", "to", "(", "self", ".", "device", ",", "non_blocking", "=", "True", ")", "\n", "r", "=", "sample", "[", "'r'", "]", ".", "to", "(", "self", ".", "device", ",", "non_blocking", "=", "True", ")", "\n", "t", "=", "sample", "[", "'t'", "]", ".", "to", "(", "self", ".", "device", ",", "non_blocking", "=", "True", ")", "\n", "R", "=", "sample", "[", "'rho_q'", "]", ".", "to", "(", "self", ".", "device", ",", "non_blocking", "=", "True", ")", "\n", "tde", "=", "sample", "[", "'tde'", "]", ".", "to", "(", "self", ".", "device", ",", "non_blocking", "=", "True", ")", "\n", "\n", "_", ",", "_", ",", "h_q", "=", "self", ".", "value_net", "(", "s_bi", ",", "self", ".", "a_zeros_bi", ",", "self", ".", "pi_rand_bi", ",", "h_q", ")", "\n", "\n", "q", ",", "q_a", ",", "_", "=", "self", ".", "value_net", "(", "s", ",", "a", ",", "self", ".", "pi_rand_seq", ",", "h_q", ")", "\n", "a_tag", "=", "torch", ".", "argmax", "(", "q", ",", "dim", "=", "2", ")", ".", "detach", "(", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "_", ",", "q_target", ",", "_", "=", "target_net", "(", "s", ",", "a_tag", ",", "self", ".", "pi_rand_seq", ",", "h_q", ")", "\n", "q_target", "=", "q_target", ".", "detach", "(", ")", "\n", "\n", "r", "=", "h_torch", "(", "r", "+", "self", ".", "discount", "**", "self", ".", "n_steps", "*", "(", "1", "-", "t", "[", ":", ",", "self", ".", "n_steps", ":", "]", ")", "*", "hinv_torch", "(", "q_target", "[", ":", ",", "self", ".", "n_steps", ":", "]", ")", ")", "\n", "\n", "is_value", "=", "tde", "**", "(", "-", "self", ".", "priority_beta", ")", "\n", "is_value", "=", "is_value", "/", "is_value", ".", "max", "(", ")", "\n", "is_value", "=", "is_value", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "self", ".", "seq_length", "-", "self", ".", "n_steps", ")", "\n", "\n", "loss_value", "=", "(", "self", ".", "q_loss", "(", "q_a", "[", ":", ",", ":", "-", "self", ".", "n_steps", "]", ",", "r", ")", "*", "is_value", "*", "(", "1", "-", "t", "[", ":", ",", ":", "-", "self", ".", "n_steps", "]", ")", ")", ".", "mean", "(", ")", "\n", "\n", "# Learning part", "\n", "\n", "self", ".", "optimizer_value", ".", "zero_grad", "(", ")", "\n", "loss_value", ".", "backward", "(", ")", "\n", "self", ".", "optimizer_value", ".", "step", "(", ")", "\n", "\n", "# collect actions statistics", "\n", "\n", "if", "not", "(", "n", "+", "1", "+", "self", ".", "n_offset", ")", "%", "10", ":", "\n", "\n", "                ", "if", "not", "(", "n", "+", "1", "+", "self", ".", "n_offset", ")", "%", "50", ":", "\n", "\n", "                    ", "a_index_np", "=", "a", "[", ":", ",", ":", "-", "self", ".", "n_steps", ",", "0", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "q_a", "=", "q_a", "[", ":", ",", ":", "-", "self", ".", "n_steps", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "r", "=", "r", ".", "view", "(", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "_", ",", "beta_index", "=", "q", "[", ":", ",", ":", "-", "self", ".", "n_steps", ",", ":", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "self", ".", "action_space", ")", ".", "data", ".", "cpu", "(", ")", ".", "max", "(", "1", ")", "\n", "beta_index", "=", "beta_index", ".", "numpy", "(", ")", "\n", "act_diff", "=", "(", "a_index_np", "!=", "beta_index", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "R", "=", "R", ".", "view", "(", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# add results", "\n", "\n", "results", "[", "'act_diff'", "]", ".", "append", "(", "act_diff", ")", "\n", "results", "[", "'a_agent'", "]", ".", "append", "(", "beta_index", ")", "\n", "results", "[", "'adv_a'", "]", ".", "append", "(", "r", ")", "\n", "results", "[", "'q_a'", "]", ".", "append", "(", "q_a", ")", "\n", "results", "[", "'a_player'", "]", ".", "append", "(", "a_index_np", ")", "\n", "results", "[", "'Hbeta'", "]", ".", "append", "(", "0", ")", "\n", "results", "[", "'Hpi'", "]", ".", "append", "(", "0", ")", "\n", "results", "[", "'mc_val'", "]", ".", "append", "(", "R", ")", "\n", "\n", "# add results", "\n", "results", "[", "'loss_beta'", "]", ".", "append", "(", "(", "(", "R", "-", "r", ")", "**", "2", ")", ".", "mean", "(", ")", ")", "\n", "results", "[", "'loss_value'", "]", ".", "append", "(", "loss_value", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "results", "[", "'loss_std'", "]", ".", "append", "(", "0", ")", "\n", "results", "[", "'n'", "]", ".", "append", "(", "n", ")", "\n", "\n", "", "if", "not", "(", "n", "+", "1", "+", "self", ".", "n_offset", ")", "%", "self", ".", "update_target_interval", ":", "\n", "# save agent state", "\n", "                    ", "target_net", ".", "load_state_dict", "(", "self", ".", "value_net", ".", "state_dict", "(", ")", ")", "\n", "\n", "", "if", "not", "(", "n", "+", "1", "+", "self", ".", "n_offset", ")", "%", "self", ".", "update_memory_interval", ":", "\n", "# save agent state", "\n", "                    ", "self", ".", "save_checkpoint", "(", "self", ".", "snapshot_path", ",", "{", "'n'", ":", "self", ".", "n_offset", "+", "n", "+", "1", "}", ")", "\n", "\n", "", "if", "not", "(", "n", "+", "1", "+", "self", ".", "n_offset", ")", "%", "n_interval", ":", "\n", "                    ", "results", "[", "'act_diff'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'act_diff'", "]", ")", "\n", "results", "[", "'a_agent'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'a_agent'", "]", ")", "\n", "results", "[", "'adv_a'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'adv_a'", "]", ")", "\n", "results", "[", "'q_a'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'q_a'", "]", ")", "\n", "results", "[", "'a_player'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'a_player'", "]", ")", "\n", "results", "[", "'mc_val'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'mc_val'", "]", ")", "\n", "results", "[", "'image'", "]", "=", "s", "[", "0", ",", "0", ",", ":", "-", "1", ",", ":", ",", ":", "]", ".", "data", ".", "cpu", "(", ")", "\n", "\n", "yield", "results", "\n", "self", ".", "value_net", ".", "train", "(", ")", "\n", "results", "=", "{", "key", ":", "[", "]", "for", "key", "in", "results", "}", "\n", "\n", "if", "(", "n", "+", "self", ".", "n_offset", ")", ">=", "n_tot", ":", "\n", "                        ", "break", "\n", "\n", "", "", "", "del", "loss_value", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.r2d2_agent.R2D2Agent.play": [[215, 297], ["range", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "r2d2_agent.R2D2Agent.env.reset", "r2d2_agent.R2D2Agent.value_net.eval", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "preprocess.get_mc_value", "numpy.array", "print", "r2d2_agent.R2D2Agent.env.s.to().unsqueeze", "r2d2_agent.R2D2Agent.value_net", "q.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy", "pi_mix.clip.clip.clip", "numpy.random.choice", "r2d2_agent.R2D2Agent.env.step", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "r2d2_agent.R2D2Agent.load_checkpoint", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "r2d2_agent.R2D2Agent.value_net.eval", "numpy.zeros", "pi_mix.clip.clip.sum", "rewards[].append", "v_target[].append", "numpy.array.append", "time.sleep", "r2d2_agent.R2D2Agent.load_checkpoint", "r2d2_agent.R2D2Agent.env.s.to", "q.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu", "rewards.append", "v_target.append", "str", "numpy.argmax", "q.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze", "q.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.squeeze"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_mc_value", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.load_checkpoint", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.load_checkpoint"], ["", "", "def", "play", "(", "self", ",", "n_tot", ",", "save", "=", "True", ",", "load", "=", "True", ",", "fix", "=", "False", ")", ":", "\n", "\n", "        ", "pi_rand_t", "=", "torch", ".", "ones", "(", "1", ",", "1", ",", "self", ".", "action_space", ",", "dtype", "=", "torch", ".", "float", ")", ".", "to", "(", "self", ".", "device", ")", "/", "self", ".", "action_space", "\n", "\n", "for", "i", "in", "range", "(", "n_tot", ")", ":", "\n", "\n", "            ", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n", "rewards", "=", "[", "[", "]", "]", "\n", "v_target", "=", "[", "[", "]", "]", "\n", "q_val", "=", "[", "]", "\n", "lives", "=", "self", ".", "env", ".", "lives", "\n", "\n", "while", "not", "fix", ":", "\n", "                ", "try", ":", "\n", "                    ", "self", ".", "load_checkpoint", "(", "self", ".", "snapshot_path", ")", "\n", "break", "\n", "", "except", ":", "\n", "                    ", "time", ".", "sleep", "(", "0.5", ")", "\n", "\n", "", "", "self", ".", "value_net", ".", "eval", "(", ")", "\n", "\n", "# Initial states", "\n", "h_q", "=", "torch", ".", "zeros", "(", "1", ",", "self", ".", "hidden_state", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "while", "not", "self", ".", "env", ".", "t", ":", "\n", "\n", "                ", "if", "load", "and", "not", "(", "self", ".", "states", "%", "self", ".", "load_memory_interval", ")", ":", "\n", "                    ", "try", ":", "\n", "                        ", "self", ".", "load_checkpoint", "(", "self", ".", "snapshot_path", ")", "\n", "", "except", ":", "\n", "                        ", "pass", "\n", "\n", "", "self", ".", "value_net", ".", "eval", "(", ")", "\n", "\n", "", "s", "=", "self", ".", "env", ".", "s", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze", "(", "0", ")", "\n", "# take q as adv", "\n", "\n", "q", ",", "_", ",", "h_q", "=", "self", ".", "value_net", "(", "s", ",", "self", ".", "a_zeros", ",", "pi_rand_t", ",", "h_q", ")", "\n", "\n", "q", "=", "q", ".", "squeeze", "(", "0", ")", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "self", ".", "n_offset", ">=", "self", ".", "random_initialization", ":", "\n", "\n", "                    ", "pi", "=", "np", ".", "zeros", "(", "self", ".", "action_space", ")", "\n", "pi", "[", "np", ".", "argmax", "(", "q", ")", "]", "=", "1", "\n", "pi_mix", "=", "self", ".", "epsilon", "*", "self", ".", "pi_rand", "+", "(", "1", "-", "self", ".", "epsilon", ")", "*", "pi", "\n", "", "else", ":", "\n", "                    ", "pi_mix", "=", "self", ".", "pi_rand", "\n", "\n", "", "pi_mix", "=", "pi_mix", ".", "clip", "(", "0", ",", "1", ")", "\n", "pi_mix", "=", "pi_mix", "/", "pi_mix", ".", "sum", "(", ")", "\n", "a", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "choices", ",", "p", "=", "pi_mix", ")", "\n", "self", ".", "env", ".", "step", "(", "a", ")", "\n", "\n", "if", "self", ".", "env", ".", "k", ">=", "self", ".", "history_length", ":", "\n", "\n", "                    ", "if", "lives", ">", "self", ".", "env", ".", "lives", ":", "\n", "                        ", "rewards", ".", "append", "(", "[", "]", ")", "\n", "v_target", ".", "append", "(", "[", "]", ")", "\n", "", "lives", "=", "self", ".", "env", ".", "lives", "\n", "\n", "rewards", "[", "-", "1", "]", ".", "append", "(", "self", ".", "env", ".", "r", ")", "\n", "v_target", "[", "-", "1", "]", ".", "append", "(", "0", ")", "\n", "q_val", ".", "append", "(", "q", "[", "a", "]", ")", "\n", "\n", "", "self", ".", "frame", "+=", "1", "\n", "\n", "", "mc_val", "=", "get_mc_value", "(", "rewards", ",", "None", ",", "self", ".", "discount", ",", "None", ")", "\n", "q_val", "=", "np", ".", "array", "(", "q_val", ")", "\n", "\n", "print", "(", "\"sts | st: %d\\t| sc: %d\\t| f: %d\\t| e: %7g\\t| typ: %2d | trg: %d | nst: %s\\t| n %d\\t| avg_r: %g\\t| avg_f: %g\"", "%", "\n", "(", "self", ".", "frame", ",", "self", ".", "env", ".", "score", ",", "self", ".", "env", ".", "k", ",", "0", ",", "0", ",", "0", ",", "str", "(", "np", ".", "nan", ")", ",", "\n", "self", ".", "n_offset", ",", "self", ".", "behavioral_avg_score", ",", "self", ".", "behavioral_avg_frame", ")", ")", "\n", "\n", "yield", "{", "'score'", ":", "self", ".", "env", ".", "score", ",", "\n", "'frames'", ":", "self", ".", "env", ".", "k", ",", "\"n\"", ":", "self", ".", "n_offset", ",", "\"mc\"", ":", "mc_val", ",", "\"q\"", ":", "q_val", "}", "\n", "\n", "if", "self", ".", "n_offset", ">=", "self", ".", "n_tot", "and", "not", "fix", ":", "\n", "                ", "break", "\n", "\n", "", "", "raise", "StopIteration", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.r2d2_agent.R2D2Agent.multiplay": [[298, 494], ["r2d2_agent.R2D2Agent.a_zeros.repeat", "numpy.repeat", "preprocess.lock_file", "numpy.load().item", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "numpy.arange", "environment.Env", "numpy.expand_dims", "numpy.arange", "mp_env[].reset", "os.path.join", "os.mkdir", "torch.zeros().to.data.cpu().numpy", "torch.zeros().to.data.cpu().numpy", "torch.zeros().to.data.cpu().numpy", "torch.zeros().to.data.cpu().numpy", "torch.zeros().to.data.cpu().numpy", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "r2d2_agent.R2D2Agent.value_net", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy", "numpy.logical_and", "numpy.repeat", "pi_mix.clip.clip.clip", "numpy.zeros.astype", "range", "range", "range", "range", "range", "range", "range", "range", "os.path.join", "range", "os.path.join", "os.path.join", "numpy.load", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "str", "range", "r2d2_agent.R2D2Agent.value_net.eval", "numpy.expand_dims", "numpy.zeros", "numpy.repeat", "numpy.random.choice", "cv2.imwrite", "episode[].append", "env.step", "[].append", "[].append", "q_expected[].append", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "r2d2_agent.R2D2Agent.load_checkpoint", "torch.zeros().to.data.cpu", "torch.zeros().to.data.cpu", "torch.zeros().to.data.cpu", "torch.zeros().to.data.cpu", "torch.zeros().to.data.cpu", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu", "numpy.array", "pi_mix.clip.clip.sum", "os.path.join", "numpy.zeros_like", "numpy.array", "rewards[].append", "v_target[].append", "q[].max", "preprocess.get_expected_value", "numpy.stack", "preprocess.get_tde", "preprocess.get_mc_value", "trajectory[].append", "h_q[].zero_", "print", "env.reset", "preprocess.lock_file", "numpy.load().item", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "os.path.join", "os.mkdir", "int", "str", "sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "numpy.argmax", "str", "numpy.load", "preprocess.lock_file", "numpy.load().item", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "numpy.concatenate", "os.path.join", "numpy.save", "preprocess.lock_file", "numpy.load", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze", "numpy.sign", "len", "psutil.virtual_memory", "numpy.append", "time.time", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.load_checkpoint", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_tde", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_mc_value", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file"], ["", "def", "multiplay", "(", "self", ")", ":", "\n", "\n", "        ", "n_players", "=", "self", ".", "n_players", "\n", "pi_rand_t", "=", "torch", ".", "ones", "(", "n_players", ",", "1", ",", "self", ".", "action_space", ",", "dtype", "=", "torch", ".", "float", ")", ".", "to", "(", "self", ".", "device", ")", "/", "self", ".", "action_space", "\n", "\n", "player_i", "=", "np", ".", "arange", "(", "self", ".", "actor_index", ",", "self", ".", "actor_index", "+", "self", ".", "n_actors", "*", "n_players", ",", "self", ".", "n_actors", ")", "/", "(", "self", ".", "n_actors", "*", "n_players", "-", "1", ")", "\n", "explore_threshold", "=", "player_i", "\n", "\n", "mp_explore", "=", "0.4", "**", "(", "1", "+", "7", "*", "(", "1", "-", "player_i", ")", ")", "\n", "\n", "mp_env", "=", "[", "Env", "(", ")", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "self", ".", "frame", "=", "0", "\n", "\n", "a_zeros_mp", "=", "self", ".", "a_zeros", ".", "repeat", "(", "n_players", ",", "1", ",", "1", ")", "\n", "mp_pi_rand", "=", "np", ".", "repeat", "(", "np", ".", "expand_dims", "(", "self", ".", "pi_rand", ",", "axis", "=", "0", ")", ",", "n_players", ",", "axis", "=", "0", ")", "\n", "\n", "rewards", "=", "[", "[", "[", "]", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "v_target", "=", "[", "[", "[", "]", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "q_expected", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "episode", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "image_dir", "=", "[", "''", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "trajectory", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "screen_dir", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"screen\"", ")", "]", "*", "n_players", "\n", "fr_s", "=", "[", "self", ".", "frame", "+", "self", ".", "history_length", "-", "1", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "\n", "trajectory_dir", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"trajectory\"", ")", "]", "*", "n_players", "\n", "readlock", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "list_dir", ",", "\"readlock_explore.npy\"", ")", "]", "*", "n_players", "\n", "\n", "# set initial episodes number", "\n", "# lock read", "\n", "fwrite", "=", "lock_file", "(", "self", ".", "episodelock", ")", "\n", "current_num", "=", "np", ".", "load", "(", "fwrite", ")", ".", "item", "(", ")", "\n", "episode_num", "=", "current_num", "+", "np", ".", "arange", "(", "n_players", ")", "\n", "fwrite", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fwrite", ",", "current_num", "+", "n_players", ")", "\n", "# unlock file", "\n", "release_file", "(", "fwrite", ")", "\n", "\n", "# Initial states", "\n", "h_q", "=", "torch", ".", "zeros", "(", "n_players", ",", "self", ".", "hidden_state", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_players", ")", ":", "\n", "            ", "mp_env", "[", "i", "]", ".", "reset", "(", ")", "\n", "image_dir", "[", "i", "]", "=", "os", ".", "path", ".", "join", "(", "screen_dir", "[", "i", "]", ",", "str", "(", "episode_num", "[", "i", "]", ")", ")", "\n", "os", ".", "mkdir", "(", "image_dir", "[", "i", "]", ")", "\n", "\n", "", "lives", "=", "[", "mp_env", "[", "i", "]", ".", "lives", "for", "i", "in", "range", "(", "n_players", ")", "]", "\n", "\n", "while", "True", ":", "\n", "\n", "            ", "if", "not", "(", "self", ".", "frame", "%", "self", ".", "load_memory_interval", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "self", ".", "load_checkpoint", "(", "self", ".", "snapshot_path", ")", "\n", "", "except", ":", "\n", "                    ", "pass", "\n", "\n", "", "self", ".", "value_net", ".", "eval", "(", ")", "\n", "\n", "# save previous hidden state to np object", "\n", "", "h_q_np", "=", "h_q", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "s", "=", "torch", ".", "cat", "(", "[", "env", ".", "s", "for", "env", "in", "mp_env", "]", ")", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "# take q as adv", "\n", "q", ",", "_", ",", "h_q", "=", "self", ".", "value_net", "(", "s", ",", "a_zeros_mp", ",", "pi_rand_t", ",", "h_q", ")", "\n", "\n", "q", "=", "q", ".", "squeeze", "(", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "mp_trigger", "=", "np", ".", "logical_and", "(", "\n", "np", ".", "array", "(", "[", "env", ".", "score", "for", "env", "in", "mp_env", "]", ")", ">=", "self", ".", "behavioral_avg_score", "*", "explore_threshold", ",", "\n", "explore_threshold", ">=", "0", ")", "\n", "exploration", "=", "np", ".", "repeat", "(", "np", ".", "expand_dims", "(", "mp_explore", "*", "mp_trigger", ",", "axis", "=", "1", ")", ",", "self", ".", "action_space", ",", "axis", "=", "1", ")", "\n", "\n", "if", "self", ".", "n_offset", ">=", "self", ".", "random_initialization", ":", "\n", "\n", "                ", "pi", "=", "np", ".", "zeros", "(", "(", "n_players", ",", "self", ".", "action_space", ")", ")", "\n", "pi", "[", "range", "(", "n_players", ")", ",", "np", ".", "argmax", "(", "q", ",", "axis", "=", "1", ")", "]", "=", "1", "\n", "\n", "", "else", ":", "\n", "                ", "pi", "=", "mp_pi_rand", "\n", "\n", "", "pi_mix", "=", "pi", "*", "(", "1", "-", "exploration", ")", "+", "exploration", "*", "mp_pi_rand", "\n", "\n", "pi_mix", "=", "pi_mix", ".", "clip", "(", "0", ",", "1", ")", "\n", "pi_mix", "=", "pi_mix", "/", "np", ".", "repeat", "(", "pi_mix", ".", "sum", "(", "axis", "=", "1", ",", "keepdims", "=", "True", ")", ",", "self", ".", "action_space", ",", "axis", "=", "1", ")", "\n", "\n", "pi", "=", "pi", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_players", ")", ":", "\n", "\n", "                ", "a", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "choices", ",", "p", "=", "pi_mix", "[", "i", "]", ")", "\n", "\n", "env", "=", "mp_env", "[", "i", "]", "\n", "cv2", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "image_dir", "[", "i", "]", ",", "\"%s.png\"", "%", "str", "(", "self", ".", "frame", ")", ")", ",", "mp_env", "[", "i", "]", ".", "image", ",", "[", "imcompress", ",", "compress_level", "]", ")", "\n", "\n", "h_beta_save", "=", "np", ".", "zeros_like", "(", "h_q_np", "[", "i", "]", ")", "if", "not", "self", ".", "frame", "%", "self", ".", "seq_overlap", "else", "None", "\n", "h_q_save", "=", "h_q_np", "[", "i", "]", "if", "not", "self", ".", "frame", "%", "self", ".", "seq_overlap", "else", "None", "\n", "\n", "episode", "[", "i", "]", ".", "append", "(", "np", ".", "array", "(", "(", "self", ".", "frame", ",", "a", ",", "pi", "[", "i", "]", ",", "\n", "h_beta_save", ",", "h_q_save", ",", "\n", "episode_num", "[", "i", "]", ",", "0.", ",", "fr_s", "[", "i", "]", ",", "0", ",", "\n", "0.", ",", "1.", ",", "1.", ",", "0", ",", "1.", ",", "0", ")", ",", "dtype", "=", "self", ".", "rec_type", ")", ")", "\n", "env", ".", "step", "(", "a", ")", "\n", "\n", "if", "lives", "[", "i", "]", ">", "env", ".", "lives", ":", "\n", "                    ", "rewards", "[", "i", "]", ".", "append", "(", "[", "]", ")", "\n", "v_target", "[", "i", "]", ".", "append", "(", "[", "]", ")", "\n", "", "lives", "[", "i", "]", "=", "env", ".", "lives", "\n", "\n", "rewards", "[", "i", "]", "[", "-", "1", "]", ".", "append", "(", "env", ".", "r", ")", "\n", "v_target", "[", "i", "]", "[", "-", "1", "]", ".", "append", "(", "q", "[", "i", "]", ".", "max", "(", ")", ")", "\n", "q_expected", "[", "i", "]", ".", "append", "(", "q", "[", "i", "]", "[", "a", "]", ")", "\n", "\n", "if", "env", ".", "t", ":", "\n", "\n", "# cancel termination reward", "\n", "                    ", "rewards", "[", "i", "]", "[", "-", "1", "]", "[", "-", "1", "]", "-=", "self", ".", "termination_reward", "*", "int", "(", "env", ".", "k", "*", "self", ".", "skip", ">=", "self", ".", "max_length", "or", "env", ".", "score", ">=", "self", ".", "max_score", ")", "\n", "td_val", "=", "get_expected_value", "(", "rewards", "[", "i", "]", ",", "v_target", "[", "i", "]", ",", "self", ".", "discount", ",", "self", ".", "n_steps", ")", "\n", "\n", "episode_df", "=", "np", ".", "stack", "(", "episode", "[", "i", "]", "[", "self", ".", "history_length", "-", "1", ":", "self", ".", "max_length", "]", ")", "\n", "\n", "tde", "=", "get_tde", "(", "rewards", "[", "i", "]", ",", "v_target", "[", "i", "]", ",", "self", ".", "discount", ",", "self", ".", "n_steps", ",", "q_expected", "[", "i", "]", ")", "\n", "episode_df", "[", "'tde'", "]", "=", "tde", "[", "self", ".", "history_length", "-", "1", ":", "self", ".", "max_length", "]", "\n", "\n", "mc_val", "=", "get_mc_value", "(", "rewards", "[", "i", "]", ",", "v_target", "[", "i", "]", ",", "self", ".", "discount", ",", "self", ".", "n_steps", ")", "\n", "\n", "episode_df", "[", "'r'", "]", "=", "td_val", "[", "self", ".", "history_length", "-", "1", ":", "self", ".", "max_length", "]", "\n", "\n", "# hack to save the true target (MC value)", "\n", "episode_df", "[", "'rho_q'", "]", "=", "mc_val", "[", "self", ".", "history_length", "-", "1", ":", "self", ".", "max_length", "]", "\n", "\n", "episode_df", "[", "'fr_e'", "]", "=", "episode_df", "[", "-", "1", "]", "[", "'fr'", "]", "+", "1", "\n", "trajectory", "[", "i", "]", ".", "append", "(", "episode_df", ")", "\n", "\n", "# reset hidden states", "\n", "h_q", "[", "i", ",", ":", "]", ".", "zero_", "(", ")", "\n", "\n", "print", "(", "\"rbi | st: %d\\t| sc: %d\\t| f: %d\\t| e: %7g\\t| typ: %2d | trg: %d | t: %d\\t| n %d\\t| avg_r: %g\\t| avg_f: %g\"", "%", "\n", "(", "self", ".", "frame", ",", "env", ".", "score", ",", "env", ".", "k", ",", "mp_explore", "[", "i", "]", ",", "np", ".", "sign", "(", "explore_threshold", "[", "i", "]", ")", ",", "1", ",", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", ",", "self", ".", "n_offset", ",", "self", ".", "behavioral_avg_score", ",", "self", ".", "behavioral_avg_frame", ")", ")", "\n", "\n", "env", ".", "reset", "(", ")", "\n", "episode", "[", "i", "]", "=", "[", "]", "\n", "q_expected", "[", "i", "]", "=", "[", "]", "\n", "rewards", "[", "i", "]", "=", "[", "[", "]", "]", "\n", "v_target", "[", "i", "]", "=", "[", "[", "]", "]", "\n", "lives", "[", "i", "]", "=", "env", ".", "lives", "\n", "fr_s", "[", "i", "]", "=", "(", "self", ".", "frame", "+", "1", ")", "+", "(", "self", ".", "history_length", "-", "1", ")", "\n", "\n", "# get new episode number", "\n", "\n", "# lock read", "\n", "fwrite", "=", "lock_file", "(", "self", ".", "episodelock", ")", "\n", "episode_num", "[", "i", "]", "=", "np", ".", "load", "(", "fwrite", ")", ".", "item", "(", ")", "\n", "fwrite", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fwrite", ",", "episode_num", "[", "i", "]", "+", "1", ")", "\n", "# unlock file", "\n", "release_file", "(", "fwrite", ")", "\n", "\n", "image_dir", "[", "i", "]", "=", "os", ".", "path", ".", "join", "(", "screen_dir", "[", "i", "]", ",", "str", "(", "episode_num", "[", "i", "]", ")", ")", "\n", "os", ".", "mkdir", "(", "image_dir", "[", "i", "]", ")", "\n", "\n", "if", "sum", "(", "[", "len", "(", "j", ")", "for", "j", "in", "trajectory", "[", "i", "]", "]", ")", ">=", "self", ".", "player_replay_size", ":", "\n", "\n", "# write if enough space is available", "\n", "                        ", "if", "psutil", ".", "virtual_memory", "(", ")", ".", "available", ">=", "mem_threshold", ":", "\n", "\n", "# lock read", "\n", "                            ", "fwrite", "=", "lock_file", "(", "self", ".", "writelock", ")", "\n", "traj_num", "=", "np", ".", "load", "(", "fwrite", ")", ".", "item", "(", ")", "\n", "fwrite", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fwrite", ",", "traj_num", "+", "1", ")", "\n", "# unlock file", "\n", "release_file", "(", "fwrite", ")", "\n", "\n", "traj_to_save", "=", "np", ".", "concatenate", "(", "trajectory", "[", "i", "]", ")", "\n", "traj_to_save", "[", "'traj'", "]", "=", "traj_num", "\n", "\n", "traj_file", "=", "os", ".", "path", ".", "join", "(", "trajectory_dir", "[", "i", "]", ",", "\"%d.npy\"", "%", "traj_num", ")", "\n", "np", ".", "save", "(", "traj_file", ",", "traj_to_save", ")", "\n", "\n", "fread", "=", "lock_file", "(", "readlock", "[", "i", "]", ")", "\n", "traj_list", "=", "np", ".", "load", "(", "fread", ")", "\n", "fread", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fread", ",", "np", ".", "append", "(", "traj_list", ",", "traj_num", ")", ")", "\n", "\n", "release_file", "(", "fread", ")", "\n", "\n", "", "trajectory", "[", "i", "]", "=", "[", "]", "\n", "\n", "# write trajectory to dir", "\n", "\n", "", "", "", "self", ".", "frame", "+=", "1", "\n", "if", "not", "self", ".", "frame", "%", "self", ".", "player_replay_size", ":", "\n", "                ", "yield", "True", "\n", "if", "self", ".", "n_offset", ">=", "self", ".", "n_tot", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.r2d2_agent.R2D2Agent.demonstrate": [[495, 588], ["r2d2_agent.R2D2Agent.value_net.eval", "range", "os.mkdir", "r2d2_agent.R2D2Agent.env.reset", "numpy.arange", "socket.gethostname", "os.path.join", "os.path.join", "r2d2_agent.R2D2Agent.env.s.to", "r2d2_agent.R2D2Agent.env.aux.to", "r2d2_agent.R2D2Agent.beta_net", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "r2d2_agent.R2D2Agent.value_net", "v.squeeze.squeeze.squeeze", "adv.squeeze.squeeze.squeeze", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy", "beta.data.cpu().numpy.data.cpu().numpy.squeeze", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "beta.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "beta.data.cpu().numpy.copy.clip", "numpy.random.choice", "r2d2_agent.R2D2Agent.env.step", "r2d2_agent.R2D2Agent.squeeze().data[].cpu().numpy", "cv2.imwrite", "beta.data.cpu().numpy.data.cpu().numpy.copy", "adv.squeeze.squeeze.copy", "numpy.argsort", "numpy.argsort().astype", "beta.data.cpu().numpy.copy.sum", "numpy.rollaxis", "os.path.join", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu", "beta.data.cpu().numpy.data.cpu().numpy.data.cpu", "numpy.argmax", "numpy.min", "numpy.logical_or", "numpy.sum", "r2d2_agent.R2D2Agent.squeeze().data[].cpu", "v.squeeze.squeeze.data.cpu().numpy", "r2d2_agent.R2D2Agent.squeeze().data.cpu().numpy", "adv.squeeze.squeeze.data.cpu().numpy", "numpy.argsort", "v.squeeze.squeeze.data.cpu", "r2d2_agent.R2D2Agent.squeeze().data.cpu", "adv.squeeze.squeeze.data.cpu", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze", "r2d2_agent.R2D2Agent.squeeze", "r2d2_agent.R2D2Agent.squeeze"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step"], ["", "", "", "", "def", "demonstrate", "(", "self", ",", "n_tot", ")", ":", "\n", "\n", "        ", "self", ".", "value_net", ".", "eval", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_tot", ")", ":", "\n", "\n", "            ", "if", "\"gpu\"", "in", "socket", ".", "gethostname", "(", ")", ":", "\n", "                ", "log_dir", "=", "os", ".", "path", ".", "join", "(", "\"/home/dsi/elad/data/rbi/runs\"", ",", "\"%s_%d\"", "%", "(", "consts", ".", "exptime", ",", "i", ")", ")", "\n", "", "else", ":", "\n", "                ", "log_dir", "=", "os", ".", "path", ".", "join", "(", "\"/tmp\"", ",", "\"%s_%d\"", "%", "(", "consts", ".", "exptime", ",", "i", ")", ")", "\n", "\n", "", "os", ".", "mkdir", "(", "log_dir", ")", "\n", "\n", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n", "# here there is a problem when there is a varying/increasing life counter as in mspacman", "\n", "\n", "choices", "=", "np", ".", "arange", "(", "self", ".", "action_space", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "while", "not", "self", ".", "env", ".", "t", ":", "\n", "\n", "                ", "s", "=", "self", ".", "env", ".", "s", ".", "to", "(", "self", ".", "device", ")", "\n", "aux", "=", "self", ".", "env", ".", "aux", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "beta", "=", "self", ".", "beta_net", "(", "s", ",", "aux", ")", "\n", "\n", "beta_softmax", "=", "F", ".", "softmax", "(", "beta", ",", "dim", "=", "2", ")", "\n", "\n", "v", ",", "adv", ",", "_", ",", "q", ",", "_", "=", "self", ".", "value_net", "(", "s", ",", "self", ".", "a_zeros", ",", "beta_softmax", ",", "aux", ")", "\n", "v", "=", "v", ".", "squeeze", "(", "0", ")", "\n", "adv", "=", "adv", ".", "squeeze", "(", "0", ")", "\n", "q", "=", "q", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "beta", "=", "beta", ".", "squeeze", "(", "0", ")", "\n", "beta", "=", "F", ".", "softmax", "(", "beta", ",", "dim", "=", "2", ")", "\n", "beta", "=", "beta", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "\n", "if", "False", ":", "\n", "\n", "                    ", "pi", "=", "beta", ".", "copy", "(", ")", "\n", "adv2", "=", "adv", ".", "copy", "(", ")", "\n", "\n", "rank", "=", "np", ".", "argsort", "(", "adv2", ")", "\n", "adv_rank", "=", "np", ".", "argsort", "(", "rank", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "\n", "pi", "=", "self", ".", "cmin", "*", "pi", "\n", "\n", "Delta", "=", "1", "-", "self", ".", "cmin", "\n", "while", "Delta", ">", "0", ":", "\n", "                        ", "a", "=", "np", ".", "argmax", "(", "adv2", ")", "\n", "Delta_a", "=", "np", ".", "min", "(", "(", "Delta", ",", "(", "self", ".", "cmax", "-", "self", ".", "cmin", ")", "*", "beta", "[", "a", "]", ")", ")", "\n", "Delta", "-=", "Delta_a", "\n", "pi", "[", "a", "]", "+=", "Delta_a", "\n", "adv2", "[", "a", "]", "=", "-", "1e11", "\n", "\n", "# pi_adv = 2 ** adv_rank * np.logical_or(adv2 >= 0, adv_rank == (self.action_space - 1))", "\n", "", "pi_adv", "=", "1.", "*", "np", ".", "logical_or", "(", "adv", ">=", "0", ",", "adv_rank", "==", "(", "self", ".", "action_space", "-", "1", ")", ")", "\n", "pi_adv", "=", "pi_adv", "/", "(", "np", ".", "sum", "(", "pi_adv", ")", ")", "\n", "\n", "pi", "=", "(", "1", "-", "self", ".", "mix", ")", "*", "pi", "+", "self", ".", "mix", "*", "pi_adv", "\n", "pi_mix", "=", "self", ".", "eps_pre", "*", "self", ".", "pi_rand", "+", "(", "1", "-", "self", ".", "eps_pre", ")", "*", "pi", "\n", "\n", "", "else", ":", "\n", "                    ", "pi", "=", "beta", "\n", "\n", "", "pi", "=", "pi", ".", "clip", "(", "0", ",", "1", ")", "\n", "pi", "=", "pi", "/", "pi", ".", "sum", "(", ")", "\n", "\n", "a", "=", "np", ".", "random", ".", "choice", "(", "choices", ",", "p", "=", "pi", ")", "\n", "self", ".", "env", ".", "step", "(", "a", ")", "\n", "\n", "# time.sleep(0.1)", "\n", "\n", "img", "=", "s", ".", "squeeze", "(", "0", ")", ".", "data", "[", ":", "3", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "img", "=", "np", ".", "rollaxis", "(", "img", ",", "0", ",", "3", ")", "[", ":", ",", ":", ",", ":", "3", "]", "\n", "img", "=", "(", "img", "*", "256", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "cv2", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"%d_%d_%d.png\"", "%", "(", "self", ".", "env", ".", "k", ",", "a", ",", "self", ".", "env", ".", "score", ")", ")", ",", "img", ")", "\n", "\n", "yield", "{", "'score'", ":", "self", ".", "env", ".", "score", ",", "\n", "\"beta\"", ":", "pi", ",", "\n", "\"v\"", ":", "v", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "\"q\"", ":", "q", ",", "\n", "\"aux\"", ":", "aux", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "\"adv\"", ":", "adv", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "\"o\"", ":", "img", ",", "\n", "'frames'", ":", "self", ".", "env", ".", "k", ",", "\n", "\"actions\"", ":", "self", ".", "env", ".", "action_meanings", ",", "\n", "\"a\"", ":", "a", "\n", "}", "\n", "\n", "", "", "raise", "StopIteration", "", "", "", ""]], "home.repos.pwc.inspect_result.eladsar_rbi.None.main.main": [[8, 48], ["torch.set_num_threads", "print", "logger.logger.info", "logger.logger.info", "vars().items", "logger.logger.info", "logger.logger.info", "experiment.Experiment", "torch.get_num_threads", "vars", "logger.logger.info", "exp.learn", "str", "logger.logger.info", "exp.play", "logger.logger.info", "exp.evaluate", "logger.logger.info", "exp.multiplay", "logger.logger.info", "exp.postprocess", "logger.logger.info", "exp.clean"], "function", ["home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.learn", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.play", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.evaluate", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.multiplay", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.postprocess", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.clean"], ["def", "main", "(", ")", ":", "\n", "\n", "    ", "torch", ".", "set_num_threads", "(", "1000", ")", "\n", "print", "(", "\"Torch %d\"", "%", "torch", ".", "get_num_threads", "(", ")", ")", "\n", "# print args of current run", "\n", "logger", ".", "info", "(", "\"Welcome to Learning from Demonstration simulation\"", ")", "\n", "logger", ".", "info", "(", "' '", "*", "26", "+", "'Simulation Hyperparameters'", ")", "\n", "for", "k", ",", "v", "in", "vars", "(", "args", ")", ".", "items", "(", ")", ":", "\n", "        ", "logger", ".", "info", "(", "' '", "*", "26", "+", "k", "+", "': '", "+", "str", "(", "v", ")", ")", "\n", "\n", "", "with", "Experiment", "(", "logger", ".", "filename", ")", "as", "exp", ":", "\n", "\n", "        ", "if", "args", ".", "learn", ":", "\n", "            ", "logger", ".", "info", "(", "\"Enter RBI Learning Session, it might take a while\"", ")", "\n", "exp", ".", "learn", "(", ")", "\n", "\n", "", "elif", "args", ".", "play", ":", "\n", "            ", "logger", ".", "info", "(", "\"Evaluate final performance\"", ")", "\n", "exp", ".", "play", "(", ")", "\n", "\n", "", "elif", "args", ".", "evaluate", ":", "# elad", "\n", "            ", "logger", ".", "info", "(", "\"Enter RBI playing Session, I hope it goes well\"", ")", "\n", "exp", ".", "evaluate", "(", ")", "\n", "\n", "", "elif", "args", ".", "multiplay", ":", "\n", "            ", "logger", ".", "info", "(", "\"Start a multiplay Session\"", ")", "\n", "exp", ".", "multiplay", "(", ")", "\n", "\n", "", "elif", "args", ".", "postprocess", ":", "\n", "            ", "logger", ".", "info", "(", "\"Create pandas Dataframe\"", ")", "\n", "exp", ".", "postprocess", "(", ")", "\n", "\n", "", "elif", "args", ".", "clean", ":", "\n", "            ", "logger", ".", "info", "(", "\"Clean old trajectories\"", ")", "\n", "exp", ".", "clean", "(", ")", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "", "logger", ".", "info", "(", "\"End of simulation\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.ppo_agent.PPOAgent.__init__": [[31, 94], ["print", "agent.Agent.__init__", "model.BehavioralNet().to", "model.ValueNet().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "ppo_agent.PPOAgent.a_zeros.repeat", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "numpy.ones", "environment.Env", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "numpy.arange", "print", "os.path.join", "os.path.join", "os.path.join", "memory.ObservationsMemory", "memory.ObservationsBatchSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "ppo_agent.PPOAgent.value_net.parameters", "ppo_agent.PPOAgent.beta_net.parameters", "model.BehavioralNet", "model.ValueNet", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "os.mkdir", "os.mkdir", "os.mkdir", "os.mkdir", "os.mkdir", "os.mkdir", "os.mkdir", "os.mkdir", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.memory.ReplayBatchSampler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "root_dir", ",", "player", "=", "False", ",", "choose", "=", "False", ",", "checkpoint", "=", "None", ")", ":", "\n", "\n", "        ", "print", "(", "\"Learning with RBIAgent\"", ")", "\n", "super", "(", "PPOAgent", ",", "self", ")", ".", "__init__", "(", "root_dir", ",", "checkpoint", ")", "\n", "\n", "self", ".", "beta_net", "=", "BehavioralNet", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "value_net", "=", "ValueNet", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "pi_rand", "=", "np", ".", "ones", "(", "self", ".", "action_space", ")", "/", "self", ".", "action_space", "\n", "self", ".", "pi_rand_batch", "=", "torch", ".", "FloatTensor", "(", "self", ".", "pi_rand", ")", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "self", ".", "batch", ",", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "a_zeros", "=", "torch", ".", "zeros", "(", "1", ",", "1", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "a_zeros_batch", "=", "self", ".", "a_zeros", ".", "repeat", "(", "self", ".", "batch", ",", "1", ")", "\n", "\n", "if", "player", ":", "\n", "\n", "# play variables", "\n", "            ", "self", ".", "env", "=", "Env", "(", ")", "\n", "self", ".", "a_zeros", "=", "torch", ".", "zeros", "(", "1", ",", "1", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "trajectory", "=", "[", "]", "\n", "self", ".", "images", "=", "[", "]", "\n", "self", ".", "choices", "=", "np", ".", "arange", "(", "self", ".", "action_space", ",", "dtype", "=", "np", ".", "int", ")", "\n", "self", ".", "n_replay_saved", "=", "1", "\n", "self", ".", "frame", "=", "0", "\n", "self", ".", "states", "=", "0", "\n", "\n", "print", "(", "\"Explorer player\"", ")", "\n", "self", ".", "trajectory_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"trajectory\"", ")", "\n", "self", ".", "screen_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"screen\"", ")", "\n", "self", ".", "readlock", "=", "os", ".", "path", ".", "join", "(", "self", ".", "list_dir", ",", "\"readlock_explore.npy\"", ")", "\n", "\n", "", "else", ":", "\n", "\n", "# self.target_net = DuelNet().to(self.device)", "\n", "# datasets", "\n", "            ", "self", ".", "train_dataset", "=", "ObservationsMemory", "(", "root_dir", ")", "\n", "self", ".", "train_sampler", "=", "ObservationsBatchSampler", "(", "root_dir", ")", "\n", "self", ".", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "self", ".", "train_dataset", ",", "batch_sampler", "=", "self", ".", "train_sampler", ",", "\n", "num_workers", "=", "args", ".", "cpu_workers", ",", "pin_memory", "=", "True", ",", "drop_last", "=", "False", ")", "\n", "\n", "try", ":", "\n", "                ", "os", ".", "mkdir", "(", "self", ".", "best_player_dir", ")", "\n", "os", ".", "mkdir", "(", "self", ".", "exploit_dir", ")", "\n", "os", ".", "mkdir", "(", "self", ".", "explore_dir", ")", "\n", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "exploit_dir", ",", "\"trajectory\"", ")", ")", "\n", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "exploit_dir", ",", "\"screen\"", ")", ")", "\n", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"trajectory\"", ")", ")", "\n", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"screen\"", ")", ")", "\n", "os", ".", "mkdir", "(", "self", ".", "list_dir", ")", "\n", "np", ".", "save", "(", "self", ".", "writelock", ",", "0", ")", "\n", "np", ".", "save", "(", "self", ".", "episodelock", ",", "0", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "self", ".", "list_dir", ",", "\"readlock_explore.npy\"", ")", ",", "[", "]", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "self", ".", "list_dir", ",", "\"readlock_exploit.npy\"", ")", ",", "[", "]", ")", "\n", "", "except", "FileExistsError", ":", "\n", "                ", "pass", "\n", "\n", "# configure learning", "\n", "\n", "# IT IS IMPORTANT TO ASSIGN MODEL TO CUDA/PARALLEL BEFORE DEFINING OPTIMIZER", "\n", "", "", "self", ".", "optimizer_value", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "value_net", ".", "parameters", "(", ")", ",", "lr", "=", "0.00025", "/", "4", ",", "eps", "=", "1.5e-4", ",", "weight_decay", "=", "0", ")", "\n", "self", ".", "optimizer_beta", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "beta_net", ".", "parameters", "(", ")", ",", "lr", "=", "0.00025", "/", "4", ",", "eps", "=", "1.5e-4", ",", "weight_decay", "=", "0", ")", "\n", "\n", "self", ".", "n_offset", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.ppo_agent.PPOAgent.save_checkpoint": [[95, 104], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "ppo_agent.PPOAgent.beta_net.state_dict", "ppo_agent.PPOAgent.value_net.state_dict", "ppo_agent.PPOAgent.optimizer_value.state_dict", "ppo_agent.PPOAgent.optimizer_beta.state_dict"], "methods", ["None"], ["", "def", "save_checkpoint", "(", "self", ",", "path", ",", "aux", "=", "None", ")", ":", "\n", "\n", "        ", "state", "=", "{", "'beta_net'", ":", "self", ".", "beta_net", ".", "state_dict", "(", ")", ",", "\n", "'value_net'", ":", "self", ".", "value_net", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_value'", ":", "self", ".", "optimizer_value", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_beta'", ":", "self", ".", "optimizer_beta", ".", "state_dict", "(", ")", ",", "\n", "'aux'", ":", "aux", "}", "\n", "\n", "torch", ".", "save", "(", "state", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.ppo_agent.PPOAgent.load_checkpoint": [[105, 120], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "ppo_agent.PPOAgent.beta_net.load_state_dict", "ppo_agent.PPOAgent.value_net.load_state_dict", "ppo_agent.PPOAgent.optimizer_beta.load_state_dict", "ppo_agent.PPOAgent.optimizer_value.load_state_dict"], "methods", ["None"], ["", "def", "load_checkpoint", "(", "self", ",", "path", ")", ":", "\n", "\n", "        ", "state", "=", "torch", ".", "load", "(", "path", ",", "map_location", "=", "\"cuda:%d\"", "%", "self", ".", "cuda_id", ")", "\n", "\n", "self", ".", "beta_net", ".", "load_state_dict", "(", "state", "[", "'beta_net'", "]", ")", "\n", "self", ".", "value_net", ".", "load_state_dict", "(", "state", "[", "'value_net'", "]", ")", "\n", "self", ".", "optimizer_beta", ".", "load_state_dict", "(", "state", "[", "'optimizer_beta'", "]", ")", "\n", "self", ".", "optimizer_value", ".", "load_state_dict", "(", "state", "[", "'optimizer_value'", "]", ")", "\n", "self", ".", "n_offset", "=", "state", "[", "'aux'", "]", "[", "'n'", "]", "\n", "try", ":", "\n", "            ", "self", ".", "behavioral_avg_score", "=", "state", "[", "'aux'", "]", "[", "'score'", "]", "\n", "", "except", ":", "\n", "            ", "pass", "\n", "\n", "", "return", "state", "[", "'aux'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.ppo_agent.PPOAgent.learn": [[121, 225], ["ppo_agent.PPOAgent.beta_net.train", "ppo_agent.PPOAgent.value_net.train", "tqdm.tqdm.tqdm", "enumerate", "sample[].to", "sample[].to().unsqueeze_", "sample[].to", "sample[].to", "sample[].to", "sample[].to", "ppo_agent.PPOAgent.beta_net", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "ppo_agent.PPOAgent.value_net", "v.squeeze.squeeze.squeeze", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "ppo_agent.PPOAgent.optimizer_beta.zero_grad", "loss_beta.backward", "ppo_agent.PPOAgent.optimizer_beta.step", "ppo_agent.PPOAgent.optimizer_value.zero_grad", "loss_value.backward", "ppo_agent.PPOAgent.optimizer_value.step", "a[].data.cpu().numpy", "pi.clamp.clamp.clamp", "pi.clamp.clamp.sum().unsqueeze().repeat", "pi.clamp.clamp.log", "torch.nn.functional.softmax().detach", "torch.nn.functional.softmax().detach", "torch.nn.functional.softmax().detach", "torch.nn.functional.softmax().detach", "numpy.ones", "numpy.ones", "r.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "torch.nn.functional.softmax().detach.data.cpu().max", "beta_index.numpy.numpy.numpy", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "sample[].to", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.min.mean", "torch.min.mean", "torch.min.mean", "torch.min.mean", "Hbeta.mean", "Hbeta.data.mean().cpu().numpy", "Hpi.data.mean().cpu().numpy", "loss_beta.data.cpu().numpy", "loss_value.data.cpu().numpy", "ppo_agent.PPOAgent.save_checkpoint", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "ppo_agent.PPOAgent.beta_net.train", "ppo_agent.PPOAgent.value_net.train", "a[].data.cpu", "pi.clamp.clamp.sum().unsqueeze", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "r.data.cpu().numpy.data.cpu().numpy.data.cpu", "torch.nn.functional.softmax().detach.data.cpu", "Hbeta.data.mean().cpu", "Hpi.data.mean().cpu", "loss_beta.data.cpu", "loss_value.data.cpu", "pi.clamp.clamp.sum", "Hbeta.data.mean", "Hpi.data.mean"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.train", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.train", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.save_checkpoint", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.train", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.train"], ["", "def", "learn", "(", "self", ",", "n_interval", ",", "n_tot", ")", ":", "\n", "\n", "        ", "self", ".", "beta_net", ".", "train", "(", ")", "\n", "self", ".", "value_net", ".", "train", "(", ")", "\n", "\n", "results", "=", "{", "'n'", ":", "[", "]", ",", "'loss_value'", ":", "[", "]", ",", "'loss_beta'", ":", "[", "]", ",", "'act_diff'", ":", "[", "]", ",", "'a_agent'", ":", "[", "]", ",", "\n", "'a_player'", ":", "[", "]", ",", "'loss_std'", ":", "[", "]", ",", "'mc_val'", ":", "[", "]", ",", "\"Hbeta\"", ":", "[", "]", ",", "\"Hpi\"", ":", "[", "]", ",", "\"adv_a\"", ":", "[", "]", ",", "\"q_a\"", ":", "[", "]", "}", "\n", "\n", "# tic = time.time()", "\n", "\n", "for", "n", ",", "sample", "in", "tqdm", "(", "enumerate", "(", "self", ".", "train_loader", ")", ")", ":", "\n", "\n", "            ", "s", "=", "sample", "[", "'s'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "a", "=", "sample", "[", "'a'", "]", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze_", "(", "1", ")", "\n", "r", "=", "sample", "[", "'r'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "rho", "=", "sample", "[", "'rho'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "pi", "=", "sample", "[", "'pi'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "aux", "=", "sample", "[", "'aux'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# Behavioral nets", "\n", "beta", "=", "self", ".", "beta_net", "(", "s", ",", "aux", ")", "\n", "beta_log", "=", "F", ".", "log_softmax", "(", "beta", ",", "dim", "=", "1", ")", "\n", "beta_soft", "=", "F", ".", "softmax", "(", "beta", ",", "dim", "=", "1", ")", "\n", "\n", "v", "=", "self", ".", "value_net", "(", "s", ",", "aux", ")", "\n", "\n", "v", "=", "v", ".", "squeeze", "(", "1", ")", "\n", "loss_value", "=", "(", "(", "v", "-", "r", ")", "**", "2", ")", ".", "mean", "(", ")", "\n", "\n", "rt", "=", "(", "beta_soft", "/", "pi", ")", ".", "gather", "(", "1", ",", "a", ")", "\n", "ppo_objective", "=", "torch", ".", "min", "(", "rt", "*", "rho", ",", "rho", "*", "torch", ".", "clamp", "(", "rt", ",", "min", "=", "1", "-", "self", ".", "ppo_eps", ",", "max", "=", "1", "+", "self", ".", "ppo_eps", ")", ")", "\n", "\n", "Hbeta", "=", "-", "(", "beta_soft", "*", "beta_log", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n", "loss_beta", "=", "-", "ppo_objective", ".", "mean", "(", ")", "-", "0.01", "*", "Hbeta", ".", "mean", "(", ")", "# Learning part", "\n", "\n", "self", ".", "optimizer_beta", ".", "zero_grad", "(", ")", "\n", "loss_beta", ".", "backward", "(", ")", "\n", "self", ".", "optimizer_beta", ".", "step", "(", ")", "\n", "\n", "self", ".", "optimizer_value", ".", "zero_grad", "(", ")", "\n", "loss_value", ".", "backward", "(", ")", "\n", "self", ".", "optimizer_value", ".", "step", "(", ")", "\n", "\n", "# collect actions statistics", "\n", "\n", "if", "not", "(", "n", "+", "1", "+", "self", ".", "n_offset", ")", "%", "50", ":", "\n", "\n", "                ", "a_index_np", "=", "a", "[", ":", ",", "0", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# avoid zero pi", "\n", "pi", "=", "pi", ".", "clamp", "(", "min", "=", "1e-4", ",", "max", "=", "1", ")", "\n", "pi", "/=", "pi", ".", "sum", "(", "dim", "=", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "self", ".", "action_space", ")", "\n", "\n", "pi_log", "=", "pi", ".", "log", "(", ")", "\n", "beta_soft", "=", "F", ".", "softmax", "(", "beta", ",", "dim", "=", "1", ")", ".", "detach", "(", ")", "\n", "\n", "Hpi", "=", "-", "(", "pi", "*", "pi_log", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "Hbeta", "=", "-", "(", "beta_soft", "*", "beta_log", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n", "adv_a", "=", "np", ".", "ones", "(", "self", ".", "batch", ")", "\n", "q_a", "=", "np", ".", "ones", "(", "self", ".", "batch", ")", "\n", "r", "=", "r", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "_", ",", "beta_index", "=", "beta_soft", ".", "data", ".", "cpu", "(", ")", ".", "max", "(", "1", ")", "\n", "beta_index", "=", "beta_index", ".", "numpy", "(", ")", "\n", "act_diff", "=", "(", "a_index_np", "!=", "beta_index", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "# add results", "\n", "\n", "results", "[", "'act_diff'", "]", ".", "append", "(", "act_diff", ")", "\n", "results", "[", "'a_agent'", "]", ".", "append", "(", "beta_index", ")", "\n", "results", "[", "'adv_a'", "]", ".", "append", "(", "adv_a", ")", "\n", "results", "[", "'q_a'", "]", ".", "append", "(", "q_a", ")", "\n", "results", "[", "'a_player'", "]", ".", "append", "(", "a_index_np", ")", "\n", "results", "[", "'Hbeta'", "]", ".", "append", "(", "Hbeta", ".", "data", ".", "mean", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "results", "[", "'Hpi'", "]", ".", "append", "(", "Hpi", ".", "data", ".", "mean", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "results", "[", "'mc_val'", "]", ".", "append", "(", "r", ")", "\n", "\n", "# add results", "\n", "results", "[", "'loss_beta'", "]", ".", "append", "(", "loss_beta", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "results", "[", "'loss_value'", "]", ".", "append", "(", "loss_value", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "results", "[", "'loss_std'", "]", ".", "append", "(", "0", ")", "\n", "results", "[", "'n'", "]", ".", "append", "(", "n", ")", "\n", "\n", "if", "not", "(", "n", "+", "1", "+", "self", ".", "n_offset", ")", "%", "self", ".", "update_memory_interval", ":", "\n", "# save agent state", "\n", "                    ", "self", ".", "save_checkpoint", "(", "self", ".", "snapshot_path", ",", "{", "'n'", ":", "self", ".", "n_offset", "+", "n", "+", "1", "}", ")", "\n", "\n", "", "if", "not", "(", "n", "+", "1", "+", "self", ".", "n_offset", ")", "%", "n_interval", ":", "\n", "                    ", "results", "[", "'act_diff'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'act_diff'", "]", ")", "\n", "results", "[", "'a_agent'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'a_agent'", "]", ")", "\n", "results", "[", "'adv_a'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'adv_a'", "]", ")", "\n", "results", "[", "'q_a'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'q_a'", "]", ")", "\n", "results", "[", "'a_player'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'a_player'", "]", ")", "\n", "results", "[", "'mc_val'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'mc_val'", "]", ")", "\n", "\n", "yield", "results", "\n", "self", ".", "beta_net", ".", "train", "(", ")", "\n", "self", ".", "value_net", ".", "train", "(", ")", "\n", "results", "=", "{", "key", ":", "[", "]", "for", "key", "in", "results", "}", "\n", "\n", "if", "(", "n", "+", "self", ".", "n_offset", ")", ">=", "n_tot", ":", "\n", "                        ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.ppo_agent.PPOAgent.clean": [[226, 252], ["time.sleep", "os.path.join", "os.path.join", "set", "os.listdir", "numpy.load", "int", "shutil.rmtree", "os.path.join", "numpy.load", "os.remove", "os.path.join", "traj.split", "os.path.join", "set.add", "os.path.join", "str"], "methods", ["None"], ["", "", "", "", "", "def", "clean", "(", "self", ")", ":", "\n", "\n", "        ", "while", "True", ":", "\n", "\n", "            ", "time", ".", "sleep", "(", "2", ")", "\n", "\n", "screen_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"screen\"", ")", "\n", "trajectory_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"trajectory\"", ")", "\n", "\n", "try", ":", "\n", "                ", "del_inf", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "list_dir", ",", "\"old_explore.npy\"", ")", ")", "\n", "", "except", "(", "IOError", ",", "ValueError", ")", ":", "\n", "                ", "continue", "\n", "", "traj_min", "=", "del_inf", "[", "0", "]", "-", "32", "\n", "episode_list", "=", "set", "(", ")", "\n", "\n", "for", "traj", "in", "os", ".", "listdir", "(", "trajectory_dir", ")", ":", "\n", "                ", "traj_num", "=", "int", "(", "traj", ".", "split", "(", "\".\"", ")", "[", "0", "]", ")", "\n", "if", "traj_num", "<", "traj_min", ":", "\n", "                    ", "traj_data", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "trajectory_dir", ",", "traj", ")", ")", "\n", "for", "d", "in", "traj_data", ":", "\n", "                        ", "episode_list", ".", "add", "(", "d", "[", "'ep'", "]", ")", "\n", "", "os", ".", "remove", "(", "os", ".", "path", ".", "join", "(", "trajectory_dir", ",", "traj", ")", ")", "\n", "\n", "", "", "for", "ep", "in", "episode_list", ":", "\n", "                ", "shutil", ".", "rmtree", "(", "os", ".", "path", ".", "join", "(", "screen_dir", ",", "str", "(", "ep", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.ppo_agent.PPOAgent.play": [[253, 348], ["range", "ppo_agent.PPOAgent.env.reset", "ppo_agent.PPOAgent.beta_net.eval", "ppo_agent.PPOAgent.value_net.eval", "preprocess._get_mc_value", "numpy.array", "print", "ppo_agent.PPOAgent.env.s.to", "ppo_agent.PPOAgent.env.aux.to", "ppo_agent.PPOAgent.beta_net", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "ppo_agent.PPOAgent.value_net", "ppo_agent.PPOAgent.squeeze().data.cpu().numpy", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy", "beta.squeeze().data.cpu().numpy.copy.clip", "numpy.random.choice", "ppo_agent.PPOAgent.env.step", "ppo_agent.PPOAgent.load_checkpoint", "ppo_agent.PPOAgent.beta_net.eval", "ppo_agent.PPOAgent.value_net.eval", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.detach", "beta.squeeze().data.cpu().numpy.copy.sum", "rewards[].append", "v_target[].append", "numpy.array.append", "time.sleep", "ppo_agent.PPOAgent.load_checkpoint", "ppo_agent.PPOAgent.squeeze().data.cpu", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.copy", "rewards.append", "v_target.append", "str", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.copy", "ppo_agent.PPOAgent.squeeze", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.load_checkpoint", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.load_checkpoint"], ["", "", "", "def", "play", "(", "self", ",", "n_tot", ",", "save", "=", "True", ",", "load", "=", "True", ",", "fix", "=", "False", ")", ":", "\n", "\n", "        ", "for", "i", "in", "range", "(", "n_tot", ")", ":", "\n", "\n", "            ", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n", "rewards", "=", "[", "[", "]", "]", "\n", "v_target", "=", "[", "[", "]", "]", "\n", "q_val", "=", "[", "]", "\n", "lives", "=", "self", ".", "env", ".", "lives", "\n", "trigger", "=", "False", "\n", "\n", "while", "not", "fix", ":", "\n", "                ", "try", ":", "\n", "                    ", "self", ".", "load_checkpoint", "(", "self", ".", "snapshot_path", ")", "\n", "break", "\n", "", "except", ":", "\n", "                    ", "time", ".", "sleep", "(", "0.5", ")", "\n", "\n", "", "", "self", ".", "beta_net", ".", "eval", "(", ")", "\n", "self", ".", "value_net", ".", "eval", "(", ")", "\n", "\n", "while", "not", "self", ".", "env", ".", "t", ":", "\n", "\n", "                ", "if", "load", "and", "not", "(", "self", ".", "states", "%", "self", ".", "load_memory_interval", ")", ":", "\n", "                    ", "try", ":", "\n", "                        ", "self", ".", "load_checkpoint", "(", "self", ".", "snapshot_path", ")", "\n", "", "except", ":", "\n", "                        ", "pass", "\n", "\n", "", "self", ".", "beta_net", ".", "eval", "(", ")", "\n", "self", ".", "value_net", ".", "eval", "(", ")", "\n", "\n", "", "s", "=", "self", ".", "env", ".", "s", ".", "to", "(", "self", ".", "device", ")", "\n", "trigger", "=", "trigger", "or", "(", "self", ".", "env", ".", "score", ">", "self", ".", "behavioral_avg_score", "*", "self", ".", "explore_threshold", ")", "\n", "# get aux data", "\n", "aux", "=", "self", ".", "env", ".", "aux", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "beta", "=", "self", ".", "beta_net", "(", "s", ",", "aux", ")", "\n", "beta", "=", "F", ".", "softmax", "(", "beta", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# take q as adv", "\n", "\n", "v", "=", "self", ".", "value_net", "(", "s", ",", "aux", ")", "\n", "\n", "v_expected", "=", "v", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "beta", "=", "beta", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "self", ".", "n_offset", ">=", "self", ".", "random_initialization", ":", "\n", "\n", "                    ", "if", "self", ".", "player", "==", "\"reroutetv\"", ":", "\n", "\n", "                        ", "pi_mix", "=", "beta", ".", "copy", "(", ")", "\n", "\n", "", "elif", "self", ".", "player", "==", "\"behavioral\"", ":", "\n", "                        ", "pi_mix", "=", "beta", ".", "copy", "(", ")", "\n", "\n", "", "else", ":", "\n", "                        ", "raise", "NotImplementedError", "\n", "\n", "", "", "else", ":", "\n", "                    ", "pi_mix", "=", "self", ".", "pi_rand", "\n", "\n", "", "pi_mix", "=", "pi_mix", ".", "clip", "(", "0", ",", "1", ")", "\n", "pi_mix", "=", "pi_mix", "/", "pi_mix", ".", "sum", "(", ")", "\n", "a", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "choices", ",", "p", "=", "pi_mix", ")", "\n", "self", ".", "env", ".", "step", "(", "a", ")", "\n", "\n", "if", "self", ".", "env", ".", "k", ">=", "self", ".", "history_length", ":", "\n", "\n", "                    ", "if", "lives", ">", "self", ".", "env", ".", "lives", ":", "\n", "                        ", "rewards", ".", "append", "(", "[", "]", ")", "\n", "v_target", ".", "append", "(", "[", "]", ")", "\n", "", "lives", "=", "self", ".", "env", ".", "lives", "\n", "\n", "rewards", "[", "-", "1", "]", ".", "append", "(", "self", ".", "env", ".", "r", ")", "\n", "v_target", "[", "-", "1", "]", ".", "append", "(", "v_expected", ")", "\n", "q_val", ".", "append", "(", "0", ")", "\n", "\n", "", "self", ".", "frame", "+=", "1", "\n", "\n", "", "mc_val", "=", "_get_mc_value", "(", "rewards", ",", "None", ",", "self", ".", "discount", ",", "None", ")", "\n", "q_val", "=", "np", ".", "array", "(", "q_val", ")", "\n", "\n", "print", "(", "\"sts | st: %d\\t| sc: %d\\t| f: %d\\t| e: %7g\\t| typ: %2d | trg: %d | nst: %s\\t| n %d\\t| avg_r: %g\\t| avg_f: %g\"", "%", "\n", "(", "self", ".", "frame", ",", "self", ".", "env", ".", "score", ",", "self", ".", "env", ".", "k", ",", "0", ",", "0", ",", "0", ",", "str", "(", "np", ".", "nan", ")", ",", "\n", "self", ".", "n_offset", ",", "self", ".", "behavioral_avg_score", ",", "self", ".", "behavioral_avg_frame", ")", ")", "\n", "\n", "yield", "{", "'score'", ":", "self", ".", "env", ".", "score", ",", "\n", "'frames'", ":", "self", ".", "env", ".", "k", ",", "\"n\"", ":", "self", ".", "n_offset", ",", "\"mc\"", ":", "mc_val", ",", "\"q\"", ":", "q_val", "}", "\n", "\n", "if", "self", ".", "n_offset", ">=", "self", ".", "n_tot", "and", "not", "fix", ":", "\n", "                ", "break", "\n", "\n", "", "", "raise", "StopIteration", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.ppo_agent.PPOAgent.multiplay": [[349, 529], ["ppo_agent.PPOAgent.a_zeros.repeat", "numpy.repeat", "numpy.arange", "preprocess.lock_file", "numpy.load().item", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "range", "numpy.arange", "environment.Env", "numpy.expand_dims", "numpy.arange", "mp_env[].reset", "os.path.join", "os.mkdir", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to.cpu().numpy().astype", "torch.cat().to.cpu().numpy().astype", "torch.cat().to.cpu().numpy().astype", "torch.cat().to.cpu().numpy().astype", "ppo_agent.PPOAgent.beta_net", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "ppo_agent.PPOAgent.value_net", "beta.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "v_expected.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy", "numpy.logical_and", "beta.data.cpu().numpy.copy.astype", "range", "range", "range", "range", "range", "range", "range", "range", "os.path.join", "os.path.join", "os.path.join", "numpy.load", "str", "range", "ppo_agent.PPOAgent.beta_net.eval", "ppo_agent.PPOAgent.value_net.eval", "beta.data.cpu().numpy.data.cpu().numpy.detach", "beta.data.cpu().numpy.data.cpu().numpy.copy", "beta.data.cpu().numpy.copy.copy", "numpy.random.choice", "cv2.imwrite", "episode[].append", "env.step", "[].append", "[].append", "[].append", "ppo_agent.PPOAgent.load_checkpoint", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat().to.cpu().numpy", "torch.cat().to.cpu().numpy", "torch.cat().to.cpu().numpy", "torch.cat().to.cpu().numpy", "beta.data.cpu().numpy.data.cpu().numpy.data.cpu", "v_expected.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu", "numpy.array", "os.path.join", "rewards[].append", "v_target[].append", "rho[].append", "preprocess.get_expected_value", "preprocess.get_gae_est", "numpy.concatenate", "enumerate", "print", "env.reset", "preprocess.lock_file", "numpy.load().item", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "os.path.join", "os.mkdir", "int", "numpy.array", "str", "len", "torch.cat().to.cpu", "torch.cat().to.cpu", "torch.cat().to.cpu", "torch.cat().to.cpu", "str", "numpy.load", "preprocess.lock_file", "numpy.load().item", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "range", "os.path.join", "numpy.save", "preprocess.lock_file", "numpy.load", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "v_expected.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze", "numpy.sign", "psutil.virtual_memory", "len", "numpy.append", "time.time", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.load_checkpoint", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_gae_est", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file"], ["", "def", "multiplay", "(", "self", ")", ":", "\n", "\n", "        ", "n_players", "=", "self", ".", "n_players", "\n", "\n", "player_i", "=", "np", ".", "arange", "(", "self", ".", "actor_index", ",", "self", ".", "actor_index", "+", "self", ".", "n_actors", "*", "n_players", ",", "self", ".", "n_actors", ")", "/", "(", "self", ".", "n_actors", "*", "n_players", "-", "1", ")", "\n", "\n", "explore_threshold", "=", "player_i", "\n", "\n", "mp_explore", "=", "0.4", "**", "(", "1", "+", "7", "*", "(", "1", "-", "player_i", ")", ")", "\n", "\n", "mp_env", "=", "[", "Env", "(", ")", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "self", ".", "frame", "=", "0", "\n", "\n", "a_zeros_mp", "=", "self", ".", "a_zeros", ".", "repeat", "(", "n_players", ",", "1", ")", "\n", "mp_pi_rand", "=", "np", ".", "repeat", "(", "np", ".", "expand_dims", "(", "self", ".", "pi_rand", ",", "axis", "=", "0", ")", ",", "n_players", ",", "axis", "=", "0", ")", "\n", "\n", "range_players", "=", "np", ".", "arange", "(", "n_players", ")", "\n", "rewards", "=", "[", "[", "[", "]", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "v_target", "=", "[", "[", "[", "]", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "rho", "=", "[", "[", "[", "]", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "episode", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "image_dir", "=", "[", "''", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "trajectory", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "screen_dir", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"screen\"", ")", "]", "*", "n_players", "\n", "\n", "trajectory_dir", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"trajectory\"", ")", "]", "*", "n_players", "\n", "\n", "readlock", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "list_dir", ",", "\"readlock_explore.npy\"", ")", "]", "*", "n_players", "\n", "\n", "# set initial episodes number", "\n", "# lock read", "\n", "fwrite", "=", "lock_file", "(", "self", ".", "episodelock", ")", "\n", "current_num", "=", "np", ".", "load", "(", "fwrite", ")", ".", "item", "(", ")", "\n", "episode_num", "=", "current_num", "+", "np", ".", "arange", "(", "n_players", ")", "\n", "fwrite", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fwrite", ",", "current_num", "+", "n_players", ")", "\n", "# unlock file", "\n", "release_file", "(", "fwrite", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_players", ")", ":", "\n", "            ", "mp_env", "[", "i", "]", ".", "reset", "(", ")", "\n", "image_dir", "[", "i", "]", "=", "os", ".", "path", ".", "join", "(", "screen_dir", "[", "i", "]", ",", "str", "(", "episode_num", "[", "i", "]", ")", ")", "\n", "os", ".", "mkdir", "(", "image_dir", "[", "i", "]", ")", "\n", "\n", "", "lives", "=", "[", "mp_env", "[", "i", "]", ".", "lives", "for", "i", "in", "range", "(", "n_players", ")", "]", "\n", "\n", "while", "True", ":", "\n", "\n", "            ", "if", "not", "(", "self", ".", "frame", "%", "self", ".", "load_memory_interval", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "self", ".", "load_checkpoint", "(", "self", ".", "snapshot_path", ")", "\n", "", "except", ":", "\n", "                    ", "pass", "\n", "\n", "", "self", ".", "beta_net", ".", "eval", "(", ")", "\n", "self", ".", "value_net", ".", "eval", "(", ")", "\n", "\n", "", "s", "=", "torch", ".", "cat", "(", "[", "env", ".", "s", "for", "env", "in", "mp_env", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "aux", "=", "torch", ".", "cat", "(", "[", "env", ".", "aux", "for", "env", "in", "mp_env", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "aux_np", "=", "aux", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "beta", "=", "self", ".", "beta_net", "(", "s", ",", "aux", ")", "\n", "beta", "=", "F", ".", "softmax", "(", "beta", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", "\n", "\n", "v_expected", "=", "self", ".", "value_net", "(", "s", ",", "aux", ")", "\n", "\n", "beta", "=", "beta", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "v_expected", "=", "v_expected", ".", "squeeze", "(", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "mp_trigger", "=", "np", ".", "logical_and", "(", "\n", "np", ".", "array", "(", "[", "env", ".", "score", "for", "env", "in", "mp_env", "]", ")", ">=", "self", ".", "behavioral_avg_score", "*", "explore_threshold", ",", "\n", "explore_threshold", ">=", "0", ")", "\n", "\n", "if", "self", ".", "n_offset", ">=", "self", ".", "random_initialization", ":", "\n", "\n", "                ", "pi", "=", "beta", ".", "copy", "(", ")", "\n", "# const explore", "\n", "pi_mix", "=", "pi", ".", "copy", "(", ")", "\n", "\n", "", "else", ":", "\n", "                ", "pi", "=", "mp_pi_rand", "\n", "pi_mix", "=", "pi", "\n", "\n", "", "pi", "=", "pi", ".", "astype", "(", "np", ".", "float32", ")", "\n", "for", "i", "in", "range", "(", "n_players", ")", ":", "\n", "\n", "                ", "a", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "choices", ",", "p", "=", "pi_mix", "[", "i", "]", ")", "\n", "\n", "env", "=", "mp_env", "[", "i", "]", "\n", "cv2", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "image_dir", "[", "i", "]", ",", "\"%s.png\"", "%", "str", "(", "self", ".", "frame", ")", ")", ",", "mp_env", "[", "i", "]", ".", "image", ",", "[", "imcompress", ",", "compress_level", "]", ")", "\n", "episode", "[", "i", "]", ".", "append", "(", "{", "\"fr\"", ":", "self", ".", "frame", ",", "\"a\"", ":", "a", ",", "\"r\"", ":", "0", ",", "\"pi\"", ":", "pi", "[", "i", "]", ",", "\"rho\"", ":", "0", ",", "\n", "\"aux\"", ":", "aux_np", "[", "i", "]", ",", "\"ep\"", ":", "episode_num", "[", "i", "]", ",", "\"t\"", ":", "0", "}", ")", "\n", "\n", "env", ".", "step", "(", "a", ")", "\n", "\n", "if", "lives", "[", "i", "]", ">", "env", ".", "lives", ":", "\n", "                    ", "rewards", "[", "i", "]", ".", "append", "(", "[", "]", ")", "\n", "v_target", "[", "i", "]", ".", "append", "(", "[", "]", ")", "\n", "rho", "[", "i", "]", ".", "append", "(", "[", "]", ")", "\n", "", "lives", "[", "i", "]", "=", "env", ".", "lives", "\n", "\n", "rewards", "[", "i", "]", "[", "-", "1", "]", ".", "append", "(", "env", ".", "r", ")", "\n", "v_target", "[", "i", "]", "[", "-", "1", "]", ".", "append", "(", "v_expected", "[", "i", "]", ")", "\n", "rho", "[", "i", "]", "[", "-", "1", "]", ".", "append", "(", "pi", "[", "i", "]", "[", "a", "]", "/", "pi_mix", "[", "i", "]", "[", "a", "]", ")", "\n", "\n", "if", "env", ".", "t", ":", "\n", "\n", "# cancel termination reward", "\n", "                    ", "rewards", "[", "i", "]", "[", "-", "1", "]", "[", "-", "1", "]", "-=", "self", ".", "termination_reward", "*", "int", "(", "env", ".", "k", "*", "self", ".", "skip", ">=", "self", ".", "max_length", "or", "env", ".", "score", ">=", "self", ".", "max_score", ")", "\n", "td_val", "=", "get_expected_value", "(", "rewards", "[", "i", "]", ",", "v_target", "[", "i", "]", ",", "self", ".", "discount", ",", "self", ".", "n_steps", ")", "\n", "rho_val", "=", "get_gae_est", "(", "rewards", "[", "i", "]", ",", "v_target", "[", "i", "]", ",", "self", ".", "discount", ")", "\n", "\n", "rho_vec", "=", "np", ".", "concatenate", "(", "rho", "[", "i", "]", ")", "\n", "for", "j", ",", "record", "in", "enumerate", "(", "episode", "[", "i", "]", ")", ":", "\n", "                        ", "record", "[", "'r'", "]", "=", "td_val", "[", "j", "]", "\n", "# record['rho'] = rho_val[j]", "\n", "record", "[", "'rho'", "]", "=", "np", ".", "array", "(", "[", "rho_vec", "[", "j", "]", ",", "rho_val", "[", "j", "]", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "trajectory", "[", "i", "]", "+=", "episode", "[", "i", "]", "[", "self", ".", "history_length", "-", "1", ":", "self", ".", "max_length", "]", "\n", "\n", "print", "(", "\"rbi | st: %d\\t| sc: %d\\t| f: %d\\t| e: %7g\\t| typ: %2d | trg: %d | t: %d\\t| n %d\\t| avg_r: %g\\t| avg_f: %g\"", "%", "\n", "(", "self", ".", "frame", ",", "env", ".", "score", ",", "env", ".", "k", ",", "mp_explore", "[", "i", "]", ",", "np", ".", "sign", "(", "explore_threshold", "[", "i", "]", ")", ",", "mp_trigger", "[", "i", "]", ",", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", ",", "self", ".", "n_offset", ",", "self", ".", "behavioral_avg_score", ",", "self", ".", "behavioral_avg_frame", ")", ")", "\n", "\n", "env", ".", "reset", "(", ")", "\n", "episode", "[", "i", "]", "=", "[", "]", "\n", "rewards", "[", "i", "]", "=", "[", "[", "]", "]", "\n", "v_target", "[", "i", "]", "=", "[", "[", "]", "]", "\n", "lives", "[", "i", "]", "=", "env", ".", "lives", "\n", "mp_trigger", "[", "i", "]", "=", "0", "\n", "\n", "# get new episode number", "\n", "\n", "# lock read", "\n", "fwrite", "=", "lock_file", "(", "self", ".", "episodelock", ")", "\n", "episode_num", "[", "i", "]", "=", "np", ".", "load", "(", "fwrite", ")", ".", "item", "(", ")", "\n", "fwrite", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fwrite", ",", "episode_num", "[", "i", "]", "+", "1", ")", "\n", "# unlock file", "\n", "release_file", "(", "fwrite", ")", "\n", "\n", "image_dir", "[", "i", "]", "=", "os", ".", "path", ".", "join", "(", "screen_dir", "[", "i", "]", ",", "str", "(", "episode_num", "[", "i", "]", ")", ")", "\n", "os", ".", "mkdir", "(", "image_dir", "[", "i", "]", ")", "\n", "\n", "if", "len", "(", "trajectory", "[", "i", "]", ")", ">=", "self", ".", "player_replay_size", ":", "\n", "\n", "# write if enough space is available", "\n", "                        ", "if", "psutil", ".", "virtual_memory", "(", ")", ".", "available", ">=", "mem_threshold", ":", "\n", "\n", "# lock read", "\n", "                            ", "fwrite", "=", "lock_file", "(", "self", ".", "writelock", ")", "\n", "traj_num", "=", "np", ".", "load", "(", "fwrite", ")", ".", "item", "(", ")", "\n", "fwrite", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fwrite", ",", "traj_num", "+", "1", ")", "\n", "# unlock file", "\n", "release_file", "(", "fwrite", ")", "\n", "\n", "traj_to_save", "=", "trajectory", "[", "i", "]", "\n", "\n", "for", "j", "in", "range", "(", "len", "(", "traj_to_save", ")", ")", ":", "\n", "                                ", "traj_to_save", "[", "j", "]", "[", "'traj'", "]", "=", "traj_num", "\n", "\n", "", "traj_file", "=", "os", ".", "path", ".", "join", "(", "trajectory_dir", "[", "i", "]", ",", "\"%d.npy\"", "%", "traj_num", ")", "\n", "\n", "np", ".", "save", "(", "traj_file", ",", "traj_to_save", ")", "\n", "\n", "fread", "=", "lock_file", "(", "readlock", "[", "i", "]", ")", "\n", "traj_list", "=", "np", ".", "load", "(", "fread", ")", "\n", "fread", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fread", ",", "np", ".", "append", "(", "traj_list", ",", "traj_num", ")", ")", "\n", "release_file", "(", "fread", ")", "\n", "\n", "", "trajectory", "[", "i", "]", "=", "[", "]", "\n", "\n", "# write trajectory to dir", "\n", "\n", "", "", "", "self", ".", "frame", "+=", "1", "\n", "if", "not", "self", ".", "frame", "%", "self", ".", "player_replay_size", ":", "\n", "                ", "yield", "True", "\n", "if", "self", ".", "n_offset", ">=", "self", ".", "n_tot", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.ppo_agent.PPOAgent.set_player": [[530, 568], ["os.path.join", "os.path.join", "os.path.join", "max"], "methods", ["None"], ["", "", "", "", "def", "set_player", "(", "self", ",", "player", ",", "cmin", "=", "None", ",", "cmax", "=", "None", ",", "delta", "=", "None", ",", "eps_pre", "=", "None", ",", "\n", "eps_post", "=", "None", ",", "temp_soft", "=", "None", ",", "behavioral_avg_score", "=", "None", ",", "\n", "behavioral_avg_frame", "=", "None", ",", "explore_threshold", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "player", "=", "player", "\n", "\n", "if", "eps_pre", "is", "not", "None", ":", "\n", "            ", "self", ".", "eps_pre", "=", "eps_pre", "*", "self", ".", "action_space", "/", "(", "self", ".", "action_space", "-", "1", ")", "\n", "\n", "", "if", "eps_post", "is", "not", "None", ":", "\n", "            ", "self", ".", "eps_post", "=", "eps_post", "*", "self", ".", "action_space", "/", "(", "self", ".", "action_space", "-", "1", ")", "\n", "\n", "", "if", "temp_soft", "is", "not", "None", ":", "\n", "            ", "self", ".", "temp_soft", "=", "temp_soft", "\n", "\n", "", "if", "cmin", "is", "not", "None", ":", "\n", "            ", "self", ".", "cmin", "=", "cmin", "\n", "\n", "", "if", "cmax", "is", "not", "None", ":", "\n", "            ", "self", ".", "cmax", "=", "cmax", "\n", "\n", "", "if", "delta", "is", "not", "None", ":", "\n", "            ", "self", ".", "delta", "=", "delta", "\n", "\n", "", "if", "explore_threshold", "is", "not", "None", ":", "\n", "            ", "self", ".", "explore_threshold", "=", "explore_threshold", "\n", "\n", "", "if", "behavioral_avg_score", "is", "not", "None", ":", "\n", "            ", "self", ".", "behavioral_avg_score", "=", "behavioral_avg_score", "\n", "\n", "", "if", "behavioral_avg_frame", "is", "not", "None", ":", "\n", "            ", "self", ".", "behavioral_avg_frame", "=", "behavioral_avg_frame", "\n", "\n", "", "self", ".", "off", "=", "True", "if", "max", "(", "self", ".", "eps_post", ",", "self", ".", "eps_pre", ")", ">", "0", "else", "False", "\n", "\n", "self", ".", "trajectory_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"trajectory\"", ")", "\n", "self", ".", "screen_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"screen\"", ")", "\n", "self", ".", "readlock", "=", "os", ".", "path", ".", "join", "(", "self", ".", "list_dir", ",", "\"readlock_explore.npy\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.ppo_agent.PPOAgent.demonstrate": [[570, 669], ["ppo_agent.PPOAgent.beta_net.eval", "ppo_agent.PPOAgent.value_net.eval", "range", "os.mkdir", "ppo_agent.PPOAgent.env.reset", "numpy.arange", "socket.gethostname", "os.path.join", "os.path.join", "ppo_agent.PPOAgent.env.s.to", "ppo_agent.PPOAgent.env.aux.to", "ppo_agent.PPOAgent.beta_net", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "ppo_agent.PPOAgent.value_net", "v.squeeze.squeeze.squeeze", "adv.squeeze.squeeze.squeeze", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy", "beta.data.cpu().numpy.data.cpu().numpy.squeeze", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "beta.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "beta.data.cpu().numpy.copy.clip", "numpy.random.choice", "ppo_agent.PPOAgent.env.step", "ppo_agent.PPOAgent.squeeze().data[].cpu().numpy", "cv2.imwrite", "beta.data.cpu().numpy.data.cpu().numpy.sum", "beta.data.cpu().numpy.data.cpu().numpy.copy", "adv.squeeze.squeeze.copy", "numpy.argsort", "numpy.argsort().astype", "beta.data.cpu().numpy.copy.sum", "numpy.rollaxis", "os.path.join", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu", "beta.data.cpu().numpy.data.cpu().numpy.data.cpu", "numpy.argmax", "numpy.min", "numpy.logical_or", "numpy.sum", "ppo_agent.PPOAgent.squeeze().data[].cpu", "v.squeeze.squeeze.data.cpu().numpy", "ppo_agent.PPOAgent.squeeze().data.cpu().numpy", "adv.squeeze.squeeze.data.cpu().numpy", "numpy.argsort", "v.squeeze.squeeze.data.cpu", "ppo_agent.PPOAgent.squeeze().data.cpu", "adv.squeeze.squeeze.data.cpu", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze", "ppo_agent.PPOAgent.squeeze", "ppo_agent.PPOAgent.squeeze"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step"], ["", "def", "demonstrate", "(", "self", ",", "n_tot", ")", ":", "\n", "\n", "        ", "self", ".", "beta_net", ".", "eval", "(", ")", "\n", "self", ".", "value_net", ".", "eval", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_tot", ")", ":", "\n", "\n", "            ", "if", "\"gpu\"", "in", "socket", ".", "gethostname", "(", ")", ":", "\n", "                ", "log_dir", "=", "os", ".", "path", ".", "join", "(", "\"/home/dsi/elad/data/rbi/runs\"", ",", "\"%s_%d\"", "%", "(", "consts", ".", "exptime", ",", "i", ")", ")", "\n", "", "else", ":", "\n", "                ", "log_dir", "=", "os", ".", "path", ".", "join", "(", "\"/tmp\"", ",", "\"%s_%d\"", "%", "(", "consts", ".", "exptime", ",", "i", ")", ")", "\n", "\n", "", "os", ".", "mkdir", "(", "log_dir", ")", "\n", "\n", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n", "# here there is a problem when there is a varying/increasing life counter as in mspacman", "\n", "\n", "choices", "=", "np", ".", "arange", "(", "self", ".", "action_space", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "while", "not", "self", ".", "env", ".", "t", ":", "\n", "\n", "                ", "s", "=", "self", ".", "env", ".", "s", ".", "to", "(", "self", ".", "device", ")", "\n", "aux", "=", "self", ".", "env", ".", "aux", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "beta", "=", "self", ".", "beta_net", "(", "s", ",", "aux", ")", "\n", "\n", "beta_softmax", "=", "F", ".", "softmax", "(", "beta", ",", "dim", "=", "1", ")", "\n", "\n", "v", ",", "adv", ",", "_", ",", "q", ",", "_", "=", "self", ".", "value_net", "(", "s", ",", "self", ".", "a_zeros", ",", "beta_softmax", ",", "aux", ")", "\n", "v", "=", "v", ".", "squeeze", "(", "0", ")", "\n", "adv", "=", "adv", ".", "squeeze", "(", "0", ")", "\n", "q", "=", "q", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "beta", "=", "beta", ".", "squeeze", "(", "0", ")", "\n", "beta", "=", "F", ".", "softmax", "(", "beta", ",", "dim", "=", "0", ")", "\n", "\n", "beta", "=", "torch", ".", "clamp", "(", "(", "beta", "-", "self", ".", "entropy_loss", "/", "self", ".", "action_space", ")", "/", "(", "1", "-", "self", ".", "entropy_loss", ")", ",", "\n", "self", ".", "eps_pre", "/", "self", ".", "action_space", ",", "1", "-", "self", ".", "eps_pre", ")", "\n", "\n", "beta", "=", "beta", "/", "beta", ".", "sum", "(", ")", "\n", "beta", "=", "beta", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "\n", "if", "False", ":", "\n", "\n", "                    ", "pi", "=", "beta", ".", "copy", "(", ")", "\n", "adv2", "=", "adv", ".", "copy", "(", ")", "\n", "\n", "rank", "=", "np", ".", "argsort", "(", "adv2", ")", "\n", "adv_rank", "=", "np", ".", "argsort", "(", "rank", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "\n", "pi", "=", "self", ".", "cmin", "*", "pi", "\n", "\n", "Delta", "=", "1", "-", "self", ".", "cmin", "\n", "while", "Delta", ">", "0", ":", "\n", "                        ", "a", "=", "np", ".", "argmax", "(", "adv2", ")", "\n", "Delta_a", "=", "np", ".", "min", "(", "(", "Delta", ",", "(", "self", ".", "cmax", "-", "self", ".", "cmin", ")", "*", "beta", "[", "a", "]", ")", ")", "\n", "Delta", "-=", "Delta_a", "\n", "pi", "[", "a", "]", "+=", "Delta_a", "\n", "adv2", "[", "a", "]", "=", "-", "1e11", "\n", "\n", "# pi_adv = 2 ** adv_rank * np.logical_or(adv2 >= 0, adv_rank == (self.action_space - 1))", "\n", "", "pi_adv", "=", "1.", "*", "np", ".", "logical_or", "(", "adv", ">=", "0", ",", "adv_rank", "==", "(", "self", ".", "action_space", "-", "1", ")", ")", "\n", "pi_adv", "=", "pi_adv", "/", "(", "np", ".", "sum", "(", "pi_adv", ")", ")", "\n", "\n", "pi", "=", "(", "1", "-", "self", ".", "mix", ")", "*", "pi", "+", "self", ".", "mix", "*", "pi_adv", "\n", "pi_mix", "=", "self", ".", "eps_pre", "*", "self", ".", "pi_rand", "+", "(", "1", "-", "self", ".", "eps_pre", ")", "*", "pi", "\n", "\n", "", "else", ":", "\n", "                    ", "pi", "=", "beta", "\n", "\n", "", "pi", "=", "pi", ".", "clip", "(", "0", ",", "1", ")", "\n", "pi", "=", "pi", "/", "pi", ".", "sum", "(", ")", "\n", "\n", "a", "=", "np", ".", "random", ".", "choice", "(", "choices", ",", "p", "=", "pi", ")", "\n", "self", ".", "env", ".", "step", "(", "a", ")", "\n", "\n", "# time.sleep(0.1)", "\n", "\n", "img", "=", "s", ".", "squeeze", "(", "0", ")", ".", "data", "[", ":", "3", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "img", "=", "np", ".", "rollaxis", "(", "img", ",", "0", ",", "3", ")", "[", ":", ",", ":", ",", ":", "3", "]", "\n", "img", "=", "(", "img", "*", "256", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "cv2", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"%d_%d_%d.png\"", "%", "(", "self", ".", "env", ".", "k", ",", "a", ",", "self", ".", "env", ".", "score", ")", ")", ",", "img", ")", "\n", "\n", "yield", "{", "'score'", ":", "self", ".", "env", ".", "score", ",", "\n", "\"beta\"", ":", "pi", ",", "\n", "\"v\"", ":", "v", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "\"q\"", ":", "q", ",", "\n", "\"aux\"", ":", "aux", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "\"adv\"", ":", "adv", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "\"o\"", ":", "img", ",", "\n", "'frames'", ":", "self", ".", "env", ".", "k", ",", "\n", "\"actions\"", ":", "self", ".", "env", ".", "action_meanings", ",", "\n", "\"a\"", ":", "a", "\n", "}", "\n", "\n", "", "", "raise", "StopIteration", "", "", "", ""]], "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_agent.RBIAgent.__init__": [[29, 82], ["print", "agent.Agent.__init__", "model.BehavioralNet", "model.DuelNet", "model.DuelNet", "rbi_agent.RBIAgent.beta_net.to", "rbi_agent.RBIAgent.value_net.to", "rbi_agent.RBIAgent.target_net.to", "rbi_agent.RBIAgent.target_net.load_state_dict", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "rbi_agent.RBIAgent.a_zeros.repeat", "torch.SmoothL1Loss", "torch.SmoothL1Loss", "torch.SmoothL1Loss", "torch.SmoothL1Loss", "torch.SmoothL1Loss", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "torch.DataParallel", "rbi_agent.RBIAgent.value_net.state_dict", "numpy.ones", "environment.Env", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "numpy.arange", "memory.Memory", "memory.ReplayBatchSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "rbi_agent.RBIAgent.value_net.parameters", "rbi_agent.RBIAgent.beta_net.parameters", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.memory.ReplayBatchSampler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "root_dir", ",", "player", "=", "False", ",", "choose", "=", "False", ",", "checkpoint", "=", "None", ")", ":", "\n", "\n", "        ", "print", "(", "\"Learning with RBIAgent\"", ")", "\n", "super", "(", "RBIAgent", ",", "self", ")", ".", "__init__", "(", "root_dir", ",", "checkpoint", ",", "player", ")", "\n", "\n", "self", ".", "beta_net", "=", "BehavioralNet", "(", ")", "\n", "self", ".", "value_net", "=", "DuelNet", "(", ")", "\n", "self", ".", "target_net", "=", "DuelNet", "(", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", ":", "\n", "            ", "self", ".", "beta_net", "=", "nn", ".", "DataParallel", "(", "self", ".", "beta_net", ")", "\n", "self", ".", "value_net", "=", "nn", ".", "DataParallel", "(", "self", ".", "value_net", ")", "\n", "self", ".", "target_net", "=", "nn", ".", "DataParallel", "(", "self", ".", "target_net", ")", "\n", "\n", "", "self", ".", "beta_net", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "value_net", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "target_net", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "target_net", ".", "load_state_dict", "(", "self", ".", "value_net", ".", "state_dict", "(", ")", ")", "\n", "\n", "self", ".", "pi_rand", "=", "np", ".", "ones", "(", "self", ".", "action_space", ")", "/", "self", ".", "action_space", "\n", "self", ".", "pi_rand_batch", "=", "torch", ".", "FloatTensor", "(", "self", ".", "pi_rand", ")", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "self", ".", "batch", ",", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "a_zeros", "=", "torch", ".", "zeros", "(", "1", ",", "1", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "a_zeros_batch", "=", "self", ".", "a_zeros", ".", "repeat", "(", "self", ".", "batch", ",", "1", ")", "\n", "\n", "self", ".", "q_loss", "=", "nn", ".", "SmoothL1Loss", "(", "reduction", "=", "'none'", ")", "\n", "\n", "if", "player", ":", "\n", "\n", "# play variables", "\n", "            ", "self", ".", "env", "=", "Env", "(", ")", "\n", "self", ".", "a_zeros", "=", "torch", ".", "zeros", "(", "1", ",", "1", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "trajectory", "=", "[", "]", "\n", "self", ".", "images", "=", "[", "]", "\n", "self", ".", "choices", "=", "np", ".", "arange", "(", "self", ".", "action_space", ",", "dtype", "=", "np", ".", "int", ")", "\n", "self", ".", "n_replay_saved", "=", "1", "\n", "self", ".", "frame", "=", "0", "\n", "self", ".", "states", "=", "0", "\n", "\n", "", "else", ":", "\n", "\n", "            ", "self", ".", "train_dataset", "=", "Memory", "(", "root_dir", ")", "\n", "self", ".", "train_sampler", "=", "ReplayBatchSampler", "(", "root_dir", ")", "\n", "self", ".", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "self", ".", "train_dataset", ",", "batch_sampler", "=", "self", ".", "train_sampler", ",", "\n", "collate_fn", "=", "collate", ",", "num_workers", "=", "args", ".", "cpu_workers", ",", "\n", "pin_memory", "=", "True", ",", "drop_last", "=", "False", ")", "\n", "\n", "# configure learning", "\n", "\n", "# IT IS IMPORTANT TO ASSIGN MODEL TO CUDA/PARALLEL BEFORE DEFINING OPTIMIZER", "\n", "", "self", ".", "optimizer_value", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "value_net", ".", "parameters", "(", ")", ",", "lr", "=", "0.00025", "/", "4", ",", "eps", "=", "1.5e-4", ",", "weight_decay", "=", "0", ")", "\n", "self", ".", "optimizer_beta", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "beta_net", ".", "parameters", "(", ")", ",", "lr", "=", "0.00025", "/", "4", ",", "eps", "=", "1.5e-4", ",", "weight_decay", "=", "0", ")", "\n", "self", ".", "n_offset", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_agent.RBIAgent.save_checkpoint": [[83, 101], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "rbi_agent.RBIAgent.beta_net.module.state_dict", "rbi_agent.RBIAgent.value_net.module.state_dict", "rbi_agent.RBIAgent.target_net.module.state_dict", "rbi_agent.RBIAgent.optimizer_value.state_dict", "rbi_agent.RBIAgent.optimizer_beta.state_dict", "rbi_agent.RBIAgent.beta_net.state_dict", "rbi_agent.RBIAgent.value_net.state_dict", "rbi_agent.RBIAgent.target_net.state_dict", "rbi_agent.RBIAgent.optimizer_value.state_dict", "rbi_agent.RBIAgent.optimizer_beta.state_dict"], "methods", ["None"], ["", "def", "save_checkpoint", "(", "self", ",", "path", ",", "aux", "=", "None", ")", ":", "\n", "\n", "        ", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", ":", "\n", "            ", "state", "=", "{", "'beta_net'", ":", "self", ".", "beta_net", ".", "module", ".", "state_dict", "(", ")", ",", "\n", "'value_net'", ":", "self", ".", "value_net", ".", "module", ".", "state_dict", "(", ")", ",", "\n", "'target_net'", ":", "self", ".", "target_net", ".", "module", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_value'", ":", "self", ".", "optimizer_value", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_beta'", ":", "self", ".", "optimizer_beta", ".", "state_dict", "(", ")", ",", "\n", "'aux'", ":", "aux", "}", "\n", "", "else", ":", "\n", "            ", "state", "=", "{", "'beta_net'", ":", "self", ".", "beta_net", ".", "state_dict", "(", ")", ",", "\n", "'value_net'", ":", "self", ".", "value_net", ".", "state_dict", "(", ")", ",", "\n", "'target_net'", ":", "self", ".", "target_net", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_value'", ":", "self", ".", "optimizer_value", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_beta'", ":", "self", ".", "optimizer_beta", ".", "state_dict", "(", ")", ",", "\n", "'aux'", ":", "aux", "}", "\n", "\n", "", "torch", ".", "save", "(", "state", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_agent.RBIAgent.load_checkpoint": [[102, 125], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "rbi_agent.RBIAgent.optimizer_beta.load_state_dict", "rbi_agent.RBIAgent.optimizer_value.load_state_dict", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "rbi_agent.RBIAgent.beta_net.module.load_state_dict", "rbi_agent.RBIAgent.value_net.module.load_state_dict", "rbi_agent.RBIAgent.target_net.module.load_state_dict", "rbi_agent.RBIAgent.beta_net.load_state_dict", "rbi_agent.RBIAgent.value_net.load_state_dict", "rbi_agent.RBIAgent.target_net.load_state_dict"], "methods", ["None"], ["", "def", "load_checkpoint", "(", "self", ",", "path", ")", ":", "\n", "\n", "        ", "state", "=", "torch", ".", "load", "(", "path", ",", "map_location", "=", "\"cuda:%d\"", "%", "self", ".", "cuda_id", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", ":", "\n", "            ", "self", ".", "beta_net", ".", "module", ".", "load_state_dict", "(", "state", "[", "'beta_net'", "]", ")", "\n", "self", ".", "value_net", ".", "module", ".", "load_state_dict", "(", "state", "[", "'value_net'", "]", ")", "\n", "self", ".", "target_net", ".", "module", ".", "load_state_dict", "(", "state", "[", "'target_net'", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "beta_net", ".", "load_state_dict", "(", "state", "[", "'beta_net'", "]", ")", "\n", "self", ".", "value_net", ".", "load_state_dict", "(", "state", "[", "'value_net'", "]", ")", "\n", "self", ".", "target_net", ".", "load_state_dict", "(", "state", "[", "'target_net'", "]", ")", "\n", "\n", "", "self", ".", "optimizer_beta", ".", "load_state_dict", "(", "state", "[", "'optimizer_beta'", "]", ")", "\n", "self", ".", "optimizer_value", ".", "load_state_dict", "(", "state", "[", "'optimizer_value'", "]", ")", "\n", "self", ".", "n_offset", "=", "state", "[", "'aux'", "]", "[", "'n'", "]", "\n", "\n", "try", ":", "\n", "            ", "self", ".", "behavioral_avg_score", "=", "state", "[", "'aux'", "]", "[", "'score'", "]", "\n", "", "except", ":", "\n", "            ", "pass", "\n", "\n", "", "return", "state", "[", "'aux'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_agent.RBIAgent.learn": [[126, 242], ["rbi_agent.RBIAgent.beta_net.train", "rbi_agent.RBIAgent.value_net.train", "rbi_agent.RBIAgent.target_net.eval", "tqdm.tqdm.tqdm", "enumerate", "sample[].to", "sample[].to", "sample[].to().unsqueeze_", "sample[].to", "sample[].to", "sample[].to", "sample[].to", "sample[].to", "rbi_agent.RBIAgent.beta_net", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "rbi_agent.RBIAgent.value_net", "rbi_agent.RBIAgent.target_net", "preprocess.h_torch", "rbi_agent.RBIAgent.optimizer_beta.zero_grad", "loss_beta.backward", "rbi_agent.RBIAgent.optimizer_beta.step", "rbi_agent.RBIAgent.optimizer_value.zero_grad", "loss_value.backward", "rbi_agent.RBIAgent.optimizer_value.step", "torch.nn.functional.softmax.detach", "is_value.max", "a[].data.cpu().numpy", "pi.clamp.clamp.clamp", "pi.clamp.clamp.sum().unsqueeze().repeat", "pi.clamp.clamp.log", "r.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "q_a.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "r.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "torch.nn.functional.softmax.data.cpu().max", "beta_index.numpy.numpy.numpy", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "sample[].to", "Hbeta.data.mean().cpu().numpy", "Hpi.data.mean().cpu().numpy", "loss_beta.data.cpu().numpy", "loss_value.data.cpu().numpy", "rbi_agent.RBIAgent.save_checkpoint", "rbi_agent.RBIAgent.target_net.load_state_dict", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "s[].data.cpu", "rbi_agent.RBIAgent.beta_net.train", "rbi_agent.RBIAgent.value_net.train", "preprocess.hinv_torch", "rbi_agent.RBIAgent.q_loss", "a[].data.cpu", "pi.clamp.clamp.sum().unsqueeze", "r.data.cpu().numpy.data.cpu().numpy.data.cpu", "q_a.data.cpu().numpy.data.cpu().numpy.data.cpu", "r.data.cpu().numpy.data.cpu().numpy.data.cpu", "torch.nn.functional.softmax.data.cpu", "rbi_agent.RBIAgent.value_net.state_dict", "Hbeta.data.mean().cpu", "Hpi.data.mean().cpu", "loss_beta.data.cpu", "loss_value.data.cpu", "pi.clamp.clamp.sum", "Hbeta.data.mean", "Hpi.data.mean"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.train", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.train", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.save_checkpoint", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.train", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.train"], ["", "def", "learn", "(", "self", ",", "n_interval", ",", "n_tot", ")", ":", "\n", "\n", "        ", "self", ".", "beta_net", ".", "train", "(", ")", "\n", "self", ".", "value_net", ".", "train", "(", ")", "\n", "self", ".", "target_net", ".", "eval", "(", ")", "\n", "\n", "results", "=", "{", "'n'", ":", "[", "]", ",", "'loss_value'", ":", "[", "]", ",", "'loss_beta'", ":", "[", "]", ",", "'act_diff'", ":", "[", "]", ",", "'a_agent'", ":", "[", "]", ",", "\n", "'a_player'", ":", "[", "]", ",", "'loss_std'", ":", "[", "]", ",", "\n", "'mc_val'", ":", "[", "]", ",", "\"Hbeta\"", ":", "[", "]", ",", "\"Hpi\"", ":", "[", "]", ",", "\"adv_a\"", ":", "[", "]", ",", "\"q_a\"", ":", "[", "]", ",", "'image'", ":", "[", "]", "}", "\n", "\n", "for", "n", ",", "sample", "in", "tqdm", "(", "enumerate", "(", "self", ".", "train_loader", ")", ")", ":", "\n", "\n", "            ", "n", "=", "self", ".", "n_offset", "+", "n", "+", "1", "\n", "\n", "s", "=", "sample", "[", "'s'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "s_tag", "=", "sample", "[", "'s_tag'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "a", "=", "sample", "[", "'a'", "]", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze_", "(", "1", ")", "\n", "r", "=", "sample", "[", "'r'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "t", "=", "sample", "[", "'t'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "pi", "=", "sample", "[", "'pi'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "pi_tag", "=", "sample", "[", "'pi_tag'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "tde", "=", "sample", "[", "'tde'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# Behavioral nets", "\n", "beta", "=", "self", ".", "beta_net", "(", "s", ")", "\n", "beta_log", "=", "F", ".", "log_softmax", "(", "beta", ",", "dim", "=", "1", ")", "\n", "beta", "=", "F", ".", "softmax", "(", "beta", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", "\n", "\n", "_", ",", "_", ",", "_", ",", "_", ",", "q_a", "=", "self", ".", "value_net", "(", "s", ",", "a", ",", "self", ".", "pi_rand_batch", ")", "\n", "_", ",", "_", ",", "_", ",", "q_tag", ",", "_", "=", "self", ".", "target_net", "(", "s_tag", ",", "a", ",", "self", ".", "pi_rand_batch", ")", "\n", "\n", "v_target", "=", "(", "q_tag", "*", "pi_tag", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "detach", "(", ")", "\n", "\n", "r", "=", "h_torch", "(", "r", "+", "self", ".", "discount", "**", "self", ".", "n_steps", "*", "(", "1", "-", "t", ")", "*", "hinv_torch", "(", "v_target", ")", ")", "\n", "\n", "is_value", "=", "tde", "**", "(", "-", "self", ".", "priority_beta", ")", "\n", "is_value", "=", "is_value", "/", "is_value", ".", "max", "(", ")", "\n", "\n", "is_policy", "=", "is_value", "\n", "\n", "loss_value", "=", "(", "self", ".", "q_loss", "(", "q_a", ",", "r", ")", "*", "is_value", ")", ".", "mean", "(", ")", "\n", "loss_beta", "=", "(", "(", "-", "pi", "*", "beta_log", ")", ".", "sum", "(", "dim", "=", "1", ")", "*", "is_policy", ")", ".", "mean", "(", ")", "\n", "\n", "# Learning part", "\n", "\n", "self", ".", "optimizer_beta", ".", "zero_grad", "(", ")", "\n", "loss_beta", ".", "backward", "(", ")", "\n", "self", ".", "optimizer_beta", ".", "step", "(", ")", "\n", "\n", "self", ".", "optimizer_value", ".", "zero_grad", "(", ")", "\n", "loss_value", ".", "backward", "(", ")", "\n", "self", ".", "optimizer_value", ".", "step", "(", ")", "\n", "\n", "# collect actions statistics", "\n", "if", "not", "n", "%", "50", ":", "\n", "\n", "                ", "a_index_np", "=", "a", "[", ":", ",", "0", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# avoid zero pi", "\n", "pi", "=", "pi", ".", "clamp", "(", "min", "=", "1e-4", ",", "max", "=", "1", ")", "\n", "pi", "/=", "pi", ".", "sum", "(", "dim", "=", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "self", ".", "action_space", ")", "\n", "\n", "pi_log", "=", "pi", ".", "log", "(", ")", "\n", "\n", "Hpi", "=", "-", "(", "pi", "*", "pi_log", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "Hbeta", "=", "-", "(", "beta", "*", "beta_log", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n", "adv_a", "=", "r", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "q_a", "=", "q_a", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "r", "=", "r", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "_", ",", "beta_index", "=", "beta", ".", "data", ".", "cpu", "(", ")", ".", "max", "(", "1", ")", "\n", "beta_index", "=", "beta_index", ".", "numpy", "(", ")", "\n", "act_diff", "=", "(", "a_index_np", "!=", "beta_index", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "# add results", "\n", "\n", "results", "[", "'act_diff'", "]", ".", "append", "(", "act_diff", ")", "\n", "results", "[", "'a_agent'", "]", ".", "append", "(", "beta_index", ")", "\n", "results", "[", "'adv_a'", "]", ".", "append", "(", "adv_a", ")", "\n", "results", "[", "'q_a'", "]", ".", "append", "(", "q_a", ")", "\n", "results", "[", "'a_player'", "]", ".", "append", "(", "a_index_np", ")", "\n", "results", "[", "'Hbeta'", "]", ".", "append", "(", "Hbeta", ".", "data", ".", "mean", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "results", "[", "'Hpi'", "]", ".", "append", "(", "Hpi", ".", "data", ".", "mean", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "results", "[", "'mc_val'", "]", ".", "append", "(", "r", ")", "\n", "\n", "# add results", "\n", "results", "[", "'loss_beta'", "]", ".", "append", "(", "loss_beta", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "results", "[", "'loss_value'", "]", ".", "append", "(", "loss_value", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "results", "[", "'loss_std'", "]", ".", "append", "(", "0", ")", "\n", "results", "[", "'n'", "]", ".", "append", "(", "n", ")", "\n", "\n", "if", "not", "n", "%", "self", ".", "update_memory_interval", ":", "\n", "# save agent state", "\n", "                    ", "self", ".", "save_checkpoint", "(", "self", ".", "snapshot_path", ",", "{", "'n'", ":", "n", "}", ")", "\n", "\n", "", "if", "not", "n", "%", "self", ".", "update_target_interval", ":", "\n", "# save agent state", "\n", "                    ", "self", ".", "target_net", ".", "load_state_dict", "(", "self", ".", "value_net", ".", "state_dict", "(", ")", ")", "\n", "\n", "", "if", "not", "n", "%", "n_interval", ":", "\n", "                    ", "results", "[", "'act_diff'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'act_diff'", "]", ")", "\n", "results", "[", "'a_agent'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'a_agent'", "]", ")", "\n", "results", "[", "'adv_a'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'adv_a'", "]", ")", "\n", "results", "[", "'q_a'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'q_a'", "]", ")", "\n", "results", "[", "'a_player'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'a_player'", "]", ")", "\n", "results", "[", "'mc_val'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'mc_val'", "]", ")", "\n", "results", "[", "'image'", "]", "=", "s", "[", "0", ",", ":", "-", "1", ",", ":", ",", ":", "]", ".", "data", ".", "cpu", "(", ")", "\n", "\n", "yield", "results", "\n", "self", ".", "beta_net", ".", "train", "(", ")", "\n", "self", ".", "value_net", ".", "train", "(", ")", "\n", "results", "=", "{", "key", ":", "[", "]", "for", "key", "in", "results", "}", "\n", "\n", "if", "n", ">=", "n_tot", ":", "\n", "                        ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_agent.RBIAgent.play": [[243, 356], ["range", "rbi_agent.RBIAgent.env.reset", "rbi_agent.RBIAgent.beta_net.eval", "rbi_agent.RBIAgent.value_net.eval", "preprocess.get_mc_value", "numpy.array", "print", "rbi_agent.RBIAgent.env.s.to", "rbi_agent.RBIAgent.beta_net", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "rbi_agent.RBIAgent.value_net", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy", "v.squeeze().data.cpu().numpy", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy", "adv.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy", "beta.squeeze().data.cpu().numpy.copy.clip", "numpy.random.choice", "rbi_agent.RBIAgent.env.step", "rbi_agent.RBIAgent.load_checkpoint", "rbi_agent.RBIAgent.beta_net.eval", "rbi_agent.RBIAgent.value_net.eval", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.detach", "beta.squeeze().data.cpu().numpy.copy.sum", "rewards[].append", "v_target[].append", "numpy.array.append", "time.sleep", "rbi_agent.RBIAgent.load_checkpoint", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu", "v.squeeze().data.cpu", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu", "adv.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.copy", "adv.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.copy", "numpy.zeros", "rewards.append", "v_target.append", "str", "numpy.argmax", "numpy.min", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.copy", "numpy.argmax", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze", "v.squeeze", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze", "adv.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_mc_value", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.load_checkpoint", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.load_checkpoint"], ["", "", "", "", "", "def", "play", "(", "self", ",", "n_tot", ",", "save", "=", "True", ",", "load", "=", "True", ",", "fix", "=", "False", ")", ":", "\n", "\n", "        ", "for", "i", "in", "range", "(", "n_tot", ")", ":", "\n", "\n", "            ", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n", "rewards", "=", "[", "[", "]", "]", "\n", "v_target", "=", "[", "[", "]", "]", "\n", "q_val", "=", "[", "]", "\n", "lives", "=", "self", ".", "env", ".", "lives", "\n", "\n", "while", "not", "fix", ":", "\n", "                ", "try", ":", "\n", "                    ", "self", ".", "load_checkpoint", "(", "self", ".", "snapshot_path", ")", "\n", "break", "\n", "", "except", ":", "\n", "                    ", "time", ".", "sleep", "(", "0.5", ")", "\n", "\n", "", "", "self", ".", "beta_net", ".", "eval", "(", ")", "\n", "self", ".", "value_net", ".", "eval", "(", ")", "\n", "\n", "while", "not", "self", ".", "env", ".", "t", ":", "\n", "\n", "                ", "if", "load", "and", "not", "(", "self", ".", "states", "%", "self", ".", "load_memory_interval", ")", ":", "\n", "                    ", "try", ":", "\n", "                        ", "self", ".", "load_checkpoint", "(", "self", ".", "snapshot_path", ")", "\n", "", "except", ":", "\n", "                        ", "pass", "\n", "\n", "", "self", ".", "beta_net", ".", "eval", "(", ")", "\n", "self", ".", "value_net", ".", "eval", "(", ")", "\n", "\n", "", "s", "=", "self", ".", "env", ".", "s", ".", "to", "(", "self", ".", "device", ")", "\n", "# get aux data", "\n", "\n", "beta", "=", "self", ".", "beta_net", "(", "s", ")", "\n", "beta", "=", "F", ".", "softmax", "(", "beta", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# take q as adv", "\n", "\n", "v", ",", "adv", ",", "_", ",", "q", ",", "_", "=", "self", ".", "value_net", "(", "s", ",", "self", ".", "a_zeros", ",", "beta", ")", "\n", "\n", "q", "=", "q", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "v_expected", "=", "v", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "beta", "=", "beta", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "adv", "=", "adv", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "self", ".", "n_offset", ">=", "self", ".", "random_initialization", ":", "\n", "\n", "                    ", "if", "self", ".", "player", "==", "\"reroutetv\"", ":", "\n", "\n", "                        ", "pi", "=", "beta", ".", "copy", "(", ")", "\n", "adv2", "=", "adv", ".", "copy", "(", ")", "\n", "\n", "pi", "=", "self", ".", "epsilon", "*", "self", ".", "pi_rand", "+", "(", "1", "-", "self", ".", "epsilon", ")", "*", "pi", "\n", "\n", "pi", "=", "self", ".", "cmin", "*", "pi", "\n", "\n", "Delta", "=", "1", "-", "self", ".", "cmin", "\n", "while", "Delta", ">", "0", ":", "\n", "                            ", "a", "=", "np", ".", "argmax", "(", "adv2", ")", "\n", "Delta_a", "=", "np", ".", "min", "(", "(", "Delta", ",", "(", "self", ".", "cmax", "-", "self", ".", "cmin", ")", "*", "beta", "[", "a", "]", ")", ")", "\n", "Delta", "-=", "Delta_a", "\n", "pi", "[", "a", "]", "+=", "Delta_a", "\n", "adv2", "[", "a", "]", "=", "-", "1e11", "\n", "\n", "", "pi_greed", "=", "np", ".", "zeros", "(", "self", ".", "action_space", ")", "\n", "pi_greed", "[", "np", ".", "argmax", "(", "adv", ")", "]", "=", "1", "\n", "\n", "pi_mix", "=", "(", "1", "-", "self", ".", "mix", ")", "*", "pi", "+", "self", ".", "mix", "*", "pi_greed", "\n", "\n", "", "elif", "self", ".", "player", "==", "\"behavioral\"", ":", "\n", "                        ", "pi_mix", "=", "beta", ".", "copy", "(", ")", "\n", "\n", "", "else", ":", "\n", "                        ", "raise", "NotImplementedError", "\n", "\n", "", "", "else", ":", "\n", "                    ", "pi_mix", "=", "self", ".", "pi_rand", "\n", "\n", "", "pi_mix", "=", "pi_mix", ".", "clip", "(", "0", ",", "1", ")", "\n", "pi_mix", "=", "pi_mix", "/", "pi_mix", ".", "sum", "(", ")", "\n", "a", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "choices", ",", "p", "=", "pi_mix", ")", "\n", "self", ".", "env", ".", "step", "(", "a", ")", "\n", "\n", "if", "self", ".", "env", ".", "k", ">=", "self", ".", "history_length", ":", "\n", "\n", "                    ", "if", "lives", ">", "self", ".", "env", ".", "lives", ":", "\n", "                        ", "rewards", ".", "append", "(", "[", "]", ")", "\n", "v_target", ".", "append", "(", "[", "]", ")", "\n", "", "lives", "=", "self", ".", "env", ".", "lives", "\n", "\n", "rewards", "[", "-", "1", "]", ".", "append", "(", "self", ".", "env", ".", "r", ")", "\n", "v_target", "[", "-", "1", "]", ".", "append", "(", "v_expected", ")", "\n", "q_val", ".", "append", "(", "q", "[", "a", "]", ")", "\n", "\n", "", "self", ".", "frame", "+=", "1", "\n", "\n", "", "mc_val", "=", "get_mc_value", "(", "rewards", ",", "None", ",", "self", ".", "discount", ",", "None", ")", "\n", "q_val", "=", "np", ".", "array", "(", "q_val", ")", "\n", "\n", "print", "(", "\"sts | st: %d\\t| sc: %d\\t| f: %d\\t| e: %7g\\t| typ: %2d | trg: %d | nst: %s\\t| n %d\\t| avg_r: %g\\t| avg_f: %g\"", "%", "\n", "(", "self", ".", "frame", ",", "self", ".", "env", ".", "score", ",", "self", ".", "env", ".", "k", ",", "0", ",", "0", ",", "0", ",", "str", "(", "np", ".", "nan", ")", ",", "\n", "self", ".", "n_offset", ",", "self", ".", "behavioral_avg_score", ",", "self", ".", "behavioral_avg_frame", ")", ")", "\n", "\n", "yield", "{", "'score'", ":", "self", ".", "env", ".", "score", ",", "\n", "'frames'", ":", "self", ".", "env", ".", "k", ",", "\"n\"", ":", "self", ".", "n_offset", ",", "\"mc\"", ":", "mc_val", ",", "\"q\"", ":", "q_val", "}", "\n", "\n", "if", "self", ".", "n_offset", ">=", "self", ".", "n_tot", "and", "not", "fix", ":", "\n", "                ", "break", "\n", "\n", "", "", "raise", "StopIteration", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_agent.RBIAgent.multiplay": [[357, 559], ["rbi_agent.RBIAgent.a_zeros.repeat", "numpy.repeat", "numpy.arange", "preprocess.lock_file", "numpy.load().item", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "range", "numpy.arange", "environment.Env", "numpy.expand_dims", "numpy.arange", "mp_env[].reset", "os.path.join", "os.mkdir", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "rbi_agent.RBIAgent.beta_net", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "rbi_agent.RBIAgent.value_net", "beta.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "q.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "adv.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "numpy.argsort", "numpy.logical_and", "numpy.repeat", "pi_mix.clip.clip.clip", "pi.astype.astype.astype", "range", "range", "range", "range", "range", "range", "range", "range", "os.path.join", "os.path.join", "os.path.join", "numpy.load", "str", "range", "rbi_agent.RBIAgent.beta_net.eval", "rbi_agent.RBIAgent.value_net.eval", "beta.data.cpu().numpy.data.cpu().numpy.detach", "numpy.expand_dims", "range", "numpy.zeros", "numpy.repeat", "numpy.random.choice", "cv2.imwrite", "episode[].append", "env.step", "[].append", "[].append", "q_a[].append", "rbi_agent.RBIAgent.load_checkpoint", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "beta.data.cpu().numpy.data.cpu().numpy.data.cpu", "q.data.cpu().numpy.data.cpu().numpy.data.cpu", "adv.data.cpu().numpy.data.cpu().numpy.data.cpu", "numpy.array", "numpy.ones", "numpy.minimum", "pi_mix.clip.clip.sum", "os.path.join", "numpy.array", "rewards[].append", "v_target[].append", "preprocess.get_tde_value", "numpy.abs", "numpy.concatenate", "preprocess.get_mc_value", "numpy.stack", "trajectory[].append", "print", "env.reset", "preprocess.lock_file", "numpy.load().item", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "os.path.join", "os.mkdir", "int", "str", "sum", "range", "numpy.argmax", "str", "numpy.array", "preprocess.get_td_value", "numpy.load", "preprocess.lock_file", "numpy.load().item", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "numpy.concatenate", "os.path.join", "numpy.save", "preprocess.lock_file", "numpy.load", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "numpy.abs", "numpy.sign", "len", "psutil.virtual_memory", "numpy.append", "time.time", "numpy.load"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.load_checkpoint", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_tde_value", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_mc_value", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_td_value", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file"], ["", "def", "multiplay", "(", "self", ")", ":", "\n", "\n", "        ", "n_players", "=", "self", ".", "n_players", "\n", "\n", "player_i", "=", "np", ".", "arange", "(", "self", ".", "actor_index", ",", "self", ".", "actor_index", "+", "self", ".", "n_actors", "*", "n_players", ",", "self", ".", "n_actors", ")", "/", "(", "self", ".", "n_actors", "*", "n_players", "-", "1", ")", "\n", "explore_threshold", "=", "player_i", "\n", "\n", "mp_explore", "=", "0.4", "**", "(", "1", "+", "7", "*", "(", "1", "-", "player_i", ")", ")", "\n", "\n", "mp_env", "=", "[", "Env", "(", ")", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "self", ".", "frame", "=", "0", "\n", "\n", "a_zeros_mp", "=", "self", ".", "a_zeros", ".", "repeat", "(", "n_players", ",", "1", ")", "\n", "mp_pi_rand", "=", "np", ".", "repeat", "(", "np", ".", "expand_dims", "(", "self", ".", "pi_rand", ",", "axis", "=", "0", ")", ",", "n_players", ",", "axis", "=", "0", ")", "\n", "\n", "range_players", "=", "np", ".", "arange", "(", "n_players", ")", "\n", "rewards", "=", "[", "[", "[", "]", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "v_target", "=", "[", "[", "[", "]", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "episode", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "q_a", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "image_dir", "=", "[", "''", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "trajectory", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "screen_dir", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"screen\"", ")", "]", "*", "n_players", "\n", "\n", "trajectory_dir", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"trajectory\"", ")", "]", "*", "n_players", "\n", "\n", "readlock", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "list_dir", ",", "\"readlock_explore.npy\"", ")", "]", "*", "n_players", "\n", "\n", "# set initial episodes number", "\n", "# lock read", "\n", "fwrite", "=", "lock_file", "(", "self", ".", "episodelock", ")", "\n", "current_num", "=", "np", ".", "load", "(", "fwrite", ")", ".", "item", "(", ")", "\n", "episode_num", "=", "current_num", "+", "np", ".", "arange", "(", "n_players", ")", "\n", "fwrite", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fwrite", ",", "current_num", "+", "n_players", ")", "\n", "# unlock file", "\n", "release_file", "(", "fwrite", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_players", ")", ":", "\n", "            ", "mp_env", "[", "i", "]", ".", "reset", "(", ")", "\n", "image_dir", "[", "i", "]", "=", "os", ".", "path", ".", "join", "(", "screen_dir", "[", "i", "]", ",", "str", "(", "episode_num", "[", "i", "]", ")", ")", "\n", "os", ".", "mkdir", "(", "image_dir", "[", "i", "]", ")", "\n", "\n", "", "lives", "=", "[", "mp_env", "[", "i", "]", ".", "lives", "for", "i", "in", "range", "(", "n_players", ")", "]", "\n", "\n", "while", "True", ":", "\n", "\n", "            ", "if", "not", "(", "self", ".", "frame", "%", "self", ".", "load_memory_interval", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "self", ".", "load_checkpoint", "(", "self", ".", "snapshot_path", ")", "\n", "", "except", ":", "\n", "                    ", "pass", "\n", "\n", "", "self", ".", "beta_net", ".", "eval", "(", ")", "\n", "self", ".", "value_net", ".", "eval", "(", ")", "\n", "\n", "", "s", "=", "torch", ".", "cat", "(", "[", "env", ".", "s", "for", "env", "in", "mp_env", "]", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "beta", "=", "self", ".", "beta_net", "(", "s", ")", "\n", "beta", "=", "F", ".", "softmax", "(", "beta", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", "\n", "# take q as adv", "\n", "_", ",", "adv", ",", "_", ",", "q", ",", "_", "=", "self", ".", "value_net", "(", "s", ",", "a_zeros_mp", ",", "beta", ")", "\n", "beta", "=", "beta", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "q", "=", "q", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "adv", "=", "adv", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "rank", "=", "np", ".", "argsort", "(", "adv", ",", "axis", "=", "1", ")", "\n", "\n", "mp_trigger", "=", "np", ".", "logical_and", "(", "\n", "np", ".", "array", "(", "[", "env", ".", "score", "for", "env", "in", "mp_env", "]", ")", ">=", "self", ".", "behavioral_avg_score", "*", "explore_threshold", ",", "\n", "explore_threshold", ">=", "0", ")", "\n", "exploration", "=", "np", ".", "repeat", "(", "np", ".", "expand_dims", "(", "mp_explore", "*", "mp_trigger", ",", "axis", "=", "1", ")", ",", "self", ".", "action_space", ",", "axis", "=", "1", ")", "\n", "\n", "if", "self", ".", "n_offset", ">=", "self", ".", "random_initialization", ":", "\n", "\n", "                ", "pi", "=", "(", "1", "-", "self", ".", "epsilon", ")", "*", "beta", "+", "self", ".", "epsilon", "/", "self", ".", "action_space", "\n", "pi", "=", "self", ".", "cmin", "*", "pi", "\n", "\n", "Delta", "=", "np", ".", "ones", "(", "n_players", ")", "-", "self", ".", "cmin", "\n", "for", "i", "in", "range", "(", "self", ".", "action_space", ")", ":", "\n", "                    ", "a", "=", "rank", "[", ":", ",", "self", ".", "action_space", "-", "1", "-", "i", "]", "\n", "Delta_a", "=", "np", ".", "minimum", "(", "Delta", ",", "(", "self", ".", "cmax", "-", "self", ".", "cmin", ")", "*", "beta", "[", "range_players", ",", "a", "]", ")", "\n", "Delta", "-=", "Delta_a", "\n", "pi", "[", "range_players", ",", "a", "]", "+=", "Delta_a", "\n", "\n", "", "pi_greed", "=", "np", ".", "zeros", "(", "(", "n_players", ",", "self", ".", "action_space", ")", ")", "\n", "pi_greed", "[", "range", "(", "n_players", ")", ",", "np", ".", "argmax", "(", "adv", ",", "axis", "=", "1", ")", "]", "=", "1", "\n", "pi", "=", "(", "1", "-", "self", ".", "mix", ")", "*", "pi", "+", "self", ".", "mix", "*", "pi_greed", "\n", "\n", "", "else", ":", "\n", "                ", "pi", "=", "mp_pi_rand", "\n", "\n", "", "pi_mix", "=", "pi", "*", "(", "1", "-", "exploration", ")", "+", "exploration", "*", "mp_pi_rand", "\n", "pi_mix", "=", "pi_mix", ".", "clip", "(", "0", ",", "1", ")", "\n", "pi_mix", "=", "pi_mix", "/", "np", ".", "repeat", "(", "pi_mix", ".", "sum", "(", "axis", "=", "1", ",", "keepdims", "=", "True", ")", ",", "self", ".", "action_space", ",", "axis", "=", "1", ")", "\n", "\n", "pi", "=", "pi", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "v_expected", "=", "(", "q", "*", "pi", ")", ".", "sum", "(", "axis", "=", "1", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_players", ")", ":", "\n", "\n", "                ", "a", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "choices", ",", "p", "=", "pi_mix", "[", "i", "]", ")", "\n", "\n", "env", "=", "mp_env", "[", "i", "]", "\n", "cv2", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "image_dir", "[", "i", "]", ",", "\"%s.png\"", "%", "str", "(", "self", ".", "frame", ")", ")", ",", "mp_env", "[", "i", "]", ".", "image", ",", "[", "imcompress", ",", "compress_level", "]", ")", "\n", "episode", "[", "i", "]", ".", "append", "(", "np", ".", "array", "(", "(", "self", ".", "frame", ",", "a", ",", "pi", "[", "i", "]", ",", "\n", "None", ",", "None", ",", "\n", "episode_num", "[", "i", "]", ",", "0.", ",", "0", ",", "0", ",", "\n", "0.", ",", "1.", ",", "1.", ",", "0", ",", "1.", ",", "0", ",", "0.", ",", "self", ".", "env", ".", "ram", ")", ",", "dtype", "=", "self", ".", "rec_type", ")", ")", "\n", "\n", "env", ".", "step", "(", "a", ")", "\n", "\n", "if", "lives", "[", "i", "]", ">", "env", ".", "lives", ":", "\n", "                    ", "rewards", "[", "i", "]", ".", "append", "(", "[", "]", ")", "\n", "v_target", "[", "i", "]", ".", "append", "(", "[", "]", ")", "\n", "", "lives", "[", "i", "]", "=", "env", ".", "lives", "\n", "\n", "rewards", "[", "i", "]", "[", "-", "1", "]", ".", "append", "(", "env", ".", "r", ")", "\n", "v_target", "[", "i", "]", "[", "-", "1", "]", ".", "append", "(", "v_expected", "[", "i", "]", ")", "\n", "q_a", "[", "i", "]", ".", "append", "(", "q", "[", "i", "]", "[", "a", "]", ")", "\n", "\n", "if", "env", ".", "t", ":", "\n", "\n", "# cancel termination reward", "\n", "                    ", "rewards", "[", "i", "]", "[", "-", "1", "]", "[", "-", "1", "]", "-=", "self", ".", "termination_reward", "*", "int", "(", "env", ".", "k", "*", "self", ".", "skip", ">=", "self", ".", "max_length", "or", "env", ".", "score", ">=", "self", ".", "max_score", ")", "\n", "\n", "td_val", ",", "t_val", "=", "get_tde_value", "(", "rewards", "[", "i", "]", ",", "self", ".", "discount", ",", "self", ".", "n_steps", ")", "\n", "tde", "=", "np", ".", "abs", "(", "np", ".", "array", "(", "q_a", "[", "i", "]", ")", "-", "get_td_value", "(", "rewards", "[", "i", "]", ",", "v_target", "[", "i", "]", ",", "self", ".", "discount", ",", "self", ".", "n_steps", ")", ")", "\n", "v_scale", "=", "np", ".", "concatenate", "(", "v_target", "[", "i", "]", ")", "\n", "mc_val", "=", "get_mc_value", "(", "rewards", "[", "i", "]", ",", "v_target", "[", "i", "]", ",", "self", ".", "discount", ",", "self", ".", "n_steps", ")", "\n", "\n", "tde", "=", "(", "(", "tde", "+", "0.01", ")", "/", "(", "np", ".", "abs", "(", "v_scale", ")", "+", "0.01", ")", ")", "**", "self", ".", "priority_alpha", "\n", "\n", "episode_df", "=", "np", ".", "stack", "(", "episode", "[", "i", "]", "[", "self", ".", "history_length", "-", "1", ":", "self", ".", "max_length", "]", ")", "\n", "episode_df", "[", "'r'", "]", "=", "td_val", "[", "self", ".", "history_length", "-", "1", ":", "self", ".", "max_length", "]", "\n", "episode_df", "[", "'t'", "]", "=", "t_val", "[", "self", ".", "history_length", "-", "1", ":", "self", ".", "max_length", "]", "\n", "episode_df", "[", "'tde'", "]", "=", "tde", "[", "self", ".", "history_length", "-", "1", ":", "self", ".", "max_length", "]", "\n", "episode_df", "[", "'R'", "]", "=", "mc_val", "[", "self", ".", "history_length", "-", "1", ":", "self", ".", "max_length", "]", "\n", "\n", "trajectory", "[", "i", "]", ".", "append", "(", "episode_df", ")", "\n", "\n", "print", "(", "\"rbi | st: %d\\t| sc: %d\\t| f: %d\\t| e: %7g\\t| typ: %2d | trg: %d | t: %d\\t| n %d\\t| avg_r: %g\\t| avg_f: %g\"", "%", "\n", "(", "self", ".", "frame", ",", "env", ".", "score", ",", "env", ".", "k", ",", "mp_explore", "[", "i", "]", ",", "np", ".", "sign", "(", "explore_threshold", "[", "i", "]", ")", ",", "mp_trigger", "[", "i", "]", ",", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", ",", "self", ".", "n_offset", ",", "self", ".", "behavioral_avg_score", ",", "self", ".", "behavioral_avg_frame", ")", ")", "\n", "\n", "# roll out a state from the active learning buffer", "\n", "ram", "=", "None", "\n", "env", ".", "reset", "(", "ram", ")", "\n", "\n", "episode", "[", "i", "]", "=", "[", "]", "\n", "q_a", "[", "i", "]", "=", "[", "]", "\n", "rewards", "[", "i", "]", "=", "[", "[", "]", "]", "\n", "v_target", "[", "i", "]", "=", "[", "[", "]", "]", "\n", "lives", "[", "i", "]", "=", "env", ".", "lives", "\n", "\n", "# get new episode number", "\n", "\n", "# lock read", "\n", "fwrite", "=", "lock_file", "(", "self", ".", "episodelock", ")", "\n", "episode_num", "[", "i", "]", "=", "np", ".", "load", "(", "fwrite", ")", ".", "item", "(", ")", "\n", "fwrite", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fwrite", ",", "episode_num", "[", "i", "]", "+", "1", ")", "\n", "# unlock file", "\n", "release_file", "(", "fwrite", ")", "\n", "\n", "image_dir", "[", "i", "]", "=", "os", ".", "path", ".", "join", "(", "screen_dir", "[", "i", "]", ",", "str", "(", "episode_num", "[", "i", "]", ")", ")", "\n", "os", ".", "mkdir", "(", "image_dir", "[", "i", "]", ")", "\n", "\n", "if", "sum", "(", "[", "len", "(", "j", ")", "for", "j", "in", "trajectory", "[", "i", "]", "]", ")", ">=", "self", ".", "player_replay_size", ":", "\n", "\n", "# write if enough space is available", "\n", "                        ", "if", "psutil", ".", "virtual_memory", "(", ")", ".", "available", ">=", "mem_threshold", ":", "\n", "\n", "# lock read", "\n", "                            ", "fwrite", "=", "lock_file", "(", "self", ".", "writelock", ")", "\n", "traj_num", "=", "np", ".", "load", "(", "fwrite", ")", ".", "item", "(", ")", "\n", "fwrite", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fwrite", ",", "traj_num", "+", "1", ")", "\n", "# unlock file", "\n", "release_file", "(", "fwrite", ")", "\n", "\n", "traj_to_save", "=", "np", ".", "concatenate", "(", "trajectory", "[", "i", "]", ")", "\n", "traj_to_save", "[", "'traj'", "]", "=", "traj_num", "\n", "\n", "traj_file", "=", "os", ".", "path", ".", "join", "(", "trajectory_dir", "[", "i", "]", ",", "\"%d.npy\"", "%", "traj_num", ")", "\n", "np", ".", "save", "(", "traj_file", ",", "traj_to_save", ")", "\n", "\n", "fread", "=", "lock_file", "(", "readlock", "[", "i", "]", ")", "\n", "traj_list", "=", "np", ".", "load", "(", "fread", ")", "\n", "fread", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fread", ",", "np", ".", "append", "(", "traj_list", ",", "traj_num", ")", ")", "\n", "release_file", "(", "fread", ")", "\n", "\n", "", "trajectory", "[", "i", "]", "=", "[", "]", "\n", "\n", "# write trajectory to dir", "\n", "\n", "", "", "", "self", ".", "frame", "+=", "1", "\n", "if", "not", "self", ".", "frame", "%", "self", ".", "player_replay_size", ":", "\n", "                ", "yield", "True", "\n", "if", "self", ".", "n_offset", ">=", "self", ".", "n_tot", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_agent.RBIAgent.demonstrate": [[560, 628], ["rbi_agent.RBIAgent.beta_net.eval", "rbi_agent.RBIAgent.value_net.eval", "range", "rbi_agent.RBIAgent.env.reset", "numpy.arange", "rbi_agent.RBIAgent.env.s.to", "rbi_agent.RBIAgent.beta_net", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "rbi_agent.RBIAgent.value_net", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.copy", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.copy", "numpy.zeros", "pi.clip.clip.clip", "numpy.random.choice", "rbi_agent.RBIAgent.env.step", "preprocess.state_to_img", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.detach", "numpy.argmax", "numpy.min", "pi.clip.clip.sum", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu", "numpy.argmax", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.state_to_img"], ["", "", "", "", "def", "demonstrate", "(", "self", ",", "n_tot", ")", ":", "\n", "\n", "        ", "self", ".", "beta_net", ".", "eval", "(", ")", "\n", "self", ".", "value_net", ".", "eval", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_tot", ")", ":", "\n", "\n", "# if \"gpu\" in socket.gethostname():", "\n", "#     log_dir = os.path.join(\"/home/dsi/elad/data/rbi/runs\", \"%s_%d\" % (consts.exptime, i))", "\n", "# else:", "\n", "#     log_dir = os.path.join(\"/tmp\", \"%s_%d\" % (consts.exptime, i))", "\n", "#", "\n", "# os.mkdir(log_dir)", "\n", "\n", "            ", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n", "# here there is a problem when there is a varying/increasing life counter as in mspacman", "\n", "\n", "choices", "=", "np", ".", "arange", "(", "self", ".", "action_space", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "while", "not", "self", ".", "env", ".", "t", ":", "\n", "\n", "                ", "s", "=", "self", ".", "env", ".", "s", ".", "to", "(", "self", ".", "device", ")", "\n", "beta", "=", "self", ".", "beta_net", "(", "s", ")", "\n", "beta", "=", "F", ".", "softmax", "(", "beta", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", "\n", "\n", "_", ",", "_", ",", "_", ",", "q", ",", "_", "=", "self", ".", "value_net", "(", "s", ",", "self", ".", "a_zeros", ",", "beta", ")", "\n", "\n", "q", "=", "q", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "beta", "=", "beta", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "pi", "=", "beta", ".", "copy", "(", ")", "\n", "adv", "=", "q", ".", "copy", "(", ")", "\n", "\n", "pi", "=", "self", ".", "epsilon", "*", "self", ".", "pi_rand", "+", "(", "1", "-", "self", ".", "epsilon", ")", "*", "pi", "\n", "pi", "=", "self", ".", "cmin", "*", "pi", "\n", "\n", "Delta", "=", "1", "-", "self", ".", "cmin", "\n", "while", "Delta", ">", "0", ":", "\n", "                    ", "a", "=", "np", ".", "argmax", "(", "adv", ")", "\n", "Delta_a", "=", "np", ".", "min", "(", "(", "Delta", ",", "(", "self", ".", "cmax", "-", "self", ".", "cmin", ")", "*", "beta", "[", "a", "]", ")", ")", "\n", "Delta", "-=", "Delta_a", "\n", "pi", "[", "a", "]", "+=", "Delta_a", "\n", "adv", "[", "a", "]", "=", "-", "1e11", "\n", "\n", "", "pi_greed", "=", "np", ".", "zeros", "(", "self", ".", "action_space", ")", "\n", "pi_greed", "[", "np", ".", "argmax", "(", "q", ")", "]", "=", "1", "\n", "pi", "=", "(", "1", "-", "self", ".", "mix", ")", "*", "pi", "+", "self", ".", "mix", "*", "pi_greed", "\n", "\n", "pi", "=", "pi", ".", "clip", "(", "0", ",", "1", ")", "\n", "pi", "=", "pi", "/", "pi", ".", "sum", "(", ")", "\n", "\n", "a", "=", "np", ".", "random", ".", "choice", "(", "choices", ",", "p", "=", "pi", ")", "\n", "self", ".", "env", ".", "step", "(", "a", ")", "\n", "\n", "# time.sleep(0.1)", "\n", "img", "=", "state_to_img", "(", "s", ")", "\n", "\n", "# cv2.imwrite(os.path.join(log_dir, \"%d_%d_%d.png\" % (self.env.k, a, self.env.score)), img)", "\n", "\n", "v", "=", "(", "pi", "*", "q", ")", ".", "sum", "(", ")", "\n", "adv", "=", "q", "-", "v", "\n", "\n", "yield", "{", "'score'", ":", "self", ".", "env", ".", "score", ",", "\"beta\"", ":", "pi", ",", "\"v\"", ":", "v", ",", "\"q\"", ":", "q", ",", "\"adv\"", ":", "adv", ",", "\"s\"", ":", "img", ",", "'frames'", ":", "self", ".", "env", ".", "k", ",", "\n", "\"actions\"", ":", "self", ".", "env", ".", "action_meanings", ",", "\"a\"", ":", "a", "\n", "}", "\n", "\n", "", "", "raise", "StopIteration", "", "", "", ""]], "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.convert_to_dataframe": [[101, 132], ["os.path.join", "os.path.join", "os.listdir", "pandas.DataFrame", "pandas.DataFrame", "pd.DataFrame.to_pickle", "pd.DataFrame.to_pickle", "os.path.isdir", "os.mkdir", "print", "os.listdir", "os.path.join", "os.path.join", "os.path.isfile", "os.path.isfile", "os.path.join", "os.path.join", "os.path.join", "numpy.load().item", "numpy.load().item", "numpy.load", "numpy.load", "os.path.join", "os.path.join"], "function", ["None"], ["def", "convert_to_dataframe", "(", "experiment", ")", ":", "\n", "\n", "    ", "run_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "experiment", ",", "\"scores\"", ")", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "experiment", ",", "\"postprocess\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "save_dir", ")", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"df_reroute\"", ")", ")", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"df_behavioral\"", ")", ")", ":", "\n", "        ", "return", "\n", "\n", "", "results_reroute", "=", "{", "'score'", ":", "[", "]", ",", "'frame'", ":", "[", "]", ",", "'n'", ":", "[", "]", ",", "'time'", ":", "[", "]", "}", "\n", "results_behavioral", "=", "{", "'score'", ":", "[", "]", ",", "'frame'", ":", "[", "]", ",", "'n'", ":", "[", "]", ",", "'time'", ":", "[", "]", "}", "\n", "\n", "for", "d", "in", "os", ".", "listdir", "(", "run_dir", ")", ":", "\n", "        ", "print", "(", "d", ")", "\n", "for", "f", "in", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "run_dir", ",", "d", ")", ")", ":", "\n", "\n", "            ", "if", "\"behavioral\"", "in", "f", ":", "\n", "                ", "for", "key", "in", "results_behavioral", ":", "\n", "                    ", "item", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "run_dir", ",", "d", ",", "f", ")", ")", ".", "item", "(", ")", "\n", "results_behavioral", "[", "key", "]", "+=", "item", "[", "key", "]", "\n", "", "", "else", ":", "\n", "                ", "for", "key", "in", "results_reroute", ":", "\n", "                    ", "item", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "run_dir", ",", "d", ",", "f", ")", ")", ".", "item", "(", ")", "\n", "results_reroute", "[", "key", "]", "+=", "item", "[", "key", "]", "\n", "\n", "", "", "", "", "df_reroute", "=", "pd", ".", "DataFrame", "(", "results_reroute", ")", "\n", "df_behavioral", "=", "pd", ".", "DataFrame", "(", "results_behavioral", ")", "\n", "\n", "df_reroute", ".", "to_pickle", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"df_reroute\"", ")", ")", "\n", "df_behavioral", ".", "to_pickle", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"df_behavioral\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.preprocess": [[134, 147], ["pandas.RangeIndex", "df.rolling().mean.sort_values", "df.rolling().mean.groupby().mean", "df.rolling().mean.reset_index().set_index", "df.rolling().mean.reindex", "df.rolling().mean.interpolate", "df.rolling().mean.rolling().mean", "df.rolling().mean.groupby", "df.rolling().mean.reset_index", "df.rolling().mean.rolling"], "function", ["None"], ["", "def", "preprocess", "(", "df", ")", ":", "\n", "\n", "    ", "idx", "=", "pd", ".", "RangeIndex", "(", "0", ",", "3125000", ",", "100", ")", "\n", "\n", "df", "=", "df", "[", "df", "[", "'n'", "]", "<=", "3125000", "]", "\n", "\n", "df", "=", "df", ".", "sort_values", "(", "\"n\"", ")", "\n", "df", "=", "df", ".", "groupby", "(", "\"n\"", ")", ".", "mean", "(", ")", "\n", "df", "=", "df", ".", "reset_index", "(", ")", ".", "set_index", "(", "\"n\"", ")", "\n", "df", ".", "reindex", "(", "idx", ")", "\n", "df", "=", "df", ".", "interpolate", "(", ")", "\n", "df", "=", "df", ".", "rolling", "(", "300", ",", "win_type", "=", "'blackmanharris'", ",", "min_periods", "=", "1", ",", "center", "=", "True", ")", ".", "mean", "(", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.preprocess_quantiles": [[149, 172], ["pandas.RangeIndex", "df.interpolate.sort_values", "df.interpolate.groupby().mean", "df.interpolate.reset_index", "df.interpolate.set_index", "df.interpolate.reindex", "df.interpolate.interpolate", "df.interpolate.rolling().quantile", "df.interpolate.rolling().quantile", "df.interpolate.groupby", "df.interpolate.rolling", "df.interpolate.rolling"], "function", ["None"], ["", "def", "preprocess_quantiles", "(", "df", ")", ":", "\n", "\n", "    ", "idx", "=", "pd", ".", "RangeIndex", "(", "0", ",", "3125000", ",", "100", ")", "\n", "\n", "df", "=", "df", "[", "df", "[", "'n'", "]", "<=", "3125000", "]", "\n", "\n", "df", "=", "df", ".", "sort_values", "(", "\"n\"", ")", "\n", "df", "=", "df", ".", "groupby", "(", "\"n\"", ")", ".", "mean", "(", ")", "\n", "df", "=", "df", ".", "reset_index", "(", ")", "\n", "df", "=", "df", ".", "set_index", "(", "\"n\"", ")", "\n", "df", ".", "reindex", "(", "idx", ")", "\n", "df", "=", "df", ".", "interpolate", "(", ")", "\n", "\n", "# df_u = df_u.interpolate()", "\n", "df_u", "=", "df", ".", "rolling", "(", "100", ",", "min_periods", "=", "1", ",", "center", "=", "True", ")", ".", "quantile", "(", "0.75", ",", "interpolation", "=", "'linear'", ")", "\n", "# df_u = df.rolling(10, win_type='blackmanharris', min_periods=1, center=True).quantile(0.75, interpolation='linear')", "\n", "\n", "# df_d = df_d.interpolate()", "\n", "# df_d = df.rolling(10, win_type='blackmanharris', min_periods=1, center=True).quantile(0.25, interpolation='linear')", "\n", "df_d", "=", "df", ".", "rolling", "(", "100", ",", "min_periods", "=", "1", ",", "center", "=", "True", ")", ".", "quantile", "(", "0.25", ",", "interpolation", "=", "'linear'", ")", "\n", "\n", "\n", "return", "df_u", ",", "df_d", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.cumulative": [[174, 186], ["pandas.RangeIndex", "df.rolling().mean.sort_values", "df.rolling().mean.reset_index", "df.rolling().mean.groupby().mean().reset_index", "df.rolling().mean.set_index", "df.rolling().mean.reindex", "df.rolling().mean.interpolate", "df.rolling().mean.rolling().mean", "df.rolling().mean.score.cumsum", "numpy.arange", "len", "df.rolling().mean.groupby().mean", "df.rolling().mean.rolling", "df.rolling().mean.groupby"], "function", ["None"], ["", "def", "cumulative", "(", "df", ")", ":", "\n", "\n", "    ", "idx", "=", "pd", ".", "RangeIndex", "(", "0", ",", "3125000", ",", "100", ")", "\n", "df", "=", "df", ".", "sort_values", "(", "\"n\"", ")", "\n", "df", "=", "df", ".", "reset_index", "(", ")", "\n", "df", ".", "score", "=", "df", ".", "score", ".", "cumsum", "(", ")", "/", "np", ".", "arange", "(", "len", "(", "df", ".", "score", ")", ")", "\n", "df", "=", "df", ".", "groupby", "(", "\"n\"", ")", ".", "mean", "(", ")", ".", "reset_index", "(", ")", "\n", "df", "=", "df", ".", "set_index", "(", "\"n\"", ")", "\n", "df", ".", "reindex", "(", "idx", ")", "\n", "df", "=", "df", ".", "interpolate", "(", ")", "\n", "df", "=", "df", ".", "rolling", "(", "200", ",", "win_type", "=", "'blackmanharris'", ",", "min_periods", "=", "1", ",", "center", "=", "True", ")", ".", "mean", "(", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.timeprocess": [[188, 200], ["scipy.interp1d", "numpy.arange", "df.set_index.set_index", "df.set_index.time.min"], "function", ["None"], ["", "def", "timeprocess", "(", "df", ")", ":", "\n", "\n", "    ", "time", "=", "(", "df", ".", "time", "-", "df", ".", "time", ".", "min", "(", ")", ")", "/", "3600", "\n", "score", "=", "df", ".", "score", "\n", "\n", "f", "=", "interp", ".", "interp1d", "(", "time", ",", "score", ")", "\n", "\n", "time_indx", "=", "np", ".", "arange", "(", "0", ",", "24", ",", "1", "/", "60", ")", "\n", "\n", "df", "=", "df", ".", "set_index", "(", "\"time\"", ")", "\n", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.plot_cumulative": [[202, 255], ["matplotlib.style.use", "matplotlib.figure", "matplotlib.rc", "matplotlib.rc", "matplotlib.ticker.FuncFormatter", "sorted", "matplotlib.savefig", "reroute_experiment_dict.keys", "os.path.join", "os.path.join", "pandas.read_pickle", "pandas.read_pickle", "plot_results.cumulative", "plot_results.cumulative", "matplotlib.subplot", "cumulative.score.rolling().std", "matplotlib.gca", "matplotlib.plot", "matplotlib.plot", "matplotlib.title", "plt.gca.yaxis.set_major_formatter", "os.path.join", "os.path.join", "matplotlib.xticks", "matplotlib.xticks", "matplotlib.legend", "cumulative.score.rolling"], "function", ["home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.cumulative", "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.cumulative"], ["", "def", "plot_cumulative", "(", ")", ":", "\n", "\n", "    ", "plt", ".", "style", ".", "use", "(", "'ggplot'", ")", "\n", "plt", ".", "figure", "(", "1", ",", "figsize", "=", "(", "12", ",", "4", ")", ")", "\n", "plt", ".", "rc", "(", "'ytick'", ",", "labelsize", "=", "6", ")", "\n", "plt", ".", "rc", "(", "'xtick'", ",", "labelsize", "=", "6", ")", "\n", "\n", "formatter", "=", "FuncFormatter", "(", "millions", ")", "\n", "\n", "i", "=", "0", "\n", "for", "experiment", "in", "sorted", "(", "reroute_experiment_dict", ".", "keys", "(", ")", ")", ":", "\n", "\n", "        ", "i", "+=", "1", "\n", "if", "reroute_experiment_dict", "[", "experiment", "]", "==", "\"na\"", ":", "\n", "            ", "continue", "\n", "\n", "# load reroute DF", "\n", "", "save_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "reroute_experiment_dict", "[", "experiment", "]", ",", "\"postprocess\"", ")", "\n", "ape_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "ape_experiment_dict", "[", "experiment", "]", ",", "\"postprocess\"", ")", "\n", "\n", "df_reroute", "=", "pd", ".", "read_pickle", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"df_reroute\"", ")", ")", "\n", "df_ape", "=", "pd", ".", "read_pickle", "(", "os", ".", "path", ".", "join", "(", "ape_dir", ",", "\"df_reroute\"", ")", ")", "\n", "\n", "df_reroute", "=", "cumulative", "(", "df_reroute", ")", "\n", "df_ape", "=", "cumulative", "(", "df_ape", ")", "\n", "plt", ".", "subplot", "(", "2", ",", "6", ",", "i", ")", "\n", "\n", "x1", "=", "df_reroute", ".", "index", "\n", "y1", "=", "df_reroute", ".", "score", "\n", "\n", "x2", "=", "df_ape", ".", "index", "\n", "y2", "=", "df_ape", ".", "score", "\n", "# y = df_reroute.score.rolling(100, win_type='triang', min_periods=1, center=True).mean()", "\n", "\n", "std", "=", "df_reroute", ".", "score", ".", "rolling", "(", "100", ")", ".", "std", "(", ")", "\n", "\n", "ax", "=", "plt", ".", "gca", "(", ")", "\n", "# plt.plot(x2, y2, x1, y1, label=experiment)", "\n", "plt", ".", "plot", "(", "x2", ",", "y2", ",", "label", "=", "\"Ape-X\"", ")", "\n", "plt", ".", "plot", "(", "x1", ",", "y1", ",", "label", "=", "\"RBI\"", ")", "\n", "# plt.plot(x, std / y.abs(), label=experiment)", "\n", "plt", ".", "title", "(", "experiment", ",", "fontsize", "=", "8", ")", "\n", "if", "i", ">", "6", ":", "\n", "            ", "plt", ".", "xticks", "(", "[", "0", ",", "1e6", ",", "2e6", ",", "3e6", "]", ",", "[", "\"0\"", ",", "\"1M\"", ",", "\"2M\"", ",", "\"3M\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "plt", ".", "xticks", "(", "[", "0", ",", "1e6", ",", "2e6", ",", "3e6", "]", ",", "[", "\"\"", ",", "\"\"", ",", "\"\"", ",", "\"\"", "]", ")", "\n", "\n", "", "if", "i", "==", "6", ":", "\n", "            ", "plt", ".", "legend", "(", ")", "\n", "", "ax", ".", "yaxis", ".", "set_major_formatter", "(", "formatter", ")", "\n", "\n", "# plt.show()", "\n", "", "plt", ".", "savefig", "(", "\"/home/elad/Dropbox/projects/deeprl/results/final_rbi/plots/cumsum_%s.pdf\"", "%", "run_time", ",", "bbox_inches", "=", "\"tight\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.plot_mini_charts": [[257, 322], ["matplotlib.style.use", "matplotlib.figure", "matplotlib.rc", "matplotlib.rc", "matplotlib.ticker.FuncFormatter", "sorted", "matplotlib.savefig", "reroute_mini_dict.keys", "os.path.join", "os.path.join", "pandas.read_pickle", "pandas.read_pickle", "plot_results.preprocess_quantiles", "plot_results.preprocess_quantiles", "plot_results.preprocess", "plot_results.preprocess", "matplotlib.subplot", "matplotlib.plot", "matplotlib.gca", "plt.gca.fill_between", "matplotlib.plot", "matplotlib.gca", "plt.gca.fill_between", "matplotlib.title", "plt.gca.yaxis.set_major_formatter", "os.path.join", "os.path.join", "matplotlib.xticks", "matplotlib.xlabel", "matplotlib.xticks", "matplotlib.legend"], "function", ["home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.preprocess_quantiles", "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.preprocess_quantiles", "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.preprocess", "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.preprocess"], ["", "def", "plot_mini_charts", "(", ")", ":", "\n", "\n", "    ", "plt", ".", "style", ".", "use", "(", "'ggplot'", ")", "\n", "plt", ".", "figure", "(", "1", ",", "figsize", "=", "(", "18", ",", "3", ")", ")", "\n", "plt", ".", "rc", "(", "'ytick'", ",", "labelsize", "=", "10", ")", "\n", "plt", ".", "rc", "(", "'xtick'", ",", "labelsize", "=", "10", ")", "\n", "\n", "formatter", "=", "FuncFormatter", "(", "millions", ")", "\n", "\n", "i", "=", "0", "\n", "for", "experiment", "in", "sorted", "(", "reroute_mini_dict", ".", "keys", "(", ")", ")", ":", "\n", "\n", "        ", "i", "+=", "1", "\n", "if", "reroute_mini_dict", "[", "experiment", "]", "==", "\"na\"", ":", "\n", "            ", "continue", "\n", "\n", "# load reroute DF", "\n", "", "save_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "reroute_mini_dict", "[", "experiment", "]", ",", "\"postprocess\"", ")", "\n", "ape_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "ape_mini_dict", "[", "experiment", "]", ",", "\"postprocess\"", ")", "\n", "\n", "df_reroute", "=", "pd", ".", "read_pickle", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"df_reroute\"", ")", ")", "\n", "df_ape", "=", "pd", ".", "read_pickle", "(", "os", ".", "path", ".", "join", "(", "ape_dir", ",", "\"df_reroute\"", ")", ")", "\n", "\n", "df_reroute_u", ",", "df_reroute_d", "=", "preprocess_quantiles", "(", "df_reroute", ")", "\n", "df_ape_u", ",", "df_ape_d", "=", "preprocess_quantiles", "(", "df_ape", ")", "\n", "\n", "df_reroute", "=", "preprocess", "(", "df_reroute", ")", "\n", "df_ape", "=", "preprocess", "(", "df_ape", ")", "\n", "# plt.subplot(2, 2, i)", "\n", "plt", ".", "subplot", "(", "1", ",", "4", ",", "i", ")", "\n", "\n", "x1", "=", "df_reroute", ".", "index", "\n", "y1", "=", "df_reroute", ".", "score", "\n", "\n", "y1_u", "=", "df_reroute_u", ".", "score", "\n", "y1_d", "=", "df_reroute_d", ".", "score", "\n", "\n", "x2", "=", "df_ape", ".", "index", "\n", "y2", "=", "df_ape", ".", "score", "\n", "\n", "y2_u", "=", "df_ape_u", ".", "score", "\n", "y2_d", "=", "df_ape_d", ".", "score", "\n", "\n", "# plt.plot(x2, y2, x1, y1, label=experiment)", "\n", "plt", ".", "plot", "(", "x2", ",", "y2", ",", "label", "=", "\"Ape-X\"", ")", "\n", "ax", "=", "plt", ".", "gca", "(", ")", "\n", "ax", ".", "fill_between", "(", "x2", ",", "y2_u", ",", "y2_d", ",", "alpha", "=", "0.5", ")", "\n", "plt", ".", "plot", "(", "x1", ",", "y1", ",", "label", "=", "\"RBI\"", ")", "\n", "ax", "=", "plt", ".", "gca", "(", ")", "\n", "ax", ".", "fill_between", "(", "x1", ",", "y1_u", ",", "y1_d", ",", "alpha", "=", "0.5", ")", "\n", "# plt.plot(x, std / y.abs(), label=experiment)", "\n", "plt", ".", "title", "(", "experiment", ",", "fontsize", "=", "14", ")", "\n", "\n", "if", "i", ">", "0", ":", "\n", "            ", "plt", ".", "xticks", "(", "[", "0", ",", "1e6", ",", "2e6", ",", "3e6", "]", ",", "[", "\"0\"", ",", "\"1M\"", ",", "\"2M\"", ",", "\"3M\"", "]", ")", "\n", "plt", ".", "xlabel", "(", "\"Minibatches (# of backward passes)\"", ")", "\n", "", "else", ":", "\n", "            ", "plt", ".", "xticks", "(", "[", "0", ",", "1e6", ",", "2e6", ",", "3e6", "]", ",", "[", "\"\"", ",", "\"\"", ",", "\"\"", ",", "\"\"", "]", ")", "\n", "\n", "", "if", "i", "==", "1", ":", "\n", "            ", "plt", ".", "legend", "(", "loc", "=", "'lower right'", ",", "prop", "=", "{", "'size'", ":", "14", "}", ")", "\n", "", "ax", ".", "yaxis", ".", "set_major_formatter", "(", "formatter", ")", "\n", "\n", "# plt.show()", "\n", "", "plt", ".", "savefig", "(", "\"/home/elad/Dropbox/projects/deeprl/results/final_rbi/plots/mini_reroute_%s.pdf\"", "%", "run_time", ",", "bbox_inches", "=", "\"tight\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.plot_charts": [[324, 386], ["matplotlib.style.use", "matplotlib.figure", "matplotlib.rc", "matplotlib.rc", "matplotlib.ticker.FuncFormatter", "sorted", "matplotlib.savefig", "reroute_experiment_dict.keys", "os.path.join", "os.path.join", "pandas.read_pickle", "pandas.read_pickle", "plot_results.preprocess_quantiles", "plot_results.preprocess_quantiles", "plot_results.preprocess", "plot_results.preprocess", "matplotlib.subplot", "matplotlib.plot", "matplotlib.gca", "plt.gca.fill_between", "matplotlib.plot", "matplotlib.gca", "plt.gca.fill_between", "matplotlib.title", "plt.gca.yaxis.set_major_formatter", "os.path.join", "os.path.join", "matplotlib.xticks", "matplotlib.xticks", "matplotlib.legend"], "function", ["home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.preprocess_quantiles", "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.preprocess_quantiles", "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.preprocess", "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.preprocess"], ["", "def", "plot_charts", "(", ")", ":", "\n", "\n", "    ", "plt", ".", "style", ".", "use", "(", "'ggplot'", ")", "\n", "plt", ".", "figure", "(", "1", ",", "figsize", "=", "(", "12", ",", "4", ")", ")", "\n", "plt", ".", "rc", "(", "'ytick'", ",", "labelsize", "=", "6", ")", "\n", "plt", ".", "rc", "(", "'xtick'", ",", "labelsize", "=", "6", ")", "\n", "\n", "formatter", "=", "FuncFormatter", "(", "millions", ")", "\n", "\n", "i", "=", "0", "\n", "for", "experiment", "in", "sorted", "(", "reroute_experiment_dict", ".", "keys", "(", ")", ")", ":", "\n", "\n", "        ", "i", "+=", "1", "\n", "if", "reroute_experiment_dict", "[", "experiment", "]", "==", "\"na\"", ":", "\n", "            ", "continue", "\n", "\n", "# load reroute DF", "\n", "", "save_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "reroute_experiment_dict", "[", "experiment", "]", ",", "\"postprocess\"", ")", "\n", "ape_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "ape_experiment_dict", "[", "experiment", "]", ",", "\"postprocess\"", ")", "\n", "\n", "df_reroute", "=", "pd", ".", "read_pickle", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"df_reroute\"", ")", ")", "\n", "df_ape", "=", "pd", ".", "read_pickle", "(", "os", ".", "path", ".", "join", "(", "ape_dir", ",", "\"df_reroute\"", ")", ")", "\n", "\n", "df_reroute_u", ",", "df_reroute_d", "=", "preprocess_quantiles", "(", "df_reroute", ")", "\n", "df_ape_u", ",", "df_ape_d", "=", "preprocess_quantiles", "(", "df_ape", ")", "\n", "\n", "df_reroute", "=", "preprocess", "(", "df_reroute", ")", "\n", "df_ape", "=", "preprocess", "(", "df_ape", ")", "\n", "plt", ".", "subplot", "(", "2", ",", "6", ",", "i", ")", "\n", "\n", "x1", "=", "df_reroute", ".", "index", "\n", "y1", "=", "df_reroute", ".", "score", "\n", "\n", "y1_u", "=", "df_reroute_u", ".", "score", "\n", "y1_d", "=", "df_reroute_d", ".", "score", "\n", "\n", "x2", "=", "df_ape", ".", "index", "\n", "y2", "=", "df_ape", ".", "score", "\n", "\n", "y2_u", "=", "df_ape_u", ".", "score", "\n", "y2_d", "=", "df_ape_d", ".", "score", "\n", "\n", "# plt.plot(x2, y2, x1, y1, label=experiment)", "\n", "plt", ".", "plot", "(", "x2", ",", "y2", ",", "label", "=", "\"Ape-X\"", ")", "\n", "ax", "=", "plt", ".", "gca", "(", ")", "\n", "ax", ".", "fill_between", "(", "x2", ",", "y2_u", ",", "y2_d", ",", "alpha", "=", "0.5", ")", "\n", "plt", ".", "plot", "(", "x1", ",", "y1", ",", "label", "=", "\"RBI\"", ")", "\n", "ax", "=", "plt", ".", "gca", "(", ")", "\n", "ax", ".", "fill_between", "(", "x1", ",", "y1_u", ",", "y1_d", ",", "alpha", "=", "0.5", ")", "\n", "# plt.plot(x, std / y.abs(), label=experiment)", "\n", "plt", ".", "title", "(", "experiment", ",", "fontsize", "=", "8", ")", "\n", "if", "i", ">", "6", ":", "\n", "            ", "plt", ".", "xticks", "(", "[", "0", ",", "1e6", ",", "2e6", ",", "3e6", "]", ",", "[", "\"0\"", ",", "\"1M\"", ",", "\"2M\"", ",", "\"3M\"", "]", ")", "\n", "", "else", ":", "\n", "            ", "plt", ".", "xticks", "(", "[", "0", ",", "1e6", ",", "2e6", ",", "3e6", "]", ",", "[", "\"\"", ",", "\"\"", ",", "\"\"", ",", "\"\"", "]", ")", "\n", "\n", "", "if", "i", "==", "6", ":", "\n", "            ", "plt", ".", "legend", "(", ")", "\n", "", "ax", ".", "yaxis", ".", "set_major_formatter", "(", "formatter", ")", "\n", "\n", "# plt.show()", "\n", "", "plt", ".", "savefig", "(", "\"/home/elad/Dropbox/projects/deeprl/results/final_rbi/plots/reroute_%s.pdf\"", "%", "run_time", ",", "bbox_inches", "=", "\"tight\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.ablation_test": [[388, 458], ["matplotlib.style.use", "matplotlib.figure", "matplotlib.rc", "matplotlib.rc", "matplotlib.ticker.FuncFormatter", "sorted", "matplotlib.savefig", "ablation_dict.keys", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "pandas.read_pickle", "pandas.read_pickle", "pandas.read_pickle", "pandas.read_pickle", "pandas.read_pickle", "plot_results.preprocess", "plot_results.preprocess", "plot_results.preprocess", "plot_results.preprocess", "plot_results.preprocess", "matplotlib.subplot", "matplotlib.gca", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.title", "matplotlib.xticks", "plt.gca.yaxis.set_major_formatter", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "matplotlib.legend", "matplotlib.legend"], "function", ["home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.preprocess", "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.preprocess", "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.preprocess", "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.preprocess", "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.preprocess"], ["", "def", "ablation_test", "(", ")", ":", "\n", "\n", "    ", "plt", ".", "style", ".", "use", "(", "'ggplot'", ")", "\n", "plt", ".", "figure", "(", "1", ",", "figsize", "=", "(", "6", ",", "3", ")", ")", "\n", "plt", ".", "rc", "(", "'ytick'", ",", "labelsize", "=", "6", ")", "\n", "plt", ".", "rc", "(", "'xtick'", ",", "labelsize", "=", "6", ")", "\n", "\n", "formatter", "=", "FuncFormatter", "(", "millions", ")", "\n", "\n", "i", "=", "0", "\n", "for", "experiment", "in", "sorted", "(", "ablation_dict", ".", "keys", "(", ")", ")", ":", "\n", "\n", "        ", "i", "+=", "1", "\n", "if", "reroute_experiment_dict", "[", "experiment", "]", "==", "\"na\"", ":", "\n", "            ", "continue", "\n", "\n", "# load reroute DF", "\n", "", "rbi_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "ablation_dict", "[", "experiment", "]", "[", "'rbi'", "]", ",", "\"postprocess\"", ")", "\n", "is_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "ablation_dict", "[", "experiment", "]", "[", "'nois'", "]", ",", "\"postprocess\"", ")", "\n", "prior_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "ablation_dict", "[", "experiment", "]", "[", "'noprior'", "]", ",", "\"postprocess\"", ")", "\n", "ppo_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "ablation_dict", "[", "experiment", "]", "[", "'ppo'", "]", ",", "\"postprocess\"", ")", "\n", "explore_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "ablation_dict", "[", "experiment", "]", "[", "'noexp'", "]", ",", "\"postprocess\"", ")", "\n", "\n", "df_rbi", "=", "pd", ".", "read_pickle", "(", "os", ".", "path", ".", "join", "(", "rbi_dir", ",", "\"df_reroute\"", ")", ")", "\n", "df_is", "=", "pd", ".", "read_pickle", "(", "os", ".", "path", ".", "join", "(", "is_dir", ",", "\"df_reroute\"", ")", ")", "\n", "df_prior", "=", "pd", ".", "read_pickle", "(", "os", ".", "path", ".", "join", "(", "prior_dir", ",", "\"df_reroute\"", ")", ")", "\n", "df_ppo", "=", "pd", ".", "read_pickle", "(", "os", ".", "path", ".", "join", "(", "ppo_dir", ",", "\"df_reroute\"", ")", ")", "\n", "df_explore", "=", "pd", ".", "read_pickle", "(", "os", ".", "path", ".", "join", "(", "explore_dir", ",", "\"df_reroute\"", ")", ")", "\n", "\n", "df_rbi", "=", "preprocess", "(", "df_rbi", ")", "\n", "df_is", "=", "preprocess", "(", "df_is", ")", "\n", "df_prior", "=", "preprocess", "(", "df_prior", ")", "\n", "df_ppo", "=", "preprocess", "(", "df_ppo", ")", "\n", "df_explore", "=", "preprocess", "(", "df_explore", ")", "\n", "\n", "plt", ".", "subplot", "(", "1", ",", "2", ",", "i", ")", "\n", "\n", "x1", "=", "df_rbi", ".", "index", "\n", "y1", "=", "df_rbi", ".", "score", "\n", "\n", "x2", "=", "df_is", ".", "index", "\n", "y2", "=", "df_is", ".", "score", "\n", "\n", "x3", "=", "df_prior", ".", "index", "\n", "y3", "=", "df_prior", ".", "score", "\n", "\n", "x4", "=", "df_ppo", ".", "index", "\n", "y4", "=", "df_ppo", ".", "score", "\n", "\n", "x5", "=", "df_explore", ".", "index", "\n", "y5", "=", "df_explore", ".", "score", "\n", "\n", "ax", "=", "plt", ".", "gca", "(", ")", "\n", "# plt.plot(x2, y2, x1, y1, label=experiment)", "\n", "plt", ".", "plot", "(", "x2", ",", "y2", ",", "label", "=", "\"No IS Correction\"", ",", "linewidth", "=", "1.0", ")", "\n", "plt", ".", "plot", "(", "x3", ",", "y3", ",", "label", "=", "\"TDE Priority\"", ",", "linewidth", "=", "1.0", ")", "\n", "plt", ".", "plot", "(", "x5", ",", "y5", ",", "label", "=", "\"Flat Explotarion\"", ",", "linewidth", "=", "1.0", ")", "\n", "plt", ".", "plot", "(", "x4", ",", "y4", ",", "label", "=", "\"Greedy\"", ",", "linewidth", "=", "1.0", ",", "color", "=", "\"goldenrod\"", ")", "\n", "plt", ".", "plot", "(", "x1", ",", "y1", ",", "label", "=", "\"RBI\"", ",", "color", "=", "\"purple\"", ")", "\n", "# plt.plot(x, std / y.abs(), label=experiment)", "\n", "plt", ".", "title", "(", "experiment", ",", "fontsize", "=", "8", ")", "\n", "plt", ".", "xticks", "(", "[", "0", ",", "1e6", ",", "2e6", ",", "3e6", "]", ",", "[", "\"0\"", ",", "\"1M\"", ",", "\"2M\"", ",", "\"3M\"", "]", ")", "\n", "\n", "if", "i", "==", "2", ":", "\n", "            ", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "legend", "(", "prop", "=", "{", "'size'", ":", "8", "}", ")", "\n", "", "ax", ".", "yaxis", ".", "set_major_formatter", "(", "formatter", ")", "\n", "\n", "# plt.show()", "\n", "", "plt", ".", "savefig", "(", "\"/home/elad/Dropbox/projects/deeprl/results/final_rbi/plots/ablation_%s.pdf\"", "%", "run_time", ",", "bbox_inches", "=", "\"tight\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.plot_time": [[460, 499], ["matplotlib.style.use", "matplotlib.figure", "matplotlib.rc", "matplotlib.rc", "sorted", "matplotlib.savefig", "reroute_experiment_dict.keys", "os.path.join", "os.path.join", "pandas.read_pickle", "pandas.read_pickle", "plot_results.preprocess", "plot_results.preprocess", "matplotlib.subplot", "matplotlib.gca", "matplotlib.plot", "matplotlib.title", "os.path.join", "os.path.join", "preprocess.time.min", "preprocess.time.min"], "function", ["home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.preprocess", "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.preprocess"], ["", "def", "plot_time", "(", ")", ":", "\n", "\n", "    ", "plt", ".", "style", ".", "use", "(", "'ggplot'", ")", "\n", "plt", ".", "figure", "(", "1", ",", "figsize", "=", "(", "12", ",", "4", ")", ")", "\n", "plt", ".", "rc", "(", "'ytick'", ",", "labelsize", "=", "4", ")", "\n", "plt", ".", "rc", "(", "'xtick'", ",", "labelsize", "=", "4", ")", "\n", "\n", "i", "=", "0", "\n", "for", "experiment", "in", "sorted", "(", "reroute_experiment_dict", ".", "keys", "(", ")", ")", ":", "\n", "\n", "        ", "i", "+=", "1", "\n", "if", "reroute_experiment_dict", "[", "experiment", "]", "==", "\"na\"", ":", "\n", "            ", "continue", "\n", "\n", "# load reroute DF", "\n", "", "save_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "reroute_experiment_dict", "[", "experiment", "]", ",", "\"postprocess\"", ")", "\n", "ape_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "ape_experiment_dict", "[", "experiment", "]", ",", "\"postprocess\"", ")", "\n", "\n", "df_reroute", "=", "pd", ".", "read_pickle", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"df_reroute\"", ")", ")", "\n", "df_ape", "=", "pd", ".", "read_pickle", "(", "os", ".", "path", ".", "join", "(", "ape_dir", ",", "\"df_reroute\"", ")", ")", "\n", "\n", "df_reroute", "=", "preprocess", "(", "df_reroute", ")", "\n", "df_ape", "=", "preprocess", "(", "df_ape", ")", "\n", "plt", ".", "subplot", "(", "2", ",", "6", ",", "i", ")", "\n", "\n", "x1", "=", "(", "df_reroute", ".", "time", "-", "df_reroute", ".", "time", ".", "min", "(", ")", ")", "/", "3600", "\n", "y1", "=", "df_reroute", ".", "score", "\n", "\n", "x2", "=", "(", "df_ape", ".", "time", "-", "df_ape", ".", "time", ".", "min", "(", ")", ")", "/", "3600", "\n", "y2", "=", "df_ape", ".", "score", "\n", "\n", "ax", "=", "plt", ".", "gca", "(", ")", "\n", "plt", ".", "plot", "(", "x2", ",", "y2", ",", "x1", ",", "y1", ",", "label", "=", "experiment", ")", "\n", "# plt.plot(x, std / y.abs(), label=experiment)", "\n", "plt", ".", "title", "(", "experiment", ",", "fontsize", "=", "8", ")", "\n", "# plt.xticks([0, 1e6, 2e6, 3e6], [\"0\", \"1e6\", \"2e6\", \"3e6\"])", "\n", "\n", "# plt.show()", "\n", "", "plt", ".", "savefig", "(", "\"/home/elad/Dropbox/projects/deeprl/results/final_rbi/plots/time_%s.pdf\"", "%", "run_time", ",", "bbox_inches", "=", "\"tight\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.millions": [[501, 510], ["None"], "function", ["None"], ["", "def", "millions", "(", "x", ",", "pos", ")", ":", "\n", "    ", "'The two args are the value and tick position'", "\n", "\n", "if", "x", "<", "1000", ":", "\n", "        ", "return", "'%1.f'", "%", "x", "\n", "", "if", "x", "<", "1e6", ":", "\n", "        ", "return", "'%1.fK'", "%", "(", "x", "*", "1e-3", ")", "\n", "", "else", ":", "\n", "        ", "return", "'%1.fM'", "%", "(", "x", "*", "1e-6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.deterministic_policies": [[512, 594], ["LinNet", "torch.randn", "torch.optim.SGD", "LinNet", "torch.optim.SGD", "LinNet.load_state_dict", "torch.rand", "torch.autograd.Variable", "range", "print", "print", "print", "range", "print", "print", "print", "print", "LinNet.parameters", "LinNet.parameters", "LinNet.state_dict", "torch.autograd.Variable.sum", "torch.autograd.Variable", "LinNet.", "torch.optim.SGD.zero_grad", "loss.backward", "torch.optim.SGD.step", "LinNet.", "int", "torch.optim.SGD.zero_grad", "loss.backward", "torch.optim.SGD.step", "super().__init__", "torch.nn.Sequential", "plot_results..layers", "torch.ones", "torch.autograd.Variable", "str", "torch.autograd.Variable", "numpy.random.choice", "[].sum", "str", "str", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.log_softmax", "torch.autograd.Variable.data.numpy", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax"], "function", ["home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.memory.ReplayBatchSampler.__init__"], ["", "", "def", "deterministic_policies", "(", ")", ":", "\n", "\n", "    ", "import", "torch", "\n", "\n", "action_space", "=", "18", "\n", "n_steps", "=", "200", "\n", "\n", "class", "LinNet", "(", "torch", ".", "nn", ".", "Module", ")", ":", "\n", "\n", "        ", "def", "__init__", "(", "self", ")", ":", "\n", "\n", "            ", "super", "(", "LinNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "layers", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "torch", ".", "nn", ".", "Linear", "(", "100", ",", "20", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", ")", ",", "\n", "torch", ".", "nn", ".", "Linear", "(", "20", ",", "action_space", ")", ",", "\n", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "            ", "y", "=", "self", ".", "layers", "(", "x", ")", "\n", "return", "y", "\n", "\n", "", "", "net2", "=", "LinNet", "(", ")", "\n", "x", "=", "torch", ".", "randn", "(", "1", ",", "100", ")", "\n", "optimizer2", "=", "torch", ".", "optim", ".", "SGD", "(", "net2", ".", "parameters", "(", ")", ",", "lr", "=", "0.001", ")", "\n", "\n", "net", "=", "LinNet", "(", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "net", ".", "parameters", "(", ")", ",", "lr", "=", "0.001", ")", "\n", "net", ".", "load_state_dict", "(", "net2", ".", "state_dict", "(", ")", ")", "\n", "\n", "# pi1 = torch.autograd.Variable(torch.FloatTensor([1, 0, 0, 0]))", "\n", "\n", "pi", "=", "torch", ".", "rand", "(", "action_space", ")", "\n", "pi", "=", "pi", "/", "pi", ".", "sum", "(", ")", "\n", "pi", "=", "torch", ".", "autograd", ".", "Variable", "(", "pi", ")", "\n", "# pi = torch.autograd.Variable(torch.FloatTensor([1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))", "\n", "# pi = torch.autograd.Variable(torch.FloatTensor([1, 0, 0, 0, 0]))", "\n", "# pi = torch.autograd.Variable(torch.FloatTensor([0.2, 0.2, 0.2, 0.2, 0.2]))", "\n", "# pi = torch.autograd.Variable(torch.FloatTensor([0.9, 0.1, 0., 0., 0.]))", "\n", "# pi = torch.autograd.Variable(torch.FloatTensor([0.9, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))", "\n", "pi", "=", "torch", ".", "autograd", ".", "Variable", "(", "torch", ".", "ones", "(", "18", ")", ")", "/", "18", "\n", "\n", "for", "i", "in", "range", "(", "n_steps", ")", ":", "\n", "\n", "        ", "y", "=", "net2", "(", "torch", ".", "autograd", ".", "Variable", "(", "x", ")", ")", "\n", "\n", "# a = int(np.random.choice(action_space, p=pi.data.numpy()))", "\n", "#", "\n", "# loss = -(torch.nn.functional.log_softmax(y, dim=1)[0, a]).sum()", "\n", "loss", "=", "-", "(", "pi", "*", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "y", ",", "dim", "=", "1", ")", ")", ".", "sum", "(", ")", "\n", "\n", "optimizer2", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer2", ".", "step", "(", ")", "\n", "\n", "", "loss", "=", "-", "(", "pi", "*", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "y", ",", "dim", "=", "1", ")", ")", ".", "sum", "(", ")", "\n", "print", "(", "i", ")", "\n", "print", "(", "\"beta: %s\"", "%", "str", "(", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "y", ",", "dim", "=", "1", ")", ")", ")", "\n", "print", "(", "\"loss: %g\"", "%", "loss", ")", "\n", "\n", "# pi1 = torch.autograd.Variable(torch.FloatTensor([0, 1, 0, 0]))", "\n", "# pi1 = torch.autograd.Variable(torch.FloatTensor([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))", "\n", "\n", "for", "i", "in", "range", "(", "n_steps", ")", ":", "\n", "        ", "y", "=", "net", "(", "torch", ".", "autograd", ".", "Variable", "(", "x", ")", ")", "\n", "\n", "a", "=", "int", "(", "np", ".", "random", ".", "choice", "(", "action_space", ",", "p", "=", "pi", ".", "data", ".", "numpy", "(", ")", ")", ")", "\n", "\n", "loss", "=", "-", "(", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "y", ",", "dim", "=", "1", ")", "[", "0", ",", "a", "]", ")", ".", "sum", "(", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "", "loss", "=", "-", "(", "pi", "*", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "y", ",", "dim", "=", "1", ")", ")", ".", "sum", "(", ")", "\n", "print", "(", "i", ")", "\n", "print", "(", "\"beta: %s\"", "%", "str", "(", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "y", ",", "dim", "=", "1", ")", ")", ")", "\n", "print", "(", "\"loss: %g\"", "%", "loss", ")", "\n", "\n", "print", "(", "\"pi: %s\"", "%", "str", "(", "pi", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.main": [[596, 609], ["plot_results.plot_mini_charts", "print"], "function", ["home.repos.pwc.inspect_result.eladsar_rbi.None.plot_results.plot_mini_charts"], ["", "def", "main", "(", ")", ":", "\n", "\n", "# deterministic_policies()", "\n", "\n", "# for experiment in os.listdir(root_dir):", "\n", "#     convert_to_dataframe(experiment)", "\n", "\n", "# plot_charts()", "\n", "    ", "plot_mini_charts", "(", ")", "\n", "# plot_time()", "\n", "# plot_cumulative()", "\n", "# ablation_test()", "\n", "print", "(", "\"end of script\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.__init__": [[12, 90], ["len", "float", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "torch.device", "print", "os.path.join", "os.path.join", "os.path.join", "numpy.nonzero", "os.mkdir", "os.mkdir", "os.mkdir", "os.mkdir", "os.mkdir", "numpy.save", "numpy.save", "numpy.save", "os.path.join", "os.path.join", "os.path.join", "numpy.exp"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "root_dir", ",", "checkpoint", "=", "None", ",", "player", "=", "False", ")", ":", "\n", "# parameters", "\n", "        ", "self", ".", "discount", "=", "args", ".", "discount", "\n", "self", ".", "update_target_interval", "=", "args", ".", "update_target_interval", "\n", "self", ".", "update_memory_interval", "=", "args", ".", "update_memory_interval", "\n", "self", ".", "load_memory_interval", "=", "args", ".", "load_memory_interval", "\n", "self", ".", "action_space", "=", "len", "(", "np", ".", "nonzero", "(", "consts", ".", "actions", "[", "args", ".", "game", "]", ")", "[", "0", "]", ")", "\n", "self", ".", "skip", "=", "args", ".", "skip", "\n", "self", ".", "termination_reward", "=", "args", ".", "termination_reward", "\n", "self", ".", "n_steps", "=", "args", ".", "n_steps", "\n", "self", ".", "reward_shape", "=", "args", ".", "reward_shape", "\n", "self", ".", "player_replay_size", "=", "args", ".", "player_replay_size", "\n", "self", ".", "cmin", "=", "args", ".", "cmin", "\n", "self", ".", "cmax", "=", "args", ".", "cmax", "\n", "self", ".", "history_length", "=", "args", ".", "history_length", "\n", "self", ".", "random_initialization", "=", "args", ".", "random_initialization", "\n", "self", ".", "epsilon", "=", "args", ".", "epsilon", "*", "self", ".", "action_space", "/", "(", "self", ".", "action_space", "-", "1", ")", "\n", "self", ".", "delta", "=", "args", ".", "delta", "\n", "self", ".", "player", "=", "args", ".", "player", "\n", "self", ".", "priority_beta", "=", "args", ".", "priority_beta", "\n", "self", ".", "priority_alpha", "=", "args", ".", "priority_alpha", "\n", "self", ".", "epsilon_a", "=", "args", ".", "epsilon_a", "\n", "self", ".", "cuda_id", "=", "args", ".", "cuda_default", "\n", "self", ".", "behavioral_avg_frame", "=", "1", "\n", "self", ".", "behavioral_avg_score", "=", "-", "1", "\n", "self", ".", "entropy_loss", "=", "float", "(", "(", "1", "-", "(", "1", "/", "(", "1", "+", "(", "self", ".", "action_space", "-", "1", ")", "*", "np", ".", "exp", "(", "-", "args", ".", "softmax_diff", ")", ")", ")", ")", "*", "(", "self", ".", "action_space", "/", "(", "self", ".", "action_space", "-", "1", ")", ")", ")", "\n", "self", ".", "batch", "=", "args", ".", "batch", "\n", "self", ".", "replay_memory_size", "=", "args", ".", "replay_memory_size", "\n", "self", ".", "n_actors", "=", "args", ".", "n_actors", "\n", "self", ".", "actor_index", "=", "args", ".", "actor_index", "\n", "self", ".", "n_players", "=", "args", ".", "n_players", "\n", "self", ".", "player", "=", "args", ".", "player", "\n", "self", ".", "n_tot", "=", "args", ".", "n_tot", "\n", "self", ".", "max_length", "=", "consts", ".", "max_length", "[", "args", ".", "game", "]", "\n", "self", ".", "max_score", "=", "consts", ".", "max_score", "[", "args", ".", "game", "]", "\n", "self", ".", "start_time", "=", "consts", ".", "start_time", "\n", "\n", "self", ".", "mix", "=", "self", ".", "delta", "\n", "self", ".", "min_loop", "=", "1.", "/", "44", "\n", "self", ".", "hidden_state", "=", "args", ".", "hidden_features_rnn", "\n", "\n", "self", ".", "seq_length", "=", "args", ".", "seq_length", "\n", "if", "args", ".", "target", "==", "'tde'", ":", "\n", "            ", "self", ".", "seq_length", "+=", "self", ".", "n_steps", "\n", "\n", "", "self", ".", "burn_in", "=", "args", ".", "burn_in", "\n", "self", ".", "seq_overlap", "=", "args", ".", "seq_overlap", "\n", "\n", "self", ".", "rec_type", "=", "consts", ".", "rec_type", "\n", "\n", "self", ".", "checkpoint", "=", "checkpoint", "\n", "self", ".", "root_dir", "=", "root_dir", "\n", "self", ".", "best_player_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"best\"", ")", "\n", "self", ".", "snapshot_path", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"snapshot\"", ")", "\n", "self", ".", "explore_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"explore\"", ")", "\n", "self", ".", "list_dir", "=", "os", ".", "path", ".", "join", "(", "root_dir", ",", "\"list\"", ")", "\n", "self", ".", "writelock", "=", "os", ".", "path", ".", "join", "(", "self", ".", "list_dir", ",", "\"writelock.npy\"", ")", "\n", "self", ".", "episodelock", "=", "os", ".", "path", ".", "join", "(", "self", ".", "list_dir", ",", "\"episodelock.npy\"", ")", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda:%d\"", "%", "self", ".", "cuda_id", ")", "\n", "\n", "if", "player", ":", "\n", "\n", "            ", "print", "(", "\"Explorer player\"", ")", "\n", "self", ".", "trajectory_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"trajectory\"", ")", "\n", "self", ".", "screen_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"screen\"", ")", "\n", "self", ".", "readlock", "=", "os", ".", "path", ".", "join", "(", "self", ".", "list_dir", ",", "\"readlock_explore.npy\"", ")", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "os", ".", "mkdir", "(", "self", ".", "best_player_dir", ")", "\n", "os", ".", "mkdir", "(", "self", ".", "explore_dir", ")", "\n", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"trajectory\"", ")", ")", "\n", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"screen\"", ")", ")", "\n", "os", ".", "mkdir", "(", "self", ".", "list_dir", ")", "\n", "np", ".", "save", "(", "self", ".", "writelock", ",", "0", ")", "\n", "np", ".", "save", "(", "self", ".", "episodelock", ",", "0", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "self", ".", "list_dir", ",", "\"readlock_explore.npy\"", ")", ",", "[", "]", ")", "\n", "", "except", "FileExistsError", ":", "\n", "                ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.save_checkpoint": [[91, 93], ["None"], "methods", ["None"], ["", "", "", "def", "save_checkpoint", "(", "self", ",", "path", ",", "aux", "=", "None", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.load_checkpoint": [[94, 97], ["None"], "methods", ["None"], ["", "def", "load_checkpoint", "(", "self", ",", "path", ")", ":", "\n", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.train": [[98, 100], ["None"], "methods", ["None"], ["", "def", "train", "(", "self", ",", "n_interval", ",", "n_tot", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.evaluate": [[101, 103], ["None"], "methods", ["None"], ["", "def", "evaluate", "(", "self", ",", "n_interval", ",", "n_tot", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.set_player": [[104, 130], ["None"], "methods", ["None"], ["", "def", "set_player", "(", "self", ",", "player", ",", "cmin", "=", "None", ",", "cmax", "=", "None", ",", "delta", "=", "None", ",", "\n", "epsilon", "=", "None", ",", "behavioral_avg_score", "=", "None", ",", "\n", "behavioral_avg_frame", "=", "None", ",", "explore_threshold", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "player", "=", "player", "\n", "\n", "if", "epsilon", "is", "not", "None", ":", "\n", "            ", "self", ".", "epsilon", "=", "epsilon", "*", "self", ".", "action_space", "/", "(", "self", ".", "action_space", "-", "1", ")", "\n", "\n", "", "if", "cmin", "is", "not", "None", ":", "\n", "            ", "self", ".", "cmin", "=", "cmin", "\n", "\n", "", "if", "cmax", "is", "not", "None", ":", "\n", "            ", "self", ".", "cmax", "=", "cmax", "\n", "\n", "", "if", "delta", "is", "not", "None", ":", "\n", "            ", "self", ".", "delta", "=", "delta", "\n", "\n", "", "if", "explore_threshold", "is", "not", "None", ":", "\n", "            ", "self", ".", "explore_threshold", "=", "explore_threshold", "\n", "\n", "", "if", "behavioral_avg_score", "is", "not", "None", ":", "\n", "            ", "self", ".", "behavioral_avg_score", "=", "behavioral_avg_score", "\n", "\n", "", "if", "behavioral_avg_frame", "is", "not", "None", ":", "\n", "            ", "self", ".", "behavioral_avg_frame", "=", "behavioral_avg_frame", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.resume": [[131, 134], ["agent.Agent.load_checkpoint"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.load_checkpoint"], ["", "", "def", "resume", "(", "self", ",", "model_path", ")", ":", "\n", "        ", "aux", "=", "self", ".", "load_checkpoint", "(", "model_path", ")", "\n", "return", "aux", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.clean": [[135, 171], ["os.path.join", "os.path.join", "itertools.count", "shutil.rmtree", "time.sleep", "set", "os.listdir", "numpy.load", "int", "shutil.rmtree", "os.path.join", "numpy.load", "os.remove", "os.path.join", "agent.Agent.load_checkpoint", "traj.split", "os.path.join", "set.add", "os.path.join", "str"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.load_checkpoint"], ["", "def", "clean", "(", "self", ")", ":", "\n", "\n", "        ", "screen_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"screen\"", ")", "\n", "trajectory_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"trajectory\"", ")", "\n", "\n", "for", "i", "in", "itertools", ".", "count", "(", ")", ":", "\n", "\n", "            ", "time", ".", "sleep", "(", "2", ")", "\n", "\n", "try", ":", "\n", "                ", "del_inf", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "list_dir", ",", "\"old_explore.npy\"", ")", ")", "\n", "", "except", "(", "IOError", ",", "ValueError", ")", ":", "\n", "                ", "continue", "\n", "", "traj_min", "=", "del_inf", "[", "0", "]", "-", "32", "\n", "episode_list", "=", "set", "(", ")", "\n", "\n", "for", "traj", "in", "os", ".", "listdir", "(", "trajectory_dir", ")", ":", "\n", "                ", "traj_num", "=", "int", "(", "traj", ".", "split", "(", "\".\"", ")", "[", "0", "]", ")", "\n", "if", "traj_num", "<", "traj_min", ":", "\n", "                    ", "traj_data", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "trajectory_dir", ",", "traj", ")", ")", "\n", "for", "d", "in", "traj_data", "[", "'ep'", "]", ":", "\n", "                        ", "episode_list", ".", "add", "(", "d", ")", "\n", "", "os", ".", "remove", "(", "os", ".", "path", ".", "join", "(", "trajectory_dir", ",", "traj", ")", ")", "\n", "\n", "", "", "for", "ep", "in", "episode_list", ":", "\n", "                ", "shutil", ".", "rmtree", "(", "os", ".", "path", ".", "join", "(", "screen_dir", ",", "str", "(", "ep", ")", ")", ")", "\n", "\n", "", "if", "not", "i", "%", "50", ":", "\n", "                ", "try", ":", "\n", "                    ", "self", ".", "load_checkpoint", "(", "self", ".", "snapshot_path", ")", "\n", "if", "self", ".", "n_offset", ">=", "args", ".", "n_tot", ":", "\n", "                        ", "break", "\n", "", "", "except", ":", "\n", "                    ", "pass", "\n", "\n", "", "", "", "shutil", ".", "rmtree", "(", "self", ".", "root_dir", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Singleton.__call__": [[11, 15], ["super().__call__"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Singleton.__call__"], ["def", "__call__", "(", "cls", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "cls", "not", "in", "cls", ".", "_instances", ":", "\n", "            ", "cls", ".", "_instances", "[", "cls", "]", "=", "super", "(", "Singleton", ",", "cls", ")", ".", "__call__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "cls", ".", "_instances", "[", "cls", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info": [[39, 42], ["Logger.logger.info"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info"], ["@", "staticmethod", "\n", "def", "info", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "Logger", ".", "logger", ".", "info", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.error": [[43, 46], ["Logger.logger.error"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.error"], ["", "@", "staticmethod", "\n", "def", "error", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "Logger", ".", "logger", ".", "error", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.debug": [[47, 50], ["Logger.logger.debug"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.debug"], ["", "@", "staticmethod", "\n", "def", "debug", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "Logger", ".", "logger", ".", "debug", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.warning": [[51, 54], ["Logger.logger.warning"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.warning"], ["", "@", "staticmethod", "\n", "def", "warning", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "Logger", ".", "logger", ".", "warning", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.memory_rnn.MemoryRNN.__init__": [[18, 37], ["super().__init__", "numpy.fliplr", "numpy.expand_dims", "numpy.arange", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.memory.ReplayBatchSampler.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "MemoryRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "history_length", "=", "args", ".", "history_length", "\n", "self", ".", "n_steps", "=", "args", ".", "n_steps", "\n", "\n", "self", ".", "seq_length", "=", "args", ".", "seq_length", "\n", "self", ".", "reward_length", "=", "args", ".", "seq_length", "\n", "\n", "if", "args", ".", "target", "==", "'tde'", ":", "\n", "            ", "self", ".", "seq_length", "+=", "self", ".", "n_steps", "\n", "", "else", ":", "\n", "            ", "self", ".", "n_steps", "=", "0", "\n", "\n", "", "self", ".", "burn_in", "=", "args", ".", "burn_in", "\n", "self", ".", "history_mat", "=", "np", ".", "expand_dims", "(", "np", ".", "arange", "(", "self", ".", "seq_length", "+", "self", ".", "burn_in", ")", ",", "axis", "=", "1", ")", "+", "np", ".", "arange", "(", "self", ".", "history_length", ")", "\n", "self", ".", "history_mat", "=", "np", ".", "fliplr", "(", "self", ".", "history_mat", ")", "\n", "\n", "self", ".", "hidden_features", "=", "args", ".", "hidden_features_rnn", "\n", "self", ".", "seq_overlap", "=", "args", ".", "seq_overlap", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.memory_rnn.MemoryRNN.__len__": [[38, 40], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "args", ".", "n_tot", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.memory_rnn.MemoryRNN.__getitem__": [[41, 43], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.memory_rnn.MemoryRNN.preprocess_trajectory": [[44, 50], ["numpy.stack", "os.path.join", "range", "cv2.resize", "cv2.imread().astype", "cv2.imread"], "methods", ["None"], ["", "def", "preprocess_trajectory", "(", "self", ",", "episode_dir", ",", "frame", ",", "k", ")", ":", "\n", "\n", "        ", "frames", "=", "[", "os", ".", "path", ".", "join", "(", "episode_dir", ",", "\"%d.png\"", "%", "(", "frame", "+", "i", ")", ")", "for", "i", "in", "range", "(", "-", "self", ".", "history_length", "+", "1", ",", "k", ")", "]", "\n", "imgs", "=", "np", ".", "stack", "(", "[", "(", "cv2", ".", "resize", "(", "cv2", ".", "imread", "(", "f0", ",", "imread_grayscale", ")", ".", "astype", "(", "np", ".", "float32", ")", ",", "\n", "(", "img_width", ",", "img_height", ")", ",", "interpolation", "=", "interpolation", ")", "/", "256.", ")", "for", "f0", "in", "frames", "]", ",", "axis", "=", "0", ")", "\n", "return", "imgs", "[", "self", ".", "history_mat", "[", ":", "k", "]", ",", ":", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.memory_rnn.ObservationsRNNMemory.__init__": [[85, 89], ["memory_rnn.MemoryRNN.__init__", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.memory.ReplayBatchSampler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "replay_dir", ")", ":", "\n", "\n", "        ", "super", "(", "ObservationsRNNMemory", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "screen_dir", "=", "os", ".", "path", ".", "join", "(", "replay_dir", ",", "\"explore\"", ",", "\"screen\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.memory_rnn.ObservationsRNNMemory.__getitem__": [[90, 137], ["len", "min", "os.path.join", "memory_rnn.ObservationsRNNMemory.preprocess_trajectory", "numpy.pad", "numpy.pad", "numpy.pad", "numpy.pad", "numpy.pad", "numpy.pad", "numpy.pad", "min", "str", "numpy.stack", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.memory_rnn.MemoryRNN.preprocess_trajectory"], ["", "def", "__getitem__", "(", "self", ",", "samples", ")", ":", "\n", "\n", "# if the first episode is too short s.t. there is no hidden state sample, take the second episode", "\n", "\n", "        ", "tde", "=", "samples", "[", "'tde'", "]", "[", "self", ".", "seq_length", "+", "self", ".", "burn_in", "]", "\n", "if", "(", "samples", "[", "'fr_e'", "]", "[", "0", "]", "-", "samples", "[", "'fr'", "]", "[", "0", "]", ")", "<=", "(", "self", ".", "burn_in", "+", "(", "-", "samples", "[", "'fr'", "]", "[", "0", "]", "%", "self", ".", "seq_overlap", ")", ")", ":", "\n", "\n", "# take the second episode", "\n", "            ", "offset", "=", "samples", "[", "'fr_e'", "]", "[", "0", "]", "-", "samples", "[", "'fr'", "]", "[", "0", "]", "\n", "start", "=", "offset", "+", "(", "-", "samples", "[", "'fr'", "]", "[", "offset", "]", "%", "self", ".", "seq_overlap", ")", "\n", "samples", "=", "samples", "[", "start", ":", "start", "+", "self", ".", "burn_in", "+", "self", ".", "seq_length", "]", "\n", "\n", "", "else", ":", "\n", "# take the first episode", "\n", "            ", "start", "=", "(", "-", "samples", "[", "'fr'", "]", "[", "0", "]", "%", "self", ".", "seq_overlap", ")", "\n", "end", "=", "min", "(", "samples", "[", "'fr_e'", "]", "[", "0", "]", "-", "samples", "[", "'fr'", "]", "[", "0", "]", ",", "(", "self", ".", "burn_in", "+", "self", ".", "seq_length", ")", "+", "start", ")", "\n", "samples", "=", "samples", "[", "start", ":", "end", "]", "\n", "\n", "", "prune_length", "=", "len", "(", "samples", ")", "\n", "pad_l", "=", "min", "(", "self", ".", "seq_length", "+", "self", ".", "burn_in", "-", "prune_length", ",", "self", ".", "burn_in", ")", "\n", "pad_r", "=", "self", ".", "seq_length", "+", "self", ".", "burn_in", "-", "(", "prune_length", "+", "pad_l", ")", "\n", "\n", "episode_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "screen_dir", ",", "str", "(", "samples", "[", "'ep'", "]", "[", "0", "]", ")", ")", "\n", "s", "=", "self", ".", "preprocess_trajectory", "(", "episode_dir", ",", "samples", "[", "'fr'", "]", "[", "0", "]", ",", "prune_length", ")", "\n", "\n", "h_q", "=", "samples", "[", "'h_q'", "]", "[", "0", "]", "\n", "h_beta", "=", "samples", "[", "'h_beta'", "]", "[", "0", "]", "\n", "\n", "r", "=", "np", ".", "pad", "(", "samples", "[", "'r'", "]", ",", "[", "(", "0", ",", "pad_r", "+", "pad_l", ")", "]", ",", "'constant'", ",", "constant_values", "=", "0", ")", "\n", "rho_v", "=", "np", ".", "pad", "(", "samples", "[", "'rho_v'", "]", ",", "[", "(", "0", ",", "pad_r", "+", "pad_l", ")", "]", ",", "'constant'", ",", "constant_values", "=", "0", ")", "\n", "rho_q", "=", "np", ".", "pad", "(", "samples", "[", "'rho_q'", "]", ",", "[", "(", "0", ",", "pad_r", "+", "pad_l", ")", "]", ",", "'constant'", ",", "constant_values", "=", "0", ")", "\n", "a", "=", "np", ".", "pad", "(", "samples", "[", "'a'", "]", ",", "[", "(", "0", ",", "pad_r", "+", "pad_l", ")", "]", ",", "'constant'", ",", "constant_values", "=", "0", ")", "\n", "pi", "=", "np", ".", "pad", "(", "np", ".", "stack", "(", "samples", "[", "'pi'", "]", ")", ",", "[", "(", "0", ",", "pad_r", "+", "pad_l", ")", ",", "(", "0", ",", "0", ")", "]", ",", "'constant'", ",", "constant_values", "=", "0", ")", "\n", "s", "=", "np", ".", "pad", "(", "s", ",", "[", "(", "0", ",", "pad_r", "+", "pad_l", ")", ",", "(", "0", ",", "0", ")", ",", "(", "0", ",", "0", ")", ",", "(", "0", ",", "0", ")", "]", ",", "'constant'", ",", "constant_values", "=", "0", ")", "\n", "t", "=", "np", ".", "pad", "(", "samples", "[", "'t'", "]", ",", "[", "(", "0", ",", "pad_r", "+", "pad_l", ")", "]", ",", "'constant'", ",", "constant_values", "=", "1", ")", "\n", "\n", "return", "{", "'s'", ":", "torch", ".", "from_numpy", "(", "s", "[", "self", ".", "burn_in", ":", "]", ")", ",", "\n", "'r'", ":", "torch", ".", "from_numpy", "(", "r", "[", "-", "self", ".", "seq_length", ":", "-", "self", ".", "n_steps", "]", ")", ",", "\n", "'rho_q'", ":", "torch", ".", "from_numpy", "(", "rho_q", "[", "-", "self", ".", "seq_length", ":", "-", "self", ".", "n_steps", "]", ")", ",", "\n", "'rho_v'", ":", "torch", ".", "from_numpy", "(", "rho_v", "[", "self", ".", "burn_in", ":", "]", ")", ",", "\n", "'a'", ":", "torch", ".", "from_numpy", "(", "a", "[", "self", ".", "burn_in", ":", "]", ")", ",", "\n", "'pi'", ":", "torch", ".", "from_numpy", "(", "pi", "[", "self", ".", "burn_in", ":", "]", ")", ",", "\n", "'h_q'", ":", "torch", ".", "from_numpy", "(", "h_q", ")", ",", "\n", "'h_beta'", ":", "torch", ".", "from_numpy", "(", "h_beta", ")", ",", "\n", "'s_bi'", ":", "torch", ".", "from_numpy", "(", "s", "[", ":", "self", ".", "burn_in", "]", ")", ",", "\n", "'t'", ":", "torch", ".", "from_numpy", "(", "t", "[", "self", ".", "burn_in", ":", "]", ")", ",", "\n", "'tde'", ":", "tde", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.memory_rnn.ObservationsRNNBatchSampler.__init__": [[141, 159], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "numpy.array"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "replay_dir", ")", ":", "\n", "\n", "        ", "self", ".", "batch", "=", "args", ".", "batch", "\n", "\n", "self", ".", "screen_dir", "=", "os", ".", "path", ".", "join", "(", "replay_dir", ",", "\"explore\"", ",", "\"screen\"", ")", "\n", "self", ".", "trajectory_dir", "=", "os", ".", "path", ".", "join", "(", "replay_dir", ",", "\"explore\"", ",", "\"trajectory\"", ")", "\n", "self", ".", "list_old_path", "=", "os", ".", "path", ".", "join", "(", "replay_dir", ",", "\"list\"", ",", "\"old_explore\"", ")", "\n", "\n", "self", ".", "replay_updates_interval", "=", "args", ".", "replay_updates_interval", "\n", "self", ".", "replay_memory_size", "=", "args", ".", "replay_memory_size", "\n", "self", ".", "readlock", "=", "os", ".", "path", ".", "join", "(", "replay_dir", ",", "\"list\"", ",", "\"readlock_explore.npy\"", ")", "\n", "\n", "self", ".", "rec_type", "=", "consts", ".", "rec_type", "\n", "\n", "self", ".", "priority_alpha", "=", "args", ".", "priority_alpha", "\n", "self", ".", "epsilon_a", "=", "args", ".", "epsilon_a", "\n", "\n", "self", ".", "tde", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.memory_rnn.ObservationsRNNBatchSampler.__iter__": [[160, 215], ["numpy.array", "numpy.arange", "preprocess.lock_file", "numpy.load", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "numpy.concatenate", "numpy.concatenate", "numpy.save", "print", "print", "min", "numpy.random.choice", "print", "range", "len", "numpy.concatenate", "prob.sum", "numpy.array", "len", "int", "numpy.load", "len", "len", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "\n", "        ", "traj_old", "=", "0", "\n", "replay_buffer", "=", "np", ".", "array", "(", "[", "]", ",", "dtype", "=", "self", ".", "rec_type", ")", "\n", "\n", "total_seq_length", "=", "args", ".", "burn_in", "+", "args", ".", "seq_length", "+", "args", ".", "seq_overlap", "\n", "\n", "if", "args", ".", "target", "==", "'tde'", ":", "\n", "            ", "total_seq_length", "+=", "args", ".", "n_steps", "\n", "\n", "", "sequence", "=", "np", ".", "arange", "(", "total_seq_length", ")", "\n", "\n", "while", "True", ":", "\n", "\n", "# load new memory", "\n", "            ", "fread", "=", "lock_file", "(", "self", ".", "readlock", ")", "\n", "traj_sorted", "=", "np", ".", "load", "(", "fread", ")", "\n", "fread", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fread", ",", "[", "]", ")", "\n", "release_file", "(", "fread", ")", "\n", "\n", "if", "not", "len", "(", "traj_sorted", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "replay", "=", "np", ".", "concatenate", "(", "\n", "[", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "trajectory_dir", ",", "\"%d.npy\"", "%", "traj", ")", ")", "for", "traj", "in", "traj_sorted", "]", ",", "axis", "=", "0", ")", "\n", "replay_buffer", "=", "np", ".", "concatenate", "(", "[", "replay_buffer", ",", "replay", "]", ",", "axis", "=", "0", ")", "\n", "\n", "offset", "=", "replay_buffer", "[", "-", "self", ".", "replay_memory_size", "]", "[", "'fr'", "]", "-", "replay_buffer", "[", "-", "self", ".", "replay_memory_size", "]", "[", "'fr_s'", "]", "if", "len", "(", "replay_buffer", ")", ">=", "self", ".", "replay_memory_size", "else", "0", "\n", "\n", "replay_buffer", "=", "replay_buffer", "[", "-", "self", ".", "replay_memory_size", "-", "offset", ":", "]", "\n", "\n", "tde", "=", "replay", "[", "'tde'", "]", "\n", "self", ".", "tde", "=", "np", ".", "concatenate", "(", "[", "self", ".", "tde", ",", "tde", "]", ")", "[", "-", "self", ".", "replay_memory_size", "-", "offset", ":", "]", "\n", "prob", "=", "self", ".", "tde", "[", ":", "-", "total_seq_length", "]", "\n", "prob", "=", "prob", "/", "prob", ".", "sum", "(", ")", "\n", "\n", "# save previous traj_old to file", "\n", "np", ".", "save", "(", "self", ".", "list_old_path", ",", "np", ".", "array", "(", "[", "traj_old", "]", ")", ")", "\n", "traj_old", "=", "replay_buffer", "[", "'traj'", "]", "[", "0", "]", "\n", "print", "(", "\"Old trajectory: %d\"", "%", "traj_old", ")", "\n", "print", "(", "\"New Sample size is: %d\"", "%", "len", "(", "replay", ")", ")", "\n", "\n", "len_replay_buffer", "=", "len", "(", "replay_buffer", ")", "-", "total_seq_length", "\n", "minibatches", "=", "min", "(", "self", ".", "replay_updates_interval", ",", "int", "(", "len_replay_buffer", "/", "self", ".", "batch", ")", ")", "\n", "\n", "shuffle_indexes", "=", "np", ".", "random", ".", "choice", "(", "len_replay_buffer", ",", "(", "minibatches", ",", "self", ".", "batch", ")", ",", "replace", "=", "False", ",", "p", "=", "prob", ")", "\n", "\n", "print", "(", "\"Explorer:Replay Buffer size is: %d\"", "%", "len_replay_buffer", ")", "\n", "\n", "for", "i", "in", "range", "(", "minibatches", ")", ":", "\n", "\n", "                ", "samples", "=", "shuffle_indexes", "[", "i", ",", ":", ",", "None", "]", "+", "sequence", "\n", "yield", "replay_buffer", "[", "samples", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.memory_rnn.ObservationsRNNBatchSampler.__len__": [[216, 218], ["None"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "inf", "", "", "", ""]], "home.repos.pwc.inspect_result.eladsar_rbi.None.memory_rnn.collate": [[52, 81], ["sum", "[].storage()._new_shared", "[].new", "sum", "[].storage()._new_shared", "[].new", "sum", "[].storage()._new_shared", "[].new", "sum", "[].storage()._new_shared", "[].new", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.FloatTensor", "torch.FloatTensor", "x[].numel", "[].storage", "x[].numel", "[].storage", "x[].numel", "[].storage", "x[].numel", "[].storage"], "function", ["None"], ["", "", "def", "collate", "(", "batch", ")", ":", "\n", "\n", "    ", "numel", "=", "sum", "(", "[", "x", "[", "'h_q'", "]", ".", "numel", "(", ")", "for", "x", "in", "batch", "]", ")", "\n", "storage", "=", "batch", "[", "0", "]", "[", "'h_q'", "]", ".", "storage", "(", ")", ".", "_new_shared", "(", "numel", ")", "\n", "out_h_q", "=", "batch", "[", "0", "]", "[", "'h_q'", "]", ".", "new", "(", "storage", ")", "\n", "\n", "numel", "=", "sum", "(", "[", "x", "[", "'h_beta'", "]", ".", "numel", "(", ")", "for", "x", "in", "batch", "]", ")", "\n", "storage", "=", "batch", "[", "0", "]", "[", "'h_beta'", "]", ".", "storage", "(", ")", ".", "_new_shared", "(", "numel", ")", "\n", "out_h_beta", "=", "batch", "[", "0", "]", "[", "'h_beta'", "]", ".", "new", "(", "storage", ")", "\n", "\n", "numel", "=", "sum", "(", "[", "x", "[", "'s'", "]", ".", "numel", "(", ")", "for", "x", "in", "batch", "]", ")", "\n", "storage", "=", "batch", "[", "0", "]", "[", "'s'", "]", ".", "storage", "(", ")", ".", "_new_shared", "(", "numel", ")", "\n", "out_s", "=", "batch", "[", "0", "]", "[", "'s'", "]", ".", "new", "(", "storage", ")", "\n", "\n", "numel", "=", "sum", "(", "[", "x", "[", "'s_bi'", "]", ".", "numel", "(", ")", "for", "x", "in", "batch", "]", ")", "\n", "storage", "=", "batch", "[", "0", "]", "[", "'s_bi'", "]", ".", "storage", "(", ")", ".", "_new_shared", "(", "numel", ")", "\n", "out_s_bi", "=", "batch", "[", "0", "]", "[", "'s_bi'", "]", ".", "new", "(", "storage", ")", "\n", "\n", "return", "{", "'s'", ":", "torch", ".", "stack", "(", "[", "sample", "[", "'s'", "]", "for", "sample", "in", "batch", "]", ",", "out", "=", "out_s", ")", ",", "\n", "'s_bi'", ":", "torch", ".", "stack", "(", "[", "sample", "[", "'s_bi'", "]", "for", "sample", "in", "batch", "]", ",", "out", "=", "out_s_bi", ")", ",", "\n", "'a'", ":", "torch", ".", "stack", "(", "[", "sample", "[", "'a'", "]", "for", "sample", "in", "batch", "]", ")", ",", "\n", "'r'", ":", "torch", ".", "stack", "(", "[", "sample", "[", "'r'", "]", "for", "sample", "in", "batch", "]", ")", ",", "\n", "'t'", ":", "torch", ".", "stack", "(", "[", "sample", "[", "'t'", "]", "for", "sample", "in", "batch", "]", ")", ",", "\n", "'rho_q'", ":", "torch", ".", "stack", "(", "[", "sample", "[", "'rho_q'", "]", "for", "sample", "in", "batch", "]", ")", ",", "\n", "'rho_v'", ":", "torch", ".", "stack", "(", "[", "sample", "[", "'rho_v'", "]", "for", "sample", "in", "batch", "]", ")", ",", "\n", "'h_beta'", ":", "torch", ".", "stack", "(", "[", "sample", "[", "'h_beta'", "]", "for", "sample", "in", "batch", "]", ",", "out", "=", "out_h_beta", ")", ",", "\n", "'h_q'", ":", "torch", ".", "stack", "(", "[", "sample", "[", "'h_q'", "]", "for", "sample", "in", "batch", "]", ",", "out", "=", "out_h_q", ")", ",", "\n", "'pi'", ":", "torch", ".", "stack", "(", "[", "sample", "[", "'pi'", "]", "for", "sample", "in", "batch", "]", ")", ",", "\n", "'tde'", ":", "torch", ".", "FloatTensor", "(", "[", "sample", "[", "'tde'", "]", "for", "sample", "in", "batch", "]", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.__init__": [[24, 109], ["os.listdir", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "logger.logger.logger.info", "logger.logger.logger.info", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "distutils.dir_util.copy_tree", "os.path.join", "os.makedirs", "tensorboardX.SummaryWriter", "max", "open", "fo.write", "os.path.abspath", "open", "fp.write", "open", "fo.write", "numpy.nonzero", "numpy.array", "Exception", "os.path.join", "int", "numpy.argmax", "int", "d.split", "d.split"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info"], ["    ", "def", "__init__", "(", "self", ",", "logger_file", ")", ":", "\n", "\n", "# parameters", "\n", "\n", "        ", "dirs", "=", "os", ".", "listdir", "(", "consts", ".", "outdir", ")", "\n", "\n", "self", ".", "load_model", "=", "args", ".", "load_last_model", "or", "args", ".", "load_best_model", "\n", "self", ".", "load_best", "=", "args", ".", "load_best_model", "\n", "self", ".", "load_last", "=", "args", ".", "load_last_model", "\n", "self", ".", "resume", "=", "args", ".", "resume", "\n", "self", ".", "action_meanings", "=", "[", "consts", ".", "action_meanings", "[", "i", "]", "for", "i", "in", "np", ".", "nonzero", "(", "consts", ".", "actions", "[", "args", ".", "game", "]", ")", "[", "0", "]", "]", "\n", "self", ".", "log_scores", "=", "args", ".", "log_scores", "\n", "\n", "temp_name", "=", "\"%s_%s_%s_exp\"", "%", "(", "args", ".", "game", ",", "args", ".", "algorithm", ",", "args", ".", "identifier", ")", "\n", "self", ".", "exp_name", "=", "\"\"", "\n", "if", "self", ".", "load_model", ":", "\n", "            ", "if", "self", ".", "resume", ">=", "0", ":", "\n", "                ", "for", "d", "in", "dirs", ":", "\n", "                    ", "if", "\"%s_%04d_\"", "%", "(", "temp_name", ",", "self", ".", "resume", ")", "in", "d", ":", "\n", "                        ", "self", ".", "exp_name", "=", "d", "\n", "self", ".", "exp_num", "=", "self", ".", "resume", "\n", "break", "\n", "", "", "", "elif", "self", ".", "resume", "==", "-", "1", ":", "\n", "\n", "                ", "ds", "=", "[", "d", "for", "d", "in", "dirs", "if", "temp_name", "in", "d", "]", "\n", "ns", "=", "np", ".", "array", "(", "[", "int", "(", "d", ".", "split", "(", "\"_\"", ")", "[", "-", "3", "]", ")", "for", "d", "in", "ds", "]", ")", "\n", "self", ".", "exp_name", "=", "ds", "[", "np", ".", "argmax", "(", "ns", ")", "]", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "\"Non-existing experiment\"", ")", "\n", "\n", "", "", "if", "not", "self", ".", "exp_name", ":", "\n", "# count similar experiments", "\n", "            ", "n", "=", "max", "(", "[", "-", "1", "]", "+", "[", "int", "(", "d", ".", "split", "(", "\"_\"", ")", "[", "-", "3", "]", ")", "for", "d", "in", "dirs", "if", "temp_name", "in", "d", "]", ")", "+", "1", "\n", "self", ".", "exp_name", "=", "\"%s_%04d_%s\"", "%", "(", "temp_name", ",", "n", ",", "consts", ".", "exptime", ")", "\n", "self", ".", "load_model", "=", "False", "\n", "self", ".", "exp_num", "=", "n", "\n", "\n", "# init experiment parameters", "\n", "", "self", ".", "root", "=", "os", ".", "path", ".", "join", "(", "consts", ".", "outdir", ",", "self", ".", "exp_name", ")", "\n", "self", ".", "indir", "=", "consts", ".", "indir", "\n", "\n", "# set dirs", "\n", "self", ".", "tensorboard_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'tensorboard'", ")", "\n", "self", ".", "checkpoints_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'checkpoints'", ")", "\n", "self", ".", "results_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'results'", ")", "\n", "self", ".", "scores_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'scores'", ")", "\n", "self", ".", "code_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'code'", ")", "\n", "self", ".", "analysis_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'analysis'", ")", "\n", "self", ".", "checkpoint", "=", "os", ".", "path", ".", "join", "(", "self", ".", "checkpoints_dir", ",", "'checkpoint'", ")", "\n", "self", ".", "checkpoint_best", "=", "os", ".", "path", ".", "join", "(", "self", ".", "checkpoints_dir", ",", "'checkpoint_best'", ")", "\n", "self", ".", "replay_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "indir", ",", "self", ".", "exp_name", ")", "\n", "\n", "if", "self", ".", "load_model", ":", "\n", "            ", "logger", ".", "info", "(", "\"Resuming existing experiment\"", ")", "\n", "with", "open", "(", "\"logger\"", ",", "\"a\"", ")", "as", "fo", ":", "\n", "                ", "fo", ".", "write", "(", "\"%s resume\\n\"", "%", "logger_file", ")", "\n", "", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"Creating new experiment\"", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "root", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "tensorboard_dir", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "checkpoints_dir", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "results_dir", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "scores_dir", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "code_dir", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "analysis_dir", ")", "\n", "# copy code to dir", "\n", "copy_tree", "(", "os", ".", "path", ".", "abspath", "(", "\".\"", ")", ",", "self", ".", "code_dir", ")", "\n", "\n", "# write args to file", "\n", "filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "\"args.txt\"", ")", "\n", "with", "open", "(", "filename", ",", "'w'", ")", "as", "fp", ":", "\n", "                ", "fp", ".", "write", "(", "'\\n'", ".", "join", "(", "sys", ".", "argv", "[", "1", ":", "]", ")", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "\"logger\"", ")", ",", "\"a\"", ")", "as", "fo", ":", "\n", "                ", "fo", ".", "write", "(", "\"%s\\n\"", "%", "logger_file", ")", "\n", "\n", "", "", "try", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "replay_dir", ")", "\n", "\n", "", "except", "FileExistsError", ":", "\n", "            ", "pass", "\n", "\n", "# initialize tensorboard writer", "\n", "", "if", "args", ".", "tensorboard", ":", "\n", "            ", "self", ".", "writer", "=", "SummaryWriter", "(", "log_dir", "=", "self", ".", "tensorboard_dir", ",", "comment", "=", "args", ".", "identifier", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.__enter__": [[110, 112], ["None"], "methods", ["None"], ["", "", "def", "__enter__", "(", "self", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.__exit__": [[113, 117], ["experiment.Experiment.writer.export_scalars_to_json", "experiment.Experiment.writer.close", "os.path.join"], "methods", ["None"], ["", "def", "__exit__", "(", "self", ",", "exc_type", ",", "exc_val", ",", "exc_tb", ")", ":", "\n", "        ", "if", "args", ".", "tensorboard", ":", "\n", "            ", "self", ".", "writer", ".", "export_scalars_to_json", "(", "os", ".", "path", ".", "join", "(", "self", ".", "tensorboard_dir", ",", "\"all_scalars.json\"", ")", ")", "\n", "self", ".", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.choose_agent": [[118, 130], ["None"], "methods", ["None"], ["", "", "def", "choose_agent", "(", "self", ")", ":", "\n", "\n", "        ", "if", "args", ".", "algorithm", "==", "\"rbi\"", ":", "\n", "            ", "return", "RBIAgent", "\n", "", "elif", "args", ".", "algorithm", "==", "\"ape\"", ":", "\n", "            ", "return", "ApeAgent", "\n", "", "elif", "args", ".", "algorithm", "==", "\"r2d2\"", ":", "\n", "            ", "return", "R2D2Agent", "\n", "", "elif", "args", ".", "algorithm", "==", "\"rbi_rnn\"", ":", "\n", "            ", "return", "RBIRNNAgent", "\n", "", "else", ":", "\n", "            ", "return", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.learn": [[131, 218], ["agent.learn", "agent.save_checkpoint", "logger.logger.logger.info", "logger.logger.logger.info", "enumerate", "experiment.Experiment.choose_agent", "agent.save_checkpoint", "print", "time.sleep", "time.sleep", "time.sleep", "time.sleep", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "experiment.Experiment.print_actions_statistics", "experiment.Experiment.get_player", "agent.save_checkpoint", "agent.resume", "len", "experiment.Experiment.writer.add_scalar", "experiment.Experiment.writer.add_scalar", "experiment.Experiment.writer.add_scalar", "experiment.Experiment.writer.add_image", "experiment.Experiment.writer.add_scalar", "experiment.Experiment.writer.add_histogram", "experiment.Experiment.writer.add_histogram", "hasattr", "hasattr", "hasattr", "agent.resume", "os.listdir", "int", "float", "float", "float", "float", "agent.beta_net.named_parameters", "agent.value_net.named_parameters", "agent.dqn_net.named_parameters", "os.path.join", "experiment.Experiment.writer.add_histogram", "experiment.Experiment.writer.add_histogram", "experiment.Experiment.writer.add_histogram", "param.clone().cpu().data.numpy", "param.clone().cpu().data.numpy", "param.clone().cpu().data.numpy", "param.clone().cpu", "param.clone().cpu", "param.clone().cpu", "param.clone", "param.clone", "param.clone"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.learn", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.save_checkpoint", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.choose_agent", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.save_checkpoint", "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.print_actions_statistics", "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.get_player", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.save_checkpoint", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.resume", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.resume"], ["", "", "def", "learn", "(", "self", ")", ":", "\n", "\n", "# init time variables", "\n", "\n", "        ", "agent", "=", "self", ".", "choose_agent", "(", ")", "(", "self", ".", "replay_dir", ",", "checkpoint", "=", "self", ".", "checkpoint", ")", "\n", "\n", "# load model", "\n", "if", "self", ".", "load_model", ":", "\n", "            ", "if", "self", ".", "load_last", ":", "\n", "                ", "aux", "=", "agent", ".", "resume", "(", "self", ".", "checkpoint", ")", "\n", "", "elif", "self", ".", "load_best", ":", "\n", "                ", "aux", "=", "agent", ".", "resume", "(", "self", ".", "checkpoint_best", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "", "n_offset", "=", "aux", "[", "'n'", "]", "\n", "", "else", ":", "\n", "            ", "n_offset", "=", "0", "\n", "# save a random init checkpoint", "\n", "agent", ".", "save_checkpoint", "(", "self", ".", "checkpoint", ",", "{", "'n'", ":", "0", "}", ")", "\n", "\n", "# define experiment generators", "\n", "", "learn", "=", "agent", ".", "learn", "(", "args", ".", "checkpoint_interval", ",", "args", ".", "n_tot", ")", "\n", "agent", ".", "save_checkpoint", "(", "agent", ".", "snapshot_path", ",", "{", "'n'", ":", "agent", ".", "n_offset", "}", ")", "\n", "\n", "batch_explore", "=", "args", ".", "batch", "\n", "\n", "hold", "=", "1", "\n", "while", "hold", ":", "\n", "            ", "print", "(", "\"wait for first samples\"", ")", "\n", "\n", "if", "len", "(", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "replay_dir", ",", "\"explore\"", ",", "\"trajectory\"", ")", ")", ")", ">=", "(", "int", "(", "500.", "/", "args", ".", "player_replay_size", "*", "batch_explore", ")", "+", "1", ")", ":", "\n", "                ", "hold", "=", "0", "\n", "\n", "", "time", ".", "sleep", "(", "5", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Begin Behavioral Distributional learning experiment\"", ")", "\n", "logger", ".", "info", "(", "\"Game: %s \"", "%", "args", ".", "game", ")", "\n", "\n", "for", "n", ",", "train_results", "in", "enumerate", "(", "learn", ")", ":", "\n", "\n", "            ", "n", "=", "n", "*", "args", ".", "checkpoint_interval", "\n", "\n", "avg_train_loss_beta", "=", "np", ".", "mean", "(", "train_results", "[", "'loss_beta'", "]", ")", "\n", "avg_train_loss_v_beta", "=", "np", ".", "mean", "(", "train_results", "[", "'loss_value'", "]", ")", "\n", "avg_train_loss_std", "=", "np", ".", "mean", "(", "train_results", "[", "'loss_std'", "]", ")", "\n", "\n", "avg_act_diff", "=", "np", ".", "mean", "(", "train_results", "[", "'act_diff'", "]", ")", "\n", "\n", "Hbeta", "=", "np", ".", "mean", "(", "train_results", "[", "'Hbeta'", "]", ")", "\n", "Hpi", "=", "np", ".", "mean", "(", "train_results", "[", "'Hpi'", "]", ")", "\n", "\n", "# log to tensorboard", "\n", "if", "args", ".", "tensorboard", ":", "\n", "                ", "self", ".", "writer", ".", "add_scalar", "(", "'train_loss/loss_beta'", ",", "float", "(", "avg_train_loss_beta", ")", ",", "n", "+", "n_offset", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'train_loss/loss_value'", ",", "float", "(", "avg_train_loss_v_beta", ")", ",", "n", "+", "n_offset", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'train_loss/loss_std'", ",", "float", "(", "avg_train_loss_std", ")", ",", "n", "+", "n_offset", ")", "\n", "\n", "self", ".", "writer", ".", "add_image", "(", "'states/state'", ",", "train_results", "[", "'image'", "]", ",", "n", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'actions/act_diff'", ",", "float", "(", "avg_act_diff", ")", ",", "n", "+", "n_offset", ")", "\n", "\n", "self", ".", "writer", ".", "add_histogram", "(", "\"actions/agent\"", ",", "train_results", "[", "'a_agent'", "]", ",", "n", "+", "n_offset", ",", "'doane'", ")", "\n", "self", ".", "writer", ".", "add_histogram", "(", "\"actions/a_player\"", ",", "train_results", "[", "'a_player'", "]", ",", "n", "+", "n_offset", ",", "'doane'", ")", "\n", "\n", "if", "hasattr", "(", "agent", ",", "\"beta_net\"", ")", ":", "\n", "                    ", "for", "name", ",", "param", "in", "agent", ".", "beta_net", ".", "named_parameters", "(", ")", ":", "\n", "                        ", "self", ".", "writer", ".", "add_histogram", "(", "\"beta_net/%s\"", "%", "name", ",", "param", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "n", "+", "n_offset", ",", "\n", "'fd'", ")", "\n", "", "", "if", "hasattr", "(", "agent", ",", "\"value_net\"", ")", ":", "\n", "                    ", "for", "name", ",", "param", "in", "agent", ".", "value_net", ".", "named_parameters", "(", ")", ":", "\n", "                        ", "self", ".", "writer", ".", "add_histogram", "(", "\"value_net/%s\"", "%", "name", ",", "param", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "n", "+", "n_offset", ",", "\n", "'fd'", ")", "\n", "\n", "", "", "if", "hasattr", "(", "agent", ",", "\"dqn_net\"", ")", ":", "\n", "                    ", "for", "name", ",", "param", "in", "agent", ".", "dqn_net", ".", "named_parameters", "(", ")", ":", "\n", "                        ", "self", ".", "writer", ".", "add_histogram", "(", "\"value_net/%s\"", "%", "name", ",", "param", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "n", "+", "n_offset", ",", "\n", "'fd'", ")", "\n", "\n", "# img = train_results['s'][0, :-1, :, :]", "\n", "# self.writer.add_image('states/state', img, n + n_offset)", "\n", "", "", "", "self", ".", "print_actions_statistics", "(", "train_results", "[", "'a_agent'", "]", ",", "train_results", "[", "'a_player'", "]", ",", "n", "+", "n_offset", ",", "Hbeta", ",", "Hpi", ",", "\n", "train_results", "[", "'adv_a'", "]", ",", "train_results", "[", "'q_a'", "]", ",", "train_results", "[", "'mc_val'", "]", ")", "\n", "\n", "player", "=", "self", ".", "get_player", "(", "agent", ")", "\n", "score", "=", "player", "[", "'high'", "]", "if", "player", "else", "0", "\n", "agent", ".", "save_checkpoint", "(", "self", ".", "checkpoint", ",", "{", "'n'", ":", "n", "+", "n_offset", ",", "'score'", ":", "score", "}", ")", "\n", "\n", "", "return", "agent", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.get_player": [[219, 246], ["os.path.isdir", "os.listdir", "os.listdir", "numpy.load().item", "time.sleep", "time.sleep", "time.sleep", "time.sleep", "numpy.load", "os.path.join"], "methods", ["None"], ["", "def", "get_player", "(", "self", ",", "agent", ")", ":", "\n", "\n", "        ", "if", "os", ".", "path", ".", "isdir", "(", "agent", ".", "best_player_dir", ")", "and", "os", ".", "listdir", "(", "agent", ".", "best_player_dir", ")", ":", "\n", "            ", "max_n", "=", "0", "\n", "\n", "for", "stat_file", "in", "os", ".", "listdir", "(", "agent", ".", "best_player_dir", ")", ":", "\n", "\n", "                ", "while", "True", ":", "\n", "                    ", "try", ":", "\n", "                        ", "data", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "agent", ".", "best_player_dir", ",", "stat_file", ")", ")", ".", "item", "(", ")", "\n", "break", "\n", "", "except", "OSError", ":", "\n", "                        ", "time", ".", "sleep", "(", "0.1", ")", "\n", "\n", "", "", "if", "max_n", "<=", "data", "[", "'n'", "]", ":", "\n", "                    ", "max_n", "=", "data", "[", "'n'", "]", "\n", "player_stats", "=", "data", "[", "'statistics'", "]", "\n", "\n", "# fix choice", "\n", "", "", "for", "pt", "in", "player_stats", ":", "\n", "                ", "if", "pt", "==", "\"reroute\"", ":", "\n", "                    ", "player_type", "=", "pt", "\n", "break", "\n", "\n", "", "", "return", "player_stats", "[", "player_type", "]", "\n", "\n", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.multiplay": [[247, 258], ["agent.multiplay", "experiment.Experiment.choose_agent", "experiment.Experiment.get_player", "agent.set_player"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.multiplay", "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.choose_agent", "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.get_player", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.set_player"], ["", "def", "multiplay", "(", "self", ")", ":", "\n", "\n", "        ", "agent", "=", "self", ".", "choose_agent", "(", ")", "(", "self", ".", "replay_dir", ",", "player", "=", "True", ",", "checkpoint", "=", "self", ".", "checkpoint", ")", "\n", "multiplayer", "=", "agent", ".", "multiplay", "(", ")", "\n", "\n", "for", "_", "in", "multiplayer", ":", "\n", "\n", "            ", "player", "=", "self", ".", "get_player", "(", "agent", ")", "\n", "if", "player", ":", "\n", "                ", "agent", ".", "set_player", "(", "player", "[", "'player'", "]", ",", "behavioral_avg_score", "=", "player", "[", "'high'", "]", ",", "\n", "behavioral_avg_frame", "=", "player", "[", "'frames'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.play": [[259, 279], ["agent.resume", "agent.play", "tqdm.tqdm.tqdm", "numpy.random.randint", "experiment.Experiment.choose_agent", "enumerate", "results[].append", "results[].append", "print", "logger.logger.logger.info", "os.path.join", "numpy.save"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.resume", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.play", "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.choose_agent", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info"], ["", "", "", "def", "play", "(", "self", ",", "params", "=", "None", ")", ":", "\n", "\n", "        ", "uuid", "=", "\"%012d\"", "%", "np", ".", "random", ".", "randint", "(", "1e12", ")", "\n", "agent", "=", "self", ".", "choose_agent", "(", ")", "(", "self", ".", "replay_dir", ",", "player", "=", "True", ",", "checkpoint", "=", "self", ".", "checkpoint", ")", "\n", "aux", "=", "agent", ".", "resume", "(", "self", ".", "checkpoint", ")", "\n", "\n", "n", "=", "aux", "[", "'n'", "]", "\n", "results", "=", "{", "\"n\"", ":", "n", ",", "\"score\"", ":", "[", "]", ",", "\"frame\"", ":", "[", "]", "}", "\n", "\n", "player", "=", "agent", ".", "play", "(", "args", ".", "play_episodes_interval", ",", "save", "=", "False", ",", "load", "=", "False", ",", "fix", "=", "True", ")", "\n", "\n", "for", "i", ",", "step", "in", "tqdm", "(", "enumerate", "(", "player", ")", ")", ":", "\n", "            ", "results", "[", "\"score\"", "]", ".", "append", "(", "step", "[", "'score'", "]", ")", "\n", "results", "[", "\"frame\"", "]", ".", "append", "(", "step", "[", "'frames'", "]", ")", "\n", "print", "(", "\"frames: %d | score: %d |\"", "%", "(", "step", "[", "'frames'", "]", ",", "step", "[", "'score'", "]", ")", ")", "\n", "\n", "", "if", "self", ".", "log_scores", ":", "\n", "            ", "logger", ".", "info", "(", "\"Save NPY file: eval_%d_%s.npy\"", "%", "(", "n", ",", "uuid", ")", ")", "\n", "filename", "=", "os", ".", "path", ".", "join", "(", "self", ".", "scores_dir", ",", "\"eval_%d_%s\"", "%", "(", "n", ",", "uuid", ")", ")", "\n", "np", ".", "save", "(", "filename", ",", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.clean": [[280, 284], ["agent.clean", "experiment.Experiment.choose_agent"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.clean", "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.choose_agent"], ["", "", "def", "clean", "(", "self", ")", ":", "\n", "\n", "        ", "agent", "=", "self", ".", "choose_agent", "(", ")", "(", "self", ".", "replay_dir", ",", "player", "=", "True", ",", "checkpoint", "=", "self", ".", "checkpoint", ",", "choose", "=", "True", ")", "\n", "agent", ".", "clean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.evaluate": [[285, 427], ["os.path.join", "os.makedirs", "os.path.join", "os.path.join", "os.makedirs", "time.sleep", "time.sleep", "time.sleep", "time.sleep", "print", "print", "numpy.random.randint", "experiment.Experiment.choose_agent", "tensorboardX.SummaryWriter", "agent.resume", "time.sleep", "time.sleep", "time.sleep", "time.sleep", "time.time", "time.time", "time.time", "time.time", "numpy.array", "numpy.array", "agent.set_player", "agent.play", "time.time", "time.time", "time.time", "time.time", "enumerate", "numpy.random.choice", "numpy.copy", "numpy.copy", "numpy.array", "numpy.array", "numpy.array.mean", "numpy.percentile", "numpy.percentile", "numpy.save", "time.sleep", "time.sleep", "time.sleep", "time.sleep", "agent.resume", "print", "time.time", "time.time", "time.time", "time.time", "scores.append", "numpy.array.append", "numpy.concatenate", "numpy.concatenate", "stats[].append", "stats[].append", "stats[].append", "stats[].append", "len", "numpy.array.mean", "agent.save_checkpoint", "experiment.Experiment.writer.add_scalar", "experiment.Experiment.writer.add_scalar", "experiment.Experiment.writer.add_scalar", "experiment.Experiment.writer.add_scalar", "experiment.Experiment.writer.add_scalar", "logger.logger.logger.info", "os.path.join", "numpy.save", "numpy.array.mean", "float", "float", "float", "float", "float", "experiment.Experiment.writer.add_histogram", "experiment.Experiment.writer.add_histogram", "time.time", "time.time", "time.time", "time.time", "numpy.array.mean", "numpy.array.max", "numpy.array.min", "numpy.array.std", "numpy.array.mean", "time.time", "time.time", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.choose_agent", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.resume", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.set_player", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.play", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.resume", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.save_checkpoint", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info"], ["", "def", "evaluate", "(", "self", ")", ":", "\n", "\n", "        ", "uuid", "=", "\"%012d\"", "%", "np", ".", "random", ".", "randint", "(", "1e12", ")", "\n", "agent", "=", "self", ".", "choose_agent", "(", ")", "(", "self", ".", "replay_dir", ",", "player", "=", "True", ",", "checkpoint", "=", "self", ".", "checkpoint", ",", "choose", "=", "True", ")", "\n", "\n", "best_score", "=", "-", "np", ".", "inf", "\n", "\n", "tensorboard_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "results_dir", ",", "uuid", ")", "\n", "os", ".", "makedirs", "(", "tensorboard_path", ")", "\n", "\n", "if", "args", ".", "tensorboard", ":", "\n", "            ", "self", ".", "writer", "=", "SummaryWriter", "(", "log_dir", "=", "tensorboard_path", ",", "comment", "=", "\"%s_%s\"", "%", "(", "args", ".", "identifier", ",", "uuid", ")", ")", "\n", "\n", "", "results_filename", "=", "os", ".", "path", ".", "join", "(", "agent", ".", "best_player_dir", ",", "\"%s.npy\"", "%", "uuid", ")", "\n", "scores_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "scores_dir", ",", "uuid", ")", "\n", "os", ".", "makedirs", "(", "scores_dir", ")", "\n", "\n", "kk", "=", "0", "\n", "\n", "if", "args", ".", "algorithm", "in", "[", "\"rbi\"", ",", "\"rbi_rnn\"", "]", ":", "\n", "            ", "results", "=", "{", "'n'", ":", "0", ",", "\n", "'statistics'", ":", "{", "\n", "'reroute'", ":", "{", "'player'", ":", "'reroutetv'", ",", "'cmin'", ":", "args", ".", "cmin", ",", "'cmax'", ":", "args", ".", "cmax", ",", "'delta'", ":", "args", ".", "delta", ",", "'score'", ":", "0", ",", "'high'", ":", "0", ",", "'frames'", ":", "1", "}", ",", "\n", "'behavioral'", ":", "{", "'player'", ":", "'behavioral'", ",", "'cmin'", ":", "None", ",", "'cmax'", ":", "None", ",", "'delta'", ":", "0", ",", "'score'", ":", "0", ",", "'high'", ":", "0", ",", "'frames'", ":", "1", "}", "\n", "}", "}", "\n", "", "elif", "args", ".", "algorithm", "in", "[", "\"ape\"", ",", "\"r2d2\"", "]", ":", "\n", "            ", "results", "=", "{", "'n'", ":", "0", ",", "\n", "'statistics'", ":", "{", "\n", "'reroute'", ":", "{", "'player'", ":", "'reroutetv'", ",", "'cmin'", ":", "args", ".", "cmin", ",", "'cmax'", ":", "args", ".", "cmax", ",", "'delta'", ":", "args", ".", "delta", ",", "'score'", ":", "0", ",", "'high'", ":", "0", ",", "'frames'", ":", "1", "}", ",", "\n", "'behavioral'", ":", "{", "'player'", ":", "'behavioral'", ",", "'cmin'", ":", "None", ",", "'cmax'", ":", "None", ",", "'delta'", ":", "0", ",", "'score'", ":", "0", ",", "'high'", ":", "0", ",", "'frames'", ":", "1", "}", "\n", "}", "}", "\n", "", "elif", "args", ".", "algorithm", "==", "\"ppo\"", ":", "\n", "            ", "results", "=", "{", "'n'", ":", "0", ",", "\n", "'statistics'", ":", "{", "\n", "'reroute'", ":", "{", "'player'", ":", "'reroutetv'", ",", "'cmin'", ":", "args", ".", "cmin", ",", "'cmax'", ":", "args", ".", "cmax", ",", "'delta'", ":", "args", ".", "delta", ",", "'score'", ":", "0", ",", "'high'", ":", "0", ",", "\n", "'frames'", ":", "1", "}", ",", "\n", "'behavioral'", ":", "{", "'player'", ":", "'behavioral'", ",", "'cmin'", ":", "None", ",", "'cmax'", ":", "None", ",", "'delta'", ":", "0", ",", "'score'", ":", "0", ",", "'high'", ":", "0", ",", "\n", "'frames'", ":", "1", "}", "\n", "}", "}", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "time", ".", "sleep", "(", "args", ".", "wait", ")", "\n", "\n", "print", "(", "\"Here\"", ")", "\n", "\n", "while", "True", ":", "\n", "\n", "# load model", "\n", "            ", "try", ":", "\n", "                ", "aux", "=", "agent", ".", "resume", "(", "agent", ".", "snapshot_path", ")", "\n", "", "except", ":", "# when reading and writing collide", "\n", "                ", "time", ".", "sleep", "(", "2", ")", "\n", "aux", "=", "agent", ".", "resume", "(", "agent", ".", "snapshot_path", ")", "\n", "\n", "", "n", "=", "aux", "[", "'n'", "]", "\n", "\n", "if", "n", "<", "args", ".", "random_initialization", ":", "\n", "                ", "time", ".", "sleep", "(", "5", ")", "\n", "continue", "\n", "\n", "", "results", "[", "'n'", "]", "=", "n", "\n", "results", "[", "'time'", "]", "=", "time", ".", "time", "(", ")", "-", "consts", ".", "start_time", "\n", "\n", "for", "player_name", "in", "results", "[", "'statistics'", "]", ":", "\n", "\n", "                ", "scores", "=", "[", "]", "\n", "frames", "=", "[", "]", "\n", "mc", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "q", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "\n", "player_params", "=", "results", "[", "'statistics'", "]", "[", "player_name", "]", "\n", "agent", ".", "set_player", "(", "player_params", "[", "'player'", "]", ",", "cmin", "=", "player_params", "[", "'cmin'", "]", ",", "cmax", "=", "player_params", "[", "'cmax'", "]", ",", "\n", "delta", "=", "player_params", "[", "'delta'", "]", ")", "\n", "\n", "player", "=", "agent", ".", "play", "(", "args", ".", "play_episodes_interval", ",", "save", "=", "False", ",", "load", "=", "False", ")", "\n", "\n", "stats", "=", "{", "\"score\"", ":", "[", "]", ",", "\"frame\"", ":", "[", "]", ",", "\"time\"", ":", "[", "]", ",", "\"n\"", ":", "[", "]", "}", "\n", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "i", ",", "step", "in", "enumerate", "(", "player", ")", ":", "\n", "\n", "                    ", "print", "(", "\"stats | player: %s | episode: %d | time: %g\"", "%", "(", "player_name", ",", "i", ",", "time", ".", "time", "(", ")", "-", "tic", ")", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "scores", ".", "append", "(", "step", "[", "'score'", "]", ")", "\n", "frames", ".", "append", "(", "step", "[", "'frames'", "]", ")", "\n", "mc", "=", "np", ".", "concatenate", "(", "(", "mc", ",", "step", "[", "'mc'", "]", ")", ")", "\n", "q", "=", "np", ".", "concatenate", "(", "(", "q", ",", "step", "[", "'q'", "]", ")", ")", "\n", "\n", "# add stats results", "\n", "stats", "[", "\"score\"", "]", ".", "append", "(", "step", "[", "'score'", "]", ")", "\n", "stats", "[", "\"frame\"", "]", ".", "append", "(", "step", "[", "'frames'", "]", ")", "\n", "stats", "[", "\"n\"", "]", ".", "append", "(", "step", "[", "'n'", "]", ")", "\n", "stats", "[", "\"time\"", "]", ".", "append", "(", "time", ".", "time", "(", ")", "-", "consts", ".", "start_time", ")", "\n", "\n", "# random selection", "\n", "", "set_size", "=", "200", "\n", "indexes", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "mc", ")", ",", "set_size", ")", "\n", "q", "=", "np", ".", "copy", "(", "q", "[", "indexes", "]", ")", "\n", "mc", "=", "np", ".", "copy", "(", "mc", "[", "indexes", "]", ")", "\n", "\n", "score", "=", "np", ".", "array", "(", "scores", ")", "\n", "frames", "=", "np", ".", "array", "(", "frames", ")", "\n", "\n", "player_params", "[", "'score'", "]", "=", "score", ".", "mean", "(", ")", "\n", "# player_params['high'] = score.max()", "\n", "player_params", "[", "'frames'", "]", "=", "np", ".", "percentile", "(", "frames", ",", "90", ")", "\n", "player_params", "[", "'high'", "]", "=", "np", ".", "percentile", "(", "scores", ",", "90", ")", "\n", "\n", "# save best player checkpoint", "\n", "if", "player_name", "!=", "\"behavioral\"", "and", "score", ".", "mean", "(", ")", ">", "best_score", ":", "\n", "                    ", "best_score", "=", "score", ".", "mean", "(", ")", "\n", "agent", ".", "save_checkpoint", "(", "self", ".", "checkpoint_best", ",", "{", "'n'", ":", "n", ",", "'score'", ":", "score", "}", ")", "\n", "\n", "", "if", "args", ".", "tensorboard", ":", "\n", "\n", "                    ", "self", ".", "writer", ".", "add_scalar", "(", "'score/%s'", "%", "player_name", ",", "float", "(", "score", ".", "mean", "(", ")", ")", ",", "n", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'high/%s'", "%", "player_name", ",", "float", "(", "score", ".", "max", "(", ")", ")", ",", "n", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'low/%s'", "%", "player_name", ",", "float", "(", "score", ".", "min", "(", ")", ")", ",", "n", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'std/%s'", "%", "player_name", ",", "float", "(", "score", ".", "std", "(", ")", ")", ",", "n", ")", "\n", "self", ".", "writer", ".", "add_scalar", "(", "'frames/%s'", "%", "player_name", ",", "float", "(", "frames", ".", "mean", "(", ")", ")", ",", "n", ")", "\n", "\n", "try", ":", "\n", "                        ", "self", ".", "writer", ".", "add_histogram", "(", "\"mc/%s\"", "%", "player_name", ",", "mc", ",", "n", ",", "'fd'", ")", "\n", "self", ".", "writer", ".", "add_histogram", "(", "\"q/%s\"", "%", "player_name", ",", "q", ",", "n", ",", "'fd'", ")", "\n", "", "except", ":", "\n", "                        ", "pass", "\n", "\n", "", "", "np", ".", "save", "(", "results_filename", ",", "results", ")", "\n", "\n", "if", "self", ".", "log_scores", ":", "\n", "                    ", "logger", ".", "info", "(", "\"Save NPY file: %d_%s_%d_%s.npy\"", "%", "(", "n", ",", "uuid", ",", "kk", ",", "player_name", ")", ")", "\n", "stat_filename", "=", "os", ".", "path", ".", "join", "(", "scores_dir", ",", "\"%d_%s_%d_%s\"", "%", "(", "n", ",", "uuid", ",", "kk", ",", "player_name", ")", ")", "\n", "np", ".", "save", "(", "stat_filename", ",", "stats", ")", "\n", "\n", "", "kk", "+=", "1", "\n", "\n", "", "if", "agent", ".", "n_offset", ">=", "args", ".", "n_tot", ":", "\n", "                ", "break", "\n", "\n", "", "", "print", "(", "\"End of evaluation\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.postprocess": [[428, 460], ["os.path.join", "os.path.join", "os.listdir", "pandas.DataFrame", "pandas.DataFrame", "pandas.DataFrame.to_pickle", "pandas.DataFrame.to_pickle", "os.path.isdir", "os.mkdir", "print", "os.listdir", "os.path.join", "os.path.join", "os.path.isfile", "os.path.isfile", "os.path.join", "os.path.join", "os.path.join", "numpy.load().item", "numpy.load().item", "numpy.load", "numpy.load", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "postprocess", "(", "self", ")", ":", "\n", "\n", "        ", "run_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "\"scores\"", ")", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "\"postprocess\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "save_dir", ")", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"df_reroute\"", ")", ")", "and", "os", ".", "path", ".", "isfile", "(", "\n", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"df_behavioral\"", ")", ")", ":", "\n", "            ", "return", "\n", "\n", "", "results_reroute", "=", "{", "'score'", ":", "[", "]", ",", "'frame'", ":", "[", "]", ",", "'n'", ":", "[", "]", ",", "'time'", ":", "[", "]", "}", "\n", "results_behavioral", "=", "{", "'score'", ":", "[", "]", ",", "'frame'", ":", "[", "]", ",", "'n'", ":", "[", "]", ",", "'time'", ":", "[", "]", "}", "\n", "\n", "for", "d", "in", "os", ".", "listdir", "(", "run_dir", ")", ":", "\n", "            ", "print", "(", "d", ")", "\n", "for", "f", "in", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "run_dir", ",", "d", ")", ")", ":", "\n", "\n", "                ", "if", "\"behavioral\"", "in", "f", ":", "\n", "                    ", "for", "key", "in", "results_behavioral", ":", "\n", "                        ", "item", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "run_dir", ",", "d", ",", "f", ")", ")", ".", "item", "(", ")", "\n", "results_behavioral", "[", "key", "]", "+=", "item", "[", "key", "]", "\n", "", "", "else", ":", "\n", "                    ", "for", "key", "in", "results_reroute", ":", "\n", "                        ", "item", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "run_dir", ",", "d", ",", "f", ")", ")", ".", "item", "(", ")", "\n", "results_reroute", "[", "key", "]", "+=", "item", "[", "key", "]", "\n", "\n", "", "", "", "", "df_reroute", "=", "pd", ".", "DataFrame", "(", "results_reroute", ")", "\n", "df_behavioral", "=", "pd", ".", "DataFrame", "(", "results_behavioral", ")", "\n", "\n", "df_reroute", ".", "to_pickle", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"df_reroute\"", ")", ")", "\n", "df_behavioral", ".", "to_pickle", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"df_behavioral\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.print_actions_statistics": [[461, 561], ["logger.logger.logger.info", "len", "logger.logger.logger.info", "len", "logger.logger.logger.info", "logger.logger.logger.info", "range", "logger.logger.logger.info", "logger.logger.logger.info", "logger.logger.logger.info", "logger.logger.logger.info", "logger.logger.logger.info", "numpy.bincount", "numpy.bincount", "match_precentage_by_action.append", "match_precentage_by_action.append", "adv_by_action.append", "adv_by_action.append", "q_by_action.append", "q_by_action.append", "r_by_action.append", "r_by_action.append", "error_precentage_by_action.append", "error_precentage_by_action.append", "numpy.concatenate", "numpy.concatenate", "adv_a[].sum", "q_a[].sum", "r_mc[].sum", "len", "numpy.arange", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info", "home.repos.pwc.inspect_result.eladsar_rbi.None.logger.Logger.info"], ["", "def", "print_actions_statistics", "(", "self", ",", "a_agent", ",", "a_player", ",", "n", ",", "Hbeta", ",", "Hpi", ",", "adv_a", ",", "q_a", ",", "r_mc", ")", ":", "\n", "\n", "# print action meanings", "\n", "        ", "logger", ".", "info", "(", "\"Actions statistics: \\tH(beta) = %g |\\t H(pi) = %g |\"", "%", "(", "Hbeta", ",", "Hpi", ")", ")", "\n", "action_space", "=", "len", "(", "self", ".", "action_meanings", ")", "\n", "\n", "line", "=", "''", "\n", "line", "+=", "\"|\\tActions Names\\t\"", "\n", "for", "a", "in", "self", ".", "action_meanings", ":", "\n", "            ", "line", "+=", "\"|%s%s  \"", "%", "(", "a", "[", ":", "11", "]", ",", "' '", "*", "(", "11", "-", "len", "(", "a", "[", ":", "11", "]", ")", ")", ")", "\n", "", "line", "+=", "\"|\"", "\n", "logger", ".", "info", "(", "line", ")", "\n", "\n", "n_actions", "=", "len", "(", "a_agent", ")", "\n", "applied_player_actions", "=", "(", "np", ".", "bincount", "(", "np", ".", "concatenate", "(", "(", "a_player", ",", "np", ".", "arange", "(", "action_space", ")", ")", ")", ")", "-", "1", ")", "/", "n_actions", "\n", "applied_agent_actions", "=", "(", "np", ".", "bincount", "(", "np", ".", "concatenate", "(", "(", "a_agent", ",", "np", ".", "arange", "(", "action_space", ")", ")", ")", ")", "-", "1", ")", "/", "n_actions", "\n", "\n", "line", "=", "''", "\n", "line", "+=", "\"|\\tPlayer actions\\t\"", "\n", "for", "a", "in", "applied_player_actions", ":", "\n", "            ", "line", "+=", "\"|%.2f\\t    \"", "%", "(", "a", "*", "100", ")", "\n", "", "line", "+=", "\"|\"", "\n", "logger", ".", "info", "(", "line", ")", "\n", "\n", "line", "=", "''", "\n", "line", "+=", "\"|\\tAgent actions\\t\"", "\n", "for", "a", "in", "applied_agent_actions", ":", "\n", "            ", "line", "+=", "\"|%.2f\\t    \"", "%", "(", "a", "*", "100", ")", "\n", "", "line", "+=", "\"|\"", "\n", "logger", ".", "info", "(", "line", ")", "\n", "\n", "match_precentage_by_action", "=", "[", "]", "\n", "error_precentage_by_action", "=", "[", "]", "\n", "adv_by_action", "=", "[", "]", "\n", "q_by_action", "=", "[", "]", "\n", "r_by_action", "=", "[", "]", "\n", "for", "a", "in", "range", "(", "action_space", ")", ":", "\n", "\n", "            ", "n_action_player", "=", "(", "a_player", "==", "a", ")", ".", "sum", "(", ")", "\n", "if", "n_action_player", ":", "\n", "                ", "match_precentage_by_action", ".", "append", "(", "(", "a_agent", "[", "a_player", "==", "a", "]", "==", "a", ")", ".", "sum", "(", ")", "/", "n_action_player", ")", "\n", "", "else", ":", "\n", "                ", "match_precentage_by_action", ".", "append", "(", "-", "0.01", ")", "\n", "\n", "", "if", "n_action_player", ":", "\n", "                ", "adv_by_action", ".", "append", "(", "(", "adv_a", "[", "a_player", "==", "a", "]", ")", ".", "sum", "(", ")", "/", "n_action_player", ")", "\n", "", "else", ":", "\n", "                ", "adv_by_action", ".", "append", "(", "-", "0.01", ")", "\n", "\n", "", "if", "n_action_player", ":", "\n", "                ", "q_by_action", ".", "append", "(", "(", "q_a", "[", "a_player", "==", "a", "]", ")", ".", "sum", "(", ")", "/", "n_action_player", ")", "\n", "", "else", ":", "\n", "                ", "q_by_action", ".", "append", "(", "-", "0.01", ")", "\n", "\n", "", "if", "n_action_player", ":", "\n", "                ", "r_by_action", ".", "append", "(", "(", "r_mc", "[", "a_player", "==", "a", "]", ")", ".", "sum", "(", ")", "/", "n_action_player", ")", "\n", "", "else", ":", "\n", "                ", "r_by_action", ".", "append", "(", "-", "0.01", ")", "\n", "\n", "", "n_not_action_player", "=", "(", "a_player", "!=", "a", ")", ".", "sum", "(", ")", "\n", "if", "n_not_action_player", ":", "\n", "                ", "error_precentage_by_action", ".", "append", "(", "(", "a_agent", "[", "a_player", "!=", "a", "]", "==", "a", ")", ".", "sum", "(", ")", "/", "n_not_action_player", ")", "\n", "", "else", ":", "\n", "                ", "error_precentage_by_action", ".", "append", "(", "-", "0.01", ")", "\n", "\n", "", "", "line", "=", "''", "\n", "line", "+=", "\"|\\tAdvantage    \\t\"", "\n", "for", "a", "in", "adv_by_action", ":", "\n", "            ", "line", "+=", "\"|%.2f\\t    \"", "%", "a", "\n", "", "line", "+=", "\"|\"", "\n", "logger", ".", "info", "(", "line", ")", "\n", "\n", "line", "=", "''", "\n", "line", "+=", "\"|\\tQ(s,a)       \\t\"", "\n", "for", "a", "in", "q_by_action", ":", "\n", "            ", "line", "+=", "\"|%.2f\\t    \"", "%", "a", "\n", "", "line", "+=", "\"|\"", "\n", "logger", ".", "info", "(", "line", ")", "\n", "\n", "line", "=", "''", "\n", "line", "+=", "\"|\\tR Monte-Carlo\\t\"", "\n", "for", "a", "in", "r_by_action", ":", "\n", "            ", "line", "+=", "\"|%.2f\\t    \"", "%", "a", "\n", "", "line", "+=", "\"|\"", "\n", "logger", ".", "info", "(", "line", ")", "\n", "\n", "\n", "line", "=", "''", "\n", "line", "+=", "\"|\\tMatch by action\\t\"", "\n", "for", "a", "in", "match_precentage_by_action", ":", "\n", "            ", "line", "+=", "\"|%.2f\\t    \"", "%", "(", "a", "*", "100", ")", "\n", "", "line", "+=", "\"|\"", "\n", "logger", ".", "info", "(", "line", ")", "\n", "\n", "line", "=", "''", "\n", "line", "+=", "\"|\\tError by action\\t\"", "\n", "for", "a", "in", "error_precentage_by_action", ":", "\n", "            ", "line", "+=", "\"|%.2f\\t    \"", "%", "(", "a", "*", "100", ")", "\n", "", "line", "+=", "\"|\"", "\n", "logger", ".", "info", "(", "line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.demonstrate": [[562, 591], ["agent.demonstrate", "enumerate", "experiment.Experiment.choose_agent", "agent.resume", "time.sleep", "time.sleep", "time.sleep", "time.sleep", "agent.resume", "agent.resume", "agent.resume", "agent.resume", "agent.resume"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.demonstrate", "home.repos.pwc.inspect_result.eladsar_rbi.None.experiment.Experiment.choose_agent", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.resume", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.resume", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.resume", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.resume", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.resume", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.resume"], ["", "def", "demonstrate", "(", "self", ",", "params", "=", "None", ")", ":", "\n", "\n", "        ", "agent", "=", "self", ".", "choose_agent", "(", ")", "(", "self", ".", "replay_dir", ",", "player", "=", "True", ",", "checkpoint", "=", "self", ".", "checkpoint", ")", "\n", "\n", "# load model", "\n", "try", ":", "\n", "            ", "if", "params", "is", "not", "None", ":", "\n", "                ", "aux", "=", "agent", ".", "resume", "(", "params", ")", "\n", "", "elif", "self", ".", "load_last", ":", "\n", "                ", "aux", "=", "agent", ".", "resume", "(", "self", ".", "checkpoint", ")", "\n", "", "elif", "self", ".", "load_best", ":", "\n", "                ", "aux", "=", "agent", ".", "resume", "(", "self", ".", "checkpoint_best", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "", "", "except", ":", "# when reading and writing collide", "\n", "            ", "time", ".", "sleep", "(", "2", ")", "\n", "if", "params", "is", "not", "None", ":", "\n", "                ", "aux", "=", "agent", ".", "resume", "(", "params", ")", "\n", "", "elif", "self", ".", "load_last", ":", "\n", "                ", "aux", "=", "agent", ".", "resume", "(", "self", ".", "checkpoint", ")", "\n", "", "elif", "self", ".", "load_best", ":", "\n", "                ", "aux", "=", "agent", ".", "resume", "(", "self", ".", "checkpoint_best", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "\n", "", "", "player", "=", "agent", ".", "demonstrate", "(", "128", ")", "\n", "\n", "for", "i", ",", "step", "in", "enumerate", "(", "player", ")", ":", "\n", "            ", "yield", "step", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.convert_screen_to_rgb": [[49, 56], ["cv2.cvtColor", "torch.from_numpy", "cv2.resize.numpy", "cv2.resize", "numpy.rollaxis", "cv2.resize.max"], "function", ["None"], ["def", "convert_screen_to_rgb", "(", "img", ",", "resize", "=", "False", ")", ":", "\n", "    ", "img", "=", "cv2", ".", "cvtColor", "(", "img", ".", "numpy", "(", ")", ",", "img_gray2rgb", ")", "\n", "#", "\n", "if", "resize", ":", "\n", "        ", "img", "=", "img", "/", "img", ".", "max", "(", ")", "\n", "img", "=", "cv2", ".", "resize", "(", "img", ",", "(", "128", ",", "1024", ")", ",", "interpolation", "=", "img_inter", ")", "\n", "", "return", "torch", ".", "from_numpy", "(", "np", ".", "rollaxis", "(", "img", ",", "2", ",", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess._h_np": [[58, 60], ["numpy.sign", "numpy.sqrt", "numpy.abs"], "function", ["None"], ["", "def", "_h_np", "(", "r", ")", ":", "\n", "    ", "return", "np", ".", "sign", "(", "r", ")", "*", "(", "np", ".", "sqrt", "(", "np", ".", "abs", "(", "r", ")", "+", "1", ")", "-", "1", ")", "+", "0.01", "*", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess._hinv_np": [[62, 64], ["numpy.sign", "numpy.sqrt", "numpy.abs"], "function", ["None"], ["", "def", "_hinv_np", "(", "r", ")", ":", "\n", "    ", "return", "np", ".", "sign", "(", "r", ")", "*", "(", "(", "(", "np", ".", "sqrt", "(", "1", "+", "0.04", "*", "(", "np", ".", "abs", "(", "r", ")", "+", "1.01", ")", ")", "-", "1", ")", "/", "0.02", ")", "**", "2", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess._h_torch": [[66, 68], ["torch.sign", "torch.sqrt", "torch.abs"], "function", ["None"], ["", "def", "_h_torch", "(", "r", ")", ":", "\n", "    ", "return", "torch", ".", "sign", "(", "r", ")", "*", "(", "torch", ".", "sqrt", "(", "torch", ".", "abs", "(", "r", ")", "+", "1", ")", "-", "1", ")", "+", "0.01", "*", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess._hinv_torch": [[70, 72], ["torch.sign", "torch.sqrt", "torch.abs"], "function", ["None"], ["", "def", "_hinv_torch", "(", "r", ")", ":", "\n", "    ", "return", "torch", ".", "sign", "(", "r", ")", "*", "(", "(", "(", "torch", ".", "sqrt", "(", "1", "+", "0.04", "*", "(", "torch", ".", "abs", "(", "r", ")", "+", "1.01", ")", ")", "-", "1", ")", "/", "0.02", ")", "**", "2", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess._hinv_np_tag": [[73, 75], ["None"], "function", ["None"], ["", "def", "_hinv_np_tag", "(", "r", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess._hinv_torch_tag": [[77, 79], ["None"], "function", ["None"], ["", "def", "_hinv_torch_tag", "(", "r", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess._idle": [[81, 83], ["None"], "function", ["None"], ["", "def", "_idle", "(", "r", ")", ":", "\n", "    ", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_truncated_value": [[101, 125], ["len", "range", "numpy.concatenate().astype", "numpy.array", "values.append", "list", "len", "numpy.arange", "numpy.clip", "numpy.correlate", "numpy.concatenate", "itertools.chain"], "function", ["None"], ["", "def", "get_truncated_value", "(", "rewards", ",", "v_target", ",", "discount", ",", "n_steps", ")", ":", "\n", "\n", "    ", "if", "infinite_horizon", ":", "\n", "        ", "rewards", "=", "[", "list", "(", "itertools", ".", "chain", "(", "*", "rewards", ")", ")", "]", "\n", "\n", "", "lives", "=", "len", "(", "rewards", ")", "\n", "\n", "values", "=", "[", "]", "\n", "for", "life", "in", "range", "(", "lives", ")", ":", "\n", "\n", "        ", "if", "not", "len", "(", "rewards", "[", "life", "]", ")", ":", "\n", "            ", "continue", "\n", "", "discounts", "=", "discount", "**", "np", ".", "arange", "(", "n_steps", ")", "\n", "\n", "r", "=", "np", ".", "array", "(", "rewards", "[", "life", "]", ")", "\n", "if", "clip", ">", "0", ":", "\n", "            ", "r", "=", "np", ".", "clip", "(", "r", ",", "-", "clip", ",", "clip", ")", "\n", "\n", "", "r", "[", "-", "1", "]", "+=", "termination_reward", "\n", "\n", "val", "=", "np", ".", "correlate", "(", "r", ",", "discounts", ",", "mode", "=", "\"full\"", ")", "[", "n_steps", "-", "1", ":", "]", "\n", "values", ".", "append", "(", "val", ")", "\n", "\n", "", "return", "np", ".", "concatenate", "(", "values", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_mc_value": [[127, 153], ["len", "range", "numpy.concatenate().astype", "numpy.array", "numpy.zeros", "range", "values.append", "list", "len", "numpy.arange", "numpy.clip", "len", "h_np", "numpy.concatenate", "itertools.chain", "len"], "function", ["None"], ["", "def", "get_mc_value", "(", "rewards", ",", "v_target", ",", "discount", ",", "n_steps", ")", ":", "\n", "\n", "    ", "if", "infinite_horizon", ":", "\n", "        ", "rewards", "=", "[", "list", "(", "itertools", ".", "chain", "(", "*", "rewards", ")", ")", "]", "\n", "\n", "", "lives", "=", "len", "(", "rewards", ")", "\n", "\n", "values", "=", "[", "]", "\n", "for", "life", "in", "range", "(", "lives", ")", ":", "\n", "\n", "        ", "if", "not", "len", "(", "rewards", "[", "life", "]", ")", ":", "\n", "            ", "continue", "\n", "", "discounts", "=", "discount", "**", "np", ".", "arange", "(", "len", "(", "rewards", "[", "life", "]", ")", "+", "1", ")", "\n", "\n", "r", "=", "np", ".", "array", "(", "rewards", "[", "life", "]", ")", "\n", "if", "clip", ">", "0", ":", "\n", "            ", "r", "=", "np", ".", "clip", "(", "r", ",", "-", "clip", ",", "clip", ")", "\n", "\n", "", "r", "[", "-", "1", "]", "+=", "termination_reward", "\n", "val", "=", "np", ".", "zeros", "(", "r", ".", "shape", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "r", ")", ")", ":", "\n", "            ", "val", "[", "i", "]", "=", "(", "r", "[", "i", ":", "]", "*", "discounts", "[", ":", "-", "i", "-", "1", "]", ")", ".", "sum", "(", ")", "\n", "\n", "", "values", ".", "append", "(", "h_np", "(", "val", ")", ")", "\n", "\n", "", "return", "np", ".", "concatenate", "(", "values", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_td_value": [[155, 190], ["len", "range", "numpy.concatenate().astype", "len", "numpy.array", "numpy.concatenate", "values.append", "list", "list", "numpy.arange", "numpy.clip", "numpy.correlate", "h_np", "numpy.concatenate", "itertools.chain", "itertools.chain", "numpy.array", "numpy.zeros", "hinv_np"], "function", ["None"], ["", "def", "get_td_value", "(", "rewards", ",", "v_target", ",", "discount", ",", "n_steps", ")", ":", "\n", "\n", "    ", "if", "infinite_horizon", ":", "\n", "        ", "rewards", "=", "[", "list", "(", "itertools", ".", "chain", "(", "*", "rewards", ")", ")", "]", "\n", "v_target", "=", "[", "list", "(", "itertools", ".", "chain", "(", "*", "v_target", ")", ")", "]", "\n", "\n", "", "lives", "=", "len", "(", "rewards", ")", "\n", "\n", "values", "=", "[", "]", "\n", "for", "life", "in", "range", "(", "lives", ")", ":", "\n", "\n", "        ", "episode_len", "=", "len", "(", "rewards", "[", "life", "]", ")", "\n", "\n", "if", "not", "episode_len", ":", "\n", "            ", "continue", "\n", "\n", "", "discounts", "=", "discount", "**", "np", ".", "arange", "(", "n_steps", ")", "\n", "\n", "r", "=", "np", ".", "array", "(", "rewards", "[", "life", "]", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "v_t", "=", "np", ".", "concatenate", "(", "(", "np", ".", "array", "(", "v_target", "[", "life", "]", ",", "dtype", "=", "np", ".", "float64", ")", ",", "np", ".", "zeros", "(", "n_steps", ")", ")", ")", "\n", "\n", "if", "clip", ">", "0", ":", "\n", "            ", "r", "=", "np", ".", "clip", "(", "r", ",", "-", "clip", ",", "clip", ")", "\n", "", "r", "[", "-", "1", "]", "+=", "termination_reward", "\n", "\n", "val", "=", "np", ".", "correlate", "(", "r", ",", "discounts", ",", "mode", "=", "\"full\"", ")", "[", "n_steps", "-", "1", ":", "]", "\n", "\n", "if", "reward_shape", ":", "\n", "            ", "val", "=", "h_np", "(", "val", "+", "discount", "**", "n_steps", "*", "hinv_np", "(", "v_t", "[", "n_steps", ":", "]", ")", ")", "\n", "", "else", ":", "\n", "            ", "val", "+=", "discount", "**", "n_steps", "*", "v_t", "[", "n_steps", ":", "]", "\n", "\n", "", "values", ".", "append", "(", "val", ")", "\n", "\n", "", "return", "np", ".", "concatenate", "(", "values", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_gae_est": [[192, 217], ["len", "range", "numpy.concatenate().astype", "len", "numpy.array", "numpy.concatenate", "numpy.clip", "values.append", "numpy.arange", "numpy.correlate", "numpy.concatenate", "numpy.array", "numpy.zeros"], "function", ["None"], ["", "def", "get_gae_est", "(", "rewards", ",", "v_target", ",", "discount", ")", ":", "\n", "\n", "    ", "lives", "=", "len", "(", "rewards", ")", "\n", "gamma", "=", "0.95", "\n", "\n", "values", "=", "[", "]", "\n", "for", "life", "in", "range", "(", "lives", ")", ":", "\n", "\n", "        ", "episode_len", "=", "len", "(", "rewards", "[", "life", "]", ")", "\n", "\n", "if", "not", "episode_len", ":", "\n", "            ", "continue", "\n", "\n", "", "discounts", "=", "(", "gamma", "*", "discount", ")", "**", "np", ".", "arange", "(", "episode_len", ")", "\n", "r", "=", "np", ".", "array", "(", "rewards", "[", "life", "]", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "v_t", "=", "np", ".", "concatenate", "(", "(", "np", ".", "array", "(", "v_target", "[", "life", "]", ",", "dtype", "=", "np", ".", "float64", ")", ",", "np", ".", "zeros", "(", "1", ")", ")", ")", "\n", "r", "=", "np", ".", "clip", "(", "r", ",", "-", "clip", ",", "clip", ")", "\n", "r", "[", "-", "1", "]", "+=", "termination_reward", "\n", "\n", "delta", "=", "r", "+", "v_t", "[", "1", ":", "]", "-", "discount", "*", "v_t", "[", ":", "-", "1", "]", "\n", "\n", "val", "=", "np", ".", "correlate", "(", "delta", ",", "discounts", ",", "mode", "=", "\"full\"", ")", "[", "episode_len", "-", "1", ":", "]", "\n", "values", ".", "append", "(", "val", ")", "\n", "\n", "", "return", "np", ".", "concatenate", "(", "values", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_rho_is": [[219, 243], ["len", "range", "numpy.concatenate().astype", "len", "numpy.concatenate", "numpy.ones", "range", "rho_is.append", "list", "numpy.concatenate", "itertools.chain", "numpy.array", "numpy.ones"], "function", ["None"], ["", "def", "get_rho_is", "(", "rho", ",", "n_steps", ")", ":", "\n", "\n", "    ", "if", "infinite_horizon", ":", "\n", "        ", "rho", "=", "[", "list", "(", "itertools", ".", "chain", "(", "*", "rho", ")", ")", "]", "\n", "\n", "", "lives", "=", "len", "(", "rho", ")", "\n", "\n", "rho_is", "=", "[", "]", "\n", "for", "life", "in", "range", "(", "lives", ")", ":", "\n", "\n", "        ", "episode_len", "=", "len", "(", "rho", "[", "life", "]", ")", "\n", "\n", "if", "not", "episode_len", ":", "\n", "            ", "continue", "\n", "\n", "", "v_t", "=", "np", ".", "concatenate", "(", "(", "np", ".", "array", "(", "rho", "[", "life", "]", ",", "dtype", "=", "np", ".", "float64", ")", ",", "np", ".", "ones", "(", "n_steps", ")", ")", ")", "\n", "\n", "val", "=", "np", ".", "ones", "(", "episode_len", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "n_steps", ")", ":", "\n", "            ", "val", "*=", "v_t", "[", "i", ":", "episode_len", "+", "i", "]", "\n", "\n", "", "rho_is", ".", "append", "(", "val", ")", "\n", "\n", "", "return", "np", ".", "concatenate", "(", "rho_is", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_tde_value": [[245, 287], ["len", "range", "len", "numpy.array", "numpy.zeros", "numpy.zeros", "range", "values.append", "terminals.append", "numpy.concatenate().astype", "numpy.concatenate().astype", "list", "numpy.arange", "numpy.clip", "len", "itertools.chain", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "len", "numpy.zeros"], "function", ["None"], ["", "def", "get_tde_value", "(", "rewards", ",", "discount", ",", "n_steps", ")", ":", "\n", "\n", "    ", "if", "infinite_horizon", ":", "\n", "        ", "rewards", "=", "[", "list", "(", "itertools", ".", "chain", "(", "*", "rewards", ")", ")", "]", "\n", "\n", "", "lives", "=", "len", "(", "rewards", ")", "\n", "\n", "values", "=", "[", "]", "\n", "terminals", "=", "[", "]", "\n", "for", "life", "in", "range", "(", "lives", ")", ":", "\n", "\n", "        ", "episode_len", "=", "len", "(", "rewards", "[", "life", "]", ")", "\n", "\n", "if", "not", "episode_len", ":", "\n", "            ", "continue", "\n", "\n", "", "discounts", "=", "discount", "**", "np", ".", "arange", "(", "len", "(", "rewards", "[", "life", "]", ")", "+", "1", ")", "\n", "\n", "r", "=", "np", ".", "array", "(", "rewards", "[", "life", "]", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n", "if", "clip", ">", "0", ":", "\n", "            ", "r", "=", "np", ".", "clip", "(", "r", ",", "-", "clip", ",", "clip", ")", "\n", "", "else", ":", "\n", "            ", "r", "=", "r", "/", "r_scale", "\n", "# r = np.sign(r) * np.log(np.abs(r) + 1)", "\n", "\n", "", "r", "[", "-", "1", "]", "+=", "termination_reward", "\n", "val", "=", "np", ".", "zeros", "(", "r", ".", "shape", ")", "\n", "t", "=", "np", ".", "zeros", "(", "r", ".", "shape", ")", "\n", "t", "[", "-", "n_steps", ":", "]", "=", "1", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "r", ")", ")", ":", "\n", "            ", "val", "[", "i", "]", "=", "(", "r", "[", "i", ":", "]", "*", "discounts", "[", ":", "-", "i", "-", "1", "]", ")", ".", "sum", "(", ")", "\n", "\n", "", "if", "episode_len", ">", "n_steps", ":", "\n", "            ", "val_shift", "=", "discount", "**", "n_steps", "*", "np", ".", "concatenate", "(", "(", "val", "[", "n_steps", ":", "]", ",", "np", ".", "zeros", "(", "n_steps", ")", ")", ")", "\n", "val", "=", "val", "-", "val_shift", "\n", "\n", "", "values", ".", "append", "(", "val", ")", "\n", "terminals", ".", "append", "(", "t", ")", "\n", "\n", "", "return", "np", ".", "concatenate", "(", "values", ")", ".", "astype", "(", "np", ".", "float32", ")", ",", "np", ".", "concatenate", "(", "terminals", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_tde": [[289, 303], ["preprocess.get_td_value", "np.concatenate.mean", "numpy.concatenate", "numpy.convolve", "pandas.Series().rolling().max().dropna", "numpy.abs", "numpy.abs", "numpy.ones", "numpy.ones", "pandas.Series().rolling().max", "numpy.array", "pandas.Series().rolling", "pandas.Series"], "function", ["home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_td_value"], ["", "def", "get_tde", "(", "rewards", ",", "v_target", ",", "discount", ",", "n_steps", ",", "q_expected", ")", ":", "\n", "\n", "# tde calculations", "\n", "    ", "td_target", "=", "get_td_value", "(", "rewards", ",", "v_target", ",", "discount", ",", "n_steps", ")", "\n", "tde", "=", "(", "np", ".", "abs", "(", "np", ".", "array", "(", "q_expected", ")", "-", "td_target", ")", "+", "0.01", ")", "/", "(", "np", ".", "abs", "(", "td_target", ")", "+", "0.01", ")", "\n", "\n", "n", "=", "seq_length", "-", "n_steps", "\n", "global_avg", "=", "tde", ".", "mean", "(", ")", "\n", "avg_td", "=", "np", ".", "convolve", "(", "tde", ",", "np", ".", "ones", "(", "n", ")", "/", "n", ",", "mode", "=", "'full'", ")", "[", ":", "-", "(", "n", "-", "1", ")", "]", "\n", "tde", "=", "np", ".", "concatenate", "(", "(", "tde", ",", "np", ".", "ones", "(", "n", "-", "1", ")", "*", "global_avg", ")", ")", "\n", "max_tde", "=", "pd", ".", "Series", "(", "tde", ")", ".", "rolling", "(", "n", ")", ".", "max", "(", ")", ".", "dropna", "(", ")", ".", "values", "\n", "# up to here", "\n", "\n", "return", "(", "priority_eta", "*", "max_tde", "+", "(", "1", "-", "priority_eta", ")", "*", "avg_td", ")", "**", "priority_alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_gtd_value": [[305, 345], ["len", "range", "numpy.concatenate().astype", "len", "numpy.arange", "numpy.flipud", "numpy.array", "numpy.array", "numpy.zeros", "range", "values.append", "list", "numpy.exp", "numpy.cumsum", "numpy.clip", "len", "numpy.clip", "numpy.concatenate", "itertools.chain", "len", "numpy.flipud", "numpy.sqrt"], "function", ["None"], ["", "def", "get_gtd_value", "(", "rewards", ",", "v_target", ",", "discount", ",", "mu", ",", "sigma", ")", ":", "\n", "\n", "    ", "if", "infinite_horizon", ":", "\n", "        ", "rewards", "=", "[", "list", "(", "itertools", ".", "chain", "(", "*", "rewards", ")", ")", "]", "\n", "\n", "", "lives", "=", "len", "(", "rewards", ")", "\n", "\n", "values", "=", "[", "]", "\n", "for", "life", "in", "range", "(", "lives", ")", ":", "\n", "\n", "        ", "episode_len", "=", "len", "(", "rewards", "[", "life", "]", ")", "\n", "\n", "if", "not", "episode_len", ":", "\n", "            ", "continue", "\n", "\n", "", "x_axis", "=", "np", ".", "arange", "(", "len", "(", "rewards", "[", "life", "]", ")", "+", "2", ")", "\n", "discounts", "=", "discount", "**", "x_axis", "\n", "\n", "alpha", "=", "1", "/", "(", "np", ".", "sqrt", "(", "2", "*", "np", ".", "pi", ")", "*", "sigma", ")", "*", "np", ".", "exp", "(", "-", "(", "x_axis", "-", "mu", ")", "**", "2", "/", "(", "2", "*", "sigma", "**", "2", ")", ")", "\n", "alpha_sum_k_inf", "=", "np", ".", "flipud", "(", "np", ".", "cumsum", "(", "np", ".", "flipud", "(", "alpha", ")", ")", ")", "\n", "\n", "r", "=", "np", ".", "array", "(", "rewards", "[", "life", "]", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "v_t", "=", "np", ".", "array", "(", "v_target", "[", "life", "]", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "\n", "if", "clip", ">", "0", ":", "\n", "            ", "r", "=", "np", ".", "clip", "(", "r", ",", "-", "clip", ",", "clip", ")", "\n", "", "else", ":", "\n", "            ", "r", "=", "r", "/", "r_scale", "\n", "# r = np.sign(r) * np.log(np.abs(r) + 1)", "\n", "\n", "", "r", "[", "-", "1", "]", "+=", "termination_reward", "\n", "val", "=", "np", ".", "zeros", "(", "r", ".", "shape", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "r", ")", ")", ":", "\n", "            ", "scale", "=", "np", ".", "clip", "(", "(", "alpha_sum_k_inf", "[", "0", "]", "-", "alpha_sum_k_inf", "[", "-", "i", "-", "1", "]", ")", ",", "a_min", "=", "1e-6", ",", "a_max", "=", "None", ")", "\n", "val", "[", "i", "]", "=", "(", "(", "r", "[", "i", ":", "]", "*", "discounts", "[", ":", "-", "i", "-", "2", "]", "*", "(", "alpha_sum_k_inf", "[", ":", "-", "i", "-", "2", "]", "-", "alpha_sum_k_inf", "[", "-", "i", "-", "1", "]", ")", ")", ".", "sum", "(", ")", "+", "\n", "(", "alpha", "[", "1", ":", "-", "i", "-", "2", "]", "*", "discounts", "[", "1", ":", "-", "i", "-", "2", "]", "*", "v_t", "[", "i", "+", "1", ":", "]", ")", ".", "sum", "(", ")", ")", "/", "scale", "\n", "\n", "", "values", ".", "append", "(", "val", ")", "\n", "\n", "", "return", "np", ".", "concatenate", "(", "values", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.state_to_img": [[357, 364], ["s.squeeze().data[].cpu().numpy", "numpy.rollaxis", "s.squeeze().data[].cpu", "s.squeeze"], "function", ["None"], ["", "def", "state_to_img", "(", "s", ")", ":", "\n", "\n", "    ", "img", "=", "s", ".", "squeeze", "(", "0", ")", ".", "data", "[", ":", "3", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "img", "=", "np", ".", "rollaxis", "(", "img", ",", "0", ",", "3", ")", "[", ":", ",", ":", ",", ":", "3", "]", "\n", "img", "=", "(", "img", "*", "256", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file": [[366, 377], ["open", "fcntl.lockf"], "function", ["None"], ["", "def", "lock_file", "(", "file", ")", ":", "\n", "\n", "    ", "fo", "=", "open", "(", "file", ",", "\"r+b\"", ")", "\n", "while", "True", ":", "\n", "        ", "try", ":", "\n", "            ", "fcntl", ".", "lockf", "(", "fo", ",", "fcntl", ".", "LOCK_EX", "|", "fcntl", ".", "LOCK_NB", ")", "\n", "break", "\n", "", "except", "IOError", ":", "\n", "            ", "pass", "\n", "\n", "", "", "return", "fo", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file": [[379, 382], ["fcntl.lockf", "fo.close"], "function", ["None"], ["", "def", "release_file", "(", "fo", ")", ":", "\n", "    ", "fcntl", ".", "lockf", "(", "fo", ",", "fcntl", ".", "LOCK_UN", ")", "\n", "fo", ".", "close", "(", ")", "", "", ""]], "home.repos.pwc.inspect_result.eladsar_rbi.None.model.DuelNet.__init__": [[12, 44], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "model.DuelNet.cnn[].bias.data.zero_", "model.DuelNet.cnn[].bias.data.zero_", "model.DuelNet.cnn[].bias.data.zero_", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.memory.ReplayBatchSampler.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "super", "(", "DuelNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# value net", "\n", "self", ".", "fc_v", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "3136", ",", "args", ".", "hidden_features", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "args", ".", "hidden_features", ",", "1", ")", ",", "\n", ")", "\n", "\n", "# advantage net", "\n", "self", ".", "fc_adv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "3136", ",", "args", ".", "hidden_features", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "args", ".", "hidden_features", ",", "action_space", ")", ",", "\n", ")", "\n", "\n", "# batch normalization and dropout", "\n", "self", ".", "cnn", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "args", ".", "history_length", ",", "32", ",", "kernel_size", "=", "8", ",", "stride", "=", "4", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", ")", "\n", "\n", "# initialization", "\n", "self", ".", "cnn", "[", "0", "]", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "cnn", "[", "2", "]", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "cnn", "[", "4", "]", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.model.DuelNet.reset": [[45, 48], ["model.DuelNet.parameters", "torch.nn.init.xavier_uniform"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "for", "weight", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform", "(", "weight", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.model.DuelNet.forward": [[49, 67], ["model.DuelNet.cnn", "s.view.view.view", "model.DuelNet.fc_v", "model.DuelNet.fc_adv", "adv.gather().squeeze", "q.gather().squeeze", "s.view.view.size", "adv.gather", "q.gather"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "s", ",", "a", ",", "beta", ")", ":", "\n", "\n", "# state CNN", "\n", "        ", "s", "=", "self", ".", "cnn", "(", "s", ")", "\n", "s", "=", "s", ".", "view", "(", "s", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "v", "=", "self", ".", "fc_v", "(", "s", ")", "\n", "adv_tilde", "=", "self", ".", "fc_adv", "(", "s", ")", "\n", "\n", "bias", "=", "(", "adv_tilde", "*", "beta", ")", ".", "sum", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "adv", "=", "adv_tilde", "-", "bias", "\n", "\n", "adv_a", "=", "adv", ".", "gather", "(", "1", ",", "a", ")", ".", "squeeze", "(", "1", ")", "\n", "q", "=", "v", "+", "adv", "\n", "\n", "q_a", "=", "q", ".", "gather", "(", "1", ",", "a", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "return", "v", ",", "adv", ",", "adv_a", ",", "q", ",", "q_a", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.model.BehavioralNet.__init__": [[71, 96], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Sequential", "model.BehavioralNet.cnn[].bias.data.zero_", "model.BehavioralNet.cnn[].bias.data.zero_", "model.BehavioralNet.cnn[].bias.data.zero_", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.memory.ReplayBatchSampler.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "super", "(", "BehavioralNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# batch normalization and dropout", "\n", "self", ".", "cnn", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "args", ".", "history_length", ",", "32", ",", "kernel_size", "=", "8", ",", "stride", "=", "4", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", ")", "\n", "\n", "# advantage net", "\n", "self", ".", "fc_beta", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "3136", ",", "args", ".", "hidden_features", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "args", ".", "hidden_features", ",", "action_space", ")", ",", "\n", ")", "\n", "\n", "# initialization", "\n", "self", ".", "cnn", "[", "0", "]", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "cnn", "[", "2", "]", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "cnn", "[", "4", "]", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.model.BehavioralNet.reset": [[97, 100], ["model.BehavioralNet.parameters", "torch.nn.init.xavier_uniform"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "for", "weight", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform", "(", "weight", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.model.BehavioralNet.forward": [[101, 110], ["model.BehavioralNet.cnn", "s.view.view.view", "model.BehavioralNet.fc_beta", "s.view.view.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "s", ")", ":", "\n", "\n", "# state CNN", "\n", "\n", "        ", "s", "=", "self", ".", "cnn", "(", "s", ")", "\n", "s", "=", "s", ".", "view", "(", "s", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "beta", "=", "self", ".", "fc_beta", "(", "s", ")", "\n", "\n", "return", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.model.DuelRNN.__init__": [[114, 153], ["torch.nn.Module.__init__", "int", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.LSTM", "model.DuelRNN.cnn[].bias.data.zero_", "model.DuelRNN.cnn[].bias.data.zero_", "model.DuelRNN.cnn[].bias.data.zero_", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.memory.ReplayBatchSampler.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "super", "(", "DuelRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "hidden_rnn", "=", "int", "(", "args", ".", "hidden_features_rnn", "/", "2", ")", "\n", "# self.hidden_rnn = int(args.hidden_features_rnn)", "\n", "\n", "# advantage net", "\n", "self", ".", "fc_adv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "hidden_rnn", ",", "args", ".", "hidden_features", ")", ",", "\n", "# nn.Linear(3136, args.hidden_features),", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "args", ".", "hidden_features", ",", "action_space", ")", ",", "\n", ")", "\n", "\n", "self", ".", "fc_v", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "hidden_rnn", ",", "args", ".", "hidden_features", ")", ",", "\n", "# nn.Linear(3136, args.hidden_features),", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "args", ".", "hidden_features", ",", "1", ")", ",", "\n", ")", "\n", "\n", "# batch normalization and dropout", "\n", "self", ".", "cnn", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "args", ".", "history_length", ",", "32", ",", "kernel_size", "=", "8", ",", "stride", "=", "4", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", ")", "\n", "\n", "# self.rnn = nn.LSTM(self.hidden_rnn, self.hidden_rnn, 1, batch_first=True, dropout=0, bidirectional=False)", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "3136", ",", "self", ".", "hidden_rnn", ",", "1", ",", "batch_first", "=", "True", ",", "dropout", "=", "0", ",", "bidirectional", "=", "False", ")", "\n", "\n", "# initialization", "\n", "self", ".", "cnn", "[", "0", "]", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "cnn", "[", "2", "]", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "cnn", "[", "4", "]", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.model.DuelRNN.forward": [[154, 179], ["s.view.view.view", "model.DuelRNN.cnn", "s.view.view.view", "torch.cat.unsqueeze_", "torch.cat.view", "model.DuelRNN.rnn", "torch.cat", "torch.cat.squeeze_", "model.DuelRNN.fc_v", "model.DuelRNN.fc_adv", "q.gather().squeeze", "torch.cat.detach", "h[].contiguous", "h[].contiguous", "q.gather"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "s", ",", "a", ",", "beta", ",", "h", ")", ":", "\n", "\n", "# state CNN", "\n", "        ", "batch", ",", "seq", ",", "channel", ",", "height", ",", "width", "=", "s", ".", "shape", "\n", "s", "=", "s", ".", "view", "(", "batch", "*", "seq", ",", "channel", ",", "height", ",", "width", ")", "\n", "s", "=", "self", ".", "cnn", "(", "s", ")", "\n", "s", "=", "s", ".", "view", "(", "batch", ",", "seq", ",", "3136", ")", "\n", "\n", "h", ".", "unsqueeze_", "(", "0", ")", "\n", "h", "=", "h", ".", "view", "(", "1", ",", "batch", ",", "self", ".", "hidden_rnn", ",", "2", ")", "\n", "s", ",", "h", "=", "self", ".", "rnn", "(", "s", ",", "(", "h", "[", ":", ",", ":", ",", ":", ",", "0", "]", ".", "contiguous", "(", ")", ",", "h", "[", ":", ",", ":", ",", ":", ",", "1", "]", ".", "contiguous", "(", ")", ")", ")", "\n", "h", "=", "torch", ".", "cat", "(", "h", ",", "dim", "=", "2", ")", "\n", "#", "\n", "# s, h = self.rnn(s, h)", "\n", "h", ".", "squeeze_", "(", "0", ")", "\n", "\n", "v", "=", "self", ".", "fc_v", "(", "s", ")", "\n", "adv_tilde", "=", "self", ".", "fc_adv", "(", "s", ")", "\n", "bias", "=", "(", "adv_tilde", "*", "beta", ")", ".", "sum", "(", "2", ")", ".", "unsqueeze", "(", "2", ")", "\n", "adv", "=", "adv_tilde", "-", "bias", "\n", "\n", "q", "=", "v", "+", "adv", "\n", "q_a", "=", "q", ".", "gather", "(", "2", ",", "a", ")", ".", "squeeze", "(", "2", ")", "\n", "\n", "return", "q", ",", "q_a", ",", "h", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.model.BehavioralRNN.__init__": [[183, 214], ["torch.nn.Module.__init__", "int", "torch.nn.Sequential", "torch.nn.LSTM", "torch.nn.Sequential", "model.BehavioralRNN.cnn[].bias.data.zero_", "model.BehavioralRNN.cnn[].bias.data.zero_", "model.BehavioralRNN.cnn[].bias.data.zero_", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Linear", "torch.nn.ReLU", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.memory.ReplayBatchSampler.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "super", "(", "BehavioralRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "hidden_rnn", "=", "int", "(", "args", ".", "hidden_features_rnn", "/", "2", ")", "\n", "\n", "# batch normalization and dropout", "\n", "self", ".", "cnn", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "args", ".", "history_length", ",", "32", ",", "kernel_size", "=", "8", ",", "stride", "=", "4", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", ")", "\n", "\n", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "3136", ",", "self", ".", "hidden_rnn", ",", "1", ",", "batch_first", "=", "True", ",", "dropout", "=", "0", ",", "bidirectional", "=", "False", ")", "\n", "# self.rnn = nn.GRU(3136, self.hidden_rnn, 1, batch_first=True, dropout=0, bidirectional=False)", "\n", "\n", "# behavior net", "\n", "self", ".", "fc_beta", "=", "nn", ".", "Sequential", "(", "\n", "# nn.Linear(3136, args.hidden_features),", "\n", "nn", ".", "Linear", "(", "self", ".", "hidden_rnn", ",", "args", ".", "hidden_features", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "args", ".", "hidden_features", ",", "action_space", ")", ",", "\n", ")", "\n", "\n", "# initialization", "\n", "self", ".", "cnn", "[", "0", "]", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "cnn", "[", "2", "]", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "cnn", "[", "4", "]", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.model.BehavioralRNN.forward": [[215, 234], ["s.view.view.view", "model.BehavioralRNN.cnn", "s.view.view.view", "torch.cat.unsqueeze_", "torch.cat.view", "model.BehavioralRNN.rnn", "torch.cat", "torch.cat.squeeze_", "model.BehavioralRNN.fc_beta", "torch.cat.detach", "h[].contiguous", "h[].contiguous"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "s", ",", "h", ")", ":", "\n", "\n", "# state CNN", "\n", "        ", "batch", ",", "seq", ",", "channel", ",", "height", ",", "width", "=", "s", ".", "shape", "\n", "s", "=", "s", ".", "view", "(", "-", "1", ",", "channel", ",", "height", ",", "width", ")", "\n", "\n", "# batch_seq, channel, height, width = s.shape", "\n", "s", "=", "self", ".", "cnn", "(", "s", ")", "\n", "s", "=", "s", ".", "view", "(", "batch", ",", "seq", ",", "3136", ")", "\n", "\n", "h", ".", "unsqueeze_", "(", "0", ")", "\n", "h", "=", "h", ".", "view", "(", "1", ",", "batch", ",", "self", ".", "hidden_rnn", ",", "2", ")", "\n", "s", ",", "h", "=", "self", ".", "rnn", "(", "s", ",", "(", "h", "[", ":", ",", ":", ",", ":", ",", "0", "]", ".", "contiguous", "(", ")", ",", "h", "[", ":", ",", ":", ",", ":", ",", "1", "]", ".", "contiguous", "(", ")", ")", ")", "\n", "h", "=", "torch", ".", "cat", "(", "h", ",", "dim", "=", "2", ")", "\n", "h", ".", "squeeze_", "(", "0", ")", "\n", "\n", "beta", "=", "self", ".", "fc_beta", "(", "s", ")", "\n", "\n", "return", "beta", ",", "h", ".", "detach", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.__init__": [[32, 76], ["print", "agent.Agent.__init__", "model.BehavioralRNN().to", "model.DuelRNN().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.FloatTensor().unsqueeze().repeat().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "rbi_rnn_agent.RBIRNNAgent.a_zeros.repeat", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "numpy.ones", "environment.Env", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "torch.zeros().long().to", "numpy.arange", "memory_rnn.ObservationsRNNMemory", "memory_rnn.ObservationsRNNBatchSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "rbi_rnn_agent.RBIRNNAgent.value_net.parameters", "rbi_rnn_agent.RBIRNNAgent.beta_net.parameters", "model.BehavioralRNN", "model.DuelRNN", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.FloatTensor().unsqueeze().repeat", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.memory.ReplayBatchSampler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "root_dir", ",", "player", "=", "False", ",", "choose", "=", "False", ",", "checkpoint", "=", "None", ")", ":", "\n", "\n", "        ", "print", "(", "\"Learning with RBIRNNAgent\"", ")", "\n", "super", "(", "RBIRNNAgent", ",", "self", ")", ".", "__init__", "(", "root_dir", ",", "checkpoint", ")", "\n", "\n", "self", ".", "beta_net", "=", "BehavioralRNN", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "value_net", "=", "DuelRNN", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "pi_rand", "=", "np", ".", "ones", "(", "self", ".", "action_space", ")", "/", "self", ".", "action_space", "\n", "self", ".", "pi_rand_batch", "=", "torch", ".", "FloatTensor", "(", "self", ".", "pi_rand", ")", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "self", ".", "batch", ",", "1", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "a_zeros", "=", "torch", ".", "zeros", "(", "1", ",", "1", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "a_zeros_batch", "=", "self", ".", "a_zeros", ".", "repeat", "(", "self", ".", "batch", ",", "1", ")", "\n", "\n", "self", ".", "rec_type", "=", "consts", ".", "rec_type", "\n", "\n", "if", "player", ":", "\n", "\n", "# play variables", "\n", "            ", "self", ".", "env", "=", "Env", "(", ")", "\n", "self", ".", "a_zeros", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "1", ")", ".", "long", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "trajectory", "=", "[", "]", "\n", "self", ".", "images", "=", "[", "]", "\n", "self", ".", "choices", "=", "np", ".", "arange", "(", "self", ".", "action_space", ",", "dtype", "=", "np", ".", "int", ")", "\n", "self", ".", "n_replay_saved", "=", "1", "\n", "self", ".", "frame", "=", "0", "\n", "self", ".", "states", "=", "0", "\n", "\n", "", "else", ":", "\n", "\n", "# self.target_net = DuelNet().to(self.device)", "\n", "# datasets", "\n", "            ", "self", ".", "train_dataset", "=", "ObservationsRNNMemory", "(", "root_dir", ")", "\n", "self", ".", "train_sampler", "=", "ObservationsRNNBatchSampler", "(", "root_dir", ")", "\n", "self", ".", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "self", ".", "train_dataset", ",", "batch_sampler", "=", "self", ".", "train_sampler", ",", "\n", "num_workers", "=", "args", ".", "cpu_workers", ",", "pin_memory", "=", "True", ",", "drop_last", "=", "False", ")", "\n", "\n", "# configure learning", "\n", "\n", "# IT IS IMPORTANT TO ASSIGN MODEL TO CUDA/PARALLEL BEFORE DEFINING OPTIMIZER", "\n", "", "self", ".", "optimizer_value", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "value_net", ".", "parameters", "(", ")", ",", "lr", "=", "0.0001", ",", "eps", "=", "1e-3", ",", "weight_decay", "=", "0", ")", "\n", "self", ".", "optimizer_beta", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "beta_net", ".", "parameters", "(", ")", ",", "lr", "=", "0.0001", ",", "eps", "=", "1e-3", ",", "weight_decay", "=", "0", ")", "\n", "\n", "self", ".", "n_offset", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.save_checkpoint": [[77, 86], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "rbi_rnn_agent.RBIRNNAgent.beta_net.state_dict", "rbi_rnn_agent.RBIRNNAgent.value_net.state_dict", "rbi_rnn_agent.RBIRNNAgent.optimizer_value.state_dict", "rbi_rnn_agent.RBIRNNAgent.optimizer_beta.state_dict"], "methods", ["None"], ["", "def", "save_checkpoint", "(", "self", ",", "path", ",", "aux", "=", "None", ")", ":", "\n", "\n", "        ", "state", "=", "{", "'beta_net'", ":", "self", ".", "beta_net", ".", "state_dict", "(", ")", ",", "\n", "'value_net'", ":", "self", ".", "value_net", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_value'", ":", "self", ".", "optimizer_value", ".", "state_dict", "(", ")", ",", "\n", "'optimizer_beta'", ":", "self", ".", "optimizer_beta", ".", "state_dict", "(", ")", ",", "\n", "'aux'", ":", "aux", "}", "\n", "\n", "torch", ".", "save", "(", "state", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.load_checkpoint": [[87, 102], ["torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "rbi_rnn_agent.RBIRNNAgent.beta_net.load_state_dict", "rbi_rnn_agent.RBIRNNAgent.value_net.load_state_dict", "rbi_rnn_agent.RBIRNNAgent.optimizer_beta.load_state_dict", "rbi_rnn_agent.RBIRNNAgent.optimizer_value.load_state_dict"], "methods", ["None"], ["", "def", "load_checkpoint", "(", "self", ",", "path", ")", ":", "\n", "\n", "        ", "state", "=", "torch", ".", "load", "(", "path", ",", "map_location", "=", "\"cuda:%d\"", "%", "self", ".", "cuda_id", ")", "\n", "\n", "self", ".", "beta_net", ".", "load_state_dict", "(", "state", "[", "'beta_net'", "]", ")", "\n", "self", ".", "value_net", ".", "load_state_dict", "(", "state", "[", "'value_net'", "]", ")", "\n", "self", ".", "optimizer_beta", ".", "load_state_dict", "(", "state", "[", "'optimizer_beta'", "]", ")", "\n", "self", ".", "optimizer_value", ".", "load_state_dict", "(", "state", "[", "'optimizer_value'", "]", ")", "\n", "self", ".", "n_offset", "=", "state", "[", "'aux'", "]", "[", "'n'", "]", "\n", "try", ":", "\n", "            ", "self", ".", "behavioral_avg_score", "=", "state", "[", "'aux'", "]", "[", "'score'", "]", "\n", "", "except", ":", "\n", "            ", "pass", "\n", "\n", "", "return", "state", "[", "'aux'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.learn": [[103, 254], ["model.DuelRNN().to", "model.DuelRNN().to.load_state_dict", "rbi_rnn_agent.RBIRNNAgent.beta_net.train", "rbi_rnn_agent.RBIRNNAgent.value_net.train", "model.DuelRNN().to.eval", "tqdm.tqdm.tqdm", "rbi_rnn_agent.RBIRNNAgent.value_net.state_dict", "enumerate", "sample[].to", "sample[].to().unsqueeze_", "sample[].to", "sample[].to().unsqueeze_", "sample[].to", "sample[].to", "sample[].to", "sample[].to", "sample[].to().unsqueeze_", "sample[].to().unsqueeze_", "rbi_rnn_agent.RBIRNNAgent.beta_net", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "rbi_rnn_agent.RBIRNNAgent.value_net", "rbi_rnn_agent.RBIRNNAgent.beta_net", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "model.DuelRNN().to.", "v_target.squeeze().detach.squeeze().detach.squeeze().detach", "preprocess.h_torch", "rbi_rnn_agent.RBIRNNAgent.value_net", "v.squeeze.squeeze.squeeze", "v.squeeze.squeeze.detach", "q_a.view().data.cpu().numpy.view().data.cpu().numpy.detach", "adv_eval.detach.detach.detach", "rbi_rnn_agent.RBIRNNAgent.optimizer_beta.zero_grad", "loss_beta.backward", "rbi_rnn_agent.RBIRNNAgent.optimizer_beta.step", "rbi_rnn_agent.RBIRNNAgent.optimizer_value.zero_grad", "loss_value.backward", "rbi_rnn_agent.RBIRNNAgent.optimizer_value.step", "model.DuelRNN", "torch.nn.functional.softmax.detach", "torch.nn.functional.softmax.detach", "is_value.mean", "is_policy.mean", "sample[].to().unsqueeze_.view().data.cpu().numpy", "pi.view().clamp.view().clamp.view().clamp", "pi.view().clamp.view().clamp.sum().unsqueeze().repeat", "pi.view().clamp.view().clamp.log", "torch.nn.functional.softmax().detach", "torch.nn.functional.softmax().detach", "torch.nn.functional.softmax().detach", "torch.nn.functional.softmax().detach", "sample[].to.view().data.cpu().numpy", "torch.cat().view().data.cpu().numpy", "torch.cat().view().data.cpu().numpy", "torch.cat().view().data.cpu().numpy", "torch.cat().view().data.cpu().numpy", "torch.cat().view().data.cpu().numpy", "torch.cat().view().data.cpu().numpy", "torch.cat().view().data.cpu().numpy", "torch.cat().view().data.cpu().numpy", "torch.cat().view().data.cpu().numpy", "torch.cat().view().data.cpu().numpy", "torch.cat().view().data.cpu().numpy", "torch.cat().view().data.cpu().numpy", "torch.cat().view().data.cpu().numpy", "torch.cat().view().data.cpu().numpy", "torch.cat().view().data.cpu().numpy", "torch.cat().view().data.cpu().numpy", "q_a.view().data.cpu().numpy.view().data.cpu().numpy.view().data.cpu().numpy", "torch.nn.functional.softmax().detach.data.cpu().max", "beta_index.numpy.numpy.numpy", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "results[].append", "sample[].to", "sample[].to", "sample[].to", "sample[].to", "v_target.squeeze().detach.squeeze().detach.squeeze", "model.DuelRNN().to.load_state_dict", "Hbeta.data.mean().cpu().numpy", "Hpi.data.mean().cpu().numpy", "loss_beta.data.cpu().numpy", "loss_value.data.cpu().numpy", "rbi_rnn_agent.RBIRNNAgent.save_checkpoint", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "rbi_rnn_agent.RBIRNNAgent.beta_net.train", "rbi_rnn_agent.RBIRNNAgent.value_net.train", "preprocess.hinv_torch", "v_eval[].abs", "v.squeeze.detach.abs", "sample[].to().unsqueeze_.view().data.cpu", "pi.view().clamp.view().clamp.view", "pi.view().clamp.view().clamp.sum().unsqueeze", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "sample[].to.view().data.cpu", "torch.cat().view().data.cpu", "torch.cat().view().data.cpu", "torch.cat().view().data.cpu", "torch.cat().view().data.cpu", "torch.cat().view().data.cpu", "torch.cat().view().data.cpu", "torch.cat().view().data.cpu", "torch.cat().view().data.cpu", "torch.cat().view().data.cpu", "torch.cat().view().data.cpu", "torch.cat().view().data.cpu", "torch.cat().view().data.cpu", "torch.cat().view().data.cpu", "torch.cat().view().data.cpu", "torch.cat().view().data.cpu", "torch.cat().view().data.cpu", "q_a.view().data.cpu().numpy.view().data.cpu().numpy.view().data.cpu", "torch.nn.functional.softmax().detach.data.cpu", "rbi_rnn_agent.RBIRNNAgent.value_net.state_dict", "torch.nn.functional.softmax.view", "Hbeta.data.mean().cpu", "Hpi.data.mean().cpu", "loss_beta.data.cpu", "loss_value.data.cpu", "pi.view().clamp.view().clamp.sum", "torch.nn.functional.log_softmax.view", "sample[].to().unsqueeze_.view", "sample[].to.view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "torch.cat().view", "q_a.view().data.cpu().numpy.view().data.cpu().numpy.view", "Hbeta.data.mean", "Hpi.data.mean", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.train", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.train", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.save_checkpoint", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.train", "home.repos.pwc.inspect_result.eladsar_rbi.None.agent.Agent.train"], ["", "def", "learn", "(", "self", ",", "n_interval", ",", "n_tot", ")", ":", "\n", "\n", "        ", "target_net", "=", "DuelRNN", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "target_net", ".", "load_state_dict", "(", "self", ".", "value_net", ".", "state_dict", "(", ")", ")", "\n", "\n", "self", ".", "beta_net", ".", "train", "(", ")", "\n", "self", ".", "value_net", ".", "train", "(", ")", "\n", "target_net", ".", "eval", "(", ")", "\n", "\n", "results", "=", "{", "'n'", ":", "[", "]", ",", "'loss_value'", ":", "[", "]", ",", "'loss_beta'", ":", "[", "]", ",", "'act_diff'", ":", "[", "]", ",", "'a_agent'", ":", "[", "]", ",", "\n", "'a_player'", ":", "[", "]", ",", "'loss_std'", ":", "[", "]", ",", "'mc_val'", ":", "[", "]", ",", "\"Hbeta\"", ":", "[", "]", ",", "\"Hpi\"", ":", "[", "]", ",", "\"adv_a\"", ":", "[", "]", ",", "\"q_a\"", ":", "[", "]", "}", "\n", "\n", "for", "n", ",", "sample", "in", "tqdm", "(", "enumerate", "(", "self", ".", "train_loader", ")", ")", ":", "\n", "\n", "            ", "s", "=", "sample", "[", "'s'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "a", "=", "sample", "[", "'a'", "]", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze_", "(", "2", ")", "\n", "\n", "s_bi", "=", "sample", "[", "'s_bi'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "a_bi", "=", "sample", "[", "'a_bi'", "]", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze_", "(", "2", ")", "\n", "\n", "r", "=", "sample", "[", "'r'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "rho_q", "=", "sample", "[", "'rho_q'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "rho_v", "=", "sample", "[", "'rho_v'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "pi", "=", "sample", "[", "'pi'", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# burn in", "\n", "\n", "h_q", "=", "sample", "[", "'h_q'", "]", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze_", "(", "0", ")", "\n", "h_beta", "=", "sample", "[", "'h_beta'", "]", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze_", "(", "0", ")", "\n", "\n", "beta", ",", "h_beta", "=", "self", ".", "beta_net", "(", "s_bi", ",", "h_beta", ")", "\n", "beta", "=", "F", ".", "softmax", "(", "beta", ".", "detach", "(", ")", ",", "dim", "=", "2", ")", "\n", "\n", "_", ",", "_", ",", "_", ",", "_", ",", "_", ",", "h_q", "=", "self", ".", "value_net", "(", "s_bi", ",", "a_bi", ",", "beta", ",", "h_q", ")", "\n", "\n", "# _, _, _, _, q_a_bi, h_q = target_net(s_bi, a_bi, beta, h_q)", "\n", "\n", "# Behavioral nets", "\n", "beta", ",", "_", "=", "self", ".", "beta_net", "(", "s", ",", "h_beta", ")", "\n", "beta_log", "=", "F", ".", "log_softmax", "(", "beta", ",", "dim", "=", "2", ")", "\n", "beta", "=", "F", ".", "softmax", "(", "beta", ".", "detach", "(", ")", ",", "dim", "=", "2", ")", "\n", "\n", "v_target", ",", "_", ",", "_", ",", "_", ",", "_", ",", "_", "=", "target_net", "(", "s", ",", "a", ",", "beta", ",", "h_q", ")", "\n", "\n", "v_target", "=", "v_target", ".", "squeeze", "(", "2", ")", ".", "detach", "(", ")", "\n", "r", "=", "h_torch", "(", "r", "[", ":", ",", ":", "-", "self", ".", "n_steps", "]", "+", "self", ".", "discount", "**", "self", ".", "n_steps", "*", "hinv_torch", "(", "v_target", "[", ":", ",", "self", ".", "n_steps", ":", "]", ")", ")", "\n", "\n", "\n", "# r = h_torch((hinv_torch(torch.cat((q_a_bi[:, -self.n_steps:], q_a_target[:, :-self.n_steps]), dim=1)) - r) / (", "\n", "#             self.discount ** self.n_steps))", "\n", "# r.detach_()", "\n", "\n", "v", ",", "adv_eval", ",", "adv_a", ",", "_", ",", "q_a", ",", "_", "=", "self", ".", "value_net", "(", "s", ",", "a", ",", "beta", ",", "h_q", ")", "\n", "\n", "v", "=", "v", ".", "squeeze", "(", "2", ")", "\n", "v_eval", "=", "v", ".", "detach", "(", ")", "\n", "q_a_eval", "=", "q_a", ".", "detach", "(", ")", "\n", "adv_eval", "=", "adv_eval", ".", "detach", "(", ")", "\n", "\n", "is_value", "=", "(", "(", "(", "r", "-", "q_a_eval", "[", ":", ",", ":", "-", "self", ".", "n_steps", "]", ")", ".", "abs", "(", ")", "+", "0.01", ")", "/", "(", "v_eval", "[", ":", ",", ":", "-", "self", ".", "n_steps", "]", ".", "abs", "(", ")", "+", "0.01", ")", ")", "**", "self", ".", "priority_beta", "\n", "# is_value = (((r - q_a_eval).abs() + 0.01) / (v_eval.abs() + 0.01)) ** self.priority_beta", "\n", "is_value", "=", "is_value", "/", "is_value", ".", "mean", "(", ")", "\n", "\n", "beta_mix", "=", "(", "1", "-", "self", ".", "entropy_loss", ")", "*", "beta", "+", "self", ".", "entropy_loss", "/", "self", ".", "action_space", "\n", "std_q", "=", "(", "(", "beta_mix", "*", "adv_eval", "**", "2", ")", ".", "sum", "(", "dim", "=", "2", ")", ")", "**", "0.5", "\n", "is_policy", "=", "(", "(", "std_q", "+", "0.1", ")", "/", "(", "v_eval", ".", "abs", "(", ")", "+", "0.1", ")", ")", "**", "self", ".", "priority_beta", "\n", "is_policy", "=", "is_policy", "/", "is_policy", ".", "mean", "(", ")", "\n", "\n", "# loss_value = ((v_eval * (1 - rho_v) + v * rho_v + adv_a - r) ** 2 * is_value * rho_q).mean()", "\n", "loss_value", "=", "(", "(", "v_eval", "[", ":", ",", ":", "-", "self", ".", "n_steps", "]", "*", "(", "1", "-", "rho_v", "[", ":", ",", ":", "-", "self", ".", "n_steps", "]", ")", "\n", "+", "v", "[", ":", ",", ":", "-", "self", ".", "n_steps", "]", "*", "rho_v", "[", ":", ",", ":", "-", "self", ".", "n_steps", "]", "\n", "+", "adv_a", "[", ":", ",", ":", "-", "self", ".", "n_steps", "]", "-", "r", ")", "**", "2", "*", "is_value", "*", "rho_q", "[", ":", ",", ":", "-", "self", ".", "n_steps", "]", ")", ".", "mean", "(", ")", "\n", "\n", "loss_beta", "=", "(", "(", "-", "pi", "*", "beta_log", ")", ".", "sum", "(", "dim", "=", "2", ")", "*", "is_policy", ")", ".", "mean", "(", ")", "\n", "\n", "# Learning part", "\n", "\n", "self", ".", "optimizer_beta", ".", "zero_grad", "(", ")", "\n", "loss_beta", ".", "backward", "(", ")", "\n", "self", ".", "optimizer_beta", ".", "step", "(", ")", "\n", "\n", "self", ".", "optimizer_value", ".", "zero_grad", "(", ")", "\n", "loss_value", ".", "backward", "(", ")", "\n", "self", ".", "optimizer_value", ".", "step", "(", ")", "\n", "\n", "# collect actions statistics", "\n", "\n", "if", "not", "(", "n", "+", "1", "+", "self", ".", "n_offset", ")", "%", "50", ":", "\n", "\n", "                ", "a_index_np", "=", "a", ".", "view", "(", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# avoid zero pi", "\n", "pi", "=", "pi", ".", "view", "(", "-", "1", ",", "self", ".", "action_space", ")", ".", "clamp", "(", "min", "=", "1e-4", ",", "max", "=", "1", ")", "\n", "pi", "/=", "pi", ".", "sum", "(", "dim", "=", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "self", ".", "action_space", ")", "\n", "\n", "pi_log", "=", "pi", ".", "log", "(", ")", "\n", "beta_soft", "=", "F", ".", "softmax", "(", "beta", ".", "view", "(", "-", "1", ",", "self", ".", "action_space", ")", ",", "dim", "=", "1", ")", ".", "detach", "(", ")", "\n", "\n", "Hpi", "=", "-", "(", "pi", "*", "pi_log", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "Hbeta", "=", "-", "(", "beta_soft", "*", "beta_log", ".", "view", "(", "-", "1", ",", "self", ".", "action_space", ")", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n", "adv_a", "=", "rho_v", ".", "view", "(", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "# r = r.view(-1).data.cpu().numpy()", "\n", "r", "=", "torch", ".", "cat", "(", "(", "r", ",", "q_a", "[", ":", ",", "-", "self", ".", "n_steps", ":", "]", ")", ",", "dim", "=", "1", ")", ".", "view", "(", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "q_a", "=", "q_a", ".", "view", "(", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "\n", "_", ",", "beta_index", "=", "beta_soft", ".", "data", ".", "cpu", "(", ")", ".", "max", "(", "1", ")", "\n", "beta_index", "=", "beta_index", ".", "numpy", "(", ")", "\n", "act_diff", "=", "(", "a_index_np", "!=", "beta_index", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "if", "not", "(", "n", "+", "1", ")", "%", "self", ".", "update_target_interval", ":", "\n", "# save agent state", "\n", "                    ", "target_net", ".", "load_state_dict", "(", "self", ".", "value_net", ".", "state_dict", "(", ")", ")", "\n", "\n", "# add results", "\n", "\n", "", "results", "[", "'act_diff'", "]", ".", "append", "(", "act_diff", ")", "\n", "results", "[", "'a_agent'", "]", ".", "append", "(", "beta_index", ")", "\n", "results", "[", "'adv_a'", "]", ".", "append", "(", "adv_a", ")", "\n", "results", "[", "'q_a'", "]", ".", "append", "(", "q_a", ")", "\n", "results", "[", "'a_player'", "]", ".", "append", "(", "a_index_np", ")", "\n", "results", "[", "'Hbeta'", "]", ".", "append", "(", "Hbeta", ".", "data", ".", "mean", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "results", "[", "'Hpi'", "]", ".", "append", "(", "Hpi", ".", "data", ".", "mean", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "results", "[", "'mc_val'", "]", ".", "append", "(", "r", ")", "\n", "\n", "# add results", "\n", "results", "[", "'loss_beta'", "]", ".", "append", "(", "loss_beta", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "results", "[", "'loss_value'", "]", ".", "append", "(", "loss_value", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "results", "[", "'loss_std'", "]", ".", "append", "(", "0", ")", "\n", "results", "[", "'n'", "]", ".", "append", "(", "n", ")", "\n", "\n", "if", "not", "(", "n", "+", "1", "+", "self", ".", "n_offset", ")", "%", "self", ".", "update_memory_interval", ":", "\n", "# save agent state", "\n", "                    ", "self", ".", "save_checkpoint", "(", "self", ".", "snapshot_path", ",", "{", "'n'", ":", "self", ".", "n_offset", "+", "n", "+", "1", "}", ")", "\n", "\n", "", "if", "not", "(", "n", "+", "1", "+", "self", ".", "n_offset", ")", "%", "n_interval", ":", "\n", "                    ", "results", "[", "'act_diff'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'act_diff'", "]", ")", "\n", "results", "[", "'a_agent'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'a_agent'", "]", ")", "\n", "results", "[", "'adv_a'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'adv_a'", "]", ")", "\n", "results", "[", "'q_a'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'q_a'", "]", ")", "\n", "results", "[", "'a_player'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'a_player'", "]", ")", "\n", "results", "[", "'mc_val'", "]", "=", "np", ".", "concatenate", "(", "results", "[", "'mc_val'", "]", ")", "\n", "\n", "yield", "results", "\n", "self", ".", "beta_net", ".", "train", "(", ")", "\n", "self", ".", "value_net", ".", "train", "(", ")", "\n", "results", "=", "{", "key", ":", "[", "]", "for", "key", "in", "results", "}", "\n", "\n", "if", "(", "n", "+", "self", ".", "n_offset", ")", ">=", "n_tot", ":", "\n", "                        ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.play": [[255, 374], ["range", "rbi_rnn_agent.RBIRNNAgent.env.reset", "rbi_rnn_agent.RBIRNNAgent.beta_net.eval", "rbi_rnn_agent.RBIRNNAgent.value_net.eval", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "_get_mc_value", "numpy.array", "print", "rbi_rnn_agent.RBIRNNAgent.env.s.to().unsqueeze", "rbi_rnn_agent.RBIRNNAgent.beta_net", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "rbi_rnn_agent.RBIRNNAgent.value_net", "q.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy", "v.squeeze().squeeze().data.cpu().numpy", "beta.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy", "adv.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy", "beta.squeeze().squeeze().data.cpu().numpy.copy.clip", "numpy.random.choice", "rbi_rnn_agent.RBIRNNAgent.env.step", "rbi_rnn_agent.RBIRNNAgent.load_checkpoint", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "rbi_rnn_agent.RBIRNNAgent.beta_net.eval", "rbi_rnn_agent.RBIRNNAgent.value_net.eval", "beta.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.detach", "beta.squeeze().squeeze().data.cpu().numpy.copy.sum", "rewards[].append", "v_target[].append", "numpy.array.append", "time.sleep", "rbi_rnn_agent.RBIRNNAgent.load_checkpoint", "rbi_rnn_agent.RBIRNNAgent.env.s.to", "q.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu", "v.squeeze().squeeze().data.cpu", "beta.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu", "adv.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu", "beta.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.copy", "adv.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.copy", "numpy.argsort", "numpy.argsort().astype", "rewards.append", "v_target.append", "str", "numpy.argmax", "numpy.min", "numpy.logical_or", "numpy.sum", "beta.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.copy", "numpy.argsort", "q.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze", "v.squeeze().squeeze", "beta.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze", "adv.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze", "q.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.squeeze", "v.squeeze", "beta.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.squeeze", "adv.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.squeeze"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.load_checkpoint", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.load_checkpoint"], ["", "", "", "", "", "def", "play", "(", "self", ",", "n_tot", ",", "save", "=", "True", ",", "load", "=", "True", ",", "fix", "=", "False", ")", ":", "\n", "\n", "        ", "for", "i", "in", "range", "(", "n_tot", ")", ":", "\n", "\n", "            ", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n", "rewards", "=", "[", "[", "]", "]", "\n", "v_target", "=", "[", "[", "]", "]", "\n", "q_val", "=", "[", "]", "\n", "lives", "=", "self", ".", "env", ".", "lives", "\n", "trigger", "=", "False", "\n", "\n", "while", "not", "fix", ":", "\n", "                ", "try", ":", "\n", "                    ", "self", ".", "load_checkpoint", "(", "self", ".", "snapshot_path", ")", "\n", "break", "\n", "", "except", ":", "\n", "                    ", "time", ".", "sleep", "(", "0.5", ")", "\n", "\n", "", "", "self", ".", "beta_net", ".", "eval", "(", ")", "\n", "self", ".", "value_net", ".", "eval", "(", ")", "\n", "\n", "# Initial states", "\n", "h_q", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "self", ".", "hidden_state", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "h_beta", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "self", ".", "hidden_state", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "while", "not", "self", ".", "env", ".", "t", ":", "\n", "\n", "                ", "if", "load", "and", "not", "(", "self", ".", "states", "%", "self", ".", "load_memory_interval", ")", ":", "\n", "                    ", "try", ":", "\n", "                        ", "self", ".", "load_checkpoint", "(", "self", ".", "snapshot_path", ")", "\n", "", "except", ":", "\n", "                        ", "pass", "\n", "\n", "", "self", ".", "beta_net", ".", "eval", "(", ")", "\n", "self", ".", "value_net", ".", "eval", "(", ")", "\n", "\n", "", "s", "=", "self", ".", "env", ".", "s", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze", "(", "0", ")", "\n", "trigger", "=", "trigger", "or", "(", "self", ".", "env", ".", "score", ">", "self", ".", "behavioral_avg_score", "*", "self", ".", "explore_threshold", ")", "\n", "\n", "beta", ",", "h_beta", "=", "self", ".", "beta_net", "(", "s", ",", "h_beta", ")", "\n", "beta", "=", "F", ".", "softmax", "(", "beta", ".", "detach", "(", ")", ",", "dim", "=", "2", ")", "\n", "\n", "# take q as adv", "\n", "\n", "v", ",", "adv", ",", "_", ",", "q", ",", "_", ",", "h_q", "=", "self", ".", "value_net", "(", "s", ",", "self", ".", "a_zeros", ",", "beta", ",", "h_q", ")", "\n", "\n", "q", "=", "q", ".", "squeeze", "(", "0", ")", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "v_expected", "=", "v", ".", "squeeze", "(", "0", ")", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "beta", "=", "beta", ".", "squeeze", "(", "0", ")", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "adv", "=", "adv", ".", "squeeze", "(", "0", ")", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "self", ".", "n_offset", ">=", "self", ".", "random_initialization", ":", "\n", "\n", "                    ", "if", "self", ".", "player", "==", "\"reroutetv\"", ":", "\n", "\n", "                        ", "pi", "=", "beta", ".", "copy", "(", ")", "\n", "adv2", "=", "adv", ".", "copy", "(", ")", "\n", "\n", "rank", "=", "np", ".", "argsort", "(", "adv", ")", "\n", "pi", "=", "self", ".", "cmin", "*", "pi", "\n", "\n", "Delta", "=", "1", "-", "self", ".", "cmin", "\n", "while", "Delta", ">", "0", ":", "\n", "                            ", "a", "=", "np", ".", "argmax", "(", "adv2", ")", "\n", "Delta_a", "=", "np", ".", "min", "(", "(", "Delta", ",", "(", "self", ".", "cmax", "-", "self", ".", "cmin", ")", "*", "beta", "[", "a", "]", ")", ")", "\n", "Delta", "-=", "Delta_a", "\n", "pi", "[", "a", "]", "+=", "Delta_a", "\n", "adv2", "[", "a", "]", "=", "-", "1e11", "\n", "\n", "", "adv_rank", "=", "np", ".", "argsort", "(", "rank", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "pi_adv", "=", "1.", "*", "np", ".", "logical_or", "(", "adv", ">=", "0", ",", "adv_rank", "==", "(", "self", ".", "action_space", "-", "1", ")", ")", "\n", "pi_adv", "=", "pi_adv", "/", "(", "np", ".", "sum", "(", "pi_adv", ")", ")", "\n", "\n", "pi", "=", "(", "1", "-", "self", ".", "mix", ")", "*", "pi", "+", "self", ".", "mix", "*", "pi_adv", "\n", "pi_mix", "=", "self", ".", "epsilon", "*", "self", ".", "pi_rand", "+", "(", "1", "-", "self", ".", "epsilon", ")", "*", "pi", "\n", "\n", "", "elif", "self", ".", "player", "==", "\"behavioral\"", ":", "\n", "                        ", "pi_mix", "=", "beta", ".", "copy", "(", ")", "\n", "\n", "", "else", ":", "\n", "                        ", "raise", "NotImplementedError", "\n", "\n", "", "", "else", ":", "\n", "                    ", "pi_mix", "=", "self", ".", "pi_rand", "\n", "\n", "", "pi_mix", "=", "pi_mix", ".", "clip", "(", "0", ",", "1", ")", "\n", "pi_mix", "=", "pi_mix", "/", "pi_mix", ".", "sum", "(", ")", "\n", "a", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "choices", ",", "p", "=", "pi_mix", ")", "\n", "self", ".", "env", ".", "step", "(", "a", ")", "\n", "\n", "if", "self", ".", "env", ".", "k", ">=", "self", ".", "history_length", ":", "\n", "\n", "                    ", "if", "lives", ">", "self", ".", "env", ".", "lives", ":", "\n", "                        ", "rewards", ".", "append", "(", "[", "]", ")", "\n", "v_target", ".", "append", "(", "[", "]", ")", "\n", "", "lives", "=", "self", ".", "env", ".", "lives", "\n", "\n", "rewards", "[", "-", "1", "]", ".", "append", "(", "self", ".", "env", ".", "r", ")", "\n", "v_target", "[", "-", "1", "]", ".", "append", "(", "v_expected", ")", "\n", "q_val", ".", "append", "(", "q", "[", "a", "]", ")", "\n", "\n", "", "self", ".", "frame", "+=", "1", "\n", "\n", "", "mc_val", "=", "_get_mc_value", "(", "rewards", ",", "None", ",", "self", ".", "discount", ",", "None", ")", "\n", "q_val", "=", "np", ".", "array", "(", "q_val", ")", "\n", "\n", "print", "(", "\"sts | st: %d\\t| sc: %d\\t| f: %d\\t| e: %7g\\t| typ: %2d | trg: %d | nst: %s\\t| n %d\\t| avg_r: %g\\t| avg_f: %g\"", "%", "\n", "(", "self", ".", "frame", ",", "self", ".", "env", ".", "score", ",", "self", ".", "env", ".", "k", ",", "0", ",", "0", ",", "0", ",", "str", "(", "np", ".", "nan", ")", ",", "\n", "self", ".", "n_offset", ",", "self", ".", "behavioral_avg_score", ",", "self", ".", "behavioral_avg_frame", ")", ")", "\n", "\n", "yield", "{", "'score'", ":", "self", ".", "env", ".", "score", ",", "\n", "'frames'", ":", "self", ".", "env", ".", "k", ",", "\"n\"", ":", "self", ".", "n_offset", ",", "\"mc\"", ":", "mc_val", ",", "\"q\"", ":", "q_val", "}", "\n", "\n", "if", "self", ".", "n_offset", ">=", "self", ".", "n_tot", "and", "not", "fix", ":", "\n", "                ", "break", "\n", "\n", "", "", "raise", "StopIteration", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.multiplay": [[375, 616], ["rbi_rnn_agent.RBIRNNAgent.a_zeros.repeat", "numpy.repeat", "numpy.arange", "preprocess.lock_file", "numpy.load().item", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "range", "numpy.arange", "environment.Env", "numpy.expand_dims", "numpy.arange", "mp_env[].reset", "os.path.join", "os.mkdir", "torch.zeros().to.squeeze().data.cpu().numpy", "torch.zeros().to.squeeze().data.cpu().numpy", "torch.zeros().to.squeeze().data.cpu().numpy", "torch.zeros().to.squeeze().data.cpu().numpy", "torch.zeros().to.squeeze().data.cpu().numpy", "torch.zeros().to.squeeze().data.cpu().numpy", "torch.zeros().to.squeeze().data.cpu().numpy", "torch.zeros().to.squeeze().data.cpu().numpy", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "torch.cat().to().unsqueeze", "rbi_rnn_agent.RBIRNNAgent.beta_net", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "rbi_rnn_agent.RBIRNNAgent.value_net", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy", "adv.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy", "v_expected.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy", "numpy.argsort", "numpy.argsort().astype", "numpy.logical_and", "numpy.repeat", "pi.astype.astype.astype", "range", "range", "range", "range", "range", "range", "range", "range", "os.path.join", "range", "os.path.join", "os.path.join", "numpy.load", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "str", "range", "rbi_rnn_agent.RBIRNNAgent.beta_net.eval", "rbi_rnn_agent.RBIRNNAgent.value_net.eval", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.detach", "numpy.expand_dims", "range", "numpy.repeat", "numpy.repeat", "pi_mix.clip.clip.clip", "numpy.random.choice", "cv2.imwrite", "episode[].append", "env.step", "[].append", "[].append", "[].append", "rbi_rnn_agent.RBIRNNAgent.load_checkpoint", "torch.zeros().to.squeeze().data.cpu", "torch.zeros().to.squeeze().data.cpu", "torch.zeros().to.squeeze().data.cpu", "torch.zeros().to.squeeze().data.cpu", "torch.zeros().to.squeeze().data.cpu", "torch.zeros().to.squeeze().data.cpu", "torch.zeros().to.squeeze().data.cpu", "torch.zeros().to.squeeze().data.cpu", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "torch.cat().to", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu", "adv.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu", "v_expected.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu", "numpy.argsort", "numpy.array", "numpy.ones", "numpy.minimum", "numpy.logical_or", "numpy.repeat", "numpy.min", "numpy.max", "numpy.repeat", "numpy.repeat", "os.path.join", "numpy.array", "rewards[].append", "v_target[].append", "rho[].append", "preprocess.get_expected_value", "preprocess.get_rho_is", "numpy.concatenate", "numpy.stack", "trajectory[].append", "h_q[].zero_", "h_beta[].zero_", "print", "env.reset", "preprocess.lock_file", "numpy.load().item", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "os.path.join", "os.mkdir", "numpy.sum", "numpy.repeat", "numpy.sum", "pi_mix.clip.clip.sum", "int", "numpy.clip", "numpy.clip", "str", "sum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "numpy.sum", "str", "numpy.load", "preprocess.lock_file", "numpy.load().item", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "numpy.concatenate", "os.path.join", "numpy.save", "preprocess.lock_file", "numpy.load", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "torch.zeros().to.squeeze", "torch.zeros().to.squeeze", "torch.zeros().to.squeeze", "torch.zeros().to.squeeze", "torch.zeros().to.squeeze", "torch.zeros().to.squeeze", "torch.zeros().to.squeeze", "torch.zeros().to.squeeze", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze", "beta.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze", "adv.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze", "v_expected.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze", "numpy.sign", "len", "psutil.virtual_memory", "numpy.append", "time.time", "numpy.load", "v_expected.squeeze().squeeze().data.cpu().numpy.squeeze().squeeze().data.cpu().numpy.squeeze"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step", "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.load_checkpoint", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.get_rho_is", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file"], ["", "def", "multiplay", "(", "self", ")", ":", "\n", "\n", "        ", "n_players", "=", "self", ".", "n_players", "\n", "\n", "player_i", "=", "np", ".", "arange", "(", "self", ".", "actor_index", ",", "self", ".", "actor_index", "+", "self", ".", "n_actors", "*", "n_players", ",", "self", ".", "n_actors", ")", "/", "(", "self", ".", "n_actors", "*", "n_players", "-", "1", ")", "\n", "\n", "explore_threshold", "=", "player_i", "\n", "\n", "mp_explore", "=", "0.4", "**", "(", "1", "+", "7", "*", "(", "1", "-", "player_i", ")", ")", "\n", "\n", "mp_env", "=", "[", "Env", "(", ")", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "self", ".", "frame", "=", "0", "\n", "\n", "a_zeros_mp", "=", "self", ".", "a_zeros", ".", "repeat", "(", "n_players", ",", "1", ",", "1", ")", "\n", "mp_pi_rand", "=", "np", ".", "repeat", "(", "np", ".", "expand_dims", "(", "self", ".", "pi_rand", ",", "axis", "=", "0", ")", ",", "n_players", ",", "axis", "=", "0", ")", "\n", "\n", "range_players", "=", "np", ".", "arange", "(", "n_players", ")", "\n", "rewards", "=", "[", "[", "[", "]", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "v_target", "=", "[", "[", "[", "]", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "rho", "=", "[", "[", "[", "]", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "episode", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "image_dir", "=", "[", "''", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "trajectory", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "screen_dir", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"screen\"", ")", "]", "*", "n_players", "\n", "fr_s", "=", "[", "self", ".", "frame", "+", "self", ".", "history_length", "-", "1", "for", "_", "in", "range", "(", "n_players", ")", "]", "\n", "\n", "trajectory_dir", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "explore_dir", ",", "\"trajectory\"", ")", "]", "*", "n_players", "\n", "\n", "readlock", "=", "[", "os", ".", "path", ".", "join", "(", "self", ".", "list_dir", ",", "\"readlock_explore.npy\"", ")", "]", "*", "n_players", "\n", "\n", "# set initial episodes number", "\n", "# lock read", "\n", "fwrite", "=", "lock_file", "(", "self", ".", "episodelock", ")", "\n", "current_num", "=", "np", ".", "load", "(", "fwrite", ")", ".", "item", "(", ")", "\n", "episode_num", "=", "current_num", "+", "np", ".", "arange", "(", "n_players", ")", "\n", "fwrite", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fwrite", ",", "current_num", "+", "n_players", ")", "\n", "# unlock file", "\n", "release_file", "(", "fwrite", ")", "\n", "\n", "# Initial states", "\n", "h_q", "=", "torch", ".", "zeros", "(", "1", ",", "n_players", ",", "self", ".", "hidden_state", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "h_beta", "=", "torch", ".", "zeros", "(", "1", ",", "n_players", ",", "self", ".", "hidden_state", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_players", ")", ":", "\n", "            ", "mp_env", "[", "i", "]", ".", "reset", "(", ")", "\n", "image_dir", "[", "i", "]", "=", "os", ".", "path", ".", "join", "(", "screen_dir", "[", "i", "]", ",", "str", "(", "episode_num", "[", "i", "]", ")", ")", "\n", "os", ".", "mkdir", "(", "image_dir", "[", "i", "]", ")", "\n", "\n", "", "lives", "=", "[", "mp_env", "[", "i", "]", ".", "lives", "for", "i", "in", "range", "(", "n_players", ")", "]", "\n", "\n", "while", "True", ":", "\n", "\n", "            ", "if", "not", "(", "self", ".", "frame", "%", "self", ".", "load_memory_interval", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "self", ".", "load_checkpoint", "(", "self", ".", "snapshot_path", ")", "\n", "", "except", ":", "\n", "                    ", "pass", "\n", "\n", "", "self", ".", "beta_net", ".", "eval", "(", ")", "\n", "self", ".", "value_net", ".", "eval", "(", ")", "\n", "\n", "# save previous hidden state to np object", "\n", "", "h_beta_np", "=", "h_beta", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "h_q_np", "=", "h_q", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "s", "=", "torch", ".", "cat", "(", "[", "env", ".", "s", "for", "env", "in", "mp_env", "]", ")", ".", "to", "(", "self", ".", "device", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "beta", ",", "h_beta", "=", "self", ".", "beta_net", "(", "s", ",", "h_beta", ")", "\n", "beta", "=", "F", ".", "softmax", "(", "beta", ".", "detach", "(", ")", ",", "dim", "=", "2", ")", "\n", "# take q as adv", "\n", "\n", "v_expected", ",", "adv", ",", "_", ",", "q", ",", "_", ",", "h_q", "=", "self", ".", "value_net", "(", "s", ",", "a_zeros_mp", ",", "beta", ",", "h_q", ")", "\n", "\n", "q", "=", "q", ".", "squeeze", "(", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "beta", "=", "beta", ".", "squeeze", "(", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "adv", "=", "adv", ".", "squeeze", "(", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "v_expected", "=", "v_expected", ".", "squeeze", "(", "1", ")", ".", "squeeze", "(", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "rank", "=", "np", ".", "argsort", "(", "adv", ",", "axis", "=", "1", ")", "\n", "adv_rank", "=", "np", ".", "argsort", "(", "rank", ",", "axis", "=", "1", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "\n", "mp_trigger", "=", "np", ".", "logical_and", "(", "\n", "np", ".", "array", "(", "[", "env", ".", "score", "for", "env", "in", "mp_env", "]", ")", ">=", "self", ".", "behavioral_avg_score", "*", "explore_threshold", ",", "\n", "explore_threshold", ">=", "0", ")", "\n", "\n", "exploration", "=", "np", ".", "repeat", "(", "np", ".", "expand_dims", "(", "mp_explore", "*", "mp_trigger", ",", "axis", "=", "1", ")", ",", "self", ".", "action_space", ",", "axis", "=", "1", ")", "\n", "\n", "if", "self", ".", "n_offset", ">=", "self", ".", "random_initialization", ":", "\n", "\n", "                ", "pi", "=", "self", ".", "cmin", "*", "beta", "\n", "\n", "Delta", "=", "np", ".", "ones", "(", "n_players", ")", "-", "self", ".", "cmin", "\n", "for", "i", "in", "range", "(", "self", ".", "action_space", ")", ":", "\n", "                    ", "a", "=", "rank", "[", ":", ",", "self", ".", "action_space", "-", "1", "-", "i", "]", "\n", "Delta_a", "=", "np", ".", "minimum", "(", "Delta", ",", "(", "self", ".", "cmax", "-", "self", ".", "cmin", ")", "*", "beta", "[", "range_players", ",", "a", "]", ")", "\n", "Delta", "-=", "Delta_a", "\n", "pi", "[", "range_players", ",", "a", "]", "+=", "Delta_a", "\n", "\n", "", "pi_adv", "=", "1.", "*", "np", ".", "logical_or", "(", "adv", ">=", "0", ",", "adv_rank", "==", "(", "self", ".", "action_space", "-", "1", ")", ")", "\n", "pi_adv", "=", "pi_adv", "/", "np", ".", "repeat", "(", "np", ".", "sum", "(", "pi_adv", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", ",", "self", ".", "action_space", ",", "axis", "=", "1", ")", "\n", "pi", "=", "(", "1", "-", "self", ".", "mix", ")", "*", "pi", "+", "self", ".", "mix", "*", "pi_adv", "\n", "\n", "# const explore", "\n", "pi", "=", "(", "1", "-", "self", ".", "eps_pre", ")", "*", "pi", "+", "self", ".", "eps_pre", "/", "self", ".", "action_space", "\n", "\n", "# soft explore", "\n", "qmin", "=", "np", ".", "repeat", "(", "np", ".", "min", "(", "q", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", ",", "self", ".", "action_space", ",", "axis", "=", "1", ")", "\n", "qmax", "=", "np", ".", "repeat", "(", "np", ".", "max", "(", "q", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", ",", "self", ".", "action_space", ",", "axis", "=", "1", ")", "\n", "\n", "soft_rand", "=", "self", ".", "temp_soft", "**", "(", "(", "q", "-", "qmin", ")", "/", "(", "qmax", "-", "qmin", ")", ")", "\n", "\n", "soft_reg", "=", "pi", "/", "(", "\n", "np", ".", "repeat", "(", "np", ".", "sum", "(", "soft_rand", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", ",", "self", ".", "action_space", ",", "axis", "=", "1", ")", "-", "soft_rand", ")", "\n", "soft_reg", "=", "np", ".", "repeat", "(", "np", ".", "sum", "(", "soft_reg", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", ",", "self", ".", "action_space", ",", "axis", "=", "1", ")", "-", "soft_reg", "\n", "\n", "pi_mix", "=", "pi", "*", "(", "1", "-", "exploration", ")", "+", "exploration", "*", "(", "soft_rand", "*", "soft_reg", ")", "\n", "\n", "pi_mix", "=", "pi_mix", ".", "clip", "(", "0", ",", "1", ")", "\n", "pi_mix", "=", "pi_mix", "/", "np", ".", "repeat", "(", "pi_mix", ".", "sum", "(", "axis", "=", "1", ",", "keepdims", "=", "True", ")", ",", "self", ".", "action_space", ",", "axis", "=", "1", ")", "\n", "\n", "", "else", ":", "\n", "                ", "pi", "=", "mp_pi_rand", "\n", "pi_mix", "=", "pi", "\n", "\n", "", "pi", "=", "pi", ".", "astype", "(", "np", ".", "float32", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_players", ")", ":", "\n", "\n", "                ", "a", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "choices", ",", "p", "=", "pi_mix", "[", "i", "]", ")", "\n", "\n", "env", "=", "mp_env", "[", "i", "]", "\n", "cv2", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "image_dir", "[", "i", "]", ",", "\"%s.png\"", "%", "str", "(", "self", ".", "frame", ")", ")", ",", "mp_env", "[", "i", "]", ".", "image", ",", "[", "imcompress", ",", "compress_level", "]", ")", "\n", "\n", "h_beta_save", "=", "h_beta_np", "[", "i", "]", "if", "not", "self", ".", "frame", "%", "self", ".", "seq_overlap", "else", "None", "\n", "h_q_save", "=", "h_q_np", "[", "i", "]", "if", "not", "self", ".", "frame", "%", "self", ".", "seq_overlap", "else", "None", "\n", "\n", "episode", "[", "i", "]", ".", "append", "(", "np", ".", "array", "(", "(", "self", ".", "frame", ",", "a", ",", "pi", "[", "i", "]", ",", "\n", "h_beta_save", ",", "h_q_save", ",", "\n", "episode_num", "[", "i", "]", ",", "0.", ",", "fr_s", "[", "i", "]", ",", "0", ",", "\n", "0.", ",", "1.", ",", "1.", ",", "0", ")", ",", "dtype", "=", "self", ".", "rec_type", ")", ")", "\n", "\n", "env", ".", "step", "(", "a", ")", "\n", "\n", "if", "lives", "[", "i", "]", ">", "env", ".", "lives", ":", "\n", "                    ", "rewards", "[", "i", "]", ".", "append", "(", "[", "]", ")", "\n", "v_target", "[", "i", "]", ".", "append", "(", "[", "]", ")", "\n", "rho", "[", "i", "]", ".", "append", "(", "[", "]", ")", "\n", "", "lives", "[", "i", "]", "=", "env", ".", "lives", "\n", "\n", "rewards", "[", "i", "]", "[", "-", "1", "]", ".", "append", "(", "env", ".", "r", ")", "\n", "v_target", "[", "i", "]", "[", "-", "1", "]", ".", "append", "(", "v_expected", "[", "i", "]", ")", "\n", "rho", "[", "i", "]", "[", "-", "1", "]", ".", "append", "(", "pi", "[", "i", "]", "[", "a", "]", "/", "pi_mix", "[", "i", "]", "[", "a", "]", ")", "\n", "\n", "if", "env", ".", "t", ":", "\n", "\n", "# cancel termination reward", "\n", "                    ", "rewards", "[", "i", "]", "[", "-", "1", "]", "[", "-", "1", "]", "-=", "self", ".", "termination_reward", "*", "int", "(", "env", ".", "k", "*", "self", ".", "skip", ">=", "self", ".", "max_length", "or", "env", ".", "score", ">=", "self", ".", "max_score", ")", "\n", "td_val", "=", "get_expected_value", "(", "rewards", "[", "i", "]", ",", "v_target", "[", "i", "]", ",", "self", ".", "discount", ",", "self", ".", "n_steps", ")", "\n", "rho_val", "=", "get_rho_is", "(", "rho", "[", "i", "]", ",", "self", ".", "n_steps", ")", "\n", "\n", "rho_vec", "=", "np", ".", "concatenate", "(", "rho", "[", "i", "]", ")", "\n", "\n", "episode_df", "=", "np", ".", "stack", "(", "episode", "[", "i", "]", "[", "self", ".", "history_length", "-", "1", ":", "self", ".", "max_length", "]", ")", "\n", "# episode_df = pd.DataFrame(episode[i][self.history_length - 1:self.max_length])", "\n", "\n", "episode_df", "[", "'r'", "]", "=", "td_val", "[", "self", ".", "history_length", "-", "1", ":", "self", ".", "max_length", "]", "\n", "episode_df", "[", "'rho_v'", "]", "=", "np", ".", "clip", "(", "rho_vec", ",", "0", ",", "1", ")", "[", "self", ".", "history_length", "-", "1", ":", "self", ".", "max_length", "]", "\n", "episode_df", "[", "'rho_q'", "]", "=", "np", ".", "clip", "(", "rho_val", ",", "0", ",", "1", ")", "[", "self", ".", "history_length", "-", "1", ":", "self", ".", "max_length", "]", "\n", "episode_df", "[", "'fr_e'", "]", "=", "episode_df", "[", "-", "1", "]", "[", "'fr'", "]", "+", "1", "\n", "\n", "trajectory", "[", "i", "]", ".", "append", "(", "episode_df", ")", "\n", "\n", "# reset hidden states", "\n", "h_q", "[", ":", ",", "i", ",", ":", "]", ".", "zero_", "(", ")", "\n", "h_beta", "[", ":", ",", "i", ",", ":", "]", ".", "zero_", "(", ")", "\n", "\n", "print", "(", "\"rbi | st: %d\\t| sc: %d\\t| f: %d\\t| e: %7g\\t| typ: %2d | trg: %d | t: %d\\t| n %d\\t| avg_r: %g\\t| avg_f: %g\"", "%", "\n", "(", "self", ".", "frame", ",", "env", ".", "score", ",", "env", ".", "k", ",", "mp_explore", "[", "i", "]", ",", "np", ".", "sign", "(", "explore_threshold", "[", "i", "]", ")", ",", "mp_trigger", "[", "i", "]", ",", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", ",", "self", ".", "n_offset", ",", "self", ".", "behavioral_avg_score", ",", "self", ".", "behavioral_avg_frame", ")", ")", "\n", "\n", "env", ".", "reset", "(", ")", "\n", "episode", "[", "i", "]", "=", "[", "]", "\n", "rewards", "[", "i", "]", "=", "[", "[", "]", "]", "\n", "rho", "[", "i", "]", "=", "[", "[", "]", "]", "\n", "v_target", "[", "i", "]", "=", "[", "[", "]", "]", "\n", "lives", "[", "i", "]", "=", "env", ".", "lives", "\n", "mp_trigger", "[", "i", "]", "=", "0", "\n", "fr_s", "[", "i", "]", "=", "(", "self", ".", "frame", "+", "1", ")", "+", "(", "self", ".", "history_length", "-", "1", ")", "\n", "\n", "# get new episode number", "\n", "\n", "# lock read", "\n", "fwrite", "=", "lock_file", "(", "self", ".", "episodelock", ")", "\n", "episode_num", "[", "i", "]", "=", "np", ".", "load", "(", "fwrite", ")", ".", "item", "(", ")", "\n", "fwrite", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fwrite", ",", "episode_num", "[", "i", "]", "+", "1", ")", "\n", "# unlock file", "\n", "release_file", "(", "fwrite", ")", "\n", "\n", "image_dir", "[", "i", "]", "=", "os", ".", "path", ".", "join", "(", "screen_dir", "[", "i", "]", ",", "str", "(", "episode_num", "[", "i", "]", ")", ")", "\n", "os", ".", "mkdir", "(", "image_dir", "[", "i", "]", ")", "\n", "\n", "if", "sum", "(", "[", "len", "(", "j", ")", "for", "j", "in", "trajectory", "[", "i", "]", "]", ")", ">=", "self", ".", "player_replay_size", ":", "\n", "\n", "# write if enough space is available", "\n", "                        ", "if", "psutil", ".", "virtual_memory", "(", ")", ".", "available", ">=", "mem_threshold", ":", "\n", "\n", "# lock read", "\n", "                            ", "fwrite", "=", "lock_file", "(", "self", ".", "writelock", ")", "\n", "traj_num", "=", "np", ".", "load", "(", "fwrite", ")", ".", "item", "(", ")", "\n", "fwrite", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fwrite", ",", "traj_num", "+", "1", ")", "\n", "# unlock file", "\n", "release_file", "(", "fwrite", ")", "\n", "\n", "traj_to_save", "=", "np", ".", "concatenate", "(", "trajectory", "[", "i", "]", ")", "\n", "# traj_to_save = pd.concat(trajectory[i])", "\n", "traj_to_save", "[", "'traj'", "]", "=", "traj_num", "\n", "\n", "traj_file", "=", "os", ".", "path", ".", "join", "(", "trajectory_dir", "[", "i", "]", ",", "\"%d.npy\"", "%", "traj_num", ")", "\n", "np", ".", "save", "(", "traj_file", ",", "traj_to_save", ")", "\n", "# traj_file = os.path.join(trajectory_dir[i], \"%d.pkl\" % traj_num)", "\n", "# traj_to_save.to_pickle(traj_file)", "\n", "\n", "fread", "=", "lock_file", "(", "readlock", "[", "i", "]", ")", "\n", "traj_list", "=", "np", ".", "load", "(", "fread", ")", "\n", "fread", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fread", ",", "np", ".", "append", "(", "traj_list", ",", "traj_num", ")", ")", "\n", "\n", "release_file", "(", "fread", ")", "\n", "\n", "", "trajectory", "[", "i", "]", "=", "[", "]", "\n", "\n", "# write trajectory to dir", "\n", "\n", "", "", "", "self", ".", "frame", "+=", "1", "\n", "if", "not", "self", ".", "frame", "%", "self", ".", "player_replay_size", ":", "\n", "                ", "yield", "True", "\n", "if", "self", ".", "n_offset", ">=", "self", ".", "n_tot", ":", "\n", "                    ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.rbi_rnn_agent.RBIRNNAgent.demonstrate": [[617, 711], ["rbi_rnn_agent.RBIRNNAgent.beta_net.eval", "rbi_rnn_agent.RBIRNNAgent.value_net.eval", "range", "os.mkdir", "rbi_rnn_agent.RBIRNNAgent.env.reset", "numpy.arange", "socket.gethostname", "os.path.join", "os.path.join", "rbi_rnn_agent.RBIRNNAgent.env.s.to", "rbi_rnn_agent.RBIRNNAgent.env.aux.to", "rbi_rnn_agent.RBIRNNAgent.beta_net", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "rbi_rnn_agent.RBIRNNAgent.value_net", "v.squeeze.squeeze.squeeze", "adv.squeeze.squeeze.squeeze", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy", "beta.data.cpu().numpy.data.cpu().numpy.squeeze", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "beta.data.cpu().numpy.data.cpu().numpy.data.cpu().numpy", "beta.data.cpu().numpy.copy.clip", "numpy.random.choice", "rbi_rnn_agent.RBIRNNAgent.env.step", "rbi_rnn_agent.RBIRNNAgent.squeeze().data[].cpu().numpy", "cv2.imwrite", "beta.data.cpu().numpy.data.cpu().numpy.copy", "adv.squeeze.squeeze.copy", "numpy.argsort", "numpy.argsort().astype", "beta.data.cpu().numpy.copy.sum", "numpy.rollaxis", "os.path.join", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze().data.cpu", "beta.data.cpu().numpy.data.cpu().numpy.data.cpu", "numpy.argmax", "numpy.min", "numpy.logical_or", "numpy.sum", "rbi_rnn_agent.RBIRNNAgent.squeeze().data[].cpu", "v.squeeze.squeeze.data.cpu().numpy", "rbi_rnn_agent.RBIRNNAgent.squeeze().data.cpu().numpy", "adv.squeeze.squeeze.data.cpu().numpy", "numpy.argsort", "v.squeeze.squeeze.data.cpu", "rbi_rnn_agent.RBIRNNAgent.squeeze().data.cpu", "adv.squeeze.squeeze.data.cpu", "q.squeeze().data.cpu().numpy.squeeze().data.cpu().numpy.squeeze", "rbi_rnn_agent.RBIRNNAgent.squeeze", "rbi_rnn_agent.RBIRNNAgent.squeeze"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset", "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step"], ["", "", "", "", "def", "demonstrate", "(", "self", ",", "n_tot", ")", ":", "\n", "\n", "        ", "self", ".", "beta_net", ".", "eval", "(", ")", "\n", "self", ".", "value_net", ".", "eval", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_tot", ")", ":", "\n", "\n", "            ", "if", "\"gpu\"", "in", "socket", ".", "gethostname", "(", ")", ":", "\n", "                ", "log_dir", "=", "os", ".", "path", ".", "join", "(", "\"/home/dsi/elad/data/rbi/runs\"", ",", "\"%s_%d\"", "%", "(", "consts", ".", "exptime", ",", "i", ")", ")", "\n", "", "else", ":", "\n", "                ", "log_dir", "=", "os", ".", "path", ".", "join", "(", "\"/tmp\"", ",", "\"%s_%d\"", "%", "(", "consts", ".", "exptime", ",", "i", ")", ")", "\n", "\n", "", "os", ".", "mkdir", "(", "log_dir", ")", "\n", "\n", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n", "# here there is a problem when there is a varying/increasing life counter as in mspacman", "\n", "\n", "choices", "=", "np", ".", "arange", "(", "self", ".", "action_space", ",", "dtype", "=", "np", ".", "int", ")", "\n", "\n", "while", "not", "self", ".", "env", ".", "t", ":", "\n", "\n", "                ", "s", "=", "self", ".", "env", ".", "s", ".", "to", "(", "self", ".", "device", ")", "\n", "aux", "=", "self", ".", "env", ".", "aux", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "beta", "=", "self", ".", "beta_net", "(", "s", ",", "aux", ")", "\n", "\n", "beta_softmax", "=", "F", ".", "softmax", "(", "beta", ",", "dim", "=", "2", ")", "\n", "\n", "v", ",", "adv", ",", "_", ",", "q", ",", "_", "=", "self", ".", "value_net", "(", "s", ",", "self", ".", "a_zeros", ",", "beta_softmax", ",", "aux", ")", "\n", "v", "=", "v", ".", "squeeze", "(", "0", ")", "\n", "adv", "=", "adv", ".", "squeeze", "(", "0", ")", "\n", "q", "=", "q", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "beta", "=", "beta", ".", "squeeze", "(", "0", ")", "\n", "beta", "=", "F", ".", "softmax", "(", "beta", ",", "dim", "=", "2", ")", "\n", "beta", "=", "beta", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "\n", "if", "False", ":", "\n", "\n", "                    ", "pi", "=", "beta", ".", "copy", "(", ")", "\n", "adv2", "=", "adv", ".", "copy", "(", ")", "\n", "\n", "rank", "=", "np", ".", "argsort", "(", "adv2", ")", "\n", "adv_rank", "=", "np", ".", "argsort", "(", "rank", ")", ".", "astype", "(", "np", ".", "float", ")", "\n", "\n", "pi", "=", "self", ".", "cmin", "*", "pi", "\n", "\n", "Delta", "=", "1", "-", "self", ".", "cmin", "\n", "while", "Delta", ">", "0", ":", "\n", "                        ", "a", "=", "np", ".", "argmax", "(", "adv2", ")", "\n", "Delta_a", "=", "np", ".", "min", "(", "(", "Delta", ",", "(", "self", ".", "cmax", "-", "self", ".", "cmin", ")", "*", "beta", "[", "a", "]", ")", ")", "\n", "Delta", "-=", "Delta_a", "\n", "pi", "[", "a", "]", "+=", "Delta_a", "\n", "adv2", "[", "a", "]", "=", "-", "1e11", "\n", "\n", "# pi_adv = 2 ** adv_rank * np.logical_or(adv2 >= 0, adv_rank == (self.action_space - 1))", "\n", "", "pi_adv", "=", "1.", "*", "np", ".", "logical_or", "(", "adv", ">=", "0", ",", "adv_rank", "==", "(", "self", ".", "action_space", "-", "1", ")", ")", "\n", "pi_adv", "=", "pi_adv", "/", "(", "np", ".", "sum", "(", "pi_adv", ")", ")", "\n", "\n", "pi", "=", "(", "1", "-", "self", ".", "mix", ")", "*", "pi", "+", "self", ".", "mix", "*", "pi_adv", "\n", "pi_mix", "=", "self", ".", "eps_pre", "*", "self", ".", "pi_rand", "+", "(", "1", "-", "self", ".", "eps_pre", ")", "*", "pi", "\n", "\n", "", "else", ":", "\n", "                    ", "pi", "=", "beta", "\n", "\n", "", "pi", "=", "pi", ".", "clip", "(", "0", ",", "1", ")", "\n", "pi", "=", "pi", "/", "pi", ".", "sum", "(", ")", "\n", "\n", "a", "=", "np", ".", "random", ".", "choice", "(", "choices", ",", "p", "=", "pi", ")", "\n", "self", ".", "env", ".", "step", "(", "a", ")", "\n", "\n", "# time.sleep(0.1)", "\n", "\n", "img", "=", "s", ".", "squeeze", "(", "0", ")", ".", "data", "[", ":", "3", "]", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "img", "=", "np", ".", "rollaxis", "(", "img", ",", "0", ",", "3", ")", "[", ":", ",", ":", ",", ":", "3", "]", "\n", "img", "=", "(", "img", "*", "256", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n", "cv2", ".", "imwrite", "(", "os", ".", "path", ".", "join", "(", "log_dir", ",", "\"%d_%d_%d.png\"", "%", "(", "self", ".", "env", ".", "k", ",", "a", ",", "self", ".", "env", ".", "score", ")", ")", ",", "img", ")", "\n", "\n", "yield", "{", "'score'", ":", "self", ".", "env", ".", "score", ",", "\n", "\"beta\"", ":", "pi", ",", "\n", "\"v\"", ":", "v", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "\"q\"", ":", "q", ",", "\n", "\"aux\"", ":", "aux", ".", "squeeze", "(", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "\"adv\"", ":", "adv", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "\"o\"", ":", "img", ",", "\n", "'frames'", ":", "self", ".", "env", ".", "k", ",", "\n", "\"actions\"", ":", "self", ".", "env", ".", "action_meanings", ",", "\n", "\"a\"", ":", "a", "\n", "}", "\n", "\n", "", "", "raise", "StopIteration", "", "", "", ""]], "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.__init__": [[15, 53], ["atari_py.ALEInterface", "environment.Env.ale.setInt", "environment.Env.ale.setFloat", "environment.Env.ale.setInt", "environment.Env.ale.setBool", "environment.Env.ale.loadROM", "numpy.nonzero", "torch.zeros", "int", "numpy.random.randint", "atari_py.get_game_path", "numpy.zeros", "numpy.log", "numpy.log"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "skip", "=", "args", ".", "skip", "\n", "\n", "self", ".", "ale", "=", "atari_py", ".", "ALEInterface", "(", ")", "\n", "self", ".", "ale", ".", "setInt", "(", "'random_seed'", ",", "np", ".", "random", ".", "randint", "(", "2", "**", "31", ")", ")", "\n", "# self.ale.setInt('max_num_frames', consts.max_length[args.game])", "\n", "self", ".", "ale", ".", "setFloat", "(", "'repeat_action_probability'", ",", "0", ")", "\n", "\n", "# self.ale.setInt('frame_skip', self.skip)", "\n", "# self.ale.setBool('color_averaging', True)", "\n", "\n", "self", ".", "ale", ".", "setInt", "(", "'frame_skip'", ",", "0", ")", "\n", "self", ".", "ale", ".", "setBool", "(", "'color_averaging'", ",", "False", ")", "\n", "self", ".", "ale", ".", "loadROM", "(", "atari_py", ".", "get_game_path", "(", "consts", ".", "gym_game_dict", "[", "args", ".", "game", "]", ")", ")", "\n", "self", ".", "actions", ",", "=", "np", ".", "nonzero", "(", "consts", ".", "actions", "[", "args", ".", "game", "]", ")", "\n", "self", ".", "action_meanings", "=", "[", "consts", ".", "action_meanings", "[", "i", "]", "for", "i", "in", "self", ".", "actions", "]", "\n", "\n", "self", ".", "k", "=", "0", "# Internal step counter", "\n", "self", ".", "kk", "=", "0", "# within life step counter", "\n", "self", ".", "lives", "=", "0", "# Life counter (used in DeepMind training)", "\n", "self", ".", "score", "=", "0", "\n", "self", ".", "frame", "=", "None", "\n", "self", ".", "s", ",", "self", ".", "r", ",", "self", ".", "t", "=", "None", ",", "None", ",", "None", "\n", "self", ".", "aux", "=", "torch", ".", "zeros", "(", "1", ",", "1", ")", "\n", "self", ".", "history_length", "=", "args", ".", "history_length", "\n", "self", ".", "buffer", "=", "[", "np", ".", "zeros", "(", "(", "args", ".", "height", ",", "args", ".", "width", ")", ",", "dtype", "=", "np", ".", "float32", ")", "]", "*", "self", ".", "history_length", "\n", "self", ".", "nop", "=", "consts", ".", "nop", "\n", "\n", "tail", "=", "int", "(", "np", ".", "log", "(", "0.01", ")", "/", "np", ".", "log", "(", "args", ".", "discount", ")", ")", "\n", "\n", "if", "args", ".", "multiplay", ":", "\n", "            ", "self", ".", "max_length", "=", "consts", ".", "max_length", "[", "args", ".", "game", "]", "+", "tail", "*", "self", ".", "skip", "\n", "", "else", ":", "\n", "            ", "self", ".", "max_length", "=", "consts", ".", "max_length", "[", "args", ".", "game", "]", "\n", "\n", "", "self", ".", "image", "=", "None", "\n", "self", ".", "max_score", "=", "consts", ".", "max_score", "[", "args", ".", "game", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.reset": [[54, 72], ["environment.Env.ale.setInt", "environment.Env.ale.reset_game", "environment.Env.ale.lives", "range", "environment.Env.step", "numpy.random.randint", "numpy.random.randint", "environment.Env.ale.act", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step"], ["", "def", "reset", "(", "self", ")", ":", "\n", "# Reset internal", "\n", "        ", "self", ".", "score", "=", "0", "\n", "self", ".", "buffer", "=", "[", "np", ".", "zeros", "(", "(", "args", ".", "height", ",", "args", ".", "width", ")", ",", "dtype", "=", "np", ".", "float32", ")", "]", "*", "self", ".", "history_length", "\n", "# Process and return initial state", "\n", "self", ".", "ale", ".", "setInt", "(", "'random_seed'", ",", "np", ".", "random", ".", "randint", "(", "2", "**", "31", ")", ")", "\n", "self", ".", "ale", ".", "reset_game", "(", ")", "\n", "self", ".", "lives", "=", "self", ".", "ale", ".", "lives", "(", ")", "\n", "\n", "# random number of no-ops 0-28 + 4", "\n", "noop_n", "=", "4", "*", "np", ".", "random", ".", "randint", "(", "10", ")", "\n", "for", "i", "in", "range", "(", "noop_n", ")", ":", "\n", "            ", "self", ".", "ale", ".", "act", "(", "self", ".", "nop", ")", "\n", "\n", "", "self", ".", "step", "(", "self", ".", "nop", ")", "\n", "self", ".", "k", "=", "0", "\n", "self", ".", "kk", "=", "0", "\n", "self", ".", "t", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.environment.Env.step": [[73, 121], ["environment.Env.ale.act", "environment.Env.ale.act", "environment.Env.ale.act", "o.append", "environment.Env.ale.act", "o.append", "environment.Env.ale.game_over", "int", "numpy.maximum", "environment.Env.buffer.pop", "environment.Env.buffer.insert", "environment.Env.ale.lives", "numpy.stack", "torch.FloatTensor", "torch.FloatTensor.unsqueeze", "environment.Env.ale.getScreenGrayscale", "environment.Env.ale.getScreenGrayscale", "cv2.resize", "environment.Env.ale.lives", "torch.ones", "environment.Env.image.astype", "float"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "a", ")", ":", "\n", "\n", "# Process state", "\n", "        ", "self", ".", "r", "=", "0", "\n", "a", "=", "self", ".", "actions", "[", "a", "]", "\n", "o", "=", "[", "]", "\n", "\n", "self", ".", "r", "+=", "self", ".", "ale", ".", "act", "(", "a", ")", "\n", "self", ".", "r", "+=", "self", ".", "ale", ".", "act", "(", "a", ")", "\n", "self", ".", "r", "+=", "self", ".", "ale", ".", "act", "(", "a", ")", "\n", "o", ".", "append", "(", "self", ".", "ale", ".", "getScreenGrayscale", "(", ")", ")", "\n", "self", ".", "r", "+=", "self", ".", "ale", ".", "act", "(", "a", ")", "\n", "o", ".", "append", "(", "self", ".", "ale", ".", "getScreenGrayscale", "(", ")", ")", "\n", "t", "=", "self", ".", "ale", ".", "game_over", "(", ")", "\n", "\n", "# self.r = self.ale.act(a)", "\n", "# # get gray scale image", "\n", "# self.image = self.ale.getScreenGrayscale()", "\n", "# t = self.ale.game_over()", "\n", "\n", "# self.last_action = action", "\n", "self", ".", "t", "=", "int", "(", "t", "or", "(", "self", ".", "k", "*", "self", ".", "skip", ">=", "self", ".", "max_length", ")", "or", "(", "self", ".", "score", ">=", "self", ".", "max_score", ")", ")", "\n", "\n", "self", ".", "image", "=", "np", ".", "maximum", "(", "o", "[", "0", "]", ",", "o", "[", "1", "]", ")", "\n", "self", ".", "frame", "=", "cv2", ".", "resize", "(", "self", ".", "image", ".", "astype", "(", "np", ".", "float32", ")", ",", "(", "img_width", ",", "img_height", ")", ",", "interpolation", "=", "interpolation", ")", "/", "256.", "\n", "\n", "self", ".", "k", "+=", "1", "\n", "\n", "# put in buffer", "\n", "self", ".", "buffer", ".", "pop", "(", ")", "\n", "self", ".", "buffer", ".", "insert", "(", "0", ",", "self", ".", "frame", ")", "\n", "\n", "if", "self", ".", "lives", ">", "self", ".", "ale", ".", "lives", "(", ")", ":", "\n", "            ", "self", ".", "kk", "=", "0", "\n", "", "else", ":", "\n", "            ", "self", ".", "kk", "+=", "1", "\n", "\n", "", "self", ".", "lives", "=", "self", ".", "ale", ".", "lives", "(", ")", "\n", "\n", "# make a tensor from stacked images", "\n", "state", "=", "np", ".", "stack", "(", "self", ".", "buffer", ",", "axis", "=", "0", ")", "\n", "state", "=", "torch", ".", "FloatTensor", "(", "state", ")", "\n", "self", ".", "s", "=", "state", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "# episode first 6 sec with off signal", "\n", "self", ".", "aux", "=", "(", "1", "if", "float", "(", "self", ".", "kk", ")", ">", "90", "else", "0", ")", "*", "torch", ".", "ones", "(", "1", ",", "1", ")", "\n", "\n", "self", ".", "score", "+=", "self", ".", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.memory.Memory.__init__": [[19, 24], ["super().__init__", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.memory.ReplayBatchSampler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "replay_dir", ")", ":", "\n", "        ", "super", "(", "Memory", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "history_length", "=", "args", ".", "history_length", "\n", "self", ".", "n_steps", "=", "args", ".", "n_steps", "\n", "self", ".", "screen_dir", "=", "os", ".", "path", ".", "join", "(", "replay_dir", ",", "\"explore\"", ",", "\"screen\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.memory.Memory.__len__": [[25, 27], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "args", ".", "n_tot", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.memory.Memory.__getitem__": [[28, 45], ["os.path.join", "memory.Memory.preprocess_history", "str", "memory.Memory.preprocess_history", "numpy.zeros", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.memory.Memory.preprocess_history", "home.repos.pwc.inspect_result.eladsar_rbi.None.memory.Memory.preprocess_history"], ["", "def", "__getitem__", "(", "self", ",", "sample", ")", ":", "\n", "\n", "        ", "sample", ",", "next_sample", "=", "sample", "\n", "\n", "episode_dir", "=", "os", ".", "path", ".", "join", "(", "self", ".", "screen_dir", ",", "str", "(", "sample", "[", "'ep'", "]", ")", ")", "\n", "s", "=", "self", ".", "preprocess_history", "(", "episode_dir", ",", "sample", "[", "'fr'", "]", ")", "\n", "\n", "if", "not", "sample", "[", "'t'", "]", ":", "\n", "            ", "s_tag", "=", "self", ".", "preprocess_history", "(", "episode_dir", ",", "next_sample", "[", "'fr'", "]", ")", "\n", "", "else", ":", "\n", "            ", "s_tag", "=", "np", ".", "zeros", "(", "(", "4", ",", "84", ",", "84", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "", "return", "{", "'s'", ":", "torch", ".", "from_numpy", "(", "s", ")", ",", "'r'", ":", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "sample", "[", "'r'", "]", ")", ")", ",", "\n", "'a'", ":", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "sample", "[", "'a'", "]", ")", ")", ",", "'t'", ":", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "sample", "[", "'t'", "]", ")", ")", ",", "\n", "'pi'", ":", "torch", ".", "from_numpy", "(", "sample", "[", "'pi'", "]", ")", ",", "\n", "'s_tag'", ":", "torch", ".", "from_numpy", "(", "s_tag", ")", ",", "'pi_tag'", ":", "torch", ".", "from_numpy", "(", "next_sample", "[", "'pi'", "]", ")", ",", "\n", "'tde'", ":", "torch", ".", "from_numpy", "(", "np", ".", "array", "(", "sample", "[", "'tde'", "]", ")", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.memory.Memory.preprocess_history": [[46, 50], ["numpy.stack", "os.path.join", "range", "cv2.resize", "cv2.imread().astype", "cv2.imread"], "methods", ["None"], ["", "def", "preprocess_history", "(", "self", ",", "episode_dir", ",", "frame", ")", ":", "\n", "\n", "        ", "frame0", "=", "[", "os", ".", "path", ".", "join", "(", "episode_dir", ",", "\"%d.png\"", "%", "(", "frame", "-", "i", ")", ")", "for", "i", "in", "range", "(", "self", ".", "history_length", ")", "]", "\n", "return", "np", ".", "stack", "(", "[", "(", "cv2", ".", "resize", "(", "cv2", ".", "imread", "(", "f0", ",", "imread_grayscale", ")", ".", "astype", "(", "np", ".", "float32", ")", ",", "(", "img_width", ",", "img_height", ")", ",", "interpolation", "=", "interpolation", ")", "/", "256.", ")", "for", "f0", "in", "frame0", "]", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.memory.ReplayBatchSampler.__init__": [[54, 68], ["os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "replay_dir", ")", ":", "\n", "\n", "        ", "self", ".", "batch", "=", "args", ".", "batch", "\n", "\n", "self", ".", "screen_dir", "=", "os", ".", "path", ".", "join", "(", "replay_dir", ",", "\"explore\"", ",", "\"screen\"", ")", "\n", "self", ".", "trajectory_dir", "=", "os", ".", "path", ".", "join", "(", "replay_dir", ",", "\"explore\"", ",", "\"trajectory\"", ")", "\n", "self", ".", "list_old_path", "=", "os", ".", "path", ".", "join", "(", "replay_dir", ",", "\"list\"", ",", "\"old_explore\"", ")", "\n", "\n", "self", ".", "replay_updates_interval", "=", "args", ".", "replay_updates_interval", "\n", "self", ".", "replay_memory_size", "=", "args", ".", "replay_memory_size", "\n", "self", ".", "readlock", "=", "os", ".", "path", ".", "join", "(", "replay_dir", ",", "\"list\"", ",", "\"readlock_explore.npy\"", ")", "\n", "\n", "self", ".", "rec_type", "=", "consts", ".", "rec_type", "\n", "self", ".", "n_steps", "=", "args", ".", "n_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.memory.ReplayBatchSampler.__iter__": [[69, 112], ["numpy.array", "preprocess.lock_file", "numpy.load", "preprocess.lock_file.seek", "numpy.save", "preprocess.release_file", "numpy.concatenate", "numpy.save", "print", "print", "len", "min", "numpy.random.choice", "print", "range", "len", "numpy.concatenate", "numpy.array", "numpy.sum", "numpy.load", "len", "int", "zip", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.lock_file", "home.repos.pwc.inspect_result.eladsar_rbi.None.preprocess.release_file"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "\n", "        ", "traj_old", "=", "0", "\n", "replay_buffer", "=", "np", ".", "array", "(", "[", "]", ",", "dtype", "=", "self", ".", "rec_type", ")", "\n", "\n", "while", "True", ":", "\n", "\n", "# load new memory", "\n", "\n", "            ", "fread", "=", "lock_file", "(", "self", ".", "readlock", ")", "\n", "traj_sorted", "=", "np", ".", "load", "(", "fread", ")", "\n", "fread", ".", "seek", "(", "0", ")", "\n", "np", ".", "save", "(", "fread", ",", "[", "]", ")", "\n", "release_file", "(", "fread", ")", "\n", "\n", "if", "not", "len", "(", "traj_sorted", ")", ":", "\n", "                ", "continue", "\n", "\n", "", "replay", "=", "np", ".", "concatenate", "(", "[", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "trajectory_dir", ",", "\"%d.npy\"", "%", "traj", ")", ")", "for", "traj", "in", "traj_sorted", "]", ",", "axis", "=", "0", ")", "\n", "\n", "replay_buffer", "=", "np", ".", "concatenate", "(", "[", "replay_buffer", ",", "replay", "]", ",", "axis", "=", "0", ")", "[", "-", "self", ".", "replay_memory_size", ":", "]", "\n", "\n", "# save previous traj_old to file", "\n", "np", ".", "save", "(", "self", ".", "list_old_path", ",", "np", ".", "array", "(", "[", "traj_old", "]", ")", ")", "\n", "traj_old", "=", "replay_buffer", "[", "0", "]", "[", "'traj'", "]", "\n", "print", "(", "\"Old trajectory: %d\"", "%", "traj_old", ")", "\n", "print", "(", "\"New Sample size is: %d\"", "%", "len", "(", "replay", ")", ")", "\n", "\n", "len_replay_buffer", "=", "len", "(", "replay_buffer", ")", "\n", "\n", "minibatches", "=", "min", "(", "self", ".", "replay_updates_interval", ",", "int", "(", "len_replay_buffer", "/", "self", ".", "batch", ")", "-", "self", ".", "n_steps", ")", "\n", "\n", "tde", "=", "replay_buffer", "[", "'tde'", "]", "/", "np", ".", "sum", "(", "replay_buffer", "[", "'tde'", "]", ")", "\n", "tde", "=", "tde", "[", ":", "-", "self", ".", "n_steps", "]", "\n", "\n", "shuffle_indexes", "=", "np", ".", "random", ".", "choice", "(", "len_replay_buffer", "-", "self", ".", "n_steps", ",", "(", "minibatches", ",", "self", ".", "batch", ")", ",", "\n", "replace", "=", "True", ",", "p", "=", "tde", ")", "\n", "\n", "print", "(", "\"Explorer:Replay Buffer size is: %d\"", "%", "len_replay_buffer", ")", "\n", "\n", "for", "i", "in", "range", "(", "minibatches", ")", ":", "\n", "                ", "samples", "=", "shuffle_indexes", "[", "i", "]", "\n", "yield", "zip", "(", "replay_buffer", "[", "samples", "]", ",", "replay_buffer", "[", "samples", "+", "self", ".", "n_steps", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.memory.ReplayBatchSampler.__len__": [[113, 115], ["None"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "inf", "\n", "\n"]], "home.repos.pwc.inspect_result.eladsar_rbi.None.memory.collate": [[117, 135], ["sum", "[].storage()._new_shared", "[].new", "sum", "[].storage()._new_shared", "[].new", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "x[].numel", "[].storage", "x[].numel", "[].storage"], "function", ["None"], ["", "", "def", "collate", "(", "batch", ")", ":", "\n", "\n", "    ", "numel", "=", "sum", "(", "[", "x", "[", "'s'", "]", ".", "numel", "(", ")", "for", "x", "in", "batch", "]", ")", "\n", "storage", "=", "batch", "[", "0", "]", "[", "'s'", "]", ".", "storage", "(", ")", ".", "_new_shared", "(", "numel", ")", "\n", "out_s", "=", "batch", "[", "0", "]", "[", "'s'", "]", ".", "new", "(", "storage", ")", "\n", "\n", "numel", "=", "sum", "(", "[", "x", "[", "'s_tag'", "]", ".", "numel", "(", ")", "for", "x", "in", "batch", "]", ")", "\n", "storage", "=", "batch", "[", "0", "]", "[", "'s_tag'", "]", ".", "storage", "(", ")", ".", "_new_shared", "(", "numel", ")", "\n", "out_s_tag", "=", "batch", "[", "0", "]", "[", "'s_tag'", "]", ".", "new", "(", "storage", ")", "\n", "\n", "return", "{", "'s'", ":", "torch", ".", "stack", "(", "[", "sample", "[", "'s'", "]", "for", "sample", "in", "batch", "]", ",", "out", "=", "out_s", ")", ",", "\n", "'s_tag'", ":", "torch", ".", "stack", "(", "[", "sample", "[", "'s_tag'", "]", "for", "sample", "in", "batch", "]", ",", "out", "=", "out_s_tag", ")", ",", "\n", "'a'", ":", "torch", ".", "stack", "(", "[", "sample", "[", "'a'", "]", "for", "sample", "in", "batch", "]", ")", ",", "\n", "'r'", ":", "torch", ".", "stack", "(", "[", "sample", "[", "'r'", "]", "for", "sample", "in", "batch", "]", ")", ",", "\n", "'t'", ":", "torch", ".", "stack", "(", "[", "sample", "[", "'t'", "]", "for", "sample", "in", "batch", "]", ")", ",", "\n", "'pi'", ":", "torch", ".", "stack", "(", "[", "sample", "[", "'pi'", "]", "for", "sample", "in", "batch", "]", ")", ",", "\n", "'pi_tag'", ":", "torch", ".", "stack", "(", "[", "sample", "[", "'pi_tag'", "]", "for", "sample", "in", "batch", "]", ")", ",", "\n", "'tde'", ":", "torch", ".", "stack", "(", "[", "sample", "[", "'tde'", "]", "for", "sample", "in", "batch", "]", ")", "}", "", "", ""]]}