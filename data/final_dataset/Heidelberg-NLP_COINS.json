{"home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.src.main_conceptnet.main": [[19, 173], ["print", "src.read_config", "src.get_parameters", "torch.manual_seed", "random.seed", "print", "x.format", "print", "src.make_data_loader", "data.make_data_loader.load_data", "print", "print", "transformers.GPT2Tokenizer.from_pretrained", "transformers.GPT2Tokenizer.from_pretrained", "GPT2Tokenizer.from_pretrained.add_special_tokens", "len", "print", "print", "src.make_model", "models.multi_gpu().cuda.resize_token_embeddings", "src.make_model", "model_knowledge_story.multi_gpu().cuda.resize_token_embeddings", "print", "print", "data.make_data_loader.reset_offsets", "src.set_max_sizes", "print", "src.train.opt.OpenAIAdam", "src.train.opt_knowledge.Knowledge_Adam", "src.make_trainer", "train.make_trainer.set_generator", "train.make_trainer.set_evaluator", "train.make_trainer.run", "src.load_config", "torch.cuda.manual_seed_all", "utils.make_name_string", "data.make_data_loader.make_tensors", "len", "len", "len", "print", "torch.cuda.set_device", "print", "models.multi_gpu().cuda.parameters", "model_knowledge_story.multi_gpu().cuda.parameters", "len", "utils.make_name", "src.multi_gpu().cuda", "src.multi_gpu().cuda", "models.multi_gpu().cuda.cuda", "model_knowledge_story.multi_gpu().cuda.cuda", "len", "src.multi_gpu", "src.multi_gpu"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.config.read_config", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.config.get_parameters", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.make_data_loader", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.GenerationDataLoader.load_data", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.from_pretrained", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.from_pretrained", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.model_knowledge_story.make_model", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.resize_token_embeddings", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.model_knowledge_story.make_model", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.resize_token_embeddings", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.GenerationDataLoader.reset_offsets", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.set_max_sizes", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.make_trainer", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.conceptnet_train.ConceptNetGenerationIteratorTrainer.set_generator", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.set_evaluator", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.IteratorTrainer.run", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.config.load_config", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.make_name_string", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.GenerationDataLoader.make_tensors", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.make_name", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.model_knowledge_story.multi_gpu", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.model_knowledge_story.multi_gpu"], ["def", "main", "(", "num", ")", ":", "\n", "# Generate configuration files depending on experiment being run", "\n", "#utils.generate_config_files(\"conceptnet\", num)", "\n", "\n", "# Loads the correct configuration file", "\n", "    ", "config_file", "=", "\"config/conceptnet/config_{}.json\"", ".", "format", "(", "num", ")", "\n", "\n", "print", "(", "config_file", ")", "\n", "\n", "# Read config file to option", "\n", "config", "=", "cfg", ".", "read_config", "(", "cfg", ".", "load_config", "(", "config_file", ")", ")", "\n", "opt", ",", "meta", "=", "cfg", ".", "get_parameters", "(", "config", ")", "\n", "\n", "# config.gpu_mode = torch.cuda.is_available()", "\n", "\n", "# Set the random seeds", "\n", "torch", ".", "manual_seed", "(", "opt", ".", "train", ".", "static", ".", "seed", ")", "\n", "random", ".", "seed", "(", "opt", ".", "train", ".", "static", ".", "seed", ")", "\n", "if", "config", ".", "gpu_mode", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "opt", ".", "train", ".", "static", ".", "seed", ")", "\n", "\n", "# Load the data", "\n", "", "splits", "=", "[", "\"train\"", ",", "\"dev\"", ",", "\"test\"", "]", "\n", "\n", "opt", ".", "train", ".", "dynamic", ".", "epoch", "=", "0", "\n", "\n", "print", "(", "\"Loading Data\"", ")", "\n", "\n", "# Initialize path to pre-set data loader", "\n", "x", "=", "\"data/conceptnet/processed/generation/rel_language-trainsize_100-devversion_12-maxe1_200-maxe2_200.pickle\"", "\n", "path", "=", "x", ".", "format", "(", "\n", "opt", ".", "exp", ",", "utils", ".", "make_name_string", "(", "opt", ".", "data", ")", ")", "\n", "print", "(", "path", ")", "\n", "\n", "# Make data loader", "\n", "data_loader", "=", "data", ".", "make_data_loader", "(", "opt", ")", "\n", "loaded", "=", "data_loader", ".", "load_data", "(", "path", ")", "\n", "#print(data_loader.sequences[\"train\"][\"total\"].size(0))", "\n", "data_loader", ".", "opt", "=", "opt", "\n", "data_loader", ".", "batch_size", "=", "opt", ".", "train", ".", "dynamic", ".", "bs", "\n", "\n", "print", "(", "\"Done.\"", ")", "\n", "print", "(", "data_loader", ")", "\n", "\n", "#text_encoder = TextEncoder(config.encoder_path, config.bpe_path)", "\n", "text_encoder", "=", "GPT2Tokenizer", ".", "from_pretrained", "(", "'gpt2'", ")", "\n", "special_tokens", "=", "{", "\"cls_token\"", ":", "\"[CLS]\"", ",", "\"unk_token\"", ":", "\"[UNK]\"", "}", "#, \"mask\": '[\"MASK\"]',\"separator\": '[\"SEP\"]', \"start_of_sentence\": '[\"SOS\"]', \"end_of_sentence\": '[\"EOS\"]'}", "\n", "text_encoder", "=", "GPT2Tokenizer", ".", "from_pretrained", "(", "\"gpt2\"", ",", "cls_token", "=", "\"[CLS]\"", ",", "unk_token", "=", "\"[UNK]\"", ",", "mask", "=", "'[\"MASK\"]'", ",", "separator", "=", "'[\"SEP\"]'", ",", "start_of_sentence", "=", "'[\"SOS\"]'", ",", "end_of_sentence", "=", "'[\"EOS\"]'", ")", "\n", "text_encoder", ".", "add_special_tokens", "(", "special_tokens", ")", "\n", "\n", "#categories = data.conceptnet_data.conceptnet_relations", "\n", "\n", "special", "=", "[", "data", ".", "start_token", ",", "data", ".", "end_token", "]", "\n", "#special += [\"<{}>\".format(cat) for cat in categories]", "\n", "\n", "if", "loaded", ":", "\n", "        ", "text_encoder", ".", "encoder", "=", "data_loader", ".", "vocab_encoder", "\n", "text_encoder", ".", "decoder", "=", "data_loader", ".", "vocab_decoder", "\n", "", "else", ":", "\n", "        ", "for", "special_token", "in", "special", ":", "\n", "            ", "text_encoder", ".", "decoder", "[", "len", "(", "encoder", ")", "]", "=", "special_token", "\n", "text_encoder", ".", "encoder", "[", "special_token", "]", "=", "len", "(", "encoder", ")", "\n", "", "data_loader", ".", "make_tensors", "(", "text_encoder", ",", "special", ")", "\n", "\n", "# Set max size of different parts of relation", "\n", "", "context_size_i1", "=", "data_loader", ".", "max_input1", "\n", "context_size_i2", "=", "data_loader", ".", "max_input2", "\n", "context_size_i3", "=", "data_loader", ".", "max_input3", "\n", "context_size_i4", "=", "data_loader", ".", "max_input4", "\n", "context_size_o1", "=", "data_loader", ".", "max_output1", "\n", "context_size_o2", "=", "data_loader", ".", "max_output2", "\n", "context_size_o3", "=", "data_loader", ".", "max_output3", "\n", "context_size_o4", "=", "data_loader", ".", "max_output4", "\n", "\n", "#opt.data.maxr = context_size_r", "\n", "\n", "n_special", "=", "len", "(", "special", ")", "\n", "n_ctx", "=", "context_size_i1", "+", "context_size_i2", "+", "context_size_i3", "+", "context_size_i4", "+", "context_size_o1", "+", "context_size_o2", "+", "context_size_o3", "+", "context_size_o4", "\n", "n_vocab", "=", "len", "(", "text_encoder", ".", "encoder", ")", "+", "n_ctx", "\n", "\n", "opt", ".", "net", ".", "vSize", "=", "n_vocab", "\n", "# Build Model", "\n", "print", "(", "\"Building Model\"", ")", "\n", "print", "(", "opt", ".", "net", ".", "init", "==", "\"pt\"", ")", "\n", "model", "=", "models", ".", "make_model", "(", "\n", "opt", ",", "n_vocab", ",", "n_ctx", ",", "n_special", ")", "\n", "model", ".", "resize_token_embeddings", "(", "len", "(", "text_encoder", ")", ")", "\n", "\n", "model_knowledge", "=", "model_knowledge_story", ".", "make_model", "(", "\n", "opt", ",", "n_vocab", ",", "n_ctx", ",", "n_special", ")", "\n", "model_knowledge", ".", "resize_token_embeddings", "(", "len", "(", "text_encoder", ")", ")", "\n", "\n", "print", "(", "\"Done.\"", ")", "\n", "\n", "print", "(", "\"Files will be logged at: {}\"", ".", "format", "(", "\n", "utils", ".", "make_name", "(", "opt", ",", "prefix", "=", "\"results/losses/\"", ",", "\n", "is_dir", "=", "True", ",", "eval_", "=", "True", ")", ")", ")", "\n", "\n", "data_loader", ".", "reset_offsets", "(", "\"train\"", ",", "keys", "=", "[", "\"total\"", "]", ")", "\n", "\n", "data", ".", "set_max_sizes", "(", "data_loader", ")", "\n", "\n", "# Push to GPU", "\n", "if", "config", ".", "gpu_mode", ":", "\n", "        ", "print", "(", "\"Pushing to GPU: {}\"", ".", "format", "(", "config", ".", "gpu_index", ")", ")", "\n", "cfg", ".", "device", "=", "config", ".", "gpu_index", "\n", "cfg", ".", "do_gpu", "=", "True", "\n", "torch", ".", "cuda", ".", "set_device", "(", "cfg", ".", "device", ")", "\n", "if", "config", ".", "multigpu", ":", "\n", "#print(\"!!! I am here !!!\")", "\n", "            ", "model", "=", "models", ".", "multi_gpu", "(", "\n", "model", ",", "config", ".", "gpu_indices", ")", ".", "cuda", "(", ")", "\n", "#model.to(f'cuda:{model.device_ids[0]}')", "\n", "model_knowledge", "=", "model_knowledge_story", ".", "multi_gpu", "(", "\n", "model_knowledge", ",", "config", ".", "gpu_indices", ")", ".", "cuda", "(", ")", "\n", "#model_knowledge.to(f'cuda:{model.device_ids[1]}')", "\n", "", "else", ":", "\n", "            ", "model", ".", "cuda", "(", "cfg", ".", "device", ")", "\n", "model_knowledge", ".", "cuda", "(", "cfg", ".", "device", ")", "\n", "", "print", "(", "\"Done.\"", ")", "\n", "\n", "", "print", "(", "\"Training\"", ")", "\n", "\n", "optimizer_m", "=", "OpenAIAdam", "(", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "opt", ".", "train", ".", "dynamic", ".", "lr", ",", "\n", "schedule", "=", "opt", ".", "train", ".", "static", ".", "lrsched", ",", "\n", "warmup", "=", "opt", ".", "train", ".", "static", ".", "lrwarm", ",", "\n", "t_total", "=", "meta", ".", "iterations", ",", "\n", "b1", "=", "opt", ".", "train", ".", "static", ".", "b1", ",", "\n", "b2", "=", "opt", ".", "train", ".", "static", ".", "b2", ",", "\n", "e", "=", "opt", ".", "train", ".", "static", ".", "e", ",", "\n", "l2", "=", "opt", ".", "train", ".", "static", ".", "l2", ",", "\n", "vector_l2", "=", "opt", ".", "train", ".", "static", ".", "vl2", ",", "\n", "max_grad_norm", "=", "opt", ".", "train", ".", "static", ".", "clip", ")", "\n", "\n", "optimizer_k", "=", "Knowledge_Adam", "(", "model_knowledge", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "opt", ".", "train", ".", "dynamic", ".", "lr", ",", "\n", "schedule", "=", "opt", ".", "train", ".", "static", ".", "lrsched", ",", "\n", "warmup", "=", "opt", ".", "train", ".", "static", ".", "lrwarm", ",", "\n", "t_total", "=", "meta", ".", "iterations", ",", "\n", "b1", "=", "opt", ".", "train", ".", "static", ".", "b1", ",", "\n", "b2", "=", "opt", ".", "train", ".", "static", ".", "b2", ",", "\n", "e", "=", "opt", ".", "train", ".", "static", ".", "e", ",", "\n", "l2", "=", "opt", ".", "train", ".", "static", ".", "l2", ",", "\n", "vector_l2", "=", "opt", ".", "train", ".", "static", ".", "vl2", ",", "\n", "max_grad_norm", "=", "opt", ".", "train", ".", "static", ".", "clip", ")", "\n", "\n", "trainer", "=", "train", ".", "make_trainer", "(", "\n", "opt", ",", "meta", ",", "data_loader", ",", "model", ",", "model_knowledge", ",", "optimizer_m", ",", "optimizer_k", ")", "\n", "\n", "trainer", ".", "set_generator", "(", "opt", ",", "model", ",", "model_knowledge", ",", "data_loader", ")", "\n", "trainer", ".", "set_evaluator", "(", "opt", ",", "model", ",", "model_knowledge", ",", "data_loader", ")", "\n", "\n", "trainer", ".", "run", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.src.main_atomic.main": [[17, 126], ["utils.generate_config_files", "print", "src.read_config", "src.get_parameters", "torch.manual_seed", "random.seed", "print", "src.make_data_loader", "data.make_data_loader.load_data", "print", "print", "src.data.utils.TextEncoder", "len", "print", "print", "src.make_model", "print", "print", "data.make_data_loader.reset_offsets", "src.set_max_sizes", "print", "src.train.opt.OpenAIAdam", "src.make_trainer", "train.make_trainer.set_evaluator", "train.make_trainer.run", "src.load_config", "torch.cuda.manual_seed_all", "utils.make_name_string", "[].size", "len", "data.make_data_loader.__dict__.keys", "print", "torch.cuda.set_device", "print", "models.multi_gpu().cuda.parameters", "utils.make_name", "src.multi_gpu().cuda", "models.multi_gpu().cuda.cuda", "src.multi_gpu"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.generate_config_files", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.config.read_config", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.config.get_parameters", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.make_data_loader", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.GenerationDataLoader.load_data", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.model_knowledge_story.make_model", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.GenerationDataLoader.reset_offsets", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.set_max_sizes", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.make_trainer", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.set_evaluator", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.IteratorTrainer.run", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.config.load_config", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.make_name_string", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.make_name", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.model_knowledge_story.multi_gpu"], ["def", "main", "(", "num", ")", ":", "\n", "# Generate configuration files depending on experiment being run", "\n", "    ", "utils", ".", "generate_config_files", "(", "\"atomic\"", ",", "num", ")", "\n", "\n", "# Loads the correct configuration file", "\n", "config_file", "=", "\"config/atomic/config_{}.json\"", ".", "format", "(", "num", ")", "\n", "\n", "print", "(", "config_file", ")", "\n", "\n", "# Read config file to option", "\n", "config", "=", "cfg", ".", "read_config", "(", "cfg", ".", "load_config", "(", "config_file", ")", ")", "\n", "opt", ",", "meta", "=", "cfg", ".", "get_parameters", "(", "config", ")", "\n", "\n", "# Set the random seeds", "\n", "torch", ".", "manual_seed", "(", "opt", ".", "train", ".", "static", ".", "seed", ")", "\n", "random", ".", "seed", "(", "opt", ".", "train", ".", "static", ".", "seed", ")", "\n", "if", "config", ".", "gpu_mode", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "opt", ".", "train", ".", "static", ".", "seed", ")", "\n", "\n", "# Where to find the data", "\n", "", "splits", "=", "[", "\"train\"", ",", "\"dev\"", ",", "\"test\"", "]", "\n", "\n", "opt", ".", "train", ".", "dynamic", ".", "epoch", "=", "0", "\n", "\n", "print", "(", "\"Loading Data\"", ")", "\n", "\n", "categories", "=", "opt", ".", "data", ".", "categories", "\n", "x", "=", "\"\"", "\n", "path", "=", "\"data/atomic/processed/{}/{}.pickle\"", ".", "format", "(", "\n", "opt", ".", "exp", ",", "utils", ".", "make_name_string", "(", "opt", ".", "data", ")", ")", "\n", "\n", "data_loader", "=", "data", ".", "make_data_loader", "(", "opt", ",", "categories", ")", "\n", "loaded", "=", "data_loader", ".", "load_data", "(", "path", ")", "\n", "print", "(", "data_loader", ".", "sequences", "[", "\"train\"", "]", "[", "\"total\"", "]", ".", "size", "(", "0", ")", ")", "\n", "data_loader", ".", "opt", "=", "opt", "\n", "data_loader", ".", "batch_size", "=", "opt", ".", "train", ".", "dynamic", ".", "bs", "\n", "\n", "print", "(", "\"Done.\"", ")", "\n", "\n", "# Initialize text_encoder", "\n", "text_encoder", "=", "TextEncoder", "(", "config", ".", "encoder_path", ",", "config", ".", "bpe_path", ")", "\n", "\n", "special", "=", "[", "data", ".", "start_token", ",", "data", ".", "end_token", "]", "\n", "special", "+=", "[", "\"<{}>\"", ".", "format", "(", "cat", ")", "for", "cat", "in", "categories", "]", "\n", "special", "+=", "[", "data", ".", "blank_token", "]", "\n", "\n", "text_encoder", ".", "encoder", "=", "data_loader", ".", "vocab_encoder", "\n", "text_encoder", ".", "decoder", "=", "data_loader", ".", "vocab_decoder", "\n", "\n", "opt", ".", "data", ".", "maxe1", "=", "data_loader", ".", "max_event", "\n", "opt", ".", "data", ".", "maxe2", "=", "data_loader", ".", "max_effect", "\n", "opt", ".", "data", ".", "maxr", "=", "data", ".", "atomic_data", ".", "num_delimiter_tokens", "[", "\"category\"", "]", "\n", "\n", "n_special", "=", "len", "(", "special", ")", "\n", "n_ctx", "=", "opt", ".", "data", ".", "maxe1", "+", "opt", ".", "data", ".", "maxe2", "\n", "n_vocab", "=", "len", "(", "text_encoder", ".", "encoder", ")", "+", "n_ctx", "\n", "\n", "print", "(", "data_loader", ".", "__dict__", ".", "keys", "(", ")", ")", "\n", "opt", ".", "net", ".", "vSize", "=", "n_vocab", "\n", "\n", "print", "(", "\"Building Model\"", ")", "\n", "\n", "model", "=", "models", ".", "make_model", "(", "\n", "opt", ",", "n_vocab", ",", "n_ctx", ",", "n_special", ",", "\n", "load", "=", "(", "opt", ".", "net", ".", "init", "==", "\"pt\"", ")", ")", "\n", "\n", "print", "(", "\"Done.\"", ")", "\n", "\n", "print", "(", "\"Files will be logged at: {}\"", ".", "format", "(", "\n", "utils", ".", "make_name", "(", "opt", ",", "prefix", "=", "\"results/losses/\"", ",", "\n", "is_dir", "=", "True", ",", "eval_", "=", "True", ")", ")", ")", "\n", "\n", "data_loader", ".", "reset_offsets", "(", "\"train\"", ")", "\n", "\n", "# Get number of examples", "\n", "data", ".", "set_max_sizes", "(", "data_loader", ")", "\n", "\n", "if", "config", ".", "gpu_mode", ":", "\n", "        ", "print", "(", "\"Pushing to GPU: {}\"", ".", "format", "(", "config", ".", "gpu_index", ")", ")", "\n", "cfg", ".", "device", "=", "config", ".", "gpu_index", "\n", "cfg", ".", "do_gpu", "=", "True", "\n", "torch", ".", "cuda", ".", "set_device", "(", "cfg", ".", "device", ")", "\n", "if", "config", ".", "multigpu", ":", "\n", "            ", "model", "=", "models", ".", "multi_gpu", "(", "\n", "model", ",", "config", ".", "gpu_indices", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "model", ".", "cuda", "(", "cfg", ".", "device", ")", "\n", "", "print", "(", "\"Done.\"", ")", "\n", "\n", "", "print", "(", "\"Training\"", ")", "\n", "\n", "optimizer", "=", "OpenAIAdam", "(", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "opt", ".", "train", ".", "dynamic", ".", "lr", ",", "\n", "schedule", "=", "opt", ".", "train", ".", "static", ".", "lrsched", ",", "\n", "warmup", "=", "opt", ".", "train", ".", "static", ".", "lrwarm", ",", "\n", "t_total", "=", "meta", ".", "iterations", ",", "\n", "b1", "=", "opt", ".", "train", ".", "static", ".", "b1", ",", "\n", "b2", "=", "opt", ".", "train", ".", "static", ".", "b2", ",", "\n", "e", "=", "opt", ".", "train", ".", "static", ".", "e", ",", "\n", "l2", "=", "opt", ".", "train", ".", "static", ".", "l2", ",", "\n", "vector_l2", "=", "opt", ".", "train", ".", "static", ".", "vl2", ",", "\n", "max_grad_norm", "=", "opt", ".", "train", ".", "static", ".", "clip", ")", "\n", "\n", "scorers", "=", "[", "\"bleu\"", ",", "\"rouge\"", ",", "\"cider\"", "]", "\n", "trainer", "=", "train", ".", "make_trainer", "(", "\n", "opt", ",", "meta", ",", "data_loader", ",", "model", ",", "optimizer", ")", "\n", "trainer", ".", "set_evaluator", "(", "opt", ",", "model", ",", "data_loader", ")", "\n", "\n", "trainer", ".", "run", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.generate.Generator.__init__": [[56, 66], ["object.__init__", "src.make_sampler", "src.make_sampler", "src.make_sampler"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.make_sampler", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.make_sampler", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.make_sampler"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "model", ",", "model_knowledge", ",", "data_loader", ",", "scorers", ",", "reward_function", "=", "None", ")", ":", "\n", "        ", "super", "(", "Generator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model_knowledge", "=", "model_knowledge", "\n", "self", ".", "data_loader", "=", "data_loader", "\n", "\n", "self", ".", "sampler", "=", "sampling", ".", "make_sampler", "(", "\n", "opt", ".", "eval", ".", "sample", ",", "opt", ",", "data_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.generate.Generator.generate": [[68, 70], ["None"], "methods", ["None"], ["", "def", "generate", "(", "self", ",", "split", "=", "\"dev\"", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.generate.Generator.generate_batch": [[71, 73], ["None"], "methods", ["None"], ["", "def", "generate_batch", "(", "self", ",", "sequences", ",", "split", ",", "verbose", "=", "False", ",", "bs", "=", "32", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.generate.do_gen_run": [[6, 26], ["generate.save_sequences", "generator.generate", "generator.generate_some", "avg_scores.items", "scores.setdefault", "scores[].setdefault"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.generate.save_sequences", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.generate"], ["def", "do_gen_run", "(", "opt", ",", "generator", ",", "l", ",", "split", "=", "\"dev\"", ",", "scores", "=", "{", "}", ")", ":", "\n", "# Generate sequences for examples in evaluation set using", "\n", "# current trained model", "\n", "\n", "    ", "if", "opt", ".", "eval", ".", "gs", "==", "\"full\"", ":", "\n", "        ", "sequences", ",", "avg_scores", ",", "indiv_scores", "=", "generator", ".", "generate", "(", "split", ")", "\n", "", "else", ":", "\n", "        ", "sequences", ",", "avg_scores", ",", "indiv_scores", "=", "generator", ".", "generate_some", "(", "split", ")", "\n", "\n", "", "if", "avg_scores", "is", "not", "None", ":", "\n", "# Record scores from generated sequences", "\n", "        ", "for", "score_name", ",", "score_val", "in", "avg_scores", ".", "items", "(", ")", ":", "\n", "            ", "scores", ".", "setdefault", "(", "score_name", ",", "{", "}", ")", "\n", "scores", "[", "score_name", "]", ".", "setdefault", "(", "l", ",", "[", "]", ")", "\n", "scores", "[", "score_name", "]", "[", "l", "]", "+=", "[", "score_val", "]", "\n", "\n", "# Save generated sequences", "\n", "", "", "save_sequences", "(", "opt", ",", "sequences", ",", "avg_scores", ",", "indiv_scores", ",", "\n", "l", ",", "split", ",", "opt", ".", "eval", ".", "gs", "==", "\"full\"", ",", "\n", "generator", ".", "data_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.generate.save_sequences": [[28, 53], ["src.save_eval_file", "src.save_eval_file", "src.save_eval_file"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file"], ["", "def", "save_sequences", "(", "opt", ",", "sequences", ",", "avg_scores", ",", "indiv_scores", ",", "\n", "l", ",", "split", ",", "full", ",", "data_loader", ")", ":", "\n", "# This seems a bit roundabout since l = opt.train.dynamic in train.py", "\n", "# But it's in case we start checkpointing outside of epoch boundaries", "\n", "    ", "opt", ".", "train", ".", "dynamic", ".", "epoch", "=", "l", "\n", "\n", "if", "cfg", ".", "save", ":", "\n", "        ", "if", "full", ":", "\n", "            ", "names", "=", "{", "\"gens\"", ":", "\"gens\"", ",", "\"scores\"", ":", "\"scores\"", ",", "\n", "\"indiv\"", ":", "\"indiv.scores\"", "}", "\n", "", "else", ":", "\n", "            ", "names", "=", "{", "\"gens\"", ":", "\"gens.small\"", ",", "\"scores\"", ":", "\"scores.small\"", ",", "\n", "\"indiv\"", ":", "\"indiv.scores.small\"", "}", "\n", "# Save generated sequences", "\n", "", "data", ".", "save_eval_file", "(", "opt", ",", "sequences", ",", "names", "[", "\"gens\"", "]", ",", "split", ")", "\n", "\n", "if", "avg_scores", "is", "not", "None", ":", "\n", "# Save average scores over evaluation set for generated sequences", "\n", "# Scores computed are the ones the generator was initialized with", "\n", "            ", "data", ".", "save_eval_file", "(", "opt", ",", "avg_scores", ",", "names", "[", "\"scores\"", "]", ",", "split", ")", "\n", "\n", "if", "split", "==", "\"dev\"", ":", "\n", "# Save individual scores", "\n", "                ", "data", ".", "save_eval_file", "(", "\n", "opt", ",", "indiv_scores", ",", "names", "[", "\"indiv\"", "]", ",", "split", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.atomic_evaluate.AtomicGenerationEvaluator.__init__": [[13, 18], ["src.Evaluator.__init__"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "model", ",", "model_knowledge", ",", "data_loader", ")", ":", "\n", "        ", "super", "(", "AtomicGenerationEvaluator", ",", "self", ")", ".", "__init__", "(", "\n", "opt", ",", "model", ",", "model_knowledge", ",", "data_loader", ")", "\n", "\n", "self", ".", "batch", "=", "batch", ".", "batch_atomic_generate", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.atomic_evaluate.AtomicGenerationEvaluator.initialize_losses": [[19, 23], ["None"], "methods", ["None"], ["", "def", "initialize_losses", "(", "self", ")", ":", "\n", "        ", "average_loss", "=", "{", "\"total_micro\"", ":", "0", ",", "\"total_macro\"", ":", "0", "}", "\n", "nums", "=", "{", "\"total_micro\"", ":", "0", ",", "\"total_macro\"", ":", "0", "}", "\n", "return", "average_loss", ",", "nums", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.atomic_evaluate.AtomicGenerationEvaluator.compute_final_scores": [[24, 32], ["numpy.exp", "numpy.exp"], "methods", ["None"], ["", "def", "compute_final_scores", "(", "self", ",", "average_loss", ",", "nums", ")", ":", "\n", "        ", "average_loss", "[", "\"total_macro\"", "]", "/=", "nums", "[", "\"total_macro\"", "]", "\n", "average_loss", "[", "\"total_micro\"", "]", "/=", "nums", "[", "\"total_micro\"", "]", "\n", "\n", "average_loss", "[", "\"ppl_macro\"", "]", "=", "np", ".", "exp", "(", "average_loss", "[", "\"total_macro\"", "]", ")", "\n", "average_loss", "[", "\"ppl_micro\"", "]", "=", "np", ".", "exp", "(", "average_loss", "[", "\"total_micro\"", "]", ")", "\n", "\n", "return", "average_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.atomic_evaluate.AtomicGenerationEvaluator.counter": [[33, 35], ["None"], "methods", ["None"], ["", "def", "counter", "(", "self", ",", "nums", ")", ":", "\n", "        ", "return", "nums", "[", "\"total_macro\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.atomic_evaluate.AtomicGenerationEvaluator.print_result": [[36, 41], ["print", "print"], "methods", ["None"], ["", "def", "print_result", "(", "self", ",", "split", ",", "epoch_losses", ")", ":", "\n", "        ", "print", "(", "\"{} Loss: \\t {}\"", ".", "format", "(", "\n", "split", ",", "epoch_losses", "[", "\"total_micro\"", "]", ")", ")", "\n", "print", "(", "\"{} Perplexity: \\t {}\"", ".", "format", "(", "\n", "split", ",", "epoch_losses", "[", "\"ppl_micro\"", "]", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.atomic_evaluate.make_evaluator": [[5, 10], ["atomic_evaluate.AtomicGenerationEvaluator", "AtomicClassificationEvaluator"], "function", ["None"], ["def", "make_evaluator", "(", "opt", ",", "*", "args", ")", ":", "\n", "    ", "if", "opt", ".", "exp", "==", "\"generation\"", ":", "\n", "        ", "return", "AtomicGenerationEvaluator", "(", "opt", ",", "*", "args", ")", "\n", "", "else", ":", "\n", "        ", "return", "AtomicClassificationEvaluator", "(", "opt", ",", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.evaluate.Evaluator.__init__": [[9, 22], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "model", ",", "model_knowledge", ",", "data_loader", ")", ":", "\n", "        ", "super", "(", "Evaluator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "data_loader", "=", "data_loader", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model_knowledge", "=", "model_knowledge", "\n", "self", ".", "batch_variables", "=", "{", "\n", "\"model\"", ":", "model", ",", "\n", "\"model_knowledge\"", ":", "model_knowledge", ",", "\n", "\"data\"", ":", "data_loader", "\n", "}", "\n", "\n", "self", ".", "opt", "=", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.evaluate.Evaluator.validate": [[23, 39], ["print", "evaluate.Evaluator.epoch", "evaluate.Evaluator.print_result", "epoch_losses_k.items", "epoch_losses_s.items", "losses_k.setdefault", "losses_s.setdefault"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.epoch", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_evaluate.ConceptNetGenerationEvaluator.print_result"], ["", "def", "validate", "(", "self", ",", "l", ",", "split", "=", "\"dev\"", ",", "losses_k", "=", "{", "}", ",", "losses_s", "=", "{", "}", ",", "keyset", "=", "None", ")", ":", "\n", "        ", "self", ".", "batch_variables", "[", "\"split\"", "]", "=", "split", "\n", "print", "(", "\"Evaluating {}\"", ".", "format", "(", "split", ")", ")", "\n", "\n", "epoch_losses_k", ",", "epoch_losses_s", "=", "self", ".", "epoch", "(", "\n", "self", ".", "opt", ",", "self", ".", "model", ",", "self", ".", "model_knowledge", ",", "self", ".", "data_loader", ",", "split", ",", "keyset", ")", "\n", "\n", "self", ".", "print_result", "(", "split", ",", "epoch_losses_k", ",", "epoch_losses_s", ")", "\n", "\n", "for", "loss_name", ",", "loss_val", "in", "epoch_losses_k", ".", "items", "(", ")", ":", "\n", "            ", "losses_k", ".", "setdefault", "(", "loss_name", ",", "{", "}", ")", "\n", "losses_k", "[", "loss_name", "]", "[", "l", "]", "=", "loss_val", "\n", "\n", "", "for", "loss_name", ",", "loss_val", "in", "epoch_losses_s", ".", "items", "(", ")", ":", "\n", "            ", "losses_s", ".", "setdefault", "(", "loss_name", ",", "{", "}", ")", "\n", "losses_s", "[", "loss_name", "]", "[", "l", "]", "=", "loss_val", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.evaluate.Evaluator.epoch": [[40, 94], ["evaluate.Evaluator.initialize_losses", "data_loader.reset_offsets", "model.eval", "model_knowledge.eval", "time.time", "utils.set_progress_bar", "torch.cuda.synchronize", "print", "evaluate.Evaluator.compute_final_scores", "evaluate.Evaluator.compute_final_scores", "torch.no_grad", "data_loader.offset_summary", "evaluate.Evaluator.batch", "data_loader.offset_summary", "split.capitalize", "utils.set_progress_bar.update", "print", "time.time", "evaluate.Evaluator.counter", "evaluate.Evaluator.counter"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.initialize_losses", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.GenerationDataLoader.reset_offsets", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.set_progress_bar", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_evaluate.ConceptNetGenerationEvaluator.compute_final_scores", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_evaluate.ConceptNetGenerationEvaluator.compute_final_scores", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.DataLoader.offset_summary", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.batch", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.DataLoader.offset_summary", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.counter", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.counter"], ["", "", "def", "epoch", "(", "self", ",", "opt", ",", "model", ",", "model_knowledge", ",", "data_loader", ",", "split", ",", "keyset", "=", "None", ")", ":", "\n", "        ", "average_loss_k", ",", "average_loss_s", ",", "nums_k", ",", "nums_s", "=", "self", ".", "initialize_losses", "(", ")", "\n", "\n", "data_loader", ".", "reset_offsets", "(", "splits", "=", "split", ",", "shuffle", "=", "False", ")", "\n", "\n", "# Set evaluation mode", "\n", "model", ".", "eval", "(", ")", "\n", "model_knowledge", ".", "eval", "(", ")", "\n", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "# Initialize progress bar", "\n", "bar", "=", "utils", ".", "set_progress_bar", "(", "\n", "data_loader", ".", "total_size", "[", "split", "]", ")", "\n", "\n", "reset", "=", "False", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "while", "not", "reset", ":", "\n", "\n", "                ", "start", "=", "data_loader", ".", "offset_summary", "(", "split", ")", "\n", "\n", "outputs", "=", "self", ".", "batch", "(", "\n", "opt", ",", "nums_k", ",", "nums_s", ",", "average_loss_k", ",", "average_loss_s", ",", "\n", "self", ".", "batch_variables", ",", "eval_mode", "=", "True", ")", "\n", "\n", "end", "=", "data_loader", ".", "offset_summary", "(", "split", ")", "\n", "\n", "reset", "=", "outputs", "[", "\"reset\"", "]", "\n", "\n", "if", "not", "reset", ":", "\n", "                    ", "bar", ".", "update", "(", "end", "-", "start", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "end", ")", "\n", "\n", "", "if", "cfg", ".", "toy", "and", "self", ".", "counter", "(", "nums", ")", ">", "100", ":", "\n", "                    ", "break", "\n", "", "if", "(", "opt", ".", "eval", ".", "es", "!=", "\"full\"", "and", "\n", "(", "self", ".", "counter", "(", "nums", ")", ">", "opt", ".", "eval", ".", "es", ")", ")", ":", "\n", "                    ", "break", "\n", "\n", "", "", "", "nums_k", "=", "outputs", "[", "\"nums_k\"", "]", "\n", "nums_s", "=", "outputs", "[", "\"nums_s\"", "]", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "\n", "print", "(", "\"{} evaluation completed in: {} s\"", ".", "format", "(", "\n", "split", ".", "capitalize", "(", ")", ",", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "\n", "average_loss_k", "=", "self", ".", "compute_final_scores", "(", "\n", "average_loss_k", ",", "nums_k", ")", "\n", "average_loss_s", "=", "self", ".", "compute_final_scores", "(", "\n", "average_loss_s", ",", "nums_s", ")", "\n", "\n", "return", "average_loss_k", ",", "average_loss_s", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.Sampler.__init__": [[16, 21], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "data_loader", ",", "batch_mode", "=", "False", ")", ":", "\n", "# Token on which to end sampling", "\n", "        ", "self", ".", "end_token", "=", "data_loader", ".", "vocab_encoder", "[", "data", ".", "end_token", "]", "\n", "\n", "self", ".", "opt", "=", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.Sampler.generate_sequence": [[22, 24], ["None"], "methods", ["None"], ["", "def", "generate_sequence", "(", "self", ",", "batch", ",", "model", ")", ":", "\n", "        ", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.GreedySampler.__init__": [[27, 29], ["sampler.Sampler.__init__"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "data_loader", ",", "batch_mode", "=", "True", ")", ":", "\n", "        ", "super", "(", "GreedySampler", ",", "self", ")", ".", "__init__", "(", "opt", ",", "data_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.GreedySampler.append_batch": [[30, 37], ["next_idx.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "X.size"], "methods", ["None"], ["", "def", "append_batch", "(", "self", ",", "X", ",", "next_idx", ",", "mask", ")", ":", "\n", "#next_pos = X[:, -1:, 1] + 1", "\n", "#print(next_idx.size())", "\n", "#print(X.size())", "\n", "        ", "next_x", "=", "next_idx", ".", "unsqueeze", "(", "1", ")", "#torch.cat((next_idx, next_pos), -1).unsqueeze(1)", "\n", "next_mask", "=", "torch", ".", "cat", "(", "[", "mask", ",", "torch", ".", "ones", "(", "X", ".", "size", "(", "0", ")", ",", "1", ",", "device", "=", "mask", ".", "device", ")", "]", ",", "1", ")", "\n", "return", "torch", ".", "cat", "(", "(", "X", ",", "next_x", ")", ",", "1", ")", ",", "next_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.GreedySampler.generate_sequence": [[38, 93], ["torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "lm_probs[].max", "indices.clone().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "model", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "lm_probs[].max", "lm_probs[].max", "next_idx.unsqueeze.unsqueeze.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sampler.GreedySampler.append_batch", "beams.append", "beams[].replace", "loss.item", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "indices.clone", "indices.view().unsqueeze", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "model", "loss.item", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "next_idx.unsqueeze.unsqueeze.item", "indices.view", "data_loader.vocab_decoder[].replace().replace", "data_loader.vocab_decoder[].replace", "tok.item"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.generate.generate_atomic_greedy.append_batch"], ["", "def", "generate_sequence", "(", "self", ",", "XMB", ",", "MMB", ",", "model", ",", "data_loader", ",", "start_idx", ",", "end_len", ")", ":", "\n", "        ", "XMB", "=", "XMB", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "lm_probs", "=", "F", ".", "log_softmax", "(", "model", "(", "\n", "XMB", ".", "unsqueeze", "(", "1", ")", ",", "attention_mask", "=", "MMB", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "values", ",", "indices", "=", "lm_probs", "[", ":", ",", "-", "1", ",", ":", "]", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "seqs", "=", "indices", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "loss", "=", "values", "\n", "counts", "=", "1", "\n", "#next_pos = XMB[:, -1:, 1] + 1", "\n", "#print(MMB.size())", "\n", "#next_x = torch.cat((indices.view(-1, 1), next_pos), -1).unsqueeze(1)", "\n", "XMB", "=", "torch", ".", "cat", "(", "(", "XMB", ",", "indices", ".", "view", "(", "-", "1", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", ",", "1", ")", "\n", "MMB", "=", "torch", ".", "cat", "(", "[", "MMB", ",", "torch", ".", "ones", "(", "XMB", ".", "size", "(", "0", ")", ",", "1", ",", "device", "=", "MMB", ".", "device", ")", "]", ",", "1", ")", "\n", "#print(MMB.size()) ", "\n", "# Sample from top k", "\n", "for", "_", "in", "range", "(", "self", ".", "opt", ".", "eval", ".", "smax", ")", ":", "\n", "            ", "lm_probs", "=", "F", ".", "log_softmax", "(", "model", "(", "\n", "XMB", ".", "unsqueeze", "(", "1", ")", ",", "attention_mask", "=", "MMB", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Sample from top k", "\n", "values", ",", "next_idx", "=", "lm_probs", "[", ":", ",", ":", ",", "-", "1", "]", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "values", ",", "next_idx", "=", "lm_probs", "[", ":", ",", "-", "1", ",", ":", "]", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "loss", "+=", "values", "\n", "counts", "+=", "1", "\n", "\n", "next_idx", "=", "next_idx", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "seqs", "=", "torch", ".", "cat", "(", "[", "seqs", ",", "next_idx", "]", ",", "1", ")", "\n", "\n", "if", "(", "next_idx", ".", "item", "(", ")", "==", "self", ".", "end_token", ")", "or", "(", "_", "==", "end_len", "-", "1", ")", ":", "\n", "                ", "break", "\n", "\n", "", "XMB", ",", "MMB", "=", "self", ".", "append_batch", "(", "XMB", ",", "next_idx", ",", "MMB", ")", "\n", "\n", "", "beams", "=", "[", "]", "\n", "\n", "for", "beam", "in", "seqs", ":", "\n", "\n", "            ", "beams", ".", "append", "(", "\" \"", ".", "join", "(", "\"\"", ".", "join", "(", "\n", "[", "data_loader", ".", "vocab_decoder", "[", "tok", ".", "item", "(", ")", "]", ".", "replace", "(", "\n", "'</w>'", ",", "' '", ")", ".", "replace", "(", "'\\n'", ",", "''", ")", "\n", "for", "tok", "in", "beam", "if", "tok", "!=", "self", ".", "end_token", "]", ")", ".", "split", "(", ")", ")", ")", "\n", "#print(beams, beams[0])", "\n", "", "sampling_result", "=", "{", "\n", "\"sequence\"", ":", "beams", "[", "0", "]", ".", "replace", "(", "'\u0120'", ",", "' '", ")", ",", "\n", "\"beams\"", ":", "beams", ",", "\n", "\"beam_losses\"", ":", "[", "loss", ".", "item", "(", ")", "]", ",", "\n", "\"loss\"", ":", "loss", ".", "item", "(", ")", ",", "\n", "\"beam_lengths\"", ":", "[", "counts", "]", ",", "\n", "\"length\"", ":", "counts", "\n", "}", "\n", "return", "sampling_result", ",", "seqs", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.TopKSampler.__init__": [[96, 98], ["sampler.Sampler.__init__"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "data_loader", ",", "batch_mode", "=", "True", ")", ":", "\n", "        ", "super", "(", "TopKSampler", ",", "self", ")", ".", "__init__", "(", "opt", ",", "data_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.TopKSampler.append_batch": [[99, 104], ["torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "X.size"], "methods", ["None"], ["", "def", "append_batch", "(", "self", ",", "X", ",", "next_idx", ",", "mask", ")", ":", "\n", "        ", "next_pos", "=", "X", "[", ":", ",", "-", "1", ":", ",", "1", "]", "+", "1", "\n", "next_x", "=", "torch", ".", "cat", "(", "(", "next_idx", ",", "next_pos", ")", ",", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "next_mask", "=", "torch", ".", "cat", "(", "[", "mask", ",", "torch", ".", "ones", "(", "X", ".", "size", "(", "0", ")", ",", "1", ",", "device", "=", "mask", ".", "device", ")", "]", ",", "1", ")", "\n", "return", "torch", ".", "cat", "(", "(", "X", ",", "next_x", ")", ",", "1", ")", ",", "next_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.TopKSampler.generate_sequence": [[105, 177], ["src.prepare_position_embeddings", "src.prepare_position_embeddings", "src.prepare_position_embeddings", "src.prepare_position_embeddings", "src.prepare_position_embeddings", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "lm_probs[].topk", "indices.t().clone", "torch.cat.repeat", "torch.cat.repeat", "torch.cat.repeat", "torch.cat.repeat", "torch.cat.repeat", "torch.cat.repeat", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "model", "values.view", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "lm_probs[].topk", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "indices.gather", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sampler.TopKSampler.append_batch", "beams.append", "losses.squeeze().tolist", "losses[].item", "counts.long().squeeze().tolist", "counts[].long().item", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "indices.t", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "model", "values.exp", "ended.sum().item", "values.gather", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "ended.long", "losses.squeeze", "counts.long().squeeze", "counts[].long", "indices.view", "ended.sum", "counts.long", "data_loader.vocab_decoder[].replace().replace", "data_loader.vocab_decoder[].replace", "tok.item"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.utils.prepare_position_embeddings", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.utils.prepare_position_embeddings", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.utils.prepare_position_embeddings", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.utils.prepare_position_embeddings", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.utils.prepare_position_embeddings", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.generate.generate_atomic_greedy.append_batch"], ["", "def", "generate_sequence", "(", "self", ",", "batch", ",", "model", ",", "data_loader", ",", "start_idx", ",", "end_len", ")", ":", "\n", "# start_idx = context_size_event + 1", "\n", "# start_idx = max_e1 + max_r", "\n", "# end_idx = context_size_effect - 1", "\n", "# end_idx = max_e2", "\n", "        ", "XMB", "=", "batch", "[", "\"sequences\"", "]", "[", ":", ",", ":", "start_idx", "]", "\n", "MMB", "=", "batch", "[", "\"attention_mask\"", "]", "[", ":", ",", ":", "start_idx", "]", "\n", "\n", "XMB", "=", "model_utils", ".", "prepare_position_embeddings", "(", "\n", "self", ".", "opt", ",", "data_loader", ".", "vocab_encoder", ",", "XMB", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "\n", "lm_probs", "=", "F", ".", "log_softmax", "(", "model", "(", "\n", "XMB", ".", "unsqueeze", "(", "1", ")", ",", "attention_mask", "=", "MMB", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "values", ",", "indices", "=", "lm_probs", "[", ":", ",", "-", "1", ",", ":", "]", ".", "topk", "(", "self", ".", "opt", ".", "eval", ".", "k", ")", "\n", "seqs", "=", "indices", ".", "t", "(", ")", ".", "clone", "(", ")", "\n", "\n", "losses", "=", "-", "values", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "\n", "ended", "=", "(", "seqs", "==", "self", ".", "end_token", ")", ".", "float", "(", ")", "\n", "counts", "=", "(", "1", "-", "ended", ")", "\n", "XMB", "=", "XMB", ".", "repeat", "(", "self", ".", "opt", ".", "eval", ".", "k", ",", "1", ",", "1", ")", "\n", "MMB", "=", "MMB", ".", "repeat", "(", "self", ".", "opt", ".", "eval", ".", "k", ",", "1", ")", "\n", "next_pos", "=", "XMB", "[", ":", ",", "-", "1", ":", ",", "1", "]", "+", "1", "\n", "next_x", "=", "torch", ".", "cat", "(", "(", "indices", ".", "view", "(", "self", ".", "opt", ".", "eval", ".", "k", ",", "-", "1", ")", ",", "next_pos", ")", ",", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "XMB", "=", "torch", ".", "cat", "(", "(", "XMB", ",", "next_x", ")", ",", "1", ")", "\n", "MMB", "=", "torch", ".", "cat", "(", "[", "MMB", ",", "torch", ".", "ones", "(", "XMB", ".", "size", "(", "0", ")", ",", "1", ",", "device", "=", "MMB", ".", "device", ")", "]", ",", "1", ")", "\n", "\n", "# Sample from top k", "\n", "\n", "for", "_", "in", "range", "(", "end_len", ")", ":", "\n", "            ", "lm_probs", "=", "F", ".", "log_softmax", "(", "model", "(", "\n", "XMB", ".", "unsqueeze", "(", "1", ")", ",", "sequence_mask", "=", "MMB", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Sample from top k", "\n", "values", ",", "indices", "=", "lm_probs", "[", ":", ",", "-", "1", ",", ":", "]", ".", "topk", "(", "self", ".", "opt", ".", "eval", ".", "k", ")", "\n", "choice", "=", "torch", ".", "multinomial", "(", "values", ".", "exp", "(", ")", ",", "1", ")", "\n", "next_idx", "=", "indices", ".", "gather", "(", "-", "1", ",", "choice", ")", "\n", "\n", "ended", "=", "ended", "+", "(", "next_idx", "==", "self", ".", "end_token", ")", ".", "float", "(", ")", "*", "(", "1", "-", "ended", ")", "\n", "\n", "next_idx", "=", "next_idx", "*", "(", "1", "-", "ended", ")", ".", "long", "(", ")", "+", "ended", ".", "long", "(", ")", "*", "self", ".", "end_token", "\n", "\n", "counts", "+=", "(", "1", "-", "ended", ")", "\n", "\n", "seqs", "=", "torch", ".", "cat", "(", "[", "seqs", ",", "next_idx", "]", ",", "1", ")", "\n", "\n", "if", "ended", ".", "sum", "(", ")", ".", "item", "(", ")", "==", "self", ".", "opt", ".", "eval", ".", "k", ":", "\n", "                ", "break", "\n", "\n", "", "losses", "-=", "values", ".", "gather", "(", "-", "1", ",", "choice", ")", "*", "(", "1", "-", "ended", ")", "\n", "\n", "XMB", ",", "MMB", "=", "self", ".", "append_batch", "(", "XMB", ",", "next_idx", ",", "MMB", ")", "\n", "\n", "", "beams", "=", "[", "]", "\n", "\n", "for", "beam", "in", "seqs", ":", "\n", "            ", "beams", ".", "append", "(", "\" \"", ".", "join", "(", "\"\"", ".", "join", "(", "\n", "[", "data_loader", ".", "vocab_decoder", "[", "tok", ".", "item", "(", ")", "]", ".", "replace", "(", "\n", "'</w>'", ",", "' '", ")", ".", "replace", "(", "'\\n'", ",", "''", ")", "\n", "for", "tok", "in", "beam", "if", "tok", "!=", "self", ".", "end_token", "]", ")", ".", "split", "(", ")", ")", ")", "\n", "\n", "", "sampling_result", "=", "{", "\n", "\"sequence\"", ":", "beams", "[", "0", "]", ",", "\n", "\"beams\"", ":", "beams", ",", "\n", "\"beam_losses\"", ":", "losses", ".", "squeeze", "(", ")", ".", "tolist", "(", ")", ",", "\n", "\"loss\"", ":", "losses", "[", "0", "]", ".", "item", "(", ")", ",", "\n", "\"beam_lengths\"", ":", "counts", ".", "long", "(", ")", ".", "squeeze", "(", ")", ".", "tolist", "(", ")", ",", "\n", "\"length\"", ":", "counts", "[", "0", "]", ".", "long", "(", ")", ".", "item", "(", ")", "\n", "}", "\n", "\n", "return", "sampling_result", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.BeamSampler.__init__": [[180, 185], ["sampler.TopKSampler.__init__", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones().to", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "data_loader", ",", "batch_mode", "=", "True", ",", "scorer", "=", "None", ")", ":", "\n", "        ", "super", "(", "BeamSampler", ",", "self", ")", ".", "__init__", "(", "opt", ",", "data_loader", ",", "batch_mode", ")", "\n", "\n", "self", ".", "kill_mask", "=", "torch", ".", "ones", "(", "opt", ".", "eval", ".", "bs", ",", "opt", ".", "eval", ".", "bs", ")", ".", "to", "(", "cfg", ".", "device", ")", "*", "9000", "\n", "self", ".", "kill_mask", "[", ":", ",", "0", "]", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.BeamSampler.make_batch": [[186, 196], ["np.array", "np.arange", "np.expand_dims", "np.stack", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "np.expand_dims", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "make_batch", "(", "self", ",", "X", ")", ":", "\n", "        ", "X", "=", "np", ".", "array", "(", "X", ")", "\n", "assert", "X", ".", "ndim", "in", "[", "1", ",", "2", "]", "\n", "if", "X", ".", "ndim", "==", "1", ":", "\n", "            ", "X", "=", "np", ".", "expand_dims", "(", "X", ",", "axis", "=", "0", ")", "\n", "", "pos_enc", "=", "np", ".", "arange", "(", "n_vocab", "+", "n_special", ",", "n_vocab", "+", "n_special", "+", "X", ".", "shape", "[", "-", "1", "]", ")", "\n", "pos_enc", "=", "np", ".", "expand_dims", "(", "pos_enc", ",", "axis", "=", "0", ")", "\n", "batch", "=", "np", ".", "stack", "(", "[", "X", ",", "pos_enc", "]", ",", "axis", "=", "-", "1", ")", "\n", "batch", "=", "torch", ".", "tensor", "(", "batch", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.BeamSampler.append_batch": [[197, 202], ["torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "X.size", "beam_toks.unsqueeze"], "methods", ["None"], ["", "def", "append_batch", "(", "self", ",", "X", ",", "beam_toks", ",", "mask", ")", ":", "\n", "        ", "next_pos", "=", "X", "[", ":", ",", "-", "1", ":", ",", "1", "]", "+", "1", "\n", "next_x", "=", "torch", ".", "cat", "(", "(", "beam_toks", ".", "unsqueeze", "(", "1", ")", ",", "next_pos", ")", ",", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "next_mask", "=", "torch", ".", "cat", "(", "[", "mask", ",", "torch", ".", "ones", "(", "X", ".", "size", "(", "0", ")", ",", "1", ",", "device", "=", "mask", ".", "device", ")", "]", ",", "1", ")", "\n", "return", "torch", ".", "cat", "(", "(", "X", ",", "next_x", ")", ",", "1", ")", ",", "next_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.BeamSampler.generate_sequence": [[203, 324], ["src.prepare_position_embeddings", "src.prepare_position_embeddings", "src.prepare_position_embeddings", "src.prepare_position_embeddings", "src.prepare_position_embeddings", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "lm_probs[].squeeze", "lm_probs[].squeeze.topk", "beam_losses.append", "beam_toks.unsqueeze.unsqueeze.unsqueeze", "beam_toks.unsqueeze.unsqueeze.clone", "torch.cat.repeat", "torch.cat.repeat", "torch.cat.repeat", "torch.cat.repeat", "torch.cat.repeat", "torch.cat.repeat", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "model", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "lm_probs[].squeeze", "lm_probs[].squeeze.topk", "ended.index_select.index_select.unsqueeze().repeat", "counts.unsqueeze().repeat().view.index_select.unsqueeze().repeat().view", "ended.index_select.index_select.index_select", "temp_counts.index_select.unsqueeze().repeat().view.index_select", "beam_losses.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sampler.BeamSampler.append_batch", "beams.append", "beam_lls.tolist", "beam_lls[].item", "counts.unsqueeze().repeat().view.index_select.tolist", "counts[].item", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "model", "beam_lls.unsqueeze().repeat().view", "beam_losses[].unsqueeze().repeat().view", "i.index_select", "hyp_beam_toks.view", "torch.cat.t().repeat().t().contiguous().view", "torch.cat.t().repeat().t().contiguous().view", "torch.cat.t().repeat().t().contiguous().view", "torch.cat.transpose().transpose().repeat().transpose().transpose().contiguous().view", "torch.cat.transpose().transpose().repeat().transpose().transpose().contiguous().view", "torch.cat.transpose().transpose().repeat().transpose().transpose().contiguous().view", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "ended.index_select.index_select.unsqueeze", "hyp_beam_lls.view", "hypothesis_mask.view", "counts.unsqueeze().repeat().view.index_select.unsqueeze().repeat", "beam_toks.unsqueeze.unsqueeze.unsqueeze", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "beam_lls.unsqueeze().repeat", "beam_losses[].unsqueeze().repeat", "torch.cat.t().repeat().t().contiguous", "torch.cat.t().repeat().t().contiguous", "torch.cat.t().repeat().t().contiguous", "torch.cat.transpose().transpose().repeat().transpose().transpose().contiguous", "torch.cat.transpose().transpose().repeat().transpose().transpose().contiguous", "torch.cat.transpose().transpose().repeat().transpose().transpose().contiguous", "counts.unsqueeze().repeat().view.index_select.unsqueeze", "beam_lls.unsqueeze", "beam_losses[].unsqueeze", "torch.cat.t().repeat().t", "torch.cat.t().repeat().t", "torch.cat.t().repeat().t", "torch.cat.transpose().transpose().repeat().transpose().transpose", "torch.cat.transpose().transpose().repeat().transpose().transpose", "torch.cat.transpose().transpose().repeat().transpose().transpose", "data_loader.vocab_decoder[].replace().replace", "torch.cat.t().repeat", "torch.cat.t().repeat", "torch.cat.t().repeat", "torch.cat.transpose().transpose().repeat().transpose", "torch.cat.transpose().transpose().repeat().transpose", "torch.cat.transpose().transpose().repeat().transpose", "data_loader.vocab_decoder[].replace", "torch.cat.t", "torch.cat.t", "torch.cat.t", "torch.cat.transpose().transpose().repeat", "torch.cat.transpose().transpose().repeat", "torch.cat.transpose().transpose().repeat", "torch.cat.transpose().transpose", "torch.cat.transpose().transpose", "torch.cat.transpose().transpose", "tok.item", "torch.cat.transpose", "torch.cat.transpose", "torch.cat.transpose"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.utils.prepare_position_embeddings", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.utils.prepare_position_embeddings", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.utils.prepare_position_embeddings", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.utils.prepare_position_embeddings", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.utils.prepare_position_embeddings", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.generate.generate_atomic_greedy.append_batch"], ["", "def", "generate_sequence", "(", "self", ",", "batch", ",", "model", ",", "data_loader", ",", "start_idx", ",", "end_len", ")", ":", "\n", "# start_idx = context_size_event + 1", "\n", "# start_idx = max_e1 + max_r", "\n", "# end_idx = context_size_effect - 1", "\n", "# end_idx = max_e2", "\n", "        ", "XMB", "=", "batch", "[", "\"sequences\"", "]", "[", ":", ",", ":", "start_idx", "]", "\n", "MMB", "=", "batch", "[", "\"attention_mask\"", "]", "[", ":", ",", ":", "start_idx", "]", "\n", "\n", "XMB", "=", "model_utils", ".", "prepare_position_embeddings", "(", "\n", "self", ".", "opt", ",", "data_loader", ".", "vocab_encoder", ",", "XMB", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "\n", "tokens", "=", "[", "]", "\n", "beam_losses", "=", "[", "]", "\n", "# Beam Search", "\n", "beam_lls", ",", "beam_toks", ",", "beam_seqs", "=", "None", ",", "None", ",", "None", "\n", "lm_probs", "=", "F", ".", "log_softmax", "(", "model", "(", "\n", "XMB", ".", "unsqueeze", "(", "1", ")", ",", "sequence_mask", "=", "MMB", ")", ",", "dim", "=", "-", "1", ")", "\n", "dist", "=", "lm_probs", "[", ":", ",", "-", "1", ",", ":", "]", ".", "squeeze", "(", ")", "\n", "beam_lls", ",", "beam_toks", "=", "dist", ".", "topk", "(", "self", ".", "opt", ".", "eval", ".", "bs", ")", "\n", "beam_losses", ".", "append", "(", "beam_lls", ")", "\n", "\n", "ended", "=", "(", "beam_toks", "==", "self", ".", "end_token", ")", ".", "float", "(", ")", "\n", "counts", "=", "(", "2", "-", "ended", ")", "\n", "beam_toks", "=", "beam_toks", ".", "unsqueeze", "(", "1", ")", "\n", "beam_seqs", "=", "beam_toks", ".", "clone", "(", ")", "\n", "XMB", "=", "XMB", ".", "repeat", "(", "self", ".", "opt", ".", "eval", ".", "bs", ",", "1", ",", "1", ")", "\n", "MMB", "=", "MMB", ".", "repeat", "(", "self", ".", "opt", ".", "eval", ".", "bs", ",", "1", ")", "\n", "next_pos", "=", "XMB", "[", ":", ",", "-", "1", ":", ",", "1", "]", "+", "1", "\n", "next_x", "=", "torch", ".", "cat", "(", "(", "beam_toks", ",", "next_pos", ")", ",", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "XMB", "=", "torch", ".", "cat", "(", "(", "XMB", ",", "next_x", ")", ",", "1", ")", "\n", "MMB", "=", "torch", ".", "cat", "(", "[", "MMB", ",", "torch", ".", "ones", "(", "XMB", ".", "size", "(", "0", ")", ",", "1", ",", "device", "=", "MMB", ".", "device", ")", "]", ",", "1", ")", "\n", "\n", "for", "_", "in", "range", "(", "end_len", ")", ":", "\n", "\n", "# Compute distribution for current beam", "\n", "            ", "lm_probs", "=", "F", ".", "log_softmax", "(", "model", "(", "\n", "XMB", ".", "unsqueeze", "(", "1", ")", ",", "attention_mask", "=", "MMB", ")", ",", "dim", "=", "-", "1", ")", "\n", "dist", "=", "lm_probs", "[", ":", ",", "-", "1", ",", ":", "]", ".", "squeeze", "(", ")", "\n", "\n", "# get hypothesis tokens for distribution", "\n", "hyp_beam_lls", ",", "hyp_beam_toks", "=", "dist", ".", "topk", "(", "self", ".", "opt", ".", "eval", ".", "bs", ")", "\n", "\n", "# Compute masks and expand beam", "\n", "expanded_ended", "=", "ended", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "self", ".", "opt", ".", "eval", ".", "bs", ")", "\n", "hypothesis_mask", "=", "expanded_ended", "*", "self", ".", "kill_mask", "+", "(", "1", "-", "expanded_ended", ")", "\n", "\n", "paper_results", "=", "False", "\n", "\n", "if", "paper_results", ":", "\n", "# Results from paper with slightly buggy beam search", "\n", "                ", "current_beam_lls", "=", "beam_lls", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "\n", "1", ",", "self", ".", "opt", ".", "eval", ".", "bs", ")", ".", "view", "(", "self", ".", "opt", ".", "eval", ".", "bs", "**", "2", ")", "\n", "", "else", ":", "\n", "# Current beam search implementation", "\n", "                ", "current_beam_lls", "=", "beam_losses", "[", "-", "1", "]", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "\n", "1", ",", "self", ".", "opt", ".", "eval", ".", "bs", ")", ".", "view", "(", "self", ".", "opt", ".", "eval", ".", "bs", "**", "2", ")", "\n", "\n", "# Compute losses of hypotheses, masking those that have ended", "\n", "", "hyp_beam_lls", "=", "(", "hyp_beam_lls", ".", "view", "(", "self", ".", "opt", ".", "eval", ".", "bs", "**", "2", ")", "*", "\n", "hypothesis_mask", ".", "view", "(", "-", "1", ")", ")", "+", "current_beam_lls", "\n", "\n", "# Get normalizer for sequences", "\n", "temp_counts", "=", "counts", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "self", ".", "opt", ".", "eval", ".", "bs", ")", ".", "view", "(", "\n", "self", ".", "opt", ".", "eval", ".", "bs", "**", "2", ")", "\n", "\n", "# Select best beams with lowest aggregate loss", "\n", "beam_lls", ",", "top_beam_idxs", "=", "(", "hyp_beam_lls", "/", "temp_counts", ")", ".", "topk", "(", "self", ".", "opt", ".", "eval", ".", "bs", ")", "\n", "\n", "# Update placements in beam based on selecetion", "\n", "beam_losses", "=", "[", "i", ".", "index_select", "(", "0", ",", "top_beam_idxs", "//", "self", ".", "opt", ".", "eval", ".", "bs", ")", "\n", "for", "i", "in", "beam_losses", "]", "\n", "ended", "=", "ended", ".", "index_select", "(", "0", ",", "top_beam_idxs", "//", "self", ".", "opt", ".", "eval", ".", "bs", ")", "\n", "counts", "=", "temp_counts", ".", "index_select", "(", "0", ",", "top_beam_idxs", ")", "\n", "\n", "# Save beam losses", "\n", "beam_losses", ".", "append", "(", "beam_lls", "*", "counts", ")", "\n", "\n", "# Update beam tokens", "\n", "ended_mask", "=", "(", "1", "-", "ended", ")", ".", "long", "(", ")", "\n", "end_replacement", "=", "(", "self", ".", "end_token", "*", "ended", ")", ".", "long", "(", ")", "\n", "next_toks", "=", "hyp_beam_toks", ".", "view", "(", "-", "1", ")", "[", "top_beam_idxs", "]", "\n", "beam_toks", "=", "next_toks", "*", "ended_mask", "+", "end_replacement", "\n", "\n", "# Update ended and counts", "\n", "ended", "=", "ended", "+", "(", "beam_toks", "==", "self", ".", "end_token", ")", ".", "float", "(", ")", "*", "(", "1", "-", "ended", ")", "\n", "counts", "=", "counts", "+", "(", "1", "-", "ended", ")", "\n", "\n", "# Update beam sequences", "\n", "beam_seqs", "=", "beam_seqs", ".", "t", "(", ")", ".", "repeat", "(", "self", ".", "opt", ".", "eval", ".", "bs", ",", "1", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "self", ".", "opt", ".", "eval", ".", "bs", "**", "2", ",", "-", "1", ")", "[", "top_beam_idxs", "]", "\n", "beam_seqs", "=", "torch", ".", "cat", "(", "(", "beam_seqs", ",", "beam_toks", ".", "unsqueeze", "(", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# I have no idea what's going on but Ari's on point with it", "\n", "XMB", "=", "XMB", ".", "transpose", "(", "0", ",", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "repeat", "(", "\n", "self", ".", "opt", ".", "eval", ".", "bs", ",", "1", ",", "1", ")", ".", "transpose", "(", "2", ",", "1", ")", ".", "transpose", "(", "\n", "1", ",", "0", ")", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "self", ".", "opt", ".", "eval", ".", "bs", "**", "2", ",", "XMB", ".", "size", "(", "1", ")", ",", "XMB", ".", "size", "(", "2", ")", ")", "[", "top_beam_idxs", "]", "\n", "\n", "XMB", ",", "MMB", "=", "self", ".", "append_batch", "(", "XMB", ",", "beam_toks", ",", "MMB", ")", "\n", "\n", "if", "(", "beam_toks", "==", "self", ".", "end_token", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "==", "self", ".", "opt", ".", "eval", ".", "bs", ":", "\n", "                ", "break", "\n", "\n", "", "", "beams", "=", "[", "]", "\n", "\n", "for", "beam", "in", "beam_seqs", ":", "\n", "            ", "beams", ".", "append", "(", "\" \"", ".", "join", "(", "\"\"", ".", "join", "(", "\n", "[", "data_loader", ".", "vocab_decoder", "[", "tok", ".", "item", "(", ")", "]", ".", "replace", "(", "\n", "'</w>'", ",", "' '", ")", ".", "replace", "(", "'\\n'", ",", "''", ")", "\n", "for", "tok", "in", "beam", "if", "tok", "!=", "self", ".", "end_token", "]", ")", ".", "split", "(", ")", ")", ")", "\n", "\n", "", "sampling_result", "=", "{", "\n", "\"sequence\"", ":", "beams", "[", "0", "]", ",", "\n", "\"beams\"", ":", "beams", ",", "\n", "\"beam_losses\"", ":", "beam_lls", ".", "tolist", "(", ")", ",", "\n", "\"loss\"", ":", "beam_lls", "[", "0", "]", ".", "item", "(", ")", ",", "\n", "\"beam_lengths\"", ":", "counts", ".", "tolist", "(", ")", ",", "\n", "\"length\"", ":", "counts", "[", "0", "]", ".", "item", "(", ")", "\n", "}", "\n", "\n", "return", "sampling_result", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.make_sampler": [[11, 14], ["print", "sampler.GreedySampler"], "function", ["None"], ["def", "make_sampler", "(", "sampler_type", ",", "opt", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "print", "(", "\"Initializing Greedy Sampler\"", ")", "\n", "return", "GreedySampler", "(", "opt", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_generate.ConceptNetGenerator.__init__": [[15, 24], ["src.make_sampler", "src.make_sampler", "src.make_sampler"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.make_sampler", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.make_sampler", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.make_sampler"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "model", ",", "model_knowledge", ",", "data_loader", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model_knowledge", "=", "model_knowledge", "\n", "self", ".", "data_loader", "=", "data_loader", "\n", "\n", "self", ".", "sampler", "=", "sampling", ".", "make_sampler", "(", "\n", "opt", ".", "eval", ".", "sample", ",", "opt", ",", "data_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_generate.ConceptNetGenerator.reset_sequences": [[25, 27], ["None"], "methods", ["None"], ["", "def", "reset_sequences", "(", "self", ")", ":", "\n", "        ", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_generate.ConceptNetGenerator.generate": [[28, 86], ["print", "conceptnet_generate.ConceptNetGenerator.model.eval", "conceptnet_generate.ConceptNetGenerator.model_knowledge.eval", "conceptnet_generate.ConceptNetGenerator.data_loader.reset_offsets", "time.time", "conceptnet_generate.ConceptNetGenerator.reset_sequences", "utils.set_progress_bar", "torch.cuda.synchronize", "print", "torch.no_grad", "len", "conceptnet_generate.ConceptNetGenerator.generate_batch", "len", "utils.set_progress_bar.update", "print", "time.time"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.GenerationDataLoader.reset_offsets", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_generate.ConceptNetGenerator.reset_sequences", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.set_progress_bar", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_generate.ConceptNetGenerator.generate_batch"], ["", "def", "generate", "(", "self", ",", "split", "=", "\"dev\"", ")", ":", "\n", "        ", "print", "(", "\"Generating Sequences\"", ")", "\n", "\n", "# Set evaluation mode", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "model_knowledge", ".", "eval", "(", ")", "\n", "\n", "\n", "# Reset evaluation set for dataset split", "\n", "self", ".", "data_loader", ".", "reset_offsets", "(", "splits", "=", "split", ",", "shuffle", "=", "False", ")", "\n", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "count", "=", "0", "\n", "sequences", "=", "None", "\n", "\n", "# Reset generated sequence buffer", "\n", "sequences", "=", "self", ".", "reset_sequences", "(", ")", "\n", "\n", "# Initialize progress bar", "\n", "bar", "=", "utils", ".", "set_progress_bar", "(", "\n", "self", ".", "data_loader", ".", "total_size", "[", "split", "]", "/", "2", ")", "\n", "\n", "reset", "=", "False", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Cycle through development set", "\n", "            ", "while", "not", "reset", ":", "\n", "\n", "                ", "start", "=", "len", "(", "sequences", ")", "\n", "# Generate a single batch", "\n", "reset", "=", "self", ".", "generate_batch", "(", "sequences", ",", "split", ",", "bs", "=", "1", ")", "\n", "\n", "end", "=", "len", "(", "sequences", ")", "\n", "\n", "if", "not", "reset", ":", "\n", "                    ", "bar", ".", "update", "(", "end", "-", "start", ")", "\n", "", "else", ":", "\n", "                    ", "print", "(", "end", ")", "\n", "\n", "", "count", "+=", "1", "\n", "\n", "if", "cfg", ".", "toy", "and", "count", ">", "10", ":", "\n", "                    ", "break", "\n", "", "if", "(", "self", ".", "opt", ".", "eval", ".", "gs", "!=", "\"full\"", "and", "(", "count", ">", "opt", ".", "eval", ".", "gs", ")", ")", ":", "\n", "                    ", "break", "\n", "\n", "", "", "", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "print", "(", "\"{} generations completed in: {} s\"", ".", "format", "(", "\n", "split", ",", "time", ".", "time", "(", ")", "-", "start", ")", ")", "\n", "\n", "# Compute scores for sequences (e.g., BLEU, ROUGE)", "\n", "# Computes scores that the generator is initialized with", "\n", "# Change define_scorers to add more scorers as possibilities", "\n", "# avg_scores, indiv_scores = self.compute_sequence_scores(", "\n", "#     sequences, split)", "\n", "avg_scores", ",", "indiv_scores", "=", "None", ",", "None", "\n", "\n", "return", "sequences", ",", "avg_scores", ",", "indiv_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_generate.ConceptNetGenerator.generate_batch": [[87, 134], ["conceptnet_generate.ConceptNetGenerator.data_loader.sample_batch", "range", "print", "print", "torch.LongTensor().fill_().cuda", "print", "conceptnet_generate.ConceptNetGenerator.sampler.generate_sequence", "print", "sequences.append", "conceptnet_generate.ConceptNetGenerator.sampler.generate_sequence", "print", "torch.LongTensor().fill_().cuda", "print", "conceptnet_generate.ConceptNetGenerator.sampler.generate_sequence", "torch.LongTensor().fill_", "XMB_knowledge.nonzero().detach", "torch.LongTensor().fill_", "torch.LongTensor().fill_().cuda.nonzero().detach", "XMB.size", "previous_XMB_knowledge.size", "previous_XMB_knowledge.size", "XMB_knowledge.size", "torch.LongTensor", "XMB_knowledge.nonzero", "torch.LongTensor", "torch.LongTensor().fill_().cuda.nonzero", "MMB.size", "MMB.size", "MMB_knowledge.size", "MMB_knowledge.size"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.GenerationDataLoader.sample_batch", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.BeamSampler.generate_sequence", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.BeamSampler.generate_sequence", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.BeamSampler.generate_sequence"], ["", "def", "generate_batch", "(", "self", ",", "sequences", ",", "split", ",", "verbose", "=", "False", ",", "bs", "=", "1", ")", ":", "\n", "# Sample batch from data loader", "\n", "        ", "batch", ",", "reset", "=", "self", ".", "data_loader", ".", "sample_batch", "(", "\n", "split", ",", "bs", "=", "bs", ",", "cat", "=", "\"total\"", ")", "\n", "\n", "input_", "=", "batch", "[", "\"sequences\"", "]", "\n", "attention_mask", "=", "batch", "[", "\"attention_mask\"", "]", "\n", "start_idx_k", "=", "self", ".", "data_loader", ".", "max_input_len_k", "\n", "max_end_len_k", "=", "self", ".", "data_loader", ".", "max_output_len_k", "\n", "start_idx_s", "=", "self", ".", "data_loader", ".", "max_input_len_s", "\n", "max_end_len_s", "=", "self", ".", "data_loader", ".", "max_output_len_s", "\n", "\n", "#.unsqueeze(-1)", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "                ", "print", "(", "\"Iteration....\"", ",", "i", ")", "\n", "#decode knowledge", "\n", "\n", "if", "i", "==", "0", ":", "\n", "                    ", "XMB_knowledge", "=", "input_", "[", ":", ",", "0", ",", "i", ",", ":", "start_idx_k", "]", "\n", "MMB_knowledge", "=", "attention_mask", "[", ":", ",", "0", ",", "i", ",", ":", "start_idx_k", "]", "\n", "sampling_result", ",", "XMB", "=", "self", ".", "sampler", ".", "generate_sequence", "(", "XMB_knowledge", ",", "MMB_knowledge", ",", "self", ".", "model_knowledge", ",", "self", ".", "data_loader", ",", "start_idx_k", ",", "max_end_len_k", ")", "\n", "print", "(", "\"Knowledge\"", ",", "sampling_result", ")", "\n", "\n", "previous_XMB_knowledge", "=", "XMB_knowledge", "[", "XMB_knowledge", ".", "nonzero", "(", ")", ".", "detach", "(", ")", "]", "\n", "\n", "", "else", ":", "\n", "                    ", "MMB_knowledge", "=", "attention_mask", "[", ":", ",", "0", ",", "i", ",", ":", "start_idx_k", "]", "\n", "\n", "XMB_knowledge_", "=", "torch", ".", "LongTensor", "(", "MMB_knowledge", ".", "size", "(", "0", ")", ",", "MMB_knowledge", ".", "size", "(", "-", "1", ")", ")", ".", "fill_", "(", "0", ")", ".", "cuda", "(", ")", "\n", "XMB_knowledge_", "[", ":", ",", ":", "previous_XMB_knowledge", ".", "size", "(", "-", "1", ")", "]", "=", "previous_XMB_knowledge", "\n", "XMB_knowledge_", "[", ":", ",", "previous_XMB_knowledge", ".", "size", "(", "-", "1", ")", ":", "XMB_knowledge", ".", "size", "(", "-", "1", ")", "]", "=", "XMB_knowledge", "\n", "print", "(", "\"Knowledge_Input\"", ",", "XMB_knowledge_", ")", "\n", "sampling_result", ",", "XMB", "=", "self", ".", "sampler", ".", "generate_sequence", "(", "XMB_knowledge_", ",", "MMB_knowledge", ",", "self", ".", "model_knowledge", ",", "self", ".", "data_loader", ",", "start_idx_k", ",", "max_end_len_k", ")", "\n", "previous_XMB_knowledge", "=", "XMB_knowledge_", "[", "XMB_knowledge_", ".", "nonzero", "(", ")", ".", "detach", "(", ")", "]", "\n", "\n", "", "print", "(", "\"Knowledge\"", ",", "sampling_result", ")", "\n", "# Decode Sentence                ", "\n", "MMB", "=", "attention_mask", "[", ":", ",", "1", ",", "i", ",", ":", "start_idx_s", "]", "\n", "XMB_sentence", "=", "torch", ".", "LongTensor", "(", "MMB", ".", "size", "(", "0", ")", ",", "MMB", ".", "size", "(", "-", "1", ")", ")", ".", "fill_", "(", "0", ")", ".", "cuda", "(", ")", "\n", "XMB_sentence", "[", ":", ",", ":", "XMB", ".", "size", "(", "-", "1", ")", "]", "=", "XMB", "\n", "print", "(", "\"Sentence Input\"", ",", "XMB_sentence", ")", "\n", "sampling_result", ",", "XMB_knowledge", "=", "self", ".", "sampler", ".", "generate_sequence", "(", "XMB_sentence", ",", "MMB", ",", "self", ".", "model", ",", "self", ".", "data_loader", ",", "start_idx_s", ",", "max_end_len_s", ")", "\n", "\n", "print", "(", "\"Sentence\"", ",", "sampling_result", ")", "\n", "sequences", ".", "append", "(", "sampling_result", ")", "\n", "\n", "", "return", "reset", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_generate.make_generator": [[10, 12], ["conceptnet_generate.ConceptNetGenerator"], "function", ["None"], ["def", "make_generator", "(", "opt", ",", "*", "args", ")", ":", "\n", "    ", "return", "ConceptNetGenerator", "(", "opt", ",", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_evaluate.ConceptNetGenerationEvaluator.__init__": [[14, 20], ["src.Evaluator.__init__"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "model", ",", "model_knowledge", ",", "data_loader", ",", "track", "=", "False", ")", ":", "\n", "        ", "super", "(", "ConceptNetGenerationEvaluator", ",", "self", ")", ".", "__init__", "(", "\n", "opt", ",", "model", ",", "model_knowledge", ",", "data_loader", ")", "\n", "\n", "if", "track", ":", "\n", "            ", "self", ".", "tracker", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_evaluate.ConceptNetGenerationEvaluator.batch": [[21, 31], ["src.batch_conceptnet_generate", "src.batch_conceptnet_generate", "src.batch_conceptnet_generate.get"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.batch_conceptnet_generate", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.batch_conceptnet_generate"], ["", "", "def", "batch", "(", "self", ",", "opt", ",", "nums_k", ",", "nums_s", ",", "average_loss_k", ",", "average_loss_s", ",", "batch_variables", ",", "eval_mode", ")", ":", "\n", "\n", "        ", "outputs", "=", "batch_utils", ".", "batch_conceptnet_generate", "(", "\n", "opt", ",", "nums_k", ",", "nums_s", ",", "average_loss_k", ",", "average_loss_s", ",", "batch_variables", ",", "eval_mode", ",", "\n", "tracking_mode", "=", "self", ".", "tracker", "is", "not", "None", ")", "\n", "\n", "if", "outputs", ".", "get", "(", "\"tracking\"", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "self", ".", "tracker", "[", "self", ".", "current_category", "]", "+=", "outputs", "[", "\"tracking\"", "]", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_evaluate.ConceptNetGenerationEvaluator.initialize_losses": [[32, 42], ["None"], "methods", ["None"], ["", "def", "initialize_losses", "(", "self", ")", ":", "\n", "        ", "average_loss_k", "=", "{", "\"total_micro\"", ":", "0", ",", "\"total_macro\"", ":", "0", "}", "\n", "average_loss_s", "=", "{", "\"total_micro\"", ":", "0", ",", "\"total_macro\"", ":", "0", "}", "\n", "nums_k", "=", "{", "\"total_micro\"", ":", "0", ",", "\"total_macro\"", ":", "0", "}", "\n", "nums_s", "=", "{", "\"total_micro\"", ":", "0", ",", "\"total_macro\"", ":", "0", "}", "\n", "self", ".", "tracker", "=", "None", "\n", "#if self.tracker is not None:", "\n", "#    self.tracker = {\"positive\": [], \"negative\": []}", "\n", "\n", "return", "average_loss_k", ",", "average_loss_s", ",", "nums_k", ",", "nums_s", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_evaluate.ConceptNetGenerationEvaluator.compute_final_scores": [[43, 63], ["numpy.exp", "numpy.exp"], "methods", ["None"], ["", "def", "compute_final_scores", "(", "self", ",", "average_loss", ",", "nums", ")", ":", "\n", "        ", "average_loss", "[", "\"total_macro\"", "]", "/=", "nums", "[", "\"total_macro\"", "]", "\n", "average_loss", "[", "\"total_micro\"", "]", "/=", "nums", "[", "\"total_micro\"", "]", "\n", "'''\n        if nums[\"negative_micro\"]:\n            average_loss[\"negative_macro\"] /= nums[\"negative_macro\"]\n            average_loss[\"negative_micro\"] /= nums[\"negative_micro\"]\n        else:\n            average_loss[\"negative_macro\"] = 0\n            average_loss[\"negative_micro\"] = 0\n\n        average_loss[\"macro_diff\"] = (average_loss[\"negative_macro\"] -\n                                      average_loss[\"total_macro\"])\n        average_loss[\"micro_diff\"] = (average_loss[\"negative_micro\"] -\n                                      average_loss[\"total_micro\"])\n        '''", "\n", "average_loss", "[", "\"ppl_macro\"", "]", "=", "np", ".", "exp", "(", "average_loss", "[", "\"total_macro\"", "]", ")", "\n", "average_loss", "[", "\"ppl_micro\"", "]", "=", "np", ".", "exp", "(", "average_loss", "[", "\"total_micro\"", "]", ")", "\n", "\n", "return", "average_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_evaluate.ConceptNetGenerationEvaluator.counter": [[64, 66], ["None"], "methods", ["None"], ["", "def", "counter", "(", "self", ",", "nums", ")", ":", "\n", "        ", "return", "nums", "[", "\"total_macro\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_evaluate.ConceptNetGenerationEvaluator.print_result": [[67, 80], ["print", "print", "print", "print"], "methods", ["None"], ["", "def", "print_result", "(", "self", ",", "split", ",", "epoch_losses_k", ",", "epoch_losses_s", ")", ":", "\n", "        ", "print", "(", "\"{} Loss: \\t {}\"", ".", "format", "(", "\n", "split", ",", "epoch_losses_k", "[", "\"total_micro\"", "]", ")", ")", "\n", "#print(\"{} Diff: \\t {}\".format(", "\n", "#    split, epoch_losses[\"micro_diff\"]))", "\n", "print", "(", "\"{} Perplexity: \\t {}\"", ".", "format", "(", "\n", "split", ",", "epoch_losses_k", "[", "\"ppl_micro\"", "]", ")", ")", "\n", "print", "(", "\"{} Loss: \\t {}\"", ".", "format", "(", "\n", "split", ",", "epoch_losses_s", "[", "\"total_micro\"", "]", ")", ")", "\n", "#print(\"{} Diff: \\t {}\".format(", "\n", "#    split, epoch_losses[\"micro_diff\"]))", "\n", "print", "(", "\"{} Perplexity: \\t {}\"", ".", "format", "(", "\n", "split", ",", "epoch_losses_s", "[", "\"ppl_micro\"", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_evaluate.make_evaluator": [[9, 11], ["conceptnet_evaluate.ConceptNetGenerationEvaluator"], "function", ["None"], ["def", "make_evaluator", "(", "opt", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "ConceptNetGenerationEvaluator", "(", "opt", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.utils.update_classification_losses": [[2, 10], ["isinstance", "print", "type"], "function", ["None"], ["def", "update_classification_losses", "(", "losses", ",", "nums", ",", "name", ",", "bs", ",", "loss", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "loss", ",", "float", ")", ":", "\n", "        ", "print", "(", "type", "(", "loss", ")", ")", "\n", "raise", "\n", "\n", "", "nums", "[", "name", "]", "+=", "bs", "\n", "\n", "losses", "[", "name", "]", "+=", "loss", "*", "bs", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.utils.update_generation_losses": [[12, 26], ["isinstance", "utils.update_indiv_generation_losses", "utils.update_tensor_generation_losses_knowledge", "utils.update_tensor_generation_losses_sentence"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.utils.update_indiv_generation_losses", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.utils.update_tensor_generation_losses_knowledge", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.utils.update_tensor_generation_losses_sentence"], ["", "def", "update_generation_losses", "(", "losses", ",", "nums", ",", "micro", ",", "macro", ",", "bs", ",", "length", ",", "loss", ",", "s", ")", ":", "\n", "# Update Losses", "\n", "    ", "nums", "[", "macro", "]", "+=", "bs", "\n", "\n", "if", "isinstance", "(", "length", ",", "int", ")", ":", "\n", "        ", "update_indiv_generation_losses", "(", "\n", "losses", ",", "nums", ",", "micro", ",", "macro", ",", "bs", ",", "length", ",", "loss", ")", "\n", "", "else", ":", "\n", "        ", "if", "s", "==", "\"knowledge\"", ":", "\n", "            ", "update_tensor_generation_losses_knowledge", "(", "\n", "losses", ",", "nums", ",", "micro", ",", "macro", ",", "bs", ",", "length", ",", "loss", ")", "\n", "", "elif", "s", "==", "\"sentence\"", ":", "\n", "            ", "update_tensor_generation_losses_sentence", "(", "\n", "losses", ",", "nums", ",", "micro", ",", "macro", ",", "bs", ",", "length", ",", "loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.utils.update_indiv_generation_losses": [[29, 37], ["None"], "function", ["None"], ["", "", "", "def", "update_indiv_generation_losses", "(", "losses", ",", "nums", ",", "micro", ",", "\n", "macro", ",", "bs", ",", "length", ",", "loss", ")", ":", "\n", "    ", "nums", "[", "micro", "]", "+=", "bs", "*", "length", "\n", "\n", "batch_loss", "=", "loss", "*", "bs", "\n", "\n", "losses", "[", "micro", "]", "+=", "batch_loss", "\n", "losses", "[", "macro", "]", "+=", "batch_loss", "/", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.utils.update_tensor_generation_losses": [[39, 45], ["length.sum().item", "loss.sum().item", "length.sum", "loss.sum", "length.float"], "function", ["None"], ["", "def", "update_tensor_generation_losses", "(", "losses", ",", "nums", ",", "micro", ",", "\n", "macro", ",", "bs", ",", "length", ",", "loss", ")", ":", "\n", "    ", "nums", "[", "micro", "]", "+=", "length", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "losses", "[", "micro", "]", "+=", "loss", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "losses", "[", "macro", "]", "+=", "(", "loss", "/", "length", ".", "float", "(", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.utils.update_tensor_generation_losses_knowledge": [[47, 52], ["length.sum().item", "loss.sum().item", "length.sum", "loss.sum", "length.float"], "function", ["None"], ["", "def", "update_tensor_generation_losses_knowledge", "(", "losses_k", ",", "nums_k", ",", "micro", ",", "\n", "macro", ",", "bs", ",", "length", ",", "loss", ")", ":", "\n", "    ", "nums_k", "[", "micro", "]", "+=", "length", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "losses_k", "[", "micro", "]", "+=", "loss", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "losses_k", "[", "macro", "]", "+=", "(", "loss", "/", "length", ".", "float", "(", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.utils.update_tensor_generation_losses_sentence": [[54, 59], ["length.sum().item", "loss.sum().item", "length.sum", "loss.sum", "length.float"], "function", ["None"], ["", "def", "update_tensor_generation_losses_sentence", "(", "losses_s", ",", "nums_s", ",", "micro", ",", "\n", "macro", ",", "bs", ",", "length", ",", "loss", ")", ":", "\n", "    ", "nums_s", "[", "micro", "]", "+=", "length", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "losses_s", "[", "micro", "]", "+=", "loss", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "losses_s", "[", "macro", "]", "+=", "(", "loss", "/", "length", ".", "float", "(", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.bleu_atomic.get_data_params": [[27, 39], ["data_str.split", "gens_file.split", "[].isdigit", "int", "[].split", "case.split", "case.split", "case.split", "case.split", "case.split", "case.split", "case.split", "case.split"], "function", ["None"], ["def", "get_data_params", "(", "gens_file", ")", ":", "\n", "    ", "data_str", "=", "gens_file", ".", "split", "(", "\"/\"", ")", "[", "5", "]", "\n", "data_objs", "=", "data_str", ".", "split", "(", "\"-\"", ")", "\n", "data_params", "=", "{", "}", "\n", "for", "case", "in", "data_objs", ":", "\n", "        ", "if", "case", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ".", "isdigit", "(", ")", ":", "\n", "            ", "data_params", "[", "case", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "]", "=", "int", "(", "case", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ")", "\n", "", "elif", "\"#\"", "in", "case", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ":", "\n", "            ", "data_params", "[", "case", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "]", "=", "case", ".", "split", "(", "\"_\"", ")", "[", "1", "]", ".", "split", "(", "\"#\"", ")", "\n", "", "else", ":", "\n", "            ", "data_params", "[", "case", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "]", "=", "case", ".", "split", "(", "\"_\"", ")", "[", "1", "]", "\n", "", "", "return", "data_params", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.bleu_atomic.flatten": [[44, 46], ["None"], "function", ["None"], ["def", "flatten", "(", "outer", ")", ":", "\n", "    ", "return", "[", "el", "for", "key", "in", "outer", "for", "el", "in", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.bleu_atomic.get_event": [[81, 86], ["event.index"], "function", ["None"], ["", "def", "get_event", "(", "event", ")", ":", "\n", "    ", "if", "\"<\"", "in", "event", "and", "\">\"", "in", "event", ":", "\n", "        ", "return", "event", "[", ":", "event", ".", "index", "(", "\"<\"", ")", "]", "\n", "", "else", ":", "\n", "        ", "return", "event", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.bleu_atomic.score": [[92, 94], ["nltk.bleu", "nltk.translate.bleu_score.SmoothingFunction"], "function", ["None"], ["def", "score", "(", "hyp", ",", "refs", ")", ":", "\n", "    ", "return", "bleu", "(", "refs", ",", "hyp", ",", "weights", "=", "weights", ",", "smoothing_function", "=", "SmoothingFunction", "(", ")", ".", "method1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_gpt2.GPT2Config.__init__": [[119, 157], ["configuration_utils.PretrainedConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", "=", "50257", ",", "\n", "n_positions", "=", "1024", ",", "\n", "n_ctx", "=", "1024", ",", "\n", "n_embd", "=", "768", ",", "\n", "n_layer", "=", "12", ",", "\n", "n_head", "=", "12", ",", "\n", "resid_pdrop", "=", "0.1", ",", "\n", "embd_pdrop", "=", "0.1", ",", "\n", "attn_pdrop", "=", "0.1", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "summary_type", "=", "\"cls_index\"", ",", "\n", "summary_use_proj", "=", "True", ",", "\n", "summary_activation", "=", "None", ",", "\n", "summary_proj_to_labels", "=", "True", ",", "\n", "summary_first_dropout", "=", "0.1", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "self", ".", "n_positions", "=", "n_positions", "\n", "self", ".", "n_embd", "=", "n_embd", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "resid_pdrop", "=", "resid_pdrop", "\n", "self", ".", "embd_pdrop", "=", "embd_pdrop", "\n", "self", ".", "attn_pdrop", "=", "attn_pdrop", "\n", "self", ".", "layer_norm_epsilon", "=", "layer_norm_epsilon", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "summary_type", "=", "summary_type", "\n", "self", ".", "summary_use_proj", "=", "summary_use_proj", "\n", "self", ".", "summary_activation", "=", "summary_activation", "\n", "self", ".", "summary_first_dropout", "=", "summary_first_dropout", "\n", "self", ".", "summary_proj_to_labels", "=", "summary_proj_to_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_gpt2.GPT2Config.max_position_embeddings": [[158, 161], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_gpt2.GPT2Config.hidden_size": [[162, 165], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_embd", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_gpt2.GPT2Config.num_attention_heads": [[166, 169], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_head", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_gpt2.GPT2Config.num_hidden_layers": [[170, 173], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.models.make_model": [[8, 30], ["print", "src.models.gpt2.GPT2LMHeadModel.from_pretrained"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.from_pretrained"], ["def", "make_model", "(", "opt", ",", "n_vocab", ",", "n_ctx", ",", "n_special", ",", "load", "=", "True", ",", "\n", "return_acts", "=", "True", ",", "return_probs", "=", "False", ",", "\n", "clf_token", "=", "\"<CLASS>\"", ",", "answer_size", "=", "None", ")", ":", "\n", "    ", "print", "(", "n_ctx", ")", "\n", "#self.output_hidden_states = config.output_hidden_states", "\n", "#self.output_attentions = config.output_attentions", "\n", "if", "opt", ".", "exp", "==", "\"generation\"", ":", "\n", "#model = GPT2Model.from_pretrained(opt.net)", "\n", "        ", "model", "=", "GPT2LMHeadModel", ".", "from_pretrained", "(", "'gpt2'", ")", "\n", "#model = OpenAIGPTDoubleHeadsModel.from_pretrained('openai-gpt')", "\n", "#model(opt.net)", "\n", "#opt.net)#, True, True)#return_acts=return_acts,\t", "\n", "#return_probs=return_probs)", "\n", "#elif opt.exp == \"classification\":", "\n", "#    model = ClfModel(", "\n", "#        opt.net, n_vocab, n_ctx, clf_token, answer_size)", "\n", "", "DEFAULT_CONFIG", "=", "GPT2Config", "\n", "#if load:", "\n", "#    print(\"LOADING PRETRAINED TRANSFORMER\")", "\n", "#    load_openai_pretrained_model(", "\n", "#        model.transformer, n_ctx=n_ctx, n_special=n_special)", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.models.multi_gpu": [[32, 34], ["torch.DataParallel"], "function", ["None"], ["", "def", "multi_gpu", "(", "model", ",", "devices", ")", ":", "\n", "    ", "return", "nn", ".", "DataParallel", "(", "model", ")", "#, device_ids=devices)", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.models.load_state_dict": [[36, 42], ["model.load_state_dict", "model.load_state_dict", "state_dict.items", "len"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.model_knowledge_story.load_state_dict", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.model_knowledge_story.load_state_dict"], ["", "def", "load_state_dict", "(", "model", ",", "state_dict", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "", "except", "RuntimeError", ":", "\n", "        ", "new_state_dict", "=", "{", "i", "[", "len", "(", "\"module.\"", ")", ":", "]", ":", "j", "for", "i", ",", "j", "in", "state_dict", ".", "items", "(", ")", "}", "\n", "model", ".", "load_state_dict", "(", "new_state_dict", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_gpt2.GPT2Tokenizer.__init__": [[115, 147], ["tokenization_utils.PreTrainedTokenizer.__init__", "tokenization_gpt2.bytes_to_unicode", "dict", "regex.compile", "open", "json.load", "open", "tuple", "zip", "tokenization_gpt2.GPT2Tokenizer.encoder.items", "tokenization_gpt2.GPT2Tokenizer.byte_encoder.items", "merges_handle.read().split", "merge.split", "range", "len", "merges_handle.read"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_gpt2.bytes_to_unicode"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_file", ",", "\n", "merges_file", ",", "\n", "errors", "=", "\"replace\"", ",", "\n", "unk_token", "=", "\"<|endoftext|>\"", ",", "\n", "bos_token", "=", "\"<|endoftext|>\"", ",", "\n", "eos_token", "=", "\"<|endoftext|>\"", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "bos_token", "=", "bos_token", ",", "eos_token", "=", "eos_token", ",", "unk_token", "=", "unk_token", ",", "**", "kwargs", ")", "\n", "self", ".", "max_len_single_sentence", "=", "(", "\n", "self", ".", "max_len", "\n", ")", "# no default special tokens - you can update this value if you add special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "(", "\n", "self", ".", "max_len", "\n", ")", "# no default special tokens - you can update this value if you add special tokens", "\n", "\n", "with", "open", "(", "vocab_file", ",", "encoding", "=", "\"utf-8\"", ")", "as", "vocab_handle", ":", "\n", "            ", "self", ".", "encoder", "=", "json", ".", "load", "(", "vocab_handle", ")", "\n", "", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "self", ".", "errors", "=", "errors", "# how to handle errors in decoding", "\n", "self", ".", "byte_encoder", "=", "bytes_to_unicode", "(", ")", "\n", "self", ".", "byte_decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "byte_encoder", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "merges_file", ",", "encoding", "=", "\"utf-8\"", ")", "as", "merges_handle", ":", "\n", "            ", "bpe_merges", "=", "merges_handle", ".", "read", "(", ")", ".", "split", "(", "\"\\n\"", ")", "[", "1", ":", "-", "1", "]", "\n", "", "bpe_merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", ")", "for", "merge", "in", "bpe_merges", "]", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "bpe_merges", ",", "range", "(", "len", "(", "bpe_merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n", "# Should haved added re.IGNORECASE so BPE merges can happen for capitalized versions of contractions", "\n", "self", ".", "pat", "=", "re", ".", "compile", "(", "r\"\"\"'s|'t|'re|'ve|'m|'ll|'d| ?\\p{L}+| ?\\p{N}+| ?[^\\s\\p{L}\\p{N}]+|\\s+(?!\\S)|\\s+\"\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_gpt2.GPT2Tokenizer.vocab_size": [[148, 151], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_gpt2.GPT2Tokenizer.bpe": [[152, 193], ["tuple", "tokenization_gpt2.get_pairs", "min", "tuple", "len", "len", "tokenization_gpt2.get_pairs", "tuple.index", "tuple.extend", "tuple.append", "tuple.append", "tokenization_gpt2.GPT2Tokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.get_pairs", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.get_pairs"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "word", "=", "tuple", "(", "token", ")", "\n", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "\"inf\"", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "", "except", "ValueError", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "\" \"", ".", "join", "(", "word", ")", "\n", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_gpt2.GPT2Tokenizer._tokenize": [[194, 210], ["regex.findall", "bpe_tokens.extend", "token.encode", "tokenization_gpt2.GPT2Tokenizer.bpe().split", "tokenization_gpt2.GPT2Tokenizer.bpe"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.encode", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.bpe"], ["", "def", "_tokenize", "(", "self", ",", "text", ",", "add_prefix_space", "=", "False", ")", ":", "\n", "        ", "\"\"\" Tokenize a string.\n            Args:\n                - add_prefix_space (boolean, default False):\n                    Begin the sentence with at least one space to get invariance to word order in GPT-2 (and RoBERTa) tokenizers.\n        \"\"\"", "\n", "if", "add_prefix_space", ":", "\n", "            ", "text", "=", "\" \"", "+", "text", "\n", "\n", "", "bpe_tokens", "=", "[", "]", "\n", "for", "token", "in", "re", ".", "findall", "(", "self", ".", "pat", ",", "text", ")", ":", "\n", "            ", "token", "=", "\"\"", ".", "join", "(", "\n", "self", ".", "byte_encoder", "[", "b", "]", "for", "b", "in", "token", ".", "encode", "(", "\"utf-8\"", ")", "\n", ")", "# Maps all our bytes to unicode strings, avoiding controle tokens of the BPE (spaces in our case)", "\n", "bpe_tokens", ".", "extend", "(", "bpe_token", "for", "bpe_token", "in", "self", ".", "bpe", "(", "token", ")", ".", "split", "(", "\" \"", ")", ")", "\n", "", "return", "bpe_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_gpt2.GPT2Tokenizer._convert_token_to_id": [[211, 214], ["tokenization_gpt2.GPT2Tokenizer.encoder.get", "tokenization_gpt2.GPT2Tokenizer.encoder.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "encoder", ".", "get", "(", "token", ",", "self", ".", "encoder", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_gpt2.GPT2Tokenizer._convert_id_to_token": [[215, 218], ["tokenization_gpt2.GPT2Tokenizer.decoder.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an index (integer) in a token (str) using the vocab.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "get", "(", "index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_gpt2.GPT2Tokenizer.convert_tokens_to_string": [[219, 224], ["bytearray().decode", "bytearray"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.decode"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "text", "=", "\"\"", ".", "join", "(", "tokens", ")", "\n", "text", "=", "bytearray", "(", "[", "self", ".", "byte_decoder", "[", "c", "]", "for", "c", "in", "text", "]", ")", ".", "decode", "(", "\"utf-8\"", ",", "errors", "=", "self", ".", "errors", ")", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_gpt2.GPT2Tokenizer.save_vocabulary": [[225, 250], ["os.path.join", "os.path.join", "os.path.isdir", "logger.error", "open", "f.write", "open", "writer.write", "sorted", "json.dumps", "tokenization_gpt2.GPT2Tokenizer.bpe_ranks.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary and merge files to a directory.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "merge_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "\"merges_file\"", "]", ")", "\n", "\n", "with", "open", "(", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "encoder", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "index", "=", "0", "\n", "with", "open", "(", "merge_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "\"#version: 0.2\\n\"", ")", "\n", "for", "bpe_tokens", ",", "token_index", "in", "sorted", "(", "self", ".", "bpe_ranks", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"Saving vocabulary to {}: BPE merge indices are not consecutive.\"", "\n", "\" Please check that the tokenizer is not corrupted!\"", ".", "format", "(", "merge_file", ")", "\n", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "\" \"", ".", "join", "(", "bpe_tokens", ")", "+", "\"\\n\"", ")", "\n", "index", "+=", "1", "\n", "\n", "", "", "return", "vocab_file", ",", "merge_file", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_gpt2.GPT2TokenizerFast.__init__": [[257, 287], ["tokenization_utils.PreTrainedTokenizerFast.__init__", "tokenizers.Tokenizer", "tokenization_gpt2.GPT2TokenizerFast._update_special_tokens", "tokenization_gpt2.GPT2TokenizerFast._tokenizer.with_pre_tokenizer", "tokenization_gpt2.GPT2TokenizerFast._tokenizer.with_decoder", "tokenization_gpt2.GPT2TokenizerFast._tokenizer.with_padding", "tokenizers.decoders.ByteLevel.new", "tokenizers.models.BPE.from_files", "tokenizers.pre_tokenizers.ByteLevel.new", "tokenizers.decoders.ByteLevel.new", "tokenization_gpt2.GPT2TokenizerFast._tokenizer.with_truncation"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_file", ",", "\n", "merges_file", ",", "\n", "unk_token", "=", "\"<|endoftext|>\"", ",", "\n", "bos_token", "=", "\"<|endoftext|>\"", ",", "\n", "eos_token", "=", "\"<|endoftext|>\"", ",", "\n", "pad_to_max_length", "=", "False", ",", "\n", "add_prefix_space", "=", "False", ",", "\n", "max_length", "=", "None", ",", "\n", "stride", "=", "0", ",", "\n", "truncation_strategy", "=", "\"longest_first\"", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "bos_token", "=", "bos_token", ",", "eos_token", "=", "eos_token", ",", "unk_token", "=", "unk_token", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "_tokenizer", "=", "tk", ".", "Tokenizer", "(", "tk", ".", "models", ".", "BPE", ".", "from_files", "(", "vocab_file", ",", "merges_file", ")", ")", "\n", "self", ".", "_update_special_tokens", "(", ")", "\n", "self", ".", "_tokenizer", ".", "with_pre_tokenizer", "(", "tk", ".", "pre_tokenizers", ".", "ByteLevel", ".", "new", "(", "add_prefix_space", "=", "add_prefix_space", ")", ")", "\n", "self", ".", "_tokenizer", ".", "with_decoder", "(", "tk", ".", "decoders", ".", "ByteLevel", ".", "new", "(", ")", ")", "\n", "if", "max_length", ":", "\n", "            ", "self", ".", "_tokenizer", ".", "with_truncation", "(", "max_length", ",", "stride", "=", "stride", ",", "strategy", "=", "truncation_strategy", ")", "\n", "", "self", ".", "_tokenizer", ".", "with_padding", "(", "\n", "max_length", "=", "max_length", "if", "pad_to_max_length", "else", "None", ",", "\n", "direction", "=", "self", ".", "padding_side", ",", "\n", "pad_id", "=", "self", ".", "pad_token_id", "if", "self", ".", "pad_token_id", "is", "not", "None", "else", "0", ",", "\n", "pad_type_id", "=", "self", ".", "pad_token_type_id", ",", "\n", "pad_token", "=", "self", ".", "pad_token", "if", "self", ".", "pad_token", "is", "not", "None", "else", "\"\"", ",", "\n", ")", "\n", "self", ".", "_decoder", "=", "tk", ".", "decoders", ".", "ByteLevel", ".", "new", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_gpt2.bytes_to_unicode": [[62, 86], ["functools.lru_cache", "range", "dict", "list", "chr", "zip", "list", "list", "range", "bs.append", "cs.append", "range", "range", "ord", "ord", "ord", "ord", "ord", "ord"], "function", ["None"], ["@", "lru_cache", "(", ")", "\n", "def", "bytes_to_unicode", "(", ")", ":", "\n", "    ", "\"\"\"\n    Returns list of utf-8 byte and a mapping to unicode strings.\n    We specifically avoids mapping to whitespace/control characters the bpe code barfs on.\n\n    The reversible bpe codes work on unicode strings.\n    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n    This is a signficant percentage of your normal, say, 32K bpe vocab.\n    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n    \"\"\"", "\n", "bs", "=", "(", "\n", "list", "(", "range", "(", "ord", "(", "\"!\"", ")", ",", "ord", "(", "\"~\"", ")", "+", "1", ")", ")", "+", "list", "(", "range", "(", "ord", "(", "\"\u00a1\"", ")", ",", "ord", "(", "\"\u00ac\"", ")", "+", "1", ")", ")", "+", "list", "(", "range", "(", "ord", "(", "\"\u00ae\"", ")", ",", "ord", "(", "\"\u00ff\"", ")", "+", "1", ")", ")", "\n", ")", "\n", "cs", "=", "bs", "[", ":", "]", "\n", "n", "=", "0", "\n", "for", "b", "in", "range", "(", "2", "**", "8", ")", ":", "\n", "        ", "if", "b", "not", "in", "bs", ":", "\n", "            ", "bs", ".", "append", "(", "b", ")", "\n", "cs", ".", "append", "(", "2", "**", "8", "+", "n", ")", "\n", "n", "+=", "1", "\n", "", "", "cs", "=", "[", "chr", "(", "n", ")", "for", "n", "in", "cs", "]", "\n", "return", "dict", "(", "zip", "(", "bs", ",", "cs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_gpt2.get_pairs": [[88, 99], ["set", "set.add"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.BeamHypotheses.add"], ["", "def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"Return set of symbol pairs in a word.\n\n    Word is represented as tuple of symbols (symbols being variable-length strings).\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.is_torch_available": [[98, 100], ["None"], "function", ["None"], ["def", "is_torch_available", "(", ")", ":", "\n", "    ", "return", "_torch_available", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.is_tf_available": [[102, 104], ["None"], "function", ["None"], ["", "def", "is_tf_available", "(", ")", ":", "\n", "    ", "return", "_tf_available", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.add_start_docstrings": [[106, 112], ["None"], "function", ["None"], ["", "def", "add_start_docstrings", "(", "*", "docstr", ")", ":", "\n", "    ", "def", "docstring_decorator", "(", "fn", ")", ":", "\n", "        ", "fn", ".", "__doc__", "=", "\"\"", ".", "join", "(", "docstr", ")", "+", "fn", ".", "__doc__", "\n", "return", "fn", "\n", "\n", "", "return", "docstring_decorator", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.add_end_docstrings": [[114, 120], ["None"], "function", ["None"], ["", "def", "add_end_docstrings", "(", "*", "docstr", ")", ":", "\n", "    ", "def", "docstring_decorator", "(", "fn", ")", ":", "\n", "        ", "fn", ".", "__doc__", "=", "fn", ".", "__doc__", "+", "\"\"", ".", "join", "(", "docstr", ")", "\n", "return", "fn", "\n", "\n", "", "return", "docstring_decorator", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.is_remote_url": [[122, 125], ["urllib.parse.urlparse"], "function", ["None"], ["", "def", "is_remote_url", "(", "url_or_filename", ")", ":", "\n", "    ", "parsed", "=", "urlparse", "(", "url_or_filename", ")", "\n", "return", "parsed", ".", "scheme", "in", "(", "\"http\"", ",", "\"https\"", ",", "\"s3\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.hf_bucket_url": [[127, 133], ["None"], "function", ["None"], ["", "def", "hf_bucket_url", "(", "identifier", ",", "postfix", "=", "None", ",", "cdn", "=", "False", ")", "->", "str", ":", "\n", "    ", "endpoint", "=", "CLOUDFRONT_DISTRIB_PREFIX", "if", "cdn", "else", "S3_BUCKET_PREFIX", "\n", "if", "postfix", "is", "None", ":", "\n", "        ", "return", "\"/\"", ".", "join", "(", "(", "endpoint", ",", "identifier", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "\"/\"", ".", "join", "(", "(", "endpoint", ",", "identifier", ",", "postfix", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.url_to_filename": [[135, 157], ["url.encode", "hashlib.sha256", "hashlib.sha256.hexdigest", "url.endswith", "etag.encode", "hashlib.sha256", "hashlib.sha256.hexdigest"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.encode", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.encode"], ["", "", "def", "url_to_filename", "(", "url", ",", "etag", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Convert `url` into a hashed filename in a repeatable way.\n    If `etag` is specified, append its hash to the url's, delimited\n    by a period.\n    If the url ends with .h5 (Keras HDF5 weights) adds '.h5' to the name\n    so that TF 2.0 can identify it as a HDF5 file\n    (see https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/python/keras/engine/network.py#L1380)\n    \"\"\"", "\n", "url_bytes", "=", "url", ".", "encode", "(", "\"utf-8\"", ")", "\n", "url_hash", "=", "sha256", "(", "url_bytes", ")", "\n", "filename", "=", "url_hash", ".", "hexdigest", "(", ")", "\n", "\n", "if", "etag", ":", "\n", "        ", "etag_bytes", "=", "etag", ".", "encode", "(", "\"utf-8\"", ")", "\n", "etag_hash", "=", "sha256", "(", "etag_bytes", ")", "\n", "filename", "+=", "\".\"", "+", "etag_hash", ".", "hexdigest", "(", ")", "\n", "\n", "", "if", "url", ".", "endswith", "(", "\".h5\"", ")", ":", "\n", "        ", "filename", "+=", "\".h5\"", "\n", "\n", "", "return", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.filename_to_url": [[159, 183], ["isinstance", "os.path.join", "str", "os.path.exists", "EnvironmentError", "os.path.exists", "EnvironmentError", "open", "json.load"], "function", ["None"], ["", "def", "filename_to_url", "(", "filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Return the url and etag (which may be ``None``) stored for `filename`.\n    Raise ``EnvironmentError`` if `filename` or its stored metadata do not exist.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "TRANSFORMERS_CACHE", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "cache_path", ")", ")", "\n", "\n", "", "meta_path", "=", "cache_path", "+", "\".json\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "meta_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "meta_path", ")", ")", "\n", "\n", "", "with", "open", "(", "meta_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "meta_file", ":", "\n", "        ", "metadata", "=", "json", ".", "load", "(", "meta_file", ")", "\n", "", "url", "=", "metadata", "[", "\"url\"", "]", "\n", "etag", "=", "metadata", "[", "\"etag\"", "]", "\n", "\n", "return", "url", ",", "etag", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.cached_path": [[185, 229], ["isinstance", "isinstance", "file_utils.is_remote_url", "str", "str", "file_utils.get_from_cache", "os.path.exists", "EnvironmentError", "ValueError", "urllib.parse.urlparse"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.is_remote_url", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.get_from_cache"], ["", "def", "cached_path", "(", "\n", "url_or_filename", ",", "cache_dir", "=", "None", ",", "force_download", "=", "False", ",", "proxies", "=", "None", ",", "resume_download", "=", "False", ",", "user_agent", "=", "None", "\n", ")", "->", "Optional", "[", "str", "]", ":", "\n", "    ", "\"\"\"\n    Given something that might be a URL (or might be a local path),\n    determine which. If it's a URL, download the file and cache it, and\n    return the path to the cached file. If it's already a local path,\n    make sure the file exists and then return the path.\n    Args:\n        cache_dir: specify a cache directory to save the file to (overwrite the default cache dir).\n        force_download: if True, re-dowload the file even if it's already cached in the cache dir.\n        resume_download: if True, resume the download if incompletly recieved file is found.\n        user_agent: Optional string or dict that will be appended to the user-agent on remote requests.\n\n    Return:\n        None in case of non-recoverable file (non-existent or inaccessible url + no cache on disk).\n        Local path (string) otherwise\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "TRANSFORMERS_CACHE", "\n", "", "if", "isinstance", "(", "url_or_filename", ",", "Path", ")", ":", "\n", "        ", "url_or_filename", "=", "str", "(", "url_or_filename", ")", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "if", "is_remote_url", "(", "url_or_filename", ")", ":", "\n", "# URL, so get it from the cache (downloading if necessary)", "\n", "        ", "return", "get_from_cache", "(", "\n", "url_or_filename", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", "force_download", "=", "force_download", ",", "\n", "proxies", "=", "proxies", ",", "\n", "resume_download", "=", "resume_download", ",", "\n", "user_agent", "=", "user_agent", ",", "\n", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "url_or_filename", ")", ":", "\n", "# File, and it exists.", "\n", "        ", "return", "url_or_filename", "\n", "", "elif", "urlparse", "(", "url_or_filename", ")", ".", "scheme", "==", "\"\"", ":", "\n", "# File, but it doesn't exist.", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "", "else", ":", "\n", "# Something unknown", "\n", "        ", "raise", "ValueError", "(", "\"unable to parse {} as a URL or as a local path\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.split_s3_path": [[231, 242], ["urllib.parse.urlparse", "s3_path.startswith", "ValueError"], "function", ["None"], ["", "", "def", "split_s3_path", "(", "url", ")", ":", "\n", "    ", "\"\"\"Split a full s3 path into the bucket name and path.\"\"\"", "\n", "parsed", "=", "urlparse", "(", "url", ")", "\n", "if", "not", "parsed", ".", "netloc", "or", "not", "parsed", ".", "path", ":", "\n", "        ", "raise", "ValueError", "(", "\"bad s3 path {}\"", ".", "format", "(", "url", ")", ")", "\n", "", "bucket_name", "=", "parsed", ".", "netloc", "\n", "s3_path", "=", "parsed", ".", "path", "\n", "# Remove '/' at beginning of path.", "\n", "if", "s3_path", ".", "startswith", "(", "\"/\"", ")", ":", "\n", "        ", "s3_path", "=", "s3_path", "[", "1", ":", "]", "\n", "", "return", "bucket_name", ",", "s3_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.s3_request": [[244, 261], ["functools.wraps", "func", "int", "EnvironmentError"], "function", ["None"], ["", "def", "s3_request", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper function for s3 requests in order to create more helpful error\n    messages.\n    \"\"\"", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "func", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "ClientError", "as", "exc", ":", "\n", "            ", "if", "int", "(", "exc", ".", "response", "[", "\"Error\"", "]", "[", "\"Code\"", "]", ")", "==", "404", ":", "\n", "                ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "\n", "", "", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.s3_etag": [[263, 270], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Object", "botocore.config.Config"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_etag", "(", "url", ",", "proxies", "=", "None", ")", ":", "\n", "    ", "\"\"\"Check ETag on S3 object.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ",", "config", "=", "Config", "(", "proxies", "=", "proxies", ")", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_object", "=", "s3_resource", ".", "Object", "(", "bucket_name", ",", "s3_path", ")", "\n", "return", "s3_object", ".", "e_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.s3_get": [[272, 278], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Bucket().download_fileobj", "botocore.config.Config", "boto3.resource.Bucket"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_get", "(", "url", ",", "temp_file", ",", "proxies", "=", "None", ")", ":", "\n", "    ", "\"\"\"Pull a file directly from S3.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ",", "config", "=", "Config", "(", "proxies", "=", "proxies", ")", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_resource", ".", "Bucket", "(", "bucket_name", ")", ".", "download_fileobj", "(", "s3_path", ",", "temp_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.http_get": [[280, 311], ["file_utils.is_torch_available", "file_utils.is_tf_available", "isinstance", "requests.get", "requests.get.headers.get", "tqdm.auto.tqdm", "requests.get.iter_content", "tqdm.auto.tqdm.close", "isinstance", "sys.version.split", "int", "bool", "tqdm.auto.tqdm.update", "temp_file.write", "len", "logger.getEffectiveLevel", "user_agent.items"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.is_torch_available", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.is_tf_available"], ["", "def", "http_get", "(", "url", ",", "temp_file", ",", "proxies", "=", "None", ",", "resume_size", "=", "0", ",", "user_agent", "=", "None", ")", ":", "\n", "    ", "ua", "=", "\"transformers/{}; python/{}\"", ".", "format", "(", "__version__", ",", "sys", ".", "version", ".", "split", "(", ")", "[", "0", "]", ")", "\n", "if", "is_torch_available", "(", ")", ":", "\n", "        ", "ua", "+=", "\"; torch/{}\"", ".", "format", "(", "torch", ".", "__version__", ")", "\n", "", "if", "is_tf_available", "(", ")", ":", "\n", "        ", "ua", "+=", "\"; tensorflow/{}\"", ".", "format", "(", "tf", ".", "__version__", ")", "\n", "", "if", "isinstance", "(", "user_agent", ",", "dict", ")", ":", "\n", "        ", "ua", "+=", "\"; \"", "+", "\"; \"", ".", "join", "(", "\"{}/{}\"", ".", "format", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "user_agent", ".", "items", "(", ")", ")", "\n", "", "elif", "isinstance", "(", "user_agent", ",", "str", ")", ":", "\n", "        ", "ua", "+=", "\"; \"", "+", "user_agent", "\n", "", "headers", "=", "{", "\"user-agent\"", ":", "ua", "}", "\n", "if", "resume_size", ">", "0", ":", "\n", "        ", "headers", "[", "\"Range\"", "]", "=", "\"bytes=%d-\"", "%", "(", "resume_size", ",", ")", "\n", "", "response", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ",", "proxies", "=", "proxies", ",", "headers", "=", "headers", ")", "\n", "if", "response", ".", "status_code", "==", "416", ":", "# Range not satisfiable", "\n", "        ", "return", "\n", "", "content_length", "=", "response", ".", "headers", ".", "get", "(", "\"Content-Length\"", ")", "\n", "total", "=", "resume_size", "+", "int", "(", "content_length", ")", "if", "content_length", "is", "not", "None", "else", "None", "\n", "progress", "=", "tqdm", "(", "\n", "unit", "=", "\"B\"", ",", "\n", "unit_scale", "=", "True", ",", "\n", "total", "=", "total", ",", "\n", "initial", "=", "resume_size", ",", "\n", "desc", "=", "\"Downloading\"", ",", "\n", "disable", "=", "bool", "(", "logger", ".", "getEffectiveLevel", "(", ")", "==", "logging", ".", "NOTSET", ")", ",", "\n", ")", "\n", "for", "chunk", "in", "response", ".", "iter_content", "(", "chunk_size", "=", "1024", ")", ":", "\n", "        ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "            ", "progress", ".", "update", "(", "len", "(", "chunk", ")", ")", "\n", "temp_file", ".", "write", "(", "chunk", ")", "\n", "", "", "progress", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.get_from_cache": [[313, 413], ["isinstance", "os.makedirs", "url.startswith", "file_utils.url_to_filename", "os.path.join", "str", "file_utils.s3_etag", "os.path.exists", "os.path.exists", "filelock.FileLock", "logger.info", "os.rename", "logger.info", "requests.head", "os.path.exists", "functools.partial", "functools.partial.", "logger.info", "url.startswith", "open", "json.dump", "requests.head.headers.get", "len", "os.path.join", "file_utils.s3_get", "file_utils.http_get", "fnmatch.filter", "open", "os.stat", "logger.warn", "os.listdir", "file.endswith", "file.endswith"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.url_to_filename", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.s3_etag", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.s3_get", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.http_get"], ["", "def", "get_from_cache", "(", "\n", "url", ",", "cache_dir", "=", "None", ",", "force_download", "=", "False", ",", "proxies", "=", "None", ",", "etag_timeout", "=", "10", ",", "resume_download", "=", "False", ",", "user_agent", "=", "None", "\n", ")", "->", "Optional", "[", "str", "]", ":", "\n", "    ", "\"\"\"\n    Given a URL, look for the corresponding file in the local cache.\n    If it's not there, download it. Then return the path to the cached file.\n\n    Return:\n        None in case of non-recoverable file (non-existent or inaccessible url + no cache on disk).\n        Local path (string) otherwise\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "TRANSFORMERS_CACHE", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "os", ".", "makedirs", "(", "cache_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Get eTag to add to filename, if it exists.", "\n", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "        ", "etag", "=", "s3_etag", "(", "url", ",", "proxies", "=", "proxies", ")", "\n", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "response", "=", "requests", ".", "head", "(", "url", ",", "allow_redirects", "=", "True", ",", "proxies", "=", "proxies", ",", "timeout", "=", "etag_timeout", ")", "\n", "if", "response", ".", "status_code", "!=", "200", ":", "\n", "                ", "etag", "=", "None", "\n", "", "else", ":", "\n", "                ", "etag", "=", "response", ".", "headers", ".", "get", "(", "\"ETag\"", ")", "\n", "", "", "except", "(", "EnvironmentError", ",", "requests", ".", "exceptions", ".", "Timeout", ")", ":", "\n", "            ", "etag", "=", "None", "\n", "\n", "", "", "filename", "=", "url_to_filename", "(", "url", ",", "etag", ")", "\n", "\n", "# get cache path to put the file", "\n", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "\n", "# etag is None = we don't have a connection, or url doesn't exist, or is otherwise inaccessible.", "\n", "# try to get the last downloaded one", "\n", "if", "etag", "is", "None", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "            ", "return", "cache_path", "\n", "", "else", ":", "\n", "            ", "matching_files", "=", "[", "\n", "file", "\n", "for", "file", "in", "fnmatch", ".", "filter", "(", "os", ".", "listdir", "(", "cache_dir", ")", ",", "filename", "+", "\".*\"", ")", "\n", "if", "not", "file", ".", "endswith", "(", "\".json\"", ")", "and", "not", "file", ".", "endswith", "(", "\".lock\"", ")", "\n", "]", "\n", "if", "len", "(", "matching_files", ")", ">", "0", ":", "\n", "                ", "return", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "matching_files", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "return", "None", "\n", "\n", "# From now on, etag is not None.", "\n", "", "", "", "if", "os", ".", "path", ".", "exists", "(", "cache_path", ")", "and", "not", "force_download", ":", "\n", "        ", "return", "cache_path", "\n", "\n", "# Prevent parallel downloads of the same file with a lock.", "\n", "", "lock_path", "=", "cache_path", "+", "\".lock\"", "\n", "with", "FileLock", "(", "lock_path", ")", ":", "\n", "\n", "        ", "if", "resume_download", ":", "\n", "            ", "incomplete_path", "=", "cache_path", "+", "\".incomplete\"", "\n", "\n", "@", "contextmanager", "\n", "def", "_resumable_file_manager", "(", ")", ":", "\n", "                ", "with", "open", "(", "incomplete_path", ",", "\"a+b\"", ")", "as", "f", ":", "\n", "                    ", "yield", "f", "\n", "\n", "", "", "temp_file_manager", "=", "_resumable_file_manager", "\n", "if", "os", ".", "path", ".", "exists", "(", "incomplete_path", ")", ":", "\n", "                ", "resume_size", "=", "os", ".", "stat", "(", "incomplete_path", ")", ".", "st_size", "\n", "", "else", ":", "\n", "                ", "resume_size", "=", "0", "\n", "", "", "else", ":", "\n", "            ", "temp_file_manager", "=", "partial", "(", "tempfile", ".", "NamedTemporaryFile", ",", "dir", "=", "cache_dir", ",", "delete", "=", "False", ")", "\n", "resume_size", "=", "0", "\n", "\n", "# Download to temporary file, then copy to cache dir once finished.", "\n", "# Otherwise you get corrupt cache entries if the download gets interrupted.", "\n", "", "with", "temp_file_manager", "(", ")", "as", "temp_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"%s not found in cache or force_download set to True, downloading to %s\"", ",", "url", ",", "temp_file", ".", "name", ")", "\n", "\n", "# GET file object", "\n", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "                ", "if", "resume_download", ":", "\n", "                    ", "logger", ".", "warn", "(", "'Warning: resumable downloads are not implemented for \"s3://\" urls'", ")", "\n", "", "s3_get", "(", "url", ",", "temp_file", ",", "proxies", "=", "proxies", ")", "\n", "", "else", ":", "\n", "                ", "http_get", "(", "url", ",", "temp_file", ",", "proxies", "=", "proxies", ",", "resume_size", "=", "resume_size", ",", "user_agent", "=", "user_agent", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"storing %s in cache at %s\"", ",", "url", ",", "cache_path", ")", "\n", "os", ".", "rename", "(", "temp_file", ".", "name", ",", "cache_path", ")", "\n", "\n", "logger", ".", "info", "(", "\"creating metadata file for %s\"", ",", "cache_path", ")", "\n", "meta", "=", "{", "\"url\"", ":", "url", ",", "\"etag\"", ":", "etag", "}", "\n", "meta_path", "=", "cache_path", "+", "\".json\"", "\n", "with", "open", "(", "meta_path", ",", "\"w\"", ")", "as", "meta_file", ":", "\n", "            ", "json", ".", "dump", "(", "meta", ",", "meta_file", ")", "\n", "\n", "", "", "return", "cache_path", "\n", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.Attention.__init__": [[103, 120], ["torch.Module.__init__", "gpt2.Attention.register_buffer", "modeling_utils.Conv1D", "modeling_utils.Conv1D", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "set", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "n_state", "=", "nx", "# in Attention: n_state=768 (nx=n_embd)", "\n", "# [switch nx => n_state from Block to Attention to keep identical to TF implem]", "\n", "assert", "n_state", "%", "config", ".", "n_head", "==", "0", "\n", "self", ".", "register_buffer", "(", "\"bias\"", ",", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "n_ctx", ",", "n_ctx", ")", ")", ".", "view", "(", "1", ",", "1", ",", "n_ctx", ",", "n_ctx", ")", ")", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "split_size", "=", "n_state", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "self", ".", "c_attn", "=", "Conv1D", "(", "n_state", "*", "3", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "attn_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attn_pdrop", ")", "\n", "self", ".", "resid_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.Attention.prune_heads": [[121, 142], ["torch.ones", "torch.ones", "torch.ones", "torch.ones", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous().eq", "[].long", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_utils.prune_conv1d_layer", "modeling_utils.prune_conv1d_layer", "gpt2.Attention.pruned_heads.union", "len", "set", "len", "sum", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous", "len", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "mask.view().contiguous().eq.view().contiguous().eq.view", "len"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.prune_conv1d_layer", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.prune_conv1d_layer"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "mask", "=", "torch", ".", "ones", "(", "self", ".", "n_head", ",", "self", ".", "split_size", "//", "self", ".", "n_head", ")", "\n", "heads", "=", "set", "(", "heads", ")", "-", "self", ".", "pruned_heads", "# Convert to set and emove already pruned heads", "\n", "for", "head", "in", "heads", ":", "\n", "# Compute how many pruned heads are before the head and move the index accordingly", "\n", "            ", "head", "=", "head", "-", "sum", "(", "1", "if", "h", "<", "head", "else", "0", "for", "h", "in", "self", ".", "pruned_heads", ")", "\n", "mask", "[", "head", "]", "=", "0", "\n", "", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "eq", "(", "1", ")", "\n", "index", "=", "torch", ".", "arange", "(", "len", "(", "mask", ")", ")", "[", "mask", "]", ".", "long", "(", ")", "\n", "index_attn", "=", "torch", ".", "cat", "(", "[", "index", ",", "index", "+", "self", ".", "split_size", ",", "index", "+", "(", "2", "*", "self", ".", "split_size", ")", "]", ")", "\n", "\n", "# Prune conv1d layers", "\n", "self", ".", "c_attn", "=", "prune_conv1d_layer", "(", "self", ".", "c_attn", ",", "index_attn", ",", "dim", "=", "1", ")", "\n", "self", ".", "c_proj", "=", "prune_conv1d_layer", "(", "self", ".", "c_proj", ",", "index", ",", "dim", "=", "0", ")", "\n", "\n", "# Update hyper params", "\n", "self", ".", "split_size", "=", "(", "self", ".", "split_size", "//", "self", ".", "n_head", ")", "*", "(", "self", ".", "n_head", "-", "len", "(", "heads", ")", ")", "\n", "self", ".", "n_head", "=", "self", ".", "n_head", "-", "len", "(", "heads", ")", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.Attention._attn": [[143, 166], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "gpt2.Attention.attn_dropout", "gpt2.Attention.size", "gpt2.Attention.size", "torch.Softmax", "torch.Softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "outputs.append", "math.sqrt", "v.size"], "methods", ["None"], ["", "def", "_attn", "(", "self", ",", "q", ",", "k", ",", "v", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "w", "=", "torch", ".", "matmul", "(", "q", ",", "k", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "w", "=", "w", "/", "math", ".", "sqrt", "(", "v", ".", "size", "(", "-", "1", ")", ")", "\n", "", "nd", ",", "ns", "=", "w", ".", "size", "(", "-", "2", ")", ",", "w", ".", "size", "(", "-", "1", ")", "\n", "b", "=", "self", ".", "bias", "[", ":", ",", ":", ",", "ns", "-", "nd", ":", "ns", ",", ":", "ns", "]", "\n", "w", "=", "w", "*", "b", "-", "1e4", "*", "(", "1", "-", "b", ")", "\n", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask", "\n", "            ", "w", "=", "w", "+", "attention_mask", "\n", "\n", "", "w", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "w", ")", "\n", "w", "=", "self", ".", "attn_dropout", "(", "w", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "w", "=", "w", "*", "head_mask", "\n", "\n", "", "outputs", "=", "[", "torch", ".", "matmul", "(", "w", ",", "v", ")", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "w", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.Attention.merge_heads": [[167, 171], ["x.permute().contiguous.permute().contiguous.permute().contiguous", "x.permute().contiguous.permute().contiguous.view", "x.permute().contiguous.permute().contiguous.permute", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size"], "methods", ["None"], ["", "def", "merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "x", ".", "size", "(", "-", "2", ")", "*", "x", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "return", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct merge_states", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.Attention.split_heads": [[172, 179], ["x.view.view.view", "x.view.view.permute", "x.view.view.permute", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "split_heads", "(", "self", ",", "x", ",", "k", "=", "False", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "n_head", ",", "x", ".", "size", "(", "-", "1", ")", "//", "self", ".", "n_head", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct split_states", "\n", "if", "k", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "# (batch, head, head_features, seq_length)", "\n", "", "else", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "# (batch, head, seq_length, head_features)", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.Attention.forward": [[180, 201], ["gpt2.Attention.c_attn", "gpt2.Attention.split", "gpt2.Attention.split_heads", "gpt2.Attention.split_heads", "gpt2.Attention.split_heads", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "gpt2.Attention._attn", "gpt2.Attention.merge_heads", "gpt2.Attention.c_proj", "gpt2.Attention.resid_dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "layer_past[].transpose", "torch.cat.transpose", "torch.cat.transpose"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Attention.split_heads", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Attention.split_heads", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Attention.split_heads", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Attention._attn", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Attention.merge_heads"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "layer_past", "=", "None", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "x", "=", "self", ".", "c_attn", "(", "x", ")", "\n", "query", ",", "key", ",", "value", "=", "x", ".", "split", "(", "self", ".", "split_size", ",", "dim", "=", "2", ")", "\n", "query", "=", "self", ".", "split_heads", "(", "query", ")", "\n", "key", "=", "self", ".", "split_heads", "(", "key", ",", "k", "=", "True", ")", "\n", "value", "=", "self", ".", "split_heads", "(", "value", ")", "\n", "if", "layer_past", "is", "not", "None", ":", "\n", "            ", "past_key", ",", "past_value", "=", "layer_past", "[", "0", "]", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "layer_past", "[", "1", "]", "# transpose back cf below", "\n", "key", "=", "torch", ".", "cat", "(", "(", "past_key", ",", "key", ")", ",", "dim", "=", "-", "1", ")", "\n", "value", "=", "torch", ".", "cat", "(", "(", "past_value", ",", "value", ")", ",", "dim", "=", "-", "2", ")", "\n", "", "present", "=", "torch", ".", "stack", "(", "(", "key", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "value", ")", ")", "# transpose to have same shapes for stacking", "\n", "\n", "attn_outputs", "=", "self", ".", "_attn", "(", "query", ",", "key", ",", "value", ",", "attention_mask", ",", "head_mask", ")", "\n", "a", "=", "attn_outputs", "[", "0", "]", "\n", "\n", "a", "=", "self", ".", "merge_heads", "(", "a", ")", "\n", "a", "=", "self", ".", "c_proj", "(", "a", ")", "\n", "a", "=", "self", ".", "resid_dropout", "(", "a", ")", "\n", "\n", "outputs", "=", "[", "a", ",", "present", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "# a, present, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.MLP.__init__": [[204, 211], ["torch.Module.__init__", "modeling_utils.Conv1D", "modeling_utils.Conv1D", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_state", ",", "config", ")", ":", "# in MLP: n_state=3072 (4 * n_embd)", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "c_fc", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "nx", ",", "n_state", ")", "\n", "self", ".", "act", "=", "gelu", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.MLP.forward": [[212, 216], ["gpt2.MLP.act", "gpt2.MLP.c_proj", "gpt2.MLP.dropout", "gpt2.MLP.c_fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "act", "(", "self", ".", "c_fc", "(", "x", ")", ")", "\n", "h2", "=", "self", ".", "c_proj", "(", "h", ")", "\n", "return", "self", ".", "dropout", "(", "h2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.Block.__init__": [[219, 226], ["torch.Module.__init__", "torch.LayerNorm", "torch.LayerNorm", "gpt2.Attention", "torch.LayerNorm", "torch.LayerNorm", "gpt2.MLP"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "ln_1", "=", "nn", ".", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "attn", "=", "Attention", "(", "nx", ",", "n_ctx", ",", "config", ",", "scale", ")", "\n", "self", ".", "ln_2", "=", "nn", ".", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "mlp", "=", "MLP", "(", "4", "*", "nx", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.Block.forward": [[227, 239], ["gpt2.Block.attn", "gpt2.Block.mlp", "gpt2.Block.ln_1", "gpt2.Block.ln_2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "layer_past", "=", "None", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "output_attn", "=", "self", ".", "attn", "(", "\n", "self", ".", "ln_1", "(", "x", ")", ",", "layer_past", "=", "layer_past", ",", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", "\n", ")", "\n", "a", "=", "output_attn", "[", "0", "]", "# output_attn: a, present, (attentions)", "\n", "\n", "x", "=", "x", "+", "a", "\n", "m", "=", "self", ".", "mlp", "(", "self", ".", "ln_2", "(", "x", ")", ")", "\n", "x", "=", "x", "+", "m", "\n", "\n", "outputs", "=", "[", "x", "]", "+", "output_attn", "[", "1", ":", "]", "\n", "return", "outputs", "# x, present, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.GPT2PreTrainedModel.__init__": [[251, 253], ["modeling_utils.PreTrainedModel.__init__"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["def", "__init__", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.GPT2PreTrainedModel._init_weights": [[254, 266], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ",", "Conv1D", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "Conv1D", ")", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.GPT2Model.__init__": [[357, 370], ["gpt2.GPT2PreTrainedModel.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.LayerNorm", "torch.LayerNorm", "gpt2.GPT2Model.init_weights", "gpt2.Block", "range"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_past", "=", "config", ".", "output_past", "\n", "\n", "self", ".", "wte", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "wpe", "=", "nn", ".", "Embedding", "(", "config", ".", "n_positions", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "self", ".", "h", "=", "nn", ".", "ModuleList", "(", "[", "Block", "(", "config", ".", "n_ctx", ",", "config", ",", "scale", "=", "True", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "self", ".", "ln_f", "=", "nn", ".", "LayerNorm", "(", "config", ".", "n_embd", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.GPT2Model.get_input_embeddings": [[371, 373], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "wte", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.GPT2Model.set_input_embeddings": [[374, 376], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "wte", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.GPT2Model._prune_heads": [[377, 383], ["heads_to_prune.items", "gpt2.GPT2Model.h[].attn.prune_heads"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "h", "[", "layer", "]", ".", "attn", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.GPT2Model.forward": [[384, 508], ["input_ids.view.view.view", "gpt2.GPT2Model.wpe", "gpt2.GPT2Model.drop", "enumerate", "gpt2.GPT2Model.ln_f", "hidden_states.view.view.view", "input_ids.view.view.size", "ValueError", "token_type_ids.view.view.view", "position_ids.unsqueeze().view.unsqueeze().view.view", "[].size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().view.unsqueeze().view.unsqueeze().view", "attention_mask.to.to.view", "attention_mask.to.to.unsqueeze().unsqueeze", "attention_mask.to.to.to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "gpt2.GPT2Model.wte", "gpt2.GPT2Model.wte", "zip", "block", "tuple", "input_ids.view.view.size", "input_ids.view.view.view", "len", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "hidden_states.view.view.size", "tuple.append", "ValueError", "position_ids.unsqueeze().view.unsqueeze().view.unsqueeze", "attention_mask.to.to.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "t.view", "gpt2.GPT2Model.size", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "hidden_states.view.view.view", "gpt2.GPT2Model.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "gpt2.GPT2Model.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", ")", ":", "\n", "        ", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "2", ")", ")", "\n", "#print(\"Sentence\")", "\n", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "", "if", "position_ids", "is", "not", "None", ":", "\n", "            ", "position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "\n", "", "if", "past", "is", "None", ":", "\n", "            ", "past_length", "=", "0", "\n", "past", "=", "[", "None", "]", "*", "len", "(", "self", ".", "h", ")", "\n", "", "else", ":", "\n", "            ", "past_length", "=", "past", "[", "0", "]", "[", "0", "]", ".", "size", "(", "-", "2", ")", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "            ", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "position_ids", "=", "torch", ".", "arange", "(", "past_length", ",", "input_shape", "[", "-", "1", "]", "+", "past_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "\n", "# Attention mask.", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "            ", "attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "attention_mask", "=", "attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "attention_mask", "=", "(", "1.0", "-", "attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# head_mask has shape n_layer x batch x n_heads x N x N", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "(", "\n", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "n_layer", "\n", "\n", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "wte", "(", "input_ids", ")", "\n", "#print(inputs_embeds)", "\n", "", "position_embeds", "=", "self", ".", "wpe", "(", "position_ids", ")", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_embeds", "=", "self", ".", "wte", "(", "token_type_ids", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "", "hidden_states", "=", "inputs_embeds", "+", "position_embeds", "+", "token_type_embeds", "\n", "hidden_states", "=", "self", ".", "drop", "(", "hidden_states", ")", "\n", "#print(\"Hidden States\", hidden_states.size()) ", "\n", "output_shape", "=", "input_shape", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "\n", "presents", "=", "(", ")", "\n", "all_attentions", "=", "[", "]", "\n", "all_hidden_states", "=", "(", ")", "\n", "for", "i", ",", "(", "block", ",", "layer_past", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "h", ",", "past", ")", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ".", "view", "(", "*", "output_shape", ")", ",", ")", "\n", "\n", "", "outputs", "=", "block", "(", "\n", "hidden_states", ",", "layer_past", "=", "layer_past", ",", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", "[", "i", "]", "\n", ")", "\n", "\n", "hidden_states", ",", "present", "=", "outputs", "[", ":", "2", "]", "\n", "if", "self", ".", "output_past", ":", "\n", "                ", "presents", "=", "presents", "+", "(", "present", ",", ")", "\n", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", ".", "append", "(", "outputs", "[", "2", "]", ")", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "ln_f", "(", "hidden_states", ")", "\n", "#exit()", "\n", "hidden_states", "=", "hidden_states", ".", "view", "(", "*", "output_shape", ")", "\n", "# Add last hidden state", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_past", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "presents", ",", ")", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "# let the number of heads free (-1) so we can extract attention even after head pruning", "\n", "            ", "attention_output_shape", "=", "input_shape", "[", ":", "-", "1", "]", "+", "(", "-", "1", ",", ")", "+", "all_attentions", "[", "0", "]", ".", "shape", "[", "-", "2", ":", "]", "\n", "all_attentions", "=", "tuple", "(", "t", ".", "view", "(", "*", "attention_output_shape", ")", "for", "t", "in", "all_attentions", ")", "\n", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "#print(outputs[0].size())", "\n", "\n", "", "return", "outputs", "# last hidden state, (presents), (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.GPT2LMHeadModel.__init__": [[557, 563], ["gpt2.GPT2PreTrainedModel.__init__", "gpt2.GPT2Model", "torch.Linear", "torch.Linear", "gpt2.GPT2LMHeadModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "GPT2Model", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.GPT2LMHeadModel.get_output_embeddings": [[564, 566], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.GPT2LMHeadModel.prepare_inputs_for_generation": [[567, 575], ["inputs.update", "input_ids[].unsqueeze"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "input_ids", ",", "**", "kwargs", ")", ":", "\n", "# only last token for inputs_ids if past is defined in kwargs", "\n", "        ", "if", "\"past\"", "in", "kwargs", "and", "kwargs", "[", "\"past\"", "]", ":", "\n", "            ", "input_ids", "=", "input_ids", "[", ":", ",", "-", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "", "inputs", "=", "{", "\"input_ids\"", ":", "input_ids", "}", "\n", "inputs", ".", "update", "(", "kwargs", ")", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.GPT2LMHeadModel.forward": [[576, 611], ["gpt2.GPT2LMHeadModel.transformer", "gpt2.GPT2LMHeadModel.lm_head", "lm_logits[].contiguous", "labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous.view", "labels[].contiguous.view", "lm_logits[].contiguous.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "past", "=", "past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# Shift so that tokens < n predict n", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "# Flatten the tokens", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "lm_logits", "# (loss), lm_logits, presents, (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.GPT2DoubleHeadsModel.__init__": [[685, 693], ["gpt2.GPT2PreTrainedModel.__init__", "gpt2.GPT2Model", "torch.Linear", "torch.Linear", "modeling_utils.SequenceSummary", "gpt2.GPT2DoubleHeadsModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "config", ".", "num_labels", "=", "1", "\n", "self", ".", "transformer", "=", "GPT2Model", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "multiple_choice_head", "=", "SequenceSummary", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.GPT2DoubleHeadsModel.get_output_embeddings": [[694, 696], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.GPT2DoubleHeadsModel.forward": [[697, 738], ["gpt2.GPT2DoubleHeadsModel.transformer", "gpt2.GPT2DoubleHeadsModel.lm_head", "gpt2.GPT2DoubleHeadsModel.multiple_choice_head().squeeze", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous", "lm_labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "gpt2.GPT2DoubleHeadsModel.multiple_choice_head", "gpt2.GPT2DoubleHeadsModel.view", "mc_labels.view", "lm_logits[].contiguous.view", "lm_labels[].contiguous.view", "gpt2.GPT2DoubleHeadsModel.size", "lm_logits[].contiguous.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "mc_token_ids", "=", "None", ",", "\n", "lm_labels", "=", "None", ",", "\n", "mc_labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "past", "=", "past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "mc_logits", "=", "self", ".", "multiple_choice_head", "(", "hidden_states", ",", "mc_token_ids", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", "mc_logits", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "mc_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "mc_logits", ".", "view", "(", "-", "1", ",", "mc_logits", ".", "size", "(", "-", "1", ")", ")", ",", "mc_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "lm_labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (lm loss), (mc loss), lm logits, mc logits, presents, (all hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.load_tf_weights_in_gpt2": [[43, 96], ["os.path.abspath", "logger.info", "tf.train.list_variables", "zip", "logger.info", "tf.train.load_variable", "names.append", "arrays.append", "name.split.split", "logger.info", "torch.from_numpy", "torch.from_numpy", "logger.error", "tf.train.load_variable.squeeze", "re.fullmatch", "re.split", "getattr", "len", "int", "getattr", "getattr", "getattr", "getattr"], "function", ["None"], ["def", "load_tf_weights_in_gpt2", "(", "model", ",", "config", ",", "gpt2_checkpoint_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\n", "\"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "gpt2_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "\"Converting TensorFlow checkpoint from {}\"", ".", "format", "(", "tf_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ".", "squeeze", "(", ")", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "name", "=", "name", "[", "6", ":", "]", "# skip \"model/\"", "\n", "name", "=", "name", ".", "split", "(", "\"/\"", ")", "\n", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r\"[A-Za-z]+\\d+\"", ",", "m_name", ")", ":", "\n", "                ", "scope_names", "=", "re", ".", "split", "(", "r\"(\\d+)\"", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "scope_names", "=", "[", "m_name", "]", "\n", "", "if", "scope_names", "[", "0", "]", "==", "\"w\"", "or", "scope_names", "[", "0", "]", "==", "\"g\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"b\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"bias\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"wpe\"", "or", "scope_names", "[", "0", "]", "==", "\"wte\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "scope_names", "[", "0", "]", ")", "\n", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "else", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "scope_names", "[", "0", "]", ")", "\n", "", "if", "len", "(", "scope_names", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "scope_names", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.gpt2.gelu": [[98, 100], ["torch.tanh", "torch.tanh", "math.sqrt", "torch.pow", "torch.pow"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.ModuleUtilsMixin.num_parameters": [[61, 67], ["sum", "filter", "modeling_utils.ModuleUtilsMixin.parameters", "modeling_utils.ModuleUtilsMixin.parameters", "p.numel"], "methods", ["None"], ["def", "num_parameters", "(", "self", ",", "only_trainable", ":", "bool", "=", "False", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Get number of (optionally, trainable) parameters in the module.\n        \"\"\"", "\n", "params", "=", "filter", "(", "lambda", "x", ":", "x", ".", "requires_grad", ",", "self", ".", "parameters", "(", ")", ")", "if", "only_trainable", "else", "self", ".", "parameters", "(", ")", "\n", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.dummy_inputs": [[90, 98], ["torch.tensor"], "methods", ["None"], ["@", "property", "\n", "def", "dummy_inputs", "(", "self", ")", ":", "\n", "        ", "\"\"\" Dummy inputs to do a forward pass in the network.\n\n        Returns:\n            torch.Tensor with dummy inputs\n        \"\"\"", "\n", "return", "{", "\"input_ids\"", ":", "torch", ".", "tensor", "(", "DUMMY_INPUTS", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.__init__": [[99, 111], ["super().__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["", "def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "config", ",", "PretrainedConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Parameter config in `{}(config)` should be an instance of class `PretrainedConfig`. \"", "\n", "\"To create a model from a pretrained model use \"", "\n", "\"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", ")", "\n", "# Save config in model", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.base_model": [[112, 115], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "base_model", "(", "self", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.get_input_embeddings": [[116, 124], ["getattr", "getattr.get_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2Model.get_input_embeddings"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "\"\"\" Get model's input embeddings\n        \"\"\"", "\n", "base_model", "=", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "\n", "if", "base_model", "is", "not", "self", ":", "\n", "            ", "return", "base_model", ".", "get_input_embeddings", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.set_input_embeddings": [[125, 133], ["getattr", "getattr.set_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2Model.set_input_embeddings"], ["", "", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "\"\"\" Set model's input embeddings\n        \"\"\"", "\n", "base_model", "=", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "\n", "if", "base_model", "is", "not", "self", ":", "\n", "            ", "base_model", ".", "set_input_embeddings", "(", "value", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.get_output_embeddings": [[134, 139], ["None"], "methods", ["None"], ["", "", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "\"\"\" Get model's output embeddings\n            Return None if the model doesn't have output embeddings\n        \"\"\"", "\n", "return", "None", "# Overwrite for models with output embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.tie_weights": [[140, 147], ["modeling_utils.PreTrainedModel.get_output_embeddings", "modeling_utils.PreTrainedModel._tie_or_clone_weights", "modeling_utils.PreTrainedModel.get_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2DoubleHeadsModel.get_output_embeddings", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel._tie_or_clone_weights", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2Model.get_input_embeddings"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Make sure we are sharing the input and output embeddings.\n            Export to TorchScript can't handle parameter sharing so we are cloning them instead.\n        \"\"\"", "\n", "output_embeddings", "=", "self", ".", "get_output_embeddings", "(", ")", "\n", "if", "output_embeddings", "is", "not", "None", ":", "\n", "            ", "self", ".", "_tie_or_clone_weights", "(", "output_embeddings", ",", "self", ".", "get_input_embeddings", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel._tie_or_clone_weights": [[148, 165], ["torch.nn.Parameter", "hasattr", "torch.nn.functional.pad", "hasattr", "hasattr", "input_embeddings.weight.clone"], "methods", ["None"], ["", "", "def", "_tie_or_clone_weights", "(", "self", ",", "output_embeddings", ",", "input_embeddings", ")", ":", "\n", "        ", "\"\"\" Tie or clone module weights depending of weither we are using TorchScript or not\n        \"\"\"", "\n", "if", "self", ".", "config", ".", "torchscript", ":", "\n", "            ", "output_embeddings", ".", "weight", "=", "nn", ".", "Parameter", "(", "input_embeddings", ".", "weight", ".", "clone", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "output_embeddings", ".", "weight", "=", "input_embeddings", ".", "weight", "\n", "\n", "", "if", "hasattr", "(", "output_embeddings", ",", "\"bias\"", ")", "and", "output_embeddings", ".", "bias", "is", "not", "None", ":", "\n", "            ", "output_embeddings", ".", "bias", ".", "data", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "\n", "output_embeddings", ".", "bias", ".", "data", ",", "\n", "(", "0", ",", "output_embeddings", ".", "weight", ".", "shape", "[", "0", "]", "-", "output_embeddings", ".", "bias", ".", "shape", "[", "0", "]", ")", ",", "\n", "\"constant\"", ",", "\n", "0", ",", "\n", ")", "\n", "", "if", "hasattr", "(", "output_embeddings", ",", "\"out_features\"", ")", "and", "hasattr", "(", "input_embeddings", ",", "\"num_embeddings\"", ")", ":", "\n", "            ", "output_embeddings", ".", "out_features", "=", "input_embeddings", ".", "num_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.resize_token_embeddings": [[166, 192], ["getattr", "getattr._resize_token_embeddings", "modeling_utils.PreTrainedModel.tie_weights"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel._resize_token_embeddings", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.tie_weights"], ["", "", "def", "resize_token_embeddings", "(", "self", ",", "new_num_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\" Resize input token embeddings matrix of the model if new_num_tokens != config.vocab_size.\n        Take care of tying weights embeddings afterwards if the model class has a `tie_weights()` method.\n\n        Arguments:\n\n            new_num_tokens: (`optional`) int:\n                New number of tokens in the embedding matrix. Increasing the size will add newly initialized vectors at the end. Reducing the size will remove vectors from the end.\n                If not provided or None: does nothing and just returns a pointer to the input tokens ``torch.nn.Embeddings`` Module of the model.\n\n        Return: ``torch.nn.Embeddings``\n            Pointer to the input tokens Embeddings Module of the model\n        \"\"\"", "\n", "base_model", "=", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "# get the base model if needed", "\n", "model_embeds", "=", "base_model", ".", "_resize_token_embeddings", "(", "new_num_tokens", ")", "\n", "if", "new_num_tokens", "is", "None", ":", "\n", "            ", "return", "model_embeds", "\n", "\n", "# Update base model and current model config", "\n", "", "self", ".", "config", ".", "vocab_size", "=", "new_num_tokens", "\n", "base_model", ".", "vocab_size", "=", "new_num_tokens", "\n", "\n", "# Tie weights again if needed", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n", "return", "model_embeds", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel._resize_token_embeddings": [[193, 198], ["modeling_utils.PreTrainedModel.get_input_embeddings", "modeling_utils.PreTrainedModel._get_resized_embeddings", "modeling_utils.PreTrainedModel.set_input_embeddings", "modeling_utils.PreTrainedModel.get_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2Model.get_input_embeddings", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel._get_resized_embeddings", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2Model.set_input_embeddings", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2Model.get_input_embeddings"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "old_embeddings", "=", "self", ".", "get_input_embeddings", "(", ")", "\n", "new_embeddings", "=", "self", ".", "_get_resized_embeddings", "(", "old_embeddings", ",", "new_num_tokens", ")", "\n", "self", ".", "set_input_embeddings", "(", "new_embeddings", ")", "\n", "return", "self", ".", "get_input_embeddings", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel._get_resized_embeddings": [[199, 232], ["old_embeddings.weight.size", "torch.nn.Embedding", "torch.nn.Embedding.to", "modeling_utils.PreTrainedModel._init_weights", "min"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2PreTrainedModel._init_weights"], ["", "def", "_get_resized_embeddings", "(", "self", ",", "old_embeddings", ",", "new_num_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\" Build a resized Embedding Module from a provided token Embedding Module.\n            Increasing the size will add newly initialized vectors at the end\n            Reducing the size will remove vectors from the end\n\n        Args:\n            new_num_tokens: (`optional`) int\n                New number of tokens in the embedding matrix.\n                Increasing the size will add newly initialized vectors at the end\n                Reducing the size will remove vectors from the end\n                If not provided or None: return the provided token Embedding Module.\n        Return: ``torch.nn.Embeddings``\n            Pointer to the resized Embedding Module or the old Embedding Module if new_num_tokens is None\n        \"\"\"", "\n", "if", "new_num_tokens", "is", "None", ":", "\n", "            ", "return", "old_embeddings", "\n", "\n", "", "old_num_tokens", ",", "old_embedding_dim", "=", "old_embeddings", ".", "weight", ".", "size", "(", ")", "\n", "if", "old_num_tokens", "==", "new_num_tokens", ":", "\n", "            ", "return", "old_embeddings", "\n", "\n", "# Build new embeddings", "\n", "", "new_embeddings", "=", "nn", ".", "Embedding", "(", "new_num_tokens", ",", "old_embedding_dim", ")", "\n", "new_embeddings", ".", "to", "(", "old_embeddings", ".", "weight", ".", "device", ")", "\n", "\n", "# initialize all new embeddings (in particular added tokens)", "\n", "self", ".", "_init_weights", "(", "new_embeddings", ")", "\n", "\n", "# Copy word embeddings from the previous weights", "\n", "num_tokens_to_copy", "=", "min", "(", "old_num_tokens", ",", "new_num_tokens", ")", "\n", "new_embeddings", ".", "weight", ".", "data", "[", ":", "num_tokens_to_copy", ",", ":", "]", "=", "old_embeddings", ".", "weight", ".", "data", "[", ":", "num_tokens_to_copy", ",", ":", "]", "\n", "\n", "return", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.init_weights": [[233, 244], ["modeling_utils.PreTrainedModel.apply", "modeling_utils.PreTrainedModel.tie_weights", "modeling_utils.PreTrainedModel.prune_heads"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.tie_weights", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Attention.prune_heads"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Initialize and prunes weights if needed. \"\"\"", "\n", "# Initialize weights", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n", "# Prune heads if needed", "\n", "if", "self", ".", "config", ".", "pruned_heads", ":", "\n", "            ", "self", ".", "prune_heads", "(", "self", ".", "config", ".", "pruned_heads", ")", "\n", "\n", "# Tie weights if needed", "\n", "", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.prune_heads": [[245, 259], ["heads_to_prune.items", "modeling_utils.PreTrainedModel.base_model._prune_heads", "list", "set", "set", "modeling_utils.PreTrainedModel.config.pruned_heads.get"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2Model._prune_heads"], ["", "def", "prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the base model.\n\n            Arguments:\n\n                heads_to_prune: dict with keys being selected layer indices (`int`) and associated values being the list of heads to prune in said layer (list of `int`).\n                E.g. {1: [0, 2], 2: [2, 3]} will prune heads 0 and 2 on layer 1 and heads 2 and 3 on layer 2.\n        \"\"\"", "\n", "# save new sets of pruned heads as union of previously stored pruned heads and newly pruned heads", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "union_heads", "=", "set", "(", "self", ".", "config", ".", "pruned_heads", ".", "get", "(", "layer", ",", "[", "]", ")", ")", "|", "set", "(", "heads", ")", "\n", "self", ".", "config", ".", "pruned_heads", "[", "layer", "]", "=", "list", "(", "union_heads", ")", "# Unfortunately we have to store it as list for JSON", "\n", "\n", "", "self", ".", "base_model", ".", "_prune_heads", "(", "heads_to_prune", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.save_pretrained": [[260, 278], ["os.path.isdir", "model_to_save.config.save_pretrained", "os.path.join", "torch.save", "logger.info", "hasattr", "model_to_save.state_dict"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.save_pretrained"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save a model and its configuration file to a directory, so that it\n            can be re-loaded using the `:func:`~transformers.PreTrainedModel.from_pretrained`` class method.\n        \"\"\"", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "\n", "save_directory", "\n", ")", ",", "\"Saving path should be a directory where the model and configuration can be saved\"", "\n", "\n", "# Only save the model itself if we are using distributed training", "\n", "model_to_save", "=", "self", ".", "module", "if", "hasattr", "(", "self", ",", "\"module\"", ")", "else", "self", "\n", "\n", "# Save configuration file", "\n", "model_to_save", ".", "config", ".", "save_pretrained", "(", "save_directory", ")", "\n", "\n", "# If we save using the predefined names, we can load using `from_pretrained`", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "WEIGHTS_NAME", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_model_file", ")", "\n", "logger", ".", "info", "(", "\"Model weights saved in {}\"", ".", "format", "(", "output_model_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.from_pretrained": [[279, 551], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "cls", "load_tf2_checkpoint_in_pytorch_model.tie_weights", "load_tf2_checkpoint_in_pytorch_model.eval", "isinstance", "cls.config_class.from_pretrained", "file_utils.cached_path.endswith", "torch.load.keys", "zip", "getattr", "torch.load.copy", "modeling_utils.PreTrainedModel.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.tie_weights", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"Instantiate a pretrained pytorch model from a pre-trained model configuration.\n\n        The model is set in evaluation mode by default using ``model.eval()`` (Dropout modules are deactivated)\n        To train the model, you should first set it back in training mode with ``model.train()``\n\n        The warning ``Weights from XXX not initialized from pretrained model`` means that the weights of XXX do not come pre-trained with the rest of the model.\n        It is up to you to train those weights with a downstream fine-tuning task.\n\n        The warning ``Weights from XXX not used in YYY`` means that the layer XXX is not used by YYY, therefore those weights are discarded.\n\n        Parameters:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a string with the `identifier name` of a pre-trained model that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n                - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n                - a path or url to a `tensorflow index checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In this case, ``from_tf`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n                - None if you are both providing the configuration and state dictionary (resp. with keyword arguments ``config`` and ``state_dict``)\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) one of:\n                    - an instance of a class derived from :class:`~transformers.PretrainedConfig`, or\n                    - a string valid as input to :func:`~transformers.PretrainedConfig.from_pretrained()`\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n\n                - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            resume_download: (`optional`) boolean, default False:\n                Do not delete incompletely recieved file. Attempt to resume the download if such a file exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            model = BertModel.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = BertModel.from_pretrained('./test/saved_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = BertModel.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = BertConfig.from_json_file('./tf_model/my_tf_model_config.json')\n            model = BertModel.from_pretrained('./tf_model/my_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "config", "=", "kwargs", ".", "pop", "(", "\"config\"", ",", "None", ")", "\n", "state_dict", "=", "kwargs", ".", "pop", "(", "\"state_dict\"", ",", "None", ")", "\n", "cache_dir", "=", "kwargs", ".", "pop", "(", "\"cache_dir\"", ",", "None", ")", "\n", "from_tf", "=", "kwargs", ".", "pop", "(", "\"from_tf\"", ",", "False", ")", "\n", "force_download", "=", "kwargs", ".", "pop", "(", "\"force_download\"", ",", "False", ")", "\n", "resume_download", "=", "kwargs", ".", "pop", "(", "\"resume_download\"", ",", "False", ")", "\n", "proxies", "=", "kwargs", ".", "pop", "(", "\"proxies\"", ",", "None", ")", "\n", "output_loading_info", "=", "kwargs", ".", "pop", "(", "\"output_loading_info\"", ",", "False", ")", "\n", "\n", "# Load config if we don't provide a configuration", "\n", "if", "not", "isinstance", "(", "config", ",", "PretrainedConfig", ")", ":", "\n", "            ", "config_path", "=", "config", "if", "config", "is", "not", "None", "else", "pretrained_model_name_or_path", "\n", "config", ",", "model_kwargs", "=", "cls", ".", "config_class", ".", "from_pretrained", "(", "\n", "config_path", ",", "\n", "*", "model_args", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", "return_unused_kwargs", "=", "True", ",", "\n", "force_download", "=", "force_download", ",", "\n", "resume_download", "=", "resume_download", ",", "\n", "proxies", "=", "proxies", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "model_kwargs", "=", "kwargs", "\n", "\n", "# Load model", "\n", "", "if", "pretrained_model_name_or_path", "is", "not", "None", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "                ", "archive_file", "=", "cls", ".", "pretrained_model_archive_map", "[", "pretrained_model_name_or_path", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "                ", "if", "from_tf", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", ")", ")", ":", "\n", "# Load from a TF 1.0 checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", ")", "\n", "", "elif", "from_tf", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF2_WEIGHTS_NAME", ")", ")", ":", "\n", "# Load from a TF 2.0 checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF2_WEIGHTS_NAME", ")", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", ")", ":", "\n", "# Load from a PyTorch checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "EnvironmentError", "(", "\n", "\"Error no file named {} found in directory {} or `from_tf` set to False\"", ".", "format", "(", "\n", "[", "WEIGHTS_NAME", ",", "TF2_WEIGHTS_NAME", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", "]", ",", "pretrained_model_name_or_path", "\n", ")", "\n", ")", "\n", "", "", "elif", "os", ".", "path", ".", "isfile", "(", "pretrained_model_name_or_path", ")", "or", "is_remote_url", "(", "pretrained_model_name_or_path", ")", ":", "\n", "                ", "archive_file", "=", "pretrained_model_name_or_path", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "pretrained_model_name_or_path", "+", "\".index\"", ")", ":", "\n", "                ", "assert", "(", "\n", "from_tf", "\n", ")", ",", "\"We found a TensorFlow checkpoint at {}, please set from_tf to True to load from this checkpoint\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", "+", "\".index\"", "\n", ")", "\n", "archive_file", "=", "pretrained_model_name_or_path", "+", "\".index\"", "\n", "", "else", ":", "\n", "                ", "archive_file", "=", "hf_bucket_url", "(", "pretrained_model_name_or_path", ",", "postfix", "=", "WEIGHTS_NAME", ")", "\n", "if", "from_tf", ":", "\n", "                    ", "raise", "EnvironmentError", "(", "\n", "\"Loading a PyTorch model from a TF checkpoint is not supported when using a model identifier name.\"", "\n", ")", "\n", "\n", "# redirect to the cache, if necessary", "\n", "", "", "try", ":", "\n", "                ", "resolved_archive_file", "=", "cached_path", "(", "\n", "archive_file", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", "force_download", "=", "force_download", ",", "\n", "proxies", "=", "proxies", ",", "\n", "resume_download", "=", "resume_download", ",", "\n", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "                ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "                    ", "msg", "=", "\"Couldn't reach server at '{}' to download pretrained weights.\"", ".", "format", "(", "archive_file", ")", "\n", "", "else", ":", "\n", "                    ", "msg", "=", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url to model weight files named one of {} but \"", "\n", "\"couldn't find any such file at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "\", \"", ".", "join", "(", "cls", ".", "pretrained_model_archive_map", ".", "keys", "(", ")", ")", ",", "\n", "archive_file", ",", "\n", "[", "WEIGHTS_NAME", ",", "TF2_WEIGHTS_NAME", ",", "TF_WEIGHTS_NAME", "]", ",", "\n", ")", "\n", ")", "\n", "", "raise", "EnvironmentError", "(", "msg", ")", "\n", "\n", "", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading weights file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading weights file {} from cache at {}\"", ".", "format", "(", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "resolved_archive_file", "=", "None", "\n", "\n", "# Instantiate model.", "\n", "", "model", "=", "cls", "(", "config", ",", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "\n", "if", "state_dict", "is", "None", "and", "not", "from_tf", ":", "\n", "            ", "try", ":", "\n", "                ", "state_dict", "=", "torch", ".", "load", "(", "resolved_archive_file", ",", "map_location", "=", "\"cpu\"", ")", "\n", "", "except", "Exception", ":", "\n", "                ", "raise", "OSError", "(", "\n", "\"Unable to load weights from pytorch checkpoint file. \"", "\n", "\"If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. \"", "\n", ")", "\n", "\n", "", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "\n", "if", "from_tf", ":", "\n", "            ", "if", "resolved_archive_file", ".", "endswith", "(", "\".index\"", ")", ":", "\n", "# Load from a TensorFlow 1.X checkpoint - provided by original authors", "\n", "                ", "model", "=", "cls", ".", "load_tf_weights", "(", "model", ",", "config", ",", "resolved_archive_file", "[", ":", "-", "6", "]", ")", "# Remove the '.index'", "\n", "", "else", ":", "\n", "# Load from our TensorFlow 2.0 checkpoints", "\n", "                ", "try", ":", "\n", "                    ", "from", "transformers", "import", "load_tf2_checkpoint_in_pytorch_model", "\n", "\n", "model", "=", "load_tf2_checkpoint_in_pytorch_model", "(", "model", ",", "resolved_archive_file", ",", "allow_missing_keys", "=", "True", ")", "\n", "", "except", "ImportError", ":", "\n", "                    ", "logger", ".", "error", "(", "\n", "\"Loading a TensorFlow model in PyTorch, requires both PyTorch and TensorFlow to be installed. Please see \"", "\n", "\"https://pytorch.org/ and https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "", "", "", "else", ":", "\n", "# Convert old format to new format if needed from a PyTorch state_dict", "\n", "            ", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "                ", "new_key", "=", "None", "\n", "if", "\"gamma\"", "in", "key", ":", "\n", "                    ", "new_key", "=", "key", ".", "replace", "(", "\"gamma\"", ",", "\"weight\"", ")", "\n", "", "if", "\"beta\"", "in", "key", ":", "\n", "                    ", "new_key", "=", "key", ".", "replace", "(", "\"beta\"", ",", "\"bias\"", ")", "\n", "", "if", "new_key", ":", "\n", "                    ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "                ", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "", "metadata", "=", "getattr", "(", "state_dict", ",", "\"_metadata\"", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "                ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "# PyTorch's `_load_from_state_dict` does not copy parameters in a module's descendants", "\n", "# so we need to apply the function recursively.", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "\"\"", ")", ":", "\n", "                ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", "\n", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                    ", "if", "child", "is", "not", "None", ":", "\n", "                        ", "load", "(", "child", ",", "prefix", "+", "name", "+", "\".\"", ")", "\n", "\n", "# Make sure we are able to load base models as well as derived models (with heads)", "\n", "", "", "", "start_prefix", "=", "\"\"", "\n", "model_to_load", "=", "model", "\n", "if", "not", "hasattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "and", "any", "(", "\n", "s", ".", "startswith", "(", "cls", ".", "base_model_prefix", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", "\n", ")", ":", "\n", "                ", "start_prefix", "=", "cls", ".", "base_model_prefix", "+", "\".\"", "\n", "", "if", "hasattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "and", "not", "any", "(", "\n", "s", ".", "startswith", "(", "cls", ".", "base_model_prefix", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", "\n", ")", ":", "\n", "                ", "model_to_load", "=", "getattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "\n", "\n", "", "load", "(", "model_to_load", ",", "prefix", "=", "start_prefix", ")", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", "\n", ")", "\n", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", "\n", ")", "\n", ")", "\n", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "\"Error(s) in loading state_dict for {}:\\n\\t{}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", "\n", ")", "\n", ")", "\n", "\n", "", "", "model", ".", "tie_weights", "(", ")", "# make sure word embedding weights are still tied if needed", "\n", "\n", "# Set model in evaluation mode to desactivate DropOut modules by default", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "if", "output_loading_info", ":", "\n", "            ", "loading_info", "=", "{", "\"missing_keys\"", ":", "missing_keys", ",", "\"unexpected_keys\"", ":", "unexpected_keys", ",", "\"error_msgs\"", ":", "error_msgs", "}", "\n", "return", "model", ",", "loading_info", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.prepare_inputs_for_generation": [[552, 554], ["None"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "input_ids", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "{", "\"input_ids\"", ":", "input_ids", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel._do_output_past": [[555, 565], ["hasattr", "hasattr", "len", "len"], "methods", ["None"], ["", "def", "_do_output_past", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "has_output_past", "=", "hasattr", "(", "self", ".", "config", ",", "\"output_past\"", ")", "and", "self", ".", "config", ".", "output_past", "\n", "has_mem_len", "=", "hasattr", "(", "self", ".", "config", ",", "\"mem_len\"", ")", "and", "self", ".", "config", ".", "mem_len", "\n", "\n", "if", "has_output_past", "and", "not", "has_mem_len", "and", "len", "(", "outputs", ")", ">", "1", ":", "\n", "            ", "return", "True", "\n", "", "elif", "has_mem_len", "and", "self", ".", "config", ".", "mem_len", ">", "0", "and", "len", "(", "outputs", ")", ">", "1", ":", "\n", "            ", "return", "True", "\n", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.generate": [[566, 763], ["torch.no_grad", "isinstance", "isinstance", "modeling_utils.PreTrainedModel.get_output_embeddings", "AttributeError", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "torch.full", "input_ids.contiguous().view.contiguous().view.unsqueeze().expand", "input_ids.contiguous().view.contiguous().view.contiguous().view", "modeling_utils.PreTrainedModel._generate_beam_search", "modeling_utils.PreTrainedModel._generate_no_beam_search", "output.view.view.view", "input_ids.contiguous().view.contiguous().view.dim", "input_ids.contiguous().view.contiguous().view.unsqueeze", "input_ids.contiguous().view.contiguous().view.contiguous", "next", "modeling_utils.PreTrainedModel.parameters"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2DoubleHeadsModel.get_output_embeddings", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel._generate_beam_search", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel._generate_no_beam_search"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "max_length", "=", "None", ",", "\n", "do_sample", "=", "None", ",", "\n", "num_beams", "=", "None", ",", "\n", "temperature", "=", "None", ",", "\n", "top_k", "=", "None", ",", "\n", "top_p", "=", "None", ",", "\n", "repetition_penalty", "=", "None", ",", "\n", "bos_token_id", "=", "None", ",", "\n", "pad_token_id", "=", "None", ",", "\n", "eos_token_ids", "=", "None", ",", "\n", "length_penalty", "=", "None", ",", "\n", "num_return_sequences", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\" Generates sequences for models with a LM head. The method currently supports greedy or penalized greedy decoding, sampling with top-k or nucleus sampling\n        and beam-search.\n\n        Adapted in part from `Facebook's XLM beam search code`_.\n\n        .. _`Facebook's XLM beam search code`:\n           https://github.com/facebookresearch/XLM/blob/9e6f6814d17be4fe5b15f2e6c43eb2b2d76daeb4/src/model/transformer.py#L529\n\n\n        Parameters:\n\n            input_ids: (`optional`) `torch.LongTensor` of shape `(batch_size, sequence_length)`\n                The sequence used as a prompt for the generation. If `None` the method initializes\n                it as an empty `torch.LongTensor` of shape `(1,)`.\n\n            max_length: (`optional`) int\n                The max length of the sequence to be generated.  Between 1 and infinity. Default to 20.\n\n            do_sample: (`optional`) bool\n                If set to `False` greedy decoding is used. Otherwise sampling is used. Default to greedy sampling.\n\n            num_beams: (`optional`) int\n                Number of beams for beam search. Must be between 1 and infinity. 1 means no beam search. Default to 1.\n\n            temperature: (`optional`) float\n                The value used to module the next token probabilities. Must be strictely positive. Default to 1.0.\n\n            top_k: (`optional`) int\n                The number of highest probability vocabulary tokens to keep for top-k-filtering. Between 1 and infinity. Default to 50.\n\n            top_p: (`optional`) float\n                The cumulative probability of parameter highest probability vocabulary tokens to keep for nucleus sampling. Must be between 0 and 1. Default to 1.\n\n            repetition_penalty: (`optional`) float\n                The parameter for repetition penalty. Between 1.0 and infinity. 1.0 means no penalty. Default to 1.0.\n\n            bos_token_id: (`optional`) int\n                Beginning of sentence token if no prompt is provided. Default to 0.\n\n            eos_token_ids: (`optional`) int or list of int\n                End of sequence token or list of tokens to stop the generation. Default to 0.\n            length_penalty: (`optional`) float\n                Exponential penalty to the length. Default to 1.\n\n            num_return_sequences: (`optional`) int\n                The number of independently computed returned sequences for each element in the batch. Default to 1.\n\n        Examples::\n\n            tokenizer = AutoTokenizer.from_pretrained('distilgpt2')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('distilgpt2')    # Download model and configuration from S3 and cache.\n            outputs = model.generate(max_length=40, bos_token_id=tokenizer.bos_token_id, eos_token_ids=tokenizer.eos_token_id)  # do greedy decoding without beam search\n            print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('openai-gpt')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('openai-gpt')    # Download model and configuration from S3 and cache.\n            input_context = 'The dog'\n            input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  # encode input context\n            outputs = model.generate(input_ids=input_ids, do_sample=True, num_beams=5, num_return_sequences=3, temperature=1.5)  # generate 3 independent sequences using beam search decoding (5 beams) with sampling from initial context 'The dog'\n            for i in range(3): #  3 output sequences were generated\n                print('Generated {}: {}'.format(i, tokenizer.decode(outputs[0][i], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('distilgpt2')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('distilgpt2')    # Download model and configuration from S3 and cache.\n            input_context = 'The dog'\n            input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  # encode input context\n            outputs = model.generate(input_ids=input_ids, max_length=40, temperature=0.7, bos_token_id=tokenizer.bos_token_id, eos_token_ids=tokenizer.eos_token_id, num_beams=3)  # generate sequences using greedy beam search decoding (3 beams)\n            print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('ctrl')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('ctrl')    # Download model and configuration from S3 and cache.\n            input_context = 'Legal My neighbor is'  # \"Legal\" is one of the control codes for ctrl\n            input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  # encode input context\n            outputs = model.generate(input_ids=input_ids, max_length=50, temperature=0.7, repetition_penalty=1.2)  # generate sequences using using greedy search\n            print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n\n        \"\"\"", "\n", "\n", "# We cannot generate if the model does not have a LM head", "\n", "if", "self", ".", "get_output_embeddings", "(", ")", "is", "None", ":", "\n", "            ", "raise", "AttributeError", "(", "\n", "\"You tried to generate sequences with a model that does not have a LM Head.\"", "\n", "\"Please use another model class (e.g. `OpenAIGPTLMHeadModel`, `XLNetLMHeadModel`, `GPT2LMHeadModel`, `CTRLLMHeadModel`, `T5WithLMHeadModel`, `TransfoXLLMHeadModel`)\"", "\n", ")", "\n", "\n", "", "max_length", "=", "max_length", "if", "max_length", "is", "not", "None", "else", "self", ".", "config", ".", "max_length", "\n", "do_sample", "=", "do_sample", "if", "do_sample", "is", "not", "None", "else", "self", ".", "config", ".", "do_sample", "\n", "num_beams", "=", "num_beams", "if", "num_beams", "is", "not", "None", "else", "self", ".", "config", ".", "num_beams", "\n", "temperature", "=", "temperature", "if", "temperature", "is", "not", "None", "else", "self", ".", "config", ".", "temperature", "\n", "top_k", "=", "top_k", "if", "top_k", "is", "not", "None", "else", "self", ".", "config", ".", "top_k", "\n", "top_p", "=", "top_p", "if", "top_p", "is", "not", "None", "else", "self", ".", "config", ".", "top_p", "\n", "repetition_penalty", "=", "repetition_penalty", "if", "repetition_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "repetition_penalty", "\n", "bos_token_id", "=", "bos_token_id", "if", "bos_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "bos_token_id", "\n", "pad_token_id", "=", "pad_token_id", "if", "pad_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "pad_token_id", "\n", "eos_token_ids", "=", "eos_token_ids", "if", "eos_token_ids", "is", "not", "None", "else", "self", ".", "config", ".", "eos_token_ids", "\n", "length_penalty", "=", "length_penalty", "if", "length_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "length_penalty", "\n", "num_return_sequences", "=", "(", "\n", "num_return_sequences", "if", "num_return_sequences", "is", "not", "None", "else", "self", ".", "config", ".", "num_return_sequences", "\n", ")", "\n", "\n", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "batch_size", "=", "input_ids", ".", "shape", "[", "0", "]", "# overriden by the input batch_size", "\n", "", "else", ":", "\n", "            ", "batch_size", "=", "1", "\n", "", "if", "isinstance", "(", "eos_token_ids", ",", "int", ")", ":", "\n", "            ", "eos_token_ids", "=", "[", "eos_token_ids", "]", "\n", "\n", "", "assert", "isinstance", "(", "max_length", ",", "int", ")", "and", "max_length", ">", "0", ",", "\"`max_length` should be a strictely positive integer.\"", "\n", "assert", "isinstance", "(", "do_sample", ",", "bool", ")", ",", "\"`do_sample` should be a boolean.\"", "\n", "assert", "isinstance", "(", "num_beams", ",", "int", ")", "and", "num_beams", ">", "0", ",", "\"`num_beams` should be a strictely positive integer.\"", "\n", "assert", "temperature", ">", "0", ",", "\"`temperature` should be strictely positive.\"", "\n", "assert", "isinstance", "(", "top_k", ",", "int", ")", "and", "top_k", ">=", "0", ",", "\"`top_k` should be a positive integer.\"", "\n", "assert", "0", "<=", "top_p", "<=", "1", ",", "\"`top_p` should be between 0 and 1.\"", "\n", "assert", "repetition_penalty", ">=", "1.0", ",", "\"`repetition_penalty` should be >= 1.\"", "\n", "assert", "isinstance", "(", "bos_token_id", ",", "int", ")", "and", "bos_token_id", ">=", "0", ",", "\"`bos_token_id` should be a positive integer.\"", "\n", "assert", "isinstance", "(", "pad_token_id", ",", "int", ")", "and", "pad_token_id", ">=", "0", ",", "\"`pad_token_id` should be a positive integer.\"", "\n", "assert", "isinstance", "(", "eos_token_ids", ",", "(", "list", ",", "tuple", ")", ")", "and", "(", "\n", "e", ">=", "0", "for", "e", "in", "eos_token_ids", "\n", ")", ",", "\"`eos_token_ids` should be a positive integer or a list/tuple of positive integers.\"", "\n", "assert", "length_penalty", ">", "0", ",", "\"`length_penalty` should be strictely positive.\"", "\n", "assert", "(", "\n", "isinstance", "(", "num_return_sequences", ",", "int", ")", "and", "num_return_sequences", ">", "0", "\n", ")", ",", "\"`num_return_sequences` should be a strictely positive integer.\"", "\n", "\n", "if", "input_ids", "is", "None", ":", "\n", "            ", "input_ids", "=", "torch", ".", "full", "(", "\n", "(", "batch_size", ",", "1", ")", ",", "bos_token_id", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", ")", "\n", "", "else", ":", "\n", "            ", "assert", "input_ids", ".", "dim", "(", ")", "==", "2", ",", "\"Input prompt should be of shape (batch_size, sequence length).\"", "\n", "\n", "# current position and vocab size", "\n", "", "cur_len", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "vocab_size", "=", "self", ".", "config", ".", "vocab_size", "\n", "\n", "if", "num_return_sequences", "!=", "1", ":", "\n", "# Expand input to num return sequences", "\n", "            ", "input_ids", "=", "input_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "num_return_sequences", ",", "cur_len", ")", "\n", "input_ids", "=", "input_ids", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "batch_size", "*", "num_return_sequences", ",", "cur_len", "\n", ")", "# (batch_size * num_return_sequences, cur_len)", "\n", "effective_batch_size", "=", "batch_size", "*", "num_return_sequences", "\n", "", "else", ":", "\n", "            ", "effective_batch_size", "=", "batch_size", "\n", "\n", "", "if", "num_beams", ">", "1", ":", "\n", "            ", "output", "=", "self", ".", "_generate_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "effective_batch_size", ",", "\n", "length_penalty", ",", "\n", "num_beams", ",", "\n", "vocab_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "_generate_no_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "effective_batch_size", ",", "\n", ")", "\n", "\n", "", "if", "num_return_sequences", "!=", "1", ":", "\n", "            ", "output", "=", "output", ".", "view", "(", "batch_size", ",", "num_return_sequences", ",", "-", "1", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel._generate_no_beam_search": [[764, 833], ["torch.cat.new().fill_", "modeling_utils.PreTrainedModel.prepare_inputs_for_generation", "modeling_utils.PreTrainedModel.", "modeling_utils.PreTrainedModel._do_output_past", "torch.cat", "input_ids[].masked_fill_", "torch.cat.new", "range", "modeling_utils.top_k_top_p_filtering", "torch.multinomial().squeeze", "torch.argmax", "torch.cat.new().fill_.mul_", "torch.cat.new().fill_.max", "torch.cat.new().fill_.to", "set", "tokens_to_add.unsqueeze", "tokens_to_add.ne().long", "input_ids[].tolist", "torch.multinomial", "torch.nn.functional.softmax", "tokens_to_add.ne"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2LMHeadModel.prepare_inputs_for_generation", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel._do_output_past", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.top_k_top_p_filtering"], ["", "def", "_generate_no_beam_search", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "batch_size", ",", "\n", ")", ":", "\n", "        ", "\"\"\" Generate sequences for each example without beam search (num_beams == 1).\n            All returned sequence are generated independantly.\n        \"\"\"", "\n", "# current position / max lengths / length of generated sentences / unfinished sentences", "\n", "unfinished_sents", "=", "input_ids", ".", "new", "(", "batch_size", ")", ".", "fill_", "(", "1", ")", "\n", "\n", "past", "=", "None", "\n", "\n", "while", "cur_len", "<", "max_length", ":", "\n", "            ", "model_inputs", "=", "self", ".", "prepare_inputs_for_generation", "(", "input_ids", ",", "past", "=", "past", ")", "\n", "outputs", "=", "self", "(", "**", "model_inputs", ")", "\n", "next_token_logits", "=", "outputs", "[", "0", "]", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "\n", "# if model has past, then set the past variable to speed up decoding", "\n", "if", "self", ".", "_do_output_past", "(", "outputs", ")", ":", "\n", "                ", "past", "=", "outputs", "[", "1", "]", "\n", "\n", "# repetition penalty from CTRL paper (https://arxiv.org/abs/1909.05858)", "\n", "", "if", "repetition_penalty", "!=", "1.0", ":", "\n", "                ", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "for", "previous_token", "in", "set", "(", "input_ids", "[", "i", "]", ".", "tolist", "(", ")", ")", ":", "\n", "# if score < 0 then repetition penalty has to multiplied to reduce the previous token probability", "\n", "                        ", "if", "next_token_logits", "[", "i", ",", "previous_token", "]", "<", "0", ":", "\n", "                            ", "next_token_logits", "[", "i", ",", "previous_token", "]", "*=", "repetition_penalty", "\n", "", "else", ":", "\n", "                            ", "next_token_logits", "[", "i", ",", "previous_token", "]", "/=", "repetition_penalty", "\n", "\n", "", "", "", "", "if", "do_sample", ":", "\n", "# Temperature (higher temperature => more likely to sample low probability tokens)", "\n", "                ", "if", "temperature", "!=", "1.0", ":", "\n", "                    ", "next_token_logits", "=", "next_token_logits", "/", "temperature", "\n", "# Top-p/top-k filtering", "\n", "", "next_token_logits", "=", "top_k_top_p_filtering", "(", "next_token_logits", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ")", "\n", "# Sample", "\n", "next_token", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", ",", "num_samples", "=", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "# Greedy decoding", "\n", "                ", "next_token", "=", "torch", ".", "argmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# update generations and finished sentences", "\n", "", "tokens_to_add", "=", "next_token", "*", "unfinished_sents", "+", "pad_token_id", "*", "(", "1", "-", "unfinished_sents", ")", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "input_ids", ",", "tokens_to_add", ".", "unsqueeze", "(", "-", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "for", "eos_token_id", "in", "eos_token_ids", ":", "\n", "                ", "unfinished_sents", ".", "mul_", "(", "tokens_to_add", ".", "ne", "(", "eos_token_id", ")", ".", "long", "(", ")", ")", "\n", "", "cur_len", "=", "cur_len", "+", "1", "\n", "\n", "# stop when there is a </s> in each sentence, or if we exceed the maximul length", "\n", "if", "unfinished_sents", ".", "max", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "# add eos_token_ids to unfinished sentences", "\n", "", "", "if", "cur_len", "==", "max_length", ":", "\n", "            ", "input_ids", "[", ":", ",", "-", "1", "]", ".", "masked_fill_", "(", "unfinished_sents", ".", "to", "(", "dtype", "=", "torch", ".", "bool", ")", ",", "eos_token_ids", "[", "0", "]", ")", "\n", "\n", "", "return", "input_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel._generate_beam_search": [[834, 1018], ["torch.cat.unsqueeze().expand", "torch.cat.contiguous().view", "torch.zeros", "beam_scores.new.new.view", "torch.cat.new", "enumerate", "torch.cat.new().fill_", "enumerate", "modeling_utils.BeamHypotheses", "modeling_utils.PreTrainedModel.prepare_inputs_for_generation", "modeling_utils.PreTrainedModel.", "modeling_utils.PreTrainedModel._do_output_past", "range", "beam_scores.new.new.new", "torch.cat.new", "torch.cat.new", "torch.cat", "all", "best.append", "torch.cat.unsqueeze", "torch.cat.contiguous", "range", "range", "range", "modeling_utils.top_k_top_p_filtering", "torch.multinomial", "torch.nn.functional.log_softmax", "torch.gather", "next_words.view.view.view", "next_scores.view.view.view", "torch.nn.functional.log_softmax", "_scores.view.view.view", "torch.topk", "next_scores.view.view.size", "next_words.view.view.size", "zip", "next_batch_beam.extend", "len", "tuple", "max", "len", "torch.cat.new", "set", "torch.nn.functional.softmax", "beam_scores[].expand_as", "torch.nn.functional.log_softmax.size", "beam_scores[].expand_as", "generated_hyps[].is_done", "next_batch_beam.extend", "len", "len", "torch.cat.new.unsqueeze", "torch.cat", "reordered_past.append", "torch.cat.new.max().item", "input_ids[].tolist", "next_scores[].max().item", "generated_hyps[].add", "next_sent_beam.append", "len", "len", "layer_past[].unsqueeze().clone().detach", "word_id.item", "input_ids[].clone", "score.item", "torch.cat.new.max", "next_scores[].max", "layer_past[].unsqueeze().clone", "layer_past[].unsqueeze"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2LMHeadModel.prepare_inputs_for_generation", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel._do_output_past", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.top_k_top_p_filtering", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.BeamHypotheses.is_done", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.BeamHypotheses.add"], ["", "def", "_generate_beam_search", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "batch_size", ",", "\n", "length_penalty", ",", "\n", "num_beams", ",", "\n", "vocab_size", ",", "\n", ")", ":", "\n", "        ", "\"\"\" Generate sequences for each example with beam search.\n        \"\"\"", "\n", "# Expand input to num beams", "\n", "input_ids", "=", "input_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "num_beams", ",", "cur_len", ")", "\n", "input_ids", "=", "input_ids", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", "*", "num_beams", ",", "cur_len", ")", "# (batch_size * num_beams, cur_len)", "\n", "\n", "# generated hypotheses", "\n", "generated_hyps", "=", "[", "\n", "BeamHypotheses", "(", "num_beams", ",", "max_length", ",", "length_penalty", ",", "early_stopping", "=", "False", ")", "for", "_", "in", "range", "(", "batch_size", ")", "\n", "]", "\n", "\n", "# scores for each sentence in the beam", "\n", "beam_scores", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "num_beams", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "beam_scores", "[", ":", ",", "1", ":", "]", "=", "-", "1e9", "\n", "beam_scores", "=", "beam_scores", ".", "view", "(", "-", "1", ")", "# shape (batch_size * num_beams,)", "\n", "\n", "# cache compute states", "\n", "past", "=", "None", "\n", "\n", "# done sentences", "\n", "done", "=", "[", "False", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "while", "cur_len", "<", "max_length", ":", "\n", "            ", "model_inputs", "=", "self", ".", "prepare_inputs_for_generation", "(", "input_ids", ",", "past", "=", "past", ")", "\n", "outputs", "=", "self", "(", "**", "model_inputs", ")", "# (batch_size * num_beams, cur_len, vocab_size)", "\n", "scores", "=", "outputs", "[", "0", "]", "[", ":", ",", "-", "1", ",", ":", "]", "# (batch_size * num_beams, vocab_size)", "\n", "\n", "# if model has past, then set the past variable to speed up decoding", "\n", "if", "self", ".", "_do_output_past", "(", "outputs", ")", ":", "\n", "                ", "past", "=", "outputs", "[", "1", "]", "\n", "\n", "# repetition penalty (from CTRL paper https://arxiv.org/abs/1909.05858)", "\n", "", "if", "repetition_penalty", "!=", "1.0", ":", "\n", "                ", "for", "i", "in", "range", "(", "batch_size", "*", "num_beams", ")", ":", "\n", "                    ", "for", "previous_token", "in", "set", "(", "input_ids", "[", "i", "]", ".", "tolist", "(", ")", ")", ":", "\n", "# if score < 0 then repetition penalty has to multiplied to reduce the previous token probability", "\n", "                        ", "if", "scores", "[", "i", ",", "previous_token", "]", "<", "0", ":", "\n", "                            ", "scores", "[", "i", ",", "previous_token", "]", "*=", "repetition_penalty", "\n", "", "else", ":", "\n", "                            ", "scores", "[", "i", ",", "previous_token", "]", "/=", "repetition_penalty", "\n", "\n", "", "", "", "", "if", "do_sample", ":", "\n", "# Temperature (higher temperature => more likely to sample low probability tokens)", "\n", "                ", "if", "temperature", "!=", "1.0", ":", "\n", "                    ", "scores", "=", "scores", "/", "temperature", "\n", "# Top-p/top-k filtering", "\n", "", "scores", "=", "top_k_top_p_filtering", "(", "\n", "scores", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ",", "min_tokens_to_keep", "=", "2", "\n", ")", "# (batch_size * num_beams, vocab_size)", "\n", "# Sample 2 next words for each beam (so we have some spare tokens and match output of greedy beam search)", "\n", "next_words", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", ",", "num_samples", "=", "2", ")", "# (batch_size * num_beams, 2)", "\n", "# Compute next scores", "\n", "_scores", "=", "F", ".", "log_softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "# (batch_size * num_beams, vocab_size)", "\n", "_scores", "=", "torch", ".", "gather", "(", "_scores", ",", "-", "1", ",", "next_words", ")", "# (batch_size * num_beams, 2)", "\n", "next_scores", "=", "_scores", "+", "beam_scores", "[", ":", ",", "None", "]", ".", "expand_as", "(", "_scores", ")", "# (batch_size * num_beams, 2)", "\n", "# Match shape of greedy beam search", "\n", "next_words", "=", "next_words", ".", "view", "(", "batch_size", ",", "2", "*", "num_beams", ")", "# (batch_size, 2 * num_beams)", "\n", "next_scores", "=", "next_scores", ".", "view", "(", "batch_size", ",", "2", "*", "num_beams", ")", "# (batch_size, 2 * num_beams)", "\n", "", "else", ":", "\n", "# do greedy beam search", "\n", "                ", "scores", "=", "F", ".", "log_softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "# (batch_size * num_beams, vocab_size)", "\n", "assert", "scores", ".", "size", "(", ")", "==", "(", "batch_size", "*", "num_beams", ",", "vocab_size", ")", "\n", "# Add the log prob of the new beams to the log prob of the beginning of the sequence (sum of logs == log of the product)", "\n", "_scores", "=", "scores", "+", "beam_scores", "[", ":", ",", "None", "]", ".", "expand_as", "(", "scores", ")", "# (batch_size * num_beams, vocab_size)", "\n", "# re-organize to group the beam together (we are keeping top hypothesis accross beams)", "\n", "_scores", "=", "_scores", ".", "view", "(", "batch_size", ",", "num_beams", "*", "vocab_size", ")", "# (batch_size, num_beams * vocab_size)", "\n", "next_scores", ",", "next_words", "=", "torch", ".", "topk", "(", "_scores", ",", "2", "*", "num_beams", ",", "dim", "=", "1", ",", "largest", "=", "True", ",", "sorted", "=", "True", ")", "\n", "\n", "", "assert", "next_scores", ".", "size", "(", ")", "==", "next_words", ".", "size", "(", ")", "==", "(", "batch_size", ",", "2", "*", "num_beams", ")", "\n", "\n", "# next batch beam content", "\n", "# list of (batch_size * num_beams) tuple(next hypothesis score, next word, current position in the batch)", "\n", "next_batch_beam", "=", "[", "]", "\n", "\n", "# for each sentence", "\n", "for", "batch_ex", "in", "range", "(", "batch_size", ")", ":", "\n", "\n", "# if we are done with this sentence", "\n", "                ", "done", "[", "batch_ex", "]", "=", "done", "[", "batch_ex", "]", "or", "generated_hyps", "[", "batch_ex", "]", ".", "is_done", "(", "next_scores", "[", "batch_ex", "]", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "if", "done", "[", "batch_ex", "]", ":", "\n", "                    ", "next_batch_beam", ".", "extend", "(", "[", "(", "0", ",", "pad_token_id", ",", "0", ")", "]", "*", "num_beams", ")", "# pad the batch", "\n", "continue", "\n", "\n", "# next sentence beam content", "\n", "", "next_sent_beam", "=", "[", "]", "\n", "\n", "# next words for this sentence", "\n", "for", "idx", ",", "score", "in", "zip", "(", "next_words", "[", "batch_ex", "]", ",", "next_scores", "[", "batch_ex", "]", ")", ":", "\n", "\n", "# get beam and word IDs", "\n", "                    ", "beam_id", "=", "idx", "//", "vocab_size", "\n", "word_id", "=", "idx", "%", "vocab_size", "\n", "\n", "# end of sentence, or next word", "\n", "if", "word_id", ".", "item", "(", ")", "in", "eos_token_ids", "or", "cur_len", "+", "1", "==", "max_length", ":", "\n", "                        ", "generated_hyps", "[", "batch_ex", "]", ".", "add", "(", "\n", "input_ids", "[", "batch_ex", "*", "num_beams", "+", "beam_id", ",", ":", "cur_len", "]", ".", "clone", "(", ")", ",", "score", ".", "item", "(", ")", "\n", ")", "\n", "", "else", ":", "\n", "                        ", "next_sent_beam", ".", "append", "(", "(", "score", ",", "word_id", ",", "batch_ex", "*", "num_beams", "+", "beam_id", ")", ")", "\n", "\n", "# the beam for next step is full", "\n", "", "if", "len", "(", "next_sent_beam", ")", "==", "num_beams", ":", "\n", "                        ", "break", "\n", "\n", "# update next beam content", "\n", "", "", "assert", "len", "(", "next_sent_beam", ")", "==", "0", "if", "cur_len", "+", "1", "==", "max_length", "else", "num_beams", "\n", "if", "len", "(", "next_sent_beam", ")", "==", "0", ":", "\n", "                    ", "next_sent_beam", "=", "[", "(", "0", ",", "pad_token_id", ",", "0", ")", "]", "*", "num_beams", "# pad the batch", "\n", "", "next_batch_beam", ".", "extend", "(", "next_sent_beam", ")", "\n", "assert", "len", "(", "next_batch_beam", ")", "==", "num_beams", "*", "(", "batch_ex", "+", "1", ")", "\n", "\n", "# sanity check / prepare next batch", "\n", "", "assert", "len", "(", "next_batch_beam", ")", "==", "batch_size", "*", "num_beams", "\n", "beam_scores", "=", "beam_scores", ".", "new", "(", "[", "x", "[", "0", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "beam_words", "=", "input_ids", ".", "new", "(", "[", "x", "[", "1", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "beam_idx", "=", "input_ids", ".", "new", "(", "[", "x", "[", "2", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "\n", "# re-order batch", "\n", "input_ids", "=", "input_ids", "[", "beam_idx", ",", ":", "]", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "input_ids", ",", "beam_words", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# re-order internal states", "\n", "if", "past", ":", "\n", "                ", "reordered_past", "=", "[", "]", "\n", "for", "layer_past", "in", "past", ":", "\n", "# get the correct batch idx from layer past batch dim", "\n", "# batch dim of `past` and `mems` is at 2nd position", "\n", "                    ", "reordered_layer_past", "=", "[", "layer_past", "[", ":", ",", "i", "]", ".", "unsqueeze", "(", "1", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "for", "i", "in", "beam_idx", "]", "\n", "reordered_layer_past", "=", "torch", ".", "cat", "(", "reordered_layer_past", ",", "dim", "=", "1", ")", "\n", "# check that shape matches", "\n", "assert", "reordered_layer_past", ".", "shape", "==", "layer_past", ".", "shape", "\n", "reordered_past", ".", "append", "(", "reordered_layer_past", ")", "\n", "", "past", "=", "tuple", "(", "reordered_past", ")", "\n", "\n", "# update current length", "\n", "", "cur_len", "=", "cur_len", "+", "1", "\n", "\n", "# stop when we are done with each sentence", "\n", "if", "all", "(", "done", ")", ":", "\n", "                ", "break", "\n", "\n", "# visualize hypotheses", "\n", "# print([len(x) for x in generated_hyps], cur_len)", "\n", "# globals().update( locals() );", "\n", "# !import code; code.interact(local=vars())", "\n", "# for ii in range(batch_size):", "\n", "#     for ss, ww in sorted(generated_hyps[ii].hyp, key=lambda x: x[0], reverse=True):", "\n", "#         print(\"%.3f \" % ss + \" \".join(self.dico[x] for x in ww.tolist()))", "\n", "#     print(\"\")", "\n", "\n", "# select the best hypotheses", "\n", "", "", "tgt_len", "=", "input_ids", ".", "new", "(", "batch_size", ")", "\n", "best", "=", "[", "]", "\n", "\n", "for", "i", ",", "hypotheses", "in", "enumerate", "(", "generated_hyps", ")", ":", "\n", "            ", "best_hyp", "=", "max", "(", "hypotheses", ".", "hyp", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "[", "1", "]", "\n", "tgt_len", "[", "i", "]", "=", "len", "(", "best_hyp", ")", "+", "1", "# +1 for the <EOS> symbol", "\n", "best", ".", "append", "(", "best_hyp", ")", "\n", "\n", "# generate target batch", "\n", "", "decoded", "=", "input_ids", ".", "new", "(", "batch_size", ",", "tgt_len", ".", "max", "(", ")", ".", "item", "(", ")", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "for", "i", ",", "hypo", "in", "enumerate", "(", "best", ")", ":", "\n", "            ", "decoded", "[", "i", ",", ":", "tgt_len", "[", "i", "]", "-", "1", "]", "=", "hypo", "\n", "decoded", "[", "i", ",", "tgt_len", "[", "i", "]", "-", "1", "]", "=", "eos_token_ids", "[", "0", "]", "\n", "\n", "", "return", "decoded", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.BeamHypotheses.__init__": [[1056, 1066], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "n_hyp", ",", "max_length", ",", "length_penalty", ",", "early_stopping", ")", ":", "\n", "        ", "\"\"\"\n        Initialize n-best list of hypotheses.\n        \"\"\"", "\n", "self", ".", "max_length", "=", "max_length", "-", "1", "# ignoring bos_token", "\n", "self", ".", "length_penalty", "=", "length_penalty", "\n", "self", ".", "early_stopping", "=", "early_stopping", "\n", "self", ".", "n_hyp", "=", "n_hyp", "\n", "self", ".", "hyp", "=", "[", "]", "\n", "self", ".", "worst_score", "=", "1e9", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.BeamHypotheses.__len__": [[1067, 1072], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Number of hypotheses in the list.\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "hyp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.BeamHypotheses.add": [[1073, 1086], ["modeling_utils.BeamHypotheses.hyp.append", "len", "len", "len", "sorted", "min", "enumerate"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "hyp", ",", "sum_logprobs", ")", ":", "\n", "        ", "\"\"\"\n        Add a new hypothesis to the list.\n        \"\"\"", "\n", "score", "=", "sum_logprobs", "/", "len", "(", "hyp", ")", "**", "self", ".", "length_penalty", "\n", "if", "len", "(", "self", ")", "<", "self", ".", "n_hyp", "or", "score", ">", "self", ".", "worst_score", ":", "\n", "            ", "self", ".", "hyp", ".", "append", "(", "(", "score", ",", "hyp", ")", ")", "\n", "if", "len", "(", "self", ")", ">", "self", ".", "n_hyp", ":", "\n", "                ", "sorted_scores", "=", "sorted", "(", "[", "(", "s", ",", "idx", ")", "for", "idx", ",", "(", "s", ",", "_", ")", "in", "enumerate", "(", "self", ".", "hyp", ")", "]", ")", "\n", "del", "self", ".", "hyp", "[", "sorted_scores", "[", "0", "]", "[", "1", "]", "]", "\n", "self", ".", "worst_score", "=", "sorted_scores", "[", "1", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "worst_score", "=", "min", "(", "score", ",", "self", ".", "worst_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.BeamHypotheses.is_done": [[1087, 1098], ["len"], "methods", ["None"], ["", "", "", "def", "is_done", "(", "self", ",", "best_sum_logprobs", ")", ":", "\n", "        ", "\"\"\"\n        If there are enough hypotheses and that none of the hypotheses being generated\n        can become better than the worst one in the heap, then we are done with this sentence.\n        \"\"\"", "\n", "if", "len", "(", "self", ")", "<", "self", ".", "n_hyp", ":", "\n", "            ", "return", "False", "\n", "", "elif", "self", ".", "early_stopping", ":", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "worst_score", ">=", "best_sum_logprobs", "/", "self", ".", "max_length", "**", "self", ".", "length_penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.Conv1D.__init__": [[1101, 1111], ["torch.nn.Module.__init__", "torch.empty", "torch.nn.init.normal_", "torch.nn.Parameter", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "nx", ")", ":", "\n", "        ", "\"\"\" Conv1D layer as defined by Radford et al. for OpenAI GPT (and also used in GPT-2)\n            Basically works like a Linear layer but the weights are transposed\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nf", "=", "nf", "\n", "w", "=", "torch", ".", "empty", "(", "nx", ",", "nf", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "w", ",", "std", "=", "0.02", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "w", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "nf", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.Conv1D.forward": [[1112, 1118], ["torch.addmm", "x.view.view.view", "x.view.view.view", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "size_out", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "nf", ",", ")", "\n", "#print(size_out)", "\n", "x", "=", "torch", ".", "addmm", "(", "self", ".", "bias", ",", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", ",", "self", ".", "weight", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "size_out", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PoolerStartLogits.__init__": [[1123, 1126], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PoolerStartLogits.forward": [[1127, 1142], ["modeling_utils.PoolerStartLogits.dense().squeeze", "modeling_utils.PoolerStartLogits.dense", "next", "modeling_utils.PoolerStartLogits.parameters"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "p_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\" Args:\n            **p_mask**: (`optional`) ``torch.FloatTensor`` of shape `(batch_size, seq_len)`\n                invalid position mask such as query and special symbols (PAD, SEP, CLS)\n                1.0 means token should be masked.\n        \"\"\"", "\n", "x", "=", "self", ".", "dense", "(", "hidden_states", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "if", "p_mask", "is", "not", "None", ":", "\n", "            ", "if", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "                ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "65500", "*", "p_mask", "\n", "", "else", ":", "\n", "                ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "1e30", "*", "p_mask", "\n", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PoolerEndLogits.__init__": [[1148, 1154], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.LayerNorm", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense_0", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dense_1", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PoolerEndLogits.forward": [[1155, 1189], ["modeling_utils.PoolerEndLogits.dense_0", "modeling_utils.PoolerEndLogits.activation", "modeling_utils.PoolerEndLogits.LayerNorm", "modeling_utils.PoolerEndLogits.dense_1().squeeze", "start_positions[].expand", "hidden_states.gather", "start_states.expand.expand.expand", "torch.cat", "modeling_utils.PoolerEndLogits.dense_1", "next", "modeling_utils.PoolerEndLogits.parameters"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "start_states", "=", "None", ",", "start_positions", "=", "None", ",", "p_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\" Args:\n            One of ``start_states``, ``start_positions`` should be not None.\n            If both are set, ``start_positions`` overrides ``start_states``.\n\n            **start_states**: ``torch.LongTensor`` of shape identical to hidden_states\n                hidden states of the first tokens for the labeled span.\n            **start_positions**: ``torch.LongTensor`` of shape ``(batch_size,)``\n                position of the first token for the labeled span:\n            **p_mask**: (`optional`) ``torch.FloatTensor`` of shape ``(batch_size, seq_len)``\n                Mask of invalid position such as query and special symbols (PAD, SEP, CLS)\n                1.0 means token should be masked.\n        \"\"\"", "\n", "assert", "(", "\n", "start_states", "is", "not", "None", "or", "start_positions", "is", "not", "None", "\n", ")", ",", "\"One of start_states, start_positions should be not None\"", "\n", "if", "start_positions", "is", "not", "None", ":", "\n", "            ", "slen", ",", "hsz", "=", "hidden_states", ".", "shape", "[", "-", "2", ":", "]", "\n", "start_positions", "=", "start_positions", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "start_positions", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "start_states", ".", "expand", "(", "-", "1", ",", "slen", ",", "-", "1", ")", "# shape (bsz, slen, hsz)", "\n", "\n", "", "x", "=", "self", ".", "dense_0", "(", "torch", ".", "cat", "(", "[", "hidden_states", ",", "start_states", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "LayerNorm", "(", "x", ")", "\n", "x", "=", "self", ".", "dense_1", "(", "x", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "if", "p_mask", "is", "not", "None", ":", "\n", "            ", "if", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "                ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "65500", "*", "p_mask", "\n", "", "else", ":", "\n", "                ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "1e30", "*", "p_mask", "\n", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PoolerAnswerClass.__init__": [[1194, 1199], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense_0", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "dense_1", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PoolerAnswerClass.forward": [[1200, 1236], ["modeling_utils.PoolerAnswerClass.dense_0", "modeling_utils.PoolerAnswerClass.activation", "modeling_utils.PoolerAnswerClass.dense_1().squeeze", "start_positions[].expand", "hidden_states.gather().squeeze", "cls_index[].expand", "hidden_states.gather().squeeze", "torch.cat", "modeling_utils.PoolerAnswerClass.dense_1", "hidden_states.gather", "hidden_states.gather"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "start_states", "=", "None", ",", "start_positions", "=", "None", ",", "cls_index", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            One of ``start_states``, ``start_positions`` should be not None.\n            If both are set, ``start_positions`` overrides ``start_states``.\n\n            **start_states**: ``torch.LongTensor`` of shape identical to ``hidden_states``.\n                hidden states of the first tokens for the labeled span.\n            **start_positions**: ``torch.LongTensor`` of shape ``(batch_size,)``\n                position of the first token for the labeled span.\n            **cls_index**: torch.LongTensor of shape ``(batch_size,)``\n                position of the CLS token. If None, take the last token.\n\n            note(Original repo):\n                no dependency on end_feature so that we can obtain one single `cls_logits`\n                for each sample\n        \"\"\"", "\n", "hsz", "=", "hidden_states", ".", "shape", "[", "-", "1", "]", "\n", "assert", "(", "\n", "start_states", "is", "not", "None", "or", "start_positions", "is", "not", "None", "\n", ")", ",", "\"One of start_states, start_positions should be not None\"", "\n", "if", "start_positions", "is", "not", "None", ":", "\n", "            ", "start_positions", "=", "start_positions", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "start_positions", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, hsz)", "\n", "\n", "", "if", "cls_index", "is", "not", "None", ":", "\n", "            ", "cls_index", "=", "cls_index", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "cls_token_state", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "cls_index", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, hsz)", "\n", "", "else", ":", "\n", "            ", "cls_token_state", "=", "hidden_states", "[", ":", ",", "-", "1", ",", ":", "]", "# shape (bsz, hsz)", "\n", "\n", "", "x", "=", "self", ".", "dense_0", "(", "torch", ".", "cat", "(", "[", "start_states", ",", "cls_token_state", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "dense_1", "(", "x", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.SQuADHead.__init__": [[1279, 1287], ["torch.nn.Module.__init__", "modeling_utils.PoolerStartLogits", "modeling_utils.PoolerEndLogits", "modeling_utils.PoolerAnswerClass"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "start_n_top", "=", "config", ".", "start_n_top", "\n", "self", ".", "end_n_top", "=", "config", ".", "end_n_top", "\n", "\n", "self", ".", "start_logits", "=", "PoolerStartLogits", "(", "config", ")", "\n", "self", ".", "end_logits", "=", "PoolerEndLogits", "(", "config", ")", "\n", "self", ".", "answer_class", "=", "PoolerAnswerClass", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.SQuADHead.forward": [[1288, 1353], ["modeling_utils.SQuADHead.start_logits", "modeling_utils.SQuADHead.end_logits", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "hidden_states.size", "torch.nn.functional.softmax", "torch.topk", "start_top_index.unsqueeze().expand", "torch.gather", "torch.einsum.unsqueeze().expand", "hidden_states.unsqueeze().expand_as", "modeling_utils.SQuADHead.end_logits", "torch.nn.functional.softmax", "torch.topk", "end_top_log_probs.view.view.view", "end_top_index.view.view.view", "torch.einsum", "modeling_utils.SQuADHead.answer_class", "modeling_utils.SQuADHead.answer_class", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss.", "p_mask.unsqueeze", "x.squeeze_", "start_top_index.unsqueeze", "torch.einsum.unsqueeze", "hidden_states.unsqueeze", "x.dim"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "hidden_states", ",", "start_positions", "=", "None", ",", "end_positions", "=", "None", ",", "cls_index", "=", "None", ",", "is_impossible", "=", "None", ",", "p_mask", "=", "None", "\n", ")", ":", "\n", "        ", "outputs", "=", "(", ")", "\n", "\n", "start_logits", "=", "self", ".", "start_logits", "(", "hidden_states", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, let's remove the dimension added by batch splitting", "\n", "            ", "for", "x", "in", "(", "start_positions", ",", "end_positions", ",", "cls_index", ",", "is_impossible", ")", ":", "\n", "                ", "if", "x", "is", "not", "None", "and", "x", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "x", ".", "squeeze_", "(", "-", "1", ")", "\n", "\n", "# during training, compute the end logits based on the ground truth of the start position", "\n", "", "", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "\n", "if", "cls_index", "is", "not", "None", "and", "is_impossible", "is", "not", "None", ":", "\n", "# Predict answerability from the representation of CLS and START", "\n", "                ", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "cls_index", "=", "cls_index", ")", "\n", "loss_fct_cls", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "cls_loss", "=", "loss_fct_cls", "(", "cls_logits", ",", "is_impossible", ")", "\n", "\n", "# note(zhiliny): by default multiply the loss by 0.5 so that the scale is comparable to start_loss and end_loss", "\n", "total_loss", "+=", "cls_loss", "*", "0.5", "\n", "\n", "", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "else", ":", "\n", "# during inference, compute the end logits based on beam search", "\n", "            ", "bsz", ",", "slen", ",", "hsz", "=", "hidden_states", ".", "size", "(", ")", "\n", "start_log_probs", "=", "F", ".", "softmax", "(", "start_logits", ",", "dim", "=", "-", "1", ")", "# shape (bsz, slen)", "\n", "\n", "start_top_log_probs", ",", "start_top_index", "=", "torch", ".", "topk", "(", "\n", "start_log_probs", ",", "self", ".", "start_n_top", ",", "dim", "=", "-", "1", "\n", ")", "# shape (bsz, start_n_top)", "\n", "start_top_index_exp", "=", "start_top_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "torch", ".", "gather", "(", "hidden_states", ",", "-", "2", ",", "start_top_index_exp", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "start_states", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "slen", ",", "-", "1", ",", "-", "1", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "\n", "hidden_states_expanded", "=", "hidden_states", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "\n", "start_states", "\n", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "p_mask", "=", "p_mask", ".", "unsqueeze", "(", "-", "1", ")", "if", "p_mask", "is", "not", "None", "else", "None", "\n", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states_expanded", ",", "start_states", "=", "start_states", ",", "p_mask", "=", "p_mask", ")", "\n", "end_log_probs", "=", "F", ".", "softmax", "(", "end_logits", ",", "dim", "=", "1", ")", "# shape (bsz, slen, start_n_top)", "\n", "\n", "end_top_log_probs", ",", "end_top_index", "=", "torch", ".", "topk", "(", "\n", "end_log_probs", ",", "self", ".", "end_n_top", ",", "dim", "=", "1", "\n", ")", "# shape (bsz, end_n_top, start_n_top)", "\n", "end_top_log_probs", "=", "end_top_log_probs", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "end_top_index", "=", "end_top_index", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "\n", "start_states", "=", "torch", ".", "einsum", "(", "\"blh,bl->bh\"", ",", "hidden_states", ",", "start_log_probs", ")", "\n", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_states", "=", "start_states", ",", "cls_index", "=", "cls_index", ")", "\n", "\n", "outputs", "=", "(", "start_top_log_probs", ",", "start_top_index", ",", "end_top_log_probs", ",", "end_top_index", ",", "cls_logits", ")", "+", "outputs", "\n", "\n", "# return start_top_log_probs, start_top_index, end_top_log_probs, end_top_index, cls_logits", "\n", "# or (if labels are provided) (total_loss,)", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.SequenceSummary.__init__": [[1371, 1400], ["torch.nn.Module.__init__", "Identity", "Identity", "Identity", "Identity", "hasattr", "hasattr", "torch.nn.Linear", "hasattr", "torch.nn.Tanh", "hasattr", "torch.nn.Dropout", "hasattr", "torch.nn.Dropout", "hasattr"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "summary_type", "=", "config", ".", "summary_type", "if", "hasattr", "(", "config", ",", "\"summary_type\"", ")", "else", "\"last\"", "\n", "if", "self", ".", "summary_type", "==", "\"attn\"", ":", "\n", "# We should use a standard multi-head attention module with absolute positional embedding for that.", "\n", "# Cf. https://github.com/zihangdai/xlnet/blob/master/modeling.py#L253-L276", "\n", "# We can probably just use the multi-head attention module of PyTorch >=1.1.0", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "summary", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "\"summary_use_proj\"", ")", "and", "config", ".", "summary_use_proj", ":", "\n", "            ", "if", "hasattr", "(", "config", ",", "\"summary_proj_to_labels\"", ")", "and", "config", ".", "summary_proj_to_labels", "and", "config", ".", "num_labels", ">", "0", ":", "\n", "                ", "num_classes", "=", "config", ".", "num_labels", "\n", "", "else", ":", "\n", "                ", "num_classes", "=", "config", ".", "hidden_size", "\n", "", "self", ".", "summary", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_classes", ")", "\n", "\n", "", "self", ".", "activation", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "\"summary_activation\"", ")", "and", "config", ".", "summary_activation", "==", "\"tanh\"", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n", "", "self", ".", "first_dropout", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "\"summary_first_dropout\"", ")", "and", "config", ".", "summary_first_dropout", ">", "0", ":", "\n", "            ", "self", ".", "first_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "summary_first_dropout", ")", "\n", "\n", "", "self", ".", "last_dropout", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "\"summary_last_dropout\"", ")", "and", "config", ".", "summary_last_dropout", ">", "0", ":", "\n", "            ", "self", ".", "last_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "summary_last_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.SequenceSummary.forward": [[1401, 1431], ["modeling_utils.SequenceSummary.first_dropout", "modeling_utils.SequenceSummary.summary", "modeling_utils.SequenceSummary.activation", "modeling_utils.SequenceSummary.last_dropout", "hidden_states.mean", "hidden_states.gather().squeeze", "torch.full_like", "cls_index.expand.expand.unsqueeze().unsqueeze", "cls_index.expand.expand.expand", "hidden_states.gather", "cls_index.expand.expand.unsqueeze", "hidden_states.size", "cls_index.expand.expand.dim"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "hidden_states", ",", "cls_index", "=", "None", ")", ":", "\n", "        ", "\"\"\" hidden_states: float Tensor in shape [bsz, ..., seq_len, hidden_size], the hidden-states of the last layer.\n            cls_index: [optional] position of the classification token if summary_type == 'cls_index',\n                shape (bsz,) or more generally (bsz, ...) where ... are optional leading dimensions of hidden_states.\n                if summary_type == 'cls_index' and cls_index is None:\n                    we take the last token of the sequence as classification token\n        \"\"\"", "\n", "if", "self", ".", "summary_type", "==", "\"last\"", ":", "\n", "            ", "output", "=", "hidden_states", "[", ":", ",", "-", "1", "]", "\n", "", "elif", "self", ".", "summary_type", "==", "\"first\"", ":", "\n", "            ", "output", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "", "elif", "self", ".", "summary_type", "==", "\"mean\"", ":", "\n", "            ", "output", "=", "hidden_states", ".", "mean", "(", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "summary_type", "==", "\"cls_index\"", ":", "\n", "            ", "if", "cls_index", "is", "None", ":", "\n", "                ", "cls_index", "=", "torch", ".", "full_like", "(", "hidden_states", "[", "...", ",", ":", "1", ",", ":", "]", ",", "hidden_states", ".", "shape", "[", "-", "2", "]", "-", "1", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "else", ":", "\n", "                ", "cls_index", "=", "cls_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "cls_index", "=", "cls_index", ".", "expand", "(", "(", "-", "1", ",", ")", "*", "(", "cls_index", ".", "dim", "(", ")", "-", "1", ")", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", ")", "\n", "# shape of cls_index: (bsz, XX, 1, hidden_size) where XX are optional leading dim of hidden_states", "\n", "", "output", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "cls_index", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, XX, hidden_size)", "\n", "", "elif", "self", ".", "summary_type", "==", "\"attn\"", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "output", "=", "self", ".", "first_dropout", "(", "output", ")", "\n", "output", "=", "self", ".", "summary", "(", "output", ")", "\n", "output", "=", "self", ".", "activation", "(", "output", ")", "\n", "output", "=", "self", ".", "last_dropout", "(", "output", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.top_k_top_p_filtering": [[1020, 1053], ["float", "min", "torch.sort", "torch.cumsum", "sorted_indices_to_remove[].clone", "sorted_indices_to_remove.scatter", "max", "logits.size", "torch.nn.functional.softmax", "torch.topk"], "function", ["None"], ["", "", "def", "top_k_top_p_filtering", "(", "logits", ",", "top_k", "=", "0", ",", "top_p", "=", "1.0", ",", "filter_value", "=", "-", "float", "(", "\"Inf\"", ")", ",", "min_tokens_to_keep", "=", "1", ")", ":", "\n", "    ", "\"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n        Args:\n            logits: logits distribution shape (batch size, vocabulary size)\n            if top_k > 0: keep only top k tokens with highest probability (top-k filtering).\n            if top_p < 1.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n            Make sure we keep at least min_tokens_to_keep per batch example in the output\n        From: https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317\n    \"\"\"", "\n", "if", "top_k", ">", "0", ":", "\n", "        ", "top_k", "=", "min", "(", "max", "(", "top_k", ",", "min_tokens_to_keep", ")", ",", "logits", ".", "size", "(", "-", "1", ")", ")", "# Safety check", "\n", "# Remove all tokens with a probability less than the last token of the top-k", "\n", "indices_to_remove", "=", "logits", "<", "torch", ".", "topk", "(", "logits", ",", "top_k", ")", "[", "0", "]", "[", "...", ",", "-", "1", ",", "None", "]", "\n", "logits", "[", "indices_to_remove", "]", "=", "filter_value", "\n", "\n", "", "if", "top_p", "<", "1.0", ":", "\n", "        ", "sorted_logits", ",", "sorted_indices", "=", "torch", ".", "sort", "(", "logits", ",", "descending", "=", "True", ")", "\n", "cumulative_probs", "=", "torch", ".", "cumsum", "(", "F", ".", "softmax", "(", "sorted_logits", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Remove tokens with cumulative probability above the threshold (token with 0 are kept)", "\n", "sorted_indices_to_remove", "=", "cumulative_probs", ">", "top_p", "\n", "if", "min_tokens_to_keep", ">", "1", ":", "\n", "# Keep at least min_tokens_to_keep (set to min_tokens_to_keep-1 because we add the first one below)", "\n", "            ", "sorted_indices_to_remove", "[", "...", ",", ":", "min_tokens_to_keep", "]", "=", "0", "\n", "# Shift the indices to the right to keep also the first token above the threshold", "\n", "", "sorted_indices_to_remove", "[", "...", ",", "1", ":", "]", "=", "sorted_indices_to_remove", "[", "...", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "sorted_indices_to_remove", "[", "...", ",", "0", "]", "=", "0", "\n", "\n", "# scatter sorted tensors to original indexing", "\n", "indices_to_remove", "=", "sorted_indices_to_remove", ".", "scatter", "(", "1", ",", "sorted_indices", ",", "sorted_indices_to_remove", ")", "\n", "logits", "[", "indices_to_remove", "]", "=", "filter_value", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.prune_linear_layer": [[1433, 1456], ["index.to.to", "layer.weight.index_select().clone().detach", "list", "len", "torch.nn.Linear().to", "nn.Linear().to.weight.copy_", "layer.weight.size", "layer.weight.index_select().clone().detach.contiguous", "nn.Linear().to.bias.copy_", "layer.weight.index_select().clone", "layer.bias.clone().detach", "layer.bias[].clone().detach", "torch.nn.Linear", "layer.bias[].clone().detach.contiguous", "layer.weight.index_select", "layer.bias.clone", "layer.bias[].clone"], "function", ["None"], ["", "", "def", "prune_linear_layer", "(", "layer", ",", "index", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\" Prune a linear layer (a model parameters) to keep only entries in index.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "index", "=", "index", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "W", "=", "layer", ".", "weight", ".", "index_select", "(", "dim", ",", "index", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "if", "layer", ".", "bias", "is", "not", "None", ":", "\n", "        ", "if", "dim", "==", "1", ":", "\n", "            ", "b", "=", "layer", ".", "bias", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "            ", "b", "=", "layer", ".", "bias", "[", "index", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "", "new_size", "=", "list", "(", "layer", ".", "weight", ".", "size", "(", ")", ")", "\n", "new_size", "[", "dim", "]", "=", "len", "(", "index", ")", "\n", "new_layer", "=", "nn", ".", "Linear", "(", "new_size", "[", "1", "]", ",", "new_size", "[", "0", "]", ",", "bias", "=", "layer", ".", "bias", "is", "not", "None", ")", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "weight", ".", "copy_", "(", "W", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "True", "\n", "if", "layer", ".", "bias", "is", "not", "None", ":", "\n", "        ", "new_layer", ".", "bias", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "bias", ".", "copy_", "(", "b", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "True", "\n", "", "return", "new_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.prune_conv1d_layer": [[1458, 1480], ["index.to.to", "layer.weight.index_select().clone().detach", "list", "len", "Conv1D().to", "Conv1D().to.weight.copy_", "Conv1D().to.bias.copy_", "layer.bias.clone().detach", "layer.bias[].clone().detach", "layer.weight.size", "layer.weight.index_select().clone().detach.contiguous", "layer.bias[].clone().detach.contiguous", "layer.weight.index_select().clone", "modeling_utils.Conv1D", "layer.bias.clone", "layer.bias[].clone", "layer.weight.index_select"], "function", ["None"], ["", "def", "prune_conv1d_layer", "(", "layer", ",", "index", ",", "dim", "=", "1", ")", ":", "\n", "    ", "\"\"\" Prune a Conv1D layer (a model parameters) to keep only entries in index.\n        A Conv1D work as a Linear layer (see e.g. BERT) but the weights are transposed.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "index", "=", "index", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "W", "=", "layer", ".", "weight", ".", "index_select", "(", "dim", ",", "index", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "if", "dim", "==", "0", ":", "\n", "        ", "b", "=", "layer", ".", "bias", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "        ", "b", "=", "layer", ".", "bias", "[", "index", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "new_size", "=", "list", "(", "layer", ".", "weight", ".", "size", "(", ")", ")", "\n", "new_size", "[", "dim", "]", "=", "len", "(", "index", ")", "\n", "new_layer", "=", "Conv1D", "(", "new_size", "[", "1", "]", ",", "new_size", "[", "0", "]", ")", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "weight", ".", "copy_", "(", "W", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "True", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "bias", ".", "copy_", "(", "b", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "True", "\n", "return", "new_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.prune_layer": [[1482, 1493], ["isinstance", "modeling_utils.prune_linear_layer", "isinstance", "modeling_utils.prune_conv1d_layer", "ValueError"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.prune_conv1d_layer"], ["", "def", "prune_layer", "(", "layer", ",", "index", ",", "dim", "=", "None", ")", ":", "\n", "    ", "\"\"\" Prune a Conv1D or nn.Linear layer (a model parameters) to keep only entries in index.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "if", "isinstance", "(", "layer", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "return", "prune_linear_layer", "(", "layer", ",", "index", ",", "dim", "=", "0", "if", "dim", "is", "None", "else", "dim", ")", "\n", "", "elif", "isinstance", "(", "layer", ",", "Conv1D", ")", ":", "\n", "        ", "return", "prune_conv1d_layer", "(", "layer", ",", "index", ",", "dim", "=", "1", "if", "dim", "is", "None", "else", "dim", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Can't prune layer of class {}\"", ".", "format", "(", "layer", ".", "__class__", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.__init__": [[53, 94], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "dict", "kwargs.pop", "dict", "kwargs.items", "dict", "zip", "setattr", "range", "int", "configuration_utils.PretrainedConfig.id2label.items", "configuration_utils.PretrainedConfig.id2label.values", "configuration_utils.PretrainedConfig.id2label.keys", "int", "configuration_utils.PretrainedConfig.label2id.items", "logger.error"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "# Attributes with defaults", "\n", "        ", "self", ".", "output_attentions", "=", "kwargs", ".", "pop", "(", "\"output_attentions\"", ",", "False", ")", "\n", "self", ".", "output_hidden_states", "=", "kwargs", ".", "pop", "(", "\"output_hidden_states\"", ",", "False", ")", "\n", "self", ".", "output_past", "=", "kwargs", ".", "pop", "(", "\"output_past\"", ",", "True", ")", "# Not used by all models", "\n", "self", ".", "torchscript", "=", "kwargs", ".", "pop", "(", "\"torchscript\"", ",", "False", ")", "# Only used by PyTorch models", "\n", "self", ".", "use_bfloat16", "=", "kwargs", ".", "pop", "(", "\"use_bfloat16\"", ",", "False", ")", "\n", "self", ".", "pruned_heads", "=", "kwargs", ".", "pop", "(", "\"pruned_heads\"", ",", "{", "}", ")", "\n", "\n", "# Is decoder is used in encoder-decoder models to differentiate encoder from decoder", "\n", "self", ".", "is_decoder", "=", "kwargs", ".", "pop", "(", "\"is_decoder\"", ",", "False", ")", "\n", "\n", "# Parameters for sequence generation", "\n", "self", ".", "max_length", "=", "kwargs", ".", "pop", "(", "\"max_length\"", ",", "20", ")", "\n", "self", ".", "do_sample", "=", "kwargs", ".", "pop", "(", "\"do_sample\"", ",", "False", ")", "\n", "self", ".", "num_beams", "=", "kwargs", ".", "pop", "(", "\"num_beams\"", ",", "1", ")", "\n", "self", ".", "temperature", "=", "kwargs", ".", "pop", "(", "\"temperature\"", ",", "1.0", ")", "\n", "self", ".", "top_k", "=", "kwargs", ".", "pop", "(", "\"top_k\"", ",", "50", ")", "\n", "self", ".", "top_p", "=", "kwargs", ".", "pop", "(", "\"top_p\"", ",", "1.0", ")", "\n", "self", ".", "repetition_penalty", "=", "kwargs", ".", "pop", "(", "\"repetition_penalty\"", ",", "1.0", ")", "\n", "self", ".", "bos_token_id", "=", "kwargs", ".", "pop", "(", "\"bos_token_id\"", ",", "0", ")", "\n", "self", ".", "pad_token_id", "=", "kwargs", ".", "pop", "(", "\"pad_token_id\"", ",", "0", ")", "\n", "self", ".", "eos_token_ids", "=", "kwargs", ".", "pop", "(", "\"eos_token_ids\"", ",", "0", ")", "\n", "self", ".", "length_penalty", "=", "kwargs", ".", "pop", "(", "\"length_penalty\"", ",", "1.0", ")", "\n", "self", ".", "num_return_sequences", "=", "kwargs", ".", "pop", "(", "\"num_return_sequences\"", ",", "1", ")", "\n", "\n", "# Fine-tuning task arguments", "\n", "self", ".", "finetuning_task", "=", "kwargs", ".", "pop", "(", "\"finetuning_task\"", ",", "None", ")", "\n", "self", ".", "num_labels", "=", "kwargs", ".", "pop", "(", "\"num_labels\"", ",", "2", ")", "\n", "self", ".", "id2label", "=", "kwargs", ".", "pop", "(", "\"id2label\"", ",", "{", "i", ":", "\"LABEL_{}\"", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "self", ".", "num_labels", ")", "}", ")", "\n", "self", ".", "id2label", "=", "dict", "(", "(", "int", "(", "key", ")", ",", "value", ")", "for", "key", ",", "value", "in", "self", ".", "id2label", ".", "items", "(", ")", ")", "\n", "self", ".", "label2id", "=", "kwargs", ".", "pop", "(", "\"label2id\"", ",", "dict", "(", "zip", "(", "self", ".", "id2label", ".", "values", "(", ")", ",", "self", ".", "id2label", ".", "keys", "(", ")", ")", ")", ")", "\n", "self", ".", "label2id", "=", "dict", "(", "(", "key", ",", "int", "(", "value", ")", ")", "for", "key", ",", "value", "in", "self", ".", "label2id", ".", "items", "(", ")", ")", "\n", "\n", "# Additional attributes without default values", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "", "except", "AttributeError", "as", "err", ":", "\n", "                ", "logger", ".", "error", "(", "\"Can't set {} with value {} for {}\"", ".", "format", "(", "key", ",", "value", ",", "self", ")", ")", "\n", "raise", "err", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.save_pretrained": [[95, 108], ["os.path.isdir", "os.path.join", "configuration_utils.PretrainedConfig.to_json_file", "logger.info"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.to_json_file"], ["", "", "", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save a configuration object to the directory `save_directory`, so that it\n            can be re-loaded using the :func:`~transformers.PretrainedConfig.from_pretrained` class method.\n        \"\"\"", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "\n", "save_directory", "\n", ")", ",", "\"Saving path should be a directory where the model and configuration can be saved\"", "\n", "\n", "# If we save using the predefined names, we can load using `from_pretrained`", "\n", "output_config_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "CONFIG_NAME", ")", "\n", "\n", "self", ".", "to_json_file", "(", "output_config_file", ")", "\n", "logger", ".", "info", "(", "\"Configuration saved in {}\"", ".", "format", "(", "output_config_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.from_pretrained": [[109, 162], ["cls.get_config_dict", "cls.from_dict"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.get_config_dict", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.from_dict"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\" Instantiate a :class:`~transformers.PretrainedConfig` (or a derived class) from a pre-trained model configuration.\n\n        Parameters:\n            pretrained_model_name_or_path: either:\n\n                - a string with the `shortcut name` of a pre-trained model configuration to load from cache or download, e.g.: ``bert-base-uncased``.\n                - a string with the `identifier name` of a pre-trained model configuration that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n                - a path to a `directory` containing a configuration file saved using the :func:`~transformers.PretrainedConfig.save_pretrained` method, e.g.: ``./my_model_directory/``.\n                - a path or url to a saved configuration JSON `file`, e.g.: ``./my_model_directory/configuration.json``.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            kwargs: (`optional`) dict: key/value pairs with which to update the configuration object after loading.\n\n                - The values in kwargs of any keys which are configuration attributes will be used to override the loaded values.\n                - Behavior concerning key/value pairs whose keys are *not* configuration attributes is controlled by the `return_unused_kwargs` keyword parameter.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            resume_download: (`optional`) boolean, default False:\n                Do not delete incompletely recieved file. Attempt to resume the download if such a file exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            return_unused_kwargs: (`optional`) bool:\n\n                - If False, then this function returns just the final configuration object.\n                - If True, then this functions returns a tuple `(config, unused_kwargs)` where `unused_kwargs` is a dictionary consisting of the key/value pairs whose keys are not configuration attributes: ie the part of kwargs which has not been used to update `config` and is otherwise ignored.\n\n        Examples::\n\n            # We can't instantiate directly the base class `PretrainedConfig` so let's show the examples on a\n            # derived class: BertConfig\n            config = BertConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n            config = BertConfig.from_pretrained('./test/saved_model/')  # E.g. config (or model) was saved using `save_pretrained('./test/saved_model/')`\n            config = BertConfig.from_pretrained('./test/saved_model/my_configuration.json')\n            config = BertConfig.from_pretrained('bert-base-uncased', output_attention=True, foo=False)\n            assert config.output_attention == True\n            config, unused_kwargs = BertConfig.from_pretrained('bert-base-uncased', output_attention=True,\n                                                               foo=False, return_unused_kwargs=True)\n            assert config.output_attention == True\n            assert unused_kwargs == {'foo': False}\n\n        \"\"\"", "\n", "config_dict", ",", "kwargs", "=", "cls", ".", "get_config_dict", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "return", "cls", ".", "from_dict", "(", "config_dict", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.get_config_dict": [[163, 236], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "os.path.isdir", "file_utils.cached_path", "cls._dict_from_json_file", "logger.info", "logger.info", "os.path.join", "EnvironmentError", "EnvironmentError", "os.path.isfile", "file_utils.is_remote_url", "file_utils.hf_bucket_url"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.cached_path", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig._dict_from_json_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.is_remote_url", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.file_utils.hf_bucket_url"], ["", "@", "classmethod", "\n", "def", "get_config_dict", "(", "\n", "cls", ",", "pretrained_model_name_or_path", ":", "str", ",", "pretrained_config_archive_map", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "**", "kwargs", "\n", ")", "->", "Tuple", "[", "Dict", ",", "Dict", "]", ":", "\n", "        ", "\"\"\"\n        From a `pretrained_model_name_or_path`, resolve to a dictionary of parameters, to be used\n        for instantiating a Config using `from_dict`.\n\n        Parameters:\n            pretrained_config_archive_map: (`optional`) Dict:\n                A map of `shortcut names` to `url`.\n                By default, will use the current class attribute.\n        \"\"\"", "\n", "cache_dir", "=", "kwargs", ".", "pop", "(", "\"cache_dir\"", ",", "None", ")", "\n", "force_download", "=", "kwargs", ".", "pop", "(", "\"force_download\"", ",", "False", ")", "\n", "resume_download", "=", "kwargs", ".", "pop", "(", "\"resume_download\"", ",", "False", ")", "\n", "proxies", "=", "kwargs", ".", "pop", "(", "\"proxies\"", ",", "None", ")", "\n", "\n", "if", "pretrained_config_archive_map", "is", "None", ":", "\n", "            ", "pretrained_config_archive_map", "=", "cls", ".", "pretrained_config_archive_map", "\n", "\n", "", "if", "pretrained_model_name_or_path", "in", "pretrained_config_archive_map", ":", "\n", "            ", "config_file", "=", "pretrained_config_archive_map", "[", "pretrained_model_name_or_path", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "            ", "config_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "CONFIG_NAME", ")", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "pretrained_model_name_or_path", ")", "or", "is_remote_url", "(", "pretrained_model_name_or_path", ")", ":", "\n", "            ", "config_file", "=", "pretrained_model_name_or_path", "\n", "", "else", ":", "\n", "            ", "config_file", "=", "hf_bucket_url", "(", "pretrained_model_name_or_path", ",", "postfix", "=", "CONFIG_NAME", ")", "\n", "\n", "", "try", ":", "\n", "# Load from URL or cache if already cached", "\n", "            ", "resolved_config_file", "=", "cached_path", "(", "\n", "config_file", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", "force_download", "=", "force_download", ",", "\n", "proxies", "=", "proxies", ",", "\n", "resume_download", "=", "resume_download", ",", "\n", ")", "\n", "# Load config dict", "\n", "if", "resolved_config_file", "is", "None", ":", "\n", "                ", "raise", "EnvironmentError", "\n", "", "config_dict", "=", "cls", ".", "_dict_from_json_file", "(", "resolved_config_file", ")", "\n", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "pretrained_config_archive_map", ":", "\n", "                ", "msg", "=", "\"Couldn't reach server at '{}' to download pretrained model configuration file.\"", ".", "format", "(", "\n", "config_file", "\n", ")", "\n", "", "else", ":", "\n", "                ", "msg", "=", "(", "\n", "\"Model name '{}' was not found in model name list. \"", "\n", "\"We assumed '{}' was a path, a model identifier, or url to a configuration file named {} or \"", "\n", "\"a directory containing such a file but couldn't find any such file at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "config_file", ",", "CONFIG_NAME", ",", "\n", ")", "\n", ")", "\n", "", "raise", "EnvironmentError", "(", "msg", ")", "\n", "\n", "", "except", "json", ".", "JSONDecodeError", ":", "\n", "            ", "msg", "=", "(", "\n", "\"Couldn't reach server at '{}' to download configuration file or \"", "\n", "\"configuration file is not a valid JSON file. \"", "\n", "\"Please check network or file content here: {}.\"", ".", "format", "(", "config_file", ",", "resolved_config_file", ")", "\n", ")", "\n", "raise", "EnvironmentError", "(", "msg", ")", "\n", "\n", "", "if", "resolved_config_file", "==", "config_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading configuration file {}\"", ".", "format", "(", "config_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading configuration file {} from cache at {}\"", ".", "format", "(", "config_file", ",", "resolved_config_file", ")", ")", "\n", "\n", "", "return", "config_dict", ",", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.from_dict": [[237, 261], ["kwargs.pop", "cls", "hasattr", "kwargs.items", "logger.info", "dict", "hasattr", "kwargs.pop", "str", "setattr", "to_remove.append", "int", "cls.pruned_heads.items"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "config_dict", ":", "Dict", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Constructs a `Config` from a Python dictionary of parameters.\"\"\"", "\n", "return_unused_kwargs", "=", "kwargs", ".", "pop", "(", "\"return_unused_kwargs\"", ",", "False", ")", "\n", "\n", "config", "=", "cls", "(", "**", "config_dict", ")", "\n", "\n", "if", "hasattr", "(", "config", ",", "\"pruned_heads\"", ")", ":", "\n", "            ", "config", ".", "pruned_heads", "=", "dict", "(", "(", "int", "(", "key", ")", ",", "value", ")", "for", "key", ",", "value", "in", "config", ".", "pruned_heads", ".", "items", "(", ")", ")", "\n", "\n", "# Update config with kwargs if needed", "\n", "", "to_remove", "=", "[", "]", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "hasattr", "(", "config", ",", "key", ")", ":", "\n", "                ", "setattr", "(", "config", ",", "key", ",", "value", ")", "\n", "to_remove", ".", "append", "(", "key", ")", "\n", "", "", "for", "key", "in", "to_remove", ":", "\n", "            ", "kwargs", ".", "pop", "(", "key", ",", "None", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Model config %s\"", ",", "str", "(", "config", ")", ")", "\n", "if", "return_unused_kwargs", ":", "\n", "            ", "return", "config", ",", "kwargs", "\n", "", "else", ":", "\n", "            ", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.from_json_file": [[262, 267], ["cls._dict_from_json_file", "cls"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig._dict_from_json_file"], ["", "", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ":", "str", ")", ":", "\n", "        ", "\"\"\"Constructs a `Config` from the path to a json file of parameters.\"\"\"", "\n", "config_dict", "=", "cls", ".", "_dict_from_json_file", "(", "json_file", ")", "\n", "return", "cls", "(", "**", "config_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig._dict_from_json_file": [[268, 273], ["json.loads", "open", "reader.read"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_dict_from_json_file", "(", "cls", ",", "json_file", ":", "str", ")", ":", "\n", "        ", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "json", ".", "loads", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.__eq__": [[274, 276], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "__dict__", "==", "other", ".", "__dict__", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.__repr__": [[277, 279], ["configuration_utils.PretrainedConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"{} {}\"", ".", "format", "(", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.to_dict": [[280, 286], ["copy.deepcopy", "hasattr"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "if", "hasattr", "(", "self", ".", "__class__", ",", "\"model_type\"", ")", ":", "\n", "            ", "output", "[", "\"model_type\"", "]", "=", "self", ".", "__class__", ".", "model_type", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.to_json_string": [[287, 290], ["json.dumps", "configuration_utils.PretrainedConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.to_json_file": [[291, 295], ["open", "writer.write", "configuration_utils.PretrainedConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.to_json_string"], ["", "def", "to_json_file", "(", "self", ",", "json_file_path", ")", ":", "\n", "        ", "\"\"\" Save this instance to a json file.\"\"\"", "\n", "with", "open", "(", "json_file_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_openai.OpenAIGPTConfig.__init__": [[119, 161], ["configuration_utils.PretrainedConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", "=", "40478", ",", "\n", "n_positions", "=", "512", ",", "\n", "n_ctx", "=", "512", ",", "\n", "n_embd", "=", "768", ",", "\n", "n_layer", "=", "12", ",", "\n", "n_head", "=", "12", ",", "\n", "afn", "=", "\"gelu\"", ",", "\n", "resid_pdrop", "=", "0.1", ",", "\n", "embd_pdrop", "=", "0.1", ",", "\n", "attn_pdrop", "=", "0.1", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "predict_special_tokens", "=", "True", ",", "\n", "summary_type", "=", "\"cls_index\"", ",", "\n", "summary_use_proj", "=", "True", ",", "\n", "summary_activation", "=", "None", ",", "\n", "summary_proj_to_labels", "=", "True", ",", "\n", "summary_first_dropout", "=", "0.1", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "self", ".", "n_positions", "=", "n_positions", "\n", "self", ".", "n_embd", "=", "n_embd", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "afn", "=", "afn", "\n", "self", ".", "resid_pdrop", "=", "resid_pdrop", "\n", "self", ".", "embd_pdrop", "=", "embd_pdrop", "\n", "self", ".", "attn_pdrop", "=", "attn_pdrop", "\n", "self", ".", "layer_norm_epsilon", "=", "layer_norm_epsilon", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "predict_special_tokens", "=", "predict_special_tokens", "\n", "self", ".", "summary_type", "=", "summary_type", "\n", "self", ".", "summary_use_proj", "=", "summary_use_proj", "\n", "self", ".", "summary_activation", "=", "summary_activation", "\n", "self", ".", "summary_first_dropout", "=", "summary_first_dropout", "\n", "self", ".", "summary_proj_to_labels", "=", "summary_proj_to_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_openai.OpenAIGPTConfig.max_position_embeddings": [[162, 165], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_openai.OpenAIGPTConfig.hidden_size": [[166, 169], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_embd", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_openai.OpenAIGPTConfig.num_attention_heads": [[170, 173], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_head", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_openai.OpenAIGPTConfig.num_hidden_layers": [[174, 177], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layer", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.utils.prepare_position_embeddings": [[4, 12], ["len", "sequences.repeat.size", "torch.LongTensor().to", "sequences.repeat.repeat", "torch.LongTensor", "range"], "function", ["None"], ["        ", "print", "(", "type", "(", "loss", ")", ")", "\n", "raise", "\n", "\n", "", "nums", "[", "name", "]", "+=", "bs", "\n", "\n", "losses", "[", "name", "]", "+=", "loss", "*", "bs", "\n", "\n", "\n", "", "def", "update_generation_losses", "(", "losses", ",", "nums", ",", "micro", ",", "macro", ",", "bs", ",", "length", ",", "loss", ",", "s", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Attention.__init__": [[103, 120], ["torch.Module.__init__", "knowledge_text_gpt2.Attention.register_buffer", "modeling_utils.Conv1D", "modeling_utils.Conv1D", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "set", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "n_state", "=", "nx", "# in Attention: n_state=768 (nx=n_embd)", "\n", "# [switch nx => n_state from Block to Attention to keep identical to TF implem]", "\n", "assert", "n_state", "%", "config", ".", "n_head", "==", "0", "\n", "self", ".", "register_buffer", "(", "\"bias\"", ",", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "n_ctx", ",", "n_ctx", ")", ")", ".", "view", "(", "1", ",", "1", ",", "n_ctx", ",", "n_ctx", ")", ")", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "split_size", "=", "n_state", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "self", ".", "c_attn", "=", "Conv1D", "(", "n_state", "*", "3", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "attn_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attn_pdrop", ")", "\n", "self", ".", "resid_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Attention.prune_heads": [[121, 142], ["torch.ones", "torch.ones", "torch.ones", "torch.ones", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous().eq", "[].long", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_utils.prune_conv1d_layer", "modeling_utils.prune_conv1d_layer", "knowledge_text_gpt2.Attention.pruned_heads.union", "len", "set", "len", "sum", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous", "len", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "mask.view().contiguous().eq.view().contiguous().eq.view", "len"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.prune_conv1d_layer", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.prune_conv1d_layer"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "mask", "=", "torch", ".", "ones", "(", "self", ".", "n_head", ",", "self", ".", "split_size", "//", "self", ".", "n_head", ")", "\n", "heads", "=", "set", "(", "heads", ")", "-", "self", ".", "pruned_heads", "# Convert to set and emove already pruned heads", "\n", "for", "head", "in", "heads", ":", "\n", "# Compute how many pruned heads are before the head and move the index accordingly", "\n", "            ", "head", "=", "head", "-", "sum", "(", "1", "if", "h", "<", "head", "else", "0", "for", "h", "in", "self", ".", "pruned_heads", ")", "\n", "mask", "[", "head", "]", "=", "0", "\n", "", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "eq", "(", "1", ")", "\n", "index", "=", "torch", ".", "arange", "(", "len", "(", "mask", ")", ")", "[", "mask", "]", ".", "long", "(", ")", "\n", "index_attn", "=", "torch", ".", "cat", "(", "[", "index", ",", "index", "+", "self", ".", "split_size", ",", "index", "+", "(", "2", "*", "self", ".", "split_size", ")", "]", ")", "\n", "\n", "# Prune conv1d layers", "\n", "self", ".", "c_attn", "=", "prune_conv1d_layer", "(", "self", ".", "c_attn", ",", "index_attn", ",", "dim", "=", "1", ")", "\n", "self", ".", "c_proj", "=", "prune_conv1d_layer", "(", "self", ".", "c_proj", ",", "index", ",", "dim", "=", "0", ")", "\n", "\n", "# Update hyper params", "\n", "self", ".", "split_size", "=", "(", "self", ".", "split_size", "//", "self", ".", "n_head", ")", "*", "(", "self", ".", "n_head", "-", "len", "(", "heads", ")", ")", "\n", "self", ".", "n_head", "=", "self", ".", "n_head", "-", "len", "(", "heads", ")", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Attention._attn": [[143, 166], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "knowledge_text_gpt2.Attention.attn_dropout", "knowledge_text_gpt2.Attention.size", "knowledge_text_gpt2.Attention.size", "torch.Softmax", "torch.Softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "outputs.append", "math.sqrt", "v.size"], "methods", ["None"], ["", "def", "_attn", "(", "self", ",", "q", ",", "k", ",", "v", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "w", "=", "torch", ".", "matmul", "(", "q", ",", "k", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "w", "=", "w", "/", "math", ".", "sqrt", "(", "v", ".", "size", "(", "-", "1", ")", ")", "\n", "", "nd", ",", "ns", "=", "w", ".", "size", "(", "-", "2", ")", ",", "w", ".", "size", "(", "-", "1", ")", "\n", "b", "=", "self", ".", "bias", "[", ":", ",", ":", ",", "ns", "-", "nd", ":", "ns", ",", ":", "ns", "]", "\n", "w", "=", "w", "*", "b", "-", "1e4", "*", "(", "1", "-", "b", ")", "\n", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask", "\n", "            ", "w", "=", "w", "+", "attention_mask", "\n", "\n", "", "w", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "w", ")", "\n", "w", "=", "self", ".", "attn_dropout", "(", "w", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "w", "=", "w", "*", "head_mask", "\n", "\n", "", "outputs", "=", "[", "torch", ".", "matmul", "(", "w", ",", "v", ")", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "w", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Attention.merge_heads": [[167, 171], ["x.permute().contiguous.permute().contiguous.permute().contiguous", "x.permute().contiguous.permute().contiguous.view", "x.permute().contiguous.permute().contiguous.permute", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size"], "methods", ["None"], ["", "def", "merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "x", ".", "size", "(", "-", "2", ")", "*", "x", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "return", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct merge_states", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Attention.split_heads": [[172, 179], ["x.view.view.view", "x.view.view.permute", "x.view.view.permute", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "split_heads", "(", "self", ",", "x", ",", "k", "=", "False", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "n_head", ",", "x", ".", "size", "(", "-", "1", ")", "//", "self", ".", "n_head", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct split_states", "\n", "if", "k", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "# (batch, head, head_features, seq_length)", "\n", "", "else", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "# (batch, head, seq_length, head_features)", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Attention.forward": [[180, 201], ["knowledge_text_gpt2.Attention.c_attn", "knowledge_text_gpt2.Attention.split", "knowledge_text_gpt2.Attention.split_heads", "knowledge_text_gpt2.Attention.split_heads", "knowledge_text_gpt2.Attention.split_heads", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "knowledge_text_gpt2.Attention._attn", "knowledge_text_gpt2.Attention.merge_heads", "knowledge_text_gpt2.Attention.c_proj", "knowledge_text_gpt2.Attention.resid_dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "layer_past[].transpose", "torch.cat.transpose", "torch.cat.transpose"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Attention.split_heads", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Attention.split_heads", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Attention.split_heads", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Attention._attn", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Attention.merge_heads"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "layer_past", "=", "None", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "x", "=", "self", ".", "c_attn", "(", "x", ")", "\n", "query", ",", "key", ",", "value", "=", "x", ".", "split", "(", "self", ".", "split_size", ",", "dim", "=", "2", ")", "\n", "query", "=", "self", ".", "split_heads", "(", "query", ")", "\n", "key", "=", "self", ".", "split_heads", "(", "key", ",", "k", "=", "True", ")", "\n", "value", "=", "self", ".", "split_heads", "(", "value", ")", "\n", "if", "layer_past", "is", "not", "None", ":", "\n", "            ", "past_key", ",", "past_value", "=", "layer_past", "[", "0", "]", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "layer_past", "[", "1", "]", "# transpose back cf below", "\n", "key", "=", "torch", ".", "cat", "(", "(", "past_key", ",", "key", ")", ",", "dim", "=", "-", "1", ")", "\n", "value", "=", "torch", ".", "cat", "(", "(", "past_value", ",", "value", ")", ",", "dim", "=", "-", "2", ")", "\n", "", "present", "=", "torch", ".", "stack", "(", "(", "key", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "value", ")", ")", "# transpose to have same shapes for stacking", "\n", "\n", "attn_outputs", "=", "self", ".", "_attn", "(", "query", ",", "key", ",", "value", ",", "attention_mask", ",", "head_mask", ")", "\n", "a", "=", "attn_outputs", "[", "0", "]", "\n", "\n", "a", "=", "self", ".", "merge_heads", "(", "a", ")", "\n", "a", "=", "self", ".", "c_proj", "(", "a", ")", "\n", "a", "=", "self", ".", "resid_dropout", "(", "a", ")", "\n", "\n", "outputs", "=", "[", "a", ",", "present", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "# a, present, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.MLP.__init__": [[204, 211], ["torch.Module.__init__", "modeling_utils.Conv1D", "modeling_utils.Conv1D", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_state", ",", "config", ")", ":", "# in MLP: n_state=3072 (4 * n_embd)", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "c_fc", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "nx", ",", "n_state", ")", "\n", "self", ".", "act", "=", "gelu", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.MLP.forward": [[212, 216], ["knowledge_text_gpt2.MLP.act", "knowledge_text_gpt2.MLP.c_proj", "knowledge_text_gpt2.MLP.dropout", "knowledge_text_gpt2.MLP.c_fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "act", "(", "self", ".", "c_fc", "(", "x", ")", ")", "\n", "h2", "=", "self", ".", "c_proj", "(", "h", ")", "\n", "return", "self", ".", "dropout", "(", "h2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Block.__init__": [[219, 226], ["torch.Module.__init__", "torch.LayerNorm", "torch.LayerNorm", "knowledge_text_gpt2.Attention", "torch.LayerNorm", "torch.LayerNorm", "knowledge_text_gpt2.MLP"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "ln_1", "=", "nn", ".", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "attn", "=", "Attention", "(", "nx", ",", "n_ctx", ",", "config", ",", "scale", ")", "\n", "self", ".", "ln_2", "=", "nn", ".", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "mlp", "=", "MLP", "(", "4", "*", "nx", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Block.forward": [[227, 239], ["knowledge_text_gpt2.Block.attn", "knowledge_text_gpt2.Block.mlp", "knowledge_text_gpt2.Block.ln_1", "knowledge_text_gpt2.Block.ln_2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "layer_past", "=", "None", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "output_attn", "=", "self", ".", "attn", "(", "\n", "self", ".", "ln_1", "(", "x", ")", ",", "layer_past", "=", "layer_past", ",", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", "\n", ")", "\n", "a", "=", "output_attn", "[", "0", "]", "# output_attn: a, present, (attentions)", "\n", "\n", "x", "=", "x", "+", "a", "\n", "m", "=", "self", ".", "mlp", "(", "self", ".", "ln_2", "(", "x", ")", ")", "\n", "x", "=", "x", "+", "m", "\n", "\n", "outputs", "=", "[", "x", "]", "+", "output_attn", "[", "1", ":", "]", "\n", "return", "outputs", "# x, present, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2PreTrainedModel.__init__": [[251, 253], ["modeling_utils.PreTrainedModel.__init__"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["def", "__init__", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2PreTrainedModel._init_weights": [[254, 266], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ",", "Conv1D", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "Conv1D", ")", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2Model.__init__": [[357, 370], ["knowledge_text_gpt2.GPT2PreTrainedModel.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.LayerNorm", "torch.LayerNorm", "knowledge_text_gpt2.GPT2Model.init_weights", "knowledge_text_gpt2.Block", "range"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_past", "=", "config", ".", "output_past", "\n", "\n", "self", ".", "wte", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "wpe", "=", "nn", ".", "Embedding", "(", "config", ".", "n_positions", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "self", ".", "h", "=", "nn", ".", "ModuleList", "(", "[", "Block", "(", "config", ".", "n_ctx", ",", "config", ",", "scale", "=", "True", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "self", ".", "ln_f", "=", "nn", ".", "LayerNorm", "(", "config", ".", "n_embd", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2Model.get_input_embeddings": [[371, 373], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "wte", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2Model.set_input_embeddings": [[374, 376], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "wte", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2Model._prune_heads": [[377, 383], ["heads_to_prune.items", "knowledge_text_gpt2.GPT2Model.h[].attn.prune_heads"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.Attention.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "h", "[", "layer", "]", ".", "attn", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2Model.forward": [[384, 507], ["input_ids.view.view.view", "knowledge_text_gpt2.GPT2Model.wpe", "knowledge_text_gpt2.GPT2Model.drop", "enumerate", "knowledge_text_gpt2.GPT2Model.ln_f", "hidden_states.view.view.view", "input_ids.view.view.size", "ValueError", "token_type_ids.view.view.view", "position_ids.unsqueeze().view.unsqueeze().view.view", "[].size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().view.unsqueeze().view.unsqueeze().view", "attention_mask.to.to.view", "attention_mask.to.to.unsqueeze().unsqueeze", "attention_mask.to.to.to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "knowledge_text_gpt2.GPT2Model.wte", "knowledge_text_gpt2.GPT2Model.wte", "zip", "block", "tuple", "input_ids.view.view.size", "input_ids.view.view.view", "len", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "hidden_states.view.view.size", "tuple.append", "ValueError", "position_ids.unsqueeze().view.unsqueeze().view.unsqueeze", "attention_mask.to.to.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "t.view", "knowledge_text_gpt2.GPT2Model.size", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "hidden_states.view.view.view", "knowledge_text_gpt2.GPT2Model.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "knowledge_text_gpt2.GPT2Model.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["None"], ["", "", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", ")", ":", "\n", "        ", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "2", ")", ")", "\n", "#print(\"Knowledge!!\")", "\n", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "", "if", "position_ids", "is", "not", "None", ":", "\n", "            ", "position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "\n", "", "if", "past", "is", "None", ":", "\n", "            ", "past_length", "=", "0", "\n", "past", "=", "[", "None", "]", "*", "len", "(", "self", ".", "h", ")", "\n", "", "else", ":", "\n", "            ", "past_length", "=", "past", "[", "0", "]", "[", "0", "]", ".", "size", "(", "-", "2", ")", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "            ", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "position_ids", "=", "torch", ".", "arange", "(", "past_length", ",", "input_shape", "[", "-", "1", "]", "+", "past_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "\n", "# Attention mask.", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "            ", "attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "attention_mask", "=", "attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "attention_mask", "=", "(", "1.0", "-", "attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# head_mask has shape n_layer x batch x n_heads x N x N", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "(", "\n", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "n_layer", "\n", "\n", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "wte", "(", "input_ids", ")", "\n", "#print(inputs_embeds)", "\n", "", "position_embeds", "=", "self", ".", "wpe", "(", "position_ids", ")", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_embeds", "=", "self", ".", "wte", "(", "token_type_ids", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "", "hidden_states", "=", "inputs_embeds", "+", "position_embeds", "+", "token_type_embeds", "\n", "hidden_states", "=", "self", ".", "drop", "(", "hidden_states", ")", "\n", "#print(\"Hidden States\", hidden_states.size()) ", "\n", "output_shape", "=", "input_shape", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "\n", "presents", "=", "(", ")", "\n", "all_attentions", "=", "[", "]", "\n", "all_hidden_states", "=", "(", ")", "\n", "for", "i", ",", "(", "block", ",", "layer_past", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "h", ",", "past", ")", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ".", "view", "(", "*", "output_shape", ")", ",", ")", "\n", "\n", "", "outputs", "=", "block", "(", "\n", "hidden_states", ",", "layer_past", "=", "layer_past", ",", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", "[", "i", "]", "\n", ")", "\n", "\n", "hidden_states", ",", "present", "=", "outputs", "[", ":", "2", "]", "\n", "if", "self", ".", "output_past", ":", "\n", "                ", "presents", "=", "presents", "+", "(", "present", ",", ")", "\n", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", ".", "append", "(", "outputs", "[", "2", "]", ")", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "ln_f", "(", "hidden_states", ")", "\n", "#exit()", "\n", "hidden_states", "=", "hidden_states", ".", "view", "(", "*", "output_shape", ")", "\n", "# Add last hidden state", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_past", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "presents", ",", ")", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "# let the number of heads free (-1) so we can extract attention even after head pruning", "\n", "            ", "attention_output_shape", "=", "input_shape", "[", ":", "-", "1", "]", "+", "(", "-", "1", ",", ")", "+", "all_attentions", "[", "0", "]", ".", "shape", "[", "-", "2", ":", "]", "\n", "all_attentions", "=", "tuple", "(", "t", ".", "view", "(", "*", "attention_output_shape", ")", "for", "t", "in", "all_attentions", ")", "\n", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "\n", "", "return", "outputs", "# last hidden state, (presents), (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2LMHeadModel.__init__": [[556, 562], ["knowledge_text_gpt2.GPT2PreTrainedModel.__init__", "knowledge_text_gpt2.GPT2Model", "torch.Linear", "torch.Linear", "knowledge_text_gpt2.GPT2LMHeadModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "GPT2Model", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2LMHeadModel.get_output_embeddings": [[563, 565], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2LMHeadModel.prepare_inputs_for_generation": [[566, 574], ["inputs.update", "input_ids[].unsqueeze"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "input_ids", ",", "**", "kwargs", ")", ":", "\n", "# only last token for inputs_ids if past is defined in kwargs", "\n", "        ", "if", "\"past\"", "in", "kwargs", "and", "kwargs", "[", "\"past\"", "]", ":", "\n", "            ", "input_ids", "=", "input_ids", "[", ":", ",", "-", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "", "inputs", "=", "{", "\"input_ids\"", ":", "input_ids", "}", "\n", "inputs", ".", "update", "(", "kwargs", ")", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2LMHeadModel.forward": [[575, 612], ["knowledge_text_gpt2.GPT2LMHeadModel.transformer", "knowledge_text_gpt2.GPT2LMHeadModel.lm_head", "lm_logits[].contiguous", "labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous.view", "labels[].contiguous.view", "lm_logits[].contiguous.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "past", "=", "past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "#print(hidden_states.size())", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "#print(lm_logits.size())", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# Shift so that tokens < n predict n", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "# Flatten the tokens", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "#print(lm_logits)", "\n", "", "return", "lm_logits", "# (loss), lm_logits, presents, (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2DoubleHeadsModel.__init__": [[686, 694], ["knowledge_text_gpt2.GPT2PreTrainedModel.__init__", "knowledge_text_gpt2.GPT2Model", "torch.Linear", "torch.Linear", "modeling_utils.SequenceSummary", "knowledge_text_gpt2.GPT2DoubleHeadsModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.PreTrainedModel.init_weights"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "config", ".", "num_labels", "=", "1", "\n", "self", ".", "transformer", "=", "GPT2Model", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "multiple_choice_head", "=", "SequenceSummary", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2DoubleHeadsModel.get_output_embeddings": [[695, 697], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.GPT2DoubleHeadsModel.forward": [[698, 739], ["knowledge_text_gpt2.GPT2DoubleHeadsModel.transformer", "knowledge_text_gpt2.GPT2DoubleHeadsModel.lm_head", "knowledge_text_gpt2.GPT2DoubleHeadsModel.multiple_choice_head().squeeze", "print", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous", "lm_labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "outputs.size", "knowledge_text_gpt2.GPT2DoubleHeadsModel.multiple_choice_head", "knowledge_text_gpt2.GPT2DoubleHeadsModel.view", "mc_labels.view", "lm_logits[].contiguous.view", "lm_labels[].contiguous.view", "knowledge_text_gpt2.GPT2DoubleHeadsModel.size", "lm_logits[].contiguous.size"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "mc_token_ids", "=", "None", ",", "\n", "lm_labels", "=", "None", ",", "\n", "mc_labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "past", "=", "past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "mc_logits", "=", "self", ".", "multiple_choice_head", "(", "hidden_states", ",", "mc_token_ids", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", "mc_logits", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "mc_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "mc_logits", ".", "view", "(", "-", "1", ",", "mc_logits", ".", "size", "(", "-", "1", ")", ")", ",", "mc_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "lm_labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "", "print", "(", "outputs", ".", "size", "(", ")", ")", "\n", "return", "outputs", "# (lm loss), (mc loss), lm logits, mc logits, presents, (all hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.load_tf_weights_in_gpt2": [[43, 96], ["os.path.abspath", "logger.info", "tf.train.list_variables", "zip", "logger.info", "tf.train.load_variable", "names.append", "arrays.append", "name.split.split", "logger.info", "torch.from_numpy", "torch.from_numpy", "logger.error", "tf.train.load_variable.squeeze", "re.fullmatch", "re.split", "getattr", "len", "int", "getattr", "getattr", "getattr", "getattr"], "function", ["None"], ["def", "load_tf_weights_in_gpt2", "(", "model", ",", "config", ",", "gpt2_checkpoint_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\n", "\"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "gpt2_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "\"Converting TensorFlow checkpoint from {}\"", ".", "format", "(", "tf_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ".", "squeeze", "(", ")", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "name", "=", "name", "[", "6", ":", "]", "# skip \"model/\"", "\n", "name", "=", "name", ".", "split", "(", "\"/\"", ")", "\n", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r\"[A-Za-z]+\\d+\"", ",", "m_name", ")", ":", "\n", "                ", "scope_names", "=", "re", ".", "split", "(", "r\"(\\d+)\"", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "scope_names", "=", "[", "m_name", "]", "\n", "", "if", "scope_names", "[", "0", "]", "==", "\"w\"", "or", "scope_names", "[", "0", "]", "==", "\"g\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"b\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"bias\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"wpe\"", "or", "scope_names", "[", "0", "]", "==", "\"wte\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "scope_names", "[", "0", "]", ")", "\n", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "else", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "scope_names", "[", "0", "]", ")", "\n", "", "if", "len", "(", "scope_names", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "scope_names", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.knowledge_text_gpt2.gelu": [[98, 100], ["torch.tanh", "torch.tanh", "math.sqrt", "torch.pow", "torch.pow"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "return", "0.5", "*", "x", "*", "(", "1", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.model_knowledge_story.make_model": [[8, 15], ["src.models.knowledge_text_gpt2.GPT2LMHeadModel.from_pretrained"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.configuration_utils.PretrainedConfig.from_pretrained"], ["def", "make_model", "(", "opt", ",", "n_vocab", ",", "n_ctx", ",", "n_special", ",", "load", "=", "True", ",", "\n", "return_acts", "=", "True", ",", "return_probs", "=", "False", ",", "\n", "clf_token", "=", "\"<CLASS>\"", ",", "answer_size", "=", "None", ")", ":", "\n", "    ", "if", "opt", ".", "exp", "==", "\"generation\"", ":", "\n", "        ", "model", "=", "GPT2LMHeadModel", ".", "from_pretrained", "(", "'gpt2'", ")", "\n", "", "DEFAULT_CONFIG", "=", "GPT2Config", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.model_knowledge_story.multi_gpu": [[17, 19], ["torch.DataParallel"], "function", ["None"], ["", "def", "multi_gpu", "(", "model", ",", "devices", ")", ":", "\n", "    ", "return", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "devices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.model_knowledge_story.load_state_dict": [[21, 27], ["model.load_state_dict", "model.load_state_dict", "state_dict.items", "len"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.model_knowledge_story.load_state_dict", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.model_knowledge_story.load_state_dict"], ["", "def", "load_state_dict", "(", "model", ",", "state_dict", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "", "except", "RuntimeError", ":", "\n", "        ", "new_state_dict", "=", "{", "i", "[", "len", "(", "\"module.\"", ")", ":", "]", ":", "j", "for", "i", ",", "j", "in", "state_dict", ".", "items", "(", ")", "}", "\n", "model", ".", "load_state_dict", "(", "new_state_dict", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_openai.OpenAIGPTTokenizer.__init__": [[84, 114], ["tokenization_utils.PreTrainedTokenizer.__init__", "dict", "English", "English.Defaults.create_tokenizer", "open", "json.load", "open", "tuple", "zip", "logger.warning", "tokenization_bert.BasicTokenizer", "tokenization_openai.OpenAIGPTTokenizer.encoder.items", "merges_handle.read().split", "merge.split", "range", "len", "merges_handle.read"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["def", "__init__", "(", "self", ",", "vocab_file", ",", "merges_file", ",", "unk_token", "=", "\"<unk>\"", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "unk_token", "=", "unk_token", ",", "**", "kwargs", ")", "\n", "\n", "self", ".", "max_len_single_sentence", "=", "(", "\n", "self", ".", "max_len", "\n", ")", "# no default special tokens - you can update this value if you add special tokens", "\n", "self", ".", "max_len_sentences_pair", "=", "(", "\n", "self", ".", "max_len", "\n", ")", "# no default special tokens - you can update this value if you add special tokens", "\n", "\n", "try", ":", "\n", "            ", "import", "ftfy", "\n", "from", "spacy", ".", "lang", ".", "en", "import", "English", "\n", "\n", "_nlp", "=", "English", "(", ")", "\n", "self", ".", "nlp", "=", "_nlp", ".", "Defaults", ".", "create_tokenizer", "(", "_nlp", ")", "\n", "self", ".", "fix_text", "=", "ftfy", ".", "fix_text", "\n", "", "except", "ImportError", ":", "\n", "            ", "logger", ".", "warning", "(", "\"ftfy or spacy is not installed using BERT BasicTokenizer instead of SpaCy & ftfy.\"", ")", "\n", "self", ".", "nlp", "=", "BasicTokenizer", "(", "do_lower_case", "=", "True", ")", "\n", "self", ".", "fix_text", "=", "None", "\n", "\n", "", "with", "open", "(", "vocab_file", ",", "encoding", "=", "\"utf-8\"", ")", "as", "vocab_handle", ":", "\n", "            ", "self", ".", "encoder", "=", "json", ".", "load", "(", "vocab_handle", ")", "\n", "", "self", ".", "decoder", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "self", ".", "encoder", ".", "items", "(", ")", "}", "\n", "with", "open", "(", "merges_file", ",", "encoding", "=", "\"utf-8\"", ")", "as", "merges_handle", ":", "\n", "            ", "merges", "=", "merges_handle", ".", "read", "(", ")", ".", "split", "(", "\"\\n\"", ")", "[", "1", ":", "-", "1", "]", "\n", "", "merges", "=", "[", "tuple", "(", "merge", ".", "split", "(", ")", ")", "for", "merge", "in", "merges", "]", "\n", "self", ".", "bpe_ranks", "=", "dict", "(", "zip", "(", "merges", ",", "range", "(", "len", "(", "merges", ")", ")", ")", ")", "\n", "self", ".", "cache", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_openai.OpenAIGPTTokenizer.vocab_size": [[115, 118], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "vocab_size", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "encoder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_openai.OpenAIGPTTokenizer.bpe": [[119, 162], ["tokenization_openai.get_pairs", "tuple", "min", "tuple", "len", "len", "tokenization_openai.get_pairs", "word.index", "tuple.extend", "tuple.append", "tuple.append", "tokenization_openai.OpenAIGPTTokenizer.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.get_pairs", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.get_pairs"], ["", "def", "bpe", "(", "self", ",", "token", ")", ":", "\n", "        ", "word", "=", "tuple", "(", "token", "[", ":", "-", "1", "]", ")", "+", "(", "token", "[", "-", "1", "]", "+", "\"</w>\"", ",", ")", "\n", "if", "token", "in", "self", ".", "cache", ":", "\n", "            ", "return", "self", ".", "cache", "[", "token", "]", "\n", "", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "\n", "if", "not", "pairs", ":", "\n", "            ", "return", "token", "+", "\"</w>\"", "\n", "\n", "", "while", "True", ":", "\n", "            ", "bigram", "=", "min", "(", "pairs", ",", "key", "=", "lambda", "pair", ":", "self", ".", "bpe_ranks", ".", "get", "(", "pair", ",", "float", "(", "\"inf\"", ")", ")", ")", "\n", "if", "bigram", "not", "in", "self", ".", "bpe_ranks", ":", "\n", "                ", "break", "\n", "", "first", ",", "second", "=", "bigram", "\n", "new_word", "=", "[", "]", "\n", "i", "=", "0", "\n", "while", "i", "<", "len", "(", "word", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "j", "=", "word", ".", "index", "(", "first", ",", "i", ")", "\n", "", "except", "ValueError", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "]", ")", "\n", "break", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "extend", "(", "word", "[", "i", ":", "j", "]", ")", "\n", "i", "=", "j", "\n", "\n", "", "if", "word", "[", "i", "]", "==", "first", "and", "i", "<", "len", "(", "word", ")", "-", "1", "and", "word", "[", "i", "+", "1", "]", "==", "second", ":", "\n", "                    ", "new_word", ".", "append", "(", "first", "+", "second", ")", "\n", "i", "+=", "2", "\n", "", "else", ":", "\n", "                    ", "new_word", ".", "append", "(", "word", "[", "i", "]", ")", "\n", "i", "+=", "1", "\n", "", "", "new_word", "=", "tuple", "(", "new_word", ")", "\n", "word", "=", "new_word", "\n", "if", "len", "(", "word", ")", "==", "1", ":", "\n", "                ", "break", "\n", "", "else", ":", "\n", "                ", "pairs", "=", "get_pairs", "(", "word", ")", "\n", "", "", "word", "=", "\" \"", ".", "join", "(", "word", ")", "\n", "if", "word", "==", "\"\\n  </w>\"", ":", "\n", "            ", "word", "=", "\"\\n</w>\"", "\n", "", "self", ".", "cache", "[", "token", "]", "=", "word", "\n", "return", "word", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_openai.OpenAIGPTTokenizer._tokenize": [[163, 183], ["tokenization_openai.OpenAIGPTTokenizer.nlp", "tokenization_openai.text_standardize", "split_tokens.extend", "tokenization_openai.OpenAIGPTTokenizer.fix_text", "tokenization_openai.OpenAIGPTTokenizer.bpe().split", "tokenization_openai.OpenAIGPTTokenizer.bpe", "token.text.lower"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.text_standardize", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.bpe"], ["", "def", "_tokenize", "(", "self", ",", "text", ")", ":", "\n", "        ", "\"\"\" Tokenize a string. \"\"\"", "\n", "split_tokens", "=", "[", "]", "\n", "#if self.fix_text is None:", "\n", "# Using BERT's BasicTokenizer", "\n", "#text = self.nlp.tokenize(text)", "\n", "#for token in text:", "\n", "#    split_tokens.extend([t for t in self.bpe(token).split(\" \")])", "\n", "#else:", "\n", "# Using SpaCy & ftfy (original tokenization process of OpenAI GPT)", "\n", "text", "=", "self", ".", "nlp", "(", "text_standardize", "(", "self", ".", "fix_text", "(", "text", ")", ")", ")", "\n", "#print(text)", "\n", "count", "=", "0", "\n", "for", "token", "in", "text", ":", "\n", "                ", "count", "=", "count", "+", "1", "\n", "split_tokens", ".", "extend", "(", "[", "t", "for", "t", "in", "self", ".", "bpe", "(", "token", ".", "text", ".", "lower", "(", ")", ")", ".", "split", "(", "\" \"", ")", "]", ")", "#[token.text.lower()])#[t for t in self.bpe(token.text.lower()).split(\" \")])  #self.bpe(token.text.lower()).split(\" \")])", "\n", "#print(count)", "\n", "#print(len(split_tokens))", "\n", "#print(split_tokens)", "\n", "", "return", "split_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_openai.OpenAIGPTTokenizer._convert_token_to_id": [[184, 187], ["tokenization_openai.OpenAIGPTTokenizer.encoder.get", "tokenization_openai.OpenAIGPTTokenizer.encoder.get"], "methods", ["None"], ["", "def", "_convert_token_to_id", "(", "self", ",", "token", ")", ":", "\n", "        ", "\"\"\" Converts a token (str) in an id using the vocab. \"\"\"", "\n", "return", "self", ".", "encoder", ".", "get", "(", "token", ",", "self", ".", "encoder", ".", "get", "(", "self", ".", "unk_token", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_openai.OpenAIGPTTokenizer._convert_id_to_token": [[188, 191], ["tokenization_openai.OpenAIGPTTokenizer.decoder.get"], "methods", ["None"], ["", "def", "_convert_id_to_token", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Converts an id in a token (BPE) using the vocab.\"\"\"", "\n", "return", "self", ".", "decoder", ".", "get", "(", "index", ",", "self", ".", "unk_token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_openai.OpenAIGPTTokenizer.convert_tokens_to_string": [[192, 196], ["None"], "methods", ["None"], ["", "def", "convert_tokens_to_string", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "\"\"\" Converts a sequence of tokens (string) in a single string. \"\"\"", "\n", "out_string", "=", "\"\"", ".", "join", "(", "tokens", ")", ".", "replace", "(", "\"</w>\"", ",", "\" \"", ")", ".", "strip", "(", ")", "\n", "return", "out_string", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_openai.OpenAIGPTTokenizer.save_vocabulary": [[197, 222], ["os.path.join", "os.path.join", "os.path.isdir", "logger.error", "open", "f.write", "open", "writer.write", "sorted", "json.dumps", "tokenization_openai.OpenAIGPTTokenizer.bpe_ranks.items", "writer.write", "logger.warning"], "methods", ["None"], ["", "def", "save_vocabulary", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\"Save the tokenizer vocabulary and merge files to a directory.\"\"\"", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "save_directory", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"Vocabulary path ({}) should be a directory\"", ".", "format", "(", "save_directory", ")", ")", "\n", "return", "\n", "", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "\"vocab_file\"", "]", ")", "\n", "merge_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "VOCAB_FILES_NAMES", "[", "\"merges_file\"", "]", ")", "\n", "\n", "with", "open", "(", "vocab_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "self", ".", "encoder", ",", "ensure_ascii", "=", "False", ")", ")", "\n", "\n", "", "index", "=", "0", "\n", "with", "open", "(", "merge_file", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "\"#version: 0.2\\n\"", ")", "\n", "for", "bpe_tokens", ",", "token_index", "in", "sorted", "(", "self", ".", "bpe_ranks", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "1", "]", ")", ":", "\n", "                ", "if", "index", "!=", "token_index", ":", "\n", "                    ", "logger", ".", "warning", "(", "\n", "\"Saving vocabulary to {}: BPE merge indices are not consecutive.\"", "\n", "\" Please check that the tokenizer is not corrupted!\"", ".", "format", "(", "merge_file", ")", "\n", ")", "\n", "index", "=", "token_index", "\n", "", "writer", ".", "write", "(", "\" \"", ".", "join", "(", "bpe_tokens", ")", "+", "\"\\n\"", ")", "\n", "index", "+=", "1", "\n", "\n", "", "", "return", "vocab_file", ",", "merge_file", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_openai.get_pairs": [[44, 55], ["set", "set.add"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.BeamHypotheses.add"], ["def", "get_pairs", "(", "word", ")", ":", "\n", "    ", "\"\"\"\n    Return set of symbol pairs in a word.\n    word is represented as tuple of symbols (symbols being variable-length strings)\n    \"\"\"", "\n", "pairs", "=", "set", "(", ")", "\n", "prev_char", "=", "word", "[", "0", "]", "\n", "for", "char", "in", "word", "[", "1", ":", "]", ":", "\n", "        ", "pairs", ".", "add", "(", "(", "prev_char", ",", "char", ")", ")", "\n", "prev_char", "=", "char", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.tokenization_openai.text_standardize": [[57, 71], ["re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub", "re.sub", "re.sub", "re.sub.strip"], "function", ["None"], ["", "def", "text_standardize", "(", "text", ")", ":", "\n", "    ", "\"\"\"\n    fixes some issues the spacy tokenizer had on books corpus\n    also does some whitespace standardization\n    \"\"\"", "\n", "text", "=", "text", ".", "replace", "(", "\"\u2014\"", ",", "\"-\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u2013\"", ",", "\"-\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u2015\"", ",", "\"-\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u2026\"", ",", "\"...\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"\u00b4\"", ",", "\"'\"", ")", "\n", "text", "=", "re", ".", "sub", "(", "r\"\"\"(-+|~+|!+|\"+|;+|\\?+|\\++|,+|\\)+|\\(+|\\\\+|\\/+|\\*+|\\[+|\\]+|}+|{+|\\|+|_+)\"\"\"", ",", "r\" \\1 \"", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r\"\\s*\\n\\s*\"", ",", "\" \\n \"", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r\"[^\\S\\n]+\"", ",", "\" \"", ",", "text", ")", "\n", "return", "text", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.conceptnet_train.ConceptNetGenerationIteratorTrainer.set_evaluator": [[18, 21], ["src.make_evaluator", "src.make_evaluator", "src.make_evaluator", "src.make_evaluator", "src.make_evaluator"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_evaluate.make_evaluator", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_evaluate.make_evaluator", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_evaluate.make_evaluator", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_evaluate.make_evaluator", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_evaluate.make_evaluator"], ["    ", "def", "set_evaluator", "(", "self", ",", "opt", ",", "model", ",", "model_knowledge", ",", "data_loader", ")", ":", "\n", "        ", "self", ".", "evaluator", "=", "evaluate", ".", "make_evaluator", "(", "\n", "opt", ",", "model", ",", "model_knowledge", ",", "data_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.conceptnet_train.ConceptNetGenerationIteratorTrainer.set_generator": [[22, 25], ["src.make_generator", "src.make_generator", "src.make_generator", "src.make_generator", "src.make_generator"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_generate.make_generator", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_generate.make_generator", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_generate.make_generator", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_generate.make_generator", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_generate.make_generator"], ["", "def", "set_generator", "(", "self", ",", "opt", ",", "model", ",", "model_knowledge", ",", "data_loader", ")", ":", "\n", "        ", "self", ".", "generator", "=", "gen", ".", "make_generator", "(", "\n", "opt", ",", "model", ",", "model_knowledge", ",", "data_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.conceptnet_train.ConceptNetGenerationIteratorTrainer.batch": [[26, 36], ["src.batch_atomic_generate", "src.batch_atomic_generate", "src.batch_atomic_generate", "src.batch_atomic_generate", "src.batch_atomic_generate"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.batch_atomic_generate", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.batch_atomic_generate", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.batch_atomic_generate", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.batch_atomic_generate", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.batch_atomic_generate"], ["", "def", "batch", "(", "self", ",", "opt", ",", "*", "args", ")", ":", "\n", "        ", "outputs", "=", "batch_utils", ".", "batch_atomic_generate", "(", "opt", ",", "*", "args", ")", "\n", "\n", "token_loss_knowledge", "=", "outputs", "[", "\"loss_knowledge\"", "]", "#+ outputs[\"loss_sentence\"]", "\n", "token_loss_sentence", "=", "outputs", "[", "\"loss_sentence\"", "]", "#+ outputs[\"loss_knowledge\"]", "\n", "nums_s", "=", "outputs", "[", "\"nums_s\"", "]", "\n", "nums_k", "=", "outputs", "[", "\"nums_k\"", "]", "\n", "reset", "=", "outputs", "[", "\"reset\"", "]", "\n", "\n", "return", "token_loss_knowledge", ",", "token_loss_sentence", ",", "nums_k", ",", "nums_s", ",", "reset", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.conceptnet_train.ConceptNetGenerationIteratorTrainer.update_top_score": [[37, 53], ["print", "conceptnet_train.ConceptNetGenerationIteratorTrainer.get_tracked_score", "print"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.get_tracked_score"], ["", "def", "update_top_score", "(", "self", ",", "opt", ")", ":", "\n", "        ", "print", "(", "self", ".", "top_score", ")", "\n", "\n", "tracked_scores", "=", "self", ".", "get_tracked_score", "(", ")", "\n", "\n", "if", "self", ".", "top_score", "is", "None", ":", "\n", "            ", "self", ".", "top_score", "=", "self", ".", "top_score", "=", "{", "\"epoch\"", ":", "{", "}", ",", "\"score\"", ":", "{", "}", "}", "\n", "self", ".", "top_score", "[", "\"epoch\"", "]", "[", "\"total_micro\"", "]", "=", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "epoch", "\n", "self", ".", "top_score", "[", "\"score\"", "]", "[", "\"total_micro\"", "]", "=", "tracked_scores", "[", "\"total_micro\"", "]", "\n", "", "else", ":", "\n", "            ", "if", "tracked_scores", "[", "\"total_micro\"", "]", "<", "self", ".", "top_score", "[", "\"score\"", "]", "[", "\"total_micro\"", "]", ":", "\n", "                ", "self", ".", "top_score", "[", "\"epoch\"", "]", "[", "\"total_micro\"", "]", "=", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "epoch", "\n", "self", ".", "top_score", "[", "\"score\"", "]", "[", "\"total_micro\"", "]", "=", "tracked_scores", "[", "\"total_micro\"", "]", "\n", "\n", "", "", "print", "(", "self", ".", "top_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.conceptnet_train.ConceptNetGenerationIteratorTrainer.get_tracked_score": [[54, 57], ["None"], "methods", ["None"], ["", "def", "get_tracked_score", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "\"total_micro\"", ":", "self", ".", "losses_k", "[", "\"dev\"", "]", "[", "\"total_micro\"", "]", "[", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "epoch", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.conceptnet_train.ConceptNetGenerationIteratorTrainer.decide_to_save": [[59, 71], ["print"], "methods", ["None"], ["", "def", "decide_to_save", "(", "self", ")", ":", "\n", "        ", "to_save", "=", "cfg", ".", "save", "and", "not", "cfg", ".", "toy", "\n", "\n", "curr_epoch", "=", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "epoch", "\n", "\n", "to_save", "=", "to_save", "or", "cfg", ".", "test_save", "\n", "print", "(", "cfg", ".", "save_strategy", ")", "\n", "if", "cfg", ".", "save_strategy", "==", "\"best\"", ":", "\n", "            ", "if", "(", "(", "self", ".", "top_score", "[", "\"epoch\"", "]", "[", "\"total_micro\"", "]", "!=", "curr_epoch", ")", ")", ":", "\n", "                ", "to_save", "=", "False", "\n", "", "", "to_save", "=", "True", "\n", "return", "to_save", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.conceptnet_train.make_trainer": [[12, 14], ["conceptnet_train.ConceptNetGenerationIteratorTrainer"], "function", ["None"], ["def", "make_trainer", "(", "opt", ",", "*", "args", ")", ":", "\n", "    ", "return", "ConceptNetGenerationIteratorTrainer", "(", "opt", ",", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.opt.OpenAIAdam.__init__": [[37, 56], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", ",", "schedule", ",", "warmup", ",", "t_total", ",", "\n", "b1", "=", "0.9", ",", "b2", "=", "0.999", ",", "e", "=", "1e-8", ",", "l2", "=", "0", ",", "\n", "vector_l2", "=", "False", ",", "max_grad_norm", "=", "-", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "0.0", "<=", "lr", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {}\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "schedule", "not", "in", "SCHEDULES", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid schedule parameter: {}\"", ".", "format", "(", "schedule", ")", ")", "\n", "", "if", "not", "0", "<=", "warmup", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid warmup: {}\"", ".", "format", "(", "warmup", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b1", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b1 parameter: {}\"", ".", "format", "(", "b1", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b2", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b2 parameter: {}\"", ".", "format", "(", "b2", ")", ")", "\n", "", "if", "not", "0.0", "<=", "e", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {}\"", ".", "format", "(", "e", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "schedule", "=", "schedule", ",", "warmup", "=", "warmup", ",", "t_total", "=", "t_total", ",", "\n", "b1", "=", "b1", ",", "b2", "=", "b2", ",", "e", "=", "e", ",", "l2", "=", "l2", ",", "vector_l2", "=", "vector_l2", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ")", "\n", "super", "(", "OpenAIAdam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.opt.OpenAIAdam.step": [[57, 123], ["closure", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "exp_avg_sq.sqrt().add_", "p.data.addcdiv_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.nn.utils.clip_grad_norm_", "schedule_fct", "p.data.add_", "exp_avg.mul_", "exp_avg_sq.mul_", "exp_avg_sq.sqrt", "math.sqrt", "len", "p.size"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "# print(group['t_total'])", "\n", "# print(group['warmup'])", "\n", "# if self.state[group['params'][0]]:", "\n", "#     print(self.state[group['params'][0]]['step'] / group['t_total'])", "\n", "# print()", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\n", "'Adam does not support sparse gradients, \\\n                        please consider SparseAdam instead'", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'b1'", "]", ",", "group", "[", "'b2'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# Add grad clipping", "\n", "if", "group", "[", "'max_grad_norm'", "]", ">", "0", ":", "\n", "                    ", "clip_grad_norm_", "(", "p", ",", "group", "[", "'max_grad_norm'", "]", ")", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'e'", "]", ")", "\n", "\n", "bias_correction1", "=", "1", "-", "beta1", "**", "state", "[", "'step'", "]", "\n", "bias_correction2", "=", "1", "-", "beta2", "**", "state", "[", "'step'", "]", "\n", "\n", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "(", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "state", "[", "'step'", "]", "/", "\n", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", ")", "\n", "step_size", "=", "(", "lr_scheduled", "*", "math", ".", "sqrt", "(", "bias_correction2", ")", "/", "\n", "bias_correction1", ")", "\n", "\n", "p", ".", "data", ".", "addcdiv_", "(", "-", "step_size", ",", "exp_avg", ",", "denom", ")", "\n", "\n", "# Add weight decay at the end (fixed version)", "\n", "if", "(", "len", "(", "p", ".", "size", "(", ")", ")", ">", "1", "or", "group", "[", "'vector_l2'", "]", ")", "and", "group", "[", "'l2'", "]", ">", "0", ":", "\n", "                    ", "p", ".", "data", ".", "add_", "(", "-", "lr_scheduled", "*", "group", "[", "'l2'", "]", ",", "p", ".", "data", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.opt.warmup_cosine": [[9, 12], ["torch.cos"], "function", ["None"], ["def", "warmup_cosine", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "s", "=", "1", "if", "x", "<=", "warmup", "else", "0", "\n", "return", "s", "*", "(", "x", "/", "warmup", ")", "+", "(", "1", "-", "s", ")", "*", "(", "0.5", "*", "(", "1", "+", "torch", ".", "cos", "(", "math", ".", "pi", "*", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.opt.warmup_constant": [[14, 17], ["None"], "function", ["None"], ["", "def", "warmup_constant", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "s", "=", "1", "if", "x", "<=", "warmup", "else", "0", "\n", "return", "s", "*", "(", "x", "/", "warmup", ")", "+", "(", "1", "-", "s", ")", "*", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.opt.warmup_linear": [[19, 25], ["None"], "function", ["None"], ["", "def", "warmup_linear", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "s", "=", "1", "if", "x", "<=", "warmup", "else", "0", "\n", "\n", "# print(s)", "\n", "\n", "return", "(", "s", "*", "(", "x", "/", "warmup", ")", "+", "(", "1", "-", "s", ")", ")", "*", "(", "1", "-", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.batch_atomic_generate": [[21, 72], ["data_loader.sample_batch", "input_.size", "range", "input_[].unsqueeze", "input_[].unsqueeze", "[].contiguous().view", "[].contiguous().view", "batch.mle_steps", "batch.mle_steps", "loss_mask[].sum", "loss_mask[].sum", "batch.update_generation_losses", "batch.update_generation_losses", "final_loss_knowledge.sum", "final_loss_sentence.sum", "[].contiguous", "[].contiguous", "input_[].unsqueeze.squeeze", "input_[].unsqueeze.squeeze"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.GenerationDataLoader.sample_batch", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.mle_steps", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.mle_steps", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.utils.update_generation_losses", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.utils.update_generation_losses"], ["def", "batch_atomic_generate", "(", "opt", ",", "nums_k", ",", "nums_s", ",", "losses_k", ",", "losses_s", ",", "batch_variables", ",", "eval_mode", "=", "False", ")", ":", "\n", "    ", "data_loader", "=", "batch_variables", "[", "\"data\"", "]", "\n", "model", "=", "batch_variables", "[", "\"model\"", "]", "\n", "model_knowledge", "=", "batch_variables", "[", "\"model_knowledge\"", "]", "\n", "split", "=", "batch_variables", "[", "\"split\"", "]", "\n", "\n", "batch", ",", "reset", "=", "data_loader", ".", "sample_batch", "(", "split", ",", "bs", "=", "opt", ".", "train", ".", "dynamic", ".", "bs", ")", "\n", "# Set loss name", "\n", "micro_name", "=", "\"total_micro\"", "\n", "macro_name", "=", "\"total_macro\"", "\n", "\n", "input_", "=", "batch", "[", "\"sequences\"", "]", "\n", "attention_mask", "=", "batch", "[", "\"attention_mask\"", "]", "\n", "loss_mask", "=", "batch", "[", "\"loss_mask\"", "]", "\n", "bs", "=", "input_", ".", "size", "(", "0", ")", "\n", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "        ", "current_input_knowledge", "=", "input_", "[", ":", ",", "0", ",", "i", ",", ":", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "current_input_story_completion", "=", "input_", "[", ":", ",", "1", ",", "i", ",", ":", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "#targets", "\n", "targets_knowledge", "=", "current_input_knowledge", ".", "squeeze", "(", "0", ")", "[", ":", ",", "1", ":", ",", "0", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "targets_story_completion", "=", "current_input_story_completion", ".", "squeeze", "(", "0", ")", "[", ":", ",", "1", ":", ",", "0", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "#attention", "\n", "attention_mask_knowledge", "=", "attention_mask", "[", ":", ",", "0", ",", "i", ",", ":", "-", "1", "]", "\n", "attention_mask_sentence", "=", "attention_mask", "[", ":", ",", "1", ",", "i", ",", ":", "-", "1", "]", "\n", "\n", "\n", "loss_know", ",", "_", "=", "mle_steps", "(", "opt", ".", "net", ".", "model", ",", "model_knowledge", ",", "current_input_knowledge", "[", ":", ",", ":", "-", "1", ",", ":", "]", ",", "targets_knowledge", ",", "attention_mask_knowledge", ",", "loss_reduction", "=", "\"none\"", ")", "\n", "loss_sentence", ",", "_", "=", "mle_steps", "(", "opt", ".", "net", ".", "model", ",", "model", ",", "current_input_story_completion", "[", ":", ",", ":", "-", "1", ",", ":", "]", ",", "targets_story_completion", ",", "attention_mask_sentence", ",", "loss_reduction", "=", "\"none\"", ")", "\n", "\n", "length_know", "=", "loss_mask", "[", ":", ",", "0", ",", "i", ",", ":", "]", ".", "sum", "(", "1", ")", "\n", "length_sentence", "=", "loss_mask", "[", ":", ",", "1", ",", "i", ",", ":", "]", ".", "sum", "(", "1", ")", "\n", "\n", "temp_loss_know", "=", "(", "loss_know", "*", "loss_mask", "[", ":", ",", "0", ",", "i", ",", ":", "]", ")", ".", "sum", "(", "1", ")", "\n", "temp_loss_sentence", "=", "(", "loss_sentence", "*", "loss_mask", "[", ":", ",", "1", ",", "i", ",", ":", "]", ")", ".", "sum", "(", "1", ")", "\n", "\n", "update_generation_losses", "(", "losses_k", ",", "nums_k", ",", "micro_name", ",", "macro_name", ",", "bs", ",", "\n", "length_know", ",", "temp_loss_know", ",", "split", ",", "\"knowledge\"", ")", "\n", "\n", "update_generation_losses", "(", "losses_s", ",", "nums_s", ",", "micro_name", ",", "macro_name", ",", "bs", ",", "\n", "length_sentence", ",", "temp_loss_sentence", ",", "split", ",", "\"sentence\"", ")", "\n", "if", "i", "==", "0", ":", "\n", "            ", "final_loss_knowledge", "=", "temp_loss_know", "/", "length_know", "\n", "final_loss_sentence", "=", "temp_loss_sentence", "/", "length_sentence", "\n", "", "else", ":", "\n", "            ", "final_loss_knowledge", "+=", "temp_loss_know", "/", "length_know", "\n", "final_loss_sentence", "+=", "temp_loss_sentence", "/", "length_sentence", "\n", "\n", "\n", "", "", "outputs", "=", "{", "\"loss_knowledge\"", ":", "final_loss_knowledge", ".", "sum", "(", ")", ",", "\"loss_sentence\"", ":", "final_loss_sentence", ".", "sum", "(", ")", ",", "\"nums_k\"", ":", "nums_k", ",", "\"nums_s\"", ":", "nums_s", ",", "\"reset\"", ":", "reset", "}", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.batch_conceptnet_generate": [[74, 130], ["data_loader.sample_batch", "input_.size", "range", "input_[].unsqueeze", "input_[].unsqueeze", "[].contiguous().view", "[].contiguous().view", "batch.mle_steps", "batch.mle_steps", "loss_mask[].sum", "loss_mask[].sum", "batch.update_generation_losses", "batch.update_generation_losses", "final_loss_knowledge.sum", "final_loss_sentence.sum", "final_loss_knowledge.squeeze().tolist", "[].contiguous", "[].contiguous", "final_loss_knowledge.squeeze", "input_[].unsqueeze.squeeze", "input_[].unsqueeze.squeeze"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.GenerationDataLoader.sample_batch", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.mle_steps", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.mle_steps", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.utils.update_generation_losses", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.utils.update_generation_losses"], ["", "def", "batch_conceptnet_generate", "(", "opt", ",", "nums_k", ",", "nums_s", ",", "losses_k", ",", "losses_s", ",", "batch_variables", ",", "\n", "eval_mode", "=", "False", ",", "tracking_mode", "=", "False", ")", ":", "\n", "\n", "    ", "data_loader", "=", "batch_variables", "[", "\"data\"", "]", "\n", "model", "=", "batch_variables", "[", "\"model\"", "]", "\n", "model_knowledge", "=", "batch_variables", "[", "\"model_knowledge\"", "]", "\n", "split", "=", "batch_variables", "[", "\"split\"", "]", "\n", "\n", "batch", ",", "reset", "=", "data_loader", ".", "sample_batch", "(", "split", ",", "bs", "=", "opt", ".", "train", ".", "dynamic", ".", "bs", ")", "\n", "# Set loss name", "\n", "micro_name", "=", "\"total_micro\"", "\n", "macro_name", "=", "\"total_macro\"", "\n", "\n", "input_", "=", "batch", "[", "\"sequences\"", "]", "\n", "attention_mask", "=", "batch", "[", "\"attention_mask\"", "]", "\n", "loss_mask", "=", "batch", "[", "\"loss_mask\"", "]", "\n", "bs", "=", "input_", ".", "size", "(", "0", ")", "\n", "\n", "for", "i", "in", "range", "(", "2", ")", ":", "\n", "        ", "current_input_knowledge", "=", "input_", "[", ":", ",", "0", ",", "i", ",", ":", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "current_input_story_completion", "=", "input_", "[", ":", ",", "1", ",", "i", ",", ":", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "#targets", "\n", "targets_knowledge", "=", "current_input_knowledge", ".", "squeeze", "(", "0", ")", "[", ":", ",", "1", ":", ",", "0", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "targets_story_completion", "=", "current_input_story_completion", ".", "squeeze", "(", "0", ")", "[", ":", ",", "1", ":", ",", "0", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "#attention", "\n", "attention_mask_knowledge", "=", "attention_mask", "[", ":", ",", "0", ",", "i", ",", ":", "-", "1", "]", "\n", "attention_mask_sentence", "=", "attention_mask", "[", ":", ",", "1", ",", "i", ",", ":", "-", "1", "]", "\n", "\n", "\n", "loss_know", ",", "_", "=", "mle_steps", "(", "opt", ".", "net", ".", "model", ",", "model_knowledge", ",", "current_input_knowledge", "[", ":", ",", ":", "-", "1", ",", ":", "]", ",", "targets_knowledge", ",", "attention_mask_knowledge", ",", "loss_reduction", "=", "\"none\"", ")", "\n", "loss_sentence", ",", "_", "=", "mle_steps", "(", "opt", ".", "net", ".", "model", ",", "model", ",", "current_input_story_completion", "[", ":", ",", ":", "-", "1", ",", ":", "]", ",", "targets_story_completion", ",", "attention_mask_sentence", ",", "loss_reduction", "=", "\"none\"", ")", "\n", "\n", "length_know", "=", "loss_mask", "[", ":", ",", "0", ",", "i", ",", ":", "]", ".", "sum", "(", "1", ")", "\n", "length_sentence", "=", "loss_mask", "[", ":", ",", "1", ",", "i", ",", ":", "]", ".", "sum", "(", "1", ")", "\n", "\n", "temp_loss_know", "=", "(", "loss_know", "*", "loss_mask", "[", ":", ",", "0", ",", "i", ",", ":", "]", ")", ".", "sum", "(", "1", ")", "\n", "temp_loss_sentence", "=", "(", "loss_sentence", "*", "loss_mask", "[", ":", ",", "1", ",", "i", ",", ":", "]", ")", ".", "sum", "(", "1", ")", "\n", "\n", "update_generation_losses", "(", "losses_k", ",", "nums_k", ",", "micro_name", ",", "macro_name", ",", "bs", ",", "\n", "length_know", ",", "temp_loss_know", ",", "split", ",", "\"knowledge\"", ")", "\n", "\n", "update_generation_losses", "(", "losses_s", ",", "nums_s", ",", "micro_name", ",", "macro_name", ",", "bs", ",", "\n", "length_sentence", ",", "temp_loss_sentence", ",", "split", ",", "\"sentence\"", ")", "\n", "\n", "if", "i", "==", "0", ":", "\n", "            ", "final_loss_knowledge", "=", "temp_loss_know", "/", "length_know", "\n", "final_loss_sentence", "=", "temp_loss_sentence", "/", "length_sentence", "\n", "", "else", ":", "\n", "            ", "final_loss_knowledge", "+=", "temp_loss_know", "/", "length_know", "\n", "final_loss_sentence", "+=", "temp_loss_sentence", "/", "length_sentence", "\n", "\n", "", "", "outputs", "=", "{", "\"loss_knowledge\"", ":", "final_loss_knowledge", ".", "sum", "(", ")", ",", "\"loss_sentence\"", ":", "final_loss_sentence", ".", "sum", "(", ")", ",", "\"nums_k\"", ":", "nums_k", ",", "\"nums_s\"", ":", "nums_s", ",", "\"reset\"", ":", "reset", "}", "\n", "\n", "if", "tracking_mode", ":", "\n", "        ", "outputs", "[", "\"tracking\"", "]", "=", "final_loss_knowledge", ".", "squeeze", "(", ")", ".", "tolist", "(", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.mle_steps": [[132, 152], ["batch.decode", "src.modify_output_for_loss_fn", "torch.nll_loss", "input_.unsqueeze", "train_utils.modify_output_for_loss_fn.view", "train_utils.modify_output_for_loss_fn.size", "F.nll_loss.view", "train_utils.modify_output_for_loss_fn.size"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.decode", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.utils.modify_output_for_loss_fn"], ["", "def", "mle_steps", "(", "key", ",", "model", ",", "input_", ",", "targets", ",", "attention_mask", ",", "\n", "loss_reduction", "=", "\"mean\"", ",", "i", "=", "None", ")", ":", "\n", "\n", "    ", "word_acts", "=", "decode", "(", "model", ",", "input_", ".", "unsqueeze", "(", "1", ")", ",", "\n", "attention_mask", ",", "i", ")", "\n", "\n", "word_dist", "=", "train_utils", ".", "modify_output_for_loss_fn", "(", "\n", "\"nll\"", ",", "word_acts", ",", "dim", "=", "-", "1", ")", "\n", "#print(word_dist.size())", "\n", "#print(word_dist.view(-1, word_dist.size(-1)).size())", "\n", "#print(targets.size())", "\n", "\n", "loss", "=", "F", ".", "nll_loss", "(", "\n", "word_dist", ".", "view", "(", "-", "1", ",", "word_dist", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "targets", ",", "reduction", "=", "loss_reduction", ")", "\n", "\n", "if", "loss_reduction", "!=", "\"mean\"", ":", "\n", "        ", "return", "loss", ".", "view", "(", "word_dist", ".", "size", "(", "0", ")", ",", "-", "1", ")", ",", "word_dist", "\n", "", "else", ":", "\n", "        ", "return", "loss", ",", "word_dist", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.decode": [[155, 157], ["model"], "function", ["None"], ["", "", "def", "decode", "(", "model", ",", "input_", ",", "attention_mask", ",", "i", ")", ":", "\n", "    ", "return", "model", "(", "input_ids", "=", "input_", ",", "attention_mask", "=", "attention_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.update_generation_losses": [[159, 167], ["src.update_generation_losses", "src.update_generation_losses"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.utils.update_generation_losses", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.utils.update_generation_losses"], ["", "def", "update_generation_losses", "(", "losses", ",", "nums", ",", "micro", ",", "macro", ",", "bs", ",", "\n", "length", ",", "loss", ",", "split", ",", "types", ")", ":", "\n", "    ", "if", "split", "==", "\"train\"", ":", "\n", "        ", "train_utils", ".", "update_generation_losses", "(", "\n", "losses", ",", "nums", ",", "micro", ",", "macro", ",", "bs", ",", "length", ",", "loss", ",", "types", ")", "\n", "", "else", ":", "\n", "        ", "eval_utils", ".", "update_generation_losses", "(", "\n", "losses", ",", "nums", ",", "micro", ",", "macro", ",", "bs", ",", "length", ",", "loss", ",", "types", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.__init__": [[20, 47], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "meta", ",", "data_loader", ",", "model", ",", "model_knowledge", ",", "optimizer_m", ",", "optimizer_k", ")", ":", "\n", "        ", "self", ".", "optimizer_m", "=", "optimizer_m", "\n", "self", ".", "optimizer_k", "=", "optimizer_k", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model_knowledge", "=", "model_knowledge", "\n", "\n", "if", "opt", ".", "trainer", "==", "\"epoch\"", ":", "\n", "            ", "self", ".", "epochs", "=", "meta", ".", "epochs", "\n", "", "self", ".", "data_loader", "=", "data_loader", "\n", "self", ".", "opt", "=", "opt", "\n", "\n", "self", ".", "losses_k", "=", "{", "\"dev\"", ":", "{", "}", ",", "\"test\"", ":", "{", "}", ",", "\"train\"", ":", "{", "}", "}", "\n", "self", ".", "losses_s", "=", "{", "\"dev\"", ":", "{", "}", ",", "\"test\"", ":", "{", "}", ",", "\"train\"", ":", "{", "}", "}", "\n", "self", ".", "top_score", "=", "None", "\n", "\n", "self", ".", "lrs_k", "=", "{", "}", "\n", "self", ".", "lrs_m", "=", "{", "}", "\n", "self", ".", "batch_variables", "=", "{", "\n", "\"data\"", ":", "self", ".", "data_loader", ",", "\n", "\"model\"", ":", "self", ".", "model", ",", "\n", "\"model_knowledge\"", ":", "self", ".", "model_knowledge", ",", "\n", "\"split\"", ":", "\"train\"", "\n", "}", "\n", "\n", "self", ".", "do_gen", "=", "cfg", ".", "do_gen", "\n", "self", ".", "samplers", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.decide_to_save": [[48, 55], ["None"], "methods", ["None"], ["", "def", "decide_to_save", "(", "self", ")", ":", "\n", "        ", "to_save", "=", "cfg", ".", "save", "and", "not", "cfg", ".", "toy", "\n", "to_save", "=", "to_save", "or", "cfg", ".", "test_save", "\n", "if", "cfg", ".", "save_strategy", "==", "\"best\"", ":", "\n", "            ", "if", "self", ".", "top_score", "[", "0", "]", "!=", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "epoch", ":", "\n", "                ", "to_save", "=", "False", "\n", "", "", "return", "to_save", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.save_model": [[56, 78], ["enumerate", "train.Trainer.decide_to_save", "enumerate", "src.save_step", "src.save_step", "src.save_step", "src.save_step", "src.save_step", "src.save_step", "src.save_step", "src.save_step", "src.save_step", "src.save_step", "src.save_step", "src.save_step", "src.save_step", "src.save_step"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.decide_to_save", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_step", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_step", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_step", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_step", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_step", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_step", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_step", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_step", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_step", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_step", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_step", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_step", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_step", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_step"], ["", "def", "save_model", "(", "self", ",", "tracked_score", ")", ":", "\n", "        ", "lrs", "=", "{", "}", "\n", "for", "i", ",", "param_group", "in", "enumerate", "(", "self", ".", "optimizer_m", ".", "param_groups", ")", ":", "\n", "            ", "lrs", "[", "i", "]", "=", "param_group", "[", "'lr'", "]", "\n", "", "self", ".", "lrs_m", "[", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "epoch", "]", "=", "lrs", "\n", "\n", "to_save", "=", "self", ".", "decide_to_save", "(", ")", "\n", "\n", "if", "to_save", ":", "\n", "            ", "data", ".", "save_step", "(", "\n", "self", ".", "model", ",", "self", ".", "data_loader", ".", "vocab_encoder", ",", "\n", "self", ".", "optimizer_m", ",", "self", ".", "opt", ",", "\n", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "epoch", ",", "self", ".", "lrs_m", ",", "\"story\"", ")", "\n", "\n", "", "for", "i", ",", "param_group", "in", "enumerate", "(", "self", ".", "optimizer_k", ".", "param_groups", ")", ":", "\n", "            ", "lrs", "[", "i", "]", "=", "param_group", "[", "'lr'", "]", "\n", "", "self", ".", "lrs_k", "[", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "epoch", "]", "=", "lrs", "\n", "if", "to_save", ":", "\n", "            ", "data", ".", "save_step", "(", "\n", "self", ".", "model_knowledge", ",", "self", ".", "data_loader", ".", "vocab_encoder", ",", "\n", "self", ".", "optimizer_k", ",", "self", ".", "opt", ",", "\n", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "epoch", ",", "self", ".", "lrs_k", ",", "\"knowledge\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.log_losses": [[79, 84], ["src.save_eval_file", "src.save_eval_file", "src.save_eval_file", "src.save_eval_file", "src.save_eval_file", "src.save_eval_file", "src.save_eval_file", "src.save_eval_file", "src.save_eval_file", "src.save_eval_file", "src.save_eval_file", "src.save_eval_file", "src.save_eval_file", "src.save_eval_file", "src.save_eval_file", "src.save_eval_file", "src.save_eval_file", "src.save_eval_file", "src.save_eval_file", "src.save_eval_file", "src.save_eval_file"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file"], ["", "", "def", "log_losses", "(", "self", ",", "opt", ",", "losses", ")", ":", "\n", "        ", "if", "(", "not", "cfg", ".", "toy", "and", "cfg", ".", "save", ")", "or", "cfg", ".", "test_save", ":", "\n", "            ", "data", ".", "save_eval_file", "(", "opt", ",", "losses", "[", "\"train\"", "]", ",", "\"losses\"", ",", "split", "=", "\"train\"", ")", "\n", "data", ".", "save_eval_file", "(", "opt", ",", "losses", "[", "'dev'", "]", ",", "\"losses\"", ",", "split", "=", "\"dev\"", ")", "\n", "data", ".", "save_eval_file", "(", "opt", ",", "losses", "[", "'test'", "]", ",", "\"losses\"", ",", "split", "=", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.set_logger": [[85, 93], ["print", "tensorboardX.SummaryWriter", "tensorboardX.SummaryWriter", "utils.make_name", "utils.make_name"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.make_name", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.make_name"], ["", "", "def", "set_logger", "(", "self", ")", ":", "\n", "        ", "if", "cfg", ".", "toy", ":", "\n", "            ", "self", ".", "logger", "=", "SummaryWriter", "(", "utils", ".", "make_name", "(", "\n", "self", ".", "opt", ",", "prefix", "=", "\"garbage/logs/\"", ",", "eval_", "=", "True", ",", "do_epoch", "=", "False", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "logger", "=", "SummaryWriter", "(", "utils", ".", "make_name", "(", "\n", "self", ".", "opt", ",", "prefix", "=", "\"logs/\"", ",", "eval_", "=", "True", ",", "do_epoch", "=", "False", ")", ")", "\n", "", "print", "(", "\"Logging Tensorboard Files at: {}\"", ".", "format", "(", "self", ".", "logger", ".", "logdir", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.stop_logger": [[94, 96], ["train.Trainer.logger.close"], "methods", ["None"], ["", "def", "stop_logger", "(", "self", ")", ":", "\n", "        ", "self", ".", "logger", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.run": [[97, 107], ["train.Trainer.set_logger", "range", "train.Trainer.stop_logger", "train.Trainer.model.train", "train.Trainer.model_knowledge.train", "train.Trainer.epoch"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.set_logger", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.stop_logger", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.epoch"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "self", ".", "set_logger", "(", ")", "\n", "self", ".", "count", "=", "0", "\n", "for", "epoch", "in", "range", "(", "self", ".", "epochs", ")", ":", "\n", "            ", "self", ".", "model", ".", "train", "(", ")", "\n", "self", ".", "model_knowledge", ".", "train", "(", ")", "\n", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "epoch", "+=", "1", "\n", "self", ".", "epoch", "(", ")", "\n", "\n", "", "self", ".", "stop_logger", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.epoch": [[108, 149], ["train.Trainer.reset_losses", "utils.initialize_progress_bar", "train.Trainer.log_losses", "train.Trainer.log_losses", "train.Trainer.update_top_score", "train.Trainer.save_model", "train.Trainer.data_loader.reset_offsets", "train.Trainer.do_forward_pass", "train.Trainer.do_backward_pass", "train.Trainer.update_parameters", "utils.initialize_progress_bar.update", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "train.Trainer.run_evaluation_cycle", "train.Trainer.get_tracked_score", "train.Trainer.logger.add_scalar", "train.Trainer.logger.add_scalar", "train.Trainer.counter", "loss.item", "loss.item"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.reset_losses", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.initialize_progress_bar", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.log_losses", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.log_losses", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.update_top_score", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.save_model", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.GenerationDataLoader.reset_offsets", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.do_forward_pass", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.do_backward_pass", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.run_evaluation_cycle", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.get_tracked_score", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.counter"], ["", "def", "epoch", "(", "self", ")", ":", "\n", "        ", "nums_k", ",", "nums_s", "=", "self", ".", "reset_losses", "(", ")", "\n", "\n", "# Initialize progress bar", "\n", "bar", "=", "utils", ".", "initialize_progress_bar", "(", "\n", "self", ".", "data_loader", ".", "sequences", "[", "\"train\"", "]", ")", "\n", "\n", "reset", "=", "False", "\n", "\n", "while", "not", "reset", ":", "\n", "            ", "loss", ",", "nums_k", ",", "nums_s", ",", "reset", "=", "self", ".", "do_forward_pass", "(", "nums_k", ",", "nums_s", ")", "\n", "self", ".", "do_backward_pass", "(", "loss", ")", "\n", "self", ".", "update_parameters", "(", ")", "\n", "\n", "bar", ".", "update", "(", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "bs", ")", "\n", "self", ".", "count", "+=", "1", "\n", "\n", "for", "loss_name", "in", "self", ".", "losses_k", "[", "\"train\"", "]", ":", "\n", "                ", "self", ".", "logger", ".", "add_scalar", "(", "\n", "\"train/{}\"", ".", "format", "(", "loss_name", ")", ",", "\n", "loss", ".", "item", "(", ")", "/", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "bs", ",", "\n", "self", ".", "count", ")", "\n", "\n", "", "for", "loss_name", "in", "self", ".", "losses_s", "[", "\"train\"", "]", ":", "\n", "                ", "self", ".", "logger", ".", "add_scalar", "(", "\n", "\"train/{}\"", ".", "format", "(", "loss_name", ")", ",", "\n", "loss", ".", "item", "(", ")", "/", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "bs", ",", "\n", "self", ".", "count", ")", "\n", "\n", "", "if", "cfg", ".", "toy", "and", "self", ".", "counter", "(", "nums", ")", ">", "300", ":", "\n", "                ", "break", "\n", "\n", "", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "run_evaluation_cycle", "(", ")", "\n", "\n", "", "self", ".", "log_losses", "(", "self", ".", "opt", ",", "self", ".", "losses_k", ")", "\n", "self", ".", "log_losses", "(", "self", ".", "opt", ",", "self", ".", "losses_s", ")", "\n", "self", ".", "update_top_score", "(", "self", ".", "opt", ")", "\n", "self", ".", "save_model", "(", "self", ".", "get_tracked_score", "(", ")", ")", "\n", "\n", "self", ".", "data_loader", ".", "reset_offsets", "(", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.run_evaluation_cycle": [[150, 172], ["train.Trainer.evaluator.validate", "src.do_gen_run", "src.do_gen_run", "src.do_gen_run", "src.do_gen_run", "src.do_gen_run", "src.do_gen_run", "src.do_gen_run", "train.Trainer.logger.add_scalar", "train.Trainer.logger.add_scalar"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.evaluate.Evaluator.validate", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.generate.do_gen_run", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.generate.do_gen_run", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.generate.do_gen_run", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.generate.do_gen_run", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.generate.do_gen_run", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.generate.do_gen_run", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.generate.do_gen_run"], ["", "def", "run_evaluation_cycle", "(", "self", ")", ":", "\n", "        ", "for", "split", "in", "[", "\"dev\"", ",", "\"test\"", "]", ":", "\n", "            ", "self", ".", "evaluator", ".", "validate", "(", "\n", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "epoch", ",", "split", ",", "\n", "self", ".", "losses_k", "[", "split", "]", ",", "self", ".", "losses_s", "[", "split", "]", ")", "\n", "if", "self", ".", "do_gen", ":", "\n", "                ", "gen", ".", "do_gen_run", "(", "\n", "self", ".", "opt", ",", "self", ".", "generator", ",", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "epoch", ",", "split", ",", "\n", "self", ".", "losses_s", "[", "split", "]", ")", "\n", "", "iter_num", "=", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "epoch", "\n", "\n", "for", "loss_name", "in", "self", ".", "losses_k", "[", "split", "]", ":", "\n", "                ", "self", ".", "logger", ".", "add_scalar", "(", "\n", "\"{}/{}\"", ".", "format", "(", "split", ",", "loss_name", ")", ",", "\n", "self", ".", "losses_k", "[", "split", "]", "[", "loss_name", "]", "[", "iter_num", "]", ",", "\n", "iter_num", ")", "\n", "\n", "", "for", "loss_name", "in", "self", ".", "losses_s", "[", "split", "]", ":", "\n", "                ", "self", ".", "logger", ".", "add_scalar", "(", "\n", "\"{}/{}\"", ".", "format", "(", "split", ",", "loss_name", ")", ",", "\n", "self", ".", "losses_s", "[", "split", "]", "[", "loss_name", "]", "[", "iter_num", "]", ",", "\n", "iter_num", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.clip_gradients": [[173, 179], ["torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "train.Trainer.model.parameters", "train.Trainer.model_knowledge.parameters"], "methods", ["None"], ["", "", "", "def", "clip_gradients", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "opt", ".", "train", ".", "static", ".", "clip", ":", "\n", "            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "self", ".", "opt", ".", "train", ".", "static", ".", "clip", ")", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "model_knowledge", ".", "parameters", "(", ")", ",", "self", ".", "opt", ".", "train", ".", "static", ".", "clip", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.do_forward_pass": [[180, 185], ["train.Trainer.batch"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.batch"], ["", "", "def", "do_forward_pass", "(", "self", ",", "nums_k", ",", "nums_s", ")", ":", "\n", "        ", "token_loss_knowledge", ",", "token_loss_sentence", ",", "nums_k", ",", "nums_s", ",", "reset", "=", "self", ".", "batch", "(", "\n", "self", ".", "opt", ",", "nums_k", ",", "nums_s", ",", "self", ".", "losses_k", "[", "\"train\"", "]", ",", "self", ".", "losses_s", "[", "\"train\"", "]", ",", "\n", "self", ".", "batch_variables", ")", "\n", "return", "token_loss_knowledge", ",", "token_loss_sentence", ",", "nums_k", ",", "nums_s", ",", "reset", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.do_backward_pass": [[186, 191], ["loss.backward", "loss.backward"], "methods", ["None"], ["", "def", "do_backward_pass", "(", "self", ",", "loss", ",", "flag", ")", ":", "\n", "        ", "if", "flag", "==", "True", ":", "\n", "            ", "loss", ".", "backward", "(", "retain_graph", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "loss", ".", "backward", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.update_parameters_knowledge": [[192, 195], ["train.Trainer.optimizer_k.step", "train.Trainer.optimizer_k.zero_grad"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.opt_knowledge.Knowledge_Adam.step"], ["", "", "def", "update_parameters_knowledge", "(", "self", ")", ":", "\n", "        ", "self", ".", "optimizer_k", ".", "step", "(", ")", "\n", "self", ".", "optimizer_k", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.update_parameters_sentence": [[196, 199], ["train.Trainer.optimizer_m.step", "train.Trainer.optimizer_m.zero_grad"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.opt_knowledge.Knowledge_Adam.step"], ["", "def", "update_parameters_sentence", "(", "self", ")", ":", "\n", "        ", "self", ".", "optimizer_m", ".", "step", "(", ")", "\n", "self", ".", "optimizer_m", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.reset_losses": [[200, 207], ["set", "set", "train.Trainer.initialize_losses", "train.Trainer.initialize_losses", "i.rstrip().rstrip", "i.rstrip().rstrip", "list", "list", "train.Trainer.losses_k[].keys", "train.Trainer.losses_s[].keys", "i.rstrip", "i.rstrip"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.initialize_losses", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.initialize_losses"], ["", "def", "reset_losses", "(", "self", ")", ":", "\n", "        ", "loss_names_k", "=", "set", "(", "[", "i", ".", "rstrip", "(", "\"maicro\"", ")", ".", "rstrip", "(", "\"_\"", ")", "for", "\n", "i", "in", "self", ".", "losses_k", "[", "\"train\"", "]", ".", "keys", "(", ")", "]", ")", "\n", "loss_names_s", "=", "set", "(", "[", "i", ".", "rstrip", "(", "\"maicro\"", ")", ".", "rstrip", "(", "\"_\"", ")", "for", "\n", "i", "in", "self", ".", "losses_s", "[", "\"train\"", "]", ".", "keys", "(", ")", "]", ")", "\n", "\n", "return", "self", ".", "initialize_losses", "(", "list", "(", "loss_names_k", ")", ")", ",", "self", ".", "initialize_losses", "(", "list", "(", "loss_names_s", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.IteratorTrainer.__init__": [[210, 216], ["train.Trainer.__init__"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "meta", ",", "data_loader", ",", "model", ",", "model_knowledge", ",", "optimizer_m", ",", "optimizer_k", ")", ":", "\n", "        ", "super", "(", "IteratorTrainer", ",", "self", ")", ".", "__init__", "(", "\n", "opt", ",", "meta", ",", "data_loader", ",", "model", ",", "model_knowledge", ",", "optimizer_m", ",", "optimizer_k", ")", "\n", "\n", "self", ".", "iters", "=", "meta", ".", "cycle", "\n", "self", ".", "total_iters", "=", "meta", ".", "iterations", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.IteratorTrainer.run": [[217, 236], ["train.IteratorTrainer.set_logger", "utils.set_progress_bar", "range", "train.IteratorTrainer.save_model", "train.IteratorTrainer.stop_logger", "int", "train.IteratorTrainer.model_knowledge.train", "train.IteratorTrainer.model.train", "train.IteratorTrainer.cycle", "train.IteratorTrainer.log_losses", "train.IteratorTrainer.update_top_score", "train.IteratorTrainer.get_tracked_score", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "train.IteratorTrainer.run_evaluation_cycle"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.set_logger", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.set_progress_bar", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.save_model", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.stop_logger", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.IteratorTrainer.cycle", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.log_losses", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.update_top_score", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.get_tracked_score", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.run_evaluation_cycle"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "self", ".", "set_logger", "(", ")", "\n", "\n", "# Initialize progress bar", "\n", "bar", "=", "utils", ".", "set_progress_bar", "(", "self", ".", "total_iters", ")", "\n", "\n", "for", "cycle_num", "in", "range", "(", "int", "(", "self", ".", "total_iters", "/", "self", ".", "iters", ")", ")", ":", "\n", "            ", "self", ".", "model_knowledge", ".", "train", "(", ")", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "self", ".", "cycle", "(", "bar", ",", "cycle_num", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "run_evaluation_cycle", "(", ")", "\n", "\n", "", "self", ".", "log_losses", "(", "self", ".", "opt", ",", "self", ".", "losses_k", ")", "\n", "self", ".", "update_top_score", "(", "self", ".", "opt", ")", "\n", "", "self", ".", "save_model", "(", "self", ".", "get_tracked_score", "(", ")", ")", "\n", "\n", "self", ".", "stop_logger", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.IteratorTrainer.cycle": [[237, 270], ["train.IteratorTrainer.reset_losses", "print", "torch.autograd.set_detect_anomaly", "torch.autograd.set_detect_anomaly", "torch.autograd.set_detect_anomaly", "torch.autograd.set_detect_anomaly", "torch.autograd.set_detect_anomaly", "torch.autograd.set_detect_anomaly", "torch.autograd.set_detect_anomaly", "torch.autograd.set_detect_anomaly", "torch.autograd.set_detect_anomaly", "range", "train.IteratorTrainer.do_forward_pass", "train.IteratorTrainer.optimizer_k.zero_grad", "train.IteratorTrainer.optimizer_m.zero_grad", "train.IteratorTrainer.do_backward_pass", "train.IteratorTrainer.update_parameters_knowledge", "train.IteratorTrainer.do_backward_pass", "train.IteratorTrainer.update_parameters_sentence", "bar.update", "train.IteratorTrainer.logger.add_scalar", "train.IteratorTrainer.logger.add_scalar", "train.IteratorTrainer.data_loader.reset_offsets", "loss_k.item", "loss_s.item"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.reset_losses", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.do_forward_pass", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.do_backward_pass", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.update_parameters_knowledge", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.do_backward_pass", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.train.Trainer.update_parameters_sentence", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.GenerationDataLoader.reset_offsets"], ["", "def", "cycle", "(", "self", ",", "bar", ",", "cycle_num", ")", ":", "\n", "        ", "nums_k", ",", "nums_s", "=", "self", ".", "reset_losses", "(", ")", "\n", "print", "(", "\"Nums\"", ",", "nums_k", ",", "nums_s", ")", "\n", "torch", ".", "autograd", ".", "set_detect_anomaly", "(", "True", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "self", ".", "iters", "+", "1", ")", ":", "\n", "            ", "loss_k", ",", "loss_s", ",", "nums_k", ",", "nums_s", ",", "reset", "=", "self", ".", "do_forward_pass", "(", "nums_k", ",", "nums_s", ")", "\n", "\n", "self", ".", "optimizer_k", ".", "zero_grad", "(", ")", "\n", "self", ".", "optimizer_m", ".", "zero_grad", "(", ")", "\n", "self", ".", "do_backward_pass", "(", "loss_k", ",", "True", ")", "\n", "self", ".", "update_parameters_knowledge", "(", ")", "\n", "self", ".", "do_backward_pass", "(", "loss_s", ",", "False", ")", "\n", "self", ".", "update_parameters_sentence", "(", ")", "\n", "\n", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "epoch", "+=", "1", "\n", "\n", "for", "loss_name", "in", "self", ".", "losses_k", "[", "\"train\"", "]", ":", "\n", "                ", "self", ".", "logger", ".", "add_scalar", "(", "\n", "\"train/{}\"", ".", "format", "(", "loss_name", ")", ",", "\n", "loss_k", ".", "item", "(", ")", "/", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "bs", ",", "\n", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "epoch", ")", "\n", "", "for", "loss_name", "in", "self", ".", "losses_s", "[", "\"train\"", "]", ":", "\n", "                ", "self", ".", "logger", ".", "add_scalar", "(", "\n", "\"train/{}\"", ".", "format", "(", "loss_name", ")", ",", "\n", "loss_s", ".", "item", "(", ")", "/", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "bs", ",", "\n", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "epoch", ")", "\n", "", "bar", ".", "update", "(", "1", ")", "\n", "\n", "if", "cfg", ".", "toy", "and", "i", ">", "10", ":", "\n", "                ", "break", "\n", "\n", "", "if", "reset", ":", "\n", "                ", "self", ".", "data_loader", ".", "reset_offsets", "(", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.opt_knowledge.Knowledge_Adam.__init__": [[37, 56], ["dict", "torch.optim.Optimizer.__init__", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["def", "__init__", "(", "self", ",", "params", ",", "lr", ",", "schedule", ",", "warmup", ",", "t_total", ",", "\n", "b1", "=", "0.9", ",", "b2", "=", "0.999", ",", "e", "=", "1e-8", ",", "l2", "=", "0", ",", "\n", "vector_l2", "=", "False", ",", "max_grad_norm", "=", "-", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "not", "0.0", "<=", "lr", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid learning rate: {}\"", ".", "format", "(", "lr", ")", ")", "\n", "", "if", "schedule", "not", "in", "SCHEDULES", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid schedule parameter: {}\"", ".", "format", "(", "schedule", ")", ")", "\n", "", "if", "not", "0", "<=", "warmup", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid warmup: {}\"", ".", "format", "(", "warmup", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b1", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b1 parameter: {}\"", ".", "format", "(", "b1", ")", ")", "\n", "", "if", "not", "0.0", "<=", "b2", "<", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid b2 parameter: {}\"", ".", "format", "(", "b2", ")", ")", "\n", "", "if", "not", "0.0", "<=", "e", ":", "\n", "            ", "raise", "ValueError", "(", "\"Invalid epsilon value: {}\"", ".", "format", "(", "e", ")", ")", "\n", "", "defaults", "=", "dict", "(", "lr", "=", "lr", ",", "schedule", "=", "schedule", ",", "warmup", "=", "warmup", ",", "t_total", "=", "t_total", ",", "\n", "b1", "=", "b1", ",", "b2", "=", "b2", ",", "e", "=", "e", ",", "l2", "=", "l2", ",", "vector_l2", "=", "vector_l2", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ")", "\n", "super", "(", "Knowledge_Adam", ",", "self", ")", ".", "__init__", "(", "params", ",", "defaults", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.opt_knowledge.Knowledge_Adam.step": [[57, 123], ["closure", "exp_avg.mul_().add_", "exp_avg_sq.mul_().addcmul_", "exp_avg_sq.sqrt().add_", "p.data.addcdiv_", "RuntimeError", "len", "torch.zeros_like", "torch.zeros_like", "torch.nn.utils.clip_grad_norm_", "schedule_fct", "p.data.add_", "exp_avg.mul_", "exp_avg_sq.mul_", "exp_avg_sq.sqrt", "math.sqrt", "len", "p.size"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "closure", "=", "None", ")", ":", "\n", "        ", "\"\"\"Performs a single optimization step.\n\n        Arguments:\n            closure (callable, optional): A closure that reevaluates the model\n                and returns the loss.\n        \"\"\"", "\n", "loss", "=", "None", "\n", "if", "closure", "is", "not", "None", ":", "\n", "            ", "loss", "=", "closure", "(", ")", "\n", "\n", "", "for", "group", "in", "self", ".", "param_groups", ":", "\n", "# print(group['t_total'])", "\n", "# print(group['warmup'])", "\n", "# if self.state[group['params'][0]]:", "\n", "#     print(self.state[group['params'][0]]['step'] / group['t_total'])", "\n", "# print()", "\n", "            ", "for", "p", "in", "group", "[", "'params'", "]", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "grad", "=", "p", ".", "grad", ".", "data", "\n", "if", "grad", ".", "is_sparse", ":", "\n", "                    ", "raise", "RuntimeError", "(", "\n", "'Adam does not support sparse gradients, \\\n                        please consider SparseAdam instead'", ")", "\n", "\n", "", "state", "=", "self", ".", "state", "[", "p", "]", "\n", "\n", "# State initialization", "\n", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "state", "[", "'step'", "]", "=", "0", "\n", "# Exponential moving average of gradient values", "\n", "state", "[", "'exp_avg'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "# Exponential moving average of squared gradient values", "\n", "state", "[", "'exp_avg_sq'", "]", "=", "torch", ".", "zeros_like", "(", "p", ".", "data", ")", "\n", "\n", "", "exp_avg", ",", "exp_avg_sq", "=", "state", "[", "'exp_avg'", "]", ",", "state", "[", "'exp_avg_sq'", "]", "\n", "beta1", ",", "beta2", "=", "group", "[", "'b1'", "]", ",", "group", "[", "'b2'", "]", "\n", "\n", "state", "[", "'step'", "]", "+=", "1", "\n", "\n", "# Add grad clipping", "\n", "if", "group", "[", "'max_grad_norm'", "]", ">", "0", ":", "\n", "                    ", "clip_grad_norm_", "(", "p", ",", "group", "[", "'max_grad_norm'", "]", ")", "\n", "\n", "# Decay the first and second moment running average coefficient", "\n", "", "exp_avg", ".", "mul_", "(", "beta1", ")", ".", "add_", "(", "1", "-", "beta1", ",", "grad", ")", "\n", "exp_avg_sq", ".", "mul_", "(", "beta2", ")", ".", "addcmul_", "(", "1", "-", "beta2", ",", "grad", ",", "grad", ")", "\n", "denom", "=", "exp_avg_sq", ".", "sqrt", "(", ")", ".", "add_", "(", "group", "[", "'e'", "]", ")", "\n", "\n", "bias_correction1", "=", "1", "-", "beta1", "**", "state", "[", "'step'", "]", "\n", "bias_correction2", "=", "1", "-", "beta2", "**", "state", "[", "'step'", "]", "\n", "\n", "schedule_fct", "=", "SCHEDULES", "[", "group", "[", "'schedule'", "]", "]", "\n", "lr_scheduled", "=", "(", "group", "[", "'lr'", "]", "*", "schedule_fct", "(", "state", "[", "'step'", "]", "/", "\n", "group", "[", "'t_total'", "]", ",", "group", "[", "'warmup'", "]", ")", ")", "\n", "step_size", "=", "(", "lr_scheduled", "*", "math", ".", "sqrt", "(", "bias_correction2", ")", "/", "\n", "bias_correction1", ")", "\n", "\n", "p", ".", "data", ".", "addcdiv_", "(", "-", "step_size", ",", "exp_avg", ",", "denom", ")", "\n", "\n", "# Add weight decay at the end (fixed version)", "\n", "if", "(", "len", "(", "p", ".", "size", "(", ")", ")", ">", "1", "or", "group", "[", "'vector_l2'", "]", ")", "and", "group", "[", "'l2'", "]", ">", "0", ":", "\n", "                    ", "p", ".", "data", ".", "add_", "(", "-", "lr_scheduled", "*", "group", "[", "'l2'", "]", ",", "p", ".", "data", ")", "\n", "\n", "", "", "", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.opt_knowledge.warmup_cosine": [[9, 12], ["torch.cos"], "function", ["None"], ["def", "warmup_cosine", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "s", "=", "1", "if", "x", "<=", "warmup", "else", "0", "\n", "return", "s", "*", "(", "x", "/", "warmup", ")", "+", "(", "1", "-", "s", ")", "*", "(", "0.5", "*", "(", "1", "+", "torch", ".", "cos", "(", "math", ".", "pi", "*", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.opt_knowledge.warmup_constant": [[14, 17], ["None"], "function", ["None"], ["", "def", "warmup_constant", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "s", "=", "1", "if", "x", "<=", "warmup", "else", "0", "\n", "return", "s", "*", "(", "x", "/", "warmup", ")", "+", "(", "1", "-", "s", ")", "*", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.opt_knowledge.warmup_linear": [[19, 25], ["None"], "function", ["None"], ["", "def", "warmup_linear", "(", "x", ",", "warmup", "=", "0.002", ")", ":", "\n", "    ", "s", "=", "1", "if", "x", "<=", "warmup", "else", "0", "\n", "\n", "# print(s)", "\n", "\n", "return", "(", "s", "*", "(", "x", "/", "warmup", ")", "+", "(", "1", "-", "s", ")", ")", "*", "(", "1", "-", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.__init__": [[14, 17], ["src.IteratorTrainer.__init__", "atomic_train.AtomicGenerationIteratorTrainer.initialize_losses", "opt.data.get"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.initialize_losses"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "*", "args", ")", ":", "\n", "        ", "super", "(", "AtomicGenerationIteratorTrainer", ",", "self", ")", ".", "__init__", "(", "opt", ",", "*", "args", ")", "\n", "self", ".", "initialize_losses", "(", "opt", ".", "data", ".", "get", "(", "\"categories\"", ",", "[", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.set_evaluator": [[18, 21], ["src.make_evaluator", "src.make_evaluator", "src.make_evaluator"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_evaluate.make_evaluator", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_evaluate.make_evaluator", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.conceptnet_evaluate.make_evaluator"], ["", "def", "set_evaluator", "(", "self", ",", "opt", ",", "model", ",", "model_knowledge", ",", "data_loader", ")", ":", "\n", "        ", "self", ".", "evaluator", "=", "evaluate", ".", "make_evaluator", "(", "\n", "opt", ",", "model", ",", "model_knowledge", ",", "data_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.set_sampler": [[26, 31], ["sampling.make_sampler"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.evaluate.sampler.make_sampler"], ["", "def", "set_sampler", "(", "self", ",", "opt", ")", ":", "\n", "        ", "if", "opt", ".", "train", ".", "static", ".", "samp", "not", "in", "self", ".", "samplers", ":", "\n", "            ", "self", ".", "samplers", "[", "opt", ".", "train", ".", "static", ".", "samp", "]", "=", "sampling", ".", "make_sampler", "(", "\n", "opt", ".", "train", ".", "static", ".", "samp", ",", "opt", ",", "self", ".", "data_loader", ",", "batch_mode", "=", "True", ")", "\n", "", "self", ".", "batch_variables", "[", "\"sampler\"", "]", "=", "self", ".", "samplers", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.batch": [[32, 41], ["src.batch_atomic_generate", "src.batch_atomic_generate", "src.batch_atomic_generate"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.batch_atomic_generate", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.batch_atomic_generate", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.batch.batch_atomic_generate"], ["", "def", "batch", "(", "self", ",", "opt", ",", "*", "args", ")", ":", "\n", "        ", "outputs", "=", "batch", ".", "batch_atomic_generate", "(", "opt", ",", "*", "args", ")", "\n", "\n", "token_loss_knowledge", "=", "outputs", "[", "\"loss_knowledge\"", "]", "\n", "token_loss_sentence", "=", "outputs", "[", "\"loss_sentence\"", "]", "\n", "nums", "=", "outputs", "[", "\"nums\"", "]", "\n", "reset", "=", "outputs", "[", "\"reset\"", "]", "\n", "\n", "return", "token_loss", ",", "nums", ",", "reset", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.initialize_losses": [[42, 66], ["None"], "methods", ["None"], ["", "def", "initialize_losses", "(", "self", ",", "categories", ")", ":", "\n", "        ", "self", ".", "losses_k", "[", "\"train\"", "]", "=", "{", "\n", "\"total_micro\"", ":", "[", "0", "]", ",", "\n", "\"total_macro\"", ":", "[", "0", "]", "\n", "}", "\n", "self", ".", "losses_s", "[", "\"train\"", "]", "=", "{", "\n", "\"total_micro\"", ":", "[", "0", "]", ",", "\n", "\"total_macro\"", ":", "[", "0", "]", "\n", "}", "\n", "\n", "nums", "=", "{", "\"total_micro\"", ":", "0", ",", "\"total_macro\"", ":", "0", "}", "\n", "\n", "for", "category", "in", "categories", ":", "\n", "            ", "micro_name", "=", "\"{}_micro\"", ".", "format", "(", "category", ")", "\n", "macro_name", "=", "\"{}_macro\"", ".", "format", "(", "category", ")", "\n", "\n", "self", ".", "losses_k", "[", "\"train\"", "]", "[", "micro_name", "]", "=", "[", "0", "]", "\n", "self", ".", "losses_k", "[", "\"train\"", "]", "[", "macro_name", "]", "=", "[", "0", "]", "\n", "self", ".", "losses_s", "[", "\"train\"", "]", "[", "micro_name", "]", "=", "[", "0", "]", "\n", "self", ".", "losses_s", "[", "\"train\"", "]", "[", "macro_name", "]", "=", "[", "0", "]", "\n", "nums", "[", "micro_name", "]", "=", "0", "\n", "nums", "[", "macro_name", "]", "=", "0", "\n", "\n", "", "return", "nums", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.update_top_score": [[67, 76], ["print", "print", "atomic_train.AtomicGenerationIteratorTrainer.get_tracked_score", "atomic_train.AtomicGenerationIteratorTrainer.get_tracked_score", "atomic_train.AtomicGenerationIteratorTrainer.get_tracked_score"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.get_tracked_score", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.get_tracked_score", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.get_tracked_score"], ["", "def", "update_top_score", "(", "self", ",", "opt", ")", ":", "\n", "        ", "print", "(", "self", ".", "top_score", ")", "\n", "if", "self", ".", "top_score", "is", "None", ":", "\n", "            ", "self", ".", "top_score", "=", "(", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "epoch", ",", "\n", "self", ".", "get_tracked_score", "(", ")", ")", "\n", "", "elif", "self", ".", "get_tracked_score", "(", ")", "<", "self", ".", "top_score", "[", "-", "1", "]", ":", "\n", "            ", "self", ".", "top_score", "=", "(", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "epoch", ",", "\n", "self", ".", "get_tracked_score", "(", ")", ")", "\n", "", "print", "(", "self", ".", "top_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.get_tracked_score": [[77, 79], ["None"], "methods", ["None"], ["", "def", "get_tracked_score", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "losses_k", "[", "\"dev\"", "]", "[", "\"total_micro\"", "]", "[", "self", ".", "opt", ".", "train", ".", "dynamic", ".", "epoch", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.AtomicGenerationIteratorTrainer.counter": [[80, 82], ["None"], "methods", ["None"], ["", "def", "counter", "(", "self", ",", "nums", ")", ":", "\n", "        ", "return", "nums", "[", "\"total_macro\"", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.atomic_train.make_trainer": [[9, 11], ["atomic_train.AtomicGenerationIteratorTrainer"], "function", ["None"], ["def", "make_trainer", "(", "opt", ",", "*", "args", ")", ":", "\n", "    ", "return", "AtomicGenerationIteratorTrainer", "(", "opt", ",", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.utils.update_generation_losses": [[8, 32], ["isinstance", "copy.deepcopy", "copy.deepcopy", "utils.update_indiv_generation_losses", "utils.update_tensor_generation_losses_knowledge", "utils.update_tensor_generation_losses_sentence"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.utils.update_indiv_generation_losses", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.utils.update_tensor_generation_losses_knowledge", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.utils.update_tensor_generation_losses_sentence"], ["\n", "losses", "[", "name", "]", "+=", "loss", "*", "bs", "\n", "\n", "\n", "", "def", "update_generation_losses", "(", "losses", ",", "nums", ",", "micro", ",", "macro", ",", "bs", ",", "length", ",", "loss", ",", "s", ")", ":", "\n", "# Update Losses", "\n", "    ", "nums", "[", "macro", "]", "+=", "bs", "\n", "\n", "if", "isinstance", "(", "length", ",", "int", ")", ":", "\n", "        ", "update_indiv_generation_losses", "(", "\n", "losses", ",", "nums", ",", "micro", ",", "macro", ",", "bs", ",", "length", ",", "loss", ")", "\n", "", "else", ":", "\n", "        ", "if", "s", "==", "\"knowledge\"", ":", "\n", "            ", "update_tensor_generation_losses_knowledge", "(", "\n", "losses", ",", "nums", ",", "micro", ",", "macro", ",", "bs", ",", "length", ",", "loss", ")", "\n", "", "elif", "s", "==", "\"sentence\"", ":", "\n", "            ", "update_tensor_generation_losses_sentence", "(", "\n", "losses", ",", "nums", ",", "micro", ",", "macro", ",", "bs", ",", "length", ",", "loss", ")", "\n", "\n", "\n", "\n", "", "", "", "def", "update_indiv_generation_losses", "(", "losses", ",", "nums", ",", "micro", ",", "\n", "macro", ",", "bs", ",", "length", ",", "loss", ")", ":", "\n", "    ", "nums", "[", "micro", "]", "+=", "bs", "*", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.utils.update_indiv_generation_losses": [[34, 43], ["None"], "function", ["None"], ["\n", "losses", "[", "micro", "]", "+=", "batch_loss", "\n", "losses", "[", "macro", "]", "+=", "batch_loss", "/", "length", "\n", "\n", "\n", "", "def", "update_tensor_generation_losses", "(", "losses", ",", "nums", ",", "micro", ",", "\n", "macro", ",", "bs", ",", "length", ",", "loss", ")", ":", "\n", "    ", "nums", "[", "micro", "]", "+=", "length", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "losses", "[", "micro", "]", "+=", "loss", ".", "sum", "(", ")", ".", "item", "(", ")", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.utils.update_tensor_generation_losses_knowledge": [[45, 53], ["length.sum().item", "loss.sum().item", "length.sum", "loss.sum", "length.float"], "function", ["None"], ["\n", "\n", "", "def", "update_tensor_generation_losses_knowledge", "(", "losses_k", ",", "nums_k", ",", "micro", ",", "\n", "macro", ",", "bs", ",", "length", ",", "loss", ")", ":", "\n", "    ", "nums_k", "[", "micro", "]", "+=", "length", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "losses_k", "[", "micro", "]", "+=", "loss", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "losses_k", "[", "macro", "]", "+=", "(", "loss", "/", "length", ".", "float", "(", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.utils.update_tensor_generation_losses_sentence": [[54, 62], ["length.sum().item", "loss.sum().item", "length.sum", "loss.sum", "length.float"], "function", ["None"], ["", "def", "update_tensor_generation_losses_sentence", "(", "losses_s", ",", "nums_s", ",", "micro", ",", "\n", "macro", ",", "bs", ",", "length", ",", "loss", ")", ":", "\n", "    ", "nums_s", "[", "micro", "]", "+=", "length", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "losses_s", "[", "micro", "]", "+=", "loss", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "losses_s", "[", "macro", "]", "+=", "(", "loss", "/", "length", ".", "float", "(", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.train.utils.modify_output_for_loss_fn": [[65, 74], ["torch.softmax", "torch.log_softmax", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "function", ["None"], []], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.config.get_parameters": [[14, 56], ["utils.utils.DD", "utils.utils.DD", "config.get_net_parameters", "config.get_training_parameters", "config.get_data_parameters", "config.get_eval_parameters", "utils.utils.DD", "int", "int", "print", "utils.utils.DD.data.get"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.config.get_net_parameters", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.config.get_training_parameters", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.config.get_data_parameters", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.config.get_eval_parameters"], ["def", "get_parameters", "(", "opt", ",", "exp_type", "=", "\"model\"", ")", ":", "\n", "    ", "params", "=", "DD", "(", ")", "\n", "params", ".", "net", "=", "DD", "(", ")", "\n", "\n", "params", ".", "mle", "=", "0", "\n", "params", ".", "dataset", "=", "opt", ".", "dataset", "\n", "\n", "params", ".", "net", "=", "get_net_parameters", "(", "opt", ")", "\n", "params", ".", "train", "=", "get_training_parameters", "(", "opt", ")", "\n", "\n", "params", ".", "model", "=", "params", ".", "net", ".", "model", "\n", "params", ".", "exp", "=", "opt", ".", "exp", "\n", "\n", "params", ".", "data", "=", "get_data_parameters", "(", "opt", ",", "params", ".", "exp", ",", "params", ".", "dataset", ")", "\n", "params", ".", "eval", "=", "get_eval_parameters", "(", "opt", ",", "params", ".", "data", ".", "get", "(", "\"categories\"", ",", "None", ")", ")", "\n", "\n", "meta", "=", "DD", "(", ")", "\n", "\n", "params", ".", "trainer", "=", "opt", ".", "trainer", "\n", "\n", "meta", ".", "iterations", "=", "int", "(", "opt", ".", "iterations", ")", "\n", "meta", ".", "cycle", "=", "opt", ".", "cycle", "\n", "params", ".", "cycle", "=", "opt", ".", "cycle", "\n", "params", ".", "iters", "=", "int", "(", "opt", ".", "iterations", ")", "\n", "\n", "global", "toy", "\n", "toy", "=", "opt", ".", "toy", "\n", "\n", "global", "do_gen", "\n", "do_gen", "=", "opt", ".", "do_gen", "\n", "\n", "global", "save", "\n", "save", "=", "opt", ".", "save", "\n", "\n", "global", "test_save", "\n", "test_save", "=", "opt", ".", "test_save", "\n", "\n", "global", "save_strategy", "\n", "save_strategy", "=", "opt", ".", "save_strategy", "\n", "\n", "print", "(", "params", ")", "\n", "return", "params", ",", "meta", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.config.get_eval_parameters": [[58, 83], ["utils.utils.DD"], "function", ["None"], ["", "def", "get_eval_parameters", "(", "opt", ",", "force_categories", "=", "None", ")", ":", "\n", "    ", "evaluate", "=", "DD", "(", ")", "\n", "\n", "if", "opt", ".", "eval_sampler", "==", "\"beam\"", ":", "\n", "        ", "evaluate", ".", "bs", "=", "opt", ".", "beam_size", "\n", "", "elif", "opt", ".", "eval_sampler", "==", "\"greedy\"", ":", "\n", "        ", "evaluate", ".", "bs", "=", "1", "\n", "", "elif", "opt", ".", "eval_sampler", "==", "\"topk\"", ":", "\n", "        ", "evaluate", ".", "k", "=", "opt", ".", "topk_size", "\n", "\n", "", "evaluate", ".", "smax", "=", "opt", ".", "gen_seqlength", "\n", "evaluate", ".", "sample", "=", "opt", ".", "eval_sampler", "\n", "\n", "evaluate", ".", "numseq", "=", "opt", ".", "num_sequences", "\n", "\n", "evaluate", ".", "gs", "=", "opt", ".", "generate_sequences", "\n", "evaluate", ".", "es", "=", "opt", ".", "evaluate_sequences", "\n", "\n", "if", "opt", ".", "dataset", "==", "\"atomic\"", ":", "\n", "        ", "if", "\"eval_categories\"", "in", "opt", "and", "force_categories", "is", "None", ":", "\n", "            ", "evaluate", ".", "categories", "=", "opt", ".", "eval_categories", "\n", "", "else", ":", "\n", "            ", "evaluate", ".", "categories", "=", "force_categories", "\n", "\n", "", "", "return", "evaluate", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.config.get_data_parameters": [[85, 108], ["utils.utils.DD", "sorted"], "function", ["None"], ["", "def", "get_data_parameters", "(", "opt", ",", "experiment", ",", "dataset", ")", ":", "\n", "    ", "data", "=", "DD", "(", ")", "\n", "if", "dataset", "==", "\"atomic\"", ":", "\n", "        ", "data", ".", "categories", "=", "sorted", "(", "opt", ".", "categories", ")", "\n", "# hard-coded", "\n", "data", ".", "maxe1", "=", "17", "\n", "data", ".", "maxe2", "=", "35", "\n", "data", ".", "maxr", "=", "1", "\n", "\n", "", "elif", "dataset", "==", "\"conceptnet\"", ":", "\n", "        ", "data", ".", "rel", "=", "opt", ".", "relation_format", "\n", "data", ".", "trainsize", "=", "opt", ".", "training_set_size", "\n", "data", ".", "devversion", "=", "opt", ".", "development_set_versions_to_use", "\n", "data", ".", "maxe1", "=", "opt", ".", "max_event_1_size", "\n", "data", ".", "maxe2", "=", "opt", ".", "max_event_2_size", "\n", "if", "data", ".", "rel", "==", "\"language\"", ":", "\n", "# hard-coded", "\n", "            ", "data", ".", "maxr", "=", "5", "\n", "", "else", ":", "\n", "# hard-coded", "\n", "            ", "data", ".", "maxr", "=", "1", "\n", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.config.get_training_parameters": [[110, 144], ["utils.utils.DD", "utils.utils.DD", "utils.utils.DD", "utils.utils.DD.update"], "function", ["None"], ["", "def", "get_training_parameters", "(", "opt", ")", ":", "\n", "    ", "train", "=", "DD", "(", ")", "\n", "static", "=", "DD", "(", ")", "\n", "static", ".", "exp", "=", "opt", ".", "exp", "\n", "\n", "static", ".", "seed", "=", "opt", ".", "random_seed", "\n", "\n", "# weight decay", "\n", "static", ".", "l2", "=", "opt", ".", "l2", "\n", "static", ".", "vl2", "=", "True", "\n", "static", ".", "lrsched", "=", "opt", ".", "learning_rate_schedule", "# 'warmup_linear'", "\n", "static", ".", "lrwarm", "=", "opt", ".", "learning_rate_warmup", "# 0.002", "\n", "\n", "# gradient clipping", "\n", "static", ".", "clip", "=", "opt", ".", "clip", "\n", "\n", "# what loss function to use", "\n", "static", ".", "loss", "=", "opt", ".", "loss", "\n", "\n", "dynamic", "=", "DD", "(", ")", "\n", "dynamic", ".", "lr", "=", "opt", ".", "learning_rate", "# learning rate", "\n", "dynamic", ".", "bs", "=", "opt", ".", "batch_size", "# batch size", "\n", "# optimizer to use {adam, rmsprop, etc.}", "\n", "dynamic", ".", "optim", "=", "opt", ".", "optimizer", "\n", "\n", "# rmsprop", "\n", "# alpha is interpolation average", "\n", "\n", "static", ".", "update", "(", "opt", "[", "dynamic", ".", "optim", "]", ")", "\n", "\n", "train", ".", "static", "=", "static", "\n", "train", ".", "dynamic", "=", "dynamic", "\n", "\n", "return", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.config.get_net_parameters": [[146, 165], ["utils.utils.DD"], "function", ["None"], ["", "def", "get_net_parameters", "(", "opt", ")", ":", "\n", "    ", "net", "=", "DD", "(", ")", "\n", "net", ".", "model", "=", "opt", ".", "model", "\n", "net", ".", "nL", "=", "opt", ".", "num_layers", "\n", "net", ".", "nH", "=", "opt", ".", "num_heads", "\n", "net", ".", "hSize", "=", "opt", ".", "hidden_dim", "\n", "net", ".", "edpt", "=", "opt", ".", "embedding_dropout", "\n", "net", ".", "adpt", "=", "opt", ".", "attention_dropout", "\n", "net", ".", "rdpt", "=", "opt", ".", "residual_dropout", "\n", "net", ".", "odpt", "=", "opt", ".", "output_dropout", "\n", "net", ".", "pt", "=", "opt", ".", "pretrain", "\n", "net", ".", "afn", "=", "opt", ".", "activation", "\n", "\n", "# how to intialize parameters", "\n", "# format is gauss+{}+{}.format(mean, std)", "\n", "# n = the default initialization pytorch", "\n", "net", ".", "init", "=", "opt", ".", "init", "\n", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.config.read_config": [[167, 181], ["utils.utils.DD", "print", "file_.items", "type", "config.read_config"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.config.read_config"], ["", "def", "read_config", "(", "file_", ")", ":", "\n", "    ", "config", "=", "DD", "(", ")", "\n", "print", "(", "file_", ")", "\n", "for", "k", ",", "v", "in", "file_", ".", "items", "(", ")", ":", "\n", "        ", "if", "v", "==", "\"True\"", "or", "v", "==", "\"T\"", "or", "v", "==", "\"true\"", ":", "\n", "            ", "config", "[", "k", "]", "=", "True", "\n", "", "elif", "v", "==", "\"False\"", "or", "v", "==", "\"F\"", "or", "v", "==", "\"false\"", ":", "\n", "            ", "config", "[", "k", "]", "=", "False", "\n", "", "elif", "type", "(", "v", ")", "==", "dict", ":", "\n", "            ", "config", "[", "k", "]", "=", "read_config", "(", "v", ")", "\n", "", "else", ":", "\n", "            ", "config", "[", "k", "]", "=", "v", "\n", "\n", "", "", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.config.load_config": [[183, 187], ["open", "json.load"], "function", ["None"], ["", "def", "load_config", "(", "name", ")", ":", "\n", "    ", "with", "open", "(", "name", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "config", "=", "json", ".", "load", "(", "f", ")", "\n", "", "return", "config", "\n", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_checkpoint": [[18, 21], ["print", "torch.save"], "function", ["None"], ["def", "save_checkpoint", "(", "state", ",", "filename", ")", ":", "\n", "    ", "print", "(", "\"Saving model to {}\"", ".", "format", "(", "filename", ")", ")", "\n", "torch", ".", "save", "(", "state", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_step": [[23, 35], ["data.save_checkpoint", "utils.make_name", "utils.make_name", "model.state_dict", "optimizer.state_dict"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_checkpoint", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.make_name", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.make_name"], ["", "def", "save_step", "(", "model", ",", "vocab", ",", "optimizer", ",", "opt", ",", "length", ",", "lrs", ",", "model_type", ")", ":", "\n", "    ", "if", "cfg", ".", "test_save", ":", "\n", "        ", "name", "=", "\"{}.pickle\"", ".", "format", "(", "utils", ".", "make_name", "(", "\n", "opt", ",", "prefix", "=", "\"garbage/models/\"", ",", "is_dir", "=", "False", ",", "eval_", "=", "True", ")", ")", "\n", "", "else", ":", "\n", "        ", "name", "=", "\"{}.pickle\"", ".", "format", "(", "utils", ".", "make_name", "(", "\n", "opt", ",", "prefix", "=", "\"models/\"", "+", "model_type", "+", "\"/\"", ",", "is_dir", "=", "False", ",", "eval_", "=", "True", ")", ")", "\n", "", "save_checkpoint", "(", "{", "\n", "\"epoch\"", ":", "length", ",", "\"state_dict\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\"opt\"", ":", "opt", ",", "\n", "\"vocab\"", ":", "vocab", ",", "\"epoch_learning_rates\"", ":", "lrs", "}", ",", "\n", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.save_eval_file": [[37, 59], ["print", "utils.make_name", "utils.make_name", "open", "pickle.dump", "open", "f.write", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.make_name", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.make_name"], ["", "def", "save_eval_file", "(", "opt", ",", "stats", ",", "eval_type", "=", "\"losses\"", ",", "split", "=", "\"dev\"", ",", "ext", "=", "\"pickle\"", ")", ":", "\n", "    ", "if", "cfg", ".", "test_save", ":", "\n", "        ", "name", "=", "\"{}/{}.{}\"", ".", "format", "(", "utils", ".", "make_name", "(", "\n", "opt", ",", "prefix", "=", "\"garbage/{}/\"", ".", "format", "(", "eval_type", ")", ",", "\n", "is_dir", "=", "True", ",", "eval_", "=", "True", ")", ",", "split", ",", "ext", ")", "\n", "", "else", ":", "\n", "        ", "name", "=", "\"{}/{}.{}\"", ".", "format", "(", "utils", ".", "make_name", "(", "\n", "opt", ",", "prefix", "=", "\"results/{}/\"", ".", "format", "(", "eval_type", ")", ",", "\n", "is_dir", "=", "True", ",", "eval_", "=", "True", ")", ",", "split", ",", "ext", ")", "\n", "", "print", "(", "\"Saving {} {} to {}\"", ".", "format", "(", "split", ",", "eval_type", ",", "name", ")", ")", "\n", "\n", "if", "ext", "==", "\"pickle\"", ":", "\n", "        ", "with", "open", "(", "name", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "pickle", ".", "dump", "(", "stats", ",", "f", ")", "\n", "", "", "elif", "ext", "==", "\"txt\"", ":", "\n", "        ", "with", "open", "(", "name", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "stats", ")", "\n", "", "", "elif", "ext", "==", "\"json\"", ":", "\n", "        ", "with", "open", "(", "name", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "stats", ",", "f", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.load_checkpoint": [[61, 68], ["os.path.exists", "torch.load", "print"], "function", ["None"], ["", "", "def", "load_checkpoint", "(", "filename", ",", "gpu", "=", "True", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "\n", "filename", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"No model found at {}\"", ".", "format", "(", "filename", ")", ")", "\n", "", "return", "checkpoint", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.make_data_loader": [[70, 75], ["src.GenerationDataLoader", "src.GenerationDataLoader"], "function", ["None"], ["", "def", "make_data_loader", "(", "opt", ",", "*", "args", ")", ":", "\n", "    ", "if", "opt", ".", "dataset", "==", "\"atomic\"", ":", "\n", "        ", "return", "atomic_data", ".", "GenerationDataLoader", "(", "opt", ",", "*", "args", ")", "\n", "", "elif", "opt", ".", "dataset", "==", "\"conceptnet\"", ":", "\n", "        ", "return", "conceptnet_data", ".", "GenerationDataLoader", "(", "opt", ",", "*", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.data.set_max_sizes": [[77, 86], ["[].size", "[].size"], "function", ["None"], ["", "", "def", "set_max_sizes", "(", "data_loader", ",", "force_split", "=", "None", ")", ":", "\n", "    ", "data_loader", ".", "total_size", "=", "{", "}", "\n", "if", "force_split", "is", "not", "None", ":", "\n", "        ", "data_loader", ".", "total_size", "[", "force_split", "]", "=", "data_loader", ".", "sequences", "[", "force_split", "]", "[", "\"total\"", "]", ".", "size", "(", "0", ")", "\n", "return", "\n", "", "for", "split", "in", "data_loader", ".", "sequences", ":", "\n", "        ", "data_loader", ".", "total_size", "[", "split", "]", "=", "data_loader", ".", "sequences", "[", "split", "]", "[", "\"total\"", "]", ".", "size", "(", "0", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.DataLoader.__init__": [[24, 44], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "opt", ")", ":", "\n", "        ", "self", ".", "data", "=", "{", "}", "\n", "self", ".", "data", "[", "\"train\"", "]", "=", "{", "}", "\n", "self", ".", "data", "[", "\"dev\"", "]", "=", "{", "}", "\n", "self", ".", "data", "[", "\"test\"", "]", "=", "{", "}", "\n", "\n", "self", ".", "sequences", "=", "{", "}", "\n", "self", ".", "sequences", "[", "\"train\"", "]", "=", "{", "}", "\n", "self", ".", "sequences", "[", "\"dev\"", "]", "=", "{", "}", "\n", "self", ".", "sequences", "[", "\"test\"", "]", "=", "{", "}", "\n", "\n", "self", ".", "masks", "=", "{", "}", "\n", "self", ".", "masks", "[", "\"train\"", "]", "=", "{", "}", "\n", "self", ".", "masks", "[", "\"dev\"", "]", "=", "{", "}", "\n", "self", ".", "masks", "[", "\"test\"", "]", "=", "{", "}", "\n", "\n", "self", ".", "offsets", "=", "{", "}", "\n", "self", ".", "offsets", "[", "\"train\"", "]", "=", "{", "}", "\n", "self", ".", "offsets", "[", "\"dev\"", "]", "=", "{", "}", "\n", "self", ".", "offsets", "[", "\"test\"", "]", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.DataLoader.offset_summary": [[45, 47], ["None"], "methods", ["None"], ["", "def", "offset_summary", "(", "self", ",", "split", ")", ":", "\n", "        ", "return", "self", ".", "offsets", "[", "split", "]", "[", "\"total\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.GenerationDataLoader.__init__": [[63, 78], ["atomic.DataLoader.__init__"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__"], ["    ", "def", "__init__", "(", "self", ",", "opt", ",", "categories", ")", ":", "\n", "        ", "super", "(", "GenerationDataLoader", ",", "self", ")", ".", "__init__", "(", "opt", ")", "\n", "\n", "self", ".", "categories", "=", "categories", "\n", "self", ".", "opt", "=", "opt", "\n", "\n", "for", "split", "in", "self", ".", "data", ":", "\n", "            ", "self", ".", "data", "[", "split", "]", "=", "{", "\"total\"", ":", "[", "]", "}", "\n", "self", ".", "offsets", "[", "split", "]", "=", "{", "\"total\"", ":", "0", "}", "\n", "\n", "", "self", ".", "vocab_encoder", "=", "None", "\n", "self", ".", "vocab_decoder", "=", "None", "\n", "self", ".", "special_chars", "=", "None", "\n", "self", ".", "max_event", "=", "None", "\n", "self", ".", "max_effect", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.GenerationDataLoader.load_data": [[79, 103], ["atomic.do_take_partial_dataset", "print", "src.load_existing_data_loader", "src.load_existing_data_loader", "pandas.read_csv", "pandas.read_csv.iloc[].apply", "atomic.select_partial_dataset", "atomic.map_name", "utils.zipped_flatten", "col.apply", "zip", "len"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.do_take_partial_dataset", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.load_existing_data_loader", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.load_existing_data_loader", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.select_partial_dataset", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.map_name", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.zipped_flatten"], ["", "def", "load_data", "(", "self", ",", "path", ")", ":", "\n", "        ", "if", "\".pickle\"", "in", "path", ":", "\n", "            ", "print", "(", "\"Loading data from: {}\"", ".", "format", "(", "path", ")", ")", "\n", "data_utils", ".", "load_existing_data_loader", "(", "self", ",", "path", ")", "\n", "\n", "return", "True", "\n", "\n", "", "for", "split", "in", "self", ".", "data", ":", "\n", "            ", "file_name", "=", "\"v4_atomic_{}.csv\"", ".", "format", "(", "map_name", "(", "split", ")", ")", "\n", "\n", "df", "=", "pandas", ".", "read_csv", "(", "\"{}/{}\"", ".", "format", "(", "path", ",", "file_name", ")", ",", "index_col", "=", "0", ")", "\n", "df", ".", "iloc", "[", ":", ",", ":", "9", "]", "=", "df", ".", "iloc", "[", ":", ",", ":", "9", "]", ".", "apply", "(", "\n", "lambda", "col", ":", "col", ".", "apply", "(", "json", ".", "loads", ")", ")", "\n", "\n", "for", "cat", "in", "self", ".", "categories", ":", "\n", "                ", "attr", "=", "df", "[", "cat", "]", "\n", "self", ".", "data", "[", "split", "]", "[", "\"total\"", "]", "+=", "utils", ".", "zipped_flatten", "(", "zip", "(", "\n", "attr", ".", "index", ",", "[", "\"<{}>\"", ".", "format", "(", "cat", ")", "]", "*", "len", "(", "attr", ")", ",", "attr", ".", "values", ")", ")", "\n", "\n", "", "", "if", "do_take_partial_dataset", "(", "self", ".", "opt", ".", "data", ")", ":", "\n", "            ", "self", ".", "data", "[", "\"train\"", "]", "[", "\"total\"", "]", "=", "select_partial_dataset", "(", "\n", "self", ".", "opt", ".", "data", ",", "self", ".", "data", "[", "\"train\"", "]", "[", "\"total\"", "]", ")", "\n", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.GenerationDataLoader.make_tensors": [[104, 138], ["max", "max", "print", "print", "atomic.get_generation_sequences", "len", "torch.LongTensor().fill_", "enumerate", "max", "max", "torch.LongTensor", "torch.LongTensor", "len", "len", "torch.LongTensor", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.get_generation_sequences"], ["", "def", "make_tensors", "(", "self", ",", "text_encoder", ",", "special", ",", "\n", "splits", "=", "[", "\"train\"", ",", "\"dev\"", ",", "\"test\"", "]", ",", "test", "=", "False", ")", ":", "\n", "        ", "self", ".", "vocab_encoder", "=", "text_encoder", ".", "encoder", "\n", "self", ".", "vocab_decoder", "=", "text_encoder", ".", "decoder", "\n", "self", ".", "special_chars", "=", "special", "\n", "\n", "sequences", "=", "{", "}", "\n", "for", "split", "in", "splits", ":", "\n", "            ", "sequences", "[", "split", "]", "=", "get_generation_sequences", "(", "\n", "self", ".", "opt", ",", "self", ".", "data", ",", "split", ",", "text_encoder", ",", "test", ")", "\n", "\n", "self", ".", "masks", "[", "split", "]", "[", "\"total\"", "]", "=", "[", "(", "len", "(", "i", "[", "0", "]", ")", ",", "len", "(", "i", "[", "1", "]", ")", ")", "for", "\n", "i", "in", "sequences", "[", "split", "]", "]", "\n", "\n", "", "self", ".", "max_event", "=", "max", "(", "[", "max", "(", "[", "l", "[", "0", "]", "for", "l", "in", "self", ".", "masks", "[", "split", "]", "[", "\"total\"", "]", "]", ")", "\n", "for", "split", "in", "self", ".", "masks", "]", ")", "\n", "self", ".", "max_effect", "=", "max", "(", "[", "max", "(", "[", "l", "[", "1", "]", "for", "l", "in", "self", ".", "masks", "[", "split", "]", "[", "\"total\"", "]", "]", ")", "\n", "for", "split", "in", "self", ".", "masks", "]", ")", "\n", "\n", "print", "(", "self", ".", "max_event", ")", "\n", "print", "(", "self", ".", "max_effect", ")", "\n", "\n", "for", "split", "in", "splits", ":", "\n", "            ", "num_elements", "=", "len", "(", "sequences", "[", "split", "]", ")", "\n", "self", ".", "sequences", "[", "split", "]", "[", "\"total\"", "]", "=", "torch", ".", "LongTensor", "(", "\n", "num_elements", ",", "self", ".", "max_event", "+", "self", ".", "max_effect", ")", ".", "fill_", "(", "0", ")", "\n", "\n", "for", "i", ",", "seq", "in", "enumerate", "(", "sequences", "[", "split", "]", ")", ":", "\n", "# print(self.sequences[split][\"total\"][i, :len(seq[0])].size())", "\n", "# print(torch.FloatTensor(seq[0]).size())", "\n", "                ", "self", ".", "sequences", "[", "split", "]", "[", "\"total\"", "]", "[", "i", ",", ":", "len", "(", "seq", "[", "0", "]", ")", "]", "=", "torch", ".", "LongTensor", "(", "seq", "[", "0", "]", ")", "\n", "self", ".", "sequences", "[", "split", "]", "[", "\"total\"", "]", "[", "i", ",", "self", ".", "max_event", ":", "self", ".", "max_event", "+", "len", "(", "seq", "[", "1", "]", ")", "]", "=", "torch", ".", "LongTensor", "(", "seq", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.GenerationDataLoader.sample_batch": [[139, 170], ["[].index_select.to", "atomic.make_attention_mask", "atomic.make_loss_mask", "[].index_select.size", "[].index_select", "torch.LongTensor().to", "len", "len", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.make_attention_mask", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.make_loss_mask"], ["", "", "", "def", "sample_batch", "(", "self", ",", "split", ",", "bs", ",", "idxs", "=", "None", ")", ":", "\n", "        ", "offset", "=", "self", ".", "offsets", "[", "split", "]", "[", "\"total\"", "]", "\n", "\n", "batch", "=", "{", "}", "\n", "\n", "# Decided not to reduce computation on here because it's all parallel", "\n", "# anyway and we don't want to run out of memory in cases where we", "\n", "# don't see the longest version quickly enough", "\n", "\n", "if", "idxs", ":", "\n", "            ", "seqs", "=", "self", ".", "sequences", "[", "split", "]", "[", "\"total\"", "]", ".", "index_select", "(", "\n", "0", ",", "torch", ".", "LongTensor", "(", "idxs", ")", ".", "to", "(", "\n", "self", ".", "sequences", "[", "split", "]", "[", "\"total\"", "]", ".", "device", ")", ")", "\n", "", "else", ":", "\n", "            ", "seqs", "=", "self", ".", "sequences", "[", "split", "]", "[", "\"total\"", "]", "[", "offset", ":", "offset", "+", "bs", "]", "\n", "", "batch", "[", "\"sequences\"", "]", "=", "seqs", ".", "to", "(", "cfg", ".", "device", ")", "\n", "batch", "[", "\"attention_mask\"", "]", "=", "make_attention_mask", "(", "seqs", ")", "\n", "batch", "[", "\"loss_mask\"", "]", "=", "make_loss_mask", "(", "\n", "seqs", ",", "self", ".", "max_event", ",", "1", ")", "\n", "batch", "[", "\"key\"", "]", "=", "(", "\"total\"", ",", "offset", ",", "offset", "+", "bs", ")", "\n", "\n", "offset", "+=", "seqs", ".", "size", "(", "0", ")", "\n", "\n", "self", ".", "offsets", "[", "split", "]", "[", "\"total\"", "]", "=", "offset", "\n", "\n", "if", "split", "==", "\"train\"", "and", "offset", "+", "bs", ">", "len", "(", "self", ".", "sequences", "[", "split", "]", "[", "\"total\"", "]", ")", ":", "\n", "            ", "return", "batch", ",", "True", "\n", "", "elif", "offset", ">=", "len", "(", "self", ".", "sequences", "[", "split", "]", "[", "\"total\"", "]", ")", ":", "\n", "            ", "return", "batch", ",", "True", "\n", "", "else", ":", "\n", "            ", "return", "batch", ",", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.GenerationDataLoader.reset_offsets": [[171, 185], ["isinstance", "atomic.GenerationDataLoader.shuffle_sequences"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.GenerationDataLoader.shuffle_sequences"], ["", "", "def", "reset_offsets", "(", "self", ",", "splits", "=", "[", "\"train\"", ",", "\"test\"", ",", "\"dev\"", "]", ",", "\n", "shuffle", "=", "True", ",", "keys", "=", "None", ")", ":", "\n", "        ", "if", "isinstance", "(", "splits", ",", "str", ")", ":", "\n", "            ", "splits", "=", "[", "splits", "]", "\n", "\n", "", "for", "split", "in", "splits", ":", "\n", "            ", "if", "keys", "is", "None", ":", "\n", "                ", "keys", "=", "[", "\"total\"", "]", "\n", "\n", "", "for", "key", "in", "keys", ":", "\n", "                ", "self", ".", "offsets", "[", "split", "]", "[", "key", "]", "=", "0", "\n", "\n", "", "if", "shuffle", ":", "\n", "                ", "self", ".", "shuffle_sequences", "(", "split", ",", "keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.GenerationDataLoader.shuffle_sequences": [[186, 205], ["atomic.GenerationDataLoader.data[].keys", "list", "random.shuffle", "[].index_select", "range", "torch.LongTensor", "len"], "methods", ["None"], ["", "", "", "def", "shuffle_sequences", "(", "self", ",", "split", "=", "\"train\"", ",", "keys", "=", "None", ")", ":", "\n", "        ", "if", "keys", "is", "None", ":", "\n", "# print(type(self.data))", "\n", "# print(type(self.data.keys()))", "\n", "            ", "keys", "=", "self", ".", "data", "[", "split", "]", ".", "keys", "(", ")", "\n", "\n", "", "for", "key", "in", "keys", ":", "\n", "            ", "idxs", "=", "list", "(", "range", "(", "len", "(", "self", ".", "data", "[", "split", "]", "[", "key", "]", ")", ")", ")", "\n", "\n", "random", ".", "shuffle", "(", "idxs", ")", "\n", "\n", "self", ".", "sequences", "[", "split", "]", "[", "key", "]", "=", "self", ".", "sequences", "[", "split", "]", "[", "key", "]", ".", "index_select", "(", "\n", "0", ",", "torch", ".", "LongTensor", "(", "idxs", ")", ")", "\n", "\n", "temp", "=", "[", "self", ".", "data", "[", "split", "]", "[", "key", "]", "[", "i", "]", "for", "i", "in", "idxs", "]", "\n", "self", ".", "data", "[", "split", "]", "[", "key", "]", "=", "temp", "\n", "temp", "=", "[", "self", ".", "masks", "[", "split", "]", "[", "key", "]", "[", "i", "]", "for", "i", "in", "idxs", "]", "\n", "self", ".", "masks", "[", "split", "]", "[", "key", "]", "=", "temp", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.map_name": [[14, 21], ["None"], "function", ["None"], ["def", "map_name", "(", "name", ")", ":", "\n", "    ", "if", "name", "==", "\"train\"", ":", "\n", "        ", "return", "\"trn\"", "\n", "", "elif", "name", "==", "\"test\"", ":", "\n", "        ", "return", "\"tst\"", "\n", "", "else", ":", "\n", "        ", "return", "\"dev\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.do_take_partial_dataset": [[49, 55], ["data_opts.get"], "function", ["None"], ["", "", "def", "do_take_partial_dataset", "(", "data_opts", ")", ":", "\n", "    ", "if", "data_opts", ".", "get", "(", "\"kr\"", ",", "None", ")", "is", "None", ":", "\n", "        ", "return", "False", "\n", "", "if", "data_opts", ".", "kr", "==", "1", ":", "\n", "        ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.select_partial_dataset": [[57, 60], ["math.ceil", "random.sample", "len"], "function", ["None"], ["", "def", "select_partial_dataset", "(", "data_opts", ",", "data", ")", ":", "\n", "    ", "num_selections", "=", "math", ".", "ceil", "(", "data_opts", ".", "kr", "*", "len", "(", "data", ")", ")", "\n", "return", "random", ".", "sample", "(", "data", ",", "num_selections", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.prune_data_for_evaluation": [[207, 220], ["enumerate", "[].index_select", "torch.LongTensor", "indices.append"], "function", ["None"], ["", "", "", "def", "prune_data_for_evaluation", "(", "data_loader", ",", "categories", ",", "split", ")", ":", "\n", "    ", "indices", "=", "[", "]", "\n", "for", "i", ",", "example", "in", "enumerate", "(", "data_loader", ".", "data", "[", "split", "]", "[", "\"total\"", "]", ")", ":", "\n", "        ", "if", "example", "[", "1", "]", "in", "categories", ":", "\n", "            ", "indices", ".", "append", "(", "i", ")", "\n", "\n", "", "", "data_loader", ".", "masks", "[", "split", "]", "[", "\"total\"", "]", "=", "[", "data_loader", ".", "masks", "[", "split", "]", "[", "\"total\"", "]", "[", "i", "]", "\n", "for", "i", "in", "indices", "]", "\n", "data_loader", ".", "sequences", "[", "split", "]", "[", "\"total\"", "]", "=", "data_loader", ".", "sequences", "[", "split", "]", "[", "\"total\"", "]", ".", "index_select", "(", "\n", "0", ",", "torch", ".", "LongTensor", "(", "indices", ")", ")", "\n", "data_loader", ".", "data", "[", "split", "]", "[", "\"total\"", "]", "=", "[", "data_loader", ".", "data", "[", "split", "]", "[", "\"total\"", "]", "[", "i", "]", "\n", "for", "i", "in", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.make_attention_mask": [[222, 224], ["None"], "function", ["None"], ["", "def", "make_attention_mask", "(", "sequences", ")", ":", "\n", "    ", "return", "(", "sequences", "!=", "0", ")", ".", "float", "(", ")", ".", "to", "(", "cfg", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.make_loss_mask": [[226, 232], ["mask[].to"], "function", ["None"], ["", "def", "make_loss_mask", "(", "sequences", ",", "max_event", ",", "num_delim_tokens", ")", ":", "\n", "# print(num_delim_tokens)", "\n", "# print(sequences.size())", "\n", "    ", "mask", "=", "(", "sequences", "!=", "0", ")", ".", "float", "(", ")", "\n", "mask", "[", ":", ",", ":", "max_event", "+", "num_delim_tokens", "]", "=", "0", "\n", "return", "mask", "[", ":", ",", "1", ":", "]", ".", "to", "(", "cfg", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.find_underscore_length": [[234, 240], ["None"], "function", ["None"], ["", "def", "find_underscore_length", "(", "seq", ")", ":", "\n", "    ", "start", "=", "\"_\"", "\n", "\n", "while", "start", "in", "seq", ":", "\n", "        ", "start", "+=", "\"_\"", "\n", "", "return", "start", "[", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.handle_underscores": [[242, 263], ["enumerate", "utils.flatten", "atomic.find_underscore_length", "i.strip", "suffix.split", "to_flatten.append", "to_flatten.append", "to_flatten.append", "text_encoder.encode", "len"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.flatten", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.find_underscore_length", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.encode"], ["", "def", "handle_underscores", "(", "suffix", ",", "text_encoder", ",", "prefix", "=", "False", ")", ":", "\n", "    ", "encoder", "=", "text_encoder", ".", "encoder", "\n", "if", "prefix", ":", "\n", "        ", "tok", "=", "\"___\"", "\n", "", "else", ":", "\n", "        ", "tok", "=", "find_underscore_length", "(", "suffix", ")", "\n", "\n", "", "suffix_parts", "=", "[", "i", ".", "strip", "(", ")", "for", "i", "in", "suffix", ".", "split", "(", "\"{}\"", ".", "format", "(", "tok", ")", ")", "]", "\n", "to_flatten", "=", "[", "]", "\n", "for", "i", ",", "part", "in", "enumerate", "(", "suffix_parts", ")", ":", "\n", "        ", "if", "part", ":", "\n", "            ", "to_flatten", ".", "append", "(", "text_encoder", ".", "encode", "(", "[", "part", "]", ",", "verbose", "=", "False", ")", "[", "0", "]", ")", "\n", "\n", "if", "i", "!=", "len", "(", "suffix_parts", ")", "-", "1", "and", "suffix_parts", "[", "i", "+", "1", "]", ":", "\n", "                ", "to_flatten", ".", "append", "(", "[", "encoder", "[", "\"<blank>\"", "]", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "to_flatten", ".", "append", "(", "[", "encoder", "[", "\"<blank>\"", "]", "]", ")", "\n", "\n", "", "", "final_suffix", "=", "utils", ".", "flatten", "(", "to_flatten", ")", "\n", "\n", "return", "final_suffix", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.get_generation_sequences": [[265, 297], ["tqdm.tqdm", "atomic.do_example", "atomic.compile_final_sequence", "sequences.append"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.do_example", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.compile_final_sequence"], ["", "def", "get_generation_sequences", "(", "opt", ",", "data", ",", "split", ",", "text_encoder", ",", "test", ")", ":", "\n", "    ", "sequences", "=", "[", "]", "\n", "count", "=", "0", "\n", "\n", "final_prefix", "=", "None", "\n", "final_suffix", "=", "None", "\n", "\n", "for", "prefix", ",", "category", ",", "suffix", "in", "tqdm", "(", "data", "[", "split", "]", "[", "\"total\"", "]", ")", ":", "\n", "        ", "final_prefix", ",", "final_suffix", "=", "do_example", "(", "\n", "text_encoder", ",", "prefix", ",", "suffix", ",", "True", ",", "True", ")", "\n", "# if do_prefix:", "\n", "#     if \"___\" in prefix:", "\n", "#         final_prefix = handle_underscores(prefix, text_encoder, True)", "\n", "#     else:", "\n", "#         final_prefix = text_encoder.encode([prefix], verbose=False)[0]", "\n", "# if do_suffix:", "\n", "#     if \"_\" in suffix:", "\n", "#         final_suffix = handle_underscores(suffix, text_encoder)", "\n", "#     else:", "\n", "#         final_suffix = text_encoder.encode([suffix], verbose=False)[0]", "\n", "\n", "final", "=", "compile_final_sequence", "(", "\n", "opt", ",", "final_prefix", ",", "final_suffix", ",", "category", ",", "text_encoder", ")", "\n", "\n", "sequences", ".", "append", "(", "final", ")", "\n", "\n", "count", "+=", "1", "\n", "\n", "if", "count", ">", "10", "and", "test", ":", "\n", "            ", "break", "\n", "\n", "", "", "return", "sequences", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.do_example": [[300, 316], ["atomic.handle_underscores", "atomic.handle_underscores", "text_encoder.encode", "text_encoder.encode"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.handle_underscores", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.handle_underscores", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.encode", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.encode"], ["", "def", "do_example", "(", "text_encoder", ",", "prefix", ",", "suffix", ",", "do_prefix", ",", "do_suffix", ")", ":", "\n", "    ", "final_prefix", "=", "None", "\n", "final_suffix", "=", "None", "\n", "\n", "if", "do_prefix", ":", "\n", "        ", "if", "\"___\"", "in", "prefix", ":", "\n", "            ", "final_prefix", "=", "handle_underscores", "(", "prefix", ",", "text_encoder", ",", "True", ")", "\n", "", "else", ":", "\n", "            ", "final_prefix", "=", "text_encoder", ".", "encode", "(", "[", "prefix", "]", ",", "verbose", "=", "False", ")", "[", "0", "]", "\n", "", "", "if", "do_suffix", ":", "\n", "        ", "if", "\"_\"", "in", "suffix", ":", "\n", "            ", "final_suffix", "=", "handle_underscores", "(", "suffix", ",", "text_encoder", ")", "\n", "", "else", ":", "\n", "            ", "final_suffix", "=", "text_encoder", ".", "encode", "(", "[", "suffix", "]", ",", "verbose", "=", "False", ")", "[", "0", "]", "\n", "\n", "", "", "return", "final_prefix", ",", "final_suffix", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.atomic.compile_final_sequence": [[318, 329], ["final.append", "final.append", "final[].append"], "function", ["None"], ["", "def", "compile_final_sequence", "(", "opt", ",", "final_prefix", ",", "final_suffix", ",", "category", ",", "text_encoder", ")", ":", "\n", "    ", "final", "=", "[", "]", "\n", "\n", "final", ".", "append", "(", "final_prefix", ")", "\n", "final", ".", "append", "(", "\n", "[", "text_encoder", ".", "encoder", "[", "category", "]", "]", "\n", "+", "final_suffix", ")", "\n", "\n", "final", "[", "-", "1", "]", ".", "append", "(", "text_encoder", ".", "encoder", "[", "\"<END>\"", "]", ")", "\n", "\n", "return", "final", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.__init__": [[61, 70], ["spacy.load", "json.load", "dict", "open", "open().read().split", "tuple", "zip", "utils.TextEncoder.encoder.items", "merge.split", "range", "open().read", "len", "open"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.bpe": [[71, 115], ["utils.get_pairs", "tuple", "min", "tuple", "len", "len", "utils.get_pairs", "word.index", "tuple.extend", "tuple.append", "tuple.append", "utils.TextEncoder.bpe_ranks.get", "tuple.extend", "float", "len"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.get_pairs", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.get_pairs"], []], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.encode": [[116, 137], ["tqdm.tqdm.tqdm", "utils.TextEncoder.nlp", "texts_tokens.append", "utils.TextEncoder.nlp", "texts_tokens.append", "utils.text_standardize", "text_tokens.extend", "utils.text_standardize", "text_tokens.extend", "ftfy.fix_text", "ftfy.fix_text", "utils.TextEncoder.encoder.get", "utils.TextEncoder.encoder.get", "utils.TextEncoder.bpe().split", "utils.TextEncoder.bpe().split", "utils.TextEncoder.bpe", "utils.TextEncoder.bpe", "token.text.lower", "token.text.lower"], "methods", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.text_standardize", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.text_standardize", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.bpe", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.TextEncoder.bpe"], []], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.load_existing_data_loader": [[10, 18], ["torch.load", "data_loader.__dict__.keys", "setattr", "torch.load.__dict__.keys", "getattr"], "function", ["None"], ["\n", "\n", "", "def", "update_generation_losses", "(", "losses", ",", "nums", ",", "micro", ",", "macro", ",", "bs", ",", "length", ",", "loss", ",", "s", ")", ":", "\n", "# Update Losses", "\n", "    ", "nums", "[", "macro", "]", "+=", "bs", "\n", "\n", "if", "isinstance", "(", "length", ",", "int", ")", ":", "\n", "        ", "update_indiv_generation_losses", "(", "\n", "losses", ",", "nums", ",", "micro", ",", "macro", ",", "bs", ",", "length", ",", "loss", ")", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.get_pairs": [[27, 38], ["set", "set.add"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.models.modeling_utils.BeamHypotheses.add"], ["\n", "\n", "", "", "", "def", "update_indiv_generation_losses", "(", "losses", ",", "nums", ",", "micro", ",", "\n", "macro", ",", "bs", ",", "length", ",", "loss", ")", ":", "\n", "    ", "nums", "[", "micro", "]", "+=", "bs", "*", "length", "\n", "\n", "batch_loss", "=", "loss", "*", "bs", "\n", "\n", "losses", "[", "micro", "]", "+=", "batch_loss", "\n", "losses", "[", "macro", "]", "+=", "batch_loss", "/", "length", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.data.utils.text_standardize": [[40, 54], ["re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub.replace", "re.sub", "re.sub", "re.sub", "re.sub.strip"], "function", ["None"], ["macro", ",", "bs", ",", "length", ",", "loss", ")", ":", "\n", "    ", "nums", "[", "micro", "]", "+=", "length", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "losses", "[", "micro", "]", "+=", "loss", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "losses", "[", "macro", "]", "+=", "(", "loss", "/", "length", ".", "float", "(", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "\n", "", "def", "update_tensor_generation_losses_knowledge", "(", "losses_k", ",", "nums_k", ",", "micro", ",", "\n", "macro", ",", "bs", ",", "length", ",", "loss", ")", ":", "\n", "    ", "nums_k", "[", "micro", "]", "+=", "length", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "losses_k", "[", "micro", "]", "+=", "loss", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "losses_k", "[", "macro", "]", "+=", "(", "loss", "/", "length", ".", "float", "(", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "\n", "", "def", "update_tensor_generation_losses_sentence", "(", "losses_s", ",", "nums_s", ",", "micro", ",", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.DD.__getattr__": [[184, 192], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.DD.__setattr__": [[193, 199], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.DD.__str__": [[200, 202], ["dict"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.DD.__repr__": [[203, 205], ["str"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.DD.__deepcopy__": [[206, 211], ["utils.DD", "utils.DD.items", "copy.deepcopy"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.make_new_tensor_from_list": [[14, 20], ["torch.tensor", "torch.device", "torch.device"], "function", ["None"], ["    ", "nums", "[", "macro", "]", "+=", "bs", "\n", "\n", "if", "isinstance", "(", "length", ",", "int", ")", ":", "\n", "        ", "update_indiv_generation_losses", "(", "\n", "losses", ",", "nums", ",", "micro", ",", "macro", ",", "bs", ",", "length", ",", "loss", ")", "\n", "", "else", ":", "\n", "        ", "if", "s", "==", "\"knowledge\"", ":", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.make_name": [[24, 55], ["utils.make_name_string", "utils.make_name_string", "utils.make_name_string", "utils.make_name_string", "distutils.dir_util.mkpath", "distutils.dir_util.mkpath", "utils.make_name_string"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.make_name_string", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.make_name_string", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.make_name_string", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.make_name_string", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.make_name_string"], ["            ", "update_tensor_generation_losses_sentence", "(", "\n", "losses", ",", "nums", ",", "micro", ",", "macro", ",", "bs", ",", "length", ",", "loss", ")", "\n", "\n", "\n", "\n", "", "", "", "def", "update_indiv_generation_losses", "(", "losses", ",", "nums", ",", "micro", ",", "\n", "macro", ",", "bs", ",", "length", ",", "loss", ")", ":", "\n", "    ", "nums", "[", "micro", "]", "+=", "bs", "*", "length", "\n", "\n", "batch_loss", "=", "loss", "*", "bs", "\n", "\n", "losses", "[", "micro", "]", "+=", "batch_loss", "\n", "losses", "[", "macro", "]", "+=", "batch_loss", "/", "length", "\n", "\n", "\n", "", "def", "update_tensor_generation_losses", "(", "losses", ",", "nums", ",", "micro", ",", "\n", "macro", ",", "bs", ",", "length", ",", "loss", ")", ":", "\n", "    ", "nums", "[", "micro", "]", "+=", "length", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "losses", "[", "micro", "]", "+=", "loss", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "losses", "[", "macro", "]", "+=", "(", "loss", "/", "length", ".", "float", "(", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "\n", "", "def", "update_tensor_generation_losses_knowledge", "(", "losses_k", ",", "nums_k", ",", "micro", ",", "\n", "macro", ",", "bs", ",", "length", ",", "loss", ")", ":", "\n", "    ", "nums_k", "[", "micro", "]", "+=", "length", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "losses_k", "[", "micro", "]", "+=", "loss", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "losses_k", "[", "macro", "]", "+=", "(", "loss", "/", "length", ".", "float", "(", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "\n", "", "def", "update_tensor_generation_losses_sentence", "(", "losses_s", ",", "nums_s", ",", "micro", ",", "\n", "macro", ",", "bs", ",", "length", ",", "loss", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.make_name_string": [[57, 85], ["dict_.items", "isinstance", "type", "utils.is_bool", "utils.is_bool", "str"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.is_bool", "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.is_bool"], ["losses_s", "[", "micro", "]", "+=", "loss", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "losses_s", "[", "macro", "]", "+=", "(", "loss", "/", "length", ".", "float", "(", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "", ""]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.is_bool": [[87, 93], ["str", "str"], "function", ["None"], []], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.generate_config_files": [[95, 123], ["json.load.update", "utils.replace_params", "distutils.dir_util.mkpath", "open", "json.load", "open", "json.load", "open", "json.dump", "open", "json.load", "open", "json.load"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.replace_params"], []], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.replace_params": [[125, 131], ["changes.items", "isinstance", "utils.replace_params"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.replace_params"], []], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.initialize_progress_bar": [[133, 137], ["sum", "utils.set_progress_bar", "len", "data_loader_list.values"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.set_progress_bar"], []], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.set_progress_bar": [[139, 143], ["tqdm.tqdm", "tqdm.tqdm.update"], "function", ["None"], []], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.merge_list_of_dicts": [[145, 150], ["result.update"], "function", ["None"], []], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.return_iterator_by_type": [[152, 158], ["isinstance", "data_type.items", "enumerate"], "function", ["None"], []], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.temp_seed": [[160, 168], ["numpy.random.get_state", "numpy.random.seed", "numpy.random.set_state"], "function", ["None"], []], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.flatten": [[170, 172], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.zipped_flatten": [[174, 176], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.utils.utils.remove_none": [[178, 180], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.generate.generate_atomic_beam_search.make_batch": [[141, 151], ["numpy.array", "numpy.arange", "numpy.expand_dims", "numpy.stack", "torch.tensor().to", "torch.tensor().to", "numpy.expand_dims", "torch.tensor", "torch.tensor"], "function", ["None"], ["def", "make_batch", "(", "X", ")", ":", "\n", "    ", "X", "=", "np", ".", "array", "(", "X", ")", "\n", "assert", "X", ".", "ndim", "in", "[", "1", ",", "2", "]", "\n", "if", "X", ".", "ndim", "==", "1", ":", "\n", "        ", "X", "=", "np", ".", "expand_dims", "(", "X", ",", "axis", "=", "0", ")", "\n", "", "pos_enc", "=", "np", ".", "arange", "(", "n_vocab", "+", "n_special", ",", "n_vocab", "+", "n_special", "+", "X", ".", "shape", "[", "-", "1", "]", ")", "\n", "pos_enc", "=", "np", ".", "expand_dims", "(", "pos_enc", ",", "axis", "=", "0", ")", "\n", "batch", "=", "np", ".", "stack", "(", "[", "X", ",", "pos_enc", "]", ",", "axis", "=", "-", "1", ")", "\n", "batch", "=", "torch", ".", "tensor", "(", "batch", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.generate.generate_atomic_beam_search.append_batch": [[152, 157], ["torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones", "torch.ones", "X.size", "beam_toks.unsqueeze"], "function", ["None"], ["", "def", "append_batch", "(", "X", ",", "beam_toks", ",", "mask", ")", ":", "\n", "    ", "next_pos", "=", "X", "[", ":", ",", "-", "1", ":", ",", "1", "]", "+", "1", "\n", "next_x", "=", "torch", ".", "cat", "(", "(", "beam_toks", ".", "unsqueeze", "(", "1", ")", ",", "next_pos", ")", ",", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "next_mask", "=", "torch", ".", "cat", "(", "[", "mask", ",", "torch", ".", "ones", "(", "X", ".", "size", "(", "0", ")", ",", "1", ",", "device", "=", "mask", ".", "device", ")", "]", ",", "1", ")", "\n", "return", "torch", ".", "cat", "(", "(", "X", ",", "next_x", ")", ",", "1", ")", ",", "next_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.generate.generate_conceptnet_beam_search.make_batch": [[175, 185], ["numpy.array", "numpy.arange", "numpy.expand_dims", "numpy.stack", "torch.tensor().to", "torch.tensor().to", "numpy.expand_dims", "torch.tensor", "torch.tensor"], "function", ["None"], ["def", "make_batch", "(", "X", ")", ":", "\n", "    ", "X", "=", "np", ".", "array", "(", "X", ")", "\n", "assert", "X", ".", "ndim", "in", "[", "1", ",", "2", "]", "\n", "if", "X", ".", "ndim", "==", "1", ":", "\n", "        ", "X", "=", "np", ".", "expand_dims", "(", "X", ",", "axis", "=", "0", ")", "\n", "", "pos_enc", "=", "np", ".", "arange", "(", "n_vocab", "+", "n_special", ",", "n_vocab", "+", "n_special", "+", "X", ".", "shape", "[", "-", "1", "]", ")", "\n", "pos_enc", "=", "np", ".", "expand_dims", "(", "pos_enc", ",", "axis", "=", "0", ")", "\n", "batch", "=", "np", ".", "stack", "(", "[", "X", ",", "pos_enc", "]", ",", "axis", "=", "-", "1", ")", "\n", "batch", "=", "torch", ".", "tensor", "(", "batch", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.generate.generate_conceptnet_beam_search.append_batch": [[187, 192], ["beam_toks.unsqueeze.unsqueeze", "beam_toks.unsqueeze.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones", "torch.ones", "X.size"], "function", ["None"], ["", "def", "append_batch", "(", "X", ",", "beam_toks", ",", "mask", ")", ":", "\n", "    ", "beam_toks", "=", "beam_toks", ".", "unsqueeze", "(", "1", ")", "\n", "next_x", "=", "beam_toks", ".", "unsqueeze", "(", "1", ")", "\n", "next_mask", "=", "torch", ".", "cat", "(", "[", "mask", ",", "torch", ".", "ones", "(", "X", ".", "size", "(", "0", ")", ",", "1", ",", "device", "=", "mask", ".", "device", ")", "]", ",", "1", ")", "\n", "return", "torch", ".", "cat", "(", "(", "X", ",", "next_x", ")", ",", "1", ")", ",", "next_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.generate.generate_conceptnet_beam_search.beam_generate_sequence": [[194, 290], ["torch.nn.CrossEntropyLoss", "torch.cat.unsqueeze", "torch.log_softmax", "lm_probs[].squeeze", "lm_probs[].max", "indices.clone().unsqueeze", "lm_probs[].squeeze.topk", "beam_losses.append", "beam_toks.unsqueeze.unsqueeze", "beam_toks.unsqueeze.clone", "torch.cat.repeat", "torch.cat.repeat", "beam_toks.unsqueeze.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "lm_model", "torch.log_softmax", "lm_probs[].squeeze", "lm_probs[].squeeze.topk", "ended.index_select.unsqueeze().repeat", "beam_lls.unsqueeze().repeat().view", "temp_counts.index_select.unsqueeze().repeat().view", "ended.index_select.index_select", "counts.unsqueeze().repeat().view.index_select", "beam_losses.append", "generate_conceptnet_beam_search.append_batch", "beams.append", "torch.cat.unsqueeze", "indices.clone", "torch.ones", "torch.ones", "lm_model", "i.index_select", "hyp_beam_toks.view", "torch.cat", "torch.cat", "torch.cat.transpose().transpose().repeat().transpose().transpose().contiguous().view", "torch.cat.size", "torch.cat.unsqueeze", "ended.index_select.unsqueeze", "beam_lls.unsqueeze().repeat", "hyp_beam_lls.view", "hypothesis_mask.view", "temp_counts.index_select.unsqueeze().repeat", "torch.cat.t().repeat().t().contiguous().view", "torch.cat.size", "torch.cat.size", "beam_toks.unsqueeze.unsqueeze", "torch.cat.transpose().transpose().repeat().transpose().transpose().contiguous", "beam_lls.unsqueeze", "temp_counts.index_select.unsqueeze", "torch.cat.t().repeat().t().contiguous", "torch.cat.transpose().transpose().repeat().transpose().transpose", "torch.cat.t().repeat().t", "text_encoder.decoder[].replace().replace().replace", "torch.cat.transpose().transpose().repeat().transpose", "torch.cat.t().repeat", "text_encoder.decoder[].replace().replace", "torch.cat.transpose().transpose().repeat", "torch.cat.t", "text_encoder.decoder[].replace", "torch.cat.transpose().transpose", "torch.cat.transpose", "tok.item"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.generate.generate_atomic_greedy.append_batch"], ["", "def", "beam_generate_sequence", "(", "XMB", ",", "MMB", ",", "lm_model", ",", "size_end", ",", "k", ")", ":", "\n", "\n", "             ", "tokens", "=", "[", "]", "\n", "beam_losses", "=", "[", "]", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "reduction", "=", "\"none\"", ")", "\n", "XMB", "=", "XMB", ".", "unsqueeze", "(", "-", "1", ")", "\n", "# Beam Search", "\n", "beam_lls", ",", "beam_toks", ",", "beam_seqs", "=", "None", ",", "None", ",", "None", "\n", "lm_probs", "=", "F", ".", "log_softmax", "(", "lm_model", "(", "XMB", ".", "unsqueeze", "(", "1", ")", ",", "attention_mask", "=", "MMB", ")", ",", "dim", "=", "-", "1", ")", "\n", "dist", "=", "lm_probs", "[", ":", ",", "-", "1", ",", ":", "]", ".", "squeeze", "(", ")", "\n", "values", ",", "indices", "=", "lm_probs", "[", ":", ",", "-", "1", ",", ":", "]", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "seqs", "=", "indices", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "\n", "beam_lls", ",", "beam_toks", "=", "dist", ".", "topk", "(", "k", ")", "\n", "beam_losses", ".", "append", "(", "beam_lls", ")", "\n", "ended", "=", "(", "beam_toks", "==", "end_token", ")", ".", "float", "(", ")", "\n", "counts", "=", "(", "2", "-", "ended", ")", "\n", "beam_toks", "=", "beam_toks", ".", "unsqueeze", "(", "1", ")", "\n", "beam_seqs", "=", "beam_toks", ".", "clone", "(", ")", "\n", "XMB", "=", "XMB", ".", "repeat", "(", "k", ",", "1", ",", "1", ")", "\n", "MMB", "=", "MMB", ".", "repeat", "(", "k", ",", "1", ")", "\n", "next_pos", "=", "XMB", "[", ":", ",", "1", ",", "-", "1", ":", "]", "+", "1", "\n", "\n", "next_x", "=", "beam_toks", ".", "unsqueeze", "(", "1", ")", "\n", "XMB", "=", "torch", ".", "cat", "(", "(", "XMB", ",", "next_x", ")", ",", "1", ")", "\n", "MMB", "=", "torch", ".", "cat", "(", "[", "MMB", ",", "torch", ".", "ones", "(", "XMB", ".", "size", "(", "0", ")", ",", "1", ",", "device", "=", "MMB", ".", "device", ")", "]", ",", "1", ")", "\n", "# Compute distribution for current beam", "\n", "for", "_", "in", "range", "(", "args", ".", "gen_len", ")", ":", "\n", "                   ", "lm_probs", "=", "F", ".", "log_softmax", "(", "lm_model", "(", "XMB", ".", "unsqueeze", "(", "1", ")", ",", "attention_mask", "=", "MMB", ")", ",", "dim", "=", "-", "1", ")", "\n", "dist", "=", "lm_probs", "[", ":", ",", "-", "1", ",", ":", "]", ".", "squeeze", "(", ")", "\n", "# get hypothesis tokens for distribution", "\n", "hyp_beam_lls", ",", "hyp_beam_toks", "=", "dist", ".", "topk", "(", "k", ")", "\n", "\n", "# Compute masks and expand beam", "\n", "expanded_ended", "=", "ended", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "k", ")", "\n", "hypothesis_mask", "=", "expanded_ended", "*", "kill_mask", "+", "(", "1", "-", "expanded_ended", ")", "\n", "current_beam_lls", "=", "beam_lls", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "k", ")", ".", "view", "(", "k", "**", "2", ")", "\n", "\n", "# Compute losses of hypotheses, masking those that have ended", "\n", "hyp_beam_lls", "=", "(", "hyp_beam_lls", ".", "view", "(", "k", "**", "2", ")", "*", "\n", "hypothesis_mask", ".", "view", "(", "-", "1", ")", ")", "+", "current_beam_lls", "\n", "# Get normalizer for sequences", "\n", "temp_counts", "=", "counts", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "k", ")", ".", "view", "(", "k", "**", "2", ")", "\n", "\n", "# Select best beams with lowest aggregate loss", "\n", "beam_lls", ",", "top_beam_idxs", "=", "(", "hyp_beam_lls", "/", "temp_counts", ")", ".", "topk", "(", "k", ")", "\n", "# Update placements in beam based on selecetion", "\n", "beam_losses", "=", "[", "i", ".", "index_select", "(", "0", ",", "top_beam_idxs", "//", "k", ")", "\n", "for", "i", "in", "beam_losses", "]", "\n", "ended", "=", "ended", ".", "index_select", "(", "0", ",", "top_beam_idxs", "//", "k", ")", "\n", "counts", "=", "temp_counts", ".", "index_select", "(", "0", ",", "top_beam_idxs", ")", "\n", "\n", "# Save beam losses", "\n", "beam_losses", ".", "append", "(", "beam_lls", "*", "counts", ")", "\n", "# Update beam tokens", "\n", "ended_mask", "=", "(", "1", "-", "ended", ")", ".", "long", "(", ")", "\n", "end_replacement", "=", "(", "end_token", "*", "ended", ")", ".", "long", "(", ")", "\n", "next_toks", "=", "hyp_beam_toks", ".", "view", "(", "-", "1", ")", "[", "top_beam_idxs", "]", "\n", "beam_toks", "=", "next_toks", "*", "ended_mask", "+", "end_replacement", "\n", "\n", "# Update ended and counts", "\n", "ended", "=", "ended", "+", "(", "beam_toks", "==", "end_token", ")", ".", "float", "(", ")", "*", "(", "1", "-", "ended", ")", "\n", "counts", "=", "counts", "+", "(", "1", "-", "ended", ")", "\n", "\n", "# Update beam sequences", "\n", "if", "(", "beam_toks", "!=", "end_token", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ":", "\n", "                       ", "beam_seqs", "=", "beam_seqs", ".", "t", "(", ")", ".", "repeat", "(", "k", ",", "1", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", ".", "view", "(", "k", "**", "2", ",", "-", "1", ")", "[", "top_beam_idxs", "]", "\n", "beam_seqs", "=", "torch", ".", "cat", "(", "(", "beam_seqs", ",", "beam_toks", ".", "unsqueeze", "(", "1", ")", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# I have no idea what's going on but Ari's on point with it", "\n", "", "XMB", "=", "XMB", ".", "transpose", "(", "0", ",", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "repeat", "(", "k", ",", "1", ",", "1", ")", ".", "transpose", "(", "2", ",", "1", ")", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", ".", "view", "(", "k", "**", "2", ",", "XMB", ".", "size", "(", "1", ")", ",", "XMB", ".", "size", "(", "2", ")", ")", "[", "top_beam_idxs", "]", "\n", "\n", "XMB", ",", "MMB", "=", "append_batch", "(", "XMB", ",", "beam_toks", ",", "MMB", ")", "\n", "\n", "if", "(", "beam_toks", "==", "end_token", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "==", "k", "or", "_", "==", "size_end", "-", "1", ":", "\n", "                          ", "break", "\n", "\n", "", "", "beams", "=", "[", "]", "\n", "value", "=", "50261", "\n", "beam_seqs", "=", "beam_seqs", "[", "beam_seqs", "!=", "value", "]", "\n", "beam_seqs", "=", "beam_seqs", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "value", "=", "50260", "\n", "beam_seqs", "=", "beam_seqs", "[", "beam_seqs", "!=", "value", "]", "\n", "beam_seqs", "=", "beam_seqs", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "for", "beam", "in", "beam_seqs", ":", "\n", "                          ", "beams", ".", "append", "(", "\" \"", ".", "join", "(", "\"\"", ".", "join", "(", "[", "text_encoder", ".", "decoder", "[", "tok", ".", "item", "(", ")", "]", ".", "replace", "(", "\n", "'</w>'", ",", "' '", ")", ".", "replace", "(", "'\\n'", ",", "''", ")", ".", "replace", "(", "'\u0120'", ",", "' '", ")", "\n", "for", "tok", "in", "beam", "if", "tok", "!=", "end_token", "]", ")", ".", "split", "(", ")", ")", ")", "\n", "", "sampling_result", "=", "{", "\n", "\"sequence\"", ":", "beams", "[", "0", "]", ",", "\n", "\"beams\"", ":", "beams", ",", "\n", "\"beam_lengths\"", ":", "[", "counts", "]", ",", "\n", "\"length\"", ":", "counts", "\n", "}", "\n", "return", "sampling_result", ",", "beam_seqs", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.generate.generate_conceptnet_beam_search.greedy_append_batch": [[291, 296], ["next_idx.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones", "torch.ones", "X.size"], "function", ["None"], ["", "def", "greedy_append_batch", "(", "X", ",", "next_idx", ",", "mask", ")", ":", "\n", "\n", "        ", "next_x", "=", "next_idx", ".", "unsqueeze", "(", "1", ")", "#torch.cat((next_idx, next_pos), -1).unsqueeze(1)", "\n", "next_mask", "=", "torch", ".", "cat", "(", "[", "mask", ",", "torch", ".", "ones", "(", "X", ".", "size", "(", "0", ")", ",", "1", ",", "device", "=", "mask", ".", "device", ")", "]", ",", "1", ")", "\n", "return", "torch", ".", "cat", "(", "(", "X", ",", "next_x", ")", ",", "1", ")", ",", "next_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.generate.generate_conceptnet_beam_search.greedy_generate_sequence": [[297, 347], ["torch.cat.unsqueeze", "torch.log_softmax", "lm_probs[].max", "indices.clone().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "lm_model", "torch.log_softmax", "lm_probs[].max", "next_idx.unsqueeze.unsqueeze", "torch.cat", "torch.cat", "generate_conceptnet_beam_search.greedy_append_batch", "beams.append", "loss.item", "torch.cat.unsqueeze", "indices.clone", "indices.view().unsqueeze", "torch.ones", "torch.ones", "lm_model", "loss.item", "torch.cat.size", "torch.cat.unsqueeze", "next_idx.unsqueeze.item", "indices.view", "data_loader.vocab_decoder[].replace().replace", "data_loader.vocab_decoder[].replace", "tok.item"], "function", ["home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.generate.generate_conceptnet_beam_search.greedy_append_batch"], ["", "def", "greedy_generate_sequence", "(", "XMB", ",", "MMB", ",", "lm_model", ",", "end_len", ")", ":", "\n", "        ", "XMB", "=", "XMB", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "lm_probs", "=", "F", ".", "log_softmax", "(", "lm_model", "(", "\n", "XMB", ".", "unsqueeze", "(", "1", ")", ",", "attention_mask", "=", "MMB", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "values", ",", "indices", "=", "lm_probs", "[", ":", ",", "-", "1", ",", ":", "]", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "seqs", "=", "indices", ".", "clone", "(", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "loss", "=", "values", "\n", "counts", "=", "1", "\n", "XMB", "=", "torch", ".", "cat", "(", "(", "XMB", ",", "indices", ".", "view", "(", "-", "1", ",", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", ",", "1", ")", "\n", "MMB", "=", "torch", ".", "cat", "(", "[", "MMB", ",", "torch", ".", "ones", "(", "XMB", ".", "size", "(", "0", ")", ",", "1", ",", "device", "=", "MMB", ".", "device", ")", "]", ",", "1", ")", "\n", "# Sample from top k", "\n", "for", "_", "in", "range", "(", "args", ".", "gen_len", ")", ":", "\n", "            ", "lm_probs", "=", "F", ".", "log_softmax", "(", "lm_model", "(", "\n", "XMB", ".", "unsqueeze", "(", "1", ")", ",", "attention_mask", "=", "MMB", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Sample from top k", "\n", "values", ",", "next_idx", "=", "lm_probs", "[", ":", ",", "-", "1", ",", ":", "]", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "loss", "+=", "values", "\n", "counts", "+=", "1", "\n", "\n", "next_idx", "=", "next_idx", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "seqs", "=", "torch", ".", "cat", "(", "[", "seqs", ",", "next_idx", "]", ",", "1", ")", "\n", "\n", "if", "(", "next_idx", ".", "item", "(", ")", "==", "end_token", ")", "or", "(", "_", "==", "end_len", "-", "1", ")", ":", "\n", "                ", "break", "\n", "\n", "", "XMB", ",", "MMB", "=", "greedy_append_batch", "(", "XMB", ",", "next_idx", ",", "MMB", ")", "\n", "\n", "", "beams", "=", "[", "]", "\n", "\n", "for", "beam", "in", "seqs", ":", "\n", "\n", "            ", "beams", ".", "append", "(", "\" \"", ".", "join", "(", "\"\"", ".", "join", "(", "\n", "[", "data_loader", ".", "vocab_decoder", "[", "tok", ".", "item", "(", ")", "]", ".", "replace", "(", "\n", "'</w>'", ",", "' '", ")", ".", "replace", "(", "'\\n'", ",", "''", ")", "\n", "for", "tok", "in", "beam", "if", "tok", "!=", "end_token", "]", ")", ".", "split", "(", ")", ")", ")", "\n", "\n", "", "sampling_result", "=", "{", "\n", "\"sequence\"", ":", "\" \"", ".", "join", "(", "beams", ")", ",", "\n", "\"beams\"", ":", "beams", ",", "\n", "\"beam_losses\"", ":", "[", "loss", ".", "item", "(", ")", "]", ",", "\n", "\"loss\"", ":", "loss", ".", "item", "(", ")", ",", "\n", "\"beam_lengths\"", ":", "[", "counts", "]", ",", "\n", "\"length\"", ":", "counts", "\n", "}", "\n", "return", "sampling_result", ",", "seqs", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.generate.generate_atomic_topk.make_batch": [[117, 127], ["numpy.array", "numpy.arange", "numpy.expand_dims", "numpy.stack", "torch.tensor().to", "torch.tensor().to", "numpy.expand_dims", "torch.tensor", "torch.tensor"], "function", ["None"], ["def", "make_batch", "(", "X", ")", ":", "\n", "    ", "X", "=", "np", ".", "array", "(", "X", ")", "\n", "assert", "X", ".", "ndim", "in", "[", "1", ",", "2", "]", "\n", "if", "X", ".", "ndim", "==", "1", ":", "\n", "        ", "X", "=", "np", ".", "expand_dims", "(", "X", ",", "axis", "=", "0", ")", "\n", "", "pos_enc", "=", "np", ".", "arange", "(", "n_vocab", "+", "n_special", ",", "n_vocab", "+", "n_special", "+", "X", ".", "shape", "[", "-", "1", "]", ")", "\n", "pos_enc", "=", "np", ".", "expand_dims", "(", "pos_enc", ",", "axis", "=", "0", ")", "\n", "batch", "=", "np", ".", "stack", "(", "[", "X", ",", "pos_enc", "]", ",", "axis", "=", "-", "1", ")", "\n", "batch", "=", "torch", ".", "tensor", "(", "batch", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.generate.generate_atomic_topk.append_batch": [[129, 134], ["torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones", "torch.ones", "X.size"], "function", ["None"], ["", "def", "append_batch", "(", "X", ",", "next_idx", ",", "mask", ")", ":", "\n", "    ", "next_pos", "=", "X", "[", ":", ",", "-", "1", ":", ",", "1", "]", "+", "1", "\n", "next_x", "=", "torch", ".", "cat", "(", "(", "next_idx", ",", "next_pos", ")", ",", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "next_mask", "=", "torch", ".", "cat", "(", "[", "mask", ",", "torch", ".", "ones", "(", "X", ".", "size", "(", "0", ")", ",", "1", ",", "device", "=", "mask", ".", "device", ")", "]", ",", "1", ")", "\n", "return", "torch", ".", "cat", "(", "(", "X", ",", "next_x", ")", ",", "1", ")", ",", "next_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.generate.generate_atomic_greedy.make_batch": [[127, 137], ["numpy.array", "numpy.arange", "numpy.expand_dims", "numpy.stack", "torch.tensor().to", "torch.tensor().to", "numpy.expand_dims", "torch.tensor", "torch.tensor"], "function", ["None"], ["def", "make_batch", "(", "X", ")", ":", "\n", "    ", "X", "=", "np", ".", "array", "(", "X", ")", "\n", "assert", "X", ".", "ndim", "in", "[", "1", ",", "2", "]", "\n", "if", "X", ".", "ndim", "==", "1", ":", "\n", "        ", "X", "=", "np", ".", "expand_dims", "(", "X", ",", "axis", "=", "0", ")", "\n", "", "pos_enc", "=", "np", ".", "arange", "(", "n_vocab", "+", "n_special", ",", "n_vocab", "+", "n_special", "+", "X", ".", "shape", "[", "-", "1", "]", ")", "\n", "pos_enc", "=", "np", ".", "expand_dims", "(", "pos_enc", ",", "axis", "=", "0", ")", "\n", "batch", "=", "np", ".", "stack", "(", "[", "X", ",", "pos_enc", "]", ",", "axis", "=", "-", "1", ")", "\n", "batch", "=", "torch", ".", "tensor", "(", "batch", ",", "dtype", "=", "torch", ".", "long", ")", ".", "to", "(", "device", ")", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.Heidelberg-NLP_COINS.generate.generate_atomic_greedy.append_batch": [[139, 144], ["torch.cat().unsqueeze", "torch.cat().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones", "torch.ones", "X.size"], "function", ["None"], ["", "def", "append_batch", "(", "X", ",", "next_idx", ",", "mask", ")", ":", "\n", "    ", "next_pos", "=", "X", "[", ":", ",", "-", "1", ":", ",", "1", "]", "+", "1", "\n", "next_x", "=", "torch", ".", "cat", "(", "(", "next_idx", ",", "next_pos", ")", ",", "-", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "next_mask", "=", "torch", ".", "cat", "(", "[", "mask", ",", "torch", ".", "ones", "(", "X", ".", "size", "(", "0", ")", ",", "1", ",", "device", "=", "mask", ".", "device", ")", "]", ",", "1", ")", "\n", "return", "torch", ".", "cat", "(", "(", "X", ",", "next_x", ")", ",", "1", ")", ",", "next_mask", "\n", "\n"]]}