{"home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.extra.relu": [[5, 7], ["theano.switch"], "function", ["None"], ["def", "relu", "(", "x", ")", ":", "\n", "    ", "return", "T", ".", "switch", "(", "x", ">", "0", ",", "x", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.extra.sharedX_value": [[9, 21], ["theano.shared", "theano.shared", "theano._asarray", "theano._asarray"], "function", ["None"], ["", "def", "sharedX_value", "(", "value", ",", "name", "=", "None", ",", "borrow", "=", "None", ",", "dtype", "=", "None", ")", ":", "\n", "    ", "\"\"\"Share a single value after transforming it to floatX type.\n\n    value: a value\n    name: variable name (str)\n    borrow: boolean\n    dtype: the type of the value when shared. default: theano.config.floatX\n    \"\"\"", "\n", "if", "dtype", "is", "None", ":", "\n", "        ", "dtype", "=", "theano", ".", "config", ".", "floatX", "\n", "", "return", "theano", ".", "shared", "(", "\n", "theano", ".", "_asarray", "(", "value", ",", "dtype", "=", "dtype", ")", ",", "name", "=", "name", ",", "borrow", "=", "borrow", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.extra.get_non_linearity_fn": [[34, 43], ["None"], "function", ["None"], ["", "def", "get_non_linearity_fn", "(", "nonlinearity", ")", ":", "\n", "        ", "if", "nonlinearity", "==", "NonLinearity", ".", "SIGMOID", ":", "\n", "            ", "return", "T", ".", "nnet", ".", "sigmoid", "\n", "", "elif", "nonlinearity", "==", "NonLinearity", ".", "RELU", ":", "\n", "            ", "return", "relu", "\n", "", "elif", "nonlinearity", "==", "NonLinearity", ".", "TANH", ":", "\n", "            ", "return", "T", ".", "tanh", "\n", "", "elif", "nonlinearity", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rate.AnnealedLearningRate.__init__": [[13, 18], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "anneal_start", ",", "freq", "=", "'epoch'", ")", ":", "\n", "        ", "self", ".", "_initialized", "=", "False", "\n", "self", ".", "_count", "=", "0.", "\n", "self", ".", "_anneal_start", "=", "anneal_start", "\n", "self", ".", "freq", "=", "freq", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rate.AnnealedLearningRate.__call__": [[19, 29], ["learning_rate.set_value", "learning_rate.get_value", "learning_rate.AnnealedLearningRate.get_current_learning_rate"], "methods", ["home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rate.AnnealedLearningRate.get_current_learning_rate"], ["", "def", "__call__", "(", "self", ",", "learning_rate", ")", ":", "\n", "        ", "\"\"\"Updates the learning rate according to the annealing schedule.\n\n        \"\"\"", "\n", "if", "not", "self", ".", "_initialized", ":", "\n", "            ", "self", ".", "_base", "=", "learning_rate", ".", "get_value", "(", ")", "\n", "self", ".", "_initialized", "=", "True", "\n", "", "self", ".", "_count", "+=", "1", "\n", "learning_rate", ".", "set_value", "(", "\n", "np", ".", "cast", "[", "theano", ".", "config", ".", "floatX", "]", "(", "self", ".", "get_current_learning_rate", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rate.AnnealedLearningRate.get_current_learning_rate": [[30, 36], ["min"], "methods", ["None"], ["", "def", "get_current_learning_rate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Calculate the current learning rate according to the annealing\n        schedule.\n\n        \"\"\"", "\n", "return", "self", ".", "_base", "*", "min", "(", "1", ",", "self", ".", "_anneal_start", "/", "self", ".", "_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rate.ExponentialDecayLearningRate.__init__": [[50, 56], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "decay_factor", ",", "min_lr", ")", ":", "\n", "        ", "self", ".", "_count", "=", "0", "\n", "self", ".", "_min_reached", "=", "False", "\n", "self", ".", "min_lr", "=", "min_lr", "\n", "self", ".", "decay_factor", "=", "decay_factor", "\n", "self", ".", "freq", "=", "'batch'", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rate.ExponentialDecayLearningRate.__call__": [[57, 75], ["learning_rate.set_value", "learning_rate.get_vale"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "learning_rate", ")", ":", "\n", "        ", "\"\"\"Update the learning rate according to the exponential decay\n        schedule.\n\n        \"\"\"", "\n", "if", "self", ".", "_count", "==", "0.", ":", "\n", "            ", "self", ".", "_base_lr", "=", "learning_rate", ".", "get_vale", "(", ")", "\n", "", "self", ".", "_count", "+=", "1", "\n", "\n", "if", "not", "self", ".", "_min_reached", ":", "\n", "            ", "new_lr", "=", "self", ".", "_base_lr", "*", "(", "self", ".", "decay_factor", "**", "(", "-", "self", ".", "_count", ")", ")", "\n", "if", "new_lr", "<=", "self", ".", "min_lr", ":", "\n", "                ", "self", ".", "_min_reached", "=", "True", "\n", "new_lr", "=", "self", ".", "_min_reached", "\n", "", "", "else", ":", "\n", "            ", "new_lr", "=", "self", ".", "min_lr", "\n", "\n", "", "learning_rate", ".", "set_value", "(", "np", ".", "cast", "[", "theano", ".", "config", ".", "floatX", "]", "(", "new_lr", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.Layer.__init__": [[13, 33], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "input", ",", "\n", "n_in", ",", "\n", "n_out", ",", "\n", "activation", "=", "T", ".", "nnet", ".", "sigmoid", ",", "\n", "sparse_initialize", "=", "False", ",", "\n", "num_pieces", "=", "1", ",", "\n", "non_zero_units", "=", "25", ",", "\n", "rng", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "num_pieces", "=", "num_pieces", "\n", "self", ".", "input", "=", "input", "\n", "self", ".", "n_in", "=", "n_in", "\n", "self", ".", "n_out", "=", "n_out", "\n", "self", ".", "rng", "=", "rng", "\n", "self", ".", "sparse_initialize", "=", "sparse_initialize", "\n", "self", ".", "non_zero_units", "=", "non_zero_units", "\n", "self", ".", "W", "=", "None", "\n", "self", ".", "b", "=", "None", "\n", "self", ".", "activation", "=", "activation", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.Layer.reset_layer": [[34, 61], ["theano.shared", "numpy.zeros", "theano.shared", "layer.Layer.sparse_initialize_weights", "numpy.asarray", "int", "numpy.sqrt", "layer.Layer.rng.uniform", "numpy.sqrt"], "methods", ["None"], ["", "def", "reset_layer", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        initailize the layer's parameters to random.\n        \"\"\"", "\n", "if", "self", ".", "W", "is", "None", ":", "\n", "            ", "if", "self", ".", "sparse_initialize", ":", "\n", "                ", "W_values", "=", "self", ".", "sparse_initialize_weights", "(", ")", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "activation", "==", "theano", ".", "tensor", ".", "tanh", ":", "\n", "                    ", "born", "=", "np", ".", "sqrt", "(", "6.", "/", "(", "self", ".", "n_in", "+", "self", ".", "n_out", ")", ")", "\n", "", "else", ":", "\n", "                    ", "born", "=", "4", "*", "np", ".", "sqrt", "(", "6.", "/", "(", "self", ".", "n_in", "+", "self", ".", "n_out", ")", ")", "\n", "", "W_values", "=", "np", ".", "asarray", "(", "self", ".", "rng", ".", "uniform", "(", "\n", "low", "=", "-", "born", ",", "\n", "high", "=", "born", ",", "\n", "size", "=", "(", "self", ".", "n_in", ",", "self", ".", "n_out", ")", ")", ",", "\n", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", "\n", "\n", "", "self", ".", "W", "=", "theano", ".", "shared", "(", "value", "=", "W_values", ",", "name", "=", "'W'", ",", "borrow", "=", "True", ")", "\n", "\n", "", "if", "self", ".", "b", "is", "None", ":", "\n", "            ", "b_values", "=", "np", ".", "zeros", "(", "int", "(", "self", ".", "n_out", "/", "self", ".", "num_pieces", ")", ",", "\n", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", "\n", "self", ".", "b", "=", "theano", ".", "shared", "(", "value", "=", "b_values", ",", "name", "=", "'b'", ",", "borrow", "=", "True", ")", "\n", "\n", "# The layer parameters", "\n", "", "self", ".", "params", "=", "[", "self", ".", "W", ",", "self", ".", "b", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.Layer.sparse_initialization_weights": [[62, 82], ["xrange", "numpy.asarray", "numpy.zeros", "layer.Layer.rng.normal", "xrange", "numpy.asarray.append", "layer.Layer.rng.permutation"], "methods", ["None"], ["", "def", "sparse_initialization_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Implement the sparse initialization technique as described in\n        J. Marten, 'Deep learning via Hessian-free optimization', ICML, 2010.\n        http://icml2010.haifa.il.ibm.com/papers/458.pdf\n        \"\"\"", "\n", "W", "=", "[", "]", "\n", "mu", ",", "sigma", "=", "0", ",", "1", "/", "self", ".", "non_zero_units", "\n", "\n", "for", "i", "in", "xrange", "(", "self", ".", "n_in", ")", ":", "\n", "            ", "row", "=", "np", ".", "zeros", "(", "self", ".", "n_out", ")", "\n", "non_zeros", "=", "self", ".", "rng", ".", "normal", "(", "mu", ",", "sigma", ",", "self", ".", "non_zero_units", ")", "\n", "# non_zeros /= non_zeros.sum()", "\n", "non_zero_idxs", "=", "self", ".", "rng", ".", "permutation", "(", "\n", "self", ".", "n_out", ")", "[", "0", ":", "self", ".", "non_zero_units", "]", "\n", "for", "j", "in", "xrange", "(", "self", ".", "non_zero_units", ")", ":", "\n", "                ", "row", "[", "non_zero_idxs", "[", "j", "]", "]", "=", "non_zeros", "[", "j", "]", "\n", "", "W", ".", "append", "(", "row", ")", "\n", "", "W", "=", "np", ".", "asarray", "(", "W", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", "\n", "return", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.HiddenLayer.__init__": [[85, 124], ["layer.Layer.__init__", "layer.HiddenLayer.reset_layer", "layer.HiddenLayer.setup_outputs", "numpy.random.RandomState"], "methods", ["home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.Adamax.__init__", "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.Layer.reset_layer", "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.AEHiddenLayer.setup_outputs"], ["    ", "def", "__init__", "(", "self", ",", "input", ",", "n_in", ",", "n_out", ",", "W", "=", "None", ",", "b", "=", "None", ",", "\n", "activation", "=", "T", ".", "tanh", ",", "rng", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Typical hidden layer of an MLP: units are fully connected and have\n        tangente hyperbolic activation function. Weight matrix (W) is of shape\n        (n_in, n_out) and the bias vector (b) is of shape (nout,).\n\n        Hidden unit activation is given by: tanh(dot(input, w)+ b)\n\n        :type rng: numpy.random.RandomState\n        :param rng: a random number generator used to initiaze the weights.\n\n        :type input: theano.tensor.dmatrix\n        :param input: a symbolic tensor of shape (n_examples, n_in)\n\n        :type n_in: int\n        :param n_in: dimension of the input\n\n        :type n_out: int\n        :param n_out: number of hidden units\n\n        :type activation: theano.Op or function\n        :param activation:  Non linearity to be applied in the hidden layer.\n        \"\"\"", "\n", "if", "rng", "is", "None", ":", "\n", "            ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", ")", "\n", "\n", "", "super", "(", "HiddenLayer", ",", "self", ")", ".", "__init__", "(", "\n", "input", ",", "n_in", ",", "n_out", ",", "activation", "=", "activation", ",", "rng", "=", "rng", ")", "\n", "self", ".", "reset_layer", "(", ")", "\n", "\n", "if", "W", "is", "not", "None", ":", "\n", "            ", "self", ".", "W", "=", "W", "\n", "\n", "", "if", "b", "is", "not", "None", ":", "\n", "            ", "self", ".", "b", "=", "b", "\n", "\n", "", "self", ".", "params", "=", "[", "self", ".", "W", ",", "self", ".", "b", "]", "\n", "self", ".", "setup_outputs", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.HiddenLayer.setup_outputs": [[125, 130], ["theano.tensor.dot", "layer.HiddenLayer.activation"], "methods", ["None"], ["", "def", "setup_outputs", "(", "self", ",", "input", ")", ":", "\n", "        ", "lin_output", "=", "T", ".", "dot", "(", "input", ",", "self", ".", "W", ")", "+", "self", ".", "b", "\n", "self", ".", "output", "=", "(", "\n", "lin_output", "if", "self", ".", "activation", "is", "None", "\n", "else", "self", ".", "activation", "(", "lin_output", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.HiddenLayer.get_outputs": [[131, 134], ["layer.HiddenLayer.setup_outputs"], "methods", ["home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.AEHiddenLayer.setup_outputs"], ["", "def", "get_outputs", "(", "self", ",", "input", ")", ":", "\n", "        ", "self", ".", "setup_outputs", "(", "input", ")", "\n", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.AEHiddenLayer.__init__": [[137, 231], ["layer.Layer.__init__", "layer.AEHiddenLayer.reset_layer", "layer.AEHiddenLayer.setup_outputs", "numpy.random.RandomState", "theano.shared", "theano.shared", "numpy.zeros", "numpy.zeros", "numpy.asarray", "numpy.asarray", "int", "layer.AEHiddenLayer.rng.normal", "numpy.sqrt", "layer.AEHiddenLayer.rng.uniform", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.Adamax.__init__", "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.Layer.reset_layer", "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.AEHiddenLayer.setup_outputs"], ["    ", "def", "__init__", "(", "self", ",", "\n", "input", ",", "\n", "n_in", ",", "\n", "n_out", ",", "\n", "n_in_dec", "=", "None", ",", "\n", "n_out_dec", "=", "None", ",", "\n", "W", "=", "None", ",", "\n", "b", "=", "None", ",", "\n", "num_pieces", "=", "1", ",", "\n", "bhid", "=", "None", ",", "\n", "activation", "=", "T", ".", "nnet", ".", "sigmoid", ",", "\n", "sparse_initialize", "=", "False", ",", "\n", "tied_weights", "=", "True", ",", "\n", "rng", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Typical hidden layer for an auto-encoder: The units are fully connected\n        and have sigmoidal activation function. Weight matrix (W) is of shape\n        (n_in, n_out) and the bias vector (b) is of shape(n_out,).\n\n        Hidden units activation is given by: sigmoid(dot(input, w)+ b)\n\n        :type rng: numpy.random.RandomState\n        :param rng: a random number generator used to initiaze the weights.\n\n        :type input: theano.tensor.dmatrix\n        :param input: a symbolic tensor of shape (n_examples, n_in)\n\n        :type n_in: int\n        :param n_in: dimension of the input\n\n        :type n_out: int\n        :param n_out: number of hidden units\n\n        :type activation: theano.Op or function\n        :param activation:  Non linearity to be applied in the hidden layer.\n        \"\"\"", "\n", "if", "rng", "is", "None", ":", "\n", "            ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", ")", "\n", "\n", "", "super", "(", "AEHiddenLayer", ",", "self", ")", ".", "__init__", "(", "\n", "input", "=", "input", ",", "\n", "n_in", "=", "n_in", ",", "\n", "n_out", "=", "n_out", ",", "\n", "num_pieces", "=", "num_pieces", ",", "\n", "activation", "=", "activation", ",", "\n", "sparse_initialize", "=", "sparse_initialize", ",", "\n", "rng", "=", "rng", ")", "\n", "\n", "self", ".", "reset_layer", "(", ")", "\n", "\n", "if", "W", "is", "not", "None", ":", "\n", "            ", "self", ".", "W", "=", "W", "\n", "\n", "", "if", "b", "is", "not", "None", ":", "\n", "            ", "self", ".", "b", "=", "b", "\n", "\n", "", "if", "bhid", "is", "not", "None", ":", "\n", "            ", "self", ".", "b_prime", "=", "bhid", "\n", "", "else", ":", "\n", "            ", "if", "n_in_dec", "is", "not", "None", ":", "\n", "                ", "b_values", "=", "np", ".", "zeros", "(", "(", "n_out_dec", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", "\n", "", "else", ":", "\n", "                ", "b_values", "=", "np", ".", "zeros", "(", "\n", "int", "(", "self", ".", "n_in", "/", "num_pieces", ")", ",", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", "\n", "\n", "", "self", ".", "b_prime", "=", "theano", ".", "shared", "(", "value", "=", "b_values", ",", "name", "=", "\"b_prime\"", ")", "\n", "\n", "", "if", "tied_weights", ":", "\n", "            ", "self", ".", "W_prime", "=", "self", ".", "W", ".", "T", "\n", "", "else", ":", "\n", "            ", "if", "n_in_dec", "is", "not", "None", "and", "n_out_dec", "is", "not", "None", ":", "\n", "                ", "W_values", "=", "np", ".", "asarray", "(", "\n", "self", ".", "rng", ".", "normal", "(", "loc", "=", "0.", ",", "\n", "scale", "=", "0.005", ",", "\n", "size", "=", "(", "n_out_dec", ",", "n_in_dec", ")", ")", ",", "\n", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "activation", "==", "theano", ".", "tensor", ".", "tanh", ":", "\n", "                    ", "born", "=", "np", ".", "sqrt", "(", "6.", "/", "(", "self", ".", "n_in", "+", "self", ".", "n_out", ")", ")", "\n", "", "else", ":", "\n", "                    ", "born", "=", "4", "*", "np", ".", "sqrt", "(", "6.", "/", "(", "self", ".", "n_in", "+", "self", ".", "n_out", ")", ")", "\n", "", "W_values", "=", "np", ".", "asarray", "(", "\n", "self", ".", "rng", ".", "uniform", "(", "\n", "low", "=", "-", "born", ",", "\n", "high", "=", "born", ",", "\n", "size", "=", "(", "self", ".", "n_out", ",", "self", ".", "n_in", ")", ")", ",", "\n", "dtype", "=", "theano", ".", "config", ".", "floatX", ")", "\n", "\n", "", "self", ".", "W_prime", "=", "theano", ".", "shared", "(", "value", "=", "W_values", ",", "name", "=", "'W_prime'", ",", "\n", "borrow", "=", "True", ")", "\n", "self", ".", "params", "+=", "[", "self", ".", "W_prime", "]", "\n", "\n", "", "self", ".", "params", "+=", "[", "self", ".", "b_prime", "]", "\n", "self", ".", "setup_outputs", "(", "input", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.AEHiddenLayer.setup_outputs": [[232, 237], ["theano.tensor.dot", "layer.AEHiddenLayer.activation"], "methods", ["None"], ["", "def", "setup_outputs", "(", "self", ",", "input", ")", ":", "\n", "        ", "lin_output", "=", "T", ".", "dot", "(", "input", ",", "self", ".", "W", ")", "+", "self", ".", "b", "\n", "self", ".", "output", "=", "(", "\n", "lin_output", "if", "self", ".", "activation", "is", "None", "\n", "else", "self", ".", "activation", "(", "lin_output", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.AEHiddenLayer.get_outputs": [[238, 241], ["layer.AEHiddenLayer.setup_outputs"], "methods", ["home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.AEHiddenLayer.setup_outputs"], ["", "def", "get_outputs", "(", "self", ",", "input", ")", ":", "\n", "        ", "self", ".", "setup_outputs", "(", "input", ")", "\n", "return", "self", ".", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.AEOutputLayer.__init__": [[244, 307], ["layer.AEHiddenLayer.__init__", "numpy.random.RandomState", "layer.AEOutputLayer.W.get_value", "theano.shared", "numpy.transpose"], "methods", ["home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.Adamax.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "input", ",", "\n", "n_in", ",", "\n", "n_out", ",", "\n", "n_in_dec", "=", "None", ",", "\n", "n_out_dec", "=", "None", ",", "\n", "W", "=", "None", ",", "\n", "b", "=", "None", ",", "\n", "num_pieces", "=", "1", ",", "\n", "bhid", "=", "None", ",", "\n", "activation", "=", "T", ".", "nnet", ".", "sigmoid", ",", "\n", "sparse_initialize", "=", "False", ",", "\n", "tied_weights", "=", "True", ",", "\n", "rng", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Typical hidden layer for an auto-encoder: The units are fully connected\n        and have sigmoidal activation function. Weight matrix (W) is of shape\n        (n_in, n_out) and the bias vector (b) is of shape(n_out,).\n        The only difference between this AE and the AEHiddeLayer is:\n        W_prime = W (real values)\n        W = W_prime.T (tensor)\n\n        Hidden units activation is given by: sigmoid(dot(input, w)+ b)\n\n        :type rng: numpy.random.RandomState\n        :param rng: a random number generator used to initiaze the weights.\n\n        :type input: theano.tensor.dmatrix\n        :param input: a symbolic tensor of shape (n_examples, n_in)\n\n        :type n_in: int\n        :param n_in: dimension of the input\n\n        :type n_out: int\n        :param n_out: number of hidden units\n\n        :type activation: theano.Op or function\n        :param activation:  Non linearity to be applied in the hidden layer.\n        \"\"\"", "\n", "if", "rng", "is", "None", ":", "\n", "            ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", ")", "\n", "\n", "", "super", "(", "AEOutputLayer", ",", "self", ")", ".", "__init__", "(", "\n", "input", "=", "input", ",", "\n", "n_in", "=", "n_in", ",", "\n", "n_out", "=", "n_out", ",", "\n", "n_in_dec", "=", "n_in_dec", ",", "\n", "n_out_dec", "=", "n_out_dec", ",", "\n", "W", "=", "W", ",", "\n", "b", "=", "b", ",", "\n", "num_pieces", "=", "num_pieces", ",", "\n", "bhid", "=", "bhid", ",", "\n", "activation", "=", "activation", ",", "\n", "sparse_initialize", "=", "sparse_initialize", ",", "\n", "tied_weights", "=", "tied_weights", ",", "\n", "rng", "=", "rng", ")", "\n", "# Reverse the weights", "\n", "if", "tied_weights", ":", "\n", "            ", "W_val", "=", "self", ".", "W", ".", "get_value", "(", ")", "\n", "self", ".", "W_prime", "=", "theano", ".", "shared", "(", "value", "=", "np", ".", "transpose", "(", "W_val", ")", ",", "\n", "name", "=", "'W_prime'", ",", "borrow", "=", "True", ")", "\n", "self", ".", "W", "=", "self", ".", "W_prime", ".", "T", "\n", "self", ".", "params", "=", "[", "self", ".", "W_prime", ",", "self", ".", "b", ",", "self", ".", "b_prime", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.LogisticRegressionLayer.__init__": [[317, 367], ["layer.Layer.__init__", "layer.LogisticRegressionLayer.reset_layer", "numpy.zeros", "numpy.zeros", "layer.LogisticRegressionLayer.reset_conf_mat", "layer.LogisticRegressionLayer.get_class_memberships", "theano.tensor.argmax", "theano.tensor.gt", "theano.tensor.flatten"], "methods", ["home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.Adamax.__init__", "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.Layer.reset_layer", "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.LogisticRegressionLayer.reset_conf_mat", "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.LogisticRegressionLayer.get_class_memberships"], ["def", "__init__", "(", "self", ",", "input", ",", "n_in", ",", "n_out", ",", "is_binary", "=", "False", ",", "threshold", "=", "0.4", ",", "\n", "rng", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialize the parameters of the logistic regression.\n        :type input: theano.tensor.TensorType\n        :param input: symbolic variable that describes the input of the\n        architecture (one minibatch)\n        :type n_in: int\n        :param n_in: number of input units, the dimension of the space in which\n        the datapoints lie\n        :type n_out: int\n        :param n_out: number of output units, the dimension of the space in\n        which the labels lie (number of classes)\n        \"\"\"", "\n", "self", ".", "activation", "=", "T", ".", "nnet", ".", "sigmoid", "\n", "self", ".", "threshold", "=", "threshold", "\n", "super", "(", "LogisticRegressionLayer", ",", "self", ")", ".", "__init__", "(", "\n", "input", ",", "\n", "n_in", ",", "\n", "n_out", ",", "\n", "self", ".", "activation", ",", "\n", "rng", ")", "\n", "\n", "self", ".", "reset_layer", "(", ")", "\n", "\n", "self", ".", "is_binary", "=", "is_binary", "\n", "if", "n_out", "==", "1", ":", "\n", "            ", "self", ".", "is_binary", "=", "True", "\n", "# The number of classes", "\n", "", "self", ".", "n_classes_seen", "=", "np", ".", "zeros", "(", "n_out", ")", "\n", "# The number of the wrong classification madefor the class i", "\n", "self", ".", "n_wrong_classif_made", "=", "np", ".", "zeros", "(", "n_out", ")", "\n", "\n", "self", ".", "reset_conf_mat", "(", ")", "\n", "\n", "# Compute vector class-membership probablities in symbolic form", "\n", "# self.p_y_given_x = T.nnet.softmax(T.dot(input, self.W)+ self.b)", "\n", "self", ".", "p_y_given_x", "=", "self", ".", "get_class_memberships", "(", "self", ".", "input", ")", "\n", "\n", "if", "not", "self", ".", "is_binary", ":", "\n", "# Compute prediction as class whose probability is maximal", "\n", "# in symbolic form", "\n", "            ", "self", ".", "y_decision", "=", "T", ".", "argmax", "(", "self", ".", "p_y_given_x", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "# If the probability is greater than the specified threshold", "\n", "# assign to the class 1, otherwise it is 0. Which alos can be", "\n", "# checked if p(y=1|x) > threshold.", "\n", "            ", "self", ".", "y_decision", "=", "T", ".", "gt", "(", "T", ".", "flatten", "(", "self", ".", "p_y_given_x", ")", ",", "self", ".", "threshold", ")", "\n", "\n", "", "self", ".", "params", "=", "[", "self", ".", "W", ",", "self", ".", "b", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.LogisticRegressionLayer.reset_conf_mat": [[368, 374], ["numpy.zeros", "numpy.dtype"], "methods", ["None"], ["", "def", "reset_conf_mat", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Reset the confusion matrix.\n        \"\"\"", "\n", "self", ".", "conf_mat", "=", "np", ".", "zeros", "(", "shape", "=", "(", "self", ".", "n_out", ",", "self", ".", "n_out", ")", ",", "\n", "dtype", "=", "np", ".", "dtype", "(", "int", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.LogisticRegressionLayer.negative_log_likelihood": [[375, 394], ["theano.tensor.mean", "theano.tensor.mean", "theano.tensor.log", "theano.tensor.log", "theano.tensor.arange"], "methods", ["None"], ["", "def", "negative_log_likelihood", "(", "self", ",", "y", ")", ":", "\n", "        ", "\"\"\"\n        Return the mean of the negative log-likelihood of the prediction\n        of this model under a given target distribution.\n        .. math::\n            \\frac{1}{|\\mathcal{D}|} \\mathcal{L} (\\theta=\\{W,b\\}, \\mathcal{D}) =\n            \\frac{1}{|\\mathcal{D}|} \\sum_{i=0}^{|\\mathcal{D}|}\n            \\log(P(Y=y^{(i)}|x^{(i)}, W,b)) \\\\\n                    \\ell (\\theta=\\{W,b\\}, \\mathcal{D})\n\n        :type y: theano.tensor.TensorType\n        :param y: corresponds to a vector that gives for each example\n            the correct label.\n        Note: We use the mean instead of the sum so that the learning rate\n            is less dependent of the batch size.\n        \"\"\"", "\n", "if", "self", ".", "is_binary", ":", "\n", "            ", "return", "-", "T", ".", "mean", "(", "T", ".", "log", "(", "self", ".", "p_y_given_x", ")", ")", "\n", "", "return", "-", "T", ".", "mean", "(", "T", ".", "log", "(", "self", ".", "p_y_given_x", ")", "[", "T", ".", "arange", "(", "y", ".", "shape", "[", "0", "]", ")", ",", "y", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.LogisticRegressionLayer.crossentropy_categorical": [[395, 400], ["theano.tensor.mean", "theano.tensor.nnet.categorical_crossentropy"], "methods", ["None"], ["", "def", "crossentropy_categorical", "(", "self", ",", "y", ")", ":", "\n", "        ", "\"\"\"\n        Find the categorical cross entropy.\n        \"\"\"", "\n", "return", "T", ".", "mean", "(", "T", ".", "nnet", ".", "categorical_crossentropy", "(", "self", ".", "p_y_given_x", ",", "y", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.LogisticRegressionLayer.crossentropy": [[401, 410], ["theano.tensor.mean", "theano.tensor.nnet.binary_crossentropy", "theano.tensor.flatten"], "methods", ["None"], ["", "def", "crossentropy", "(", "self", ",", "y", ")", ":", "\n", "        ", "\"\"\"\n        use the theano nnet cross entropy function. Return the mean.\n        Note: self.p_y_given_x is (batch_size, 1) but y is (batch_size,).\n        In order to establish the compliance, we should flatten the\n        p_y_given_x.\n        \"\"\"", "\n", "return", "T", ".", "mean", "(", "\n", "T", ".", "nnet", ".", "binary_crossentropy", "(", "T", ".", "flatten", "(", "self", ".", "p_y_given_x", ")", ",", "y", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.LogisticRegressionLayer.get_class_memberships": [[411, 418], ["theano.tensor.nnet.softmax", "theano.tensor.dot", "theano.tensor.nnet.sigmoid"], "methods", ["None"], ["", "def", "get_class_memberships", "(", "self", ",", "x", ")", ":", "\n", "        ", "lin_activation", "=", "T", ".", "dot", "(", "x", ",", "self", ".", "W", ")", "+", "self", ".", "b", "\n", "if", "self", ".", "is_binary", ":", "\n", "# return the sigmoid value", "\n", "            ", "return", "T", ".", "nnet", ".", "sigmoid", "(", "lin_activation", ")", "\n", "# else retunr the softmax", "\n", "", "return", "T", ".", "nnet", ".", "softmax", "(", "lin_activation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.LogisticRegressionLayer.update_conf_mat": [[419, 430], ["xrange", "numpy.argmax"], "methods", ["None"], ["", "def", "update_conf_mat", "(", "self", ",", "y", ",", "p_y_given_x", ")", ":", "\n", "        ", "\"\"\"\n        Update the confusion matrix with the given true labels and estimated\n        labels.\n        \"\"\"", "\n", "if", "self", ".", "n_out", "==", "1", ":", "\n", "            ", "y_decision", "=", "(", "p_y_given_x", ">", "self", ".", "threshold", ")", "\n", "", "else", ":", "\n", "            ", "y_decision", "=", "np", ".", "argmax", "(", "p_y_given_x", ",", "axis", "=", "1", ")", "\n", "", "for", "i", "in", "xrange", "(", "y", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "self", ".", "conf_mat", "[", "y", "[", "i", "]", "]", "[", "y_decision", "[", "i", "]", "]", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.LogisticRegressionLayer.errors": [[431, 450], ["TypeError", "y.dtype.startswith", "y.dtype.startswith", "theano.tensor.mean", "NotImplementedError", "theano.tensor.neq"], "methods", ["None"], ["", "", "def", "errors", "(", "self", ",", "y", ")", ":", "\n", "        ", "\"\"\"\n        returns a float representing the number of errors in the minibatch\n        over the total number of examples of the minibatch. Zero one loss\n        over the size of the minibatch.\n\n        :type y: theano.tensor.TensorType\n        :param y: corresponds to a vector that gives for each example the\n        correct label.\n        \"\"\"", "\n", "if", "y", ".", "ndim", "!=", "self", ".", "y_decision", ".", "ndim", ":", "\n", "            ", "raise", "TypeError", "(", "\"y should have the same shape as self.y_decision\"", ",", "\n", "(", "'y'", ",", "y", ".", "type", ",", "\"y_decision\"", ",", "self", ".", "y_decision", ".", "type", ")", ")", "\n", "", "if", "y", ".", "dtype", ".", "startswith", "(", "'int'", ")", "or", "y", ".", "dtype", ".", "startswith", "(", "'uint'", ")", ":", "\n", "# The T.neq operator returns a vector of 0s and 1s, where:", "\n", "# 1 represents a mistake in classification", "\n", "            ", "return", "T", ".", "mean", "(", "T", ".", "neq", "(", "self", ".", "y_decision", ",", "y", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.LogisticRegressionLayer.raw_prediction_errors": [[451, 470], ["TypeError", "y.dtype.startswith", "y.dtype.startswith", "theano.tensor.neq", "NotImplementedError"], "methods", ["None"], ["", "", "def", "raw_prediction_errors", "(", "self", ",", "y", ")", ":", "\n", "        ", "\"\"\"\n        Returns a binary array where each each element indicates if the\n        corresponding sample has been correctly classified (0) or not (1) in\n        the minibatch.\n\n        :type y: theano.tensor.TensorType\n        :param y: corresponds to a vector that gives for each example the\n        correct label.\n        \"\"\"", "\n", "if", "y", ".", "ndim", "!=", "self", ".", "y_decision", ".", "ndim", ":", "\n", "            ", "raise", "TypeError", "(", "\"y should have the same shape as self.y_decision\"", ",", "\n", "(", "'y'", ",", "y", ".", "type", ",", "\"y_decision\"", ",", "self", ".", "y_decision", ".", "type", ")", ")", "\n", "", "if", "y", ".", "dtype", ".", "startswith", "(", "'int'", ")", "or", "y", ".", "dtype", ".", "startswith", "(", "'uint'", ")", ":", "\n", "# The T.neq operator returns a vector of 0s and 1s, where:", "\n", "# 1 represents a mistake in classification", "\n", "            ", "return", "T", ".", "neq", "(", "self", ".", "y_decision", ",", "y", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.layer.LogisticRegressionLayer.error_per_calss": [[471, 493], ["TypeError", "y.dtype.startswith", "y.dtype.startswith", "theano.tensor.neq", "enumerate", "NotImplementedError", "theano.tensor.mean"], "methods", ["None"], ["", "", "def", "error_per_calss", "(", "self", ",", "y", ")", ":", "\n", "        ", "\"\"\"\n        Return an array where each value is the error for the corresponding\n        classe in the minibatch.\n\n        :type y: theano.tensor.TensorType\n        :param y: corresponds to a vector that gives for each example the\n        correct label.\n        \"\"\"", "\n", "if", "y", ".", "ndim", "!=", "self", ".", "y_decision", ".", "ndim", ":", "\n", "            ", "raise", "TypeError", "(", "\"y should have the same shape as self.y_decision\"", ",", "\n", "(", "'y'", ",", "y", ".", "type", ",", "\"y_decision\"", ",", "self", ".", "y_decision", ".", "type", ")", ")", "\n", "", "if", "y", ".", "dtype", ".", "startswith", "(", "'int'", ")", "or", "y", ".", "dtype", ".", "startswith", "(", "'uint'", ")", ":", "\n", "            ", "y_decision_res", "=", "T", ".", "neq", "(", "self", ".", "y_decision", ",", "y", ")", "\n", "for", "(", "i", ",", "y_decision_r", ")", "in", "enumerate", "(", "y_decision_res", ")", ":", "\n", "                ", "self", ".", "n_classes_seen", "[", "y", "[", "i", "]", "]", "+=", "1", "\n", "if", "y_decision_r", ":", "\n", "                    ", "self", ".", "n_wrong_classif_made", "[", "y", "[", "i", "]", "]", "+=", "1", "\n", "", "", "pred_per_class", "=", "self", ".", "n_wrong_classif_made", "/", "self", ".", "n_classes_seen", "\n", "return", "T", ".", "mean", "(", "y_decision_res", ")", ",", "pred_per_class", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.LearningRule.get_updates": [[92, 99], ["NotImplementedError", "str", "type"], "methods", ["None"], ["def", "get_updates", "(", "self", ",", "learning_rate", ",", "params", ",", "grads", ",", "lr_scalers", ")", ":", "\n", "        ", "\"\"\" Compute the current updates for the parameters.\n\n        \"\"\"", "\n", "\n", "raise", "NotImplementedError", "(", "\n", "str", "(", "type", "(", "self", ")", ")", "+", "\" does not implement get_updates.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.Momentum.__init__": [[129, 146], ["sop_embed.tools.sharedX_value", "sop_embed.tools.sharedX_value"], "methods", ["home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.extra.sharedX_value", "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.extra.sharedX_value"], ["def", "__init__", "(", "self", ",", "init_momentum", ",", "nesterov_momentum", "=", "False", ",", "\n", "imagenet", "=", "False", ",", "imagenetDecay", "=", "5e-4", ",", "max_colm_norm", "=", "False", ",", "\n", "max_norm", "=", "15.0", ")", ":", "\n", "        ", "assert", "init_momentum", ">=", "0.", ",", "'The initial momentum should be >=0.'", "\n", "assert", "init_momentum", "<", "1.", ",", "'The initial momentum should be < 1.'", "\n", "\n", "self", ".", "momentum", "=", "sharedX_value", "(", "value", "=", "init_momentum", ",", "name", "=", "\"momentum\"", ",", "\n", "borrow", "=", "True", ")", "\n", "self", ".", "nesterov_momentum", "=", "nesterov_momentum", "\n", "self", ".", "_first_time", "=", "True", "\n", "self", ".", "velocity", "=", "None", "# tracks the velocity at the previous time", "\n", "self", ".", "imagenet", "=", "imagenet", "\n", "self", ".", "imagenetDecay", "=", "sharedX_value", "(", "value", "=", "imagenetDecay", ",", "\n", "name", "=", "\"imagenetDecay\"", ",", "\n", "borrow", "=", "True", ")", "\n", "self", ".", "max_colm_norm", "=", "max_colm_norm", "\n", "self", ".", "max_norm", "=", "max_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.Momentum.get_updates": [[147, 189], ["zip", "updates.append", "updates.append", "sop_embed.tools.sharedX_mtx", "learning_rule.norm_constraint", "param.get_value"], "methods", ["home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.norm_constraint"], ["", "def", "get_updates", "(", "self", ",", "learning_rate", ",", "params", ",", "grads", ",", "lr_scalers", ")", ":", "\n", "        ", "\"\"\"\n        get the updates (params, and velocity)\n        \"\"\"", "\n", "# the initial velocity is zero.", "\n", "if", "self", ".", "_first_time", ":", "\n", "            ", "self", ".", "velocity", "=", "[", "\n", "sharedX_mtx", "(", "\n", "param", ".", "get_value", "(", ")", "*", "0.", ",", "\n", "name", "=", "'vel_'", "+", "param", ".", "name", ",", "borrow", "=", "True", ")", "for", "param", "in", "params", "]", "\n", "\n", "", "updates", "=", "[", "]", "\n", "for", "(", "param", ",", "grad", ",", "vel", ",", "lr_sc", ")", "in", "zip", "(", "\n", "params", ",", "grads", ",", "self", ".", "velocity", ",", "lr_scalers", ")", ":", "\n", "            ", "lr_scaled", "=", "learning_rate", "*", "lr_sc", "\n", "if", "self", ".", "imagenet", ":", "\n", "                ", "new_vel", "=", "self", ".", "momentum", "*", "vel", "-", "lr_scaled", "*", "self", ".", "imagenetDecay", "*", "param", "-", "lr_scaled", "*", "grad", "\n", "", "else", ":", "\n", "                ", "new_vel", "=", "self", ".", "momentum", "*", "vel", "-", "lr_scaled", "*", "grad", "\n", "\n", "", "updates", ".", "append", "(", "(", "vel", ",", "new_vel", ")", ")", "\n", "inc", "=", "new_vel", "\n", "# this is the equivalence of NAG in [3].3.5, eq [7].", "\n", "# It helps to avoid calculating the new grad(param+vel_(t-1)).", "\n", "# The only different from the paper is: momentum_(t)", "\n", "# which it's set to momentum_(t-1). If you develop the final inc,", "\n", "# you will find that it's equivalent to eq.[7] mentioned above.", "\n", "if", "self", ".", "nesterov_momentum", ":", "\n", "                ", "inc", "=", "self", ".", "momentum", "*", "new_vel", "-", "lr_scaled", "*", "grad", "\n", "\n", "", "new_param", "=", "param", "+", "inc", "\n", "if", "self", ".", "max_colm_norm", "and", "param", ".", "name", "in", "[", "\"W\"", ",", "\"w\"", "]", ":", "\n", "                ", "new_param_final", "=", "norm_constraint", "(", "tensor_var", "=", "new_param", ",", "\n", "max_norm", "=", "self", ".", "max_norm", ")", "\n", "", "else", ":", "\n", "                ", "new_param_final", "=", "new_param", "\n", "", "updates", ".", "append", "(", "(", "param", ",", "new_param_final", ")", ")", "\n", "\n", "# add the velocity updates to updates", "\n", "\n", "", "return", "updates", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.MomentumLinearAdjusterOverEpoch.__init__": [[204, 215], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "final_momentum", ",", "start", ",", "saturate", ")", ":", "\n", "        ", "assert", "saturate", ">=", "start", ",", "\"The momentum can not saturate before it \"", "\"starts increasing. Please set a saturation value higher than the\"", "\" start value.\"", "\n", "self", ".", "_initialized", "=", "False", "\n", "self", ".", "_count", "=", "0", "\n", "self", ".", "saturate", "=", "saturate", "\n", "self", ".", "final_momentum", "=", "final_momentum", "\n", "self", ".", "start", "=", "start", "\n", "self", ".", "freq", "=", "'epoch'", "# it works only on epochs", "\n", "self", ".", "_first_time", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.MomentumLinearAdjusterOverEpoch.__call__": [[216, 234], ["learning_rule.MomentumLinearAdjusterOverEpoch._apply_momentum", "hasattr", "ValueError", "str", "type"], "methods", ["home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.MomentumLinearAdjusterOverEpoch._apply_momentum"], ["", "def", "__call__", "(", "self", ",", "learning_rule", ",", "seen_epochs", ")", ":", "\n", "        ", "\"\"\"Update the momentum according to the number of the epochs already\n        seen.\n\n        Parameters:\n            trainingAlgorithm: instance of\n                training_algorithm.trainingAlgorithm,\n                the current algorithm used for training the model.\n        \"\"\"", "\n", "# check", "\n", "if", "not", "hasattr", "(", "learning_rule", ",", "'momentum'", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "str", "(", "type", "(", "self", ")", ")", "+", "' works only when the learning_rule '", "\n", "'specified in the training algorithm has the attribute '", "\n", "'<momentum>. For examples: \"sarco.learning_rule.Momentum\"'", ")", "\n", "\n", "", "self", ".", "_count", "=", "seen_epochs", "\n", "self", ".", "_apply_momentum", "(", "learning_rule", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.MomentumLinearAdjusterOverEpoch._apply_momentum": [[235, 245], ["momentum.set_value", "momentum.get_value", "learning_rule.MomentumLinearAdjusterOverEpoch.get_current_momentum"], "methods", ["home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.MomentumLinearAdjusterOverEpoch.get_current_momentum"], ["", "def", "_apply_momentum", "(", "self", ",", "learning_rule", ")", ":", "\n", "        ", "\"\"\"Apply the momentum.\n        \"\"\"", "\n", "\n", "momentum", "=", "learning_rule", ".", "momentum", "\n", "if", "not", "self", ".", "_initialized", ":", "\n", "            ", "self", ".", "_init_momentum", "=", "momentum", ".", "get_value", "(", ")", "\n", "self", ".", "_initialized", "=", "True", "\n", "", "momentum", ".", "set_value", "(", "\n", "np", ".", "cast", "[", "theano", ".", "config", ".", "floatX", "]", "(", "self", ".", "get_current_momentum", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.MomentumLinearAdjusterOverEpoch.get_current_momentum": [[246, 270], ["float", "float"], "methods", ["None"], ["", "def", "get_current_momentum", "(", "self", ")", ":", "\n", "        ", "\"\"\"Return the current momentum with the desired schedule.\n\n        \"\"\"", "\n", "w", "=", "self", ".", "saturate", "-", "self", ".", "start", "\n", "if", "w", "==", "0", ":", "\n", "# saturate=start, jump straighforward to the final momentum value", "\n", "# if we exceeded the saturation, return the final momentum", "\n", "            ", "if", "self", ".", "_count", ">=", "self", ".", "saturate", ":", "\n", "                ", "return", "self", ".", "final_momentum", "\n", "", "else", ":", "\n", "# else: (we didn't reach yet the saturation point),", "\n", "# return the initial momentum", "\n", "                ", "return", "self", ".", "_init_momentum", "\n", "\n", "", "", "coef", "=", "float", "(", "self", ".", "_count", "-", "self", ".", "start", ")", "/", "float", "(", "w", ")", "\n", "if", "coef", "<", "0.", ":", "\n", "            ", "coef", "=", "0.", "# no effect", "\n", "", "if", "coef", ">", "1.", ":", "\n", "            ", "coef", "=", "1.", "\n", "\n", "", "cu_m", "=", "self", ".", "_init_momentum", "*", "(", "1", "-", "coef", ")", "+", "coef", "*", "self", ".", "final_momentum", "\n", "\n", "return", "cu_m", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.AdaDelta.__init__": [[284, 295], ["str", "str", "type", "type"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "decay", "=", "0.95", ",", "max_colm_norm", "=", "False", ",", "max_norm", "=", "15.0", ")", ":", "\n", "        ", "assert", "decay", ">=", "0.", ",", "'The decay parameter in '", "+", "str", "(", "type", "(", "self", ")", ")", "+", "' must be >= 0.'", "\n", "assert", "decay", "<", "1.", ",", "'The decay parameter in '", "+", "str", "(", "type", "(", "self", ")", ")", "+", "' must be < 1.'", "\n", "self", ".", "decay", "=", "decay", "\n", "self", ".", "_first_time", "=", "True", "\n", "self", ".", "mean_square_grad", "=", "None", "\n", "self", ".", "mean_squar_dx", "=", "None", "\n", "self", ".", "max_colm_norm", "=", "max_colm_norm", "\n", "self", ".", "max_norm", "=", "max_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.AdaDelta.get_updates": [[296, 346], ["zip", "theano.sqrt", "theano.sqrt", "theano.sqrt", "theano.sqrt", "updates.append", "updates.append", "updates.append", "sop_embed.tools.sharedX_mtx", "sop_embed.tools.sharedX_mtx", "learning_rule.norm_constraint", "theano.sqr", "theano.sqr", "theano.sqr", "theano.sqr", "param.get_value", "param.get_value"], "methods", ["home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.norm_constraint"], ["", "def", "get_updates", "(", "self", ",", "learning_rate", ",", "params", ",", "grads", ",", "lr_scalers", ")", ":", "\n", "        ", "\"\"\"Compute the AdaDelta updates of the model's parameters.\n\n        param_t := param_(t-1) + AdaDelta_update_t\n        \"\"\"", "\n", "if", "self", ".", "_first_time", ":", "\n", "            ", "self", ".", "mean_square_grad", "=", "[", "\n", "sharedX_mtx", "(", "\n", "param", ".", "get_value", "(", ")", "*", "0.", ",", "\n", "name", "=", "'mean_square_grad_'", "+", "param", ".", "name", ",", "\n", "borrow", "=", "True", ")", "for", "param", "in", "params", "]", "\n", "self", ".", "mean_squar_dx", "=", "[", "\n", "sharedX_mtx", "(", "\n", "param", ".", "get_value", "(", ")", "*", "0.", ",", "\n", "name", "=", "'mean_square_dx_'", "+", "param", ".", "name", ",", "\n", "borrow", "=", "True", ")", "for", "param", "in", "params", "]", "\n", "self", ".", "_first_time", "=", "False", "\n", "\n", "", "updates", "=", "[", "]", "\n", "for", "(", "param", ",", "grad", ",", "mean_square_grad", ",", "mean_squar_dx", ",", "lr_sc", ")", "in", "zip", "(", "\n", "params", ",", "grads", ",", "self", ".", "mean_square_grad", ",", "self", ".", "mean_squar_dx", ",", "\n", "lr_scalers", ")", ":", "\n", "# Calculate the running average gradient: E[g^2]_t", "\n", "            ", "new_mean_square_grad", "=", "(", "\n", "self", ".", "decay", "*", "mean_square_grad", "+", "(", "1", "-", "self", ".", "decay", ")", "*", "T", ".", "sqr", "(", "grad", ")", ")", "\n", "\n", "# The update: delta_x_t", "\n", "lr_scaled", "=", "learning_rate", "*", "lr_sc", "\n", "epsilon", "=", "lr_scaled", "\n", "rms_dx_t_1", "=", "T", ".", "sqrt", "(", "mean_squar_dx", "+", "epsilon", ")", "\n", "rms_grad_t", "=", "T", ".", "sqrt", "(", "new_mean_square_grad", "+", "epsilon", ")", "\n", "delta_x_t", "=", "-", "(", "rms_dx_t_1", "/", "rms_grad_t", ")", "*", "grad", "\n", "# Compute: E[delta_x^2]_t", "\n", "new_mean_square_dx", "=", "(", "\n", "self", ".", "decay", "*", "mean_squar_dx", "+", "\n", "(", "1", "-", "self", ".", "decay", ")", "*", "T", ".", "sqr", "(", "delta_x_t", ")", ")", "\n", "\n", "# update the params", "\n", "new_param", "=", "param", "+", "delta_x_t", "\n", "# Send for the update", "\n", "updates", ".", "append", "(", "(", "mean_square_grad", ",", "new_mean_square_grad", ")", ")", "\n", "updates", ".", "append", "(", "(", "mean_squar_dx", ",", "new_mean_square_dx", ")", ")", "\n", "if", "self", ".", "max_colm_norm", "and", "param", ".", "name", "in", "[", "\"W\"", ",", "\"w\"", "]", ":", "\n", "                ", "new_param_final", "=", "norm_constraint", "(", "tensor_var", "=", "new_param", ",", "\n", "max_norm", "=", "self", ".", "max_norm", ")", "\n", "", "else", ":", "\n", "                ", "new_param_final", "=", "new_param", "\n", "", "updates", ".", "append", "(", "(", "param", ",", "new_param_final", ")", ")", "\n", "\n", "", "return", "updates", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.AdaGrad.__init__": [[359, 364], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "max_colm_norm", "=", "False", ",", "max_norm", "=", "15.0", ")", ":", "\n", "        ", "self", ".", "_first_time", "=", "True", "\n", "self", ".", "sum_square_grad", "=", "None", "\n", "self", ".", "max_colm_norm", "=", "max_colm_norm", "\n", "self", ".", "max_norm", "=", "max_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.AdaGrad.get_updates": [[365, 402], ["zip", "theano.sqrt", "theano.sqrt", "updates.append", "updates.append", "sop_embed.tools.sharedX_mtx", "theano.sqr", "theano.sqr", "learning_rule.norm_constraint", "param.get_value"], "methods", ["home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.norm_constraint"], ["", "def", "get_updates", "(", "self", ",", "learning_rate", ",", "params", ",", "grads", ",", "lr_scalers", ")", ":", "\n", "        ", "\"\"\"Compute the AdaDelta updates of the model's parameters.\n\n        param_t := param_(t-1) + AdaDelta_update_t\n        \"\"\"", "\n", "if", "self", ".", "_first_time", ":", "\n", "            ", "self", ".", "sum_square_grad", "=", "[", "\n", "sharedX_mtx", "(", "\n", "param", ".", "get_value", "(", ")", "*", "0.", ",", "\n", "name", "=", "'sum_square_grad_'", "+", "param", ".", "name", ",", "\n", "borrow", "=", "True", ")", "for", "param", "in", "params", "]", "\n", "self", ".", "_first_time", "=", "False", "\n", "\n", "", "updates", "=", "[", "]", "\n", "for", "(", "param", ",", "grad", ",", "sum_square_grad", ",", "lr_sc", ")", "in", "zip", "(", "\n", "params", ",", "grads", ",", "self", ".", "sum_square_grad", ",", "lr_scalers", ")", ":", "\n", "# Calculate the running average gradient: E[g^2]_t", "\n", "            ", "new_sum_square_grad", "=", "sum_square_grad", "+", "T", ".", "sqr", "(", "grad", ")", "\n", "\n", "# The update: delta_x_t", "\n", "lr_scaled", "=", "learning_rate", "*", "lr_sc", "\n", "epsilon", "=", "lr_scaled", "\n", "sqrt_sum_grad_t", "=", "T", ".", "sqrt", "(", "new_sum_square_grad", ")", "\n", "delta_x_t", "=", "-", "(", "epsilon", "/", "sqrt_sum_grad_t", ")", "*", "grad", "\n", "\n", "# update the params", "\n", "new_param", "=", "param", "+", "delta_x_t", "\n", "# Send for the update", "\n", "updates", ".", "append", "(", "(", "sum_square_grad", ",", "new_sum_square_grad", ")", ")", "\n", "if", "self", ".", "max_colm_norm", "and", "param", ".", "name", "in", "[", "\"W\"", ",", "\"w\"", "]", ":", "\n", "                ", "new_param_final", "=", "norm_constraint", "(", "tensor_var", "=", "new_param", ",", "\n", "max_norm", "=", "self", ".", "max_norm", ")", "\n", "", "else", ":", "\n", "                ", "new_param_final", "=", "new_param", "\n", "", "updates", ".", "append", "(", "(", "param", ",", "new_param_final", ")", ")", "\n", "\n", "", "return", "updates", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.RMSProp.__init__": [[422, 432], ["sop_embed.tools.sharedX_value"], "methods", ["home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.extra.sharedX_value"], ["def", "__init__", "(", "self", ",", "decay", "=", "0.9", ",", "max_scaling", "=", "1e5", ",", "max_colm_norm", "=", "False", ",", "\n", "max_norm", "=", "15.0", ")", ":", "\n", "        ", "assert", "0.", "<=", "decay", "<", "1.", ",", "'decay must be: 0. <= decay < 1'", "\n", "assert", "max_scaling", ">", "0.", ",", "'max_scaling must be > 0.'", "\n", "self", ".", "decay", "=", "sharedX_value", "(", "decay", ",", "name", "=", "'decay'", ",", "borrow", "=", "True", ")", "\n", "self", ".", "epsilon", "=", "1.", "/", "max_scaling", "\n", "self", ".", "mean_square_grads", "=", "None", "\n", "self", ".", "_first_time", "=", "True", "\n", "self", ".", "max_colm_norm", "=", "max_colm_norm", "\n", "self", ".", "max_norm", "=", "max_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.RMSProp.get_updates": [[433, 466], ["zip", "theano.sqrt", "theano.sqrt", "theano.maximum", "theano.maximum", "updates.append", "updates.append", "sop_embed.tools.sharedX_mtx", "learning_rule.norm_constraint", "theano.sqr", "theano.sqr", "param.get_value"], "methods", ["home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.norm_constraint"], ["", "def", "get_updates", "(", "self", ",", "learning_rate", ",", "params", ",", "grads", ",", "lr_scalers", ")", ":", "\n", "        ", "\"\"\"Compute the parameters' updates.\n\n        \"\"\"", "\n", "if", "self", ".", "_first_time", ":", "\n", "            ", "self", ".", "mean_square_grads", "=", "[", "\n", "sharedX_mtx", "(", "\n", "param", ".", "get_value", "(", ")", "*", "0.", ",", "\n", "name", "=", "'mean_square_grad_'", "+", "param", ".", "name", ",", "\n", "borrow", "=", "True", ")", "for", "param", "in", "params", "]", "\n", "self", ".", "_first_time", "=", "False", "\n", "", "updates", "=", "[", "]", "\n", "for", "(", "param", ",", "grad", ",", "mean_square_grad", ",", "lr_sc", ")", "in", "zip", "(", "\n", "params", ",", "grads", ",", "self", ".", "mean_square_grads", ",", "lr_scalers", ")", ":", "\n", "            ", "new_mean_square_grad", "=", "(", "\n", "self", ".", "decay", "*", "mean_square_grad", "+", "(", "1", "-", "self", ".", "decay", ")", "*", "T", ".", "sqr", "(", "grad", ")", ")", "\n", "# the update", "\n", "rms_grad_t", "=", "T", ".", "sqrt", "(", "new_mean_square_grad", ")", "\n", "rms_grad_t", "=", "T", ".", "maximum", "(", "rms_grad_t", ",", "self", ".", "epsilon", ")", "\n", "lr_scaled", "=", "learning_rate", "*", "lr_sc", "\n", "delta_x_t", "=", "-", "lr_scaled", "*", "grad", "/", "rms_grad_t", "\n", "\n", "new_param", "=", "param", "+", "delta_x_t", "\n", "# updates", "\n", "if", "self", ".", "max_colm_norm", "and", "param", ".", "name", "in", "[", "\"W\"", ",", "\"w\"", "]", ":", "\n", "                ", "new_param_final", "=", "norm_constraint", "(", "tensor_var", "=", "new_param", ",", "\n", "max_norm", "=", "self", ".", "max_norm", ")", "\n", "", "else", ":", "\n", "                ", "new_param_final", "=", "new_param", "\n", "", "updates", ".", "append", "(", "(", "param", ",", "new_param_final", ")", ")", "\n", "updates", ".", "append", "(", "(", "mean_square_grad", ",", "new_mean_square_grad", ")", ")", "\n", "\n", "", "return", "updates", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.Adam.__init__": [[487, 494], ["sop_embed.tools.sharedX_value", "sop_embed.tools.sharedX_value", "sop_embed.tools.sharedX_value"], "methods", ["home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.extra.sharedX_value", "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.extra.sharedX_value", "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.extra.sharedX_value"], ["def", "__init__", "(", "self", ",", "beta1", "=", "0.9", ",", "beta2", "=", "0.999", ",", "epsilon", "=", "1e-8", ",", "\n", "max_colm_norm", "=", "False", ",", "max_norm", "=", "15.0", ")", ":", "\n", "        ", "self", ".", "beta1", "=", "sharedX_value", "(", "beta1", ",", "name", "=", "'beta1'", ",", "borrow", "=", "True", ")", "\n", "self", ".", "beta2", "=", "sharedX_value", "(", "beta2", ",", "name", "=", "'beta2'", ",", "borrow", "=", "True", ")", "\n", "self", ".", "epsilon", "=", "sharedX_value", "(", "epsilon", ",", "name", "=", "'epsilon'", ",", "borrow", "=", "True", ")", "\n", "self", ".", "max_colm_norm", "=", "max_colm_norm", "\n", "self", ".", "max_norm", "=", "max_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.Adam.get_updates": [[495, 532], ["theano.shared", "theano.shared", "theano.shared", "theano.shared", "collections.OrderedDict", "theano.constant", "theano.constant", "zip", "sop_embed.tools.floatX", "param.get_value", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.sqrt", "theano.sqrt", "numpy.zeros", "numpy.zeros", "learning_rule.norm_constraint", "theano.sqrt", "theano.sqrt"], "methods", ["home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.norm_constraint"], ["", "def", "get_updates", "(", "self", ",", "learning_rate", ",", "params", ",", "grads", ",", "lr_scalers", ")", ":", "\n", "        ", "\"\"\"Compute the parameters' updates.\n\n        \"\"\"", "\n", "t_prev", "=", "theano", ".", "shared", "(", "floatX", "(", "0.", ")", ")", "\n", "updates", "=", "OrderedDict", "(", ")", "\n", "\n", "# Using theano constant to prevent upcasting of float32", "\n", "one", "=", "T", ".", "constant", "(", "1", ")", "\n", "\n", "t", "=", "t_prev", "+", "1", "\n", "a_t", "=", "learning_rate", "*", "T", ".", "sqrt", "(", "one", "-", "self", ".", "beta2", "**", "t", ")", "/", "(", "one", "-", "self", ".", "beta1", "**", "t", ")", "\n", "\n", "for", "param", ",", "g_t", "in", "zip", "(", "params", ",", "grads", ")", ":", "\n", "            ", "value", "=", "param", ".", "get_value", "(", "borrow", "=", "True", ")", "\n", "m_prev", "=", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "value", ".", "shape", ",", "dtype", "=", "value", ".", "dtype", ")", ",", "\n", "broadcastable", "=", "param", ".", "broadcastable", ")", "\n", "v_prev", "=", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "value", ".", "shape", ",", "dtype", "=", "value", ".", "dtype", ")", ",", "\n", "broadcastable", "=", "param", ".", "broadcastable", ")", "\n", "\n", "m_t", "=", "self", ".", "beta1", "*", "m_prev", "+", "(", "one", "-", "self", ".", "beta1", ")", "*", "g_t", "\n", "v_t", "=", "self", ".", "beta2", "*", "v_prev", "+", "(", "one", "-", "self", ".", "beta2", ")", "*", "g_t", "**", "2", "\n", "step", "=", "a_t", "*", "m_t", "/", "(", "T", ".", "sqrt", "(", "v_t", ")", "+", "self", ".", "epsilon", ")", "\n", "\n", "updates", "[", "m_prev", "]", "=", "m_t", "\n", "updates", "[", "v_prev", "]", "=", "v_t", "\n", "new_param", "=", "param", "-", "step", "\n", "if", "self", ".", "max_colm_norm", "and", "param", ".", "name", "in", "[", "\"W\"", ",", "\"w\"", "]", ":", "\n", "                ", "new_param_final", "=", "norm_constraint", "(", "tensor_var", "=", "new_param", ",", "\n", "max_norm", "=", "self", ".", "max_norm", ")", "\n", "", "else", ":", "\n", "                ", "new_param_final", "=", "new_param", "\n", "", "updates", "[", "param", "]", "=", "new_param_final", "\n", "\n", "", "updates", "[", "t_prev", "]", "=", "t", "\n", "\n", "return", "updates", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.Adamax.__init__": [[555, 562], ["sop_embed.tools.sharedX_value", "sop_embed.tools.sharedX_value", "sop_embed.tools.sharedX_value"], "methods", ["home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.extra.sharedX_value", "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.extra.sharedX_value", "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.extra.sharedX_value"], ["def", "__init__", "(", "self", ",", "beta1", "=", "0.9", ",", "beta2", "=", "0.999", ",", "epsilon", "=", "1e-8", ",", "\n", "max_colm_norm", "=", "False", ",", "max_norm", "=", "15.0", ")", ":", "\n", "        ", "self", ".", "beta1", "=", "sharedX_value", "(", "beta1", ",", "name", "=", "'beta1'", ",", "borrow", "=", "True", ")", "\n", "self", ".", "beta2", "=", "sharedX_value", "(", "beta2", ",", "name", "=", "'beta2'", ",", "borrow", "=", "True", ")", "\n", "self", ".", "epsilon", "=", "sharedX_value", "(", "epsilon", ",", "name", "=", "'epsilon'", ",", "borrow", "=", "True", ")", "\n", "self", ".", "max_colm_norm", "=", "max_colm_norm", "\n", "self", ".", "max_norm", "=", "max_norm", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.Adamax.get_updates": [[563, 600], ["theano.shared", "theano.shared", "theano.shared", "theano.shared", "collections.OrderedDict", "theano.constant", "theano.constant", "zip", "sop_embed.tools.floatX", "param.get_value", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.shared", "theano.maximum", "theano.maximum", "numpy.zeros", "numpy.zeros", "abs", "learning_rule.norm_constraint"], "methods", ["home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.norm_constraint"], ["", "def", "get_updates", "(", "self", ",", "learning_rate", ",", "params", ",", "grads", ",", "lr_scalers", ")", ":", "\n", "        ", "\"\"\"Compute the parameters' updates.\n\n        \"\"\"", "\n", "t_prev", "=", "theano", ".", "shared", "(", "floatX", "(", "0.", ")", ")", "\n", "updates", "=", "OrderedDict", "(", ")", "\n", "\n", "# Using theano constant to prevent upcasting of float32", "\n", "one", "=", "T", ".", "constant", "(", "1", ")", "\n", "\n", "t", "=", "t_prev", "+", "1", "\n", "a_t", "=", "learning_rate", "/", "(", "one", "-", "self", ".", "beta1", "**", "t", ")", "\n", "\n", "for", "param", ",", "g_t", "in", "zip", "(", "params", ",", "grads", ")", ":", "\n", "            ", "value", "=", "param", ".", "get_value", "(", "borrow", "=", "True", ")", "\n", "m_prev", "=", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "value", ".", "shape", ",", "dtype", "=", "value", ".", "dtype", ")", ",", "\n", "broadcastable", "=", "param", ".", "broadcastable", ")", "\n", "u_prev", "=", "theano", ".", "shared", "(", "np", ".", "zeros", "(", "value", ".", "shape", ",", "dtype", "=", "value", ".", "dtype", ")", ",", "\n", "broadcastable", "=", "param", ".", "broadcastable", ")", "\n", "\n", "m_t", "=", "self", ".", "beta1", "*", "m_prev", "+", "(", "one", "-", "self", ".", "beta1", ")", "*", "g_t", "\n", "u_t", "=", "T", ".", "maximum", "(", "self", ".", "beta2", "*", "u_prev", ",", "abs", "(", "g_t", ")", ")", "\n", "step", "=", "a_t", "*", "m_t", "/", "(", "u_t", "+", "self", ".", "epsilon", ")", "\n", "\n", "updates", "[", "m_prev", "]", "=", "m_t", "\n", "updates", "[", "u_prev", "]", "=", "u_t", "\n", "new_param", "=", "param", "-", "step", "\n", "if", "self", ".", "max_colm_norm", "and", "param", ".", "name", "in", "[", "\"W\"", ",", "\"w\"", "]", ":", "\n", "                ", "new_param_final", "=", "norm_constraint", "(", "tensor_var", "=", "new_param", ",", "\n", "max_norm", "=", "self", ".", "max_norm", ")", "\n", "", "else", ":", "\n", "                ", "new_param_final", "=", "new_param", "\n", "", "updates", "[", "param", "]", "=", "new_param_final", "\n", "\n", "", "updates", "[", "t_prev", "]", "=", "t", "\n", "\n", "return", "updates", "\n", "", "", ""]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.sop_embed.learning_rule.norm_constraint": [[16, 84], ["theano.sqrt", "theano.clip", "tuple", "numpy.dtype", "theano.sum", "dtype", "theano.sqr", "tuple", "ValueError", "dtype", "range"], "function", ["None"], ["def", "norm_constraint", "(", "tensor_var", ",", "max_norm", ",", "norm_axes", "=", "None", ",", "epsilon", "=", "1e-7", ")", ":", "\n", "    ", "\"\"\"Max weight norm constraints and gradient clipping\n\n    This takes a TensorVariable and rescales it so that incoming weight\n    norms are below a specified constraint value. Vectors violating the\n    constraint are rescaled so that they are within the allowed range.\n\n    Parameters\n    ----------\n    tensor_var : TensorVariable\n        Theano expression for update, gradient, or other quantity.\n    max_norm : scalar\n        This value sets the maximum allowed value of any norm in\n        `tensor_var`.\n    norm_axes : sequence (list or tuple)\n        The axes over which to compute the norm.  This overrides the\n        default norm axes defined for the number of dimensions\n        in `tensor_var`. When this is not specified and `tensor_var` is a\n        matrix (2D), this is set to `(0,)`. If `tensor_var` is a 3D, 4D or\n        5D tensor, it is set to a tuple listing all axes but axis 0. The\n        former default is useful for working with dense layers, the latter\n        is useful for 1D, 2D and 3D convolutional layers.\n        (Optional)\n    epsilon : scalar, optional\n        Value used to prevent numerical instability when dividing by\n        very small or zero norms.\n\n    Credit:\n        https://github.com/Lasagne/Lasagne/blob/master/lasagne/updates.py\n\n    Returns\n    -------\n    TensorVariable\n        Input `tensor_var` with rescaling applied to weight vectors\n        that violate the specified constraints.\n\n\n    Notes\n    -----\n    When `norm_axes` is not specified, the axes over which the norm is\n    computed depend on the dimensionality of the input variable. If it is\n    2D, it is assumed to come from a dense layer, and the norm is computed\n    over axis 0. If it is 3D, 4D or 5D, it is assumed to come from a\n    convolutional layer and the norm is computed over all trailing axes\n    beyond axis 0. For other uses, you should explicitly specify the axes\n    over which to compute the norm using `norm_axes`.\n    \"\"\"", "\n", "ndim", "=", "tensor_var", ".", "ndim", "\n", "\n", "if", "norm_axes", "is", "not", "None", ":", "\n", "        ", "sum_over", "=", "tuple", "(", "norm_axes", ")", "\n", "", "elif", "ndim", "==", "2", ":", "# DenseLayer", "\n", "        ", "sum_over", "=", "(", "0", ",", ")", "\n", "", "elif", "ndim", "in", "[", "3", ",", "4", ",", "5", "]", ":", "# Conv{1,2,3}DLayer", "\n", "        ", "sum_over", "=", "tuple", "(", "range", "(", "1", ",", "ndim", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Unsupported tensor dimensionality {}.\"", "\n", "\"Must specify `norm_axes`\"", ".", "format", "(", "ndim", ")", "\n", ")", "\n", "\n", "", "dtype", "=", "np", ".", "dtype", "(", "theano", ".", "config", ".", "floatX", ")", ".", "type", "\n", "norms", "=", "T", ".", "sqrt", "(", "T", ".", "sum", "(", "T", ".", "sqr", "(", "tensor_var", ")", ",", "axis", "=", "sum_over", ",", "keepdims", "=", "True", ")", ")", "\n", "target_norms", "=", "T", ".", "clip", "(", "norms", ",", "0", ",", "dtype", "(", "max_norm", ")", ")", "\n", "constrained_output", "=", "(", "tensor_var", "*", "(", "target_norms", "/", "(", "dtype", "(", "epsilon", ")", "+", "norms", ")", ")", ")", "\n", "\n", "return", "constrained_output", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.experiments.plot_cdfs.superpose": [[6, 32], ["numpy.arange", "matplotlib.ioff", "matplotlib.figure", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.xticks", "matplotlib.grid", "matplotlib.legend", "plt.figure.suptitle", "matplotlib.xlabel", "matplotlib.ylabel", "plt.figure.savefig", "matplotlib.ion", "matplotlib.plot", "str", "str", "str", "numpy.float"], "function", ["None"], ["def", "superpose", "(", "cdfs", ",", "outputpath", ",", "data", ")", ":", "\n", "    ", "border_x", "=", "0.5", "\n", "dx", "=", "0.001", "\n", "x", "=", "np", ".", "arange", "(", "0", ",", "border_x", ",", "dx", ")", "\n", "plt", ".", "ioff", "(", ")", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "8", ")", ")", "\n", "plt", ".", "xticks", "(", "[", "0.01", ",", "0.02", ",", "0.05", ",", "0.07", ",", "0.09", ",", "0.1", ",", "0.15", ",", "0.2", ",", "0.25", ",", "0.3", ",", "0.35", ",", "0.4", ",", "0.45", ",", "0.5", "]", ")", "\n", "plt", ".", "yticks", "(", "[", "0.1", ",", "0.2", ",", "0.3", ",", "0.4", ",", "0.45", ",", "0.5", ",", "0.55", ",", "0.6", ",", "0.65", ",", "0.7", ",", "0.75", ",", "0.8", ",", "0.85", ",", "0.9", ",", "0.95", ",", "1.0", "]", ")", "\n", "plt", ".", "xticks", "(", "rotation", "=", "70", ")", "\n", "plt", ".", "grid", "(", "b", "=", "True", ",", "which", "=", "'major'", ",", "axis", "=", "'both'", ",", "linestyle", "=", "'dotted'", ")", "\n", "floating", "=", "3", "\n", "prec", "=", "\"%.\"", "+", "str", "(", "floating", ")", "+", "\"f\"", "\n", "for", "cdf", "in", "cdfs", ":", "\n", "        ", "title", "=", "cdf", "[", "\"title\"", "]", "\n", "auc", "=", "cdf", "[", "\"auc\"", "]", "\n", "cdf01", "=", "cdf", "[", "\"cdf01\"", "]", "\n", "cdf_val", "=", "cdf", "[", "\"cdf\"", "]", "\n", "plt", ".", "plot", "(", "x", ",", "cdf_val", ",", "marker", "=", "','", ",", "\n", "label", "=", "title", "+", "\", CDF(0.1)=\"", "+", "str", "(", "prec", "%", "(", "cdf01", "*", "100", ")", ")", "+", "\"%, AUC=\"", "+", "\n", "str", "(", "prec", "%", "np", ".", "float", "(", "auc", ")", ")", "+", "\"%\"", ")", "\n", "", "plt", ".", "legend", "(", "loc", "=", "4", ",", "prop", "=", "{", "'size'", ":", "8", "}", ",", "fancybox", "=", "True", ",", "shadow", "=", "True", ")", "\n", "fig", ".", "suptitle", "(", "'Cumulative distribution function (CDF) of NRMSE over '", "+", "data", "+", "' test set.'", ")", "\n", "plt", ".", "xlabel", "(", "'NRMSE'", ")", "\n", "plt", ".", "ylabel", "(", "'Data proportion'", ")", "\n", "fig", ".", "savefig", "(", "outputpath", ",", "bbox_inches", "=", "'tight'", ",", "format", "=", "'eps'", ",", "dpi", "=", "1000", ")", "\n", "plt", ".", "ion", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbelharbi_structured-output-ae.experiments.plot_cdfs.format_it": [[34, 48], ["open", "cPickle.load"], "function", ["None"], ["", "def", "format_it", "(", "path", ",", "title", ")", ":", "\n", "    ", "with", "open", "(", "path", "+", "\"/errors.pkl\"", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "stuff", "=", "pkl", ".", "load", "(", "f", ")", "\n", "auc", "=", "stuff", "[", "\"auc\"", "]", "\n", "cdf", "=", "stuff", "[", "\"cdf\"", "]", "\n", "cdf01", "=", "stuff", "[", "\"cdf0_1\"", "]", "\n", "model_cdf", "=", "{", "\"auc\"", ":", "auc", ",", "\"cdf\"", ":", "cdf", ",", "\"cdf01\"", ":", "cdf01", ",", "\"title\"", ":", "title", "}", "\n", "# mean shape", "\n", "auc_ms", "=", "stuff", "[", "\"auc_ms\"", "]", "\n", "cdf_ms", "=", "stuff", "[", "\"cdf_ms\"", "]", "\n", "cdf01_ms", "=", "stuff", "[", "\"cdf0_1_ms\"", "]", "\n", "ms_cdf", "=", "{", "\"auc\"", ":", "auc_ms", ",", "\"cdf\"", ":", "cdf_ms", ",", "\"cdf01\"", ":", "cdf01_ms", ",", "\n", "\"title\"", ":", "\"CDF NRMSE mean shape\"", "}", "\n", "return", "model_cdf", ",", "ms_cdf", "\n", "\n"]]}