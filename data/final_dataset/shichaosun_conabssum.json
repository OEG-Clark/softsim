{"home.repos.pwc.inspect_result.shichaosun_conabssum.src.consum.ConSumModule.__init__": [[23, 29], ["finetune.SummarizationModule.__init__"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hparams", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "hparams", ",", "**", "kwargs", ")", "\n", "self", ".", "loss_length_penalty", "=", "hparams", ".", "loss_length_penalty", "\n", "self", ".", "margin_value", "=", "hparams", ".", "margin_value", "\n", "self", ".", "a", "=", "hparams", ".", "a", "\n", "self", ".", "b", "=", "hparams", ".", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.consum.ConSumModule.cal_loss": [[32, 74], ["torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax.gather", "torch.nn.functional.log_softmax.gather", "p_tgt_ids.unsqueeze.unsqueeze.eq", "n_tgt_ids.unsqueeze.unsqueeze.eq", "p_logprobs.squeeze.squeeze.masked_fill_", "n_logprobs.squeeze.squeeze.masked_fill_", "p_logprobs.squeeze.squeeze.squeeze", "n_logprobs.squeeze.squeeze.squeeze", "p_pad_mask.squeeze.squeeze.squeeze", "n_pad_mask.squeeze.squeeze.squeeze", "p_logprobs.squeeze.squeeze.sum", "n_logprobs.squeeze.squeeze.sum", "torch.nn.functional.relu", "loss.mean.mean.mean", "p_tgt_ids.unsqueeze.unsqueeze.dim", "p_tgt_ids.unsqueeze.unsqueeze.unsqueeze", "n_tgt_ids.unsqueeze.unsqueeze.dim", "n_tgt_ids.unsqueeze.unsqueeze.unsqueeze", "p_tgt_ids.unsqueeze.unsqueeze.size", "p_pad_mask.squeeze.squeeze.sum", "n_tgt_ids.unsqueeze.unsqueeze.size", "n_pad_mask.squeeze.squeeze.sum", "torch.nn.functional.log_softmax.dim", "torch.nn.functional.log_softmax.dim", "p_score.mean", "n_score.mean"], "methods", ["None"], ["", "def", "cal_loss", "(", "self", ",", "p_lm_logits", ",", "n_lm_logits", ",", "p_tgt_ids", ",", "n_tgt_ids", ")", ":", "\n", "        ", "p_lodprobs", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "p_lm_logits", ",", "dim", "=", "-", "1", ")", "\n", "n_lodprobs", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "n_lm_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "p_tgt_ids", ".", "dim", "(", ")", "==", "p_lodprobs", ".", "dim", "(", ")", "-", "1", ":", "\n", "            ", "p_tgt_ids", "=", "p_tgt_ids", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "if", "n_tgt_ids", ".", "dim", "(", ")", "==", "n_lodprobs", ".", "dim", "(", ")", "-", "1", ":", "\n", "            ", "n_tgt_ids", "=", "n_tgt_ids", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "", "p_logprobs", "=", "p_lodprobs", ".", "gather", "(", "dim", "=", "-", "1", ",", "index", "=", "p_tgt_ids", ")", "\n", "n_logprobs", "=", "n_lodprobs", ".", "gather", "(", "dim", "=", "-", "1", ",", "index", "=", "n_tgt_ids", ")", "\n", "\n", "p_pad_mask", "=", "p_tgt_ids", ".", "eq", "(", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "n_pad_mask", "=", "n_tgt_ids", ".", "eq", "(", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "\n", "p_logprobs", ".", "masked_fill_", "(", "p_pad_mask", ",", "0.0", ")", "\n", "n_logprobs", ".", "masked_fill_", "(", "n_pad_mask", ",", "0.0", ")", "\n", "\n", "p_logprobs", "=", "p_logprobs", ".", "squeeze", "(", "-", "1", ")", "\n", "n_logprobs", "=", "n_logprobs", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "p_pad_mask", "=", "p_pad_mask", ".", "squeeze", "(", "-", "1", ")", "\n", "n_pad_mask", "=", "n_pad_mask", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "p_sum_logprobs", "=", "p_logprobs", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "n_sum_logprobs", "=", "n_logprobs", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "\n", "p_length", "=", "p_tgt_ids", ".", "size", "(", "1", ")", "-", "p_pad_mask", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "n_length", "=", "n_tgt_ids", ".", "size", "(", "1", ")", "-", "n_pad_mask", ".", "sum", "(", "dim", "=", "-", "1", ")", "\n", "\n", "p_score", "=", "p_sum_logprobs", "/", "(", "p_length", "**", "self", ".", "loss_length_penalty", ")", "\n", "n_score", "=", "n_sum_logprobs", "/", "(", "n_length", "**", "self", ".", "loss_length_penalty", ")", "\n", "\n", "ce_loss", "=", "-", "p_sum_logprobs", "/", "p_length", "\n", "\n", "con_loss", "=", "torch", ".", "nn", ".", "functional", ".", "relu", "(", "n_score", "-", "p_score", "+", "self", ".", "margin_value", ")", "\n", "\n", "loss", "=", "con_loss", "*", "self", ".", "a", "+", "ce_loss", "*", "self", ".", "b", "\n", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "\n", "return", "loss", ",", "-", "p_score", ".", "mean", "(", ")", ",", "-", "n_score", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.consum.ConSumModule.add_model_specific_args": [[75, 80], ["finetune.SummarizationModule.add_model_specific_args", "consum.add_contrastive_args"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.add_model_specific_args", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.consum.add_contrastive_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parser", ",", "root_dir", ")", ":", "\n", "        ", "SummarizationModule", ".", "add_model_specific_args", "(", "parser", ",", "root_dir", ")", "\n", "add_contrastive_args", "(", "parser", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.consum.ConSumModule.calculate_lm_logits": [[81, 86], ["transformers.models.bart.modeling_bart.shift_tokens_right", "consum.ConSumModule."], "methods", ["None"], ["", "def", "calculate_lm_logits", "(", "self", ",", "src_ids", ",", "src_mask", ",", "tgt_ids", ")", ":", "\n", "        ", "pad_token_id", "=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "decoder_input_ids", "=", "shift_tokens_right", "(", "tgt_ids", ",", "pad_token_id", ")", "\n", "outputs", "=", "self", "(", "src_ids", ",", "attention_mask", "=", "src_mask", ",", "decoder_input_ids", "=", "decoder_input_ids", ",", "use_cache", "=", "False", ")", "\n", "return", "outputs", "[", "\"logits\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.consum.ConSumModule.training_step": [[87, 112], ["consum.ConSumModule.model.eval", "consum.ConSumModule.model.generate", "consum.ConSumModule.model.train", "consum.ConSumModule.calculate_lm_logits", "consum.ConSumModule.calculate_lm_logits", "consum.ConSumModule.cal_loss", "zip"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.consum.ConSumModule.calculate_lm_logits", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.consum.ConSumModule.calculate_lm_logits", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.consum.ConSumModule.cal_loss"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", "->", "Dict", ":", "\n", "        ", "src_ids", ",", "src_mask", "=", "batch", "[", "\"input_ids\"", "]", ",", "batch", "[", "\"attention_mask\"", "]", "\n", "tgt_ids", "=", "batch", "[", "\"labels\"", "]", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "silver_tgt_ids", "=", "self", ".", "model", ".", "generate", "(", "\n", "src_ids", ",", "\n", "attention_mask", "=", "src_mask", ",", "\n", "use_cache", "=", "True", ",", "\n", "decoder_start_token_id", "=", "self", ".", "decoder_start_token_id", ",", "\n", "num_beams", "=", "1", ",", "\n", "max_length", "=", "self", ".", "eval_max_length", ",", "\n", ")", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "\n", "p_lm_logits", "=", "self", ".", "calculate_lm_logits", "(", "src_ids", ",", "src_mask", ",", "tgt_ids", ")", "\n", "n_lm_logits", "=", "self", ".", "calculate_lm_logits", "(", "src_ids", ",", "src_mask", ",", "silver_tgt_ids", ")", "\n", "\n", "loss", ",", "p_loss", ",", "n_loss", "=", "self", ".", "cal_loss", "(", "p_lm_logits", ",", "n_lm_logits", ",", "tgt_ids", ",", "silver_tgt_ids", ")", "\n", "\n", "loss_tensors", "=", "(", "loss", ",", ")", "\n", "\n", "logs", "=", "{", "name", ":", "loss", "for", "name", ",", "loss", "in", "zip", "(", "self", ".", "loss_names", ",", "loss_tensors", ")", "}", "\n", "logs", "[", "\"p_loss\"", "]", "=", "p_loss", "\n", "logs", "[", "\"n_loss\"", "]", "=", "n_loss", "\n", "return", "{", "\"loss\"", ":", "loss_tensors", "[", "0", "]", ",", "\"log\"", ":", "logs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.consum.add_contrastive_args": [[114, 119], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "", "def", "add_contrastive_args", "(", "parser", ")", ":", "\n", "    ", "parser", ".", "add_argument", "(", "\"--loss_length_penalty\"", ",", "default", "=", "0.6", ",", "type", "=", "float", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--margin_value\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--a\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--b\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "required", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.__init__": [[53, 114], ["lightning_base.BaseTransformer.__init__", "utils.use_task_specific_params", "utils.pickle_save", "collections.defaultdict", "dict", "pathlib.Path", "pathlib.Path", "utils.freeze_embeds", "utils.freeze_params", "utils.assert_all_frozen", "isinstance", "hasattr", "n_observations_per_split.items", "finetune.SummarizationModule.model.get_encoder", "finetune.SummarizationModule.model.get_encoder", "NotImplementedError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.__init__", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.use_task_specific_params", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.pickle_save", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.freeze_embeds", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.freeze_params", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.assert_all_frozen"], ["def", "__init__", "(", "self", ",", "hparams", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "hparams", ".", "sortish_sampler", "and", "hparams", ".", "gpus", ">", "1", ":", "\n", "            ", "hparams", ".", "replace_sampler_ddp", "=", "False", "\n", "", "elif", "hparams", ".", "max_tokens_per_batch", "is", "not", "None", ":", "\n", "            ", "if", "hparams", ".", "gpus", ">", "1", ":", "\n", "                ", "raise", "NotImplementedError", "(", "\"Dynamic Batch size does not work for multi-gpu training\"", ")", "\n", "", "if", "hparams", ".", "sortish_sampler", ":", "\n", "                ", "raise", "ValueError", "(", "\"--sortish_sampler and --max_tokens_per_batch may not be used simultaneously\"", ")", "\n", "\n", "", "", "super", "(", ")", ".", "__init__", "(", "hparams", ",", "num_labels", "=", "None", ",", "mode", "=", "self", ".", "mode", ",", "**", "kwargs", ")", "\n", "use_task_specific_params", "(", "self", ".", "model", ",", "\"summarization\"", ")", "\n", "# save_git_info(self.hparams.output_dir)", "\n", "self", ".", "metrics_save_path", "=", "Path", "(", "self", ".", "output_dir", ")", "/", "\"metrics.json\"", "\n", "self", ".", "hparams_save_path", "=", "Path", "(", "self", ".", "output_dir", ")", "/", "\"hparams.pkl\"", "\n", "pickle_save", "(", "self", ".", "hparams", ",", "self", ".", "hparams_save_path", ")", "\n", "self", ".", "step_count", "=", "0", "\n", "self", ".", "metrics", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "model_type", "=", "self", ".", "config", ".", "model_type", "\n", "self", ".", "vocab_size", "=", "self", ".", "config", ".", "tgt_vocab_size", "if", "self", ".", "model_type", "==", "\"fsmt\"", "else", "self", ".", "config", ".", "vocab_size", "\n", "\n", "self", ".", "dataset_kwargs", ":", "dict", "=", "dict", "(", "\n", "data_dir", "=", "self", ".", "hparams", ".", "data_dir", ",", "\n", "max_source_length", "=", "self", ".", "hparams", ".", "max_source_length", ",", "\n", "prefix", "=", "self", ".", "model", ".", "config", ".", "prefix", "or", "\"\"", ",", "\n", ")", "\n", "n_observations_per_split", "=", "{", "\n", "\"train\"", ":", "self", ".", "hparams", ".", "n_train", ",", "\n", "\"val\"", ":", "self", ".", "hparams", ".", "n_val", ",", "\n", "\"test\"", ":", "self", ".", "hparams", ".", "n_test", ",", "\n", "}", "\n", "self", ".", "n_obs", "=", "{", "k", ":", "v", "if", "v", ">=", "0", "else", "None", "for", "k", ",", "v", "in", "n_observations_per_split", ".", "items", "(", ")", "}", "\n", "\n", "self", ".", "target_lens", "=", "{", "\n", "\"train\"", ":", "self", ".", "hparams", ".", "max_target_length", ",", "\n", "\"val\"", ":", "self", ".", "hparams", ".", "val_max_target_length", ",", "\n", "\"test\"", ":", "self", ".", "hparams", ".", "test_max_target_length", ",", "\n", "}", "\n", "assert", "self", ".", "target_lens", "[", "\"train\"", "]", "<=", "self", ".", "target_lens", "[", "\"val\"", "]", ",", "f\"target_lens: {self.target_lens}\"", "\n", "assert", "self", ".", "target_lens", "[", "\"train\"", "]", "<=", "self", ".", "target_lens", "[", "\"test\"", "]", ",", "f\"target_lens: {self.target_lens}\"", "\n", "if", "self", ".", "hparams", ".", "freeze_embeds", ":", "\n", "            ", "freeze_embeds", "(", "self", ".", "model", ")", "\n", "", "if", "self", ".", "hparams", ".", "freeze_encoder", ":", "\n", "            ", "freeze_params", "(", "self", ".", "model", ".", "get_encoder", "(", ")", ")", "\n", "assert_all_frozen", "(", "self", ".", "model", ".", "get_encoder", "(", ")", ")", "\n", "\n", "# self.hparams.git_sha = get_git_info()[\"repo_sha\"]", "\n", "", "self", ".", "num_workers", "=", "hparams", ".", "num_workers", "\n", "self", ".", "decoder_start_token_id", "=", "None", "# default to config", "\n", "if", "self", ".", "model", ".", "config", ".", "decoder_start_token_id", "is", "None", "and", "isinstance", "(", "self", ".", "tokenizer", ",", "MBartTokenizer", ")", ":", "\n", "            ", "self", ".", "decoder_start_token_id", "=", "self", ".", "tokenizer", ".", "lang_code_to_id", "[", "hparams", ".", "tgt_lang", "]", "\n", "self", ".", "model", ".", "config", ".", "decoder_start_token_id", "=", "self", ".", "decoder_start_token_id", "\n", "", "self", ".", "dataset_class", "=", "(", "\n", "Seq2SeqDataset", "if", "hasattr", "(", "self", ".", "tokenizer", ",", "\"prepare_seq2seq_batch\"", ")", "else", "LegacySeq2SeqDataset", "\n", ")", "\n", "self", ".", "already_saved_batch", "=", "False", "\n", "self", ".", "eval_beams", "=", "self", ".", "model", ".", "config", ".", "num_beams", "if", "self", ".", "hparams", ".", "eval_beams", "is", "None", "else", "self", ".", "hparams", ".", "eval_beams", "\n", "if", "self", ".", "hparams", ".", "eval_max_gen_length", "is", "not", "None", ":", "\n", "            ", "self", ".", "eval_max_length", "=", "self", ".", "hparams", ".", "eval_max_gen_length", "\n", "", "else", ":", "\n", "            ", "self", ".", "eval_max_length", "=", "self", ".", "model", ".", "config", ".", "max_length", "\n", "", "self", ".", "val_metric", "=", "self", ".", "default_val_metric", "if", "self", ".", "hparams", ".", "val_metric", "is", "None", "else", "self", ".", "hparams", ".", "val_metric", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.save_readable_batch": [[115, 125], ["utils.save_json", "utils.save_json", "finetune.SummarizationModule.tokenizer.batch_decode", "batch.items", "pathlib.Path", "v.tolist", "pathlib.Path", "v.tolist", "batch.items"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.save_json", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.save_json"], ["", "def", "save_readable_batch", "(", "self", ",", "batch", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ")", "->", "Dict", "[", "str", ",", "List", "[", "str", "]", "]", ":", "\n", "        ", "\"\"\"A debugging utility\"\"\"", "\n", "readable_batch", "=", "{", "\n", "k", ":", "self", ".", "tokenizer", ".", "batch_decode", "(", "v", ".", "tolist", "(", ")", ")", "if", "\"mask\"", "not", "in", "k", "else", "v", ".", "shape", "for", "k", ",", "v", "in", "batch", ".", "items", "(", ")", "\n", "}", "\n", "save_json", "(", "readable_batch", ",", "Path", "(", "self", ".", "output_dir", ")", "/", "\"text_batch.json\"", ")", "\n", "save_json", "(", "{", "k", ":", "v", ".", "tolist", "(", ")", "for", "k", ",", "v", "in", "batch", ".", "items", "(", ")", "}", ",", "Path", "(", "self", ".", "output_dir", ")", "/", "\"tok_batch.json\"", ")", "\n", "\n", "self", ".", "already_saved_batch", "=", "True", "\n", "return", "readable_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.forward": [[126, 128], ["finetune.SummarizationModule.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "model", "(", "input_ids", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.ids_to_clean_text": [[129, 134], ["finetune.SummarizationModule.tokenizer.batch_decode", "utils.lmap"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.lmap"], ["", "def", "ids_to_clean_text", "(", "self", ",", "generated_ids", ":", "List", "[", "int", "]", ")", ":", "\n", "        ", "gen_text", "=", "self", ".", "tokenizer", ".", "batch_decode", "(", "\n", "generated_ids", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "True", "\n", ")", "\n", "return", "lmap", "(", "str", ".", "strip", ",", "gen_text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule._step": [[135, 161], ["isinstance", "finetune.SummarizationModule.", "finetune.SummarizationModule.model._shift_right", "transformers.models.bart.modeling_bart.shift_tokens_right", "finetune.SummarizationModule.save_readable_batch", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.functional.log_softmax", "utils.label_smoothed_nll_loss", "lm_logits.view", "tgt_ids.view"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.save_readable_batch", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.label_smoothed_nll_loss"], ["", "def", "_step", "(", "self", ",", "batch", ":", "dict", ")", "->", "Tuple", ":", "\n", "        ", "pad_token_id", "=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "src_ids", ",", "src_mask", "=", "batch", "[", "\"input_ids\"", "]", ",", "batch", "[", "\"attention_mask\"", "]", "\n", "tgt_ids", "=", "batch", "[", "\"labels\"", "]", "\n", "if", "isinstance", "(", "self", ".", "model", ",", "T5ForConditionalGeneration", ")", ":", "\n", "            ", "decoder_input_ids", "=", "self", ".", "model", ".", "_shift_right", "(", "tgt_ids", ")", "\n", "", "else", ":", "\n", "            ", "decoder_input_ids", "=", "shift_tokens_right", "(", "tgt_ids", ",", "pad_token_id", ")", "\n", "", "if", "not", "self", ".", "already_saved_batch", ":", "# This would be slightly better if it only happened on rank zero", "\n", "            ", "batch", "[", "\"decoder_input_ids\"", "]", "=", "decoder_input_ids", "\n", "self", ".", "save_readable_batch", "(", "batch", ")", "\n", "\n", "", "outputs", "=", "self", "(", "src_ids", ",", "attention_mask", "=", "src_mask", ",", "decoder_input_ids", "=", "decoder_input_ids", ",", "use_cache", "=", "False", ")", "\n", "lm_logits", "=", "outputs", "[", "\"logits\"", "]", "\n", "if", "self", ".", "hparams", ".", "label_smoothing", "==", "0", ":", "\n", "# Same behavior as modeling_bart.py, besides ignoring pad_token_id", "\n", "            ", "ce_loss_fct", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "ignore_index", "=", "pad_token_id", ")", "\n", "\n", "assert", "lm_logits", ".", "shape", "[", "-", "1", "]", "==", "self", ".", "vocab_size", "\n", "loss", "=", "ce_loss_fct", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "lm_logits", ".", "shape", "[", "-", "1", "]", ")", ",", "tgt_ids", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "lprobs", "=", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "lm_logits", ",", "dim", "=", "-", "1", ")", "\n", "loss", ",", "nll_loss", "=", "label_smoothed_nll_loss", "(", "\n", "lprobs", ",", "tgt_ids", ",", "self", ".", "hparams", ".", "label_smoothing", ",", "ignore_index", "=", "pad_token_id", "\n", ")", "\n", "", "return", "(", "loss", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.pad": [[162, 165], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "pad", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.training_step": [[166, 177], ["finetune.SummarizationModule._step", "batch[].eq().sum", "batch[].eq().float().mean", "batch[].ne().sum", "batch[].ne().sum", "zip", "batch[].eq", "batch[].eq().float", "batch[].ne", "batch[].ne", "batch[].eq"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule._step"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", "->", "Dict", ":", "\n", "        ", "loss_tensors", "=", "self", ".", "_step", "(", "batch", ")", "\n", "\n", "logs", "=", "{", "name", ":", "loss", "for", "name", ",", "loss", "in", "zip", "(", "self", ".", "loss_names", ",", "loss_tensors", ")", "}", "\n", "# tokens per batch", "\n", "logs", "[", "\"tpb\"", "]", "=", "batch", "[", "\"input_ids\"", "]", ".", "ne", "(", "self", ".", "pad", ")", ".", "sum", "(", ")", "+", "batch", "[", "\"labels\"", "]", ".", "ne", "(", "self", ".", "pad", ")", ".", "sum", "(", ")", "\n", "logs", "[", "\"bs\"", "]", "=", "batch", "[", "\"input_ids\"", "]", ".", "shape", "[", "0", "]", "\n", "logs", "[", "\"src_pad_tok\"", "]", "=", "batch", "[", "\"input_ids\"", "]", ".", "eq", "(", "self", ".", "pad", ")", ".", "sum", "(", ")", "\n", "logs", "[", "\"src_pad_frac\"", "]", "=", "batch", "[", "\"input_ids\"", "]", ".", "eq", "(", "self", ".", "pad", ")", ".", "float", "(", ")", ".", "mean", "(", ")", "\n", "# TODO(SS): make a wandb summary metric for this", "\n", "return", "{", "\"loss\"", ":", "loss_tensors", "[", "0", "]", ",", "\"log\"", ":", "logs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.validation_step": [[178, 180], ["finetune.SummarizationModule._generative_step"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule._generative_step"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", "->", "Dict", ":", "\n", "        ", "return", "self", ".", "_generative_step", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.validation_epoch_end": [[181, 203], ["torch.tensor().type_as", "generative_metrics.update", "losses.update", "finetune.SummarizationModule.metrics[].append", "utils.flatten_list", "torch.stack().mean", "numpy.array().mean", "torch.tensor", "v.item", "losses.items", "torch.stack", "numpy.array", "losses.items"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.flatten_list"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ",", "prefix", "=", "\"val\"", ")", "->", "Dict", ":", "\n", "        ", "self", ".", "step_count", "+=", "1", "\n", "losses", "=", "{", "k", ":", "torch", ".", "stack", "(", "[", "x", "[", "k", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "for", "k", "in", "self", ".", "loss_names", "}", "\n", "loss", "=", "losses", "[", "\"loss\"", "]", "\n", "generative_metrics", "=", "{", "\n", "k", ":", "np", ".", "array", "(", "[", "x", "[", "k", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "for", "k", "in", "self", ".", "metric_names", "+", "[", "\"gen_time\"", ",", "\"gen_len\"", "]", "\n", "}", "\n", "metric_val", "=", "(", "\n", "generative_metrics", "[", "self", ".", "val_metric", "]", "if", "self", ".", "val_metric", "in", "generative_metrics", "else", "losses", "[", "self", ".", "val_metric", "]", "\n", ")", "\n", "metric_tensor", ":", "torch", ".", "FloatTensor", "=", "torch", ".", "tensor", "(", "metric_val", ")", ".", "type_as", "(", "loss", ")", "\n", "generative_metrics", ".", "update", "(", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "losses", ".", "items", "(", ")", "}", ")", "\n", "losses", ".", "update", "(", "generative_metrics", ")", "\n", "all_metrics", "=", "{", "f\"{prefix}_avg_{k}\"", ":", "x", "for", "k", ",", "x", "in", "losses", ".", "items", "(", ")", "}", "\n", "all_metrics", "[", "\"step_count\"", "]", "=", "self", ".", "step_count", "\n", "self", ".", "metrics", "[", "prefix", "]", ".", "append", "(", "all_metrics", ")", "# callback writes this to self.metrics_save_path", "\n", "preds", "=", "flatten_list", "(", "[", "x", "[", "\"preds\"", "]", "for", "x", "in", "outputs", "]", ")", "\n", "return", "{", "\n", "\"log\"", ":", "all_metrics", ",", "\n", "\"preds\"", ":", "preds", ",", "\n", "f\"{prefix}_loss\"", ":", "loss", ",", "\n", "f\"{prefix}_{self.val_metric}\"", ":", "metric_tensor", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.calc_generative_metrics": [[205, 207], ["utils.calculate_rouge"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.calculate_rouge"], ["", "def", "calc_generative_metrics", "(", "self", ",", "preds", ",", "target", ")", "->", "Dict", ":", "\n", "        ", "return", "calculate_rouge", "(", "preds", ",", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule._generative_step": [[208, 229], ["time.time", "finetune.SummarizationModule.model.generate", "finetune.SummarizationModule.ids_to_clean_text", "finetune.SummarizationModule.ids_to_clean_text", "finetune.SummarizationModule._step", "finetune.SummarizationModule.calc_generative_metrics", "numpy.mean", "base_metrics.update", "utils.lmap", "time.time", "zip"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.ids_to_clean_text", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.ids_to_clean_text", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule._step", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.TranslationModule.calc_generative_metrics", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.lmap"], ["", "def", "_generative_step", "(", "self", ",", "batch", ":", "dict", ")", "->", "dict", ":", "\n", "        ", "t0", "=", "time", ".", "time", "(", ")", "\n", "\n", "# parser.add_argument('--eval_max_gen_length', type=int, default=None, help='never generate more than n tokens')", "\n", "generated_ids", "=", "self", ".", "model", ".", "generate", "(", "\n", "batch", "[", "\"input_ids\"", "]", ",", "\n", "attention_mask", "=", "batch", "[", "\"attention_mask\"", "]", ",", "\n", "use_cache", "=", "True", ",", "\n", "decoder_start_token_id", "=", "self", ".", "decoder_start_token_id", ",", "\n", "num_beams", "=", "self", ".", "eval_beams", ",", "\n", "max_length", "=", "self", ".", "eval_max_length", ",", "\n", ")", "\n", "gen_time", "=", "(", "time", ".", "time", "(", ")", "-", "t0", ")", "/", "batch", "[", "\"input_ids\"", "]", ".", "shape", "[", "0", "]", "\n", "preds", ":", "List", "[", "str", "]", "=", "self", ".", "ids_to_clean_text", "(", "generated_ids", ")", "\n", "target", ":", "List", "[", "str", "]", "=", "self", ".", "ids_to_clean_text", "(", "batch", "[", "\"labels\"", "]", ")", "\n", "loss_tensors", "=", "self", ".", "_step", "(", "batch", ")", "\n", "base_metrics", "=", "{", "name", ":", "loss", "for", "name", ",", "loss", "in", "zip", "(", "self", ".", "loss_names", ",", "loss_tensors", ")", "}", "\n", "rouge", ":", "Dict", "=", "self", ".", "calc_generative_metrics", "(", "preds", ",", "target", ")", "\n", "summ_len", "=", "np", ".", "mean", "(", "lmap", "(", "len", ",", "generated_ids", ")", ")", "\n", "base_metrics", ".", "update", "(", "gen_time", "=", "gen_time", ",", "gen_len", "=", "summ_len", ",", "preds", "=", "preds", ",", "target", "=", "target", ",", "**", "rouge", ")", "\n", "return", "base_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.test_step": [[230, 232], ["finetune.SummarizationModule._generative_step"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule._generative_step"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "return", "self", ".", "_generative_step", "(", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.test_epoch_end": [[233, 235], ["finetune.SummarizationModule.validation_epoch_end"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.validation_epoch_end"], ["", "def", "test_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "return", "self", ".", "validation_epoch_end", "(", "outputs", ",", "prefix", "=", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.get_dataset": [[236, 247], ["finetune.SummarizationModule.dataset_class"], "methods", ["None"], ["", "def", "get_dataset", "(", "self", ",", "type_path", ")", "->", "Seq2SeqDataset", ":", "\n", "        ", "n_obs", "=", "self", ".", "n_obs", "[", "type_path", "]", "\n", "max_target_length", "=", "self", ".", "target_lens", "[", "type_path", "]", "\n", "dataset", "=", "self", ".", "dataset_class", "(", "\n", "self", ".", "tokenizer", ",", "\n", "type_path", "=", "type_path", ",", "\n", "n_obs", "=", "n_obs", ",", "\n", "max_target_length", "=", "max_target_length", ",", "\n", "**", "self", ".", "dataset_kwargs", ",", "\n", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.get_dataloader": [[248, 282], ["finetune.SummarizationModule.get_dataset", "finetune.SummarizationModule.make_sortish_sampler", "torch.utils.data.DataLoader", "finetune.SummarizationModule.make_dynamic_sampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.get_dataset", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.AbstractSeq2SeqDataset.make_sortish_sampler", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.AbstractSeq2SeqDataset.make_dynamic_sampler"], ["", "def", "get_dataloader", "(", "self", ",", "type_path", ":", "str", ",", "batch_size", ":", "int", ",", "shuffle", ":", "bool", "=", "False", ")", "->", "DataLoader", ":", "\n", "        ", "dataset", "=", "self", ".", "get_dataset", "(", "type_path", ")", "\n", "\n", "if", "self", ".", "hparams", ".", "sortish_sampler", "and", "type_path", "!=", "\"test\"", "and", "type_path", "!=", "\"val\"", ":", "\n", "            ", "sampler", "=", "dataset", ".", "make_sortish_sampler", "(", "batch_size", ",", "distributed", "=", "self", ".", "hparams", ".", "gpus", ">", "1", ")", "\n", "return", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ",", "\n", "shuffle", "=", "False", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "sampler", "=", "sampler", ",", "\n", ")", "\n", "\n", "", "elif", "self", ".", "hparams", ".", "max_tokens_per_batch", "is", "not", "None", "and", "type_path", "!=", "\"test\"", "and", "type_path", "!=", "\"val\"", ":", "\n", "            ", "batch_sampler", "=", "dataset", ".", "make_dynamic_sampler", "(", "\n", "self", ".", "hparams", ".", "max_tokens_per_batch", ",", "distributed", "=", "self", ".", "hparams", ".", "gpus", ">", "1", "\n", ")", "\n", "return", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_sampler", "=", "batch_sampler", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ",", "\n", "# shuffle=False,", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "# batch_size=None,", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "collate_fn", "=", "dataset", ".", "collate_fn", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "num_workers", "=", "self", ".", "num_workers", ",", "\n", "sampler", "=", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.train_dataloader": [[284, 287], ["finetune.SummarizationModule.get_dataloader"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.get_dataloader"], ["", "", "def", "train_dataloader", "(", "self", ")", "->", "DataLoader", ":", "\n", "        ", "dataloader", "=", "self", ".", "get_dataloader", "(", "\"train\"", ",", "batch_size", "=", "self", ".", "hparams", ".", "train_batch_size", ",", "shuffle", "=", "True", ")", "\n", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.val_dataloader": [[288, 290], ["finetune.SummarizationModule.get_dataloader"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.get_dataloader"], ["", "def", "val_dataloader", "(", "self", ")", "->", "DataLoader", ":", "\n", "        ", "return", "self", ".", "get_dataloader", "(", "\"val\"", ",", "batch_size", "=", "self", ".", "hparams", ".", "eval_batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.test_dataloader": [[291, 293], ["finetune.SummarizationModule.get_dataloader"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.get_dataloader"], ["", "def", "test_dataloader", "(", "self", ")", "->", "DataLoader", ":", "\n", "        ", "return", "self", ".", "get_dataloader", "(", "\"test\"", ",", "batch_size", "=", "self", ".", "hparams", ".", "eval_batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.add_model_specific_args": [[294, 355], ["lightning_base.BaseTransformer.add_model_specific_args", "lightning_base.add_generic_args", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.add_model_specific_args", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.add_generic_args"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parser", ",", "root_dir", ")", ":", "\n", "        ", "BaseTransformer", ".", "add_model_specific_args", "(", "parser", ",", "root_dir", ")", "\n", "add_generic_args", "(", "parser", ",", "root_dir", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_source_length\"", ",", "\n", "default", "=", "1024", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_target_length\"", ",", "\n", "default", "=", "56", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--val_max_target_length\"", ",", "\n", "default", "=", "142", ",", "# these defaults are optimized for CNNDM. For xsum, see README.md.", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--test_max_target_length\"", ",", "\n", "default", "=", "142", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--freeze_encoder\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--freeze_embeds\"", ",", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--sortish_sampler\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "default", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_tokens_per_batch\"", ",", "type", "=", "int", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "\"--logger_name\"", ",", "type", "=", "str", ",", "choices", "=", "[", "\"default\"", ",", "\"wandb\"", ",", "\"wandb_shared\"", "]", ",", "default", "=", "\"default\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_train\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "required", "=", "False", ",", "help", "=", "\"# examples. -1 means use all.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_val\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "required", "=", "False", ",", "help", "=", "\"# examples. -1 means use all.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_test\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "required", "=", "False", ",", "help", "=", "\"# examples. -1 means use all.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--task\"", ",", "type", "=", "str", ",", "default", "=", "\"summarization\"", ",", "required", "=", "False", ",", "help", "=", "\"# examples. -1 means use all.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--label_smoothing\"", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--src_lang\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--tgt_lang\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_beams\"", ",", "type", "=", "int", ",", "default", "=", "None", ",", "required", "=", "False", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--val_metric\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "required", "=", "False", ",", "choices", "=", "[", "\"bleu\"", ",", "\"rouge2\"", ",", "\"loss\"", ",", "None", "]", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_max_gen_length\"", ",", "type", "=", "int", ",", "default", "=", "None", ",", "help", "=", "\"never generate more than n tokens\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_top_k\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "required", "=", "False", ",", "help", "=", "\"How many checkpoints to save\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--early_stopping_patience\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "-", "1", ",", "\n", "required", "=", "False", ",", "\n", "help", "=", "\"-1 means never early stop. early_stopping_patience is measured in validation checks, not epochs. So val_check_interval will effect it.\"", ",", "\n", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.TranslationModule.__init__": [[363, 367], ["finetune.SummarizationModule.__init__"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.__init__"], ["def", "__init__", "(", "self", ",", "hparams", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "hparams", ",", "**", "kwargs", ")", "\n", "self", ".", "dataset_kwargs", "[", "\"src_lang\"", "]", "=", "hparams", ".", "src_lang", "\n", "self", ".", "dataset_kwargs", "[", "\"tgt_lang\"", "]", "=", "hparams", ".", "tgt_lang", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.TranslationModule.calc_generative_metrics": [[368, 370], ["utils.calculate_bleu"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.calculate_bleu"], ["", "def", "calc_generative_metrics", "(", "self", ",", "preds", ",", "target", ")", "->", "dict", ":", "\n", "        ", "return", "calculate_bleu", "(", "preds", ",", "target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.main": [[372, 430], ["pathlib.Path().mkdir", "utils.check_output_dir", "lightning_base.generic_train", "utils.pickle_save", "list", "trainer.logger.log_hyperparams", "trainer.test", "pathlib.Path", "str().startswith", "str().startswith", "callbacks.get_early_stopping_callback", "sorted", "pathlib.Path", "finetune.SummarizationModule", "finetune.TranslationModule", "os.environ.get", "WandbLogger", "callbacks.Seq2SeqLoggingCallback", "callbacks.get_checkpoint_callback", "glob.glob", "str", "str", "WandbLogger", "os.path.join"], "function", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.check_output_dir", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.generic_train", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.pickle_save", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.callbacks.get_early_stopping_callback", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.callbacks.get_checkpoint_callback"], ["", "", "def", "main", "(", "args", ",", "model", "=", "None", ")", "->", "SummarizationModule", ":", "\n", "    ", "Path", "(", "args", ".", "output_dir", ")", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "check_output_dir", "(", "args", ",", "expected_items", "=", "3", ")", "\n", "\n", "if", "model", "is", "None", ":", "\n", "        ", "if", "\"summarization\"", "in", "args", ".", "task", ":", "\n", "            ", "model", ":", "SummarizationModule", "=", "SummarizationModule", "(", "args", ")", "\n", "", "else", ":", "\n", "            ", "model", ":", "SummarizationModule", "=", "TranslationModule", "(", "args", ")", "\n", "", "", "dataset", "=", "Path", "(", "args", ".", "data_dir", ")", ".", "name", "\n", "if", "(", "\n", "args", ".", "logger_name", "==", "\"default\"", "\n", "or", "args", ".", "fast_dev_run", "\n", "or", "str", "(", "args", ".", "output_dir", ")", ".", "startswith", "(", "\"/tmp\"", ")", "\n", "or", "str", "(", "args", ".", "output_dir", ")", ".", "startswith", "(", "\"/var\"", ")", "\n", ")", ":", "\n", "        ", "logger", "=", "True", "# don't pollute wandb logs unnecessarily", "\n", "", "elif", "args", ".", "logger_name", "==", "\"wandb\"", ":", "\n", "        ", "from", "pytorch_lightning", ".", "loggers", "import", "WandbLogger", "\n", "\n", "project", "=", "os", ".", "environ", ".", "get", "(", "\"WANDB_PROJECT\"", ",", "dataset", ")", "\n", "logger", "=", "WandbLogger", "(", "name", "=", "model", ".", "output_dir", ".", "name", ",", "project", "=", "project", ")", "\n", "\n", "", "elif", "args", ".", "logger_name", "==", "\"wandb_shared\"", ":", "\n", "        ", "from", "pytorch_lightning", ".", "loggers", "import", "WandbLogger", "\n", "\n", "logger", "=", "WandbLogger", "(", "name", "=", "model", ".", "output_dir", ".", "name", ",", "project", "=", "f\"hf_{dataset}\"", ")", "\n", "\n", "", "if", "args", ".", "early_stopping_patience", ">=", "0", ":", "\n", "        ", "es_callback", "=", "get_early_stopping_callback", "(", "model", ".", "val_metric", ",", "args", ".", "early_stopping_patience", ")", "\n", "", "else", ":", "\n", "        ", "es_callback", "=", "False", "\n", "\n", "", "lower_is_better", "=", "args", ".", "val_metric", "==", "\"loss\"", "\n", "trainer", ":", "pl", ".", "Trainer", "=", "generic_train", "(", "\n", "model", ",", "\n", "args", ",", "\n", "logging_callback", "=", "Seq2SeqLoggingCallback", "(", ")", ",", "\n", "checkpoint_callback", "=", "get_checkpoint_callback", "(", "\n", "args", ".", "output_dir", ",", "model", ".", "val_metric", ",", "args", ".", "save_top_k", ",", "lower_is_better", "\n", ")", ",", "\n", "early_stopping_callback", "=", "es_callback", ",", "\n", "logger", "=", "logger", ",", "\n", ")", "\n", "pickle_save", "(", "model", ".", "hparams", ",", "model", ".", "output_dir", "/", "\"hparams.pkl\"", ")", "\n", "if", "not", "args", ".", "do_predict", ":", "\n", "        ", "return", "model", "\n", "\n", "", "model", ".", "hparams", ".", "test_checkpoint", "=", "\"\"", "\n", "checkpoints", "=", "list", "(", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"*.ckpt\"", ")", ",", "recursive", "=", "True", ")", ")", ")", "\n", "if", "checkpoints", ":", "\n", "        ", "model", ".", "hparams", ".", "test_checkpoint", "=", "checkpoints", "[", "-", "1", "]", "\n", "trainer", ".", "resume_from_checkpoint", "=", "checkpoints", "[", "-", "1", "]", "\n", "", "trainer", ".", "logger", ".", "log_hyperparams", "(", "model", ".", "hparams", ")", "\n", "\n", "# test() without a model tests using the best checkpoint automatically", "\n", "trainer", ".", "test", "(", "verbose", "=", "False", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.sentence_splitter.add_newline_to_end_of_each_sentence": [[20, 26], ["x.replace"], "function", ["None"], ["", "", "def", "add_newline_to_end_of_each_sentence", "(", "x", ":", "str", ")", "->", "str", ":", "\n", "    ", "\"\"\"This was added to get rougeLsum scores matching published rougeL scores for BART and PEGASUS.\"\"\"", "\n", "if", "\"<n>\"", "in", "x", ":", "\n", "        ", "return", "x", ".", "replace", "(", "\"<n>\"", ",", "\"\\n\"", ")", "# remove pegasus newline char", "\n", "", "else", ":", "\n", "        ", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.callbacks.Seq2SeqLoggingCallback.on_batch_end": [[27, 30], ["pl_module.logger.log_metrics", "enumerate"], "methods", ["None"], ["    ", "def", "on_batch_end", "(", "self", ",", "trainer", ",", "pl_module", ")", ":", "\n", "        ", "lrs", "=", "{", "f\"lr_group_{i}\"", ":", "param", "[", "\"lr\"", "]", "for", "i", ",", "param", "in", "enumerate", "(", "pl_module", ".", "trainer", ".", "optimizers", "[", "0", "]", ".", "param_groups", ")", "}", "\n", "pl_module", ".", "logger", ".", "log_metrics", "(", "lrs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.callbacks.Seq2SeqLoggingCallback._write_logs": [[31, 66], ["logger.info", "trainer.logger.log_metrics", "pathlib.Path", "results_file.parent.mkdir", "generations_file.parent.mkdir", "open", "sorted", "generations_file.open().write", "isinstance", "writer.write", "metrics.items", "val.item.item.item", "generations_file.open"], "methods", ["None"], ["", "@", "rank_zero_only", "\n", "def", "_write_logs", "(", "\n", "self", ",", "trainer", ":", "pl", ".", "Trainer", ",", "pl_module", ":", "pl", ".", "LightningModule", ",", "type_path", ":", "str", ",", "save_generations", "=", "True", "\n", ")", "->", "None", ":", "\n", "        ", "logger", ".", "info", "(", "f\"***** {type_path} results at step {trainer.global_step:05d} *****\"", ")", "\n", "metrics", "=", "trainer", ".", "callback_metrics", "\n", "trainer", ".", "logger", ".", "log_metrics", "(", "{", "k", ":", "v", "for", "k", ",", "v", "in", "metrics", ".", "items", "(", ")", "if", "k", "not", "in", "[", "\"log\"", ",", "\"progress_bar\"", ",", "\"preds\"", "]", "}", ")", "\n", "# Log results", "\n", "od", "=", "Path", "(", "pl_module", ".", "hparams", ".", "output_dir", ")", "\n", "if", "type_path", "==", "\"test\"", ":", "\n", "            ", "results_file", "=", "od", "/", "\"test_results.txt\"", "\n", "generations_file", "=", "od", "/", "\"test_generations.txt\"", "\n", "", "else", ":", "\n", "# this never gets hit. I prefer not to save intermediate generations, and results are in metrics.json", "\n", "# If people want this it will be easy enough to add back.", "\n", "            ", "results_file", "=", "od", "/", "f\"{type_path}_results/{trainer.global_step:05d}.txt\"", "\n", "generations_file", "=", "od", "/", "f\"{type_path}_generations/{trainer.global_step:05d}.txt\"", "\n", "results_file", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "generations_file", ".", "parent", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "", "with", "open", "(", "results_file", ",", "\"a+\"", ")", "as", "writer", ":", "\n", "            ", "for", "key", "in", "sorted", "(", "metrics", ")", ":", "\n", "                ", "if", "key", "in", "[", "\"log\"", ",", "\"progress_bar\"", ",", "\"preds\"", "]", ":", "\n", "                    ", "continue", "\n", "", "val", "=", "metrics", "[", "key", "]", "\n", "if", "isinstance", "(", "val", ",", "torch", ".", "Tensor", ")", ":", "\n", "                    ", "val", "=", "val", ".", "item", "(", ")", "\n", "", "msg", "=", "f\"{key}: {val:.6f}\\n\"", "\n", "writer", ".", "write", "(", "msg", ")", "\n", "\n", "", "", "if", "not", "save_generations", ":", "\n", "            ", "return", "\n", "\n", "", "if", "\"preds\"", "in", "metrics", ":", "\n", "            ", "content", "=", "\"\\n\"", ".", "join", "(", "metrics", "[", "\"preds\"", "]", ")", "\n", "generations_file", ".", "open", "(", "\"w+\"", ",", "encoding", "=", "\"utf8\"", ")", ".", "write", "(", "content", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.callbacks.Seq2SeqLoggingCallback.on_train_start": [[67, 77], ["callbacks.count_trainable_parameters", "trainer.logger.log_metrics", "pl_module.model.model.num_parameters", "pl_module.model.num_parameters"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.callbacks.count_trainable_parameters"], ["", "", "@", "rank_zero_only", "\n", "def", "on_train_start", "(", "self", ",", "trainer", ",", "pl_module", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "npars", "=", "pl_module", ".", "model", ".", "model", ".", "num_parameters", "(", ")", "\n", "", "except", "AttributeError", ":", "\n", "            ", "npars", "=", "pl_module", ".", "model", ".", "num_parameters", "(", ")", "\n", "\n", "", "n_trainable_pars", "=", "count_trainable_parameters", "(", "pl_module", ")", "\n", "# mp stands for million parameters", "\n", "trainer", ".", "logger", ".", "log_metrics", "(", "{", "\"n_params\"", ":", "npars", ",", "\"mp\"", ":", "npars", "/", "1e6", ",", "\"grad_mp\"", ":", "n_trainable_pars", "/", "1e6", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.callbacks.Seq2SeqLoggingCallback.on_test_end": [[78, 82], ["utils.save_json", "callbacks.Seq2SeqLoggingCallback._write_logs"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.save_json", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.callbacks.Seq2SeqLoggingCallback._write_logs"], ["", "@", "rank_zero_only", "\n", "def", "on_test_end", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ",", "pl_module", ":", "pl", ".", "LightningModule", ")", ":", "\n", "        ", "save_json", "(", "pl_module", ".", "metrics", ",", "pl_module", ".", "metrics_save_path", ")", "\n", "return", "self", ".", "_write_logs", "(", "trainer", ",", "pl_module", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.callbacks.Seq2SeqLoggingCallback.on_validation_end": [[83, 86], ["utils.save_json"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.save_json"], ["", "@", "rank_zero_only", "\n", "def", "on_validation_end", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ",", "pl_module", ")", ":", "\n", "        ", "save_json", "(", "pl_module", ".", "metrics", ",", "pl_module", ".", "metrics_save_path", ")", "\n", "# Uncommenting this will save val generations", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.callbacks.count_trainable_parameters": [[17, 21], ["filter", "sum", "model.parameters", "numpy.prod", "p.size"], "function", ["None"], ["def", "count_trainable_parameters", "(", "model", ")", ":", "\n", "    ", "model_parameters", "=", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", "\n", "params", "=", "sum", "(", "[", "np", ".", "prod", "(", "p", ".", "size", "(", ")", ")", "for", "p", "in", "model_parameters", "]", ")", "\n", "return", "params", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.callbacks.get_checkpoint_callback": [[90, 110], ["pytorch_lightning.callbacks.ModelCheckpoint", "os.path.join", "NotImplementedError"], "function", ["None"], ["", "", "def", "get_checkpoint_callback", "(", "output_dir", ",", "metric", ",", "save_top_k", "=", "1", ",", "lower_is_better", "=", "False", ")", ":", "\n", "    ", "\"\"\"Saves the best model by validation ROUGE2 score.\"\"\"", "\n", "if", "metric", "==", "\"rouge2\"", ":", "\n", "        ", "exp", "=", "\"{val_avg_rouge2:.4f}-{step_count}\"", "\n", "", "elif", "metric", "==", "\"bleu\"", ":", "\n", "        ", "exp", "=", "\"{val_avg_bleu:.4f}-{step_count}\"", "\n", "", "elif", "metric", "==", "\"loss\"", ":", "\n", "        ", "exp", "=", "\"{val_avg_loss:.4f}-{step_count}\"", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\n", "f\"seq2seq callbacks only support rouge2, bleu and loss, got {metric}, You can make your own by adding to this function.\"", "\n", ")", "\n", "\n", "", "checkpoint_callback", "=", "ModelCheckpoint", "(", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "exp", ")", ",", "\n", "monitor", "=", "f\"val_{metric}\"", ",", "\n", "mode", "=", "\"min\"", "if", "\"loss\"", "in", "metric", "else", "\"max\"", ",", "\n", "save_top_k", "=", "save_top_k", ",", "\n", ")", "\n", "return", "checkpoint_callback", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.callbacks.get_early_stopping_callback": [[112, 118], ["pytorch_lightning.callbacks.EarlyStopping"], "function", ["None"], ["", "def", "get_early_stopping_callback", "(", "metric", ",", "patience", ")", ":", "\n", "    ", "return", "EarlyStopping", "(", "\n", "monitor", "=", "f\"val_{metric}\"", ",", "# does this need avg?", "\n", "mode", "=", "\"min\"", "if", "\"loss\"", "in", "metric", "else", "\"max\"", ",", "\n", "patience", "=", "patience", ",", "\n", "verbose", "=", "True", ",", "\n", ")", ""]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.AbstractSeq2SeqDataset.__init__": [[112, 144], ["torch.utils.data.Dataset.__init__", "pathlib.Path().joinpath", "pathlib.Path().joinpath", "pathlib.Path().joinpath", "os.path.exists", "dataset_kwargs.update", "utils.pickle_load", "utils.AbstractSeq2SeqDataset.get_char_lens", "min", "pathlib.Path", "pathlib.Path", "pathlib.Path", "isinstance"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.__init__", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.pickle_load", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.AbstractSeq2SeqDataset.get_char_lens"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "tokenizer", ",", "\n", "data_dir", ",", "\n", "max_source_length", ",", "\n", "max_target_length", ",", "\n", "type_path", "=", "\"train\"", ",", "\n", "n_obs", "=", "None", ",", "\n", "prefix", "=", "\"\"", ",", "\n", "**", "dataset_kwargs", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "src_file", "=", "Path", "(", "data_dir", ")", ".", "joinpath", "(", "type_path", "+", "\".source\"", ")", "\n", "self", ".", "tgt_file", "=", "Path", "(", "data_dir", ")", ".", "joinpath", "(", "type_path", "+", "\".target\"", ")", "\n", "self", ".", "len_file", "=", "Path", "(", "data_dir", ")", ".", "joinpath", "(", "type_path", "+", "\".len\"", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "len_file", ")", ":", "\n", "            ", "self", ".", "src_lens", "=", "pickle_load", "(", "self", ".", "len_file", ")", "\n", "self", ".", "used_char_len", "=", "False", "\n", "", "else", ":", "\n", "            ", "self", ".", "src_lens", "=", "self", ".", "get_char_lens", "(", "self", ".", "src_file", ")", "\n", "self", ".", "used_char_len", "=", "True", "\n", "", "self", ".", "max_source_length", "=", "max_source_length", "\n", "self", ".", "max_target_length", "=", "max_target_length", "\n", "assert", "min", "(", "self", ".", "src_lens", ")", ">", "0", ",", "f\"found empty line in {self.src_file}\"", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "prefix", "=", "prefix", "if", "prefix", "is", "not", "None", "else", "\"\"", "\n", "\n", "if", "n_obs", "is", "not", "None", ":", "\n", "            ", "self", ".", "src_lens", "=", "self", ".", "src_lens", "[", ":", "n_obs", "]", "\n", "", "self", ".", "pad_token_id", "=", "self", ".", "tokenizer", ".", "pad_token_id", "\n", "self", ".", "dataset_kwargs", "=", "dataset_kwargs", "\n", "dataset_kwargs", ".", "update", "(", "{", "\"add_prefix_space\"", ":", "True", "}", "if", "isinstance", "(", "self", ".", "tokenizer", ",", "BartTokenizer", ")", "else", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.AbstractSeq2SeqDataset.__len__": [[145, 147], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "src_lens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.AbstractSeq2SeqDataset.get_char_lens": [[148, 151], ["len", "pathlib.Path().open().readlines", "pathlib.Path().open", "pathlib.Path"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_char_lens", "(", "data_file", ")", ":", "\n", "        ", "return", "[", "len", "(", "x", ")", "for", "x", "in", "Path", "(", "data_file", ")", ".", "open", "(", "encoding", "=", "\"utf8\"", ")", ".", "readlines", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.AbstractSeq2SeqDataset.tgt_lens": [[152, 156], ["utils.AbstractSeq2SeqDataset.get_char_lens"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.AbstractSeq2SeqDataset.get_char_lens"], ["", "@", "cached_property", "\n", "def", "tgt_lens", "(", "self", ")", ":", "\n", "        ", "\"\"\"Length in characters of target documents\"\"\"", "\n", "return", "self", ".", "get_char_lens", "(", "self", ".", "tgt_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.AbstractSeq2SeqDataset.make_sortish_sampler": [[157, 162], ["utils.DistributedSortishSampler", "utils.SortishSampler"], "methods", ["None"], ["", "def", "make_sortish_sampler", "(", "self", ",", "batch_size", ",", "distributed", "=", "False", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "distributed", ":", "\n", "            ", "return", "DistributedSortishSampler", "(", "self", ",", "batch_size", ",", "shuffle", "=", "shuffle", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "return", "SortishSampler", "(", "self", ".", "src_lens", ",", "batch_size", ",", "shuffle", "=", "shuffle", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.AbstractSeq2SeqDataset.make_dynamic_sampler": [[163, 187], ["list", "batch_by_size", "numpy.argmax", "utils.AbstractSeq2SeqDataset.make_sortish_sampler", "min", "numpy.random.permutation", "max", "len", "range", "len"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.AbstractSeq2SeqDataset.make_sortish_sampler"], ["", "", "def", "make_dynamic_sampler", "(", "self", ",", "max_tokens_per_batch", "=", "1024", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "FAIRSEQ_AVAILABLE", ",", "\"Dynamic batch size requires `pip install fairseq`\"", "\n", "assert", "not", "self", ".", "used_char_len", ",", "\"You must call  python make_len_file.py before calling make_dynamic_sampler\"", "\n", "sorted_indices", "=", "list", "(", "self", ".", "make_sortish_sampler", "(", "1024", ",", "shuffle", "=", "False", ")", ")", "\n", "\n", "def", "num_tokens_in_example", "(", "i", ")", ":", "\n", "            ", "return", "min", "(", "self", ".", "src_lens", "[", "i", "]", ",", "self", ".", "max_target_length", ")", "\n", "\n", "# call fairseq cython function", "\n", "", "batch_sampler", ":", "List", "[", "List", "[", "int", "]", "]", "=", "batch_by_size", "(", "\n", "sorted_indices", ",", "\n", "num_tokens_fn", "=", "num_tokens_in_example", ",", "\n", "max_tokens", "=", "max_tokens_per_batch", ",", "\n", "required_batch_size_multiple", "=", "64", ",", "\n", ")", "\n", "shuffled_batches", "=", "[", "batch_sampler", "[", "i", "]", "for", "i", "in", "np", ".", "random", ".", "permutation", "(", "range", "(", "len", "(", "batch_sampler", ")", ")", ")", "]", "\n", "# move the largest batch to the front to OOM quickly (uses an approximation for padding)", "\n", "approximate_toks_per_batch", "=", "[", "max", "(", "self", ".", "src_lens", "[", "i", "]", "for", "i", "in", "batch", ")", "*", "len", "(", "batch", ")", "for", "batch", "in", "shuffled_batches", "]", "\n", "largest_batch_idx", "=", "np", ".", "argmax", "(", "approximate_toks_per_batch", ")", "\n", "shuffled_batches", "[", "0", "]", ",", "shuffled_batches", "[", "largest_batch_idx", "]", "=", "(", "\n", "shuffled_batches", "[", "largest_batch_idx", "]", ",", "\n", "shuffled_batches", "[", "0", "]", ",", "\n", ")", "\n", "return", "shuffled_batches", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.AbstractSeq2SeqDataset.__getitem__": [[188, 190], ["NotImplementedError"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"You must implement this\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.AbstractSeq2SeqDataset.collate_fn": [[191, 193], ["NotImplementedError"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "batch", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"You must implement this\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.LegacySeq2SeqDataset.__getitem__": [[196, 213], ["linecache.getline().rstrip", "utils.LegacySeq2SeqDataset.encode_line", "utils.LegacySeq2SeqDataset.encode_line", "source_inputs[].squeeze", "target_inputs[].squeeze", "source_inputs[].squeeze", "linecache.getline().rstrip", "linecache.getline", "linecache.getline", "str", "str"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.LegacySeq2SeqDataset.encode_line", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.LegacySeq2SeqDataset.encode_line"], ["    ", "def", "__getitem__", "(", "self", ",", "index", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Call tokenizer on src and tgt_lines\"\"\"", "\n", "index", "=", "index", "+", "1", "# linecache starts at 1", "\n", "source_line", "=", "self", ".", "prefix", "+", "linecache", ".", "getline", "(", "str", "(", "self", ".", "src_file", ")", ",", "index", ")", ".", "rstrip", "(", "\"\\n\"", ")", "\n", "tgt_line", "=", "linecache", ".", "getline", "(", "str", "(", "self", ".", "tgt_file", ")", ",", "index", ")", ".", "rstrip", "(", "\"\\n\"", ")", "\n", "assert", "source_line", ",", "f\"empty source line for index {index}\"", "\n", "assert", "tgt_line", ",", "f\"empty tgt line for index {index}\"", "\n", "source_inputs", "=", "self", ".", "encode_line", "(", "self", ".", "tokenizer", ",", "source_line", ",", "self", ".", "max_source_length", ")", "\n", "target_inputs", "=", "self", ".", "encode_line", "(", "self", ".", "tokenizer", ",", "tgt_line", ",", "self", ".", "max_target_length", ")", "\n", "\n", "source_ids", "=", "source_inputs", "[", "\"input_ids\"", "]", ".", "squeeze", "(", ")", "\n", "target_ids", "=", "target_inputs", "[", "\"input_ids\"", "]", ".", "squeeze", "(", ")", "\n", "src_mask", "=", "source_inputs", "[", "\"attention_mask\"", "]", ".", "squeeze", "(", ")", "\n", "return", "{", "\n", "\"input_ids\"", ":", "source_ids", ",", "\n", "\"attention_mask\"", ":", "src_mask", ",", "\n", "\"labels\"", ":", "target_ids", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.LegacySeq2SeqDataset.encode_line": [[215, 224], ["tokenizer"], "methods", ["None"], ["", "def", "encode_line", "(", "self", ",", "tokenizer", ",", "line", ",", "max_length", ",", "pad_to_max_length", "=", "True", ",", "return_tensors", "=", "\"pt\"", ")", ":", "\n", "        ", "\"\"\"Only used by LegacyDataset\"\"\"", "\n", "return", "tokenizer", "(", "\n", "[", "line", "]", ",", "\n", "max_length", "=", "max_length", ",", "\n", "padding", "=", "\"max_length\"", "if", "pad_to_max_length", "else", "None", ",", "\n", "truncation", "=", "True", ",", "\n", "return_tensors", "=", "return_tensors", ",", "\n", "**", "self", ".", "dataset_kwargs", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.LegacySeq2SeqDataset.collate_fn": [[226, 239], ["torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "utils.trim_batch", "utils.trim_batch"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.trim_batch", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.trim_batch"], ["", "def", "collate_fn", "(", "self", ",", "batch", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "input_ids", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"input_ids\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "masks", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"attention_mask\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "target_ids", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"labels\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "pad_token_id", "=", "self", ".", "pad_token_id", "\n", "y", "=", "trim_batch", "(", "target_ids", ",", "pad_token_id", ")", "\n", "source_ids", ",", "source_mask", "=", "trim_batch", "(", "input_ids", ",", "pad_token_id", ",", "attention_mask", "=", "masks", ")", "\n", "batch", "=", "{", "\n", "\"input_ids\"", ":", "source_ids", ",", "\n", "\"attention_mask\"", ":", "source_mask", ",", "\n", "\"labels\"", ":", "y", ",", "\n", "}", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.Seq2SeqDataset.__getitem__": [[244, 251], ["linecache.getline().rstrip", "linecache.getline().rstrip", "linecache.getline", "linecache.getline", "str", "str"], "methods", ["None"], ["def", "__getitem__", "(", "self", ",", "index", ")", "->", "Dict", "[", "str", ",", "str", "]", ":", "\n", "        ", "index", "=", "index", "+", "1", "# linecache starts at 1", "\n", "source_line", "=", "self", ".", "prefix", "+", "linecache", ".", "getline", "(", "str", "(", "self", ".", "src_file", ")", ",", "index", ")", ".", "rstrip", "(", "\"\\n\"", ")", "\n", "tgt_line", "=", "linecache", ".", "getline", "(", "str", "(", "self", ".", "tgt_file", ")", ",", "index", ")", ".", "rstrip", "(", "\"\\n\"", ")", "\n", "assert", "source_line", ",", "f\"empty source line for index {index}\"", "\n", "assert", "tgt_line", ",", "f\"empty tgt line for index {index}\"", "\n", "return", "{", "\"tgt_texts\"", ":", "tgt_line", ",", "\"src_texts\"", ":", "source_line", ",", "\"id\"", ":", "index", "-", "1", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.Seq2SeqDataset.collate_fn": [[252, 264], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "utils.Seq2SeqDataset.tokenizer.prepare_seq2seq_batch"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "batch", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"Call prepare_seq2seq_batch.\"\"\"", "\n", "batch_encoding", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "=", "self", ".", "tokenizer", ".", "prepare_seq2seq_batch", "(", "\n", "[", "x", "[", "\"src_texts\"", "]", "for", "x", "in", "batch", "]", ",", "\n", "tgt_texts", "=", "[", "x", "[", "\"tgt_texts\"", "]", "for", "x", "in", "batch", "]", ",", "\n", "max_length", "=", "self", ".", "max_source_length", ",", "\n", "max_target_length", "=", "self", ".", "max_target_length", ",", "\n", "return_tensors", "=", "\"pt\"", ",", "\n", "**", "self", ".", "dataset_kwargs", ",", "\n", ")", ".", "data", "\n", "batch_encoding", "[", "\"ids\"", "]", "=", "torch", ".", "tensor", "(", "[", "x", "[", "\"id\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "return", "batch_encoding", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.Seq2SeqDataCollator.__init__": [[267, 280], ["isinstance"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "data_args", ",", "tpu_num_cores", "=", "None", ")", ":", "\n", "        ", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "pad_token_id", "=", "tokenizer", ".", "pad_token_id", "\n", "assert", "(", "\n", "self", ".", "pad_token_id", "is", "not", "None", "\n", ")", ",", "f\"pad_token_id is not defined for ({self.tokenizer.__class__.__name__}), it must be defined.\"", "\n", "self", ".", "data_args", "=", "data_args", "\n", "self", ".", "tpu_num_cores", "=", "tpu_num_cores", "\n", "self", ".", "dataset_kwargs", "=", "{", "\"add_prefix_space\"", ":", "True", "}", "if", "isinstance", "(", "tokenizer", ",", "BartTokenizer", ")", "else", "{", "}", "\n", "if", "data_args", ".", "src_lang", "is", "not", "None", ":", "\n", "            ", "self", ".", "dataset_kwargs", "[", "\"src_lang\"", "]", "=", "data_args", ".", "src_lang", "\n", "", "if", "data_args", ".", "tgt_lang", "is", "not", "None", ":", "\n", "            ", "self", ".", "dataset_kwargs", "[", "\"tgt_lang\"", "]", "=", "data_args", ".", "tgt_lang", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.Seq2SeqDataCollator.__call__": [[281, 309], ["hasattr", "isinstance", "utils.Seq2SeqDataCollator._encode", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "utils.trim_batch", "utils.trim_batch", "utils.Seq2SeqDataCollator._shift_right_t5", "transformers.models.bart.modeling_bart.shift_tokens_right"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.Seq2SeqDataCollator._encode", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.trim_batch", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.trim_batch", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.Seq2SeqDataCollator._shift_right_t5"], ["", "", "def", "__call__", "(", "self", ",", "batch", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "if", "hasattr", "(", "self", ".", "tokenizer", ",", "\"prepare_seq2seq_batch\"", ")", ":", "\n", "            ", "batch", "=", "self", ".", "_encode", "(", "batch", ")", "\n", "input_ids", ",", "attention_mask", ",", "labels", "=", "(", "\n", "batch", "[", "\"input_ids\"", "]", ",", "\n", "batch", "[", "\"attention_mask\"", "]", ",", "\n", "batch", "[", "\"labels\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "input_ids", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"input_ids\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "attention_mask", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"attention_mask\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "labels", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"labels\"", "]", "for", "x", "in", "batch", "]", ")", "\n", "\n", "labels", "=", "trim_batch", "(", "labels", ",", "self", ".", "pad_token_id", ")", "\n", "input_ids", ",", "attention_mask", "=", "trim_batch", "(", "input_ids", ",", "self", ".", "pad_token_id", ",", "attention_mask", "=", "attention_mask", ")", "\n", "\n", "", "if", "isinstance", "(", "self", ".", "tokenizer", ",", "T5Tokenizer", ")", ":", "\n", "            ", "decoder_input_ids", "=", "self", ".", "_shift_right_t5", "(", "labels", ")", "\n", "", "else", ":", "\n", "            ", "decoder_input_ids", "=", "shift_tokens_right", "(", "labels", ",", "self", ".", "pad_token_id", ")", "\n", "\n", "", "batch", "=", "{", "\n", "\"input_ids\"", ":", "input_ids", ",", "\n", "\"attention_mask\"", ":", "attention_mask", ",", "\n", "\"decoder_input_ids\"", ":", "decoder_input_ids", ",", "\n", "\"labels\"", ":", "labels", ",", "\n", "}", "\n", "return", "batch", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.Seq2SeqDataCollator._shift_right_t5": [[310, 316], ["input_ids.new_zeros", "input_ids[].clone"], "methods", ["None"], ["", "def", "_shift_right_t5", "(", "self", ",", "input_ids", ")", ":", "\n", "# shift inputs to the right", "\n", "        ", "shifted_input_ids", "=", "input_ids", ".", "new_zeros", "(", "input_ids", ".", "shape", ")", "\n", "shifted_input_ids", "[", "...", ",", "1", ":", "]", "=", "input_ids", "[", "...", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "shifted_input_ids", "[", "...", ",", "0", "]", "=", "self", ".", "pad_token_id", "\n", "return", "shifted_input_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.Seq2SeqDataCollator._encode": [[317, 328], ["utils.Seq2SeqDataCollator.tokenizer.prepare_seq2seq_batch"], "methods", ["None"], ["", "def", "_encode", "(", "self", ",", "batch", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "batch_encoding", "=", "self", ".", "tokenizer", ".", "prepare_seq2seq_batch", "(", "\n", "[", "x", "[", "\"src_texts\"", "]", "for", "x", "in", "batch", "]", ",", "\n", "tgt_texts", "=", "[", "x", "[", "\"tgt_texts\"", "]", "for", "x", "in", "batch", "]", ",", "\n", "max_length", "=", "self", ".", "data_args", ".", "max_source_length", ",", "\n", "max_target_length", "=", "self", ".", "data_args", ".", "max_target_length", ",", "\n", "padding", "=", "\"max_length\"", "if", "self", ".", "tpu_num_cores", "is", "not", "None", "else", "\"longest\"", ",", "# TPU hack", "\n", "return_tensors", "=", "\"pt\"", ",", "\n", "**", "self", ".", "dataset_kwargs", ",", "\n", ")", "\n", "return", "batch_encoding", ".", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.SortishSampler.__init__": [[333, 335], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data", ",", "batch_size", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "self", ".", "data", ",", "self", ".", "bs", ",", "self", ".", "shuffle", "=", "data", ",", "batch_size", ",", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.SortishSampler.__len__": [[336, 338], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.SortishSampler.__iter__": [[339, 341], ["iter", "utils.sortish_sampler_indices"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.sortish_sampler_indices"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "iter", "(", "sortish_sampler_indices", "(", "self", ".", "data", ",", "self", ".", "bs", ",", "shuffle", "=", "self", ".", "shuffle", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.DistributedSortishSampler.__init__": [[367, 389], ["torch.get_world_size", "torch.get_world_size", "torch.get_rank", "torch.get_rank", "int", "len", "len", "torch.is_available", "torch.is_available", "RuntimeError", "torch.is_available", "torch.is_available", "RuntimeError", "math.ceil", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dataset", ",", "batch_size", ",", "num_replicas", "=", "None", ",", "rank", "=", "None", ",", "add_extra_examples", "=", "True", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "if", "num_replicas", "is", "None", ":", "\n", "            ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"Requires distributed package to be available\"", ")", "\n", "", "num_replicas", "=", "dist", ".", "get_world_size", "(", ")", "\n", "", "if", "rank", "is", "None", ":", "\n", "            ", "if", "not", "dist", ".", "is_available", "(", ")", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"Requires distributed package to be available\"", ")", "\n", "", "rank", "=", "dist", ".", "get_rank", "(", ")", "\n", "", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "num_replicas", "=", "num_replicas", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "epoch", "=", "0", "\n", "if", "add_extra_examples", ":", "\n", "            ", "self", ".", "num_samples", "=", "int", "(", "math", ".", "ceil", "(", "len", "(", "self", ".", "dataset", ")", "*", "1.0", "/", "self", ".", "num_replicas", ")", ")", "\n", "self", ".", "total_size", "=", "self", ".", "num_samples", "*", "self", ".", "num_replicas", "\n", "", "else", ":", "\n", "            ", "self", ".", "total_size", "=", "len", "(", "dataset", ")", "\n", "self", ".", "num_samples", "=", "len", "(", "self", ".", "available_indices", ")", "\n", "", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "add_extra_examples", "=", "add_extra_examples", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.DistributedSortishSampler.__iter__": [[390, 399], ["torch.Generator", "torch.Generator", "torch.Generator", "torch.Generator", "torch.Generator.manual_seed", "torch.Generator.manual_seed", "utils.sortish_sampler_indices", "iter", "len"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.sortish_sampler_indices"], ["", "def", "__iter__", "(", "self", ")", "->", "Iterable", ":", "\n", "        ", "g", "=", "torch", ".", "Generator", "(", ")", "\n", "g", ".", "manual_seed", "(", "self", ".", "epoch", ")", "\n", "\n", "sortish_data", "=", "[", "self", ".", "dataset", ".", "src_lens", "[", "i", "]", "for", "i", "in", "self", ".", "available_indices", "]", "\n", "sortish_indices", "=", "sortish_sampler_indices", "(", "sortish_data", ",", "self", ".", "batch_size", ",", "shuffle", "=", "self", ".", "shuffle", ")", "\n", "indices", "=", "[", "self", ".", "available_indices", "[", "i", "]", "for", "i", "in", "sortish_indices", "]", "\n", "assert", "len", "(", "indices", ")", "==", "self", ".", "num_samples", "\n", "return", "iter", "(", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.DistributedSortishSampler.available_indices": [[400, 409], ["list", "range", "len", "len", "len"], "methods", ["None"], ["", "@", "cached_property", "\n", "def", "available_indices", "(", "self", ")", "->", "np", ".", "array", ":", "\n", "        ", "indices", "=", "list", "(", "range", "(", "len", "(", "self", ".", "dataset", ")", ")", ")", "\n", "# add extra samples to make it evenly divisible", "\n", "indices", "+=", "indices", "[", ":", "(", "self", ".", "total_size", "-", "len", "(", "indices", ")", ")", "]", "\n", "assert", "len", "(", "indices", ")", "==", "self", ".", "total_size", "\n", "# subsample", "\n", "available_indices", "=", "indices", "[", "self", ".", "rank", ":", "self", ".", "total_size", ":", "self", ".", "num_replicas", "]", "\n", "return", "available_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.DistributedSortishSampler.__len__": [[410, 412], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.DistributedSortishSampler.set_epoch": [[413, 415], ["None"], "methods", ["None"], ["", "def", "set_epoch", "(", "self", ",", "epoch", ")", ":", "\n", "        ", "self", ".", "epoch", "=", "epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.label_smoothed_nll_loss": [[38, 57], ["nll_loss.squeeze.sum", "smooth_loss.squeeze.sum", "target.unsqueeze.dim", "target.unsqueeze.unsqueeze", "lprobs.gather", "lprobs.sum", "target.unsqueeze.eq", "nll_loss.squeeze.masked_fill_", "smooth_loss.squeeze.masked_fill_", "nll_loss.squeeze.squeeze", "smooth_loss.squeeze.squeeze", "lprobs.size", "lprobs.dim"], "function", ["None"], ["", "def", "label_smoothed_nll_loss", "(", "lprobs", ",", "target", ",", "epsilon", ",", "ignore_index", "=", "-", "100", ")", ":", "\n", "    ", "\"\"\"From fairseq\"\"\"", "\n", "if", "target", ".", "dim", "(", ")", "==", "lprobs", ".", "dim", "(", ")", "-", "1", ":", "\n", "        ", "target", "=", "target", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "nll_loss", "=", "-", "lprobs", ".", "gather", "(", "dim", "=", "-", "1", ",", "index", "=", "target", ")", "\n", "smooth_loss", "=", "-", "lprobs", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "if", "ignore_index", "is", "not", "None", ":", "\n", "        ", "pad_mask", "=", "target", ".", "eq", "(", "ignore_index", ")", "\n", "nll_loss", ".", "masked_fill_", "(", "pad_mask", ",", "0.0", ")", "\n", "smooth_loss", ".", "masked_fill_", "(", "pad_mask", ",", "0.0", ")", "\n", "", "else", ":", "\n", "        ", "nll_loss", "=", "nll_loss", ".", "squeeze", "(", "-", "1", ")", "\n", "smooth_loss", "=", "smooth_loss", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "", "nll_loss", "=", "nll_loss", ".", "sum", "(", ")", "# mean()? Scared to break other math.", "\n", "smooth_loss", "=", "smooth_loss", ".", "sum", "(", ")", "\n", "eps_i", "=", "epsilon", "/", "lprobs", ".", "size", "(", "-", "1", ")", "\n", "loss", "=", "(", "1.0", "-", "epsilon", ")", "*", "nll_loss", "+", "eps_i", "*", "smooth_loss", "\n", "return", "loss", ",", "nll_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.lmap": [[59, 62], ["list", "map"], "function", ["None"], ["", "def", "lmap", "(", "f", ":", "Callable", ",", "x", ":", "Iterable", ")", "->", "List", ":", "\n", "    ", "\"\"\"list(map(f, x))\"\"\"", "\n", "return", "list", "(", "map", "(", "f", ",", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.calculate_bleu": [[64, 67], ["round", "sacrebleu.corpus_bleu"], "function", ["None"], ["", "def", "calculate_bleu", "(", "output_lns", ",", "refs_lns", ",", "**", "kwargs", ")", "->", "dict", ":", "\n", "    ", "\"\"\"Uses sacrebleu's corpus_bleu implementation.\"\"\"", "\n", "return", "{", "\"bleu\"", ":", "round", "(", "corpus_bleu", "(", "output_lns", ",", "[", "refs_lns", "]", ",", "**", "kwargs", ")", ".", "score", ",", "4", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.build_compute_metrics_fn": [[69, 96], ["numpy.count_nonzero", "tokenizer.batch_decode", "tokenizer.batch_decode", "utils.lmap", "utils.lmap", "utils.build_compute_metrics_fn.decode_pred"], "function", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.lmap", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.lmap"], ["", "def", "build_compute_metrics_fn", "(", "task_name", ":", "str", ",", "tokenizer", ":", "PreTrainedTokenizer", ")", "->", "Callable", "[", "[", "EvalPrediction", "]", ",", "Dict", "]", ":", "\n", "    ", "def", "non_pad_len", "(", "tokens", ":", "np", ".", "ndarray", ")", "->", "int", ":", "\n", "        ", "return", "np", ".", "count_nonzero", "(", "tokens", "!=", "tokenizer", ".", "pad_token_id", ")", "\n", "\n", "", "def", "decode_pred", "(", "pred", ":", "EvalPrediction", ")", "->", "Tuple", "[", "List", "[", "str", "]", ",", "List", "[", "str", "]", "]", ":", "\n", "        ", "pred_str", "=", "tokenizer", ".", "batch_decode", "(", "pred", ".", "predictions", ",", "skip_special_tokens", "=", "True", ")", "\n", "label_str", "=", "tokenizer", ".", "batch_decode", "(", "pred", ".", "label_ids", ",", "skip_special_tokens", "=", "True", ")", "\n", "pred_str", "=", "lmap", "(", "str", ".", "strip", ",", "pred_str", ")", "\n", "label_str", "=", "lmap", "(", "str", ".", "strip", ",", "label_str", ")", "\n", "return", "pred_str", ",", "label_str", "\n", "\n", "", "def", "summarization_metrics", "(", "pred", ":", "EvalPrediction", ")", "->", "Dict", ":", "\n", "        ", "pred_str", ",", "label_str", "=", "decode_pred", "(", "pred", ")", "\n", "rouge", ":", "Dict", "=", "calculate_rouge", "(", "pred_str", ",", "label_str", ")", "\n", "summ_len", "=", "np", ".", "round", "(", "np", ".", "mean", "(", "lmap", "(", "non_pad_len", ",", "pred", ".", "predictions", ")", ")", ",", "1", ")", "\n", "rouge", ".", "update", "(", "{", "\"gen_len\"", ":", "summ_len", "}", ")", "\n", "return", "rouge", "\n", "\n", "", "def", "translation_metrics", "(", "pred", ":", "EvalPrediction", ")", "->", "Dict", ":", "\n", "        ", "pred_str", ",", "label_str", "=", "decode_pred", "(", "pred", ")", "\n", "bleu", ":", "Dict", "=", "calculate_bleu", "(", "pred_str", ",", "label_str", ")", "\n", "gen_len", "=", "np", ".", "round", "(", "np", ".", "mean", "(", "lmap", "(", "non_pad_len", ",", "pred", ".", "predictions", ")", ")", ",", "1", ")", "\n", "bleu", ".", "update", "(", "{", "\"gen_len\"", ":", "gen_len", "}", ")", "\n", "return", "bleu", "\n", "\n", "", "compute_metrics_fn", "=", "summarization_metrics", "if", "\"summarization\"", "in", "task_name", "else", "translation_metrics", "\n", "return", "compute_metrics_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.trim_batch": [[98, 109], ["input_ids.ne().any", "input_ids.ne"], "function", ["None"], ["", "def", "trim_batch", "(", "\n", "input_ids", ",", "\n", "pad_token_id", ",", "\n", "attention_mask", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Remove columns that are populated exclusively by pad_token_id\"\"\"", "\n", "keep_column_mask", "=", "input_ids", ".", "ne", "(", "pad_token_id", ")", ".", "any", "(", "dim", "=", "0", ")", "\n", "if", "attention_mask", "is", "None", ":", "\n", "        ", "return", "input_ids", "[", ":", ",", "keep_column_mask", "]", "\n", "", "else", ":", "\n", "        ", "return", "(", "input_ids", "[", ":", ",", "keep_column_mask", "]", ",", "attention_mask", "[", ":", ",", "keep_column_mask", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.sortish_sampler_indices": [[343, 362], ["numpy.random.permutation", "numpy.concatenate", "numpy.argmax", "numpy.concatenate", "numpy.argsort", "len", "numpy.concatenate", "numpy.array", "range", "sorted", "range", "utils.sortish_sampler_indices.key_fn"], "function", ["None"], ["", "", "def", "sortish_sampler_indices", "(", "data", ":", "List", ",", "bs", ":", "int", ",", "shuffle", "=", "True", ")", "->", "np", ".", "array", ":", "\n", "    ", "\"Go through the text data by order of src length with a bit of randomness. From fastai repo.\"", "\n", "if", "not", "shuffle", ":", "\n", "        ", "return", "np", ".", "argsort", "(", "np", ".", "array", "(", "data", ")", "*", "-", "1", ")", "\n", "\n", "", "def", "key_fn", "(", "i", ")", ":", "\n", "        ", "return", "data", "[", "i", "]", "\n", "\n", "", "idxs", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "data", ")", ")", "\n", "sz", "=", "bs", "*", "50", "\n", "ck_idx", "=", "[", "idxs", "[", "i", ":", "i", "+", "sz", "]", "for", "i", "in", "range", "(", "0", ",", "len", "(", "idxs", ")", ",", "sz", ")", "]", "\n", "sort_idx", "=", "np", ".", "concatenate", "(", "[", "sorted", "(", "s", ",", "key", "=", "key_fn", ",", "reverse", "=", "True", ")", "for", "s", "in", "ck_idx", "]", ")", "\n", "sz", "=", "bs", "\n", "ck_idx", "=", "[", "sort_idx", "[", "i", ":", "i", "+", "sz", "]", "for", "i", "in", "range", "(", "0", ",", "len", "(", "sort_idx", ")", ",", "sz", ")", "]", "\n", "max_ck", "=", "np", ".", "argmax", "(", "[", "key_fn", "(", "ck", "[", "0", "]", ")", "for", "ck", "in", "ck_idx", "]", ")", "# find the chunk with the largest key,", "\n", "ck_idx", "[", "0", "]", ",", "ck_idx", "[", "max_ck", "]", "=", "ck_idx", "[", "max_ck", "]", ",", "ck_idx", "[", "0", "]", "# then make sure it goes first.", "\n", "sort_idx", "=", "np", ".", "concatenate", "(", "np", ".", "random", ".", "permutation", "(", "ck_idx", "[", "1", ":", "]", ")", ")", "if", "len", "(", "ck_idx", ")", ">", "1", "else", "np", ".", "array", "(", "[", "]", ",", "dtype", "=", "np", ".", "int", ")", "\n", "sort_idx", "=", "np", ".", "concatenate", "(", "(", "ck_idx", "[", "0", "]", ",", "sort_idx", ")", ")", "\n", "return", "sort_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.use_task_specific_params": [[420, 428], ["task_specific_params.get", "logger.info", "model.config.update"], "function", ["None"], ["def", "use_task_specific_params", "(", "model", ",", "task", ")", ":", "\n", "    ", "\"\"\"Update config with summarization specific params.\"\"\"", "\n", "task_specific_params", "=", "model", ".", "config", ".", "task_specific_params", "\n", "\n", "if", "task_specific_params", "is", "not", "None", ":", "\n", "        ", "pars", "=", "task_specific_params", ".", "get", "(", "task", ",", "{", "}", ")", "\n", "logger", ".", "info", "(", "f\"using task specific params for {task}: {pars}\"", ")", "\n", "model", ".", "config", ".", "update", "(", "pars", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.pickle_load": [[430, 434], ["open", "pickle.load"], "function", ["None"], ["", "", "def", "pickle_load", "(", "path", ")", ":", "\n", "    ", "\"\"\"pickle.load(path)\"\"\"", "\n", "with", "open", "(", "path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "return", "pickle", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.pickle_save": [[436, 440], ["open", "pickle.dump"], "function", ["None"], ["", "", "def", "pickle_save", "(", "obj", ",", "path", ")", ":", "\n", "    ", "\"\"\"pickle.dump(obj, path)\"\"\"", "\n", "with", "open", "(", "path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "return", "pickle", ".", "dump", "(", "obj", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.flatten_list": [[442, 444], ["itertools.chain.from_iterable"], "function", ["None"], ["", "", "def", "flatten_list", "(", "summary_ids", ":", "List", "[", "List", "]", ")", ":", "\n", "    ", "return", "[", "x", "for", "x", "in", "itertools", ".", "chain", ".", "from_iterable", "(", "summary_ids", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.save_git_info": [[446, 450], ["utils.get_git_info", "utils.save_json", "os.path.join"], "function", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.get_git_info", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.save_json"], ["", "def", "save_git_info", "(", "folder_path", ":", "str", ")", "->", "None", ":", "\n", "    ", "\"\"\"Save git information to output_dir/git_log.json\"\"\"", "\n", "repo_infos", "=", "get_git_info", "(", ")", "\n", "save_json", "(", "repo_infos", ",", "os", ".", "path", ".", "join", "(", "folder_path", ",", "\"git_log.json\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.save_json": [[452, 455], ["open", "json.dump"], "function", ["None"], ["", "def", "save_json", "(", "content", ",", "path", ",", "indent", "=", "4", ",", "**", "json_dump_kwargs", ")", ":", "\n", "    ", "with", "open", "(", "path", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "content", ",", "f", ",", "indent", "=", "indent", ",", "**", "json_dump_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.load_json": [[457, 460], ["open", "json.load"], "function", ["None"], ["", "", "def", "load_json", "(", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", ")", "as", "f", ":", "\n", "        ", "return", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.get_git_info": [[462, 478], ["git.Repo", "str", "str", "str", "str", "socket.gethostname"], "function", ["None"], ["", "", "def", "get_git_info", "(", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "repo", "=", "git", ".", "Repo", "(", "search_parent_directories", "=", "True", ")", "\n", "repo_infos", "=", "{", "\n", "\"repo_id\"", ":", "str", "(", "repo", ")", ",", "\n", "\"repo_sha\"", ":", "str", "(", "repo", ".", "head", ".", "object", ".", "hexsha", ")", ",", "\n", "\"repo_branch\"", ":", "str", "(", "repo", ".", "active_branch", ")", ",", "\n", "\"hostname\"", ":", "str", "(", "socket", ".", "gethostname", "(", ")", ")", ",", "\n", "}", "\n", "return", "repo_infos", "\n", "", "except", "TypeError", ":", "\n", "        ", "return", "{", "\n", "\"repo_id\"", ":", "None", ",", "\n", "\"repo_sha\"", ":", "None", ",", "\n", "\"repo_branch\"", ":", "None", ",", "\n", "\"hostname\"", ":", "None", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.extract_rouge_mid_statistics": [[484, 490], ["dct.items", "round", "getattr"], "function", ["None"], ["def", "extract_rouge_mid_statistics", "(", "dct", ")", ":", "\n", "    ", "new_dict", "=", "{", "}", "\n", "for", "k1", ",", "v1", "in", "dct", ".", "items", "(", ")", ":", "\n", "        ", "mid", "=", "v1", ".", "mid", "\n", "new_dict", "[", "k1", "]", "=", "{", "stat", ":", "round", "(", "getattr", "(", "mid", ",", "stat", ")", ",", "4", ")", "for", "stat", "in", "[", "\"precision\"", ",", "\"recall\"", ",", "\"fmeasure\"", "]", "}", "\n", "", "return", "new_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.calculate_rouge": [[492, 538], ["rouge_score.rouge_scorer.RougeScorer", "rouge_score.scoring.BootstrapAggregator", "zip", "rouge_scorer.RougeScorer.score", "scoring.BootstrapAggregator.add_scores", "scoring.BootstrapAggregator.aggregate", "sentence_splitter.add_newline_to_end_of_each_sentence", "sentence_splitter.add_newline_to_end_of_each_sentence", "utils.extract_rouge_mid_statistics", "round", "aggregator.aggregate.items"], "function", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.sentence_splitter.add_newline_to_end_of_each_sentence", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.sentence_splitter.add_newline_to_end_of_each_sentence", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.extract_rouge_mid_statistics"], ["", "def", "calculate_rouge", "(", "\n", "pred_lns", ":", "List", "[", "str", "]", ",", "\n", "tgt_lns", ":", "List", "[", "str", "]", ",", "\n", "use_stemmer", "=", "True", ",", "\n", "rouge_keys", "=", "ROUGE_KEYS", ",", "\n", "return_precision_and_recall", "=", "False", ",", "\n", "bootstrap_aggregation", "=", "True", ",", "\n", "newline_sep", "=", "True", ",", "\n", ")", "->", "Dict", ":", "\n", "    ", "\"\"\"Calculate rouge using rouge_scorer package.\n\n    Args:\n        pred_lns: list of summaries generated by model\n        tgt_lns: list of groundtruth summaries (e.g. contents of val.target)\n        use_stemmer:  Bool indicating whether Porter stemmer should be used to\n        strip word suffixes to improve matching.\n        rouge_keys:  which metrics to compute, defaults to rouge1, rouge2, rougeL, rougeLsum\n        return_precision_and_recall: (False) whether to also return precision and recall.\n        bootstrap_aggregation: whether to do the typical bootstrap resampling of scores. Defaults to True, if False\n            this function returns a collections.defaultdict[metric: list of values for each observation for each subscore]``\n        newline_sep:(default=True) whether to add newline between sentences. This is essential for calculation rougeL\n        on multi sentence summaries (CNN/DM dataset).\n\n    Returns:\n         Dict[score: value] if aggregate else defaultdict(list) keyed by rouge_keys\n\n    \"\"\"", "\n", "scorer", "=", "rouge_scorer", ".", "RougeScorer", "(", "rouge_keys", ",", "use_stemmer", "=", "use_stemmer", ")", "\n", "aggregator", "=", "scoring", ".", "BootstrapAggregator", "(", ")", "\n", "# fix the bug of original code", "\n", "for", "pred", ",", "tgt", "in", "zip", "(", "pred_lns", ",", "tgt_lns", ")", ":", "\n", "# rougeLsum expects \"\\n\" separated sentences within a summary", "\n", "        ", "if", "newline_sep", ":", "\n", "            ", "pred", "=", "add_newline_to_end_of_each_sentence", "(", "pred", ")", "\n", "tgt", "=", "add_newline_to_end_of_each_sentence", "(", "tgt", ")", "\n", "", "scores", "=", "scorer", ".", "score", "(", "pred", ",", "tgt", ")", "\n", "aggregator", ".", "add_scores", "(", "scores", ")", "\n", "\n", "", "if", "bootstrap_aggregation", ":", "\n", "        ", "result", "=", "aggregator", ".", "aggregate", "(", ")", "\n", "if", "return_precision_and_recall", ":", "\n", "            ", "return", "extract_rouge_mid_statistics", "(", "result", ")", "# here we return dict", "\n", "", "else", ":", "\n", "            ", "return", "{", "k", ":", "round", "(", "v", ".", "mid", ".", "fmeasure", "*", "100", ",", "4", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", "}", "\n", "", "", "else", ":", "\n", "        ", "return", "aggregator", ".", "_scores", "# here we return defaultdict(list)", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.freeze_params": [[543, 547], ["model.parameters"], "function", ["None"], ["", "", "def", "freeze_params", "(", "model", ":", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Set requires_grad=False for each of model.parameters()\"\"\"", "\n", "for", "par", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "par", ".", "requires_grad", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.freeze_embeds": [[549, 566], ["utils.freeze_params", "utils.freeze_params", "utils.freeze_params", "utils.freeze_params", "utils.freeze_params", "utils.freeze_params", "utils.freeze_params"], "function", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.freeze_params", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.freeze_params", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.freeze_params", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.freeze_params", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.freeze_params", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.freeze_params", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.freeze_params"], ["", "", "def", "freeze_embeds", "(", "model", ")", ":", "\n", "    ", "\"\"\"Freeze token embeddings and positional embeddings for bart, just token embeddings for t5.\"\"\"", "\n", "model_type", "=", "model", ".", "config", ".", "model_type", "\n", "\n", "if", "model_type", "==", "\"t5\"", ":", "\n", "        ", "freeze_params", "(", "model", ".", "shared", ")", "\n", "for", "d", "in", "[", "model", ".", "encoder", ",", "model", ".", "decoder", "]", ":", "\n", "            ", "freeze_params", "(", "d", ".", "embed_tokens", ")", "\n", "", "", "elif", "model_type", "==", "\"fsmt\"", ":", "\n", "        ", "for", "d", "in", "[", "model", ".", "model", ".", "encoder", ",", "model", ".", "model", ".", "decoder", "]", ":", "\n", "            ", "freeze_params", "(", "d", ".", "embed_positions", ")", "\n", "freeze_params", "(", "d", ".", "embed_tokens", ")", "\n", "", "", "else", ":", "\n", "        ", "freeze_params", "(", "model", ".", "model", ".", "shared", ")", "\n", "for", "d", "in", "[", "model", ".", "model", ".", "encoder", ",", "model", ".", "model", ".", "decoder", "]", ":", "\n", "            ", "freeze_params", "(", "d", ".", "embed_positions", ")", "\n", "freeze_params", "(", "d", ".", "embed_tokens", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.grad_status": [[568, 570], ["model.parameters"], "function", ["None"], ["", "", "", "def", "grad_status", "(", "model", ":", "nn", ".", "Module", ")", "->", "Iterable", ":", "\n", "    ", "return", "(", "par", ".", "requires_grad", "for", "par", "in", "model", ".", "parameters", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.any_requires_grad": [[572, 574], ["any", "utils.grad_status"], "function", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.grad_status"], ["", "def", "any_requires_grad", "(", "model", ":", "nn", ".", "Module", ")", "->", "bool", ":", "\n", "    ", "return", "any", "(", "grad_status", "(", "model", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.assert_all_frozen": [[576, 581], ["list", "sum", "len", "utils.grad_status", "utils.lmap", "any"], "function", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.grad_status", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.lmap"], ["", "def", "assert_all_frozen", "(", "model", ")", ":", "\n", "    ", "model_grads", ":", "List", "[", "bool", "]", "=", "list", "(", "grad_status", "(", "model", ")", ")", "\n", "n_require_grad", "=", "sum", "(", "lmap", "(", "int", ",", "model_grads", ")", ")", "\n", "npars", "=", "len", "(", "model_grads", ")", "\n", "assert", "not", "any", "(", "model_grads", ")", ",", "f\"{n_require_grad/npars:.1%} of {npars} weights require grad\"", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.assert_not_all_frozen": [[583, 587], ["list", "len", "any", "utils.grad_status"], "function", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.grad_status"], ["", "def", "assert_not_all_frozen", "(", "model", ")", ":", "\n", "    ", "model_grads", ":", "List", "[", "bool", "]", "=", "list", "(", "grad_status", "(", "model", ")", ")", "\n", "npars", "=", "len", "(", "model_grads", ")", "\n", "assert", "any", "(", "model_grads", ")", ",", "f\"none of {npars} weights require grad\"", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.parse_numeric_n_bool_cl_kwargs": [[589, 612], ["range", "len", "unparsed_args[].startswith", "len", "unparsed_args[].lower", "unparsed_args[].lower", "int", "float"], "function", ["None"], ["", "def", "parse_numeric_n_bool_cl_kwargs", "(", "unparsed_args", ":", "List", "[", "str", "]", ")", "->", "Dict", "[", "str", ",", "Union", "[", "int", ",", "float", ",", "bool", "]", "]", ":", "\n", "    ", "\"\"\"\n    Parse an argv list of unspecified command line args to a dict.\n    Assumes all values are either numeric or boolean in the form of true/false.\n    \"\"\"", "\n", "result", "=", "{", "}", "\n", "assert", "len", "(", "unparsed_args", ")", "%", "2", "==", "0", ",", "f\"got odd number of unparsed args: {unparsed_args}\"", "\n", "num_pairs", "=", "len", "(", "unparsed_args", ")", "//", "2", "\n", "for", "pair_num", "in", "range", "(", "num_pairs", ")", ":", "\n", "        ", "i", "=", "2", "*", "pair_num", "\n", "assert", "unparsed_args", "[", "i", "]", ".", "startswith", "(", "\"--\"", ")", "\n", "if", "unparsed_args", "[", "i", "+", "1", "]", ".", "lower", "(", ")", "==", "\"true\"", ":", "\n", "            ", "value", "=", "True", "\n", "", "elif", "unparsed_args", "[", "i", "+", "1", "]", ".", "lower", "(", ")", "==", "\"false\"", ":", "\n", "            ", "value", "=", "False", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "value", "=", "int", "(", "unparsed_args", "[", "i", "+", "1", "]", ")", "\n", "", "except", "ValueError", ":", "\n", "                ", "value", "=", "float", "(", "unparsed_args", "[", "i", "+", "1", "]", ")", "# this can raise another informative ValueError", "\n", "\n", "", "", "result", "[", "unparsed_args", "[", "i", "]", "[", "2", ":", "]", "]", "=", "value", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.write_txt_file": [[614, 619], ["pathlib.Path().open", "Path().open.write", "Path().open.flush", "pathlib.Path"], "function", ["None"], ["", "def", "write_txt_file", "(", "ordered_tgt", ",", "path", ")", ":", "\n", "    ", "f", "=", "Path", "(", "path", ")", ".", "open", "(", "\"w\"", ")", "\n", "for", "ln", "in", "ordered_tgt", ":", "\n", "        ", "f", ".", "write", "(", "ln", "+", "\"\\n\"", ")", "\n", "f", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.chunks": [[621, 625], ["range", "len"], "function", ["None"], ["", "", "def", "chunks", "(", "lst", ",", "n", ")", ":", "\n", "    ", "\"\"\"Yield successive n-sized chunks from lst.\"\"\"", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "lst", ")", ",", "n", ")", ":", "\n", "        ", "yield", "lst", "[", "i", ":", "i", "+", "n", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.utils.check_output_dir": [[627, 646], ["os.path.exists", "ValueError", "len", "os.listdir", "len", "os.listdir"], "function", ["None"], ["", "", "def", "check_output_dir", "(", "args", ",", "expected_items", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Checks whether to bail out if output_dir already exists and has more than expected_items in it\n\n    `args`: needs to have the following attributes of `args`:\n      - output_dir\n      - do_train\n      - overwrite_output_dir\n\n    `expected_items`: normally 0 (default) - i.e. empty dir, but in some cases a few files are expected (e.g. recovery from OOM)\n    \"\"\"", "\n", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "len", "(", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", ")", ">", "expected_items", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Output directory ({args.output_dir}) already exists and \"", "\n", "f\"has {len(os.listdir(args.output_dir))} items in it (expected {expected_items} items). \"", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.__init__": [[78, 131], ["pytorch_lightning.LightningModule.__init__", "lightning_base.BaseTransformer.save_hyperparameters", "pathlib.Path", "transformers.AutoConfig.from_pretrained", "getattr", "transformers.AutoTokenizer.from_pretrained", "lightning_base.BaseTransformer.model_type.from_pretrained", "hasattr", "setattr", "getattr", "bool"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "hparams", ":", "argparse", ".", "Namespace", ",", "\n", "num_labels", "=", "None", ",", "\n", "mode", "=", "\"base\"", ",", "\n", "config", "=", "None", ",", "\n", "tokenizer", "=", "None", ",", "\n", "model", "=", "None", ",", "\n", "**", "config_kwargs", "\n", ")", ":", "\n", "        ", "\"\"\"Initialize a model, tokenizer and config.\"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# TODO: move to self.save_hyperparameters()", "\n", "# self.save_hyperparameters()", "\n", "# can also expand arguments into trainer signature for easier reading", "\n", "\n", "self", ".", "save_hyperparameters", "(", "hparams", ")", "\n", "self", ".", "step_count", "=", "0", "\n", "self", ".", "output_dir", "=", "Path", "(", "self", ".", "hparams", ".", "output_dir", ")", "\n", "cache_dir", "=", "self", ".", "hparams", ".", "cache_dir", "if", "self", ".", "hparams", ".", "cache_dir", "else", "None", "\n", "if", "config", "is", "None", ":", "\n", "            ", "self", ".", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "self", ".", "hparams", ".", "config_name", "if", "self", ".", "hparams", ".", "config_name", "else", "self", ".", "hparams", ".", "model_name_or_path", ",", "\n", "**", "(", "{", "\"num_labels\"", ":", "num_labels", "}", "if", "num_labels", "is", "not", "None", "else", "{", "}", ")", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", "**", "config_kwargs", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "config", ":", "PretrainedConfig", "=", "config", "\n", "\n", "", "extra_model_params", "=", "(", "\"encoder_layerdrop\"", ",", "\"decoder_layerdrop\"", ",", "\"dropout\"", ",", "\"attention_dropout\"", ")", "\n", "for", "p", "in", "extra_model_params", ":", "\n", "            ", "if", "getattr", "(", "self", ".", "hparams", ",", "p", ",", "None", ")", ":", "\n", "                ", "assert", "hasattr", "(", "self", ".", "config", ",", "p", ")", ",", "f\"model config doesn't have a `{p}` attribute\"", "\n", "setattr", "(", "self", ".", "config", ",", "p", ",", "getattr", "(", "self", ".", "hparams", ",", "p", ")", ")", "\n", "\n", "", "", "if", "tokenizer", "is", "None", ":", "\n", "            ", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "self", ".", "hparams", ".", "tokenizer_name", "if", "self", ".", "hparams", ".", "tokenizer_name", "else", "self", ".", "hparams", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "tokenizer", ":", "PreTrainedTokenizer", "=", "tokenizer", "\n", "", "self", ".", "model_type", "=", "MODEL_MODES", "[", "mode", "]", "\n", "if", "model", "is", "None", ":", "\n", "            ", "self", ".", "model", "=", "self", ".", "model_type", ".", "from_pretrained", "(", "\n", "self", ".", "hparams", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "self", ".", "hparams", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "self", ".", "config", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", "=", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.load_hf_checkpoint": [[132, 134], ["lightning_base.BaseTransformer.model_type.from_pretrained"], "methods", ["None"], ["", "", "def", "load_hf_checkpoint", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "model", "=", "self", ".", "model_type", ".", "from_pretrained", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.get_lr_scheduler": [[135, 142], ["get_schedule_func", "lightning_base.BaseTransformer.total_steps"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.total_steps"], ["", "def", "get_lr_scheduler", "(", "self", ")", ":", "\n", "        ", "get_schedule_func", "=", "arg_to_scheduler", "[", "self", ".", "hparams", ".", "lr_scheduler", "]", "\n", "scheduler", "=", "get_schedule_func", "(", "\n", "self", ".", "opt", ",", "num_warmup_steps", "=", "self", ".", "hparams", ".", "warmup_steps", ",", "num_training_steps", "=", "self", ".", "total_steps", "(", ")", "\n", ")", "\n", "scheduler", "=", "{", "\"scheduler\"", ":", "scheduler", ",", "\"interval\"", ":", "\"step\"", ",", "\"frequency\"", ":", "1", "}", "\n", "return", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.configure_optimizers": [[143, 170], ["lightning_base.BaseTransformer.get_lr_scheduler", "transformers.optimization.Adafactor", "transformers.AdamW", "model.named_parameters", "model.named_parameters", "any", "any"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.get_lr_scheduler"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "\"\"\"Prepare optimizer and schedule (linear warmup and decay)\"\"\"", "\n", "model", "=", "self", ".", "model", "\n", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "self", ".", "hparams", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "}", ",", "\n", "]", "\n", "if", "self", ".", "hparams", ".", "adafactor", ":", "\n", "            ", "optimizer", "=", "Adafactor", "(", "\n", "optimizer_grouped_parameters", ",", "lr", "=", "self", ".", "hparams", ".", "learning_rate", ",", "scale_parameter", "=", "False", ",", "relative_step", "=", "False", "\n", ")", "\n", "\n", "", "else", ":", "\n", "            ", "optimizer", "=", "AdamW", "(", "\n", "optimizer_grouped_parameters", ",", "lr", "=", "self", ".", "hparams", ".", "learning_rate", ",", "eps", "=", "self", ".", "hparams", ".", "adam_epsilon", "\n", ")", "\n", "", "self", ".", "opt", "=", "optimizer", "\n", "scheduler", "=", "self", ".", "get_lr_scheduler", "(", ")", "\n", "\n", "return", "[", "optimizer", "]", ",", "[", "scheduler", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.test_step": [[171, 173], ["lightning_base.BaseTransformer.validation_step"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.finetune.SummarizationModule.validation_step"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_nb", ")", ":", "\n", "        ", "return", "self", ".", "validation_step", "(", "batch", ",", "batch_nb", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.test_epoch_end": [[174, 176], ["lightning_base.BaseTransformer.validation_end"], "methods", ["None"], ["", "def", "test_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "return", "self", ".", "validation_end", "(", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.total_steps": [[177, 182], ["max"], "methods", ["None"], ["", "def", "total_steps", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"The number of total training steps that will be run. Used for lr scheduler purposes.\"\"\"", "\n", "num_devices", "=", "max", "(", "1", ",", "self", ".", "hparams", ".", "gpus", ")", "# TODO: consider num_tpu_cores", "\n", "effective_batch_size", "=", "self", ".", "hparams", ".", "train_batch_size", "*", "self", ".", "hparams", ".", "accumulate_grad_batches", "*", "num_devices", "\n", "return", "(", "self", ".", "dataset_size", "/", "effective_batch_size", ")", "*", "self", ".", "hparams", ".", "max_epochs", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.setup": [[183, 189], ["len", "lightning_base.BaseTransformer.get_dataloader", "len", "lightning_base.BaseTransformer.test_dataloader", "lightning_base.BaseTransformer.train_dataloader"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.get_dataloader", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.test_dataloader", "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.train_dataloader"], ["", "def", "setup", "(", "self", ",", "mode", ")", ":", "\n", "        ", "if", "mode", "==", "\"test\"", ":", "\n", "            ", "self", ".", "dataset_size", "=", "len", "(", "self", ".", "test_dataloader", "(", ")", ".", "dataset", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "train_loader", "=", "self", ".", "get_dataloader", "(", "\"train\"", ",", "self", ".", "hparams", ".", "train_batch_size", ",", "shuffle", "=", "True", ")", "\n", "self", ".", "dataset_size", "=", "len", "(", "self", ".", "train_dataloader", "(", ")", ".", "dataset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.get_dataloader": [[190, 192], ["NotImplementedError"], "methods", ["None"], ["", "", "def", "get_dataloader", "(", "self", ",", "type_path", ":", "str", ",", "batch_size", ":", "int", ",", "shuffle", ":", "bool", "=", "False", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"You must implement this for your task\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.train_dataloader": [[193, 195], ["None"], "methods", ["None"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "train_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.val_dataloader": [[196, 198], ["lightning_base.BaseTransformer.get_dataloader"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.get_dataloader"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "get_dataloader", "(", "\"dev\"", ",", "self", ".", "hparams", ".", "eval_batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.test_dataloader": [[199, 201], ["lightning_base.BaseTransformer.get_dataloader"], "methods", ["home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.get_dataloader"], ["", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "get_dataloader", "(", "\"test\"", ",", "self", ".", "hparams", ".", "eval_batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer._feature_file": [[202, 209], ["os.path.join", "list().pop", "str", "list", "filter", "lightning_base.BaseTransformer.hparams.model_name_or_path.split"], "methods", ["None"], ["", "def", "_feature_file", "(", "self", ",", "mode", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "hparams", ".", "data_dir", ",", "\n", "\"cached_{}_{}_{}\"", ".", "format", "(", "\n", "mode", ",", "\n", "list", "(", "filter", "(", "None", ",", "self", ".", "hparams", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "self", ".", "hparams", ".", "max_seq_length", ")", ",", "\n", ")", ",", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.on_save_checkpoint": [[212, 218], ["lightning_base.BaseTransformer.output_dir.joinpath", "lightning_base.BaseTransformer.model.save_pretrained", "lightning_base.BaseTransformer.tokenizer.save_pretrained"], "methods", ["None"], ["", "@", "pl", ".", "utilities", ".", "rank_zero_only", "\n", "def", "on_save_checkpoint", "(", "self", ",", "checkpoint", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "None", ":", "\n", "        ", "save_path", "=", "self", ".", "output_dir", ".", "joinpath", "(", "\"best_tfmr\"", ")", "\n", "self", ".", "model", ".", "config", ".", "save_step", "=", "self", ".", "step_count", "\n", "self", ".", "model", ".", "save_pretrained", "(", "save_path", ")", "\n", "self", ".", "tokenizer", ".", "save_pretrained", "(", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.BaseTransformer.add_model_specific_args": [[219, 280], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "add_model_specific_args", "(", "parser", ",", "root_dir", ")", ":", "\n", "        ", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pretrained model or model identifier from huggingface.co/models\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from huggingface.co\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--encoder_layerdrop\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Encoder layer dropout probability (Optional). Goes into model.config\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--decoder_layerdrop\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Decoder layer dropout probability (Optional). Goes into model.config\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Dropout probability (Optional). Goes into model.config\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--attention_dropout\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"Attention dropout probability (Optional). Goes into model.config\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lr_scheduler\"", ",", "\n", "default", "=", "\"linear\"", ",", "\n", "choices", "=", "arg_to_scheduler_choices", ",", "\n", "metavar", "=", "arg_to_scheduler_metavar", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Learning rate scheduler\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_workers\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"kwarg passed to DataLoader\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "dest", "=", "\"max_epochs\"", ",", "default", "=", "3", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_batch_size\"", ",", "default", "=", "32", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_batch_size\"", ",", "default", "=", "32", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--adafactor\"", ",", "action", "=", "\"store_true\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.LoggingCallback.on_batch_end": [[283, 287], ["pl_module.logger.log_metrics", "enumerate", "lr_scheduler.get_lr"], "methods", ["None"], ["    ", "def", "on_batch_end", "(", "self", ",", "trainer", ",", "pl_module", ")", ":", "\n", "        ", "lr_scheduler", "=", "trainer", ".", "lr_schedulers", "[", "0", "]", "[", "\"scheduler\"", "]", "\n", "lrs", "=", "{", "f\"lr_group_{i}\"", ":", "lr", "for", "i", ",", "lr", "in", "enumerate", "(", "lr_scheduler", ".", "get_lr", "(", ")", ")", "}", "\n", "pl_module", ".", "logger", ".", "log_metrics", "(", "lrs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.LoggingCallback.on_validation_end": [[288, 295], ["pytorch_lightning.utilities.rank_zero_info", "sorted", "pytorch_lightning.utilities.rank_zero_info", "str"], "methods", ["None"], ["", "def", "on_validation_end", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ",", "pl_module", ":", "pl", ".", "LightningModule", ")", ":", "\n", "        ", "rank_zero_info", "(", "\"***** Validation results *****\"", ")", "\n", "metrics", "=", "trainer", ".", "callback_metrics", "\n", "# Log results", "\n", "for", "key", "in", "sorted", "(", "metrics", ")", ":", "\n", "            ", "if", "key", "not", "in", "[", "\"log\"", ",", "\"progress_bar\"", "]", ":", "\n", "                ", "rank_zero_info", "(", "\"{} = {}\\n\"", ".", "format", "(", "key", ",", "str", "(", "metrics", "[", "key", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.LoggingCallback.on_test_end": [[296, 306], ["pytorch_lightning.utilities.rank_zero_info", "os.path.join", "open", "sorted", "pytorch_lightning.utilities.rank_zero_info", "writer.write", "str", "str"], "methods", ["None"], ["", "", "", "def", "on_test_end", "(", "self", ",", "trainer", ":", "pl", ".", "Trainer", ",", "pl_module", ":", "pl", ".", "LightningModule", ")", ":", "\n", "        ", "rank_zero_info", "(", "\"***** Test results *****\"", ")", "\n", "metrics", "=", "trainer", ".", "callback_metrics", "\n", "# Log and save results to file", "\n", "output_test_results_file", "=", "os", ".", "path", ".", "join", "(", "pl_module", ".", "hparams", ".", "output_dir", ",", "\"test_results.txt\"", ")", "\n", "with", "open", "(", "output_test_results_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "for", "key", "in", "sorted", "(", "metrics", ")", ":", "\n", "                ", "if", "key", "not", "in", "[", "\"log\"", ",", "\"progress_bar\"", "]", ":", "\n", "                    ", "rank_zero_info", "(", "\"{} = {}\\n\"", ".", "format", "(", "key", ",", "str", "(", "metrics", "[", "key", "]", ")", ")", ")", "\n", "writer", ".", "write", "(", "\"{} = {}\\n\"", ".", "format", "(", "key", ",", "str", "(", "metrics", "[", "key", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.require_min_ver": [[41, 46], ["pkg_resources.get_distribution", "packaging.version.parse", "packaging.version.parse", "logger.warning"], "function", ["None"], ["def", "require_min_ver", "(", "pkg", ",", "min_ver", ")", ":", "\n", "    ", "got_ver", "=", "pkg_resources", ".", "get_distribution", "(", "pkg", ")", ".", "version", "\n", "if", "packaging", ".", "version", ".", "parse", "(", "got_ver", ")", "<", "packaging", ".", "version", ".", "parse", "(", "min_ver", ")", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "f\"{pkg}>={min_ver} is required for a normal functioning of this module, but found {pkg}=={got_ver}. \"", "\n", "\"Try: pip install -r examples/requirements.txt\"", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.add_generic_args": [[308, 349], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "", "", "", "", "def", "add_generic_args", "(", "parser", ",", "root_dir", ")", "->", "None", ":", "\n", "#  To allow all pl args uncomment the following line", "\n", "#  parser = pl.Trainer.add_argparse_args(parser)", "\n", "    ", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O2\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--n_tpu_cores\"", ",", "dest", "=", "\"tpu_cores\"", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "dest", "=", "\"gradient_clip_val\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_predict\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run predictions on the test set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "dest", "=", "\"accumulate_grad_batches\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The input data dir. Should contain the training files for the CoNLL-2003 NER task.\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.shichaosun_conabssum.src.lightning_base.generic_train": [[352, 403], ["pytorch_lightning.seed_everything", "pathlib.Path", "pathlib.Path.mkdir", "pytorch_lightning.Trainer.from_argparse_args", "pytorch_lightning.callbacks.ModelCheckpoint", "extra_callbacks.append", "lightning_base.LoggingCallback", "pl.Trainer.from_argparse_args.fit"], "function", ["None"], ["", "def", "generic_train", "(", "\n", "model", ":", "BaseTransformer", ",", "\n", "args", ":", "argparse", ".", "Namespace", ",", "\n", "early_stopping_callback", "=", "None", ",", "\n", "logger", "=", "True", ",", "# can pass WandbLogger() here", "\n", "extra_callbacks", "=", "[", "]", ",", "\n", "checkpoint_callback", "=", "None", ",", "\n", "logging_callback", "=", "None", ",", "\n", "**", "extra_train_kwargs", "\n", ")", ":", "\n", "    ", "pl", ".", "seed_everything", "(", "args", ".", "seed", ")", "\n", "\n", "# init model", "\n", "odir", "=", "Path", "(", "model", ".", "hparams", ".", "output_dir", ")", "\n", "odir", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "\n", "# add custom checkpoints", "\n", "if", "checkpoint_callback", "is", "None", ":", "\n", "        ", "checkpoint_callback", "=", "pl", ".", "callbacks", ".", "ModelCheckpoint", "(", "\n", "filepath", "=", "args", ".", "output_dir", ",", "prefix", "=", "\"checkpoint\"", ",", "monitor", "=", "\"val_loss\"", ",", "mode", "=", "\"min\"", ",", "save_top_k", "=", "1", "\n", ")", "\n", "", "if", "early_stopping_callback", ":", "\n", "        ", "extra_callbacks", ".", "append", "(", "early_stopping_callback", ")", "\n", "", "if", "logging_callback", "is", "None", ":", "\n", "        ", "logging_callback", "=", "LoggingCallback", "(", ")", "\n", "\n", "", "train_params", "=", "{", "}", "\n", "\n", "# TODO: remove with PyTorch 1.6 since pl uses native amp", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "train_params", "[", "\"precision\"", "]", "=", "16", "\n", "train_params", "[", "\"amp_level\"", "]", "=", "args", ".", "fp16_opt_level", "\n", "\n", "", "if", "args", ".", "gpus", ">", "1", ":", "\n", "        ", "train_params", "[", "\"distributed_backend\"", "]", "=", "\"ddp\"", "\n", "\n", "", "train_params", "[", "\"accumulate_grad_batches\"", "]", "=", "args", ".", "accumulate_grad_batches", "\n", "\n", "trainer", "=", "pl", ".", "Trainer", ".", "from_argparse_args", "(", "\n", "args", ",", "\n", "weights_summary", "=", "None", ",", "\n", "callbacks", "=", "[", "logging_callback", "]", "+", "extra_callbacks", ",", "\n", "logger", "=", "logger", ",", "\n", "checkpoint_callback", "=", "checkpoint_callback", ",", "\n", "**", "train_params", ",", "\n", ")", "\n", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "trainer", ".", "fit", "(", "model", ")", "\n", "\n", "", "return", "trainer", "\n", "", ""]]}