{"home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.pytorch.run_pre.run_exp": [[13, 34], ["os.system", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["None"], ["def", "run_exp", "(", "lr", "=", "0.1", ",", "gamma", "=", "0.2", ",", "step_size", "=", "30", ")", ":", "\n", "    ", "max_epoch", "=", "110", "\n", "shot", "=", "1", "\n", "query", "=", "15", "\n", "way", "=", "5", "\n", "gpu", "=", "1", "\n", "base_lr", "=", "0.01", "\n", "\n", "the_command", "=", "'python3 main.py'", "+", "' --pre_max_epoch='", "+", "str", "(", "max_epoch", ")", "+", "' --shot='", "+", "str", "(", "shot", ")", "+", "' --train_query='", "+", "str", "(", "query", ")", "+", "' --way='", "+", "str", "(", "way", ")", "+", "' --pre_step_size='", "+", "str", "(", "step_size", ")", "+", "' --pre_gamma='", "+", "str", "(", "gamma", ")", "+", "' --gpu='", "+", "str", "(", "gpu", ")", "+", "' --base_lr='", "+", "str", "(", "base_lr", ")", "+", "' --pre_lr='", "+", "str", "(", "lr", ")", "+", "' --phase=pre_train'", "\n", "\n", "os", ".", "system", "(", "the_command", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.pytorch.run_meta.run_exp": [[13, 35], ["os.system", "os.system", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["None"], ["def", "run_exp", "(", "num_batch", "=", "1000", ",", "shot", "=", "1", ",", "query", "=", "15", ",", "lr1", "=", "0.0001", ",", "lr2", "=", "0.001", ",", "base_lr", "=", "0.01", ",", "update_step", "=", "10", ",", "gamma", "=", "0.5", ")", ":", "\n", "    ", "max_epoch", "=", "100", "\n", "way", "=", "5", "\n", "step_size", "=", "10", "\n", "gpu", "=", "1", "\n", "\n", "the_command", "=", "'python3 main.py'", "+", "' --max_epoch='", "+", "str", "(", "max_epoch", ")", "+", "' --num_batch='", "+", "str", "(", "num_batch", ")", "+", "' --shot='", "+", "str", "(", "shot", ")", "+", "' --train_query='", "+", "str", "(", "query", ")", "+", "' --way='", "+", "str", "(", "way", ")", "+", "' --meta_lr1='", "+", "str", "(", "lr1", ")", "+", "' --meta_lr2='", "+", "str", "(", "lr2", ")", "+", "' --step_size='", "+", "str", "(", "step_size", ")", "+", "' --gamma='", "+", "str", "(", "gamma", ")", "+", "' --gpu='", "+", "str", "(", "gpu", ")", "+", "' --base_lr='", "+", "str", "(", "base_lr", ")", "+", "' --update_step='", "+", "str", "(", "update_step", ")", "\n", "\n", "os", ".", "system", "(", "the_command", "+", "' --phase=meta_train'", ")", "\n", "os", ".", "system", "(", "the_command", "+", "' --phase=meta_eval'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.gpu_tools.set_gpu": [[14, 17], ["print"], "function", ["None"], ["def", "set_gpu", "(", "cuda_device", ")", ":", "\n", "    ", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "cuda_device", "\n", "print", "(", "'Using gpu:'", ",", "cuda_device", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Averager.__init__": [[31, 34], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "n", "=", "0", "\n", "self", ".", "v", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Averager.add": [[35, 38], ["None"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "x", ")", ":", "\n", "        ", "self", ".", "v", "=", "(", "self", ".", "v", "*", "self", ".", "n", "+", "x", ")", "/", "(", "self", ".", "n", "+", "1", ")", "\n", "self", ".", "n", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Averager.item": [[39, 41], ["None"], "methods", ["None"], ["", "def", "item", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Timer.__init__": [[57, 59], ["time.time"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "o", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Timer.measure": [[60, 68], ["int", "time.time", "round"], "methods", ["None"], ["", "def", "measure", "(", "self", ",", "p", "=", "1", ")", ":", "\n", "        ", "x", "=", "(", "time", ".", "time", "(", ")", "-", "self", ".", "o", ")", "/", "p", "\n", "x", "=", "int", "(", "x", ")", "\n", "if", "x", ">=", "3600", ":", "\n", "            ", "return", "'{:.1f}h'", ".", "format", "(", "x", "/", "3600", ")", "\n", "", "if", "x", ">=", "60", ":", "\n", "            ", "return", "'{}m'", ".", "format", "(", "round", "(", "x", "/", "60", ")", ")", "\n", "", "return", "'{}s'", ".", "format", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.ensure_path": [[19, 28], ["os.path.exists", "os.mkdir"], "function", ["None"], ["def", "ensure_path", "(", "path", ")", ":", "\n", "    ", "\"\"\"The function to make log path.\n    Args:\n      path: the generated saving path.\n    \"\"\"", "\n", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "pass", "\n", "", "else", ":", "\n", "        ", "os", ".", "mkdir", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.count_acc": [[42, 54], ["torch.softmax().argmax", "torch.cuda.is_available", "torch.cuda.is_available", "torch.softmax"], "function", ["None"], ["", "", "def", "count_acc", "(", "logits", ",", "label", ")", ":", "\n", "    ", "\"\"\"The function to calculate the .\n    Args:\n      logits: input logits.\n      label: ground truth labels.\n    Return:\n      The output accuracy.\n    \"\"\"", "\n", "pred", "=", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "1", ")", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "(", "pred", "==", "label", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "return", "(", "pred", "==", "label", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.pprint": [[71, 73], ["_utils_pp.pprint"], "function", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.pprint"], ["def", "pprint", "(", "x", ")", ":", "\n", "    ", "_utils_pp", ".", "pprint", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.compute_confidence_interval": [[74, 88], ["numpy.mean", "numpy.std", "numpy.array", "numpy.sqrt", "len"], "function", ["None"], ["", "def", "compute_confidence_interval", "(", "data", ")", ":", "\n", "    ", "\"\"\"The function to calculate the .\n    Args:\n      data: input records\n      label: ground truth labels.\n    Return:\n      m: mean value\n      pm: confidence interval.\n    \"\"\"", "\n", "a", "=", "1.0", "*", "np", ".", "array", "(", "data", ")", "\n", "m", "=", "np", ".", "mean", "(", "a", ")", "\n", "std", "=", "np", ".", "std", "(", "a", ")", "\n", "pm", "=", "1.96", "*", "(", "std", "/", "np", ".", "sqrt", "(", "len", "(", "a", ")", ")", ")", "\n", "return", "m", ",", "pm", "\n", "", ""]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.get_smallest_k_index": [[25, 40], ["numpy.copy", "range", "numpy.argmin", "k_list.append", "numpy.max"], "function", ["None"], ["        ", "pass", "\n", "", "else", ":", "\n", "        ", "os", ".", "mkdir", "(", "path", ")", "\n", "\n", "", "", "class", "Averager", "(", ")", ":", "\n", "    ", "\"\"\"The class to calculate the average.\"\"\"", "\n", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "n", "=", "0", "\n", "self", ".", "v", "=", "0", "\n", "\n", "", "def", "add", "(", "self", ",", "x", ")", ":", "\n", "        ", "self", ".", "v", "=", "(", "self", ".", "v", "*", "self", ".", "n", "+", "x", ")", "/", "(", "self", ".", "n", "+", "1", ")", "\n", "self", ".", "n", "+=", "1", "\n", "\n", "", "def", "item", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "v", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.one_hot": [[41, 54], ["numpy.zeros", "range", "inp.max"], "function", ["None"], ["\n", "", "", "def", "count_acc", "(", "logits", ",", "label", ")", ":", "\n", "    ", "\"\"\"The function to calculate the .\n    Args:\n      logits: input logits.\n      label: ground truth labels.\n    Return:\n      The output accuracy.\n    \"\"\"", "\n", "pred", "=", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "1", ")", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "(", "pred", "==", "label", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "return", "(", "pred", "==", "label", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.one_hot_class": [[55, 68], ["numpy.zeros", "range"], "function", ["None"], ["", "class", "Timer", "(", ")", ":", "\n", "    ", "\"\"\"The class for timer.\"\"\"", "\n", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "o", "=", "time", ".", "time", "(", ")", "\n", "\n", "", "def", "measure", "(", "self", ",", "p", "=", "1", ")", ":", "\n", "        ", "x", "=", "(", "time", ".", "time", "(", ")", "-", "self", ".", "o", ")", "/", "p", "\n", "x", "=", "int", "(", "x", ")", "\n", "if", "x", ">=", "3600", ":", "\n", "            ", "return", "'{:.1f}h'", ".", "format", "(", "x", "/", "3600", ")", "\n", "", "if", "x", ">=", "60", ":", "\n", "            ", "return", "'{}m'", ".", "format", "(", "round", "(", "x", "/", "60", ")", ")", "\n", "", "return", "'{}s'", ".", "format", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.process_batch": [[69, 100], ["range", "numpy.array().reshape", "one_hot().reshape", "list", "random.shuffle", "matplotlib.pyplot.imread", "numpy.reshape", "img_list.append", "range", "new_path_list.append", "new_label_list.append", "numpy.array", "misc.one_hot", "numpy.array"], "function", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.one_hot"], ["", "", "_utils_pp", "=", "pprint", ".", "PrettyPrinter", "(", ")", "\n", "\n", "def", "pprint", "(", "x", ")", ":", "\n", "    ", "_utils_pp", ".", "pprint", "(", "x", ")", "\n", "\n", "", "def", "compute_confidence_interval", "(", "data", ")", ":", "\n", "    ", "\"\"\"The function to calculate the .\n    Args:\n      data: input records\n      label: ground truth labels.\n    Return:\n      m: mean value\n      pm: confidence interval.\n    \"\"\"", "\n", "a", "=", "1.0", "*", "np", ".", "array", "(", "data", ")", "\n", "m", "=", "np", ".", "mean", "(", "a", ")", "\n", "std", "=", "np", ".", "std", "(", "a", ")", "\n", "pm", "=", "1.96", "*", "(", "std", "/", "np", ".", "sqrt", "(", "len", "(", "a", ")", ")", ")", "\n", "return", "m", ",", "pm", "\n", "", ""]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.process_batch_augmentation": [[101, 140], ["range", "numpy.array().reshape", "one_hot().reshape", "list", "random.shuffle", "matplotlib.pyplot.imread", "cv2.flip", "numpy.reshape", "img_list.append", "numpy.reshape", "img_list_h.append", "range", "new_path_list.append", "new_label_list.append", "numpy.array", "misc.one_hot", "numpy.array"], "function", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.one_hot"], []], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.get_images": [[142, 162], ["random.shuffle", "random.sample", "os.path.join", "zip", "sampler", "os.listdir"], "function", ["None"], []], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.get_pretrain_images": [[163, 176], ["os.listdir", "images.append", "os.path.join"], "function", ["None"], []], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.get_images_tc": [[177, 203], ["random.shuffle", "random.sample", "os.path.join", "zip", "sampler", "os.path.join", "zip", "sampler", "os.listdir", "os.listdir"], "function", ["None"], []], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.leaky_relu": [[207, 216], ["tensorflow.maximum"], "function", ["None"], []], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.resnet_conv_block": [[217, 242], ["misc.normalize", "tensorflow.nn.conv2d"], "function", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.normalize"], []], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.resnet_nob_conv_block": [[243, 256], ["tensorflow.nn.conv2d"], "function", ["None"], []], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.normalize": [[257, 277], ["tensorflow.contrib.layers.python.layers.batch_norm", "tensorflow.contrib.layers.python.layers.layer_norm", "ValueError", "activation"], "function", ["None"], []], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.mse": [[280, 291], ["tensorflow.reshape", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.square"], "function", ["None"], []], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.softmaxloss": [[292, 301], ["tensorflow.reduce_mean", "tensorflow.nn.softmax_cross_entropy_with_logits"], "function", ["None"], []], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.xent": [[302, 312], ["tensorflow.nn.softmax_cross_entropy_with_logits"], "function", ["None"], []], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.dataloader.samplers.CategoriesSampler.__init__": [[17, 28], ["numpy.array", "range", "numpy.argwhere().reshape", "torch.from_numpy", "samplers.CategoriesSampler.m_ind.append", "max", "numpy.argwhere"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "label", ",", "n_batch", ",", "n_cls", ",", "n_per", ")", ":", "\n", "        ", "self", ".", "n_batch", "=", "n_batch", "\n", "self", ".", "n_cls", "=", "n_cls", "\n", "self", ".", "n_per", "=", "n_per", "\n", "\n", "label", "=", "np", ".", "array", "(", "label", ")", "\n", "self", ".", "m_ind", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "max", "(", "label", ")", "+", "1", ")", ":", "\n", "            ", "ind", "=", "np", ".", "argwhere", "(", "label", "==", "i", ")", ".", "reshape", "(", "-", "1", ")", "\n", "ind", "=", "torch", ".", "from_numpy", "(", "ind", ")", "\n", "self", ".", "m_ind", ".", "append", "(", "ind", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.dataloader.samplers.CategoriesSampler.__len__": [[29, 31], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_batch", "\n", "", "def", "__iter__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.dataloader.samplers.CategoriesSampler.__iter__": [[31, 41], ["range", "torch.stack().t().reshape", "torch.randperm", "torch.stack().t().reshape.append", "len", "torch.randperm", "torch.stack().t", "len", "torch.stack"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "i_batch", "in", "range", "(", "self", ".", "n_batch", ")", ":", "\n", "            ", "batch", "=", "[", "]", "\n", "classes", "=", "torch", ".", "randperm", "(", "len", "(", "self", ".", "m_ind", ")", ")", "[", ":", "self", ".", "n_cls", "]", "\n", "for", "c", "in", "classes", ":", "\n", "                ", "l", "=", "self", ".", "m_ind", "[", "c", "]", "\n", "pos", "=", "torch", ".", "randperm", "(", "len", "(", "l", ")", ")", "[", ":", "self", ".", "n_per", "]", "\n", "batch", ".", "append", "(", "l", "[", "pos", "]", ")", "\n", "", "batch", "=", "torch", ".", "stack", "(", "batch", ")", ".", "t", "(", ")", ".", "reshape", "(", "-", "1", ")", "\n", "yield", "batch", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.dataloader.dataset_loader.DatasetLoader.__init__": [[21, 73], ["enumerate", "len", "os.join", "os.join", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "os.join", "os.join", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "set", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "os.join", "os.join", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "os.path.isdir", "os.path.isdir", "os.path.isdir", "os.path.isdir", "data.append", "label.append", "os.join", "os.join", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "ValueError", "os.join", "os.join", "os.join", "os.join", "torchvision.transforms.Resize", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.CenterCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "setname", ",", "args", ",", "train_aug", "=", "False", ")", ":", "\n", "# Set the path according to train, val and test        ", "\n", "        ", "if", "setname", "==", "'train'", ":", "\n", "            ", "THE_PATH", "=", "osp", ".", "join", "(", "args", ".", "dataset_dir", ",", "'train'", ")", "\n", "label_list", "=", "os", ".", "listdir", "(", "THE_PATH", ")", "\n", "", "elif", "setname", "==", "'test'", ":", "\n", "            ", "THE_PATH", "=", "osp", ".", "join", "(", "args", ".", "dataset_dir", ",", "'test'", ")", "\n", "label_list", "=", "os", ".", "listdir", "(", "THE_PATH", ")", "\n", "", "elif", "setname", "==", "'val'", ":", "\n", "            ", "THE_PATH", "=", "osp", ".", "join", "(", "args", ".", "dataset_dir", ",", "'val'", ")", "\n", "label_list", "=", "os", ".", "listdir", "(", "THE_PATH", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Wrong setname.'", ")", "\n", "\n", "# Generate empty list for data and label           ", "\n", "", "data", "=", "[", "]", "\n", "label", "=", "[", "]", "\n", "\n", "# Get folders' name", "\n", "folders", "=", "[", "osp", ".", "join", "(", "THE_PATH", ",", "the_label", ")", "for", "the_label", "in", "label_list", "if", "os", ".", "path", ".", "isdir", "(", "osp", ".", "join", "(", "THE_PATH", ",", "the_label", ")", ")", "]", "\n", "\n", "# Get the images' paths and labels", "\n", "for", "idx", ",", "this_folder", "in", "enumerate", "(", "folders", ")", ":", "\n", "            ", "this_folder_images", "=", "os", ".", "listdir", "(", "this_folder", ")", "\n", "for", "image_path", "in", "this_folder_images", ":", "\n", "                ", "data", ".", "append", "(", "osp", ".", "join", "(", "this_folder", ",", "image_path", ")", ")", "\n", "label", ".", "append", "(", "idx", ")", "\n", "\n", "# Set data, label and class number to be accessable from outside", "\n", "", "", "self", ".", "data", "=", "data", "\n", "self", ".", "label", "=", "label", "\n", "self", ".", "num_class", "=", "len", "(", "set", "(", "label", ")", ")", "\n", "\n", "# Transformation", "\n", "if", "train_aug", ":", "\n", "            ", "image_size", "=", "80", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "92", ")", ",", "\n", "transforms", ".", "RandomResizedCrop", "(", "88", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "image_size", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "np", ".", "array", "(", "[", "x", "/", "255.0", "for", "x", "in", "[", "125.3", ",", "123.0", ",", "113.9", "]", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "x", "/", "255.0", "for", "x", "in", "[", "63.0", ",", "62.1", ",", "66.7", "]", "]", ")", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "image_size", "=", "80", "\n", "self", ".", "transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "92", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "image_size", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "np", ".", "array", "(", "[", "x", "/", "255.0", "for", "x", "in", "[", "125.3", ",", "123.0", ",", "113.9", "]", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "x", "/", "255.0", "for", "x", "in", "[", "63.0", ",", "62.1", ",", "66.7", "]", "]", ")", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.dataloader.dataset_loader.DatasetLoader.__len__": [[75, 77], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.dataloader.dataset_loader.DatasetLoader.__getitem__": [[78, 82], ["dataset_loader.DatasetLoader.transform", "PIL.Image.open().convert", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "path", ",", "label", "=", "self", ".", "data", "[", "i", "]", ",", "self", ".", "label", "[", "i", "]", "\n", "image", "=", "self", ".", "transform", "(", "Image", ".", "open", "(", "path", ")", ".", "convert", "(", "'RGB'", ")", ")", "\n", "return", "image", ",", "label", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet_mtl.BasicBlock.__init__": [[22, 31], ["torch.Module.__init__", "resnet_mtl.conv3x3", "torch.BatchNorm2d", "torch.ReLU", "resnet_mtl.conv3x3", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.__init__", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet_mtl.conv3x3", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet_mtl.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet_mtl.BasicBlock.forward": [[32, 49], ["resnet_mtl.BasicBlock.conv1", "resnet_mtl.BasicBlock.bn1", "resnet_mtl.BasicBlock.relu", "resnet_mtl.BasicBlock.conv2", "resnet_mtl.BasicBlock.bn2", "resnet_mtl.BasicBlock.relu", "resnet_mtl.BasicBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet_mtl.Bottleneck.__init__": [[53, 65], ["torch.Module.__init__", "torch.Conv2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", "*", "self", ".", "expansion", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet_mtl.Bottleneck.forward": [[66, 87], ["resnet_mtl.Bottleneck.conv1", "resnet_mtl.Bottleneck.bn1", "resnet_mtl.Bottleneck.relu", "resnet_mtl.Bottleneck.conv2", "resnet_mtl.Bottleneck.bn2", "resnet_mtl.Bottleneck.relu", "resnet_mtl.Bottleneck.conv3", "resnet_mtl.Bottleneck.bn3", "resnet_mtl.Bottleneck.relu", "resnet_mtl.Bottleneck.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet_mtl.BasicBlockMtl.__init__": [[96, 105], ["torch.Module.__init__", "resnet_mtl.conv3x3mtl", "torch.BatchNorm2d", "torch.ReLU", "resnet_mtl.conv3x3mtl", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.__init__", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet_mtl.conv3x3mtl", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet_mtl.conv3x3mtl"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlockMtl", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv3x3mtl", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3mtl", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet_mtl.BasicBlockMtl.forward": [[106, 123], ["resnet_mtl.BasicBlockMtl.conv1", "resnet_mtl.BasicBlockMtl.bn1", "resnet_mtl.BasicBlockMtl.relu", "resnet_mtl.BasicBlockMtl.conv2", "resnet_mtl.BasicBlockMtl.bn2", "resnet_mtl.BasicBlockMtl.relu", "resnet_mtl.BasicBlockMtl.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet_mtl.BottleneckMtl.__init__": [[128, 140], ["torch.Module.__init__", "models.conv2d_mtl.Conv2dMtl", "torch.BatchNorm2d", "models.conv2d_mtl.Conv2dMtl", "torch.BatchNorm2d", "models.conv2d_mtl.Conv2dMtl", "torch.BatchNorm2d", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "BottleneckMtl", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "Conv2dMtl", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "Conv2dMtl", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "Conv2dMtl", "(", "planes", ",", "planes", "*", "self", ".", "expansion", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "self", ".", "expansion", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet_mtl.BottleneckMtl.forward": [[141, 162], ["resnet_mtl.BottleneckMtl.conv1", "resnet_mtl.BottleneckMtl.bn1", "resnet_mtl.BottleneckMtl.relu", "resnet_mtl.BottleneckMtl.conv2", "resnet_mtl.BottleneckMtl.bn2", "resnet_mtl.BottleneckMtl.relu", "resnet_mtl.BottleneckMtl.conv3", "resnet_mtl.BottleneckMtl.bn3", "resnet_mtl.BottleneckMtl.relu", "resnet_mtl.BottleneckMtl.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet_mtl.ResNetMtl.__init__": [[165, 189], ["torch.Module.__init__", "int", "resnet_mtl.ResNetMtl.Conv2d", "torch.BatchNorm2d", "torch.ReLU", "resnet_mtl.ResNetMtl._make_layer", "resnet_mtl.ResNetMtl._make_layer", "resnet_mtl.ResNetMtl._make_layer", "torch.AvgPool2d", "resnet_mtl.ResNetMtl.modules", "isinstance", "torch.init.kaiming_normal_", "isinstance", "torch.init.constant_", "torch.init.constant_"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.__init__", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet_mtl.ResNetMtl._make_layer", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet_mtl.ResNetMtl._make_layer", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet_mtl.ResNetMtl._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "layers", "=", "[", "4", ",", "4", ",", "4", "]", ",", "mtl", "=", "True", ")", ":", "\n", "        ", "super", "(", "ResNetMtl", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "mtl", ":", "\n", "            ", "self", ".", "Conv2d", "=", "Conv2dMtl", "\n", "block", "=", "BasicBlockMtl", "\n", "", "else", ":", "\n", "            ", "self", ".", "Conv2d", "=", "nn", ".", "Conv2d", "\n", "block", "=", "BasicBlock", "\n", "", "cfg", "=", "[", "160", ",", "320", ",", "640", "]", "\n", "self", ".", "inplanes", "=", "iChannels", "=", "int", "(", "cfg", "[", "0", "]", "/", "2", ")", "\n", "self", ".", "conv1", "=", "self", ".", "Conv2d", "(", "3", ",", "iChannels", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "iChannels", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "cfg", "[", "0", "]", ",", "layers", "[", "0", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "cfg", "[", "1", "]", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "cfg", "[", "2", "]", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "10", ",", "stride", "=", "1", ")", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "self", ".", "Conv2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "mode", "=", "'fan_out'", ",", "nonlinearity", "=", "'relu'", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "weight", ",", "1", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet_mtl.ResNetMtl._make_layer": [[190, 205], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "block", "layers.append", "resnet_mtl.ResNetMtl.Conv2d", "torch.BatchNorm2d", "block"], "methods", ["None"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "self", ".", "Conv2d", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet_mtl.ResNetMtl.forward": [[206, 218], ["resnet_mtl.ResNetMtl.conv1", "resnet_mtl.ResNetMtl.bn1", "resnet_mtl.ResNetMtl.relu", "resnet_mtl.ResNetMtl.layer1", "resnet_mtl.ResNetMtl.layer2", "resnet_mtl.ResNetMtl.layer3", "resnet_mtl.ResNetMtl.avgpool", "x.view.view.view", "x.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet_mtl.conv3x3": [[15, 18], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet_mtl.conv3x3mtl": [[88, 91], ["models.conv2d_mtl.Conv2dMtl"], "function", ["None"], ["", "", "def", "conv3x3mtl", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "return", "Conv2dMtl", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.mtl.BaseLearner.__init__": [[18, 28], ["torch.Module.__init__", "torch.ParameterList", "torch.ParameterList", "torch.ParameterList", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "torch.nn.init.kaiming_normal_", "mtl.BaseLearner.vars.append", "torch.Parameter", "torch.Parameter", "torch.Parameter", "mtl.BaseLearner.vars.append", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.__init__"], ["def", "__init__", "(", "self", ",", "args", ",", "z_dim", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "self", ".", "vars", "=", "nn", ".", "ParameterList", "(", ")", "\n", "self", ".", "fc1_w", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "[", "self", ".", "args", ".", "way", ",", "self", ".", "z_dim", "]", ")", ")", "\n", "torch", ".", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "fc1_w", ")", "\n", "self", ".", "vars", ".", "append", "(", "self", ".", "fc1_w", ")", "\n", "self", ".", "fc1_b", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "args", ".", "way", ")", ")", "\n", "self", ".", "vars", ".", "append", "(", "self", ".", "fc1_b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.mtl.BaseLearner.forward": [[29, 36], ["torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_x", ",", "the_vars", "=", "None", ")", ":", "\n", "        ", "if", "the_vars", "is", "None", ":", "\n", "            ", "the_vars", "=", "self", ".", "vars", "\n", "", "fc1_w", "=", "the_vars", "[", "0", "]", "\n", "fc1_b", "=", "the_vars", "[", "1", "]", "\n", "net", "=", "F", ".", "linear", "(", "input_x", ",", "fc1_w", ",", "fc1_b", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.mtl.BaseLearner.parameters": [[37, 39], ["None"], "methods", ["None"], ["", "def", "parameters", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "vars", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.mtl.MtlLearner.__init__": [[42, 56], ["torch.Module.__init__", "mtl.BaseLearner", "models.resnet_mtl.ResNetMtl", "models.resnet_mtl.ResNetMtl", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.__init__"], ["def", "__init__", "(", "self", ",", "args", ",", "mode", "=", "'meta'", ",", "num_cls", "=", "64", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "update_lr", "=", "args", ".", "base_lr", "\n", "self", ".", "update_step", "=", "args", ".", "update_step", "\n", "z_dim", "=", "640", "\n", "self", ".", "base_learner", "=", "BaseLearner", "(", "args", ",", "z_dim", ")", "\n", "\n", "if", "self", ".", "mode", "==", "'meta'", ":", "\n", "            ", "self", ".", "encoder", "=", "ResNetMtl", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "encoder", "=", "ResNetMtl", "(", "mtl", "=", "False", ")", "\n", "self", ".", "pre_fc", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "640", ",", "1000", ")", ",", "nn", ".", "ReLU", "(", ")", ",", "nn", ".", "Linear", "(", "1000", ",", "num_cls", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.mtl.MtlLearner.forward": [[57, 74], ["mtl.MtlLearner.pretrain_forward", "mtl.MtlLearner.meta_forward", "mtl.MtlLearner.preval_forward", "ValueError"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.mtl.MtlLearner.pretrain_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.mtl.MtlLearner.meta_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.mtl.MtlLearner.preval_forward"], ["", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "\"\"\"The function to forward the model.\n        Args:\n          inp: input images.\n        Returns:\n          the outputs of MTL model.\n        \"\"\"", "\n", "if", "self", ".", "mode", "==", "'pre'", ":", "\n", "            ", "return", "self", ".", "pretrain_forward", "(", "inp", ")", "\n", "", "elif", "self", ".", "mode", "==", "'meta'", ":", "\n", "            ", "data_shot", ",", "label_shot", ",", "data_query", "=", "inp", "\n", "return", "self", ".", "meta_forward", "(", "data_shot", ",", "label_shot", ",", "data_query", ")", "\n", "", "elif", "self", ".", "mode", "==", "'preval'", ":", "\n", "            ", "data_shot", ",", "label_shot", ",", "data_query", "=", "inp", "\n", "return", "self", ".", "preval_forward", "(", "data_shot", ",", "label_shot", ",", "data_query", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Please set the correct mode.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.mtl.MtlLearner.pretrain_forward": [[75, 83], ["mtl.MtlLearner.pre_fc", "mtl.MtlLearner.encoder"], "methods", ["None"], ["", "", "def", "pretrain_forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "\"\"\"The function to forward pretrain phase.\n        Args:\n          inp: input images.\n        Returns:\n          the outputs of pretrain model.\n        \"\"\"", "\n", "return", "self", ".", "pre_fc", "(", "self", ".", "encoder", "(", "inp", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.mtl.MtlLearner.meta_forward": [[84, 108], ["mtl.MtlLearner.encoder", "mtl.MtlLearner.encoder", "mtl.MtlLearner.base_learner", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "list", "mtl.MtlLearner.base_learner", "range", "mtl.MtlLearner.base_learner.parameters", "map", "mtl.MtlLearner.base_learner", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "list", "mtl.MtlLearner.base_learner", "zip", "map", "mtl.MtlLearner.base_learner.parameters", "zip"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.mtl.BaseLearner.parameters", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.mtl.BaseLearner.parameters"], ["", "def", "meta_forward", "(", "self", ",", "data_shot", ",", "label_shot", ",", "data_query", ")", ":", "\n", "        ", "\"\"\"The function to forward meta-train phase.\n        Args:\n          data_shot: train images for the task\n          label_shot: train labels for the task\n          data_query: test images for the task.\n        Returns:\n          logits_q: the predictions for the test samples.\n        \"\"\"", "\n", "embedding_query", "=", "self", ".", "encoder", "(", "data_query", ")", "\n", "embedding_shot", "=", "self", ".", "encoder", "(", "data_shot", ")", "\n", "logits", "=", "self", ".", "base_learner", "(", "embedding_shot", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ",", "label_shot", ")", "\n", "grad", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "self", ".", "base_learner", ".", "parameters", "(", ")", ")", "\n", "fast_weights", "=", "list", "(", "map", "(", "lambda", "p", ":", "p", "[", "1", "]", "-", "self", ".", "update_lr", "*", "p", "[", "0", "]", ",", "zip", "(", "grad", ",", "self", ".", "base_learner", ".", "parameters", "(", ")", ")", ")", ")", "\n", "logits_q", "=", "self", ".", "base_learner", "(", "embedding_query", ",", "fast_weights", ")", "\n", "\n", "for", "_", "in", "range", "(", "1", ",", "self", ".", "update_step", ")", ":", "\n", "            ", "logits", "=", "self", ".", "base_learner", "(", "embedding_shot", ",", "fast_weights", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ",", "label_shot", ")", "\n", "grad", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "fast_weights", ")", "\n", "fast_weights", "=", "list", "(", "map", "(", "lambda", "p", ":", "p", "[", "1", "]", "-", "self", ".", "update_lr", "*", "p", "[", "0", "]", ",", "zip", "(", "grad", ",", "fast_weights", ")", ")", ")", "\n", "logits_q", "=", "self", ".", "base_learner", "(", "embedding_query", ",", "fast_weights", ")", "\n", "", "return", "logits_q", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.mtl.MtlLearner.preval_forward": [[109, 133], ["mtl.MtlLearner.encoder", "mtl.MtlLearner.encoder", "mtl.MtlLearner.base_learner", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "list", "mtl.MtlLearner.base_learner", "range", "mtl.MtlLearner.base_learner.parameters", "map", "mtl.MtlLearner.base_learner", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "torch.autograd.grad", "list", "mtl.MtlLearner.base_learner", "zip", "map", "mtl.MtlLearner.base_learner.parameters", "zip"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.mtl.BaseLearner.parameters", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.mtl.BaseLearner.parameters"], ["", "def", "preval_forward", "(", "self", ",", "data_shot", ",", "label_shot", ",", "data_query", ")", ":", "\n", "        ", "\"\"\"The function to forward meta-validation during pretrain phase.\n        Args:\n          data_shot: train images for the task\n          label_shot: train labels for the task\n          data_query: test images for the task.\n        Returns:\n          logits_q: the predictions for the test samples.\n        \"\"\"", "\n", "embedding_query", "=", "self", ".", "encoder", "(", "data_query", ")", "\n", "embedding_shot", "=", "self", ".", "encoder", "(", "data_shot", ")", "\n", "logits", "=", "self", ".", "base_learner", "(", "embedding_shot", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ",", "label_shot", ")", "\n", "grad", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "self", ".", "base_learner", ".", "parameters", "(", ")", ")", "\n", "fast_weights", "=", "list", "(", "map", "(", "lambda", "p", ":", "p", "[", "1", "]", "-", "0.01", "*", "p", "[", "0", "]", ",", "zip", "(", "grad", ",", "self", ".", "base_learner", ".", "parameters", "(", ")", ")", ")", ")", "\n", "logits_q", "=", "self", ".", "base_learner", "(", "embedding_query", ",", "fast_weights", ")", "\n", "\n", "for", "_", "in", "range", "(", "1", ",", "100", ")", ":", "\n", "            ", "logits", "=", "self", ".", "base_learner", "(", "embedding_shot", ",", "fast_weights", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ",", "label_shot", ")", "\n", "grad", "=", "torch", ".", "autograd", ".", "grad", "(", "loss", ",", "fast_weights", ")", "\n", "fast_weights", "=", "list", "(", "map", "(", "lambda", "p", ":", "p", "[", "1", "]", "-", "0.01", "*", "p", "[", "0", "]", ",", "zip", "(", "grad", ",", "fast_weights", ")", ")", ")", "\n", "logits_q", "=", "self", ".", "base_learner", "(", "embedding_query", ",", "fast_weights", ")", "\n", "", "return", "logits_q", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.conv2d_mtl._ConvNdMtl.__init__": [[21, 54], ["torch.nn.modules.module.Module.__init__", "conv2d_mtl._ConvNdMtl.reset_parameters", "ValueError", "ValueError", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "conv2d_mtl._ConvNdMtl.register_parameter", "conv2d_mtl._ConvNdMtl.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.__init__", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.conv2d_mtl._ConvNdMtl.reset_parameters"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ",", "\n", "padding", ",", "dilation", ",", "transposed", ",", "output_padding", ",", "groups", ",", "bias", ")", ":", "\n", "        ", "super", "(", "_ConvNdMtl", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "in_channels", "%", "groups", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'in_channels must be divisible by groups'", ")", "\n", "", "if", "out_channels", "%", "groups", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "'out_channels must be divisible by groups'", ")", "\n", "", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "dilation", "=", "dilation", "\n", "self", ".", "transposed", "=", "transposed", "\n", "self", ".", "output_padding", "=", "output_padding", "\n", "self", ".", "groups", "=", "groups", "\n", "if", "transposed", ":", "\n", "            ", "self", ".", "weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "\n", "in_channels", ",", "out_channels", "//", "groups", ",", "*", "kernel_size", ")", ")", "\n", "self", ".", "mtl_weight", "=", "Parameter", "(", "torch", ".", "ones", "(", "in_channels", ",", "out_channels", "//", "groups", ",", "1", ",", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "\n", "out_channels", ",", "in_channels", "//", "groups", ",", "*", "kernel_size", ")", ")", "\n", "self", ".", "mtl_weight", "=", "Parameter", "(", "torch", ".", "ones", "(", "out_channels", ",", "in_channels", "//", "groups", ",", "1", ",", "1", ")", ")", "\n", "", "self", ".", "weight", ".", "requires_grad", "=", "False", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_channels", ")", ")", "\n", "self", ".", "bias", ".", "requires_grad", "=", "False", "\n", "self", ".", "mtl_bias", "=", "Parameter", "(", "torch", ".", "zeros", "(", "out_channels", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "self", ".", "register_parameter", "(", "'mtl_bias'", ",", "None", ")", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.conv2d_mtl._ConvNdMtl.reset_parameters": [[55, 65], ["conv2d_mtl._ConvNdMtl.weight.data.uniform_", "conv2d_mtl._ConvNdMtl.mtl_weight.data.uniform_", "math.sqrt", "conv2d_mtl._ConvNdMtl.bias.data.uniform_", "conv2d_mtl._ConvNdMtl.mtl_bias.data.uniform_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "n", "=", "self", ".", "in_channels", "\n", "for", "k", "in", "self", ".", "kernel_size", ":", "\n", "            ", "n", "*=", "k", "\n", "", "stdv", "=", "1.", "/", "math", ".", "sqrt", "(", "n", ")", "\n", "self", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "stdv", ",", "stdv", ")", "\n", "self", ".", "mtl_weight", ".", "data", ".", "uniform_", "(", "1", ",", "1", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "self", ".", "bias", ".", "data", ".", "uniform_", "(", "-", "stdv", ",", "stdv", ")", "\n", "self", ".", "mtl_bias", ".", "data", ".", "uniform_", "(", "0", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.conv2d_mtl._ConvNdMtl.extra_repr": [[66, 80], ["s.format", "len", "len", "len"], "methods", ["None"], ["", "", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "s", "=", "(", "'{in_channels}, {out_channels}, kernel_size={kernel_size}'", "\n", "', stride={stride}'", ")", "\n", "if", "self", ".", "padding", "!=", "(", "0", ",", ")", "*", "len", "(", "self", ".", "padding", ")", ":", "\n", "            ", "s", "+=", "', padding={padding}'", "\n", "", "if", "self", ".", "dilation", "!=", "(", "1", ",", ")", "*", "len", "(", "self", ".", "dilation", ")", ":", "\n", "            ", "s", "+=", "', dilation={dilation}'", "\n", "", "if", "self", ".", "output_padding", "!=", "(", "0", ",", ")", "*", "len", "(", "self", ".", "output_padding", ")", ":", "\n", "            ", "s", "+=", "', output_padding={output_padding}'", "\n", "", "if", "self", ".", "groups", "!=", "1", ":", "\n", "            ", "s", "+=", "', groups={groups}'", "\n", "", "if", "self", ".", "bias", "is", "None", ":", "\n", "            ", "s", "+=", "', bias=False'", "\n", "", "return", "s", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.conv2d_mtl.Conv2dMtl.__init__": [[83, 92], ["torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair", "conv2d_mtl._ConvNdMtl.__init__", "torch.nn.modules.utils._pair", "torch.nn.modules.utils._pair"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.__init__"], ["def", "__init__", "(", "self", ",", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "dilation", "=", "1", ",", "groups", "=", "1", ",", "bias", "=", "True", ")", ":", "\n", "        ", "kernel_size", "=", "_pair", "(", "kernel_size", ")", "\n", "stride", "=", "_pair", "(", "stride", ")", "\n", "padding", "=", "_pair", "(", "padding", ")", "\n", "dilation", "=", "_pair", "(", "dilation", ")", "\n", "super", "(", "Conv2dMtl", ",", "self", ")", ".", "__init__", "(", "\n", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "stride", ",", "padding", ",", "dilation", ",", "\n", "False", ",", "_pair", "(", "0", ")", ",", "groups", ",", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.conv2d_mtl.Conv2dMtl.forward": [[93, 102], ["conv2d_mtl.Conv2dMtl.mtl_weight.expand", "conv2d_mtl.Conv2dMtl.weight.mul", "torch.conv2d", "torch.conv2d"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "new_mtl_weight", "=", "self", ".", "mtl_weight", ".", "expand", "(", "self", ".", "weight", ".", "shape", ")", "\n", "new_weight", "=", "self", ".", "weight", ".", "mul", "(", "new_mtl_weight", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "new_bias", "=", "self", ".", "bias", "+", "self", ".", "mtl_bias", "\n", "", "else", ":", "\n", "            ", "new_bias", "=", "None", "\n", "", "return", "F", ".", "conv2d", "(", "inp", ",", "new_weight", ",", "new_bias", ",", "self", ".", "stride", ",", "\n", "self", ".", "padding", ",", "self", ".", "dilation", ",", "self", ".", "groups", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet12.Models.__init__": [[22, 44], ["tensorflow.placeholder_with_default", "tensorflow.placeholder_with_default"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "# Set the dimension number for the input feature maps", "\n", "        ", "self", ".", "dim_input", "=", "FLAGS", ".", "img_size", "*", "FLAGS", ".", "img_size", "*", "3", "\n", "# Set the dimension number for the outputs", "\n", "self", ".", "dim_output", "=", "FLAGS", ".", "way_num", "\n", "# Load base learning rates from FLAGS", "\n", "self", ".", "update_lr", "=", "FLAGS", ".", "base_lr", "\n", "# Load the pre-train phase class number from FLAGS", "\n", "self", ".", "pretrain_class_num", "=", "FLAGS", ".", "pretrain_class_num", "\n", "# Set the initial meta learning rate", "\n", "self", ".", "meta_lr", "=", "tf", ".", "placeholder_with_default", "(", "FLAGS", ".", "meta_lr", ",", "(", ")", ")", "\n", "# Set the initial pre-train learning rate", "\n", "self", ".", "pretrain_lr", "=", "tf", ".", "placeholder_with_default", "(", "FLAGS", ".", "pre_lr", ",", "(", ")", ")", "\n", "\n", "# Set the default objective functions for meta-train and pre-train", "\n", "self", ".", "loss_func", "=", "xent", "\n", "self", ".", "pretrain_loss_func", "=", "softmaxloss", "\n", "\n", "# Set the default channel number to 3", "\n", "self", ".", "channels", "=", "3", "\n", "# Load the image size from FLAGS", "\n", "self", ".", "img_size", "=", "FLAGS", ".", "img_size", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet12.Models.process_ss_weights": [[45, 57], ["tensorflow.tile", "tensorflow.multiply", "weights[].get_shape().as_list", "weights[].get_shape"], "methods", ["None"], ["", "def", "process_ss_weights", "(", "self", ",", "weights", ",", "ss_weights", ",", "label", ")", ":", "\n", "        ", "\"\"\"The function to process the scaling operation\n        Args:\n          weights: the weights for the resnet.\n          ss_weights: the weights for scaling and shifting operation.\n          label: the label to indicate which layer we are operating.\n        Return:\n          The processed weights for the new resnet.\n        \"\"\"", "\n", "[", "dim0", ",", "dim1", "]", "=", "weights", "[", "label", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", ":", "2", "]", "\n", "this_ss_weights", "=", "tf", ".", "tile", "(", "ss_weights", "[", "label", "]", ",", "multiples", "=", "[", "dim0", ",", "dim1", ",", "1", ",", "1", "]", ")", "\n", "return", "tf", ".", "multiply", "(", "weights", "[", "label", "]", ",", "this_ss_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet12.Models.forward_pretrain_resnet": [[58, 76], ["tensorflow.reshape", "resnet12.Models.pretrain_block_forward", "resnet12.Models.pretrain_block_forward", "resnet12.Models.pretrain_block_forward", "resnet12.Models.pretrain_block_forward", "tensorflow.nn.avg_pool", "tensorflow.reshape", "numpy.prod", "int", "tensorflow.reshape.get_shape"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.pretrain_block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.pretrain_block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.pretrain_block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.pretrain_block_forward"], ["", "def", "forward_pretrain_resnet", "(", "self", ",", "inp", ",", "weights", ",", "reuse", "=", "False", ",", "scope", "=", "''", ")", ":", "\n", "        ", "\"\"\"The function to forward the resnet during pre-train phase\n        Args:\n          inp: input feature maps.\n          weights: input resnet weights.\n          reuse: reuse the batch norm weights or not.\n          scope: the label to indicate which layer we are processing.\n        Return:\n          The processed feature maps.\n        \"\"\"", "\n", "inp", "=", "tf", ".", "reshape", "(", "inp", ",", "[", "-", "1", ",", "self", ".", "img_size", ",", "self", ".", "img_size", ",", "self", ".", "channels", "]", ")", "\n", "net", "=", "self", ".", "pretrain_block_forward", "(", "inp", ",", "weights", ",", "'block1'", ",", "reuse", ",", "scope", ")", "\n", "net", "=", "self", ".", "pretrain_block_forward", "(", "net", ",", "weights", ",", "'block2'", ",", "reuse", ",", "scope", ")", "\n", "net", "=", "self", ".", "pretrain_block_forward", "(", "net", ",", "weights", ",", "'block3'", ",", "reuse", ",", "scope", ")", "\n", "net", "=", "self", ".", "pretrain_block_forward", "(", "net", ",", "weights", ",", "'block4'", ",", "reuse", ",", "scope", ")", "\n", "net", "=", "tf", ".", "nn", ".", "avg_pool", "(", "net", ",", "[", "1", ",", "5", ",", "5", ",", "1", "]", ",", "[", "1", ",", "5", ",", "5", ",", "1", "]", ",", "'VALID'", ")", "\n", "net", "=", "tf", ".", "reshape", "(", "net", ",", "[", "-", "1", ",", "np", ".", "prod", "(", "[", "int", "(", "dim", ")", "for", "dim", "in", "net", ".", "get_shape", "(", ")", "[", "1", ":", "]", "]", ")", "]", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet12.Models.forward_resnet": [[77, 96], ["tensorflow.reshape", "resnet12.Models.block_forward", "resnet12.Models.block_forward", "resnet12.Models.block_forward", "resnet12.Models.block_forward", "tensorflow.nn.avg_pool", "tensorflow.reshape", "numpy.prod", "int", "tensorflow.reshape.get_shape"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.block_forward"], ["", "def", "forward_resnet", "(", "self", ",", "inp", ",", "weights", ",", "ss_weights", ",", "reuse", "=", "False", ",", "scope", "=", "''", ")", ":", "\n", "        ", "\"\"\"The function to forward the resnet during meta-train phase\n        Args:\n          inp: input feature maps.\n          weights: input resnet weights.\n          ss_weights: input scaling weights.\n          reuse: reuse the batch norm weights or not.\n          scope: the label to indicate which layer we are processing.\n        Return:\n          The processed feature maps.\n        \"\"\"", "\n", "inp", "=", "tf", ".", "reshape", "(", "inp", ",", "[", "-", "1", ",", "self", ".", "img_size", ",", "self", ".", "img_size", ",", "self", ".", "channels", "]", ")", "\n", "net", "=", "self", ".", "block_forward", "(", "inp", ",", "weights", ",", "ss_weights", ",", "'block1'", ",", "reuse", ",", "scope", ")", "\n", "net", "=", "self", ".", "block_forward", "(", "net", ",", "weights", ",", "ss_weights", ",", "'block2'", ",", "reuse", ",", "scope", ")", "\n", "net", "=", "self", ".", "block_forward", "(", "net", ",", "weights", ",", "ss_weights", ",", "'block3'", ",", "reuse", ",", "scope", ")", "\n", "net", "=", "self", ".", "block_forward", "(", "net", ",", "weights", ",", "ss_weights", ",", "'block4'", ",", "reuse", ",", "scope", ")", "\n", "net", "=", "tf", ".", "nn", ".", "avg_pool", "(", "net", ",", "[", "1", ",", "5", ",", "5", ",", "1", "]", ",", "[", "1", ",", "5", ",", "5", ",", "1", "]", ",", "'VALID'", ")", "\n", "net", "=", "tf", ".", "reshape", "(", "net", ",", "[", "-", "1", ",", "np", ".", "prod", "(", "[", "int", "(", "dim", ")", "for", "dim", "in", "net", ".", "get_shape", "(", ")", "[", "1", ":", "]", "]", ")", "]", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet12.Models.forward_fc": [[97, 107], ["tensorflow.matmul"], "methods", ["None"], ["", "def", "forward_fc", "(", "self", ",", "inp", ",", "fc_weights", ")", ":", "\n", "        ", "\"\"\"The function to forward the fc layer\n        Args:\n          inp: input feature maps.\n          fc_weights: input fc weights.\n        Return:\n          The processed feature maps.\n        \"\"\"", "\n", "net", "=", "tf", ".", "matmul", "(", "inp", ",", "fc_weights", "[", "'w5'", "]", ")", "+", "fc_weights", "[", "'b5'", "]", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet12.Models.pretrain_block_forward": [[108, 127], ["utils.misc.resnet_conv_block", "utils.misc.resnet_conv_block", "utils.misc.resnet_conv_block", "utils.misc.resnet_nob_conv_block", "tensorflow.nn.max_pool", "tensorflow.nn.dropout"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.resnet_conv_block", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.resnet_conv_block", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.resnet_conv_block", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.resnet_nob_conv_block"], ["", "def", "pretrain_block_forward", "(", "self", ",", "inp", ",", "weights", ",", "block", ",", "reuse", ",", "scope", ")", ":", "\n", "        ", "\"\"\"The function to forward a resnet block during pre-train phase\n        Args:\n          inp: input feature maps.\n          weights: input resnet weights.\n          block: the string to indicate which block we are processing.\n          reuse: reuse the batch norm weights or not.\n          scope: the label to indicate which layer we are processing.\n        Return:\n          The processed feature maps.\n        \"\"\"", "\n", "net", "=", "resnet_conv_block", "(", "inp", ",", "weights", "[", "block", "+", "'_conv1'", "]", ",", "weights", "[", "block", "+", "'_bias1'", "]", ",", "reuse", ",", "scope", "+", "block", "+", "'0'", ")", "\n", "net", "=", "resnet_conv_block", "(", "net", ",", "weights", "[", "block", "+", "'_conv2'", "]", ",", "weights", "[", "block", "+", "'_bias2'", "]", ",", "reuse", ",", "scope", "+", "block", "+", "'1'", ")", "\n", "net", "=", "resnet_conv_block", "(", "net", ",", "weights", "[", "block", "+", "'_conv3'", "]", ",", "weights", "[", "block", "+", "'_bias3'", "]", ",", "reuse", ",", "scope", "+", "block", "+", "'2'", ")", "\n", "res", "=", "resnet_nob_conv_block", "(", "inp", ",", "weights", "[", "block", "+", "'_conv_res'", "]", ",", "reuse", ",", "scope", "+", "block", "+", "'res'", ")", "\n", "net", "=", "net", "+", "res", "\n", "net", "=", "tf", ".", "nn", ".", "max_pool", "(", "net", ",", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "'VALID'", ")", "\n", "net", "=", "tf", ".", "nn", ".", "dropout", "(", "net", ",", "keep_prob", "=", "FLAGS", ".", "pretrain_dropout_keep", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet12.Models.block_forward": [[128, 151], ["utils.misc.resnet_conv_block", "utils.misc.resnet_conv_block", "utils.misc.resnet_conv_block", "utils.misc.resnet_nob_conv_block", "tensorflow.nn.max_pool", "tensorflow.nn.dropout", "resnet12.Models.process_ss_weights", "resnet12.Models.process_ss_weights", "resnet12.Models.process_ss_weights"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.resnet_conv_block", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.resnet_conv_block", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.resnet_conv_block", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.resnet_nob_conv_block", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.process_ss_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.process_ss_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.process_ss_weights"], ["", "def", "block_forward", "(", "self", ",", "inp", ",", "weights", ",", "ss_weights", ",", "block", ",", "reuse", ",", "scope", ")", ":", "\n", "        ", "\"\"\"The function to forward a resnet block during meta-train phase\n        Args:\n          inp: input feature maps.\n          weights: input resnet weights.\n          ss_weights: input scaling weights.\n          block: the string to indicate which block we are processing.\n          reuse: reuse the batch norm weights or not.\n          scope: the label to indicate which layer we are processing.\n        Return:\n          The processed feature maps.\n        \"\"\"", "\n", "net", "=", "resnet_conv_block", "(", "inp", ",", "self", ".", "process_ss_weights", "(", "weights", ",", "ss_weights", ",", "block", "+", "'_conv1'", ")", ",", "ss_weights", "[", "block", "+", "'_bias1'", "]", ",", "reuse", ",", "scope", "+", "block", "+", "'0'", ")", "\n", "net", "=", "resnet_conv_block", "(", "net", ",", "self", ".", "process_ss_weights", "(", "weights", ",", "ss_weights", ",", "block", "+", "'_conv2'", ")", ",", "ss_weights", "[", "block", "+", "'_bias2'", "]", ",", "reuse", ",", "scope", "+", "block", "+", "'1'", ")", "\n", "net", "=", "resnet_conv_block", "(", "net", ",", "self", ".", "process_ss_weights", "(", "weights", ",", "ss_weights", ",", "block", "+", "'_conv3'", ")", ",", "ss_weights", "[", "block", "+", "'_bias3'", "]", ",", "reuse", ",", "scope", "+", "block", "+", "'2'", ")", "\n", "res", "=", "resnet_nob_conv_block", "(", "inp", ",", "weights", "[", "block", "+", "'_conv_res'", "]", ",", "reuse", ",", "scope", "+", "block", "+", "'res'", ")", "\n", "net", "=", "net", "+", "res", "\n", "net", "=", "tf", ".", "nn", ".", "max_pool", "(", "net", ",", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "'VALID'", ")", "\n", "net", "=", "tf", ".", "nn", ".", "dropout", "(", "net", ",", "keep_prob", "=", "1", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet12.Models.construct_fc_weights": [[152, 167], ["tensorflow.contrib.layers.xavier_initializer", "tensorflow.get_variable", "tensorflow.Variable", "tensorflow.get_variable", "tensorflow.Variable", "tensorflow.zeros", "tensorflow.zeros"], "methods", ["None"], ["", "def", "construct_fc_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"The function to construct fc weights.\n        Return:\n          The fc weights.\n        \"\"\"", "\n", "dtype", "=", "tf", ".", "float32", "\n", "fc_weights", "=", "{", "}", "\n", "fc_initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", "dtype", "=", "dtype", ")", "\n", "if", "FLAGS", ".", "phase", "==", "'pre'", ":", "\n", "            ", "fc_weights", "[", "'w5'", "]", "=", "tf", ".", "get_variable", "(", "'fc_w5'", ",", "[", "512", ",", "FLAGS", ".", "pretrain_class_num", "]", ",", "initializer", "=", "fc_initializer", ")", "\n", "fc_weights", "[", "'b5'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "FLAGS", ".", "pretrain_class_num", "]", ")", ",", "name", "=", "'fc_b5'", ")", "\n", "", "else", ":", "\n", "            ", "fc_weights", "[", "'w5'", "]", "=", "tf", ".", "get_variable", "(", "'fc_w5'", ",", "[", "512", ",", "self", ".", "dim_output", "]", ",", "initializer", "=", "fc_initializer", ")", "\n", "fc_weights", "[", "'b5'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "self", ".", "dim_output", "]", ")", ",", "name", "=", "'fc_b5'", ")", "\n", "", "return", "fc_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet12.Models.construct_resnet_weights": [[168, 184], ["tensorflow.contrib.layers.xavier_initializer_conv2d", "tensorflow.contrib.layers.xavier_initializer", "resnet12.Models.construct_residual_block_weights", "resnet12.Models.construct_residual_block_weights", "resnet12.Models.construct_residual_block_weights", "resnet12.Models.construct_residual_block_weights", "tensorflow.get_variable", "tensorflow.Variable", "tensorflow.zeros"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_weights"], ["", "def", "construct_resnet_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"The function to construct resnet weights.\n        Return:\n          The resnet weights.\n        \"\"\"", "\n", "weights", "=", "{", "}", "\n", "dtype", "=", "tf", ".", "float32", "\n", "conv_initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer_conv2d", "(", "dtype", "=", "dtype", ")", "\n", "fc_initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", "dtype", "=", "dtype", ")", "\n", "weights", "=", "self", ".", "construct_residual_block_weights", "(", "weights", ",", "3", ",", "3", ",", "64", ",", "conv_initializer", ",", "dtype", ",", "'block1'", ")", "\n", "weights", "=", "self", ".", "construct_residual_block_weights", "(", "weights", ",", "3", ",", "64", ",", "128", ",", "conv_initializer", ",", "dtype", ",", "'block2'", ")", "\n", "weights", "=", "self", ".", "construct_residual_block_weights", "(", "weights", ",", "3", ",", "128", ",", "256", ",", "conv_initializer", ",", "dtype", ",", "'block3'", ")", "\n", "weights", "=", "self", ".", "construct_residual_block_weights", "(", "weights", ",", "3", ",", "256", ",", "512", ",", "conv_initializer", ",", "dtype", ",", "'block4'", ")", "\n", "weights", "[", "'w5'", "]", "=", "tf", ".", "get_variable", "(", "'w5'", ",", "[", "512", ",", "FLAGS", ".", "pretrain_class_num", "]", ",", "initializer", "=", "fc_initializer", ")", "\n", "weights", "[", "'b5'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "FLAGS", ".", "pretrain_class_num", "]", ")", ",", "name", "=", "'b5'", ")", "\n", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet12.Models.construct_residual_block_weights": [[185, 210], ["tensorflow.get_variable", "tensorflow.Variable", "tensorflow.get_variable", "tensorflow.Variable", "tensorflow.get_variable", "tensorflow.Variable", "tensorflow.get_variable", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.zeros"], "methods", ["None"], ["", "def", "construct_residual_block_weights", "(", "self", ",", "weights", ",", "k", ",", "last_dim_hidden", ",", "dim_hidden", ",", "conv_initializer", ",", "dtype", ",", "scope", "=", "'block0'", ")", ":", "\n", "        ", "\"\"\"The function to construct one block of the resnet weights.\n        Args:\n          weights: the resnet weight list.\n          k: the dimension number of the convolution kernel.\n          last_dim_hidden: the hidden dimension number of last block.\n          dim_hidden: the hidden dimension number of the block.\n          conv_initializer: the convolution initializer.\n          dtype: the dtype for numpy.\n          scope: the label to indicate which block we are processing.\n        Return:\n          The resnet block weights.\n        \"\"\"", "\n", "weights", "[", "scope", "+", "'_conv1'", "]", "=", "tf", ".", "get_variable", "(", "scope", "+", "'_conv1'", ",", "[", "k", ",", "k", ",", "last_dim_hidden", ",", "dim_hidden", "]", ",", "initializer", "=", "conv_initializer", ",", "dtype", "=", "dtype", ")", "\n", "weights", "[", "scope", "+", "'_bias1'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "dim_hidden", "]", ")", ",", "name", "=", "scope", "+", "'_bias1'", ")", "\n", "weights", "[", "scope", "+", "'_conv2'", "]", "=", "tf", ".", "get_variable", "(", "scope", "+", "'_conv2'", ",", "[", "k", ",", "k", ",", "dim_hidden", ",", "dim_hidden", "]", ",", "initializer", "=", "conv_initializer", ",", "dtype", "=", "dtype", ")", "\n", "weights", "[", "scope", "+", "'_bias2'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "dim_hidden", "]", ")", ",", "name", "=", "scope", "+", "'_bias2'", ")", "\n", "weights", "[", "scope", "+", "'_conv3'", "]", "=", "tf", ".", "get_variable", "(", "scope", "+", "'_conv3'", ",", "[", "k", ",", "k", ",", "dim_hidden", ",", "dim_hidden", "]", ",", "initializer", "=", "conv_initializer", ",", "dtype", "=", "dtype", ")", "\n", "weights", "[", "scope", "+", "'_bias3'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "dim_hidden", "]", ")", ",", "name", "=", "scope", "+", "'_bias3'", ")", "\n", "weights", "[", "scope", "+", "'_conv_res'", "]", "=", "tf", ".", "get_variable", "(", "scope", "+", "'_conv_res'", ",", "[", "1", ",", "1", ",", "last_dim_hidden", ",", "dim_hidden", "]", ",", "initializer", "=", "conv_initializer", ",", "dtype", "=", "dtype", ")", "\n", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet12.Models.construct_resnet_ss_weights": [[211, 222], ["resnet12.Models.construct_residual_block_ss_weights", "resnet12.Models.construct_residual_block_ss_weights", "resnet12.Models.construct_residual_block_ss_weights", "resnet12.Models.construct_residual_block_ss_weights"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_ss_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_ss_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_ss_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_ss_weights"], ["", "def", "construct_resnet_ss_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"The function to construct ss weights.\n        Return:\n          The ss weights.\n        \"\"\"", "\n", "ss_weights", "=", "{", "}", "\n", "ss_weights", "=", "self", ".", "construct_residual_block_ss_weights", "(", "ss_weights", ",", "3", ",", "64", ",", "'block1'", ")", "\n", "ss_weights", "=", "self", ".", "construct_residual_block_ss_weights", "(", "ss_weights", ",", "64", ",", "128", ",", "'block2'", ")", "\n", "ss_weights", "=", "self", ".", "construct_residual_block_ss_weights", "(", "ss_weights", ",", "128", ",", "256", ",", "'block3'", ")", "\n", "ss_weights", "=", "self", ".", "construct_residual_block_ss_weights", "(", "ss_weights", ",", "256", ",", "512", ",", "'block4'", ")", "\n", "return", "ss_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet12.Models.construct_residual_block_ss_weights": [[223, 240], ["tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.ones", "tensorflow.zeros", "tensorflow.ones", "tensorflow.zeros", "tensorflow.ones", "tensorflow.zeros"], "methods", ["None"], ["", "def", "construct_residual_block_ss_weights", "(", "self", ",", "ss_weights", ",", "last_dim_hidden", ",", "dim_hidden", ",", "scope", "=", "'block0'", ")", ":", "\n", "        ", "\"\"\"The function to construct one block ss weights.\n        Args:\n          ss_weights: the ss weight list.\n          last_dim_hidden: the hidden dimension number of last block.\n          dim_hidden: the hidden dimension number of the block.\n          scope: the label to indicate which block we are processing.\n        Return:\n          The ss block weights.\n        \"\"\"", "\n", "ss_weights", "[", "scope", "+", "'_conv1'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "ones", "(", "[", "1", ",", "1", ",", "last_dim_hidden", ",", "dim_hidden", "]", ")", ",", "name", "=", "scope", "+", "'_conv1'", ")", "\n", "ss_weights", "[", "scope", "+", "'_bias1'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "dim_hidden", "]", ")", ",", "name", "=", "scope", "+", "'_bias1'", ")", "\n", "ss_weights", "[", "scope", "+", "'_conv2'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "ones", "(", "[", "1", ",", "1", ",", "dim_hidden", ",", "dim_hidden", "]", ")", ",", "name", "=", "scope", "+", "'_conv2'", ")", "\n", "ss_weights", "[", "scope", "+", "'_bias2'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "dim_hidden", "]", ")", ",", "name", "=", "scope", "+", "'_bias2'", ")", "\n", "ss_weights", "[", "scope", "+", "'_conv3'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "ones", "(", "[", "1", ",", "1", ",", "dim_hidden", ",", "dim_hidden", "]", ")", ",", "name", "=", "scope", "+", "'_conv3'", ")", "\n", "ss_weights", "[", "scope", "+", "'_bias3'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "dim_hidden", "]", ")", ",", "name", "=", "scope", "+", "'_bias3'", ")", "\n", "return", "ss_weights", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.__init__": [[22, 44], ["tensorflow.placeholder_with_default", "tensorflow.placeholder_with_default"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "# Set the dimension number for the input feature maps", "\n", "        ", "self", ".", "dim_input", "=", "FLAGS", ".", "img_size", "*", "FLAGS", ".", "img_size", "*", "3", "\n", "# Set the dimension number for the outputs", "\n", "self", ".", "dim_output", "=", "FLAGS", ".", "way_num", "\n", "# Load base learning rates from FLAGS", "\n", "self", ".", "update_lr", "=", "FLAGS", ".", "base_lr", "\n", "# Load the pre-train phase class number from FLAGS", "\n", "self", ".", "pretrain_class_num", "=", "FLAGS", ".", "pretrain_class_num", "\n", "# Set the initial meta learning rate", "\n", "self", ".", "meta_lr", "=", "tf", ".", "placeholder_with_default", "(", "FLAGS", ".", "meta_lr", ",", "(", ")", ")", "\n", "# Set the initial pre-train learning rate", "\n", "self", ".", "pretrain_lr", "=", "tf", ".", "placeholder_with_default", "(", "FLAGS", ".", "pre_lr", ",", "(", ")", ")", "\n", "\n", "# Set the default objective functions for meta-train and pre-train", "\n", "self", ".", "loss_func", "=", "xent", "\n", "self", ".", "pretrain_loss_func", "=", "softmaxloss", "\n", "\n", "# Set the default channel number to 3", "\n", "self", ".", "channels", "=", "3", "\n", "# Load the image size from FLAGS", "\n", "self", ".", "img_size", "=", "FLAGS", ".", "img_size", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.process_ss_weights": [[45, 57], ["tensorflow.tile", "tensorflow.multiply", "weights[].get_shape().as_list", "weights[].get_shape"], "methods", ["None"], ["", "def", "process_ss_weights", "(", "self", ",", "weights", ",", "ss_weights", ",", "label", ")", ":", "\n", "        ", "\"\"\"The function to process the scaling operation\n        Args:\n          weights: the weights for the resnet.\n          ss_weights: the weights for scaling and shifting operation.\n          label: the label to indicate which layer we are operating.\n        Return:\n          The processed weights for the new resnet.\n        \"\"\"", "\n", "[", "dim0", ",", "dim1", "]", "=", "weights", "[", "label", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "0", ":", "2", "]", "\n", "this_ss_weights", "=", "tf", ".", "tile", "(", "ss_weights", "[", "label", "]", ",", "multiples", "=", "[", "dim0", ",", "dim1", ",", "1", ",", "1", "]", ")", "\n", "return", "tf", ".", "multiply", "(", "weights", "[", "label", "]", ",", "this_ss_weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.forward_pretrain_resnet": [[58, 87], ["tensorflow.reshape", "tensorflow.image.resize_images", "resnet18.Models.pretrain_first_block_forward", "resnet18.Models.pretrain_block_forward", "resnet18.Models.pretrain_block_forward", "resnet18.Models.pretrain_block_forward", "resnet18.Models.pretrain_block_forward", "resnet18.Models.pretrain_block_forward", "resnet18.Models.pretrain_block_forward", "resnet18.Models.pretrain_block_forward", "resnet18.Models.pretrain_block_forward", "tensorflow.nn.avg_pool", "tensorflow.reshape", "numpy.prod", "int", "tensorflow.reshape.get_shape"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.pretrain_first_block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.pretrain_block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.pretrain_block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.pretrain_block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.pretrain_block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.pretrain_block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.pretrain_block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.pretrain_block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.pretrain_block_forward"], ["", "def", "forward_pretrain_resnet", "(", "self", ",", "inp", ",", "weights", ",", "reuse", "=", "False", ",", "scope", "=", "''", ")", ":", "\n", "        ", "\"\"\"The function to forward the resnet during pre-train phase\n        Args:\n          inp: input feature maps.\n          weights: input resnet weights.\n          reuse: reuse the batch norm weights or not.\n          scope: the label to indicate which layer we are processing.\n        Return:\n          The processed feature maps.\n        \"\"\"", "\n", "inp", "=", "tf", ".", "reshape", "(", "inp", ",", "[", "-", "1", ",", "self", ".", "img_size", ",", "self", ".", "img_size", ",", "self", ".", "channels", "]", ")", "\n", "inp", "=", "tf", ".", "image", ".", "resize_images", "(", "inp", ",", "size", "=", "[", "224", ",", "224", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "BILINEAR", ")", "\n", "net", "=", "self", ".", "pretrain_first_block_forward", "(", "inp", ",", "weights", ",", "'block0_1'", ",", "reuse", ",", "scope", ")", "\n", "\n", "net", "=", "self", ".", "pretrain_block_forward", "(", "net", ",", "weights", ",", "'block1_1'", ",", "reuse", ",", "scope", ")", "\n", "net", "=", "self", ".", "pretrain_block_forward", "(", "net", ",", "weights", ",", "'block1_2'", ",", "reuse", ",", "scope", ",", "block_last_layer", "=", "True", ")", "\n", "\n", "net", "=", "self", ".", "pretrain_block_forward", "(", "net", ",", "weights", ",", "'block2_1'", ",", "reuse", ",", "scope", ")", "\n", "net", "=", "self", ".", "pretrain_block_forward", "(", "net", ",", "weights", ",", "'block2_2'", ",", "reuse", ",", "scope", ",", "block_last_layer", "=", "True", ")", "\n", "\n", "net", "=", "self", ".", "pretrain_block_forward", "(", "net", ",", "weights", ",", "'block3_1'", ",", "reuse", ",", "scope", ")", "\n", "net", "=", "self", ".", "pretrain_block_forward", "(", "net", ",", "weights", ",", "'block3_2'", ",", "reuse", ",", "scope", ",", "block_last_layer", "=", "True", ")", "\n", "\n", "net", "=", "self", ".", "pretrain_block_forward", "(", "net", ",", "weights", ",", "'block4_1'", ",", "reuse", ",", "scope", ")", "\n", "net", "=", "self", ".", "pretrain_block_forward", "(", "net", ",", "weights", ",", "'block4_2'", ",", "reuse", ",", "scope", ",", "block_last_layer", "=", "True", ")", "\n", "\n", "net", "=", "tf", ".", "nn", ".", "avg_pool", "(", "net", ",", "[", "1", ",", "7", ",", "7", ",", "1", "]", ",", "[", "1", ",", "7", ",", "7", ",", "1", "]", ",", "'SAME'", ")", "\n", "net", "=", "tf", ".", "reshape", "(", "net", ",", "[", "-", "1", ",", "np", ".", "prod", "(", "[", "int", "(", "dim", ")", "for", "dim", "in", "net", ".", "get_shape", "(", ")", "[", "1", ":", "]", "]", ")", "]", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.forward_resnet": [[88, 118], ["tensorflow.reshape", "tensorflow.image.resize_images", "resnet18.Models.first_block_forward", "resnet18.Models.block_forward", "resnet18.Models.block_forward", "resnet18.Models.block_forward", "resnet18.Models.block_forward", "resnet18.Models.block_forward", "resnet18.Models.block_forward", "resnet18.Models.block_forward", "resnet18.Models.block_forward", "tensorflow.nn.avg_pool", "tensorflow.reshape", "numpy.prod", "int", "tensorflow.reshape.get_shape"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.first_block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.block_forward", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.block_forward"], ["", "def", "forward_resnet", "(", "self", ",", "inp", ",", "weights", ",", "ss_weights", ",", "reuse", "=", "False", ",", "scope", "=", "''", ")", ":", "\n", "        ", "\"\"\"The function to forward the resnet during meta-train phase\n        Args:\n          inp: input feature maps.\n          weights: input resnet weights.\n          ss_weights: input scaling weights.\n          reuse: reuse the batch norm weights or not.\n          scope: the label to indicate which layer we are processing.\n        Return:\n          The processed feature maps.\n        \"\"\"", "\n", "inp", "=", "tf", ".", "reshape", "(", "inp", ",", "[", "-", "1", ",", "self", ".", "img_size", ",", "self", ".", "img_size", ",", "self", ".", "channels", "]", ")", "\n", "inp", "=", "tf", ".", "image", ".", "resize_images", "(", "inp", ",", "size", "=", "[", "224", ",", "224", "]", ",", "method", "=", "tf", ".", "image", ".", "ResizeMethod", ".", "BILINEAR", ")", "\n", "net", "=", "self", ".", "first_block_forward", "(", "inp", ",", "weights", ",", "ss_weights", ",", "'block0_1'", ",", "reuse", ",", "scope", ")", "\n", "\n", "net", "=", "self", ".", "block_forward", "(", "net", ",", "weights", ",", "ss_weights", ",", "'block1_1'", ",", "reuse", ",", "scope", ")", "\n", "net", "=", "self", ".", "block_forward", "(", "net", ",", "weights", ",", "ss_weights", ",", "'block1_2'", ",", "reuse", ",", "scope", ",", "block_last_layer", "=", "True", ")", "\n", "\n", "net", "=", "self", ".", "block_forward", "(", "net", ",", "weights", ",", "ss_weights", ",", "'block2_1'", ",", "reuse", ",", "scope", ")", "\n", "net", "=", "self", ".", "block_forward", "(", "net", ",", "weights", ",", "ss_weights", ",", "'block2_2'", ",", "reuse", ",", "scope", ",", "block_last_layer", "=", "True", ")", "\n", "\n", "net", "=", "self", ".", "block_forward", "(", "net", ",", "weights", ",", "ss_weights", ",", "'block3_1'", ",", "reuse", ",", "scope", ")", "\n", "net", "=", "self", ".", "block_forward", "(", "net", ",", "weights", ",", "ss_weights", ",", "'block3_2'", ",", "reuse", ",", "scope", ",", "block_last_layer", "=", "True", ")", "\n", "\n", "net", "=", "self", ".", "block_forward", "(", "net", ",", "weights", ",", "ss_weights", ",", "'block4_1'", ",", "reuse", ",", "scope", ")", "\n", "net", "=", "self", ".", "block_forward", "(", "net", ",", "weights", ",", "ss_weights", ",", "'block4_2'", ",", "reuse", ",", "scope", ",", "block_last_layer", "=", "True", ")", "\n", "\n", "net", "=", "tf", ".", "nn", ".", "avg_pool", "(", "net", ",", "[", "1", ",", "7", ",", "7", ",", "1", "]", ",", "[", "1", ",", "7", ",", "7", ",", "1", "]", ",", "'SAME'", ")", "\n", "net", "=", "tf", ".", "reshape", "(", "net", ",", "[", "-", "1", ",", "np", ".", "prod", "(", "[", "int", "(", "dim", ")", "for", "dim", "in", "net", ".", "get_shape", "(", ")", "[", "1", ":", "]", "]", ")", "]", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.forward_fc": [[119, 129], ["tensorflow.matmul"], "methods", ["None"], ["", "def", "forward_fc", "(", "self", ",", "inp", ",", "fc_weights", ")", ":", "\n", "        ", "\"\"\"The function to forward the fc layer\n        Args:\n          inp: input feature maps.\n          fc_weights: input fc weights.\n        Return:\n          The processed feature maps.\n        \"\"\"", "\n", "net", "=", "tf", ".", "matmul", "(", "inp", ",", "fc_weights", "[", "'w5'", "]", ")", "+", "fc_weights", "[", "'b5'", "]", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.pretrain_block_forward": [[130, 150], ["utils.misc.resnet_conv_block", "utils.misc.resnet_conv_block", "utils.misc.resnet_nob_conv_block", "tensorflow.nn.dropout", "tensorflow.nn.max_pool"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.resnet_conv_block", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.resnet_conv_block", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.resnet_nob_conv_block"], ["", "def", "pretrain_block_forward", "(", "self", ",", "inp", ",", "weights", ",", "block", ",", "reuse", ",", "scope", ",", "block_last_layer", "=", "False", ")", ":", "\n", "        ", "\"\"\"The function to forward a resnet block during pre-train phase\n        Args:\n          inp: input feature maps.\n          weights: input resnet weights.\n          block: the string to indicate which block we are processing.\n          reuse: reuse the batch norm weights or not.\n          scope: the label to indicate which layer we are processing.\n          block_last_layer: whether it is the last layer of this block.\n        Return:\n          The processed feature maps.\n        \"\"\"", "\n", "net", "=", "resnet_conv_block", "(", "inp", ",", "weights", "[", "block", "+", "'_conv1'", "]", ",", "weights", "[", "block", "+", "'_bias1'", "]", ",", "reuse", ",", "scope", "+", "block", "+", "'0'", ")", "\n", "net", "=", "resnet_conv_block", "(", "net", ",", "weights", "[", "block", "+", "'_conv2'", "]", ",", "weights", "[", "block", "+", "'_bias2'", "]", ",", "reuse", ",", "scope", "+", "block", "+", "'1'", ")", "\n", "res", "=", "resnet_nob_conv_block", "(", "inp", ",", "weights", "[", "block", "+", "'_conv_res'", "]", ",", "reuse", ",", "scope", "+", "block", "+", "'res'", ")", "\n", "net", "=", "net", "+", "res", "\n", "if", "block_last_layer", ":", "\n", "            ", "net", "=", "tf", ".", "nn", ".", "max_pool", "(", "net", ",", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "'SAME'", ")", "\n", "", "net", "=", "tf", ".", "nn", ".", "dropout", "(", "net", ",", "keep_prob", "=", "FLAGS", ".", "pretrain_dropout_keep", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.block_forward": [[151, 174], ["utils.misc.resnet_conv_block", "utils.misc.resnet_conv_block", "utils.misc.resnet_nob_conv_block", "tensorflow.nn.dropout", "resnet18.Models.process_ss_weights", "resnet18.Models.process_ss_weights", "tensorflow.nn.max_pool"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.resnet_conv_block", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.resnet_conv_block", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.resnet_nob_conv_block", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.process_ss_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.process_ss_weights"], ["", "def", "block_forward", "(", "self", ",", "inp", ",", "weights", ",", "ss_weights", ",", "block", ",", "reuse", ",", "scope", ",", "block_last_layer", "=", "False", ")", ":", "\n", "        ", "\"\"\"The function to forward a resnet block during meta-train phase\n        Args:\n          inp: input feature maps.\n          weights: input resnet weights.\n          ss_weights: input scaling weights.\n          block: the string to indicate which block we are processing.\n          reuse: reuse the batch norm weights or not.\n          scope: the label to indicate which layer we are processing.\n          block_last_layer: whether it is the last layer of this block.\n        Return:\n          The processed feature maps.\n        \"\"\"", "\n", "net", "=", "resnet_conv_block", "(", "inp", ",", "self", ".", "process_ss_weights", "(", "weights", ",", "ss_weights", ",", "block", "+", "'_conv1'", ")", ",", "ss_weights", "[", "block", "+", "'_bias1'", "]", ",", "reuse", ",", "scope", "+", "block", "+", "'0'", ")", "\n", "net", "=", "resnet_conv_block", "(", "net", ",", "self", ".", "process_ss_weights", "(", "weights", ",", "ss_weights", ",", "block", "+", "'_conv2'", ")", ",", "ss_weights", "[", "block", "+", "'_bias2'", "]", ",", "reuse", ",", "scope", "+", "block", "+", "'1'", ")", "\n", "res", "=", "resnet_nob_conv_block", "(", "inp", ",", "weights", "[", "block", "+", "'_conv_res'", "]", ",", "reuse", ",", "scope", "+", "block", "+", "'res'", ")", "\n", "net", "=", "net", "+", "res", "\n", "if", "block_last_layer", ":", "\n", "            ", "net", "=", "tf", ".", "nn", ".", "max_pool", "(", "net", ",", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "'SAME'", ")", "\n", "", "net", "=", "tf", ".", "nn", ".", "dropout", "(", "net", ",", "keep_prob", "=", "1", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.pretrain_first_block_forward": [[175, 190], ["utils.misc.resnet_conv_block", "tensorflow.nn.max_pool", "tensorflow.nn.dropout"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.resnet_conv_block"], ["", "def", "pretrain_first_block_forward", "(", "self", ",", "inp", ",", "weights", ",", "block", ",", "reuse", ",", "scope", ")", ":", "\n", "        ", "\"\"\"The function to forward the first resnet block during pre-train phase\n        Args:\n          inp: input feature maps.\n          weights: input resnet weights.\n          block: the string to indicate which block we are processing.\n          reuse: reuse the batch norm weights or not.\n          scope: the label to indicate which layer we are processing.\n        Return:\n          The processed feature maps.\n        \"\"\"", "\n", "net", "=", "resnet_conv_block", "(", "inp", ",", "weights", "[", "block", "+", "'_conv1'", "]", ",", "weights", "[", "block", "+", "'_bias1'", "]", ",", "reuse", ",", "scope", "+", "block", "+", "'0'", ")", "\n", "net", "=", "tf", ".", "nn", ".", "max_pool", "(", "net", ",", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "'SAME'", ")", "\n", "net", "=", "tf", ".", "nn", ".", "dropout", "(", "net", ",", "keep_prob", "=", "FLAGS", ".", "pretrain_dropout_keep", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.first_block_forward": [[191, 207], ["utils.misc.resnet_conv_block", "tensorflow.nn.max_pool", "tensorflow.nn.dropout", "resnet18.Models.process_ss_weights"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.resnet_conv_block", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.process_ss_weights"], ["", "def", "first_block_forward", "(", "self", ",", "inp", ",", "weights", ",", "ss_weights", ",", "block", ",", "reuse", ",", "scope", ",", "block_last_layer", "=", "False", ")", ":", "\n", "        ", "\"\"\"The function to forward the first resnet block during meta-train phase\n        Args:\n          inp: input feature maps.\n          weights: input resnet weights.\n          block: the string to indicate which block we are processing.\n          reuse: reuse the batch norm weights or not.\n          scope: the label to indicate which layer we are processing.\n        Return:\n          The processed feature maps.\n        \"\"\"", "\n", "net", "=", "resnet_conv_block", "(", "inp", ",", "self", ".", "process_ss_weights", "(", "weights", ",", "ss_weights", ",", "block", "+", "'_conv1'", ")", ",", "ss_weights", "[", "block", "+", "'_bias1'", "]", ",", "reuse", ",", "scope", "+", "block", "+", "'0'", ")", "\n", "net", "=", "tf", ".", "nn", ".", "max_pool", "(", "net", ",", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "'SAME'", ")", "\n", "net", "=", "tf", ".", "nn", ".", "dropout", "(", "net", ",", "keep_prob", "=", "1", ")", "\n", "return", "net", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_fc_weights": [[208, 223], ["tensorflow.contrib.layers.xavier_initializer", "tensorflow.get_variable", "tensorflow.Variable", "tensorflow.get_variable", "tensorflow.Variable", "tensorflow.zeros", "tensorflow.zeros"], "methods", ["None"], ["", "def", "construct_fc_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"The function to construct fc weights.\n        Return:\n          The fc weights.\n        \"\"\"", "\n", "dtype", "=", "tf", ".", "float32", "\n", "fc_weights", "=", "{", "}", "\n", "fc_initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", "dtype", "=", "dtype", ")", "\n", "if", "FLAGS", ".", "phase", "==", "'pre'", ":", "\n", "            ", "fc_weights", "[", "'w5'", "]", "=", "tf", ".", "get_variable", "(", "'fc_w5'", ",", "[", "512", ",", "FLAGS", ".", "pretrain_class_num", "]", ",", "initializer", "=", "fc_initializer", ")", "\n", "fc_weights", "[", "'b5'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "FLAGS", ".", "pretrain_class_num", "]", ")", ",", "name", "=", "'fc_b5'", ")", "\n", "", "else", ":", "\n", "            ", "fc_weights", "[", "'w5'", "]", "=", "tf", ".", "get_variable", "(", "'fc_w5'", ",", "[", "512", ",", "self", ".", "dim_output", "]", ",", "initializer", "=", "fc_initializer", ")", "\n", "fc_weights", "[", "'b5'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "self", ".", "dim_output", "]", ")", ",", "name", "=", "'fc_b5'", ")", "\n", "", "return", "fc_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_resnet_weights": [[224, 250], ["tensorflow.contrib.layers.xavier_initializer_conv2d", "tensorflow.contrib.layers.xavier_initializer", "resnet18.Models.construct_first_block_weights", "resnet18.Models.construct_residual_block_weights", "resnet18.Models.construct_residual_block_weights", "resnet18.Models.construct_residual_block_weights", "resnet18.Models.construct_residual_block_weights", "resnet18.Models.construct_residual_block_weights", "resnet18.Models.construct_residual_block_weights", "resnet18.Models.construct_residual_block_weights", "resnet18.Models.construct_residual_block_weights", "tensorflow.get_variable", "tensorflow.Variable", "tensorflow.zeros"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_first_block_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_weights"], ["", "def", "construct_resnet_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"The function to construct resnet weights.\n        Return:\n          The resnet weights.\n        \"\"\"", "\n", "weights", "=", "{", "}", "\n", "dtype", "=", "tf", ".", "float32", "\n", "conv_initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer_conv2d", "(", "dtype", "=", "dtype", ")", "\n", "fc_initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", "dtype", "=", "dtype", ")", "\n", "weights", "=", "self", ".", "construct_first_block_weights", "(", "weights", ",", "7", ",", "3", ",", "64", ",", "conv_initializer", ",", "dtype", ",", "'block0_1'", ")", "\n", "\n", "weights", "=", "self", ".", "construct_residual_block_weights", "(", "weights", ",", "3", ",", "64", ",", "64", ",", "conv_initializer", ",", "dtype", ",", "'block1_1'", ")", "\n", "weights", "=", "self", ".", "construct_residual_block_weights", "(", "weights", ",", "3", ",", "64", ",", "64", ",", "conv_initializer", ",", "dtype", ",", "'block1_2'", ")", "\n", "\n", "weights", "=", "self", ".", "construct_residual_block_weights", "(", "weights", ",", "3", ",", "64", ",", "128", ",", "conv_initializer", ",", "dtype", ",", "'block2_1'", ")", "\n", "weights", "=", "self", ".", "construct_residual_block_weights", "(", "weights", ",", "3", ",", "128", ",", "128", ",", "conv_initializer", ",", "dtype", ",", "'block2_2'", ")", "\n", "\n", "weights", "=", "self", ".", "construct_residual_block_weights", "(", "weights", ",", "3", ",", "128", ",", "256", ",", "conv_initializer", ",", "dtype", ",", "'block3_1'", ")", "\n", "weights", "=", "self", ".", "construct_residual_block_weights", "(", "weights", ",", "3", ",", "256", ",", "256", ",", "conv_initializer", ",", "dtype", ",", "'block3_2'", ")", "\n", "\n", "weights", "=", "self", ".", "construct_residual_block_weights", "(", "weights", ",", "3", ",", "256", ",", "512", ",", "conv_initializer", ",", "dtype", ",", "'block4_1'", ")", "\n", "weights", "=", "self", ".", "construct_residual_block_weights", "(", "weights", ",", "3", ",", "512", ",", "512", ",", "conv_initializer", ",", "dtype", ",", "'block4_2'", ")", "\n", "\n", "weights", "[", "'w5'", "]", "=", "tf", ".", "get_variable", "(", "'w5'", ",", "[", "512", ",", "FLAGS", ".", "pretrain_class_num", "]", ",", "initializer", "=", "fc_initializer", ")", "\n", "weights", "[", "'b5'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "FLAGS", ".", "pretrain_class_num", "]", ")", ",", "name", "=", "'b5'", ")", "\n", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_weights": [[251, 273], ["tensorflow.get_variable", "tensorflow.Variable", "tensorflow.get_variable", "tensorflow.Variable", "tensorflow.get_variable", "tensorflow.zeros", "tensorflow.zeros"], "methods", ["None"], ["", "def", "construct_residual_block_weights", "(", "self", ",", "weights", ",", "k", ",", "last_dim_hidden", ",", "dim_hidden", ",", "conv_initializer", ",", "dtype", ",", "scope", "=", "'block0'", ")", ":", "\n", "        ", "\"\"\"The function to construct one block of the resnet weights.\n        Args:\n          weights: the resnet weight list.\n          k: the dimension number of the convolution kernel.\n          last_dim_hidden: the hidden dimension number of last block.\n          dim_hidden: the hidden dimension number of the block.\n          conv_initializer: the convolution initializer.\n          dtype: the dtype for numpy.\n          scope: the label to indicate which block we are processing.\n        Return:\n          The resnet block weights.\n        \"\"\"", "\n", "weights", "[", "scope", "+", "'_conv1'", "]", "=", "tf", ".", "get_variable", "(", "scope", "+", "'_conv1'", ",", "[", "k", ",", "k", ",", "last_dim_hidden", ",", "dim_hidden", "]", ",", "initializer", "=", "conv_initializer", ",", "dtype", "=", "dtype", ")", "\n", "weights", "[", "scope", "+", "'_bias1'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "dim_hidden", "]", ")", ",", "name", "=", "scope", "+", "'_bias1'", ")", "\n", "weights", "[", "scope", "+", "'_conv2'", "]", "=", "tf", ".", "get_variable", "(", "scope", "+", "'_conv2'", ",", "[", "k", ",", "k", ",", "dim_hidden", ",", "dim_hidden", "]", ",", "initializer", "=", "conv_initializer", ",", "dtype", "=", "dtype", ")", "\n", "weights", "[", "scope", "+", "'_bias2'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "dim_hidden", "]", ")", ",", "name", "=", "scope", "+", "'_bias2'", ")", "\n", "weights", "[", "scope", "+", "'_conv_res'", "]", "=", "tf", ".", "get_variable", "(", "scope", "+", "'_conv_res'", ",", "[", "1", ",", "1", ",", "last_dim_hidden", ",", "dim_hidden", "]", ",", "initializer", "=", "conv_initializer", ",", "dtype", "=", "dtype", ")", "\n", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_first_block_weights": [[274, 291], ["tensorflow.get_variable", "tensorflow.Variable", "tensorflow.zeros"], "methods", ["None"], ["", "def", "construct_first_block_weights", "(", "self", ",", "weights", ",", "k", ",", "last_dim_hidden", ",", "dim_hidden", ",", "conv_initializer", ",", "dtype", ",", "scope", "=", "'block0'", ")", ":", "\n", "        ", "\"\"\"The function to construct the first block of the resnet weights.\n        Args:\n          weights: the resnet weight list.\n          k: the dimension number of the convolution kernel.\n          last_dim_hidden: the hidden dimension number of last block.\n          dim_hidden: the hidden dimension number of the block.\n          conv_initializer: the convolution initializer.\n          dtype: the dtype for numpy.\n          scope: the label to indicate which block we are processing.\n        Return:\n          The resnet block weights.\n        \"\"\"", "\n", "weights", "[", "scope", "+", "'_conv1'", "]", "=", "tf", ".", "get_variable", "(", "scope", "+", "'_conv1'", ",", "[", "k", ",", "k", ",", "last_dim_hidden", ",", "dim_hidden", "]", ",", "initializer", "=", "conv_initializer", ",", "dtype", "=", "dtype", ")", "\n", "weights", "[", "scope", "+", "'_bias1'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "dim_hidden", "]", ")", ",", "name", "=", "scope", "+", "'_bias1'", ")", "\n", "return", "weights", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_first_block_ss_weights": [[292, 300], ["tensorflow.Variable", "tensorflow.Variable", "tensorflow.ones", "tensorflow.zeros"], "methods", ["None"], ["", "def", "construct_first_block_ss_weights", "(", "self", ",", "ss_weights", ",", "last_dim_hidden", ",", "dim_hidden", ",", "scope", "=", "'block0'", ")", ":", "\n", "        ", "\"\"\"The function to construct first block's ss weights.\n        Return:\n          The ss weights.\n        \"\"\"", "\n", "ss_weights", "[", "scope", "+", "'_conv1'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "ones", "(", "[", "1", ",", "1", ",", "last_dim_hidden", ",", "dim_hidden", "]", ")", ",", "name", "=", "scope", "+", "'_conv1'", ")", "\n", "ss_weights", "[", "scope", "+", "'_bias1'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "dim_hidden", "]", ")", ",", "name", "=", "scope", "+", "'_bias1'", ")", "\n", "return", "ss_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_resnet_ss_weights": [[301, 322], ["resnet18.Models.construct_first_block_ss_weights", "resnet18.Models.construct_residual_block_ss_weights", "resnet18.Models.construct_residual_block_ss_weights", "resnet18.Models.construct_residual_block_ss_weights", "resnet18.Models.construct_residual_block_ss_weights", "resnet18.Models.construct_residual_block_ss_weights", "resnet18.Models.construct_residual_block_ss_weights", "resnet18.Models.construct_residual_block_ss_weights", "resnet18.Models.construct_residual_block_ss_weights"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_first_block_ss_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_ss_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_ss_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_ss_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_ss_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_ss_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_ss_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_ss_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_ss_weights"], ["", "def", "construct_resnet_ss_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"The function to construct ss weights.\n        Return:\n          The ss weights.\n        \"\"\"", "\n", "ss_weights", "=", "{", "}", "\n", "ss_weights", "=", "self", ".", "construct_first_block_ss_weights", "(", "ss_weights", ",", "3", ",", "64", ",", "'block0_1'", ")", "\n", "\n", "ss_weights", "=", "self", ".", "construct_residual_block_ss_weights", "(", "ss_weights", ",", "64", ",", "64", ",", "'block1_1'", ")", "\n", "ss_weights", "=", "self", ".", "construct_residual_block_ss_weights", "(", "ss_weights", ",", "64", ",", "64", ",", "'block1_2'", ")", "\n", "\n", "ss_weights", "=", "self", ".", "construct_residual_block_ss_weights", "(", "ss_weights", ",", "64", ",", "128", ",", "'block2_1'", ")", "\n", "ss_weights", "=", "self", ".", "construct_residual_block_ss_weights", "(", "ss_weights", ",", "128", ",", "128", ",", "'block2_2'", ")", "\n", "\n", "ss_weights", "=", "self", ".", "construct_residual_block_ss_weights", "(", "ss_weights", ",", "128", ",", "256", ",", "'block3_1'", ")", "\n", "ss_weights", "=", "self", ".", "construct_residual_block_ss_weights", "(", "ss_weights", ",", "256", ",", "256", ",", "'block3_2'", ")", "\n", "\n", "ss_weights", "=", "self", ".", "construct_residual_block_ss_weights", "(", "ss_weights", ",", "256", ",", "512", ",", "'block4_1'", ")", "\n", "ss_weights", "=", "self", ".", "construct_residual_block_ss_weights", "(", "ss_weights", ",", "512", ",", "512", ",", "'block4_2'", ")", "\n", "\n", "return", "ss_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_residual_block_ss_weights": [[323, 338], ["tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.ones", "tensorflow.zeros", "tensorflow.ones", "tensorflow.zeros"], "methods", ["None"], ["", "def", "construct_residual_block_ss_weights", "(", "self", ",", "ss_weights", ",", "last_dim_hidden", ",", "dim_hidden", ",", "scope", "=", "'block0'", ")", ":", "\n", "        ", "\"\"\"The function to construct one block ss weights.\n        Args:\n          ss_weights: the ss weight list.\n          last_dim_hidden: the hidden dimension number of last block.\n          dim_hidden: the hidden dimension number of the block.\n          scope: the label to indicate which block we are processing.\n        Return:\n          The ss block weights.\n        \"\"\"", "\n", "ss_weights", "[", "scope", "+", "'_conv1'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "ones", "(", "[", "1", ",", "1", ",", "last_dim_hidden", ",", "dim_hidden", "]", ")", ",", "name", "=", "scope", "+", "'_conv1'", ")", "\n", "ss_weights", "[", "scope", "+", "'_bias1'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "dim_hidden", "]", ")", ",", "name", "=", "scope", "+", "'_bias1'", ")", "\n", "ss_weights", "[", "scope", "+", "'_conv2'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "ones", "(", "[", "1", ",", "1", ",", "dim_hidden", ",", "dim_hidden", "]", ")", ",", "name", "=", "scope", "+", "'_conv2'", ")", "\n", "ss_weights", "[", "scope", "+", "'_bias2'", "]", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "[", "dim_hidden", "]", ")", ",", "name", "=", "scope", "+", "'_bias2'", ")", "\n", "return", "ss_weights", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.meta_model.MakeMetaModel": [[19, 233], ["MetaModel", "print", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.minimize", "meta_model..training_summaries.append", "meta_model..training_summaries.append", "range", "range", "tensorflow.summary.merge", "tensorflow.placeholder", "tensorflow.placeholder", "meta_model..val_summaries.append", "meta_model..val_summaries.append", "tensorflow.summary.merge", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.variable_scope", "meta_model..construct_resnet_ss_weights", "meta_model..construct_resnet_weights", "meta_model..construct_fc_weights", "tensorflow.map_fn", "tensorflow.reduce_sum", "tensorflow.to_float", "tensorflow.reduce_sum", "tensorflow.to_float", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "meta_model..training_summaries.append", "meta_model..training_summaries.append", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.variable_scope", "meta_model..construct_resnet_ss_weights", "meta_model..construct_resnet_weights", "meta_model..construct_fc_weights", "tensorflow.map_fn", "tensorflow.reduce_sum", "meta_model..forward_resnet", "meta_model..forward_resnet", "meta_model..forward_fc", "meta_model..loss_func", "lossa_list.append", "meta_model..forward_fc", "meta_model..loss_func", "lossb_list.append", "tensorflow.gradients", "dict", "dict", "range", "meta_model..forward_fc", "meta_model..loss_func", "tensorflow.contrib.metrics.accuracy", "task_metalearn"], "function", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_resnet_ss_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_resnet_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_fc_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_resnet_ss_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_resnet_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_fc_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.forward_resnet", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.forward_resnet", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.forward_fc", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.forward_fc", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.forward_fc"], ["def", "MakeMetaModel", "(", ")", ":", "\n", "    ", "\"\"\"The function to make meta model.\n    Arg:\n      Meta-train model class.\n    \"\"\"", "\n", "if", "FLAGS", ".", "backbone_arch", "==", "'resnet12'", ":", "\n", "        ", "try", ":", "#python2", "\n", "            ", "from", "resnet12", "import", "Models", "\n", "", "except", "ImportError", ":", "#python3", "\n", "            ", "from", "models", ".", "resnet12", "import", "Models", "\n", "", "", "elif", "FLAGS", ".", "backbone_arch", "==", "'resnet18'", ":", "\n", "        ", "try", ":", "#python2", "\n", "            ", "from", "resnet18", "import", "Models", "\n", "", "except", "ImportError", ":", "#python3", "\n", "            ", "from", "models", ".", "resnet18", "import", "Models", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "'Please set the correct backbone'", ")", "\n", "\n", "", "class", "MetaModel", "(", "Models", ")", ":", "\n", "        ", "\"\"\"The class for the meta models. This class is inheritance from Models, so some variables are in the Models class.\"\"\"", "\n", "def", "construct_model", "(", "self", ")", ":", "\n", "            ", "\"\"\"The function to construct meta-train model.\"\"\"", "\n", "# Set the placeholder for the input episode", "\n", "self", ".", "inputa", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "# episode train images", "\n", "self", ".", "inputb", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "# episode test images", "\n", "self", ".", "labela", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "# episode train labels", "\n", "self", ".", "labelb", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "# episode test labels", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'meta-model'", ",", "reuse", "=", "None", ")", "as", "training_scope", ":", "\n", "# construct the model weights", "\n", "                ", "self", ".", "ss_weights", "=", "ss_weights", "=", "self", ".", "construct_resnet_ss_weights", "(", ")", "\n", "self", ".", "weights", "=", "weights", "=", "self", ".", "construct_resnet_weights", "(", ")", "\n", "self", ".", "fc_weights", "=", "fc_weights", "=", "self", ".", "construct_fc_weights", "(", ")", "\n", "\n", "# Load base epoch number from FLAGS", "\n", "num_updates", "=", "FLAGS", ".", "train_base_epoch_num", "\n", "\n", "def", "task_metalearn", "(", "inp", ",", "reuse", "=", "True", ")", ":", "\n", "                    ", "\"\"\"The function to process one episode in a meta-batch.\n                    Args:\n                      inp: the input episode.\n                      reuse: whether reuse the variables for the normalization.\n                    Returns:\n                      A serious outputs like losses and accuracies.\n                    \"\"\"", "\n", "# Seperate inp to different variables", "\n", "inputa", ",", "inputb", ",", "labela", ",", "labelb", "=", "inp", "\n", "# Generate empty list to record losses", "\n", "lossa_list", "=", "[", "]", "# Base train loss list", "\n", "lossb_list", "=", "[", "]", "# Base test loss list", "\n", "\n", "# Embed the input images to embeddings with ss weights", "\n", "emb_outputa", "=", "self", ".", "forward_resnet", "(", "inputa", ",", "weights", ",", "ss_weights", ",", "reuse", "=", "reuse", ")", "# Embed episode train", "\n", "emb_outputb", "=", "self", ".", "forward_resnet", "(", "inputb", ",", "weights", ",", "ss_weights", ",", "reuse", "=", "True", ")", "# Embed episode test", "\n", "\n", "# Run the first epoch of the base learning", "\n", "# Forward fc layer for episode train", "\n", "outputa", "=", "self", ".", "forward_fc", "(", "emb_outputa", ",", "fc_weights", ")", "\n", "# Calculate base train loss", "\n", "lossa", "=", "self", ".", "loss_func", "(", "outputa", ",", "labela", ")", "\n", "# Record base train loss", "\n", "lossa_list", ".", "append", "(", "lossa", ")", "\n", "# Forward fc layer for episode test", "\n", "outputb", "=", "self", ".", "forward_fc", "(", "emb_outputb", ",", "fc_weights", ")", "\n", "# Calculate base test loss", "\n", "lossb", "=", "self", ".", "loss_func", "(", "outputb", ",", "labelb", ")", "\n", "# Record base test loss", "\n", "lossb_list", ".", "append", "(", "lossb", ")", "\n", "# Calculate the gradients for the fc layer", "\n", "grads", "=", "tf", ".", "gradients", "(", "lossa", ",", "list", "(", "fc_weights", ".", "values", "(", ")", ")", ")", "\n", "gradients", "=", "dict", "(", "zip", "(", "fc_weights", ".", "keys", "(", ")", ",", "grads", ")", ")", "\n", "# Use graient descent to update the fc layer", "\n", "fast_fc_weights", "=", "dict", "(", "zip", "(", "fc_weights", ".", "keys", "(", ")", ",", "[", "fc_weights", "[", "key", "]", "-", "self", ".", "update_lr", "*", "gradients", "[", "key", "]", "for", "key", "in", "fc_weights", ".", "keys", "(", ")", "]", ")", ")", "\n", "\n", "for", "j", "in", "range", "(", "num_updates", "-", "1", ")", ":", "\n", "# Run the following base epochs, these are similar to the first base epoch", "\n", "                        ", "lossa", "=", "self", ".", "loss_func", "(", "self", ".", "forward_fc", "(", "emb_outputa", ",", "fast_fc_weights", ")", ",", "labela", ")", "\n", "lossa_list", ".", "append", "(", "lossa", ")", "\n", "lossb", "=", "self", ".", "loss_func", "(", "self", ".", "forward_fc", "(", "emb_outputb", ",", "fast_fc_weights", ")", ",", "labelb", ")", "\n", "lossb_list", ".", "append", "(", "lossb", ")", "\n", "grads", "=", "tf", ".", "gradients", "(", "lossa", ",", "list", "(", "fast_fc_weights", ".", "values", "(", ")", ")", ")", "\n", "gradients", "=", "dict", "(", "zip", "(", "fast_fc_weights", ".", "keys", "(", ")", ",", "grads", ")", ")", "\n", "fast_fc_weights", "=", "dict", "(", "zip", "(", "fast_fc_weights", ".", "keys", "(", ")", ",", "[", "fast_fc_weights", "[", "key", "]", "-", "self", ".", "update_lr", "*", "gradients", "[", "key", "]", "for", "key", "in", "fast_fc_weights", ".", "keys", "(", ")", "]", ")", ")", "\n", "\n", "# Calculate final episode test predictions", "\n", "", "outputb", "=", "self", ".", "forward_fc", "(", "emb_outputb", ",", "fast_fc_weights", ")", "\n", "# Calculate the final episode test loss, it is the loss for the episode on meta-train ", "\n", "final_lossb", "=", "self", ".", "loss_func", "(", "outputb", ",", "labelb", ")", "\n", "# Calculate the final episode test accuarcy", "\n", "accb", "=", "tf", ".", "contrib", ".", "metrics", ".", "accuracy", "(", "tf", ".", "argmax", "(", "tf", ".", "nn", ".", "softmax", "(", "outputb", ")", ",", "1", ")", ",", "tf", ".", "argmax", "(", "labelb", ",", "1", ")", ")", "\n", "\n", "# Reorganize all the outputs to a list", "\n", "task_output", "=", "[", "final_lossb", ",", "lossb_list", ",", "lossa_list", ",", "accb", "]", "\n", "\n", "return", "task_output", "\n", "\n", "# Initial the batch normalization weights", "\n", "", "if", "FLAGS", ".", "norm", "is", "not", "None", ":", "\n", "                    ", "unused", "=", "task_metalearn", "(", "(", "self", ".", "inputa", "[", "0", "]", ",", "self", ".", "inputb", "[", "0", "]", ",", "self", ".", "labela", "[", "0", "]", ",", "self", ".", "labelb", "[", "0", "]", ")", ",", "False", ")", "\n", "\n", "# Set the dtype of the outputs", "\n", "", "out_dtype", "=", "[", "tf", ".", "float32", ",", "[", "tf", ".", "float32", "]", "*", "num_updates", ",", "[", "tf", ".", "float32", "]", "*", "num_updates", ",", "tf", ".", "float32", "]", "\n", "\n", "# Run two episodes for a meta batch using parallel setting", "\n", "result", "=", "tf", ".", "map_fn", "(", "task_metalearn", ",", "elems", "=", "(", "self", ".", "inputa", ",", "self", ".", "inputb", ",", "self", ".", "labela", ",", "self", ".", "labelb", ")", ",", "dtype", "=", "out_dtype", ",", "parallel_iterations", "=", "FLAGS", ".", "meta_batch_size", ")", "\n", "# Seperate the outputs to different variables", "\n", "lossb", ",", "lossesb", ",", "lossesa", ",", "accsb", "=", "result", "\n", "\n", "# Set the variables to output from the tensorflow graph", "\n", "", "self", ".", "total_loss", "=", "total_loss", "=", "tf", ".", "reduce_sum", "(", "lossb", ")", "/", "tf", ".", "to_float", "(", "FLAGS", ".", "meta_batch_size", ")", "\n", "self", ".", "total_accuracy", "=", "total_accuracy", "=", "tf", ".", "reduce_sum", "(", "accsb", ")", "/", "tf", ".", "to_float", "(", "FLAGS", ".", "meta_batch_size", ")", "\n", "self", ".", "total_lossa", "=", "total_lossa", "=", "[", "tf", ".", "reduce_sum", "(", "lossesa", "[", "j", "]", ")", "/", "tf", ".", "to_float", "(", "FLAGS", ".", "meta_batch_size", ")", "for", "j", "in", "range", "(", "num_updates", ")", "]", "\n", "self", ".", "total_lossb", "=", "total_lossb", "=", "[", "tf", ".", "reduce_sum", "(", "lossesb", "[", "j", "]", ")", "/", "tf", ".", "to_float", "(", "FLAGS", ".", "meta_batch_size", ")", "for", "j", "in", "range", "(", "num_updates", ")", "]", "\n", "\n", "# Set the meta-train optimizer", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "meta_lr", ")", "\n", "self", ".", "metatrain_op", "=", "optimizer", ".", "minimize", "(", "total_loss", ",", "var_list", "=", "list", "(", "ss_weights", ".", "values", "(", ")", ")", "+", "list", "(", "fc_weights", ".", "values", "(", ")", ")", ")", "\n", "\n", "# Set the tensorboard", "\n", "self", ".", "training_summaries", "=", "[", "]", "\n", "self", ".", "training_summaries", ".", "append", "(", "tf", ".", "summary", ".", "scalar", "(", "'Meta Train Loss'", ",", "(", "total_loss", "/", "tf", ".", "to_float", "(", "FLAGS", ".", "metatrain_epite_sample_num", ")", ")", ")", ")", "\n", "self", ".", "training_summaries", ".", "append", "(", "tf", ".", "summary", ".", "scalar", "(", "'Meta Train Accuracy'", ",", "total_accuracy", ")", ")", "\n", "for", "j", "in", "range", "(", "num_updates", ")", ":", "\n", "                ", "self", ".", "training_summaries", ".", "append", "(", "tf", ".", "summary", ".", "scalar", "(", "'Base Train Loss Step'", "+", "str", "(", "j", "+", "1", ")", ",", "total_lossa", "[", "j", "]", ")", ")", "\n", "", "for", "j", "in", "range", "(", "num_updates", ")", ":", "\n", "                ", "self", ".", "training_summaries", ".", "append", "(", "tf", ".", "summary", ".", "scalar", "(", "'Base Val Loss Step'", "+", "str", "(", "j", "+", "1", ")", ",", "total_lossb", "[", "j", "]", ")", ")", "\n", "\n", "", "self", ".", "training_summ_op", "=", "tf", ".", "summary", ".", "merge", "(", "self", ".", "training_summaries", ")", "\n", "\n", "self", ".", "input_val_loss", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "\n", "self", ".", "input_val_acc", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "\n", "self", ".", "val_summaries", "=", "[", "]", "\n", "self", ".", "val_summaries", ".", "append", "(", "tf", ".", "summary", ".", "scalar", "(", "'Meta Val Loss'", ",", "self", ".", "input_val_loss", ")", ")", "\n", "self", ".", "val_summaries", ".", "append", "(", "tf", ".", "summary", ".", "scalar", "(", "'Meta Val Accuracy'", ",", "self", ".", "input_val_acc", ")", ")", "\n", "self", ".", "val_summ_op", "=", "tf", ".", "summary", ".", "merge", "(", "self", ".", "val_summaries", ")", "\n", "\n", "", "def", "construct_test_model", "(", "self", ")", ":", "\n", "            ", "\"\"\"The function to construct meta-test model.\"\"\"", "\n", "# Set the placeholder for the input episode", "\n", "self", ".", "inputa", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "\n", "self", ".", "inputb", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "\n", "self", ".", "labela", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "\n", "self", ".", "labelb", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'meta-test-model'", ",", "reuse", "=", "None", ")", "as", "training_scope", ":", "\n", "# construct the model weights", "\n", "                ", "self", ".", "ss_weights", "=", "ss_weights", "=", "self", ".", "construct_resnet_ss_weights", "(", ")", "\n", "self", ".", "weights", "=", "weights", "=", "self", ".", "construct_resnet_weights", "(", ")", "\n", "self", ".", "fc_weights", "=", "fc_weights", "=", "self", ".", "construct_fc_weights", "(", ")", "\n", "\n", "# Load test base epoch number from FLAGS", "\n", "num_updates", "=", "FLAGS", ".", "test_base_epoch_num", "\n", "\n", "def", "task_metalearn", "(", "inp", ",", "reuse", "=", "True", ")", ":", "\n", "                    ", "\"\"\"The function to process one episode in a meta-batch.\n                    Args:\n                      inp: the input episode.\n                      reuse: whether reuse the variables for the normalization.\n                    Returns:\n                      A serious outputs like losses and accuracies.\n                    \"\"\"", "\n", "# Seperate inp to different variables", "\n", "inputa", ",", "inputb", ",", "labela", ",", "labelb", "=", "inp", "\n", "# Generate empty list to record accuracies", "\n", "accb_list", "=", "[", "]", "\n", "\n", "# Embed the input images to embeddings with ss weights", "\n", "emb_outputa", "=", "self", ".", "forward_resnet", "(", "inputa", ",", "weights", ",", "ss_weights", ",", "reuse", "=", "reuse", ")", "\n", "emb_outputb", "=", "self", ".", "forward_resnet", "(", "inputb", ",", "weights", ",", "ss_weights", ",", "reuse", "=", "True", ")", "\n", "\n", "# This part is similar to the meta-train function, you may refer to the comments above", "\n", "outputa", "=", "self", ".", "forward_fc", "(", "emb_outputa", ",", "fc_weights", ")", "\n", "lossa", "=", "self", ".", "loss_func", "(", "outputa", ",", "labela", ")", "\n", "grads", "=", "tf", ".", "gradients", "(", "lossa", ",", "list", "(", "fc_weights", ".", "values", "(", ")", ")", ")", "\n", "gradients", "=", "dict", "(", "zip", "(", "fc_weights", ".", "keys", "(", ")", ",", "grads", ")", ")", "\n", "fast_fc_weights", "=", "dict", "(", "zip", "(", "fc_weights", ".", "keys", "(", ")", ",", "[", "fc_weights", "[", "key", "]", "-", "self", ".", "update_lr", "*", "gradients", "[", "key", "]", "for", "key", "in", "fc_weights", ".", "keys", "(", ")", "]", ")", ")", "\n", "outputb", "=", "self", ".", "forward_fc", "(", "emb_outputb", ",", "fast_fc_weights", ")", "\n", "accb", "=", "tf", ".", "contrib", ".", "metrics", ".", "accuracy", "(", "tf", ".", "argmax", "(", "tf", ".", "nn", ".", "softmax", "(", "outputb", ")", ",", "1", ")", ",", "tf", ".", "argmax", "(", "labelb", ",", "1", ")", ")", "\n", "accb_list", ".", "append", "(", "accb", ")", "\n", "\n", "for", "j", "in", "range", "(", "num_updates", "-", "1", ")", ":", "\n", "                        ", "lossa", "=", "self", ".", "loss_func", "(", "self", ".", "forward_fc", "(", "emb_outputa", ",", "fast_fc_weights", ")", ",", "labela", ")", "\n", "grads", "=", "tf", ".", "gradients", "(", "lossa", ",", "list", "(", "fast_fc_weights", ".", "values", "(", ")", ")", ")", "\n", "gradients", "=", "dict", "(", "zip", "(", "fast_fc_weights", ".", "keys", "(", ")", ",", "grads", ")", ")", "\n", "fast_fc_weights", "=", "dict", "(", "zip", "(", "fast_fc_weights", ".", "keys", "(", ")", ",", "[", "fast_fc_weights", "[", "key", "]", "-", "self", ".", "update_lr", "*", "gradients", "[", "key", "]", "for", "key", "in", "fast_fc_weights", ".", "keys", "(", ")", "]", ")", ")", "\n", "outputb", "=", "self", ".", "forward_fc", "(", "emb_outputb", ",", "fast_fc_weights", ")", "\n", "accb", "=", "tf", ".", "contrib", ".", "metrics", ".", "accuracy", "(", "tf", ".", "argmax", "(", "tf", ".", "nn", ".", "softmax", "(", "outputb", ")", ",", "1", ")", ",", "tf", ".", "argmax", "(", "labelb", ",", "1", ")", ")", "\n", "accb_list", ".", "append", "(", "accb", ")", "\n", "\n", "", "lossb", "=", "self", ".", "loss_func", "(", "outputb", ",", "labelb", ")", "\n", "\n", "task_output", "=", "[", "lossb", ",", "accb", ",", "accb_list", "]", "\n", "\n", "return", "task_output", "\n", "\n", "", "if", "FLAGS", ".", "norm", "is", "not", "None", ":", "\n", "                    ", "unused", "=", "task_metalearn", "(", "(", "self", ".", "inputa", "[", "0", "]", ",", "self", ".", "inputb", "[", "0", "]", ",", "self", ".", "labela", "[", "0", "]", ",", "self", ".", "labelb", "[", "0", "]", ")", ",", "False", ")", "\n", "\n", "", "out_dtype", "=", "[", "tf", ".", "float32", ",", "tf", ".", "float32", ",", "[", "tf", ".", "float32", "]", "*", "num_updates", "]", "\n", "\n", "result", "=", "tf", ".", "map_fn", "(", "task_metalearn", ",", "elems", "=", "(", "self", ".", "inputa", ",", "self", ".", "inputb", ",", "self", ".", "labela", ",", "self", ".", "labelb", ")", ",", "dtype", "=", "out_dtype", ",", "parallel_iterations", "=", "FLAGS", ".", "meta_batch_size", ")", "\n", "lossesb", ",", "accsb", ",", "accsb_list", "=", "result", "\n", "\n", "", "self", ".", "metaval_total_loss", "=", "total_loss", "=", "tf", ".", "reduce_sum", "(", "lossesb", ")", "\n", "self", ".", "metaval_total_accuracy", "=", "total_accuracy", "=", "tf", ".", "reduce_sum", "(", "accsb", ")", "\n", "self", ".", "metaval_total_accuracies", "=", "total_accuracies", "=", "[", "tf", ".", "reduce_sum", "(", "accsb_list", "[", "j", "]", ")", "for", "j", "in", "range", "(", "num_updates", ")", "]", "\n", "\n", "", "", "return", "MetaModel", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.pre_model.MakePreModel": [[17, 65], ["PreModel", "print", "tensorflow.variable_scope", "pre_model..construct_resnet_weights", "pre_model..construct_fc_weights", "pre_model..forward_fc", "pre_model..pretrain_loss_func", "tensorflow.train.AdamOptimizer", "tf.train.AdamOptimizer.minimize", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "pre_model..forward_fc", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "pre_model..forward_pretrain_resnet", "tensorflow.contrib.metrics.accuracy", "pre_model..forward_pretrain_resnet", "tensorflow.contrib.metrics.accuracy", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.argmax", "pre_model..values", "pre_model..values", "tensorflow.nn.softmax", "tensorflow.nn.softmax"], "function", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_resnet_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.construct_fc_weights", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.forward_fc", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.forward_fc", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.forward_pretrain_resnet", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.resnet18.Models.forward_pretrain_resnet"], ["def", "MakePreModel", "(", ")", ":", "\n", "    ", "\"\"\"The function to make pre model.\n    Arg:\n      Pre-train model class.\n    \"\"\"", "\n", "if", "FLAGS", ".", "backbone_arch", "==", "'resnet12'", ":", "\n", "        ", "try", ":", "#python2", "\n", "            ", "from", "resnet12", "import", "Models", "\n", "", "except", "ImportError", ":", "#python3", "\n", "            ", "from", "models", ".", "resnet12", "import", "Models", "\n", "", "", "elif", "FLAGS", ".", "backbone_arch", "==", "'resnet18'", ":", "\n", "        ", "try", ":", "#python2", "\n", "            ", "from", "resnet18", "import", "Models", "\n", "", "except", "ImportError", ":", "#python3", "\n", "            ", "from", "models", ".", "resnet18", "import", "Models", "\n", "", "", "else", ":", "\n", "        ", "print", "(", "'Please set the correct backbone'", ")", "\n", "\n", "", "class", "PreModel", "(", "Models", ")", ":", "\n", "        ", "\"\"\"The class for pre-train model.\"\"\"", "\n", "def", "construct_pretrain_model", "(", "self", ",", "input_tensors", "=", "None", ",", "is_val", "=", "False", ")", ":", "\n", "            ", "\"\"\"The function to construct pre-train model.\n            Args:\n              input_tensors: the input tensor to construct pre-train model.\n              is_val: whether the model is for validation.\n            \"\"\"", "\n", "self", ".", "input", "=", "input_tensors", "[", "'pretrain_input'", "]", "\n", "self", ".", "label", "=", "input_tensors", "[", "'pretrain_label'", "]", "\n", "with", "tf", ".", "variable_scope", "(", "'pretrain-model'", ",", "reuse", "=", "None", ")", "as", "training_scope", ":", "\n", "                ", "self", ".", "weights", "=", "weights", "=", "self", ".", "construct_resnet_weights", "(", ")", "\n", "self", ".", "fc_weights", "=", "fc_weights", "=", "self", ".", "construct_fc_weights", "(", ")", "\n", "\n", "if", "is_val", "is", "False", ":", "\n", "                    ", "self", ".", "pretrain_task_output", "=", "self", ".", "forward_fc", "(", "self", ".", "forward_pretrain_resnet", "(", "self", ".", "input", ",", "weights", ",", "reuse", "=", "False", ")", ",", "fc_weights", ")", "\n", "self", ".", "pretrain_task_loss", "=", "self", ".", "pretrain_loss_func", "(", "self", ".", "pretrain_task_output", ",", "self", ".", "label", ")", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "pretrain_lr", ")", "\n", "self", ".", "pretrain_op", "=", "optimizer", ".", "minimize", "(", "self", ".", "pretrain_task_loss", ",", "var_list", "=", "weights", ".", "values", "(", ")", "+", "fc_weights", ".", "values", "(", ")", ")", "\n", "self", ".", "pretrain_task_accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "contrib", ".", "metrics", ".", "accuracy", "(", "tf", ".", "argmax", "(", "tf", ".", "nn", ".", "softmax", "(", "self", ".", "pretrain_task_output", ")", ",", "1", ")", ",", "tf", ".", "argmax", "(", "self", ".", "label", ",", "1", ")", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'pretrain train loss'", ",", "self", ".", "pretrain_task_loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'pretrain train accuracy'", ",", "self", ".", "pretrain_task_accuracy", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "pretrain_task_output_val", "=", "self", ".", "forward_fc", "(", "self", ".", "forward_pretrain_resnet", "(", "self", ".", "input", ",", "weights", ",", "reuse", "=", "True", ")", ",", "fc_weights", ")", "\n", "self", ".", "pretrain_task_accuracy_val", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "contrib", ".", "metrics", ".", "accuracy", "(", "tf", ".", "argmax", "(", "tf", ".", "nn", ".", "softmax", "(", "self", ".", "pretrain_task_output_val", ")", ",", "1", ")", ",", "tf", ".", "argmax", "(", "self", ".", "label", ",", "1", ")", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'pretrain val accuracy'", ",", "self", ".", "pretrain_task_accuracy_val", ")", "\n", "\n", "", "", "", "", "return", "PreModel", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.trainer.meta.MetaTrainer.__init__": [[30, 152], ["os.system", "data_generator.meta_data_generator.MetaDataGenerator.meta_data_generator.MetaDataGenerator", "tensorflow.global_variables_initializer().run", "tensorflow.train.start_queue_runners", "print", "models.meta_model.MakeMetaModel", "meta.MetaTrainer.model.construct_model", "print", "meta.MetaTrainer.start_session", "data_generator.meta_data_generator.MetaDataGenerator.meta_data_generator.MetaDataGenerator.generate_data", "data_generator.meta_data_generator.MetaDataGenerator.meta_data_generator.MetaDataGenerator.generate_data", "data_generator.meta_data_generator.MetaDataGenerator.meta_data_generator.MetaDataGenerator.generate_data", "print", "models.meta_model.MakeMetaModel", "meta.MetaTrainer.model.construct_test_model", "tensorflow.summary.merge_all", "print", "meta.MetaTrainer.start_session", "data_generator.meta_data_generator.MetaDataGenerator.meta_data_generator.MetaDataGenerator.generate_data", "numpy.load().tolist.keys", "numpy.load().tolist.keys", "numpy.load().tolist.keys", "print", "meta.MetaTrainer.train", "meta.MetaTrainer.test", "random.seed", "random.seed", "random.seed", "random.seed", "tensorflow.global_variables_initializer", "os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "numpy.load().tolist.keys", "print", "meta.MetaTrainer.sess.run", "meta.MetaTrainer.sess.run", "meta.MetaTrainer.sess.run", "numpy.save", "numpy.save", "numpy.save", "print", "numpy.load().tolist", "numpy.load().tolist", "numpy.load().tolist", "numpy.load().tolist.keys", "numpy.load().tolist.keys", "numpy.load().tolist.keys", "print", "numpy.load().tolist", "numpy.load().tolist", "numpy.load().tolist", "numpy.load().tolist", "numpy.load().tolist", "numpy.load().tolist", "meta.MetaTrainer.sess.run", "meta.MetaTrainer.sess.run", "meta.MetaTrainer.sess.run", "print", "print", "str", "print", "numpy.load().tolist", "print", "os.path.join", "numpy.load().tolist", "meta.MetaTrainer.sess.run", "meta.MetaTrainer.sess.run", "meta.MetaTrainer.sess.run", "meta.MetaTrainer.sess.run", "meta.MetaTrainer.sess.run", "tensorflow.assign", "tensorflow.assign", "tensorflow.assign", "numpy.load().tolist.keys", "tensorflow.assign", "tensorflow.assign", "numpy.load", "numpy.load", "numpy.load", "tensorflow.assign", "tensorflow.assign", "tensorflow.assign", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "str", "numpy.load", "numpy.load", "os.path.join", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.meta_model.MakeMetaModel", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.trainer.meta.MetaTrainer.start_session", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.generate_data", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.generate_data", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.generate_data", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.meta_model.MakeMetaModel", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.trainer.meta.MetaTrainer.start_session", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.generate_data", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.trainer.pre.PreTrainer.train", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.trainer.meta.MetaTrainer.test"], ["if", "not", "osp", ".", "exists", "(", "log_base_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "log_base_dir", ")", "\n", "", "meta_base_dir", "=", "osp", ".", "join", "(", "log_base_dir", ",", "'meta'", ")", "\n", "if", "not", "osp", ".", "exists", "(", "meta_base_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "meta_base_dir", ")", "\n", "", "save_path1", "=", "'_'", ".", "join", "(", "[", "args", ".", "dataset", ",", "args", ".", "model_type", ",", "'MTL'", "]", ")", "\n", "save_path2", "=", "'shot'", "+", "str", "(", "args", ".", "shot", ")", "+", "'_way'", "+", "str", "(", "args", ".", "way", ")", "+", "'_query'", "+", "str", "(", "args", ".", "train_query", ")", "+", "'_step'", "+", "str", "(", "args", ".", "step_size", ")", "+", "'_gamma'", "+", "str", "(", "args", ".", "gamma", ")", "+", "'_lr1'", "+", "str", "(", "args", ".", "meta_lr1", ")", "+", "'_lr2'", "+", "str", "(", "args", ".", "meta_lr2", ")", "+", "'_batch'", "+", "str", "(", "args", ".", "num_batch", ")", "+", "'_maxepoch'", "+", "str", "(", "args", ".", "max_epoch", ")", "+", "'_baselr'", "+", "str", "(", "args", ".", "base_lr", ")", "+", "'_updatestep'", "+", "str", "(", "args", ".", "update_step", ")", "+", "'_stepsize'", "+", "str", "(", "args", ".", "step_size", ")", "+", "'_'", "+", "args", ".", "meta_label", "\n", "args", ".", "save_path", "=", "meta_base_dir", "+", "'/'", "+", "save_path1", "+", "'_'", "+", "save_path2", "\n", "ensure_path", "(", "args", ".", "save_path", ")", "\n", "\n", "# Set args to be shareable in the class", "\n", "self", ".", "args", "=", "args", "\n", "\n", "# Load meta-train set", "\n", "self", ".", "trainset", "=", "Dataset", "(", "'train'", ",", "self", ".", "args", ")", "\n", "self", ".", "train_sampler", "=", "CategoriesSampler", "(", "self", ".", "trainset", ".", "label", ",", "self", ".", "args", ".", "num_batch", ",", "self", ".", "args", ".", "way", ",", "self", ".", "args", ".", "shot", "+", "self", ".", "args", ".", "train_query", ")", "\n", "self", ".", "train_loader", "=", "DataLoader", "(", "dataset", "=", "self", ".", "trainset", ",", "batch_sampler", "=", "self", ".", "train_sampler", ",", "num_workers", "=", "8", ",", "pin_memory", "=", "True", ")", "\n", "\n", "# Load meta-val set", "\n", "self", ".", "valset", "=", "Dataset", "(", "'val'", ",", "self", ".", "args", ")", "\n", "self", ".", "val_sampler", "=", "CategoriesSampler", "(", "self", ".", "valset", ".", "label", ",", "600", ",", "self", ".", "args", ".", "way", ",", "self", ".", "args", ".", "shot", "+", "self", ".", "args", ".", "val_query", ")", "\n", "self", ".", "val_loader", "=", "DataLoader", "(", "dataset", "=", "self", ".", "valset", ",", "batch_sampler", "=", "self", ".", "val_sampler", ",", "num_workers", "=", "8", ",", "pin_memory", "=", "True", ")", "\n", "\n", "# Build meta-transfer learning model", "\n", "self", ".", "model", "=", "MtlLearner", "(", "self", ".", "args", ")", "\n", "\n", "# Set optimizer ", "\n", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "[", "{", "'params'", ":", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "self", ".", "model", ".", "encoder", ".", "parameters", "(", ")", ")", "}", ",", "{", "'params'", ":", "self", ".", "model", ".", "base_learner", ".", "parameters", "(", ")", ",", "'lr'", ":", "self", ".", "args", ".", "meta_lr2", "}", "]", ",", "lr", "=", "self", ".", "args", ".", "meta_lr1", ")", "\n", "# Set learning rate scheduler ", "\n", "self", ".", "lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "self", ".", "optimizer", ",", "step_size", "=", "self", ".", "args", ".", "step_size", ",", "gamma", "=", "self", ".", "args", ".", "gamma", ")", "\n", "\n", "# load pretrained model without FC classifier", "\n", "self", ".", "model_dict", "=", "self", ".", "model", ".", "state_dict", "(", ")", "\n", "if", "self", ".", "args", ".", "init_weights", "is", "not", "None", ":", "\n", "            ", "pretrained_dict", "=", "torch", ".", "load", "(", "self", ".", "args", ".", "init_weights", ")", "[", "'params'", "]", "\n", "", "else", ":", "\n", "            ", "pre_base_dir", "=", "osp", ".", "join", "(", "log_base_dir", ",", "'pre'", ")", "\n", "pre_save_path1", "=", "'_'", ".", "join", "(", "[", "args", ".", "dataset", ",", "args", ".", "model_type", "]", ")", "\n", "pre_save_path2", "=", "'batchsize'", "+", "str", "(", "args", ".", "pre_batch_size", ")", "+", "'_lr'", "+", "str", "(", "args", ".", "pre_lr", ")", "+", "'_gamma'", "+", "str", "(", "args", ".", "pre_gamma", ")", "+", "'_step'", "+", "str", "(", "args", ".", "pre_step_size", ")", "+", "'_maxepoch'", "+", "str", "(", "args", ".", "pre_max_epoch", ")", "\n", "pre_save_path", "=", "pre_base_dir", "+", "'/'", "+", "pre_save_path1", "+", "'_'", "+", "pre_save_path2", "\n", "pretrained_dict", "=", "torch", ".", "load", "(", "osp", ".", "join", "(", "pre_save_path", ",", "'max_acc.pth'", ")", ")", "[", "'params'", "]", "\n", "", "pretrained_dict", "=", "{", "'encoder.'", "+", "k", ":", "v", "for", "k", ",", "v", "in", "pretrained_dict", ".", "items", "(", ")", "}", "\n", "pretrained_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "pretrained_dict", ".", "items", "(", ")", "if", "k", "in", "self", ".", "model_dict", "}", "\n", "print", "(", "pretrained_dict", ".", "keys", "(", ")", ")", "\n", "self", ".", "model_dict", ".", "update", "(", "pretrained_dict", ")", "\n", "self", ".", "model", ".", "load_state_dict", "(", "self", ".", "model_dict", ")", "\n", "\n", "# Set model to GPU", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "self", ".", "model", "=", "self", ".", "model", ".", "cuda", "(", ")", "\n", "\n", "", "", "def", "save_model", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"The function to save checkpoints.\n        Args:\n          name: the name for saved checkpoint\n        \"\"\"", "\n", "torch", ".", "save", "(", "dict", "(", "params", "=", "self", ".", "model", ".", "state_dict", "(", ")", ")", ",", "osp", ".", "join", "(", "self", ".", "args", ".", "save_path", ",", "name", "+", "'.pth'", ")", ")", "\n", "\n", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "\"\"\"The function for the meta-train phase.\"\"\"", "\n", "\n", "# Set the meta-train log", "\n", "trlog", "=", "{", "}", "\n", "trlog", "[", "'args'", "]", "=", "vars", "(", "self", ".", "args", ")", "\n", "trlog", "[", "'train_loss'", "]", "=", "[", "]", "\n", "trlog", "[", "'val_loss'", "]", "=", "[", "]", "\n", "trlog", "[", "'train_acc'", "]", "=", "[", "]", "\n", "trlog", "[", "'val_acc'", "]", "=", "[", "]", "\n", "trlog", "[", "'max_acc'", "]", "=", "0.0", "\n", "trlog", "[", "'max_acc_epoch'", "]", "=", "0", "\n", "\n", "# Set the timer", "\n", "timer", "=", "Timer", "(", ")", "\n", "# Set global count to zero", "\n", "global_count", "=", "0", "\n", "# Set tensorboardX", "\n", "writer", "=", "SummaryWriter", "(", "comment", "=", "self", ".", "args", ".", "save_path", ")", "\n", "\n", "# Generate the labels for train set of the episodes", "\n", "label_shot", "=", "torch", ".", "arange", "(", "self", ".", "args", ".", "way", ")", ".", "repeat", "(", "self", ".", "args", ".", "shot", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "label_shot", "=", "label_shot", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", "\n", "", "else", ":", "\n", "            ", "label_shot", "=", "label_shot", ".", "type", "(", "torch", ".", "LongTensor", ")", "\n", "\n", "# Start meta-train", "\n", "", "for", "epoch", "in", "range", "(", "1", ",", "self", ".", "args", ".", "max_epoch", "+", "1", ")", ":", "\n", "# Update learning rate", "\n", "            ", "self", ".", "lr_scheduler", ".", "step", "(", ")", "\n", "# Set the model to train mode", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "# Set averager classes to record training losses and accuracies", "\n", "train_loss_averager", "=", "Averager", "(", ")", "\n", "train_acc_averager", "=", "Averager", "(", ")", "\n", "\n", "# Generate the labels for test set of the episodes during meta-train updates", "\n", "label", "=", "torch", ".", "arange", "(", "self", ".", "args", ".", "way", ")", ".", "repeat", "(", "self", ".", "args", ".", "train_query", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "label", "=", "label", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", "\n", "", "else", ":", "\n", "                ", "label", "=", "label", ".", "type", "(", "torch", ".", "LongTensor", ")", "\n", "\n", "# Using tqdm to read samples from train loader", "\n", "", "tqdm_gen", "=", "tqdm", ".", "tqdm", "(", "self", ".", "train_loader", ")", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "tqdm_gen", ",", "1", ")", ":", "\n", "# Update global count number ", "\n", "                ", "global_count", "=", "global_count", "+", "1", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "data", ",", "_", "=", "[", "_", ".", "cuda", "(", ")", "for", "_", "in", "batch", "]", "\n", "", "else", ":", "\n", "                    ", "data", "=", "batch", "[", "0", "]", "\n", "", "p", "=", "self", ".", "args", ".", "shot", "*", "self", ".", "args", ".", "way", "\n", "data_shot", ",", "data_query", "=", "data", "[", ":", "p", "]", ",", "data", "[", "p", ":", "]", "\n", "# Output logits for model", "\n", "logits", "=", "self", ".", "model", "(", "(", "data_shot", ",", "label_shot", ",", "data_query", ")", ")", "\n", "# Calculate meta-train loss", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.trainer.meta.MetaTrainer.save_model": [[88, 94], ["torch.save", "torch.save", "torch.save", "torch.save", "dict", "os.join", "os.join", "meta.MetaTrainer.model.state_dict"], "methods", ["None"], ["", "", "def", "save_model", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"The function to save checkpoints.\n        Args:\n          name: the name for saved checkpoint\n        \"\"\"", "\n", "torch", ".", "save", "(", "dict", "(", "params", "=", "self", ".", "model", ".", "state_dict", "(", ")", ")", ",", "osp", ".", "join", "(", "self", ".", "args", ".", "save_path", ",", "name", "+", "'.pth'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.trainer.meta.MetaTrainer.train": [[162, 273], ["tensorflow.summary.FileWriter", "print", "data_generator.load_data", "data_generator.load_data", "tqdm.trange", "meta.MetaTrainer.sess.run", "meta.MetaTrainer.sess.run", "meta.MetaTrainer.sess.run", "numpy.save", "numpy.save", "numpy.save", "range", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "input_tensors.extend", "input_tensors.extend", "input_tensors.extend", "meta.MetaTrainer.sess.run", "loss_list.append", "acc_list.append", "tensorflow.summary.FileWriter.add_summary", "data_generator.load_episode", "numpy.array.append", "numpy.array.append", "numpy.array.append", "numpy.array.append", "print", "meta.MetaTrainer.sess.run", "meta.MetaTrainer.sess.run", "meta.MetaTrainer.sess.run", "numpy.save", "numpy.save", "numpy.save", "range", "meta.MetaTrainer.sess.run", "tensorflow.summary.FileWriter.add_summary", "print", "print", "str", "str", "data_generator.load_episode", "meta.MetaTrainer.sess.run", "test_loss.append", "test_accs.append", "str", "str", "str", "str", "numpy.mean", "numpy.float", "numpy.mean", "numpy.float", "str", "str", "str", "str", "numpy.mean", "numpy.float", "str", "numpy.mean", "numpy.mean", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.load_data", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.load_data", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.load_episode", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.load_episode"], ["# Add loss and accuracy for the averagers", "\n", "train_loss_averager", ".", "add", "(", "loss", ".", "item", "(", ")", ")", "\n", "train_acc_averager", ".", "add", "(", "acc", ")", "\n", "\n", "# Loss backwards and optimizer updates", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Update the averagers", "\n", "", "train_loss_averager", "=", "train_loss_averager", ".", "item", "(", ")", "\n", "train_acc_averager", "=", "train_acc_averager", ".", "item", "(", ")", "\n", "\n", "# Start validation for this epoch, set model to eval mode", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "# Set averager classes to record validation losses and accuracies", "\n", "val_loss_averager", "=", "Averager", "(", ")", "\n", "val_acc_averager", "=", "Averager", "(", ")", "\n", "\n", "# Generate the labels for test set of the episodes during meta-val for this epoch", "\n", "label", "=", "torch", ".", "arange", "(", "self", ".", "args", ".", "way", ")", ".", "repeat", "(", "self", ".", "args", ".", "val_query", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "label", "=", "label", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", "\n", "", "else", ":", "\n", "                ", "label", "=", "label", ".", "type", "(", "torch", ".", "LongTensor", ")", "\n", "\n", "# Print previous information", "\n", "", "if", "epoch", "%", "10", "==", "0", ":", "\n", "                ", "print", "(", "'Best Epoch {}, Best Val Acc={:.4f}'", ".", "format", "(", "trlog", "[", "'max_acc_epoch'", "]", ",", "trlog", "[", "'max_acc'", "]", ")", ")", "\n", "# Run meta-validation", "\n", "", "for", "i", ",", "batch", "in", "enumerate", "(", "self", ".", "val_loader", ",", "1", ")", ":", "\n", "                ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "data", ",", "_", "=", "[", "_", ".", "cuda", "(", ")", "for", "_", "in", "batch", "]", "\n", "", "else", ":", "\n", "                    ", "data", "=", "batch", "[", "0", "]", "\n", "", "p", "=", "self", ".", "args", ".", "shot", "*", "self", ".", "args", ".", "way", "\n", "data_shot", ",", "data_query", "=", "data", "[", ":", "p", "]", ",", "data", "[", "p", ":", "]", "\n", "logits", "=", "self", ".", "model", "(", "(", "data_shot", ",", "label_shot", ",", "data_query", ")", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ",", "label", ")", "\n", "acc", "=", "count_acc", "(", "logits", ",", "label", ")", "\n", "\n", "val_loss_averager", ".", "add", "(", "loss", ".", "item", "(", ")", ")", "\n", "val_acc_averager", ".", "add", "(", "acc", ")", "\n", "\n", "# Update validation averagers", "\n", "", "val_loss_averager", "=", "val_loss_averager", ".", "item", "(", ")", "\n", "val_acc_averager", "=", "val_acc_averager", ".", "item", "(", ")", "\n", "# Write the tensorboardX records", "\n", "writer", ".", "add_scalar", "(", "'data/val_loss'", ",", "float", "(", "val_loss_averager", ")", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'data/val_acc'", ",", "float", "(", "val_acc_averager", ")", ",", "epoch", ")", "\n", "# Print loss and accuracy for this epoch", "\n", "print", "(", "'Epoch {}, Val, Loss={:.4f} Acc={:.4f}'", ".", "format", "(", "epoch", ",", "val_loss_averager", ",", "val_acc_averager", ")", ")", "\n", "\n", "# Update best saved model", "\n", "if", "val_acc_averager", ">", "trlog", "[", "'max_acc'", "]", ":", "\n", "                ", "trlog", "[", "'max_acc'", "]", "=", "val_acc_averager", "\n", "trlog", "[", "'max_acc_epoch'", "]", "=", "epoch", "\n", "self", ".", "save_model", "(", "'max_acc'", ")", "\n", "# Save model every 10 epochs", "\n", "", "if", "epoch", "%", "10", "==", "0", ":", "\n", "                ", "self", ".", "save_model", "(", "'epoch'", "+", "str", "(", "epoch", ")", ")", "\n", "\n", "# Update the logs", "\n", "", "trlog", "[", "'train_loss'", "]", ".", "append", "(", "train_loss_averager", ")", "\n", "trlog", "[", "'train_acc'", "]", ".", "append", "(", "train_acc_averager", ")", "\n", "trlog", "[", "'val_loss'", "]", ".", "append", "(", "val_loss_averager", ")", "\n", "trlog", "[", "'val_acc'", "]", ".", "append", "(", "val_acc_averager", ")", "\n", "\n", "# Save log", "\n", "torch", ".", "save", "(", "trlog", ",", "osp", ".", "join", "(", "self", ".", "args", ".", "save_path", ",", "'trlog'", ")", ")", "\n", "\n", "if", "epoch", "%", "10", "==", "0", ":", "\n", "                ", "print", "(", "'Running Time: {}, Estimated Time: {}'", ".", "format", "(", "timer", ".", "measure", "(", ")", ",", "timer", ".", "measure", "(", "epoch", "/", "self", ".", "args", ".", "max_epoch", ")", ")", ")", "\n", "\n", "", "", "writer", ".", "close", "(", ")", "\n", "\n", "", "def", "eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"The function for the meta-eval phase.\"\"\"", "\n", "# Load the logs", "\n", "trlog", "=", "torch", ".", "load", "(", "osp", ".", "join", "(", "self", ".", "args", ".", "save_path", ",", "'trlog'", ")", ")", "\n", "\n", "# Load meta-test set", "\n", "test_set", "=", "Dataset", "(", "'test'", ",", "self", ".", "args", ")", "\n", "sampler", "=", "CategoriesSampler", "(", "test_set", ".", "label", ",", "600", ",", "self", ".", "args", ".", "way", ",", "self", ".", "args", ".", "shot", "+", "self", ".", "args", ".", "val_query", ")", "\n", "loader", "=", "DataLoader", "(", "test_set", ",", "batch_sampler", "=", "sampler", ",", "num_workers", "=", "8", ",", "pin_memory", "=", "True", ")", "\n", "\n", "# Set test accuracy recorder", "\n", "test_acc_record", "=", "np", ".", "zeros", "(", "(", "600", ",", ")", ")", "\n", "\n", "# Load model for meta-test phase", "\n", "if", "self", ".", "args", ".", "eval_weights", "is", "not", "None", ":", "\n", "            ", "self", ".", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "self", ".", "args", ".", "eval_weights", ")", "[", "'params'", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "osp", ".", "join", "(", "self", ".", "args", ".", "save_path", ",", "'max_acc'", "+", "'.pth'", ")", ")", "[", "'params'", "]", ")", "\n", "# Set model to eval mode", "\n", "", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "# Set accuracy averager", "\n", "ave_acc", "=", "Averager", "(", ")", "\n", "\n", "# Generate labels", "\n", "label", "=", "torch", ".", "arange", "(", "self", ".", "args", ".", "way", ")", ".", "repeat", "(", "self", ".", "args", ".", "val_query", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "label", "=", "label", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", "\n", "", "else", ":", "\n", "            ", "label", "=", "label", ".", "type", "(", "torch", ".", "LongTensor", ")", "\n", "", "label_shot", "=", "torch", ".", "arange", "(", "self", ".", "args", ".", "way", ")", ".", "repeat", "(", "self", ".", "args", ".", "shot", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "label_shot", "=", "label_shot", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", "\n", "", "else", ":", "\n", "            ", "label_shot", "=", "label_shot", ".", "type", "(", "torch", ".", "LongTensor", ")", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.trainer.meta.MetaTrainer.eval": [[239, 294], ["torch.load", "torch.load", "torch.load", "torch.load", "dataloader.dataset_loader.DatasetLoader", "dataloader.samplers.CategoriesSampler", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "numpy.zeros", "meta.MetaTrainer.model.eval", "utils.misc.Averager", "torch.arange().repeat", "torch.arange().repeat", "torch.arange().repeat", "torch.arange().repeat", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.arange().repeat", "torch.arange().repeat", "torch.arange().repeat", "torch.arange().repeat", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "enumerate", "utils.misc.compute_confidence_interval", "print", "print", "os.join", "os.join", "meta.MetaTrainer.model.load_state_dict", "meta.MetaTrainer.model.load_state_dict", "label.type.type.type", "label.type.type.type", "label_shot.type.type.type", "label_shot.type.type.type", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "meta.MetaTrainer.model", "utils.misc.count_acc", "utils.misc.Averager.add", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "print", "utils.misc.Averager.item", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "_.cuda", "os.join", "os.join", "utils.misc.Averager.item"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.trainer.meta.MetaTrainer.eval", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.compute_confidence_interval", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.count_acc", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Averager.add", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Averager.item", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Averager.item"], ["", "def", "eval", "(", "self", ")", ":", "\n", "        ", "\"\"\"The function for the meta-eval phase.\"\"\"", "\n", "# Load the logs", "\n", "trlog", "=", "torch", ".", "load", "(", "osp", ".", "join", "(", "self", ".", "args", ".", "save_path", ",", "'trlog'", ")", ")", "\n", "\n", "# Load meta-test set", "\n", "test_set", "=", "Dataset", "(", "'test'", ",", "self", ".", "args", ")", "\n", "sampler", "=", "CategoriesSampler", "(", "test_set", ".", "label", ",", "600", ",", "self", ".", "args", ".", "way", ",", "self", ".", "args", ".", "shot", "+", "self", ".", "args", ".", "val_query", ")", "\n", "loader", "=", "DataLoader", "(", "test_set", ",", "batch_sampler", "=", "sampler", ",", "num_workers", "=", "8", ",", "pin_memory", "=", "True", ")", "\n", "\n", "# Set test accuracy recorder", "\n", "test_acc_record", "=", "np", ".", "zeros", "(", "(", "600", ",", ")", ")", "\n", "\n", "# Load model for meta-test phase", "\n", "if", "self", ".", "args", ".", "eval_weights", "is", "not", "None", ":", "\n", "            ", "self", ".", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "self", ".", "args", ".", "eval_weights", ")", "[", "'params'", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "osp", ".", "join", "(", "self", ".", "args", ".", "save_path", ",", "'max_acc'", "+", "'.pth'", ")", ")", "[", "'params'", "]", ")", "\n", "# Set model to eval mode", "\n", "", "self", ".", "model", ".", "eval", "(", ")", "\n", "\n", "# Set accuracy averager", "\n", "ave_acc", "=", "Averager", "(", ")", "\n", "\n", "# Generate labels", "\n", "label", "=", "torch", ".", "arange", "(", "self", ".", "args", ".", "way", ")", ".", "repeat", "(", "self", ".", "args", ".", "val_query", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "label", "=", "label", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", "\n", "", "else", ":", "\n", "            ", "label", "=", "label", ".", "type", "(", "torch", ".", "LongTensor", ")", "\n", "", "label_shot", "=", "torch", ".", "arange", "(", "self", ".", "args", ".", "way", ")", ".", "repeat", "(", "self", ".", "args", ".", "shot", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "label_shot", "=", "label_shot", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", "\n", "", "else", ":", "\n", "            ", "label_shot", "=", "label_shot", ".", "type", "(", "torch", ".", "LongTensor", ")", "\n", "\n", "# Start meta-test", "\n", "", "for", "i", ",", "batch", "in", "enumerate", "(", "loader", ",", "1", ")", ":", "\n", "            ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "data", ",", "_", "=", "[", "_", ".", "cuda", "(", ")", "for", "_", "in", "batch", "]", "\n", "", "else", ":", "\n", "                ", "data", "=", "batch", "[", "0", "]", "\n", "", "k", "=", "self", ".", "args", ".", "way", "*", "self", ".", "args", ".", "shot", "\n", "data_shot", ",", "data_query", "=", "data", "[", ":", "k", "]", ",", "data", "[", "k", ":", "]", "\n", "logits", "=", "self", ".", "model", "(", "(", "data_shot", ",", "label_shot", ",", "data_query", ")", ")", "\n", "acc", "=", "count_acc", "(", "logits", ",", "label", ")", "\n", "ave_acc", ".", "add", "(", "acc", ")", "\n", "test_acc_record", "[", "i", "-", "1", "]", "=", "acc", "\n", "if", "i", "%", "100", "==", "0", ":", "\n", "                ", "print", "(", "'batch {}: {:.2f}({:.2f})'", ".", "format", "(", "i", ",", "ave_acc", ".", "item", "(", ")", "*", "100", ",", "acc", "*", "100", ")", ")", "\n", "\n", "# Calculate the confidence interval, update the logs", "\n", "", "", "m", ",", "pm", "=", "compute_confidence_interval", "(", "test_acc_record", ")", "\n", "print", "(", "'Val Best Epoch {}, Acc {:.4f}, Test Acc {:.4f}'", ".", "format", "(", "trlog", "[", "'max_acc_epoch'", "]", ",", "trlog", "[", "'max_acc'", "]", ",", "ave_acc", ".", "item", "(", ")", ")", ")", "\n", "print", "(", "'Test Acc {:.4f} + {:.4f}'", ".", "format", "(", "m", ",", "pm", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.trainer.pre.PreTrainer.__init__": [[26, 52], ["print", "data_generator.pre_data_generator.PreDataGenerator", "data_generator.pre_data_generator.PreDataGenerator.make_data_tensor", "models.pre_model.MakePreModel", "pre.PreTrainer.model.construct_pretrain_model", "tensorflow.summary.merge_all", "tensorflow.global_variables_initializer().run", "tensorflow.train.start_queue_runners", "pre.PreTrainer.pre_train", "tensorflow.ConfigProto", "tensorflow.InteractiveSession", "tensorflow.InteractiveSession", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.pre_data_generator.PreDataGenerator.make_data_tensor", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.models.pre_model.MakePreModel", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.trainer.pre.PreTrainer.pre_train"], ["# Set the folder to save the records and checkpoints", "\n", "        ", "log_base_dir", "=", "'./logs/'", "\n", "if", "not", "osp", ".", "exists", "(", "log_base_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "log_base_dir", ")", "\n", "", "pre_base_dir", "=", "osp", ".", "join", "(", "log_base_dir", ",", "'pre'", ")", "\n", "if", "not", "osp", ".", "exists", "(", "pre_base_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "pre_base_dir", ")", "\n", "", "save_path1", "=", "'_'", ".", "join", "(", "[", "args", ".", "dataset", ",", "args", ".", "model_type", "]", ")", "\n", "save_path2", "=", "'batchsize'", "+", "str", "(", "args", ".", "pre_batch_size", ")", "+", "'_lr'", "+", "str", "(", "args", ".", "pre_lr", ")", "+", "'_gamma'", "+", "str", "(", "args", ".", "pre_gamma", ")", "+", "'_step'", "+", "str", "(", "args", ".", "pre_step_size", ")", "+", "'_maxepoch'", "+", "str", "(", "args", ".", "pre_max_epoch", ")", "\n", "args", ".", "save_path", "=", "pre_base_dir", "+", "'/'", "+", "save_path1", "+", "'_'", "+", "save_path2", "\n", "ensure_path", "(", "args", ".", "save_path", ")", "\n", "\n", "# Set args to be shareable in the class", "\n", "self", ".", "args", "=", "args", "\n", "\n", "# Load pretrain set", "\n", "self", ".", "trainset", "=", "Dataset", "(", "'train'", ",", "self", ".", "args", ",", "train_aug", "=", "True", ")", "\n", "self", ".", "train_loader", "=", "DataLoader", "(", "dataset", "=", "self", ".", "trainset", ",", "batch_size", "=", "args", ".", "pre_batch_size", ",", "shuffle", "=", "True", ",", "num_workers", "=", "8", ",", "pin_memory", "=", "True", ")", "\n", "\n", "# Load meta-val set", "\n", "self", ".", "valset", "=", "Dataset", "(", "'val'", ",", "self", ".", "args", ")", "\n", "self", ".", "val_sampler", "=", "CategoriesSampler", "(", "self", ".", "valset", ".", "label", ",", "600", ",", "self", ".", "args", ".", "way", ",", "self", ".", "args", ".", "shot", "+", "self", ".", "args", ".", "val_query", ")", "\n", "self", ".", "val_loader", "=", "DataLoader", "(", "dataset", "=", "self", ".", "valset", ",", "batch_sampler", "=", "self", ".", "val_sampler", ",", "num_workers", "=", "8", ",", "pin_memory", "=", "True", ")", "\n", "\n", "# Set pretrain class number ", "\n", "num_class_pretrain", "=", "self", ".", "trainset", ".", "num_class", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.trainer.pre.PreTrainer.save_model": [[70, 76], ["torch.save", "torch.save", "torch.save", "torch.save", "dict", "os.join", "os.join", "pre.PreTrainer.model.encoder.state_dict"], "methods", ["None"], ["", "", "def", "save_model", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"The function to save checkpoints.\n        Args:\n          name: the name for saved checkpoint\n        \"\"\"", "\n", "torch", ".", "save", "(", "dict", "(", "params", "=", "self", ".", "model", ".", "encoder", ".", "state_dict", "(", ")", ")", ",", "osp", ".", "join", "(", "self", ".", "args", ".", "save_path", ",", "name", "+", "'.pth'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.trainer.pre.PreTrainer.train": [[77, 214], ["vars", "utils.misc.Timer", "tensorboardX.SummaryWriter", "range", "tensorboardX.SummaryWriter.close", "pre.PreTrainer.lr_scheduler.step", "pre.PreTrainer.model.train", "utils.misc.Averager", "utils.misc.Averager", "tqdm.tqdm", "enumerate", "train_loss_averager.item.item.item", "train_acc_averager.item.item.item", "pre.PreTrainer.model.eval", "utils.misc.Averager", "utils.misc.Averager", "torch.arange().repeat", "torch.arange().repeat", "torch.arange().repeat", "torch.arange().repeat", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.arange().repeat", "torch.arange().repeat", "torch.arange().repeat", "torch.arange().repeat", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "enumerate", "val_loss_averager.item.item.item", "val_acc_averager.item.item.item", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "print", "trlog[].append", "trlog[].append", "trlog[].append", "trlog[].append", "torch.save", "torch.save", "torch.save", "torch.save", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "pre.PreTrainer.model", "torch.cross_entropy", "torch.cross_entropy", "utils.misc.count_acc", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "tqdm.tqdm.set_description", "train_loss_averager.item.item.add", "train_acc_averager.item.item.add", "pre.PreTrainer.optimizer.zero_grad", "torch.cross_entropy.backward", "pre.PreTrainer.optimizer.step", "label.type.type.type", "label.type.type.type", "label_shot.type.type.type", "label_shot.type.type.type", "print", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "pre.PreTrainer.model", "torch.cross_entropy", "torch.cross_entropy", "utils.misc.count_acc", "val_loss_averager.item.item.add", "val_acc_averager.item.item.add", "float", "float", "pre.PreTrainer.save_model", "pre.PreTrainer.save_model", "os.join", "os.join", "print", "label.type.type.type", "label.type.type.type", "float", "float", "torch.cross_entropy.item", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.cross_entropy.item", "_.cuda", "torch.cross_entropy.item", "_.cuda", "str", "utils.misc.Timer.measure", "utils.misc.Timer.measure"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.trainer.pre.PreTrainer.train", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Averager.item", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Averager.item", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.trainer.meta.MetaTrainer.eval", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Averager.item", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Averager.item", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.count_acc", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Averager.add", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Averager.add", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.count_acc", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Averager.add", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Averager.add", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.trainer.pre.PreTrainer.save_model", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.trainer.pre.PreTrainer.save_model", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Averager.item", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Averager.item", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Averager.item", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Timer.measure", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.Timer.measure"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "\"\"\"The function for the pre-train phase.\"\"\"", "\n", "\n", "# Set the pretrain log", "\n", "trlog", "=", "{", "}", "\n", "trlog", "[", "'args'", "]", "=", "vars", "(", "self", ".", "args", ")", "\n", "trlog", "[", "'train_loss'", "]", "=", "[", "]", "\n", "trlog", "[", "'val_loss'", "]", "=", "[", "]", "\n", "trlog", "[", "'train_acc'", "]", "=", "[", "]", "\n", "trlog", "[", "'val_acc'", "]", "=", "[", "]", "\n", "trlog", "[", "'max_acc'", "]", "=", "0.0", "\n", "trlog", "[", "'max_acc_epoch'", "]", "=", "0", "\n", "\n", "# Set the timer", "\n", "timer", "=", "Timer", "(", ")", "\n", "# Set global count to zero", "\n", "global_count", "=", "0", "\n", "# Set tensorboardX", "\n", "writer", "=", "SummaryWriter", "(", "comment", "=", "self", ".", "args", ".", "save_path", ")", "\n", "\n", "# Start pretrain", "\n", "for", "epoch", "in", "range", "(", "1", ",", "self", ".", "args", ".", "pre_max_epoch", "+", "1", ")", ":", "\n", "# Update learning rate", "\n", "            ", "self", ".", "lr_scheduler", ".", "step", "(", ")", "\n", "# Set the model to train mode", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "self", ".", "model", ".", "mode", "=", "'pre'", "\n", "# Set averager classes to record training losses and accuracies", "\n", "train_loss_averager", "=", "Averager", "(", ")", "\n", "train_acc_averager", "=", "Averager", "(", ")", "\n", "\n", "# Using tqdm to read samples from train loader", "\n", "tqdm_gen", "=", "tqdm", ".", "tqdm", "(", "self", ".", "train_loader", ")", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "tqdm_gen", ",", "1", ")", ":", "\n", "# Update global count number ", "\n", "                ", "global_count", "=", "global_count", "+", "1", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "data", ",", "_", "=", "[", "_", ".", "cuda", "(", ")", "for", "_", "in", "batch", "]", "\n", "", "else", ":", "\n", "                    ", "data", "=", "batch", "[", "0", "]", "\n", "", "label", "=", "batch", "[", "1", "]", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "label", "=", "label", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", "\n", "", "else", ":", "\n", "                    ", "label", "=", "label", ".", "type", "(", "torch", ".", "LongTensor", ")", "\n", "# Output logits for model", "\n", "", "logits", "=", "self", ".", "model", "(", "data", ")", "\n", "# Calculate train loss", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ",", "label", ")", "\n", "# Calculate train accuracy", "\n", "acc", "=", "count_acc", "(", "logits", ",", "label", ")", "\n", "# Write the tensorboardX records", "\n", "writer", ".", "add_scalar", "(", "'data/loss'", ",", "float", "(", "loss", ")", ",", "global_count", ")", "\n", "writer", ".", "add_scalar", "(", "'data/acc'", ",", "float", "(", "acc", ")", ",", "global_count", ")", "\n", "# Print loss and accuracy for this step", "\n", "tqdm_gen", ".", "set_description", "(", "'Epoch {}, Loss={:.4f} Acc={:.4f}'", ".", "format", "(", "epoch", ",", "loss", ".", "item", "(", ")", ",", "acc", ")", ")", "\n", "\n", "# Add loss and accuracy for the averagers", "\n", "train_loss_averager", ".", "add", "(", "loss", ".", "item", "(", ")", ")", "\n", "train_acc_averager", ".", "add", "(", "acc", ")", "\n", "\n", "# Loss backwards and optimizer updates", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Update the averagers", "\n", "", "train_loss_averager", "=", "train_loss_averager", ".", "item", "(", ")", "\n", "train_acc_averager", "=", "train_acc_averager", ".", "item", "(", ")", "\n", "\n", "# Start validation for this epoch, set model to eval mode", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "model", ".", "mode", "=", "'preval'", "\n", "\n", "# Set averager classes to record validation losses and accuracies", "\n", "val_loss_averager", "=", "Averager", "(", ")", "\n", "val_acc_averager", "=", "Averager", "(", ")", "\n", "\n", "# Generate the labels for test ", "\n", "label", "=", "torch", ".", "arange", "(", "self", ".", "args", ".", "way", ")", ".", "repeat", "(", "self", ".", "args", ".", "val_query", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "label", "=", "label", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", "\n", "", "else", ":", "\n", "                ", "label", "=", "label", ".", "type", "(", "torch", ".", "LongTensor", ")", "\n", "", "label_shot", "=", "torch", ".", "arange", "(", "self", ".", "args", ".", "way", ")", ".", "repeat", "(", "self", ".", "args", ".", "shot", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "label_shot", "=", "label_shot", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", "\n", "", "else", ":", "\n", "                ", "label_shot", "=", "label_shot", ".", "type", "(", "torch", ".", "LongTensor", ")", "\n", "\n", "# Print previous information  ", "\n", "", "if", "epoch", "%", "10", "==", "0", ":", "\n", "                ", "print", "(", "'Best Epoch {}, Best Val acc={:.4f}'", ".", "format", "(", "trlog", "[", "'max_acc_epoch'", "]", ",", "trlog", "[", "'max_acc'", "]", ")", ")", "\n", "# Run meta-validation", "\n", "", "for", "i", ",", "batch", "in", "enumerate", "(", "self", ".", "val_loader", ",", "1", ")", ":", "\n", "                ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                    ", "data", ",", "_", "=", "[", "_", ".", "cuda", "(", ")", "for", "_", "in", "batch", "]", "\n", "", "else", ":", "\n", "                    ", "data", "=", "batch", "[", "0", "]", "\n", "", "p", "=", "self", ".", "args", ".", "shot", "*", "self", ".", "args", ".", "way", "\n", "data_shot", ",", "data_query", "=", "data", "[", ":", "p", "]", ",", "data", "[", "p", ":", "]", "\n", "logits", "=", "self", ".", "model", "(", "(", "data_shot", ",", "label_shot", ",", "data_query", ")", ")", "\n", "loss", "=", "F", ".", "cross_entropy", "(", "logits", ",", "label", ")", "\n", "acc", "=", "count_acc", "(", "logits", ",", "label", ")", "\n", "val_loss_averager", ".", "add", "(", "loss", ".", "item", "(", ")", ")", "\n", "val_acc_averager", ".", "add", "(", "acc", ")", "\n", "\n", "# Update validation averagers", "\n", "", "val_loss_averager", "=", "val_loss_averager", ".", "item", "(", ")", "\n", "val_acc_averager", "=", "val_acc_averager", ".", "item", "(", ")", "\n", "# Write the tensorboardX records", "\n", "writer", ".", "add_scalar", "(", "'data/val_loss'", ",", "float", "(", "val_loss_averager", ")", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'data/val_acc'", ",", "float", "(", "val_acc_averager", ")", ",", "epoch", ")", "\n", "# Print loss and accuracy for this epoch", "\n", "print", "(", "'Epoch {}, Val, Loss={:.4f} Acc={:.4f}'", ".", "format", "(", "epoch", ",", "val_loss_averager", ",", "val_acc_averager", ")", ")", "\n", "\n", "# Update best saved model", "\n", "if", "val_acc_averager", ">", "trlog", "[", "'max_acc'", "]", ":", "\n", "                ", "trlog", "[", "'max_acc'", "]", "=", "val_acc_averager", "\n", "trlog", "[", "'max_acc_epoch'", "]", "=", "epoch", "\n", "self", ".", "save_model", "(", "'max_acc'", ")", "\n", "# Save model every 10 epochs", "\n", "", "if", "epoch", "%", "10", "==", "0", ":", "\n", "                ", "self", ".", "save_model", "(", "'epoch'", "+", "str", "(", "epoch", ")", ")", "\n", "\n", "# Update the logs", "\n", "", "trlog", "[", "'train_loss'", "]", ".", "append", "(", "train_loss_averager", ")", "\n", "trlog", "[", "'train_acc'", "]", ".", "append", "(", "train_acc_averager", ")", "\n", "trlog", "[", "'val_loss'", "]", ".", "append", "(", "val_loss_averager", ")", "\n", "trlog", "[", "'val_acc'", "]", ".", "append", "(", "val_acc_averager", ")", "\n", "\n", "# Save log", "\n", "torch", ".", "save", "(", "trlog", ",", "osp", ".", "join", "(", "self", ".", "args", ".", "save_path", ",", "'trlog'", ")", ")", "\n", "\n", "if", "epoch", "%", "10", "==", "0", ":", "\n", "                ", "print", "(", "'Running Time: {}, Estimated Time: {}'", ".", "format", "(", "timer", ".", "measure", "(", ")", ",", "timer", ".", "measure", "(", "epoch", "/", "self", ".", "args", ".", "max_epoch", ")", ")", ")", "\n", "", "", "writer", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.trainer.meta.MetaTrainer.start_session": [[153, 161], ["tensorflow.ConfigProto", "tensorflow.InteractiveSession", "tensorflow.InteractiveSession"], "methods", ["None"], ["loss", "=", "F", ".", "cross_entropy", "(", "logits", ",", "label", ")", "\n", "# Calculate meta-train accuracy", "\n", "acc", "=", "count_acc", "(", "logits", ",", "label", ")", "\n", "# Write the tensorboardX records", "\n", "writer", ".", "add_scalar", "(", "'data/loss'", ",", "float", "(", "loss", ")", ",", "global_count", ")", "\n", "writer", ".", "add_scalar", "(", "'data/acc'", ",", "float", "(", "acc", ")", ",", "global_count", ")", "\n", "# Print loss and accuracy for this step", "\n", "tqdm_gen", ".", "set_description", "(", "'Epoch {}, Loss={:.4f} Acc={:.4f}'", ".", "format", "(", "epoch", ",", "loss", ".", "item", "(", ")", ",", "acc", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.trainer.meta.MetaTrainer.test": [[274, 322], ["print", "numpy.random.seed", "data_generator.load_data", "tqdm.trange", "numpy.array", "numpy.mean", "numpy.std", "print", "print", "data_generator.load_episode", "meta.MetaTrainer.sess.run", "numpy.array.append", "numpy.sqrt", "open", "pickle.dump", "open", "csv.writer", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "str", "str", "str", "str", "str", "range", "len"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.load_data", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.load_episode"], ["\n", "# Start meta-test", "\n", "", "for", "i", ",", "batch", "in", "enumerate", "(", "loader", ",", "1", ")", ":", "\n", "            ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "data", ",", "_", "=", "[", "_", ".", "cuda", "(", ")", "for", "_", "in", "batch", "]", "\n", "", "else", ":", "\n", "                ", "data", "=", "batch", "[", "0", "]", "\n", "", "k", "=", "self", ".", "args", ".", "way", "*", "self", ".", "args", ".", "shot", "\n", "data_shot", ",", "data_query", "=", "data", "[", ":", "k", "]", ",", "data", "[", "k", ":", "]", "\n", "logits", "=", "self", ".", "model", "(", "(", "data_shot", ",", "label_shot", ",", "data_query", ")", ")", "\n", "acc", "=", "count_acc", "(", "logits", ",", "label", ")", "\n", "ave_acc", ".", "add", "(", "acc", ")", "\n", "test_acc_record", "[", "i", "-", "1", "]", "=", "acc", "\n", "if", "i", "%", "100", "==", "0", ":", "\n", "                ", "print", "(", "'batch {}: {:.2f}({:.2f})'", ".", "format", "(", "i", ",", "ave_acc", ".", "item", "(", ")", "*", "100", ",", "acc", "*", "100", ")", ")", "\n", "\n", "# Calculate the confidence interval, update the logs", "\n", "", "", "m", ",", "pm", "=", "compute_confidence_interval", "(", "test_acc_record", ")", "\n", "print", "(", "'Val Best Epoch {}, Acc {:.4f}, Test Acc {:.4f}'", ".", "format", "(", "trlog", "[", "'max_acc_epoch'", "]", ",", "trlog", "[", "'max_acc'", "]", ",", "ave_acc", ".", "item", "(", ")", ")", ")", "\n", "print", "(", "'Test Acc {:.4f} + {:.4f}'", ".", "format", "(", "m", ",", "pm", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.trainer.pre.PreTrainer.pre_train": [[53, 97], ["os.path.join", "tensorflow.summary.FileWriter", "print", "print", "tqdm.trange", "os.path.exists", "os.mkdir", "input_tensors.extend", "pre.PreTrainer.sess.run", "print", "tensorflow.summary.FileWriter.add_summary", "print", "pre.PreTrainer.sess.run", "numpy.save", "str", "os.path.join", "str"], "methods", ["None"], ["\n", "# Build pretrain model", "\n", "self", ".", "model", "=", "MtlLearner", "(", "self", ".", "args", ",", "mode", "=", "'pre'", ",", "num_cls", "=", "num_class_pretrain", ")", "\n", "\n", "# Set optimizer ", "\n", "self", ".", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "[", "{", "'params'", ":", "self", ".", "model", ".", "encoder", ".", "parameters", "(", ")", ",", "'lr'", ":", "self", ".", "args", ".", "pre_lr", "}", ",", "{", "'params'", ":", "self", ".", "model", ".", "pre_fc", ".", "parameters", "(", ")", ",", "'lr'", ":", "self", ".", "args", ".", "pre_lr", "}", "]", ",", "momentum", "=", "self", ".", "args", ".", "pre_custom_momentum", ",", "nesterov", "=", "True", ",", "weight_decay", "=", "self", ".", "args", ".", "pre_custom_weight_decay", ")", "\n", "# Set learning rate scheduler ", "\n", "self", ".", "lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "self", ".", "optimizer", ",", "step_size", "=", "self", ".", "args", ".", "pre_step_size", ",", "gamma", "=", "self", ".", "args", ".", "pre_gamma", ")", "\n", "\n", "# Set model to GPU", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "            ", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "\n", "self", ".", "model", "=", "self", ".", "model", ".", "cuda", "(", ")", "\n", "\n", "", "", "def", "save_model", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"The function to save checkpoints.\n        Args:\n          name: the name for saved checkpoint\n        \"\"\"", "\n", "torch", ".", "save", "(", "dict", "(", "params", "=", "self", ".", "model", ".", "encoder", ".", "state_dict", "(", ")", ")", ",", "osp", ".", "join", "(", "self", ".", "args", ".", "save_path", ",", "name", "+", "'.pth'", ")", ")", "\n", "\n", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "\"\"\"The function for the pre-train phase.\"\"\"", "\n", "\n", "# Set the pretrain log", "\n", "trlog", "=", "{", "}", "\n", "trlog", "[", "'args'", "]", "=", "vars", "(", "self", ".", "args", ")", "\n", "trlog", "[", "'train_loss'", "]", "=", "[", "]", "\n", "trlog", "[", "'val_loss'", "]", "=", "[", "]", "\n", "trlog", "[", "'train_acc'", "]", "=", "[", "]", "\n", "trlog", "[", "'val_acc'", "]", "=", "[", "]", "\n", "trlog", "[", "'max_acc'", "]", "=", "0.0", "\n", "trlog", "[", "'max_acc_epoch'", "]", "=", "0", "\n", "\n", "# Set the timer", "\n", "timer", "=", "Timer", "(", ")", "\n", "# Set global count to zero", "\n", "global_count", "=", "0", "\n", "# Set tensorboardX", "\n", "writer", "=", "SummaryWriter", "(", "comment", "=", "self", ".", "args", ".", "save_path", ")", "\n", "\n", "# Start pretrain", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.tensorflow.main.main": [[133, 144], ["print", "str", "trainer.pre.PreTrainer", "str", "trainer.meta.MetaTrainer", "Exception"], "function", ["None"], []], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.tensorflow.run_experiment.run_experiment": [[15, 120], ["print", "os.system", "print", "os.system", "print", "range", "print", "os.system", "print", "os.system", "str", "str", "str", "run_experiment.run_experiment.process_test_command"], "function", ["None"], ["def", "run_experiment", "(", "PHASE", "=", "'META'", ")", ":", "\n", "    ", "\"\"\"The function to generate commands to run the experiments.\n    Arg:\n      PHASE: the phase for MTL. 'PRE' means pre-train phase, and 'META' means meta-train and meta-test phases.\n    \"\"\"", "\n", "# Some important options", "\n", "# Please note that not all the options are shown here. For more detailed options, please edit main.py", "\n", "\n", "# Basic options", "\n", "LOG_DIR", "=", "'experiment_results'", "# Name of the folder to save the log files", "\n", "GPU_ID", "=", "1", "# GPU device id", "\n", "NET_ARCH", "=", "'resnet12'", "# Additional label for pre-train model", "\n", "\n", "# Pre-train phase options", "\n", "PRE_TRA_LABEL", "=", "'normal'", "# Additional label for pre-train model", "\n", "PRE_TRA_ITER_MAX", "=", "20000", "# Iteration number for the pre-train phase", "\n", "PRE_TRA_DROP", "=", "0.9", "# Dropout keep rate for the pre-train phase", "\n", "PRE_DROP_STEP", "=", "5000", "# Iteration number for the pre-train learning rate reducing", "\n", "PRE_LR", "=", "0.001", "# Pre-train learning rate", "\n", "\n", "# Meta options", "\n", "SHOT_NUM", "=", "1", "# Shot number for the few-shot tasks", "\n", "WAY_NUM", "=", "5", "# Class number for the few-shot tasks", "\n", "MAX_ITER", "=", "20000", "# Iteration number for meta-train", "\n", "META_BATCH_SIZE", "=", "2", "# Meta batch size ", "\n", "PRE_ITER", "=", "10000", "# Iteration number for the pre-train model used in the meta-train phase", "\n", "UPDATE_NUM", "=", "20", "# Epoch number for the base learning", "\n", "SAVE_STEP", "=", "100", "# Iteration number to save the meta model", "\n", "META_LR", "=", "0.001", "# Meta learning rate", "\n", "META_LR_MIN", "=", "0.0001", "# Meta learning rate min value", "\n", "LR_DROP_STEP", "=", "1000", "# The iteration number for the meta learning rate reducing", "\n", "BASE_LR", "=", "0.001", "# Base learning rate", "\n", "\n", "# Data directories", "\n", "PRE_TRA_DIR", "=", "'./data/mini-imagenet/train'", "# Directory for the pre-train phase images", "\n", "META_TRA_DIR", "=", "'./data/mini-imagenet/train'", "# Directory for the meta-train images", "\n", "META_VAL_DIR", "=", "'./data/mini-imagenet/val'", "# Directory for the meta-validation images", "\n", "META_TES_DIR", "=", "'./data/mini-imagenet/test'", "# Directory for the meta-test images", "\n", "\n", "# Generate the base command for main.py", "\n", "base_command", "=", "'python main.py'", "+", "' --backbone_arch='", "+", "str", "(", "NET_ARCH", ")", "+", "' --metatrain_iterations='", "+", "str", "(", "MAX_ITER", ")", "+", "' --meta_batch_size='", "+", "str", "(", "META_BATCH_SIZE", ")", "+", "' --shot_num='", "+", "str", "(", "SHOT_NUM", ")", "+", "' --meta_lr='", "+", "str", "(", "META_LR", ")", "+", "' --min_meta_lr='", "+", "str", "(", "META_LR_MIN", ")", "+", "' --base_lr='", "+", "str", "(", "BASE_LR", ")", "+", "' --train_base_epoch_num='", "+", "str", "(", "UPDATE_NUM", ")", "+", "' --way_num='", "+", "str", "(", "WAY_NUM", ")", "+", "' --exp_log_label='", "+", "LOG_DIR", "+", "' --pretrain_dropout_keep='", "+", "str", "(", "PRE_TRA_DROP", ")", "+", "' --activation=leaky_relu'", "+", "' --pre_lr='", "+", "str", "(", "PRE_LR", ")", "+", "' --pre_lr_dropstep='", "+", "str", "(", "PRE_DROP_STEP", ")", "+", "' --meta_save_step='", "+", "str", "(", "SAVE_STEP", ")", "+", "' --lr_drop_step='", "+", "str", "(", "LR_DROP_STEP", ")", "+", "' --pretrain_folders='", "+", "PRE_TRA_DIR", "+", "' --pretrain_label='", "+", "PRE_TRA_LABEL", "+", "' --device_id='", "+", "str", "(", "GPU_ID", ")", "+", "' --metatrain_dir='", "+", "META_TRA_DIR", "+", "' --metaval_dir='", "+", "META_VAL_DIR", "+", "' --metatest_dir='", "+", "META_TES_DIR", "\n", "\n", "def", "process_test_command", "(", "TEST_STEP", ",", "in_command", ")", ":", "\n", "        ", "\"\"\"The function to adapt the base command to the meta-test phase.\n        Args:\n          TEST_STEP: the iteration number for the meta model to be loaded.\n          in_command: the input base command.\n        Return:\n          Processed command.\n        \"\"\"", "\n", "output_test_command", "=", "in_command", "+", "' --phase=meta'", "+", "' --pretrain_iterations='", "+", "str", "(", "PRE_ITER", ")", "+", "' --metatrain=False'", "+", "' --test_iter='", "+", "str", "(", "TEST_STEP", ")", "\n", "return", "output_test_command", "\n", "\n", "", "if", "PHASE", "==", "'PRE'", ":", "\n", "        ", "print", "(", "'****** Start Pre-train Phase ******'", ")", "\n", "pre_command", "=", "base_command", "+", "' --phase=pre'", "+", "' --pretrain_iterations='", "+", "str", "(", "PRE_TRA_ITER_MAX", ")", "\n", "os", ".", "system", "(", "pre_command", ")", "\n", "\n", "", "if", "PHASE", "==", "'META'", ":", "\n", "        ", "print", "(", "'****** Start Meta-train Phase ******'", ")", "\n", "meta_train_command", "=", "base_command", "+", "' --phase=meta'", "+", "' --pretrain_iterations='", "+", "str", "(", "PRE_ITER", ")", "\n", "os", ".", "system", "(", "meta_train_command", ")", "\n", "\n", "print", "(", "'****** Start Meta-test Phase ******'", ")", "\n", "for", "idx", "in", "range", "(", "MAX_ITER", ")", ":", "\n", "            ", "if", "idx", "%", "SAVE_STEP", "==", "0", ":", "\n", "                ", "print", "(", "'[*] Runing meta-test, load model for '", "+", "str", "(", "idx", ")", "+", "' iterations'", ")", "\n", "test_command", "=", "process_test_command", "(", "idx", ",", "base_command", ")", "\n", "os", ".", "system", "(", "test_command", ")", "\n", "\n", "", "", "", "if", "PHASE", "==", "'META_LOAD'", ":", "\n", "        ", "print", "(", "'****** Start Meta-train Phase with Downloaded Weights ******'", ")", "\n", "meta_train_command", "=", "base_command", "+", "' --phase=meta'", "+", "' --pretrain_iterations='", "+", "str", "(", "PRE_ITER", ")", "+", "' --load_saved_weights=True'", "\n", "os", ".", "system", "(", "meta_train_command", ")", "\n", "\n", "", "if", "PHASE", "==", "'TEST_LOAD'", ":", "\n", "        ", "print", "(", "'****** Start Meta-test Phase with Downloaded Weights ******'", ")", "\n", "test_command", "=", "process_test_command", "(", "0", ",", "base_command", ")", "+", "' --load_saved_weights=True'", "\n", "os", ".", "system", "(", "test_command", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.pre_data_generator.PreDataGenerator.__init__": [[26, 36], ["numpy.prod", "os.path.join", "os.listdir", "os.path.isdir", "os.path.join"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "num_classes", "=", "FLAGS", ".", "way_num", "\n", "self", ".", "img_size", "=", "(", "FLAGS", ".", "img_size", ",", "FLAGS", ".", "img_size", ")", "\n", "self", ".", "dim_input", "=", "np", ".", "prod", "(", "self", ".", "img_size", ")", "*", "3", "\n", "self", ".", "pretrain_class_num", "=", "FLAGS", ".", "pretrain_class_num", "\n", "self", ".", "pretrain_batch_size", "=", "FLAGS", ".", "pretrain_batch_size", "\n", "pretrain_folder", "=", "FLAGS", ".", "pretrain_folders", "\n", "\n", "pretrain_folders", "=", "[", "os", ".", "path", ".", "join", "(", "pretrain_folder", ",", "label", ")", "for", "label", "in", "os", ".", "listdir", "(", "pretrain_folder", ")", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "pretrain_folder", ",", "label", ")", ")", "]", "\n", "self", ".", "pretrain_character_folders", "=", "pretrain_folders", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.pre_data_generator.PreDataGenerator.make_data_tensor": [[37, 64], ["print", "enumerate", "random.shuffle", "tensorflow.train.string_input_producer", "tensorflow.train.slice_input_producer", "tensorflow.WholeFileReader", "tensorflow.WholeFileReader.read", "tensorflow.image.decode_jpeg", "tensorflow.reshape.set_shape", "tensorflow.reshape", "tensorflow.train.batch", "tensorflow.one_hot", "utils.misc.get_pretrain_images", "tensorflow.convert_to_tensor", "tensorflow.cast", "tensorflow.reshape", "tensorflow.convert_to_tensor"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.one_hot", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.get_pretrain_images"], ["", "def", "make_data_tensor", "(", "self", ")", ":", "\n", "        ", "\"\"\"The function to make tensor for the tensorflow model.\"\"\"", "\n", "print", "(", "'Generating pre-training data'", ")", "\n", "all_filenames_and_labels", "=", "[", "]", "\n", "folders", "=", "self", ".", "pretrain_character_folders", "\n", "\n", "for", "idx", ",", "path", "in", "enumerate", "(", "folders", ")", ":", "\n", "            ", "all_filenames_and_labels", "+=", "get_pretrain_images", "(", "path", ",", "idx", ")", "\n", "", "random", ".", "shuffle", "(", "all_filenames_and_labels", ")", "\n", "all_labels", "=", "[", "li", "[", "0", "]", "for", "li", "in", "all_filenames_and_labels", "]", "\n", "all_filenames", "=", "[", "li", "[", "1", "]", "for", "li", "in", "all_filenames_and_labels", "]", "\n", "filename_queue", "=", "tf", ".", "train", ".", "string_input_producer", "(", "tf", ".", "convert_to_tensor", "(", "all_filenames", ")", ",", "shuffle", "=", "False", ")", "\n", "label_queue", "=", "tf", ".", "train", ".", "slice_input_producer", "(", "[", "tf", ".", "convert_to_tensor", "(", "all_labels", ")", "]", ",", "shuffle", "=", "False", ")", "\n", "image_reader", "=", "tf", ".", "WholeFileReader", "(", ")", "\n", "_", ",", "image_file", "=", "image_reader", ".", "read", "(", "filename_queue", ")", "\n", "\n", "image", "=", "tf", ".", "image", ".", "decode_jpeg", "(", "image_file", ",", "channels", "=", "3", ")", "\n", "image", ".", "set_shape", "(", "(", "self", ".", "img_size", "[", "0", "]", ",", "self", ".", "img_size", "[", "1", "]", ",", "3", ")", ")", "\n", "image", "=", "tf", ".", "reshape", "(", "image", ",", "[", "self", ".", "dim_input", "]", ")", "\n", "image", "=", "tf", ".", "cast", "(", "image", ",", "tf", ".", "float32", ")", "/", "255.0", "\n", "\n", "num_preprocess_threads", "=", "1", "\n", "min_queue_examples", "=", "256", "\n", "batch_image_size", "=", "self", ".", "pretrain_batch_size", "\n", "image_batch", ",", "label_batch", "=", "tf", ".", "train", ".", "batch", "(", "[", "image", ",", "label_queue", "]", ",", "batch_size", "=", "batch_image_size", ",", "num_threads", "=", "num_preprocess_threads", ",", "capacity", "=", "min_queue_examples", "+", "3", "*", "batch_image_size", ")", "\n", "label_batch", "=", "tf", ".", "one_hot", "(", "tf", ".", "reshape", "(", "label_batch", ",", "[", "-", "1", "]", ")", ",", "self", ".", "pretrain_class_num", ")", "\n", "return", "image_batch", ",", "label_batch", "\n", "", "", ""]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.__init__": [[26, 37], ["os.path.exists", "os.mkdir", "os.path.exists", "os.mkdir", "str", "str", "str", "str"], "methods", ["None"], ["def", "__init__", "(", "self", ")", ":", "\n", "# Set the base folder to save the data lists", "\n", "        ", "filename_dir", "=", "FLAGS", ".", "logdir_base", "+", "'processed_data/'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "filename_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "filename_dir", ")", "\n", "\n", "# Set the detailed folder name for saving the data lists", "\n", "", "self", ".", "this_setting_filename_dir", "=", "filename_dir", "+", "'shot('", "+", "str", "(", "FLAGS", ".", "shot_num", ")", "+", "').way('", "+", "str", "(", "FLAGS", ".", "way_num", ")", "+", "').metatr_epite('", "+", "str", "(", "FLAGS", ".", "metatrain_epite_sample_num", ")", "+", "').metate_epite('", "+", "str", "(", "FLAGS", ".", "metatest_epite_sample_num", ")", "+", "')/'", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "this_setting_filename_dir", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "self", ".", "this_setting_filename_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.generate_data": [[38, 110], ["os.path.exists", "print", "tqdm.trange", "numpy.save", "print", "print", "os.path.join", "random.sample", "random.shuffle", "utils.misc.get_images", "range", "data_list.append", "os.listdir", "os.path.isdir", "os.path.join", "Exception", "range", "os.path.join", "os.listdir", "os.path.isdir", "os.path.join", "os.path.join", "os.listdir", "os.path.isdir", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.get_images"], ["", "", "def", "generate_data", "(", "self", ",", "data_type", "=", "'train'", ")", ":", "\n", "        ", "\"\"\"The function to generate the data lists.\n        Arg:\n          data_type: the phase for meta-learning.\n        \"\"\"", "\n", "if", "data_type", "==", "'train'", ":", "\n", "            ", "metatrain_folder", "=", "FLAGS", ".", "metatrain_dir", "\n", "folders", "=", "[", "os", ".", "path", ".", "join", "(", "metatrain_folder", ",", "label", ")", "for", "label", "in", "os", ".", "listdir", "(", "metatrain_folder", ")", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "metatrain_folder", ",", "label", ")", ")", "]", "\n", "num_total_batches", "=", "FLAGS", ".", "metatrain_iterations", "*", "FLAGS", ".", "meta_batch_size", "+", "10", "\n", "num_samples_per_class", "=", "FLAGS", ".", "shot_num", "+", "FLAGS", ".", "metatrain_epite_sample_num", "\n", "\n", "", "elif", "data_type", "==", "'test'", ":", "\n", "            ", "metatest_folder", "=", "FLAGS", ".", "metatest_dir", "\n", "folders", "=", "[", "os", ".", "path", ".", "join", "(", "metatest_folder", ",", "label", ")", "for", "label", "in", "os", ".", "listdir", "(", "metatest_folder", ")", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "metatest_folder", ",", "label", ")", ")", "]", "\n", "num_total_batches", "=", "600", "\n", "if", "FLAGS", ".", "metatest_epite_sample_num", "==", "0", ":", "\n", "                ", "num_samples_per_class", "=", "FLAGS", ".", "shot_num", "*", "2", "\n", "", "else", ":", "\n", "                ", "num_samples_per_class", "=", "FLAGS", ".", "shot_num", "+", "FLAGS", ".", "metatest_epite_sample_num", "\n", "", "", "elif", "data_type", "==", "'val'", ":", "\n", "            ", "metaval_folder", "=", "FLAGS", ".", "metaval_dir", "\n", "folders", "=", "[", "os", ".", "path", ".", "join", "(", "metaval_folder", ",", "label", ")", "for", "label", "in", "os", ".", "listdir", "(", "metaval_folder", ")", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "metaval_folder", ",", "label", ")", ")", "]", "\n", "num_total_batches", "=", "600", "\n", "if", "FLAGS", ".", "metatest_epite_sample_num", "==", "0", ":", "\n", "                ", "num_samples_per_class", "=", "FLAGS", ".", "shot_num", "*", "2", "\n", "", "else", ":", "\n", "                ", "num_samples_per_class", "=", "FLAGS", ".", "shot_num", "+", "FLAGS", ".", "metatest_epite_sample_num", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Please check data list type'", ")", "\n", "\n", "", "task_num", "=", "FLAGS", ".", "way_num", "*", "num_samples_per_class", "\n", "epitr_sample_num", "=", "FLAGS", ".", "shot_num", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "this_setting_filename_dir", "+", "'/'", "+", "data_type", "+", "'_data.npy'", ")", ":", "\n", "            ", "print", "(", "'Generating '", "+", "data_type", "+", "' data'", ")", "\n", "data_list", "=", "[", "]", "\n", "for", "epi_idx", "in", "trange", "(", "num_total_batches", ")", ":", "\n", "                ", "sampled_character_folders", "=", "random", ".", "sample", "(", "folders", ",", "FLAGS", ".", "way_num", ")", "\n", "random", ".", "shuffle", "(", "sampled_character_folders", ")", "\n", "labels_and_images", "=", "get_images", "(", "sampled_character_folders", ",", "range", "(", "FLAGS", ".", "way_num", ")", ",", "nb_samples", "=", "num_samples_per_class", ",", "shuffle", "=", "False", ")", "\n", "labels", "=", "[", "li", "[", "0", "]", "for", "li", "in", "labels_and_images", "]", "\n", "filenames", "=", "[", "li", "[", "1", "]", "for", "li", "in", "labels_and_images", "]", "\n", "this_task_tr_filenames", "=", "[", "]", "\n", "this_task_tr_labels", "=", "[", "]", "\n", "this_task_te_filenames", "=", "[", "]", "\n", "this_task_te_labels", "=", "[", "]", "\n", "for", "class_idx", "in", "range", "(", "FLAGS", ".", "way_num", ")", ":", "\n", "                    ", "this_class_filenames", "=", "filenames", "[", "class_idx", "*", "num_samples_per_class", ":", "(", "class_idx", "+", "1", ")", "*", "num_samples_per_class", "]", "\n", "this_class_label", "=", "labels", "[", "class_idx", "*", "num_samples_per_class", ":", "(", "class_idx", "+", "1", ")", "*", "num_samples_per_class", "]", "\n", "this_task_tr_filenames", "+=", "this_class_filenames", "[", "0", ":", "epitr_sample_num", "]", "\n", "this_task_tr_labels", "+=", "this_class_label", "[", "0", ":", "epitr_sample_num", "]", "\n", "this_task_te_filenames", "+=", "this_class_filenames", "[", "epitr_sample_num", ":", "]", "\n", "this_task_te_labels", "+=", "this_class_label", "[", "epitr_sample_num", ":", "]", "\n", "\n", "", "this_batch_data", "=", "{", "'filenamea'", ":", "this_task_tr_filenames", ",", "'filenameb'", ":", "this_task_te_filenames", ",", "'labela'", ":", "this_task_tr_labels", ",", "'labelb'", ":", "this_task_te_labels", "}", "\n", "data_list", ".", "append", "(", "this_batch_data", ")", "\n", "\n", "", "np", ".", "save", "(", "self", ".", "this_setting_filename_dir", "+", "'/'", "+", "data_type", "+", "'_data.npy'", ",", "data_list", ")", "\n", "print", "(", "'The '", "+", "data_type", "+", "' data are saved'", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'The '", "+", "data_type", "+", "' data have already been created'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.load_data": [[111, 125], ["numpy.load", "print"], "methods", ["None"], ["", "", "def", "load_data", "(", "self", ",", "data_type", "=", "'test'", ")", ":", "\n", "        ", "\"\"\"The function to load the data lists.\n        Arg:\n          data_type: the phase for meta-learning.\n        \"\"\"", "\n", "data_list", "=", "np", ".", "load", "(", "self", ".", "this_setting_filename_dir", "+", "'/'", "+", "data_type", "+", "'_data.npy'", ",", "allow_pickle", "=", "True", ",", "encoding", "=", "\"latin1\"", ")", "\n", "if", "data_type", "==", "'train'", ":", "\n", "            ", "self", ".", "train_data", "=", "data_list", "\n", "", "elif", "data_type", "==", "'test'", ":", "\n", "            ", "self", ".", "test_data", "=", "data_list", "\n", "", "elif", "data_type", "==", "'val'", ":", "\n", "            ", "self", ".", "val_data", "=", "data_list", "\n", "", "else", ":", "\n", "            ", "print", "(", "'[Error] Please check data list type'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.data_generator.meta_data_generator.MetaDataGenerator.load_episode": [[126, 170], ["utils.misc.process_batch_augmentation", "utils.misc.process_batch", "utils.misc.process_batch", "utils.misc.process_batch", "Exception"], "methods", ["home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.process_batch_augmentation", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.process_batch", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.process_batch", "home.repos.pwc.inspect_result.yaoyao-liu_meta-transfer-learning.utils.misc.process_batch"], ["", "", "def", "load_episode", "(", "self", ",", "index", ",", "data_type", "=", "'train'", ")", ":", "\n", "        ", "\"\"\"The function to load the episodes.\n        Args:\n          index: the index for the episodes.\n          data_type: the phase for meta-learning.\n        \"\"\"", "\n", "if", "data_type", "==", "'train'", ":", "\n", "            ", "data_list", "=", "self", ".", "train_data", "\n", "epite_sample_num", "=", "FLAGS", ".", "metatrain_epite_sample_num", "\n", "", "elif", "data_type", "==", "'test'", ":", "\n", "            ", "data_list", "=", "self", ".", "test_data", "\n", "if", "FLAGS", ".", "metatest_epite_sample_num", "==", "0", ":", "\n", "                ", "epite_sample_num", "=", "FLAGS", ".", "shot_num", "\n", "", "else", ":", "\n", "                ", "epite_sample_num", "=", "FLAGS", ".", "metatest_episode_test_sample", "\n", "", "", "elif", "data_type", "==", "'val'", ":", "\n", "            ", "data_list", "=", "self", ".", "val_data", "\n", "if", "FLAGS", ".", "metatest_epite_sample_num", "==", "0", ":", "\n", "                ", "epite_sample_num", "=", "FLAGS", ".", "shot_num", "\n", "", "else", ":", "\n", "                ", "epite_sample_num", "=", "FLAGS", ".", "metatest_episode_test_sample", "\n", "", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Please check data list type'", ")", "\n", "\n", "", "dim_input", "=", "FLAGS", ".", "img_size", "*", "FLAGS", ".", "img_size", "*", "3", "\n", "epitr_sample_num", "=", "FLAGS", ".", "shot_num", "\n", "\n", "this_episode", "=", "data_list", "[", "index", "]", "\n", "this_task_tr_filenames", "=", "this_episode", "[", "'filenamea'", "]", "\n", "this_task_te_filenames", "=", "this_episode", "[", "'filenameb'", "]", "\n", "this_task_tr_labels", "=", "this_episode", "[", "'labela'", "]", "\n", "this_task_te_labels", "=", "this_episode", "[", "'labelb'", "]", "\n", "\n", "if", "FLAGS", ".", "metatrain", "is", "False", "and", "FLAGS", ".", "base_augmentation", ":", "\n", "            ", "this_inputa", ",", "this_labela", "=", "process_batch_augmentation", "(", "this_task_tr_filenames", ",", "this_task_tr_labels", ",", "dim_input", ",", "epitr_sample_num", ")", "\n", "this_inputb", ",", "this_labelb", "=", "process_batch", "(", "this_task_te_filenames", ",", "this_task_te_labels", ",", "dim_input", ",", "epite_sample_num", ")", "\n", "", "else", ":", "\n", "            ", "this_inputa", ",", "this_labela", "=", "process_batch", "(", "this_task_tr_filenames", ",", "this_task_tr_labels", ",", "dim_input", ",", "epitr_sample_num", ")", "\n", "this_inputb", ",", "this_labelb", "=", "process_batch", "(", "this_task_te_filenames", ",", "this_task_te_labels", ",", "dim_input", ",", "epite_sample_num", ")", "\n", "", "return", "this_inputa", ",", "this_labela", ",", "this_inputb", ",", "this_labelb", "\n", "", "", ""]]}