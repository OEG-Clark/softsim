{"home.repos.pwc.inspect_result.HazyResearch_structured-nets.pytorch.main.save_args": [[58, 75], ["subprocess.check_output().strip", "print", "open", "open.write", "open.close", "pickle.dump", "pprint.pformat", "os.path.exists", "os.makedirs", "os.path.join", "open", "subprocess.check_output", "vars", "os.path.join", "str"], "function", ["None"], ["def", "save_args", "(", "args", ",", "results_dir", ")", ":", "\n", "    ", "commit_id", "=", "subprocess", ".", "check_output", "(", "[", "'git'", ",", "'rev-parse'", ",", "'--short'", ",", "'HEAD'", "]", ")", ".", "strip", "(", ")", "\n", "command", "=", "' '", ".", "join", "(", "sys", ".", "argv", ")", "\n", "param_str", "=", "str", "(", "commit_id", ")", "+", "'\\n'", "+", "command", "+", "'\\n'", "+", "pprint", ".", "pformat", "(", "vars", "(", "args", ")", ")", "\n", "print", "(", "param_str", ")", "\n", "\n", "# Make new dir with timestamp", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "results_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "results_dir", ")", "\n", "\n", "# Save the parameters in readable form", "\n", "", "text_file", "=", "open", "(", "os", ".", "path", ".", "join", "(", "results_dir", ",", "'params.txt'", ")", ",", "\"w\"", ")", "\n", "text_file", ".", "write", "(", "param_str", ")", "\n", "text_file", ".", "close", "(", ")", "\n", "\n", "# Save the Namespace object", "\n", "pkl", ".", "dump", "(", "args", ",", "open", "(", "os", ".", "path", ".", "join", "(", "results_dir", ",", "'params.p'", ")", ",", "\"wb\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.pytorch.main.mlp": [[77, 134], ["dataset.DatasetLoaders", "models.nets.construct_model", "itertools.product", "os.path.join", "main.save_args", "str", "range", "os.path.join", "os.path.join", "os.path.join", "models.nets.construct_model.reset_parameters", "torch.optim.lr_scheduler.StepLR", "str", "str", "str", "str", "str", "str", "torch.optim.SGD", "learning.prune.prune", "learning.train.train", "str", "datetime.datetime.now().strftime", "models.nets.construct_model.parameters", "torch.optim.Adam", "models.nets.construct_model.parameters", "torch.optim.Adam", "str", "datetime.datetime.now", "models.nets.construct_model.parameters", "str", "str", "str", "str", "str", "str", "models.nets.construct_model.name"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.construct_model", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.pytorch.main.save_args", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonalC.reset_parameters", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.prune.prune", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.train.train", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.name"], ["", "def", "mlp", "(", "args", ")", ":", "\n", "    ", "for", "train_frac", "in", "args", ".", "train_frac", ":", "\n", "        ", "dataset", "=", "DatasetLoaders", "(", "args", ".", "dataset", ",", "args", ".", "data_dir", ",", "args", ".", "val_frac", ",", "args", ".", "transform", ",", "train_frac", ",", "args", ".", "batch_size", ")", "\n", "model", "=", "construct_model", "(", "nets", "[", "args", ".", "model", "]", ",", "dataset", ".", "in_size", ",", "dataset", ".", "out_size", ",", "args", ")", "\n", "\n", "for", "lr", ",", "mom", "in", "itertools", ".", "product", "(", "args", ".", "lr", ",", "args", ".", "mom", ")", ":", "\n", "            ", "run_name", "=", "args", ".", "name", "+", "'_'", "+", "model", ".", "name", "(", ")", "+", "'_lr'", "+", "str", "(", "lr", ")", "+", "'_lrd'", "+", "str", "(", "args", ".", "lr_decay", ")", "+", "'_mom'", "+", "str", "(", "mom", ")", "+", "'_bs'", "+", "str", "(", "args", ".", "batch_size", ")", "+", "'_ep'", "+", "str", "(", "args", ".", "epochs", ")", "+", "'_'", "+", "str", "(", "args", ".", "dataset", ")", "+", "'_vf'", "+", "str", "(", "args", ".", "val_frac", ")", "+", "'_m'", "+", "str", "(", "args", ".", "model", ")", "+", "'_hs'", "+", "str", "(", "args", ".", "hidden_size", ")", "\n", "\n", "#+ '_nl' + str(args.num_layers)", "\n", "\n", "if", "train_frac", "is", "not", "None", ":", "\n", "                ", "run_name", "+=", "'_tf'", "+", "str", "(", "train_frac", ")", "\n", "\n", "", "if", "args", ".", "prune", ":", "\n", "                ", "run_name", "+=", "'_pf'", "+", "str", "(", "args", ".", "prune_factor", ")", "\n", "\n", "", "results_dir", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\n", "'results'", ",", "\n", "args", ".", "result_dir", ",", "\n", "run_name", "+", "'_'", "+", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y-%m-%d-%H-%M-%S\"", ")", ")", ")", "\n", "save_args", "(", "args", ",", "results_dir", ")", "\n", "\n", "trial_ids", "=", "args", ".", "trial_id", "if", "args", ".", "trial_id", "is", "not", "None", "else", "range", "(", "args", ".", "trials", ")", "\n", "for", "trial_iter", "in", "trial_ids", ":", "\n", "                ", "log_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'tensorboard'", ",", "args", ".", "result_dir", ",", "run_name", ",", "str", "(", "trial_iter", ")", ")", "\n", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'checkpoints'", ",", "args", ".", "result_dir", ",", "run_name", ",", "str", "(", "trial_iter", ")", ")", "\n", "result_path", "=", "os", ".", "path", ".", "join", "(", "results_dir", ",", "str", "(", "trial_iter", ")", ")", "\n", "\n", "model", ".", "reset_parameters", "(", ")", "\n", "if", "args", ".", "optim", "==", "'sgd'", ":", "\n", "                    ", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "momentum", "=", "mom", ")", "\n", "", "elif", "args", ".", "optim", "==", "'adam'", ":", "\n", "                    ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "amsgrad", "=", "False", ")", "\n", "", "elif", "args", ".", "optim", "==", "'ams'", ":", "\n", "                    ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "amsgrad", "=", "True", ")", "\n", "", "else", ":", "\n", "                    ", "assert", "False", ",", "\"invalid optimizer\"", "\n", "", "lr_scheduler", "=", "StepLR", "(", "optimizer", ",", "step_size", "=", "1", ",", "gamma", "=", "args", ".", "lr_decay", ")", "\n", "\n", "if", "args", ".", "prune", ":", "\n", "# Is there a better way to enforce pruning only for unconstrained and MLP?", "\n", "                    ", "assert", "model", ".", "class_type", "in", "[", "'unconstrained'", ",", "'u'", "]", "and", "args", ".", "model", "in", "[", "'MLP'", ",", "'CNN'", "]", "\n", "prune", ".", "prune", "(", "dataset", ",", "model", ",", "optimizer", ",", "lr_scheduler", ",", "args", ".", "epochs", ",", "args", ".", "log_freq", ",", "log_path", ",", "\n", "checkpoint_path", ",", "result_path", ",", "args", ".", "test", ",", "args", ".", "save_model", ",", "args", ".", "prune_lr_decay", ",", "args", ".", "prune_factor", ",", "\n", "args", ".", "prune_iters", ")", "\n", "", "else", ":", "\n", "                    ", "train", ".", "train", "(", "dataset", ",", "model", ",", "optimizer", ",", "lr_scheduler", ",", "args", ".", "epochs", ",", "args", ".", "log_freq", ",", "\n", "log_path", ",", "checkpoint_path", ",", "result_path", ",", "args", ".", "test", ",", "args", ".", "save_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.pytorch.dataset.DatasetLoaders.__init__": [[149, 157], ["name.startswith", "dataset.create_data_loaders"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.pytorch.dataset.create_data_loaders"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "data_dir", ",", "val_fraction", ",", "transform", "=", "None", ",", "train_fraction", "=", "None", ",", "batch_size", "=", "50", ")", ":", "\n", "        ", "if", "name", ".", "startswith", "(", "'true'", ")", ":", "\n", "# TODO: Add support for synthetic datasets back. Possibly should be split into separate class", "\n", "            ", "self", ".", "loss", "=", "utils", ".", "mse_loss", "\n", "", "else", ":", "\n", "            ", "self", ".", "train_loader", ",", "self", ".", "val_loader", ",", "self", ".", "test_loader", ",", "self", ".", "in_size", ",", "self", ".", "out_size", "=", "create_data_loaders", "(", "name", ",", "\n", "data_dir", ",", "transform", ",", "train_fraction", ",", "val_fraction", ",", "batch_size", ")", "\n", "self", ".", "loss", "=", "utils", ".", "cross_entropy_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.pytorch.dataset.get_dataset": [[15, 78], ["pickle.load", "pickle.load", "dataset.postprocess", "dataset.postprocess", "print", "print", "print", "print", "os.path.join", "os.path.join", "open", "open", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "dataset_name.startswith", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "str", "str", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "print"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.postprocess", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.postprocess"], ["def", "get_dataset", "(", "dataset_name", ",", "data_dir", ",", "transform", ")", ":", "\n", "    ", "\"\"\"\n    Get paths of datasets.\n    \"\"\"", "\n", "if", "dataset_name", "==", "'mnist'", ":", "\n", "        ", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'mnist/train_normalized'", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'mnist/test_normalized'", ")", "\n", "", "elif", "dataset_name", "==", "'cifar10'", ":", "\n", "        ", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'cifar10_combined/train'", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'cifar10_combined/test'", ")", "\n", "", "elif", "dataset_name", "==", "'cifar10mono'", ":", "\n", "        ", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'cifar10_combined/train_grayscale'", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'cifar10_combined/test_grayscale'", ")", "\n", "", "elif", "dataset_name", ".", "startswith", "(", "'mnist_noise'", ")", ":", "\n", "        ", "idx", "=", "dataset_name", "[", "-", "1", "]", "\n", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'mnist_noise/train_'", "+", "str", "(", "idx", ")", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'mnist_noise/test_'", "+", "str", "(", "idx", ")", ")", "\n", "", "elif", "dataset_name", "==", "'norb'", ":", "\n", "        ", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'norb_full/processed_py2_train_32.pkl'", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'norb_full/processed_py2_test_32.pkl'", ")", "\n", "", "elif", "dataset_name", "==", "'rect_images'", ":", "#TODO", "\n", "        ", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'rect_images/rectangles_im_train.amat'", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'rect_images/rectangles_im_test.amat'", ")", "\n", "", "elif", "dataset_name", "==", "'rect'", ":", "\n", "        ", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'rect/train_normalized'", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'rect/test_normalized'", ")", "\n", "", "elif", "dataset_name", "==", "'convex'", ":", "\n", "        ", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'convex/train_normalized'", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'convex/test_normalized'", ")", "\n", "", "elif", "dataset_name", "==", "'mnist_rand_bg'", ":", "#TODO", "\n", "        ", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'mnist_rand_bg/mnist_background_random_train.amat'", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'mnist_rand_bg/mnist_background_random_test.amat'", ")", "\n", "", "elif", "dataset_name", "==", "'mnist_bg_rot'", ":", "\n", "        ", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'mnist_bg_rot/train_normalized'", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'mnist_bg_rot/test_normalized'", ")", "\n", "", "elif", "dataset_name", "==", "'mnist_bg_rot_swap'", ":", "\n", "        ", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'mnist_bg_rot/test_normalized'", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'mnist_bg_rot/train_normalized'", ")", "\n", "#TODO handle iwslt, copy tasks", "\n", "# TODO smallnorb, timit", "\n", "", "else", ":", "\n", "        ", "print", "(", "'dataset.py: unknown dataset name'", ")", "\n", "\n", "# TODO maybe want the .amat if that's standard and do postprocessing in a uniform way instead of having a separate script per dataset", "\n", "", "train_data", "=", "pkl", ".", "load", "(", "open", "(", "train_loc", ",", "'rb'", ")", ")", "\n", "train_X", "=", "train_data", "[", "'X'", "]", "\n", "train_Y", "=", "train_data", "[", "'Y'", "]", "\n", "test_data", "=", "pkl", ".", "load", "(", "open", "(", "test_loc", ",", "'rb'", ")", ")", "\n", "test_X", "=", "test_data", "[", "'X'", "]", "\n", "test_Y", "=", "test_data", "[", "'Y'", "]", "\n", "\n", "train_X", ",", "train_Y", "=", "postprocess", "(", "transform", ",", "train_X", ",", "train_Y", ")", "\n", "test_X", ",", "test_Y", "=", "postprocess", "(", "transform", ",", "test_X", ",", "test_Y", ")", "\n", "\n", "in_size", "=", "train_X", ".", "shape", "[", "1", "]", "\n", "out_size", "=", "train_Y", ".", "shape", "[", "1", "]", "\n", "\n", "print", "(", "\"Train dataset size: \"", ",", "train_X", ".", "shape", "[", "0", "]", ")", "\n", "print", "(", "\"Test dataset size: \"", ",", "test_X", ".", "shape", "[", "0", "]", ")", "\n", "print", "(", "\"In size: \"", ",", "in_size", ")", "\n", "print", "(", "\"Out size: \"", ",", "out_size", ")", "\n", "\n", "return", "torch", ".", "FloatTensor", "(", "train_X", ")", ",", "torch", ".", "FloatTensor", "(", "train_Y", ")", ",", "torch", ".", "FloatTensor", "(", "test_X", ")", ",", "torch", ".", "FloatTensor", "(", "test_Y", ")", ",", "in_size", ",", "out_size", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.pytorch.dataset.split_train_val": [[79, 117], ["numpy.arange", "numpy.random.shuffle", "int", "numpy.arange", "numpy.random.shuffle", "print", "print", "print", "print", "int"], "function", ["None"], ["", "def", "split_train_val", "(", "train_X", ",", "train_Y", ",", "val_fraction", ",", "train_fraction", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Input: training data as a torch.Tensor\n    \"\"\"", "\n", "# Shuffle", "\n", "idx", "=", "np", ".", "arange", "(", "train_X", ".", "shape", "[", "0", "]", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "idx", ")", "\n", "train_X", "=", "train_X", "[", "idx", ",", ":", "]", "\n", "train_Y", "=", "train_Y", "[", "idx", ",", ":", "]", "\n", "\n", "# Compute validation set size", "\n", "val_size", "=", "int", "(", "val_fraction", "*", "train_X", ".", "shape", "[", "0", "]", ")", "\n", "\n", "# Downsample for sample complexity experiments", "\n", "if", "train_fraction", "is", "not", "None", ":", "\n", "        ", "train_size", "=", "int", "(", "train_fraction", "*", "train_X", ".", "shape", "[", "0", "]", ")", "\n", "assert", "val_size", "+", "train_size", "<=", "train_X", ".", "shape", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "train_size", "=", "train_X", ".", "shape", "[", "0", "]", "-", "val_size", "\n", "\n", "# Shuffle X", "\n", "", "idx", "=", "np", ".", "arange", "(", "0", ",", "train_X", ".", "shape", "[", "0", "]", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "idx", ")", "\n", "\n", "train_idx", "=", "idx", "[", "0", ":", "train_size", "]", "\n", "val_idx", "=", "idx", "[", "-", "val_size", ":", "]", "\n", "val_X", "=", "train_X", "[", "val_idx", ",", ":", "]", "\n", "val_Y", "=", "train_Y", "[", "val_idx", ",", ":", "]", "\n", "train_X", "=", "train_X", "[", "train_idx", ",", ":", "]", "\n", "train_Y", "=", "train_Y", "[", "train_idx", ",", ":", "]", "\n", "\n", "print", "(", "'train_X: '", ",", "train_X", ".", "shape", ")", "\n", "print", "(", "'train_Y: '", ",", "train_Y", ".", "shape", ")", "\n", "print", "(", "'val_X: '", ",", "val_X", ".", "shape", ")", "\n", "print", "(", "'val_Y: '", ",", "val_Y", ".", "shape", ")", "\n", "\n", "\n", "return", "train_X", ",", "train_Y", ",", "val_X", ",", "val_Y", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.pytorch.dataset.create_data_loaders": [[120, 146], ["dataset.get_dataset", "dataset.split_train_val", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.pytorch.dataset.get_dataset", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.pytorch.dataset.split_train_val"], ["", "def", "create_data_loaders", "(", "dataset_name", ",", "data_dir", ",", "transform", ",", "train_fraction", ",", "val_fraction", ",", "batch_size", ")", ":", "\n", "    ", "if", "device", ".", "type", "==", "'cuda'", ":", "\n", "        ", "loader_args", "=", "{", "'num_workers'", ":", "16", ",", "'pin_memory'", ":", "True", "}", "\n", "", "else", ":", "\n", "        ", "loader_args", "=", "{", "'num_workers'", ":", "4", ",", "'pin_memory'", ":", "False", "}", "\n", "\n", "", "train_X", ",", "train_Y", ",", "test_X", ",", "test_Y", ",", "in_size", ",", "out_size", "=", "get_dataset", "(", "dataset_name", ",", "data_dir", ",", "transform", ")", "# train/test data, input/output size", "\n", "# train_X, train_Y = postprocess(transform, train_X, train_Y)", "\n", "# test_X, test_Y = postprocess(transform, test_X, test_Y)", "\n", "\n", "# TODO: use torch.utils.data.random_split instead", "\n", "# however, this requires creating the dataset, then splitting, then applying transformations", "\n", "train_X", ",", "train_Y", ",", "val_X", ",", "val_Y", "=", "split_train_val", "(", "train_X", ",", "train_Y", ",", "val_fraction", ",", "train_fraction", ")", "\n", "\n", "\n", "# TODO: use pytorch transforms to postprocess", "\n", "\n", "train_dataset", "=", "torch", ".", "utils", ".", "data", ".", "TensorDataset", "(", "train_X", ",", "train_Y", ")", "\n", "val_dataset", "=", "torch", ".", "utils", ".", "data", ".", "TensorDataset", "(", "val_X", ",", "val_Y", ")", "\n", "test_dataset", "=", "torch", ".", "utils", ".", "data", ".", "TensorDataset", "(", "test_X", ",", "test_Y", ")", "\n", "# create dataloaders", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ",", "**", "loader_args", ")", "\n", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "val_dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ",", "**", "loader_args", ")", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ",", "**", "loader_args", ")", "\n", "\n", "return", "train_loader", ",", "val_loader", ",", "test_loader", ",", "in_size", ",", "out_size", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.pytorch.dataset.postprocess": [[163, 173], ["print", "numpy.pad().reshape", "numpy.random.shuffle", "type", "numpy.pad", "np.pad().reshape.reshape"], "function", ["None"], ["", "", "", "def", "postprocess", "(", "transform", ",", "X", ",", "Y", "=", "None", ")", ":", "\n", "# pad from 784 to 1024", "\n", "    ", "if", "'pad'", "in", "transform", ":", "\n", "        ", "assert", "X", ".", "shape", "[", "1", "]", "==", "784", "\n", "print", "(", "X", ".", "shape", ",", "type", "(", "X", ")", ")", "\n", "X", "=", "np", ".", "pad", "(", "X", ".", "reshape", "(", "(", "-", "1", ",", "28", ",", "28", ")", ")", ",", "(", "(", "0", ",", "0", ")", ",", "(", "2", ",", "2", ")", ",", "(", "2", ",", "2", ")", ")", ",", "'constant'", ")", ".", "reshape", "(", "-", "1", ",", "1024", ")", "\n", "", "if", "'randomize'", "in", "transform", ":", "\n", "        ", "assert", "Y", "is", "not", "None", "\n", "np", ".", "random", ".", "shuffle", "(", "Y", ")", "\n", "", "return", "X", ",", "Y", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.pytorch.dataset.augment": [[174, 209], ["numpy.arange", "numpy.random.shuffle", "np.concatenate().reshape.reshape", "dataset.augment.scale_patch"], "function", ["None"], ["", "def", "augment", "(", "self", ",", "X", ",", "Y", "=", "None", ")", ":", "\n", "    ", "if", "'contrast'", "in", "self", ".", "transform", ":", "\n", "        ", "def", "scale_patch", "(", "X", ")", ":", "\n", "            ", "patch", "=", "(", "(", "9", ",", "19", ")", ",", "(", "9", ",", "19", ")", ")", "\n", "X_", "=", "X", ".", "copy", "(", ")", "\n", "X_", "[", ":", ",", "patch", "[", "0", "]", "[", "0", "]", ":", "patch", "[", "0", "]", "[", "1", "]", ",", "patch", "[", "1", "]", "[", "0", "]", ":", "patch", "[", "1", "]", "[", "1", "]", "]", "*=", "2", "\n", "return", "X_", "\n", "# subsample", "\n", "", "idx", "=", "np", ".", "arange", "(", "X", ".", "shape", "[", "0", "]", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "idx", ")", "\n", "X", "=", "X", "[", "idx", ",", "...", "]", "\n", "Y", "=", "Y", "[", "idx", ",", "...", "]", "\n", "\n", "X1", "=", "X", ".", "reshape", "(", "(", "-", "1", ",", "28", ",", "28", ")", ")", "\n", "X2", "=", "scale_patch", "(", "X1", ")", "\n", "X3", "=", "scale_patch", "(", "X2", ")", "\n", "X4", "=", "scale_patch", "(", "X3", ")", "\n", "# X5 = scale_patch(X4)", "\n", "X", "=", "np", ".", "concatenate", "(", "[", "X1", ",", "X2", ",", "X3", ",", "X4", "]", ",", "axis", "=", "0", ")", ".", "reshape", "(", "-", "1", ",", "28", "*", "28", ")", "\n", "Y", "=", "np", ".", "concatenate", "(", "[", "Y", ",", "Y", ",", "Y", ",", "Y", "]", ",", "axis", "=", "0", ")", "\n", "\n", "", "if", "'patch'", "in", "self", ".", "transform", ":", "\n", "        ", "def", "add_patch", "(", "X", ")", ":", "\n", "            ", "patch", "=", "(", "(", "0", ",", "4", ")", ",", "(", "10", ",", "18", ")", ")", "\n", "X_", "=", "X", ".", "copy", "(", ")", "\n", "X_", "[", ":", ",", "patch", "[", "0", "]", "[", "0", "]", ":", "patch", "[", "0", "]", "[", "1", "]", ",", "patch", "[", "1", "]", "[", "0", "]", ":", "patch", "[", "1", "]", "[", "1", "]", "]", "+=", "3.0", "\n", "return", "X_", "\n", "", "X1", "=", "X", ".", "reshape", "(", "(", "-", "1", ",", "28", ",", "28", ")", ")", "\n", "X2", "=", "add_patch", "(", "X1", ")", "\n", "X3", "=", "add_patch", "(", "X2", ")", "\n", "X4", "=", "add_patch", "(", "X3", ")", "\n", "X", "=", "np", ".", "concatenate", "(", "[", "X1", ",", "X2", ",", "X3", ",", "X4", "]", ",", "axis", "=", "0", ")", ".", "reshape", "(", "-", "1", ",", "28", "*", "28", ")", "\n", "Y", "=", "np", ".", "concatenate", "(", "[", "Y", ",", "Y", ",", "Y", ",", "Y", "]", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "X", ",", "Y", "\n", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.pytorch.utils.mse_loss": [[4, 10], ["torch.MSELoss", "nn.MSELoss.", "torch.FloatTensor", "torch.FloatTensor"], "function", ["None"], ["def", "mse_loss", "(", "pred", ",", "true", ")", ":", "\n", "    ", "loss_fn", "=", "nn", ".", "MSELoss", "(", ")", "\n", "mse", "=", "loss_fn", "(", "pred", ",", "true", ")", "\n", "accuracy", "=", "torch", ".", "FloatTensor", "(", "[", "0", "]", ")", "\n", "\n", "return", "mse", ",", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.pytorch.utils.cross_entropy_loss": [[11, 21], ["torch.CrossEntropyLoss", "torch.max", "torch.max", "nn.CrossEntropyLoss.", "torch.max", "torch.max", "torch.eq", "torch.eq", "torch.mean", "torch.mean", "torch.eq.float"], "function", ["None"], ["", "def", "cross_entropy_loss", "(", "pred", ",", "true", ")", ":", "\n", "    ", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "_", ",", "true_argmax", "=", "torch", ".", "max", "(", "true", ",", "1", ")", "\n", "cross_entropy", "=", "loss_fn", "(", "pred", ",", "true_argmax", ")", "\n", "\n", "_", ",", "pred_argmax", "=", "torch", ".", "max", "(", "pred", ",", "1", ")", "\n", "correct_prediction", "=", "torch", ".", "eq", "(", "true_argmax", ",", "pred_argmax", ")", "\n", "accuracy", "=", "torch", ".", "mean", "(", "correct_prediction", ".", "float", "(", ")", ")", "\n", "\n", "return", "cross_entropy", ",", "accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.pytorch.utils.get_commit_id": [[23, 25], ["subprocess.check_output"], "function", ["None"], ["", "def", "get_commit_id", "(", ")", ":", "\n", "  ", "return", "subprocess", ".", "check_output", "(", "[", "'git'", ",", "'rev-parse'", ",", "'--short'", ",", "'HEAD'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.pytorch.utils.descendants": [[26, 36], ["cls.__subclasses__", "desc.append", "desc.extend", "utils.descendants"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.pytorch.utils.descendants"], ["", "def", "descendants", "(", "cls", ")", ":", "\n", "    ", "\"\"\"\n    Get all subclasses (recursively) of class cls, not including itself\n    Assumes no multiple inheritance\n    \"\"\"", "\n", "desc", "=", "[", "]", "\n", "for", "subcls", "in", "cls", ".", "__subclasses__", "(", ")", ":", "\n", "        ", "desc", ".", "append", "(", "subcls", ")", "\n", "desc", ".", "extend", "(", "descendants", "(", "subcls", ")", ")", "\n", "", "return", "desc", "\n", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.main.batchify": [[85, 93], ["data.view().t().contiguous.narrow", "data.view().t().contiguous.view().t().contiguous", "data.view().t().contiguous.to", "data.view().t().contiguous.size", "data.view().t().contiguous.view().t", "data.view().t().contiguous.view"], "function", ["None"], ["+", "'_lrd'", "+", "str", "(", "args", ".", "lr_decay", ")", "+", "'_mom'", "+", "str", "(", "mom", ")", "+", "'_bs'", "+", "str", "(", "args", ".", "batch_size", ")", "+", "'_ep'", "+", "str", "(", "args", ".", "epochs", ")", "+", "'_'", "+", "str", "(", "args", ".", "dataset", ")", "+", "'_vf'", "+", "str", "(", "args", ".", "val_frac", ")", "+", "'_m'", "+", "str", "(", "args", ".", "model", ")", "+", "'_hs'", "+", "str", "(", "args", ".", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.main.repackage_hidden": [[122, 128], ["isinstance", "h.detach", "tuple", "main.repackage_hidden"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.main.repackage_hidden"], ["                    ", "assert", "False", ",", "\"invalid optimizer\"", "\n", "", "lr_scheduler", "=", "StepLR", "(", "optimizer", ",", "step_size", "=", "1", ",", "gamma", "=", "args", ".", "lr_decay", ")", "\n", "\n", "if", "args", ".", "prune", ":", "\n", "# Is there a better way to enforce pruning only for unconstrained and MLP?", "\n", "                    ", "assert", "model", ".", "class_type", "in", "[", "'unconstrained'", ",", "'u'", "]", "and", "args", ".", "model", "in", "[", "'MLP'", ",", "'CNN'", "]", "\n", "prune", ".", "prune", "(", "dataset", ",", "model", ",", "optimizer", ",", "lr_scheduler", ",", "args", ".", "epochs", ",", "args", ".", "log_freq", ",", "log_path", ",", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.main.get_batch": [[140, 145], ["min", "source[].view", "len"], "function", ["None"], ["# mlp_parser.set_defaults(task=mlp)", "\n", "\n", "# MLP models", "\n", "model_options", "=", "[", "]", "\n", "nets", "=", "{", "}", "\n", "for", "model", "in", "descendants", "(", "ArghModel", ")", ":", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.main.evaluate": [[147, 161], ["model.eval", "len", "model.init_hidden", "torch.no_grad", "torch.no_grad", "range", "len", "main.get_batch", "model", "output.view", "main.repackage_hidden", "data_source.size", "len", "criterion().item", "criterion"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.main.get_batch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.main.repackage_hidden"], ["    ", "model", ".", "args", ".", "__name__", "=", "model", ".", "__name__", "\n", "model_options", ".", "append", "(", "model", ".", "args", ")", "\n", "nets", "[", "model", ".", "__name__", "]", "=", "model", "\n", "", "argh", ".", "add_commands", "(", "parser", ",", "model_options", ",", "namespace", "=", "'model'", ",", "namespace_kwargs", "=", "{", "'dest'", ":", "'model'", "}", ")", "\n", "for", "model", "in", "ArghModel", ".", "__subclasses__", "(", ")", ":", "\n", "# Change names back", "\n", "    ", "model", ".", "args", ".", "__name__", "=", "'args'", "\n", "\n", "\n", "", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "args", ".", "task", "(", "args", ")", "\n", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.main.train": [[163, 199], ["model.train", "time.time", "len", "model.init_hidden", "enumerate", "range", "main.get_batch", "main.repackage_hidden", "model.zero_grad", "model", "criterion", "criterion.backward", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "model.parameters", "criterion.item", "output.view", "model.parameters", "p.data.add_", "print", "time.time", "train_data.size", "time.time", "math.exp", "len"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.train.train", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.main.get_batch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.main.repackage_hidden", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.CycleDownMultCuda.backward"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.lstm.LSTMCell.__init__": [[14, 32], ["torch.nn.Module.__init__", "structure.StructuredLinear", "torch.nn.Parameter", "lstm.LSTMCell.reset_parameters", "torch.FloatTensor", "torch.nn.Parameter", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonalC.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "class_type", ",", "r", ",", "input_size", ",", "hidden_size", ",", "use_bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "LSTMCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "use_bias", "=", "use_bias", "\n", "self", ".", "class_type", "=", "class_type", "\n", "self", ".", "r", "=", "r", "\n", "\n", "# Replace W_ih with structured matrices", "\n", "self", ".", "W_ih", "=", "sl", ".", "StructuredLinear", "(", "class_type", ",", "layer_size", "=", "4", "*", "hidden_size", ",", "r", "=", "r", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "W_hh", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "FloatTensor", "(", "hidden_size", ",", "4", "*", "hidden_size", ")", ")", "\n", "if", "use_bias", ":", "\n", "            ", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "4", "*", "hidden_size", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bias", "=", "None", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.lstm.LSTMCell.reset_parameters": [[33, 38], ["torch.eye().repeat", "lstm.LSTMCell.W_hh.data.set_", "torch.nn.init.constant", "torch.eye"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "W_hh_data", "=", "torch", ".", "eye", "(", "self", ".", "hidden_size", ")", ".", "repeat", "(", "1", ",", "4", ")", "\n", "self", ".", "W_hh", ".", "data", ".", "set_", "(", "W_hh_data", ")", "\n", "if", "self", ".", "use_bias", ":", "\n", "            ", "init", ".", "constant", "(", "self", ".", "bias", ".", "data", ",", "val", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.lstm.LSTMCell.forward": [[39, 56], ["h_0.squeeze.squeeze.squeeze", "c_0.squeeze.squeeze.squeeze", "h_0.squeeze.squeeze.size", "lstm.LSTMCell.bias.unsqueeze().expand", "torch.addmm", "torch.zeros().cuda", "torch.cat", "lstm.LSTMCell.W_ih", "torch.split", "torch.sigmoid", "torch.tanh", "lstm.LSTMCell.bias.unsqueeze", "lstm.LSTMCell.bias.size", "torch.zeros", "torch.sigmoid", "torch.sigmoid", "torch.tanh", "input_.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_", ",", "hx", ")", ":", "\n", "        ", "h_0", ",", "c_0", "=", "hx", "\n", "h_0", "=", "h_0", ".", "squeeze", "(", ")", "\n", "c_0", "=", "c_0", ".", "squeeze", "(", ")", "\n", "batch_size", "=", "h_0", ".", "size", "(", "0", ")", "\n", "bias_batch", "=", "(", "self", ".", "bias", ".", "unsqueeze", "(", "0", ")", "\n", ".", "expand", "(", "batch_size", ",", "*", "self", ".", "bias", ".", "size", "(", ")", ")", ")", "\n", "wh_b", "=", "torch", ".", "addmm", "(", "bias_batch", ",", "h_0", ",", "self", ".", "W_hh", ")", "\n", "z", "=", "torch", ".", "zeros", "(", "input_", ".", "size", "(", "0", ")", ",", "3", "*", "self", ".", "hidden_size", ")", ".", "cuda", "(", ")", "\n", "input_padded", "=", "torch", ".", "cat", "(", "(", "input_", ",", "z", ")", ",", "dim", "=", "1", ")", "\n", "wi", "=", "self", ".", "W_ih", "(", "input_padded", ")", "\n", "\n", "f", ",", "i", ",", "o", ",", "g", "=", "torch", ".", "split", "(", "wh_b", "+", "wi", ",", "\n", "split_size_or_sections", "=", "self", ".", "hidden_size", ",", "dim", "=", "1", ")", "\n", "c_1", "=", "torch", ".", "sigmoid", "(", "f", ")", "*", "c_0", "+", "torch", ".", "sigmoid", "(", "i", ")", "*", "torch", ".", "tanh", "(", "g", ")", "\n", "h_1", "=", "torch", ".", "sigmoid", "(", "o", ")", "*", "torch", ".", "tanh", "(", "c_1", ")", "\n", "return", "h_1", ",", "c_1", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.lstm.SingleLayerLSTM.__init__": [[58, 70], ["torch.nn.Module.__init__", "lstm.LSTMCell", "torch.nn.Dropout", "lstm.SingleLayerLSTM.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonalC.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "class_type", ",", "r", ",", "input_size", ",", "hidden_size", ",", "use_bias", "=", "True", ",", "dropout", "=", "0", ")", ":", "\n", "        ", "super", "(", "SingleLayerLSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "use_bias", "=", "use_bias", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "# Initialize LSTMCell", "\n", "self", ".", "cell", "=", "LSTMCell", "(", "class_type", "=", "class_type", ",", "r", "=", "r", ",", "input_size", "=", "input_size", ",", "\n", "hidden_size", "=", "hidden_size", ",", "use_bias", "=", "use_bias", ")", "\n", "self", ".", "dropout_layer", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.lstm.SingleLayerLSTM.reset_parameters": [[71, 73], ["lstm.SingleLayerLSTM.cell.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonalC.reset_parameters"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "cell", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.lstm.SingleLayerLSTM._forward_rnn": [[74, 88], ["input_.size", "range", "torch.stack", "cell", "torch.stack.append"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_forward_rnn", "(", "cell", ",", "input_", ",", "length", ",", "hx", ")", ":", "\n", "        ", "max_time", "=", "input_", ".", "size", "(", "0", ")", "\n", "output", "=", "[", "]", "\n", "for", "time", "in", "range", "(", "max_time", ")", ":", "\n", "            ", "h_next", ",", "c_next", "=", "cell", "(", "input_", "=", "input_", "[", "time", "]", ",", "hx", "=", "hx", ")", "\n", "mask", "=", "(", "time", "<", "length", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "h_next", ")", "\n", "h_next", "=", "h_next", "*", "mask", "+", "hx", "[", "0", "]", "*", "(", "1", "-", "mask", ")", "\n", "c_next", "=", "c_next", "*", "mask", "+", "hx", "[", "1", "]", "*", "(", "1", "-", "mask", ")", "\n", "hx_next", "=", "(", "h_next", ",", "c_next", ")", "\n", "output", ".", "append", "(", "h_next", ")", "\n", "hx", "=", "hx_next", "\n", "", "output", "=", "torch", ".", "stack", "(", "output", ",", "0", ")", "\n", "return", "output", ",", "hx", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.lstm.SingleLayerLSTM.forward": [[89, 100], ["lstm.SingleLayerLSTM.size", "torch.autograd.Variable", "lstm.SingleLayerLSTM._forward_rnn", "lstm.SingleLayerLSTM.dropout_layer", "torch.LongTensor", "lstm.SingleLayerLSTM.get_device", "length.cuda.cuda.cuda"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.lstm.SingleLayerLSTM._forward_rnn"], ["", "def", "forward", "(", "self", ",", "input_", ",", "hx", ")", ":", "\n", "        ", "max_time", ",", "batch_size", ",", "_", "=", "input_", ".", "size", "(", ")", "\n", "length", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "[", "max_time", "]", "*", "batch_size", ")", ")", "\n", "if", "input_", ".", "is_cuda", ":", "\n", "            ", "device", "=", "input_", ".", "get_device", "(", ")", "\n", "length", "=", "length", ".", "cuda", "(", "device", ")", "\n", "\n", "", "output", ",", "(", "h_n", ",", "c_n", ")", "=", "SingleLayerLSTM", ".", "_forward_rnn", "(", "\n", "cell", "=", "self", ".", "cell", ",", "input_", "=", "input_", ",", "length", "=", "length", ",", "hx", "=", "hx", ")", "\n", "input_", "=", "self", ".", "dropout_layer", "(", "output", ")", "\n", "return", "output", ",", "(", "h_n", ",", "c_n", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.data.Dictionary.__init__": [[9, 12], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "word2idx", "=", "{", "}", "\n", "self", ".", "idx2word", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.data.Dictionary.add_word": [[13, 18], ["data.Dictionary.idx2word.append", "len"], "methods", ["None"], ["", "def", "add_word", "(", "self", ",", "word", ")", ":", "\n", "        ", "if", "word", "not", "in", "self", ".", "word2idx", ":", "\n", "            ", "self", ".", "idx2word", ".", "append", "(", "word", ")", "\n", "self", ".", "word2idx", "[", "word", "]", "=", "len", "(", "self", ".", "idx2word", ")", "-", "1", "\n", "", "return", "self", ".", "word2idx", "[", "word", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.data.Dictionary.__len__": [[19, 21], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "idx2word", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.data.Corpus.__init__": [[24, 29], ["data.Dictionary", "data.Corpus.tokenize", "data.Corpus.tokenize", "data.Corpus.tokenize", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.data.Corpus.tokenize", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.data.Corpus.tokenize", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.data.Corpus.tokenize"], ["    ", "def", "__init__", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "dictionary", "=", "Dictionary", "(", ")", "\n", "self", ".", "train", "=", "self", ".", "tokenize", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ")", "\n", "self", ".", "valid", "=", "self", ".", "tokenize", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ")", "\n", "self", ".", "test", "=", "self", ".", "tokenize", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.data.Corpus.tokenize": [[30, 53], ["os.path.exists", "open", "open", "torch.LongTensor", "len", "line.split", "data.Corpus.dictionary.add_word", "line.split"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.data.Dictionary.add_word"], ["", "def", "tokenize", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"Tokenizes a text file.\"\"\"", "\n", "assert", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "# Add words to the dictionary", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "tokens", "=", "0", "\n", "for", "line", "in", "f", ":", "\n", "                ", "words", "=", "line", ".", "split", "(", ")", "+", "[", "'<eos>'", "]", "\n", "tokens", "+=", "len", "(", "words", ")", "\n", "for", "word", "in", "words", ":", "\n", "                    ", "self", ".", "dictionary", ".", "add_word", "(", "word", ")", "\n", "\n", "# Tokenize file content", "\n", "", "", "", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "ids", "=", "torch", ".", "LongTensor", "(", "tokens", ")", "\n", "token", "=", "0", "\n", "for", "line", "in", "f", ":", "\n", "                ", "words", "=", "line", ".", "split", "(", ")", "+", "[", "'<eos>'", "]", "\n", "for", "word", "in", "words", ":", "\n", "                    ", "ids", "[", "token", "]", "=", "self", ".", "dictionary", ".", "word2idx", "[", "word", "]", "\n", "token", "+=", "1", "\n", "\n", "", "", "", "return", "ids", "\n", "", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.model.RNNModel.__init__": [[15, 50], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "model.RNNModel.init_weights", "print", "torch.RNN", "torch.RNN", "lstm.SingleLayerLSTM", "ValueError", "getattr", "ValueError"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.model.RNNModel.init_weights"], ["def", "__init__", "(", "self", ",", "class_type", ",", "r", ",", "rnn_type", ",", "ntoken", ",", "ninp", ",", "nhid", ",", "nlayers", ",", "dropout", "=", "0.5", ",", "tie_weights", "=", "False", ")", ":", "\n", "        ", "super", "(", "RNNModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "encoder", "=", "nn", ".", "Embedding", "(", "ntoken", ",", "ninp", ")", "\n", "if", "rnn_type", "in", "[", "'LSTM'", ",", "'GRU'", "]", ":", "\n", "            ", "print", "(", "'ninp, nhid, nlayers: '", ",", "ninp", ",", "nhid", ",", "nlayers", ")", "\n", "if", "rnn_type", "==", "'LSTM'", ":", "\n", "                ", "self", ".", "rnn", "=", "SingleLayerLSTM", "(", "class_type", ",", "r", ",", "input_size", "=", "ninp", ",", "hidden_size", "=", "nhid", ",", "dropout", "=", "dropout", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "rnn", "=", "getattr", "(", "nn", ",", "rnn_type", ")", "(", "ninp", ",", "nhid", ",", "nlayers", ",", "dropout", "=", "dropout", ")", "\n", "", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "nonlinearity", "=", "{", "'RNN_TANH'", ":", "'tanh'", ",", "'RNN_RELU'", ":", "'relu'", "}", "[", "rnn_type", "]", "\n", "", "except", "KeyError", ":", "\n", "                ", "raise", "ValueError", "(", "\"\"\"An invalid option for `--model` was supplied,\n                                 options are ['LSTM', 'GRU', 'RNN_TANH' or 'RNN_RELU']\"\"\"", ")", "\n", "", "self", ".", "rnn", "=", "nn", ".", "RNN", "(", "ninp", ",", "nhid", ",", "nlayers", ",", "nonlinearity", "=", "nonlinearity", ",", "dropout", "=", "dropout", ")", "\n", "", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "nhid", ",", "ntoken", ")", "\n", "\n", "# Optionally tie weights as in:", "\n", "# \"Using the Output Embedding to Improve Language Models\" (Press & Wolf 2016)", "\n", "# https://arxiv.org/abs/1608.05859", "\n", "# and", "\n", "# \"Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling\" (Inan et al. 2016)", "\n", "# https://arxiv.org/abs/1611.01462", "\n", "if", "tie_weights", ":", "\n", "            ", "if", "nhid", "!=", "ninp", ":", "\n", "                ", "raise", "ValueError", "(", "'When using the tied flag, nhid must be equal to emsize'", ")", "\n", "", "self", ".", "decoder", ".", "weight", "=", "self", ".", "encoder", ".", "weight", "\n", "\n", "", "self", ".", "init_weights", "(", ")", "\n", "\n", "self", ".", "rnn_type", "=", "rnn_type", "\n", "self", ".", "nhid", "=", "nhid", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.model.RNNModel.init_weights": [[51, 56], ["model.RNNModel.encoder.weight.data.uniform_", "model.RNNModel.decoder.bias.data.zero_", "model.RNNModel.decoder.weight.data.uniform_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "self", ".", "encoder", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "decoder", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "decoder", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.model.RNNModel.forward": [[57, 65], ["model.RNNModel.drop", "model.RNNModel.rnn", "model.RNNModel.squeeze", "model.RNNModel.drop", "model.RNNModel.decoder", "model.RNNModel.encoder", "hidden[].squeeze", "hidden[].squeeze", "model.RNNModel.view", "model.RNNModel.view", "model.RNNModel.size", "model.RNNModel.size", "model.RNNModel.size", "model.RNNModel.size", "model.RNNModel.size", "model.RNNModel.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "hidden", ")", ":", "\n", "        ", "emb", "=", "self", ".", "drop", "(", "self", ".", "encoder", "(", "input", ")", ")", "\n", "output", ",", "hidden", "=", "self", ".", "rnn", "(", "emb", ",", "hx", "=", "hidden", ")", "\n", "output", "=", "output", ".", "squeeze", "(", ")", "\n", "hidden", "=", "(", "hidden", "[", "0", "]", ".", "squeeze", "(", "0", ")", ",", "hidden", "[", "1", "]", ".", "squeeze", "(", "0", ")", ")", "\n", "output", "=", "self", ".", "drop", "(", "output", ")", "\n", "decoded", "=", "self", ".", "decoder", "(", "output", ".", "view", "(", "output", ".", "size", "(", "0", ")", "*", "output", ".", "size", "(", "1", ")", ",", "output", ".", "size", "(", "2", ")", ")", ")", "\n", "return", "decoded", ".", "view", "(", "output", ".", "size", "(", "0", ")", ",", "output", ".", "size", "(", "1", ")", ",", "decoded", ".", "size", "(", "1", ")", ")", ",", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.word_language_model.model.RNNModel.init_hidden": [[66, 73], ["next", "model.RNNModel.parameters", "next.new_zeros", "next.new_zeros", "next.new_zeros"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "weight", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", "\n", "if", "self", ".", "rnn_type", "==", "'LSTM'", ":", "\n", "            ", "return", "(", "weight", ".", "new_zeros", "(", "self", ".", "nlayers", ",", "bsz", ",", "self", ".", "nhid", ")", ",", "\n", "weight", ".", "new_zeros", "(", "self", ".", "nlayers", ",", "bsz", ",", "self", ".", "nhid", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "weight", ".", "new_zeros", "(", "self", ".", "nlayers", ",", "bsz", ",", "self", ".", "nhid", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.vae.main.VAE.__init__": [[59, 66], ["torch.nn.Module.__init__", "structure.StructuredLinear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear"], ["    ", "commit_id", "=", "subprocess", ".", "check_output", "(", "[", "'git'", ",", "'rev-parse'", ",", "'--short'", ",", "'HEAD'", "]", ")", ".", "strip", "(", ")", "\n", "command", "=", "' '", ".", "join", "(", "sys", ".", "argv", ")", "\n", "param_str", "=", "str", "(", "commit_id", ")", "+", "'\\n'", "+", "command", "+", "'\\n'", "+", "pprint", ".", "pformat", "(", "vars", "(", "args", ")", ")", "\n", "print", "(", "param_str", ")", "\n", "\n", "# Make new dir with timestamp", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "results_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "results_dir", ")", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.vae.main.VAE.encode": [[67, 70], ["torch.nn.functional.relu", "torch.nn.functional.relu", "main.VAE.fc1", "main.VAE.fc21", "main.VAE.fc22"], "methods", ["None"], ["\n", "# Save the parameters in readable form", "\n", "", "text_file", "=", "open", "(", "os", ".", "path", ".", "join", "(", "results_dir", ",", "'params.txt'", ")", ",", "\"w\"", ")", "\n", "text_file", ".", "write", "(", "param_str", ")", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.vae.main.VAE.reparameterize": [[71, 78], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like.mul().add_", "torch.randn_like.mul().add_", "torch.randn_like.mul", "torch.randn_like.mul"], "methods", ["None"], ["text_file", ".", "close", "(", ")", "\n", "\n", "# Save the Namespace object", "\n", "pkl", ".", "dump", "(", "args", ",", "open", "(", "os", ".", "path", ".", "join", "(", "results_dir", ",", "'params.p'", ")", ",", "\"wb\"", ")", ")", "\n", "\n", "\n", "", "def", "mlp", "(", "args", ")", ":", "\n", "    ", "for", "train_frac", "in", "args", ".", "train_frac", ":", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.vae.main.VAE.decode": [[79, 82], ["torch.nn.functional.relu", "torch.nn.functional.relu", "torch.nn.functional.sigmoid", "torch.nn.functional.sigmoid", "main.VAE.fc3", "main.VAE.fc4"], "methods", ["None"], ["        ", "dataset", "=", "DatasetLoaders", "(", "args", ".", "dataset", ",", "args", ".", "data_dir", ",", "args", ".", "val_frac", ",", "args", ".", "transform", ",", "train_frac", ",", "args", ".", "batch_size", ")", "\n", "model", "=", "construct_model", "(", "nets", "[", "args", ".", "model", "]", ",", "dataset", ".", "in_size", ",", "dataset", ".", "out_size", ",", "args", ")", "\n", "\n", "for", "lr", ",", "mom", "in", "itertools", ".", "product", "(", "args", ".", "lr", ",", "args", ".", "mom", ")", ":", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.vae.main.VAE.forward": [[83, 87], ["main.VAE.encode", "main.VAE.reparameterize", "x.view", "main.VAE.decode"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.EncoderDecoder.encode", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.vae.main.VAE.reparameterize", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.EncoderDecoder.decode"], ["            ", "run_name", "=", "args", ".", "name", "+", "'_'", "+", "model", ".", "name", "(", ")", "+", "'_lr'", "+", "str", "(", "lr", ")", "+", "'_lrd'", "+", "str", "(", "args", ".", "lr_decay", ")", "+", "'_mom'", "+", "str", "(", "mom", ")", "+", "'_bs'", "+", "str", "(", "args", ".", "batch_size", ")"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.vae.main.loss_function": [[97, 107], ["torch.nn.functional.binary_cross_entropy", "x.view", "torch.sum", "torch.sum", "logvar.exp", "mu.pow"], "function", ["None"], ["                ", "run_name", "+=", "'_tf'", "+", "str", "(", "train_frac", ")", "\n", "\n", "", "if", "args", ".", "prune", ":", "\n", "                ", "run_name", "+=", "'_pf'", "+", "str", "(", "args", ".", "prune_factor", ")", "\n", "\n", "", "results_dir", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\n", "'results'", ",", "\n", "args", ".", "result_dir", ",", "\n", "run_name", "+", "'_'", "+", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y-%m-%d-%H-%M-%S\"", ")", ")", ")", "\n", "save_args", "(", "args", ",", "results_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.vae.main.train": [[109, 130], ["model.train", "enumerate", "print", "data.to.to", "optimizer.zero_grad", "model", "main.loss_function", "loss_function.backward", "loss_function.item", "optimizer.step", "len", "print", "len", "len", "len", "len", "loss_function.item", "len"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.train.train", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.vae.main.loss_function", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.CycleDownMultCuda.backward", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.NoamOpt.step"], ["for", "trial_iter", "in", "trial_ids", ":", "\n", "                ", "log_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'tensorboard'", ",", "args", ".", "result_dir", ",", "run_name", ",", "str", "(", "trial_iter", ")", ")", "\n", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'checkpoints'", ",", "args", ".", "result_dir", ",", "run_name", ",", "str", "(", "trial_iter", ")", ")", "\n", "result_path", "=", "os", ".", "path", ".", "join", "(", "results_dir", ",", "str", "(", "trial_iter", ")", ")", "\n", "\n", "model", ".", "reset_parameters", "(", ")", "\n", "if", "args", ".", "optim", "==", "'sgd'", ":", "\n", "                    ", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "momentum", "=", "mom", ")", "\n", "", "elif", "args", ".", "optim", "==", "'adam'", ":", "\n", "                    ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "amsgrad", "=", "False", ")", "\n", "", "elif", "args", ".", "optim", "==", "'ams'", ":", "\n", "                    ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ",", "amsgrad", "=", "True", ")", "\n", "", "else", ":", "\n", "                    ", "assert", "False", ",", "\"invalid optimizer\"", "\n", "", "lr_scheduler", "=", "StepLR", "(", "optimizer", ",", "step_size", "=", "1", ",", "gamma", "=", "args", ".", "lr_decay", ")", "\n", "\n", "if", "args", ".", "prune", ":", "\n", "# Is there a better way to enforce pruning only for unconstrained and MLP?", "\n", "                    ", "assert", "model", ".", "class_type", "in", "[", "'unconstrained'", ",", "'u'", "]", "and", "args", ".", "model", "in", "[", "'MLP'", ",", "'CNN'", "]", "\n", "prune", ".", "prune", "(", "dataset", ",", "model", ",", "optimizer", ",", "lr_scheduler", ",", "args", ".", "epochs", ",", "args", ".", "log_freq", ",", "log_path", ",", "\n", "checkpoint_path", ",", "result_path", ",", "args", ".", "test", ",", "args", ".", "save_model", ",", "args", ".", "prune_lr_decay", ",", "args", ".", "prune_factor", ",", "\n", "args", ".", "prune_iters", ")", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.vae.main.test": [[131, 149], ["model.eval", "len", "print", "torch.no_grad", "torch.no_grad", "enumerate", "data.to.to", "model", "loss_function().item", "min", "torch.cat", "torch.cat", "torchvision.utils.save_image", "main.loss_function", "data.to.size", "torch.cat.cpu", "recon_batch.view", "str"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.vae.main.loss_function"], ["", "else", ":", "\n", "                    ", "train", ".", "train", "(", "dataset", ",", "model", ",", "optimizer", ",", "lr_scheduler", ",", "args", ".", "epochs", ",", "args", ".", "log_freq", ",", "\n", "log_path", ",", "checkpoint_path", ",", "result_path", ",", "args", ".", "test", ",", "args", ".", "save_model", ")", "\n", "\n", "\n", "## Parse", "\n", "", "", "", "", "", "parser", ".", "set_defaults", "(", "task", "=", "mlp", ")", "\n", "# subparsers = parser.add_subparsers()", "\n", "# mlp_parser = subparsers.add_parser('MLP')", "\n", "# mlp_parser.set_defaults(task=mlp)", "\n", "\n", "# MLP models", "\n", "model_options", "=", "[", "]", "\n", "nets", "=", "{", "}", "\n", "for", "model", "in", "descendants", "(", "ArghModel", ")", ":", "\n", "# Change the names so argh can create parsers", "\n", "    ", "model", ".", "args", ".", "__name__", "=", "model", ".", "__name__", "\n", "model_options", ".", "append", "(", "model", ".", "args", ")", "\n", "nets", "[", "model", ".", "__name__", "]", "=", "model", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_reconstruction.krylov": [[10, 16], ["range", "torch.stack", "fn", "cols.append"], "function", ["None"], ["def", "krylov", "(", "fn", ",", "v", ",", "n", ")", ":", "\n", "    ", "cols", "=", "[", "v", "]", "\n", "for", "_", "in", "range", "(", "n", "-", "1", ")", ":", "\n", "        ", "v", "=", "fn", "(", "v", ")", "\n", "cols", ".", "append", "(", "v", ")", "\n", "", "return", "torch", ".", "stack", "(", "cols", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_reconstruction.krylov_recon": [[17, 32], ["torch.autograd.Variable", "range", "torch.zeros().cuda", "torch_reconstruction.krylov", "krylov().t", "torch.matmul().cuda", "torch.add", "torch.zeros", "torch_reconstruction.krylov", "torch.matmul"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.krylov"], ["", "def", "krylov_recon", "(", "r", ",", "n", ",", "G", ",", "H", ",", "fn_A", ",", "fn_B_T", ")", ":", "\n", "    ", "\"G, H: (r, n)\"", "\n", "W1", "=", "Variable", "(", "torch", ".", "zeros", "(", "n", ",", "n", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "r", ")", ":", "\n", "        ", "K_A", "=", "krylov", "(", "fn_A", ",", "G", "[", "i", "]", ",", "n", ")", "\n", "\n", "K_B", "=", "krylov", "(", "fn_B_T", ",", "H", "[", "i", "]", ",", "n", ")", ".", "t", "(", ")", "\n", "\n", "prod", "=", "torch", ".", "matmul", "(", "K_A", ",", "K_B", ")", ".", "cuda", "(", ")", "\n", "#print('W1: ', W1)", "\n", "#print('prod: ', prod)", "\n", "W1", "=", "torch", ".", "add", "(", "W1", ",", "prod", ")", "\n", "\n", "", "return", "W1", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_reconstruction.recon": [[33, 51], ["torch_reconstruction.krylov_recon", "torch.prod", "torch.prod", "print"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.krylov_recon"], ["", "def", "recon", "(", "net", ")", ":", "\n", "    ", "W", "=", "krylov_recon", "(", "net", ".", "params", ".", "r", ",", "net", ".", "params", ".", "layer_size", ",", "net", ".", "G", ",", "net", ".", "H", ",", "net", ".", "fn_A", ",", "net", ".", "fn_B_T", ")", "\n", "\n", "# Normalize", "\n", "if", "net", ".", "params", ".", "class_type", "in", "[", "'vandermonde_like'", ",", "'hankel_like'", "]", ":", "\n", "        ", "return", "W", "\n", "", "if", "net", ".", "params", ".", "class_type", "==", "'toeplitz_like'", ":", "\n", "        ", "return", "0.5", "*", "W", "\n", "", "elif", "net", ".", "params", ".", "class_type", "in", "[", "'circulant_sparsity'", ",", "'tridiagonal_corner'", "]", ":", "\n", "# Compute a and b", "\n", "        ", "a", "=", "torch", ".", "prod", "(", "net", ".", "subdiag_f_A", ")", "\n", "b", "=", "torch", ".", "prod", "(", "net", ".", "subdiag_f_B", ")", "\n", "\n", "coeff", "=", "1.0", "/", "(", "1", "-", "a", "*", "b", ")", "\n", "return", "coeff", "*", "W", "\n", "", "else", ":", "\n", "        ", "print", "(", "(", "'Class_type not supported: '", ",", "net", ".", "params", ".", "class_type", ")", ")", "\n", "assert", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_krylov.Z_mult_fn": [[8, 10], ["torch.cat"], "function", ["None"], ["def", "Z_mult_fn", "(", "f", ",", "x", ")", ":", "\n", "    ", "return", "torch", ".", "cat", "(", "(", "f", "*", "x", "[", "-", "1", "]", ",", "x", "[", ":", "-", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_krylov.Z_transpose_mult_fn": [[12, 17], ["torch.cat"], "function", ["None"], ["", "def", "Z_transpose_mult_fn", "(", "f", ",", "x", ")", ":", "\n", "#print('x[1:]: ', x[1:])", "\n", "#print('f*x[0]: ', f*x[0])", "\n", "#return torch.cat((x[1:], torch.FloatTensor([f * x[0]])))", "\n", "    ", "return", "torch", ".", "cat", "(", "(", "x", "[", "1", ":", "]", ",", "f", "*", "x", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_krylov.diag_mult_fn": [[19, 21], ["None"], "function", ["None"], ["", "def", "diag_mult_fn", "(", "diag", ",", "x", ")", ":", "\n", "    ", "return", "diag", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_krylov.circ_mult_fn": [[23, 27], ["torch.cat"], "function", ["None"], ["", "def", "circ_mult_fn", "(", "subdiag_f", ",", "x", ")", ":", "\n", "# note: f corresponds to last element instead of first", "\n", "    ", "y", "=", "torch", ".", "cat", "(", "(", "x", "[", "-", "1", "]", ",", "x", "[", ":", "-", "1", "]", ")", ")", "\n", "return", "y", "*", "subdiag_f", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_krylov.circ_transpose_mult_fn": [[28, 34], ["torch.cat"], "function", ["None"], ["", "def", "circ_transpose_mult_fn", "(", "subdiag_f", ",", "x", ")", ":", "\n", "# Circular shift", "\n", "    ", "y", "=", "torch", ".", "cat", "(", "(", "x", "[", "1", ":", "]", ",", "x", "[", "0", "]", ")", ")", "\n", "\n", "# Scale by [v f]", "\n", "return", "y", "*", "subdiag_f", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_krylov.tridiag_transpose_mult_fn": [[37, 45], ["torch.cat", "torch.autograd.Variable", "torch.cat", "torch.zeros().cuda", "torch.zeros"], "function", ["None"], ["", "def", "tridiag_transpose_mult_fn", "(", "subdiag_f", ",", "diag", ",", "supdiag", ",", "x", ")", ":", "\n", "    ", "y", "=", "torch", ".", "cat", "(", "(", "x", "[", "1", ":", "]", ",", "x", "[", "0", "]", ")", ")", "\n", "sub_result", "=", "y", "*", "subdiag_f", "\n", "z", "=", "Variable", "(", "torch", ".", "zeros", "(", "1", ")", ".", "cuda", "(", ")", ")", "\n", "sup_result", "=", "torch", ".", "cat", "(", "(", "z", ",", "x", "[", ":", "-", "1", "]", "*", "supdiag", ")", ")", "\n", "diag_result", "=", "x", "*", "diag", "\n", "\n", "return", "sup_result", "+", "sub_result", "+", "diag_result", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_krylov.set_mult_fns": [[49, 95], ["functools.partial", "functools.partial", "functools.partial", "functools.partial", "Parameter", "torch.nn.init.normal_", "functools.partial", "functools.partial", "torch.Tensor", "Parameter", "Parameter", "torch.nn.init.normal_", "torch.nn.init.normal_", "functools.partial", "functools.partial", "torch.Tensor", "torch.Tensor", "Parameter", "Parameter", "Parameter", "Parameter", "Parameter", "Parameter", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "functools.partial", "functools.partial", "print", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "function", ["None"], ["", "def", "set_mult_fns", "(", "self", ",", "params", ")", ":", "\n", "# assert params.disp_type == 'stein'", "\n", "    ", "if", "params", ".", "class_type", "in", "[", "'toeplitz_like'", ",", "'toep_corner'", ",", "'toep_nocorn'", "]", ":", "\n", "        ", "fn_A", "=", "functools", ".", "partial", "(", "Z_mult_fn", ",", "1", ")", "\n", "fn_B_T", "=", "functools", ".", "partial", "(", "Z_mult_fn", ",", "-", "1", ")", "\n", "# TODO: operators for hankel and vandermonde have not been checked for transpose consistency", "\n", "", "elif", "params", ".", "class_type", "==", "'hankel_like'", ":", "\n", "        ", "fn_A", "=", "functools", ".", "partial", "(", "Z_transpose_mult_fn", ",", "1", ")", "\n", "fn_B_T", "=", "functools", ".", "partial", "(", "Z_mult_fn", ",", "0", ")", "\n", "", "elif", "params", ".", "class_type", "==", "'vandermonde_like'", ":", "\n", "        ", "v", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "params", ".", "layer_size", ")", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "v", ",", "std", "=", "params", ".", "init_stddev", ")", "\n", "self", ".", "v", "=", "v", "\n", "fn_A", "=", "functools", ".", "partial", "(", "diag_mult_fn", ",", "self", ".", "v", ")", "\n", "fn_B_T", "=", "functools", ".", "partial", "(", "Z_transpose_mult_fn", ",", "0", ")", "\n", "", "elif", "params", ".", "class_type", "==", "'circulant_sparsity'", ":", "\n", "        ", "self", ".", "subdiag_f_A", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "params", ".", "layer_size", ")", ")", "\n", "self", ".", "subdiag_f_B", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "params", ".", "layer_size", ")", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "subdiag_f_A", ",", "std", "=", "params", ".", "init_stddev", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "subdiag_f_B", ",", "std", "=", "params", ".", "init_stddev", ")", "\n", "\n", "fn_A", "=", "functools", ".", "partial", "(", "circ_mult_fn", ",", "self", ".", "subdiag_f_A", ")", "\n", "fn_B_T", "=", "functools", ".", "partial", "(", "circ_mult_fn", ",", "self", ".", "subdiag_f_B", ")", "\n", "\n", "", "elif", "params", ".", "class_type", "==", "'tridiagonal_corner'", ":", "\n", "        ", "self", ".", "subdiag_f_A", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "params", ".", "layer_size", ")", ")", "\n", "self", ".", "subdiag_f_B", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "params", ".", "layer_size", ")", ")", "\n", "self", ".", "diag_A", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "params", ".", "layer_size", ")", ")", "\n", "self", ".", "diag_B", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "params", ".", "layer_size", ")", ")", "\n", "self", ".", "supdiag_A", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "params", ".", "layer_size", "-", "1", ")", ")", "\n", "self", ".", "supdiag_B", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "params", ".", "layer_size", "-", "1", ")", ")", "\n", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "subdiag_f_A", ",", "std", "=", "params", ".", "init_stddev", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "subdiag_f_B", ",", "std", "=", "params", ".", "init_stddev", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "diag_A", ",", "std", "=", "params", ".", "init_stddev", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "diag_B", ",", "std", "=", "params", ".", "init_stddev", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "supdiag_A", ",", "std", "=", "params", ".", "init_stddev", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "supdiag_B", ",", "std", "=", "params", ".", "init_stddev", ")", "\n", "\n", "fn_A", "=", "functools", ".", "partial", "(", "tridiag_mult_fn", ",", "self", ".", "subdiag_f_A", ",", "self", ".", "diag_A", ",", "self", ".", "supdiag_A", ")", "\n", "fn_B_T", "=", "functools", ".", "partial", "(", "tridiag_mult_fn", ",", "self", ".", "subdiag_f_B", ",", "self", ".", "diag_B", ",", "self", ".", "supdiag_B", ")", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "(", "'Not supported: '", ",", "params", ".", "class_type", ")", ")", "\n", "assert", "0", "\n", "", "return", "fn_A", ",", "fn_B_T", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_utils.NoamOpt.__init__": [[28, 35], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model_size", ",", "factor", ",", "warmup", ",", "optimizer", ")", ":", "\n", "        ", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "_step", "=", "0", "\n", "self", ".", "warmup", "=", "warmup", "\n", "self", ".", "factor", "=", "factor", "\n", "self", ".", "model_size", "=", "model_size", "\n", "self", ".", "_rate", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_utils.NoamOpt.step": [[36, 44], ["torch_utils.NoamOpt.rate", "torch_utils.NoamOpt.optimizer.step"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.NoamOpt.rate", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.NoamOpt.step"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"Update parameters and rate\"", "\n", "self", ".", "_step", "+=", "1", "\n", "rate", "=", "self", ".", "rate", "(", ")", "\n", "for", "p", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "            ", "p", "[", "'lr'", "]", "=", "rate", "\n", "", "self", ".", "_rate", "=", "rate", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_utils.NoamOpt.rate": [[45, 52], ["min"], "methods", ["None"], ["", "def", "rate", "(", "self", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"Implement `lrate` above\"", "\n", "if", "step", "is", "None", ":", "\n", "            ", "step", "=", "self", ".", "_step", "\n", "", "return", "self", ".", "factor", "*", "(", "self", ".", "model_size", "**", "(", "-", "0.5", ")", "*", "\n", "min", "(", "step", "**", "(", "-", "0.5", ")", ",", "step", "*", "self", ".", "warmup", "**", "(", "-", "1.5", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_utils.SimpleLossCompute.__init__": [[74, 78], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "generator", ",", "criterion", ",", "opt", "=", "None", ")", ":", "\n", "        ", "self", ".", "generator", "=", "generator", "\n", "self", ".", "criterion", "=", "criterion", "\n", "self", ".", "opt", "=", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_utils.SimpleLossCompute.__call__": [[79, 88], ["torch_utils.SimpleLossCompute.generator", "loss.backward", "torch_utils.SimpleLossCompute.criterion", "torch_utils.SimpleLossCompute.opt.step", "torch_utils.SimpleLossCompute.opt.optimizer.zero_grad", "torch_utils.SimpleLossCompute.contiguous().view", "y.contiguous().view", "torch_utils.SimpleLossCompute.size", "torch_utils.SimpleLossCompute.contiguous", "y.contiguous"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.CycleDownMultCuda.backward", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.NoamOpt.step"], ["", "def", "__call__", "(", "self", ",", "x", ",", "y", ",", "norm", ")", ":", "\n", "        ", "x", "=", "self", ".", "generator", "(", "x", ")", "\n", "loss", "=", "self", ".", "criterion", "(", "x", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "y", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ")", "/", "norm", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "opt", "is", "not", "None", ":", "\n", "            ", "self", ".", "opt", ".", "step", "(", ")", "\n", "self", ".", "opt", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "", "return", "loss", ".", "data", "[", "0", "]", "*", "norm", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_utils.LabelSmoothing.__init__": [[91, 99], ["torch.Module.__init__", "torch.KLDivLoss", "torch.KLDivLoss"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__"], ["def", "__init__", "(", "self", ",", "size", ",", "padding_idx", ",", "smoothing", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "LabelSmoothing", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "criterion", "=", "nn", ".", "KLDivLoss", "(", "size_average", "=", "False", ")", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "confidence", "=", "1.0", "-", "smoothing", "\n", "self", ".", "smoothing", "=", "smoothing", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "true_dist", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_utils.LabelSmoothing.forward": [[100, 111], ["x.data.clone", "x.data.clone.fill_", "x.data.clone.scatter_", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch_utils.LabelSmoothing.criterion", "x.size", "target.data.unsqueeze", "torch.nonzero.dim", "torch.nonzero.dim", "x.data.clone.index_fill_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.nonzero.squeeze", "torch.nonzero.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "target", ")", ":", "\n", "        ", "assert", "x", ".", "size", "(", "1", ")", "==", "self", ".", "size", "\n", "true_dist", "=", "x", ".", "data", ".", "clone", "(", ")", "\n", "true_dist", ".", "fill_", "(", "self", ".", "smoothing", "/", "(", "self", ".", "size", "-", "2", ")", ")", "\n", "true_dist", ".", "scatter_", "(", "1", ",", "target", ".", "data", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "confidence", ")", "\n", "true_dist", "[", ":", ",", "self", ".", "padding_idx", "]", "=", "0", "\n", "mask", "=", "torch", ".", "nonzero", "(", "target", ".", "data", "==", "self", ".", "padding_idx", ")", "\n", "if", "mask", ".", "dim", "(", ")", ">", "0", ":", "\n", "            ", "true_dist", ".", "index_fill_", "(", "0", ",", "mask", ".", "squeeze", "(", ")", ",", "0.0", ")", "\n", "", "self", ".", "true_dist", "=", "true_dist", "\n", "return", "self", ".", "criterion", "(", "x", ",", "Variable", "(", "true_dist", ",", "requires_grad", "=", "False", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_utils.gen_Z_f": [[7, 19], ["numpy.eye", "numpy.hstack", "numpy.vstack", "range", "numpy.zeros", "numpy.zeros"], "function", ["None"], ["def", "gen_Z_f", "(", "m", ",", "f", ",", "v", "=", "None", ")", ":", "\n", "    ", "if", "v", "is", "not", "None", ":", "\n", "        ", "assert", "v", ".", "size", "<=", "m", "-", "1", "\n", "", "I_m", "=", "np", ".", "eye", "(", "m", "-", "1", ",", "m", "-", "1", ")", "\n", "Z_f", "=", "np", ".", "hstack", "(", "(", "I_m", ",", "np", ".", "zeros", "(", "(", "m", "-", "1", ",", "1", ")", ")", ")", ")", "\n", "Z_f", "=", "np", ".", "vstack", "(", "(", "np", ".", "zeros", "(", "(", "1", ",", "m", ")", ")", ",", "Z_f", ")", ")", "\n", "Z_f", "[", "0", ",", "-", "1", "]", "=", "f", "\n", "if", "v", "is", "not", "None", ":", "\n", "        ", "for", "i", "in", "range", "(", "v", ".", "size", ")", ":", "\n", "            ", "Z_f", "[", "i", "+", "1", ",", "i", "]", "=", "v", "[", "i", "]", "\n", "\n", "", "", "return", "Z_f", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_utils.subsequent_mask": [[20, 25], ["numpy.triu().astype", "torch.from_numpy", "torch.from_numpy", "numpy.triu", "numpy.ones"], "function", ["None"], ["", "def", "subsequent_mask", "(", "size", ")", ":", "\n", "    ", "\"Mask out subsequent positions.\"", "\n", "attn_shape", "=", "(", "1", ",", "size", ",", "size", ")", "\n", "subsequent_mask", "=", "np", ".", "triu", "(", "np", ".", "ones", "(", "attn_shape", ")", ",", "k", "=", "1", ")", ".", "astype", "(", "'uint8'", ")", "\n", "return", "torch", ".", "from_numpy", "(", "subsequent_mask", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_utils.get_std_opt": [[53, 56], ["torch_utils.NoamOpt", "torch.optim.Adam", "torch.optim.Adam", "model.parameters"], "function", ["None"], ["", "", "def", "get_std_opt", "(", "model", ")", ":", "\n", "    ", "return", "NoamOpt", "(", "model", ".", "src_embed", "[", "0", "]", ".", "d_model", ",", "2", ",", "4000", ",", "\n", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "0", ",", "betas", "=", "(", "0.9", ",", "0.98", ")", ",", "eps", "=", "1e-9", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_utils.get_loss": [[58, 71], ["params.dataset_name.startswith", "torch.MSELoss", "params.dataset_name.startswith", "torch_utils.LabelSmoothing", "torch_utils.SimpleLossCompute", "torch.CrossEntropyLoss"], "function", ["None"], ["", "def", "get_loss", "(", "params", ",", "generator", "=", "None", ",", "model_opt", "=", "None", ")", ":", "\n", "    ", "loss_fn", "=", "None", "\n", "if", "params", ".", "dataset_name", ".", "startswith", "(", "'true'", ")", ":", "\n", "        ", "assert", "params", ".", "loss", "==", "'mse'", "\n", "loss_fn", "=", "nn", ".", "MSELoss", "(", ")", "\n", "", "elif", "params", ".", "dataset_name", ".", "startswith", "(", "'copy'", ")", ":", "\n", "        ", "assert", "params", ".", "loss", "==", "'label_smoothing'", "\n", "ls", "=", "LabelSmoothing", "(", "params", ".", "ls_size", ",", "params", ".", "ls_padding_idx", ",", "params", ".", "ls_smoothing", ")", "\n", "loss_fn", "=", "SimpleLossCompute", "(", "generator", ",", "ls", ",", "model_opt", ")", "\n", "", "else", ":", "\n", "        ", "assert", "params", ".", "loss", "==", "'cross_entropy'", "\n", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "", "return", "params", ".", "loss", ",", "loss_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.utils.torch_utils.compute_loss_and_accuracy": [[113, 135], ["torch.MSELoss", "nn.CrossEntropyLoss.", "torch.FloatTensor", "torch.FloatTensor", "torch.CrossEntropyLoss", "torch.max", "torch.max", "nn.CrossEntropyLoss.", "torch.max", "torch.max", "torch.eq", "torch.eq", "torch.mean", "torch.mean", "print", "torch.eq.float"], "function", ["None"], ["", "", "def", "compute_loss_and_accuracy", "(", "pred", ",", "true", ",", "loss_name", ")", ":", "\n", "    ", "if", "loss_name", "==", "'mse'", ":", "\n", "        ", "loss_fn", "=", "nn", ".", "MSELoss", "(", ")", "\n", "mse", "=", "loss_fn", "(", "pred", ",", "true", ")", "\n", "accuracy", "=", "torch", ".", "FloatTensor", "(", "[", "0", "]", ")", "\n", "\n", "return", "mse", ",", "accuracy", "\n", "\n", "", "elif", "loss_name", "==", "'cross_entropy'", ":", "\n", "        ", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "_", ",", "true_argmax", "=", "torch", ".", "max", "(", "true", ",", "1", ")", "\n", "cross_entropy", "=", "loss_fn", "(", "pred", ",", "true_argmax", ")", "\n", "\n", "_", ",", "pred_argmax", "=", "torch", ".", "max", "(", "pred", ",", "1", ")", "\n", "correct_prediction", "=", "torch", ".", "eq", "(", "true_argmax", ",", "pred_argmax", ")", "\n", "accuracy", "=", "torch", ".", "mean", "(", "correct_prediction", ".", "float", "(", ")", ")", "\n", "\n", "return", "cross_entropy", ",", "accuracy", "\n", "\n", "", "else", ":", "\n", "        ", "print", "(", "(", "'Not supported: '", ",", "loss_name", ")", ")", "\n", "assert", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.optimize_iwslt.tokenize_de": [[20, 22], ["spacy_de.tokenizer"], "function", ["None"], ["def", "tokenize_de", "(", "text", ")", ":", "\n", "    ", "return", "[", "tok", ".", "text", "for", "tok", "in", "spacy_de", ".", "tokenizer", "(", "text", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.optimize_iwslt.tokenize_en": [[23, 25], ["spacy_en.tokenizer"], "function", ["None"], ["", "def", "tokenize_en", "(", "text", ")", ":", "\n", "    ", "return", "[", "tok", ".", "text", "for", "tok", "in", "spacy_en", ".", "tokenizer", "(", "text", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.optimize_iwslt.create_src_tgt": [[26, 44], ["torchtext.data.Field", "torchtext.data.Field", "torchtext.datasets.IWSLT.splits", "data.Field.build_vocab", "data.Field.build_vocab", "len", "len", "vars", "vars"], "function", ["None"], ["", "def", "create_src_tgt", "(", ")", ":", "\n", "    ", "BOS_WORD", "=", "'<s>'", "\n", "EOS_WORD", "=", "'</s>'", "\n", "BLANK_WORD", "=", "\"<blank>\"", "\n", "SRC", "=", "data", ".", "Field", "(", "tokenize", "=", "tokenize_de", ",", "pad_token", "=", "BLANK_WORD", ")", "\n", "TGT", "=", "data", ".", "Field", "(", "tokenize", "=", "tokenize_en", ",", "init_token", "=", "BOS_WORD", ",", "\n", "eos_token", "=", "EOS_WORD", ",", "pad_token", "=", "BLANK_WORD", ")", "\n", "\n", "MAX_LEN", "=", "100", "\n", "train", ",", "val", ",", "test", "=", "datasets", ".", "IWSLT", ".", "splits", "(", "\n", "exts", "=", "(", "'.de'", ",", "'.en'", ")", ",", "fields", "=", "(", "SRC", ",", "TGT", ")", ",", "\n", "filter_pred", "=", "lambda", "x", ":", "len", "(", "vars", "(", "x", ")", "[", "'src'", "]", ")", "<=", "MAX_LEN", "and", "\n", "len", "(", "vars", "(", "x", ")", "[", "'trg'", "]", ")", "<=", "MAX_LEN", ")", "\n", "MIN_FREQ", "=", "2", "\n", "SRC", ".", "build_vocab", "(", "train", ".", "src", ",", "min_freq", "=", "MIN_FREQ", ")", "\n", "TGT", ".", "build_vocab", "(", "train", ".", "trg", ",", "min_freq", "=", "MIN_FREQ", ")", "\n", "\n", "return", "SRC", ",", "TGT", ",", "train", ",", "val", ",", "test", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.optimize_iwslt.run_epoch": [[46, 74], ["time.time", "enumerate", "model.forward", "loss_compute", "batch.src.cuda", "batch.trg.cuda", "batch.src_mask.cuda", "batch.trg_mask.cuda", "print", "time.time", "losses.append", "time.time"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.forward"], ["", "def", "run_epoch", "(", "data_iter", ",", "model", ",", "loss_compute", ")", ":", "\n", "    ", "\"Standard Training and Logging Function\"", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "total_tokens", "=", "0", "\n", "total_loss", "=", "0", "\n", "tokens", "=", "0", "\n", "losses", "=", "[", "]", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "data_iter", ")", ":", "\n", "        ", "batch", ".", "src", ",", "batch", ".", "trg", ",", "batch", ".", "src_mask", ",", "batch", ".", "trg_mask", "=", "batch", ".", "src", ".", "cuda", "(", ")", ",", "batch", ".", "trg", ".", "cuda", "(", ")", ",", "batch", ".", "src_mask", ".", "cuda", "(", ")", ",", "batch", ".", "trg_mask", ".", "cuda", "(", ")", "\n", "#print('batch.src:', batch.src)", "\n", "#print('batch.trg: ', batch.trg)", "\n", "#print('batch.src_mask: ', batch.src_mask)", "\n", "#print('batch.trg_mask: ', batch.trg_mask)", "\n", "#quit()", "\n", "out", "=", "model", ".", "forward", "(", "batch", ".", "src", ",", "batch", ".", "trg", ",", "\n", "batch", ".", "src_mask", ",", "batch", ".", "trg_mask", ")", "\n", "loss", "=", "loss_compute", "(", "out", ",", "batch", ".", "trg_y", ",", "batch", ".", "ntokens", ")", "\n", "total_loss", "+=", "loss", "\n", "total_tokens", "+=", "batch", ".", "ntokens", "\n", "tokens", "+=", "batch", ".", "ntokens", "\n", "if", "i", "%", "50", "==", "1", ":", "\n", "            ", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start", "\n", "print", "(", "(", "\"Epoch Step: %d Loss: %f Tokens per Sec: %f\"", "%", "\n", "(", "i", ",", "loss", "/", "batch", ".", "ntokens", ",", "tokens", "/", "elapsed", ")", ")", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "tokens", "=", "0", "\n", "losses", ".", "append", "(", "loss", "/", "batch", ".", "ntokens", ")", "\n", "", "", "return", "total_loss", "/", "total_tokens", ",", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.optimize_iwslt.compute_bleu": [[75, 93], ["enumerate", "greedy_decode", "print", "range", "print", "print", "range", "print", "batch.src.transpose", "greedy_decode.size", "print", "batch.trg.size", "print"], "function", ["None"], ["", "def", "compute_bleu", "(", "model", ")", ":", "\n", "    ", "for", "i", ",", "batch", "in", "enumerate", "(", "valid_iter", ")", ":", "\n", "        ", "src", "=", "batch", ".", "src", ".", "transpose", "(", "0", ",", "1", ")", "[", ":", "1", "]", "\n", "src_mask", "=", "(", "src", "!=", "SRC", ".", "vocab", ".", "stoi", "[", "\"<blank>\"", "]", ")", ".", "unsqueeze", "(", "-", "2", ")", "\n", "out", "=", "greedy_decode", "(", "model", ",", "src", ",", "src_mask", ",", "max_len", "=", "60", ",", "start_symbol", "=", "TGT", ".", "vocab", ".", "stoi", "[", "\"<s>\"", "]", ")", "\n", "print", "(", "\"Translation:\"", ",", "end", "=", "\"\\t\"", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "out", ".", "size", "(", "1", ")", ")", ":", "\n", "            ", "sym", "=", "TGT", ".", "vocab", ".", "itos", "[", "out", "[", "0", ",", "i", "]", "]", "\n", "if", "sym", "==", "\"</s>\"", ":", "break", "\n", "print", "(", "sym", ",", "end", "=", "\" \"", ")", "\n", "", "print", "(", ")", "\n", "print", "(", "\"Target:\"", ",", "end", "=", "\"\\t\"", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "batch", ".", "trg", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "sym", "=", "TGT", ".", "vocab", ".", "itos", "[", "batch", ".", "trg", ".", "data", "[", "i", ",", "0", "]", "]", "\n", "if", "sym", "==", "\"</s>\"", ":", "break", "\n", "print", "(", "sym", ",", "end", "=", "\" \"", ")", "\n", "", "print", "(", ")", "\n", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.optimize_iwslt.optimize_iwslt": [[94, 159], ["optimize_iwslt.create_src_tgt", "attention.make_model", "attention.make_model.cuda", "print", "attention.make_model.named_parameters", "tensorboardX.SummaryWriter", "LabelSmoothing", "LabelSmoothing.cuda", "MyIterator", "MyIterator", "NoamOpt", "range", "tensorboardX.SummaryWriter.export_scalars_to_json", "tensorboardX.SummaryWriter.close", "len", "len", "torch.cuda.get_device_name", "torch.cuda.get_device_name", "torch.optim.Adam", "torch.optim.Adam", "attention.make_model.train", "optimize_iwslt.run_epoch", "print", "tensorboardX.SummaryWriter.add_scalar", "attention.make_model.eval", "optimize_iwslt.run_epoch", "print", "tensorboardX.SummaryWriter.add_scalar", "print", "os.path.join", "print", "len", "attention.make_model.parameters", "SimpleLossCompute", "SimpleLossCompute", "rebatch", "rebatch", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.optimize_iwslt.create_src_tgt", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.make_model", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.train.train", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.optimize_nmt.run_epoch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.optimize_nmt.run_epoch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.rebatch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.rebatch"], ["", "", "def", "optimize_iwslt", "(", "dataset", ",", "params", ")", ":", "\n", "\t", "SRC", ",", "TGT", ",", "train", ",", "val", ",", "test", "=", "create_src_tgt", "(", ")", "\n", "pad_idx", "=", "TGT", ".", "vocab", ".", "stoi", "[", "\"<blank>\"", "]", "\n", "model", "=", "make_model", "(", "params", ",", "len", "(", "SRC", ".", "vocab", ")", ",", "len", "(", "TGT", ".", "vocab", ")", ",", "N", "=", "1", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "\n", "print", "(", "(", "torch", ".", "cuda", ".", "get_device_name", "(", "0", ")", ")", ")", "\n", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "\t    ", "if", "param", ".", "requires_grad", ":", "\n", "\t        ", "print", "(", "(", "'Parameter name, shape: '", ",", "name", ",", "param", ".", "data", ".", "shape", ")", ")", "\n", "\n", "", "", "writer", "=", "SummaryWriter", "(", "params", ".", "log_path", ")", "\n", "losses", "=", "{", "'train'", ":", "[", "]", ",", "'val'", ":", "[", "]", ",", "'DR'", ":", "[", "]", ",", "'ratio'", ":", "[", "]", "}", "\n", "accuracies", "=", "{", "'train'", ":", "[", "]", ",", "'val'", ":", "[", "]", "}", "\n", "criterion", "=", "LabelSmoothing", "(", "size", "=", "len", "(", "TGT", ".", "vocab", ")", ",", "padding_idx", "=", "pad_idx", ",", "smoothing", "=", "0.1", ")", "\n", "criterion", ".", "cuda", "(", ")", "\n", "train_iter", "=", "MyIterator", "(", "train", ",", "batch_size", "=", "params", ".", "batch_size", ",", "device", "=", "0", ",", "\n", "repeat", "=", "False", ",", "sort_key", "=", "lambda", "x", ":", "(", "len", "(", "x", ".", "src", ")", ",", "len", "(", "x", ".", "trg", ")", ")", ",", "\n", "batch_size_fn", "=", "batch_size_fn", ",", "train", "=", "True", ")", "\n", "valid_iter", "=", "MyIterator", "(", "val", ",", "batch_size", "=", "params", ".", "batch_size", ",", "device", "=", "0", ",", "\n", "repeat", "=", "False", ",", "sort_key", "=", "lambda", "x", ":", "(", "len", "(", "x", ".", "src", ")", ",", "len", "(", "x", ".", "trg", ")", ")", ",", "\n", "batch_size_fn", "=", "batch_size_fn", ",", "train", "=", "False", ")", "\n", "\n", "\n", "model_opt", "=", "NoamOpt", "(", "model", ".", "src_embed", "[", "0", "]", ".", "d_model", ",", "1", ",", "2000", ",", "\n", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "0", ",", "betas", "=", "(", "0.9", ",", "0.98", ")", ",", "eps", "=", "1e-9", ")", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "params", ".", "steps", ")", ":", "\n", "\t\t", "model", ".", "train", "(", ")", "\n", "train_total_loss_fraction", ",", "train_losses", "=", "run_epoch", "(", "(", "rebatch", "(", "pad_idx", ",", "b", ")", "for", "b", "in", "train_iter", ")", ",", "\n", "model", ",", "\n", "SimpleLossCompute", "(", "model", ".", "generator", ",", "criterion", ",", "model_opt", ")", ")", "\n", "losses", "[", "'train'", "]", "+=", "train_losses", "\n", "print", "(", "'Train, epoch: '", ",", "train_total_loss_fraction", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'Train/Loss'", ",", "train_total_loss_fraction", ",", "epoch", ")", "\n", "model", ".", "eval", "(", ")", "\n", "val_total_loss_fraction", ",", "val_losses", "=", "run_epoch", "(", "(", "rebatch", "(", "pad_idx", ",", "b", ")", "for", "b", "in", "valid_iter", ")", ",", "\n", "model", ",", "\n", "SimpleLossCompute", "(", "model", ".", "generator", ",", "criterion", ",", "None", ")", ")", "\n", "losses", "[", "'val'", "]", "+=", "val_losses", "\n", "print", "(", "'Val, epoch: '", ",", "val_total_loss_fraction", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'Val/Loss'", ",", "val_total_loss_fraction", ",", "epoch", ")", "\n", "print", "(", "loss", ")", "\n", "\n", "", "\"\"\"\n\tlosses['train'] += train_losses\n\tprint('Train, epoch: ', train_total_loss_fraction, epoch)\n\twriter.add_scalar('Train/Loss', train_total_loss_fraction, epoch)\n\tval_total_loss_fraction, val_losses = run_epoch(writer, data_gen(V, 30, 5), model, \n\t\t    SimpleLossCompute(model.generator, criterion, None))\n\tlosses['val'] += val_losses\n\tprint('Val, epoch: ', val_total_loss_fraction, epoch)\n\twriter.add_scalar('Val/Loss', val_total_loss_fraction, epoch)\n\n\t# Checkpoint\n\tsave_path = os.path.join(params.checkpoint_path, str(epoch))\n\twith open(save_path, 'wb') as f: \n\ttorch.save(model.state_dict(), f)\n\tprint((\"Model saved in file: %s\" % save_path))\n\t\"\"\"", "\n", "\n", "writer", ".", "export_scalars_to_json", "(", "os", ".", "path", ".", "join", "(", "params", ".", "log_path", ",", "\"all_scalars.json\"", ")", ")", "\n", "writer", ".", "close", "(", ")", "\n", "return", "losses", ",", "accuracies", "\n", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.MultiGPULossCompute.__init__": [[15, 23], ["torch.parallel.replicate", "torch.parallel.replicate", "torch.parallel.replicate"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "generator", ",", "criterion", ",", "devices", ",", "opt", "=", "None", ",", "chunk_size", "=", "5", ")", ":", "\n", "# Send out to different gpus.", "\n", "        ", "self", ".", "generator", "=", "generator", "\n", "self", ".", "criterion", "=", "nn", ".", "parallel", ".", "replicate", "(", "criterion", ",", "\n", "devices", "=", "devices", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "devices", "=", "devices", "\n", "self", ".", "chunk_size", "=", "chunk_size", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.MultiGPULossCompute.__call__": [[24, 71], ["torch.parallel.replicate", "torch.parallel.replicate", "torch.parallel.replicate", "torch.parallel.scatter", "torch.parallel.scatter", "torch.parallel.scatter", "torch.parallel.scatter", "torch.parallel.scatter", "torch.parallel.scatter", "range", "out_scatter[].size", "torch.parallel.parallel_apply", "torch.parallel.parallel_apply", "torch.parallel.parallel_apply", "torch.parallel.parallel_apply", "torch.parallel.parallel_apply", "torch.parallel.parallel_apply", "torch.parallel.gather", "torch.parallel.gather", "torch.parallel.gather", "torch.parallel.gather", "torch.parallel.gather", "torch.parallel.gather", "o1.backward", "train.MultiGPULossCompute.opt.step", "train.MultiGPULossCompute.opt.optimizer.zero_grad", "torch.parallel.gather.backward", "enumerate", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "g.contiguous().view", "t[].contiguous().view", "zip", "torch.parallel.gather.sum", "out_grad[].append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "g.size", "[].grad.data.clone", "g.contiguous", "t[].contiguous"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.CycleDownMultCuda.backward", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.NoamOpt.step", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.CycleDownMultCuda.backward"], ["", "def", "__call__", "(", "self", ",", "out", ",", "targets", ",", "normalize", ")", ":", "\n", "        ", "total", "=", "0.0", "\n", "generator", "=", "nn", ".", "parallel", ".", "replicate", "(", "self", ".", "generator", ",", "\n", "devices", "=", "self", ".", "devices", ")", "\n", "out_scatter", "=", "nn", ".", "parallel", ".", "scatter", "(", "out", ",", "\n", "target_gpus", "=", "self", ".", "devices", ")", "\n", "out_grad", "=", "[", "[", "]", "for", "_", "in", "out_scatter", "]", "\n", "targets", "=", "nn", ".", "parallel", ".", "scatter", "(", "targets", ",", "\n", "target_gpus", "=", "self", ".", "devices", ")", "\n", "\n", "# Divide generating into chunks.", "\n", "chunk_size", "=", "self", ".", "chunk_size", "\n", "for", "i", "in", "range", "(", "0", ",", "out_scatter", "[", "0", "]", ".", "size", "(", "1", ")", ",", "chunk_size", ")", ":", "\n", "# Predict distributions", "\n", "            ", "out_column", "=", "[", "[", "Variable", "(", "o", "[", ":", ",", "i", ":", "i", "+", "chunk_size", "]", ".", "data", ",", "\n", "requires_grad", "=", "self", ".", "opt", "is", "not", "None", ")", "]", "\n", "for", "o", "in", "out_scatter", "]", "\n", "gen", "=", "nn", ".", "parallel", ".", "parallel_apply", "(", "generator", ",", "out_column", ")", "\n", "\n", "# Compute loss. ", "\n", "y", "=", "[", "(", "g", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "g", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "t", "[", ":", ",", "i", ":", "i", "+", "chunk_size", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ")", "\n", "for", "g", ",", "t", "in", "zip", "(", "gen", ",", "targets", ")", "]", "\n", "loss", "=", "nn", ".", "parallel", ".", "parallel_apply", "(", "self", ".", "criterion", ",", "y", ")", "\n", "\n", "# Sum and normalize loss", "\n", "l", "=", "nn", ".", "parallel", ".", "gather", "(", "loss", ",", "\n", "target_device", "=", "self", ".", "devices", "[", "0", "]", ")", "\n", "l", "=", "l", ".", "sum", "(", ")", "[", "0", "]", "/", "normalize", "\n", "total", "+=", "l", ".", "data", "[", "0", "]", "\n", "\n", "# Backprop loss to output of transformer", "\n", "if", "self", ".", "opt", "is", "not", "None", ":", "\n", "                ", "l", ".", "backward", "(", ")", "\n", "for", "j", ",", "l", "in", "enumerate", "(", "loss", ")", ":", "\n", "                    ", "out_grad", "[", "j", "]", ".", "append", "(", "out_column", "[", "j", "]", "[", "0", "]", ".", "grad", ".", "data", ".", "clone", "(", ")", ")", "\n", "\n", "# Backprop all loss through transformer.            ", "\n", "", "", "", "if", "self", ".", "opt", "is", "not", "None", ":", "\n", "            ", "out_grad", "=", "[", "Variable", "(", "torch", ".", "cat", "(", "og", ",", "dim", "=", "1", ")", ")", "for", "og", "in", "out_grad", "]", "\n", "o1", "=", "out", "\n", "o2", "=", "nn", ".", "parallel", ".", "gather", "(", "out_grad", ",", "\n", "target_device", "=", "self", ".", "devices", "[", "0", "]", ")", "\n", "o1", ".", "backward", "(", "gradient", "=", "o2", ")", "\n", "self", ".", "opt", ".", "step", "(", ")", "\n", "self", ".", "opt", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "", "return", "total", "*", "normalize", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.MyIterator.create_batches": [[73, 89], ["train.MyIterator.create_batches.pool"], "methods", ["None"], ["    ", "def", "create_batches", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "train", ":", "\n", "            ", "def", "pool", "(", "d", ",", "random_shuffler", ")", ":", "\n", "                ", "for", "p", "in", "data", ".", "batch", "(", "d", ",", "self", ".", "batch_size", "*", "100", ")", ":", "\n", "                    ", "p_batch", "=", "data", ".", "batch", "(", "\n", "sorted", "(", "p", ",", "key", "=", "self", ".", "sort_key", ")", ",", "\n", "self", ".", "batch_size", ",", "self", ".", "batch_size_fn", ")", "\n", "for", "b", "in", "random_shuffler", "(", "list", "(", "p_batch", ")", ")", ":", "\n", "                        ", "yield", "b", "\n", "", "", "", "self", ".", "batches", "=", "pool", "(", "self", ".", "data", "(", ")", ",", "self", ".", "random_shuffler", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "batches", "=", "[", "]", "\n", "for", "b", "in", "data", ".", "batch", "(", "self", ".", "data", "(", ")", ",", "self", ".", "batch_size", ",", "\n", "self", ".", "batch_size_fn", ")", ":", "\n", "                ", "self", ".", "batches", ".", "append", "(", "sorted", "(", "b", ",", "key", "=", "self", ".", "sort_key", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.LabelSmoothing.__init__": [[97, 105], ["torch.Module.__init__", "torch.KLDivLoss", "torch.KLDivLoss", "torch.KLDivLoss"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__"], ["def", "__init__", "(", "self", ",", "size", ",", "padding_idx", ",", "smoothing", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "LabelSmoothing", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "criterion", "=", "nn", ".", "KLDivLoss", "(", "size_average", "=", "False", ")", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "confidence", "=", "1.0", "-", "smoothing", "\n", "self", ".", "smoothing", "=", "smoothing", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "true_dist", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.LabelSmoothing.forward": [[106, 117], ["x.data.clone", "x.data.clone.fill_", "x.data.clone.scatter_", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero", "train.LabelSmoothing.criterion", "x.size", "target.data.unsqueeze", "torch.nonzero.dim", "torch.nonzero.dim", "torch.nonzero.dim", "x.data.clone.index_fill_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.nonzero.squeeze", "torch.nonzero.squeeze", "torch.nonzero.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "target", ")", ":", "\n", "        ", "assert", "x", ".", "size", "(", "1", ")", "==", "self", ".", "size", "\n", "true_dist", "=", "x", ".", "data", ".", "clone", "(", ")", "\n", "true_dist", ".", "fill_", "(", "self", ".", "smoothing", "/", "(", "self", ".", "size", "-", "2", ")", ")", "\n", "true_dist", ".", "scatter_", "(", "1", ",", "target", ".", "data", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "confidence", ")", "\n", "true_dist", "[", ":", ",", "self", ".", "padding_idx", "]", "=", "0", "\n", "mask", "=", "torch", ".", "nonzero", "(", "target", ".", "data", "==", "self", ".", "padding_idx", ")", "\n", "if", "mask", ".", "dim", "(", ")", ">", "0", ":", "\n", "            ", "true_dist", ".", "index_fill_", "(", "0", ",", "mask", ".", "squeeze", "(", ")", ",", "0.0", ")", "\n", "", "self", ".", "true_dist", "=", "true_dist", "\n", "return", "self", ".", "criterion", "(", "x", ",", "Variable", "(", "true_dist", ",", "requires_grad", "=", "False", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.Batch.__init__": [[120, 129], ["train.Batch.make_std_mask"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.Batch.make_std_mask"], ["def", "__init__", "(", "self", ",", "src", ",", "trg", "=", "None", ",", "pad", "=", "0", ")", ":", "\n", "        ", "self", ".", "src", "=", "src", "\n", "self", ".", "src_mask", "=", "(", "src", "!=", "pad", ")", ".", "unsqueeze", "(", "-", "2", ")", "\n", "if", "trg", "is", "not", "None", ":", "\n", "            ", "self", ".", "trg", "=", "trg", "[", ":", ",", ":", "-", "1", "]", "\n", "self", ".", "trg_y", "=", "trg", "[", ":", ",", "1", ":", "]", "\n", "self", ".", "trg_mask", "=", "self", ".", "make_std_mask", "(", "self", ".", "trg", ",", "pad", ")", "\n", "self", ".", "ntokens", "=", "(", "self", ".", "trg_y", "!=", "pad", ")", ".", "data", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.Batch.make_std_mask": [[130, 137], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "attention.attention.subsequent_mask().type_as", "attention.attention.subsequent_mask", "tgt.size"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.subsequent_mask"], ["", "", "@", "staticmethod", "\n", "def", "make_std_mask", "(", "tgt", ",", "pad", ")", ":", "\n", "        ", "\"Create a mask to hide padding and future words.\"", "\n", "tgt_mask", "=", "(", "tgt", "!=", "pad", ")", ".", "unsqueeze", "(", "-", "2", ")", "\n", "tgt_mask", "=", "tgt_mask", "&", "Variable", "(", "\n", "subsequent_mask", "(", "tgt", ".", "size", "(", "-", "1", ")", ")", ".", "type_as", "(", "tgt_mask", ".", "data", ")", ")", "\n", "return", "tgt_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.NoamOpt.__init__": [[174, 181], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model_size", ",", "factor", ",", "warmup", ",", "optimizer", ")", ":", "\n", "        ", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "_step", "=", "0", "\n", "self", ".", "warmup", "=", "warmup", "\n", "self", ".", "factor", "=", "factor", "\n", "self", ".", "model_size", "=", "model_size", "\n", "self", ".", "_rate", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.NoamOpt.step": [[182, 190], ["train.NoamOpt.rate", "train.NoamOpt.optimizer.step"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.NoamOpt.rate", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.NoamOpt.step"], ["", "def", "step", "(", "self", ")", ":", "\n", "        ", "\"Update parameters and rate\"", "\n", "self", ".", "_step", "+=", "1", "\n", "rate", "=", "self", ".", "rate", "(", ")", "\n", "for", "p", "in", "self", ".", "optimizer", ".", "param_groups", ":", "\n", "            ", "p", "[", "'lr'", "]", "=", "rate", "\n", "", "self", ".", "_rate", "=", "rate", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.NoamOpt.rate": [[191, 198], ["min"], "methods", ["None"], ["", "def", "rate", "(", "self", ",", "step", "=", "None", ")", ":", "\n", "        ", "\"Implement `lrate` above\"", "\n", "if", "step", "is", "None", ":", "\n", "            ", "step", "=", "self", ".", "_step", "\n", "", "return", "self", ".", "factor", "*", "(", "self", ".", "model_size", "**", "(", "-", "0.5", ")", "*", "\n", "min", "(", "step", "**", "(", "-", "0.5", ")", ",", "step", "*", "self", ".", "warmup", "**", "(", "-", "1.5", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.SimpleLossCompute.__init__": [[214, 218], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "generator", ",", "criterion", ",", "opt", "=", "None", ")", ":", "\n", "        ", "self", ".", "generator", "=", "generator", "\n", "self", ".", "criterion", "=", "criterion", "\n", "self", ".", "opt", "=", "opt", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.SimpleLossCompute.__call__": [[219, 228], ["train.SimpleLossCompute.generator", "loss.backward", "train.SimpleLossCompute.criterion", "train.SimpleLossCompute.opt.step", "train.SimpleLossCompute.opt.optimizer.zero_grad", "train.SimpleLossCompute.contiguous().view", "y.contiguous().view", "train.SimpleLossCompute.size", "train.SimpleLossCompute.contiguous", "y.contiguous"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.CycleDownMultCuda.backward", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.NoamOpt.step"], ["", "def", "__call__", "(", "self", ",", "x", ",", "y", ",", "norm", ")", ":", "\n", "        ", "x", "=", "self", ".", "generator", "(", "x", ")", "\n", "loss", "=", "self", ".", "criterion", "(", "x", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "y", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ")", "/", "norm", "\n", "loss", ".", "backward", "(", ")", "\n", "if", "self", ".", "opt", "is", "not", "None", ":", "\n", "            ", "self", ".", "opt", ".", "step", "(", ")", "\n", "self", ".", "opt", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "", "return", "loss", ".", "data", "[", "0", "]", "*", "norm", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.rebatch": [[90, 94], ["train.Batch", "batch.src.transpose", "batch.trg.transpose"], "function", ["None"], ["", "", "", "", "def", "rebatch", "(", "pad_idx", ",", "batch", ")", ":", "\n", "    ", "\"Fix order in torchtext to match ours\"", "\n", "src", ",", "trg", "=", "batch", ".", "src", ".", "transpose", "(", "0", ",", "1", ")", ",", "batch", ".", "trg", ".", "transpose", "(", "0", ",", "1", ")", "\n", "return", "Batch", "(", "src", ",", "trg", ",", "pad_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.run_epoch": [[138, 158], ["time.time", "enumerate", "model.forward", "loss_compute", "print", "time.time", "time.time"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.forward"], ["", "", "def", "run_epoch", "(", "data_iter", ",", "model", ",", "loss_compute", ")", ":", "\n", "    ", "\"Standard Training and Logging Function\"", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "total_tokens", "=", "0", "\n", "total_loss", "=", "0", "\n", "tokens", "=", "0", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "data_iter", ")", ":", "\n", "        ", "out", "=", "model", ".", "forward", "(", "batch", ".", "src", ",", "batch", ".", "trg", ",", "\n", "batch", ".", "src_mask", ",", "batch", ".", "trg_mask", ")", "\n", "loss", "=", "loss_compute", "(", "out", ",", "batch", ".", "trg_y", ",", "batch", ".", "ntokens", ")", "\n", "total_loss", "+=", "loss", "\n", "total_tokens", "+=", "batch", ".", "ntokens", "\n", "tokens", "+=", "batch", ".", "ntokens", "\n", "if", "i", "%", "50", "==", "1", ":", "\n", "            ", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start", "\n", "print", "(", "(", "\"Epoch Step: %d Loss: %f Tokens per Sec: %f\"", "%", "\n", "(", "i", ",", "loss", "/", "batch", ".", "ntokens", ",", "tokens", "/", "elapsed", ")", ")", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "tokens", "=", "0", "\n", "", "", "return", "total_loss", "/", "total_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.batch_size_fn": [[160, 171], ["max", "max", "max", "len", "len"], "function", ["None"], ["def", "batch_size_fn", "(", "new", ",", "count", ",", "sofar", ")", ":", "\n", "    ", "\"Keep augmenting batch and calculate total number of tokens + padding.\"", "\n", "global", "max_src_in_batch", ",", "max_tgt_in_batch", "\n", "if", "count", "==", "1", ":", "\n", "        ", "max_src_in_batch", "=", "0", "\n", "max_tgt_in_batch", "=", "0", "\n", "", "max_src_in_batch", "=", "max", "(", "max_src_in_batch", ",", "len", "(", "new", ".", "src", ")", ")", "\n", "max_tgt_in_batch", "=", "max", "(", "max_tgt_in_batch", ",", "len", "(", "new", ".", "trg", ")", "+", "2", ")", "\n", "src_elements", "=", "count", "*", "max_src_in_batch", "\n", "tgt_elements", "=", "count", "*", "max_tgt_in_batch", "\n", "return", "max", "(", "src_elements", ",", "tgt_elements", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.get_std_opt": [[199, 202], ["train.NoamOpt", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "model.parameters"], "function", ["None"], ["", "", "def", "get_std_opt", "(", "model", ")", ":", "\n", "    ", "return", "NoamOpt", "(", "model", ".", "src_embed", "[", "0", "]", ".", "d_model", ",", "2", ",", "4000", ",", "\n", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "0", ",", "betas", "=", "(", "0.9", ",", "0.98", ")", ",", "eps", "=", "1e-9", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.data_gen": [[203, 211], ["range", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.autograd.Variable", "torch.autograd.Variable", "numpy.random.randint", "train.Batch"], "function", ["None"], ["", "def", "data_gen", "(", "V", ",", "batch", ",", "nbatches", ")", ":", "\n", "    ", "\"Generate random data for a src-tgt copy task.\"", "\n", "for", "i", "in", "range", "(", "nbatches", ")", ":", "\n", "        ", "data", "=", "torch", ".", "from_numpy", "(", "np", ".", "random", ".", "randint", "(", "1", ",", "V", ",", "size", "=", "(", "batch", ",", "10", ")", ")", ")", "\n", "data", "[", ":", ",", "0", "]", "=", "1", "\n", "src", "=", "Variable", "(", "data", ",", "requires_grad", "=", "False", ")", "\n", "tgt", "=", "Variable", "(", "data", ",", "requires_grad", "=", "False", ")", "\n", "yield", "Batch", "(", "src", ",", "tgt", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.EncoderDecoder.__init__": [[20, 27], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__"], ["def", "__init__", "(", "self", ",", "encoder", ",", "decoder", ",", "src_embed", ",", "tgt_embed", ",", "generator", ")", ":", "\n", "        ", "super", "(", "EncoderDecoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "encoder", "=", "encoder", "\n", "self", ".", "decoder", "=", "decoder", "\n", "self", ".", "src_embed", "=", "src_embed", "\n", "self", ".", "tgt_embed", "=", "tgt_embed", "\n", "self", ".", "generator", "=", "generator", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.EncoderDecoder.forward": [[28, 32], ["attention.EncoderDecoder.decode", "attention.EncoderDecoder.encode"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.EncoderDecoder.decode", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.EncoderDecoder.encode"], ["", "def", "forward", "(", "self", ",", "src", ",", "tgt", ",", "src_mask", ",", "tgt_mask", ")", ":", "\n", "        ", "\"Take in and process masked src and target sequences.\"", "\n", "return", "self", ".", "decode", "(", "self", ".", "encode", "(", "src", ",", "src_mask", ")", ",", "src_mask", ",", "\n", "tgt", ",", "tgt_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.EncoderDecoder.encode": [[33, 35], ["attention.EncoderDecoder.encoder", "attention.EncoderDecoder.src_embed"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "src", ",", "src_mask", ")", ":", "\n", "        ", "return", "self", ".", "encoder", "(", "self", ".", "src_embed", "(", "src", ")", ",", "src_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.EncoderDecoder.decode": [[36, 38], ["attention.EncoderDecoder.decoder", "attention.EncoderDecoder.tgt_embed"], "methods", ["None"], ["", "def", "decode", "(", "self", ",", "memory", ",", "src_mask", ",", "tgt", ",", "tgt_mask", ")", ":", "\n", "        ", "return", "self", ".", "decoder", "(", "self", ".", "tgt_embed", "(", "tgt", ")", ",", "memory", ",", "src_mask", ",", "tgt_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.Generator.__init__": [[41, 44], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "vocab", ")", ":", "\n", "        ", "super", "(", "Generator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "proj", "=", "nn", ".", "Linear", "(", "d_model", ",", "vocab", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.Generator.forward": [[45, 47], ["torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "attention.Generator.proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "F", ".", "log_softmax", "(", "self", ".", "proj", "(", "x", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.Encoder.__init__": [[54, 58], ["torch.Module.__init__", "attention.clones", "attention.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.clones"], ["def", "__init__", "(", "self", ",", "layer", ",", "N", ")", ":", "\n", "        ", "super", "(", "Encoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "clones", "(", "layer", ",", "N", ")", "\n", "self", ".", "norm", "=", "LayerNorm", "(", "layer", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.Encoder.forward": [[59, 64], ["attention.Encoder.norm", "layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ")", ":", "\n", "        ", "\"Pass the input (and mask) through each layer in turn.\"", "\n", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "layer", "(", "x", ",", "mask", ")", "\n", "", "return", "self", ".", "norm", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.LayerNorm.__init__": [[67, 72], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__"], ["def", "__init__", "(", "self", ",", "features", ",", "eps", "=", "1e-6", ")", ":", "\n", "        ", "super", "(", "LayerNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "a_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "features", ")", ")", "\n", "self", ".", "b_2", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "features", ")", ")", "\n", "self", ".", "eps", "=", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.LayerNorm.forward": [[73, 77], ["x.mean", "x.std"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "mean", "=", "x", ".", "mean", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "std", "=", "x", ".", "std", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "self", ".", "a_2", "*", "(", "x", "-", "mean", ")", "/", "(", "std", "+", "self", ".", "eps", ")", "+", "self", ".", "b_2", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.SublayerConnection.__init__": [[83, 87], ["torch.Module.__init__", "attention.LayerNorm", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__"], ["def", "__init__", "(", "self", ",", "size", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "SublayerConnection", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "norm", "=", "LayerNorm", "(", "size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.SublayerConnection.forward": [[88, 91], ["attention.SublayerConnection.dropout", "sublayer", "attention.SublayerConnection.norm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "sublayer", ")", ":", "\n", "        ", "\"Apply residual connection to any sublayer with the same size.\"", "\n", "return", "x", "+", "self", ".", "dropout", "(", "sublayer", "(", "self", ".", "norm", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.EncoderLayer.__init__": [[94, 100], ["torch.Module.__init__", "attention.clones", "attention.SublayerConnection"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.clones"], ["def", "__init__", "(", "self", ",", "size", ",", "self_attn", ",", "feed_forward", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "EncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self_attn", "=", "self_attn", "\n", "self", ".", "feed_forward", "=", "feed_forward", "\n", "self", ".", "sublayer", "=", "clones", "(", "SublayerConnection", "(", "size", ",", "dropout", ")", ",", "2", ")", "\n", "self", ".", "size", "=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.EncoderLayer.forward": [[101, 105], ["attention.EncoderLayer.self_attn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "mask", ")", ":", "\n", "        ", "\"Follow Figure 1 (left) for connections.\"", "\n", "x", "=", "self", ".", "sublayer", "[", "0", "]", "(", "x", ",", "lambda", "x", ":", "self", ".", "self_attn", "(", "x", ",", "x", ",", "x", ",", "mask", ")", ")", "\n", "return", "self", ".", "sublayer", "[", "1", "]", "(", "x", ",", "self", ".", "feed_forward", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.Decoder.__init__": [[108, 112], ["torch.Module.__init__", "attention.clones", "attention.LayerNorm"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.clones"], ["def", "__init__", "(", "self", ",", "layer", ",", "N", ")", ":", "\n", "        ", "super", "(", "Decoder", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "clones", "(", "layer", ",", "N", ")", "\n", "self", ".", "norm", "=", "LayerNorm", "(", "layer", ".", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.Decoder.forward": [[113, 117], ["attention.Decoder.norm", "layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "memory", ",", "src_mask", ",", "tgt_mask", ")", ":", "\n", "        ", "for", "layer", "in", "self", ".", "layers", ":", "\n", "            ", "x", "=", "layer", "(", "x", ",", "memory", ",", "src_mask", ",", "tgt_mask", ")", "\n", "", "return", "self", ".", "norm", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.DecoderLayer.__init__": [[120, 129], ["torch.Module.__init__", "print", "print", "attention.clones", "attention.SublayerConnection"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.clones"], ["def", "__init__", "(", "self", ",", "size", ",", "self_attn", ",", "src_attn", ",", "feed_forward", ",", "dropout", ")", ":", "\n", "        ", "super", "(", "DecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "self_attn", "=", "self_attn", "\n", "self", ".", "src_attn", "=", "src_attn", "\n", "print", "(", "'self_atten: '", ",", "self_attn", ")", "\n", "print", "(", "'src_attn:'", ",", "src_attn", ")", "\n", "self", ".", "feed_forward", "=", "feed_forward", "\n", "self", ".", "sublayer", "=", "clones", "(", "SublayerConnection", "(", "size", ",", "dropout", ")", ",", "3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.DecoderLayer.forward": [[130, 136], ["attention.DecoderLayer.self_attn", "attention.DecoderLayer.src_attn"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "memory", ",", "src_mask", ",", "tgt_mask", ")", ":", "\n", "        ", "\"Follow Figure 1 (right) for connections.\"", "\n", "m", "=", "memory", "\n", "x", "=", "self", ".", "sublayer", "[", "0", "]", "(", "x", ",", "lambda", "x", ":", "self", ".", "self_attn", "(", "x", ",", "x", ",", "x", ",", "tgt_mask", ")", ")", "\n", "x", "=", "self", ".", "sublayer", "[", "1", "]", "(", "x", ",", "lambda", "x", ":", "self", ".", "src_attn", "(", "x", ",", "m", ",", "m", ",", "src_mask", ")", ")", "\n", "return", "self", ".", "sublayer", "[", "2", "]", "(", "x", ",", "self", ".", "feed_forward", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.MultiHeadedAttention.__init__": [[156, 171], ["torch.Module.__init__", "print", "torch.Dropout", "torch.Dropout", "torch.Dropout", "attention.clones", "attention.MultiHeadedAttention.linears.append", "attention.clones", "torch.Linear", "torch.Linear", "torch.Linear", "StructuredLinear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.clones", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.clones", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear"], ["    ", "def", "__init__", "(", "self", ",", "params", ",", "h", ",", "d_model", ",", "structured", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "\"Take in model size and number of heads.\"", "\n", "super", "(", "MultiHeadedAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "d_model", "%", "h", "==", "0", "\n", "# We assume d_v always equals d_k", "\n", "self", ".", "d_k", "=", "d_model", "//", "h", "\n", "self", ".", "h", "=", "h", "\n", "print", "(", "(", "'d_model, h, d_k: '", ",", "d_model", ",", "h", ",", "self", ".", "d_k", ")", ")", "\n", "if", "structured", ":", "\n", "            ", "self", ".", "linears", "=", "clones", "(", "nn", ".", "Linear", "(", "d_model", ",", "d_model", ")", ",", "3", ")", "\n", "self", ".", "linears", ".", "append", "(", "StructuredLinear", "(", "params", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "linears", "=", "clones", "(", "nn", ".", "Linear", "(", "d_model", ",", "d_model", ")", ",", "4", ")", "\n", "", "self", ".", "attn", "=", "None", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.MultiHeadedAttention.forward": [[172, 192], ["query.size", "attention.attention", "x.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "mask.unsqueeze.unsqueeze.unsqueeze", "l().view().transpose", "zip", "x.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "l().view", "x.transpose().contiguous().view.transpose().contiguous().view.transpose", "l"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.attention"], ["", "def", "forward", "(", "self", ",", "query", ",", "key", ",", "value", ",", "mask", "=", "None", ")", ":", "\n", "        ", "\"Implements Figure 2\"", "\n", "if", "mask", "is", "not", "None", ":", "\n", "# Same mask applied to all h heads.", "\n", "            ", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "\n", "", "nbatches", "=", "query", ".", "size", "(", "0", ")", "\n", "\n", "# 1) Do all the linear projections in batch from d_model => h x d_k ", "\n", "query", ",", "key", ",", "value", "=", "[", "l", "(", "x", ")", ".", "view", "(", "nbatches", ",", "-", "1", ",", "self", ".", "h", ",", "self", ".", "d_k", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "for", "l", ",", "x", "in", "zip", "(", "self", ".", "linears", ",", "(", "query", ",", "key", ",", "value", ")", ")", "]", "\n", "\n", "# 2) Apply attention on all the projected vectors in batch. ", "\n", "x", ",", "self", ".", "attn", "=", "attention", "(", "query", ",", "key", ",", "value", ",", "mask", "=", "mask", ",", "\n", "dropout", "=", "self", ".", "dropout", ")", "\n", "\n", "# 3) \"Concat\" using a view and apply a final linear. ", "\n", "x", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", ".", "view", "(", "nbatches", ",", "-", "1", ",", "self", ".", "h", "*", "self", ".", "d_k", ")", "\n", "return", "self", ".", "linears", "[", "-", "1", "]", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.PositionwiseFeedForward.__init__": [[195, 200], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "d_ff", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "PositionwiseFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "w_1", "=", "nn", ".", "Linear", "(", "d_model", ",", "d_ff", ")", "\n", "self", ".", "w_2", "=", "nn", ".", "Linear", "(", "d_ff", ",", "d_model", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.PositionwiseFeedForward.forward": [[201, 203], ["attention.PositionwiseFeedForward.w_2", "attention.PositionwiseFeedForward.dropout", "torch.relu", "torch.relu", "torch.relu", "attention.PositionwiseFeedForward.w_1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "w_2", "(", "self", ".", "dropout", "(", "F", ".", "relu", "(", "self", ".", "w_1", "(", "x", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.Embeddings.__init__": [[205, 209], ["torch.Module.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_model", ",", "vocab", ")", ":", "\n", "        ", "super", "(", "Embeddings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lut", "=", "nn", ".", "Embedding", "(", "vocab", ",", "d_model", ")", "\n", "self", ".", "d_model", "=", "d_model", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.Embeddings.forward": [[210, 212], ["attention.Embeddings.lut", "math.sqrt"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "lut", "(", "x", ")", "*", "math", ".", "sqrt", "(", "self", ".", "d_model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.PositionalEncoding.__init__": [[215, 228], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "torch.cos", "pe.unsqueeze.unsqueeze.unsqueeze", "attention.PositionalEncoding.register_buffer", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "math.log"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__"], ["def", "__init__", "(", "self", ",", "d_model", ",", "dropout", ",", "max_len", "=", "5000", ")", ":", "\n", "        ", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n", "# Compute the positional encodings once in log space.", "\n", "pe", "=", "torch", ".", "zeros", "(", "max_len", ",", "d_model", ")", "\n", "position", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ")", ".", "unsqueeze", "(", "1", ")", "\n", "div_term", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "0", ",", "d_model", ",", "2", ")", "*", "\n", "-", "(", "math", ".", "log", "(", "10000.0", ")", "/", "d_model", ")", ")", "\n", "pe", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "sin", "(", "position", "*", "div_term", ")", "\n", "pe", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "cos", "(", "position", "*", "div_term", ")", "\n", "pe", "=", "pe", ".", "unsqueeze", "(", "0", ")", "\n", "self", ".", "register_buffer", "(", "'pe'", ",", "pe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.PositionalEncoding.forward": [[229, 233], ["attention.PositionalEncoding.dropout", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", "+", "Variable", "(", "self", ".", "pe", "[", ":", ",", ":", "x", ".", "size", "(", "1", ")", "]", ",", "\n", "requires_grad", "=", "False", ")", "\n", "return", "self", ".", "dropout", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.clones": [[48, 51], ["torch.ModuleList", "copy.deepcopy", "range"], "function", ["None"], ["", "", "def", "clones", "(", "module", ",", "N", ")", ":", "\n", "    ", "\"Produce N identical layers.\"", "\n", "return", "nn", ".", "ModuleList", "(", "[", "copy", ".", "deepcopy", "(", "module", ")", "for", "_", "in", "range", "(", "N", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.subsequent_mask": [[137, 142], ["numpy.triu().astype", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.triu", "numpy.ones"], "function", ["None"], ["", "", "def", "subsequent_mask", "(", "size", ")", ":", "\n", "    ", "\"Mask out subsequent positions.\"", "\n", "attn_shape", "=", "(", "1", ",", "size", ",", "size", ")", "\n", "subsequent_mask", "=", "np", ".", "triu", "(", "np", ".", "ones", "(", "attn_shape", ")", ",", "k", "=", "1", ")", ".", "astype", "(", "'uint8'", ")", "\n", "return", "torch", ".", "from_numpy", "(", "subsequent_mask", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.attention": [[143, 154], ["query.size", "torch.softmax", "torch.matmul", "torch.matmul", "torch.matmul", "math.sqrt", "scores.masked_fill.masked_fill", "dropout", "torch.matmul", "torch.matmul", "torch.matmul", "key.transpose"], "function", ["None"], ["", "def", "attention", "(", "query", ",", "key", ",", "value", ",", "mask", "=", "None", ",", "dropout", "=", "None", ")", ":", "\n", "    ", "\"Compute 'Scaled Dot Product Attention'\"", "\n", "d_k", "=", "query", ".", "size", "(", "-", "1", ")", "\n", "scores", "=", "torch", ".", "matmul", "(", "query", ",", "key", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ")", "/", "math", ".", "sqrt", "(", "d_k", ")", "\n", "if", "mask", "is", "not", "None", ":", "\n", "        ", "scores", "=", "scores", ".", "masked_fill", "(", "mask", "==", "0", ",", "-", "1e9", ")", "\n", "", "p_attn", "=", "F", ".", "softmax", "(", "scores", ",", "dim", "=", "-", "1", ")", "\n", "if", "dropout", "is", "not", "None", ":", "\n", "        ", "p_attn", "=", "dropout", "(", "p_attn", ")", "\n", "", "return", "torch", ".", "matmul", "(", "p_attn", ",", "value", ")", ",", "p_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.make_model": [[234, 256], ["attention.MultiHeadedAttention", "attention.MultiHeadedAttention", "attention.PositionwiseFeedForward", "attention.PositionalEncoding", "attention.EncoderDecoder", "EncoderDecoder.parameters", "attention.Encoder", "attention.Decoder", "torch.Sequential", "torch.Sequential", "attention.Generator", "attention.EncoderLayer", "attention.DecoderLayer", "attention.Embeddings", "c", "attention.Embeddings", "c", "p.dim", "torch.init.xavier_uniform", "c", "c", "c", "c", "c"], "function", ["None"], ["", "", "def", "make_model", "(", "params", ",", "src_vocab", ",", "tgt_vocab", ",", "N", "=", "6", ",", "\n", "d_model", "=", "512", ",", "d_ff", "=", "2048", ",", "h", "=", "8", ",", "dropout", "=", "0.1", ")", ":", "\n", "    ", "\"Helper: Construct a model from hyperparameters.\"", "\n", "c", "=", "copy", ".", "deepcopy", "\n", "attn", "=", "MultiHeadedAttention", "(", "params", ",", "h", ",", "d_model", ",", "False", ")", "\n", "structured_attn", "=", "MultiHeadedAttention", "(", "params", ",", "h", ",", "d_model", ",", "True", ")", "\n", "ff", "=", "PositionwiseFeedForward", "(", "d_model", ",", "d_ff", ",", "dropout", ")", "\n", "position", "=", "PositionalEncoding", "(", "d_model", ",", "dropout", ")", "\n", "model", "=", "EncoderDecoder", "(", "\n", "Encoder", "(", "EncoderLayer", "(", "d_model", ",", "c", "(", "structured_attn", ")", ",", "c", "(", "ff", ")", ",", "dropout", ")", ",", "N", ")", ",", "\n", "Decoder", "(", "DecoderLayer", "(", "d_model", ",", "c", "(", "attn", ")", ",", "c", "(", "attn", ")", ",", "\n", "c", "(", "ff", ")", ",", "dropout", ")", ",", "N", ")", ",", "\n", "nn", ".", "Sequential", "(", "Embeddings", "(", "d_model", ",", "src_vocab", ")", ",", "c", "(", "position", ")", ")", ",", "\n", "nn", ".", "Sequential", "(", "Embeddings", "(", "d_model", ",", "tgt_vocab", ")", ",", "c", "(", "position", ")", ")", ",", "\n", "Generator", "(", "d_model", ",", "tgt_vocab", ")", ")", "\n", "\n", "# This was important from their code. ", "\n", "# Initialize parameters with Glorot / fan_avg.", "\n", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "if", "p", ".", "dim", "(", ")", ">", "1", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform", "(", "p", ")", "\n", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.optimize_nmt.run_epoch": [[14, 42], ["time.time", "enumerate", "model.forward", "loss_compute", "batch.src.cuda", "batch.trg.cuda", "batch.src_mask.cuda", "batch.trg_mask.cuda", "print", "time.time", "losses.append", "time.time"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.forward"], ["def", "run_epoch", "(", "writer", ",", "data_iter", ",", "model", ",", "loss_compute", ")", ":", "\n", "    ", "\"Standard Training and Logging Function\"", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "total_tokens", "=", "0", "\n", "total_loss", "=", "0", "\n", "tokens", "=", "0", "\n", "losses", "=", "[", "]", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "data_iter", ")", ":", "\n", "        ", "batch", ".", "src", ",", "batch", ".", "trg", ",", "batch", ".", "src_mask", ",", "batch", ".", "trg_mask", "=", "batch", ".", "src", ".", "cuda", "(", ")", ",", "batch", ".", "trg", ".", "cuda", "(", ")", ",", "batch", ".", "src_mask", ".", "cuda", "(", ")", ",", "batch", ".", "trg_mask", ".", "cuda", "(", ")", "\n", "#print('batch.src:', batch.src)", "\n", "#print('batch.trg: ', batch.trg)", "\n", "#print('batch.src_mask: ', batch.src_mask)", "\n", "#print('batch.trg_mask: ', batch.trg_mask)", "\n", "#quit()", "\n", "out", "=", "model", ".", "forward", "(", "batch", ".", "src", ",", "batch", ".", "trg", ",", "\n", "batch", ".", "src_mask", ",", "batch", ".", "trg_mask", ")", "\n", "loss", "=", "loss_compute", "(", "out", ",", "batch", ".", "trg_y", ",", "batch", ".", "ntokens", ")", "\n", "total_loss", "+=", "loss", "\n", "total_tokens", "+=", "batch", ".", "ntokens", "\n", "tokens", "+=", "batch", ".", "ntokens", "\n", "if", "i", "%", "50", "==", "1", ":", "\n", "            ", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start", "\n", "print", "(", "(", "\"Epoch Step: %d Loss: %f Tokens per Sec: %f\"", "%", "\n", "(", "i", ",", "loss", "/", "batch", ".", "ntokens", ",", "tokens", "/", "elapsed", ")", ")", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "tokens", "=", "0", "\n", "losses", ".", "append", "(", "loss", "/", "batch", ".", "ntokens", ")", "\n", "", "", "return", "total_loss", "/", "total_tokens", ",", "losses", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.optimize_nmt.optimize_nmt": [[43, 84], ["tensorboardX.SummaryWriter", "LabelSmoothing", "attention.make_model", "attention.make_model.named_parameters", "NoamOpt", "attention.make_model.cuda", "range", "tensorboardX.SummaryWriter.export_scalars_to_json", "tensorboardX.SummaryWriter.close", "torch.optim.Adam", "torch.optim.Adam", "attention.make_model.train", "optimize_nmt.run_epoch", "print", "tensorboardX.SummaryWriter.add_scalar", "attention.make_model.eval", "optimize_nmt.run_epoch", "print", "tensorboardX.SummaryWriter.add_scalar", "os.path.join", "print", "os.path.join", "print", "attention.make_model.parameters", "data_gen", "SimpleLossCompute", "data_gen", "SimpleLossCompute", "str", "open", "torch.save", "torch.save", "attention.make_model.state_dict"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.attention.make_model", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.train.train", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.optimize_nmt.run_epoch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.optimize_nmt.run_epoch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.data_gen", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.data_gen", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model_params.ModelParams.save", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model_params.ModelParams.save"], ["", "def", "optimize_nmt", "(", "dataset", ",", "params", ")", ":", "\n", "\t", "V", "=", "11", "\n", "writer", "=", "SummaryWriter", "(", "params", ".", "log_path", ")", "\n", "losses", "=", "{", "'train'", ":", "[", "]", ",", "'val'", ":", "[", "]", ",", "'DR'", ":", "[", "]", ",", "'ratio'", ":", "[", "]", "}", "\n", "accuracies", "=", "{", "'train'", ":", "[", "]", ",", "'val'", ":", "[", "]", "}", "\n", "\n", "criterion", "=", "LabelSmoothing", "(", "size", "=", "V", ",", "padding_idx", "=", "0", ",", "smoothing", "=", "0.0", ")", "\n", "model", "=", "make_model", "(", "params", ",", "V", ",", "V", ",", "N", "=", "1", ")", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "\t    ", "if", "param", ".", "requires_grad", ":", "\n", "\t        ", "print", "(", "(", "'Parameter name, shape: '", ",", "name", ",", "param", ".", "data", ".", "shape", ")", ")", "\n", "\n", "", "", "model_opt", "=", "NoamOpt", "(", "model", ".", "src_embed", "[", "0", "]", ".", "d_model", ",", "1", ",", "400", ",", "\n", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "0", ",", "betas", "=", "(", "0.9", ",", "0.98", ")", ",", "eps", "=", "1e-9", ")", ")", "\n", "\n", "model", ".", "cuda", "(", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "params", ".", "steps", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "train_total_loss_fraction", ",", "train_losses", "=", "run_epoch", "(", "writer", ",", "data_gen", "(", "V", ",", "30", ",", "20", ")", ",", "model", ",", "\n", "SimpleLossCompute", "(", "model", ".", "generator", ",", "criterion", ",", "model_opt", ")", ")", "\n", "losses", "[", "'train'", "]", "+=", "train_losses", "\n", "print", "(", "'Train, epoch: '", ",", "train_total_loss_fraction", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'Train/Loss'", ",", "train_total_loss_fraction", ",", "epoch", ")", "\n", "model", ".", "eval", "(", ")", "\n", "val_total_loss_fraction", ",", "val_losses", "=", "run_epoch", "(", "writer", ",", "data_gen", "(", "V", ",", "30", ",", "5", ")", ",", "model", ",", "\n", "SimpleLossCompute", "(", "model", ".", "generator", ",", "criterion", ",", "None", ")", ")", "\n", "losses", "[", "'val'", "]", "+=", "val_losses", "\n", "print", "(", "'Val, epoch: '", ",", "val_total_loss_fraction", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'Val/Loss'", ",", "val_total_loss_fraction", ",", "epoch", ")", "\n", "\n", "# Checkpoint", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "params", ".", "checkpoint_path", ",", "str", "(", "epoch", ")", ")", "\n", "with", "open", "(", "save_path", ",", "'wb'", ")", "as", "f", ":", "\n", "                ", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "f", ")", "\n", "", "print", "(", "(", "\"Model saved in file: %s\"", "%", "save_path", ")", ")", "\n", "\n", "\n", "", "writer", ".", "export_scalars_to_json", "(", "os", ".", "path", ".", "join", "(", "params", ".", "log_path", ",", "\"all_scalars.json\"", ")", ")", "\n", "writer", ".", "close", "(", ")", "\n", "return", "losses", ",", "accuracies", "\n", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.RNN.__init__": [[185, 193], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LogSoftmax", "torch.LogSoftmax"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "output_size", ")", ":", "\n", "        ", "super", "(", "RNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "\n", "self", ".", "i2h", "=", "nn", ".", "Linear", "(", "input_size", "+", "hidden_size", ",", "hidden_size", ")", "\n", "self", ".", "i2o", "=", "nn", ".", "Linear", "(", "input_size", "+", "hidden_size", ",", "output_size", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.RNN.forward": [[194, 200], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "char_rnn_classification_tutorial.RNN.i2h", "char_rnn_classification_tutorial.RNN.i2o", "char_rnn_classification_tutorial.RNN.softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "hidden", ")", ":", "\n", "        ", "combined", "=", "torch", ".", "cat", "(", "(", "input", ",", "hidden", ")", ",", "1", ")", "\n", "hidden", "=", "self", ".", "i2h", "(", "combined", ")", "\n", "output", "=", "self", ".", "i2o", "(", "combined", ")", "\n", "output", "=", "self", ".", "softmax", "(", "output", ")", "\n", "return", "output", ",", "hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.RNN.initHidden": [[201, 203], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "initHidden", "(", "self", ")", ":", "\n", "        ", "return", "torch", ".", "zeros", "(", "1", ",", "self", ".", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.findFiles": [[71, 72], ["glob.glob"], "function", ["None"], ["def", "findFiles", "(", "path", ")", ":", "return", "glob", ".", "glob", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.unicodeToAscii": [[82, 87], ["unicodedata.normalize", "unicodedata.category"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.normalize"], ["def", "unicodeToAscii", "(", "s", ")", ":", "\n", "    ", "return", "''", ".", "join", "(", "\n", "c", "for", "c", "in", "unicodedata", ".", "normalize", "(", "'NFD'", ",", "s", ")", "\n", "if", "unicodedata", ".", "category", "(", "c", ")", "!=", "'Mn'", "\n", "and", "c", "in", "all_letters", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.readLines": [[96, 99], ["io.open().read().strip().split", "char_rnn_classification_tutorial.unicodeToAscii", "io.open().read().strip", "io.open().read", "io.open"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.unicodeToAscii"], ["def", "readLines", "(", "filename", ")", ":", "\n", "    ", "lines", "=", "open", "(", "filename", ",", "encoding", "=", "'utf-8'", ")", ".", "read", "(", ")", ".", "strip", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "return", "[", "unicodeToAscii", "(", "line", ")", "for", "line", "in", "lines", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.letterToIndex": [[139, 141], ["all_letters.find"], "function", ["None"], ["def", "letterToIndex", "(", "letter", ")", ":", "\n", "    ", "return", "all_letters", ".", "find", "(", "letter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.letterToTensor": [[143, 147], ["torch.zeros", "torch.zeros", "char_rnn_classification_tutorial.letterToIndex"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.letterToIndex"], ["", "def", "letterToTensor", "(", "letter", ")", ":", "\n", "    ", "tensor", "=", "torch", ".", "zeros", "(", "1", ",", "n_letters", ")", "\n", "tensor", "[", "0", "]", "[", "letterToIndex", "(", "letter", ")", "]", "=", "1", "\n", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.lineToTensor": [[150, 155], ["torch.zeros", "torch.zeros", "enumerate", "len", "char_rnn_classification_tutorial.letterToIndex"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.letterToIndex"], ["", "def", "lineToTensor", "(", "line", ")", ":", "\n", "    ", "tensor", "=", "torch", ".", "zeros", "(", "len", "(", "line", ")", ",", "1", ",", "n_letters", ")", "\n", "for", "li", ",", "letter", "in", "enumerate", "(", "line", ")", ":", "\n", "        ", "tensor", "[", "li", "]", "[", "0", "]", "[", "letterToIndex", "(", "letter", ")", "]", "=", "1", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.categoryFromOutput": [[255, 259], ["output.topk", "top_i[].item"], "function", ["None"], ["def", "categoryFromOutput", "(", "output", ")", ":", "\n", "    ", "top_n", ",", "top_i", "=", "output", ".", "topk", "(", "1", ")", "\n", "category_i", "=", "top_i", "[", "0", "]", ".", "item", "(", ")", "\n", "return", "all_categories", "[", "category_i", "]", ",", "category_i", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.randomChoice": [[270, 272], ["random.randint", "len"], "function", ["None"], ["def", "randomChoice", "(", "l", ")", ":", "\n", "    ", "return", "l", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "l", ")", "-", "1", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.randomTrainingExample": [[273, 279], ["char_rnn_classification_tutorial.randomChoice", "char_rnn_classification_tutorial.randomChoice", "torch.tensor", "torch.tensor", "char_rnn_classification_tutorial.lineToTensor", "all_categories.index"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.randomChoice", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.randomChoice", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.lineToTensor"], ["", "def", "randomTrainingExample", "(", ")", ":", "\n", "    ", "category", "=", "randomChoice", "(", "all_categories", ")", "\n", "line", "=", "randomChoice", "(", "category_lines", "[", "category", "]", ")", "\n", "category_tensor", "=", "torch", ".", "tensor", "(", "[", "all_categories", ".", "index", "(", "category", ")", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "line_tensor", "=", "lineToTensor", "(", "line", ")", "\n", "return", "category", ",", "line", ",", "category_tensor", ",", "line_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.train": [[315, 331], ["rnn.initHidden", "rnn.zero_grad", "range", "criterion", "criterion.backward", "rnn.parameters", "rnn", "p.data.add_", "criterion.item", "line_tensor.size"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.RNN.initHidden", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.CycleDownMultCuda.backward"], ["def", "train", "(", "category_tensor", ",", "line_tensor", ")", ":", "\n", "    ", "hidden", "=", "rnn", ".", "initHidden", "(", ")", "\n", "\n", "rnn", ".", "zero_grad", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "line_tensor", ".", "size", "(", ")", "[", "0", "]", ")", ":", "\n", "        ", "output", ",", "hidden", "=", "rnn", "(", "line_tensor", "[", "i", "]", ",", "hidden", ")", "\n", "\n", "", "loss", "=", "criterion", "(", "output", ",", "category_tensor", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# Add parameters' gradients to their values, multiplied by learning rate", "\n", "for", "p", "in", "rnn", ".", "parameters", "(", ")", ":", "\n", "        ", "p", ".", "data", ".", "add_", "(", "-", "learning_rate", ",", "p", ".", "grad", ".", "data", ")", "\n", "\n", "", "return", "output", ",", "loss", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.timeSince": [[354, 360], ["time.time", "math.floor"], "function", ["None"], ["def", "timeSince", "(", "since", ")", ":", "\n", "    ", "now", "=", "time", ".", "time", "(", ")", "\n", "s", "=", "now", "-", "since", "\n", "m", "=", "math", ".", "floor", "(", "s", "/", "60", ")", "\n", "s", "-=", "m", "*", "60", "\n", "return", "'%dm %ds'", "%", "(", "m", ",", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.evaluate": [[410, 417], ["rnn.initHidden", "range", "rnn", "line_tensor.size"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.RNN.initHidden"], ["def", "evaluate", "(", "line_tensor", ")", ":", "\n", "    ", "hidden", "=", "rnn", ".", "initHidden", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "line_tensor", ".", "size", "(", ")", "[", "0", "]", ")", ":", "\n", "        ", "output", ",", "hidden", "=", "rnn", "(", "line_tensor", "[", "i", "]", ",", "hidden", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.predict": [[471, 485], ["print", "torch.no_grad", "torch.no_grad", "char_rnn_classification_tutorial.evaluate", "evaluate.topk", "range", "char_rnn_classification_tutorial.lineToTensor", "[].item", "[].item", "print", "predictions.append"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.evaluate", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.charRNN.char_rnn_classification_tutorial.lineToTensor"], ["def", "predict", "(", "input_line", ",", "n_predictions", "=", "3", ")", ":", "\n", "    ", "print", "(", "'\\n> %s'", "%", "input_line", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "output", "=", "evaluate", "(", "lineToTensor", "(", "input_line", ")", ")", "\n", "\n", "# Get top N categories", "\n", "topv", ",", "topi", "=", "output", ".", "topk", "(", "n_predictions", ",", "1", ",", "True", ")", "\n", "predictions", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "n_predictions", ")", ":", "\n", "            ", "value", "=", "topv", "[", "0", "]", "[", "i", "]", ".", "item", "(", ")", "\n", "category_index", "=", "topi", "[", "0", "]", "[", "i", "]", ".", "item", "(", ")", "\n", "print", "(", "'(%.2f) %s'", "%", "(", "value", ",", "all_categories", "[", "category_index", "]", ")", ")", "\n", "predictions", ".", "append", "(", "[", "value", ",", "all_categories", "[", "category_index", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.circulant.TwoLayerNet.__init__": [[19, 23], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_features", ",", "n_classes", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "n_features", ",", "n_features", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "n_features", ",", "n_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.circulant.TwoLayerNet.forward": [[24, 27], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "circulant.TwoLayerNet.fc2", "circulant.TwoLayerNet.fc1", "x.view", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "feat", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", ")", ")", "\n", "return", "self", ".", "fc2", "(", "feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.circulant.TwoLayerNet.loss": [[28, 31], ["torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "loss", "(", "output", ",", "target", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "return", "F", ".", "cross_entropy", "(", "output", ",", "target", ",", "reduce", "=", "reduce", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.circulant.TwoLayerNet.predict": [[32, 35], ["output.data.max"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "predict", "(", "output", ")", ":", "\n", "        ", "return", "output", ".", "data", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.circulant.Circulant.__init__": [[37, 46], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "circulant.Circulant.reset_parameters", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "circulant.Circulant.register_parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonalC.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "in_features", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "in_features", ")", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "in_features", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.circulant.Circulant.reset_parameters": [[47, 52], ["circulant.Circulant.weight.data.uniform_", "math.sqrt", "circulant.Circulant.bias.data.uniform_", "circulant.Circulant.weight.size"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "stdv", "=", "1.", "/", "math", ".", "sqrt", "(", "self", ".", "weight", ".", "size", "(", "0", ")", ")", "\n", "self", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "stdv", ",", "stdv", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "self", ".", "bias", ".", "data", ".", "uniform_", "(", "-", "stdv", ",", "stdv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.circulant.Circulant.forward": [[53, 55], ["torch.linear", "torch.linear", "torch.linear", "torch.linear", "Krylov().t", "circulant.Krylov"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "return", "F", ".", "linear", "(", "input", ",", "Krylov", "(", "shift", ",", "self", ".", "weight", ")", ".", "t", "(", ")", ",", "self", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.circulant.TwoLayerCirculant.__init__": [[58, 62], ["torch.Module.__init__", "circulant.Circulant", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_features", ",", "n_classes", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "Circulant", "(", "n_features", ",", "bias", "=", "True", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "n_features", ",", "n_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.circulant.TwoLayerCirculant.forward": [[63, 66], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "circulant.TwoLayerCirculant.fc2", "circulant.TwoLayerCirculant.fc1", "x.view", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "feat", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", ")", ")", "\n", "return", "self", ".", "fc2", "(", "feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.circulant.TwoLayerCirculant.loss": [[67, 70], ["torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "loss", "(", "output", ",", "target", ",", "reduce", "=", "True", ")", ":", "\n", "        ", "return", "F", ".", "cross_entropy", "(", "output", ",", "target", ",", "reduce", "=", "reduce", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.circulant.TwoLayerCirculant.predict": [[71, 74], ["output.data.max"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "predict", "(", "output", ")", ":", "\n", "        ", "return", "output", ".", "data", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.circulant.shift": [[75, 77], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "v.size"], "function", ["None"], ["", "", "def", "shift", "(", "v", ",", "f", "=", "1", ")", ":", "\n", "    ", "return", "torch", ".", "cat", "(", "(", "f", "*", "v", "[", "[", "v", ".", "size", "(", "0", ")", "-", "1", "]", "]", ",", "v", "[", ":", "-", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.circulant.Krylov": [[78, 86], ["range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "linear_map.size", "cols.append", "circulant.shift"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.circulant.shift"], ["", "def", "Krylov", "(", "linear_map", ",", "v", ",", "n", "=", "None", ")", ":", "\n", "    ", "if", "n", "is", "None", ":", "\n", "        ", "n", "=", "v", ".", "size", "(", "0", ")", "\n", "", "cols", "=", "[", "v", "]", "\n", "for", "_", "in", "range", "(", "n", "-", "1", ")", ":", "\n", "        ", "v", "=", "linear_map", "(", "v", ")", "\n", "cols", ".", "append", "(", "v", ")", "\n", "", "return", "torch", ".", "stack", "(", "cols", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.circulant.loader_from_dataset": [[93, 96], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "function", ["None"], ["", "def", "loader_from_dataset", "(", "dataset", ")", ":", "\n", "    ", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "**", "loader_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.circulant.sgd_opt_from_model": [[118, 122], ["torch.SGD", "model.parameters"], "function", ["None"], ["def", "sgd_opt_from_model", "(", "model", ",", "learning_rate", "=", "0.01", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "0.001", ")", ":", "\n", "    ", "return", "optim", ".", "SGD", "(", "(", "p", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", ",", "\n", "lr", "=", "learning_rate", ",", "momentum", "=", "momentum", ",", "\n", "weight_decay", "=", "weight_decay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.utils.get_train_valid_datasets": [[11, 45], ["len", "list", "int", "range", "numpy.random.seed", "numpy.random.shuffle", "numpy.floor", "copy.copy", "copy.copy"], "function", ["None"], ["", "def", "cross_entropy_loss", "(", "pred", ",", "true", ")", ":", "\n", "    ", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "_", ",", "true_argmax", "=", "torch", ".", "max", "(", "true", ",", "1", ")", "\n", "cross_entropy", "=", "loss_fn", "(", "pred", ",", "true_argmax", ")", "\n", "\n", "_", ",", "pred_argmax", "=", "torch", ".", "max", "(", "pred", ",", "1", ")", "\n", "correct_prediction", "=", "torch", ".", "eq", "(", "true_argmax", ",", "pred_argmax", ")", "\n", "accuracy", "=", "torch", ".", "mean", "(", "correct_prediction", ".", "float", "(", ")", ")", "\n", "\n", "return", "cross_entropy", ",", "accuracy", "\n", "\n", "\n", "", "def", "get_commit_id", "(", ")", ":", "\n", "  ", "return", "subprocess", ".", "check_output", "(", "[", "'git'", ",", "'rev-parse'", ",", "'--short'", ",", "'HEAD'", "]", ")", "\n", "\n", "", "def", "descendants", "(", "cls", ")", ":", "\n", "    ", "\"\"\"\n    Get all subclasses (recursively) of class cls, not including itself\n    Assumes no multiple inheritance\n    \"\"\"", "\n", "desc", "=", "[", "]", "\n", "for", "subcls", "in", "cls", ".", "__subclasses__", "(", ")", ":", "\n", "        ", "desc", ".", "append", "(", "subcls", ")", "\n", "desc", ".", "extend", "(", "descendants", "(", "subcls", ")", ")", "\n", "", "return", "desc", "\n", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.utils.copy_with_new_transform": [[47, 53], ["copy.copy"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.utils.augment_transforms": [[55, 71], ["torchvision.transforms.Lambda", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "base_transform", "base_transform", "base_transform", "aug", "aug"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.utils.train": [[73, 91], ["model.train", "optimizer.zero_grad", "model", "model.predict", "model.loss", "model.loss.backward", "optimizer.step", "train_loss.append", "train_acc.append", "target.data.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "data.cuda", "target.cuda"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.train.train", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.circulant.TwoLayerCirculant.predict", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.loss", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.CycleDownMultCuda.backward", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.NoamOpt.step"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.utils.train_models_compute_agreement": [[93, 115], ["model.train", "zip", "numpy.array", "numpy.array", "train_agreement.append", "optimizer.zero_grad", "model", "np.array.append", "model.loss", "model.loss.backward", "optimizer.step", "np.array.append", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "model.predict", "p.cpu().numpy", "data.cuda", "target.cuda", "p.cpu"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.train.train", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.loss", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.CycleDownMultCuda.backward", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.attention.train.NoamOpt.step", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.circulant.TwoLayerCirculant.predict"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.utils.train_all_epochs": [[117, 138], ["model.train", "range", "utils.train", "utils.accuracy", "valid_acc.append", "print", "print"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.train.train", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.train.train", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.utils.accuracy"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.utils.accuracy": [[140, 158], ["model.eval", "model.train", "model", "model.predict", "target.size", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "data.cuda", "target.cuda"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.train.train", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.circulant.TwoLayerCirculant.predict"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.utils.all_losses": [[160, 175], ["model.eval", "model.train", "numpy.array", "losses.append", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "data.cuda", "target.cuda", "model.all_losses"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.train.train", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.utils.all_losses"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.utils.agreement_kl_accuracy": [[177, 202], ["zip", "model.eval", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.log_softmax", "torch.softmax().detach", "valid_kl.append", "valid_acc.append", "valid_agreement.append", "model.train", "model", "torch.stack.append", "torch.stack.append", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "model.predict", "torch.softmax", "data.cuda", "target.cuda", "torch.kl_div().data.cpu", "F.softmax().detach.size", "torch.kl_div"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.train.train", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.circtest.circulant.TwoLayerCirculant.predict"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.ArghModel.__init__": [[19, 30], ["torch.Module.__init__", "nets.ArghModel.__dict__.update", "nets.ArghModel.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonalC.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "in_size", ",", "out_size", ",", "**", "options", ")", ":", "\n", "        ", "\"\"\"\"\n        options: dictionary of options/params that args() accepts\n        If the model if constructed with construct_model(), the options will contain defaults based on its args() function\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "in_size", "=", "in_size", "\n", "self", ".", "out_size", "=", "out_size", "\n", "self", ".", "__dict__", ".", "update", "(", "**", "options", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.ArghModel.args": [[31, 36], ["None"], "methods", ["None"], ["", "def", "args", "(", ")", ":", "\n", "        ", "\"\"\"\n        Empty function whose signature contains parameters and defaults for the class\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.ArghModel.reset_parameters": [[37, 39], ["None"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.ArghModel.name": [[40, 46], ["None"], "methods", ["None"], ["", "def", "name", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Short string summarizing the main parameters of the class\n        Used to construct a unique identifier for an experiment\n        \"\"\"", "\n", "return", "''", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.ArghModel.loss": [[47, 52], ["None"], "methods", ["None"], ["", "def", "loss", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Model-specific loss function (e.g. per-parameter regularization)\n        \"\"\"", "\n", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.Lenet.reset_parameters": [[57, 66], ["torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["None"], ["    ", "def", "reset_parameters", "(", "self", ")", ":", "\n", "# super().__init__()", "\n", "# in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True", "\n", "        ", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "6", ",", "5", ")", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "6", ",", "16", ",", "5", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "16", "*", "5", "*", "5", ",", "120", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "120", ",", "84", ")", "\n", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "84", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.Lenet.forward": [[67, 76], ["nets.Lenet.view", "nets.Lenet.pool", "nets.Lenet.pool", "nets.Lenet.view", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "nets.Lenet.fc3", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "nets.Lenet.fc1", "nets.Lenet.fc2", "nets.Lenet.conv1", "nets.Lenet.conv2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "view", "(", "-", "1", ",", "3", ",", "32", ",", "32", ")", "\n", "x", "=", "self", ".", "pool", "(", "F", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "x", "=", "self", ".", "pool", "(", "F", ".", "relu", "(", "self", ".", "conv2", "(", "x", ")", ")", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "16", "*", "5", "*", "5", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc2", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "fc3", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.CNN.name": [[82, 84], ["nets.CNN.layers[].name"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.name"], ["def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "layers", "[", "0", "]", ".", "name", "(", ")", "\n", "", "def", "args", "(", "class_type", "=", "'unconstrained'", ",", "layer_size", "=", "-", "1", ",", "r", "=", "1", ",", "bias", "=", "True", ",", "hidden_size", "=", "-", "1", ")", ":", "pass", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.CNN.args": [[84, 85], ["None"], "methods", ["None"], ["", "def", "args", "(", "class_type", "=", "'unconstrained'", ",", "layer_size", "=", "-", "1", ",", "r", "=", "1", ",", "bias", "=", "True", ",", "hidden_size", "=", "-", "1", ")", ":", "pass", "\n", "def", "reset_parameters", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.CNN.reset_parameters": [[85, 100], ["int", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "layers.append", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "torch.Linear", "numpy.sqrt", "structure.StructuredLinear", "structure.StructuredLinear"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear"], ["def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "layer_size", "==", "-", "1", ":", "\n", "            ", "self", ".", "layer_size", "=", "self", ".", "in_size", "\n", "", "if", "self", ".", "hidden_size", "==", "-", "1", ":", "\n", "            ", "self", ".", "hidden_size", "=", "self", ".", "layer_size", "\n", "", "assert", "self", ".", "layer_size", "==", "self", ".", "in_size", "\n", "self", ".", "d", "=", "int", "(", "np", ".", "sqrt", "(", "self", ".", "layer_size", ")", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "1", ",", "6", ",", "5", ",", "padding", "=", "2", ")", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "6", ",", "16", ",", "5", ",", "padding", "=", "2", ")", "\n", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "sl", ".", "StructuredLinear", "(", "self", ".", "class_type", ",", "layer_size", "=", "self", ".", "layer_size", ",", "r", "=", "self", ".", "r", ",", "bias", "=", "self", ".", "bias", ",", "\n", "hidden_size", "=", "self", ".", "hidden_size", ")", ")", "\n", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "layers", ")", "\n", "self", ".", "logits", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_size", ",", "self", ".", "out_size", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.CNN.forward": [[100, 108], ["nets.CNN.view", "nets.CNN.pool", "nets.CNN.pool", "nets.CNN.view", "torch.relu", "torch.relu", "torch.relu", "nets.CNN.logits", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "nets.CNN.conv1", "nets.CNN.conv2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "view", "(", "-", "1", ",", "1", ",", "self", ".", "d", ",", "self", ".", "d", ")", "\n", "x", "=", "self", ".", "pool", "(", "F", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "x", "=", "self", ".", "pool", "(", "F", ".", "relu", "(", "self", ".", "conv2", "(", "x", ")", ")", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "self", ".", "layer_size", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "layers", "[", "0", "]", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "logits", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.CNNColor.args": [[113, 114], ["None"], "methods", ["None"], ["def", "args", "(", "class_type", "=", "'unconstrained'", ",", "layer_size", "=", "-", "1", ",", "r", "=", "1", ",", "bias", "=", "True", ",", "hidden_size", "=", "-", "1", ")", ":", "pass", "\n", "def", "reset_parameters", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.CNNColor.reset_parameters": [[114, 125], ["int", "int", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "structure.StructuredLinear", "structure.StructuredLinear", "torch.Linear", "torch.Linear", "torch.Linear", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear"], ["def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "layer_size", "=", "int", "(", "self", ".", "in_size", "/", "3", ")", "\n", "if", "self", ".", "hidden_size", "==", "-", "1", ":", "\n", "            ", "self", ".", "hidden_size", "=", "self", ".", "layer_size", "\n", "", "self", ".", "d", "=", "int", "(", "np", ".", "sqrt", "(", "self", ".", "layer_size", ")", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "6", ",", "5", ",", "padding", "=", "2", ")", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "6", ",", "16", ",", "5", ",", "padding", "=", "2", ")", "\n", "self", ".", "W", "=", "sl", ".", "StructuredLinear", "(", "self", ".", "class_type", ",", "layer_size", "=", "self", ".", "layer_size", ",", "r", "=", "self", ".", "r", ",", "bias", "=", "self", ".", "bias", ",", "\n", "hidden_size", "=", "self", ".", "hidden_size", ")", "\n", "self", ".", "logits", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_size", ",", "self", ".", "out_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.CNNColor.name": [[126, 128], ["nets.CNNColor.W.name"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.name"], ["", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "W", ".", "name", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.CNNColor.forward": [[129, 137], ["nets.CNNColor.view", "nets.CNNColor.pool", "nets.CNNColor.pool", "nets.CNNColor.view", "torch.relu", "torch.relu", "torch.relu", "nets.CNNColor.logits", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "nets.CNNColor.W", "nets.CNNColor.conv1", "nets.CNNColor.conv2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "view", "(", "-", "1", ",", "3", ",", "self", ".", "d", ",", "self", ".", "d", ")", "\n", "x", "=", "self", ".", "pool", "(", "F", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "x", "=", "self", ".", "pool", "(", "F", ".", "relu", "(", "self", ".", "conv2", "(", "x", ")", ")", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "self", ".", "layer_size", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "W", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "logits", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.CNNPool.name": [[142, 144], ["str"], "methods", ["None"], ["def", "name", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "channels", ")", "+", "'pool'", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.CNNPool.args": [[145, 146], ["None"], "methods", ["None"], ["", "def", "args", "(", "channels", "=", "3", ",", "fc_size", "=", "512", ")", ":", "pass", "\n", "def", "reset_parameters", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.CNNPool.reset_parameters": [[146, 152], ["torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["None"], ["def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "self", ".", "channels", ",", "5", ",", "padding", "=", "2", ")", "\n", "self", ".", "pool", "=", "nn", ".", "MaxPool2d", "(", "2", ",", "2", ")", "\n", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "self", ".", "channels", "*", "1024", "//", "4", ",", "self", ".", "fc_size", ")", "\n", "self", ".", "logits", "=", "nn", ".", "Linear", "(", "self", ".", "fc_size", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.CNNPool.forward": [[153, 162], ["nets.CNNPool.view", "torch.relu", "torch.relu", "torch.relu", "nets.CNNPool.pool", "nets.CNNPool.view", "torch.relu", "torch.relu", "torch.relu", "nets.CNNPool.logits", "nets.CNNPool.conv1", "nets.CNNPool.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "view", "(", "-", "1", ",", "3", ",", "32", ",", "32", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "pool", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "self", ".", "channels", "*", "1024", "//", "4", ")", "\n", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "logits", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.TwoLayer.name": [[168, 170], ["None"], "methods", ["None"], ["def", "name", "(", "self", ")", ":", "\n", "        ", "return", "\"3conv\"", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.TwoLayer.args": [[171, 172], ["None"], "methods", ["None"], ["", "def", "args", "(", "conv", "=", "True", ")", ":", "pass", "\n", "def", "reset_parameters", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.TwoLayer.reset_parameters": [[172, 180], ["torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["None"], ["def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "conv", ":", "\n", "            ", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "3", ",", "5", ",", "padding", "=", "2", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv1", "=", "nn", ".", "Linear", "(", "3", "*", "1024", ",", "3", "*", "1024", ")", "\n", "\n", "", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "3", "*", "1024", ",", "512", ")", "\n", "self", ".", "logits", "=", "nn", ".", "Linear", "(", "512", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.TwoLayer.forward": [[181, 192], ["torch.relu", "torch.relu", "torch.relu", "nets.TwoLayer.logits", "torch.relu.view", "torch.relu", "torch.relu", "torch.relu", "torch.relu.view", "torch.relu", "torch.relu", "torch.relu", "nets.TwoLayer.fc", "nets.TwoLayer.conv1", "nets.TwoLayer.conv1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "conv", ":", "\n", "            ", "x", "=", "x", ".", "view", "(", "-", "1", ",", "3", ",", "32", ",", "32", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "3", "*", "1024", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", "\n", "\n", "", "x", "=", "F", ".", "relu", "(", "self", ".", "fc", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "logits", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.TwoLayer.loss": [[193, 195], ["None"], "methods", ["None"], ["", "def", "loss", "(", "self", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.WLDRFC.name": [[200, 202], ["nets.WLDRFC.W.name"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.name"], ["def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "W", ".", "name", "(", ")", "+", "'u'", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.WLDRFC.args": [[203, 204], ["None"], "methods", ["None"], ["", "def", "args", "(", "class_type", "=", "'unconstrained'", ",", "layer_size", "=", "-", "1", ",", "r", "=", "1", ",", "fc_size", "=", "512", ")", ":", "pass", "\n", "def", "reset_parameters", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.WLDRFC.reset_parameters": [[204, 209], ["structure.StructuredLinear", "structure.StructuredLinear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear"], ["def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "layer_size", "==", "-", "1", ":", "self", ".", "layer_size", "=", "self", ".", "in_size", "\n", "self", ".", "W", "=", "sl", ".", "StructuredLinear", "(", "self", ".", "class_type", ",", "layer_size", "=", "self", ".", "layer_size", ",", "r", "=", "self", ".", "r", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "3", "*", "1024", ",", "self", ".", "fc_size", ")", "\n", "self", ".", "logits", "=", "nn", ".", "Linear", "(", "self", ".", "fc_size", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.WLDRFC.forward": [[210, 215], ["nets.WLDRFC.W", "torch.relu", "torch.relu", "torch.relu", "nets.WLDRFC.logits", "nets.WLDRFC.fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "W", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "logits", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.WLDRFC.loss": [[216, 218], ["nets.WLDRFC.W.loss"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.loss"], ["", "def", "loss", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "W", ".", "loss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.LDRFC.name": [[224, 226], ["nets.LDRFC.W.name"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.name"], ["def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "W", ".", "name", "(", ")", "+", "'u'", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.LDRFC.args": [[227, 228], ["None"], "methods", ["None"], ["", "def", "args", "(", "class_type", "=", "'t'", ",", "r", "=", "1", ",", "channels", "=", "3", ",", "fc_size", "=", "512", ")", ":", "pass", "\n", "def", "reset_parameters", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.LDRFC.reset_parameters": [[228, 234], ["structure.LDR", "structure.LDR", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["None"], ["def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "n", "=", "1024", "\n", "\n", "self", ".", "LDR1", "=", "ldr", ".", "LDR", "(", "self", ".", "class_type", ",", "3", ",", "self", ".", "channels", ",", "self", ".", "r", ",", "self", ".", "n", ",", "bias", "=", "True", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "self", ".", "channels", "*", "self", ".", "n", ",", "self", ".", "fc_size", ")", "\n", "self", ".", "logits", "=", "nn", ".", "Linear", "(", "self", ".", "fc_size", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.LDRFC.forward": [[235, 244], ["nets.LDRFC.view", "nets.LDRFC.transpose().contiguous().view", "torch.relu", "torch.relu", "torch.relu", "nets.LDRFC.transpose", "nets.LDRFC.contiguous().view", "torch.relu", "torch.relu", "torch.relu", "nets.LDRFC.logits", "nets.LDRFC.LDR1", "nets.LDRFC.fc", "nets.LDRFC.transpose().contiguous", "nets.LDRFC.contiguous", "nets.LDRFC.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "view", "(", "-", "1", ",", "3", ",", "1024", ")", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "3", ",", "-", "1", ",", "self", ".", "n", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "LDR1", "(", "x", ")", ")", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", "# swap batches and channels axis", "\n", "x", "=", "x", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "self", ".", "channels", "*", "self", ".", "n", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "logits", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.LDRFC.loss": [[245, 247], ["nets.LDRFC.LDR1.loss"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.loss"], ["", "def", "loss", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "LDR1", ".", "loss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.LDRLDR.name": [[253, 256], ["nets.LDRLDR.LDR1.name", "nets.LDRLDR.LDR211.name"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.name", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.name"], ["def", "name", "(", "self", ")", ":", "\n", "# w = 'wide' if not self.channels else ''", "\n", "        ", "return", "self", ".", "LDR1", ".", "name", "(", ")", "+", "self", ".", "LDR211", ".", "name", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.LDRLDR.args": [[257, 258], ["None"], "methods", ["None"], ["", "def", "args", "(", "class1", "=", "'toeplitz'", ",", "class2", "=", "'toeplitz'", ",", "channels", "=", "False", ",", "rank1", "=", "48", ",", "rank2", "=", "16", ")", ":", "pass", "\n", "def", "reset_parameters", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.LDRLDR.reset_parameters": [[258, 275], ["structure.StructuredLinear", "structure.StructuredLinear", "structure.StructuredLinear", "structure.StructuredLinear", "structure.StructuredLinear", "structure.StructuredLinear", "structure.StructuredLinear", "structure.StructuredLinear", "structure.StructuredLinear", "structure.StructuredLinear", "structure.StructuredLinear", "structure.StructuredLinear", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.Linear", "torch.Linear", "torch.Linear", "structure.LDR", "structure.LDR", "structure.StructuredLinear", "structure.StructuredLinear", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear"], ["def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "n", "=", "1024", "\n", "self", ".", "fc_size", "=", "self", ".", "n", "//", "2", "\n", "\n", "if", "self", ".", "channels", ":", "\n", "            ", "self", ".", "LDR1", "=", "ldr", ".", "LDR", "(", "self", ".", "class1", ",", "3", ",", "3", ",", "self", ".", "rank1", ",", "self", ".", "n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "LDR1", "=", "sl", ".", "StructuredLinear", "(", "self", ".", "class1", ",", "layer_size", "=", "3", "*", "self", ".", "n", ",", "r", "=", "self", ".", "rank1", ")", "\n", "\n", "", "self", ".", "LDR211", "=", "sl", ".", "StructuredLinear", "(", "self", ".", "class2", ",", "layer_size", "=", "self", ".", "fc_size", ",", "r", "=", "self", ".", "rank2", ")", "\n", "self", ".", "LDR212", "=", "sl", ".", "StructuredLinear", "(", "self", ".", "class2", ",", "layer_size", "=", "self", ".", "fc_size", ",", "r", "=", "self", ".", "rank2", ")", "\n", "self", ".", "LDR221", "=", "sl", ".", "StructuredLinear", "(", "self", ".", "class2", ",", "layer_size", "=", "self", ".", "fc_size", ",", "r", "=", "self", ".", "rank2", ")", "\n", "self", ".", "LDR222", "=", "sl", ".", "StructuredLinear", "(", "self", ".", "class2", ",", "layer_size", "=", "self", ".", "fc_size", ",", "r", "=", "self", ".", "rank2", ")", "\n", "self", ".", "LDR231", "=", "sl", ".", "StructuredLinear", "(", "self", ".", "class2", ",", "layer_size", "=", "self", ".", "fc_size", ",", "r", "=", "self", ".", "rank2", ")", "\n", "self", ".", "LDR232", "=", "sl", ".", "StructuredLinear", "(", "self", ".", "class2", ",", "layer_size", "=", "self", ".", "fc_size", ",", "r", "=", "self", ".", "rank2", ")", "\n", "self", ".", "b", "=", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "fc_size", ")", ")", "\n", "self", ".", "logits", "=", "nn", ".", "Linear", "(", "self", ".", "fc_size", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.LDRLDR.forward": [[276, 294], ["torch.relu", "torch.relu", "torch.relu", "nets.LDRLDR.logits", "x.transpose().contiguous().view.transpose().contiguous().view.view", "x.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "x.transpose().contiguous().view.transpose().contiguous().view.view", "x.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous().view", "nets.LDRLDR.LDR1", "nets.LDRLDR.LDR1", "x.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "x.transpose().contiguous().view.transpose().contiguous().view.transpose().contiguous", "nets.LDRLDR.LDR232", "nets.LDRLDR.LDR231", "x.transpose().contiguous().view.transpose().contiguous().view.transpose", "x.transpose().contiguous().view.transpose().contiguous().view.transpose", "nets.LDRLDR.LDR222", "nets.LDRLDR.LDR221", "nets.LDRLDR.LDR211", "nets.LDRLDR.LDR212"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "channels", ":", "\n", "            ", "x", "=", "x", ".", "view", "(", "-", "1", ",", "3", ",", "self", ".", "n", ")", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "3", ",", "-", "1", ",", "self", ".", "n", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "LDR1", "(", "x", ")", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "F", ".", "relu", "(", "self", ".", "LDR1", "(", "x", ")", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "3", ",", "self", ".", "n", ")", "\n", "x", "=", "x", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "3", ",", "-", "1", ",", "self", ".", "n", ")", "\n", "", "x11", "=", "x", "[", "0", "]", "[", ":", ",", ":", "self", ".", "fc_size", "]", "\n", "x12", "=", "x", "[", "0", "]", "[", ":", ",", "self", ".", "fc_size", ":", "]", "\n", "x21", "=", "x", "[", "1", "]", "[", ":", ",", ":", "self", ".", "fc_size", "]", "\n", "x22", "=", "x", "[", "1", "]", "[", ":", ",", "self", ".", "fc_size", ":", "]", "\n", "x31", "=", "x", "[", "2", "]", "[", ":", ",", ":", "self", ".", "fc_size", "]", "\n", "x32", "=", "x", "[", "2", "]", "[", ":", ",", "self", ".", "fc_size", ":", "]", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "LDR211", "(", "x11", ")", "+", "self", ".", "LDR212", "(", "x12", ")", "+", "self", ".", "LDR221", "(", "x21", ")", "+", "self", ".", "LDR222", "(", "x22", ")", "+", "self", ".", "LDR231", "(", "x31", ")", "+", "self", ".", "LDR232", "(", "x32", ")", "+", "self", ".", "b", ")", "\n", "x", "=", "self", ".", "logits", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.LDRLDR.loss": [[295, 297], ["nets.LDRLDR.LDR1.loss"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.loss"], ["", "def", "loss", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "LDR1", ".", "loss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.LDRLDR2.name": [[303, 305], ["nets.LDRLDR2.LDR1.name", "nets.LDRLDR2.LDR2.name"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.name", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.name"], ["def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "LDR1", ".", "name", "(", ")", "+", "self", ".", "LDR2", ".", "name", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.LDRLDR2.args": [[306, 307], ["None"], "methods", ["None"], ["", "def", "args", "(", "class1", "=", "'toeplitz'", ",", "class2", "=", "'toeplitz'", ",", "layer_size", "=", "-", "1", ",", "channels", "=", "3", ",", "fc_size", "=", "512", ",", "rank1", "=", "48", ",", "rank2", "=", "16", ")", ":", "pass", "\n", "def", "reset_parameters", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.LDRLDR2.reset_parameters": [[307, 315], ["structure.StructuredLinear", "structure.StructuredLinear", "structure.StructuredLinear", "structure.StructuredLinear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear"], ["def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "layer_size", "==", "-", "1", ":", "\n", "            ", "self", ".", "layer_size", "=", "self", ".", "in_size", "\n", "", "self", ".", "n", "=", "self", ".", "layer_size", "\n", "\n", "self", ".", "LDR1", "=", "sl", ".", "StructuredLinear", "(", "self", ".", "class1", ",", "layer_size", "=", "self", ".", "channels", "*", "self", ".", "n", ",", "r", "=", "self", ".", "rank1", ",", "bias", "=", "True", ")", "\n", "self", ".", "LDR2", "=", "sl", ".", "StructuredLinear", "(", "self", ".", "class2", ",", "layer_size", "=", "self", ".", "channels", "*", "self", ".", "n", ",", "r", "=", "self", ".", "rank2", ",", "bias", "=", "True", ")", "\n", "self", ".", "logits", "=", "nn", ".", "Linear", "(", "self", ".", "fc_size", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.LDRLDR2.forward": [[316, 324], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "nets.LDRLDR2.logits", "nets.LDRLDR2.LDR1", "nets.LDRLDR2.LDR2", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "batch_size", ",", "n", "=", "x", ".", "shape", "[", "0", "]", ",", "x", ".", "shape", "[", "1", "]", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "torch", ".", "zeros", "(", "batch_size", ",", "self", ".", "channels", "*", "self", ".", "n", "-", "n", ")", ".", "cuda", "(", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "LDR1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "LDR2", "(", "x", ")", ")", "\n", "x", "=", "x", "[", ":", ",", ":", "self", ".", "fc_size", "]", "\n", "x", "=", "self", ".", "logits", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.LDRLDR2.loss": [[325, 327], ["nets.LDRLDR2.LDR1.loss"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.loss"], ["", "def", "loss", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "LDR1", ".", "loss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.SL.name": [[333, 335], ["nets.SL.W.name"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.name"], ["def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "W", ".", "name", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.SL.args": [[336, 337], ["None"], "methods", ["None"], ["", "def", "args", "(", "class_type", "=", "'unconstrained'", ",", "layer_size", "=", "-", "1", ",", "r", "=", "1", ",", "bias", "=", "False", ",", "hidden_size", "=", "-", "1", ")", ":", "pass", "\n", "def", "reset_parameters", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.SL.reset_parameters": [[337, 344], ["structure.StructuredLinear", "structure.StructuredLinear"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear"], ["def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "layer_size", "==", "-", "1", ":", "\n", "            ", "self", ".", "layer_size", "=", "self", ".", "in_size", "\n", "", "if", "self", ".", "hidden_size", "==", "-", "1", ":", "\n", "            ", "self", ".", "hidden_size", "=", "self", ".", "in_size", "\n", "", "self", ".", "W", "=", "sl", ".", "StructuredLinear", "(", "self", ".", "class_type", ",", "layer_size", "=", "self", ".", "layer_size", ",", "r", "=", "self", ".", "r", ",", "bias", "=", "self", ".", "bias", ",", "\n", "hidden_size", "=", "self", ".", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.SL.forward": [[345, 347], ["nets.SL.W"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "W", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.SHL.args": [[352, 353], ["None"], "methods", ["None"], ["def", "args", "(", "class_type", "=", "'unconstrained'", ",", "layer_size", "=", "-", "1", ",", "r", "=", "1", ",", "bias", "=", "True", ",", "hidden_size", "=", "-", "1", ")", ":", "pass", "\n", "def", "reset_parameters", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.SHL.reset_parameters": [[353, 356], ["nets.SL.reset_parameters", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonalC.reset_parameters"], ["def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "reset_parameters", "(", ")", "\n", "self", ".", "W2", "=", "nn", ".", "Linear", "(", "self", ".", "hidden_size", ",", "self", ".", "out_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.SHL.forward": [[357, 359], ["nets.SHL.W2", "torch.relu", "torch.relu", "torch.relu", "nets.SHL.W"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "W2", "(", "F", ".", "relu", "(", "self", ".", "W", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.MLP.name": [[364, 366], ["nets.MLP.layers[].name"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.name"], ["def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "layers", "[", "0", "]", ".", "name", "(", ")", "\n", "", "def", "args", "(", "class_type", "=", "'unconstrained'", ",", "layer_size", "=", "-", "1", ",", "r", "=", "1", ",", "bias", "=", "True", ",", "num_layers", "=", "1", ")", ":", "pass", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.MLP.args": [[366, 367], ["None"], "methods", ["None"], ["", "def", "args", "(", "class_type", "=", "'unconstrained'", ",", "layer_size", "=", "-", "1", ",", "r", "=", "1", ",", "bias", "=", "True", ",", "num_layers", "=", "1", ")", ":", "pass", "\n", "def", "reset_parameters", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.MLP.reset_parameters": [[367, 375], ["range", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.Linear", "torch.Linear", "torch.Linear", "layers.append", "structure.StructuredLinear", "structure.StructuredLinear"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear"], ["def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "layer_size", "==", "-", "1", ":", "\n", "            ", "self", ".", "layer_size", "=", "self", ".", "in_size", "\n", "", "layers", "=", "[", "]", "\n", "for", "layer", "in", "range", "(", "self", ".", "num_layers", ")", ":", "\n", "            ", "layers", ".", "append", "(", "sl", ".", "StructuredLinear", "(", "self", ".", "class_type", ",", "layer_size", "=", "self", ".", "layer_size", ",", "r", "=", "self", ".", "r", ",", "bias", "=", "self", ".", "bias", ")", ")", "\n", "", "self", ".", "layers", "=", "nn", ".", "ModuleList", "(", "layers", ")", "\n", "self", ".", "W2", "=", "nn", ".", "Linear", "(", "self", ".", "layer_size", ",", "self", ".", "out_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.MLP.forward": [[376, 381], ["torch.relu", "torch.relu", "torch.relu", "range", "nets.MLP.W2", "torch.relu", "torch.relu", "torch.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "output", "=", "F", ".", "relu", "(", "self", ".", "layers", "[", "0", "]", "(", "x", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_layers", "-", "1", ")", ":", "\n", "            ", "output", "=", "F", ".", "relu", "(", "self", ".", "layers", "[", "i", "+", "1", "]", "(", "output", ")", ")", "\n", "", "return", "self", ".", "W2", "(", "output", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.models.nets.construct_model": [[12, 17], ["cls", "vars", "inspect.signature"], "function", ["None"], ["def", "construct_model", "(", "cls", ",", "in_size", ",", "out_size", ",", "args", ")", ":", "\n", "    ", "args_fn", "=", "cls", ".", "args", "\n", "options", "=", "{", "param", ":", "vars", "(", "args", ")", "[", "param", "]", "\n", "for", "param", "in", "signature", "(", "args_fn", ")", ".", "parameters", "}", "\n", "return", "cls", "(", "in_size", "=", "in_size", ",", "out_size", "=", "out_size", ",", "**", "options", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.train.test_split": [[11, 24], ["len", "net", "loss_fn", "batch_X.to", "batch_Y.to", "len", "loss_batch.data.item", "len", "acc_batch.data.item"], "function", ["None"], ["\n", "# Skip if not interested in multigpu.", "\n", "class", "MultiGPULossCompute", ":", "\n", "    ", "\"A multi-gpu loss compute and train function.\"", "\n", "def", "__init__", "(", "self", ",", "generator", ",", "criterion", ",", "devices", ",", "opt", "=", "None", ",", "chunk_size", "=", "5", ")", ":", "\n", "# Send out to different gpus.", "\n", "        ", "self", ".", "generator", "=", "generator", "\n", "self", ".", "criterion", "=", "nn", ".", "parallel", ".", "replicate", "(", "criterion", ",", "\n", "devices", "=", "devices", ")", "\n", "self", ".", "opt", "=", "opt", "\n", "self", ".", "devices", "=", "devices", "\n", "self", ".", "chunk_size", "=", "chunk_size", "\n", "\n", "", "def", "__call__", "(", "self", ",", "out", ",", "targets", ",", "normalize", ")", ":", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.train.train": [[27, 155], ["logging.debug", "logging.debug", "logging.debug", "os.makedirs", "tensorboardX.SummaryWriter", "net.to", "logging.debug", "net.named_parameters", "time.time", "train.test_split", "train.train.log_stats"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.train.test_split"], ["devices", "=", "self", ".", "devices", ")", "\n", "out_scatter", "=", "nn", ".", "parallel", ".", "scatter", "(", "out", ",", "\n", "target_gpus", "=", "self", ".", "devices", ")", "\n", "out_grad", "=", "[", "[", "]", "for", "_", "in", "out_scatter", "]", "\n", "targets", "=", "nn", ".", "parallel", ".", "scatter", "(", "targets", ",", "\n", "target_gpus", "=", "self", ".", "devices", ")", "\n", "\n", "# Divide generating into chunks.", "\n", "chunk_size", "=", "self", ".", "chunk_size", "\n", "for", "i", "in", "range", "(", "0", ",", "out_scatter", "[", "0", "]", ".", "size", "(", "1", ")", ",", "chunk_size", ")", ":", "\n", "# Predict distributions", "\n", "            ", "out_column", "=", "[", "[", "Variable", "(", "o", "[", ":", ",", "i", ":", "i", "+", "chunk_size", "]", ".", "data", ",", "\n", "requires_grad", "=", "self", ".", "opt", "is", "not", "None", ")", "]", "\n", "for", "o", "in", "out_scatter", "]", "\n", "gen", "=", "nn", ".", "parallel", ".", "parallel_apply", "(", "generator", ",", "out_column", ")", "\n", "\n", "# Compute loss. ", "\n", "y", "=", "[", "(", "g", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "g", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "t", "[", ":", ",", "i", ":", "i", "+", "chunk_size", "]", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", ")", "\n", "for", "g", ",", "t", "in", "zip", "(", "gen", ",", "targets", ")", "]", "\n", "loss", "=", "nn", ".", "parallel", ".", "parallel_apply", "(", "self", ".", "criterion", ",", "y", ")", "\n", "\n", "# Sum and normalize loss", "\n", "l", "=", "nn", ".", "parallel", ".", "gather", "(", "loss", ",", "\n", "target_device", "=", "self", ".", "devices", "[", "0", "]", ")", "\n", "l", "=", "l", ".", "sum", "(", ")", "[", "0", "]", "/", "normalize", "\n", "total", "+=", "l", ".", "data", "[", "0", "]", "\n", "\n", "# Backprop loss to output of transformer", "\n", "if", "self", ".", "opt", "is", "not", "None", ":", "\n", "                ", "l", ".", "backward", "(", ")", "\n", "for", "j", ",", "l", "in", "enumerate", "(", "loss", ")", ":", "\n", "                    ", "out_grad", "[", "j", "]", ".", "append", "(", "out_column", "[", "j", "]", "[", "0", "]", ".", "grad", ".", "data", ".", "clone", "(", ")", ")", "\n", "\n", "# Backprop all loss through transformer.            ", "\n", "", "", "", "if", "self", ".", "opt", "is", "not", "None", ":", "\n", "            ", "out_grad", "=", "[", "Variable", "(", "torch", ".", "cat", "(", "og", ",", "dim", "=", "1", ")", ")", "for", "og", "in", "out_grad", "]", "\n", "o1", "=", "out", "\n", "o2", "=", "nn", ".", "parallel", ".", "gather", "(", "out_grad", ",", "\n", "target_device", "=", "self", ".", "devices", "[", "0", "]", ")", "\n", "o1", ".", "backward", "(", "gradient", "=", "o2", ")", "\n", "self", ".", "opt", ".", "step", "(", ")", "\n", "self", ".", "opt", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "", "return", "total", "*", "normalize", "\n", "\n", "", "", "class", "MyIterator", "(", "data", ".", "Iterator", ")", ":", "\n", "    ", "def", "create_batches", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "train", ":", "\n", "            ", "def", "pool", "(", "d", ",", "random_shuffler", ")", ":", "\n", "                ", "for", "p", "in", "data", ".", "batch", "(", "d", ",", "self", ".", "batch_size", "*", "100", ")", ":", "\n", "                    ", "p_batch", "=", "data", ".", "batch", "(", "\n", "sorted", "(", "p", ",", "key", "=", "self", ".", "sort_key", ")", ",", "\n", "self", ".", "batch_size", ",", "self", ".", "batch_size_fn", ")", "\n", "for", "b", "in", "random_shuffler", "(", "list", "(", "p_batch", ")", ")", ":", "\n", "                        ", "yield", "b", "\n", "", "", "", "self", ".", "batches", "=", "pool", "(", "self", ".", "data", "(", ")", ",", "self", ".", "random_shuffler", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "batches", "=", "[", "]", "\n", "for", "b", "in", "data", ".", "batch", "(", "self", ".", "data", "(", ")", ",", "self", ".", "batch_size", ",", "\n", "self", ".", "batch_size_fn", ")", ":", "\n", "                ", "self", ".", "batches", ".", "append", "(", "sorted", "(", "b", ",", "key", "=", "self", ".", "sort_key", ")", ")", "\n", "\n", "", "", "", "", "def", "rebatch", "(", "pad_idx", ",", "batch", ")", ":", "\n", "    ", "\"Fix order in torchtext to match ours\"", "\n", "src", ",", "trg", "=", "batch", ".", "src", ".", "transpose", "(", "0", ",", "1", ")", ",", "batch", ".", "trg", ".", "transpose", "(", "0", ",", "1", ")", "\n", "return", "Batch", "(", "src", ",", "trg", ",", "pad_idx", ")", "\n", "\n", "", "class", "LabelSmoothing", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"Implement label smoothing.\"", "\n", "def", "__init__", "(", "self", ",", "size", ",", "padding_idx", ",", "smoothing", "=", "0.0", ")", ":", "\n", "        ", "super", "(", "LabelSmoothing", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "criterion", "=", "nn", ".", "KLDivLoss", "(", "size_average", "=", "False", ")", "\n", "self", ".", "padding_idx", "=", "padding_idx", "\n", "self", ".", "confidence", "=", "1.0", "-", "smoothing", "\n", "self", ".", "smoothing", "=", "smoothing", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "true_dist", "=", "None", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "target", ")", ":", "\n", "        ", "assert", "x", ".", "size", "(", "1", ")", "==", "self", ".", "size", "\n", "true_dist", "=", "x", ".", "data", ".", "clone", "(", ")", "\n", "true_dist", ".", "fill_", "(", "self", ".", "smoothing", "/", "(", "self", ".", "size", "-", "2", ")", ")", "\n", "true_dist", ".", "scatter_", "(", "1", ",", "target", ".", "data", ".", "unsqueeze", "(", "1", ")", ",", "self", ".", "confidence", ")", "\n", "true_dist", "[", ":", ",", "self", ".", "padding_idx", "]", "=", "0", "\n", "mask", "=", "torch", ".", "nonzero", "(", "target", ".", "data", "==", "self", ".", "padding_idx", ")", "\n", "if", "mask", ".", "dim", "(", ")", ">", "0", ":", "\n", "            ", "true_dist", ".", "index_fill_", "(", "0", ",", "mask", ".", "squeeze", "(", ")", ",", "0.0", ")", "\n", "", "self", ".", "true_dist", "=", "true_dist", "\n", "return", "self", ".", "criterion", "(", "x", ",", "Variable", "(", "true_dist", ",", "requires_grad", "=", "False", ")", ")", "\n", "\n", "", "", "class", "Batch", ":", "\n", "    ", "\"Object for holding a batch of data with mask during training.\"", "\n", "def", "__init__", "(", "self", ",", "src", ",", "trg", "=", "None", ",", "pad", "=", "0", ")", ":", "\n", "        ", "self", ".", "src", "=", "src", "\n", "self", ".", "src_mask", "=", "(", "src", "!=", "pad", ")", ".", "unsqueeze", "(", "-", "2", ")", "\n", "if", "trg", "is", "not", "None", ":", "\n", "            ", "self", ".", "trg", "=", "trg", "[", ":", ",", ":", "-", "1", "]", "\n", "self", ".", "trg_y", "=", "trg", "[", ":", ",", "1", ":", "]", "\n", "self", ".", "trg_mask", "=", "self", ".", "make_std_mask", "(", "self", ".", "trg", ",", "pad", ")", "\n", "self", ".", "ntokens", "=", "(", "self", ".", "trg_y", "!=", "pad", ")", ".", "data", ".", "sum", "(", ")", "\n", "\n", "", "", "@", "staticmethod", "\n", "def", "make_std_mask", "(", "tgt", ",", "pad", ")", ":", "\n", "        ", "\"Create a mask to hide padding and future words.\"", "\n", "tgt_mask", "=", "(", "tgt", "!=", "pad", ")", ".", "unsqueeze", "(", "-", "2", ")", "\n", "tgt_mask", "=", "tgt_mask", "&", "Variable", "(", "\n", "subsequent_mask", "(", "tgt", ".", "size", "(", "-", "1", ")", ")", ".", "type_as", "(", "tgt_mask", ".", "data", ")", ")", "\n", "return", "tgt_mask", "\n", "\n", "", "", "def", "run_epoch", "(", "data_iter", ",", "model", ",", "loss_compute", ")", ":", "\n", "    ", "\"Standard Training and Logging Function\"", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "total_tokens", "=", "0", "\n", "total_loss", "=", "0", "\n", "tokens", "=", "0", "\n", "for", "i", ",", "batch", "in", "enumerate", "(", "data_iter", ")", ":", "\n", "        ", "out", "=", "model", ".", "forward", "(", "batch", ".", "src", ",", "batch", ".", "trg", ",", "\n", "batch", ".", "src_mask", ",", "batch", ".", "trg_mask", ")", "\n", "loss", "=", "loss_compute", "(", "out", ",", "batch", ".", "trg_y", ",", "batch", ".", "ntokens", ")", "\n", "total_loss", "+=", "loss", "\n", "total_tokens", "+=", "batch", ".", "ntokens", "\n", "tokens", "+=", "batch", ".", "ntokens", "\n", "if", "i", "%", "50", "==", "1", ":", "\n", "            ", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start", "\n", "print", "(", "(", "\"Epoch Step: %d Loss: %f Tokens per Sec: %f\"", "%", "\n", "(", "i", ",", "loss", "/", "batch", ".", "ntokens", ",", "tokens", "/", "elapsed", ")", ")", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.prune.generate_mask": [[7, 18], ["W.W.cpu().data.numpy", "int", "numpy.zeros", "Z.reshape.reshape", "numpy.abs().argsort", "W.W.cpu", "numpy.abs", "W.W.cpu().data.numpy.flatten"], "function", ["None"], ["def", "generate_mask", "(", "W", ",", "prune_factor", ")", ":", "\n", "    ", "weights", "=", "W", ".", "W", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "N", "=", "int", "(", "weights", ".", "size", "/", "prune_factor", ")", "\n", "# Get indices of N highest magnitude weights", "\n", "idx", "=", "np", ".", "abs", "(", "weights", ".", "flatten", "(", ")", ")", ".", "argsort", "(", ")", "[", "-", "N", ":", "]", "[", ":", ":", "-", "1", "]", "\n", "\n", "Z", "=", "np", ".", "zeros", "(", "weights", ".", "size", ")", "\n", "Z", "[", "idx", "]", "=", "1", "\n", "Z", "=", "Z", ".", "reshape", "(", "weights", ".", "shape", ")", "\n", "\n", "return", "Z", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.prune.set_masks": [[19, 23], ["prune.generate_mask", "layer.set_mask"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.prune.generate_mask", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Unconstrained.set_mask"], ["", "def", "set_masks", "(", "net", ",", "prune_factor", ",", "device", ")", ":", "\n", "    ", "for", "layer", "in", "net", ".", "layers", ":", "\n", "        ", "mask", "=", "generate_mask", "(", "layer", ",", "prune_factor", ")", "\n", "layer", ".", "set_mask", "(", "mask", ",", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.prune.prune": [[24, 37], ["learning.train.train", "range", "prune.set_masks", "learning.train.train"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.train.train", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.prune.set_masks", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.learning.train.train"], ["", "", "def", "prune", "(", "dataset", ",", "net", ",", "optimizer", ",", "lr_scheduler", ",", "epochs", ",", "log_freq", ",", "log_path", ",", "checkpoint_path", ",", "result_path", ",", "test", ",", "save", ",", "prune_lr_decay", ",", "prune_factor", ",", "prune_iters", ")", ":", "\n", "# Initial training", "\n", "    ", "train", ".", "train", "(", "dataset", ",", "net", ",", "optimizer", ",", "lr_scheduler", ",", "epochs", ",", "log_freq", ",", "log_path", ",", "checkpoint_path", ",", "result_path", ",", "0", ",", "save", ")", "\n", "\n", "for", "i", "in", "range", "(", "prune_iters", ")", ":", "\n", "        ", "set_masks", "(", "net", ",", "prune_factor", ",", "device", ")", "\n", "\n", "# Update learning rate", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "            ", "param_group", "[", "'lr'", "]", "=", "prune_lr_decay", "*", "param_group", "[", "'lr'", "]", "\n", "\n", "# Retrain", "\n", "", "train", ".", "train", "(", "dataset", ",", "net", ",", "optimizer", ",", "lr_scheduler", ",", "epochs", ",", "log_freq", ",", "log_path", ",", "checkpoint_path", ",", "result_path", ",", "test", ",", "save", ",", "(", "i", "+", "1", ")", "*", "epochs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz.toeplitz_krylov_transpose_multiply": [[14, 48], ["torch.ifft", "torch.fft", "complex_utils.complex_mult", "torch.fft", "torch.rfft", "torch.rfft", "complex_utils.complex_mult", "[].flip", "abs", "torch.stack", "torch.stack", "complex_utils.conjugate", "torch.cat", "torch.cat", "torch.arange", "torch.ones", "torch.zeros", "torch.arange", "torch.cos", "torch.sin", "u.flip", "torch.zeros_like", "torch.zeros_like", "torch.irfft"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.complex_utils.complex_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.complex_utils.complex_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.complex_utils.conjugate"], ["def", "toeplitz_krylov_transpose_multiply", "(", "v", ",", "u", ",", "f", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"Multiply Krylov(Z_f, v_i)^T @ u.\n    Parameters:\n        v: (rank, n)\n        u: (batch_size, n)\n        f: real number\n    Returns:\n        product: (batch, rank, n)\n    \"\"\"", "\n", "_", ",", "n", "=", "u", ".", "shape", "\n", "_", ",", "n_", "=", "v", ".", "shape", "\n", "assert", "n", "==", "n_", ",", "'u and v must have the same last dimension'", "\n", "if", "f", "!=", "0.0", ":", "# cycle version", "\n", "# Computing the roots of f", "\n", "        ", "mod", "=", "abs", "(", "f", ")", "**", "(", "torch", ".", "arange", "(", "n", ",", "dtype", "=", "u", ".", "dtype", ",", "device", "=", "u", ".", "device", ")", "/", "n", ")", "\n", "if", "f", ">", "0", ":", "\n", "            ", "arg", "=", "torch", ".", "stack", "(", "(", "torch", ".", "ones", "(", "n", ",", "dtype", "=", "u", ".", "dtype", ",", "device", "=", "u", ".", "device", ")", ",", "\n", "torch", ".", "zeros", "(", "n", ",", "dtype", "=", "u", ".", "dtype", ",", "device", "=", "u", ".", "device", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "# Find primitive roots of -1", "\n", "            ", "angles", "=", "torch", ".", "arange", "(", "n", ",", "dtype", "=", "u", ".", "dtype", ",", "device", "=", "u", ".", "device", ")", "/", "n", "*", "np", ".", "pi", "\n", "arg", "=", "torch", ".", "stack", "(", "(", "torch", ".", "cos", "(", "angles", ")", ",", "torch", ".", "sin", "(", "angles", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "eta", "=", "mod", "[", ":", ",", "np", ".", "newaxis", "]", "*", "arg", "\n", "eta_inverse", "=", "(", "1.0", "/", "mod", ")", "[", ":", ",", "np", ".", "newaxis", "]", "*", "conjugate", "(", "arg", ")", "\n", "u_f", "=", "torch", ".", "ifft", "(", "eta_inverse", "*", "u", "[", "...", ",", "np", ".", "newaxis", "]", ",", "1", ")", "\n", "v_f", "=", "torch", ".", "fft", "(", "eta", "*", "v", "[", "...", ",", "np", ".", "newaxis", "]", ",", "1", ")", "\n", "uv_f", "=", "complex_mult", "(", "u_f", "[", ":", ",", "np", ".", "newaxis", "]", ",", "v_f", "[", "np", ".", "newaxis", "]", ")", "\n", "uv", "=", "torch", ".", "fft", "(", "uv_f", ",", "1", ")", "\n", "# We only need the real part of complex_mult(eta, uv)", "\n", "return", "eta", "[", "...", ",", "0", "]", "*", "uv", "[", "...", ",", "0", "]", "-", "eta", "[", "...", ",", "1", "]", "*", "uv", "[", "...", ",", "1", "]", "\n", "", "else", ":", "\n", "        ", "u_f", "=", "torch", ".", "rfft", "(", "torch", ".", "cat", "(", "(", "u", ".", "flip", "(", "1", ")", ",", "torch", ".", "zeros_like", "(", "u", ")", ")", ",", "dim", "=", "-", "1", ")", ",", "1", ")", "\n", "v_f", "=", "torch", ".", "rfft", "(", "torch", ".", "cat", "(", "(", "v", ",", "torch", ".", "zeros_like", "(", "v", ")", ")", ",", "dim", "=", "-", "1", ")", ",", "1", ")", "\n", "uv_f", "=", "complex_mult", "(", "u_f", "[", ":", ",", "np", ".", "newaxis", "]", ",", "v_f", "[", "np", ".", "newaxis", "]", ")", "\n", "return", "torch", ".", "irfft", "(", "uv_f", ",", "1", ",", "signal_sizes", "=", "(", "2", "*", "n", ",", ")", ")", "[", "...", ",", ":", "n", "]", ".", "flip", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz.toeplitz_krylov_multiply_by_autodiff": [[50, 69], ["torch.zeros", "toeplitz.toeplitz_krylov_transpose_multiply", "torch.autograd.grad"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz.toeplitz_krylov_transpose_multiply"], ["", "", "def", "toeplitz_krylov_multiply_by_autodiff", "(", "v", ",", "w", ",", "f", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"Multiply \\sum_i Krylov(Z_f, v_i) @ w_i, using Pytorch's autodiff.\n    This function is just to check the result of toeplitz_krylov_multiply.\n    Parameters:\n        v: (rank, n)\n        w: (batch_size, rank, n)\n        f: real number\n    Returns:\n        product: (batch, n)\n    \"\"\"", "\n", "batch_size", ",", "rank", ",", "n", "=", "w", ".", "shape", "\n", "rank_", ",", "n_", "=", "v", ".", "shape", "\n", "assert", "n", "==", "n_", ",", "'w and v must have the same last dimension'", "\n", "assert", "rank", "==", "rank_", ",", "'w and v must have the same rank'", "\n", "\n", "u", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "n", ")", ",", "dtype", "=", "v", ".", "dtype", ",", "device", "=", "v", ".", "device", ",", "requires_grad", "=", "True", ")", "\n", "prod", "=", "toeplitz_krylov_transpose_multiply", "(", "v", ",", "u", ",", "f", ")", "\n", "result", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "prod", ",", "u", ",", "grad_outputs", "=", "w", ",", "create_graph", "=", "True", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz.toeplitz_krylov_multiply": [[71, 106], ["torch.fft", "torch.fft", "complex_utils.complex_mult().sum", "torch.ifft", "torch.rfft", "torch.rfft", "complex_utils.complex_mult().sum", "abs", "torch.stack", "torch.stack", "complex_utils.conjugate", "torch.cat", "torch.cat", "torch.irfft", "torch.arange", "complex_utils.complex_mult", "complex_utils.complex_mult", "torch.ones", "torch.zeros", "torch.arange", "torch.cos", "torch.sin", "torch.zeros_like", "torch.zeros_like"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.complex_utils.conjugate", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.complex_utils.complex_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.complex_utils.complex_mult"], ["", "def", "toeplitz_krylov_multiply", "(", "v", ",", "w", ",", "f", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"Multiply \\sum_i Krylov(Z_f, v_i) @ w_i.\n    Parameters:\n        v: (rank, n)\n        w: (batch_size, rank, n)\n        f: real number\n    Returns:\n        product: (batch, n)\n    \"\"\"", "\n", "_", ",", "rank", ",", "n", "=", "w", ".", "shape", "\n", "rank_", ",", "n_", "=", "v", ".", "shape", "\n", "assert", "n", "==", "n_", ",", "'w and v must have the same last dimension'", "\n", "assert", "rank", "==", "rank_", ",", "'w and v must have the same rank'", "\n", "if", "f", "!=", "0.0", ":", "# cycle version", "\n", "# Computing the roots of f", "\n", "        ", "mod", "=", "abs", "(", "f", ")", "**", "(", "torch", ".", "arange", "(", "n", ",", "dtype", "=", "w", ".", "dtype", ",", "device", "=", "w", ".", "device", ")", "/", "n", ")", "\n", "if", "f", ">", "0", ":", "\n", "            ", "arg", "=", "torch", ".", "stack", "(", "(", "torch", ".", "ones", "(", "n", ",", "dtype", "=", "w", ".", "dtype", ",", "device", "=", "w", ".", "device", ")", ",", "\n", "torch", ".", "zeros", "(", "n", ",", "dtype", "=", "w", ".", "dtype", ",", "device", "=", "w", ".", "device", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "# Find primitive roots of -1", "\n", "            ", "angles", "=", "torch", ".", "arange", "(", "n", ",", "dtype", "=", "w", ".", "dtype", ",", "device", "=", "w", ".", "device", ")", "/", "n", "*", "np", ".", "pi", "\n", "arg", "=", "torch", ".", "stack", "(", "(", "torch", ".", "cos", "(", "angles", ")", ",", "torch", ".", "sin", "(", "angles", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "eta", "=", "mod", "[", ":", ",", "np", ".", "newaxis", "]", "*", "arg", "\n", "eta_inverse", "=", "(", "1.0", "/", "mod", ")", "[", ":", ",", "np", ".", "newaxis", "]", "*", "conjugate", "(", "arg", ")", "\n", "w_f", "=", "torch", ".", "fft", "(", "eta", "*", "w", "[", "...", ",", "np", ".", "newaxis", "]", ",", "1", ")", "\n", "v_f", "=", "torch", ".", "fft", "(", "eta", "*", "v", "[", "...", ",", "np", ".", "newaxis", "]", ",", "1", ")", "\n", "wv_sum_f", "=", "complex_mult", "(", "w_f", ",", "v_f", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "wv_sum", "=", "torch", ".", "ifft", "(", "wv_sum_f", ",", "1", ")", "\n", "# We only need the real part of complex_mult(eta_inverse, wv_sum)", "\n", "return", "eta_inverse", "[", "...", ",", "0", "]", "*", "wv_sum", "[", "...", ",", "0", "]", "-", "eta_inverse", "[", "...", ",", "1", "]", "-", "wv_sum", "[", "...", ",", "1", "]", "\n", "", "else", ":", "\n", "        ", "w_f", "=", "torch", ".", "rfft", "(", "torch", ".", "cat", "(", "(", "w", ",", "torch", ".", "zeros_like", "(", "w", ")", ")", ",", "dim", "=", "-", "1", ")", ",", "1", ")", "\n", "v_f", "=", "torch", ".", "rfft", "(", "torch", ".", "cat", "(", "(", "v", ",", "torch", ".", "zeros_like", "(", "v", ")", ")", ",", "dim", "=", "-", "1", ")", ",", "1", ")", "\n", "wv_sum_f", "=", "complex_mult", "(", "w_f", ",", "v_f", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "return", "torch", ".", "irfft", "(", "wv_sum_f", ",", "1", ",", "signal_sizes", "=", "(", "2", "*", "n", ",", ")", ")", "[", "...", ",", ":", "n", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz.toeplitz_mult": [[108, 122], ["toeplitz.toeplitz_krylov_transpose_multiply", "toeplitz.toeplitz_krylov_multiply"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz.toeplitz_krylov_transpose_multiply", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz.toeplitz_krylov_multiply"], ["", "", "def", "toeplitz_mult", "(", "G", ",", "H", ",", "x", ",", "cycle", "=", "True", ")", ":", "\n", "    ", "\"\"\"Multiply \\sum_i Krylov(Z_f, G_i) @ Krylov(Z_f, H_i) @ x.\n    Parameters:\n        G: Tensor of shape (rank, n)\n        H: Tensor of shape (rank, n)\n        x: Tensor of shape (batch_size, n)\n        cycle: whether to use f = (1, -1) or f = (0, 0)\n    Returns:\n        product: Tensor of shape (batch_size, n)\n    \"\"\"", "\n", "# f = (1,-1) if cycle else (1,1)", "\n", "f", "=", "(", "1", ",", "-", "1", ")", "if", "cycle", "else", "(", "0", ",", "0", ")", "\n", "transpose_out", "=", "toeplitz_krylov_transpose_multiply", "(", "H", ",", "x", ",", "f", "[", "1", "]", ")", "\n", "return", "toeplitz_krylov_multiply", "(", "G", ",", "transpose_out", ",", "f", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz.toeplitz_Z_f_linear_map": [[126, 135], ["torch.cat"], "function", ["None"], ["", "def", "toeplitz_Z_f_linear_map", "(", "f", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"The linear map for multiplying by Z_f.\n    This implementation is slow and not batched wrt rank, but easy to understand.\n    Parameters:\n        f: real number\n    Returns:\n        linear_map: v -> product, with v of shape (n, )\n    \"\"\"", "\n", "return", "lambda", "v", ":", "torch", ".", "cat", "(", "(", "f", "*", "v", "[", "[", "-", "1", "]", "]", ",", "v", "[", ":", "-", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz.krylov_toeplitz_fast": [[137, 154], ["torch.arange"], "function", ["None"], ["", "def", "krylov_toeplitz_fast", "(", "v", ",", "f", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"Explicit construction of Krylov matrix [v  A @ v  A^2 @ v  ...  A^{n-1} @ v]\n    where A = Z_f. This uses vectorized indexing and cumprod so it's much\n    faster than using the Krylov function.\n    Parameters:\n        v: the starting vector of size n or (rank, n).\n        f: real number\n    Returns:\n        K: Krylov matrix of size (n, n) or (rank, n, n).\n    \"\"\"", "\n", "rank", ",", "n", "=", "v", ".", "shape", "\n", "a", "=", "torch", ".", "arange", "(", "n", ",", "device", "=", "v", ".", "device", ")", "\n", "b", "=", "-", "a", "\n", "indices", "=", "a", "[", ":", ",", "np", ".", "newaxis", "]", "+", "b", "[", "np", ".", "newaxis", "]", "\n", "K", "=", "v", "[", ":", ",", "indices", "]", "\n", "K", "[", ":", ",", "indices", "<", "0", "]", "*=", "f", "\n", "return", "K", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz.toeplitz_mult_slow": [[156, 174], ["sum().t", "krylov.Krylov", "krylov.Krylov().t", "range", "sum", "toeplitz.toeplitz_Z_f_linear_map", "x.t", "krylov.Krylov", "toeplitz.toeplitz_Z_f_linear_map"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz.toeplitz_Z_f_linear_map", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz.toeplitz_Z_f_linear_map"], ["", "def", "toeplitz_mult_slow", "(", "G", ",", "H", ",", "x", ",", "cycle", "=", "True", ")", ":", "\n", "    ", "\"\"\"Multiply \\sum_i Krylov(Z_f, G_i) @ Krylov(Z_f, H_i) @ x.\n    Uses the explicit Krylov construction with slow (and easy to understand)\n    linear map.\n    Parameters:\n        G: Tensor of shape (rank, n)\n        H: Tensor of shape (rank, n)\n        x: Tensor of shape (batch_size, n)\n        cycle: whether to use f = (1, -1) or f = (0, 0)\n    Returns:\n        product: Tensor of shape (batch_size, n)\n    \"\"\"", "\n", "assert", "G", ".", "shape", "==", "H", ".", "shape", ",", "'G and H must have the same shape'", "\n", "rank", ",", "n", "=", "G", ".", "shape", "\n", "f", "=", "(", "1", ",", "-", "1", ")", "if", "cycle", "else", "(", "0", ",", "0", ")", "\n", "krylovs", "=", "[", "(", "Krylov", "(", "toeplitz_Z_f_linear_map", "(", "f", "[", "0", "]", ")", ",", "G", "[", "i", "]", ")", ",", "Krylov", "(", "toeplitz_Z_f_linear_map", "(", "f", "[", "1", "]", ")", ",", "H", "[", "i", "]", ")", ".", "t", "(", ")", ")", "for", "i", "in", "range", "(", "rank", ")", "]", "\n", "prods", "=", "[", "K", "[", "0", "]", "@", "(", "K", "[", "1", "]", "@", "x", ".", "t", "(", ")", ")", "for", "K", "in", "krylovs", "]", "\n", "return", "sum", "(", "prods", ")", ".", "t", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz.toeplitz_mult_slow_fast": [[176, 191], ["toeplitz.krylov_toeplitz_fast", "toeplitz.krylov_toeplitz_fast", "K_G.transpose"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz.krylov_toeplitz_fast", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz.krylov_toeplitz_fast"], ["", "def", "toeplitz_mult_slow_fast", "(", "G", ",", "H", ",", "x", ",", "cycle", "=", "True", ")", ":", "\n", "    ", "\"\"\"Multiply \\sum_i Krylov(Z_f, G_i) @ Krylov(Z_f, H_i) @ x.\n    Uses the fast construction of Krylov matrix.\n    Parameters:\n        G: Tensor of shape (rank, n)\n        H: Tensor of shape (rank, n)\n        x: Tensor of shape (batch_size, n)\n        cycle: whether to use f = (1, -1) or f = (0, 0)\n    Returns:\n        product: Tensor of shape (batch_size, n)\n    \"\"\"", "\n", "assert", "G", ".", "shape", "==", "H", ".", "shape", "\n", "f_G", ",", "f_H", "=", "(", "1", ",", "-", "1", ")", "if", "cycle", "else", "(", "0", ",", "0", ")", "\n", "K_G", ",", "K_H", "=", "krylov_toeplitz_fast", "(", "G", ",", "f_G", ")", ",", "krylov_toeplitz_fast", "(", "H", ",", "f_H", ")", "\n", "return", "(", "(", "x", "@", "K_H", ")", "@", "K_G", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz.test_toeplitz_mult": [[193, 238], ["torch.tensor", "torch.tensor", "toeplitz.toeplitz_krylov_transpose_multiply", "toeplitz.toeplitz_mult", "toeplitz.toeplitz_mult_slow", "toeplitz.toeplitz_mult", "toeplitz.toeplitz_mult_slow", "torch.rand", "torch.rand", "toeplitz.toeplitz_mult", "torch.autograd.grad", "toeplitz.toeplitz_mult_slow", "torch.autograd.grad", "toeplitz.toeplitz_mult_slow_fast", "torch.autograd.grad", "print", "print", "print", "print", "print", "print", "print", "print", "toeplitz_mult.sum", "toeplitz_mult_slow.sum", "toeplitz_mult_slow_fast.sum"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz.toeplitz_krylov_transpose_multiply", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz_cpu.toeplitz_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz_cpu.toeplitz_mult_slow", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz_cpu.toeplitz_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz_cpu.toeplitz_mult_slow", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz_cpu.toeplitz_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz_cpu.toeplitz_mult_slow", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz.toeplitz_mult_slow_fast"], ["", "def", "test_toeplitz_mult", "(", ")", ":", "\n", "    ", "v", "=", "torch", ".", "tensor", "(", "[", "[", "0", ",", "1", ",", "0", ",", "-", "1", "]", ",", "[", "0", ",", "1", ",", "2", ",", "3", "]", "]", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ",", "requires_grad", "=", "True", ")", "\n", "u", "=", "torch", ".", "tensor", "(", "[", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "[", "0", ",", "1", ",", "2", ",", "3", "]", "]", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ",", "requires_grad", "=", "True", ")", "\n", "\n", "w", "=", "toeplitz_krylov_transpose_multiply", "(", "v", ",", "u", ",", "f", "=", "-", "1", ")", "\n", "# output:", "\n", "# [[[ 0 2  2 0]", "\n", "#   [ 6 0 -4 -6]]", "\n", "\n", "#  [[ -2 2 4  2]", "\n", "#   [ 14 8 0 -8]]]", "\n", "\n", "toeplitz_mult", "(", "v", ",", "v", ",", "u", ")", "\n", "toeplitz_mult_slow", "(", "v", ",", "v", ",", "u", ")", "\n", "# output:", "\n", "# array([[-16., -20.,  -4.,  16.],", "\n", "#        [ 16.,  -8.,  12.,  64.]])", "\n", "\n", "toeplitz_mult", "(", "v", ",", "v", ",", "u", ",", "cycle", "=", "False", ")", "\n", "toeplitz_mult_slow", "(", "v", ",", "v", ",", "u", ",", "cycle", "=", "False", ")", "\n", "# output:", "\n", "# array([[ 0.,  6., 16., 26.],", "\n", "#        [ 0., 12., 38., 66.]])", "\n", "\n", "m", "=", "10", "\n", "n", "=", "1", "<<", "m", "\n", "batch_size", "=", "50", "\n", "rank", "=", "16", "\n", "u", "=", "torch", ".", "rand", "(", "(", "batch_size", ",", "n", ")", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "\n", "v", "=", "torch", ".", "rand", "(", "(", "rank", ",", "n", ")", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "\n", "result", "=", "toeplitz_mult", "(", "v", ",", "v", ",", "u", ",", "cycle", "=", "True", ")", "\n", "grad", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "result", ".", "sum", "(", ")", ",", "v", ",", "retain_graph", "=", "True", ")", "\n", "result_slow", "=", "toeplitz_mult_slow", "(", "v", ",", "v", ",", "u", ",", "cycle", "=", "True", ")", "\n", "grad_slow", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "result_slow", ".", "sum", "(", ")", ",", "v", ",", "retain_graph", "=", "True", ")", "\n", "result_slow_fast", "=", "toeplitz_mult_slow_fast", "(", "v", ",", "v", ",", "u", ",", "cycle", "=", "True", ")", "\n", "grad_slow_fast", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "result_slow_fast", ".", "sum", "(", ")", ",", "v", ",", "retain_graph", "=", "True", ")", "\n", "# These max and mean errors should be small", "\n", "print", "(", "(", "result", "-", "result_slow", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_slow", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_slow", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_slow", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_slow_fast", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_slow_fast", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_slow_fast", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_slow_fast", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz.test_memory": [[240, 248], ["range", "torch.empty", "torch.empty", "toeplitz.toeplitz_mult", "torch.autograd.grad", "torch.sum"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz_cpu.toeplitz_mult"], ["", "def", "test_memory", "(", ")", ":", "\n", "    ", "\"\"\"Memory stress test to make sure there's no memory leak.\n    \"\"\"", "\n", "for", "_", "in", "range", "(", "10000", ")", ":", "\n", "        ", "a", "=", "torch", ".", "empty", "(", "(", "2", ",", "4096", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ",", "requires_grad", "=", "True", ")", "\n", "b", "=", "torch", ".", "empty", "(", "(", "2", ",", "4096", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ",", "requires_grad", "=", "True", ")", "\n", "c", "=", "toeplitz_mult", "(", "a", ",", "a", ",", "b", ")", "\n", "g", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "torch", ".", "sum", "(", "c", ")", ",", "a", ",", "retain_graph", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz_cpu.KT_Toeplitz.__init__": [[11, 29], ["int", "numpy.log2", "numpy.power", "numpy.abs", "numpy.ones", "numpy.arange", "numpy.fft.fft", "numpy.eye"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "n", ",", "f", "=", "0", ",", "batch_size", "=", "1", ",", "rank", "=", "1", ")", ":", "\n", "        ", "m", "=", "int", "(", "np", ".", "log2", "(", "n", ")", ")", "\n", "assert", "n", "==", "1", "<<", "m", ",", "'n must be a power of 2'", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "m", "=", "m", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "rank", "=", "rank", "\n", "\n", "self", ".", "eta", "=", "None", "\n", "if", "f", "==", "0", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "mod", "=", "np", ".", "power", "(", "np", ".", "abs", "(", "f", ")", ",", "np", ".", "arange", "(", "n", ")", "/", "n", ")", "\n", "if", "f", ">", "0", ":", "\n", "                ", "arg", "=", "np", ".", "ones", "(", "n", ")", "\n", "", "else", ":", "\n", "                ", "arg", "=", "np", ".", "fft", ".", "fft", "(", "np", ".", "eye", "(", "1", ",", "2", "*", "n", ",", "2", "*", "n", "-", "1", ")", ")", "[", "0", ",", ":", "n", "]", "\n", "", "self", ".", "eta", "=", "mod", "*", "arg", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz_cpu.KT_Toeplitz.__call__": [[31, 52], ["numpy.fft.ifft", "numpy.fft.fft", "numpy.real", "numpy.fft.rfft", "numpy.fft.rfft", "numpy.fft.rfft.reshape", "numpy.fft.rfft.reshape", "numpy.fft.fft", "numpy.concatenate", "numpy.concatenate", "numpy.fft.rfft.reshape", "numpy.fft.rfft.reshape", "numpy.fft.irfft", "numpy.zeros_like", "numpy.zeros_like"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "v", ",", "u", ")", ":", "\n", "        ", "\"\"\"\n        Multiply Krylov(Z_f, v)^T @ u\n        v: (rank, n)\n        u: (batch, n)\n        out: (batch, rank, n)\n        \"\"\"", "\n", "n", ",", "m", ",", "batch_size", ",", "rank", "=", "self", ".", "n", ",", "self", ".", "m", ",", "self", ".", "batch_size", ",", "self", ".", "rank", "\n", "\n", "if", "self", ".", "eta", "is", "not", "None", ":", "# cycle version", "\n", "            ", "u_", "=", "np", ".", "fft", ".", "ifft", "(", "1", "/", "self", ".", "eta", "*", "u", ")", "\n", "v_", "=", "np", ".", "fft", ".", "fft", "(", "self", ".", "eta", "*", "v", ")", "\n", "uv_", "=", "u_", ".", "reshape", "(", "batch_size", ",", "1", ",", "n", ")", "*", "v_", ".", "reshape", "(", "1", ",", "rank", ",", "n", ")", "\n", "ans", "=", "self", ".", "eta", "*", "np", ".", "fft", ".", "fft", "(", "uv_", ")", "\n", "return", "np", ".", "real", "(", "ans", ")", "\n", "", "else", ":", "\n", "            ", "u_", "=", "np", ".", "fft", ".", "rfft", "(", "np", ".", "concatenate", "(", "(", "u", "[", "...", ",", ":", ":", "-", "1", "]", ",", "np", ".", "zeros_like", "(", "u", ")", ")", ",", "axis", "=", "-", "1", ")", ")", "\n", "v_", "=", "np", ".", "fft", ".", "rfft", "(", "np", ".", "concatenate", "(", "(", "v", ",", "np", ".", "zeros_like", "(", "v", ")", ")", ",", "axis", "=", "-", "1", ")", ")", "\n", "uv_", "=", "u_", ".", "reshape", "(", "batch_size", ",", "1", ",", "-", "1", ")", "*", "v_", ".", "reshape", "(", "1", ",", "rank", ",", "-", "1", ")", "\n", "ans", "=", "np", ".", "fft", ".", "irfft", "(", "uv_", ")", "[", "...", ",", "n", "-", "1", ":", ":", "-", "1", "]", "\n", "return", "ans", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz_cpu.K_Toeplitz.__init__": [[58, 77], ["int", "numpy.log2", "numpy.power", "numpy.abs", "numpy.ones", "numpy.arange", "numpy.fft.fft", "numpy.eye"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "n", ",", "f", ",", "batch_size", "=", "1", ",", "rank", "=", "1", ")", ":", "\n", "        ", "m", "=", "int", "(", "np", ".", "log2", "(", "n", ")", ")", "\n", "assert", "n", "==", "1", "<<", "m", ",", "'n must be a power of 2'", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "m", "=", "m", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "rank", "=", "rank", "\n", "\n", "self", ".", "eta", "=", "None", "\n", "if", "f", "==", "0", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "mod", "=", "np", ".", "power", "(", "np", ".", "abs", "(", "f", ")", ",", "np", ".", "arange", "(", "n", ")", "/", "n", ")", "\n", "if", "f", ">", "0", ":", "\n", "                ", "arg", "=", "np", ".", "ones", "(", "n", ")", "\n", "", "else", ":", "\n", "                ", "arg", "=", "np", ".", "fft", ".", "fft", "(", "np", ".", "eye", "(", "1", ",", "2", "*", "n", ",", "2", "*", "n", "-", "1", ")", ")", "[", "0", ",", ":", "n", "]", "\n", "# arg = np.exp(np.arange(n) * 1j * np.pi / n)", "\n", "", "self", ".", "eta", "=", "mod", "*", "arg", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz_cpu.K_Toeplitz.__call__": [[78, 97], ["numpy.fft.fft", "numpy.fft.fft", "numpy.real", "numpy.fft.rfft", "numpy.fft.rfft", "numpy.fft.rfft.reshape", "numpy.fft.ifft", "numpy.concatenate", "numpy.concatenate", "numpy.fft.rfft.reshape", "numpy.fft.irfft", "numpy.sum", "numpy.sum", "numpy.zeros_like", "numpy.zeros_like"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "v", ",", "w", ")", ":", "\n", "        ", "\"\"\"\n        v: (rank, n)\n        w: (batch_size, rank, n)\n        out: (batch_size, n)\n        \"\"\"", "\n", "n", ",", "m", ",", "batch_size", ",", "rank", "=", "self", ".", "n", ",", "self", ".", "m", ",", "self", ".", "batch_size", ",", "self", ".", "rank", "\n", "if", "self", ".", "eta", "is", "not", "None", ":", "\n", "            ", "w_", "=", "np", ".", "fft", ".", "fft", "(", "self", ".", "eta", "*", "w", ")", "\n", "v_", "=", "np", ".", "fft", ".", "fft", "(", "self", ".", "eta", "*", "v", ")", "\n", "wv_", "=", "w_", "*", "v_", ".", "reshape", "(", "(", "1", ",", "rank", ",", "n", ")", ")", "\n", "ans", "=", "1", "/", "self", ".", "eta", "*", "np", ".", "fft", ".", "ifft", "(", "np", ".", "sum", "(", "wv_", ",", "axis", "=", "1", ")", ")", "\n", "ans", "=", "np", ".", "real", "(", "ans", ")", "\n", "", "else", ":", "\n", "            ", "w_", "=", "np", ".", "fft", ".", "rfft", "(", "np", ".", "concatenate", "(", "(", "w", ",", "np", ".", "zeros_like", "(", "w", ")", ")", ",", "axis", "=", "-", "1", ")", ")", "\n", "v_", "=", "np", ".", "fft", ".", "rfft", "(", "np", ".", "concatenate", "(", "(", "v", ",", "np", ".", "zeros_like", "(", "v", ")", ")", ",", "axis", "=", "-", "1", ")", ")", "\n", "wv_", "=", "w_", "*", "v_", ".", "reshape", "(", "(", "1", ",", "rank", ",", "-", "1", ")", ")", "\n", "ans", "=", "np", ".", "fft", ".", "irfft", "(", "np", ".", "sum", "(", "wv_", ",", "axis", "=", "1", ")", ")", "[", "...", ",", ":", "n", "]", "\n", "", "return", "ans", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz_cpu.toeplitz_mult": [[99, 106], ["toeplitz_cpu.KT_Toeplitz", "toeplitz_cpu.K_Toeplitz"], "function", ["None"], ["", "", "def", "toeplitz_mult", "(", "G", ",", "H", ",", "x", ",", "cycle", "=", "True", ")", ":", "\n", "    ", "rank", ",", "n", "=", "G", ".", "shape", "\n", "batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "f", "=", "(", "1", ",", "-", "1", ")", "if", "cycle", "else", "(", "0", ",", "0", ")", "\n", "transpose_out", "=", "KT_Toeplitz", "(", "n", ",", "f", "[", "1", "]", ",", "batch_size", ",", "rank", ")", "(", "H", ",", "x", ")", "\n", "krylov_out", "=", "K_Toeplitz", "(", "n", ",", "f", "[", "0", "]", ",", "batch_size", ",", "rank", ")", "(", "G", ",", "transpose_out", ")", "\n", "return", "krylov_out", "/", "2", "if", "cycle", "else", "krylov_out", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz_cpu.krylov_construct": [[110, 118], ["numpy.zeros", "range"], "function", ["None"], ["", "def", "krylov_construct", "(", "f", ",", "v", ",", "m", ")", ":", "\n", "    ", "n", "=", "v", ".", "shape", "[", "0", "]", "\n", "K", "=", "np", ".", "zeros", "(", "shape", "=", "(", "m", ",", "n", ")", ")", "\n", "K", "[", "0", ",", ":", "]", "=", "v", "\n", "for", "i", "in", "range", "(", "1", ",", "m", ")", ":", "\n", "        ", "K", "[", "i", ",", "1", ":", "]", "=", "K", "[", "i", "-", "1", ",", ":", "-", "1", "]", "\n", "K", "[", "i", ",", "0", "]", "=", "f", "*", "K", "[", "i", "-", "1", ",", "-", "1", "]", "\n", "", "return", "K", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz_cpu.toeplitz_mult_slow": [[119, 126], ["numpy.sum", "toeplitz_cpu.krylov_construct", "range", "numpy.array", "toeplitz_cpu.krylov_construct"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.krylov_construct", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.krylov_construct"], ["", "def", "toeplitz_mult_slow", "(", "G", ",", "H", ",", "x", ",", "cycle", "=", "True", ")", ":", "\n", "    ", "assert", "G", ".", "shape", "==", "H", ".", "shape", "\n", "rank", ",", "n", "=", "G", ".", "shape", "\n", "f", "=", "(", "1", ",", "-", "1", ")", "if", "cycle", "else", "(", "0", ",", "0", ")", "\n", "krylovs", "=", "[", "(", "krylov_construct", "(", "f", "[", "0", "]", ",", "G", "[", "i", "]", ",", "n", ")", ",", "krylov_construct", "(", "f", "[", "1", "]", ",", "H", "[", "i", "]", ",", "n", ")", ".", "T", ")", "for", "i", "in", "range", "(", "rank", ")", "]", "\n", "prods", "=", "[", "K", "[", "0", "]", "@", "K", "[", "1", "]", "@", "x", ".", "T", "for", "K", "in", "krylovs", "]", "\n", "return", "np", ".", "sum", "(", "np", ".", "array", "(", "prods", ")", ",", "axis", "=", "0", ")", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.circulant.circulant_multiply": [[7, 16], ["torch.irfft", "complex_utils.complex_mult", "torch.rfft", "torch.rfft"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.complex_utils.complex_mult"], ["import", "torch", ".", "nn", ".", "functional", "as", "F", "\n", "from", "torch", ".", "nn", ".", "parameter", "import", "Parameter", "\n", "from", "torchvision", "import", "datasets", ",", "transforms", "\n", "from", "torch", "import", "autograd", "\n", "from", "torch", ".", "autograd", "import", "Variable", "\n", "\n", "from", "utils", "import", "get_train_valid_datasets", ",", "train", ",", "train_all_epochs", ",", "accuracy", ",", "all_losses", "\n", "\n", "use_cuda", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.circulant.test_circulant_multiply": [[17, 24], ["torch.rand", "torch.rand", "torch.tensor", "circulant.circulant_multiply", "print", "scipy.linalg.circulant", "torch.tensor.t", "torch.rand.detach().cpu().numpy", "torch.rand.detach().cpu", "torch.rand.detach"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.circulant.circulant_multiply"], ["class", "TwoLayerNet", "(", "nn", ".", "Module", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "n_features", ",", "n_classes", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "n_features", ",", "n_features", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "n_features", ",", "n_classes", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Layer.name": [[18, 20], ["None"], "methods", ["None"], ["def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "abbrev", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Layer.__init__": [[21, 27], ["torch.Module.__init__", "layer.Layer.__dict__.update", "layer.Layer.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonalC.reset_parameters"], ["", "def", "__init__", "(", "self", ",", "layer_size", "=", "None", ",", "bias", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer_size", "=", "layer_size", "\n", "self", ".", "bias", "=", "bias", "\n", "self", ".", "__dict__", ".", "update", "(", "kwargs", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Layer.reset_parameters": [[28, 33], ["torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "assert", "self", ".", "layer_size", "is", "not", "None", "\n", "self", ".", "b", "=", "None", "\n", "if", "self", ".", "bias", ":", "\n", "            ", "self", ".", "b", "=", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "layer_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Layer.apply_bias": [[34, 39], ["None"], "methods", ["None"], ["", "", "def", "apply_bias", "(", "self", ",", "out", ")", ":", "\n", "        ", "if", "self", ".", "b", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "b", "+", "out", "\n", "", "else", ":", "\n", "            ", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Layer.loss": [[40, 42], ["None"], "methods", ["None"], ["", "", "def", "loss", "(", "self", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Unconstrained.name": [[47, 49], ["str"], "methods", ["None"], ["def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "abbrev", "+", "str", "(", "self", ".", "hidden_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Unconstrained.__init__": [[50, 54], ["layer.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__"], ["", "def", "__init__", "(", "self", ",", "layer_size", ",", "hidden_size", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "hidden_size", "is", "None", ":", "\n", "            ", "hidden_size", "=", "layer_size", "\n", "", "super", "(", ")", ".", "__init__", "(", "layer_size", ",", "hidden_size", "=", "hidden_size", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Unconstrained.reset_parameters": [[55, 63], ["layer.Layer.reset_parameters", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "numpy.sqrt", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonalC.reset_parameters"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "reset_parameters", "(", ")", "\n", "self", ".", "W", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "layer_size", ",", "self", ".", "hidden_size", ")", ")", "\n", "self", ".", "init_stddev", "=", "np", ".", "sqrt", "(", "1.", "/", "self", ".", "layer_size", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "W", ",", "std", "=", "self", ".", "init_stddev", ")", "\n", "self", ".", "mask", "=", "None", "\n", "if", "self", ".", "bias", ":", "\n", "            ", "self", ".", "b", "=", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "hidden_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Unconstrained.set_mask": [[64, 68], ["torch.autograd.Variable", "torch.autograd.Variable", "print", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.nonzero().size", "torch.nonzero().size", "torch.nonzero().size", "torch.nonzero().size", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.nonzero", "torch.nonzero", "torch.nonzero", "torch.nonzero"], "methods", ["None"], ["", "", "def", "set_mask", "(", "self", ",", "mask", ",", "device", ")", ":", "\n", "        ", "self", ".", "mask", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "mask", ")", ".", "to", "(", "device", ")", ",", "requires_grad", "=", "False", ")", "\n", "self", ".", "W", ".", "data", "*=", "self", ".", "mask", ".", "data", "\n", "print", "(", "'Num. nonzero entries after pruning: '", ",", "torch", ".", "nonzero", "(", "self", ".", "W", ")", ".", "size", "(", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Unconstrained.forward": [[69, 78], ["layer.Unconstrained.apply_bias", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Layer.apply_bias"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "mask", "is", "not", "None", ":", "\n", "            ", "masked_W", "=", "self", ".", "W", "*", "self", ".", "mask", "\n", "#print('NNZ, mask: ', torch.nonzero(self.mask).size(0))", "\n", "#print('NNZ, masked_W: ', torch.nonzero(masked_W).size(0))", "\n", "out", "=", "torch", ".", "matmul", "(", "x", ",", "masked_W", ")", "\n", "", "else", ":", "\n", "            ", "out", "=", "torch", ".", "matmul", "(", "x", ",", "self", ".", "W", ")", "\n", "", "return", "self", ".", "apply_bias", "(", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Circulant.reset_parameters": [[85, 90], ["layer.Layer.reset_parameters", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "numpy.sqrt", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonalC.reset_parameters"], ["def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "reset_parameters", "(", ")", "\n", "self", ".", "c", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "layer_size", ")", ")", "\n", "self", ".", "init_stddev", "=", "np", ".", "sqrt", "(", "1.", "/", "self", ".", "layer_size", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "c", ",", "std", "=", "self", ".", "init_stddev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Circulant.forward": [[91, 93], ["layer.Circulant.apply_bias", "circulant.circulant_multiply"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Layer.apply_bias", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.circulant.circulant_multiply"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "apply_bias", "(", "circ", ".", "circulant_multiply", "(", "self", ".", "c", ",", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.FastFood.reset_parameters": [[99, 113], ["layer.Layer.reset_parameters", "numpy.sqrt", "numpy.random.randn", "numpy.linalg.norm", "numpy.random.choice", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "numpy.random.chisquare", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "numpy.random.permutation"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonalC.reset_parameters"], ["def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "reset_parameters", "(", ")", "\n", "# Initialize as non adaptive Fastfood (Le et al. 2013)", "\n", "# TODO: check initialization of S (scaling matrix) is correct", "\n", "# S,G,B: diagonal, learnable parameters", "\n", "# P: permutation, fixed", "\n", "S", "=", "np", ".", "sqrt", "(", "np", ".", "random", ".", "chisquare", "(", "self", ".", "layer_size", ",", "size", "=", "self", ".", "layer_size", ")", ")", "\n", "G", "=", "np", ".", "random", ".", "randn", "(", "self", ".", "layer_size", ")", "\n", "S", "/=", "np", ".", "linalg", ".", "norm", "(", "G", ")", "\n", "B", "=", "np", ".", "random", ".", "choice", "(", "(", "-", "1", ",", "1", ")", ",", "size", "=", "self", ".", "layer_size", ")", "\n", "self", ".", "S", "=", "Parameter", "(", "torch", ".", "FloatTensor", "(", "S", ")", ")", "\n", "self", ".", "G", "=", "Parameter", "(", "torch", ".", "FloatTensor", "(", "G", ")", ")", "\n", "self", ".", "B", "=", "Parameter", "(", "torch", ".", "FloatTensor", "(", "B", ")", ")", "\n", "self", ".", "P", "=", "torch", ".", "LongTensor", "(", "np", ".", "random", ".", "permutation", "(", "self", ".", "layer_size", ")", ")", "\n", "#self.init_stddev = np.sqrt(1./self.layer_size)", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.FastFood.forward": [[118, 120], ["layer.FastFood.apply_bias", "fastfood.fastfood_multiply"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Layer.apply_bias", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.fastfood.fastfood_multiply"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "apply_bias", "(", "ff", ".", "fastfood_multiply", "(", "self", ".", "S", ",", "self", ".", "G", ",", "self", ".", "B", ",", "self", ".", "P", ",", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LowRank.name": [[125, 127], ["str"], "methods", ["None"], ["def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "abbrev", "+", "str", "(", "self", ".", "r", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LowRank.__init__": [[128, 130], ["layer.Layer.__init__"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__"], ["", "def", "__init__", "(", "self", ",", "layer_size", ",", "r", "=", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "layer_size", ",", "r", "=", "r", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LowRank.reset_parameters": [[131, 139], ["layer.Layer.reset_parameters", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "numpy.power", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonalC.reset_parameters"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "reset_parameters", "(", ")", "\n", "self", ".", "G", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "r", ",", "self", ".", "layer_size", ")", ")", "\n", "self", ".", "H", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "r", ",", "self", ".", "layer_size", ")", ")", "\n", "# self.init_stddev = 0.01", "\n", "self", ".", "init_stddev", "=", "np", ".", "power", "(", "1.", "/", "(", "self", ".", "r", "*", "self", ".", "layer_size", ")", ",", "1", "/", "2", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "G", ",", "std", "=", "self", ".", "init_stddev", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "H", ",", "std", "=", "self", ".", "init_stddev", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LowRank.forward": [[140, 144], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "layer.LowRank.apply_bias", "layer.LowRank.H.t"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Layer.apply_bias"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "xH", "=", "torch", ".", "matmul", "(", "x", ",", "self", ".", "H", ".", "t", "(", ")", ")", "\n", "out", "=", "torch", ".", "matmul", "(", "xH", ",", "self", ".", "G", ")", "\n", "return", "self", ".", "apply_bias", "(", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LowRank.loss": [[145, 147], ["None"], "methods", ["None"], ["", "def", "loss", "(", "self", ")", ":", "\n", "        ", "return", "0", "\n", "# lamb = 0.0001", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.ToeplitzLike.reset_parameters": [[155, 158], ["layer.LowRank.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonalC.reset_parameters"], ["def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "reset_parameters", "(", ")", "\n", "self", ".", "corner", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.ToeplitzLike.forward": [[159, 162], ["toeplitz.toeplitz_mult", "layer.ToeplitzLike.apply_bias"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz_cpu.toeplitz_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Layer.apply_bias"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "toep", ".", "toeplitz_mult", "(", "self", ".", "G", ",", "self", ".", "H", ",", "x", ",", "self", ".", "corner", ")", "\n", "return", "self", ".", "apply_bias", "(", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.ToeplitzLikeC.reset_parameters": [[167, 170], ["layer.ToeplitzLike.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonalC.reset_parameters"], ["def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "reset_parameters", "(", ")", "\n", "self", ".", "corner", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.HankelLike.forward": [[175, 178], ["toeplitz.toeplitz_mult", "layer.HankelLike.apply_bias", "toeplitz.toeplitz_mult.flip", "toeplitz.toeplitz_mult.dim"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz_cpu.toeplitz_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Layer.apply_bias"], ["def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "toep", ".", "toeplitz_mult", "(", "self", ".", "G", ",", "self", ".", "H", ",", "x", ",", "True", ")", "\n", "return", "self", ".", "apply_bias", "(", "out", ".", "flip", "(", "out", ".", "dim", "(", ")", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.VandermondeLike.reset_parameters": [[183, 187], ["layer.LowRank.reset_parameters", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonalC.reset_parameters"], ["def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "reset_parameters", "(", ")", "\n", "self", ".", "diag", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "layer_size", ")", ")", "\n", "torch", ".", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "diag", ",", "-", "0.7", ",", "0.7", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.VandermondeLike.forward": [[188, 202], ["x.size", "toeplitz.toeplitz_krylov_transpose_multiply", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "layer.VandermondeLike.apply_bias", "layer.VandermondeLike.diag.unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "layer.VandermondeLike.G.unsqueeze", "torch.sum.transpose", "torch.sum.transpose", "K_A.transpose"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz.toeplitz_krylov_transpose_multiply", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Layer.apply_bias"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "# want: K_A[i,j,k] = g_i[j] * d[j] ** k", "\n", "# K_A = kry.Krylov(lambda v: self.diag * v, self.G)", "\n", "        ", "n", "=", "x", ".", "size", "(", "-", "1", ")", "\n", "d_", "=", "self", ".", "diag", ".", "unsqueeze", "(", "1", ")", "**", "torch", ".", "arange", "(", "n", ",", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", "\n", "K_A", "=", "self", ".", "G", ".", "unsqueeze", "(", "-", "1", ")", "*", "d_", "\n", "\n", "# K_B = kry.Krylov(lambda v: torch.cat((v[...,1:],0*v[...,:1]),dim=-1), self.H)", "\n", "# out = (x @ K_B) @ K_A.transpose(1,2)", "\n", "\n", "out", "=", "toep", ".", "toeplitz_krylov_transpose_multiply", "(", "self", ".", "H", ",", "x", ")", "\n", "out", "=", "out", ".", "transpose", "(", "0", ",", "1", ")", "@", "K_A", ".", "transpose", "(", "1", ",", "2", ")", "\n", "out", "=", "torch", ".", "sum", "(", "out", ",", "dim", "=", "0", ")", "\n", "return", "self", ".", "apply_bias", "(", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LearnedOperator.__init__": [[216, 218], ["layer.LowRank.__init__"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__"], ["def", "__init__", "(", "self", ",", "tie_operators", "=", "False", ",", "corner", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "tie_operators", "=", "tie_operators", ",", "corner", "=", "corner", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRSubdiagonal.reset_parameters": [[223, 230], ["layer.LowRank.reset_parameters", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonalC.reset_parameters"], ["def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "reset_parameters", "(", ")", "\n", "self", ".", "subd_A", "=", "Parameter", "(", "torch", ".", "ones", "(", "self", ".", "layer_size", "-", "1", ")", ")", "\n", "if", "self", ".", "tie_operators", ":", "\n", "            ", "self", ".", "subd_B", "=", "self", ".", "subd_A", "\n", "", "else", ":", "\n", "            ", "self", ".", "subd_B", "=", "Parameter", "(", "torch", ".", "ones", "(", "self", ".", "layer_size", "-", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRSubdiagonal.forward": [[231, 235], ["krylov.subdiag_mult", "layer.LDRSubdiagonal.apply_bias"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Layer.apply_bias"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "kry", ".", "subdiag_mult", "(", "self", ".", "subd_A", ",", "self", ".", "subd_B", ",", "self", ".", "G", ",", "self", ".", "H", ",", "x", ")", "\n", "#out = kry.subdiag_mult_conv(self.subd_A, self.subd_B, self.G, self.H, x)", "\n", "return", "self", ".", "apply_bias", "(", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRSubdiagonalC.reset_parameters": [[240, 244], ["layer.LDRSubdiagonal.reset_parameters", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonalC.reset_parameters"], ["def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "reset_parameters", "(", ")", "\n", "self", ".", "corner_A", "=", "Parameter", "(", "torch", ".", "tensor", "(", "0.0", ")", ")", "\n", "self", ".", "corner_B", "=", "Parameter", "(", "torch", ".", "tensor", "(", "0.0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRSubdiagonalC.forward": [[245, 248], ["krylov.subdiag_mult_cuda", "layer.LDRSubdiagonalC.apply_bias"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_mult_cuda", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Layer.apply_bias"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "kry", ".", "subdiag_mult_cuda", "(", "self", ".", "subd_A", ",", "self", ".", "subd_B", ",", "self", ".", "G", ",", "self", ".", "H", ",", "x", ",", "corner_A", "=", "self", ".", "corner_A", ",", "corner_B", "=", "self", ".", "corner_B", ")", "\n", "return", "self", ".", "apply_bias", "(", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonal.reset_parameters": [[253, 268], ["layer.LowRank.reset_parameters", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonalC.reset_parameters"], ["def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "reset_parameters", "(", ")", "\n", "self", ".", "subd_A", "=", "Parameter", "(", "torch", ".", "ones", "(", "self", ".", "layer_size", "-", "1", ")", ")", "\n", "self", ".", "diag_A", "=", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "layer_size", ")", ")", "\n", "self", ".", "supd_A", "=", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "layer_size", "-", "1", ")", ")", "\n", "if", "self", ".", "tie_operators", ":", "\n", "            ", "self", ".", "subd_B", "=", "self", ".", "subd_A", "\n", "self", ".", "diag_B", "=", "self", ".", "diag_A", "\n", "self", ".", "supd_B", "=", "self", ".", "supd_A", "\n", "", "else", ":", "\n", "            ", "self", ".", "subd_B", "=", "Parameter", "(", "torch", ".", "ones", "(", "self", ".", "layer_size", "-", "1", ")", ")", "\n", "self", ".", "diag_B", "=", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "layer_size", ")", ")", "\n", "self", ".", "supd_B", "=", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "layer_size", "-", "1", ")", ")", "\n", "", "self", ".", "corners_A", "=", "(", "0.0", ",", "0.0", ")", "\n", "self", ".", "corners_B", "=", "(", "0.0", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonal.forward": [[269, 272], ["krylov.tridiag_mult_slow", "layer.LDRTridiagonal.apply_bias"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.tridiag_mult_slow", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.Layer.apply_bias"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "kry", ".", "tridiag_mult_slow", "(", "self", ".", "subd_A", ",", "self", ".", "diag_A", ",", "self", ".", "supd_A", ",", "self", ".", "subd_B", ",", "self", ".", "diag_B", ",", "self", ".", "supd_B", ",", "self", ".", "G", ",", "self", ".", "H", ",", "x", ",", "corners_A", "=", "self", ".", "corners_A", ",", "corners_B", "=", "self", ".", "corners_B", ")", "\n", "return", "self", ".", "apply_bias", "(", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonalC.reset_parameters": [[277, 281], ["layer.LDRTridiagonal.reset_parameters", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.LDRTridiagonalC.reset_parameters"], ["def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "reset_parameters", "(", ")", "\n", "self", ".", "corners_A", "=", "(", "Parameter", "(", "torch", ".", "tensor", "(", "0.0", ")", ")", ",", "Parameter", "(", "torch", ".", "tensor", "(", "0.0", ")", ")", ")", "\n", "self", ".", "corners_B", "=", "(", "Parameter", "(", "torch", ".", "tensor", "(", "0.0", ")", ")", ",", "Parameter", "(", "torch", ".", "tensor", "(", "0.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.layer.StructuredLinear": [[290, 292], ["None"], "function", ["None"], ["", "def", "StructuredLinear", "(", "class_type", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "class_map", "[", "class_type", "]", "(", "**", "kwargs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.name": [[13, 15], ["str", "str", "str"], "methods", ["None"], ["    ", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "in_channels", ")", "+", "str", "(", "self", ".", "out_channels", ")", "+", "self", ".", "displacement", "+", "str", "(", "self", ".", "r", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.__init__": [[17, 39], ["torch.Module.__init__", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.nn.parameter.Parameter", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__"], ["", "def", "__init__", "(", "self", ",", "displacement", ",", "in_channels", ",", "out_channels", ",", "rank", ",", "layer_size", ",", "bias", "=", "True", ")", ":", "\n", "        ", "super", "(", "LDR", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "displacement", "=", "displacement", "\n", "self", ".", "in_channels", "=", "in_channels", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "r", "=", "rank", "\n", "self", ".", "n", "=", "layer_size", "\n", "self", ".", "bias", "=", "None", "\n", "\n", "self", ".", "G", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "self", ".", "r", ",", "self", ".", "n", ")", ")", "\n", "self", ".", "H", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "self", ".", "r", ",", "self", ".", "n", ")", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "G", ",", "std", "=", "0.01", ")", "#TODO", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "H", ",", "std", "=", "0.01", ")", "\n", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "out_channels", ",", "1", ",", "self", ".", "n", ")", ")", "\n", "", "if", "self", ".", "displacement", "==", "'toeplitz_corner'", "or", "self", ".", "displacement", "==", "'tc'", ":", "\n", "            ", "self", ".", "corner", "=", "True", "\n", "", "elif", "self", ".", "displacement", "==", "'toeplitz'", "or", "self", ".", "displacement", "==", "'t'", ":", "\n", "            ", "self", ".", "corner", "=", "False", "\n", "", "elif", "self", ".", "displacement", "==", "'subdiagonal'", "or", "self", ".", "displacement", "==", "'sd'", ":", "\n", "            ", "self", ".", "subd_A", "=", "Parameter", "(", "torch", ".", "ones", "(", "(", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "self", ".", "n", "-", "1", ")", ")", ")", "\n", "self", ".", "subd_B", "=", "Parameter", "(", "torch", ".", "ones", "(", "(", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "self", ".", "n", "-", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.forward": [[41, 63], ["torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "range", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "range", "torch.autograd.Variable", "torch.autograd.Variable", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "toeplitz.toeplitz_mult", "krylov.subdiag_mult_conv"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.toeplitz_cpu.toeplitz_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_mult_conv"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        x: (in_channels, batch, n)\n        out: (out_channels, batch, n)\n        \"\"\"", "\n", "_", ",", "b", ",", "n", "=", "x", ".", "shape", "\n", "assert", "n", "==", "self", ".", "n", "\n", "\n", "# print(\"shapes \", self.G[0,0].shape, self.H[0,0].shape, x[0].shape)", "\n", "comps", "=", "Variable", "(", "torch", ".", "Tensor", "(", "self", ".", "in_channels", ",", "self", ".", "out_channels", ",", "b", ",", "self", ".", "n", ")", ")", ".", "cuda", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "in_channels", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "out_channels", ")", ":", "\n", "                ", "if", "self", ".", "displacement", "in", "[", "'toeplitz_corner'", ",", "'toeplitz'", ",", "'tc'", ",", "'t'", "]", ":", "\n", "                    ", "g", "=", "self", ".", "G", "[", "i", ",", "j", "]", "\n", "h", "=", "self", ".", "H", "[", "i", ",", "j", "]", "\n", "comps", "[", "i", ",", "j", "]", "=", "toep", ".", "toeplitz_mult", "(", "self", ".", "G", "[", "i", ",", "j", "]", ",", "self", ".", "H", "[", "i", ",", "j", "]", ",", "x", "[", "i", "]", ",", "self", ".", "corner", ")", "\n", "", "elif", "self", ".", "displacement", "==", "'subdiagonal'", "or", "self", ".", "displacement", "==", "'sd'", ":", "\n", "                    ", "comps", "[", "i", ",", "j", "]", "=", "kry", ".", "subdiag_mult_conv", "(", "self", ".", "subd_A", "[", "i", ",", "j", "]", ",", "self", ".", "subd_B", "[", "i", ",", "j", "]", ",", "self", ".", "G", "[", "i", ",", "j", "]", ",", "self", ".", "H", "[", "i", ",", "j", "]", ",", "x", "[", "i", "]", ")", "\n", "", "", "", "out", "=", "torch", ".", "sum", "(", "comps", ",", "dim", "=", "0", ")", "\n", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "out", "+=", "self", ".", "bias", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.LDR.LDR.loss": [[64, 68], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["None"], ["", "def", "loss", "(", "self", ")", ":", "\n", "        ", "lamb", "=", "0.0001", "\n", "# lamb = 0", "\n", "return", "lamb", "*", "torch", ".", "sum", "(", "torch", ".", "abs", "(", "self", ".", "G", ")", ")", "+", "lamb", "*", "torch", ".", "sum", "(", "torch", ".", "abs", "(", "self", ".", "H", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.hadamard.HadamardTransformCuda.forward": [[47, 50], ["hadamard_cuda.hadamard_transform"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "u", ")", ":", "\n", "        ", "return", "hadamard_cuda", ".", "hadamard_transform", "(", "u", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.hadamard.HadamardTransformCuda.backward": [[51, 54], ["HadamardTransformCuda.apply"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad", ")", ":", "\n", "        ", "return", "HadamardTransformCuda", ".", "apply", "(", "grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.hadamard.hadamard_transform_torch": [[26, 42], ["int", "numpy.log2", "range", "torch.cat", "torch.cat.squeeze", "torch.cat.squeeze"], "function", ["None"], ["def", "hadamard_transform_torch", "(", "u", ",", "normalize", "=", "False", ")", ":", "\n", "    ", "\"\"\"Multiply H_n @ u where H_n is the Hadamard matrix of dimension n x n.\n    n must be a power of 2.\n    Parameters:\n        u: Tensor of shape (..., n)\n        normalize: if True, divide the result by 2^{m/2} where m = log_2(n).\n    Returns:\n        product: Tensor of shape (..., n)\n    \"\"\"", "\n", "batch_size", ",", "n", "=", "u", ".", "shape", "\n", "m", "=", "int", "(", "np", ".", "log2", "(", "n", ")", ")", "\n", "assert", "n", "==", "1", "<<", "m", ",", "'n must be a power of 2'", "\n", "x", "=", "u", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "for", "d", "in", "range", "(", "m", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "        ", "x", "=", "torch", ".", "cat", "(", "(", "x", "[", "...", ",", ":", ":", "2", ",", ":", "]", "+", "x", "[", "...", ",", "1", ":", ":", "2", ",", ":", "]", ",", "x", "[", "...", ",", ":", ":", "2", ",", ":", "]", "-", "x", "[", "...", ",", "1", ":", ":", "2", ",", ":", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "", "return", "x", ".", "squeeze", "(", "-", "2", ")", "/", "2", "**", "(", "m", "/", "2", ")", "if", "normalize", "else", "x", ".", "squeeze", "(", "-", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.hadamard.hadamard_transform_cuda": [[56, 70], ["int", "HadamardTransformCuda.apply", "numpy.log2"], "function", ["None"], ["", "", "def", "hadamard_transform_cuda", "(", "u", ",", "normalize", "=", "False", ")", ":", "\n", "    ", "\"\"\"Multiply H_n @ u where H_n is the Hadamard matrix of dimension n x n.\n    n must be a power of 2.\n    Parameters:\n        u: Tensor of shape (..., n)\n        normalize: if True, divide the result by 2^{m/2} where m = log_2(n).\n    Returns:\n        product: Tensor of shape (..., n)\n    \"\"\"", "\n", "_", ",", "n", "=", "u", ".", "shape", "\n", "m", "=", "int", "(", "np", ".", "log2", "(", "n", ")", ")", "\n", "assert", "n", "==", "1", "<<", "m", ",", "'n must be a power of 2'", "\n", "output", "=", "HadamardTransformCuda", ".", "apply", "(", "u", ")", "\n", "return", "output", "/", "2", "**", "(", "m", "/", "2", ")", "if", "normalize", "else", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.hadamard.test_hadamard_transform": [[72, 90], ["torch.rand", "hadamard.hadamard_transform_cuda", "torch.autograd.grad", "hadamard.hadamard_transform_torch", "torch.autograd.grad", "torch.tensor", "print", "print", "print", "print", "print", "print", "hadamard_transform_cuda.sum", "hadamard_transform_torch.sum", "scipy.linalg.hadamard", "torch.tensor.t"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.hadamard.hadamard_transform_cuda", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.hadamard.hadamard_transform_torch"], ["", "def", "test_hadamard_transform", "(", ")", ":", "\n", "    ", "m", "=", "15", "\n", "n", "=", "1", "<<", "m", "\n", "batch_size", "=", "50", "\n", "u", "=", "torch", ".", "rand", "(", "(", "batch_size", ",", "n", ")", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "\n", "result_cuda", "=", "hadamard_transform_cuda", "(", "u", ")", "\n", "grad_cuda", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "result_cuda", ".", "sum", "(", ")", ",", "u", ",", "retain_graph", "=", "True", ")", "\n", "result_torch", "=", "hadamard_transform_torch", "(", "u", ")", "\n", "grad_torch", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "result_torch", ".", "sum", "(", ")", ",", "u", ",", "retain_graph", "=", "True", ")", "\n", "# Explicit construction from scipy", "\n", "H", "=", "torch", ".", "tensor", "(", "hadamard", "(", "n", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "result_explicit", "=", "u", "@", "H", ".", "t", "(", ")", "\n", "print", "(", "(", "result_cuda", "-", "result_explicit", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result_cuda", "-", "result_explicit", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result_torch", "-", "result_explicit", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result_torch", "-", "result_explicit", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad_cuda", "-", "grad_torch", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad_cuda", "-", "grad_torch", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.complex_utils.conjugate": [[9, 12], ["torch.tensor"], "function", ["None"], ["def", "conjugate", "(", "X", ")", ":", "\n", "    ", "assert", "X", ".", "shape", "[", "-", "1", "]", "==", "2", ",", "'Last dimension must be 2'", "\n", "return", "X", "*", "torch", ".", "tensor", "(", "(", "1", ",", "-", "1", ")", ",", "dtype", "=", "X", ".", "dtype", ",", "device", "=", "X", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.complex_utils.complex_mult": [[14, 20], ["torch.stack"], "function", ["None"], ["", "def", "complex_mult", "(", "X", ",", "Y", ")", ":", "\n", "    ", "assert", "X", ".", "shape", "[", "-", "1", "]", "==", "2", "and", "Y", ".", "shape", "[", "-", "1", "]", "==", "2", ",", "'Last dimension must be 2'", "\n", "return", "torch", ".", "stack", "(", "\n", "(", "X", "[", "...", ",", "0", "]", "*", "Y", "[", "...", ",", "0", "]", "-", "X", "[", "...", ",", "1", "]", "*", "Y", "[", "...", ",", "1", "]", ",", "\n", "X", "[", "...", ",", "0", "]", "*", "Y", "[", "...", ",", "1", "]", "+", "X", "[", "...", ",", "1", "]", "*", "Y", "[", "...", ",", "0", "]", ")", ",", "\n", "dim", "=", "-", "1", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.fastfood.fastfood_multiply": [[11, 16], ["hadamard.hadamard_transform", "hadamard.hadamard_transform"], "function", ["None"], ["def", "fastfood_multiply", "(", "S", ",", "G", ",", "B", ",", "P", ",", "x", ")", ":", "\n", "    ", "HBx", "=", "hadamard_transform", "(", "B", "*", "x", ")", "\n", "PHBx", "=", "HBx", "[", ":", ",", "P", "]", "\n", "HGPHBx", "=", "hadamard_transform", "(", "G", "*", "PHBx", ")", "\n", "return", "S", "*", "HGPHBx", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.fastfood.test_fastfood_multiply": [[17, 38], ["numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.permutation", "numpy.random.randn", "scipy.linalg.hadamard", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "fastfood.fastfood_multiply", "print", "numpy.dot", "numpy.dot", "numpy.linalg.norm"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.fastfood.fastfood_multiply"], ["", "def", "test_fastfood_multiply", "(", "n", ",", "batch_size", ")", ":", "\n", "    ", "S", "=", "np", ".", "random", ".", "randn", "(", "n", ")", "\n", "G", "=", "np", ".", "random", ".", "randn", "(", "n", ")", "\n", "B", "=", "np", ".", "random", ".", "randn", "(", "n", ")", "\n", "P", "=", "np", ".", "random", ".", "permutation", "(", "n", ")", "\n", "x", "=", "np", ".", "random", ".", "randn", "(", "batch_size", ",", "n", ")", "\n", "H", "=", "hadamard", "(", "n", ")", "\n", "HBx", "=", "np", ".", "dot", "(", "H", ",", "(", "B", "*", "x", ")", ".", "T", ")", ".", "T", "\n", "PHBx", "=", "HBx", "[", ":", ",", "P", "]", "\n", "HGPHBx", "=", "np", ".", "dot", "(", "H", ",", "(", "G", "*", "PHBx", ")", ".", "T", ")", ".", "T", "\n", "output_explicit", "=", "S", "*", "HGPHBx", "\n", "\n", "S", "=", "torch", ".", "tensor", "(", "S", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "G", "=", "torch", ".", "tensor", "(", "G", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "B", "=", "torch", ".", "tensor", "(", "B", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "P", "=", "torch", ".", "tensor", "(", "P", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "x", "=", "torch", ".", "tensor", "(", "x", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "\n", "output", "=", "fastfood_multiply", "(", "S", ",", "G", ",", "B", ",", "P", ",", "x", ")", "\n", "\n", "print", "(", "np", ".", "linalg", ".", "norm", "(", "output_explicit", "-", "output", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.CycleDownMultCuda.forward": [[804, 808], ["ctx.save_for_backward", "diag_mult_cuda.cycle_mult"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "subdiag", ",", "v", ")", ":", "\n", "        ", "ctx", ".", "save_for_backward", "(", "subdiag", ",", "v", ")", "\n", "return", "diag_mult_cuda", ".", "cycle_mult", "(", "subdiag", ",", "v", ",", "0", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.CycleDownMultCuda.backward": [[809, 813], ["diag_mult_cuda.cycle_mult().sum", "diag_mult_cuda.cycle_mult", "diag_mult_cuda.cycle_mult"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad", ")", ":", "\n", "        ", "subdiag", ",", "v", "=", "ctx", ".", "saved_tensors", "\n", "return", "diag_mult_cuda", ".", "cycle_mult", "(", "grad", ",", "v", ",", "0", ",", "-", "1", ")", ".", "sum", "(", "dim", "=", "0", ")", ",", "diag_mult_cuda", ".", "cycle_mult", "(", "subdiag", ",", "grad", ",", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.poly_mult_sum_benchmark": [[40, 78], ["print", "torch.cuda.synchronize", "time.perf_counter", "range", "torch.cuda.synchronize", "time.perf_counter", "print", "time.perf_counter", "range", "torch.cuda.synchronize", "time.perf_counter", "print", "torch.nn.functional.conv1d", "torch.nn.functional.conv1d", "torch.autograd.grad", "torch.cat", "torch.rfft", "torch.stack", "torch.autograd.grad", "q.flip", "q.flip", "F.conv1d.sum", "torch.irfft", "T_00_sum.sum", "torch.cat", "torch.zeros", "q.dim", "q.dim"], "function", ["None"], ["def", "poly_mult_sum_benchmark", "(", "p", ",", "q", ")", ":", "\n", "    ", "\"\"\"Multiply and sum two sets of polynomials.\n    Parameters:\n        p: (batch_size, n1, n2)\n        q: (rank, n1, n2)\n    Output:\n        o: (batch_size, rank, 2 * n2 - 1)\n    \"\"\"", "\n", "print", "(", "p", ".", "shape", "[", "2", "]", ")", "\n", "\n", "import", "time", "\n", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "for", "_", "in", "range", "(", "100", ")", ":", "\n", "        ", "y", "=", "F", ".", "conv1d", "(", "p", ",", "q", ".", "flip", "(", "q", ".", "dim", "(", ")", "-", "1", ")", ",", "padding", "=", "p", ".", "shape", "[", "-", "1", "]", "-", "1", ")", "\n", "g", "=", "torch", ".", "autograd", ".", "grad", "(", "y", ".", "sum", "(", ")", ",", "(", "p", ",", "q", ")", ",", "retain_graph", "=", "True", ")", "\n", "", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "end", "=", "time", ".", "perf_counter", "(", ")", "\n", "print", "(", "f'Elapsed time conv1d: {end - start}s.'", ")", "\n", "\n", "batch_size", ",", "rank", "=", "p", ".", "shape", "[", "0", "]", ",", "q", ".", "shape", "[", "0", "]", "\n", "n1", ",", "n2", "=", "p", ".", "shape", "[", "1", "]", ",", "p", ".", "shape", "[", "2", "]", "\n", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "for", "_", "in", "range", "(", "100", ")", ":", "\n", "        ", "S", "=", "torch", ".", "cat", "(", "(", "torch", ".", "cat", "(", "(", "q", ",", "p", ")", ")", ",", "\n", "torch", ".", "zeros", "(", "(", "rank", "+", "batch_size", ",", "p", ".", "shape", "[", "1", "]", ",", "p", ".", "shape", "[", "2", "]", ")", ",", "dtype", "=", "q", ".", "dtype", ",", "device", "=", "q", ".", "device", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "S_f", "=", "torch", ".", "rfft", "(", "S", ",", "1", ")", "\n", "S0_10_f", ",", "S1_01_f", "=", "S_f", "[", ":", "rank", "]", ",", "S_f", "[", "rank", ":", "rank", "+", "batch_size", "]", "\n", "prod", "=", "(", "S1_01_f", "[", ":", ",", "np", ".", "newaxis", ",", "...", ",", "np", ".", "newaxis", "]", "*", "S0_10_f", "[", "np", ".", "newaxis", ",", "...", ",", "np", ".", "newaxis", ",", ":", "]", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "T_00_f_sum", "=", "torch", ".", "stack", "(", "(", "prod", "[", "...", ",", "0", ",", "0", "]", "-", "prod", "[", "...", ",", "1", ",", "1", "]", ",", "prod", "[", "...", ",", "0", ",", "1", "]", "+", "prod", "[", "...", ",", "1", ",", "0", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "T_00_sum", "=", "torch", ".", "irfft", "(", "T_00_f_sum", ",", "1", ",", "signal_sizes", "=", "(", "2", "*", "n2", ",", ")", ")", "[", "...", ",", ":", "-", "1", "]", "\n", "g", "=", "torch", ".", "autograd", ".", "grad", "(", "T_00_sum", ".", "sum", "(", ")", ",", "(", "p", ",", "q", ")", ",", "retain_graph", "=", "True", ")", "\n", "", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "end", "=", "time", ".", "perf_counter", "(", ")", "\n", "print", "(", "f'Elapsed time FFT: {end - start}s.\\n'", ")", "\n", "\n", "return", "F", ".", "conv1d", "(", "p", ",", "q", ".", "flip", "(", "q", ".", "dim", "(", ")", "-", "1", ")", ",", "padding", "=", "p", ".", "shape", "[", "-", "1", "]", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.poly_mult_sum_backward_benchmark": [[80, 119], ["print", "torch.cuda.synchronize", "time.perf_counter", "range", "torch.cuda.synchronize", "time.perf_counter", "print", "time.perf_counter", "range", "torch.cuda.synchronize", "time.perf_counter", "print", "torch.nn.functional.conv_transpose1d", "torch.nn.functional.conv_transpose1d", "torch.autograd.grad", "torch.cat", "torch.rfft", "torch.rfft", "torch.stack", "torch.autograd.grad", "q.flip", "q.flip", "F.conv_transpose1d.sum", "torch.cat", "torch.irfft", "F.conv_transpose1d.sum", "torch.zeros", "torch.zeros_like"], "function", ["None"], ["", "def", "poly_mult_sum_backward_benchmark", "(", "grad", ",", "q", ")", ":", "\n", "    ", "\"\"\"Backward pass of multiplying and summing two sets of polynomials.\n    Parameters:\n        grad: (batch_size, rank, 2 * n2 - 1)\n        q: (rank, n1, n2)\n    Output:\n        dp: (batch_size, n1, n2)\n    \"\"\"", "\n", "print", "(", "q", ".", "shape", "[", "2", "]", ")", "\n", "\n", "import", "time", "\n", "\n", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "for", "_", "in", "range", "(", "100", ")", ":", "\n", "        ", "dp", "=", "F", ".", "conv_transpose1d", "(", "grad", ",", "q", ".", "flip", "(", "2", ")", ",", "padding", "=", "q", ".", "shape", "[", "-", "1", "]", "-", "1", ")", "\n", "g", "=", "torch", ".", "autograd", ".", "grad", "(", "dp", ".", "sum", "(", ")", ",", "(", "grad", ",", "q", ")", ",", "retain_graph", "=", "True", ")", "\n", "", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "end", "=", "time", ".", "perf_counter", "(", ")", "\n", "print", "(", "f'Elapsed time conv1d: {end - start}s.'", ")", "\n", "\n", "batch_size", ",", "rank", "=", "grad", ".", "shape", "[", "0", "]", ",", "q", ".", "shape", "[", "0", "]", "\n", "n1", ",", "n2", "=", "q", ".", "shape", "[", "1", "]", ",", "q", ".", "shape", "[", "2", "]", "\n", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "for", "_", "in", "range", "(", "100", ")", ":", "\n", "        ", "dT_00_sum", "=", "torch", ".", "cat", "(", "(", "grad", ",", "torch", ".", "zeros", "(", "(", "batch_size", ",", "rank", ",", "1", ")", ",", "dtype", "=", "grad", ".", "dtype", ",", "device", "=", "grad", ".", "device", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "dT_00_sum_f", "=", "torch", ".", "rfft", "(", "dT_00_sum", ",", "1", ")", "\n", "S0_10_f", "=", "torch", ".", "rfft", "(", "torch", ".", "cat", "(", "(", "q", ",", "torch", ".", "zeros_like", "(", "q", ")", ")", ",", "dim", "=", "-", "1", ")", ",", "1", ")", "\n", "# dS1_01_f = complex_mult(conjugate(S0_10_f), dT_00_sum_f[:, :, np.newaxis]).sum(dim=1)", "\n", "# Manually doing complex multiply", "\n", "prod", "=", "(", "S0_10_f", "[", "...", ",", "np", ".", "newaxis", "]", "*", "dT_00_sum_f", "[", ":", ",", ":", ",", "np", ".", "newaxis", ",", ":", ",", "np", ".", "newaxis", ",", ":", "]", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "dS1_01_f", "=", "torch", ".", "stack", "(", "(", "prod", "[", "...", ",", "0", ",", "0", "]", "+", "prod", "[", "...", ",", "1", ",", "1", "]", ",", "prod", "[", "...", ",", "0", ",", "1", "]", "-", "prod", "[", "...", ",", "1", ",", "0", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "dp", "=", "torch", ".", "irfft", "(", "dS1_01_f", ",", "1", ",", "signal_sizes", "=", "(", "2", "*", "n2", ",", ")", ")", "[", ":", ",", ":", ",", ":", "n2", "]", "\n", "g", "=", "torch", ".", "autograd", ".", "grad", "(", "dp", ".", "sum", "(", ")", ",", "(", "grad", ",", "q", ")", ",", "retain_graph", "=", "True", ")", "\n", "", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "end", "=", "time", ".", "perf_counter", "(", ")", "\n", "print", "(", "f'Elapsed time FFT: {end - start}s.\\n'", ")", "\n", "\n", "return", "F", ".", "conv_transpose1d", "(", "grad", ",", "q", ".", "flip", "(", "2", ")", ",", "padding", "=", "q", ".", "shape", "[", "-", "1", "]", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_transpose_multiply_conv": [[121, 177], ["int", "torch.zeros", "torch.ones", "numpy.log2", "v.t", "range", "torch.cat", "torch.cat", "torch.nn.functional.conv1d", "torch.cat", "torch.rfft", "torch.einsum", "torch.stack", "S0_10_mult_subdiag.flip", "torch.irfft", "torch.cat", "torch.zeros"], "function", ["None"], ["", "def", "krylov_transpose_multiply_conv", "(", "subdiag", ",", "v", ",", "u", ")", ":", "\n", "    ", "\"\"\"Multiply Krylov(A, v_i)^T @ u when A is zero except on the subdiagonal.\n    Use either Pytorch's conv1d or FFT for polynomial multiplication, depending\n    on polynomial degree. This is the fastest implementation.\n    Parameters:\n        subdiag: Tensor of shape (n - 1, )\n        v: Tensor of shape (rank, n)\n        u: Tensor of shape (batch_size, n)\n    Returns:\n        product: Tensor of shape (batch_size, rank, n)\n    \"\"\"", "\n", "batch_size", ",", "n", "=", "u", ".", "shape", "\n", "rank", ",", "n_", "=", "v", ".", "shape", "\n", "assert", "n", "==", "n_", ",", "'u and v must have the same last dimension'", "\n", "m", "=", "int", "(", "np", ".", "log2", "(", "n", ")", ")", "\n", "assert", "n", "==", "1", "<<", "m", ",", "'n must be a power of 2'", "\n", "\n", "result", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "rank", ",", "n", ")", ",", "dtype", "=", "u", ".", "dtype", ",", "device", "=", "u", ".", "device", ")", "\n", "T_00_sum", "=", "u", "@", "v", ".", "t", "(", ")", "\n", "result", "[", ":", ",", ":", ",", "0", "]", "+=", "T_00_sum", "\n", "T_01", "=", "u", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "T_10", "=", "v", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "T_11", "=", "torch", ".", "ones", "(", "n", ",", "device", "=", "T_00_sum", ".", "device", ")", "\n", "for", "d", "in", "range", "(", "m", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "        ", "n1", ",", "n2", "=", "1", "<<", "d", ",", "1", "<<", "(", "m", "-", "d", "-", "1", ")", "\n", "S_00_sum", ",", "S_01", ",", "S_10", ",", "S_11", "=", "T_00_sum", ",", "T_01", ",", "T_10", ",", "T_11", "\n", "S0_10_mult_subdiag", "=", "S_10", "[", ":", ",", ":", ":", "2", "]", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", ",", "np", ".", "newaxis", "]", "\n", "# polynomial multiplication", "\n", "# T_00_sum = poly_mult_sum_benchmark(S_01[:, 1::2], S0_10_mult_subdiag)", "\n", "if", "n2", "<=", "128", ":", "# Pick between 2 implementations based on polynomial degree n2", "\n", "            ", "T_00_sum", "=", "F", ".", "conv1d", "(", "S_01", "[", ":", ",", "1", ":", ":", "2", "]", ",", "S0_10_mult_subdiag", ".", "flip", "(", "2", ")", ",", "padding", "=", "n2", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "S", "=", "torch", ".", "cat", "(", "(", "torch", ".", "cat", "(", "(", "S0_10_mult_subdiag", ",", "S_01", "[", ":", ",", "1", ":", ":", "2", "]", ")", ")", ",", "\n", "torch", ".", "zeros", "(", "(", "rank", "+", "batch_size", ",", "n1", ",", "n2", ")", ",", "dtype", "=", "S_10", ".", "dtype", ",", "device", "=", "S_10", ".", "device", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "S_f", "=", "torch", ".", "rfft", "(", "S", ",", "1", ")", "\n", "S0_10_f", ",", "S1_01_f", "=", "S_f", "[", ":", "rank", "]", ",", "S_f", "[", "rank", ":", "rank", "+", "batch_size", "]", "\n", "# Different ways to compute the same expression, for speed vs readability", "\n", "# Option 1: call complex_mult, slowest", "\n", "# T_00_f_sum = complex_mult(S1_01_f[:, np.newaxis], S0_10_f[np.newaxis]).sum(dim=2)", "\n", "# Option 2: multiply and sum", "\n", "# prod = (S1_01_f[:, np.newaxis, ..., np.newaxis] * S0_10_f[np.newaxis, ..., np.newaxis, :]).sum(dim=2)", "\n", "# Option 3: einsum", "\n", "prod", "=", "torch", ".", "einsum", "(", "'bnmo,rnmp->brmop'", ",", "S1_01_f", ",", "S0_10_f", ")", "\n", "# Option 4: manually doing permute and reshape and bmm, only 3% faster than einsum.", "\n", "# temp1 = S1_01_f.permute(2, 0, 3, 1).reshape((-1, batch_size * 2, n1))", "\n", "# temp2 = S0_10_f.permute(2, 1, 0, 3).reshape((-1, n1, rank * 2))", "\n", "# prod = (temp1 @ temp2).reshape((-1, batch_size, 2, rank, 2)).permute(1, 3, 0, 2, 4)", "\n", "T_00_f_sum", "=", "torch", ".", "stack", "(", "(", "prod", "[", "...", ",", "0", ",", "0", "]", "-", "prod", "[", "...", ",", "1", ",", "1", "]", ",", "prod", "[", "...", ",", "0", ",", "1", "]", "+", "prod", "[", "...", ",", "1", ",", "0", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "T_00_sum", "=", "torch", ".", "irfft", "(", "T_00_f_sum", ",", "1", ",", "signal_sizes", "=", "(", "2", "*", "n2", ",", ")", ")", "[", "...", ",", ":", "-", "1", "]", "\n", "# polynomial additions", "\n", "", "result", "[", ":", ",", ":", ",", "1", ":", "2", "*", "n2", "]", "+=", "T_00_sum", "\n", "S0_11_mult_subdiag", "=", "S_11", "[", ":", ":", "2", "]", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", "]", "\n", "T_01", "=", "torch", ".", "cat", "(", "(", "S_01", "[", ":", ",", ":", ":", "2", "]", ",", "S_01", "[", ":", ",", "1", ":", ":", "2", "]", "*", "S0_11_mult_subdiag", "[", ":", ",", "np", ".", "newaxis", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "T_10", "=", "torch", ".", "cat", "(", "(", "S_10", "[", ":", ",", "1", ":", ":", "2", "]", ",", "S0_10_mult_subdiag", "*", "S_11", "[", "1", ":", ":", "2", "]", "[", ":", ",", "np", ".", "newaxis", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "T_11", "=", "S0_11_mult_subdiag", "*", "S_11", "[", "1", ":", ":", "2", "]", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_transpose_multiply": [[179, 238], ["int", "torch.zeros", "torch.ones", "numpy.log2", "v.t", "range", "torch.cat", "torch.rfft", "torch.einsum", "torch.stack", "torch.cat", "torch.cat", "torch.irfft", "torch.cat", "torch.zeros"], "function", ["None"], ["", "def", "krylov_transpose_multiply", "(", "subdiag", ",", "v", ",", "u", ")", ":", "\n", "    ", "\"\"\"Multiply Krylov(A, v_i)^T @ u when A is zero except on the subdiagonal.\n    Parameters:\n        subdiag: Tensor of shape (n - 1, )\n        v: Tensor of shape (rank, n)\n        u: Tensor of shape (batch_size, n)\n    Returns:\n        product: Tensor of shape (batch_size, rank, n)\n    \"\"\"", "\n", "batch_size", ",", "n", "=", "u", ".", "shape", "\n", "rank", ",", "n_", "=", "v", ".", "shape", "\n", "assert", "n", "==", "n_", ",", "'u and v must have the same last dimension'", "\n", "m", "=", "int", "(", "np", ".", "log2", "(", "n", ")", ")", "\n", "assert", "n", "==", "1", "<<", "m", ",", "'n must be a power of 2'", "\n", "\n", "result", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "rank", ",", "n", ")", ",", "dtype", "=", "u", ".", "dtype", ",", "device", "=", "u", ".", "device", ")", "\n", "# T_00_sum = (u[:, np.newaxis, ..., np.newaxis] * v[np.newaxis, ..., np.newaxis]).sum(dim=2)", "\n", "T_00_sum", "=", "u", "@", "v", ".", "t", "(", ")", "\n", "result", "[", ":", ",", ":", ",", "0", "]", "=", "T_00_sum", "\n", "T_01", "=", "u", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "T_10", "=", "v", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "T_11", "=", "torch", ".", "ones", "(", "n", ",", "device", "=", "T_00_sum", ".", "device", ")", "\n", "for", "d", "in", "range", "(", "m", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "        ", "n1", ",", "n2", "=", "1", "<<", "d", ",", "1", "<<", "(", "m", "-", "d", "-", "1", ")", "\n", "S_01", ",", "S_10", ",", "S_11", "=", "T_01", ",", "T_10", ",", "T_11", "\n", "# S0_10 = torch.cat((S_10[:, ::2], torch.zeros_like(S_10[:, ::2])), dim=-1)", "\n", "# S1_01 = torch.cat((S_01[:, 1::2], torch.zeros_like(S_01[:, 1::2])), dim=-1)", "\n", "# S = torch.cat((S0_10, S1_01))", "\n", "S0_10_mult_subdiag", "=", "S_10", "[", ":", ",", ":", ":", "2", "]", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", ",", "np", ".", "newaxis", "]", "\n", "S", "=", "torch", ".", "cat", "(", "(", "torch", ".", "cat", "(", "(", "S0_10_mult_subdiag", ",", "S_01", "[", ":", ",", "1", ":", ":", "2", "]", ")", ")", ",", "\n", "torch", ".", "zeros", "(", "(", "rank", "+", "batch_size", ",", "n1", ",", "n2", ")", ",", "dtype", "=", "S_10", ".", "dtype", ",", "device", "=", "S_10", ".", "device", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# polynomial multiplications", "\n", "S_f", "=", "torch", ".", "rfft", "(", "S", ",", "1", ")", "\n", "S0_10_f", ",", "S1_01_f", "=", "S_f", "[", ":", "rank", "]", ",", "S_f", "[", "rank", ":", "rank", "+", "batch_size", "]", "\n", "# Different ways to compute the same expression, for speed vs readability", "\n", "# Option 1: call complex_mult, slowest", "\n", "# T_00_f_sum = complex_mult(S1_01_f[:, np.newaxis], S0_10_f[np.newaxis]).sum(dim=2)", "\n", "# Option 2: multiply and sum", "\n", "# Manually doing complex multiply, somehow this is faster than Cupy's complex mult", "\n", "# prod = (S1_01_f[:, np.newaxis, ..., np.newaxis] * S0_10_f[np.newaxis, ..., np.newaxis, :]).sum(dim=2)", "\n", "# Option 3: einsum", "\n", "prod", "=", "torch", ".", "einsum", "(", "'bnmo,rnmp->brmop'", ",", "S1_01_f", ",", "S0_10_f", ")", "\n", "# Option 4: manually doing permute and reshape and bmm, only 3% faster than einsum.", "\n", "# temp1 = S1_01_f.permute(2, 0, 3, 1).reshape((-1, batch_size * 2, n1))", "\n", "# temp2 = S0_10_f.permute(2, 1, 0, 3).reshape((-1, n1, rank * 2))", "\n", "# prod = (temp1 @ temp2).reshape((-1, batch_size, 2, rank, 2)).permute(1, 3, 0, 2, 4)", "\n", "# prod = (S1_01_f[:, np.newaxis, ..., np.newaxis] * S0_10_f[np.newaxis, ..., np.newaxis, :]).sum(dim=2)", "\n", "T_00_f_sum", "=", "torch", ".", "stack", "(", "(", "prod", "[", "...", ",", "0", ",", "0", "]", "-", "prod", "[", "...", ",", "1", ",", "1", "]", ",", "prod", "[", "...", ",", "0", ",", "1", "]", "+", "prod", "[", "...", ",", "1", ",", "0", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "T_00_sum", "=", "torch", ".", "irfft", "(", "T_00_f_sum", ",", "1", ",", "signal_sizes", "=", "(", "2", "*", "n2", ",", ")", ")", "[", "...", ",", ":", "-", "1", "]", "\n", "\n", "# polynomial additions", "\n", "result", "[", ":", ",", ":", ",", "1", ":", "2", "*", "n2", "]", "+=", "T_00_sum", "\n", "S0_11_mult_subdiag", "=", "S_11", "[", ":", ":", "2", "]", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", "]", "\n", "T_01", "=", "torch", ".", "cat", "(", "(", "S_01", "[", ":", ",", ":", ":", "2", "]", ",", "S_01", "[", ":", ",", "1", ":", ":", "2", "]", "*", "S0_11_mult_subdiag", "[", ":", ",", "np", ".", "newaxis", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "T_10", "=", "torch", ".", "cat", "(", "(", "S_10", "[", ":", ",", "1", ":", ":", "2", "]", ",", "S0_10_mult_subdiag", "*", "S_11", "[", "1", ":", ":", "2", "]", "[", ":", ",", "np", ".", "newaxis", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "T_11", "=", "S0_11_mult_subdiag", "*", "S_11", "[", "1", ":", ":", "2", "]", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.KTu_traceable": [[240, 299], ["int", "T_00_sum.unsqueeze", "torch.ones", "numpy.log2", "v.t", "range", "torch.cat", "torch.rfft", "torch.einsum", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.irfft", "torch.cat", "torch.zeros"], "function", ["None"], ["", "def", "KTu_traceable", "(", "subdiag", ",", "v", ",", "u", ")", ":", "\n", "    ", "\"\"\"Multiply Krylov(A, v_i)^T @ u when A is zero except on the subdiagonal.\n    (WIP) Written to be traceable by Pytorch 1.0 JIT compiler.\n    Parameters:\n        subdiag: Tensor of shape (n - 1, )\n        v: Tensor of shape (rank, n)\n        u: Tensor of shape (batch_size, n)\n    Returns:\n        product: Tensor of shape (batch_size, rank, n)\n    \"\"\"", "\n", "batch_size", ",", "n", "=", "u", ".", "shape", "\n", "rank", ",", "n_", "=", "v", ".", "shape", "\n", "# assert n == n_, 'u and v must have the same last dimension'", "\n", "m", "=", "int", "(", "np", ".", "log2", "(", "n", ")", ")", "\n", "# assert n == 1 << m, 'n must be a power of 2'", "\n", "\n", "# T_00_sum = (u[:, np.newaxis, ..., np.newaxis] * v[np.newaxis, ..., np.newaxis]).sum(dim=2)", "\n", "T_00_sum", "=", "u", "@", "v", ".", "t", "(", ")", "\n", "result", "=", "T_00_sum", ".", "unsqueeze", "(", "-", "1", ")", "\n", "T_01", "=", "u", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "T_10", "=", "v", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "T_11", "=", "torch", ".", "ones", "(", "n", ",", "device", "=", "T_00_sum", ".", "device", ")", "\n", "for", "d", "in", "range", "(", "m", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "        ", "n1", ",", "n2", "=", "1", "<<", "d", ",", "1", "<<", "(", "m", "-", "d", "-", "1", ")", "\n", "S_01", ",", "S_10", ",", "S_11", "=", "T_01", ",", "T_10", ",", "T_11", "\n", "# S0_10 = torch.cat((S_10[:, ::2], torch.zeros_like(S_10[:, ::2])), dim=-1)", "\n", "# S1_01 = torch.cat((S_01[:, 1::2], torch.zeros_like(S_01[:, 1::2])), dim=-1)", "\n", "# S = torch.cat((S0_10, S1_01))", "\n", "S0_10_mult_subdiag", "=", "S_10", "[", ":", ",", ":", ":", "2", "]", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", ",", "np", ".", "newaxis", "]", "\n", "S", "=", "torch", ".", "cat", "(", "(", "torch", ".", "cat", "(", "(", "S0_10_mult_subdiag", ",", "S_01", "[", ":", ",", "1", ":", ":", "2", "]", ")", ")", ",", "\n", "torch", ".", "zeros", "(", "(", "rank", "+", "batch_size", ",", "n1", ",", "n2", ")", ",", "dtype", "=", "S_10", ".", "dtype", ",", "device", "=", "S_10", ".", "device", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# polynomial multiplications", "\n", "S_f", "=", "torch", ".", "rfft", "(", "S", ",", "1", ")", "\n", "S0_10_f", ",", "S1_01_f", "=", "S_f", "[", ":", "rank", "]", ",", "S_f", "[", "rank", ":", "rank", "+", "batch_size", "]", "\n", "# Different ways to compute the same expression, for speed vs readability", "\n", "# Option 1: call complex_mult, slowest", "\n", "# T_00_f_sum = complex_mult(S1_01_f[:, np.newaxis], S0_10_f[np.newaxis]).sum(dim=2)", "\n", "# Option 2: multiply and sum", "\n", "# Manually doing complex multiply, somehow this is faster than Cupy's complex mult", "\n", "# prod = (S1_01_f[:, np.newaxis, ..., np.newaxis] * S0_10_f[np.newaxis, ..., np.newaxis, :]).sum(dim=2)", "\n", "# Option 3: einsum", "\n", "prod", "=", "torch", ".", "einsum", "(", "'bnmo,rnmp->brmop'", ",", "S1_01_f", ",", "S0_10_f", ")", "\n", "# Option 4: manually doing permute and reshape and bmm, only 3% faster than einsum.", "\n", "# temp1 = S1_01_f.permute(2, 0, 3, 1).reshape((-1, batch_size * 2, n1))", "\n", "# temp2 = S0_10_f.permute(2, 1, 0, 3).reshape((-1, n1, rank * 2))", "\n", "# prod = (temp1 @ temp2).reshape((-1, batch_size, 2, rank, 2)).permute(1, 3, 0, 2, 4)", "\n", "# prod = (S1_01_f[:, np.newaxis, ..., np.newaxis] * S0_10_f[np.newaxis, ..., np.newaxis, :]).sum(dim=2)", "\n", "T_00_f_sum", "=", "torch", ".", "stack", "(", "(", "prod", "[", "...", ",", "0", ",", "0", "]", "-", "prod", "[", "...", ",", "1", ",", "1", "]", ",", "prod", "[", "...", ",", "0", ",", "1", "]", "+", "prod", "[", "...", ",", "1", ",", "0", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "T_00_sum", "=", "torch", ".", "irfft", "(", "T_00_f_sum", ",", "1", ",", "signal_sizes", "=", "(", "2", "*", "n2", ",", ")", ")", "[", "...", ",", ":", "-", "1", "]", "\n", "\n", "# polynomial additions", "\n", "result", "=", "torch", ".", "cat", "(", "(", "result", "[", ":", ",", ":", ",", ":", "1", "]", ",", "result", "[", ":", ",", ":", ",", "1", ":", "]", "+", "T_00_sum", "[", ":", ",", ":", ",", ":", "n2", "-", "1", "]", ",", "T_00_sum", "[", ":", ",", ":", ",", "n2", "-", "1", ":", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "S0_11_mult_subdiag", "=", "S_11", "[", ":", ":", "2", "]", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", "]", "\n", "T_01", "=", "torch", ".", "cat", "(", "(", "S_01", "[", ":", ",", ":", ":", "2", "]", ",", "S_01", "[", ":", ",", "1", ":", ":", "2", "]", "*", "S0_11_mult_subdiag", "[", ":", ",", "np", ".", "newaxis", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "T_10", "=", "torch", ".", "cat", "(", "(", "S_10", "[", ":", ",", "1", ":", ":", "2", "]", ",", "S0_10_mult_subdiag", "*", "S_11", "[", "1", ":", ":", "2", "]", "[", ":", ",", "np", ".", "newaxis", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "T_11", "=", "S0_11_mult_subdiag", "*", "S_11", "[", "1", ":", ":", "2", "]", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_transpose_multiply_old": [[301, 353], ["int", "torch.ones", "torch.cat.squeeze().flip", "numpy.log2", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.rfft", "complex_utils.complex_mult", "torch.cat", "torch.cat", "torch.cat", "torch.irfft", "torch.cat.squeeze", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.complex_utils.complex_mult"], ["", "def", "krylov_transpose_multiply_old", "(", "subdiag", ",", "v", ",", "u", ")", ":", "\n", "    ", "\"\"\"Multiply Krylov(A, v_i)^T @ u when A is zero except on the subdiagonal.\n    Uses the old algorithm that scales worse when batching.\n    Parameters:\n        subdiag: Tensor of shape (n - 1, )\n        v: Tensor of shape (rank, n)\n        u: Tensor of shape (batch_size, n)\n    Returns:\n        product: Tensor of shape (batch_size, rank, n)\n    \"\"\"", "\n", "batch_size", ",", "n", "=", "u", ".", "shape", "\n", "rank", ",", "n_", "=", "v", ".", "shape", "\n", "assert", "n", "==", "n_", ",", "'u and v must have the same last dimension'", "\n", "m", "=", "int", "(", "np", ".", "log2", "(", "n", ")", ")", "\n", "assert", "n", "==", "1", "<<", "m", ",", "'n must be a power of 2'", "\n", "\n", "T_00", "=", "u", "[", ":", ",", "np", ".", "newaxis", ",", "...", ",", "np", ".", "newaxis", "]", "*", "v", "[", "np", ".", "newaxis", ",", "...", ",", "np", ".", "newaxis", "]", "\n", "T_01", "=", "u", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "T_10", "=", "v", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "T_11", "=", "torch", ".", "ones", "(", "(", "n", ",", "1", ")", ",", "device", "=", "T_00", ".", "device", ")", "\n", "for", "d", "in", "range", "(", "m", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "        ", "n1", ",", "n2", "=", "1", "<<", "d", ",", "1", "<<", "(", "m", "-", "d", "-", "1", ")", "\n", "S_00", ",", "S_01", ",", "S_10", ",", "S_11", "=", "T_00", ",", "T_01", ",", "T_10", ",", "T_11", "\n", "S0_10", "=", "torch", ".", "cat", "(", "(", "S_10", "[", ":", ",", ":", ":", "2", "]", ",", "torch", ".", "zeros_like", "(", "S_10", "[", ":", ",", ":", ":", "2", "]", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "S1_01", "=", "torch", ".", "cat", "(", "(", "S_01", "[", ":", ",", "1", ":", ":", "2", "]", ",", "torch", ".", "zeros_like", "(", "S_01", "[", ":", ",", "1", ":", ":", "2", "]", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "S0_11", "=", "torch", ".", "cat", "(", "(", "S_11", "[", ":", ":", "2", "]", ",", "torch", ".", "zeros_like", "(", "S_11", "[", ":", ":", "2", "]", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "S1_11", "=", "torch", ".", "cat", "(", "(", "S_11", "[", "1", ":", ":", "2", "]", ",", "torch", ".", "zeros_like", "(", "S_11", "[", "1", ":", ":", "2", "]", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "S", "=", "torch", ".", "cat", "(", "(", "S0_10", ",", "S0_11", "[", "np", ".", "newaxis", "]", ",", "S1_01", ",", "S1_11", "[", "np", ".", "newaxis", "]", ")", ")", "\n", "\n", "# polynomial multiplications", "\n", "S_f", "=", "torch", ".", "rfft", "(", "S", ",", "1", ")", "\n", "# S0_10_f, S0_11_f, S1_01_f, S1_11_f = S_f[:rank], S_f[rank], S_f[rank+1:rank+1+batch_size], S_f[-1]", "\n", "# T_00_f = complex_mult(S1_01_f[:, np.newaxis], S0_10_f[np.newaxis])", "\n", "# T_01_f = complex_mult(S1_01_f, S0_11_f)", "\n", "# T_10_f = complex_mult(S1_11_f, S0_10_f)", "\n", "# T_11_f = complex_mult(S1_11_f, S0_11_f)", "\n", "\n", "# T_f = torch.cat((torch.cat((T_00_f, T_01_f[:, np.newaxis]), dim=1),", "\n", "#                  torch.cat((T_10_f[np.newaxis], T_11_f[np.newaxis, np.newaxis]), dim=1)))", "\n", "\n", "# I didn't realize you could just batch all 4 multiplications like this", "\n", "T_f", "=", "complex_mult", "(", "S_f", "[", "rank", "+", "1", ":", ",", "np", ".", "newaxis", "]", ",", "S_f", "[", ":", "rank", "+", "1", "]", ")", "\n", "\n", "T", "=", "torch", ".", "irfft", "(", "T_f", ",", "1", ",", "signal_sizes", "=", "(", "2", "*", "n2", ",", ")", ")", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", ",", "np", ".", "newaxis", "]", "\n", "T_00", ",", "T_01", ",", "T_10", ",", "T_11", "=", "T", "[", ":", "batch_size", ",", ":", "rank", "]", ",", "T", "[", ":", "batch_size", ",", "-", "1", "]", ",", "T", "[", "-", "1", ",", ":", "rank", "]", ",", "T", "[", "-", "1", ",", "-", "1", "]", "\n", "\n", "# polynomial additions", "\n", "T_00", "=", "torch", ".", "cat", "(", "(", "T_00", "[", ":", ",", ":", ",", ":", ",", ":", "n2", "]", ",", "T_00", "[", ":", ",", ":", ",", ":", ",", "n2", ":", "]", "+", "S_00", "[", ":", ",", ":", ",", ":", ":", "2", "]", "+", "S_00", "[", ":", ",", ":", ",", "1", ":", ":", "2", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "T_01", "=", "torch", ".", "cat", "(", "(", "T_01", "[", ":", ",", ":", ",", ":", "n2", "]", ",", "T_01", "[", ":", ",", ":", ",", "n2", ":", "]", "+", "S_01", "[", ":", ",", ":", ":", "2", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "T_10", "=", "torch", ".", "cat", "(", "(", "T_10", "[", ":", ",", ":", ",", ":", "n2", "]", ",", "T_10", "[", ":", ",", ":", ",", "n2", ":", "]", "+", "S_10", "[", ":", ",", "1", ":", ":", "2", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "return", "T_00", ".", "squeeze", "(", "dim", "=", "2", ")", ".", "flip", "(", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_multiply_conv": [[355, 419], ["int", "torch.ones", "torch.zeros", "range", "numpy.log2", "range", "torch.cat", "torch.empty", "torch.zeros.squeeze", "torch.nn.functional.conv_transpose1d", "torch.cat", "torch.rfft", "torch.rfft", "torch.einsum", "torch.stack", "S0_10_mult_subdiag.flip", "torch.cat", "torch.irfft", "torch.zeros", "torch.zeros_like"], "function", ["None"], ["", "def", "krylov_multiply_conv", "(", "subdiag", ",", "v", ",", "w", ")", ":", "\n", "    ", "\"\"\"Multiply \\sum_i Krylov(A, v_i) @ w_i when A is zero except on the subdiagonal.\n    Since K @ w can be computed by autodiffing K^T @ u, the algorithm is just\n    hand-differentiating the code of @krylov_transpose_multiply.\n    Use either Pytorch's conv1d or FFT for polynomial multiplication, depending\n    on polynomial degree. This is the fastest implementation.\n    Parameters:\n        subdiag: Tensor of shape (n - 1, )\n        v: Tensor of shape (rank, n)\n        w: Tensor of shape (batch_size, rank, n)\n    Returns:\n        product: Tensor of shape (batch_size, n)\n    \"\"\"", "\n", "batch_size", ",", "rank", ",", "n", "=", "w", ".", "shape", "\n", "rank_", ",", "n_", "=", "v", ".", "shape", "\n", "assert", "n", "==", "n_", ",", "'w and v must have the same last dimension'", "\n", "assert", "rank", "==", "rank_", ",", "'w and v must have the same rank'", "\n", "m", "=", "int", "(", "np", ".", "log2", "(", "n", ")", ")", "\n", "assert", "n", "==", "1", "<<", "m", ",", "'n must be a power of 2'", "\n", "\n", "# Forward pass. Since K @ w can be computed by autodiffing K^T @ u, we", "\n", "# carry out the forward pass K^T @ u for u = 0 here to save the", "\n", "# intermediate values. This code is exactly the same as the function", "\n", "# @krylov_transpose_multiply, specialized to the case where u = 0.", "\n", "save_for_backward", "=", "[", "None", "]", "*", "m", "\n", "T_10", "=", "v", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "T_11", "=", "torch", ".", "ones", "(", "(", "n", ")", ",", "device", "=", "T_10", ".", "device", ")", "\n", "for", "d", "in", "range", "(", "m", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "        ", "n1", ",", "n2", "=", "1", "<<", "d", ",", "1", "<<", "(", "m", "-", "d", "-", "1", ")", "\n", "S_10", ",", "S_11", "=", "T_10", ",", "T_11", "\n", "S0_10_mult_subdiag", "=", "S_10", "[", ":", ",", ":", ":", "2", "]", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", ",", "np", ".", "newaxis", "]", "\n", "T_10", "=", "torch", ".", "cat", "(", "(", "S_10", "[", ":", ",", "1", ":", ":", "2", "]", ",", "S0_10_mult_subdiag", "*", "S_11", "[", "1", ":", ":", "2", "]", "[", ":", ",", "np", ".", "newaxis", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "S0_11_mult_subdiag", "=", "S_11", "[", ":", ":", "2", "]", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", "]", "\n", "save_for_backward", "[", "d", "]", "=", "S0_10_mult_subdiag", ",", "S0_11_mult_subdiag", "\n", "T_11", "=", "S0_11_mult_subdiag", "*", "S_11", "[", "1", ":", ":", "2", "]", "\n", "\n", "# Backward pass", "\n", "", "dT_01", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "1", ",", "n", ")", ",", "dtype", "=", "w", ".", "dtype", ",", "device", "=", "w", ".", "device", ")", "\n", "\n", "for", "d", "in", "range", "(", "m", ")", ":", "\n", "        ", "n1", ",", "n2", "=", "1", "<<", "d", ",", "1", "<<", "(", "m", "-", "d", "-", "1", ")", "\n", "S0_10_mult_subdiag", ",", "S0_11_mult_subdiag", "=", "save_for_backward", "[", "d", "]", "\n", "dS_01", "=", "torch", ".", "empty", "(", "(", "batch_size", ",", "2", "*", "n1", ",", "n2", ")", ",", "device", "=", "w", ".", "device", ")", "\n", "dS_01", "[", ":", ",", ":", ":", "2", "]", "=", "dT_01", "[", ":", ",", ":", ",", ":", "n2", "]", "\n", "# dS1_01 = poly_mult_sum_backward_benchmark(w[:, :, 1:2*n2], S0_10_mult_subdiag)", "\n", "if", "n2", "<=", "128", ":", "\n", "            ", "dS1_01", "=", "F", ".", "conv_transpose1d", "(", "w", "[", ":", ",", ":", ",", "1", ":", "2", "*", "n2", "]", ",", "S0_10_mult_subdiag", ".", "flip", "(", "2", ")", ",", "padding", "=", "n2", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "dT_00_sum", "=", "torch", ".", "cat", "(", "(", "w", "[", ":", ",", ":", ",", "1", ":", "2", "*", "n2", "]", ",", "torch", ".", "zeros", "(", "(", "batch_size", ",", "rank", ",", "1", ")", ",", "dtype", "=", "w", ".", "dtype", ",", "device", "=", "w", ".", "device", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "dT_00_sum_f", "=", "torch", ".", "rfft", "(", "dT_00_sum", ",", "1", ")", "\n", "S0_10_f", "=", "torch", ".", "rfft", "(", "torch", ".", "cat", "(", "(", "S0_10_mult_subdiag", ",", "torch", ".", "zeros_like", "(", "S0_10_mult_subdiag", ")", ")", ",", "dim", "=", "-", "1", ")", ",", "1", ")", "\n", "# dS1_01_f = complex_mult(conjugate(S0_10_f), dT_00_sum_f[:, :, np.newaxis]).sum(dim=1)", "\n", "# Manually doing complex multiply", "\n", "# prod = (S0_10_f[..., np.newaxis] * dT_00_sum_f[:, :, np.newaxis, :, np.newaxis, :]).sum(dim=1)", "\n", "prod", "=", "torch", ".", "einsum", "(", "'rnmo,brmp->bnmop'", ",", "S0_10_f", ",", "dT_00_sum_f", ")", "\n", "dS1_01_f", "=", "torch", ".", "stack", "(", "(", "prod", "[", "...", ",", "0", ",", "0", "]", "+", "prod", "[", "...", ",", "1", ",", "1", "]", ",", "prod", "[", "...", ",", "0", ",", "1", "]", "-", "prod", "[", "...", ",", "1", ",", "0", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "dS1_01", "=", "torch", ".", "irfft", "(", "dS1_01_f", ",", "1", ",", "signal_sizes", "=", "(", "2", "*", "n2", ",", ")", ")", "[", ":", ",", ":", ",", ":", "n2", "]", "\n", "", "dS_01", "[", ":", ",", "1", ":", ":", "2", "]", "=", "dT_01", "[", ":", ",", ":", ",", "n2", ":", "]", "*", "S0_11_mult_subdiag", "[", ":", ",", "np", ".", "newaxis", "]", "+", "dS1_01", "\n", "\n", "dT_01", "=", "dS_01", "\n", "\n", "# du = ((dT_00_sum[:, :, np.newaxis] * v[np.newaxis, :, :, np.newaxis]).sum(dim=1) + dT_01).squeeze(dim=-1)", "\n", "", "du", "=", "w", "[", ":", ",", ":", ",", "0", "]", "@", "v", "+", "dT_01", ".", "squeeze", "(", "dim", "=", "-", "1", ")", "\n", "return", "du", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_multiply": [[420, 479], ["int", "torch.ones", "torch.zeros", "range", "numpy.log2", "range", "torch.cat", "torch.empty", "torch.cat", "torch.rfft", "torch.rfft", "torch.einsum", "torch.stack", "torch.zeros.squeeze", "torch.cat", "torch.irfft", "torch.zeros", "torch.zeros_like"], "function", ["None"], ["", "def", "krylov_multiply", "(", "subdiag", ",", "v", ",", "w", ")", ":", "\n", "    ", "\"\"\"Multiply \\sum_i Krylov(A, v_i) @ w_i when A is zero except on the subdiagonal.\n    Since K @ w can be computed by autodiffing K^T @ u, the algorithm is just\n    hand-differentiating the code of @krylov_transpose_multiply.\n    Parameters:\n        subdiag: Tensor of shape (n - 1, )\n        v: Tensor of shape (rank, n)\n        w: Tensor of shape (batch_size, rank, n)\n    Returns:\n        product: Tensor of shape (batch_size, n)\n    \"\"\"", "\n", "batch_size", ",", "rank", ",", "n", "=", "w", ".", "shape", "\n", "rank_", ",", "n_", "=", "v", ".", "shape", "\n", "assert", "n", "==", "n_", ",", "'w and v must have the same last dimension'", "\n", "assert", "rank", "==", "rank_", ",", "'w and v must have the same rank'", "\n", "m", "=", "int", "(", "np", ".", "log2", "(", "n", ")", ")", "\n", "assert", "n", "==", "1", "<<", "m", ",", "'n must be a power of 2'", "\n", "\n", "# Forward pass. Since K @ w can be computed by autodiffing K^T @ u, we", "\n", "# carry out the forward pass K^T @ u for u = 0 here to save the", "\n", "# intermediate values. This code is exactly the same as the function", "\n", "# @krylov_transpose_multiply, specialized to the case where u = 0.", "\n", "save_for_backward", "=", "[", "None", "]", "*", "m", "\n", "T_10", "=", "v", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "T_11", "=", "torch", ".", "ones", "(", "(", "n", ")", ",", "device", "=", "T_10", ".", "device", ")", "\n", "for", "d", "in", "range", "(", "m", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "        ", "n1", ",", "n2", "=", "1", "<<", "d", ",", "1", "<<", "(", "m", "-", "d", "-", "1", ")", "\n", "S_10", ",", "S_11", "=", "T_10", ",", "T_11", "\n", "S0_10_mult_subdiag", "=", "S_10", "[", ":", ",", ":", ":", "2", "]", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", ",", "np", ".", "newaxis", "]", "\n", "T_10", "=", "torch", ".", "cat", "(", "(", "S_10", "[", ":", ",", "1", ":", ":", "2", "]", ",", "S0_10_mult_subdiag", "*", "S_11", "[", "1", ":", ":", "2", "]", "[", ":", ",", "np", ".", "newaxis", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "S0_11_mult_subdiag", "=", "S_11", "[", ":", ":", "2", "]", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", "]", "\n", "save_for_backward", "[", "d", "]", "=", "S0_10_mult_subdiag", ",", "S0_11_mult_subdiag", "\n", "T_11", "=", "S0_11_mult_subdiag", "*", "S_11", "[", "1", ":", ":", "2", "]", "\n", "\n", "# Backward pass", "\n", "", "dT_01", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "1", ",", "n", ")", ",", "dtype", "=", "w", ".", "dtype", ",", "device", "=", "w", ".", "device", ")", "\n", "\n", "for", "d", "in", "range", "(", "m", ")", ":", "\n", "        ", "n1", ",", "n2", "=", "1", "<<", "d", ",", "1", "<<", "(", "m", "-", "d", "-", "1", ")", "\n", "S0_10_mult_subdiag", ",", "S0_11_mult_subdiag", "=", "save_for_backward", "[", "d", "]", "\n", "dS_01", "=", "torch", ".", "empty", "(", "(", "batch_size", ",", "2", "*", "n1", ",", "n2", ")", ",", "device", "=", "w", ".", "device", ")", "\n", "dS_01", "[", ":", ",", ":", ":", "2", "]", "=", "dT_01", "[", ":", ",", ":", ",", ":", "n2", "]", "\n", "dT_00_sum", "=", "torch", ".", "cat", "(", "(", "w", "[", ":", ",", ":", ",", "1", ":", "2", "*", "n2", "]", ",", "torch", ".", "zeros", "(", "(", "batch_size", ",", "rank", ",", "1", ")", ",", "dtype", "=", "w", ".", "dtype", ",", "device", "=", "w", ".", "device", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "dT_00_sum_f", "=", "torch", ".", "rfft", "(", "dT_00_sum", ",", "1", ")", "\n", "S0_10_f", "=", "torch", ".", "rfft", "(", "torch", ".", "cat", "(", "(", "S0_10_mult_subdiag", ",", "torch", ".", "zeros_like", "(", "S0_10_mult_subdiag", ")", ")", ",", "dim", "=", "-", "1", ")", ",", "1", ")", "\n", "# dS1_01_f = complex_mult(conjugate(S0_10_f), dT_00_sum_f[:, :, np.newaxis]).sum(dim=1)", "\n", "# Manually doing complex multiply", "\n", "# prod = (S0_10_f[..., np.newaxis] * dT_00_sum_f[:, :, np.newaxis, :, np.newaxis, :]).sum(dim=1)", "\n", "prod", "=", "torch", ".", "einsum", "(", "'rnmo,brmp->bnmop'", ",", "S0_10_f", ",", "dT_00_sum_f", ")", "\n", "dS1_01_f", "=", "torch", ".", "stack", "(", "(", "prod", "[", "...", ",", "0", ",", "0", "]", "+", "prod", "[", "...", ",", "1", ",", "1", "]", ",", "prod", "[", "...", ",", "0", ",", "1", "]", "-", "prod", "[", "...", ",", "1", ",", "0", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "dS1_01", "=", "torch", ".", "irfft", "(", "dS1_01_f", ",", "1", ",", "signal_sizes", "=", "(", "2", "*", "n2", ",", ")", ")", "[", ":", ",", ":", ",", ":", "n2", "]", "\n", "dS_01", "[", ":", ",", "1", ":", ":", "2", "]", "=", "dT_01", "[", ":", ",", ":", ",", "n2", ":", "]", "*", "S0_11_mult_subdiag", "[", ":", ",", "np", ".", "newaxis", "]", "+", "dS1_01", "\n", "\n", "dT_01", "=", "dS_01", "\n", "\n", "# du = ((dT_00_sum[:, :, np.newaxis] * v[np.newaxis, :, :, np.newaxis]).sum(dim=1) + dT_01).squeeze(dim=-1)", "\n", "", "du", "=", "w", "[", ":", ",", ":", ",", "0", "]", "@", "v", "+", "dT_01", ".", "squeeze", "(", "dim", "=", "-", "1", ")", "\n", "return", "du", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_multiply_by_autodiff": [[480, 500], ["int", "torch.zeros", "krylov.krylov_transpose_multiply", "torch.autograd.grad", "numpy.log2"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_transpose_multiply"], ["", "def", "krylov_multiply_by_autodiff", "(", "subdiag", ",", "v", ",", "w", ")", ":", "\n", "    ", "\"\"\"Multiply \\sum_i Krylov(A, v_i) @ w_i when A is zero except on the subdiagonal, using Pytorch's autodiff.\n    Parameters:\n        subdiag: Tensor of shape (n - 1, )\n        v: Tensor of shape (rank, n)\n        w: Tensor of shape (batch_size, rank, n)\n    Returns:\n        product: Tensor of shape (batch_size, n)\n    \"\"\"", "\n", "batch_size", ",", "rank", ",", "n", "=", "w", ".", "shape", "\n", "rank_", ",", "n_", "=", "v", ".", "shape", "\n", "assert", "n", "==", "n_", ",", "'w and v must have the same last dimension'", "\n", "assert", "rank", "==", "rank_", ",", "'w and v must have the same rank'", "\n", "m", "=", "int", "(", "np", ".", "log2", "(", "n", ")", ")", "\n", "assert", "n", "==", "1", "<<", "m", ",", "'n must be a power of 2'", "\n", "\n", "u", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "n", ")", ",", "dtype", "=", "v", ".", "dtype", ",", "device", "=", "v", ".", "device", ",", "requires_grad", "=", "True", ")", "\n", "prod", "=", "krylov_transpose_multiply", "(", "subdiag", ",", "v", ",", "u", ")", "\n", "result", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "prod", ",", "u", ",", "grad_outputs", "=", "w", ",", "create_graph", "=", "True", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_multiply_forward_old_": [[502, 550], ["int", "torch.ones", "numpy.log2", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.rfft", "complex_utils.complex_mult", "torch.cat", "torch.irfft", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.complex_utils.complex_mult"], ["", "def", "krylov_multiply_forward_old_", "(", "subdiag", ",", "v", ")", ":", "\n", "    ", "\"\"\"Forward pass of Krylov_multiply. Since K @ w can be computed by\n    autodiffing K^T @ u, we carry out the forward pass K^T @ u for u = 0 here\n    to save the intermediate values. This code is exactly the same as the\n    function @krylov_transpose_multiply_old, specialized to the case where u = 0.\n    Uses the old algorithm that scales worse when batching.\n    Parameters:\n        subdiag: Tensor of shape (n - 1, )\n        v: Tensor of shape (rank, n)\n    Returns:\n        save_for_backward: list of length log n, containing intermediate values\n    necessary for the backward pass K @ w.\n    \"\"\"", "\n", "rank", ",", "n", "=", "v", ".", "shape", "\n", "m", "=", "int", "(", "np", ".", "log2", "(", "n", ")", ")", "\n", "assert", "n", "==", "1", "<<", "m", ",", "'n must be a power of 2'", "\n", "\n", "save_for_backward", "=", "[", "None", "]", "*", "m", "\n", "T_10", "=", "v", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "T_11", "=", "torch", ".", "ones", "(", "(", "n", ",", "1", ")", ",", "device", "=", "T_10", ".", "device", ")", "\n", "for", "d", "in", "range", "(", "m", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "        ", "n1", ",", "n2", "=", "1", "<<", "d", ",", "1", "<<", "(", "m", "-", "d", "-", "1", ")", "\n", "S_10", ",", "S_11", "=", "T_10", ",", "T_11", "\n", "S0_10", "=", "torch", ".", "cat", "(", "(", "S_10", "[", ":", ",", ":", ":", "2", "]", ",", "torch", ".", "zeros_like", "(", "S_10", "[", ":", ",", ":", ":", "2", "]", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "S0_11", "=", "torch", ".", "cat", "(", "(", "S_11", "[", ":", ":", "2", "]", ",", "torch", ".", "zeros_like", "(", "S_11", "[", ":", ":", "2", "]", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "S1_11", "=", "torch", ".", "cat", "(", "(", "S_11", "[", "1", ":", ":", "2", "]", ",", "torch", ".", "zeros_like", "(", "S_11", "[", "1", ":", ":", "2", "]", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "S", "=", "torch", ".", "cat", "(", "(", "S0_10", ",", "S0_11", "[", "np", ".", "newaxis", "]", ",", "S1_11", "[", "np", ".", "newaxis", "]", ")", ")", "\n", "\n", "# polynomial multiplications", "\n", "S_f", "=", "torch", ".", "rfft", "(", "S", ",", "1", ")", "\n", "# S0_10_f, S0_11_f, S1_11_f = S_f[:rank], S_f[-2], S_f[-1]", "\n", "# save_for_backward[d] = (S0_10_f, S0_11_f)", "\n", "\n", "# T_10_f = complex_mult(S1_11_f, S0_10_f)", "\n", "# T_11_f = complex_mult(S1_11_f, S0_11_f)", "\n", "\n", "# T_f = torch.cat((T_10_f, T_11_f[np.newaxis]))", "\n", "\n", "save_for_backward", "[", "d", "]", "=", "S_f", "[", ":", "rank", "+", "1", "]", "\n", "T_f", "=", "complex_mult", "(", "S_f", "[", "-", "1", "]", ",", "S_f", "[", ":", "rank", "+", "1", "]", ")", "\n", "\n", "T", "=", "torch", ".", "irfft", "(", "T_f", ",", "1", ",", "signal_sizes", "=", "(", "2", "*", "n2", ",", ")", ")", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", ",", "np", ".", "newaxis", "]", "\n", "T_10", ",", "T_11", "=", "T", "[", ":", "rank", "]", ",", "T", "[", "-", "1", "]", "\n", "\n", "# polynomial additions", "\n", "T_10", "=", "torch", ".", "cat", "(", "(", "T_10", "[", ":", ",", ":", ",", ":", "n2", "]", ",", "T_10", "[", ":", ",", ":", ",", "n2", ":", "]", "+", "S_10", "[", ":", ",", "1", ":", ":", "2", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "", "return", "save_for_backward", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_multiply_old": [[551, 600], ["int", "krylov.krylov_multiply_forward_old_", "range", "numpy.log2", "w.flip", "torch.zeros", "torch.empty", "torch.empty", "torch.cat", "complex_utils.complex_mult().sum", "torch.rfft", "torch.irfft", "w.dim", "complex_utils.complex_mult", "complex_utils.conjugate"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_multiply_forward_old_", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.complex_utils.complex_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.complex_utils.conjugate"], ["", "def", "krylov_multiply_old", "(", "subdiag", ",", "v", ",", "w", ")", ":", "\n", "    ", "\"\"\"Multiply \\sum_i Krylov(A, v_i) @ w_i when A is zero except on the subdiagonal.\n    Since K @ w can be computed by autodiffing K^T @ u, the algorithm is just\n    hand-differentiating the code of @krylov_transpose_multiply.\n    Uses the old algorithm that scales worse when batching.\n    Parameters:\n        subdiag: Tensor of shape (n - 1, )\n        v: Tensor of shape (rank, n)\n        w: Tensor of shape (batch_size, rank, n)\n    Returns:\n        product: Tensor of shape (batch_size, n)\n    \"\"\"", "\n", "batch_size", ",", "rank", ",", "n", "=", "w", ".", "shape", "\n", "rank_", ",", "n_", "=", "v", ".", "shape", "\n", "assert", "n", "==", "n_", ",", "'w and v must have the same last dimension'", "\n", "assert", "rank", "==", "rank_", ",", "'w and v must have the same rank'", "\n", "m", "=", "int", "(", "np", ".", "log2", "(", "n", ")", ")", "\n", "assert", "n", "==", "1", "<<", "m", ",", "'n must be a power of 2'", "\n", "\n", "save_for_backward", "=", "krylov_multiply_forward_old_", "(", "subdiag", ",", "v", ")", "\n", "w", "=", "w", "[", ":", ",", ":", ",", "np", ".", "newaxis", ",", ":", "]", "\n", "dT_00", ",", "dT_01", "=", "w", ".", "flip", "(", "w", ".", "dim", "(", ")", "-", "1", ")", ",", "torch", ".", "zeros", "(", "(", "batch_size", ",", "1", ",", "n", ")", ",", "dtype", "=", "w", ".", "dtype", ",", "device", "=", "w", ".", "device", ")", "\n", "\n", "for", "d", "in", "range", "(", "m", ")", ":", "\n", "        ", "n1", ",", "n2", "=", "1", "<<", "d", ",", "1", "<<", "(", "m", "-", "d", "-", "1", ")", "\n", "dS_00", "=", "torch", ".", "empty", "(", "(", "batch_size", ",", "rank", ",", "2", "*", "n1", ",", "n2", ")", ",", "device", "=", "w", ".", "device", ")", "\n", "dS_00", "[", ":", ",", ":", ",", ":", ":", "2", "]", "=", "dT_00", "[", ":", ",", ":", ",", ":", ",", "n2", ":", "]", "\n", "dS_00", "[", ":", ",", ":", ",", "1", ":", ":", "2", "]", "=", "dT_00", "[", ":", ",", ":", ",", ":", ",", "n2", ":", "]", "\n", "dS_01", "=", "torch", ".", "empty", "(", "(", "batch_size", ",", "2", "*", "n1", ",", "n2", ")", ",", "device", "=", "w", ".", "device", ")", "\n", "dS_01", "[", ":", ",", ":", ":", "2", "]", "=", "dT_01", "[", ":", ",", ":", ",", "n2", ":", "]", "\n", "\n", "dT", "=", "torch", ".", "cat", "(", "(", "dT_00", ",", "dT_01", "[", ":", ",", "np", ".", "newaxis", "]", ")", ",", "dim", "=", "1", ")", "\n", "dT", "=", "dT", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", ",", "np", ".", "newaxis", "]", "\n", "\n", "dT_f", "=", "torch", ".", "rfft", "(", "dT", ",", "1", ")", "/", "(", "2", "*", "n2", ")", "\n", "# dT_00_f, dT_01_f = dT_f[:, :rank], dT_f[:, -1]", "\n", "\n", "# S0_10_f, S0_11_f = save_for_backward[d]", "\n", "# dS1_01_f = complex_mult(conjugate(S0_10_f)[np.newaxis], dT_00_f).sum(dim=1) + complex_mult(conjugate(S0_11_f), dT_01_f)", "\n", "\n", "dS1_01_f", "=", "complex_mult", "(", "conjugate", "(", "save_for_backward", "[", "d", "]", ")", ",", "dT_f", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n", "dS1_01", "=", "torch", ".", "irfft", "(", "dS1_01_f", ",", "1", ",", "signal_sizes", "=", "(", "2", "*", "n2", ",", ")", ")", "*", "(", "2", "*", "n2", ")", "\n", "dS_01", "[", ":", ",", "1", ":", ":", "2", "]", "=", "dS1_01", "[", ":", ",", ":", ",", ":", "n2", "]", "\n", "\n", "dT_00", ",", "dT_01", "=", "dS_00", ",", "dS_01", "\n", "\n", "", "du", "=", "(", "(", "dT_00", "*", "v", "[", "np", ".", "newaxis", ",", ":", ",", ":", ",", "np", ".", "newaxis", "]", ")", ".", "sum", "(", "dim", "=", "1", ")", "+", "dT_01", ")", ".", "squeeze", "(", "dim", "=", "-", "1", ")", "\n", "return", "du", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_mult_conv": [[601, 630], ["int", "krylov.krylov_transpose_multiply_conv", "krylov.krylov_multiply_conv", "numpy.ceil", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "numpy.log2", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_transpose_multiply_conv", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_multiply_conv"], ["", "def", "subdiag_mult_conv", "(", "subdiag_A", ",", "subdiag_B", ",", "G", ",", "H", ",", "x", ")", ":", "\n", "    ", "\"\"\"Multiply \\sum_i Krylov(A, G_i) @ Krylov(B, H_i) @ x when A and B are zero except on the subdiagonal.\n    Uses the fast algorithm.\n    Use either Pytorch's conv1d or FFT for polynomial multiplication, depending\n    on polynomial degree. This is the fastest implementation.\n    Parameters:\n        subdiag_A: Tensor of shape (n - 1, )\n        subdiag_B: Tensor of shape (n - 1, )\n        G: Tensor of shape (rank, n)\n        H: Tensor of shape (rank, n)\n        x: Tensor of shape (batch_size, n)\n    Returns:\n        product: Tensor of shape (batch_size, n)\n    \"\"\"", "\n", "rank", ",", "n", "=", "G", ".", "shape", "\n", "batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "# if not power of 2, round everything up", "\n", "# TODO: this can maybe be handled better. also should benchmark how much speed non-po2 FFT loses", "\n", "m", "=", "int", "(", "np", ".", "ceil", "(", "np", ".", "log2", "(", "n", ")", ")", ")", "\n", "n_extended", "=", "1", "<<", "m", "\n", "if", "n", "!=", "n_extended", ":", "\n", "        ", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "torch", ".", "zeros", "(", "batch_size", ",", "n_extended", "-", "n", ",", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "G", "=", "torch", ".", "cat", "(", "(", "G", ",", "torch", ".", "zeros", "(", "rank", ",", "n_extended", "-", "n", ",", "dtype", "=", "G", ".", "dtype", ",", "device", "=", "G", ".", "device", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "H", "=", "torch", ".", "cat", "(", "(", "H", ",", "torch", ".", "zeros", "(", "rank", ",", "n_extended", "-", "n", ",", "dtype", "=", "H", ".", "dtype", ",", "device", "=", "H", ".", "device", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "subdiag_A", "=", "torch", ".", "cat", "(", "(", "subdiag_A", ",", "torch", ".", "zeros", "(", "n_extended", "-", "n", ",", "dtype", "=", "subdiag_A", ".", "dtype", ",", "device", "=", "subdiag_A", ".", "device", ")", ")", ")", "\n", "subdiag_B", "=", "torch", ".", "cat", "(", "(", "subdiag_B", ",", "torch", ".", "zeros", "(", "n_extended", "-", "n", ",", "dtype", "=", "subdiag_B", ".", "dtype", ",", "device", "=", "subdiag_B", ".", "device", ")", ")", ")", "\n", "", "KT_out", "=", "krylov_transpose_multiply_conv", "(", "subdiag_B", ",", "H", ",", "x", ")", "\n", "K_out", "=", "krylov_multiply_conv", "(", "subdiag_A", ",", "G", ",", "KT_out", ")", "\n", "return", "K_out", "[", ":", ",", ":", "n", "]", "if", "n", "!=", "n_extended", "else", "K_out", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_mult": [[632, 659], ["int", "krylov.krylov_transpose_multiply", "krylov.krylov_multiply", "numpy.ceil", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "numpy.log2", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_transpose_multiply", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_multiply"], ["", "def", "subdiag_mult", "(", "subdiag_A", ",", "subdiag_B", ",", "G", ",", "H", ",", "x", ")", ":", "\n", "    ", "\"\"\"Multiply \\sum_i Krylov(A, G_i) @ Krylov(B, H_i) @ x when A and B are zero except on the subdiagonal.\n    Uses the fast algorithm.\n    Parameters:\n        subdiag_A: Tensor of shape (n - 1, )\n        subdiag_B: Tensor of shape (n - 1, )\n        G: Tensor of shape (rank, n)\n        H: Tensor of shape (rank, n)\n        x: Tensor of shape (batch_size, n)\n    Returns:\n        product: Tensor of shape (batch_size, n)\n    \"\"\"", "\n", "rank", ",", "n", "=", "G", ".", "shape", "\n", "batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "# if not power of 2, round everything up", "\n", "# TODO: this can maybe be handled better. also should benchmark how much speed non-po2 FFT loses", "\n", "m", "=", "int", "(", "np", ".", "ceil", "(", "np", ".", "log2", "(", "n", ")", ")", ")", "\n", "n_extended", "=", "1", "<<", "m", "\n", "if", "n", "!=", "n_extended", ":", "\n", "        ", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "torch", ".", "zeros", "(", "batch_size", ",", "n_extended", "-", "n", ",", "dtype", "=", "x", ".", "dtype", ",", "device", "=", "x", ".", "device", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "G", "=", "torch", ".", "cat", "(", "(", "G", ",", "torch", ".", "zeros", "(", "rank", ",", "n_extended", "-", "n", ",", "dtype", "=", "G", ".", "dtype", ",", "device", "=", "G", ".", "device", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "H", "=", "torch", ".", "cat", "(", "(", "H", ",", "torch", ".", "zeros", "(", "rank", ",", "n_extended", "-", "n", ",", "dtype", "=", "H", ".", "dtype", ",", "device", "=", "H", ".", "device", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "subdiag_A", "=", "torch", ".", "cat", "(", "(", "subdiag_A", ",", "torch", ".", "zeros", "(", "n_extended", "-", "n", ",", "dtype", "=", "subdiag_A", ".", "dtype", ",", "device", "=", "subdiag_A", ".", "device", ")", ")", ")", "\n", "subdiag_B", "=", "torch", ".", "cat", "(", "(", "subdiag_B", ",", "torch", ".", "zeros", "(", "n_extended", "-", "n", ",", "dtype", "=", "subdiag_B", ".", "dtype", ",", "device", "=", "subdiag_B", ".", "device", ")", ")", ")", "\n", "", "KT_out", "=", "krylov_transpose_multiply", "(", "subdiag_B", ",", "H", ",", "x", ")", "\n", "K_out", "=", "krylov_multiply", "(", "subdiag_A", ",", "G", ",", "KT_out", ")", "\n", "return", "K_out", "[", ":", ",", ":", "n", "]", "if", "n", "!=", "n_extended", "else", "K_out", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov": [[662, 678], ["range", "torch.stack", "linear_map.size", "linear_map", "cols.append"], "function", ["None"], ["", "def", "Krylov", "(", "linear_map", ",", "v", ",", "m", "=", "None", ")", ":", "\n", "    ", "\"\"\"Explicit construction of Krylov matrix [v  A @ v  A^2 @ v  ...  A^{m-1} @ v].\n    Parameters:\n        linear_map: a function v -> A @ v that takes a vector of size m and returns a vector of size m.\n        v: the starting vector of size m or (rank, m).\n        m: max power of A.\n    Returns:\n        K: Krylov matrix of size (m, m) or (rank, m, m).\n    \"\"\"", "\n", "if", "m", "is", "None", ":", "\n", "        ", "m", "=", "v", ".", "size", "(", "-", "1", ")", "\n", "", "cols", "=", "[", "v", "]", "\n", "for", "_", "in", "range", "(", "m", "-", "1", ")", ":", "\n", "        ", "v", "=", "linear_map", "(", "v", ")", "\n", "cols", ".", "append", "(", "v", ")", "\n", "", "return", "torch", ".", "stack", "(", "cols", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.shift_subdiag": [[680, 691], ["torch.cat"], "function", ["None"], ["", "def", "shift_subdiag", "(", "subdiag", ",", "v", ",", "upper_right_corner", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"The linear map for multiplying with a subdiagonal matrix (possibly with an upper right corner).\n    This implementation is slow and not batched wrt rank, but easy to understand.\n    Parameters:\n        subdiag: (n - 1, )\n        v: (n, )\n        upper_right_corner: real number\n    Returns:\n        prod: (n, )\n    \"\"\"", "\n", "return", "torch", ".", "cat", "(", "(", "upper_right_corner", "*", "v", "[", "[", "-", "1", "]", "]", ",", "subdiag", "*", "v", "[", ":", "-", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_linear_map": [[693, 712], ["torch.arange", "torch.cat", "subdiag.size", "torch.tensor"], "function", ["None"], ["", "def", "subdiag_linear_map", "(", "subdiag", ",", "upper_right_corner", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"Construct the linear map for multiplying with a subdiagonal matrix (possibly with an upper right corner).\n    This implementation is faster. The slowness of the Krylov construction is\n    from the kernel launch overhead in CUDA: we have n sequential steps, each\n    step having a few CUDA calls. To make it faster, we want to reduce the\n    number of CUDA operations. Here we reduce each step to 2 operations:\n    indexing, and pointwise multiplication.\n    Parameters:\n        subdiag: (n - 1, )\n        upper_right_corner: real number\n    Returns:\n        linear_map: v -> product, with v of shape either (n, ) or (rank, n)\n    \"\"\"", "\n", "n", "=", "subdiag", ".", "size", "(", "0", ")", "+", "1", "\n", "shift_down", "=", "torch", ".", "arange", "(", "-", "1", ",", "n", "-", "1", ",", "device", "=", "subdiag", ".", "device", ")", "\n", "subdiag_extended", "=", "torch", ".", "cat", "(", "(", "torch", ".", "tensor", "(", "[", "upper_right_corner", "]", ",", "dtype", "=", "subdiag", ".", "dtype", ",", "device", "=", "subdiag", ".", "device", ")", ",", "subdiag", ")", ")", "\n", "# Pytorch 1.0 has torch.roll that should be much faster", "\n", "# return lambda v: subdiag_extended * v.roll(1, dims=-1)", "\n", "return", "lambda", "v", ":", "subdiag_extended", "*", "v", "[", "...", ",", "shift_down", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_subdiag_fast": [[714, 740], ["torch.arange", "torch.cat", "subdiag_circulant.cumprod", "torch.tensor"], "function", ["None"], ["", "def", "krylov_subdiag_fast", "(", "subdiag", ",", "v", ",", "upper_right_corner", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"Explicit construction of Krylov matrix [v  A @ v  A^2 @ v  ...  A^{n-1} @ v]\n    where A is a subdiagonal matrix (possibly with an upper right corner).\n    This uses vectorized indexing and cumprod so it's much faster than using\n    the Krylov function. However, the backward pass is slow because of\n    inefficient implementation of cumprod_backward in Pytorch.\n    This should yields similar speed (forward + backward) to the fast\n    multiplication algorithm, but requires more memory.\n    Parameters:\n        subdiag: (n - 1, )\n        v: the starting vector of size n or (rank, n).\n        upper_right_corner: real number\n    Returns:\n        K: Krylov matrix of size (n, n) or (rank, n, n).\n    \"\"\"", "\n", "rank", ",", "n", "=", "v", ".", "shape", "\n", "a", "=", "torch", ".", "arange", "(", "n", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "v", ".", "device", ")", "\n", "b", "=", "-", "a", "\n", "indices", "=", "a", "[", ":", ",", "np", ".", "newaxis", "]", "+", "b", "[", "np", ".", "newaxis", "]", "\n", "v_circulant", "=", "v", "[", ":", ",", "indices", "]", "\n", "subdiag_extended", "=", "torch", ".", "cat", "(", "(", "torch", ".", "tensor", "(", "[", "upper_right_corner", "]", ",", "dtype", "=", "subdiag", ".", "dtype", ",", "device", "=", "subdiag", ".", "device", ")", ",", "subdiag", ")", ")", "\n", "subdiag_circulant", "=", "subdiag_extended", "[", "indices", "]", "\n", "subdiag_cumprod", "=", "subdiag_circulant", ".", "cumprod", "(", "dim", "=", "1", ")", "\n", "K", "=", "v_circulant", "\n", "K", "[", ":", ",", ":", ",", "1", ":", "]", "*=", "subdiag_cumprod", "[", ":", ",", ":", "-", "1", "]", "\n", "return", "K", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_mult_slow_old": [[742, 761], ["functools.partial", "functools.partial", "sum().t", "krylov.Krylov", "Krylov().t", "range", "sum", "x.t", "krylov.Krylov"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov"], ["", "def", "subdiag_mult_slow_old", "(", "subdiag_A", ",", "subdiag_B", ",", "G", ",", "H", ",", "x", ")", ":", "\n", "    ", "\"\"\"Multiply \\sum_i Krylov(A, G_i) @ Krylov(B, H_i) @ x when A and B are zero except on the subdiagonal.\n    Uses the explicit Krylov construction with slow (and easy to understand)\n    linear map.\n    Parameters:\n        subdiag_A: Tensor of shape (n - 1, )\n        subdiag_B: Tensor of shape (n - 1, )\n        G: Tensor of shape (rank, n)\n        H: Tensor of shape (rank, n)\n        x: Tensor of shape (batch_size, n)\n    Returns:\n        product: Tensor of shape (batch_size, n)\n    \"\"\"", "\n", "rank", ",", "n", "=", "G", ".", "shape", "\n", "linear_map_A", "=", "functools", ".", "partial", "(", "shift_subdiag", ",", "subdiag_A", ")", "\n", "linear_map_B", "=", "functools", ".", "partial", "(", "shift_subdiag", ",", "subdiag_B", ")", "\n", "krylovs", "=", "[", "(", "Krylov", "(", "linear_map_A", ",", "G", "[", "i", "]", ")", ",", "Krylov", "(", "linear_map_B", ",", "H", "[", "i", "]", ")", ".", "t", "(", ")", ")", "for", "i", "in", "range", "(", "rank", ")", "]", "\n", "prods", "=", "[", "K", "[", "0", "]", "@", "(", "K", "[", "1", "]", "@", "x", ".", "t", "(", ")", ")", "for", "K", "in", "krylovs", "]", "\n", "return", "sum", "(", "prods", ")", ".", "t", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_mult_slow": [[763, 783], ["krylov.Krylov", "krylov.Krylov", "krylov.Krylov", "krylov.Krylov", "krylov.subdiag_linear_map", "krylov.subdiag_linear_map", "Krylov.t", "krylov.subdiag_linear_map", "krylov.subdiag_linear_map", "Krylov.transpose"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_linear_map", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_linear_map", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_linear_map", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_linear_map"], ["", "def", "subdiag_mult_slow", "(", "subdiag_A", ",", "subdiag_B", ",", "G", ",", "H", ",", "x", ",", "corner_A", "=", "0.0", ",", "corner_B", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"Multiply \\sum_i Krylov(A, G_i) @ Krylov(B, H_i) @ x when A and B are zero except on the subdiagonal.\n    Uses the explicit Krylov construction with the more careful implementation of linear map.\n    Parameters:\n        subdiag_A: Tensor of shape (n - 1, )\n        subdiag_B: Tensor of shape (n - 1, )\n        G: Tensor of shape (rank, n)\n        H: Tensor of shape (rank, n)\n        x: Tensor of shape (batch_size, n)\n    Returns:\n        product: Tensor of shape (batch_size, n)\n    \"\"\"", "\n", "if", "G", ".", "shape", "[", "0", "]", "==", "1", ":", "# specialized code for rank=1, giving 2x speedup.", "\n", "        ", "K_G", "=", "Krylov", "(", "subdiag_linear_map", "(", "subdiag_A", ",", "corner_A", ")", ",", "G", "[", "0", "]", ")", "\n", "K_H", "=", "Krylov", "(", "subdiag_linear_map", "(", "subdiag_B", ",", "corner_B", ")", ",", "H", "[", "0", "]", ")", "\n", "return", "(", "x", "@", "K_H", ")", "@", "K_G", ".", "t", "(", ")", "\n", "", "else", ":", "\n", "        ", "K_G", "=", "Krylov", "(", "subdiag_linear_map", "(", "subdiag_A", ",", "corner_A", ")", ",", "G", ")", "\n", "K_H", "=", "Krylov", "(", "subdiag_linear_map", "(", "subdiag_B", ",", "corner_B", ")", ",", "H", ")", "\n", "return", "(", "(", "x", "@", "K_H", ")", "@", "K_G", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_mult_slow_fast": [[785, 799], ["krylov.krylov_subdiag_fast", "krylov.krylov_subdiag_fast", "K_G.transpose"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_subdiag_fast", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_subdiag_fast"], ["", "", "def", "subdiag_mult_slow_fast", "(", "subdiag_A", ",", "subdiag_B", ",", "G", ",", "H", ",", "x", ")", ":", "\n", "    ", "\"\"\"Multiply \\sum_i Krylov(A, G_i) @ Krylov(B, H_i) @ x when A and B are zero except on the subdiagonal.\n    Uses the fast construction of Krylov matrix.\n    Parameters:\n        subdiag_A: Tensor of shape (n - 1, )\n        subdiag_B: Tensor of shape (n - 1, )\n        G: Tensor of shape (rank, n)\n        H: Tensor of shape (rank, n)\n        x: Tensor of shape (batch_size, n)\n    Returns:\n        product: Tensor of shape (batch_size, n)\n    \"\"\"", "\n", "K_G", ",", "K_H", "=", "krylov_subdiag_fast", "(", "subdiag_A", ",", "G", ")", ",", "krylov_subdiag_fast", "(", "subdiag_B", ",", "H", ")", "\n", "return", "(", "(", "x", "@", "K_H", ")", "@", "K_G", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.test_cycle_down_mult": [[816, 830], ["torch.rand", "torch.rand", "cycle_down_mult", "torch.cat", "print", "torch.rand_like", "torch.autograd.grad", "torch.autograd.grad", "print", "print", "cycle_down_mult.sum"], "function", ["None"], ["def", "test_cycle_down_mult", "(", ")", ":", "\n", "    ", "n", "=", "1", "<<", "10", "\n", "rank", "=", "16", "\n", "subdiag", "=", "torch", ".", "rand", "(", "n", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "\n", "v", "=", "torch", ".", "rand", "(", "(", "rank", ",", "n", ")", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "\n", "z", "=", "cycle_down_mult", "(", "subdiag", ",", "v", ")", "\n", "y", "=", "torch", ".", "cat", "(", "(", "subdiag", "[", "0", "]", "*", "v", "[", "...", ",", "-", "1", ":", "]", ",", "subdiag", "[", "1", ":", "]", "*", "v", "[", "...", ",", ":", "-", "1", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "print", "(", "(", "z", "-", "y", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "grad_output", "=", "torch", ".", "rand_like", "(", "y", ")", "\n", "gs", ",", "gv", "=", "torch", ".", "autograd", ".", "grad", "(", "y", ",", "(", "subdiag", ",", "v", ")", ",", "grad_output", ",", "retain_graph", "=", "True", ")", "\n", "zs", ",", "zv", "=", "torch", ".", "autograd", ".", "grad", "(", "z", ".", "sum", "(", ")", ",", "(", "subdiag", ",", "v", ")", ",", "grad_output", ",", "retain_graph", "=", "True", ")", "\n", "print", "(", "(", "zs", "-", "gs", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "zv", "-", "gv", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_linear_map_cuda": [[832, 843], ["torch.cat", "cycle_down_mult", "torch.tensor"], "function", ["None"], ["", "def", "subdiag_linear_map_cuda", "(", "subdiag", ",", "upper_right_corner", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"Construct the linear map for multiplying with a subdiagonal matrix (possibly with an upper right corner).\n    Uses the construction in CUDA, so it's pretty fast.\n    Parameters:\n        subdiag: (n - 1, )\n        upper_right_corner: real number\n    Returns:\n        linear_map: v -> product, with v of shape either (n, ) or (rank, n)\n    \"\"\"", "\n", "subdiag_extended", "=", "torch", ".", "cat", "(", "(", "torch", ".", "tensor", "(", "[", "upper_right_corner", "]", ",", "dtype", "=", "subdiag", ".", "dtype", ",", "device", "=", "subdiag", ".", "device", ")", ",", "subdiag", ")", ")", "\n", "return", "lambda", "v", ":", "cycle_down_mult", "(", "subdiag_extended", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_mult_cuda": [[845, 860], ["krylov.Krylov", "krylov.Krylov", "krylov.subdiag_linear_map_cuda", "krylov.subdiag_linear_map_cuda", "Krylov.transpose"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_linear_map_cuda", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_linear_map_cuda"], ["", "def", "subdiag_mult_cuda", "(", "subdiag_A", ",", "subdiag_B", ",", "G", ",", "H", ",", "x", ",", "corner_A", "=", "0.0", ",", "corner_B", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"Multiply \\sum_i Krylov(A, G_i) @ Krylov(B, H_i) @ x when A and B are zero except on the subdiagonal.\n    Uses the explicit Krylov construction in CUDA.\n    Parameters:\n        subdiag_A: Tensor of shape (n - 1, )\n        subdiag_B: Tensor of shape (n - 1, )\n        G: Tensor of shape (rank, n)\n        H: Tensor of shape (rank, n)\n        x: Tensor of shape (batch_size, n)\n    Returns:\n        product: Tensor of shape (batch_size, n)\n    \"\"\"", "\n", "K_G", "=", "Krylov", "(", "subdiag_linear_map_cuda", "(", "subdiag_A", ",", "corner_A", ")", ",", "G", ")", "\n", "K_H", "=", "Krylov", "(", "subdiag_linear_map_cuda", "(", "subdiag_B", ",", "corner_B", ")", ",", "H", ")", "\n", "return", "(", "(", "x", "@", "K_H", ")", "@", "K_G", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.tridiag_linear_map": [[863, 887], ["diag.size", "torch.arange", "torch.stack", "torch.cat", "torch.cat", "torch.stack", "torch.tensor", "torch.tensor"], "function", ["None"], ["", "def", "tridiag_linear_map", "(", "subdiag", ",", "diag", ",", "superdiag", ",", "upper_right_corner", "=", "0.0", ",", "lower_left_corner", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"Construct the linear map for multiplying with a tridiagonal matrix\n    (possibly with upper right and lower left corners).\n    Similar to subdiag_linear_map, we want to reduce the number of CUDA\n    operations. Here we reduce each step to 3 operations: indexing,\n    pointwise multiplication, and summing.\n    Parameters:\n        subdiag: (n - 1, )\n        diag: (n, )\n        superdiag: (n - 1, )\n        upper_right_corner: real number\n        lower_left_corner: real number\n    Returns:\n        linear_map: v -> product, with v of shape either (n, ) or (rank, n)\n    \"\"\"", "\n", "n", "=", "diag", ".", "size", "(", "0", ")", "\n", "shift_none", "=", "torch", ".", "arange", "(", "n", ",", "device", "=", "diag", ".", "device", ")", "\n", "shift_down", "=", "shift_none", "-", "1", "\n", "shift_up", "=", "(", "shift_none", "+", "1", ")", "%", "n", "\n", "shifts", "=", "torch", ".", "stack", "(", "(", "shift_down", ",", "shift_none", ",", "shift_up", ")", ")", "\n", "subdiag_extended", "=", "torch", ".", "cat", "(", "(", "torch", ".", "tensor", "(", "[", "upper_right_corner", "]", ",", "dtype", "=", "subdiag", ".", "dtype", ",", "device", "=", "subdiag", ".", "device", ")", ",", "subdiag", ")", ")", "\n", "superdiag_extended", "=", "torch", ".", "cat", "(", "(", "superdiag", ",", "torch", ".", "tensor", "(", "[", "lower_left_corner", "]", ",", "dtype", "=", "superdiag", ".", "dtype", ",", "device", "=", "superdiag", ".", "device", ")", ")", ")", "\n", "diags", "=", "torch", ".", "stack", "(", "(", "subdiag_extended", ",", "diag", ",", "superdiag_extended", ")", ")", "\n", "return", "lambda", "v", ":", "(", "diags", "*", "v", "[", "...", ",", "shifts", "]", ")", ".", "sum", "(", "dim", "=", "-", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.tridiag_linear_map_slow": [[889, 903], ["torch.cat", "torch.cat"], "function", ["None"], ["", "def", "tridiag_linear_map_slow", "(", "subdiag", ",", "diag", ",", "superdiag", ",", "upper_right_corner", "=", "0.0", ",", "lower_left_corner", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"The linear map for multiplying with a tridiagonal matrix (possibly with\n    upper right and lower left corner).\n    This implementation is slow, but easy to understand.\n    Parameters:\n        subdiag: (n - 1, )\n        diag: (n, )\n        superdiag: (n - 1, )\n        upper_right_corner: real number\n        lower_left_corner: real number\n    Returns:\n        linear_map: v -> product, with v of shape either (n, ) or (rank, n)\n    \"\"\"", "\n", "return", "lambda", "v", ":", "torch", ".", "cat", "(", "(", "upper_right_corner", "*", "v", "[", "...", ",", "-", "1", ":", "]", ",", "subdiag", "*", "v", "[", "...", ",", ":", "-", "1", "]", ")", ",", "dim", "=", "-", "1", ")", "+", "diag", "*", "v", "+", "torch", ".", "cat", "(", "(", "superdiag", "*", "v", "[", "...", ",", "1", ":", "]", ",", "lower_left_corner", "*", "v", "[", "...", ",", ":", "1", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.tridiag_mult_slow": [[905, 931], ["krylov.Krylov", "krylov.Krylov", "krylov.Krylov", "krylov.Krylov", "krylov.tridiag_linear_map", "krylov.tridiag_linear_map", "Krylov.t", "krylov.tridiag_linear_map", "krylov.tridiag_linear_map", "Krylov.transpose"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.tridiag_linear_map", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.tridiag_linear_map", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.tridiag_linear_map", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.tridiag_linear_map"], ["", "def", "tridiag_mult_slow", "(", "subdiag_A", ",", "diag_A", ",", "superdiag_A", ",", "subdiag_B", ",", "diag_B", ",", "superdiag_B", ",", "G", ",", "H", ",", "x", ",", "corners_A", "=", "(", "0.0", ",", "0.0", ")", ",", "corners_B", "=", "(", "0.0", ",", "0.0", ")", ")", ":", "\n", "    ", "\"\"\"Multiply \\sum_i Krylov(A, G_i) @ Krylov(B, H_i) @ x when A and B are zero except on the subdiagonal.\n    Uses the explicit Krylov construction with the more careful implementation of linear map.\n    Parameters:\n        subdiag_A: Tensor of shape (n - 1, )\n        diag_A: Tensor of shape (n, )\n        superdiag_A: Tensor of shape (n - 1, )\n        subdiag_B: Tensor of shape (n - 1, )\n        diag_B: Tensor of shape (n, )\n        superdiag_B: Tensor of shape (n - 1, )\n        G: Tensor of shape (rank, n)\n        H: Tensor of shape (rank, n)\n        x: Tensor of shape (batch_size, n)\n        corners_A: two real numbers, the upper right and lower left corners of A.\n        corners_B: two real numbers, the upper right and lower left corners of A.\n    Returns:\n        product: Tensor of shape (batch_size, n)\n    \"\"\"", "\n", "if", "G", ".", "shape", "[", "0", "]", "==", "1", ":", "# specialized code for rank=1, giving 2x speedup.", "\n", "        ", "K_G", "=", "Krylov", "(", "tridiag_linear_map", "(", "subdiag_A", ",", "diag_A", ",", "superdiag_A", ",", "*", "corners_A", ")", ",", "G", "[", "0", "]", ")", "\n", "K_H", "=", "Krylov", "(", "tridiag_linear_map", "(", "subdiag_B", ",", "diag_B", ",", "superdiag_B", ",", "*", "corners_B", ")", ",", "H", "[", "0", "]", ")", "\n", "return", "(", "x", "@", "K_H", ")", "@", "K_G", ".", "t", "(", ")", "\n", "", "else", ":", "\n", "        ", "K_G", "=", "Krylov", "(", "tridiag_linear_map", "(", "subdiag_A", ",", "diag_A", ",", "superdiag_A", ",", "*", "corners_A", ")", ",", "G", ")", "\n", "K_H", "=", "Krylov", "(", "tridiag_linear_map", "(", "subdiag_B", ",", "diag_B", ",", "superdiag_B", ",", "*", "corners_B", ")", ",", "H", ")", "\n", "return", "(", "(", "x", "@", "K_H", ")", "@", "K_G", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.test_krylov_transpose_multiply": [[933, 979], ["torch.rand", "numpy.diag", "torch.rand", "torch.rand", "krylov.krylov_transpose_multiply", "torch.autograd.grad", "torch.rand.data.cpu().numpy", "numpy.stack", "torch.tensor.swapaxes().squeeze", "torch.tensor", "torch.stack", "result_gpu_dense.transpose().squeeze.transpose().squeeze", "krylov.Krylov", "torch.autograd.grad", "krylov.krylov_subdiag_fast", "torch.autograd.grad", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "torch.rand.data.cpu().numpy", "krylov_transpose_multiply.sum", "scratch.krylovslow.krylov_construct", "torch.tensor", "krylov.subdiag_linear_map", "result_gpu.sum", "result_gpu_fast.sum", "range", "torch.rand.data.cpu", "torch.tensor.swapaxes", "result_gpu_dense.transpose().squeeze.transpose", "torch.rand.data.cpu", "torch.rand.data.cpu().numpy", "K.t", "torch.rand.data.cpu"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_transpose_multiply", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_subdiag_fast", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.krylov_construct", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_linear_map"], ["", "", "def", "test_krylov_transpose_multiply", "(", ")", ":", "\n", "    ", "m", "=", "10", "\n", "n", "=", "1", "<<", "m", "\n", "batch_size", "=", "50", "\n", "rank", "=", "16", "\n", "subdiag", "=", "torch", ".", "rand", "(", "n", "-", "1", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "\n", "A", "=", "np", ".", "diag", "(", "subdiag", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "-", "1", ")", "\n", "u", "=", "torch", ".", "rand", "(", "(", "batch_size", ",", "n", ")", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "\n", "v", "=", "torch", ".", "rand", "(", "(", "rank", ",", "n", ")", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "\n", "# Fast algorithm on GPU", "\n", "# KTu_traced = torch.jit.trace(KTu_traceable, (subdiag, v, u))", "\n", "result", "=", "krylov_transpose_multiply", "(", "subdiag", ",", "v", ",", "u", ")", "\n", "# result = krylov_transpose_multiply_conv(subdiag, v, u)", "\n", "# result = krylov_transpose_multiply_old(subdiag, v, u)", "\n", "grad", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "result", ".", "sum", "(", ")", ",", "subdiag", ",", "retain_graph", "=", "True", ")", "\n", "# CPU dense multiply", "\n", "Ks", "=", "[", "krylov_construct", "(", "A", ",", "v", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "i", "]", ",", "n", ")", "for", "i", "in", "range", "(", "rank", ")", "]", "\n", "u_cpu", "=", "u", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "result_cpu", "=", "np", ".", "stack", "(", "[", "u_cpu", "@", "K", ".", "T", "for", "K", "in", "Ks", "]", ")", "\n", "result_cpu", "=", "result_cpu", ".", "swapaxes", "(", "0", ",", "1", ")", ".", "squeeze", "(", ")", "\n", "result_cpu", "=", "torch", ".", "tensor", "(", "result_cpu", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "# GPU dense multiply", "\n", "Ks_gpu_dense", "=", "[", "torch", ".", "tensor", "(", "K", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "for", "K", "in", "Ks", "]", "\n", "result_gpu_dense", "=", "torch", ".", "stack", "(", "[", "u", "@", "K", ".", "t", "(", ")", "for", "K", "in", "Ks_gpu_dense", "]", ")", "\n", "result_gpu_dense", "=", "result_gpu_dense", ".", "transpose", "(", "0", ",", "1", ")", ".", "squeeze", "(", ")", "\n", "# Explicit construction on GPU", "\n", "Ks_gpu", "=", "Krylov", "(", "subdiag_linear_map", "(", "subdiag", ")", ",", "v", ")", "\n", "result_gpu", "=", "(", "u", "@", "Ks_gpu", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "grad_gpu", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "result_gpu", ".", "sum", "(", ")", ",", "subdiag", ",", "retain_graph", "=", "True", ")", "\n", "# Explicit construction on GPU, but faster", "\n", "Ks_gpu_fast", "=", "krylov_subdiag_fast", "(", "subdiag", ",", "v", ")", "\n", "result_gpu_fast", "=", "(", "u", "@", "Ks_gpu_fast", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "grad_gpu_fast", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "result_gpu_fast", ".", "sum", "(", ")", ",", "subdiag", ",", "retain_graph", "=", "True", ")", "\n", "# These max and mean differences should be small", "\n", "print", "(", "(", "result", "-", "result_cpu", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_cpu", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_gpu_dense", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_gpu_dense", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_gpu", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_gpu", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_gpu", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_gpu", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_gpu_fast", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_gpu_fast", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_gpu_fast", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_gpu_fast", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.test_krylov_multiply": [[984, 1030], ["torch.rand", "numpy.diag", "torch.rand", "torch.rand", "torch.rand", "krylov.krylov_multiply", "torch.autograd.grad", "krylov.krylov_multiply_by_autodiff", "torch.autograd.grad", "torch.rand.data.cpu().numpy", "numpy.stack().sum().squeeze", "torch.tensor", "krylov.Krylov", "torch.autograd.grad", "krylov.krylov_subdiag_fast", "torch.autograd.grad", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "torch.rand.data.cpu().numpy", "krylov_multiply.sum", "krylov_multiply_by_autodiff.sum", "scratch.krylovslow.krylov_construct", "krylov.subdiag_linear_map", "result_gpu.sum", "result_gpu_fast.sum", "range", "torch.rand.data.cpu", "numpy.stack().sum", "torch.rand.data.cpu", "torch.rand.data.cpu().numpy", "torch.rand.transpose", "Krylov.transpose", "torch.rand.transpose", "krylov_subdiag_fast.transpose", "numpy.stack", "torch.rand.data.cpu", "range"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_multiply", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_multiply_by_autodiff", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_subdiag_fast", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.krylov_construct", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_linear_map"], ["", "def", "test_krylov_multiply", "(", ")", ":", "\n", "    ", "m", "=", "10", "\n", "n", "=", "1", "<<", "m", "\n", "batch_size", "=", "50", "\n", "rank", "=", "16", "\n", "subdiag", "=", "torch", ".", "rand", "(", "n", "-", "1", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "\n", "A", "=", "np", ".", "diag", "(", "subdiag", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "-", "1", ")", "\n", "u", "=", "torch", ".", "rand", "(", "(", "batch_size", ",", "n", ")", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "\n", "v", "=", "torch", ".", "rand", "(", "(", "rank", ",", "n", ")", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "\n", "w", "=", "torch", ".", "rand", "(", "(", "batch_size", ",", "rank", ",", "n", ")", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "\n", "# Fast algorithm on GPU", "\n", "# result = krylov_multiply_conv(subdiag, v, w)", "\n", "result", "=", "krylov_multiply", "(", "subdiag", ",", "v", ",", "w", ")", "\n", "# result = krylov_multiply_old(subdiag, v, w)", "\n", "grad", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "result", ".", "sum", "(", ")", ",", "subdiag", ",", "retain_graph", "=", "True", ")", "\n", "# Using autodiff", "\n", "result_autodiff", "=", "krylov_multiply_by_autodiff", "(", "subdiag", ",", "v", ",", "w", ")", "\n", "grad_autodiff", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "result_autodiff", ".", "sum", "(", ")", ",", "subdiag", ",", "retain_graph", "=", "True", ")", "\n", "# CPU dense multiply", "\n", "Ks", "=", "[", "krylov_construct", "(", "A", ",", "v", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "i", "]", ",", "n", ")", "for", "i", "in", "range", "(", "rank", ")", "]", "\n", "w_cpu", "=", "w", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "result_cpu", "=", "np", ".", "stack", "(", "[", "w_cpu", "[", ":", ",", "i", "]", "@", "Ks", "[", "i", "]", "for", "i", "in", "range", "(", "rank", ")", "]", ")", ".", "sum", "(", "axis", "=", "0", ")", ".", "squeeze", "(", ")", "\n", "result_cpu", "=", "torch", ".", "tensor", "(", "result_cpu", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "# Explicit construction on GPU", "\n", "Ks_gpu", "=", "Krylov", "(", "subdiag_linear_map", "(", "subdiag", ")", ",", "v", ")", "\n", "result_gpu", "=", "(", "w", ".", "transpose", "(", "0", ",", "1", ")", "@", "Ks_gpu", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "grad_gpu", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "result_gpu", ".", "sum", "(", ")", ",", "subdiag", ",", "retain_graph", "=", "True", ")", "\n", "# Explicit construction on GPU, but faster", "\n", "Ks_gpu_fast", "=", "krylov_subdiag_fast", "(", "subdiag", ",", "v", ")", "\n", "result_gpu_fast", "=", "(", "w", ".", "transpose", "(", "0", ",", "1", ")", "@", "Ks_gpu_fast", ".", "transpose", "(", "1", ",", "2", ")", ")", ".", "sum", "(", "dim", "=", "0", ")", "\n", "grad_gpu_fast", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "result_gpu_fast", ".", "sum", "(", ")", ",", "subdiag", ",", "retain_graph", "=", "True", ")", "\n", "# These max and mean differences should be small", "\n", "print", "(", "(", "result", "-", "result_autodiff", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_autodiff", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_autodiff", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_autodiff", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_cpu", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_cpu", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_gpu", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_gpu", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_gpu", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_gpu", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_gpu_fast", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_gpu_fast", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_gpu_fast", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_gpu_fast", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.test_subdiag_mult": [[1032, 1075], ["torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "krylov.Krylov", "krylov.krylov_subdiag_fast", "print", "krylov.subdiag_mult_conv", "torch.autograd.grad", "krylov.subdiag_mult_slow_old", "torch.autograd.grad", "krylov.subdiag_mult_slow", "torch.autograd.grad", "krylov.subdiag_mult_slow_fast", "torch.autograd.grad", "krylov.subdiag_mult_cuda", "torch.autograd.grad", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "krylov.subdiag_linear_map", "subdiag_mult_conv.sum", "subdiag_mult_slow_old.sum", "subdiag_mult_slow.sum", "subdiag_mult_slow_fast.sum", "subdiag_mult_cuda.sum"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.krylov_subdiag_fast", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_mult_conv", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_mult_slow_old", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_mult_slow", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_mult_slow_fast", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_mult_cuda", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.subdiag_linear_map"], ["", "def", "test_subdiag_mult", "(", ")", ":", "\n", "    ", "m", "=", "10", "\n", "n", "=", "1", "<<", "m", "\n", "batch_size", "=", "50", "\n", "rank", "=", "16", "\n", "subdiag", "=", "torch", ".", "rand", "(", "n", "-", "1", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "\n", "diag", "=", "torch", ".", "rand", "(", "n", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "\n", "superdiag", "=", "torch", ".", "rand", "(", "n", "-", "1", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "\n", "u", "=", "torch", ".", "rand", "(", "(", "batch_size", ",", "n", ")", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "\n", "v", "=", "torch", ".", "rand", "(", "(", "rank", ",", "n", ")", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "\n", "\n", "K", "=", "Krylov", "(", "subdiag_linear_map", "(", "subdiag", ",", "1.0", ")", ",", "v", ")", "\n", "K_fast", "=", "krylov_subdiag_fast", "(", "subdiag", ",", "v", ",", "upper_right_corner", "=", "1.0", ")", "\n", "print", "(", "(", "K", "-", "K_fast", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "result", "=", "subdiag_mult_conv", "(", "subdiag", ",", "subdiag", ",", "v", ",", "v", ",", "u", ")", "\n", "# result = subdiag_mult(subdiag, subdiag, v, v, u)", "\n", "grad", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "result", ".", "sum", "(", ")", ",", "subdiag", ",", "retain_graph", "=", "True", ")", "\n", "result_slow_old", "=", "subdiag_mult_slow_old", "(", "subdiag", ",", "subdiag", ",", "v", ",", "v", ",", "u", ")", "\n", "grad_slow_old", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "result_slow_old", ".", "sum", "(", ")", ",", "subdiag", ",", "retain_graph", "=", "True", ")", "\n", "result_slow", "=", "subdiag_mult_slow", "(", "subdiag", ",", "subdiag", ",", "v", ",", "v", ",", "u", ")", "\n", "grad_slow", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "result_slow", ".", "sum", "(", ")", ",", "subdiag", ",", "retain_graph", "=", "True", ")", "\n", "result_slow_fast", "=", "subdiag_mult_slow_fast", "(", "subdiag", ",", "subdiag", ",", "v", ",", "v", ",", "u", ")", "\n", "grad_slow_fast", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "result_slow_fast", ".", "sum", "(", ")", ",", "subdiag", ",", "retain_graph", "=", "True", ")", "\n", "result_cuda", "=", "subdiag_mult_cuda", "(", "subdiag", ",", "subdiag", ",", "v", ",", "v", ",", "u", ")", "\n", "grad_cuda", ",", "=", "torch", ".", "autograd", ".", "grad", "(", "result_cuda", ".", "sum", "(", ")", ",", "subdiag", ",", "retain_graph", "=", "True", ")", "\n", "# These max and mean differences should be small", "\n", "print", "(", "(", "result", "-", "result_slow_old", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_slow_old", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_slow_old", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_slow_old", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_slow", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_slow", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_slow", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_slow", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_slow_fast", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_slow_fast", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_slow_fast", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_slow_fast", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_cuda", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "result", "-", "result_cuda", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_cuda", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "print", "(", "(", "grad", "-", "grad_cuda", ")", ".", "abs", "(", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.test_tridiag_mult": [[1077, 1091], ["torch.rand", "torch.rand", "krylov.Krylov", "krylov.Krylov", "print", "krylov.tridiag_mult_slow", "torch.rand", "torch.rand", "torch.rand", "krylov.tridiag_linear_map", "krylov.tridiag_linear_map_slow"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.Krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.tridiag_mult_slow", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.tridiag_linear_map", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.krylov.tridiag_linear_map_slow"], ["", "def", "test_tridiag_mult", "(", ")", ":", "\n", "    ", "m", "=", "10", "\n", "n", "=", "1", "<<", "m", "\n", "batch_size", "=", "50", "\n", "rank", "=", "16", "\n", "subdiag", "=", "torch", ".", "rand", "(", "n", "-", "1", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "/", "2", "\n", "diag", "=", "torch", ".", "rand", "(", "n", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "/", "2", "\n", "superdiag", "=", "torch", ".", "rand", "(", "n", "-", "1", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "/", "2", "\n", "u", "=", "torch", ".", "rand", "(", "(", "batch_size", ",", "n", ")", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "\n", "v", "=", "torch", ".", "rand", "(", "(", "rank", ",", "n", ")", ",", "requires_grad", "=", "True", ",", "device", "=", "device", ")", "\n", "K", "=", "Krylov", "(", "tridiag_linear_map", "(", "subdiag", ",", "diag", ",", "superdiag", ",", "0.5", ",", "0.5", ")", ",", "v", ")", "\n", "K_old", "=", "Krylov", "(", "tridiag_linear_map_slow", "(", "subdiag", ",", "diag", ",", "superdiag", ",", "0.5", ",", "0.5", ")", ",", "v", ")", "\n", "print", "(", "(", "K", "-", "K_old", ")", ".", "abs", "(", ")", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "trid_slow", "=", "tridiag_mult_slow", "(", "subdiag", ",", "diag", ",", "superdiag", ",", "subdiag", ",", "diag", ",", "superdiag", ",", "v", ",", "v", ",", "u", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.poly_add": [[9, 20], ["None"], "function", ["None"], ["def", "poly_add", "(", "p1", ",", "p2", ",", "n", ")", ":", "\n", "    ", "\"\"\"p1,p2 of degree exactly n-1\"\"\"", "\n", "# TODO: change these to equals", "\n", "assert", "p1", ".", "shape", "==", "(", "n", ",", ")", "\n", "assert", "p2", ".", "shape", "==", "(", "n", ",", ")", "\n", "# n = np.maximum(p1.shape[0], p2.shape[0])", "\n", "# q1 = np.pad(p1, (0,n-p1.shape[0]), 'constant')", "\n", "# q2 = np.pad(p2, (0,n-p2.shape[0]), 'constant')", "\n", "# print(q1)", "\n", "# print(q2)", "\n", "return", "p1", "+", "p2", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.poly_mult_slow": [[21, 30], ["numpy.zeros", "range", "range"], "function", ["None"], ["", "def", "poly_mult_slow", "(", "p1", ",", "p2", ")", ":", "\n", "    ", "d1", "=", "p1", ".", "shape", "[", "0", "]", "-", "1", "\n", "d2", "=", "p2", ".", "shape", "[", "0", "]", "-", "1", "\n", "n", "=", "d1", "+", "d2", "\n", "prod", "=", "np", ".", "zeros", "(", "n", "+", "1", ")", "\n", "for", "i", "in", "range", "(", "d1", "+", "1", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "d2", "+", "1", ")", ":", "\n", "            ", "prod", "[", "i", "+", "j", "]", "+=", "p1", "[", "i", "]", "*", "p2", "[", "j", "]", "\n", "", "", "return", "prod", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.poly_mult_fft": [[31, 55], ["scipy.rfft", "scipy.rfft", "scipy.irfft"], "function", ["None"], ["", "def", "poly_mult_fft", "(", "p1", ",", "p2", ")", ":", "\n", "    ", "d1", "=", "p1", ".", "shape", "[", "0", "]", "-", "1", "\n", "d2", "=", "p2", ".", "shape", "[", "0", "]", "-", "1", "\n", "# if d1 < 0:", "\n", "#     p1 = np.array([0])", "\n", "#     d1 = 0", "\n", "# if d2 < 0:", "\n", "#     p2 = np.array([0])", "\n", "#     d2 = 0", "\n", "# n = d1 + d2", "\n", "\n", "# numpy fft", "\n", "# f1 = np.fft.rfft(p1, n+1)", "\n", "# f2 = np.fft.rfft(p2, n+1)", "\n", "# prod = np.fft.irfft(f1*f2, n+1)", "\n", "\n", "# scipy fft (currently has bug because it stores output of rfft differently)", "\n", "f1", "=", "fft", ".", "rfft", "(", "p1", ",", "n", "+", "1", ")", "\n", "f2", "=", "fft", ".", "rfft", "(", "p2", ",", "n", "+", "1", ")", "\n", "prod", "=", "fft", ".", "irfft", "(", "f1", "*", "f2", ",", "n", "+", "1", ")", "\n", "\n", "# prod = signal.convolve(p1, p2, method='fft')", "\n", "\n", "return", "prod", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.poly_mult": [[57, 77], ["scipy.signal.fftconvolve", "numpy.convolve"], "function", ["None"], ["", "def", "poly_mult", "(", "p1", ",", "p2", ")", ":", "\n", "# return poly_mult_slow(p1, p2)", "\n", "    ", "d1", "=", "p1", ".", "shape", "[", "0", "]", "-", "1", "\n", "d2", "=", "p2", ".", "shape", "[", "0", "]", "-", "1", "\n", "n", "=", "d1", "+", "d2", "\n", "# q1 = np.pad(p1, (0,d2), 'constant')", "\n", "# q2 = np.pad(p2, (0,d1), 'constant')", "\n", "# assert q1.shape[0] == n+1", "\n", "# assert q2.shape[0] == n+1", "\n", "if", "n", ">=", "128", ":", "\n", "        ", "prod", "=", "signal", ".", "fftconvolve", "(", "p1", ",", "p2", ",", "mode", "=", "'full'", ")", "\n", "", "else", ":", "\n", "        ", "prod", "=", "np", ".", "convolve", "(", "p1", ",", "p2", ")", "\n", "# prod = np.convolve(p1, p2)", "\n", "# if prod.shape[0] != n+1:", "\n", "#     print(d1, d2, p1.shape, p2.shape, prod.shape)", "\n", "#     assert false", "\n", "# assert prod.shape[0] == n+1", "\n", "\n", "", "return", "prod", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.poly_inv": [[78, 106], ["krylovslow.poly_inv", "krylovslow.poly_mult", "krylovslow.poly_mult", "numpy.array", "numpy.concatenate", "min", "min"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.poly_inv", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.poly_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.poly_mult"], ["", "def", "poly_inv", "(", "p", ",", "n", ")", ":", "\n", "    ", "\"\"\"\n    invert p mod x^n\n    \"\"\"", "\n", "assert", "n", ">=", "1", "\n", "if", "n", "==", "1", ":", "\n", "        ", "return", "np", ".", "array", "(", "[", "1", "/", "p", "[", "0", "]", "]", ")", "\n", "\n", "# represent p = p_low + x^k p_high, and its inverse q similarly", "\n", "", "d", "=", "p", ".", "shape", "[", "0", "]", "\n", "k", "=", "(", "n", "+", "1", ")", "//", "2", "\n", "\n", "# invert the lower order terms", "\n", "q_low", "=", "poly_inv", "(", "p", "[", ":", "min", "(", "d", ",", "k", ")", "]", ",", "k", ")", "\n", "# print(q_low)", "\n", "\n", "# since 2k >= n, p q_l + x^k p_l q_h = 1 (mod x^n)", "\n", "# so p_l q_h = (1 - p q_l)/x^k  (mod x^{n-k})", "\n", "r", "=", "poly_mult", "(", "p", ",", "q_low", ")", "\n", "r", "[", "0", "]", "-=", "1", "\n", "# assert np.all(r[:min(r.shape[0],k)] == 0)", "\n", "# but we know p_l^{-1} mod x^{n-k} since we already know it mod x^k", "\n", "q_high", "=", "poly_mult", "(", "-", "r", "[", "k", ":", "min", "(", "r", ".", "shape", "[", "0", "]", ",", "n", ")", "]", ",", "q_low", ")", "\n", "\n", "# q_low = np.pad(q_low, (0,k-q_low.shape[0]), 'constant')", "\n", "q", "=", "np", ".", "concatenate", "(", "(", "q_low", ",", "q_high", ")", ")", "[", ":", "n", "]", "\n", "# q = np.trim_zeros(q, 'b')", "\n", "return", "q", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.resolvent_bilinear": [[109, 156], ["krylovslow.resolvent_bilinear", "krylovslow.resolvent_bilinear", "numpy.array", "krylovslow.poly_mult", "krylovslow.poly_mult", "numpy.pad", "krylovslow.poly_mult", "krylovslow.poly_mult", "krylovslow.poly_mult", "numpy.array", "numpy.array", "krylovslow.poly_mult", "krylovslow.poly_mult", "krylovslow.poly_mult", "krylovslow.poly_mult"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.resolvent_bilinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.resolvent_bilinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.poly_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.poly_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.poly_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.poly_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.poly_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.poly_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.poly_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.poly_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.poly_mult"], ["", "def", "resolvent_bilinear", "(", "A", ",", "v", ",", "u", ",", "n", ")", ":", "\n", "    ", "\"\"\"\n    Compute [u e_n]^T * (I-Ax)^{-1} * [v e_1]\n    (2x2 matrix of rational fractions)\n    output: array of shape (2, 2, n), array shape (n)\n    (numerator, denominator)\n\n    invariants:\n        numerator has degree n-1\n        denominator degree n\n    \"\"\"", "\n", "if", "n", "==", "1", ":", "\n", "# don't know how write outer product in numpy", "\n", "        ", "return", "(", "np", ".", "array", "(", "[", "[", "[", "u", "[", "0", "]", "*", "v", "[", "0", "]", "]", ",", "[", "u", "[", "0", "]", "*", "1", "]", "]", ",", "[", "[", "1", "*", "v", "[", "0", "]", "]", ",", "[", "1", "*", "1", "]", "]", "]", ")", ",", "np", ".", "array", "(", "[", "1", ",", "-", "A", "[", "0", ",", "0", "]", "]", ")", ")", "\n", "\n", "", "k", "=", "n", "//", "2", "\n", "# Let M00 = M[0:k, 0:k], M10 = M[k:n, 0:k], M11 = M[k:n,k:n]", "\n", "# i.e. M = [M00 0 ; M10 M11] (where M = I-Ax)", "\n", "# then M^{-1} = [M00^{-1} 0 ; -M11^{-1} M_10^{-1} M_00^{-1}]", "\n", "S0", ",", "d0", "=", "resolvent_bilinear", "(", "A", "[", ":", "k", ",", ":", "k", "]", ",", "v", "[", ":", "k", "]", ",", "u", "[", ":", "k", "]", ",", "k", ")", "\n", "S1", ",", "d1", "=", "resolvent_bilinear", "(", "A", "[", "k", ":", ",", "k", ":", "]", ",", "v", "[", "k", ":", "]", ",", "u", "[", "k", ":", "]", ",", "n", "-", "k", ")", "\n", "\n", "# the part corresponding to bottom left corner is", "\n", "# -A[k, k-1]x * u_1^T M_11^{-1} e_1 * e_k^T M_00^{-1} v_0", "\n", "# or S1[:,1] * S0[1,:]", "\n", "L", "=", "np", ".", "array", "(", "[", "[", "poly_mult", "(", "S1", "[", "0", ",", "1", "]", ",", "S0", "[", "1", ",", "0", "]", ")", ",", "poly_mult", "(", "S1", "[", "0", ",", "1", "]", ",", "S0", "[", "1", ",", "1", "]", ")", "]", ",", "[", "poly_mult", "(", "S1", "[", "1", ",", "1", "]", ",", "S0", "[", "1", ",", "0", "]", ")", ",", "poly_mult", "(", "S1", "[", "1", ",", "1", "]", ",", "S0", "[", "1", ",", "1", "]", ")", "]", "]", ")", "\n", "# print(L)", "\n", "L", "=", "A", "[", "k", ",", "k", "-", "1", "]", "*", "np", ".", "pad", "(", "L", ",", "(", "(", "0", ",", "0", ")", ",", "(", "0", ",", "0", ")", ",", "(", "1", ",", "0", ")", ")", ",", "'constant'", ")", "# multiply by X", "\n", "# TODO: above padding should be able to be optimized away; when we allocate memory properly can store the coefficients directly in the right place", "\n", "# print(L)", "\n", "\n", "# clear denominators", "\n", "# S0 = np.array([[ poly_mult(s, d1) for s in r ] for r in S0])", "\n", "# S1 = np.array([[ poly_mult(s, d0) for s in r ] for r in S1])", "\n", "# print(S0)", "\n", "\n", "# really need to define poly matrix operations", "\n", "# S = np.array([[poly_add(S0[i,j],S1[i,j]) for j in range(2)] for i in range(2)])", "\n", "# S = np.array([[poly_add(S[i,j],L[i,j]) for j in range(2)] for i in range(2)])", "\n", "# L[0,0] = poly_add(L[0,0], poly_mult(S0[0,0], d1), n)", "\n", "# L[0,1] = poly_add(L[0,1], poly_mult(S0[0,1], d1), n)", "\n", "# L[0,0] = poly_add(L[0,0], poly_mult(S1[0,0], d0), n)", "\n", "# L[1,0] = poly_add(L[1,0], poly_mult(S1[1,0], d0), n)", "\n", "L", "[", "0", ",", "0", "]", "+=", "poly_mult", "(", "S0", "[", "0", ",", "0", "]", ",", "d1", ")", "+", "poly_mult", "(", "S1", "[", "0", ",", "0", "]", ",", "d0", ")", "\n", "L", "[", "0", ",", "1", "]", "+=", "poly_mult", "(", "S0", "[", "0", ",", "1", "]", ",", "d1", ")", "\n", "L", "[", "1", ",", "0", "]", "+=", "poly_mult", "(", "S1", "[", "1", ",", "0", "]", ",", "d0", ")", "\n", "return", "(", "L", ",", "poly_mult", "(", "d0", ",", "d1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.krylov_mult": [[157, 172], ["krylovslow.resolvent_bilinear", "krylovslow.poly_mult", "krylovslow.poly_inv"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.resolvent_bilinear", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.poly_mult", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.poly_inv"], ["", "def", "krylov_mult", "(", "A", ",", "v", ",", "u", ",", "m", ")", ":", "\n", "    ", "\"\"\"\n    Compute the matrix-vector product Kry(A, v)^T * u\n    A: R^{n \\times n}, lower triangular and 2-banded\n    u: R^n\n    v: R^n\n    m: output dimension (i.e. width of K)\n    \"\"\"", "\n", "\n", "n", "=", "v", ".", "shape", "[", "0", "]", "\n", "assert", "A", ".", "shape", "==", "(", "n", ",", "n", ")", "\n", "\n", "R", ",", "d", "=", "resolvent_bilinear", "(", "A", ",", "v", ",", "u", ",", "n", ")", "\n", "ans", "=", "poly_mult", "(", "R", "[", "0", ",", "0", "]", ",", "poly_inv", "(", "d", ",", "m", ")", ")", "\n", "return", "ans", "[", ":", "m", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.Amult": [[173, 177], ["None"], "function", ["None"], ["", "def", "Amult", "(", "d", ",", "subd", ",", "v", ")", ":", "\n", "    ", "ans", "=", "d", "*", "v", "\n", "ans", "[", "1", ":", "]", "+=", "subd", "*", "v", "[", ":", "-", "1", "]", "\n", "return", "ans", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.krylov_mult_slow": [[178, 188], ["numpy.diagonal", "numpy.diagonal", "range", "numpy.stack", "cols.append", "krylovslow.Amult"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.Amult"], ["", "def", "krylov_mult_slow", "(", "A", ",", "v", ",", "u", ",", "m", ")", ":", "\n", "    ", "n", "=", "v", ".", "shape", "[", "0", "]", "\n", "assert", "A", ".", "shape", "==", "(", "n", ",", "n", ")", "\n", "cols", "=", "[", "v", "]", "\n", "d", "=", "np", ".", "diagonal", "(", "A", ",", "0", ")", "\n", "subd", "=", "np", ".", "diagonal", "(", "A", ",", "-", "1", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "m", ")", ":", "\n", "        ", "cols", ".", "append", "(", "Amult", "(", "d", ",", "subd", ",", "cols", "[", "-", "1", "]", ")", ")", "\n", "", "K", "=", "np", ".", "stack", "(", "cols", ",", "axis", "=", "1", ")", "\n", "return", "K", ".", "T", "@", "u", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.krylov_mult_slow_allocated": [[189, 200], ["numpy.diagonal", "numpy.diagonal", "numpy.empty", "range", "krylovslow.Amult"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.Amult"], ["", "def", "krylov_mult_slow_allocated", "(", "A", ",", "v", ",", "u", ",", "m", ")", ":", "\n", "    ", "n", "=", "v", ".", "shape", "[", "0", "]", "\n", "assert", "A", ".", "shape", "==", "(", "n", ",", "n", ")", "\n", "d", "=", "np", ".", "diagonal", "(", "A", ",", "0", ")", "\n", "subd", "=", "np", ".", "diagonal", "(", "A", ",", "-", "1", ")", "\n", "# Allocate memory at once to K", "\n", "K_T", "=", "np", ".", "empty", "(", "(", "m", ",", "n", ")", ")", "\n", "K_T", "[", "0", "]", "=", "v", "\n", "for", "i", "in", "range", "(", "1", ",", "m", ")", ":", "\n", "        ", "K_T", "[", "i", "]", "=", "Amult", "(", "d", ",", "subd", ",", "K_T", "[", "i", "-", "1", "]", ")", "\n", "", "return", "K_T", "@", "u", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.krylov_construct": [[201, 212], ["numpy.diagonal", "numpy.diagonal", "numpy.zeros", "range"], "function", ["None"], ["", "def", "krylov_construct", "(", "A", ",", "v", ",", "m", ")", ":", "\n", "    ", "n", "=", "v", ".", "shape", "[", "0", "]", "\n", "assert", "A", ".", "shape", "==", "(", "n", ",", "n", ")", "\n", "d", "=", "np", ".", "diagonal", "(", "A", ",", "0", ")", "\n", "subd", "=", "np", ".", "diagonal", "(", "A", ",", "-", "1", ")", "\n", "\n", "K", "=", "np", ".", "zeros", "(", "shape", "=", "(", "m", ",", "n", ")", ")", "\n", "K", "[", "0", ",", ":", "]", "=", "v", "\n", "for", "i", "in", "range", "(", "1", ",", "m", ")", ":", "\n", "        ", "K", "[", "i", ",", "1", ":", "]", "=", "subd", "*", "K", "[", "i", "-", "1", ",", ":", "-", "1", "]", "\n", "", "return", "K", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.krylov_mult_slow_faster": [[213, 216], ["krylovslow.krylov_construct"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.krylov_construct"], ["", "def", "krylov_mult_slow_faster", "(", "A", ",", "v", ",", "u", ",", "m", ")", ":", "\n", "    ", "K", "=", "krylov_construct", "(", "A", ",", "v", ",", "m", ")", "\n", "return", "K", "@", "u", "\n", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.fft.init": [[12, 19], ["numpy.zeros", "numpy.array", "itertools.product", "list", "range", "range", "range", "numpy.sum", "numpy.array"], "function", ["None"], ["def", "init", "(", "f", ")", ":", "\n", "    ", "x", "=", "np", ".", "zeros", "(", "d", "*", "[", "p", "]", ",", "dtype", "=", "np", ".", "complex_", ")", "\n", "idx", "=", "[", "list", "(", "range", "(", "p", ")", ")", "for", "i", "in", "range", "(", "d", ")", "]", "\n", "powers", "=", "np", ".", "array", "(", "[", "p", "**", "i", "for", "i", "in", "range", "(", "d", ")", "]", ")", "\n", "for", "t", "in", "itertools", ".", "product", "(", "*", "idx", ")", ":", "\n", "        ", "x", "[", "t", "]", "=", "f", "[", "np", ".", "sum", "(", "powers", "*", "np", ".", "array", "(", "t", ")", ")", "]", "\n", "", "return", "x", "\n", "", "x", "=", "init", "(", "f", ")", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.fft.unshape": [[22, 29], ["numpy.zeros", "numpy.array", "itertools.product", "list", "range", "range", "range", "numpy.sum", "numpy.array"], "function", ["None"], ["def", "unshape", "(", "x", ")", ":", "\n", "    ", "f", "=", "np", ".", "zeros", "(", "p", "**", "d", ",", "dtype", "=", "np", ".", "complex_", ")", "\n", "idx", "=", "[", "list", "(", "range", "(", "p", ")", ")", "for", "i", "in", "range", "(", "d", ")", "]", "\n", "powers", "=", "np", ".", "array", "(", "[", "p", "**", "i", "for", "i", "in", "range", "(", "d", ")", "]", ")", "\n", "for", "t", "in", "itertools", ".", "product", "(", "*", "idx", ")", ":", "\n", "        ", "f", "[", "np", ".", "sum", "(", "powers", "*", "np", ".", "array", "(", "t", ")", ")", "]", "=", "x", "[", "t", "]", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.fft.pass_it_": [[43, 66], ["numpy.array", "itertools.product", "list", "print", "range", "range", "numpy.sum", "print", "numpy.exp", "numpy.complex", "range", "numpy.array"], "function", ["None"], ["", "def", "pass_it_", "(", "x", ",", "x_new", ",", "r", ",", "verbose", "=", "False", ")", ":", "\n", "# The index ranges", "\n", "# (x_0,...,x_{d-r-2},x_{d-r-1}, y_{0}, .., y_{r-1}, y_r)", "\n", "    ", "idx", "=", "[", "list", "(", "range", "(", "p", ")", ")", "for", "i", "in", "range", "(", "d", "+", "1", ")", "]", "\n", "omega", "=", "-", "2", "*", "np", ".", "complex", "(", "0", ",", "1", ")", "*", "np", ".", "pi", "/", "(", "p", "**", "d", ")", "\n", "powers", "=", "np", ".", "array", "(", "[", "p", "**", "i", "for", "i", "in", "range", "(", "r", "+", "1", ")", "]", ")", "\n", "# powers  = np.array([p**i for i in range(r,-1,-1)])", "\n", "for", "t", "in", "itertools", ".", "product", "(", "*", "idx", ")", ":", "\n", "# The last index are the ys", "\n", "        ", "x_base", "=", "t", "[", "0", ":", "d", "-", "r", "-", "1", "]", "\n", "x_last", "=", "t", "[", "d", "-", "r", "-", "1", "]", "# this is xm", "\n", "y_base", "=", "t", "[", "d", "-", "r", ":", "d", "]", "\n", "y_last", "=", "t", "[", "d", "]", "\n", "# marginalize out over xm, but keep the ys in the same order?", "\n", "new_t", "=", "x_base", "+", "y_base", "+", "(", "y_last", ",", ")", "\n", "old_t", "=", "x_base", "+", "(", "x_last", ",", ")", "+", "y_base", "\n", "y_sum", "=", "np", ".", "sum", "(", "np", ".", "array", "(", "t", "[", "d", "-", "r", ":", "d", "+", "1", "]", ")", "*", "powers", ")", "*", "p", "**", "(", "d", "-", "r", "-", "1", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "f\"x={x_base},{x_last} -> y={y_base},{y_last} :: new={new_t} += old={old_t} y_sum={y_sum} {y_sum*x_last}\"", ")", "\n", "", "q", "=", "omega", "*", "x_last", "*", "y_sum", "\n", "x_new", "[", "new_t", "]", "+=", "x", "[", "old_t", "]", "*", "np", ".", "exp", "(", "q", ")", "\n", "", "if", "verbose", ":", "print", "(", "\"**\"", ")", "\n", "return", "x_new", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.fft.pass_it": [[67, 70], ["numpy.zeros", "fft.pass_it_"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.fft.pass_it_"], ["", "def", "pass_it", "(", "x", ",", "r", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "x_new", "=", "np", ".", "zeros", "(", "d", "*", "[", "p", "]", ",", "dtype", "=", "np", ".", "complex_", ")", "\n", "return", "pass_it_", "(", "x", ",", "x_new", ",", "r", ",", "verbose", "=", "verbose", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.fft.fft_pass": [[71, 79], ["numpy.copy", "numpy.zeros", "range", "fft.pass_it_"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.fft.pass_it_"], ["", "def", "fft_pass", "(", "x", ")", ":", "\n", "    ", "_x", "=", "np", ".", "copy", "(", "x", ")", "\n", "x_new", "=", "np", ".", "zeros", "(", "d", "*", "[", "p", "]", ",", "dtype", "=", "np", ".", "complex_", ")", "\n", "for", "r", "in", "range", "(", "d", ")", ":", "\n", "        ", "pass_it_", "(", "_x", ",", "x_new", ",", "r", ")", "\n", "(", "_x", ",", "x_new", ")", "=", "(", "x_new", ",", "_x", ")", "\n", "x_new", "[", ":", "]", "=", "0", "\n", "", "return", "_x", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.fft.slow_fft": [[80, 92], ["numpy.zeros", "numpy.array", "itertools.product", "list", "numpy.sum", "itertools.product", "range", "range", "numpy.sum", "numpy.complex", "range", "numpy.array", "numpy.exp", "numpy.array"], "function", ["None"], ["", "def", "slow_fft", "(", "x", ")", ":", "\n", "    ", "y", "=", "np", ".", "zeros", "(", "x", ".", "shape", ",", "dtype", "=", "np", ".", "complex_", ")", "\n", "idx", "=", "[", "list", "(", "range", "(", "p", ")", ")", "for", "i", "in", "range", "(", "d", ")", "]", "\n", "omega", "=", "-", "2", "*", "np", ".", "complex", "(", "0", ",", "1", ")", "*", "np", ".", "pi", "/", "(", "p", "**", "d", ")", "\n", "powers", "=", "np", ".", "array", "(", "[", "p", "**", "i", "for", "i", "in", "range", "(", "d", ")", "]", ")", "\n", "# powers  = np.array([p**i for i in range(d-1,-1,-1)])", "\n", "for", "t", "in", "itertools", ".", "product", "(", "*", "idx", ")", ":", "\n", "        ", "y_t", "=", "np", ".", "sum", "(", "powers", "*", "np", ".", "array", "(", "t", ")", ")", "\n", "for", "u", "in", "itertools", ".", "product", "(", "*", "idx", ")", ":", "\n", "            ", "x_t", "=", "np", ".", "sum", "(", "powers", "*", "np", ".", "array", "(", "u", ")", ")", "\n", "y", "[", "t", "]", "+=", "x", "[", "u", "]", "*", "np", ".", "exp", "(", "omega", "*", "y_t", "*", "x_t", ")", "\n", "", "", "return", "y", "\n", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.KrylovTransposeMultiply.__init__": [[169, 177], ["int", "krylovfast.KrylovTransposeMultiply.plan_ffts_forward_pass", "numpy.log2"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.KrylovTransposeMultiply.plan_ffts_forward_pass"], ["def", "__init__", "(", "self", ",", "n", ",", "batch_size", "=", "1", ",", "rank", "=", "1", ")", ":", "\n", "        ", "m", "=", "int", "(", "np", ".", "log2", "(", "n", ")", ")", "\n", "assert", "n", "==", "1", "<<", "m", ",", "'n must be a power of 2'", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "m", "=", "m", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "plan_ffts_forward_pass", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.KrylovTransposeMultiply.plan_ffts_forward_pass": [[178, 190], ["enumerate", "numpy.empty", "numpy.empty", "numpy.empty", "zip", "S.reshape.reshape.reshape", "pyfftw.FFTW", "pyfftw.FFTW", "krylovfast.KrylovTransposeMultiply.ffts_forward_pass.append", "numpy.empty", "range", "range", "range"], "methods", ["None"], ["", "def", "plan_ffts_forward_pass", "(", "self", ")", ":", "\n", "        ", "n", ",", "m", ",", "batch_size", ",", "rank", "=", "self", ".", "n", ",", "self", ".", "m", ",", "self", ".", "batch_size", ",", "self", ".", "rank", "\n", "self", ".", "S_storage", "=", "[", "np", ".", "empty", "(", "(", "batch_size", "+", "rank", ",", "n", ")", ")", "]", "*", "m", "\n", "self", ".", "S_f_storage", "=", "[", "np", ".", "empty", "(", "(", "batch_size", "+", "rank", ",", "1", "<<", "d", ",", "(", "1", "<<", "(", "m", "-", "d", "-", "1", ")", ")", "+", "1", ")", ",", "dtype", "=", "'complex128'", ")", "for", "d", "in", "range", "(", "m", ")", "]", "\n", "self", ".", "T_f_storage", "=", "[", "np", ".", "empty", "(", "(", "batch_size", ",", "rank", ",", "(", "1", "<<", "(", "m", "-", "d", "-", "1", ")", ")", "+", "1", ")", ",", "dtype", "=", "'complex128'", ")", "for", "d", "in", "range", "(", "m", ")", "]", "\n", "self", ".", "T_storage", "=", "[", "np", ".", "empty", "(", "(", "batch_size", ",", "rank", ",", "1", "<<", "(", "m", "-", "d", ")", ")", ")", "for", "d", "in", "range", "(", "m", ")", "]", "\n", "self", ".", "ffts_forward_pass", "=", "[", "]", "\n", "for", "d", ",", "(", "S", ",", "S_f", ",", "T_f", ",", "T", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "S_storage", ",", "self", ".", "S_f_storage", ",", "self", ".", "T_f_storage", ",", "self", ".", "T_storage", ")", ")", ":", "\n", "            ", "S", "=", "S", ".", "reshape", "(", "(", "batch_size", "+", "rank", ",", "1", "<<", "d", ",", "1", "<<", "(", "m", "-", "d", ")", ")", ")", "\n", "fft_time2freq", "=", "pyfftw", ".", "FFTW", "(", "S", ",", "S_f", ",", "direction", "=", "'FFTW_FORWARD'", ",", "flags", "=", "[", "'FFTW_MEASURE'", ",", "'FFTW_DESTROY_INPUT'", "]", ",", "threads", "=", "1", ")", "\n", "fft_freq2time", "=", "pyfftw", ".", "FFTW", "(", "T_f", ",", "T", ",", "direction", "=", "'FFTW_BACKWARD'", ",", "flags", "=", "[", "'FFTW_MEASURE'", ",", "'FFTW_DESTROY_INPUT'", "]", ",", "threads", "=", "1", ")", "\n", "self", ".", "ffts_forward_pass", ".", "append", "(", "(", "fft_time2freq", ",", "fft_freq2time", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.KrylovTransposeMultiply.__call__": [[191, 237], ["numpy.zeros", "u.reshape().copy", "v.reshape", "numpy.ones", "u.reshape", "v.reshape", "range", "krylovfast.KrylovTransposeMultiply.S_storage[].reshape", "fft_time2freq", "numpy.einsum", "fft_freq2time", "S_01.reshape", "numpy.concatenate", "u.reshape"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ",", "subdiag", ",", "v", ",", "u", ")", ":", "\n", "        ", "\"\"\"Multiply Krylov(A, v)^T @ u when A is zero except on the subdiagonal.\n        We don't use bit reversal here.\n        \"\"\"", "\n", "n", ",", "m", ",", "batch_size", ",", "rank", "=", "self", ".", "n", ",", "self", ".", "m", ",", "self", ".", "batch_size", ",", "self", ".", "rank", "\n", "u", ",", "v", "=", "u", ".", "reshape", "(", "batch_size", ",", "n", ")", ",", "v", ".", "reshape", "(", "rank", ",", "n", ")", "\n", "result", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "rank", ",", "n", ")", ",", "dtype", "=", "u", ".", "dtype", ")", "\n", "# T_00_sum = u @ v.T", "\n", "T_00_sum", "=", "(", "u", "[", ":", ",", "np", ".", "newaxis", "]", "*", "v", ")", ".", "sum", "(", "axis", "=", "-", "1", ")", "\n", "result", "[", ":", ",", ":", ",", "0", "]", "+=", "T_00_sum", "\n", "T_01", "=", "u", ".", "reshape", "(", "batch_size", ",", "n", ",", "1", ")", ".", "copy", "(", ")", "# Copy since we'll be changing this array directly", "\n", "T_10", "=", "v", ".", "reshape", "(", "rank", ",", "n", ",", "1", ")", "\n", "T_11", "=", "np", ".", "ones", "(", "n", ")", "\n", "for", "d", "in", "range", "(", "m", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "            ", "n1", ",", "n2", "=", "1", "<<", "d", ",", "1", "<<", "(", "m", "-", "d", "-", "1", ")", "\n", "S", "=", "self", ".", "S_storage", "[", "d", "]", ".", "reshape", "(", "(", "batch_size", "+", "rank", ",", "n1", ",", "2", "*", "n2", ")", ")", "\n", "S_f", "=", "self", ".", "S_f_storage", "[", "d", "]", "\n", "T_f", "=", "self", ".", "T_f_storage", "[", "d", "]", "\n", "T", "=", "self", ".", "T_storage", "[", "d", "]", "\n", "fft_time2freq", ",", "fft_freq2time", "=", "self", ".", "ffts_forward_pass", "[", "d", "]", "\n", "\n", "S_00_sum", ",", "S_01", ",", "S_10", ",", "S_11", "=", "T_00_sum", ",", "T_01", ",", "T_10", ",", "T_11", "\n", "S", "[", ":", ",", ":", ",", "n2", ":", "]", "=", "0.0", "\n", "S0_10_mult_subdiag", ",", "S1_01", "=", "S", "[", ":", "rank", ",", ":", ",", ":", "n2", "]", ",", "S", "[", "rank", ":", "rank", "+", "batch_size", ",", ":", ",", ":", "n2", "]", "\n", "S0_10_mult_subdiag", "[", ":", "]", "=", "S_10", "[", ":", ",", ":", ":", "2", "]", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", ",", "np", ".", "newaxis", "]", "\n", "S1_01", "[", ":", "]", "=", "S_01", "[", ":", ",", "1", ":", ":", "2", "]", "\n", "\n", "# polynomial multiplications", "\n", "S_f", "=", "fft_time2freq", "(", "S", ",", "output_array", "=", "S_f", ")", "\n", "S0_10_f", ",", "S1_01_f", "=", "S_f", "[", ":", "rank", "]", ",", "S_f", "[", "rank", ":", "rank", "+", "batch_size", "]", "\n", "T_00_f_sum", "=", "T_f", "\n", "# T_00_f_sum[:] = (S1_01_f[:, np.newaxis] * S0_10_f[np.newaxis]).sum(axis=-2)", "\n", "np", ".", "einsum", "(", "\"bnm,rnm->brm\"", ",", "S1_01_f", ",", "S0_10_f", ",", "out", "=", "T_00_f_sum", ")", "\n", "T", "=", "fft_freq2time", "(", "T_f", ",", "output_array", "=", "T", ")", "\n", "T_00_sum", "=", "T", "\n", "\n", "# polynomial additions", "\n", "result", "[", ":", ",", ":", ",", "1", ":", "2", "*", "n2", "]", "+=", "T_00_sum", "[", "...", ",", ":", "-", "1", "]", "\n", "S0_11_mult_subdiag", "=", "S_11", "[", ":", ":", "2", "]", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", "]", "\n", "# T_01 = np.concatenate((S_01[:, ::2], S_01[:, 1::2] * S0_11_mult_subdiag[:, np.newaxis]), axis=-1)", "\n", "T_01", "=", "S_01", ".", "reshape", "(", "batch_size", ",", "n1", ",", "2", "*", "n2", ")", "\n", "T_01", "[", ":", ",", ":", ",", "n2", ":", "]", "*=", "S0_11_mult_subdiag", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "T_10", "=", "np", ".", "concatenate", "(", "(", "S_10", "[", ":", ",", "1", ":", ":", "2", "]", ",", "S0_10_mult_subdiag", "*", "S_11", "[", "1", ":", ":", "2", "]", "[", ":", ",", "np", ".", "newaxis", "]", ")", ",", "axis", "=", "-", "1", ")", "\n", "T_11", "=", "S0_11_mult_subdiag", "*", "S_11", "[", "1", ":", ":", "2", "]", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.KrylovMultiply.__init__": [[243, 252], ["int", "krylovfast.KrylovMultiply.plan_ffts_forward_pass_u_zero", "krylovfast.KrylovMultiply.plan_ffts_backward_pass", "numpy.log2"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.KrylovMultiply.plan_ffts_forward_pass_u_zero", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.KrylovMultiply.plan_ffts_backward_pass"], ["def", "__init__", "(", "self", ",", "n", ",", "batch_size", "=", "1", ",", "rank", "=", "1", ")", ":", "\n", "        ", "m", "=", "int", "(", "np", ".", "log2", "(", "n", ")", ")", "\n", "assert", "n", "==", "1", "<<", "m", ",", "'n must be a power of 2'", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "m", "=", "m", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "rank", "=", "rank", "\n", "self", ".", "plan_ffts_forward_pass_u_zero", "(", ")", "\n", "self", ".", "plan_ffts_backward_pass", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.KrylovMultiply.plan_ffts_forward_pass_u_zero": [[253, 262], ["enumerate", "numpy.empty", "zip", "S.reshape.reshape.reshape", "pyfftw.FFTW", "krylovfast.KrylovMultiply.ffts_forward_pass.append", "numpy.empty", "range"], "methods", ["None"], ["", "def", "plan_ffts_forward_pass_u_zero", "(", "self", ")", ":", "\n", "        ", "n", ",", "m", ",", "batch_size", ",", "rank", "=", "self", ".", "n", ",", "self", ".", "m", ",", "self", ".", "batch_size", ",", "self", ".", "rank", "\n", "self", ".", "S_storage", "=", "[", "np", ".", "empty", "(", "(", "rank", ",", "n", ")", ")", "]", "*", "m", "\n", "self", ".", "S_f_storage", "=", "[", "np", ".", "empty", "(", "(", "rank", ",", "1", "<<", "d", ",", "(", "1", "<<", "(", "m", "-", "d", "-", "1", ")", ")", "+", "1", ")", ",", "dtype", "=", "'complex128'", ")", "for", "d", "in", "range", "(", "m", ")", "]", "\n", "self", ".", "ffts_forward_pass", "=", "[", "]", "\n", "for", "d", ",", "(", "S", ",", "S_f", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "S_storage", ",", "self", ".", "S_f_storage", ")", ")", ":", "\n", "            ", "S", "=", "S", ".", "reshape", "(", "(", "rank", ",", "1", "<<", "d", ",", "1", "<<", "(", "m", "-", "d", ")", ")", ")", "\n", "fft_time2freq", "=", "pyfftw", ".", "FFTW", "(", "S", ",", "S_f", ",", "direction", "=", "'FFTW_FORWARD'", ",", "flags", "=", "[", "'FFTW_MEASURE'", ",", "'FFTW_DESTROY_INPUT'", "]", ",", "threads", "=", "1", ")", "\n", "self", ".", "ffts_forward_pass", ".", "append", "(", "fft_time2freq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.KrylovMultiply.plan_ffts_backward_pass": [[263, 275], ["enumerate", "numpy.empty", "numpy.empty", "numpy.empty", "zip", "dS.reshape.reshape.reshape", "pyfftw.FFTW", "pyfftw.FFTW", "krylovfast.KrylovMultiply.ffts_backward_pass.append", "range", "range", "range", "numpy.empty"], "methods", ["None"], ["", "", "def", "plan_ffts_backward_pass", "(", "self", ")", ":", "\n", "        ", "n", ",", "m", ",", "batch_size", ",", "rank", "=", "self", ".", "n", ",", "self", ".", "m", ",", "self", ".", "batch_size", ",", "self", ".", "rank", "\n", "self", ".", "dT_storage", "=", "[", "np", ".", "empty", "(", "(", "batch_size", ",", "rank", ",", "1", "<<", "(", "m", "-", "d", ")", ")", ")", "for", "d", "in", "range", "(", "m", ")", "]", "\n", "self", ".", "dT_f_storage", "=", "[", "np", ".", "empty", "(", "(", "batch_size", ",", "rank", ",", "(", "1", "<<", "(", "m", "-", "d", "-", "1", ")", ")", "+", "1", ")", ",", "dtype", "=", "'complex128'", ")", "for", "d", "in", "range", "(", "m", ")", "]", "\n", "self", ".", "dS_f_storage", "=", "[", "np", ".", "empty", "(", "(", "batch_size", ",", "1", "<<", "d", ",", "(", "1", "<<", "(", "m", "-", "d", "-", "1", ")", ")", "+", "1", ")", ",", "dtype", "=", "'complex128'", ")", "for", "d", "in", "range", "(", "m", ")", "]", "\n", "self", ".", "dS_storage", "=", "[", "np", ".", "empty", "(", "(", "batch_size", ",", "n", ")", ")", "]", "*", "m", "\n", "self", ".", "ffts_backward_pass", "=", "[", "]", "\n", "for", "d", ",", "(", "dT", ",", "dT_f", ",", "dS_f", ",", "dS", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "dT_storage", ",", "self", ".", "dT_f_storage", ",", "self", ".", "dS_f_storage", ",", "self", ".", "dS_storage", ")", ")", ":", "\n", "            ", "dS", "=", "dS", ".", "reshape", "(", "(", "batch_size", ",", "1", "<<", "d", ",", "1", "<<", "(", "m", "-", "d", ")", ")", ")", "\n", "fft_time2freq", "=", "pyfftw", ".", "FFTW", "(", "dT", ",", "dT_f", ",", "direction", "=", "'FFTW_FORWARD'", ",", "flags", "=", "[", "'FFTW_MEASURE'", ",", "'FFTW_DESTROY_INPUT'", "]", ",", "threads", "=", "1", ")", "\n", "fft_freq2time", "=", "pyfftw", ".", "FFTW", "(", "dS_f", ",", "dS", ",", "direction", "=", "'FFTW_BACKWARD'", ",", "flags", "=", "[", "'FFTW_MEASURE'", ",", "'FFTW_DESTROY_INPUT'", "]", ",", "threads", "=", "1", ")", "\n", "self", ".", "ffts_backward_pass", ".", "append", "(", "(", "fft_time2freq", ",", "fft_freq2time", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.KrylovMultiply.__call__": [[276, 331], ["v.reshape", "numpy.ones", "numpy.zeros", "range", "range", "krylovfast.KrylovMultiply.S_storage[].reshape", "fft_time2freq", "numpy.concatenate", "w.reshape", "v.reshape", "krylovfast.KrylovMultiply.dS_storage[].reshape", "numpy.empty", "fft_time2freq", "numpy.einsum", "fft_freq2time", "numpy.zeros.squeeze", "numpy.conjugate"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.structure.complex_utils.conjugate"], ["", "", "def", "__call__", "(", "self", ",", "subdiag", ",", "v", ",", "w", ")", ":", "\n", "        ", "n", ",", "m", ",", "batch_size", ",", "rank", "=", "self", ".", "n", ",", "self", ".", "m", ",", "self", ".", "batch_size", ",", "self", ".", "rank", "\n", "# Forward pass. Since K @ w can be computed by autodiffing K^T @ u, we", "\n", "# carry out the forward pass K^T @ u for u = 0 here to save the", "\n", "# intermediate values. This code is exactly the same as the function", "\n", "# @krylov_transpose_multiply, specialized to the case where u = 0.", "\n", "save_for_backward", "=", "[", "None", "]", "*", "m", "\n", "T_10", "=", "v", ".", "reshape", "(", "rank", ",", "n", ",", "1", ")", "\n", "T_11", "=", "np", ".", "ones", "(", "n", ")", "\n", "for", "d", "in", "range", "(", "m", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "            ", "n1", ",", "n2", "=", "1", "<<", "d", ",", "1", "<<", "(", "m", "-", "d", "-", "1", ")", "\n", "S", "=", "self", ".", "S_storage", "[", "d", "]", ".", "reshape", "(", "(", "rank", ",", "n1", ",", "2", "*", "n2", ")", ")", "\n", "S_f", "=", "self", ".", "S_f_storage", "[", "d", "]", "\n", "fft_time2freq", "=", "self", ".", "ffts_forward_pass", "[", "d", "]", "\n", "S_10", ",", "S_11", "=", "T_10", ",", "T_11", "\n", "S0_10_mult_subdiag", "=", "S", "[", ":", ",", ":", ",", ":", "n2", "]", "\n", "S0_10_mult_subdiag", "[", ":", "]", "=", "S_10", "[", ":", ",", ":", ":", "2", "]", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", ",", "np", ".", "newaxis", "]", "\n", "S", "[", ":", ",", ":", ",", "n2", ":", "]", "=", "0.0", "\n", "S0_10_mult_subdiag_f", "=", "fft_time2freq", "(", "S", ",", "output_array", "=", "S_f", ")", "\n", "T_10", "=", "np", ".", "concatenate", "(", "(", "S_10", "[", ":", ",", "1", ":", ":", "2", "]", ",", "S0_10_mult_subdiag", "*", "S_11", "[", "1", ":", ":", "2", "]", "[", ":", ",", "np", ".", "newaxis", "]", ")", ",", "axis", "=", "-", "1", ")", "\n", "S0_11_mult_subdiag", "=", "S_11", "[", ":", ":", "2", "]", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", "]", "\n", "save_for_backward", "[", "d", "]", "=", "S0_10_mult_subdiag_f", ",", "S0_11_mult_subdiag", "\n", "T_11", "=", "S0_11_mult_subdiag", "*", "S_11", "[", "1", ":", ":", "2", "]", "\n", "\n", "# Backward pass", "\n", "", "w", ",", "v", "=", "w", ".", "reshape", "(", "batch_size", ",", "rank", ",", "n", ")", ",", "v", ".", "reshape", "(", "(", "rank", ",", "n", ")", ")", "\n", "dT_01", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "1", ",", "n", ")", ",", "dtype", "=", "w", ".", "dtype", ")", "\n", "\n", "for", "d", "in", "range", "(", "m", ")", ":", "\n", "            ", "n1", ",", "n2", "=", "1", "<<", "d", ",", "1", "<<", "(", "m", "-", "d", "-", "1", ")", "\n", "dT", "=", "self", ".", "dT_storage", "[", "d", "]", "\n", "dT_f", "=", "self", ".", "dT_f_storage", "[", "d", "]", "\n", "dS_f", "=", "self", ".", "dS_f_storage", "[", "d", "]", "\n", "dS", "=", "self", ".", "dS_storage", "[", "d", "]", ".", "reshape", "(", "(", "batch_size", ",", "n1", ",", "2", "*", "n2", ")", ")", "\n", "fft_time2freq", ",", "fft_freq2time", "=", "self", ".", "ffts_backward_pass", "[", "d", "]", "\n", "\n", "S0_10_mult_subdiag_f", ",", "S0_11_mult_subdiag", "=", "save_for_backward", "[", "d", "]", "\n", "dS_01", "=", "np", ".", "empty", "(", "(", "batch_size", ",", "2", "*", "n1", ",", "n2", ")", ",", "dtype", "=", "w", ".", "dtype", ")", "\n", "dS_01", "[", ":", ",", ":", ":", "2", "]", "=", "dT_01", "[", ":", ",", ":", ",", ":", "n2", "]", "\n", "dT_00_sum", "=", "dT", "\n", "dT_00_sum", "[", ":", ",", ":", ",", ":", "2", "*", "n2", "-", "1", "]", "=", "w", "[", ":", ",", ":", ",", "1", ":", "2", "*", "n2", "]", "\n", "dT_00_sum", "[", ":", ",", ":", ",", "-", "1", "]", "=", "0.0", "\n", "\n", "dT_00_sum_f", "=", "fft_time2freq", "(", "dT", ",", "output_array", "=", "dT_f", ")", "\n", "dS1_01_f", "=", "dS_f", "\n", "# dS1_01_f[:] = (np.conjugate(S0_10_mult_subdiag_f, out=S0_10_mult_subdiag_f) * dT_00_sum_f[:, :, np.newaxis]).sum(axis=1)", "\n", "np", ".", "einsum", "(", "\"brm,rnm->bnm\"", ",", "dT_00_sum_f", ",", "np", ".", "conjugate", "(", "S0_10_mult_subdiag_f", ",", "out", "=", "S0_10_mult_subdiag_f", ")", ",", "out", "=", "dS1_01_f", ")", "\n", "\n", "dS1_01", "=", "fft_freq2time", "(", "dS_f", ",", "output_array", "=", "dS", ")", "\n", "dS_01", "[", ":", ",", "1", ":", ":", "2", "]", "=", "dT_01", "[", ":", ",", ":", ",", "n2", ":", "]", "*", "S0_11_mult_subdiag", "[", ":", ",", "np", ".", "newaxis", "]", "+", "dS1_01", "[", ":", ",", ":", ",", ":", "n2", "]", "\n", "dT_01", "=", "dS_01", "\n", "\n", "# du = ((dT_00_sum[:, :, np.newaxis] * v[np.newaxis, :, :, np.newaxis]).sum(dim=1) + dT_01).squeeze(axis=-1)", "\n", "", "du", "=", "w", "[", ":", ",", ":", ",", "0", "]", "@", "v", "+", "dT_01", ".", "squeeze", "(", "axis", "=", "-", "1", ")", "\n", "return", "du", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast._plan_ffts": [[11, 33], ["numpy.zeros", "numpy.empty", "pyfftw.empty_aligned", "pyfftw.empty_aligned", "pyfftw.FFTW", "pyfftw.empty_aligned", "pyfftw.empty_aligned", "pyfftw.FFTW", "numpy.fft.rfft", "numpy.fft.irfft"], "function", ["None"], ["def", "_plan_ffts", "(", "in_shape", ",", "lib", "=", "'numpy'", ")", ":", "\n", "    ", "out_shape", "=", "in_shape", "[", ":", "-", "1", "]", "+", "(", "in_shape", "[", "-", "1", "]", "//", "2", "+", "1", ",", ")", "\n", "if", "lib", "==", "'numpy'", ":", "\n", "        ", "x_for", "=", "np", ".", "zeros", "(", "shape", "=", "in_shape", ")", "\n", "fft", "=", "lambda", ":", "np", ".", "fft", ".", "rfft", "(", "x_for", ")", "\n", "\n", "y_bak", "=", "np", ".", "empty", "(", "shape", "=", "out_shape", ",", "dtype", "=", "'complex128'", ")", "\n", "ifft", "=", "lambda", ":", "np", ".", "fft", ".", "irfft", "(", "y_bak", ")", "\n", "return", "(", "(", "x_for", ",", "fft", ")", ",", "(", "y_bak", ",", "ifft", ")", ")", "\n", "", "if", "lib", "==", "'scipy'", ":", "\n", "        ", "pass", "\n", "", "if", "lib", "==", "'fftw'", ":", "\n", "        ", "out_shape", "=", "in_shape", "[", ":", "-", "1", "]", "+", "(", "in_shape", "[", "-", "1", "]", "//", "2", "+", "1", ",", ")", "\n", "x_for", "=", "pyfftw", ".", "empty_aligned", "(", "in_shape", ",", "dtype", "=", "'float64'", ")", "\n", "y_for", "=", "pyfftw", ".", "empty_aligned", "(", "out_shape", ",", "dtype", "=", "'complex128'", ")", "\n", "fft_for", "=", "pyfftw", ".", "FFTW", "(", "x_for", ",", "y_for", ",", "direction", "=", "'FFTW_FORWARD'", ",", "flags", "=", "[", "'FFTW_MEASURE'", "]", ")", "# don't destroy input so 0s are preserved", "\n", "x_for", "[", ":", "]", "=", "0", "\n", "\n", "x_bak", "=", "pyfftw", ".", "empty_aligned", "(", "in_shape", ",", "dtype", "=", "'float64'", ")", "\n", "y_bak", "=", "pyfftw", ".", "empty_aligned", "(", "out_shape", ",", "dtype", "=", "'complex128'", ")", "\n", "fft_bak", "=", "pyfftw", ".", "FFTW", "(", "y_bak", ",", "x_bak", ",", "direction", "=", "'FFTW_BACKWARD'", ",", "flags", "=", "[", "'FFTW_MEASURE'", ",", "'FFTW_DESTROY_INPUT'", "]", ")", "\n", "return", "(", "(", "x_for", ",", "fft_for", ")", ",", "(", "y_bak", ",", "fft_bak", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.plan_ffts": [[35, 42], ["range", "krylovfast._plan_ffts"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast._plan_ffts"], ["", "", "def", "plan_ffts", "(", "m", ",", "lib", "=", "'numpy'", ")", ":", "\n", "    ", "fft_plans", "=", "[", "None", "]", "*", "m", "\n", "for", "d", "in", "range", "(", "m", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "        ", "n1", ",", "n2", "=", "1", "<<", "d", ",", "1", "<<", "(", "m", "-", "d", ")", "\n", "in_shape", "=", "(", "4", ",", "n1", ",", "n2", ")", "\n", "fft_plans", "[", "d", "]", "=", "_plan_ffts", "(", "in_shape", ",", "lib", ")", "\n", "", "return", "fft_plans", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast._resolvent_bilinear_flattened": [[49, 99], ["fft", "ifft"], "function", ["None"], ["", "def", "_resolvent_bilinear_flattened", "(", "fft_plans", ",", "subd", ",", "m", ",", "d", ",", "S", ")", ":", "\n", "# pass at depth d computes 4 arrays:", "\n", "# each array is length n, indexed by x_{m-1}, ..., x_{m-d}, y_{m-d-1}, ..., y_0", "\n", "# for convenience, store as x_{m-d}, ..., x_{m-1}, y_{m-d-1}, ..., y_0 (index is bit-reversed)", "\n", "\n", "# assert d < m # assume leaf pass done in main function", "\n", "\n", "    ", "S_00", ",", "S_01", ",", "S_10", ",", "S_11", "=", "S", "# answers to previous layer: indexed by x_{m-d-1}, x_{m-d}, ..., x_{m-1}, y_{m-d-2}, ..., y_0", "\n", "# these are the same as the S0[0,0],S1[0,0] in the recursive version", "\n", "\n", "# assert S_00.shape == (1<<(d+1), 1<<(m-d-1))", "\n", "n1", ",", "n2", "=", "1", "<<", "d", ",", "1", "<<", "(", "m", "-", "d", "-", "1", ")", "# input shape 2n1 x n2, output shape n1 x 2n2", "\n", "\n", "(", "(", "S_", ",", "fft", ")", ",", "(", "T_", ",", "ifft", ")", ")", "=", "fft_plans", "[", "d", "]", "\n", "S0_10_mult_subdiag", ",", "S0_11", ",", "S1_01", ",", "S1_11", "=", "S_", "## pass", "\n", "S0_10_mult_subdiag", "[", ":", ",", ":", "n2", "]", "=", "S_10", "[", ":", "n1", ",", ":", "]", "\n", "S1_01", "[", ":", ",", ":", "n2", "]", "=", "S_01", "[", "n1", ":", ",", ":", "]", "\n", "S0_11", "[", ":", ",", ":", "n2", "]", "=", "S_11", "[", ":", "n1", ",", ":", "]", "\n", "S1_11", "[", ":", ",", ":", "n2", "]", "=", "S_11", "[", "n1", ":", ",", ":", "]", "## dS_11[...] = dS1_11[...]", "\n", "\n", "# polynomial multiplications", "\n", "S0_10_f", ",", "S0_11_f", ",", "S1_01_f", ",", "S1_11_f", "=", "fft", "(", ")", "## dS_ = fft(dS*_**_f)", "\n", "\n", "# subproblem for branch x_{m-d}, ..., x_{m-1} is A[\\overline{x_{m-1}...x_{m-d}} + 2^{m-d-1}]", "\n", "T_", "[", "0", "]", "=", "S1_01_f", "*", "S0_10_f", "\n", "T_", "[", "1", "]", "=", "S1_01_f", "*", "S0_11_f", "\n", "T_", "[", "2", "]", "=", "S1_11_f", "*", "S0_10_f", "\n", "T_", "[", "3", "]", "=", "S1_11_f", "*", "S0_11_f", "## dS1_01_f += dT_[0] * S0_10_f; dS0_10_f += dT_[0] * S1_01_f", "\n", "## note that the S*_**_f are the only things that need to be stored in t he forward pass", "\n", "## also note that there is an optimization here; should only need half", "\n", "\n", "T__", "=", "ifft", "(", ")", "## dT_ = ifft(dT__) (because DFT matrix symmetric)", "\n", "T__", "*=", "subd", "[", "n1", ":", "n1", "*", "2", ",", "np", ".", "newaxis", "]", "## dT__ *= subd[...]", "\n", "## for learning A, should get somethiign like dsubd[...] = T__", "\n", "\n", "T_00", ",", "T_01", ",", "T_10", ",", "T_11", "=", "T__", "\n", "\n", "# polynomial additions", "\n", "T_00", "[", ":", ",", "n2", ":", "]", "+=", "S_00", "[", ":", "n1", ",", ":", "]", "## dS_00[:n1,:] = T_00[:,n2:]", "\n", "T_00", "[", ":", ",", "n2", ":", "]", "+=", "S_00", "[", "n1", ":", ",", ":", "]", "\n", "T_01", "[", ":", ",", "n2", ":", "]", "+=", "S_01", "[", ":", "n1", ",", ":", "]", "\n", "T_10", "[", ":", ",", "n2", ":", "]", "+=", "S_10", "[", "n1", ":", ",", ":", "]", "\n", "\n", "## autodiff correspondences annotated in with '##'", "\n", "## this function takes in S and outputs T;", "\n", "## the backwards pass calls these lines in reverse,", "\n", "## taking dT and outputting dS where ## dx := \\partial{L}/\\partial{x},", "\n", "## (L is the final output of the entire algorithm)", "\n", "\n", "return", "(", "T_00", ",", "T_01", ",", "T_10", ",", "T_11", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.bitreversal_slow": [[100, 109], ["x.reshape", "numpy.empty", "itertools.product", "np.empty.reshape"], "function", ["None"], ["", "def", "bitreversal_slow", "(", "x", ",", "n", ",", "m", ")", ":", "\n", "    ", "\"\"\" Compute the bit reversal permutation \"\"\"", "\n", "assert", "n", "==", "1", "<<", "m", "# power of 2 for now", "\n", "x_", "=", "x", ".", "reshape", "(", "[", "2", "]", "*", "m", ")", "\n", "x_bf_", "=", "np", ".", "empty", "(", "shape", "=", "[", "2", "]", "*", "m", ")", "\n", "for", "i", "in", "itertools", ".", "product", "(", "*", "(", "[", "[", "0", ",", "1", "]", "]", "*", "m", ")", ")", ":", "\n", "        ", "x_bf_", "[", "i", "[", ":", ":", "-", "1", "]", "]", "=", "x_", "[", "i", "]", "\n", "", "x_bf", "=", "x_bf_", ".", "reshape", "(", "n", ")", "\n", "return", "x_bf", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.bitreversal_stack": [[113, 123], ["x.reshape", "range", "np.hstack.squeeze", "numpy.hstack"], "function", ["None"], ["", "def", "bitreversal_stack", "(", "x", ",", "n", ",", "m", ")", ":", "\n", "    ", "\"\"\" faster version in numpy \"\"\"", "\n", "assert", "n", "==", "1", "<<", "m", "\n", "n1", ",", "n2", "=", "n", ",", "1", "\n", "x_", "=", "x", ".", "reshape", "(", "(", "n1", ",", "n2", ")", ")", "\n", "for", "i", "in", "range", "(", "m", ")", ":", "\n", "        ", "n1", "//=", "2", "\n", "n2", "*=", "2", "\n", "x_", "=", "np", ".", "hstack", "(", "(", "x_", "[", ":", "n1", ",", ":", "]", ",", "x_", "[", "n1", ":", ",", ":", "]", ")", ")", "\n", "", "return", "x_", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.create": [[131, 164], ["krylovfast.plan_ffts", "krylovfast.bitreversal_stack", "numpy.arange", "numpy.empty", "numpy.diagonal", "bitreversal", "bitreversal().reshape", "bitreversal().reshape", "numpy.ones", "range", "krylovfast._resolvent_bilinear_flattened", "S[].squeeze", "bitreversal", "bitreversal"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.plan_ffts", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.bitreversal_stack", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast._resolvent_bilinear_flattened"], ["", "def", "create", "(", "n", ",", "m", ",", "lib", "=", "'numpy'", ")", ":", "\n", "    ", "fft_plans", "=", "plan_ffts", "(", "m", ",", "lib", ")", "\n", "bf_perm", "=", "bitreversal_stack", "(", "np", ".", "arange", "(", "n", ")", ",", "n", ",", "m", ")", "\n", "# Shorter versions but much slower. Maybe we don't care about speed because", "\n", "# this will done only once.", "\n", "# bf_perm_1 = np.array([int(np.binary_repr(i, width=m)[::-1], 2) for i in range(n)])", "\n", "# bf_perm_2 = np.array([int(f'{x:0{m}b}'[::-1], 2) for i in range(n)])", "\n", "# bf_perm_3 = np.array([int(bin(i + n)[:2:-1], 2) for i in range(n)])", "\n", "bitreversal", "=", "lambda", "x", ",", "n", ",", "m", ":", "x", "[", "bf_perm", "]", "\n", "\n", "# @profile", "\n", "def", "resolvent_bilinear_flattened", "(", "A", ",", "v", ",", "u", ",", "n", ",", "m", ")", ":", "\n", "        ", "assert", "n", "==", "1", "<<", "m", "# power of 2 for now", "\n", "\n", "# assume A is subdiagonal for now", "\n", "subd", "=", "np", ".", "empty", "(", "(", "n", ",", ")", ")", "\n", "subd", "[", "1", ":", "]", "=", "np", ".", "diagonal", "(", "A", ",", "-", "1", ")", "\n", "subd", "=", "bitreversal", "(", "subd", ",", "n", ",", "m", ")", "\n", "\n", "# reshape u,v to be indexed consistently with the above", "\n", "# i.e. bit flip their indices", "\n", "u_bf", "=", "bitreversal", "(", "u", ",", "n", ",", "m", ")", ".", "reshape", "(", "(", "n", ",", "1", ")", ")", "# tri says use [:,np.newaxis]", "\n", "v_bf", "=", "bitreversal", "(", "v", ",", "n", ",", "m", ")", ".", "reshape", "(", "(", "n", ",", "1", ")", ")", "\n", "\n", "S", "=", "(", "u_bf", "*", "v_bf", ",", "u_bf", ",", "v_bf", ",", "np", ".", "ones", "(", "(", "n", ",", "1", ")", ")", ")", "\n", "\n", "for", "d", "in", "range", "(", "m", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "            ", "S", "=", "_resolvent_bilinear_flattened", "(", "fft_plans", ",", "subd", ",", "m", ",", "d", ",", "S", ")", "\n", "\n", "# return np.flip(S[0], axis=-1)", "\n", "", "return", "S", "[", "0", "]", ".", "squeeze", "(", ")", "[", ":", ":", "-", "1", "]", "\n", "\n", "", "return", "resolvent_bilinear_flattened", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.test_krylov_transpose_multiply": [[333, 351], ["numpy.random.random", "numpy.diag", "numpy.random.random", "numpy.random.random", "krylovfast.create", "krylovfast.KrylovTransposeMultiply", "create.", "KrylovTransposeMultiply.", "numpy.allclose"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.create"], ["", "", "def", "test_krylov_transpose_multiply", "(", ")", ":", "\n", "    ", "m", "=", "14", "\n", "n", "=", "1", "<<", "m", "\n", "batch_size", "=", "3", "\n", "rank", "=", "2", "\n", "subdiag", "=", "np", ".", "random", ".", "random", "(", "n", "-", "1", ")", "\n", "A", "=", "np", ".", "diag", "(", "subdiag", ",", "-", "1", ")", "\n", "u", "=", "np", ".", "random", ".", "random", "(", "(", "batch_size", ",", "n", ")", ")", "\n", "v", "=", "np", ".", "random", ".", "random", "(", "(", "rank", ",", "n", ")", ")", "\n", "# k1 = krylov_mult_slow(A,v,u,n)", "\n", "# k1_allocated = krylov_mult_slow_allocated(A,v,u,n)", "\n", "# k11 = krylov_mult_slow_faster(A,v,u,n)", "\n", "# k2 = krylov_mult(A,v,u,n)", "\n", "resolvent_bilinear_flattened", "=", "create", "(", "n", ",", "m", ",", "lib", "=", "'fftw'", ")", "\n", "krylov_transpose_multiply", "=", "KrylovTransposeMultiply", "(", "n", ",", "batch_size", ",", "rank", ")", "\n", "k3", "=", "resolvent_bilinear_flattened", "(", "A", ",", "v", "[", "0", "]", ",", "u", "[", "0", "]", ",", "n", ",", "m", ")", "\n", "k3_nobf", "=", "krylov_transpose_multiply", "(", "subdiag", ",", "v", ",", "u", ")", "\n", "assert", "np", ".", "allclose", "(", "k3", ",", "k3_nobf", "[", "0", ",", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.test_krylov_multiply": [[353, 367], ["numpy.random.random", "numpy.diag", "numpy.random.random", "numpy.random.random", "krylovfast.KrylovMultiply", "KrylovMultiply.", "numpy.stack().swapaxes().sum", "numpy.allclose", "structure.scratch.krylovslow.krylov_construct", "range", "numpy.stack().swapaxes", "numpy.stack", "range"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovslow.krylov_construct"], ["", "def", "test_krylov_multiply", "(", ")", ":", "\n", "    ", "m", "=", "14", "\n", "n", "=", "1", "<<", "m", "\n", "batch_size", "=", "3", "\n", "rank", "=", "2", "\n", "subdiag", "=", "np", ".", "random", ".", "random", "(", "n", "-", "1", ")", "\n", "A", "=", "np", ".", "diag", "(", "subdiag", ",", "-", "1", ")", "\n", "w", "=", "np", ".", "random", ".", "random", "(", "(", "batch_size", ",", "rank", ",", "n", ")", ")", "\n", "v", "=", "np", ".", "random", ".", "random", "(", "(", "rank", ",", "n", ")", ")", "\n", "krylov_multiply", "=", "KrylovMultiply", "(", "n", ",", "batch_size", ",", "rank", ")", "\n", "result1", "=", "krylov_multiply", "(", "subdiag", ",", "v", ",", "w", ")", "\n", "Ks", "=", "[", "krylov_construct", "(", "A", ",", "v", "[", "i", "]", ",", "n", ")", "for", "i", "in", "range", "(", "rank", ")", "]", "\n", "result2", "=", "np", ".", "stack", "(", "[", "w", "[", ":", ",", "i", "]", "@", "Ks", "[", "i", "]", "for", "i", "in", "range", "(", "rank", ")", "]", ")", ".", "swapaxes", "(", "0", ",", "1", ")", ".", "sum", "(", "axis", "=", "1", ")", "\n", "assert", "np", ".", "allclose", "(", "result1", ",", "result2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.main": [[369, 372], ["krylovfast.test_krylov_transpose_multiply", "krylovfast.test_krylov_multiply"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.test_krylov_transpose_multiply", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.scratch.krylovfast.test_krylov_multiply"], ["", "def", "main", "(", ")", ":", "\n", "    ", "test_krylov_transpose_multiply", "(", ")", "\n", "test_krylov_multiply", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.optimize_tf.restore_from_checkpoint": [[13, 20], ["saver.restore", "print", "sess.run", "print", "tensorflow.train.latest_checkpoint"], "function", ["None"], ["def", "restore_from_checkpoint", "(", "dataset", ",", "params", ",", "sess", ",", "saver", ",", "x", ",", "y_", ",", "loss", ",", "accuracy", ")", ":", "\n", "# Restore the best validation checkpoint, test on that", "\n", "    ", "saver", ".", "restore", "(", "sess", ",", "tf", ".", "train", ".", "latest_checkpoint", "(", "params", ".", "checkpoint_path", ")", ")", "\n", "print", "(", "'Restored from most recent checkpoint: '", ")", "\n", "val_loss", ",", "val_accuracy", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "val_X", ",", "y_", ":", "dataset", ".", "val_Y", "}", ")", "\n", "print", "(", "'After restoring, val loss and accuracy: %f, %f'", "%", "(", "val_loss", ",", "val_accuracy", ")", ")", "\n", "return", "val_loss", ",", "val_accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.optimize_tf.optimize_tf": [[21, 155], ["tensorflow.placeholder", "model.forward", "tensorflow.placeholder", "utils.compute_loss_and_accuracy", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.FileWriter", "tensorflow.Variable", "tensorflow.train.exponential_decay", "tensorflow.train.MomentumOptimizer().minimize", "tensorflow.InteractiveSession", "tensorflow.initialize_all_variables().run", "tensorflow.train.Saver", "time.time", "range", "int", "optimize_tf.restore_from_checkpoint", "tf.InteractiveSession.run", "dataset.batch", "tf.InteractiveSession.run", "model.check_rank", "losses[].append", "losses[].append", "losses[].append", "dataset.load_test_data", "tensorflow.get_default_graph", "tensorflow.train.MomentumOptimizer", "tensorflow.initialize_all_variables", "logging.debug", "time.time", "logging.debug", "tf.InteractiveSession.run", "tf.InteractiveSession.run", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "losses[].append", "accuracies[].append", "losses[].append", "accuracies[].append", "pickle.dump", "pickle.dump", "logging.debug", "logging.debug", "logging.debug", "logging.debug", "tf.train.Saver.save", "logging.debug", "logging.debug", "visualize.visualize", "tf.InteractiveSession.run", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "logging.debug", "logging.debug", "optimize_tf.restore_from_checkpoint", "tf.InteractiveSession.run", "logging.debug", "logging.debug", "model.check_rank", "losses[].append", "losses[].append", "losses[].append", "[].append", "[].append", "[].append", "[].append", "open", "open", "os.path.join", "logging.debug", "time.time", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.forward", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.compute_loss_and_accuracy", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.optimize_tf.restore_from_checkpoint", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.batch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.check_rank", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.load_test_data", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model_params.ModelParams.save", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.visualize.visualize", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.optimize_tf.restore_from_checkpoint", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.check_rank"], ["", "def", "optimize_tf", "(", "dataset", ",", "params", ")", ":", "\n", "# Create model", "\n", "    ", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "[", "None", ",", "params", ".", "input_size", "]", ",", "name", "=", "'x'", ")", "\n", "y", ",", "model", "=", "forward", "(", "x", ",", "params", ")", "\n", "y_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "[", "None", ",", "params", ".", "out_size", "]", ",", "name", "=", "'y_'", ")", "\n", "loss", ",", "accuracy", "=", "compute_loss_and_accuracy", "(", "y", ",", "y_", ",", "params", ")", "\n", "\n", "train_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'train_loss'", ",", "loss", ")", "\n", "train_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'train_accuracy'", ",", "accuracy", ")", "\n", "val_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'val_loss'", ",", "loss", ")", "\n", "val_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'val_accuracy'", ",", "accuracy", ")", "\n", "test_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'test_loss'", ",", "loss", ")", "\n", "test_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'test_accuracy'", ",", "accuracy", ")", "\n", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "params", ".", "log_path", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", ")", "\n", "\n", "# Allow for decay of learning rate", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ")", "\n", "learning_rate", "=", "tf", ".", "train", ".", "exponential_decay", "(", "params", ".", "lr", ",", "global_step", ",", "\n", "int", "(", "params", ".", "decay_freq", "*", "params", ".", "steps", ")", ",", "params", ".", "decay_rate", ",", "staircase", "=", "True", ")", "\n", "\n", "train_step", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "learning_rate", ",", "params", ".", "mom", ")", ".", "minimize", "(", "loss", ",", "global_step", "=", "global_step", ")", "\n", "sess", "=", "tf", ".", "InteractiveSession", "(", ")", "\n", "tf", ".", "initialize_all_variables", "(", ")", ".", "run", "(", ")", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "if", "params", ".", "restore_from_checkpoint", ":", "\n", "        ", "val_loss", ",", "val_accuracy", "=", "restore_from_checkpoint", "(", "dataset", ",", "params", ",", "sess", ",", "saver", ",", "x", ",", "y_", ",", "loss", ",", "accuracy", ")", "\n", "\n", "", "eigvals", "=", "{", "'E'", ":", "[", "]", ",", "'W'", ":", "[", "]", ",", "'A'", ":", "[", "]", ",", "'B'", ":", "[", "]", "}", "\n", "model_params", "=", "{", "'E'", ":", "[", "]", ",", "'W'", ":", "[", "]", ",", "'A'", ":", "[", "]", ",", "'B'", ":", "[", "]", "}", "\n", "losses", "=", "{", "'train'", ":", "[", "]", ",", "'val'", ":", "[", "]", ",", "'DR'", ":", "[", "]", ",", "'ratio'", ":", "[", "]", ",", "'eigvals'", ":", "eigvals", ",", "'params'", ":", "model_params", "}", "\n", "accuracies", "=", "{", "'train'", ":", "[", "]", ",", "'val'", ":", "[", "]", ",", "'best_val'", ":", "0.0", ",", "'best_val_iter'", ":", "0", "}", "\n", "t1", "=", "time", ".", "time", "(", ")", "\n", "for", "_", "in", "range", "(", "params", ".", "steps", ")", ":", "\n", "        ", "this_step", ",", "lr", "=", "sess", ".", "run", "(", "[", "global_step", ",", "learning_rate", "]", ")", "\n", "batch_xs", ",", "batch_ys", "=", "dataset", ".", "batch", "(", "params", ".", "batch_size", ",", "this_step", ")", "\n", "_", "=", "sess", ".", "run", "(", "[", "train_step", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "\n", "if", "this_step", "%", "params", ".", "test_freq", "==", "0", ":", "\n", "            ", "logging", ".", "debug", "(", "time", ".", "time", "(", ")", "-", "t1", ")", "\n", "t1", "=", "time", ".", "time", "(", ")", "\n", "logging", ".", "debug", "(", "'Training step: '", "+", "str", "(", "this_step", ")", ")", "\n", "# Verify displacement rank", "\n", "if", "params", ".", "check_disp", "and", "this_step", "%", "params", ".", "check_disp_freq", "==", "0", ":", "\n", "                ", "dr", ",", "norm_res", ",", "norm_W", ",", "E_ev", ",", "W_ev", ",", "A_ev", ",", "B_ev", "=", "check_rank", "(", "sess", ",", "x", ",", "y_", ",", "batch_xs", ",", "batch_ys", ",", "params", ",", "model", ")", "\n", "losses", "[", "'DR'", "]", ".", "append", "(", "dr", ")", "\n", "losses", "[", "'norm_res'", "]", ".", "append", "(", "norm_res", ")", "\n", "losses", "[", "'norm_W'", "]", ".", "append", "(", "norm_W", ")", "\n", "losses", "[", "'eigvals'", "]", "[", "'E'", "]", ".", "append", "(", "E_ev", ")", "\n", "losses", "[", "'eigvals'", "]", "[", "'W'", "]", ".", "append", "(", "W_ev", ")", "\n", "losses", "[", "'eigvals'", "]", "[", "'A'", "]", ".", "append", "(", "A_ev", ")", "\n", "losses", "[", "'eigvals'", "]", "[", "'B'", "]", ".", "append", "(", "B_ev", ")", "\n", "", "train_loss", ",", "train_accuracy", ",", "train_loss_summ", ",", "train_acc_summ", ",", "y_pred", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "train_loss_summary", ",", "\n", "train_acc_summary", ",", "y", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "val_loss", ",", "val_accuracy", ",", "val_loss_summ", ",", "val_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "val_loss_summary", ",", "\n", "val_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "val_X", ",", "y_", ":", "dataset", ".", "val_Y", "}", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "train_loss_summ", ",", "this_step", ")", "\n", "summary_writer", ".", "add_summary", "(", "train_acc_summ", ",", "this_step", ")", "\n", "summary_writer", ".", "add_summary", "(", "val_loss_summ", ",", "this_step", ")", "\n", "summary_writer", ".", "add_summary", "(", "val_acc_summ", ",", "this_step", ")", "\n", "\n", "losses", "[", "'train'", "]", ".", "append", "(", "train_loss", ")", "\n", "accuracies", "[", "'train'", "]", ".", "append", "(", "train_accuracy", ")", "\n", "losses", "[", "'val'", "]", ".", "append", "(", "val_loss", ")", "\n", "accuracies", "[", "'val'", "]", ".", "append", "(", "val_accuracy", ")", "\n", "\n", "# Save", "\n", "pkl", ".", "dump", "(", "losses", ",", "open", "(", "params", ".", "result_path", "+", "'_losses.p'", ",", "'wb'", ")", ",", "protocol", "=", "2", ")", "\n", "pkl", ".", "dump", "(", "accuracies", ",", "open", "(", "params", ".", "result_path", "+", "'_accuracies.p'", ",", "'wb'", ")", ",", "protocol", "=", "2", ")", "\n", "\n", "logging", ".", "debug", "(", "'Saved losses, accuracies to: %s'", "%", "(", "params", ".", "result_path", ")", ")", "\n", "logging", ".", "debug", "(", "'Train loss, accuracy for class %s: %f, %f'", "%", "(", "params", ".", "class_type", ",", "train_loss", ",", "train_accuracy", ")", ")", "\n", "logging", ".", "debug", "(", "'Validation loss, accuracy %s: %f, %f'", "%", "(", "params", ".", "class_type", ",", "val_loss", ",", "val_accuracy", ")", ")", "\n", "logging", ".", "debug", "(", "\"Best validation accuracy so far: %f\"", "%", "accuracies", "[", "'best_val'", "]", ")", "\n", "\n", "# Update checkpoint if better validation accuracy", "\n", "", "if", "val_accuracy", ">", "accuracies", "[", "'best_val'", "]", ":", "\n", "            ", "accuracies", "[", "'best_val'", "]", "=", "val_accuracy", "\n", "accuracies", "[", "'best_val_iter'", "]", "=", "this_step", "\n", "#if this_step > 0 and this_step % params.checkpoint_freq == 0:", "\n", "#save_path = saver.save(sess, os.path.join(params.checkpoint_path, str(this_step)))", "\n", "save_path", "=", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "params", ".", "checkpoint_path", ",", "str", "(", "this_step", ")", "+", "'_'", "+", "str", "(", "accuracies", "[", "'best_val'", "]", ")", ")", ")", "\n", "logging", ".", "debug", "(", "\"Updating validation accuracy so far: %f\"", "%", "accuracies", "[", "'best_val'", "]", ")", "\n", "logging", ".", "debug", "(", "\"Model saved in file: %s\"", "%", "save_path", ")", "\n", "\n", "\n", "", "elif", "accuracies", "[", "'best_val_iter'", "]", "<=", "this_step", "-", "params", ".", "early_stop_steps", ":", "\n", "            ", "logging", ".", "debug", "(", "'Early stopping: best val iter at %d, current step %d'", "%", "(", "accuracies", "[", "'best_val_iter'", "]", ",", "this_step", ")", ")", "\n", "break", "\n", "\n", "", "if", "this_step", ">", "0", "and", "params", ".", "viz_freq", ">", "0", "and", "this_step", "%", "params", ".", "viz_freq", "==", "0", ":", "\n", "            ", "visualize", "(", "params", ",", "sess", ",", "model", ",", "x", ",", "y_", ",", "batch_xs", ",", "batch_ys", ",", "y_pred", ",", "this_step", ")", "\n", "\n", "# Get final params", "\n", "", "", "if", "params", ".", "check_disp", ":", "\n", "        ", "dr", ",", "norm_res", ",", "norm_W", ",", "E_ev", ",", "W_ev", ",", "A_ev", ",", "B_ev", ",", "E", ",", "W", ",", "A", ",", "B", "=", "check_rank", "(", "sess", ",", "x", ",", "y_", ",", "batch_xs", ",", "batch_ys", ",", "params", ",", "model", ")", "\n", "losses", "[", "'DR'", "]", ".", "append", "(", "dr", ")", "\n", "losses", "[", "'norm_res'", "]", ".", "append", "(", "norm_res", ")", "\n", "losses", "[", "'norm_W'", "]", ".", "append", "(", "norm_W", ")", "\n", "losses", "[", "'params'", "]", "[", "'E'", "]", "=", "E", "\n", "losses", "[", "'params'", "]", "[", "'W'", "]", "=", "W", "\n", "losses", "[", "'params'", "]", "[", "'A'", "]", "=", "A", "\n", "losses", "[", "'params'", "]", "[", "'B'", "]", "=", "B", "\n", "\n", "# Test trained model", "\n", "", "if", "params", ".", "test", ":", "\n", "# Load test", "\n", "        ", "dataset", ".", "load_test_data", "(", ")", "\n", "# Test on the current model", "\n", "if", "not", "params", ".", "test_best_val_checkpoint", ":", "\n", "            ", "test_loss", ",", "test_accuracy", ",", "test_loss_summ", ",", "test_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "test_loss_summary", ",", "test_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "test_X", ",", "y_", ":", "dataset", ".", "test_Y", "}", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "test_loss_summ", ",", "this_step", ")", "\n", "summary_writer", ".", "add_summary", "(", "test_acc_summ", ",", "this_step", ")", "\n", "\n", "logging", ".", "debug", "(", "'Test loss, %s: %f'", "%", "(", "params", ".", "class_type", ",", "test_loss", ")", ")", "\n", "logging", ".", "debug", "(", "'Test accuracy, %s: %f '", "%", "(", "params", ".", "class_type", ",", "test_accuracy", ")", ")", "\n", "\n", "losses", "[", "'test'", "]", "=", "test_loss", "\n", "accuracies", "[", "'test'", "]", "=", "test_accuracy", "\n", "\n", "", "else", ":", "\n", "            ", "restore_from_checkpoint", "(", "dataset", ",", "params", ",", "sess", ",", "saver", ",", "x", ",", "y_", ",", "loss", ",", "accuracy", ")", "\n", "test_loss", ",", "test_accuracy", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "test_X", ",", "y_", ":", "dataset", ".", "test_Y", "}", ")", "\n", "\n", "logging", ".", "debug", "(", "'Test loss of best val checkpoint, %s: %f'", "%", "(", "params", ".", "class_type", ",", "test_loss", ")", ")", "\n", "logging", ".", "debug", "(", "'Test accuracy of best val checkpoint, %s: %f '", "%", "(", "params", ".", "class_type", ",", "test_accuracy", ")", ")", "\n", "\n", "losses", "[", "'test_best_val'", "]", "=", "test_loss", "\n", "accuracies", "[", "'test_best_val'", "]", "=", "test_accuracy", "\n", "\n", "", "", "return", "losses", ",", "accuracies", "\n", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model_params.ModelParams.__init__": [[6, 72], ["print", "model_params.ModelParams.set_cnn_params"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model_params.ModelParams.set_cnn_params"], ["    ", "def", "__init__", "(", "self", ",", "dataset_name", ",", "transform", ",", "test", ",", "log_path", ",", "input_size", ",", "\n", "layer_size", ",", "out_size", ",", "num_layers", ",", "loss", ",", "r", ",", "steps", ",", "batch_size", ",", "\n", "lr", ",", "mom", ",", "init_type", ",", "class_type", ",", "learn_corner", ",", "n_diag_learned", ",", "\n", "init_stddev", ",", "fix_G", ",", "check_disp", ",", "check_disp_freq", ",", "checkpoint_freq", ",", "checkpoint_path", ",", "\n", "test_freq", ",", "verbose", ",", "decay_rate", ",", "decay_freq", ",", "learn_diagonal", ",", "\n", "fix_A_identity", ",", "stochastic_train", ",", "flip_K_B", ",", "num_conv_layers", ",", "\n", "torch", ",", "model", ",", "viz_freq", ",", "num_pred_plot", ",", "viz_powers", ",", "early_stop_steps", ",", "replacement", ",", "\n", "test_best_val_checkpoint", ",", "restore_from_checkpoint", ",", "num_structured_layers", ",", "\n", "tie_operators_same_layer", ",", "tie_layers_A_A", ",", "tie_layers_A_B", ",", "train_fraction", ")", ":", "\n", "        ", "if", "class_type", "not", "in", "[", "'symmetric'", ",", "'polynomial_transform'", ",", "'low_rank'", ",", "'toeplitz_like'", ",", "'toep_corner'", ",", "'subdiagonal'", ",", "'toep_nocorn'", ",", "'hankel_like'", ",", "'vandermonde_like'", ",", "'unconstrained'", ",", "'circulant_sparsity'", ",", "'tridiagonal_corner'", ",", "'tridiagonal_corners'", "]", ":", "\n", "            ", "print", "(", "'Class type '", "+", "class_type", "+", "' not supported'", ")", "\n", "assert", "0", "\n", "", "self", ".", "dataset_name", "=", "dataset_name", "\n", "# grayscale", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "train_fraction", "=", "train_fraction", "\n", "self", ".", "replacement", "=", "replacement", "\n", "self", ".", "test", "=", "test", "\n", "self", ".", "early_stop_steps", "=", "early_stop_steps", "\n", "self", ".", "log_path", "=", "log_path", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "layer_size", "=", "layer_size", "\n", "self", ".", "out_size", "=", "out_size", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "loss", "=", "loss", "\n", "self", ".", "r", "=", "r", "\n", "self", ".", "fix_G", "=", "fix_G", "\n", "self", ".", "steps", "=", "steps", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "mom", "=", "mom", "\n", "self", ".", "init_type", "=", "init_type", "\n", "self", ".", "disp_type", "=", "'stein'", "\n", "if", "class_type", "==", "'toeplitz_like'", ":", "\n", "            ", "disp_type", "=", "'sylvester'", "\n", "", "self", ".", "class_type", "=", "class_type", "\n", "self", ".", "learn_corner", "=", "learn_corner", "\n", "self", ".", "n_diag_learned", "=", "n_diag_learned", "\n", "self", ".", "init_stddev", "=", "init_stddev", "\n", "self", ".", "check_disp", "=", "check_disp", "\n", "self", ".", "check_disp_freq", "=", "check_disp_freq", "\n", "self", ".", "checkpoint_freq", "=", "checkpoint_freq", "\n", "self", ".", "checkpoint_path", "=", "checkpoint_path", "\n", "self", ".", "test_freq", "=", "test_freq", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "decay_rate", "=", "decay_rate", "\n", "self", ".", "decay_freq", "=", "decay_freq", "\n", "self", ".", "learn_diagonal", "=", "learn_diagonal", "\n", "self", ".", "fix_A_identity", "=", "fix_A_identity", "\n", "self", ".", "stochastic_train", "=", "stochastic_train", "\n", "self", ".", "flip_K_B", "=", "flip_K_B", "\n", "self", ".", "num_conv_layers", "=", "num_conv_layers", "\n", "self", ".", "torch", "=", "torch", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "viz_freq", "=", "viz_freq", "\n", "self", ".", "num_pred_plot", "=", "num_pred_plot", "\n", "self", ".", "viz_powers", "=", "viz_powers", "\n", "self", ".", "test_best_val_checkpoint", "=", "test_best_val_checkpoint", "\n", "self", ".", "restore_from_checkpoint", "=", "restore_from_checkpoint", "\n", "self", ".", "num_structured_layers", "=", "num_structured_layers", "\n", "self", ".", "tie_operators_same_layer", "=", "tie_operators_same_layer", "\n", "self", ".", "tie_layers_A_A", "=", "tie_layers_A_A", "\n", "self", ".", "tie_layers_A_B", "=", "tie_layers_A_B", "\n", "# c1_filters, c1_ksize, p1_size, p1_strides, c2_filters, c2_ksize, p2_size, p2_strides", "\n", "if", "self", ".", "model", "==", "'CNN'", "or", "'cnn'", "in", "self", ".", "transform", ":", "\n", "            ", "self", ".", "set_cnn_params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model_params.ModelParams.set_cnn_params": [[74, 116], ["model_params.ModelParams.dataset_name.startswith", "model_params.ModelParams.dataset_name.startswith", "print"], "methods", ["None"], ["", "", "def", "set_cnn_params", "(", "self", ")", ":", "\n", "        ", "cnn_params", "=", "{", "}", "\n", "if", "self", ".", "dataset_name", ".", "startswith", "(", "'mnist_noise'", ")", "or", "self", ".", "dataset_name", "==", "'norb'", ":", "\n", "            ", "cnn_params", "[", "'c1_ksize'", "]", "=", "5", "\n", "cnn_params", "[", "'p1_size'", "]", "=", "2", "\n", "cnn_params", "[", "'p1_strides'", "]", "=", "2", "\n", "cnn_params", "[", "'c2_ksize'", "]", "=", "5", "\n", "cnn_params", "[", "'p2_size'", "]", "=", "2", "\n", "cnn_params", "[", "'p2_strides'", "]", "=", "2", "\n", "cnn_params", "[", "'c1_filters'", "]", "=", "6", "\n", "cnn_params", "[", "'c2_filters'", "]", "=", "16", "\n", "cnn_params", "[", "'p2_flat_size'", "]", "=", "7", "*", "7", "*", "cnn_params", "[", "'c2_filters'", "]", "\n", "self", ".", "cnn_params", "=", "cnn_params", "\n", "\n", "", "elif", "self", ".", "dataset_name", "==", "'cifar10'", ":", "\n", "            ", "cnn_params", "[", "'c1_ksize'", "]", "=", "5", "\n", "cnn_params", "[", "'p1_size'", "]", "=", "2", "\n", "cnn_params", "[", "'p1_strides'", "]", "=", "2", "\n", "cnn_params", "[", "'c2_ksize'", "]", "=", "5", "\n", "cnn_params", "[", "'p2_size'", "]", "=", "2", "\n", "cnn_params", "[", "'p2_strides'", "]", "=", "2", "\n", "cnn_params", "[", "'c1_filters'", "]", "=", "6", "\n", "cnn_params", "[", "'c2_filters'", "]", "=", "16", "\n", "cnn_params", "[", "'p2_flat_size'", "]", "=", "8", "*", "8", "*", "cnn_params", "[", "'c2_filters'", "]", "\n", "self", ".", "cnn_params", "=", "cnn_params", "\n", "\n", "", "elif", "self", ".", "dataset_name", ".", "startswith", "(", "'true'", ")", ":", "\n", "            ", "self", ".", "cnn_params", "=", "cnn_params", "\n", "\n", "", "elif", "self", ".", "dataset_name", "in", "[", "'copy'", ",", "'iwslt'", ",", "'mnist_bg_rot'", ",", "'mnist'", ",", "'convex'", "]", ":", "\n", "            ", "return", "\n", "#elif self.dataset_name.startswith('norb'):", "\n", "#    cnn_params['c1_filters'] = 9", "\n", "#    cnn_params['c2_filters'] = 9", "\n", "#    cnn_params['p1_size'] = 3", "\n", "#    cnn_params['p1_strides'] = 3", "\n", "#    cnn_params['p2_size'] = 1", "\n", "#    cnn_params['p2_strides'] = 1", "\n", "#    cnn_params['p2_flat_size'] = 9 * 9 * cnn_params['c2_filters']", "\n", "", "else", ":", "\n", "            ", "print", "(", "'dataset_name not supported: '", ",", "self", ".", "dataset_name", ")", "\n", "assert", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model_params.ModelParams.save": [[119, 137], ["print", "os.path.join", "open", "open.write", "open.close", "pickle.dump", "str", "os.path.exists", "os.makedirs", "os.path.join", "open", "str", "os.path.join", "datetime.datetime.now().strftime", "str", "datetime.datetime.now"], "methods", ["None"], ["", "", "def", "save", "(", "self", ",", "results_dir", ",", "name", ",", "commit_id", ",", "command", ")", ":", "\n", "# Append git commit ID and command", "\n", "        ", "param_str", "=", "str", "(", "commit_id", ")", "+", "'\\n'", "+", "command", "+", "'\\n'", "+", "str", "(", "self", ")", "\n", "print", "(", "param_str", ")", "\n", "\n", "# Make new dir with timestamp", "\n", "this_results_dir", "=", "os", ".", "path", ".", "join", "(", "results_dir", ",", "name", "+", "'_'", "+", "str", "(", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y-%m-%d-%H-%M-%S\"", ")", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "this_results_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "this_results_dir", ")", "\n", "\n", "", "text_file", "=", "open", "(", "os", ".", "path", ".", "join", "(", "this_results_dir", ",", "'params.txt'", ")", ",", "\"w\"", ")", "\n", "text_file", ".", "write", "(", "param_str", ")", "\n", "text_file", ".", "close", "(", ")", "\n", "\n", "# Save the dict", "\n", "pkl", ".", "dump", "(", "self", ".", "__dict__", ",", "open", "(", "os", ".", "path", ".", "join", "(", "this_results_dir", ",", "'params.p'", ")", ",", "\"wb\"", ")", ")", "\n", "\n", "return", "this_results_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model_params.ModelParams.__str__": [[138, 144], ["str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "attr_dict", "=", "self", ".", "__dict__", "\n", "param_str", "=", "''", "\n", "for", "attr", "in", "attr_dict", ":", "\n", "            ", "param_str", "+=", "attr", "+", "': '", "+", "str", "(", "attr_dict", "[", "attr", "]", ")", "+", "'\\n'", "\n", "", "return", "param_str", "\n", "", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.compare.compare": [[27, 69], ["model_params.ModelParams", "model_params.ModelParams.save", "range", "dataset.out_size", "str", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "logging.debug", "logging.debug", "logging.debug", "logging.debug", "optimize_tf.optimize_tf", "tf.reset_default_graph", "pickle.dump", "pickle.dump", "logging.debug", "str", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "open", "open", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model_params.ModelParams.save", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.out_size", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.optimize_tf.optimize_tf"], ["def", "compare", "(", "args", ",", "method", ",", "rank", ",", "lr", ",", "decay_rate", ",", "mom", ",", "train_frac", ",", "steps", ")", ":", "\n", "    ", "params", "=", "ModelParams", "(", "args", ".", "dataset", ",", "args", ".", "transform", ",", "args", ".", "test", ",", "log_path", ",", "\n", "dataset", ".", "input_size", ",", "args", ".", "layer_size", ",", "dataset", ".", "out_size", "(", ")", ",", "num_layers", ",", "\n", "loss", ",", "rank", ",", "steps", ",", "args", ".", "batch_size", ",", "lr", ",", "mom", ",", "init_type", ",", "\n", "method", ",", "learn_corner", ",", "n_diag_learned", ",", "init_stddev", ",", "fix_G", ",", "\n", "check_disp", ",", "check_disp_freq", ",", "checkpoint_freq", ",", "checkpoint_path", ",", "test_freq", ",", "verbose", ",", "\n", "decay_rate", ",", "args", ".", "decay_freq", ",", "learn_diagonal", ",", "fix_A_identity", ",", "\n", "stochastic_train", ",", "flip_K_B", ",", "num_conv_layers", ",", "args", ".", "torch", ",", "args", ".", "model", ",", "\n", "viz_freq", ",", "num_pred_plot", ",", "viz_powers", ",", "early_stop_steps", ",", "replacement", ",", "\n", "test_best_val_checkpoint", ",", "args", ".", "restore", ",", "num_structured_layers", ",", "\n", "tie_operators_same_layer", ",", "tie_layers_A_A", ",", "tie_layers_A_B", ",", "train_frac", ")", "\n", "\n", "# Save params + git commit ID", "\n", "this_id", "=", "args", ".", "name", "+", "'_'", "+", "method_map", "[", "method", "]", "+", "'_r'", "+", "str", "(", "rank", ")", "+", "'_lr'", "+", "str", "(", "lr", ")", "+", "'_dr'", "+", "str", "(", "decay_rate", ")", "+", "'_mom'", "+", "str", "(", "mom", ")", "+", "'_bs'", "+", "str", "(", "args", ".", "batch_size", ")", "+", "'_tf'", "+", "str", "(", "train_frac", ")", "+", "'_steps'", "+", "str", "(", "steps", ")", "\n", "this_results_dir", "=", "params", ".", "save", "(", "results_dir", ",", "this_id", ",", "commit_id", ",", "command", ")", "\n", "\n", "for", "test_iter", "in", "range", "(", "args", ".", "trials", ")", ":", "\n", "        ", "this_iter_name", "=", "this_id", "+", "'_'", "+", "str", "(", "test_iter", ")", "\n", "params", ".", "log_path", "=", "os", ".", "path", ".", "join", "(", "log_path", ",", "this_iter_name", ")", "\n", "params", ".", "checkpoint_path", "=", "os", ".", "path", ".", "join", "(", "checkpoint_path", ",", "this_iter_name", ")", "\n", "params", ".", "vis_path", "=", "os", ".", "path", ".", "join", "(", "vis_path", ",", "this_iter_name", ")", "\n", "params", ".", "result_path", "=", "os", ".", "path", ".", "join", "(", "this_results_dir", ",", "this_iter_name", ")", "\n", "\n", "logging", ".", "debug", "(", "'Tensorboard log path: '", "+", "params", ".", "log_path", ")", "\n", "logging", ".", "debug", "(", "'Tensorboard checkpoint path: '", "+", "params", ".", "checkpoint_path", ")", "\n", "logging", ".", "debug", "(", "'Tensorboard vis path: '", "+", "params", ".", "vis_path", ")", "\n", "logging", ".", "debug", "(", "'Results dir: '", "+", "params", ".", "result_path", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "params", ".", "checkpoint_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "params", ".", "checkpoint_path", ")", "\n", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "params", ".", "vis_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "params", ".", "vis_path", ")", "\n", "\n", "", "losses", ",", "accuracies", "=", "optimize_tf", "(", "dataset", ",", "params", ")", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "\n", "pkl", ".", "dump", "(", "losses", ",", "open", "(", "params", ".", "result_path", "+", "'_losses.p'", ",", "'wb'", ")", ",", "protocol", "=", "2", ")", "\n", "pkl", ".", "dump", "(", "accuracies", ",", "open", "(", "params", ".", "result_path", "+", "'_accuracies.p'", ",", "'wb'", ")", ",", "protocol", "=", "2", ")", "\n", "\n", "logging", ".", "debug", "(", "'Saved losses and accuracies for '", "+", "method", "+", "' to: '", "+", "params", ".", "result_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.__init__": [[14, 239], ["dataset.Dataset.get_input_size", "dataset.Dataset.set_data_locs", "print", "print", "print", "print", "sklearn.preprocessing.OneHotEncoder", "sklearn.preprocessing.OneHotEncoder.fit_transform().todense", "int", "numpy.arange", "numpy.random.shuffle", "h5py.File", "numpy.array", "scipy.loadmat", "dataset.Dataset.name.startswith", "pickle.load", "numpy.arange", "numpy.random.shuffle", "numpy.arange", "numpy.random.shuffle", "dataset.Dataset.postprocess", "dataset.Dataset.postprocess", "sklearn.preprocessing.OneHotEncoder.fit_transform", "open", "int", "int", "pickle.load", "print", "numpy.arange", "numpy.random.shuffle", "open", "tensorflow.examples.tutorials.mnist.input_data.read_data_sets", "dataset.Dataset.augment", "dataset.Dataset.load_train_data", "dataset.Dataset.name.startswith", "numpy.genfromtxt", "numpy.expand_dims", "sklearn.preprocessing.OneHotEncoder", "sklearn.preprocessing.OneHotEncoder.fit_transform().todense", "numpy.arange", "numpy.random.shuffle", "dataset.Dataset.postprocess", "dataset.Dataset.postprocess", "dataset.Dataset.load_train_data", "sklearn.preprocessing.OneHotEncoder.fit_transform", "numpy.genfromtxt", "numpy.expand_dims", "sklearn.preprocessing.OneHotEncoder", "sklearn.preprocessing.OneHotEncoder.fit_transform().todense", "numpy.arange", "numpy.random.shuffle", "dataset.Dataset.name.startswith", "utils.gen_matrix", "utils.gen_batch", "utils.gen_batch", "print", "sklearn.preprocessing.OneHotEncoder.fit_transform", "utils.gen_batch", "dataset.Dataset.name.split"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.get_input_size", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.set_data_locs", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.postprocess", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.postprocess", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.augment", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.load_train_data", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.postprocess", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.postprocess", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.load_train_data", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_matrix", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_batch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_batch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_batch"], ["\n", "def", "get_dataset", "(", "dataset_name", ",", "data_dir", ",", "transform", ")", ":", "\n", "    ", "\"\"\"\n    Get paths of datasets.\n    \"\"\"", "\n", "if", "dataset_name", "==", "'mnist'", ":", "\n", "        ", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'mnist/train_normalized'", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'mnist/test_normalized'", ")", "\n", "", "elif", "dataset_name", "==", "'cifar10'", ":", "\n", "        ", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'cifar10_combined/train'", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'cifar10_combined/test'", ")", "\n", "", "elif", "dataset_name", "==", "'cifar10mono'", ":", "\n", "        ", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'cifar10_combined/train_grayscale'", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'cifar10_combined/test_grayscale'", ")", "\n", "", "elif", "dataset_name", ".", "startswith", "(", "'mnist_noise'", ")", ":", "\n", "        ", "idx", "=", "dataset_name", "[", "-", "1", "]", "\n", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'mnist_noise/train_'", "+", "str", "(", "idx", ")", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'mnist_noise/test_'", "+", "str", "(", "idx", ")", ")", "\n", "", "elif", "dataset_name", "==", "'norb'", ":", "\n", "        ", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'norb_full/processed_py2_train_32.pkl'", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'norb_full/processed_py2_test_32.pkl'", ")", "\n", "", "elif", "dataset_name", "==", "'rect_images'", ":", "#TODO", "\n", "        ", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'rect_images/rectangles_im_train.amat'", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'rect_images/rectangles_im_test.amat'", ")", "\n", "", "elif", "dataset_name", "==", "'rect'", ":", "\n", "        ", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'rect/train_normalized'", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'rect/test_normalized'", ")", "\n", "", "elif", "dataset_name", "==", "'convex'", ":", "\n", "        ", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'convex/train_normalized'", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'convex/test_normalized'", ")", "\n", "", "elif", "dataset_name", "==", "'mnist_rand_bg'", ":", "#TODO", "\n", "        ", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'mnist_rand_bg/mnist_background_random_train.amat'", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'mnist_rand_bg/mnist_background_random_test.amat'", ")", "\n", "", "elif", "dataset_name", "==", "'mnist_bg_rot'", ":", "\n", "        ", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'mnist_bg_rot/train_normalized'", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'mnist_bg_rot/test_normalized'", ")", "\n", "", "elif", "dataset_name", "==", "'mnist_bg_rot_swap'", ":", "\n", "        ", "train_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'mnist_bg_rot/test_normalized'", ")", "\n", "test_loc", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'mnist_bg_rot/train_normalized'", ")", "\n", "#TODO handle iwslt, copy tasks", "\n", "# TODO smallnorb, timit", "\n", "", "else", ":", "\n", "        ", "print", "(", "'dataset.py: unknown dataset name'", ")", "\n", "\n", "# TODO maybe want the .amat if that's standard and do postprocessing in a uniform way instead of having a separate script per dataset", "\n", "", "train_data", "=", "pkl", ".", "load", "(", "open", "(", "train_loc", ",", "'rb'", ")", ")", "\n", "train_X", "=", "train_data", "[", "'X'", "]", "\n", "train_Y", "=", "train_data", "[", "'Y'", "]", "\n", "test_data", "=", "pkl", ".", "load", "(", "open", "(", "test_loc", ",", "'rb'", ")", ")", "\n", "test_X", "=", "test_data", "[", "'X'", "]", "\n", "test_Y", "=", "test_data", "[", "'Y'", "]", "\n", "\n", "train_X", ",", "train_Y", "=", "postprocess", "(", "transform", ",", "train_X", ",", "train_Y", ")", "\n", "test_X", ",", "test_Y", "=", "postprocess", "(", "transform", ",", "test_X", ",", "test_Y", ")", "\n", "\n", "in_size", "=", "train_X", ".", "shape", "[", "1", "]", "\n", "out_size", "=", "train_Y", ".", "shape", "[", "1", "]", "\n", "\n", "print", "(", "\"Train dataset size: \"", ",", "train_X", ".", "shape", "[", "0", "]", ")", "\n", "print", "(", "\"Test dataset size: \"", ",", "test_X", ".", "shape", "[", "0", "]", ")", "\n", "print", "(", "\"In size: \"", ",", "in_size", ")", "\n", "print", "(", "\"Out size: \"", ",", "out_size", ")", "\n", "\n", "return", "torch", ".", "FloatTensor", "(", "train_X", ")", ",", "torch", ".", "FloatTensor", "(", "train_Y", ")", ",", "torch", ".", "FloatTensor", "(", "test_X", ")", ",", "torch", ".", "FloatTensor", "(", "test_Y", ")", ",", "in_size", ",", "out_size", "\n", "\n", "", "def", "split_train_val", "(", "train_X", ",", "train_Y", ",", "val_fraction", ",", "train_fraction", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Input: training data as a torch.Tensor\n    \"\"\"", "\n", "# Shuffle", "\n", "idx", "=", "np", ".", "arange", "(", "train_X", ".", "shape", "[", "0", "]", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "idx", ")", "\n", "train_X", "=", "train_X", "[", "idx", ",", ":", "]", "\n", "train_Y", "=", "train_Y", "[", "idx", ",", ":", "]", "\n", "\n", "# Compute validation set size", "\n", "val_size", "=", "int", "(", "val_fraction", "*", "train_X", ".", "shape", "[", "0", "]", ")", "\n", "\n", "# Downsample for sample complexity experiments", "\n", "if", "train_fraction", "is", "not", "None", ":", "\n", "        ", "train_size", "=", "int", "(", "train_fraction", "*", "train_X", ".", "shape", "[", "0", "]", ")", "\n", "assert", "val_size", "+", "train_size", "<=", "train_X", ".", "shape", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "train_size", "=", "train_X", ".", "shape", "[", "0", "]", "-", "val_size", "\n", "\n", "# Shuffle X", "\n", "", "idx", "=", "np", ".", "arange", "(", "0", ",", "train_X", ".", "shape", "[", "0", "]", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "idx", ")", "\n", "\n", "train_idx", "=", "idx", "[", "0", ":", "train_size", "]", "\n", "val_idx", "=", "idx", "[", "-", "val_size", ":", "]", "\n", "val_X", "=", "train_X", "[", "val_idx", ",", ":", "]", "\n", "val_Y", "=", "train_Y", "[", "val_idx", ",", ":", "]", "\n", "train_X", "=", "train_X", "[", "train_idx", ",", ":", "]", "\n", "train_Y", "=", "train_Y", "[", "train_idx", ",", ":", "]", "\n", "\n", "print", "(", "'train_X: '", ",", "train_X", ".", "shape", ")", "\n", "print", "(", "'train_Y: '", ",", "train_Y", ".", "shape", ")", "\n", "print", "(", "'val_X: '", ",", "val_X", ".", "shape", ")", "\n", "print", "(", "'val_Y: '", ",", "val_Y", ".", "shape", ")", "\n", "\n", "\n", "return", "train_X", ",", "train_Y", ",", "val_X", ",", "val_Y", "\n", "\n", "\n", "\n", "", "def", "create_data_loaders", "(", "dataset_name", ",", "data_dir", ",", "transform", ",", "train_fraction", ",", "val_fraction", ",", "batch_size", ")", ":", "\n", "    ", "if", "device", ".", "type", "==", "'cuda'", ":", "\n", "        ", "loader_args", "=", "{", "'num_workers'", ":", "16", ",", "'pin_memory'", ":", "True", "}", "\n", "", "else", ":", "\n", "        ", "loader_args", "=", "{", "'num_workers'", ":", "4", ",", "'pin_memory'", ":", "False", "}", "\n", "\n", "", "train_X", ",", "train_Y", ",", "test_X", ",", "test_Y", ",", "in_size", ",", "out_size", "=", "get_dataset", "(", "dataset_name", ",", "data_dir", ",", "transform", ")", "# train/test data, input/output size", "\n", "# train_X, train_Y = postprocess(transform, train_X, train_Y)", "\n", "# test_X, test_Y = postprocess(transform, test_X, test_Y)", "\n", "\n", "# TODO: use torch.utils.data.random_split instead", "\n", "# however, this requires creating the dataset, then splitting, then applying transformations", "\n", "train_X", ",", "train_Y", ",", "val_X", ",", "val_Y", "=", "split_train_val", "(", "train_X", ",", "train_Y", ",", "val_fraction", ",", "train_fraction", ")", "\n", "\n", "\n", "# TODO: use pytorch transforms to postprocess", "\n", "\n", "train_dataset", "=", "torch", ".", "utils", ".", "data", ".", "TensorDataset", "(", "train_X", ",", "train_Y", ")", "\n", "val_dataset", "=", "torch", ".", "utils", ".", "data", ".", "TensorDataset", "(", "val_X", ",", "val_Y", ")", "\n", "test_dataset", "=", "torch", ".", "utils", ".", "data", ".", "TensorDataset", "(", "test_X", ",", "test_Y", ")", "\n", "# create dataloaders", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ",", "**", "loader_args", ")", "\n", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "val_dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ",", "**", "loader_args", ")", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ",", "**", "loader_args", ")", "\n", "\n", "return", "train_loader", ",", "val_loader", ",", "test_loader", ",", "in_size", ",", "out_size", "\n", "\n", "\n", "", "class", "DatasetLoaders", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "name", ",", "data_dir", ",", "val_fraction", ",", "transform", "=", "None", ",", "train_fraction", "=", "None", ",", "batch_size", "=", "50", ")", ":", "\n", "        ", "if", "name", ".", "startswith", "(", "'true'", ")", ":", "\n", "# TODO: Add support for synthetic datasets back. Possibly should be split into separate class", "\n", "            ", "self", ".", "loss", "=", "utils", ".", "mse_loss", "\n", "", "else", ":", "\n", "            ", "self", ".", "train_loader", ",", "self", ".", "val_loader", ",", "self", ".", "test_loader", ",", "self", ".", "in_size", ",", "self", ".", "out_size", "=", "create_data_loaders", "(", "name", ",", "\n", "data_dir", ",", "transform", ",", "train_fraction", ",", "val_fraction", ",", "batch_size", ")", "\n", "self", ".", "loss", "=", "utils", ".", "cross_entropy_loss", "\n", "\n", "\n", "\n", "\n", "\n", "### Utilities for processing data arrays in numpy", "\n", "", "", "", "def", "postprocess", "(", "transform", ",", "X", ",", "Y", "=", "None", ")", ":", "\n", "# pad from 784 to 1024", "\n", "    ", "if", "'pad'", "in", "transform", ":", "\n", "        ", "assert", "X", ".", "shape", "[", "1", "]", "==", "784", "\n", "print", "(", "X", ".", "shape", ",", "type", "(", "X", ")", ")", "\n", "X", "=", "np", ".", "pad", "(", "X", ".", "reshape", "(", "(", "-", "1", ",", "28", ",", "28", ")", ")", ",", "(", "(", "0", ",", "0", ")", ",", "(", "2", ",", "2", ")", ",", "(", "2", ",", "2", ")", ")", ",", "'constant'", ")", ".", "reshape", "(", "-", "1", ",", "1024", ")", "\n", "", "if", "'randomize'", "in", "transform", ":", "\n", "        ", "assert", "Y", "is", "not", "None", "\n", "np", ".", "random", ".", "shuffle", "(", "Y", ")", "\n", "", "return", "X", ",", "Y", "\n", "\n", "", "def", "augment", "(", "self", ",", "X", ",", "Y", "=", "None", ")", ":", "\n", "    ", "if", "'contrast'", "in", "self", ".", "transform", ":", "\n", "        ", "def", "scale_patch", "(", "X", ")", ":", "\n", "            ", "patch", "=", "(", "(", "9", ",", "19", ")", ",", "(", "9", ",", "19", ")", ")", "\n", "X_", "=", "X", ".", "copy", "(", ")", "\n", "X_", "[", ":", ",", "patch", "[", "0", "]", "[", "0", "]", ":", "patch", "[", "0", "]", "[", "1", "]", ",", "patch", "[", "1", "]", "[", "0", "]", ":", "patch", "[", "1", "]", "[", "1", "]", "]", "*=", "2", "\n", "return", "X_", "\n", "# subsample", "\n", "", "idx", "=", "np", ".", "arange", "(", "X", ".", "shape", "[", "0", "]", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "idx", ")", "\n", "X", "=", "X", "[", "idx", ",", "...", "]", "\n", "Y", "=", "Y", "[", "idx", ",", "...", "]", "\n", "\n", "X1", "=", "X", ".", "reshape", "(", "(", "-", "1", ",", "28", ",", "28", ")", ")", "\n", "X2", "=", "scale_patch", "(", "X1", ")", "\n", "X3", "=", "scale_patch", "(", "X2", ")", "\n", "X4", "=", "scale_patch", "(", "X3", ")", "\n", "# X5 = scale_patch(X4)", "\n", "X", "=", "np", ".", "concatenate", "(", "[", "X1", ",", "X2", ",", "X3", ",", "X4", "]", ",", "axis", "=", "0", ")", ".", "reshape", "(", "-", "1", ",", "28", "*", "28", ")", "\n", "Y", "=", "np", ".", "concatenate", "(", "[", "Y", ",", "Y", ",", "Y", ",", "Y", "]", ",", "axis", "=", "0", ")", "\n", "\n", "", "if", "'patch'", "in", "self", ".", "transform", ":", "\n", "        ", "def", "add_patch", "(", "X", ")", ":", "\n", "            ", "patch", "=", "(", "(", "0", ",", "4", ")", ",", "(", "10", ",", "18", ")", ")", "\n", "X_", "=", "X", ".", "copy", "(", ")", "\n", "X_", "[", ":", ",", "patch", "[", "0", "]", "[", "0", "]", ":", "patch", "[", "0", "]", "[", "1", "]", ",", "patch", "[", "1", "]", "[", "0", "]", ":", "patch", "[", "1", "]", "[", "1", "]", "]", "+=", "3.0", "\n", "return", "X_", "\n", "", "X1", "=", "X", ".", "reshape", "(", "(", "-", "1", ",", "28", ",", "28", ")", ")", "\n", "X2", "=", "add_patch", "(", "X1", ")", "\n", "X3", "=", "add_patch", "(", "X2", ")", "\n", "X4", "=", "add_patch", "(", "X3", ")", "\n", "X", "=", "np", ".", "concatenate", "(", "[", "X1", ",", "X2", ",", "X3", ",", "X4", "]", ",", "axis", "=", "0", ")", ".", "reshape", "(", "-", "1", ",", "28", "*", "28", ")", "\n", "Y", "=", "np", ".", "concatenate", "(", "[", "Y", ",", "Y", ",", "Y", ",", "Y", "]", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "X", ",", "Y", "\n", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.print_dataset_stats": [[241, 250], ["print", "print", "print", "print", "numpy.mean", "numpy.std", "numpy.min", "numpy.max", "numpy.mean", "numpy.std", "numpy.min", "numpy.max", "print", "print", "numpy.mean", "numpy.std", "numpy.min", "numpy.max"], "methods", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.set_data_locs": [[251, 288], ["os.path.join", "os.path.join", "dataset.Dataset.name.startswith", "os.path.join", "os.path.join", "dataset.Dataset.name.startswith", "os.path.join", "os.path.join", "str", "str", "os.path.join", "os.path.join", "str", "str", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.get_input_size": [[289, 312], ["dataset.Dataset.name.startswith", "print"], "methods", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.postprocess": [[313, 321], ["numpy.pad().reshape", "numpy.pad", "numpy.pad().reshape.reshape"], "methods", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.augment": [[322, 357], ["numpy.arange", "numpy.random.shuffle", "numpy.concatenate().reshape.reshape", "dataset.Dataset.augment.scale_patch"], "methods", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.out_size": [[358, 371], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.load_test_data": [[372, 407], ["dataset.Dataset.postprocess", "print", "print", "print", "numpy.array", "print", "sklearn.preprocessing.OneHotEncoder", "sklearn.preprocessing.OneHotEncoder.fit_transform().todense", "print", "scipy.loadmat", "scipy.loadmat", "sklearn.preprocessing.OneHotEncoder.fit_transform", "dataset.Dataset.name.startswith", "pickle.load", "open", "numpy.genfromtxt", "numpy.expand_dims", "sklearn.preprocessing.OneHotEncoder", "sklearn.preprocessing.OneHotEncoder.fit_transform().todense", "sklearn.preprocessing.OneHotEncoder.fit_transform"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.postprocess"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.load_train_data": [[409, 418], ["numpy.genfromtxt", "numpy.expand_dims", "sklearn.preprocessing.OneHotEncoder", "sklearn.preprocessing.OneHotEncoder.fit_transform().todense", "sklearn.preprocessing.OneHotEncoder.fit_transform"], "methods", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.update_batch_idx": [[419, 423], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.next_batch": [[425, 439], ["min", "dataset.Dataset.update_batch_idx", "numpy.arange", "numpy.random.shuffle", "print"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.update_batch_idx"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.batch": [[440, 445], ["dataset.Dataset.sample_with_replacement", "dataset.Dataset.sample_without_replacement"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.sample_with_replacement", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.sample_without_replacement"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.sample_with_replacement": [[446, 464], ["dataset.Dataset.name.startswith", "dataset.Dataset.name.startswith", "numpy.random.randint", "dataset.Dataset.name.startswith", "print", "utils.gen_batch", "dataset.Dataset.next_batch"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_batch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.next_batch"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.sample_without_replacement": [[465, 482], ["dataset.Dataset.name.startswith", "dataset.Dataset.name.startswith", "dataset.Dataset.next_batch", "dataset.Dataset.name.startswith", "print", "utils.gen_batch", "dataset.Dataset.next_batch"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.next_batch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_batch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.next_batch"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.compare_parallel.create_command": [[15, 19], ["None"], "function", ["None"], ["def", "create_command", "(", "args", ",", "method", ",", "rank", ",", "lr", ",", "decay_rate", ",", "mom", ")", ":", "\n", "\t", "command", "=", "'python compare.py --name=%s --methods=%s --dataset=%s --result_dir=%s --r=%s --lr=%s --decay_rate=%s --decay_freq=%s --mom=%s --steps=%s --batch_size=%s --test=%s --layer_size=%s --transform=%s --torch=%s --model=%s'", "\n", "\n", "return", "command", "%", "(", "args", ".", "name", ",", "method", ",", "args", ".", "dataset", ",", "args", ".", "result_dir", ",", "rank", ",", "lr", ",", "decay_rate", ",", "args", ".", "decay_freq", ",", "mom", ",", "args", ".", "steps", ",", "args", ".", "batch_size", ",", "args", ".", "test", ",", "args", ".", "layer_size", ",", "args", ".", "transform", ",", "args", ".", "torch", ",", "args", ".", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.check_rank": [[9, 125], ["print", "print", "print", "numpy.abs", "numpy.abs", "numpy.abs", "numpy.abs", "utils.gen_operators", "sess.run", "print", "utils.compute_disp", "numpy.linalg.matrix_rank", "numpy.linalg.norm", "numpy.linalg.norm", "numpy.linalg.eigvals", "numpy.linalg.eigvals", "numpy.linalg.eigvals", "numpy.linalg.eigvals", "sess.run", "sess.run", "print", "print", "numpy.linalg.matrix_rank", "sess.run", "sess.run", "sess.run", "sess.run", "sess.run", "sess.run", "sess.run", "sess.run", "utils.gen_tridiag_corner", "sess.run", "utils.compute_disp", "numpy.linalg.matrix_rank", "numpy.linalg.norm", "numpy.linalg.norm", "utils.gen_tridiag_corner", "sess.run", "sess.run", "utils.gen_Z_f", "sess.run", "utils.compute_disp", "numpy.linalg.matrix_rank", "numpy.linalg.norm", "numpy.linalg.norm", "numpy.eye", "sess.run", "sess.run", "utils.gen_tridiag_corners", "sess.run", "utils.compute_disp", "numpy.linalg.matrix_rank", "numpy.linalg.norm", "numpy.linalg.norm", "utils.gen_Z_f", "utils.gen_tridiag_corners", "sess.run", "numpy.linalg.matrix_rank", "numpy.linalg.norm", "sess.run", "numpy.diag", "utils.compute_disp", "numpy.linalg.matrix_rank", "numpy.linalg.norm", "numpy.linalg.norm", "print", "utils.gen_Z_f"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_operators", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.compute_disp", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_tridiag_corner", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.compute_disp", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_tridiag_corner", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.compute_disp", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_tridiag_corners", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.compute_disp", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_tridiag_corners", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.compute_disp", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f"], ["import", "sys", "\n", "from", "lstm", "import", "SingleLayerLSTM", ",", "LSTMCell", "\n", "\n", "class", "RNNModel", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Container module with an encoder, a recurrent module, and a decoder.\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ",", "class_type", ",", "r", ",", "rnn_type", ",", "ntoken", ",", "ninp", ",", "nhid", ",", "nlayers", ",", "dropout", "=", "0.5", ",", "tie_weights", "=", "False", ")", ":", "\n", "        ", "super", "(", "RNNModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "encoder", "=", "nn", ".", "Embedding", "(", "ntoken", ",", "ninp", ")", "\n", "if", "rnn_type", "in", "[", "'LSTM'", ",", "'GRU'", "]", ":", "\n", "            ", "print", "(", "'ninp, nhid, nlayers: '", ",", "ninp", ",", "nhid", ",", "nlayers", ")", "\n", "if", "rnn_type", "==", "'LSTM'", ":", "\n", "                ", "self", ".", "rnn", "=", "SingleLayerLSTM", "(", "class_type", ",", "r", ",", "input_size", "=", "ninp", ",", "hidden_size", "=", "nhid", ",", "dropout", "=", "dropout", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "rnn", "=", "getattr", "(", "nn", ",", "rnn_type", ")", "(", "ninp", ",", "nhid", ",", "nlayers", ",", "dropout", "=", "dropout", ")", "\n", "", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "nonlinearity", "=", "{", "'RNN_TANH'", ":", "'tanh'", ",", "'RNN_RELU'", ":", "'relu'", "}", "[", "rnn_type", "]", "\n", "", "except", "KeyError", ":", "\n", "                ", "raise", "ValueError", "(", "\"\"\"An invalid option for `--model` was supplied,\n                                 options are ['LSTM', 'GRU', 'RNN_TANH' or 'RNN_RELU']\"\"\"", ")", "\n", "", "self", ".", "rnn", "=", "nn", ".", "RNN", "(", "ninp", ",", "nhid", ",", "nlayers", ",", "nonlinearity", "=", "nonlinearity", ",", "dropout", "=", "dropout", ")", "\n", "", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "nhid", ",", "ntoken", ")", "\n", "\n", "# Optionally tie weights as in:", "\n", "# \"Using the Output Embedding to Improve Language Models\" (Press & Wolf 2016)", "\n", "# https://arxiv.org/abs/1608.05859", "\n", "# and", "\n", "# \"Tying Word Vectors and Word Classifiers: A Loss Framework for Language Modeling\" (Inan et al. 2016)", "\n", "# https://arxiv.org/abs/1611.01462", "\n", "if", "tie_weights", ":", "\n", "            ", "if", "nhid", "!=", "ninp", ":", "\n", "                ", "raise", "ValueError", "(", "'When using the tied flag, nhid must be equal to emsize'", ")", "\n", "", "self", ".", "decoder", ".", "weight", "=", "self", ".", "encoder", ".", "weight", "\n", "\n", "", "self", ".", "init_weights", "(", ")", "\n", "\n", "self", ".", "rnn_type", "=", "rnn_type", "\n", "self", ".", "nhid", "=", "nhid", "\n", "self", ".", "nlayers", "=", "nlayers", "\n", "\n", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "self", ".", "encoder", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "decoder", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "self", ".", "decoder", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "input", ",", "hidden", ")", ":", "\n", "        ", "emb", "=", "self", ".", "drop", "(", "self", ".", "encoder", "(", "input", ")", ")", "\n", "output", ",", "hidden", "=", "self", ".", "rnn", "(", "emb", ",", "hx", "=", "hidden", ")", "\n", "output", "=", "output", ".", "squeeze", "(", ")", "\n", "hidden", "=", "(", "hidden", "[", "0", "]", ".", "squeeze", "(", "0", ")", ",", "hidden", "[", "1", "]", ".", "squeeze", "(", "0", ")", ")", "\n", "output", "=", "self", ".", "drop", "(", "output", ")", "\n", "decoded", "=", "self", ".", "decoder", "(", "output", ".", "view", "(", "output", ".", "size", "(", "0", ")", "*", "output", ".", "size", "(", "1", ")", ",", "output", ".", "size", "(", "2", ")", ")", ")", "\n", "return", "decoded", ".", "view", "(", "output", ".", "size", "(", "0", ")", ",", "output", ".", "size", "(", "1", ")", ",", "decoded", ".", "size", "(", "1", ")", ")", ",", "hidden", "\n", "\n", "", "def", "init_hidden", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "weight", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", "\n", "if", "self", ".", "rnn_type", "==", "'LSTM'", ":", "\n", "            ", "return", "(", "weight", ".", "new_zeros", "(", "self", ".", "nlayers", ",", "bsz", ",", "self", ".", "nhid", ")", ",", "\n", "weight", ".", "new_zeros", "(", "self", ".", "nlayers", ",", "bsz", ",", "self", ".", "nhid", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "weight", ".", "new_zeros", "(", "self", ".", "nlayers", ",", "bsz", ",", "self", ".", "nhid", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.get_structured_W": [[126, 302], ["tensorflow.Variable", "tensorflow.truncated_normal", "tensorflow.Variable", "tensorflow.Variable", "print", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "tensorflow.matmul", "tensorflow.transpose", "utils.symm_tridiag_corner_mask", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.multiply", "tensorflow.multiply", "reconstruction.general_recon", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "functools.partial", "functools.partial", "reconstruction.krylov_recon", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "tensorflow.reduce_prod", "tensorflow.reduce_prod", "utils.gen_Z_f", "utils.gen_Z_f", "numpy.random.random", "numpy.random.random", "tensorflow.Variable", "tensorflow.matrix_band_part", "tensorflow.Variable", "tensorflow.matrix_band_part", "reconstruction.general_recon", "reconstruction.toeplitz_like_recon", "tensorflow.transpose", "tensorflow.transpose", "utils.gen_Z_f", "reconstruction.rect_recon_tf", "tensorflow.Variable", "reconstruction.vand_recon", "tensorflow.truncated_normal", "utils.get_x_f", "reconstruction.krylov_recon", "tensorflow.reduce_prod", "tensorflow.reduce_prod", "tensorflow.scalar_mul", "tensorflow.Variable", "tensorflow.Variable", "functools.partial", "functools.partial", "utils.get_tridiag_corners_vars", "functools.partial", "functools.partial", "reconstruction.krylov_recon", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.zeros", "tensorflow.zeros", "print", "functools.partial", "functools.partial", "functools.partial", "tensorflow.reduce_prod", "tensorflow.reduce_prod", "utils.get_tridiag_corner_vars", "functools.partial", "functools.partial", "reconstruction.krylov_recon", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.reduce_prod", "tensorflow.reduce_prod"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.symm_tridiag_corner_mask", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.general_recon", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.krylov_recon", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.general_recon", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.toeplitz_like_recon", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.rect_recon_tf", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.vand_recon", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_x_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.krylov_recon", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_tridiag_corners_vars", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.krylov_recon", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_tridiag_corner_vars", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.krylov_recon"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.forward": [[303, 307], ["model.get_structured_W", "model.compute_y"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.get_structured_W", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.compute_y"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.compute_y": [[308, 327], ["utils.compute_y_cnn", "tensorflow.matmul", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.matmul", "tensorflow.nn.relu", "tensorflow.matmul", "tensorflow.add", "print", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "tensorflow.truncated_normal"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.compute_y_cnn"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.visualize.show_learned_operators": [[27, 46], ["matplotlib.clf", "matplotlib.subplots", "plots[].imshow", "plots[].set_title", "plots[].imshow", "plots[].set_title", "plots[].imshow", "plots[].set_title", "plots[].axis", "plots[].axis", "plots[].axis", "matplotlib.savefig", "matplotlib.close", "os.path.join", "str"], "function", ["None"], ["def", "show_learned_operators", "(", "vis_path", ",", "A", ",", "B", ",", "W", ",", "step", ")", ":", "\n", "    ", "\"\"\"\n    print('A: ', A.shape)\n    print('B: ', B.shape)\n    print('W: ', W.shape)\n    \"\"\"", "\n", "plt", ".", "clf", "(", ")", "\n", "f", ",", "plots", "=", "plt", ".", "subplots", "(", "3", ",", "figsize", "=", "(", "5", ",", "15", ")", ")", "\n", "plots", "[", "0", "]", ".", "imshow", "(", "A", ")", "\n", "plots", "[", "0", "]", ".", "set_title", "(", "'A'", ")", "\n", "plots", "[", "1", "]", ".", "imshow", "(", "B", ")", "\n", "plots", "[", "1", "]", ".", "set_title", "(", "'B'", ")", "\n", "plots", "[", "2", "]", ".", "imshow", "(", "W", ")", "\n", "plots", "[", "2", "]", ".", "set_title", "(", "'W'", ")", "\n", "plots", "[", "0", "]", ".", "axis", "(", "'off'", ")", "\n", "plots", "[", "1", "]", ".", "axis", "(", "'off'", ")", "\n", "plots", "[", "2", "]", ".", "axis", "(", "'off'", ")", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "vis_path", ",", "str", "(", "step", ")", "+", "'_A_B_W.png'", ")", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.visualize.show_prediction": [[48, 84], ["matplotlib.clf", "matplotlib.subplots", "range", "plots[].imshow", "range", "matplotlib.savefig", "matplotlib.close", "range", "str", "plots[].set_title", "plots[].set_title", "len", "[].reshape", "[].reshape", "[].reshape", "plots[].imshow", "plots[].set_title", "plots[].imshow", "plots[].set_title", "plots[].imshow", "plots[].set_title", "os.path.join", "len", "len", "plots[].axis", "str", "str", "str", "str", "str", "str", "str"], "function", ["None"], ["", "def", "show_prediction", "(", "vis_path", ",", "idx", ",", "viz_powers", ",", "image", ",", "true", ",", "pred", ",", "Bis", ",", "GHTBis", ",", "AiGHTBis", ",", "step", ")", ":", "\n", "    ", "plt", ".", "clf", "(", ")", "\n", "f", ",", "plots", "=", "plt", ".", "subplots", "(", "len", "(", "viz_powers", ")", "+", "1", ",", "ncols", ",", "figsize", "=", "(", "20", ",", "20", ")", ")", "\n", "\n", "for", "row", "in", "range", "(", "len", "(", "viz_powers", ")", "+", "1", ")", ":", "\n", "        ", "for", "col", "in", "range", "(", "ncols", ")", ":", "\n", "            ", "plots", "[", "row", ",", "col", "]", ".", "axis", "(", "'off'", ")", "\n", "\n", "", "", "plots", "[", "0", ",", "1", "]", ".", "imshow", "(", "image", ")", "\n", "caption", "=", "'Orig. Im., True: '", "+", "str", "(", "true", ")", "+", "'; Pred: '", "+", "str", "(", "pred", ")", "\n", "if", "true", "==", "pred", ":", "\n", "        ", "plots", "[", "0", ",", "1", "]", ".", "set_title", "(", "caption", ",", "color", "=", "'green'", ")", "\n", "", "else", ":", "\n", "        ", "plots", "[", "0", ",", "1", "]", ".", "set_title", "(", "caption", ",", "color", "=", "'red'", ")", "\n", "\n", "", "for", "row", "in", "range", "(", "len", "(", "viz_powers", ")", ")", ":", "\n", "        ", "Bi", "=", "Bis", "[", "row", "]", "[", "idx", ",", ":", "]", ".", "reshape", "(", "(", "image", ".", "shape", "[", "0", "]", ",", "image", ".", "shape", "[", "1", "]", ")", ")", "\n", "GHTBi", "=", "GHTBis", "[", "row", "]", "[", "idx", ",", ":", "]", ".", "reshape", "(", "(", "image", ".", "shape", "[", "0", "]", ",", "image", ".", "shape", "[", "1", "]", ")", ")", "\n", "AiGHTBi", "=", "AiGHTBis", "[", "row", "]", "[", "idx", ",", ":", "]", ".", "reshape", "(", "(", "image", ".", "shape", "[", "0", "]", ",", "image", ".", "shape", "[", "1", "]", ")", ")", "\n", "\n", "plots", "[", "row", "+", "1", ",", "0", "]", ".", "imshow", "(", "Bi", ")", "\n", "plots", "[", "row", "+", "1", ",", "0", "]", ".", "set_title", "(", "r'$B^{'", "+", "str", "(", "viz_powers", "[", "row", "]", ")", "+", "'}x$'", ",", "color", "=", "'green'", ")", "\n", "plots", "[", "row", "+", "1", ",", "1", "]", ".", "imshow", "(", "GHTBi", ")", "\n", "plots", "[", "row", "+", "1", ",", "1", "]", ".", "set_title", "(", "r'$GH^TB^{'", "+", "str", "(", "viz_powers", "[", "row", "]", ")", "+", "'}x$'", ",", "color", "=", "'green'", ")", "\n", "plots", "[", "row", "+", "1", ",", "2", "]", ".", "imshow", "(", "AiGHTBi", ")", "\n", "plots", "[", "row", "+", "1", ",", "2", "]", ".", "set_title", "(", "r'$A^{'", "+", "str", "(", "viz_powers", "[", "row", "]", ")", "+", "'}GH^TB^{'", "+", "str", "(", "viz_powers", "[", "row", "]", ")", "+", "'}x$'", ",", "color", "=", "'green'", ")", "\n", "\n", "", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "vis_path", ",", "str", "(", "step", ")", "+", "'_predictions_'", "+", "str", "(", "idx", ")", "+", "'.png'", ")", ")", "\n", "\"\"\"\n    plt.savefig(ram,format='png')\n    ram.seek(0)\n    im = Image.open(ram)\n    im2 = im.convert('RGB').convert('P', palette=Image.ADAPTIVE)\n    im2.save('predictions' + str(idx) + '.png', format='PNG')\n    \"\"\"", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.visualize.show_predictions": [[85, 109], ["numpy.sqrt", "int", "len", "matplotlib.subplots", "range", "print", "x[].reshape", "time.time", "visualize.show_prediction", "time.time"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.visualize.show_prediction"], ["", "def", "show_predictions", "(", "vis_path", ",", "step", ",", "num_pred_plot", ",", "layer_size", ",", "viz_powers", ",", "x", ",", "y", ",", "pred", ",", "Bis", ",", "GHTBis", ",", "AiGHTBis", ")", ":", "\n", "    ", "assert", "num_pred_plot", "==", "x", ".", "shape", "[", "0", "]", "==", "y", ".", "size", "==", "pred", ".", "size", "\n", "img_size", "=", "np", ".", "sqrt", "(", "layer_size", ")", "\n", "assert", "img_size", ".", "is_integer", "\n", "img_size", "=", "int", "(", "img_size", ")", "\n", "nrows", "=", "len", "(", "viz_powers", ")", "\n", "\n", "f", ",", "plots", "=", "plt", ".", "subplots", "(", "num_pred_plot", ",", "ncols", ",", "figsize", "=", "(", "20", ",", "20", ")", ")", "\n", "times", "=", "0", "\n", "\n", "for", "idx", "in", "range", "(", "num_pred_plot", ")", ":", "\n", "        ", "this_image", "=", "x", "[", "idx", "]", ".", "reshape", "(", "(", "img_size", ",", "img_size", ")", ")", "\n", "\n", "# Get correct", "\n", "this_true", "=", "y", "[", "idx", "]", "\n", "\n", "# Get predicted", "\n", "this_pred", "=", "pred", "[", "idx", "]", "\n", "\n", "t1", "=", "time", ".", "time", "(", ")", "\n", "show_prediction", "(", "vis_path", ",", "idx", ",", "viz_powers", ",", "this_image", ",", "this_true", ",", "\n", "this_pred", ",", "Bis", ",", "GHTBis", ",", "AiGHTBis", ",", "step", ")", "\n", "times", "+=", "(", "time", ".", "time", "(", ")", "-", "t1", ")", "\n", "", "print", "(", "'Average time of show_prediction: '", ",", "times", "/", "num_pred_plot", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.visualize.visualize_predictions": [[110, 112], ["visualize.show_predictions"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.visualize.show_predictions"], ["", "def", "visualize_predictions", "(", "params", ",", "x", ",", "y", ",", "pred", ")", ":", "\n", "    ", "return", "show_predictions", "(", "params", ".", "num_pred_plot", ",", "params", ".", "layer_size", ",", "x", ",", "y", ",", "pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.visualize.compute_powers": [[113, 133], ["numpy.linalg.matrix_power", "numpy.linalg.matrix_power", "numpy.dot", "numpy.dot", "Bis.append", "GHTBis.append", "AiGHTBis.append", "numpy.dot", "numpy.dot", "numpy.dot"], "function", ["None"], ["", "def", "compute_powers", "(", "powers", ",", "A", ",", "GHT", ",", "B", ",", "x", ")", ":", "\n", "    ", "Bis", "=", "[", "]", "\n", "GHTBis", "=", "[", "]", "\n", "AiGHTBis", "=", "[", "]", "\n", "\n", "for", "power", "in", "powers", ":", "\n", "        ", "A_i", "=", "np", ".", "linalg", ".", "matrix_power", "(", "A", ",", "power", ")", "\n", "B_i", "=", "np", ".", "linalg", ".", "matrix_power", "(", "B", ",", "power", ")", "\n", "#print('B_i: ', B_i)", "\n", "GHTB_i", "=", "np", ".", "dot", "(", "GHT", ",", "B_i", ")", "\n", "A_iGHTB_i", "=", "np", ".", "dot", "(", "A_i", ",", "GHTB_i", ")", "\n", "Bis", ".", "append", "(", "np", ".", "dot", "(", "B_i", ",", "x", ".", "T", ")", ".", "T", ")", "\n", "\n", "#print('x: ', x)", "\n", "#print('B_ix: ', Bis[-1])", "\n", "\n", "GHTBis", ".", "append", "(", "np", ".", "dot", "(", "GHTB_i", ",", "x", ".", "T", ")", ".", "T", ")", "\n", "AiGHTBis", ".", "append", "(", "np", ".", "dot", "(", "A_iGHTB_i", ",", "x", ".", "T", ")", ".", "T", ")", "\n", "\n", "", "return", "Bis", ",", "GHTBis", ",", "AiGHTBis", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.visualize.make_plots_params": [[134, 144], ["visualize.make_plots", "visualize.show_learned_operators"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.visualize.make_plots", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.visualize.show_learned_operators"], ["", "def", "make_plots_params", "(", "params", ",", "A", ",", "B", ",", "G", ",", "H", ",", "W", ",", "x", ",", "y", ",", "pred", ",", "step", ")", ":", "\n", "    ", "\"\"\"\n    print('A: ', A.shape)\n    print('B: ', B.shape)\n    print('W: ', W.shape)\n    \"\"\"", "\n", "make_plots", "(", "params", ".", "vis_path", ",", "params", ".", "num_pred_plot", ",", "params", ".", "layer_size", ",", "params", ".", "viz_powers", ",", "A", ",", "B", ",", "G", ",", "H", ",", "W", ",", "x", ",", "y", ",", "pred", ",", "step", ")", "\n", "\n", "# Just A,B,W", "\n", "show_learned_operators", "(", "params", ".", "vis_path", ",", "A", ",", "B", ",", "W", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.visualize.make_plots": [[145, 173], ["numpy.random.randint", "numpy.dot", "time.time", "visualize.compute_powers", "print", "visualize.show_predictions", "numpy.dot", "time.time"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.visualize.compute_powers", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.visualize.show_predictions"], ["", "def", "make_plots", "(", "vis_path", ",", "num_pred_plot", ",", "layer_size", ",", "viz_powers", ",", "A", ",", "B", ",", "G", ",", "H", ",", "W", ",", "x", ",", "y", ",", "pred", ",", "step", ")", ":", "\n", "    ", "\"\"\"\n    print('x.shape: ', x.shape)\n    print('y.shape: ', y.shape)\n    print('pred.shape: ', pred.shape)\n    \"\"\"", "\n", "assert", "x", ".", "shape", "[", "0", "]", "==", "y", ".", "size", "==", "pred", ".", "size", "\n", "idx", "=", "np", ".", "random", ".", "randint", "(", "x", ".", "shape", "[", "0", "]", ",", "size", "=", "num_pred_plot", ")", "\n", "x", "=", "x", "[", "idx", ",", ":", "]", "\n", "y", "=", "y", "[", "idx", "]", "\n", "pred", "=", "pred", "[", "idx", "]", "\n", "assert", "x", ".", "shape", "[", "0", "]", "==", "y", ".", "size", "==", "pred", ".", "size", "\n", "\n", "\n", "# GH^Tx", "\n", "low_rank", "=", "np", ".", "dot", "(", "G", ",", "H", ".", "T", ")", "\n", "low_rank_pred", "=", "np", ".", "dot", "(", "low_rank", ",", "x", ".", "T", ")", ".", "T", "\n", "\n", "# B^ix, various i", "\n", "# GH^T(B^ix), various i", "\n", "# A^i(GH^T(B^ix)), various i", "\n", "t1", "=", "time", ".", "time", "(", ")", "\n", "Bis", ",", "GHTBis", ",", "AiGHTBis", "=", "compute_powers", "(", "viz_powers", ",", "A", ",", "low_rank", ",", "B", ",", "x", ")", "\n", "print", "(", "'Time of compute_powers: '", ",", "time", ".", "time", "(", ")", "-", "t1", ")", "\n", "\n", "\n", "# Various inputs, predictions, and ground truth", "\n", "show_predictions", "(", "vis_path", ",", "step", ",", "num_pred_plot", ",", "layer_size", ",", "viz_powers", ",", "x", ",", "y", ",", "pred", ",", "Bis", ",", "GHTBis", ",", "AiGHTBis", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.visualize.get_model_params": [[174, 213], ["sess.run", "sess.run", "sess.run", "sess.run", "utils.gen_Z_f", "numpy.eye", "sess.run", "sess.run", "sess.run", "sess.run", "sess.run", "sess.run", "sess.run", "sess.run", "utils.gen_tridiag_corner", "utils.gen_tridiag_corner", "print", "utils.gen_Z_f"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_tridiag_corner", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_tridiag_corner", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f"], ["", "def", "get_model_params", "(", "params", ",", "x", ",", "y_", ",", "batch_xs", ",", "batch_ys", ",", "sess", ",", "model", ")", ":", "\n", "    ", "G", ",", "H", "=", "sess", ".", "run", "(", "[", "model", "[", "'G'", "]", ",", "model", "[", "'H'", "]", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "W", "=", "sess", ".", "run", "(", "model", "[", "'W'", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "if", "params", ".", "class_type", "==", "'circulant_sparsity'", ":", "\n", "# Construct A", "\n", "        ", "f_x_A", "=", "sess", ".", "run", "(", "model", "[", "'f_x_A'", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "# Construct B", "\n", "f_x_B", "=", "sess", ".", "run", "(", "model", "[", "'f_x_B'", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "\n", "if", "params", ".", "fix_A_identity", ":", "\n", "            ", "A", "=", "np", ".", "eye", "(", "params", ".", "layer_size", ")", "\n", "", "else", ":", "\n", "            ", "A", "=", "gen_Z_f", "(", "params", ".", "layer_size", ",", "f_x_B", "[", "0", "]", ",", "f_x_B", "[", "1", ":", "]", ")", ".", "T", "\n", "\n", "", "B", "=", "gen_Z_f", "(", "params", ".", "layer_size", ",", "f_x_B", "[", "0", "]", ",", "f_x_B", "[", "1", ":", "]", ")", "\n", "", "elif", "params", ".", "class_type", "==", "'tridiagonal_corner'", ":", "\n", "# Construct A", "\n", "        ", "supdiag_A", "=", "sess", ".", "run", "(", "model", "[", "'supdiag_A'", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "diag_A", "=", "sess", ".", "run", "(", "model", "[", "'diag_A'", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "subdiag_A", "=", "sess", ".", "run", "(", "model", "[", "'subdiag_A'", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "f_A", "=", "sess", ".", "run", "(", "model", "[", "'f_A'", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "# Construct B", "\n", "supdiag_B", "=", "sess", ".", "run", "(", "model", "[", "'supdiag_B'", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "diag_B", "=", "sess", ".", "run", "(", "model", "[", "'diag_B'", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "subdiag_B", "=", "sess", ".", "run", "(", "model", "[", "'subdiag_B'", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "f_B", "=", "sess", ".", "run", "(", "model", "[", "'f_B'", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "\n", "# Check if this is transpose", "\n", "A", "=", "gen_tridiag_corner", "(", "subdiag_A", ",", "supdiag_A", ",", "diag_A", ",", "f_A", ")", "\n", "B", "=", "gen_tridiag_corner", "(", "subdiag_B", ",", "supdiag_B", ",", "diag_B", ",", "f_B", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Class type not supported: '", ",", "params", ".", "class_type", ")", "\n", "assert", "0", "\n", "", "\"\"\"\n    print('A: ', A.shape)\n    print('B: ', B.shape)\n    print('W: ', W.shape)\n    \"\"\"", "\n", "return", "A", ",", "B", ",", "G", ",", "H", ",", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.visualize.visualize": [[214, 230], ["visualize.get_model_params", "numpy.argmax", "numpy.argmax", "visualize.make_plots_params"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.visualize.get_model_params", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.visualize.make_plots_params"], ["", "def", "visualize", "(", "params", ",", "sess", ",", "model", ",", "x", ",", "y_", ",", "batch_xs", ",", "batch_ys", ",", "y_pred", ",", "this_step", ")", ":", "\n", "    ", "A", ",", "B", ",", "G", ",", "H", ",", "W", "=", "get_model_params", "(", "params", ",", "x", ",", "y_", ",", "batch_xs", ",", "batch_ys", ",", "sess", ",", "model", ")", "\n", "\n", "\"\"\"\n    print('A: ', A.shape)\n    print('B: ', B.shape)\n    print('W: ', W.shape)\n    print('A: ', A)\n    print('B: ', B)\n    print('G: ', G)\n    print('H: ', H)\n    quit()\n    \"\"\"", "\n", "y_true", "=", "np", ".", "argmax", "(", "batch_ys", ",", "axis", "=", "1", ")", "\n", "y_pred", "=", "np", ".", "argmax", "(", "y_pred", ",", "axis", "=", "1", ")", "\n", "make_plots_params", "(", "params", ",", "A", ",", "B", ",", "G", ",", "H", ",", "W", ",", "batch_xs", ",", "y_true", ",", "y_pred", ",", "this_step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.fixed_operators.vandermonde_like": [[8, 112], ["tensorflow.placeholder", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "reconstruction.vand_recon", "model.compute_y", "tensorflow.placeholder", "utils.compute_loss_and_accuracy", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.FileWriter", "tensorflow.train.MomentumOptimizer().minimize", "tensorflow.InteractiveSession", "tensorflow.initialize_all_variables().run", "tensorflow.train.Saver", "utils.gen_Z_f", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "dataset.batch", "tf.InteractiveSession.run", "dataset.load_test_data", "tf.InteractiveSession.run", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "print", "print", "tensorflow.get_default_graph", "tensorflow.train.MomentumOptimizer", "tensorflow.initialize_all_variables", "print", "tf.InteractiveSession.run", "tf.InteractiveSession.run", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "train_losses.append", "train_accuracies.append", "val_losses.append", "val_accuracies.append", "print", "print", "tf.train.Saver.save", "print", "tf.InteractiveSession.run", "numpy.diag", "print", "print", "os.path.join", "numpy.dot", "str", "numpy.dot", "numpy.linalg.matrix_rank"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.vand_recon", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.compute_y", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.compute_loss_and_accuracy", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.batch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.load_test_data", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model_params.ModelParams.save"], ["def", "vandermonde_like", "(", "dataset", ",", "params", ",", "test_freq", "=", "100", ",", "verbose", "=", "False", ")", ":", "\n", "# A is learned, B is fixed", "\n", "\t", "B_vand", "=", "gen_Z_f", "(", "params", ".", "layer_size", ",", "0", ")", ".", "T", "\n", "f_V", "=", "0", "\n", "\n", "# Create the model", "\n", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "[", "None", ",", "params", ".", "input_size", "]", ")", "\n", "v", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "params", ".", "layer_size", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "G", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "params", ".", "layer_size", ",", "params", ".", "r", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "H", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "params", ".", "layer_size", ",", "params", ".", "r", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "\n", "W1", "=", "vand_recon", "(", "G", ",", "H", ",", "v", ",", "params", ".", "layer_size", ",", "params", ".", "layer_size", ",", "f_V", ",", "params", ".", "r", ")", "\n", "\n", "y", "=", "compute_y", "(", "x", ",", "W1", ",", "params", ")", "\n", "\n", "y_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "[", "None", ",", "params", ".", "out_size", "]", ")", "\n", "\n", "loss", ",", "accuracy", "=", "compute_loss_and_accuracy", "(", "y", ",", "y_", ",", "params", ")", "\n", "\n", "train_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'train_loss'", ",", "loss", ")", "\n", "train_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'train_accuracy'", ",", "accuracy", ")", "\n", "val_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'val_loss'", ",", "loss", ")", "\n", "val_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'val_accuracy'", ",", "accuracy", ")", "\n", "test_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'test_loss'", ",", "loss", ")", "\n", "test_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'test_accuracy'", ",", "accuracy", ")", "\n", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "params", ".", "log_path", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", ")", "\n", "\n", "train_step", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "params", ".", "lr", ",", "params", ".", "mom", ")", ".", "minimize", "(", "loss", ")", "\n", "sess", "=", "tf", ".", "InteractiveSession", "(", ")", "\n", "tf", ".", "initialize_all_variables", "(", ")", ".", "run", "(", ")", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "step", "=", "0", "\n", "\n", "losses", "=", "{", "}", "\n", "accuracies", "=", "{", "}", "\n", "train_losses", "=", "[", "]", "\n", "train_accuracies", "=", "[", "]", "\n", "val_losses", "=", "[", "]", "\n", "val_accuracies", "=", "[", "]", "\n", "\n", "while", "step", "<", "params", ".", "steps", ":", "\n", "\t\t", "batch_xs", ",", "batch_ys", "=", "dataset", ".", "batch", "(", "params", ".", "batch_size", ",", "step", ")", "\n", "_", "=", "sess", ".", "run", "(", "[", "train_step", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "\n", "if", "step", "%", "test_freq", "==", "0", ":", "\n", "\t\t\t", "print", "(", "(", "'Training step: '", ",", "step", ")", ")", "\n", "# Verify displacement rank", "\n", "if", "params", ".", "check_disp", ":", "\n", "\t\t\t\t", "v_real", ",", "W1_real", "=", "sess", ".", "run", "(", "[", "v", ",", "W1", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "A", "=", "np", ".", "diag", "(", "v_real", ")", "\n", "E", "=", "W1_real", "-", "np", ".", "dot", "(", "A", ",", "np", ".", "dot", "(", "W1_real", ",", "B_vand", ")", ")", "\n", "print", "(", "(", "'Disp rank: '", ",", "np", ".", "linalg", ".", "matrix_rank", "(", "E", ")", ")", ")", "\n", "\n", "", "train_loss", ",", "train_accuracy", ",", "train_loss_summ", ",", "train_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "train_loss_summary", ",", "\n", "train_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "val_loss", ",", "val_accuracy", ",", "val_loss_summ", ",", "val_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "val_loss_summary", ",", "\n", "val_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "val_X", ",", "y_", ":", "dataset", ".", "val_Y", "}", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "train_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "train_acc_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "val_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "val_acc_summ", ",", "step", ")", "\n", "\n", "train_losses", ".", "append", "(", "train_loss", ")", "\n", "train_accuracies", ".", "append", "(", "train_accuracy", ")", "\n", "val_losses", ".", "append", "(", "val_loss", ")", "\n", "val_accuracies", ".", "append", "(", "val_accuracy", ")", "\n", "\n", "print", "(", "(", "'Train loss, accuracy: '", ",", "train_loss", ",", "train_accuracy", ")", ")", "\n", "print", "(", "(", "'Validation loss, accuracy: '", ",", "val_loss", ",", "val_accuracy", ")", ")", "\n", "\n", "if", "verbose", ":", "\n", "\t\t\t\t", "print", "(", "(", "'Current W1: '", ",", "W1_real", ")", ")", "\n", "\n", "", "", "if", "step", "%", "params", ".", "checkpoint_freq", "==", "0", ":", "\n", "\t\t\t", "save_path", "=", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "params", ".", "checkpoint_path", ",", "str", "(", "step", ")", ")", ")", "\n", "print", "(", "(", "\"Model saved in file: %s\"", "%", "save_path", ")", ")", "\n", "\n", "", "step", "+=", "1", "\n", "\n", "", "losses", "[", "'train'", "]", "=", "train_losses", "\n", "losses", "[", "'val'", "]", "=", "val_losses", "\n", "accuracies", "[", "'train'", "]", "=", "train_accuracies", "\n", "accuracies", "[", "'val'", "]", "=", "val_accuracies", "\n", "\n", "# Test trained model", "\n", "if", "params", ".", "test", ":", "\n", "# Load test", "\n", "\t\t", "dataset", ".", "load_test_data", "(", ")", "\n", "test_loss", ",", "test_accuracy", ",", "test_loss_summ", ",", "test_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "test_loss_summary", ",", "test_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "test_X", ",", "y_", ":", "dataset", ".", "test_Y", "}", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "test_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "test_acc_summ", ",", "step", ")", "\n", "\n", "print", "(", "(", "'SGD test loss, Vandermonde-like: '", ",", "test_loss", ")", ")", "\n", "print", "(", "(", "'SGD test accuracy, Vandermonde-like: '", ",", "test_accuracy", ")", ")", "\n", "\n", "losses", "[", "'test'", "]", "=", "test_loss", "\n", "accuracies", "[", "'test'", "]", "=", "test_accuracy", "\n", "\n", "", "return", "losses", ",", "accuracies", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.fixed_operators.hankel_like": [[113, 218], ["utils.gen_Z_f", "utils.gen_Z_f", "tensorflow.placeholder", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "reconstruction.rect_recon_tf", "model.compute_y", "tensorflow.placeholder", "utils.compute_loss_and_accuracy", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.FileWriter", "tensorflow.train.MomentumOptimizer().minimize", "tensorflow.InteractiveSession", "tensorflow.initialize_all_variables().run", "tensorflow.train.Saver", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "dataset.batch", "tf.InteractiveSession.run", "dataset.load_test_data", "tf.InteractiveSession.run", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "print", "print", "tensorflow.get_default_graph", "tensorflow.train.MomentumOptimizer", "tensorflow.initialize_all_variables", "print", "tf.InteractiveSession.run", "tf.InteractiveSession.run", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "train_losses.append", "train_accuracies.append", "val_losses.append", "val_accuracies.append", "print", "print", "tf.train.Saver.save", "print", "tf.InteractiveSession.run", "print", "print", "os.path.join", "numpy.dot", "str", "numpy.dot", "numpy.linalg.matrix_rank"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.rect_recon_tf", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.compute_y", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.compute_loss_and_accuracy", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.batch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.load_test_data", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model_params.ModelParams.save"], ["", "def", "hankel_like", "(", "dataset", ",", "params", ",", "test_freq", "=", "100", ",", "verbose", "=", "False", ")", ":", "\n", "\t", "f", "=", "0", "\n", "g", "=", "1", "\n", "A", "=", "gen_Z_f", "(", "params", ".", "layer_size", ",", "f", ")", "\n", "B", "=", "gen_Z_f", "(", "params", ".", "layer_size", ",", "g", ")", "\n", "\n", "# Create the model", "\n", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "[", "None", ",", "params", ".", "input_size", "]", ")", "\n", "v", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "params", ".", "layer_size", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "G", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "params", ".", "layer_size", ",", "params", ".", "r", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "H", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "params", ".", "layer_size", ",", "params", ".", "r", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "\n", "\n", "W1", "=", "rect_recon_tf", "(", "G", ",", "H", ",", "B", ",", "params", ".", "layer_size", ",", "params", ".", "layer_size", ",", "f", ",", "g", ",", "params", ".", "r", ")", "\n", "\n", "y", "=", "compute_y", "(", "x", ",", "W1", ",", "params", ")", "\n", "\n", "y_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "[", "None", ",", "params", ".", "out_size", "]", ")", "\n", "\n", "loss", ",", "accuracy", "=", "compute_loss_and_accuracy", "(", "y", ",", "y_", ",", "params", ")", "\n", "\n", "train_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'train_loss'", ",", "loss", ")", "\n", "train_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'train_accuracy'", ",", "accuracy", ")", "\n", "val_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'val_loss'", ",", "loss", ")", "\n", "val_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'val_accuracy'", ",", "accuracy", ")", "\n", "test_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'test_loss'", ",", "loss", ")", "\n", "test_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'test_accuracy'", ",", "accuracy", ")", "\n", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "params", ".", "log_path", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", ")", "\n", "\n", "train_step", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "params", ".", "lr", ",", "params", ".", "mom", ")", ".", "minimize", "(", "loss", ")", "\n", "sess", "=", "tf", ".", "InteractiveSession", "(", ")", "\n", "tf", ".", "initialize_all_variables", "(", ")", ".", "run", "(", ")", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "step", "=", "0", "\n", "\n", "losses", "=", "{", "}", "\n", "accuracies", "=", "{", "}", "\n", "train_losses", "=", "[", "]", "\n", "train_accuracies", "=", "[", "]", "\n", "val_losses", "=", "[", "]", "\n", "val_accuracies", "=", "[", "]", "\n", "\n", "while", "step", "<", "params", ".", "steps", ":", "\n", "\t\t", "batch_xs", ",", "batch_ys", "=", "dataset", ".", "batch", "(", "params", ".", "batch_size", ",", "step", ")", "\n", "_", "=", "sess", ".", "run", "(", "[", "train_step", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "\n", "if", "step", "%", "test_freq", "==", "0", ":", "\n", "\t\t\t", "print", "(", "(", "'Training step: '", ",", "step", ")", ")", "\n", "if", "params", ".", "check_disp", ":", "\n", "# Verify displacement rank", "\n", "\t\t\t\t", "W1_real", "=", "sess", ".", "run", "(", "W1", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "E", "=", "W1_real", "-", "np", ".", "dot", "(", "A", ",", "np", ".", "dot", "(", "W1_real", ",", "B", ")", ")", "\n", "print", "(", "(", "'Disp rank: '", ",", "np", ".", "linalg", ".", "matrix_rank", "(", "E", ")", ")", ")", "\n", "\n", "", "train_loss", ",", "train_accuracy", ",", "train_loss_summ", ",", "train_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "train_loss_summary", ",", "\n", "train_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "val_loss", ",", "val_accuracy", ",", "val_loss_summ", ",", "val_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "val_loss_summary", ",", "\n", "val_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "val_X", ",", "y_", ":", "dataset", ".", "val_Y", "}", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "train_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "train_acc_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "val_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "val_acc_summ", ",", "step", ")", "\n", "\n", "train_losses", ".", "append", "(", "train_loss", ")", "\n", "train_accuracies", ".", "append", "(", "train_accuracy", ")", "\n", "val_losses", ".", "append", "(", "val_loss", ")", "\n", "val_accuracies", ".", "append", "(", "val_accuracy", ")", "\n", "\n", "print", "(", "(", "'Train loss, accuracy: '", ",", "train_loss", ",", "train_accuracy", ")", ")", "\n", "print", "(", "(", "'Validation loss, accuracy: '", ",", "val_loss", ",", "val_accuracy", ")", ")", "\n", "\n", "if", "verbose", ":", "\n", "\t\t\t\t", "print", "(", "(", "'Current W1: '", ",", "W1_real", ")", ")", "\n", "\n", "", "", "if", "step", "%", "params", ".", "checkpoint_freq", "==", "0", ":", "\n", "\t\t\t", "save_path", "=", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "params", ".", "checkpoint_path", ",", "str", "(", "step", ")", ")", ")", "\n", "print", "(", "(", "\"Model saved in file: %s\"", "%", "save_path", ")", ")", "\n", "\n", "", "step", "+=", "1", "\n", "\n", "", "losses", "[", "'train'", "]", "=", "train_losses", "\n", "losses", "[", "'val'", "]", "=", "val_losses", "\n", "accuracies", "[", "'train'", "]", "=", "train_accuracies", "\n", "accuracies", "[", "'val'", "]", "=", "val_accuracies", "\n", "\n", "# Test trained model", "\n", "if", "params", ".", "test", ":", "\n", "# Load test", "\n", "\t\t", "dataset", ".", "load_test_data", "(", ")", "\n", "\n", "test_loss", ",", "test_accuracy", ",", "test_loss_summ", ",", "test_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "test_loss_summary", ",", "test_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "test_X", ",", "y_", ":", "dataset", ".", "test_Y", "}", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "test_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "test_acc_summ", ",", "step", ")", "\n", "\n", "print", "(", "(", "'SGD test loss, Hankel-like: '", ",", "test_loss", ")", ")", "\n", "print", "(", "(", "'SGD test accuracy, Hankel-like: '", ",", "test_accuracy", ")", ")", "\n", "losses", "[", "'test'", "]", "=", "test_loss", "\n", "accuracies", "[", "'test'", "]", "=", "test_accuracy", "\n", "\n", "", "return", "losses", ",", "accuracies", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.fixed_operators.toeplitz_like": [[220, 324], ["utils.gen_Z_f", "utils.gen_Z_f", "tensorflow.placeholder", "tensorflow.Variable", "tensorflow.Variable", "reconstruction.toeplitz_like_recon", "model.compute_y", "tensorflow.placeholder", "utils.compute_loss_and_accuracy", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.FileWriter", "tensorflow.train.MomentumOptimizer().minimize", "tensorflow.InteractiveSession", "tensorflow.initialize_all_variables().run", "tensorflow.train.Saver", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "dataset.batch", "tf.InteractiveSession.run", "dataset.load_test_data", "tf.InteractiveSession.run", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "print", "print", "tensorflow.get_default_graph", "tensorflow.train.MomentumOptimizer", "tensorflow.initialize_all_variables", "print", "tf.InteractiveSession.run", "tf.InteractiveSession.run", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "train_losses.append", "train_accuracies.append", "val_losses.append", "val_accuracies.append", "print", "print", "tf.train.Saver.save", "print", "tf.InteractiveSession.run", "print", "print", "os.path.join", "numpy.dot", "numpy.dot", "str", "numpy.linalg.matrix_rank"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.toeplitz_like_recon", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.compute_y", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.compute_loss_and_accuracy", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.batch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.load_test_data", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model_params.ModelParams.save"], ["", "def", "toeplitz_like", "(", "dataset", ",", "params", ",", "test_freq", "=", "100", ",", "verbose", "=", "False", ")", ":", "\n", "\t", "A", "=", "gen_Z_f", "(", "params", ".", "layer_size", ",", "1", ")", "\n", "B", "=", "gen_Z_f", "(", "params", ".", "layer_size", ",", "-", "1", ")", "\n", "\n", "# Create the model", "\n", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "[", "None", ",", "params", ".", "input_size", "]", ")", "\n", "G", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "params", ".", "layer_size", ",", "params", ".", "r", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "H", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "params", ".", "layer_size", ",", "params", ".", "r", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "\n", "W1", "=", "toeplitz_like_recon", "(", "G", ",", "H", ",", "params", ".", "layer_size", ",", "params", ".", "r", ")", "\n", "\n", "y", "=", "compute_y", "(", "x", ",", "W1", ",", "params", ")", "\n", "\n", "y_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "[", "None", ",", "params", ".", "out_size", "]", ")", "\n", "\n", "loss", ",", "accuracy", "=", "compute_loss_and_accuracy", "(", "y", ",", "y_", ",", "params", ")", "\n", "\n", "train_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'train_loss'", ",", "loss", ")", "\n", "train_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'train_accuracy'", ",", "accuracy", ")", "\n", "val_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'val_loss'", ",", "loss", ")", "\n", "val_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'val_accuracy'", ",", "accuracy", ")", "\n", "test_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'test_loss'", ",", "loss", ")", "\n", "test_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'test_accuracy'", ",", "accuracy", ")", "\n", "\n", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "params", ".", "log_path", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", ")", "\n", "\n", "train_step", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "params", ".", "lr", ",", "params", ".", "mom", ")", ".", "minimize", "(", "loss", ")", "\n", "sess", "=", "tf", ".", "InteractiveSession", "(", ")", "\n", "tf", ".", "initialize_all_variables", "(", ")", ".", "run", "(", ")", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "step", "=", "0", "\n", "\n", "losses", "=", "{", "}", "\n", "accuracies", "=", "{", "}", "\n", "train_losses", "=", "[", "]", "\n", "train_accuracies", "=", "[", "]", "\n", "val_losses", "=", "[", "]", "\n", "val_accuracies", "=", "[", "]", "\n", "\n", "while", "step", "<", "params", ".", "steps", ":", "\n", "\t\t", "batch_xs", ",", "batch_ys", "=", "dataset", ".", "batch", "(", "params", ".", "batch_size", ",", "step", ")", "\n", "_", ",", "=", "sess", ".", "run", "(", "[", "train_step", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "\n", "\n", "if", "step", "%", "test_freq", "==", "0", ":", "\n", "\t\t\t", "print", "(", "(", "'Training step: '", ",", "step", ")", ")", "\n", "if", "params", ".", "check_disp", ":", "\n", "# Verify displacement rank", "\n", "\t\t\t\t", "W1_real", "=", "sess", ".", "run", "(", "W1", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "E_sylv", "=", "np", ".", "dot", "(", "A", ",", "W1_real", ")", "-", "np", ".", "dot", "(", "W1_real", ",", "B", ")", "\n", "print", "(", "(", "'Disp rank, Sylv: '", ",", "np", ".", "linalg", ".", "matrix_rank", "(", "E_sylv", ")", ")", ")", "\n", "\n", "", "train_loss", ",", "train_accuracy", ",", "train_loss_summ", ",", "train_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "train_loss_summary", ",", "\n", "train_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "val_loss", ",", "val_accuracy", ",", "val_loss_summ", ",", "val_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "val_loss_summary", ",", "\n", "val_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "val_X", ",", "y_", ":", "dataset", ".", "val_Y", "}", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "train_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "train_acc_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "val_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "val_acc_summ", ",", "step", ")", "\n", "\n", "train_losses", ".", "append", "(", "train_loss", ")", "\n", "train_accuracies", ".", "append", "(", "train_accuracy", ")", "\n", "val_losses", ".", "append", "(", "val_loss", ")", "\n", "val_accuracies", ".", "append", "(", "val_accuracy", ")", "\n", "\n", "print", "(", "(", "'Train loss, accuracy: '", ",", "train_loss", ",", "train_accuracy", ")", ")", "\n", "print", "(", "(", "'Validation loss, accuracy: '", ",", "val_loss", ",", "val_accuracy", ")", ")", "\n", "\n", "if", "verbose", ":", "\n", "\t\t\t\t", "print", "(", "(", "'Current W1: '", ",", "W1_real", ")", ")", "\n", "\n", "", "", "if", "step", "%", "params", ".", "checkpoint_freq", "==", "0", ":", "\n", "\t\t\t", "save_path", "=", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "params", ".", "checkpoint_path", ",", "str", "(", "step", ")", ")", ")", "\n", "print", "(", "(", "\"Model saved in file: %s\"", "%", "save_path", ")", ")", "\n", "\n", "", "step", "+=", "1", "\n", "\n", "", "losses", "[", "'train'", "]", "=", "train_losses", "\n", "losses", "[", "'val'", "]", "=", "val_losses", "\n", "accuracies", "[", "'train'", "]", "=", "train_accuracies", "\n", "accuracies", "[", "'val'", "]", "=", "val_accuracies", "\n", "\n", "# Test trained model", "\n", "if", "params", ".", "test", ":", "\n", "# Load test", "\n", "\t\t", "dataset", ".", "load_test_data", "(", ")", "\n", "\n", "test_loss", ",", "test_accuracy", ",", "test_loss_summ", ",", "test_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "test_loss_summary", ",", "\n", "test_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "test_X", ",", "y_", ":", "dataset", ".", "test_Y", "}", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "test_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "test_acc_summ", ",", "step", ")", "\n", "\n", "print", "(", "(", "'SGD test loss, Toeplitz-like: '", ",", "test_loss", ")", ")", "\n", "print", "(", "(", "'SGD test accuracy, Toeplitz-like: '", ",", "test_accuracy", ")", ")", "\n", "losses", "[", "'test'", "]", "=", "test_loss", "\n", "accuracies", "[", "'test'", "]", "=", "test_accuracy", "\n", "\n", "", "return", "losses", ",", "accuracies", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.fixed_operators.low_rank": [[326, 418], ["tensorflow.placeholder", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.matmul", "model.compute_y", "tensorflow.placeholder", "utils.compute_loss_and_accuracy", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.FileWriter", "tensorflow.train.MomentumOptimizer().minimize", "tensorflow.InteractiveSession", "tensorflow.initialize_all_variables().run", "tensorflow.train.Saver", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "dataset.batch", "tf.InteractiveSession.run", "dataset.load_test_data", "tf.InteractiveSession.run", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "print", "print", "tensorflow.get_default_graph", "tensorflow.train.MomentumOptimizer", "tensorflow.initialize_all_variables", "print", "tf.InteractiveSession.run", "tf.InteractiveSession.run", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "train_losses.append", "train_accuracies.append", "val_losses.append", "val_accuracies.append", "print", "print", "tf.train.Saver.save", "print", "print", "os.path.join", "str"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.compute_y", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.compute_loss_and_accuracy", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.batch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.load_test_data", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model_params.ModelParams.save"], ["", "def", "low_rank", "(", "dataset", ",", "params", ",", "test_freq", "=", "100", ",", "verbose", "=", "False", ")", ":", "\n", "# Create the model", "\n", "\t", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "[", "None", ",", "params", ".", "input_size", "]", ")", "\n", "G", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "params", ".", "layer_size", ",", "params", ".", "r", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "H", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "params", ".", "layer_size", ",", "params", ".", "r", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "\n", "W1", "=", "tf", ".", "matmul", "(", "G", ",", "H", ")", "\n", "\n", "y", "=", "compute_y", "(", "x", ",", "W1", ",", "params", ")", "\n", "y_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "[", "None", ",", "params", ".", "out_size", "]", ")", "\n", "\n", "loss", ",", "accuracy", "=", "compute_loss_and_accuracy", "(", "y", ",", "y_", ",", "params", ")", "\n", "train_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'train_loss'", ",", "loss", ")", "\n", "train_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'train_accuracy'", ",", "accuracy", ")", "\n", "val_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'val_loss'", ",", "loss", ")", "\n", "val_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'val_accuracy'", ",", "accuracy", ")", "\n", "test_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'test_loss'", ",", "loss", ")", "\n", "test_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'test_accuracy'", ",", "accuracy", ")", "\n", "\n", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "params", ".", "log_path", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", ")", "\n", "\n", "train_step", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "params", ".", "lr", ",", "params", ".", "mom", ")", ".", "minimize", "(", "loss", ")", "\n", "sess", "=", "tf", ".", "InteractiveSession", "(", ")", "\n", "tf", ".", "initialize_all_variables", "(", ")", ".", "run", "(", ")", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "step", "=", "0", "\n", "\n", "losses", "=", "{", "}", "\n", "accuracies", "=", "{", "}", "\n", "train_losses", "=", "[", "]", "\n", "train_accuracies", "=", "[", "]", "\n", "val_losses", "=", "[", "]", "\n", "val_accuracies", "=", "[", "]", "\n", "\n", "while", "step", "<", "params", ".", "steps", ":", "\n", "\t\t", "batch_xs", ",", "batch_ys", "=", "dataset", ".", "batch", "(", "params", ".", "batch_size", ",", "step", ")", "\n", "_", ",", "=", "sess", ".", "run", "(", "[", "train_step", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "\n", "\n", "if", "step", "%", "test_freq", "==", "0", ":", "\n", "\t\t\t", "print", "(", "(", "'Training step: '", ",", "step", ")", ")", "\n", "train_loss", ",", "train_accuracy", ",", "train_loss_summ", ",", "train_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "train_loss_summary", ",", "\n", "train_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "val_loss", ",", "val_accuracy", ",", "val_loss_summ", ",", "val_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "val_loss_summary", ",", "\n", "val_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "val_X", ",", "y_", ":", "dataset", ".", "val_Y", "}", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "train_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "train_acc_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "val_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "val_acc_summ", ",", "step", ")", "\n", "\n", "train_losses", ".", "append", "(", "train_loss", ")", "\n", "train_accuracies", ".", "append", "(", "train_accuracy", ")", "\n", "val_losses", ".", "append", "(", "val_loss", ")", "\n", "val_accuracies", ".", "append", "(", "val_accuracy", ")", "\n", "\n", "print", "(", "(", "'Train loss, accuracy: '", ",", "train_loss", ",", "train_accuracy", ")", ")", "\n", "print", "(", "(", "'Validation loss, accuracy: '", ",", "val_loss", ",", "val_accuracy", ")", ")", "\n", "\n", "if", "verbose", ":", "\n", "\t\t\t\t", "print", "(", "(", "'Current W1: '", ",", "W1_real", ")", ")", "\n", "\n", "", "", "if", "step", "%", "params", ".", "checkpoint_freq", "==", "0", ":", "\n", "\t\t\t", "save_path", "=", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "params", ".", "checkpoint_path", ",", "str", "(", "step", ")", ")", ")", "\n", "print", "(", "(", "\"Model saved in file: %s\"", "%", "save_path", ")", ")", "\n", "\n", "", "step", "+=", "1", "\n", "\n", "", "losses", "[", "'train'", "]", "=", "train_losses", "\n", "losses", "[", "'val'", "]", "=", "val_losses", "\n", "accuracies", "[", "'train'", "]", "=", "train_accuracies", "\n", "accuracies", "[", "'val'", "]", "=", "val_accuracies", "\n", "\n", "# Test trained model", "\n", "if", "params", ".", "test", ":", "\n", "# Load test", "\n", "\t\t", "dataset", ".", "load_test_data", "(", ")", "\n", "\n", "test_loss", ",", "test_accuracy", ",", "test_loss_summ", ",", "test_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "test_loss_summary", ",", "test_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "test_X", ",", "y_", ":", "dataset", ".", "test_Y", "}", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "test_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "test_acc_summ", ",", "step", ")", "\n", "\n", "print", "(", "(", "'SGD test loss, low rank: '", ",", "test_loss", ")", ")", "\n", "print", "(", "(", "'SGD test accuracy, low rank: '", ",", "test_accuracy", ")", ")", "\n", "losses", "[", "'test'", "]", "=", "test_loss", "\n", "accuracies", "[", "'test'", "]", "=", "test_accuracy", "\n", "\n", "", "return", "losses", ",", "accuracies", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.fixed_operators.unconstrained": [[419, 509], ["tensorflow.placeholder", "tensorflow.Variable", "model.compute_y", "tensorflow.placeholder", "utils.compute_loss_and_accuracy", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.FileWriter", "tensorflow.train.MomentumOptimizer().minimize", "tensorflow.InteractiveSession", "tensorflow.initialize_all_variables().run", "tensorflow.train.Saver", "tensorflow.truncated_normal", "dataset.batch", "tf.InteractiveSession.run", "dataset.load_test_data", "tf.InteractiveSession.run", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "print", "print", "tensorflow.get_default_graph", "tensorflow.train.MomentumOptimizer", "tensorflow.initialize_all_variables", "print", "tf.InteractiveSession.run", "tf.InteractiveSession.run", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "train_losses.append", "train_accuracies.append", "val_losses.append", "val_accuracies.append", "print", "print", "tf.train.Saver.save", "print", "print", "os.path.join", "str"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.compute_y", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.compute_loss_and_accuracy", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.batch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.load_test_data", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model_params.ModelParams.save"], ["", "def", "unconstrained", "(", "dataset", ",", "params", ",", "test_freq", "=", "100", ",", "verbose", "=", "False", ")", ":", "\n", "# Create the model", "\n", "\t", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "[", "None", ",", "params", ".", "input_size", "]", ")", "\n", "W1", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "params", ".", "layer_size", ",", "params", ".", "layer_size", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "y", "=", "compute_y", "(", "x", ",", "W1", ",", "params", ")", "\n", "y_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "[", "None", ",", "params", ".", "out_size", "]", ")", "\n", "\n", "loss", ",", "accuracy", "=", "compute_loss_and_accuracy", "(", "y", ",", "y_", ",", "params", ")", "\n", "\n", "train_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'train_loss'", ",", "loss", ")", "\n", "train_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'train_accuracy'", ",", "accuracy", ")", "\n", "val_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'val_loss'", ",", "loss", ")", "\n", "val_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'val_accuracy'", ",", "accuracy", ")", "\n", "test_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'test_loss'", ",", "loss", ")", "\n", "test_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'test_accuracy'", ",", "accuracy", ")", "\n", "\n", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "params", ".", "log_path", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", ")", "\n", "\n", "train_step", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "params", ".", "lr", ",", "params", ".", "mom", ")", ".", "minimize", "(", "loss", ")", "\n", "sess", "=", "tf", ".", "InteractiveSession", "(", ")", "\n", "tf", ".", "initialize_all_variables", "(", ")", ".", "run", "(", ")", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "step", "=", "0", "\n", "\n", "losses", "=", "{", "}", "\n", "accuracies", "=", "{", "}", "\n", "train_losses", "=", "[", "]", "\n", "train_accuracies", "=", "[", "]", "\n", "val_losses", "=", "[", "]", "\n", "val_accuracies", "=", "[", "]", "\n", "\n", "while", "step", "<", "params", ".", "steps", ":", "\n", "\t\t", "batch_xs", ",", "batch_ys", "=", "dataset", ".", "batch", "(", "params", ".", "batch_size", ",", "step", ")", "\n", "_", "=", "sess", ".", "run", "(", "[", "train_step", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "\n", "\n", "if", "step", "%", "test_freq", "==", "0", ":", "\n", "\t\t\t", "print", "(", "(", "'Training step: '", ",", "step", ")", ")", "\n", "train_loss", ",", "train_accuracy", ",", "train_loss_summ", ",", "train_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "train_loss_summary", ",", "\n", "train_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "val_loss", ",", "val_accuracy", ",", "val_loss_summ", ",", "val_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "val_loss_summary", ",", "\n", "val_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "val_X", ",", "y_", ":", "dataset", ".", "val_Y", "}", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "train_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "train_acc_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "val_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "val_acc_summ", ",", "step", ")", "\n", "\n", "train_losses", ".", "append", "(", "train_loss", ")", "\n", "train_accuracies", ".", "append", "(", "train_accuracy", ")", "\n", "val_losses", ".", "append", "(", "val_loss", ")", "\n", "val_accuracies", ".", "append", "(", "val_accuracy", ")", "\n", "\n", "print", "(", "(", "'Train loss, accuracy: '", ",", "train_loss", ",", "train_accuracy", ")", ")", "\n", "print", "(", "(", "'Validation loss, accuracy: '", ",", "val_loss", ",", "val_accuracy", ")", ")", "\n", "\n", "if", "verbose", ":", "\n", "\t\t\t\t", "print", "(", "(", "'Current W1: '", ",", "W1_real", ")", ")", "\n", "\n", "", "", "if", "step", "%", "params", ".", "checkpoint_freq", "==", "0", ":", "\n", "\t\t\t", "save_path", "=", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "params", ".", "checkpoint_path", ",", "str", "(", "step", ")", ")", ")", "\n", "print", "(", "(", "\"Model saved in file: %s\"", "%", "save_path", ")", ")", "\n", "\n", "", "step", "+=", "1", "\n", "\n", "", "losses", "[", "'train'", "]", "=", "train_losses", "\n", "losses", "[", "'val'", "]", "=", "val_losses", "\n", "accuracies", "[", "'train'", "]", "=", "train_accuracies", "\n", "accuracies", "[", "'val'", "]", "=", "val_accuracies", "\n", "\n", "# Test trained model", "\n", "if", "params", ".", "test", ":", "\n", "# Load test", "\n", "\t\t", "dataset", ".", "load_test_data", "(", ")", "\n", "\n", "test_loss", ",", "test_accuracy", ",", "test_loss_summ", ",", "test_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "test_loss_summary", ",", "\n", "test_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "test_X", ",", "y_", ":", "dataset", ".", "test_Y", "}", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "test_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "test_acc_summ", ",", "step", ")", "\n", "\n", "print", "(", "(", "'SGD test loss, unconstrained: '", ",", "test_loss", ")", ")", "\n", "print", "(", "(", "'SGD test accuracy, unconstrained: '", ",", "test_accuracy", ")", ")", "\n", "losses", "[", "'test'", "]", "=", "test_loss", "\n", "accuracies", "[", "'test'", "]", "=", "test_accuracy", "\n", "\n", "", "return", "losses", ",", "accuracies", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.eigendecomp": [[8, 12], ["tensorflow.self_adjoint_eig", "tensorflow.diag", "tensorflow.matrix_inverse"], "function", ["None"], ["def", "eigendecomp", "(", "A", ")", ":", "\n", "    ", "d", ",", "P", "=", "tf", ".", "self_adjoint_eig", "(", "A", ")", "\n", "\n", "return", "P", ",", "tf", ".", "diag", "(", "d", ")", ",", "tf", ".", "matrix_inverse", "(", "P", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.general_recon": [[13, 40], ["reconstruction.eigendecomp", "reconstruction.eigendecomp", "tensorflow.diag_part", "tensorflow.diag_part", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.multiply", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.matmul"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.eigendecomp", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.eigendecomp"], ["", "def", "general_recon", "(", "G", ",", "H", ",", "A", ",", "B", ")", ":", "\n", "    ", "P", ",", "D_A", ",", "Pinv", "=", "eigendecomp", "(", "A", ")", "\n", "Q", ",", "D_B", ",", "Qinv", "=", "eigendecomp", "(", "B", ")", "\n", "\n", "#sess = tf.InteractiveSession()", "\n", "#tf.initialize_all_variables().run()", "\n", "\n", "eig_A", "=", "tf", ".", "diag_part", "(", "D_A", ")", "\n", "eig_B", "=", "tf", ".", "diag_part", "(", "D_B", ")", "\n", "\n", "eig_A_reshaped", "=", "tf", ".", "reshape", "(", "eig_A", ",", "[", "-", "1", ",", "1", "]", ")", "\n", "\n", "\n", "diff", "=", "eig_A_reshaped", "-", "eig_B", "\n", "C", "=", "1.0", "/", "diff", "\n", "\n", "E", "=", "tf", ".", "matmul", "(", "G", ",", "tf", ".", "transpose", "(", "H", ")", ")", "\n", "\n", "term", "=", "tf", ".", "matmul", "(", "Pinv", ",", "tf", ".", "matmul", "(", "E", ",", "Q", ")", ")", "\n", "term", "=", "tf", ".", "multiply", "(", "term", ",", "C", ")", "# Elementwise", "\n", "W", "=", "tf", ".", "matmul", "(", "P", ",", "tf", ".", "matmul", "(", "term", ",", "Qinv", ")", ")", "\n", "\n", "#print 'W: ', sess.run(W)", "\n", "#print 'Q: ', sess.run(Q)", "\n", "#quit()", "\n", "\n", "return", "W", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.krylov_recon_params": [[41, 52], ["tensorflow.zeros", "range", "krylov.krylov", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.add", "krylov.krylov", "tensorflow.reverse"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.krylov"], ["", "def", "krylov_recon_params", "(", "layer_size", ",", "r", ",", "flip_K_B", ",", "G", ",", "H", ",", "fn_A", ",", "fn_B", ")", ":", "\n", "    ", "W1", "=", "tf", ".", "zeros", "(", "[", "layer_size", ",", "layer_size", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "for", "i", "in", "range", "(", "r", ")", ":", "\n", "        ", "K_A", "=", "krylov", "(", "fn_A", ",", "G", "[", ":", ",", "i", "]", ",", "layer_size", ")", "\n", "K_B", "=", "tf", ".", "transpose", "(", "krylov", "(", "fn_B", ",", "H", "[", ":", ",", "i", "]", ",", "layer_size", ")", ")", "\n", "if", "flip_K_B", ":", "\n", "            ", "K_B", "=", "tf", ".", "reverse", "(", "K_B", ",", "[", "0", "]", ")", "\n", "", "prod", "=", "tf", ".", "matmul", "(", "K_A", ",", "K_B", ")", "\n", "W1", "=", "tf", ".", "add", "(", "W1", ",", "prod", ")", "\n", "\n", "", "return", "W1", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.krylov_recon": [[53, 55], ["reconstruction.krylov_recon_params"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.krylov_recon_params"], ["", "def", "krylov_recon", "(", "params", ",", "G", ",", "H", ",", "fn_A", ",", "fn_B", ")", ":", "\n", "    ", "return", "krylov_recon_params", "(", "params", ".", "layer_size", ",", "params", ".", "r", ",", "params", ".", "flip_K_B", ",", "G", ",", "H", ",", "fn_A", ",", "fn_B", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.circ_sparsity_recon_hadamard": [[56, 121], ["time.time", "tensorflow.constant", "time.time", "tensorflow.constant", "tensorflow.ones", "tensorflow.where", "tensorflow.where", "utils.gen_index_arr", "tensorflow.zeros", "range", "tensorflow.scalar_mul", "tensorflow.constant", "tensorflow.constant", "utils.gen_circ_scaling_mask", "tf.constant.get_shape", "time.time", "reconstruction.circ_sparsity_recon_rank1", "tensorflow.add", "tensorflow.reduce_prod", "tensorflow.reduce_prod", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "print", "tensorflow.ones", "tensorflow.ones", "tensorflow.Variable", "tensorflow.Variable", "print", "range", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "range"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_index_arr", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_circ_scaling_mask", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.circ_sparsity_recon_rank1"], ["", "def", "circ_sparsity_recon_hadamard", "(", "G", ",", "H", ",", "n", ",", "r", ",", "learn_corner", ",", "n_diag_learned", ",", "init_type", ",", "stddev", ")", ":", "\n", "    ", "if", "learn_corner", ":", "\n", "        ", "if", "init_type", "==", "'toeplitz'", ":", "\n", "            ", "f_A", "=", "tf", ".", "Variable", "(", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "f_B", "=", "tf", ".", "Variable", "(", "[", "-", "1", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "", "elif", "init_type", "==", "'random'", ":", "\n", "            ", "f_A", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "1", "]", ",", "stddev", "=", "stddev", ",", "dtype", "=", "tf", ".", "float64", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "f_B", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "1", "]", ",", "stddev", "=", "stddev", ",", "dtype", "=", "tf", ".", "float64", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'init_type not supported: '", ",", "init_type", ")", "\n", "assert", "0", "\n", "", "", "else", ":", "\n", "        ", "f_A", "=", "tf", ".", "constant", "(", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "f_B", "=", "tf", ".", "constant", "(", "[", "-", "1", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "# diag: first n_learned entries", "\n", "", "v_A", "=", "None", "\n", "v_B", "=", "None", "\n", "if", "n_diag_learned", ">", "0", ":", "\n", "        ", "if", "init_type", "==", "'toeplitz'", ":", "\n", "            ", "v_A", "=", "tf", ".", "Variable", "(", "tf", ".", "ones", "(", "n_diag_learned", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "v_B", "=", "tf", ".", "Variable", "(", "tf", ".", "ones", "(", "n_diag_learned", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "", "elif", "init_type", "==", "'random'", ":", "\n", "            ", "v_A", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "n_diag_learned", "]", ",", "stddev", "=", "stddev", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "v_B", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "n_diag_learned", "]", ",", "stddev", "=", "stddev", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'init_type not supported: '", ",", "init_type", ")", "\n", "assert", "0", "\n", "\n", "", "", "t0", "=", "time", ".", "time", "(", ")", "\n", "scaling_mask", "=", "tf", ".", "constant", "(", "gen_circ_scaling_mask", "(", "n", ")", ")", "\n", "\n", "t1", "=", "time", ".", "time", "(", ")", "\n", "\n", "f_mask_pattern", "=", "tf", ".", "constant", "(", "[", "[", "True", "if", "j", ">", "k", "else", "False", "for", "j", "in", "range", "(", "n", ")", "]", "for", "k", "in", "range", "(", "n", ")", "]", ")", "\n", "all_ones", "=", "tf", ".", "ones", "(", "f_mask_pattern", ".", "get_shape", "(", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "f_A_mask", "=", "tf", ".", "where", "(", "f_mask_pattern", ",", "f_A", "*", "all_ones", ",", "all_ones", ")", "\n", "f_B_mask", "=", "tf", ".", "where", "(", "f_mask_pattern", ",", "f_B", "*", "all_ones", ",", "all_ones", ")", "\n", "\n", "# Reconstruct W1 from G and H", "\n", "index_arr", "=", "gen_index_arr", "(", "n", ")", "\n", "\n", "\n", "W1", "=", "tf", ".", "zeros", "(", "[", "n", ",", "n", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "for", "i", "in", "range", "(", "r", ")", ":", "\n", "        ", "t", "=", "time", ".", "time", "(", ")", "\n", "prod", "=", "circ_sparsity_recon_rank1", "(", "n", ",", "v_A", ",", "v_B", ",", "G", "[", ":", ",", "i", "]", ",", "H", "[", ":", ",", "i", "]", ",", "f_A_mask", ",", "f_B_mask", ",", "scaling_mask", ",", "index_arr", ",", "n_diag_learned", ")", "\n", "W1", "=", "tf", ".", "add", "(", "W1", ",", "prod", ")", "\n", "\n", "# Compute a and b", "\n", "", "a", "=", "f_A", "\n", "b", "=", "f_B", "\n", "if", "v_A", "is", "not", "None", ":", "\n", "        ", "a", "*=", "tf", ".", "reduce_prod", "(", "v_A", ")", "\n", "", "if", "v_B", "is", "not", "None", ":", "\n", "        ", "b", "*=", "tf", ".", "reduce_prod", "(", "v_B", ")", "\n", "\n", "", "coeff", "=", "1.0", "/", "(", "1", "-", "a", "*", "b", ")", "\n", "\n", "#coeff = tf.Print(coeff,[coeff], message=\"my W1-values:\") # <-------- TF PRINT STATMENT", "\n", "\n", "W1_scaled", "=", "tf", ".", "scalar_mul", "(", "coeff", "[", "0", "]", ",", "W1", ")", "\n", "\n", "return", "W1_scaled", ",", "f_A", ",", "f_B", ",", "v_A", ",", "v_B", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.circ_sparsity_recon_rank1": [[124, 133], ["time.time", "utils.krylov_circ_transpose", "time.time", "utils.krylov_circ_transpose", "tensorflow.matmul", "tensorflow.transpose"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.krylov_circ_transpose", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.krylov_circ_transpose"], ["", "def", "circ_sparsity_recon_rank1", "(", "n", ",", "v_A", ",", "v_B", ",", "g", ",", "h", ",", "f_A_mask", ",", "f_B_mask", ",", "scaling_mask", ",", "index_arr", ",", "num_learned", ")", ":", "\n", "    ", "t1", "=", "time", ".", "time", "(", ")", "\n", "K1", "=", "krylov_circ_transpose", "(", "n", ",", "v_A", ",", "g", ",", "num_learned", ",", "f_A_mask", ",", "scaling_mask", ",", "index_arr", ")", "\n", "t2", "=", "time", ".", "time", "(", ")", "\n", "K2", "=", "krylov_circ_transpose", "(", "n", ",", "v_B", ",", "h", ",", "num_learned", ",", "f_B_mask", ",", "scaling_mask", ",", "index_arr", ")", "\n", "\n", "prod", "=", "tf", ".", "matmul", "(", "K1", ",", "tf", ".", "transpose", "(", "K2", ")", ")", "\n", "\n", "return", "prod", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.general_tf": [[135, 146], ["tensorflow.zeros", "range", "utils.krylov_tf", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.add", "utils.krylov_tf", "tensorflow.transpose"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.krylov_tf", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.krylov_tf"], ["", "def", "general_tf", "(", "A", ",", "B", ",", "G", ",", "H", ",", "r", ",", "m", ",", "n", ")", ":", "\n", "    ", "M", "=", "tf", ".", "zeros", "(", "[", "m", ",", "n", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "for", "i", "in", "range", "(", "r", ")", ":", "\n", "        ", "K_A_g", "=", "krylov_tf", "(", "A", ",", "G", "[", ":", ",", "i", "]", ",", "m", ")", "\n", "K_B_h", "=", "tf", ".", "transpose", "(", "krylov_tf", "(", "tf", ".", "transpose", "(", "B", ")", ",", "H", "[", ":", ",", "i", "]", ",", "n", ")", ")", "\n", "\n", "this_prod", "=", "tf", ".", "matmul", "(", "K_A_g", ",", "K_B_h", ")", "\n", "M", "=", "tf", ".", "add", "(", "M", ",", "this_prod", ")", "\n", "\n", "", "return", "0.5", "*", "M", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.compute_J_term": [[147, 154], ["numpy.linalg.inv", "numpy.flipud", "numpy.dot", "numpy.eye", "numpy.eye", "numpy.linalg.matrix_power"], "function", ["None"], ["", "def", "compute_J_term", "(", "m", ",", "n", ",", "B", ",", "e", ")", ":", "\n", "    ", "term", "=", "np", ".", "eye", "(", "n", ")", "-", "e", "*", "np", ".", "linalg", ".", "matrix_power", "(", "B", ",", "m", ")", "\n", "term_inv", "=", "np", ".", "linalg", ".", "inv", "(", "term", ")", "\n", "J", "=", "np", ".", "flipud", "(", "np", ".", "eye", "(", "n", ")", ")", "#np.flip(np.eye(n), axis=0)", "\n", "\n", "# Multiply by J", "\n", "return", "np", ".", "dot", "(", "J", ",", "term_inv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.rect_recon_tf": [[155, 180], ["tensorflow.constant", "utils.gen_f_mask", "int", "reconstruction.compute_J_term", "utils.gen_index_arr", "utils.gen_index_arr", "tensorflow.zeros", "tensorflow.reverse", "range", "tensorflow.matmul", "numpy.ceil", "utils.circulant_tf", "utils.circulant_mn_tf", "tensorflow.matmul", "tensorflow.add", "tensorflow.transpose", "range", "float", "range"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_f_mask", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.compute_J_term", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_index_arr", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_index_arr", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.circulant_tf", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.circulant_mn_tf"], ["", "def", "rect_recon_tf", "(", "G", ",", "H", ",", "B", ",", "m", ",", "n", ",", "e", ",", "f", ",", "r", ")", ":", "\n", "    ", "e_mask", "=", "tf", ".", "constant", "(", "[", "[", "e", "if", "j", ">", "k", "else", "1", "for", "j", "in", "range", "(", "m", ")", "]", "for", "k", "in", "range", "(", "m", ")", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "f_mask", "=", "gen_f_mask", "(", "f", ",", "n", ",", "m", ")", "\n", "num_reps", "=", "int", "(", "np", ".", "ceil", "(", "float", "(", "m", ")", "/", "n", ")", ")", "\n", "\n", "# Compute J-term: once", "\n", "J_term", "=", "compute_J_term", "(", "m", ",", "n", ",", "B", ",", "e", ")", "\n", "\n", "index_arr_m", "=", "gen_index_arr", "(", "m", ")", "\n", "index_arr_n", "=", "gen_index_arr", "(", "n", ")", "\n", "\n", "recon_mat_partial", "=", "tf", ".", "zeros", "(", "[", "m", ",", "n", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "Jh", "=", "tf", ".", "reverse", "(", "H", ",", "[", "0", "]", ")", "\n", "\n", "for", "i", "in", "range", "(", "r", ")", ":", "\n", "        ", "Zg_i", "=", "circulant_tf", "(", "G", "[", ":", ",", "i", "]", ",", "index_arr_m", ",", "e_mask", ")", "\n", "Zh_i", "=", "circulant_mn_tf", "(", "Jh", "[", ":", ",", "i", "]", ",", "index_arr_n", ",", "m", ",", "num_reps", ",", "f_mask", ")", "\n", "\n", "this_prod", "=", "tf", ".", "matmul", "(", "Zg_i", ",", "tf", ".", "transpose", "(", "Zh_i", ")", ")", "\n", "recon_mat_partial", "=", "tf", ".", "add", "(", "recon_mat_partial", ",", "this_prod", ")", "\n", "\n", "", "recon_mat_partial", "=", "tf", ".", "matmul", "(", "recon_mat_partial", ",", "J_term", ")", "\n", "\n", "return", "recon_mat_partial", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.toeplitz_recon": [[182, 184], ["None"], "function", ["None"], ["", "def", "toeplitz_recon", "(", "r", ",", "c", ")", ":", "\n", "    ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.toeplitz_like_recon": [[185, 202], ["tensorflow.zeros", "tensorflow.constant", "tensorflow.constant", "utils.gen_index_arr", "range", "tensorflow.scalar_mul", "utils.circulant_tf", "utils.circulant_tf", "tensorflow.matmul", "tensorflow.add", "tensorflow.reverse", "range", "range", "tensorflow.constant", "range", "range"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_index_arr", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.circulant_tf", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.circulant_tf"], ["", "def", "toeplitz_like_recon", "(", "G", ",", "H", ",", "n", ",", "r", ")", ":", "\n", "    ", "W1", "=", "tf", ".", "zeros", "(", "[", "n", ",", "n", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "f", "=", "1", "\n", "g", "=", "-", "1", "\n", "f_mask", "=", "tf", ".", "constant", "(", "[", "[", "f", "if", "j", ">", "k", "else", "1", "for", "j", "in", "range", "(", "n", ")", "]", "for", "k", "in", "range", "(", "n", ")", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "g_mask", "=", "tf", ".", "constant", "(", "[", "[", "g", "if", "j", ">", "k", "else", "1", "for", "j", "in", "range", "(", "n", ")", "]", "for", "k", "in", "range", "(", "n", ")", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "index_arr", "=", "gen_index_arr", "(", "n", ")", "\n", "\n", "for", "i", "in", "range", "(", "r", ")", ":", "\n", "        ", "Z_g_i", "=", "circulant_tf", "(", "G", "[", ":", ",", "i", "]", ",", "index_arr", ",", "f_mask", ")", "\n", "Z_h_i", "=", "circulant_tf", "(", "tf", ".", "reverse", "(", "H", "[", ":", ",", "i", "]", ",", "tf", ".", "constant", "(", "[", "0", "]", ")", ")", ",", "index_arr", ",", "g_mask", ")", "\n", "prod", "=", "tf", ".", "matmul", "(", "Z_g_i", ",", "Z_h_i", ")", "\n", "W1", "=", "tf", ".", "add", "(", "W1", ",", "prod", ")", "\n", "\n", "", "W1", "=", "tf", ".", "scalar_mul", "(", "0.5", ",", "W1", ")", "\n", "\n", "return", "W1", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.vand_recon": [[205, 232], ["tensorflow.pow", "tensorflow.cast", "tensorflow.subtract", "tensorflow.divide", "tensorflow.diag", "utils.gen_index_arr", "utils.gen_f_mask", "tensorflow.zeros", "range", "tensorflow.matmul", "tensorflow.scalar_mul", "tensorflow.constant", "tensorflow.constant", "tensorflow.diag", "utils.V_mn", "utils.circulant_tf", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.matmul", "tensorflow.add"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_index_arr", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_f_mask", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.V_mn", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.circulant_tf"], ["", "def", "vand_recon", "(", "G", ",", "H", ",", "v", ",", "m", ",", "n", ",", "f", ",", "r", ")", ":", "\n", "# Create vector of fv_i^n", "\n", "    ", "raised", "=", "tf", ".", "pow", "(", "v", ",", "n", ")", "\n", "scaled", "=", "tf", ".", "cast", "(", "tf", ".", "scalar_mul", "(", "f", ",", "raised", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "denom", "=", "tf", ".", "subtract", "(", "tf", ".", "constant", "(", "1", ",", "dtype", "=", "tf", ".", "float64", ")", ",", "scaled", ")", "\n", "divided", "=", "tf", ".", "divide", "(", "tf", ".", "constant", "(", "1", ",", "dtype", "=", "tf", ".", "float64", ")", ",", "denom", ")", "\n", "D", "=", "tf", ".", "diag", "(", "divided", ")", "\n", "\n", "index_arr", "=", "gen_index_arr", "(", "n", ")", "\n", "f_mask", "=", "gen_f_mask", "(", "f", ",", "n", ",", "n", ")", "\n", "\n", "recon", "=", "tf", ".", "zeros", "(", "[", "m", ",", "n", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "for", "i", "in", "range", "(", "r", ")", ":", "\n", "        ", "D_g_i", "=", "tf", ".", "diag", "(", "G", "[", ":", ",", "i", "]", ")", "\n", "V_v", "=", "V_mn", "(", "v", ",", "m", ",", "n", ")", "\n", "Z_h_i", "=", "circulant_tf", "(", "H", "[", ":", ",", "i", "]", ",", "index_arr", ",", "f_mask", ")", "\n", "Z_h_i", "=", "tf", ".", "transpose", "(", "Z_h_i", ")", "\n", "\n", "this_prod", "=", "tf", ".", "matmul", "(", "D_g_i", ",", "V_v", ")", "\n", "this_prod", "=", "tf", ".", "matmul", "(", "this_prod", ",", "Z_h_i", ")", "\n", "\n", "recon", "=", "tf", ".", "add", "(", "recon", ",", "this_prod", ")", "\n", "\n", "", "recon", "=", "tf", ".", "matmul", "(", "D", ",", "recon", ")", "\n", "\n", "return", "recon", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.reconstruction.sylvester": [[233, 247], ["numpy.random.random", "numpy.random.random", "numpy.dot", "scipy.linalg.solve_sylvester", "numpy.dot", "numpy.dot"], "function", ["None"], ["", "def", "sylvester", "(", "M", ",", "N", ",", "n", ",", "r", ")", ":", "\n", "# Generate random rank r error matrix", "\n", "    ", "G", "=", "np", ".", "random", ".", "random", "(", "(", "n", ",", "r", ")", ")", "\n", "H", "=", "np", ".", "random", ".", "random", "(", "(", "n", ",", "r", ")", ")", "\n", "GH", "=", "np", ".", "dot", "(", "G", ",", "H", ".", "T", ")", "\n", "\n", "# Solve Sylvester equation to recover A", "\n", "# Such that MA - AN^T = GH^T", "\n", "A", "=", "solve_sylvester", "(", "M", ",", "-", "N", ",", "GH", ")", "\n", "\n", "E", "=", "np", ".", "dot", "(", "M", ",", "A", ")", "-", "np", ".", "dot", "(", "A", ",", "N", ")", "\n", "\n", "\n", "return", "A", ",", "G", ",", "H", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.learned_operators.tridiagonal_corner": [[10, 122], ["tensorflow.placeholder", "tensorflow.Variable", "utils.get_tridiag_corner_vars", "functools.partial", "functools.partial", "tensorflow.zeros", "range", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.multiply", "compute_y", "tensorflow.placeholder", "utils.compute_loss_and_accuracy", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.FileWriter", "tensorflow.train.MomentumOptimizer().minimize", "tensorflow.InteractiveSession", "tensorflow.initialize_all_variables().run", "tensorflow.train.Saver", "tensorflow.truncated_normal", "tensorflow.Variable", "tensorflow.truncated_normal", "krylov.krylov", "krylov.krylov", "tensorflow.matmul", "tensorflow.add", "tensorflow.reduce_prod", "tensorflow.reduce_prod", "dataset.batch", "tf.InteractiveSession.run", "dataset.load_test_data", "tf.InteractiveSession.run", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "print", "print", "tensorflow.truncated_normal", "tensorflow.transpose", "tensorflow.get_default_graph", "tensorflow.train.MomentumOptimizer", "tensorflow.initialize_all_variables", "print", "tf.InteractiveSession.run", "tf.InteractiveSession.run", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "train_losses.append", "train_accuracies.append", "val_losses.append", "val_accuracies.append", "print", "print", "tf.train.Saver.save", "print", "print", "os.path.join", "str"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_tridiag_corner_vars", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.compute_y", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.compute_loss_and_accuracy", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.batch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.load_test_data", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model_params.ModelParams.save"], ["def", "tridiagonal_corner", "(", "dataset", ",", "params", ",", "test_freq", "=", "100", ",", "verbose", "=", "False", ")", ":", "\n", "# Create the model", "\n", "\t", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "[", "None", ",", "params", ".", "input_size", "]", ")", "\n", "if", "params", ".", "fix_G", ":", "\n", "\t\t", "G", "=", "tf", ".", "truncated_normal", "(", "[", "params", ".", "layer_size", ",", "params", ".", "r", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "", "else", ":", "\n", "\t\t", "G", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "params", ".", "layer_size", ",", "params", ".", "r", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "", "H", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "params", ".", "layer_size", ",", "params", ".", "r", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "\n", "subdiag_A", ",", "supdiag_A", ",", "diag_A", ",", "f_A", ",", "subdiag_B", ",", "supdiag_B", ",", "diag_B", ",", "f_B", "=", "get_tridiag_corner_vars", "(", "params", ".", "layer_size", ",", "params", ".", "init_type", ",", "params", ".", "init_stddev", ",", "params", ".", "learn_corner", ")", "\n", "\n", "fn_A", "=", "functools", ".", "partial", "(", "tridiag_corner_transpose_mult_fn", ",", "subdiag_A", ",", "diag_A", ",", "supdiag_A", ",", "f_A", ")", "\n", "fn_B", "=", "functools", ".", "partial", "(", "tridiag_corner_transpose_mult_fn", ",", "subdiag_B", ",", "diag_B", ",", "supdiag_B", ",", "f_B", ")", "\n", "\n", "W1", "=", "tf", ".", "zeros", "(", "[", "params", ".", "layer_size", ",", "params", ".", "layer_size", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "for", "i", "in", "range", "(", "params", ".", "r", ")", ":", "\n", "\t\t", "K_A", "=", "krylov", "(", "fn_A", ",", "G", "[", ":", ",", "i", "]", ",", "params", ".", "layer_size", ")", "\n", "K_B", "=", "krylov", "(", "fn_B", ",", "H", "[", ":", ",", "i", "]", ",", "params", ".", "layer_size", ")", "\n", "prod", "=", "tf", ".", "matmul", "(", "K_A", ",", "tf", ".", "transpose", "(", "K_B", ")", ")", "\n", "W1", "=", "tf", ".", "add", "(", "W1", ",", "prod", ")", "\n", "\n", "# Compute a and b", "\n", "", "a", "=", "tf", ".", "multiply", "(", "f_A", ",", "tf", ".", "reduce_prod", "(", "subdiag_A", ")", ")", "\n", "b", "=", "tf", ".", "multiply", "(", "f_B", ",", "tf", ".", "reduce_prod", "(", "subdiag_B", ")", ")", "\n", "\n", "coeff", "=", "1.0", "/", "(", "1", "-", "a", "*", "b", ")", "\n", "\n", "W1", "=", "tf", ".", "multiply", "(", "coeff", ",", "W1", ")", "\n", "\n", "y", "=", "compute_y", "(", "x", ",", "W1", ",", "params", ")", "\n", "\n", "y_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "[", "None", ",", "params", ".", "out_size", "]", ")", "\n", "\n", "loss", ",", "accuracy", "=", "compute_loss_and_accuracy", "(", "y", ",", "y_", ",", "params", ")", "\n", "\n", "train_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'train_loss'", ",", "loss", ")", "\n", "train_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'train_accuracy'", ",", "accuracy", ")", "\n", "val_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'val_loss'", ",", "loss", ")", "\n", "val_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'val_accuracy'", ",", "accuracy", ")", "\n", "test_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'test_loss'", ",", "loss", ")", "\n", "test_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'test_accuracy'", ",", "accuracy", ")", "\n", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "params", ".", "log_path", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", ")", "\n", "\n", "train_step", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "params", ".", "lr", ",", "params", ".", "mom", ")", ".", "minimize", "(", "loss", ")", "\n", "sess", "=", "tf", ".", "InteractiveSession", "(", ")", "\n", "tf", ".", "initialize_all_variables", "(", ")", ".", "run", "(", ")", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "step", "=", "0", "\n", "\n", "losses", "=", "{", "}", "\n", "accuracies", "=", "{", "}", "\n", "train_losses", "=", "[", "]", "\n", "train_accuracies", "=", "[", "]", "\n", "val_losses", "=", "[", "]", "\n", "val_accuracies", "=", "[", "]", "\n", "\n", "while", "step", "<", "params", ".", "steps", ":", "\n", "\t\t", "batch_xs", ",", "batch_ys", "=", "dataset", ".", "batch", "(", "params", ".", "batch_size", ",", "step", ")", "\n", "_", "=", "sess", ".", "run", "(", "[", "train_step", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "\n", "if", "step", "%", "test_freq", "==", "0", ":", "\n", "\t\t\t", "print", "(", "(", "'Training step: '", ",", "step", ")", ")", "\n", "train_loss", ",", "train_accuracy", ",", "train_loss_summ", ",", "train_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "train_loss_summary", ",", "\n", "train_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "val_loss", ",", "val_accuracy", ",", "val_loss_summ", ",", "val_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "val_loss_summary", ",", "\n", "val_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "val_X", ",", "y_", ":", "dataset", ".", "val_Y", "}", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "train_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "train_acc_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "val_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "val_acc_summ", ",", "step", ")", "\n", "\n", "train_losses", ".", "append", "(", "train_loss", ")", "\n", "train_accuracies", ".", "append", "(", "train_accuracy", ")", "\n", "val_losses", ".", "append", "(", "val_loss", ")", "\n", "val_accuracies", ".", "append", "(", "val_accuracy", ")", "\n", "\n", "print", "(", "(", "'Train loss, accuracy: '", ",", "train_loss", ",", "train_accuracy", ")", ")", "\n", "print", "(", "(", "'Validation loss, accuracy: '", ",", "val_loss", ",", "val_accuracy", ")", ")", "\n", "\n", "if", "verbose", ":", "\n", "\t\t\t\t", "print", "(", "(", "'Current W1: '", ",", "W1_real", ")", ")", "\n", "\n", "", "", "if", "step", "%", "params", ".", "checkpoint_freq", "==", "0", ":", "\n", "\t\t\t", "save_path", "=", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "params", ".", "checkpoint_path", ",", "str", "(", "step", ")", ")", ")", "\n", "print", "(", "(", "\"Model saved in file: %s\"", "%", "save_path", ")", ")", "\n", "\n", "", "step", "+=", "1", "\n", "\n", "", "losses", "[", "'train'", "]", "=", "train_losses", "\n", "losses", "[", "'val'", "]", "=", "val_losses", "\n", "accuracies", "[", "'train'", "]", "=", "train_accuracies", "\n", "accuracies", "[", "'val'", "]", "=", "val_accuracies", "\n", "\n", "# Test trained model", "\n", "if", "params", ".", "test", ":", "\n", "# Load test", "\n", "\t\t", "dataset", ".", "load_test_data", "(", ")", "\n", "test_loss", ",", "test_accuracy", ",", "test_loss_summ", ",", "test_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "test_loss_summary", ",", "test_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "test_X", ",", "y_", ":", "dataset", ".", "test_Y", "}", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "test_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "test_acc_summ", ",", "step", ")", "\n", "\n", "print", "(", "(", "'SGD test loss, tridiagonal+corner: '", ",", "test_loss", ")", ")", "\n", "print", "(", "(", "'SGD test accuracy, tridiagonal+corner: '", ",", "test_accuracy", ")", ")", "\n", "losses", "[", "'test'", "]", "=", "test_loss", "\n", "accuracies", "[", "'test'", "]", "=", "test_accuracy", "\n", "\n", "", "return", "losses", ",", "accuracies", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.learned_operators.polynomial_transform": [[123, 241], ["tensorflow.placeholder", "tensorflow.Variable", "utils.get_symm_pos_tridiag_vars", "functools.partial", "functools.partial", "tensorflow.zeros", "range", "compute_y", "tensorflow.placeholder", "utils.compute_loss_and_accuracy", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.FileWriter", "tensorflow.train.MomentumOptimizer().minimize", "tensorflow.InteractiveSession", "tensorflow.initialize_all_variables().run", "tensorflow.train.Saver", "tensorflow.truncated_normal", "tensorflow.Variable", "tensorflow.truncated_normal", "krylov.krylov", "krylov.krylov", "tensorflow.matmul", "tensorflow.add", "dataset.batch", "tf.InteractiveSession.run", "dataset.load_test_data", "tf.InteractiveSession.run", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "print", "print", "tensorflow.truncated_normal", "tensorflow.transpose", "tensorflow.get_default_graph", "tensorflow.train.MomentumOptimizer", "tensorflow.initialize_all_variables", "print", "tf.InteractiveSession.run", "tf.InteractiveSession.run", "print", "print", "print", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "train_losses.append", "train_accuracies.append", "val_losses.append", "val_accuracies.append", "print", "print", "tf.train.Saver.save", "print", "print", "os.path.join", "str"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_symm_pos_tridiag_vars", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.compute_y", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.compute_loss_and_accuracy", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.batch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.load_test_data", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model_params.ModelParams.save"], ["", "def", "polynomial_transform", "(", "dataset", ",", "params", ",", "test_freq", "=", "100", ",", "verbose", "=", "False", ")", ":", "\n", "# Create the model", "\n", "\t", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "[", "None", ",", "params", ".", "input_size", "]", ")", "\n", "if", "params", ".", "fix_G", ":", "\n", "\t\t", "G", "=", "tf", ".", "truncated_normal", "(", "[", "params", ".", "n", ",", "params", ".", "r", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "", "else", ":", "\n", "\t\t", "G", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "params", ".", "n", ",", "params", ".", "r", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "", "H", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "params", ".", "n", ",", "params", ".", "r", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "\n", "diag_A", ",", "off_diag_A", ",", "diag_B", "=", "get_symm_pos_tridiag_vars", "(", "params", ".", "n", ",", "params", ".", "init_type", ",", "params", ".", "init_stddev", ")", "\n", "\n", "fn_A", "=", "functools", ".", "partial", "(", "symm_tridiag_mult_fn", ",", "diag_A", ",", "off_diag_A", ")", "\n", "fn_B", "=", "functools", ".", "partial", "(", "diag_mult_fn", ",", "diag_B", ")", "\n", "\n", "W1", "=", "tf", ".", "zeros", "(", "[", "params", ".", "n", ",", "params", ".", "n", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "for", "i", "in", "range", "(", "params", ".", "r", ")", ":", "\n", "\t\t", "K_A", "=", "krylov", "(", "fn_A", ",", "G", "[", ":", ",", "i", "]", ",", "params", ".", "n", ")", "\n", "K_B", "=", "krylov", "(", "fn_B", ",", "H", "[", ":", ",", "i", "]", ",", "params", ".", "n", ")", "\n", "prod", "=", "tf", ".", "matmul", "(", "K_A", ",", "tf", ".", "transpose", "(", "K_B", ")", ")", "\n", "W1", "=", "tf", ".", "add", "(", "W1", ",", "prod", ")", "\n", "\n", "# Compute a and b", "\n", "", "\"\"\"\n\ta = tf.reduce_prod(f_x_A)\n\tb = tf.reduce_prod(f_x_B)\n\n\tcoeff = 1.0/(1 - a*b)\n\n\tW1 = tf.scalar_mul(coeff, W1)\n\t\"\"\"", "\n", "\n", "y", "=", "compute_y", "(", "x", ",", "W1", ",", "params", ")", "\n", "\n", "y_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "[", "None", ",", "params", ".", "out_size", "]", ")", "\n", "\n", "loss", ",", "accuracy", "=", "compute_loss_and_accuracy", "(", "y", ",", "y_", ",", "params", ")", "\n", "\n", "train_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'train_loss'", ",", "loss", ")", "\n", "train_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'train_accuracy'", ",", "accuracy", ")", "\n", "val_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'val_loss'", ",", "loss", ")", "\n", "val_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'val_accuracy'", ",", "accuracy", ")", "\n", "test_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'test_loss'", ",", "loss", ")", "\n", "test_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'test_accuracy'", ",", "accuracy", ")", "\n", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "params", ".", "log_path", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", ")", "\n", "\n", "train_step", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "params", ".", "lr", ",", "params", ".", "mom", ")", ".", "minimize", "(", "loss", ")", "\n", "sess", "=", "tf", ".", "InteractiveSession", "(", ")", "\n", "tf", ".", "initialize_all_variables", "(", ")", ".", "run", "(", ")", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "step", "=", "0", "\n", "\n", "losses", "=", "{", "}", "\n", "accuracies", "=", "{", "}", "\n", "train_losses", "=", "[", "]", "\n", "train_accuracies", "=", "[", "]", "\n", "val_losses", "=", "[", "]", "\n", "val_accuracies", "=", "[", "]", "\n", "\n", "while", "step", "<", "params", ".", "steps", ":", "\n", "\t\t", "batch_xs", ",", "batch_ys", "=", "dataset", ".", "batch", "(", "params", ".", "batch_size", ",", "step", ")", "\n", "_", "=", "sess", ".", "run", "(", "[", "train_step", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "\n", "if", "step", "%", "test_freq", "==", "0", ":", "\n", "\t\t\t", "print", "(", "(", "'Training step: '", ",", "step", ")", ")", "\n", "train_loss", ",", "train_accuracy", ",", "train_loss_summ", ",", "train_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "train_loss_summary", ",", "\n", "train_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "val_loss", ",", "val_accuracy", ",", "val_loss_summ", ",", "val_acc_summ", ",", "this_diag_A", ",", "this_off_diag_A", ",", "this_diag_B", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "val_loss_summary", ",", "\n", "val_acc_summary", ",", "diag_A", ",", "off_diag_A", ",", "diag_B", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "val_X", ",", "y_", ":", "dataset", ".", "val_Y", "}", ")", "\n", "\n", "print", "(", "'diag_A: '", ",", "this_diag_A", ")", "\n", "print", "(", "'off_diag_A: '", ",", "this_off_diag_A", ")", "\n", "print", "(", "'diag_B: '", ",", "this_diag_B", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "train_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "train_acc_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "val_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "val_acc_summ", ",", "step", ")", "\n", "\n", "train_losses", ".", "append", "(", "train_loss", ")", "\n", "train_accuracies", ".", "append", "(", "train_accuracy", ")", "\n", "val_losses", ".", "append", "(", "val_loss", ")", "\n", "val_accuracies", ".", "append", "(", "val_accuracy", ")", "\n", "\n", "print", "(", "(", "'Train loss, accuracy: '", ",", "train_loss", ",", "train_accuracy", ")", ")", "\n", "print", "(", "(", "'Validation loss, accuracy: '", ",", "val_loss", ",", "val_accuracy", ")", ")", "\n", "\n", "if", "verbose", ":", "\n", "\t\t\t\t", "print", "(", "(", "'Current W1: '", ",", "W1_real", ")", ")", "\n", "\n", "", "", "if", "step", "%", "params", ".", "checkpoint_freq", "==", "0", ":", "\n", "\t\t\t", "save_path", "=", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "params", ".", "checkpoint_path", ",", "str", "(", "step", ")", ")", ")", "\n", "print", "(", "(", "\"Model saved in file: %s\"", "%", "save_path", ")", ")", "\n", "\n", "", "step", "+=", "1", "\n", "\n", "", "losses", "[", "'train'", "]", "=", "train_losses", "\n", "losses", "[", "'val'", "]", "=", "val_losses", "\n", "accuracies", "[", "'train'", "]", "=", "train_accuracies", "\n", "accuracies", "[", "'val'", "]", "=", "val_accuracies", "\n", "\n", "# Test trained model", "\n", "if", "params", ".", "test", ":", "\n", "# Load test", "\n", "\t\t", "dataset", ".", "load_test_data", "(", ")", "\n", "test_loss", ",", "test_accuracy", ",", "test_loss_summ", ",", "test_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "test_loss_summary", ",", "test_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "test_X", ",", "y_", ":", "dataset", ".", "test_Y", "}", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "test_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "test_acc_summ", ",", "step", ")", "\n", "\n", "print", "(", "(", "'SGD test loss, polynomial transform: '", ",", "test_loss", ")", ")", "\n", "print", "(", "(", "'SGD test accuracy, polynomial transform: '", ",", "test_accuracy", ")", ")", "\n", "losses", "[", "'test'", "]", "=", "test_loss", "\n", "accuracies", "[", "'test'", "]", "=", "test_accuracy", "\n", "\n", "", "return", "losses", ",", "accuracies", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.learned_operators.circulant_sparsity": [[242, 362], ["tensorflow.placeholder", "tensorflow.Variable", "get_f_x", "tensorflow.zeros", "range", "tensorflow.reduce_prod", "tensorflow.reduce_prod", "tensorflow.scalar_mul", "compute_y", "tensorflow.placeholder", "utils.compute_loss_and_accuracy", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.FileWriter", "tensorflow.train.MomentumOptimizer().minimize", "tensorflow.InteractiveSession", "tensorflow.initialize_all_variables().run", "tensorflow.train.Saver", "tensorflow.truncated_normal", "tensorflow.Variable", "tensorflow.truncated_normal", "tensorflow.Variable", "tensorflow.Variable", "functools.partial", "functools.partial", "functools.partial", "functools.partial", "krylov.krylov", "krylov.krylov", "tensorflow.matmul", "tensorflow.add", "dataset.batch", "tf.InteractiveSession.run", "dataset.load_test_data", "tf.InteractiveSession.run", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "print", "print", "tensorflow.truncated_normal", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.reverse", "tensorflow.reverse", "tensorflow.reverse", "tensorflow.reverse", "tensorflow.transpose", "tensorflow.get_default_graph", "tensorflow.train.MomentumOptimizer", "tensorflow.initialize_all_variables", "print", "tf.InteractiveSession.run", "tf.InteractiveSession.run", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "tf.summary.FileWriter.add_summary", "train_losses.append", "train_accuracies.append", "val_losses.append", "val_accuracies.append", "print", "print", "tf.train.Saver.save", "print", "print", "os.path.join", "str"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.compute_y", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.compute_loss_and_accuracy", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.krylov", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.batch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.load_test_data", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model_params.ModelParams.save"], ["", "def", "circulant_sparsity", "(", "dataset", ",", "params", ",", "test_freq", "=", "100", ",", "verbose", "=", "False", ")", ":", "\n", "# Create the model", "\n", "\t", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "[", "None", ",", "params", ".", "input_size", "]", ")", "\n", "if", "params", ".", "fix_G", ":", "\n", "\t\t", "G", "=", "tf", ".", "truncated_normal", "(", "[", "params", ".", "layer_size", ",", "params", ".", "r", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "", "else", ":", "\n", "\t\t", "G", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "params", ".", "layer_size", ",", "params", ".", "r", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "", "H", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "params", ".", "layer_size", ",", "params", ".", "r", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "\n", "f_x_A", ",", "f_x_B", "=", "get_f_x", "(", "params", ".", "layer_size", ",", "params", ".", "init_type", ",", "params", ".", "learn_corner", ",", "params", ".", "n_diag_learned", ",", "params", ".", "init_stddev", ")", "\n", "\n", "if", "params", ".", "learn_diagonal", ":", "\n", "\t\t", "diag_A", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "params", ".", "layer_size", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "diag_B", "=", "tf", ".", "Variable", "(", "tf", ".", "zeros", "(", "params", ".", "layer_size", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "fn_A", "=", "functools", ".", "partial", "(", "circ_diag_transpose_mult_fn", ",", "tf", ".", "reverse", "(", "f_x_A", ",", "[", "0", "]", ")", ",", "diag_A", ")", "\n", "fn_B", "=", "functools", ".", "partial", "(", "circ_diag_transpose_mult_fn", ",", "tf", ".", "reverse", "(", "f_x_B", ",", "[", "0", "]", ")", ",", "diag_B", ")", "\n", "\n", "", "else", ":", "\n", "\t\t", "fn_A", "=", "functools", ".", "partial", "(", "circ_transpose_mult_fn", ",", "tf", ".", "reverse", "(", "f_x_A", ",", "[", "0", "]", ")", ")", "\n", "fn_B", "=", "functools", ".", "partial", "(", "circ_transpose_mult_fn", ",", "tf", ".", "reverse", "(", "f_x_B", ",", "[", "0", "]", ")", ")", "\n", "\n", "", "W1", "=", "tf", ".", "zeros", "(", "[", "params", ".", "layer_size", ",", "params", ".", "layer_size", "]", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "for", "i", "in", "range", "(", "params", ".", "r", ")", ":", "\n", "\t\t", "K_A", "=", "krylov", "(", "fn_A", ",", "G", "[", ":", ",", "i", "]", ",", "params", ".", "layer_size", ")", "\n", "K_B", "=", "krylov", "(", "fn_B", ",", "H", "[", ":", ",", "i", "]", ",", "params", ".", "layer_size", ")", "\n", "prod", "=", "tf", ".", "matmul", "(", "K_A", ",", "tf", ".", "transpose", "(", "K_B", ")", ")", "\n", "W1", "=", "tf", ".", "add", "(", "W1", ",", "prod", ")", "\n", "\n", "# Compute a and b", "\n", "", "a", "=", "tf", ".", "reduce_prod", "(", "f_x_A", ")", "\n", "b", "=", "tf", ".", "reduce_prod", "(", "f_x_B", ")", "\n", "\n", "coeff", "=", "1.0", "/", "(", "1", "-", "a", "*", "b", ")", "\n", "\n", "W1", "=", "tf", ".", "scalar_mul", "(", "coeff", ",", "W1", ")", "\n", "\n", "y", "=", "compute_y", "(", "x", ",", "W1", ",", "params", ")", "\n", "\n", "y_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "[", "None", ",", "params", ".", "out_size", "]", ")", "\n", "\n", "loss", ",", "accuracy", "=", "compute_loss_and_accuracy", "(", "y", ",", "y_", ",", "params", ")", "\n", "\n", "train_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'train_loss'", ",", "loss", ")", "\n", "train_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'train_accuracy'", ",", "accuracy", ")", "\n", "val_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'val_loss'", ",", "loss", ")", "\n", "val_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'val_accuracy'", ",", "accuracy", ")", "\n", "test_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'test_loss'", ",", "loss", ")", "\n", "test_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'test_accuracy'", ",", "accuracy", ")", "\n", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "params", ".", "log_path", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", ")", "\n", "\n", "train_step", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "params", ".", "lr", ",", "params", ".", "mom", ")", ".", "minimize", "(", "loss", ")", "\n", "sess", "=", "tf", ".", "InteractiveSession", "(", ")", "\n", "tf", ".", "initialize_all_variables", "(", ")", ".", "run", "(", ")", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "step", "=", "0", "\n", "\n", "losses", "=", "{", "}", "\n", "accuracies", "=", "{", "}", "\n", "train_losses", "=", "[", "]", "\n", "train_accuracies", "=", "[", "]", "\n", "val_losses", "=", "[", "]", "\n", "val_accuracies", "=", "[", "]", "\n", "\n", "while", "step", "<", "params", ".", "steps", ":", "\n", "\t\t", "batch_xs", ",", "batch_ys", "=", "dataset", ".", "batch", "(", "params", ".", "batch_size", ",", "step", ")", "\n", "_", "=", "sess", ".", "run", "(", "[", "train_step", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "\n", "\n", "if", "step", "%", "test_freq", "==", "0", ":", "\n", "\t\t\t", "print", "(", "(", "'Training step: '", ",", "step", ")", ")", "\n", "train_loss", ",", "train_accuracy", ",", "train_loss_summ", ",", "train_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "train_loss_summary", ",", "\n", "train_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "val_loss", ",", "val_accuracy", ",", "val_loss_summ", ",", "val_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "val_loss_summary", ",", "\n", "val_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "val_X", ",", "y_", ":", "dataset", ".", "val_Y", "}", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "train_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "train_acc_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "val_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "val_acc_summ", ",", "step", ")", "\n", "\n", "train_losses", ".", "append", "(", "train_loss", ")", "\n", "train_accuracies", ".", "append", "(", "train_accuracy", ")", "\n", "val_losses", ".", "append", "(", "val_loss", ")", "\n", "val_accuracies", ".", "append", "(", "val_accuracy", ")", "\n", "\n", "print", "(", "(", "'Train loss, accuracy: '", ",", "train_loss", ",", "train_accuracy", ")", ")", "\n", "print", "(", "(", "'Validation loss, accuracy: '", ",", "val_loss", ",", "val_accuracy", ")", ")", "\n", "\n", "if", "verbose", ":", "\n", "\t\t\t\t", "print", "(", "(", "'Current W1: '", ",", "W1_real", ")", ")", "\n", "\n", "", "", "if", "step", "%", "params", ".", "checkpoint_freq", "==", "0", ":", "\n", "\t\t\t", "save_path", "=", "saver", ".", "save", "(", "sess", ",", "os", ".", "path", ".", "join", "(", "params", ".", "checkpoint_path", ",", "str", "(", "step", ")", ")", ")", "\n", "print", "(", "(", "\"Model saved in file: %s\"", "%", "save_path", ")", ")", "\n", "\n", "", "step", "+=", "1", "\n", "\n", "", "losses", "[", "'train'", "]", "=", "train_losses", "\n", "losses", "[", "'val'", "]", "=", "val_losses", "\n", "accuracies", "[", "'train'", "]", "=", "train_accuracies", "\n", "accuracies", "[", "'val'", "]", "=", "val_accuracies", "\n", "\n", "# Test trained model", "\n", "if", "params", ".", "test", ":", "\n", "# Load test", "\n", "\t\t", "dataset", ".", "load_test_data", "(", ")", "\n", "test_loss", ",", "test_accuracy", ",", "test_loss_summ", ",", "test_acc_summ", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", ",", "test_loss_summary", ",", "test_acc_summary", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "test_X", ",", "y_", ":", "dataset", ".", "test_Y", "}", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "test_loss_summ", ",", "step", ")", "\n", "summary_writer", ".", "add_summary", "(", "test_acc_summ", ",", "step", ")", "\n", "\n", "print", "(", "(", "'SGD test loss, circulant sparsity operators: '", ",", "test_loss", ")", ")", "\n", "print", "(", "(", "'SGD test accuracy, circulant sparsity operators: '", ",", "test_accuracy", ")", ")", "\n", "losses", "[", "'test'", "]", "=", "test_loss", "\n", "accuracies", "[", "'test'", "]", "=", "test_accuracy", "\n", "\n", "", "return", "losses", ",", "accuracies", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.learned_operators.circulant_sparsity_hadamard": [[363, 444], ["tensorflow.placeholder", "tensorflow.Variable", "time.time", "circ_sparsity_recon", "print", "compute_y", "tensorflow.placeholder", "utils.compute_loss_and_accuracy", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.FileWriter", "tensorflow.train.MomentumOptimizer().minimize", "tensorflow.InteractiveSession", "tensorflow.initialize_all_variables().run", "tensorflow.train.Saver", "print", "print", "tensorflow.truncated_normal", "tensorflow.Variable", "tensorflow.truncated_normal", "dataset.batch", "tf.InteractiveSession.run", "tf.summary.FileWriter.add_summary", "tensorflow.truncated_normal", "time.time", "tensorflow.get_default_graph", "tensorflow.train.MomentumOptimizer", "tensorflow.initialize_all_variables", "print", "utils.gen_Z_f", "print", "tf.InteractiveSession.run", "losses.append", "accuracies.append", "print", "print", "tf.InteractiveSession.run", "tf.InteractiveSession.run", "tf.InteractiveSession.run", "tf.InteractiveSession.run", "utils.gen_Z_f", "numpy.dot", "print", "numpy.dot", "numpy.linalg.matrix_rank"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.model.compute_y", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.compute_loss_and_accuracy", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.dataset.Dataset.batch", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f"], ["", "def", "circulant_sparsity_hadamard", "(", "dataset", ",", "params", ",", "test_freq", "=", "100", ",", "verbose", "=", "False", ")", ":", "\n", "# Create the model", "\n", "\t", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "[", "None", ",", "params", ".", "input_size", "]", ")", "\n", "if", "params", ".", "fix_G", ":", "\n", "\t\t", "G", "=", "tf", ".", "truncated_normal", "(", "[", "params", ".", "n", ",", "params", ".", "r", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "", "else", ":", "\n", "\t\t", "G", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "params", ".", "n", ",", "params", ".", "r", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "", "H", "=", "tf", ".", "Variable", "(", "tf", ".", "truncated_normal", "(", "[", "params", ".", "n", ",", "params", ".", "r", "]", ",", "stddev", "=", "0.01", ",", "dtype", "=", "tf", ".", "float64", ")", ")", "\n", "\n", "t1", "=", "time", ".", "time", "(", ")", "\n", "W1", ",", "f_A", ",", "f_B", ",", "v_A", ",", "v_B", "=", "circ_sparsity_recon", "(", "G", ",", "H", ",", "params", ".", "n", ",", "params", ".", "r", ",", "params", ".", "learn_corner", ",", "\n", "params", ".", "n_diag_learned", ",", "params", ".", "init_type", ",", "params", ".", "init_stddev", ")", "\n", "print", "(", "'overall time of circ_sparsity_recon: '", ",", "time", ".", "time", "(", ")", "-", "t1", ")", "\n", "\n", "y", "=", "compute_y", "(", "x", ",", "W1", ",", "params", ")", "\n", "\n", "y_", "=", "tf", ".", "placeholder", "(", "tf", ".", "float64", ",", "[", "None", ",", "params", ".", "out_size", "]", ")", "\n", "\n", "loss", ",", "accuracy", "=", "compute_loss_and_accuracy", "(", "y", ",", "y_", ",", "params", ")", "\n", "\n", "train_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'train_loss'", ",", "loss", ")", "\n", "train_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'train_accuracy'", ",", "accuracy", ")", "\n", "val_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'val_loss'", ",", "loss", ")", "\n", "val_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'val_accuracy'", ",", "accuracy", ")", "\n", "test_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'test_loss'", ",", "loss", ")", "\n", "test_acc_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "'test_accuracy'", ",", "accuracy", ")", "\n", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "params", ".", "log_path", ",", "graph", "=", "tf", ".", "get_default_graph", "(", ")", ")", "\n", "\n", "train_step", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "params", ".", "lr", ",", "params", ".", "mom", ")", ".", "minimize", "(", "loss", ")", "\n", "sess", "=", "tf", ".", "InteractiveSession", "(", ")", "\n", "tf", ".", "initialize_all_variables", "(", ")", ".", "run", "(", ")", "\n", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "\n", "step", "=", "0", "\n", "\n", "losses", "=", "{", "}", "\n", "accuracies", "=", "{", "}", "\n", "train_losses", "=", "[", "]", "\n", "train_accuracies", "=", "[", "]", "\n", "val_losses", "=", "[", "]", "\n", "val_accuracies", "=", "[", "]", "\n", "\n", "while", "step", "<", "params", ".", "steps", ":", "\n", "\t\t", "batch_xs", ",", "batch_ys", "=", "dataset", ".", "batch", "(", "params", ".", "batch_size", ",", "step", ")", "\n", "summary", ",", "_", ",", "=", "sess", ".", "run", "(", "[", "merged_summary_op", ",", "train_step", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "\n", "summary_writer", ".", "add_summary", "(", "summary", ",", "step", ")", "\n", "\n", "if", "step", "%", "test_freq", "==", "0", ":", "\n", "\t\t\t", "print", "(", "(", "'Training step: '", ",", "step", ")", ")", "\n", "# Verify displacement rank: Stein", "\n", "v_A_real", "=", "None", "\n", "v_B_real", "=", "None", "\n", "if", "params", ".", "n_diag_learned", ">", "0", ":", "\n", "\t\t\t\t", "f_A_real", ",", "f_B_real", ",", "v_A_real", ",", "v_B_real", ",", "W1_real", "=", "sess", ".", "run", "(", "[", "f_A", ",", "f_B", ",", "v_A", ",", "v_B", ",", "W1", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "f_A_real", ",", "f_B_real", ",", "W1_real", "=", "sess", ".", "run", "(", "[", "f_A", ",", "f_B", ",", "W1", "]", ",", "feed_dict", "=", "{", "x", ":", "batch_xs", ",", "y_", ":", "batch_ys", "}", ")", "\n", "\n", "", "A", "=", "gen_Z_f", "(", "params", ".", "n", ",", "f_A_real", ",", "v_A_real", ")", ".", "T", "\n", "B", "=", "gen_Z_f", "(", "params", ".", "n", ",", "f_B_real", ",", "v_B_real", ")", "\n", "\n", "E", "=", "W1_real", "-", "np", ".", "dot", "(", "A", ",", "np", ".", "dot", "(", "W1_real", ",", "B", ")", ")", "\n", "print", "(", "(", "'Disp rank: '", ",", "np", ".", "linalg", ".", "matrix_rank", "(", "E", ")", ")", ")", "\n", "\n", "this_loss", ",", "this_accuracy", "=", "sess", ".", "run", "(", "[", "loss", ",", "accuracy", "]", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "test_X", ",", "y_", ":", "dataset", ".", "test_Y", "}", ")", "\n", "losses", ".", "append", "(", "this_loss", ")", "\n", "accuracies", ".", "append", "(", "this_accuracy", ")", "\n", "print", "(", "(", "'Test loss: '", ",", "this_loss", ")", ")", "\n", "print", "(", "(", "'Test accuracy: '", ",", "this_accuracy", ")", ")", "\n", "if", "verbose", ":", "\n", "\t\t\t\t", "print", "(", "(", "'Current W1: '", ",", "W1_real", ")", ")", "\n", "\n", "", "", "step", "+=", "1", "\n", "\n", "# Test trained model", "\n", "", "print", "(", "(", "'SGD final loss, learned operators (fixed circulant sparsity pattern): '", ",", "sess", ".", "run", "(", "loss", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "test_X", ",", "y_", ":", "dataset", ".", "test_Y", "}", ")", ")", ")", "\n", "print", "(", "(", "'SGD final accuracy, learned operators (fixed circulant sparsity pattern): '", ",", "sess", ".", "run", "(", "accuracy", ",", "feed_dict", "=", "{", "x", ":", "dataset", ".", "test_X", ",", "y_", ":", "dataset", ".", "test_Y", "}", ")", ")", ")", "\n", "\n", "return", "losses", ",", "accuracies", "\n", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.kth_diag_indices": [[8, 16], ["numpy.diag_indices_from"], "function", ["None"], ["\n", "return", "mse", ",", "accuracy", "\n", "\n", "", "def", "cross_entropy_loss", "(", "pred", ",", "true", ")", ":", "\n", "    ", "loss_fn", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "_", ",", "true_argmax", "=", "torch", ".", "max", "(", "true", ",", "1", ")", "\n", "cross_entropy", "=", "loss_fn", "(", "pred", ",", "true_argmax", ")", "\n", "\n", "_", ",", "pred_argmax", "=", "torch", ".", "max", "(", "pred", ",", "1", ")", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.symm_tridiag_corner_mask": [[19, 31], ["numpy.zeros", "utils.kth_diag_indices", "utils.kth_diag_indices", "utils.kth_diag_indices"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.misc.projections.kth_diag_indices", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.misc.projections.kth_diag_indices", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.misc.projections.kth_diag_indices"], ["\n", "return", "cross_entropy", ",", "accuracy", "\n", "\n", "\n", "", "def", "get_commit_id", "(", ")", ":", "\n", "  ", "return", "subprocess", ".", "check_output", "(", "[", "'git'", ",", "'rev-parse'", ",", "'--short'", ",", "'HEAD'", "]", ")", "\n", "\n", "", "def", "descendants", "(", "cls", ")", ":", "\n", "    ", "\"\"\"\n    Get all subclasses (recursively) of class cls, not including itself\n    Assumes no multiple inheritance\n    \"\"\"", "\n", "desc", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.sylvester_disp": [[32, 34], ["numpy.dot", "numpy.dot"], "function", ["None"], ["for", "subcls", "in", "cls", ".", "__subclasses__", "(", ")", ":", "\n", "        ", "desc", ".", "append", "(", "subcls", ")", "\n", "desc", ".", "extend", "(", "descendants", "(", "subcls", ")", ")", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.stein_disp": [[35, 37], ["numpy.dot", "numpy.dot"], "function", ["None"], ["", "return", "desc", "\n", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.compute_disp": [[38, 46], ["utils.sylvester_disp", "utils.stein_disp", "print"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.sylvester_disp", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.stein_disp"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_tridiag_corner_transpose": [[47, 51], ["scipy.sparse.diags().toarray", "scipy.sparse.diags"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_tridiag_corner": [[52, 57], ["scipy.sparse.diags().toarray", "scipy.sparse.diags"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_tridiag_corners": [[58, 64], ["scipy.sparse.diags().toarray", "scipy.sparse.diags"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_fs": [[66, 87], ["tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "print", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "tensorflow.truncated_normal"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_f": [[88, 104], ["tensorflow.constant", "tensorflow.constant", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "print", "tensorflow.truncated_normal", "tensorflow.truncated_normal"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_subdiag": [[105, 115], ["tensorflow.Variable", "tensorflow.ones", "tensorflow.Variable", "print", "tensorflow.truncated_normal"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_x_f": [[117, 141], ["utils.get_f", "utils.get_subdiag", "utils.get_subdiag", "tensorflow.concat", "tensorflow.concat", "tensorflow.ones", "tensorflow.concat", "tensorflow.concat"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_subdiag", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_subdiag"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_symm_tridiag_vars": [[142, 144], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_symm_pos_tridiag_vars": [[145, 165], ["tensorflow.Variable", "tensorflow.get_variable", "tensorflow.Variable", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "print", "tensorflow.Variable", "tensorflow.get_variable", "tensorflow.Variable", "print", "tensorflow.truncated_normal", "tensorflow.zeros", "tensorflow.random_uniform", "tensorflow.clip_by_value", "tensorflow.ones", "tensorflow.clip_by_value"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_tridiag_vars": [[166, 179], ["tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.ones", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "print", "tensorflow.truncated_normal", "tensorflow.truncated_normal", "tensorflow.truncated_normal"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_tridiag_corner_vars": [[181, 187], ["utils.get_tridiag_vars", "utils.get_tridiag_vars", "utils.get_f"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_tridiag_vars", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_tridiag_vars", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_f"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_tridiag_corners_vars": [[189, 195], ["utils.get_tridiag_vars", "utils.get_tridiag_vars", "utils.get_fs"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_tridiag_vars", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_tridiag_vars", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_fs"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.compute_loss_and_accuracy": [[197, 213], ["tensorflow.reduce_mean", "tensorflow.constant", "tensorflow.squared_difference", "tensorflow.reduce_mean", "tensorflow.equal", "tensorflow.reduce_mean", "print", "tensorflow.nn.softmax_cross_entropy_with_logits", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.cast"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.compute_y_cnn": [[214, 284], ["tensorflow.cast", "print", "tensorflow.layers.conv2d", "print", "tensorflow.layers.max_pooling2d", "print", "print", "tensorflow.layers.dense", "print", "print", "tensorflow.reshape", "int", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.cast", "print", "tensorflow.nn.relu", "tensorflow.layers.conv2d", "print", "tensorflow.layers.max_pooling2d", "print", "tensorflow.reshape", "tensorflow.cast", "print", "tensorflow.nn.relu", "numpy.sqrt", "tensorflow.matmul", "tensorflow.matmul"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_commit_id": [[285, 287], ["subprocess.check_output"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_operators": [[288, 296], ["utils.gen_sylvester_operators", "utils.gen_stein_operators", "print"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_sylvester_operators", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_stein_operators"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_sylvester_operators": [[298, 319], ["class_type.startswith", "utils.gen_Z_f", "utils.gen_Z_f", "class_type.startswith", "utils.gen_Z_f", "class_type.startswith", "utils.gen_Z_f", "class_type.startswith", "utils.gen_Z_f", "utils.gen_Z_f", "numpy.random.random", "numpy.diag", "utils.gen_Z_f", "utils.gen_Z_f", "utils.gen_Z_f", "numpy.random.random", "numpy.random.random", "print"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_stein_operators": [[321, 339], ["class_type.startswith", "utils.gen_Z_f", "class_type.startswith", "utils.gen_Z_f", "utils.gen_Z_f", "utils.gen_Z_f", "class_type.startswith", "numpy.random.random", "numpy.diag", "utils.gen_Z_f", "numpy.random.random", "numpy.random.random", "print"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_stein_operators_tf": [[341, 344], ["utils.gen_stein_operators", "tensorflow.Variable", "tensorflow.Variable"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_stein_operators"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_trid_mask": [[345, 354], ["list", "list", "scipy.sparse.diags().toarray", "numpy.ones", "numpy.ones", "scipy.sparse.diags"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_trid_corner_mask": [[355, 360], ["utils.gen_trid_mask"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_trid_mask"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f": [[362, 374], ["numpy.eye", "numpy.hstack", "numpy.vstack", "range", "numpy.zeros", "numpy.zeros"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_circ_scaling_mask": [[384, 390], ["numpy.zeros", "range", "numpy.roll().astype", "numpy.roll"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.tf_roll_rows": [[393, 401], ["tensorflow.transpose", "tensorflow.concat", "tensorflow.transpose", "tf.transpose.get_shape().as_list", "tf.transpose.get_shape"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.update_mask": [[403, 406], ["tensorflow.ones", "tensorflow.where", "mask.get_shape"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_circ_scaling_tf": [[407, 430], ["time.time", "utils.update_mask", "print", "numpy.arange", "print", "print", "tensorflow.ones", "time.time", "utils.update_mask", "time.time", "tensorflow.multiply", "mask.get_shape", "time.time", "utils.tf_roll_rows", "time.time", "time.time"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.update_mask", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.update_mask", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.tf_roll_rows"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_f_mask": [[431, 441], ["numpy.ones", "numpy.tril_indices", "tensorflow.constant"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_index_arr": [[442, 457], ["numpy.arange", "numpy.expand_dims", "numpy.expand_dims", "numpy.expand_dims", "numpy.multiply", "numpy.multiply"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.sylvester": [[458, 473], ["numpy.random.random", "numpy.random.random", "numpy.dot", "scipy.linalg.solve_sylvester", "numpy.dot", "numpy.dot", "numpy.linalg.norm"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_matrix": [[474, 554], ["prefix.startswith", "int", "numpy.random.random", "numpy.random.random", "numpy.dot", "numpy.random.random", "numpy.random.random", "scipy.linalg.toeplitz", "numpy.random.random", "numpy.random.random", "numpy.flipud", "scipy.linalg.toeplitz", "numpy.random.random", "numpy.vander", "numpy.random.random", "numpy.random.random", "numpy.random.random", "np.random.random.reshape", "utils.gen_Z_f", "utils.gen_Z_f", "utils.sylvester", "utils.gen_Z_f", "utils.sylvester", "utils.gen_Z_f", "numpy.random.random", "numpy.vander", "numpy.diag", "utils.gen_Z_f", "utils.sylvester", "numpy.random.random", "numpy.random.random", "numpy.diag", "numpy.diag", "utils.sylvester", "numpy.random.random", "numpy.random.random", "utils.gen_trid_corner_mask", "numpy.multiply", "numpy.multiply", "utils.sylvester", "np.random.random.reshape", "numpy.random.random", "numpy.random.random", "utils.gen_Z_f", "numpy.multiply", "numpy.multiply", "utils.sylvester", "print"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.sylvester", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.sylvester", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.sylvester", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.sylvester", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_trid_corner_mask", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.sylvester", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_Z_f", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.sylvester"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_batch": [[556, 575], ["numpy.random.random", "numpy.dot", "numpy.isclose", "numpy.linalg.norm", "numpy.random.random", "numpy.dot", "numpy.dot"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_GH": [[576, 587], ["numpy.linalg.matrix_rank", "numpy.linalg.svd", "numpy.dot", "numpy.diag"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.sylvester_project": [[588, 618], ["time.time", "utils.get_GH", "numpy.dot", "print", "scipy.linalg.solve_sylvester", "print", "print", "print", "print", "print", "print", "numpy.dot", "numpy.dot", "numpy.linalg.norm", "numpy.linalg.matrix_rank", "numpy.linalg.matrix_rank", "numpy.linalg.matrix_rank", "numpy.linalg.norm", "numpy.dot", "numpy.dot", "numpy.linalg.matrix_rank", "time.time"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.get_GH"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.circulant_tf": [[619, 628], ["tensorflow.gather_nd", "tensorflow.multiply"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.circulant_mn_tf": [[630, 642], ["utils.circulant_tf", "tensorflow.constant", "tensorflow.tile", "tensorflow.cast", "tensorflow.multiply"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.circulant_tf"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.krylov_circ_transpose": [[645, 662], ["time.time", "utils.gen_circ_scaling_tf", "print", "time.time", "utils.circulant_tf", "print", "tensorflow.reverse", "tensorflow.multiply", "tensorflow.reverse", "time.time", "time.time"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.gen_circ_scaling_tf", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.circulant_tf"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.krylov_tf": [[663, 678], ["tensorflow.expand_dims", "range", "tensorflow.transpose", "tensorflow.matmul", "tensorflow.matmul", "cols.append", "tensorflow.stack", "tensorflow.squeeze"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.Ax_circ": [[679, 685], ["tensorflow.concat", "tensorflow.multiply"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.krylov_tf_circ": [[686, 699], ["tensorflow.expand_dims", "range", "tensorflow.stack", "tensorflow.transpose", "utils.Ax_circ", "cols.append", "tensorflow.squeeze", "tensorflow.expand_dims"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.Ax_circ"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.utils.V_mn": [[700, 716], ["tensorflow.ones", "range", "tensorflow.transpose", "tensorflow.cast", "tensorflow.pow", "cols.append", "tensorflow.stack"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.identity_mult_fn": [[7, 9], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.circ_diag_transpose_mult_fn": [[11, 22], ["tensorflow.concat", "tensorflow.multiply", "tensorflow.multiply"], "function", ["None"], ["\n", "import", "functools", "\n", "import", "numpy", "as", "np", "\n", "\n", "import", "torch", "\n", "from", "torch", ".", "nn", "import", "functional", "as", "F", "\n", "\n", "from", ".", "scratch", ".", "krylovslow", "import", "krylov_construct", "\n", "from", ".", "complex_utils", "import", "complex_mult", ",", "conjugate", "\n", "\n", "try", ":", "\n", "    ", "import", "diag_mult_cuda", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.circ_transpose_mult_fn": [[24, 35], ["tensorflow.concat", "tensorflow.multiply"], "function", ["None"], ["# diag_mult_cuda = torch.utils.cpp_extension.load(", "\n", "#     name='diag_mult_cuda',", "\n", "#     sources=[", "\n", "#         'diag_mult_cuda/diag_mult_cuda.cpp',", "\n", "#         'diag_mult_cuda/diag_mult_cuda_kernel.cu',", "\n", "#     ],", "\n", "#     extra_cuda_cflags=['-O2'],", "\n", "#     verbose=False", "\n", "#     )", "\n", "", "except", "(", "ImportError", ",", "RuntimeError", ")", "as", "e", ":", "\n", "    ", "print", "(", "\"CUDA version of slow Krylov multiply isn't installed.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.circ_mult_fn": [[36, 42], ["tensorflow.concat", "tensorflow.multiply"], "function", ["None"], ["", "device", "=", "torch", ".", "device", "(", "\"cuda:0\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "\n", "##### Fast multiplication for the subdiagonal case", "\n", "\n", "def", "poly_mult_sum_benchmark", "(", "p", ",", "q", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.symm_tridiag_mult_fn": [[43, 51], ["tensorflow.multiply", "tensorflow.multiply", "tensorflow.concat", "tensorflow.concat", "tensorflow.multiply"], "function", ["None"], ["\n", "print", "(", "p", ".", "shape", "[", "2", "]", ")", "\n", "\n", "import", "time", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.tridiag_corners_mult_fn": [[52, 66], ["tensorflow.multiply", "tensorflow.concat", "tensorflow.multiply", "tensorflow.concat", "tensorflow.zeros", "tensorflow.zeros", "tensorflow.multiply", "tensorflow.concat", "tensorflow.multiply", "tensorflow.concat", "tensorflow.multiply"], "function", ["None"], ["torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "for", "_", "in", "range", "(", "100", ")", ":", "\n", "        ", "y", "=", "F", ".", "conv1d", "(", "p", ",", "q", ".", "flip", "(", "q", ".", "dim", "(", ")", "-", "1", ")", ",", "padding", "=", "p", ".", "shape", "[", "-", "1", "]", "-", "1", ")", "\n", "g", "=", "torch", ".", "autograd", ".", "grad", "(", "y", ".", "sum", "(", ")", ",", "(", "p", ",", "q", ")", ",", "retain_graph", "=", "True", ")", "\n", "", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "end", "=", "time", ".", "perf_counter", "(", ")", "\n", "print", "(", "f'Elapsed time conv1d: {end - start}s.'", ")", "\n", "\n", "batch_size", ",", "rank", "=", "p", ".", "shape", "[", "0", "]", ",", "q", ".", "shape", "[", "0", "]", "\n", "n1", ",", "n2", "=", "p", ".", "shape", "[", "1", "]", ",", "p", ".", "shape", "[", "2", "]", "\n", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "for", "_", "in", "range", "(", "100", ")", ":", "\n", "        ", "S", "=", "torch", ".", "cat", "(", "(", "torch", ".", "cat", "(", "(", "q", ",", "p", ")", ")", ",", "\n", "torch", ".", "zeros", "(", "(", "rank", "+", "batch_size", ",", "p", ".", "shape", "[", "1", "]", ",", "p", ".", "shape", "[", "2", "]", ")", ",", "dtype", "=", "q", ".", "dtype", ",", "device", "=", "q", ".", "device", ")", ")", ",", "dim", "=", "-", "1", ")", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.tridiag_corners_transpose_mult_fn": [[68, 70], ["krylov.tridiag_corners_mult_fn"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.tridiag_corners_mult_fn"], ["S0_10_f", ",", "S1_01_f", "=", "S_f", "[", ":", "rank", "]", ",", "S_f", "[", "rank", ":", "rank", "+", "batch_size", "]", "\n", "prod", "=", "(", "S1_01_f", "[", ":", ",", "np", ".", "newaxis", ",", "...", ",", "np", ".", "newaxis", "]", "*", "S0_10_f", "[", "np", ".", "newaxis", ",", "...", ",", "np", ".", "newaxis", ",", ":", "]", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "T_00_f_sum", "=", "torch", ".", "stack", "(", "(", "prod", "[", "...", ",", "0", ",", "0", "]", "-", "prod", "[", "...", ",", "1", ",", "1", "]", ",", "prod", "[", "...", ",", "0", ",", "1", "]", "+", "prod", "[", "...", ",", "1", ",", "0", "]", ")", ",", "dim", "=", "-", "1", ")", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.tridiag_corner_transpose_mult_fn": [[93, 104], ["tensorflow.multiply", "tensorflow.multiply", "tensorflow.concat", "tensorflow.concat", "tensorflow.zeros", "tensorflow.multiply", "tensorflow.concat", "tensorflow.multiply"], "function", ["None"], ["start", "=", "time", ".", "perf_counter", "(", ")", "\n", "for", "_", "in", "range", "(", "100", ")", ":", "\n", "        ", "dp", "=", "F", ".", "conv_transpose1d", "(", "grad", ",", "q", ".", "flip", "(", "2", ")", ",", "padding", "=", "q", ".", "shape", "[", "-", "1", "]", "-", "1", ")", "\n", "g", "=", "torch", ".", "autograd", ".", "grad", "(", "dp", ".", "sum", "(", ")", ",", "(", "grad", ",", "q", ")", ",", "retain_graph", "=", "True", ")", "\n", "", "torch", ".", "cuda", ".", "synchronize", "(", ")", "\n", "end", "=", "time", ".", "perf_counter", "(", ")", "\n", "print", "(", "f'Elapsed time conv1d: {end - start}s.'", ")", "\n", "\n", "batch_size", ",", "rank", "=", "grad", ".", "shape", "[", "0", "]", ",", "q", ".", "shape", "[", "0", "]", "\n", "n1", ",", "n2", "=", "q", ".", "shape", "[", "1", "]", ",", "q", ".", "shape", "[", "2", "]", "\n", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "for", "_", "in", "range", "(", "100", ")", ":", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.tridiag_corner_mult_fn": [[124, 137], ["tensorflow.multiply", "tensorflow.multiply", "tensorflow.concat", "tensorflow.concat", "tensorflow.zeros", "tensorflow.concat", "tensorflow.multiply", "tensorflow.multiply"], "function", ["None"], ["\n", "batch_size", ",", "n", "=", "u", ".", "shape", "\n", "rank", ",", "n_", "=", "v", ".", "shape", "\n", "assert", "n", "==", "n_", ",", "'u and v must have the same last dimension'", "\n", "m", "=", "int", "(", "np", ".", "log2", "(", "n", ")", ")", "\n", "assert", "n", "==", "1", "<<", "m", ",", "'n must be a power of 2'", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.diag_mult_fn": [[139, 141], ["tensorflow.multiply"], "function", ["None"], ["T_00_sum", "=", "u", "@", "v", ".", "t", "(", ")", "\n", "result", "[", ":", ",", ":", ",", "0", "]", "+=", "T_00_sum", "\n", "T_01", "=", "u", "[", "...", ",", "np", ".", "newaxis", "]", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.krylov": [[142, 156], ["tensorflow.expand_dims", "range", "tensorflow.stack", "tensorflow.transpose", "fn", "cols.append", "tensorflow.squeeze", "tensorflow.expand_dims"], "function", ["None"], ["T_10", "=", "v", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "T_11", "=", "torch", ".", "ones", "(", "n", ",", "device", "=", "T_00_sum", ".", "device", ")", "\n", "for", "d", "in", "range", "(", "m", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "        ", "n1", ",", "n2", "=", "1", "<<", "d", ",", "1", "<<", "(", "m", "-", "d", "-", "1", ")", "\n", "S_00_sum", ",", "S_01", ",", "S_10", ",", "S_11", "=", "T_00_sum", ",", "T_01", ",", "T_10", ",", "T_11", "\n", "S0_10_mult_subdiag", "=", "S_10", "[", ":", ",", ":", ":", "2", "]", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", ",", "np", ".", "newaxis", "]", "\n", "# polynomial multiplication", "\n", "# T_00_sum = poly_mult_sum_benchmark(S_01[:, 1::2], S0_10_mult_subdiag)", "\n", "if", "n2", "<=", "128", ":", "# Pick between 2 implementations based on polynomial degree n2", "\n", "            ", "T_00_sum", "=", "F", ".", "conv1d", "(", "S_01", "[", ":", ",", "1", ":", ":", "2", "]", ",", "S0_10_mult_subdiag", ".", "flip", "(", "2", ")", ",", "padding", "=", "n2", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "S", "=", "torch", ".", "cat", "(", "(", "torch", ".", "cat", "(", "(", "S0_10_mult_subdiag", ",", "S_01", "[", ":", ",", "1", ":", ":", "2", "]", ")", ")", ",", "\n", "torch", ".", "zeros", "(", "(", "rank", "+", "batch_size", ",", "n1", ",", "n2", ")", ",", "dtype", "=", "S_10", ".", "dtype", ",", "device", "=", "S_10", ".", "device", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "S_f", "=", "torch", ".", "rfft", "(", "S", ",", "1", ")", "\n", "S0_10_f", ",", "S1_01_f", "=", "S_f", "[", ":", "rank", "]", ",", "S_f", "[", "rank", ":", "rank", "+", "batch_size", "]", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.test_circ_sparsity": [[157, 189], ["numpy.array", "numpy.zeros", "numpy.zeros", "print", "numpy.array", "tensorflow.constant", "tensorflow.constant", "tensorflow.concat", "functools.partial", "print", "print", "tensorflow.constant", "functools.partial.", "tensorflow.InteractiveSession", "tensorflow.initialize_all_variables().run", "print", "scipy.sparse.diags().toarray", "numpy.dot", "tf.InteractiveSession.run", "tensorflow.initialize_all_variables", "scipy.sparse.diags"], "function", ["None"], ["# Different ways to compute the same expression, for speed vs readability", "\n", "# Option 1: call complex_mult, slowest", "\n", "# T_00_f_sum = complex_mult(S1_01_f[:, np.newaxis], S0_10_f[np.newaxis]).sum(dim=2)", "\n", "# Option 2: multiply and sum", "\n", "# prod = (S1_01_f[:, np.newaxis, ..., np.newaxis] * S0_10_f[np.newaxis, ..., np.newaxis, :]).sum(dim=2)", "\n", "# Option 3: einsum", "\n", "prod", "=", "torch", ".", "einsum", "(", "'bnmo,rnmp->brmop'", ",", "S1_01_f", ",", "S0_10_f", ")", "\n", "# Option 4: manually doing permute and reshape and bmm, only 3% faster than einsum.", "\n", "# temp1 = S1_01_f.permute(2, 0, 3, 1).reshape((-1, batch_size * 2, n1))", "\n", "# temp2 = S0_10_f.permute(2, 1, 0, 3).reshape((-1, n1, rank * 2))", "\n", "# prod = (temp1 @ temp2).reshape((-1, batch_size, 2, rank, 2)).permute(1, 3, 0, 2, 4)", "\n", "T_00_f_sum", "=", "torch", ".", "stack", "(", "(", "prod", "[", "...", ",", "0", ",", "0", "]", "-", "prod", "[", "...", ",", "1", ",", "1", "]", ",", "prod", "[", "...", ",", "0", ",", "1", "]", "+", "prod", "[", "...", ",", "1", ",", "0", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "T_00_sum", "=", "torch", ".", "irfft", "(", "T_00_f_sum", ",", "1", ",", "signal_sizes", "=", "(", "2", "*", "n2", ",", ")", ")", "[", "...", ",", ":", "-", "1", "]", "\n", "# polynomial additions", "\n", "", "result", "[", ":", ",", ":", ",", "1", ":", "2", "*", "n2", "]", "+=", "T_00_sum", "\n", "S0_11_mult_subdiag", "=", "S_11", "[", ":", ":", "2", "]", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", "]", "\n", "T_01", "=", "torch", ".", "cat", "(", "(", "S_01", "[", ":", ",", ":", ":", "2", "]", ",", "S_01", "[", ":", ",", "1", ":", ":", "2", "]", "*", "S0_11_mult_subdiag", "[", ":", ",", "np", ".", "newaxis", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "T_10", "=", "torch", ".", "cat", "(", "(", "S_10", "[", ":", ",", "1", ":", ":", "2", "]", ",", "S0_10_mult_subdiag", "*", "S_11", "[", "1", ":", ":", "2", "]", "[", ":", ",", "np", ".", "newaxis", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "T_11", "=", "S0_11_mult_subdiag", "*", "S_11", "[", "1", ":", ":", "2", "]", "\n", "", "return", "result", "\n", "\n", "\n", "", "def", "krylov_transpose_multiply", "(", "subdiag", ",", "v", ",", "u", ")", ":", "\n", "    ", "\"\"\"Multiply Krylov(A, v_i)^T @ u when A is zero except on the subdiagonal.\n    Parameters:\n        subdiag: Tensor of shape (n - 1, )\n        v: Tensor of shape (rank, n)\n        u: Tensor of shape (batch_size, n)\n    Returns:\n        product: Tensor of shape (batch_size, rank, n)\n    \"\"\"", "\n", "batch_size", ",", "n", "=", "u", ".", "shape", "\n", "rank", ",", "n_", "=", "v", ".", "shape", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.test_tridiag_corner": [[190, 226], ["numpy.array", "numpy.array", "numpy.array", "print", "print", "print", "print", "numpy.array", "print", "print", "functools.partial", "print", "tensorflow.constant", "functools.partial.", "tensorflow.InteractiveSession", "tensorflow.initialize_all_variables().run", "print", "scipy.sparse.diags().toarray", "numpy.dot", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tf.InteractiveSession.run", "tensorflow.initialize_all_variables", "scipy.sparse.diags"], "function", ["None"], ["assert", "n", "==", "n_", ",", "'u and v must have the same last dimension'", "\n", "m", "=", "int", "(", "np", ".", "log2", "(", "n", ")", ")", "\n", "assert", "n", "==", "1", "<<", "m", ",", "'n must be a power of 2'", "\n", "\n", "result", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "rank", ",", "n", ")", ",", "dtype", "=", "u", ".", "dtype", ",", "device", "=", "u", ".", "device", ")", "\n", "# T_00_sum = (u[:, np.newaxis, ..., np.newaxis] * v[np.newaxis, ..., np.newaxis]).sum(dim=2)", "\n", "T_00_sum", "=", "u", "@", "v", ".", "t", "(", ")", "\n", "result", "[", ":", ",", ":", ",", "0", "]", "=", "T_00_sum", "\n", "T_01", "=", "u", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "T_10", "=", "v", "[", "...", ",", "np", ".", "newaxis", "]", "\n", "T_11", "=", "torch", ".", "ones", "(", "n", ",", "device", "=", "T_00_sum", ".", "device", ")", "\n", "for", "d", "in", "range", "(", "m", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "        ", "n1", ",", "n2", "=", "1", "<<", "d", ",", "1", "<<", "(", "m", "-", "d", "-", "1", ")", "\n", "S_01", ",", "S_10", ",", "S_11", "=", "T_01", ",", "T_10", ",", "T_11", "\n", "# S0_10 = torch.cat((S_10[:, ::2], torch.zeros_like(S_10[:, ::2])), dim=-1)", "\n", "# S1_01 = torch.cat((S_01[:, 1::2], torch.zeros_like(S_01[:, 1::2])), dim=-1)", "\n", "# S = torch.cat((S0_10, S1_01))", "\n", "S0_10_mult_subdiag", "=", "S_10", "[", ":", ",", ":", ":", "2", "]", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", ",", "np", ".", "newaxis", "]", "\n", "S", "=", "torch", ".", "cat", "(", "(", "torch", ".", "cat", "(", "(", "S0_10_mult_subdiag", ",", "S_01", "[", ":", ",", "1", ":", ":", "2", "]", ")", ")", ",", "\n", "torch", ".", "zeros", "(", "(", "rank", "+", "batch_size", ",", "n1", ",", "n2", ")", ",", "dtype", "=", "S_10", ".", "dtype", ",", "device", "=", "S_10", ".", "device", ")", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# polynomial multiplications", "\n", "S_f", "=", "torch", ".", "rfft", "(", "S", ",", "1", ")", "\n", "S0_10_f", ",", "S1_01_f", "=", "S_f", "[", ":", "rank", "]", ",", "S_f", "[", "rank", ":", "rank", "+", "batch_size", "]", "\n", "# Different ways to compute the same expression, for speed vs readability", "\n", "# Option 1: call complex_mult, slowest", "\n", "# T_00_f_sum = complex_mult(S1_01_f[:, np.newaxis], S0_10_f[np.newaxis]).sum(dim=2)", "\n", "# Option 2: multiply and sum", "\n", "# Manually doing complex multiply, somehow this is faster than Cupy's complex mult", "\n", "# prod = (S1_01_f[:, np.newaxis, ..., np.newaxis] * S0_10_f[np.newaxis, ..., np.newaxis, :]).sum(dim=2)", "\n", "# Option 3: einsum", "\n", "prod", "=", "torch", ".", "einsum", "(", "'bnmo,rnmp->brmop'", ",", "S1_01_f", ",", "S0_10_f", ")", "\n", "# Option 4: manually doing permute and reshape and bmm, only 3% faster than einsum.", "\n", "# temp1 = S1_01_f.permute(2, 0, 3, 1).reshape((-1, batch_size * 2, n1))", "\n", "# temp2 = S0_10_f.permute(2, 1, 0, 3).reshape((-1, n1, rank * 2))", "\n", "# prod = (temp1 @ temp2).reshape((-1, batch_size, 2, rank, 2)).permute(1, 3, 0, 2, 4)", "\n", "# prod = (S1_01_f[:, np.newaxis, ..., np.newaxis] * S0_10_f[np.newaxis, ..., np.newaxis, :]).sum(dim=2)", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.test_symm_tridiag": [[227, 252], ["numpy.array", "numpy.array", "scipy.sparse.diags().toarray", "print", "print", "numpy.array", "print", "functools.partial", "tensorflow.constant", "krylov.krylov", "tensorflow.InteractiveSession", "tensorflow.initialize_all_variables().run", "print", "numpy.linalg.norm", "numpy.dot", "tensorflow.constant", "tensorflow.constant", "tf.InteractiveSession.run", "scipy.sparse.diags", "numpy.linalg.matrix_power", "tensorflow.initialize_all_variables"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.tensorflow.krylov.krylov"], ["T_00_f_sum", "=", "torch", ".", "stack", "(", "(", "prod", "[", "...", ",", "0", ",", "0", "]", "-", "prod", "[", "...", ",", "1", ",", "1", "]", ",", "prod", "[", "...", ",", "0", ",", "1", "]", "+", "prod", "[", "...", ",", "1", ",", "0", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "T_00_sum", "=", "torch", ".", "irfft", "(", "T_00_f_sum", ",", "1", ",", "signal_sizes", "=", "(", "2", "*", "n2", ",", ")", ")", "[", "...", ",", ":", "-", "1", "]", "\n", "\n", "# polynomial additions", "\n", "result", "[", ":", ",", ":", ",", "1", ":", "2", "*", "n2", "]", "+=", "T_00_sum", "\n", "S0_11_mult_subdiag", "=", "S_11", "[", ":", ":", "2", "]", "*", "subdiag", "[", "(", "n2", "-", "1", ")", ":", ":", "(", "2", "*", "n2", ")", "]", "\n", "T_01", "=", "torch", ".", "cat", "(", "(", "S_01", "[", ":", ",", ":", ":", "2", "]", ",", "S_01", "[", ":", ",", "1", ":", ":", "2", "]", "*", "S0_11_mult_subdiag", "[", ":", ",", "np", ".", "newaxis", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "T_10", "=", "torch", ".", "cat", "(", "(", "S_10", "[", ":", ",", "1", ":", ":", "2", "]", ",", "S0_10_mult_subdiag", "*", "S_11", "[", "1", ":", ":", "2", "]", "[", ":", ",", "np", ".", "newaxis", "]", ")", ",", "dim", "=", "-", "1", ")", "\n", "T_11", "=", "S0_11_mult_subdiag", "*", "S_11", "[", "1", ":", ":", "2", "]", "\n", "\n", "", "return", "result", "\n", "\n", "\n", "", "def", "KTu_traceable", "(", "subdiag", ",", "v", ",", "u", ")", ":", "\n", "    ", "\"\"\"Multiply Krylov(A, v_i)^T @ u when A is zero except on the subdiagonal.\n    (WIP) Written to be traceable by Pytorch 1.0 JIT compiler.\n    Parameters:\n        subdiag: Tensor of shape (n - 1, )\n        v: Tensor of shape (rank, n)\n        u: Tensor of shape (batch_size, n)\n    Returns:\n        product: Tensor of shape (batch_size, rank, n)\n    \"\"\"", "\n", "batch_size", ",", "n", "=", "u", ".", "shape", "\n", "rank", ",", "n_", "=", "v", ".", "shape", "\n", "# assert n == n_, 'u and v must have the same last dimension'", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.plot_speed.test_unstructured": [[20, 28], ["min", "timeit.repeat"], "function", ["None"], ["def", "test_unstructured", "(", "n", ",", "trials", ",", "reps", ")", ":", "\n", "    ", "u_setup_str", "=", "'''\nimport numpy as np\nnp.random.seed(0)\nA = np.random.normal(size=({n}, {n}))\nv = np.random.normal(size=({n}))\n'''", ".", "format", "(", "n", "=", "n", ")", "\n", "return", "min", "(", "timeit", ".", "repeat", "(", "\"A @ v\"", ",", "u_setup_str", ",", "number", "=", "trials", ",", "repeat", "=", "reps", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.plot_speed.test_toeplitz": [[29, 39], ["min", "timeit.repeat"], "function", ["None"], ["", "def", "test_toeplitz", "(", "n", ",", "r", ",", "trials", ",", "reps", ")", ":", "\n", "    ", "t_setup_str", "=", "'''\nimport numpy as np\nimport structure.toeplitz_cpu as toep\nnp.random.seed(0)\nG = np.random.normal(size=({r}, {n}))\nH = np.random.normal(size=({r}, {n}))\nv = np.random.normal(size=(1,{n}))\n'''", ".", "format", "(", "n", "=", "n", ",", "r", "=", "r", ")", "\n", "return", "min", "(", "timeit", ".", "repeat", "(", "\"toep.toeplitz_mult(G, H, v)\"", ",", "t_setup_str", ",", "number", "=", "trials", ",", "repeat", "=", "reps", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.plot_speed.test_lr": [[40, 49], ["min", "timeit.repeat"], "function", ["None"], ["", "def", "test_lr", "(", "n", ",", "r", ",", "trials", ",", "reps", ")", ":", "\n", "    ", "lr_setup_str", "=", "'''\nimport numpy as np\nnp.random.seed(0)\nG = np.random.normal(size=({n}, {r}))\nH = np.random.normal(size=({r}, {n}))\nv = np.random.normal(size={n})\n'''", ".", "format", "(", "n", "=", "n", ",", "r", "=", "r", ")", "\n", "return", "min", "(", "timeit", ".", "repeat", "(", "\"Hv = H @ v;G @ Hv\"", ",", "lr_setup_str", ",", "number", "=", "trials", ",", "repeat", "=", "reps", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.plot_speed.test_sd": [[51, 65], ["min", "timeit.repeat"], "function", ["None"], ["", "def", "test_sd", "(", "n", ",", "r", ",", "trials", ",", "reps", ")", ":", "\n", "    ", "sd_setup_str", "=", "'''\nimport numpy as np\nimport structure.scratch.krylovfast as subd\nnp.random.seed(0)\nG = np.random.normal(size=({r}, {n}))\nH = np.random.normal(size=({r}, {n}))\nv = np.random.normal(size=(1,{n}))\nK = subd.KrylovMultiply({n}, 1, {r})\nKT = subd.KrylovTransposeMultiply({n}, 1, {r})\nsubd_A = np.random.normal(size=({n}-1))\nsubd_B = np.random.normal(size=({n}-1))\n'''", ".", "format", "(", "n", "=", "n", ",", "r", "=", "r", ")", "\n", "return", "min", "(", "timeit", ".", "repeat", "(", "\"K(subd_A, G, KT(subd_B, H, v))\"", ",", "sd_setup_str", ",", "number", "=", "trials", ",", "repeat", "=", "reps", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.update_minmax": [[8, 10], ["min", "max", "min", "max"], "function", ["None"], ["def", "update_minmax", "(", "mini", ",", "maxi", ",", "a", ")", ":", "\n", "    ", "return", "min", "(", "mini", ",", "min", "(", "a", ")", ")", ",", "max", "(", "maxi", ",", "max", "(", "a", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.normalize": [[11, 13], ["float"], "function", ["None"], ["", "def", "normalize", "(", "params", ",", "n", ")", ":", "\n", "    ", "return", "[", "float", "(", "p", ")", "/", "n", "**", "2", "for", "p", "in", "params", "]", "\n", "# return [n**2/float(p) for p in params]", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.plot_all": [[15, 83], ["acc_vs_params.normalize", "ax.plot", "ax.set_aspect", "ax.set_xlim", "ax.set_ylim", "numpy.linspace", "ax.set_xticks", "ax.set_xticklabels", "list", "min", "max", "min", "max", "list", "acc_vs_params.normalize", "acc_vs_params.update_minmax", "acc_vs_params.update_minmax", "ax.plot", "list", "acc_vs_params.normalize", "acc_vs_params.update_minmax", "acc_vs_params.update_minmax", "ax.plot", "list", "acc_vs_params.normalize", "acc_vs_params.update_minmax", "acc_vs_params.update_minmax", "ax.plot", "list", "acc_vs_params.normalize", "acc_vs_params.update_minmax", "acc_vs_params.update_minmax", "ax.plot", "list", "acc_vs_params.normalize", "acc_vs_params.update_minmax", "acc_vs_params.update_minmax", "ax.plot", "acc_vs_params.update_minmax", "ax.plot", "list", "map", "map", "map", "map", "map", "map", "map"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.normalize", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.normalize", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.update_minmax", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.update_minmax", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.normalize", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.update_minmax", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.update_minmax", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.normalize", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.update_minmax", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.update_minmax", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.normalize", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.update_minmax", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.update_minmax", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.normalize", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.update_minmax", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.update_minmax", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.visualizations.acc_vs_params.update_minmax"], ["", "def", "plot_all", "(", "ax", ",", "n", ",", "sd", ",", "td", ",", "t", "=", "None", ",", "v", "=", "None", ",", "h", "=", "None", ",", "lr", "=", "None", ",", "u", "=", "None", ",", "fc", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    pass in as dict of three arrays: r, acc, std\n    sd: subdiagonal\n    td: tridiagonal\n    t:  toeplitz\n    v:  vandermonde\n    h:  hankel\n    lr: low rank\n\n    pass in as dict of three arrays: h (hidden units), acc, std\n    u:  unconstrained\n\n    pass in as tuple of two numbers: acc, std\n    fc: n hidden units, fully connected\n    \"\"\"", "\n", "learned_params", "=", "[", "2", "*", "n", "]", "+", "list", "(", "map", "(", "lambda", "r", ":", "2", "*", "n", "*", "(", "r", "+", "1", ")", ",", "sd", "[", "'r'", "]", ")", ")", "+", "list", "(", "map", "(", "lambda", "r", ":", "2", "*", "n", "*", "(", "r", "+", "3", ")", ",", "td", "[", "'r'", "]", ")", ")", "\n", "learned_params", "=", "normalize", "(", "learned_params", ",", "n", ")", "\n", "learned_acc", "=", "[", "t", "[", "'acc'", "]", "[", "0", "]", "]", "+", "sd", "[", "'acc'", "]", "+", "td", "[", "'acc'", "]", "\n", "learned_std", "=", "[", "t", "[", "'std'", "]", "[", "0", "]", "]", "+", "sd", "[", "'std'", "]", "+", "td", "[", "'std'", "]", "\n", "minp", ",", "maxp", "=", "min", "(", "learned_params", ")", ",", "max", "(", "learned_params", ")", "\n", "mina", ",", "maxa", "=", "min", "(", "learned_acc", ")", ",", "max", "(", "learned_acc", ")", "\n", "# ax.plot(learned_params, learned_acc, linewidth=3, marker='d',  label=r\"\\textbf{Learned operators}\")", "\n", "ax", ".", "plot", "(", "learned_params", ",", "learned_acc", ",", "linewidth", "=", "3", ",", "marker", "=", "'d'", ",", "label", "=", "r\"Learned operators (ours)\"", ")", "\n", "if", "t", "is", "not", "None", ":", "\n", "        ", "t_params", "=", "list", "(", "map", "(", "lambda", "r", ":", "2", "*", "n", "*", "r", ",", "t", "[", "'r'", "]", ")", ")", "\n", "t_params_", "=", "normalize", "(", "t_params", ",", "n", ")", "\n", "minp", ",", "maxp", "=", "update_minmax", "(", "minp", ",", "maxp", ",", "t_params_", ")", "\n", "mina", ",", "maxa", "=", "update_minmax", "(", "mina", ",", "maxa", ",", "t", "[", "'acc'", "]", ")", "\n", "ax", ".", "plot", "(", "t_params_", ",", "t", "[", "'acc'", "]", ",", "linewidth", "=", "3", ",", "linestyle", "=", "'-'", ",", "marker", "=", "'.'", ",", "label", "=", "'Toeplitz-like'", ")", "\n", "", "if", "v", "is", "not", "None", ":", "\n", "        ", "v_params", "=", "list", "(", "map", "(", "lambda", "r", ":", "2", "*", "n", "*", "r", ",", "v", "[", "'r'", "]", ")", ")", "# should be +n but looks weird for visualization", "\n", "v_params", "=", "normalize", "(", "v_params", ",", "n", ")", "\n", "minp", ",", "maxp", "=", "update_minmax", "(", "minp", ",", "maxp", ",", "v_params", ")", "\n", "mina", ",", "maxa", "=", "update_minmax", "(", "mina", ",", "maxa", ",", "v", "[", "'acc'", "]", ")", "\n", "ax", ".", "plot", "(", "v_params", ",", "v", "[", "'acc'", "]", ",", "linewidth", "=", "3", ",", "linestyle", "=", "'-'", ",", "marker", "=", "'.'", ",", "label", "=", "'Vandermonde-like'", ")", "\n", "", "if", "h", "is", "not", "None", ":", "\n", "        ", "h_params", "=", "list", "(", "map", "(", "lambda", "r", ":", "2", "*", "n", "*", "r", ",", "h", "[", "'r'", "]", ")", ")", "\n", "h_params", "=", "normalize", "(", "h_params", ",", "n", ")", "\n", "minp", ",", "maxp", "=", "update_minmax", "(", "minp", ",", "maxp", ",", "h_params", ")", "\n", "mina", ",", "maxa", "=", "update_minmax", "(", "mina", ",", "maxa", ",", "h", "[", "'acc'", "]", ")", "\n", "ax", ".", "plot", "(", "h_params", ",", "h", "[", "'acc'", "]", ",", "linewidth", "=", "3", ",", "linestyle", "=", "'-'", ",", "marker", "=", "'.'", ",", "label", "=", "'Hankel-like'", ")", "\n", "", "if", "lr", "is", "not", "None", ":", "\n", "        ", "lr_params", "=", "list", "(", "map", "(", "lambda", "r", ":", "2", "*", "n", "*", "r", ",", "lr", "[", "'r'", "]", ")", ")", "\n", "lr_params", "=", "normalize", "(", "lr_params", ",", "n", ")", "\n", "minp", ",", "maxp", "=", "update_minmax", "(", "minp", ",", "maxp", ",", "lr_params", ")", "\n", "mina", ",", "maxa", "=", "update_minmax", "(", "mina", ",", "maxa", ",", "lr", "[", "'acc'", "]", ")", "\n", "ax", ".", "plot", "(", "lr_params", ",", "lr", "[", "'acc'", "]", ",", "linewidth", "=", "3", ",", "linestyle", "=", "'-'", ",", "marker", "=", "'.'", ",", "label", "=", "'Low Rank'", ")", "\n", "", "if", "u", "is", "not", "None", ":", "\n", "        ", "u_params", "=", "list", "(", "map", "(", "lambda", "h", ":", "n", "*", "h", ",", "u", "[", "'h'", "]", ")", ")", "\n", "u_params", "=", "normalize", "(", "u_params", ",", "n", ")", "\n", "minp", ",", "maxp", "=", "update_minmax", "(", "minp", ",", "maxp", ",", "u_params", ")", "\n", "mina", ",", "maxa", "=", "update_minmax", "(", "mina", ",", "maxa", ",", "u", "[", "'acc'", "]", ")", "\n", "ax", ".", "plot", "(", "u_params", ",", "u", "[", "'acc'", "]", ",", "linewidth", "=", "3", ",", "linestyle", "=", "'-'", ",", "label", "=", "'Unconstrained'", ")", "\n", "", "if", "fc", "is", "not", "None", ":", "\n", "        ", "mina", ",", "maxa", "=", "update_minmax", "(", "mina", ",", "maxa", ",", "[", "fc", "[", "0", "]", "]", ")", "\n", "ax", ".", "plot", "(", "[", "minp", ",", "maxp", "]", ",", "[", "fc", "[", "0", "]", ",", "fc", "[", "0", "]", "]", ",", "label", "=", "'Fully Connected'", ",", "color", "=", "'black'", ",", "linewidth", "=", "3", ",", "linestyle", "=", "'-.'", ")", "\n", "\n", "# ax.set_xticks(t_params_, ['1/'+str(n**2/p) for p in t_params])", "\n", "# ax.set_xticks(t_params_)", "\n", "", "ax", ".", "set_aspect", "(", "'auto'", ",", "adjustable", "=", "'box'", ")", "\n", "ax", ".", "set_xlim", "(", "[", "minp", ",", "maxp", "]", ")", "\n", "ax", ".", "set_ylim", "(", "[", "mina", "-", "(", "maxa", "-", "mina", ")", "*", "0.1", ",", "maxa", "+", "(", "maxa", "-", "mina", ")", "*", "0.1", "]", ")", "\n", "ticks", "=", "np", ".", "linspace", "(", "minp", ",", "maxp", ",", "num", "=", "7", ")", "\n", "ax", ".", "set_xticks", "(", "ticks", ")", "\n", "# ax.set_xticklabels([f'1/{n**2/p:.1f}' for p in t_params])", "\n", "ax", ".", "set_xticklabels", "(", "[", "f'{1./p:.1f}'", "for", "p", "in", "ticks", "]", ")", "\n", "# ax.set_xlabel('Total number of parameters')", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.smallnorb.SmallNORBExample.__init__": [[16, 24], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "image_lt", "=", "None", "\n", "self", ".", "image_rt", "=", "None", "\n", "self", ".", "category", "=", "None", "\n", "self", ".", "instance", "=", "None", "\n", "self", ".", "elevation", "=", "None", "\n", "self", ".", "azimuth", "=", "None", "\n", "self", ".", "lighting", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.smallnorb.SmallNORBExample.__lt__": [[25, 28], ["None"], "methods", ["None"], ["", "def", "__lt__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "category", "<", "other", ".", "category", "or", "(", "self", ".", "category", "==", "other", ".", "category", "and", "self", ".", "instance", "<", "other", ".", "instance", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.smallnorb.SmallNORBExample.show": [[29, 36], ["fig.suptitle", "axes[].imshow", "axes[].imshow"], "methods", ["None"], ["", "def", "show", "(", "self", ",", "subplots", ")", ":", "\n", "        ", "fig", ",", "axes", "=", "subplots", "\n", "fig", ".", "suptitle", "(", "\n", "'Category: {:02d} - Instance: {:02d} - Elevation: {:02d} - Azimuth: {:02d} - Lighting: {:02d}'", ".", "format", "(", "\n", "self", ".", "category", ",", "self", ".", "instance", ",", "self", ".", "elevation", ",", "self", ".", "azimuth", ",", "self", ".", "lighting", ")", ")", "\n", "axes", "[", "0", "]", ".", "imshow", "(", "self", ".", "image_lt", ",", "cmap", "=", "'gray'", ")", "\n", "axes", "[", "1", "]", ".", "imshow", "(", "self", ".", "image_rt", ",", "cmap", "=", "'gray'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.smallnorb.SmallNORBExample.pose": [[37, 40], ["numpy.array"], "methods", ["None"], ["", "@", "property", "\n", "def", "pose", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "array", "(", "[", "self", ".", "elevation", ",", "self", ".", "azimuth", ",", "self", ".", "lighting", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.smallnorb.SmallNORBDataset.__init__": [[50, 88], ["smallnorb.SmallNORBDataset._fill_data_structures", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "smallnorb.SmallNORBExample", "smallnorb.SmallNORBExample", "range", "range"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset._fill_data_structures"], ["def", "__init__", "(", "self", ",", "dataset_root", ")", ":", "\n", "        ", "\"\"\"\n        Initialize small NORB dataset wrapper\n        \n        Parameters\n        ----------\n        dataset_root: str\n            Path to directory where small NORB archives have been extracted.\n        \"\"\"", "\n", "\n", "self", ".", "dataset_root", "=", "dataset_root", "\n", "self", ".", "initialized", "=", "False", "\n", "\n", "# Store path for each file in small NORB dataset (for compatibility the original filename is kept)", "\n", "self", ".", "dataset_files", "=", "{", "\n", "'train'", ":", "{", "\n", "'cat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'smallnorb-5x46789x9x18x6x2x96x96-training-cat.mat'", ")", ",", "\n", "'info'", ":", "join", "(", "self", ".", "dataset_root", ",", "'smallnorb-5x46789x9x18x6x2x96x96-training-info.mat'", ")", ",", "\n", "'dat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'smallnorb-5x46789x9x18x6x2x96x96-training-dat.mat'", ")", "\n", "}", ",", "\n", "'test'", ":", "{", "\n", "'cat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'smallnorb-5x01235x9x18x6x2x96x96-testing-cat.mat'", ")", ",", "\n", "'info'", ":", "join", "(", "self", ".", "dataset_root", ",", "'smallnorb-5x01235x9x18x6x2x96x96-testing-info.mat'", ")", ",", "\n", "'dat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'smallnorb-5x01235x9x18x6x2x96x96-testing-dat.mat'", ")", "\n", "}", "\n", "}", "\n", "\n", "# Initialize both train and test data structures", "\n", "self", ".", "data", "=", "{", "\n", "'train'", ":", "[", "SmallNORBExample", "(", ")", "for", "_", "in", "range", "(", "SmallNORBDataset", ".", "n_examples", ")", "]", ",", "\n", "'test'", ":", "[", "SmallNORBExample", "(", ")", "for", "_", "in", "range", "(", "SmallNORBDataset", ".", "n_examples", ")", "]", "\n", "}", "\n", "\n", "# Fill data structures parsing dataset binary files", "\n", "for", "data_split", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "self", ".", "_fill_data_structures", "(", "data_split", ")", "\n", "\n", "", "self", ".", "initialized", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.smallnorb.SmallNORBDataset.explore_random_examples": [[89, 108], ["matplotlib.subplots", "numpy.random.permutation", "[].show", "matplotlib.waitforbuttonpress", "matplotlib.cla"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBExample.show"], ["", "def", "explore_random_examples", "(", "self", ",", "dataset_split", ")", ":", "\n", "        ", "\"\"\"\n        Visualize random examples for dataset exploration purposes\n        \n        Parameters\n        ----------\n        dataset_split: str\n            Dataset split, can be either 'train' or 'test'\n\n        Returns\n        -------\n        None\n        \"\"\"", "\n", "if", "self", ".", "initialized", ":", "\n", "            ", "subplots", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "2", ")", "\n", "for", "i", "in", "np", ".", "random", ".", "permutation", "(", "SmallNORBDataset", ".", "n_examples", ")", ":", "\n", "                ", "self", ".", "data", "[", "dataset_split", "]", "[", "i", "]", ".", "show", "(", "subplots", ")", "\n", "plt", ".", "waitforbuttonpress", "(", ")", "\n", "plt", ".", "cla", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.smallnorb.SmallNORBDataset.export_to_jpg": [[109, 141], ["print", "print", "os.path.join", "enumerate", "os.path.exists", "os.makedirs", "os.path.join", "os.path.join", "scipy.misc.imsave", "scipy.misc.imsave"], "methods", ["None"], ["", "", "", "def", "export_to_jpg", "(", "self", ",", "export_dir", ")", ":", "\n", "        ", "\"\"\"\n        Export all dataset images to `export_dir` directory\n        \n        Parameters\n        ----------\n        export_dir: str\n            Path to export directory (which is created if nonexistent)\n            \n        Returns\n        -------\n        None\n        \"\"\"", "\n", "if", "self", ".", "initialized", ":", "\n", "            ", "print", "(", "(", "'Exporting images to {}...'", ".", "format", "(", "export_dir", ")", ")", ")", "#end='', flush=True)", "\n", "for", "split_name", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "\n", "                ", "split_dir", "=", "join", "(", "export_dir", ",", "split_name", ")", "\n", "if", "not", "exists", "(", "split_dir", ")", ":", "\n", "                    ", "makedirs", "(", "split_dir", ")", "\n", "\n", "", "for", "i", ",", "norb_example", "in", "enumerate", "(", "self", ".", "data", "[", "split_name", "]", ")", ":", "\n", "\n", "                    ", "category", "=", "SmallNORBDataset", ".", "categories", "[", "norb_example", ".", "category", "]", "\n", "instance", "=", "norb_example", ".", "instance", "\n", "\n", "image_lt_path", "=", "join", "(", "split_dir", ",", "'{:06d}_{}_{:02d}_lt.jpg'", ".", "format", "(", "i", ",", "category", ",", "instance", ")", ")", "\n", "image_rt_path", "=", "join", "(", "split_dir", ",", "'{:06d}_{}_{:02d}_rt.jpg'", ".", "format", "(", "i", ",", "category", ",", "instance", ")", ")", "\n", "\n", "scipy", ".", "misc", ".", "imsave", "(", "image_lt_path", ",", "norb_example", ".", "image_lt", ")", "\n", "scipy", ".", "misc", ".", "imsave", "(", "image_rt_path", ",", "norb_example", ".", "image_rt", ")", "\n", "", "", "print", "(", "'Done.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.smallnorb.SmallNORBDataset.group_dataset_by_category_and_instance": [[142, 166], ["itertools.groupby", "ValueError", "groups.append", "sorted", "list"], "methods", ["None"], ["", "", "def", "group_dataset_by_category_and_instance", "(", "self", ",", "dataset_split", ")", ":", "\n", "        ", "\"\"\"\n        Group small NORB dataset for (category, instance) key\n        \n        Parameters\n        ----------\n        dataset_split: str\n            Dataset split, can be either 'train' or 'test'\n\n        Returns\n        -------\n        groups: list\n            List of 25 groups of 972 elements each. All examples of each group are\n            from the same category and instance\n        \"\"\"", "\n", "if", "dataset_split", "not", "in", "[", "'train'", ",", "'test'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "'Dataset split \"{}\" not allowed.'", ".", "format", "(", "dataset_split", ")", ")", "\n", "\n", "", "groups", "=", "[", "]", "\n", "for", "key", ",", "group", "in", "groupby", "(", "iterable", "=", "sorted", "(", "self", ".", "data", "[", "dataset_split", "]", ")", ",", "\n", "key", "=", "lambda", "x", ":", "(", "x", ".", "category", ",", "x", ".", "instance", ")", ")", ":", "\n", "            ", "groups", ".", "append", "(", "list", "(", "group", ")", ")", "\n", "\n", "", "return", "groups", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.smallnorb.SmallNORBDataset._fill_data_structures": [[167, 195], ["smallnorb.SmallNORBDataset._parse_NORB_dat_file", "smallnorb.SmallNORBDataset._parse_NORB_cat_file", "smallnorb.SmallNORBDataset._parse_NORB_info_file", "enumerate"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset._parse_NORB_dat_file", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset._parse_NORB_cat_file", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset._parse_NORB_info_file"], ["", "def", "_fill_data_structures", "(", "self", ",", "dataset_split", ")", ":", "\n", "        ", "\"\"\"\n        Fill SmallNORBDataset data structures for a certain `dataset_split`.\n        \n        This means all images, category and additional information are loaded from binary\n        files of the current split.\n        \n        Parameters\n        ----------\n        dataset_split: str\n            Dataset split, can be either 'train' or 'test'\n\n        Returns\n        -------\n        None\n\n        \"\"\"", "\n", "dat_data", "=", "self", ".", "_parse_NORB_dat_file", "(", "self", ".", "dataset_files", "[", "dataset_split", "]", "[", "'dat'", "]", ")", "\n", "cat_data", "=", "self", ".", "_parse_NORB_cat_file", "(", "self", ".", "dataset_files", "[", "dataset_split", "]", "[", "'cat'", "]", ")", "\n", "info_data", "=", "self", ".", "_parse_NORB_info_file", "(", "self", ".", "dataset_files", "[", "dataset_split", "]", "[", "'info'", "]", ")", "\n", "for", "i", ",", "small_norb_example", "in", "enumerate", "(", "self", ".", "data", "[", "dataset_split", "]", ")", ":", "\n", "            ", "small_norb_example", ".", "image_lt", "=", "dat_data", "[", "2", "*", "i", "]", "\n", "small_norb_example", ".", "image_rt", "=", "dat_data", "[", "2", "*", "i", "+", "1", "]", "\n", "small_norb_example", ".", "category", "=", "cat_data", "[", "i", "]", "\n", "small_norb_example", ".", "instance", "=", "info_data", "[", "i", "]", "[", "0", "]", "\n", "small_norb_example", ".", "elevation", "=", "info_data", "[", "i", "]", "[", "1", "]", "\n", "small_norb_example", ".", "azimuth", "=", "info_data", "[", "i", "]", "[", "2", "]", "\n", "small_norb_example", ".", "lighting", "=", "info_data", "[", "i", "]", "[", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.smallnorb.SmallNORBDataset.matrix_type_from_magic": [[196, 219], ["bytearray().hex().upper", "bytearray().hex", "bytearray", "reversed"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "matrix_type_from_magic", "(", "magic_number", ")", ":", "\n", "        ", "\"\"\"\n        Get matrix data type from magic number\n        See here: https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/readme for details.\n\n        Parameters\n        ----------\n        magic_number: tuple\n            First 4 bytes read from small NORB files \n\n        Returns\n        -------\n        element type of the matrix\n        \"\"\"", "\n", "convention", "=", "{", "'1E3D4C51'", ":", "'single precision matrix'", ",", "\n", "'1E3D4C52'", ":", "'packed matrix'", ",", "\n", "'1E3D4C53'", ":", "'double precision matrix'", ",", "\n", "'1E3D4C54'", ":", "'integer matrix'", ",", "\n", "'1E3D4C55'", ":", "'byte matrix'", ",", "\n", "'1E3D4C56'", ":", "'short matrix'", "}", "\n", "magic_str", "=", "bytearray", "(", "reversed", "(", "magic_number", ")", ")", ".", "hex", "(", ")", ".", "upper", "(", ")", "\n", "return", "convention", "[", "magic_str", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.smallnorb.SmallNORBDataset._parse_small_NORB_header": [[220, 248], ["struct.unpack", "struct.unpack", "range", "file_pointer.read", "file_pointer.read", "dimensions.extend", "smallnorb.SmallNORBDataset.matrix_type_from_magic", "struct.unpack", "file_pointer.read"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.matrix_type_from_magic"], ["", "@", "staticmethod", "\n", "def", "_parse_small_NORB_header", "(", "file_pointer", ")", ":", "\n", "        ", "\"\"\"\n        Parse header of small NORB binary file\n        \n        Parameters\n        ----------\n        file_pointer: BufferedReader\n            File pointer just opened in a small NORB binary file\n\n        Returns\n        -------\n        file_header_data: dict\n            Dictionary containing header information\n        \"\"\"", "\n", "# Read magic number", "\n", "magic", "=", "struct", ".", "unpack", "(", "'<BBBB'", ",", "file_pointer", ".", "read", "(", "4", ")", ")", "# '<' is little endian)", "\n", "\n", "# Read dimensions", "\n", "dimensions", "=", "[", "]", "\n", "num_dims", ",", "=", "struct", ".", "unpack", "(", "'<i'", ",", "file_pointer", ".", "read", "(", "4", ")", ")", "# '<' is little endian)", "\n", "for", "_", "in", "range", "(", "num_dims", ")", ":", "\n", "            ", "dimensions", ".", "extend", "(", "struct", ".", "unpack", "(", "'<i'", ",", "file_pointer", ".", "read", "(", "4", ")", ")", ")", "\n", "\n", "", "file_header_data", "=", "{", "'magic_number'", ":", "magic", ",", "\n", "'matrix_type'", ":", "SmallNORBDataset", ".", "matrix_type_from_magic", "(", "magic", ")", ",", "\n", "'dimensions'", ":", "dimensions", "}", "\n", "return", "file_header_data", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.smallnorb.SmallNORBDataset._parse_NORB_cat_file": [[249, 278], ["open", "smallnorb.SmallNORBDataset._parse_small_NORB_header", "struct.unpack", "struct.unpack", "numpy.zeros", "tqdm.tqdm.tqdm", "f.read", "f.read", "list", "struct.unpack", "range", "f.read"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset._parse_small_NORB_header"], ["", "@", "staticmethod", "\n", "def", "_parse_NORB_cat_file", "(", "file_path", ")", ":", "\n", "        ", "\"\"\"\n        Parse small NORB category file\n        \n        Parameters\n        ----------\n        file_path: str\n            Path of the small NORB `*-cat.mat` file\n\n        Returns\n        -------\n        examples: ndarray\n            Ndarray of shape (24300,) containing the category of each example\n        \"\"\"", "\n", "with", "open", "(", "file_path", ",", "mode", "=", "'rb'", ")", "as", "f", ":", "\n", "            ", "header", "=", "SmallNORBDataset", ".", "_parse_small_NORB_header", "(", "f", ")", "\n", "\n", "num_examples", ",", "=", "header", "[", "'dimensions'", "]", "\n", "\n", "struct", ".", "unpack", "(", "'<BBBB'", ",", "f", ".", "read", "(", "4", ")", ")", "# ignore this integer", "\n", "struct", ".", "unpack", "(", "'<BBBB'", ",", "f", ".", "read", "(", "4", ")", ")", "# ignore this integer", "\n", "\n", "examples", "=", "np", ".", "zeros", "(", "shape", "=", "num_examples", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "for", "i", "in", "tqdm", "(", "list", "(", "range", "(", "num_examples", ")", ")", ",", "desc", "=", "'Loading categories...'", ")", ":", "\n", "                ", "category", ",", "=", "struct", ".", "unpack", "(", "'<i'", ",", "f", ".", "read", "(", "4", ")", ")", "\n", "examples", "[", "i", "]", "=", "category", "\n", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.smallnorb.SmallNORBDataset._parse_NORB_dat_file": [[279, 312], ["open", "smallnorb.SmallNORBDataset._parse_small_NORB_header", "numpy.zeros", "tqdm.tqdm.tqdm", "list", "struct.unpack", "numpy.uint8", "range", "f.read", "numpy.reshape"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset._parse_small_NORB_header"], ["", "", "@", "staticmethod", "\n", "def", "_parse_NORB_dat_file", "(", "file_path", ")", ":", "\n", "        ", "\"\"\"\n        Parse small NORB data file\n\n        Parameters\n        ----------\n        file_path: str\n            Path of the small NORB `*-dat.mat` file\n\n        Returns\n        -------\n        examples: ndarray\n            Ndarray of shape (48600, 96, 96) containing images couples. Each image couple\n            is stored in position [i, :, :] and [i+1, :, :]\n        \"\"\"", "\n", "with", "open", "(", "file_path", ",", "mode", "=", "'rb'", ")", "as", "f", ":", "\n", "\n", "            ", "header", "=", "SmallNORBDataset", ".", "_parse_small_NORB_header", "(", "f", ")", "\n", "\n", "num_examples", ",", "channels", ",", "height", ",", "width", "=", "header", "[", "'dimensions'", "]", "\n", "\n", "examples", "=", "np", ".", "zeros", "(", "shape", "=", "(", "num_examples", "*", "channels", ",", "height", ",", "width", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n", "for", "i", "in", "tqdm", "(", "list", "(", "range", "(", "num_examples", "*", "channels", ")", ")", ",", "desc", "=", "'Loading images...'", ")", ":", "\n", "\n", "# Read raw image data and restore shape as appropriate", "\n", "                ", "image", "=", "struct", ".", "unpack", "(", "'<'", "+", "height", "*", "width", "*", "'B'", ",", "f", ".", "read", "(", "height", "*", "width", ")", ")", "\n", "image", "=", "np", ".", "uint8", "(", "np", ".", "reshape", "(", "image", ",", "newshape", "=", "(", "height", ",", "width", ")", ")", ")", "\n", "\n", "examples", "[", "i", "]", "=", "image", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.smallnorb.SmallNORBDataset._parse_NORB_info_file": [[313, 350], ["open", "smallnorb.SmallNORBDataset._parse_small_NORB_header", "struct.unpack", "numpy.zeros", "tqdm.tqdm.tqdm", "f.read", "list", "range", "range", "struct.unpack", "f.read"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset._parse_small_NORB_header"], ["", "@", "staticmethod", "\n", "def", "_parse_NORB_info_file", "(", "file_path", ")", ":", "\n", "        ", "\"\"\"\n        Parse small NORB information file\n\n        Parameters\n        ----------\n        file_path: str\n            Path of the small NORB `*-info.mat` file\n\n        Returns\n        -------\n        examples: ndarray\n            Ndarray of shape (24300,4) containing the additional info of each example.\n            \n             - column 1: the instance in the category (0 to 9)\n             - column 2: the elevation (0 to 8, which mean cameras are 30, 35,40,45,50,55,60,65,70 \n               degrees from the horizontal respectively)\n             - column 3: the azimuth (0,2,4,...,34, multiply by 10 to get the azimuth in degrees)\n             - column 4: the lighting condition (0 to 5)\n        \"\"\"", "\n", "with", "open", "(", "file_path", ",", "mode", "=", "'rb'", ")", "as", "f", ":", "\n", "\n", "            ", "header", "=", "SmallNORBDataset", ".", "_parse_small_NORB_header", "(", "f", ")", "\n", "\n", "struct", ".", "unpack", "(", "'<BBBB'", ",", "f", ".", "read", "(", "4", ")", ")", "# ignore this integer", "\n", "\n", "num_examples", ",", "num_info", "=", "header", "[", "'dimensions'", "]", "\n", "\n", "examples", "=", "np", ".", "zeros", "(", "shape", "=", "(", "num_examples", ",", "num_info", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "for", "r", "in", "tqdm", "(", "list", "(", "range", "(", "num_examples", ")", ")", ",", "desc", "=", "'Loading info...'", ")", ":", "\n", "                ", "for", "c", "in", "range", "(", "num_info", ")", ":", "\n", "                    ", "info", ",", "=", "struct", ".", "unpack", "(", "'<i'", ",", "f", ".", "read", "(", "4", ")", ")", "\n", "examples", "[", "r", ",", "c", "]", "=", "info", "\n", "\n", "", "", "", "return", "examples", "\n", "", "", ""]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBExample.__init__": [[18, 26], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "image_lt", "=", "None", "\n", "self", ".", "image_rt", "=", "None", "\n", "self", ".", "category", "=", "None", "\n", "self", ".", "instance", "=", "None", "\n", "self", ".", "elevation", "=", "None", "\n", "self", ".", "azimuth", "=", "None", "\n", "self", ".", "lighting", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBExample.__lt__": [[27, 30], ["None"], "methods", ["None"], ["", "def", "__lt__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "category", "<", "other", ".", "category", "or", "(", "self", ".", "category", "==", "other", ".", "category", "and", "self", ".", "instance", "<", "other", ".", "instance", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBExample.show": [[31, 38], ["fig.suptitle", "axes[].imshow", "axes[].imshow"], "methods", ["None"], ["", "def", "show", "(", "self", ",", "subplots", ")", ":", "\n", "        ", "fig", ",", "axes", "=", "subplots", "\n", "fig", ".", "suptitle", "(", "\n", "'Category: {:02d} - Instance: {:02d} - Elevation: {:02d} - Azimuth: {:02d} - Lighting: {:02d}'", ".", "format", "(", "\n", "self", ".", "category", ",", "self", ".", "instance", ",", "self", ".", "elevation", ",", "self", ".", "azimuth", ",", "self", ".", "lighting", ")", ")", "\n", "axes", "[", "0", "]", ".", "imshow", "(", "self", ".", "image_lt", ",", "cmap", "=", "'gray'", ")", "\n", "axes", "[", "1", "]", ".", "imshow", "(", "self", ".", "image_rt", ",", "cmap", "=", "'gray'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBExample.pose": [[39, 42], ["numpy.array"], "methods", ["None"], ["", "@", "property", "\n", "def", "pose", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "array", "(", "[", "self", ".", "elevation", ",", "self", ".", "azimuth", ",", "self", ".", "lighting", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.__init__": [[52, 141], ["print", "norb.NORBDataset._fill_data_structures", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "norb.NORBExample", "range"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset._fill_data_structures"], ["def", "__init__", "(", "self", ",", "dataset_root", ",", "names", ")", ":", "\n", "        ", "\"\"\"\n        Initialize small NORB dataset wrapper\n\n        Parameters\n        ----------\n        dataset_root: str\n            Path to directory where small NORB archives have been extracted.\n        \"\"\"", "\n", "self", ".", "names", "=", "names", "\n", "self", ".", "dataset_root", "=", "dataset_root", "\n", "self", ".", "initialized", "=", "False", "\n", "\n", "# Store path for each file in small NORB dataset (for compatibility the original filename is kept)", "\n", "self", ".", "dataset_files", "=", "{", "\n", "'train1'", ":", "{", "\n", "'cat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-01-cat.mat'", ")", ",", "\n", "'info'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-01-info.mat'", ")", ",", "\n", "'dat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-01-dat.mat'", ")", "\n", "}", ",", "\n", "'train2'", ":", "{", "\n", "'cat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-02-cat.mat'", ")", ",", "\n", "'info'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-02-info.mat'", ")", ",", "\n", "'dat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-02-dat.mat'", ")", "\n", "}", ",", "\n", "'train3'", ":", "{", "\n", "'cat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-03-cat.mat'", ")", ",", "\n", "'info'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-03-info.mat'", ")", ",", "\n", "'dat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-03-dat.mat'", ")", "\n", "}", ",", "\n", "'train4'", ":", "{", "\n", "'cat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-04-cat.mat'", ")", ",", "\n", "'info'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-04-info.mat'", ")", ",", "\n", "'dat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-04-dat.mat'", ")", "\n", "}", ",", "\n", "'train5'", ":", "{", "\n", "'cat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-05-cat.mat'", ")", ",", "\n", "'info'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-05-info.mat'", ")", ",", "\n", "'dat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-05-dat.mat'", ")", "\n", "}", ",", "\n", "'train6'", ":", "{", "\n", "'cat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-06-cat.mat'", ")", ",", "\n", "'info'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-06-info.mat'", ")", ",", "\n", "'dat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-06-dat.mat'", ")", "\n", "}", ",", "\n", "'train7'", ":", "{", "\n", "'cat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-07-cat.mat'", ")", ",", "\n", "'info'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-07-info.mat'", ")", ",", "\n", "'dat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-07-dat.mat'", ")", "\n", "}", ",", "\n", "'train8'", ":", "{", "\n", "'cat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-08-cat.mat'", ")", ",", "\n", "'info'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-08-info.mat'", ")", ",", "\n", "'dat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-08-dat.mat'", ")", "\n", "}", ",", "\n", "'train9'", ":", "{", "\n", "'cat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-09-cat.mat'", ")", ",", "\n", "'info'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-09-info.mat'", ")", ",", "\n", "'dat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-09-dat.mat'", ")", "\n", "}", ",", "\n", "'train10'", ":", "{", "\n", "'cat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-10-cat.mat'", ")", ",", "\n", "'info'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-10-info.mat'", ")", ",", "\n", "'dat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x46789x9x18x6x2x108x108-training-10-dat.mat'", ")", "\n", "}", ",", "\n", "'test1'", ":", "{", "\n", "'cat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x01235x9x18x6x2x108x108-testing-01-cat.mat'", ")", ",", "\n", "'info'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x01235x9x18x6x2x108x108-testing-01-info.mat'", ")", ",", "\n", "'dat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x01235x9x18x6x2x108x108-testing-01-dat.mat'", ")", "\n", "}", ",", "\n", "'test2'", ":", "{", "\n", "'cat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x01235x9x18x6x2x108x108-testing-02-cat.mat'", ")", ",", "\n", "'info'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x01235x9x18x6x2x108x108-testing-02-info.mat'", ")", ",", "\n", "'dat'", ":", "join", "(", "self", ".", "dataset_root", ",", "'norb-5x01235x9x18x6x2x108x108-testing-02-dat.mat'", ")", "\n", "}", "\n", "}", "\n", "\n", "# Initialize both train and test data structures", "\n", "self", ".", "data", "=", "{", "}", "\n", "\n", "for", "name", "in", "self", ".", "names", ":", "\n", "            ", "self", ".", "data", "[", "name", "]", "=", "[", "NORBExample", "(", ")", "for", "_", "in", "range", "(", "NORBDataset", ".", "n_examples", ")", "]", "\n", "\n", "# Fill data structures parsing dataset binary files", "\n", "", "for", "data_split", "in", "self", ".", "names", ":", "\n", "            ", "print", "(", "'filling for data split: '", ",", "data_split", ")", "\n", "self", ".", "_fill_data_structures", "(", "data_split", ")", "\n", "\n", "", "self", ".", "initialized", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.explore_random_examples": [[142, 161], ["plt.subplots", "numpy.random.permutation", "[].show", "plt.waitforbuttonpress", "plt.cla"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBExample.show"], ["", "def", "explore_random_examples", "(", "self", ",", "dataset_split", ")", ":", "\n", "        ", "\"\"\"\n        Visualize random examples for dataset exploration purposes\n\n        Parameters\n        ----------\n        dataset_split: str\n            Dataset split, can be either 'train' or 'test'\n\n        Returns\n        -------\n        None\n        \"\"\"", "\n", "if", "self", ".", "initialized", ":", "\n", "            ", "subplots", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "2", ")", "\n", "for", "i", "in", "np", ".", "random", ".", "permutation", "(", "NORBDataset", ".", "n_examples", ")", ":", "\n", "                ", "self", ".", "data", "[", "dataset_split", "]", "[", "i", "]", ".", "show", "(", "subplots", ")", "\n", "plt", ".", "waitforbuttonpress", "(", ")", "\n", "plt", ".", "cla", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.export_to_jpg": [[162, 194], ["print", "print", "os.path.join", "enumerate", "os.path.exists", "os.makedirs", "os.path.join", "os.path.join", "scipy.misc.imsave", "scipy.misc.imsave"], "methods", ["None"], ["", "", "", "def", "export_to_jpg", "(", "self", ",", "export_dir", ")", ":", "\n", "        ", "\"\"\"\n        Export all dataset images to `export_dir` directory\n\n        Parameters\n        ----------\n        export_dir: str\n            Path to export directory (which is created if nonexistent)\n\n        Returns\n        -------\n        None\n        \"\"\"", "\n", "if", "self", ".", "initialized", ":", "\n", "            ", "print", "(", "(", "'Exporting images to {}...'", ".", "format", "(", "export_dir", ")", ")", ")", "#end='', flush=True)", "\n", "for", "split_name", "in", "names", ":", "\n", "\n", "                ", "split_dir", "=", "join", "(", "export_dir", ",", "split_name", ")", "\n", "if", "not", "exists", "(", "split_dir", ")", ":", "\n", "                    ", "makedirs", "(", "split_dir", ")", "\n", "\n", "", "for", "i", ",", "norb_example", "in", "enumerate", "(", "self", ".", "data", "[", "split_name", "]", ")", ":", "\n", "\n", "                    ", "category", "=", "NORBDataset", ".", "categories", "[", "norb_example", ".", "category", "]", "\n", "instance", "=", "norb_example", ".", "instance", "\n", "\n", "image_lt_path", "=", "join", "(", "split_dir", ",", "'{:06d}_{}_{:02d}_lt.jpg'", ".", "format", "(", "i", ",", "category", ",", "instance", ")", ")", "\n", "image_rt_path", "=", "join", "(", "split_dir", ",", "'{:06d}_{}_{:02d}_rt.jpg'", ".", "format", "(", "i", ",", "category", ",", "instance", ")", ")", "\n", "\n", "scipy", ".", "misc", ".", "imsave", "(", "image_lt_path", ",", "norb_example", ".", "image_lt", ")", "\n", "scipy", ".", "misc", ".", "imsave", "(", "image_rt_path", ",", "norb_example", ".", "image_rt", ")", "\n", "", "", "print", "(", "'Done.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.group_dataset_by_category_and_instance": [[195, 219], ["itertools.groupby", "ValueError", "groups.append", "sorted", "list"], "methods", ["None"], ["", "", "def", "group_dataset_by_category_and_instance", "(", "self", ",", "dataset_split", ")", ":", "\n", "        ", "\"\"\"\n        Group small NORB dataset for (category, instance) key\n\n        Parameters\n        ----------\n        dataset_split: str\n            Dataset split, can be either 'train' or 'test'\n\n        Returns\n        -------\n        groups: list\n            List of 25 groups of 972 elements each. All examples of each group are\n            from the same category and instance\n        \"\"\"", "\n", "if", "dataset_split", "not", "in", "self", ".", "names", ":", "\n", "            ", "raise", "ValueError", "(", "'Dataset split \"{}\" not allowed.'", ".", "format", "(", "dataset_split", ")", ")", "\n", "\n", "", "groups", "=", "[", "]", "\n", "for", "key", ",", "group", "in", "groupby", "(", "iterable", "=", "sorted", "(", "self", ".", "data", "[", "dataset_split", "]", ")", ",", "\n", "key", "=", "lambda", "x", ":", "(", "x", ".", "category", ",", "x", ".", "instance", ")", ")", ":", "\n", "            ", "groups", ".", "append", "(", "list", "(", "group", ")", ")", "\n", "\n", "", "return", "groups", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset._fill_data_structures": [[220, 248], ["norb.NORBDataset._parse_NORB_dat_file", "norb.NORBDataset._parse_NORB_cat_file", "norb.NORBDataset._parse_NORB_info_file", "enumerate"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset._parse_NORB_dat_file", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset._parse_NORB_cat_file", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset._parse_NORB_info_file"], ["", "def", "_fill_data_structures", "(", "self", ",", "dataset_split", ")", ":", "\n", "        ", "\"\"\"\n        Fill NORBDataset data structures for a certain `dataset_split`.\n\n        This means all images, category and additional information are loaded from binary\n        files of the current split.\n\n        Parameters\n        ----------\n        dataset_split: str\n            Dataset split, can be either 'train' or 'test'\n\n        Returns\n        -------\n        None\n\n        \"\"\"", "\n", "dat_data", "=", "self", ".", "_parse_NORB_dat_file", "(", "self", ".", "dataset_files", "[", "dataset_split", "]", "[", "'dat'", "]", ")", "\n", "cat_data", "=", "self", ".", "_parse_NORB_cat_file", "(", "self", ".", "dataset_files", "[", "dataset_split", "]", "[", "'cat'", "]", ")", "\n", "info_data", "=", "self", ".", "_parse_NORB_info_file", "(", "self", ".", "dataset_files", "[", "dataset_split", "]", "[", "'info'", "]", ")", "\n", "for", "i", ",", "small_norb_example", "in", "enumerate", "(", "self", ".", "data", "[", "dataset_split", "]", ")", ":", "\n", "            ", "small_norb_example", ".", "image_lt", "=", "dat_data", "[", "2", "*", "i", "]", "\n", "small_norb_example", ".", "image_rt", "=", "dat_data", "[", "2", "*", "i", "+", "1", "]", "\n", "small_norb_example", ".", "category", "=", "cat_data", "[", "i", "]", "\n", "small_norb_example", ".", "instance", "=", "info_data", "[", "i", "]", "[", "0", "]", "\n", "small_norb_example", ".", "elevation", "=", "info_data", "[", "i", "]", "[", "1", "]", "\n", "small_norb_example", ".", "azimuth", "=", "info_data", "[", "i", "]", "[", "2", "]", "\n", "small_norb_example", ".", "lighting", "=", "info_data", "[", "i", "]", "[", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.matrix_type_from_magic": [[249, 272], ["bytearray().hex().upper", "bytearray().hex", "bytearray", "reversed"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "matrix_type_from_magic", "(", "magic_number", ")", ":", "\n", "        ", "\"\"\"\n        Get matrix data type from magic number\n        See here: https://cs.nyu.edu/~ylclab/data/norb-v1.0-small/readme for details.\n\n        Parameters\n        ----------\n        magic_number: tuple\n            First 4 bytes read from small NORB files\n\n        Returns\n        -------\n        element type of the matrix\n        \"\"\"", "\n", "convention", "=", "{", "'1E3D4C51'", ":", "'single precision matrix'", ",", "\n", "'1E3D4C52'", ":", "'packed matrix'", ",", "\n", "'1E3D4C53'", ":", "'double precision matrix'", ",", "\n", "'1E3D4C54'", ":", "'integer matrix'", ",", "\n", "'1E3D4C55'", ":", "'byte matrix'", ",", "\n", "'1E3D4C56'", ":", "'short matrix'", "}", "\n", "magic_str", "=", "bytearray", "(", "reversed", "(", "magic_number", ")", ")", ".", "hex", "(", ")", ".", "upper", "(", ")", "\n", "return", "convention", "[", "magic_str", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset._parse_small_NORB_header": [[273, 301], ["struct.unpack", "struct.unpack", "range", "file_pointer.read", "file_pointer.read", "dimensions.extend", "norb.NORBDataset.matrix_type_from_magic", "struct.unpack", "file_pointer.read"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset.matrix_type_from_magic"], ["", "@", "staticmethod", "\n", "def", "_parse_small_NORB_header", "(", "file_pointer", ")", ":", "\n", "        ", "\"\"\"\n        Parse header of small NORB binary file\n\n        Parameters\n        ----------\n        file_pointer: BufferedReader\n            File pointer just opened in a small NORB binary file\n\n        Returns\n        -------\n        file_header_data: dict\n            Dictionary containing header information\n        \"\"\"", "\n", "# Read magic number", "\n", "magic", "=", "struct", ".", "unpack", "(", "'<BBBB'", ",", "file_pointer", ".", "read", "(", "4", ")", ")", "# '<' is little endian)", "\n", "\n", "# Read dimensions", "\n", "dimensions", "=", "[", "]", "\n", "num_dims", ",", "=", "struct", ".", "unpack", "(", "'<i'", ",", "file_pointer", ".", "read", "(", "4", ")", ")", "# '<' is little endian)", "\n", "for", "_", "in", "range", "(", "num_dims", ")", ":", "\n", "            ", "dimensions", ".", "extend", "(", "struct", ".", "unpack", "(", "'<i'", ",", "file_pointer", ".", "read", "(", "4", ")", ")", ")", "\n", "\n", "", "file_header_data", "=", "{", "'magic_number'", ":", "magic", ",", "\n", "'matrix_type'", ":", "NORBDataset", ".", "matrix_type_from_magic", "(", "magic", ")", ",", "\n", "'dimensions'", ":", "dimensions", "}", "\n", "return", "file_header_data", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset._parse_NORB_cat_file": [[302, 331], ["open", "norb.NORBDataset._parse_small_NORB_header", "struct.unpack", "struct.unpack", "numpy.zeros", "tqdm.tqdm.tqdm", "f.read", "f.read", "list", "struct.unpack", "range", "f.read"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset._parse_small_NORB_header"], ["", "@", "staticmethod", "\n", "def", "_parse_NORB_cat_file", "(", "file_path", ")", ":", "\n", "        ", "\"\"\"\n        Parse small NORB category file\n\n        Parameters\n        ----------\n        file_path: str\n            Path of the small NORB `*-cat.mat` file\n\n        Returns\n        -------\n        examples: ndarray\n            Ndarray of shape (24300,) containing the category of each example\n        \"\"\"", "\n", "with", "open", "(", "file_path", ",", "mode", "=", "'rb'", ")", "as", "f", ":", "\n", "            ", "header", "=", "NORBDataset", ".", "_parse_small_NORB_header", "(", "f", ")", "\n", "\n", "num_examples", ",", "=", "header", "[", "'dimensions'", "]", "\n", "\n", "struct", ".", "unpack", "(", "'<BBBB'", ",", "f", ".", "read", "(", "4", ")", ")", "# ignore this integer", "\n", "struct", ".", "unpack", "(", "'<BBBB'", ",", "f", ".", "read", "(", "4", ")", ")", "# ignore this integer", "\n", "\n", "examples", "=", "np", ".", "zeros", "(", "shape", "=", "num_examples", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "for", "i", "in", "tqdm", "(", "list", "(", "range", "(", "num_examples", ")", ")", ",", "desc", "=", "'Loading categories...'", ")", ":", "\n", "                ", "category", ",", "=", "struct", ".", "unpack", "(", "'<i'", ",", "f", ".", "read", "(", "4", ")", ")", "\n", "examples", "[", "i", "]", "=", "category", "\n", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset._parse_NORB_dat_file": [[332, 366], ["print", "open", "norb.NORBDataset._parse_small_NORB_header", "print", "numpy.zeros", "tqdm.tqdm.tqdm", "list", "struct.unpack", "numpy.uint8", "range", "f.read", "numpy.reshape"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset._parse_small_NORB_header"], ["", "", "@", "staticmethod", "\n", "def", "_parse_NORB_dat_file", "(", "file_path", ")", ":", "\n", "        ", "\"\"\"\n        Parse small NORB data file\n\n        Parameters\n        ----------\n        file_path: str\n            Path of the small NORB `*-dat.mat` file\n\n        Returns\n        -------\n        examples: ndarray\n            Ndarray of shape (48600, 96, 96) containing images couples. Each image couple\n            is stored in position [i, :, :] and [i+1, :, :]\n        \"\"\"", "\n", "print", "(", "'norb file path: '", ",", "file_path", ")", "\n", "with", "open", "(", "file_path", ",", "mode", "=", "'rb'", ")", "as", "f", ":", "\n", "\n", "            ", "header", "=", "NORBDataset", ".", "_parse_small_NORB_header", "(", "f", ")", "\n", "print", "(", "'header: '", ",", "header", ")", "\n", "num_examples", ",", "channels", ",", "height", ",", "width", "=", "header", "[", "'dimensions'", "]", "\n", "\n", "examples", "=", "np", ".", "zeros", "(", "shape", "=", "(", "num_examples", "*", "channels", ",", "height", ",", "width", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n", "for", "i", "in", "tqdm", "(", "list", "(", "range", "(", "num_examples", "*", "channels", ")", ")", ",", "desc", "=", "'Loading images...'", ")", ":", "\n", "\n", "# Read raw image data and restore shape as appropriate", "\n", "                ", "image", "=", "struct", ".", "unpack", "(", "'<'", "+", "height", "*", "width", "*", "'B'", ",", "f", ".", "read", "(", "height", "*", "width", ")", ")", "\n", "image", "=", "np", ".", "uint8", "(", "np", ".", "reshape", "(", "image", ",", "newshape", "=", "(", "height", ",", "width", ")", ")", ")", "\n", "\n", "examples", "[", "i", "]", "=", "image", "\n", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset._parse_NORB_info_file": [[367, 404], ["open", "norb.NORBDataset._parse_small_NORB_header", "struct.unpack", "numpy.zeros", "tqdm.tqdm.tqdm", "f.read", "list", "range", "range", "struct.unpack", "f.read"], "methods", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.norb.NORBDataset._parse_small_NORB_header"], ["", "@", "staticmethod", "\n", "def", "_parse_NORB_info_file", "(", "file_path", ")", ":", "\n", "        ", "\"\"\"\n        Parse small NORB information file\n\n        Parameters\n        ----------\n        file_path: str\n            Path of the small NORB `*-info.mat` file\n\n        Returns\n        -------\n        examples: ndarray\n            Ndarray of shape (24300,4) containing the additional info of each example.\n\n             - column 1: the instance in the category (0 to 9)\n             - column 2: the elevation (0 to 8, which mean cameras are 30, 35,40,45,50,55,60,65,70\n               degrees from the horizontal respectively)\n             - column 3: the azimuth (0,2,4,...,34, multiply by 10 to get the azimuth in degrees)\n             - column 4: the lighting condition (0 to 5)\n        \"\"\"", "\n", "with", "open", "(", "file_path", ",", "mode", "=", "'rb'", ")", "as", "f", ":", "\n", "\n", "            ", "header", "=", "NORBDataset", ".", "_parse_small_NORB_header", "(", "f", ")", "\n", "\n", "struct", ".", "unpack", "(", "'<BBBB'", ",", "f", ".", "read", "(", "4", ")", ")", "# ignore this integer", "\n", "\n", "num_examples", ",", "num_info", "=", "header", "[", "'dimensions'", "]", "\n", "\n", "examples", "=", "np", ".", "zeros", "(", "shape", "=", "(", "num_examples", ",", "num_info", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "\n", "for", "r", "in", "tqdm", "(", "list", "(", "range", "(", "num_examples", ")", ")", ",", "desc", "=", "'Loading info...'", ")", ":", "\n", "                ", "for", "c", "in", "range", "(", "num_info", ")", ":", "\n", "                    ", "info", ",", "=", "struct", ".", "unpack", "(", "'<i'", ",", "f", ".", "read", "(", "4", ")", ")", "\n", "examples", "[", "r", ",", "c", "]", "=", "info", "\n", "\n", "", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.data_utils.normalize_data": [[3, 8], ["numpy.mean", "numpy.std", "data_utils.apply_normalization"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.data_utils.apply_normalization"], ["def", "normalize_data", "(", "data", ")", ":", "\n", "    ", "mean", "=", "np", ".", "mean", "(", "data", ",", "axis", "=", "0", ")", "\n", "std", "=", "np", ".", "std", "(", "data", ",", "axis", "=", "0", ")", "\n", "\n", "return", "apply_normalization", "(", "data", ",", "mean", ",", "std", ")", ",", "mean", ",", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.data_utils.apply_normalization": [[9, 13], ["print", "numpy.mean", "numpy.std"], "function", ["None"], ["", "def", "apply_normalization", "(", "data", ",", "mean", ",", "std", ")", ":", "\n", "    ", "normalized", "=", "(", "data", "-", "mean", ")", "/", "std", "\n", "print", "(", "'Apply normalization: mean, std: '", ",", "np", ".", "mean", "(", "normalized", ",", "axis", "=", "0", ")", ",", "np", ".", "std", "(", "normalized", ",", "axis", "=", "0", ")", ")", "\n", "return", "normalized", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.data_utils.standardize": [[14, 19], ["print", "numpy.min", "numpy.max"], "function", ["None"], ["", "def", "standardize", "(", "data", ",", "max_val", "=", "255.0", ")", ":", "\n", "    ", "scaled", "=", "data", "/", "max_val", "\n", "scaled", "=", "(", "scaled", "-", "0.5", ")", "/", "0.5", "\n", "print", "(", "'min, max: '", ",", "np", ".", "min", "(", "scaled", ")", ",", "np", ".", "max", "(", "scaled", ")", ")", "\n", "return", "scaled", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.preprocess_mnist_bg_rot.process_data": [[8, 16], ["numpy.expand_dims", "sklearn.preprocessing.OneHotEncoder", "sklearn.preprocessing.OneHotEncoder.fit_transform().todense", "sklearn.preprocessing.OneHotEncoder.fit_transform"], "function", ["None"], ["def", "process_data", "(", "data", ")", ":", "\n", "    ", "X", "=", "data", "[", ":", ",", ":", "-", "1", "]", "\n", "Y", "=", "np", ".", "expand_dims", "(", "data", "[", ":", ",", "-", "1", "]", ",", "1", ")", "\n", "\n", "# Y must be one-hot", "\n", "enc", "=", "OneHotEncoder", "(", ")", "\n", "Y", "=", "enc", ".", "fit_transform", "(", "Y", ")", ".", "todense", "(", ")", "\n", "return", "X", ",", "Y", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.preprocess_convex.process_data": [[8, 16], ["numpy.expand_dims", "sklearn.preprocessing.OneHotEncoder", "sklearn.preprocessing.OneHotEncoder.fit_transform().todense", "sklearn.preprocessing.OneHotEncoder.fit_transform"], "function", ["None"], ["def", "process_data", "(", "data", ")", ":", "\n", "    ", "X", "=", "data", "[", ":", ",", ":", "-", "1", "]", "\n", "Y", "=", "np", ".", "expand_dims", "(", "data", "[", ":", ",", "-", "1", "]", ",", "1", ")", "\n", "\n", "# Y must be one-hot", "\n", "enc", "=", "OneHotEncoder", "(", ")", "\n", "Y", "=", "enc", ".", "fit_transform", "(", "Y", ")", ".", "todense", "(", ")", "\n", "return", "X", ",", "Y", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.preprocess_smallnorb.process_image": [[19, 28], ["scipy.misc.imresize", "scipy.misc.imresize.flatten"], "function", ["None"], ["def", "process_image", "(", "image", ")", ":", "\n", "# Downsample", "\n", "\t", "ds", "=", "imresize", "(", "image", ",", "DS_SIZE", ",", "'nearest'", ")", "\n", "\n", "# Normalize", "\n", "ds", "=", "ds", "/", "MAX_VAL", "\n", "\n", "# Flatten", "\n", "return", "ds", ".", "flatten", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.preprocess_smallnorb.process_data": [[32, 49], ["numpy.array", "numpy.array", "numpy.expand_dims", "sklearn.preprocessing.OneHotEncoder", "sklearn.preprocessing.OneHotEncoder.fit_transform().todense", "np.array.append", "enc.fit_transform().todense.append", "preprocess_smallnorb.process_image", "sklearn.preprocessing.OneHotEncoder.fit_transform"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.preprocess_norb.process_image"], ["def", "process_data", "(", "data", ")", ":", "\n", "\t", "X", "=", "[", "]", "\n", "Y", "=", "[", "]", "\n", "\n", "for", "ex", "in", "data", ":", "\n", "\t\t", "this_image", "=", "ex", ".", "image_lt", "\n", "this_category", "=", "ex", ".", "category", "\n", "X", ".", "append", "(", "process_image", "(", "this_image", ")", ")", "\n", "Y", ".", "append", "(", "this_category", ")", "\n", "\n", "", "X", "=", "np", ".", "array", "(", "X", ")", "\n", "Y", "=", "np", ".", "array", "(", "Y", ")", "\n", "Y", "=", "np", ".", "expand_dims", "(", "Y", ",", "1", ")", "\n", "enc", "=", "OneHotEncoder", "(", "N_CATEGORIES", ")", "\n", "Y", "=", "enc", ".", "fit_transform", "(", "Y", ")", ".", "todense", "(", ")", "\n", "\n", "return", "X", ",", "Y", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.preprocess_rect.process_data": [[8, 16], ["numpy.expand_dims", "sklearn.preprocessing.OneHotEncoder", "sklearn.preprocessing.OneHotEncoder.fit_transform().todense", "sklearn.preprocessing.OneHotEncoder.fit_transform"], "function", ["None"], ["def", "process_data", "(", "data", ")", ":", "\n", "    ", "X", "=", "data", "[", ":", ",", ":", "-", "1", "]", "\n", "Y", "=", "np", ".", "expand_dims", "(", "data", "[", ":", ",", "-", "1", "]", ",", "1", ")", "\n", "\n", "# Y must be one-hot", "\n", "enc", "=", "OneHotEncoder", "(", ")", "\n", "Y", "=", "enc", ".", "fit_transform", "(", "Y", ")", ".", "todense", "(", ")", "\n", "return", "X", ",", "Y", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.timit.process": [[6, 27], ["numpy.array", "print", "scipy.loadmat", "numpy.bincount", "print", "numpy.argsort", "print", "print", "print", "print", "h5py.File", "numpy.array", "scipy.loadmat", "lab.flatten", "numpy.sum", "range"], "function", ["None"], ["def", "process", "(", "feat_loc", ",", "lab_loc", ",", "train", ",", "top_N_classes", "=", "None", ",", "N", "=", "None", ")", ":", "\n", "\t", "lab", "=", "sio", ".", "loadmat", "(", "lab_loc", ")", "[", "'lab'", "]", "\n", "if", "train", ":", "\n", "\t\t", "with", "h5py", ".", "File", "(", "feat_loc", ")", "as", "f", ":", "\n", "\t\t\t", "feat", "=", "np", ".", "array", "(", "f", "[", "'fea'", "]", ")", "\n", "", "", "else", ":", "\n", "\t\t", "feat", "=", "sio", ".", "loadmat", "(", "feat_loc", ")", "[", "'fea'", "]", "\n", "", "if", "top_N_classes", "is", "None", ":", "\n", "\t\t", "assert", "N", "is", "not", "None", "\n", "counts", "=", "np", ".", "bincount", "(", "lab", ".", "flatten", "(", ")", ")", "\n", "print", "(", "'counts: '", ",", "counts", ")", "\n", "idx_array", "=", "np", ".", "argsort", "(", "counts", ")", "\n", "print", "(", "'idx array: '", ",", "idx_array", ")", "\n", "top_N_classes", "=", "idx_array", "[", "-", "N", ":", "]", "[", ":", ":", "-", "1", "]", "\n", "print", "(", "'top N classes: '", ",", "top_N_classes", ")", "\n", "print", "(", "'top N counts: '", ",", "counts", "[", "top_N_classes", "]", ")", "\n", "print", "(", "'top N total: '", ",", "np", ".", "sum", "(", "counts", "[", "top_N_classes", "]", ")", ")", "\n", "", "idx", "=", "np", ".", "array", "(", "[", "i", "for", "i", "in", "range", "(", "lab", ".", "size", ")", "if", "lab", "[", "i", "]", "in", "top_N_classes", "]", ")", "\n", "print", "(", "'idx: '", ",", "idx", ".", "shape", ")", "\n", "\n", "return", "feat", "[", "idx", ",", ":", "]", ",", "lab", "[", "idx", "]", ",", "top_N_classes", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.preprocess_norb.process_image": [[19, 25], ["scipy.misc.imresize", "scipy.misc.imresize.flatten"], "function", ["None"], ["def", "process_image", "(", "image", ")", ":", "\n", "# Downsample", "\n", "    ", "ds", "=", "imresize", "(", "image", ",", "DS_SIZE", ",", "'nearest'", ")", "\n", "\n", "# Flatten", "\n", "return", "ds", ".", "flatten", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.preprocess_norb.process_data": [[29, 46], ["numpy.array", "numpy.array", "numpy.expand_dims", "sklearn.preprocessing.OneHotEncoder", "sklearn.preprocessing.OneHotEncoder.fit_transform().todense", "np.array.append", "enc.fit_transform().todense.append", "preprocess_norb.process_image", "sklearn.preprocessing.OneHotEncoder.fit_transform"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.preprocess_norb.process_image"], ["def", "process_data", "(", "data", ")", ":", "\n", "    ", "X", "=", "[", "]", "\n", "Y", "=", "[", "]", "\n", "\n", "for", "ex", "in", "data", ":", "\n", "        ", "this_image", "=", "ex", ".", "image_lt", "\n", "this_category", "=", "ex", ".", "category", "\n", "X", ".", "append", "(", "process_image", "(", "this_image", ")", ")", "\n", "Y", ".", "append", "(", "this_category", ")", "\n", "\n", "", "X", "=", "np", ".", "array", "(", "X", ")", "\n", "Y", "=", "np", ".", "array", "(", "Y", ")", "\n", "Y", "=", "np", ".", "expand_dims", "(", "Y", ",", "1", ")", "\n", "enc", "=", "OneHotEncoder", "(", "N_CATEGORIES", ")", "\n", "Y", "=", "enc", ".", "fit_transform", "(", "Y", ")", ".", "todense", "(", ")", "\n", "\n", "return", "X", ",", "Y", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.preprocess_norb.process_images": [[47, 83], ["print", "norb.NORBDataset", "print", "numpy.vstack", "numpy.vstack", "numpy.arange", "numpy.random.shuffle", "pickle.dump", "norb.NORBDataset.data.keys", "preprocess_norb.process_data", "print", "Xs.append", "Ys.append", "data_utils.normalize_data", "print", "data_utils.apply_normalization", "open"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.preprocess_norb.process_data", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.data_utils.normalize_data", "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.data_utils.apply_normalization"], ["", "def", "process_images", "(", "names", ",", "out_loc", ",", "mean", "=", "None", ",", "sd", "=", "None", ")", ":", "\n", "    ", "print", "(", "'Names: '", ",", "names", ")", "\n", "dataset", "=", "NORBDataset", "(", "dataset_root", "=", "'/dfs/scratch1/thomasat/datasets/norb'", ",", "names", "=", "names", ")", "\n", "\n", "Xs", "=", "[", "]", "\n", "Ys", "=", "[", "]", "\n", "\n", "print", "(", "'Dataset names: '", ",", "dataset", ".", "data", ".", "keys", "(", ")", ")", "\n", "\n", "for", "name", "in", "names", ":", "\n", "        ", "X", ",", "Y", "=", "process_data", "(", "dataset", ".", "data", "[", "name", "]", ")", "\n", "print", "(", "'X,Y shape: '", ",", "X", ".", "shape", ",", "Y", ".", "shape", ")", "\n", "Xs", ".", "append", "(", "X", ")", "\n", "Ys", ".", "append", "(", "Y", ")", "\n", "\n", "", "X", "=", "np", ".", "vstack", "(", "Xs", ")", "\n", "Y", "=", "np", ".", "vstack", "(", "Ys", ")", "\n", "\n", "# Shuffle", "\n", "idx", "=", "np", ".", "arange", "(", "0", ",", "X", ".", "shape", "[", "0", "]", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "idx", ")", "\n", "X", "=", "X", "[", "idx", ",", ":", "]", "\n", "Y", "=", "Y", "[", "idx", ",", ":", "]", "\n", "\n", "if", "mean", "is", "None", "and", "sd", "is", "None", ":", "\n", "        ", "X", ",", "mean", ",", "sd", "=", "normalize_data", "(", "X", ")", "\n", "print", "(", "'X, Y: '", ",", "X", ".", "shape", ",", "Y", ".", "shape", ")", "\n", "", "else", ":", "\n", "        ", "X", "=", "apply_normalization", "(", "X", ",", "mean", ",", "sd", ")", "\n", "\n", "# Save", "\n", "", "data_dict", "=", "{", "'X'", ":", "X", ",", "'Y'", ":", "Y", "}", "\n", "\n", "pkl", ".", "dump", "(", "data_dict", ",", "open", "(", "out_loc", ",", "'wb'", ")", ",", "protocol", "=", "2", ")", "\n", "\n", "return", "mean", ",", "sd", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.preprocess_cifar10.convert_grayscale": [[12, 23], ["int", "print", "data[].reshape", "data[].reshape", "data[].reshape", "numpy.stack", "numpy.mean", "np.mean.reshape"], "function", ["None"], ["def", "convert_grayscale", "(", "data", ",", "img_size", "=", "32", ")", ":", "\n", "    ", "n", "=", "data", ".", "shape", "[", "0", "]", "\n", "channel_size", "=", "int", "(", "data", ".", "shape", "[", "1", "]", "/", "3", ")", "\n", "print", "(", "'channel_size:'", ",", "channel_size", ")", "\n", "im_r", "=", "data", "[", ":", ",", "0", ":", "channel_size", "]", ".", "reshape", "(", "(", "n", ",", "img_size", ",", "img_size", ")", ")", "\n", "im_g", "=", "data", "[", ":", ",", "channel_size", ":", "2", "*", "channel_size", "]", ".", "reshape", "(", "(", "n", ",", "img_size", ",", "img_size", ")", ")", "\n", "im_b", "=", "data", "[", ":", ",", "2", "*", "channel_size", ":", "]", ".", "reshape", "(", "(", "n", ",", "img_size", ",", "img_size", ")", ")", "\n", "img", "=", "np", ".", "stack", "(", "(", "im_r", ",", "im_g", ",", "im_b", ")", ",", "axis", "=", "-", "1", ")", "\n", "avg_img", "=", "np", ".", "mean", "(", "img", ",", "axis", "=", "-", "1", ")", "\n", "data", "=", "avg_img", ".", "reshape", "(", "(", "n", ",", "img_size", "*", "img_size", ")", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.preprocess_cifar10.load_data": [[25, 37], ["pickle.load", "numpy.array", "numpy.expand_dims", "enc.fit_transform().todense", "print", "open", "print", "preprocess_cifar10.convert_grayscale", "enc.fit_transform"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.data.preprocess_cifar10.convert_grayscale"], ["", "def", "load_data", "(", "loc", ")", ":", "\n", "    ", "data_dict", "=", "pkl", ".", "load", "(", "open", "(", "loc", ",", "'rb'", ")", ",", "encoding", "=", "'latin1'", ")", "\n", "X", "=", "data_dict", "[", "'data'", "]", "\n", "if", "grayscale", ":", "\n", "        ", "print", "(", "'Converting to grayscale'", ")", "\n", "X", "=", "convert_grayscale", "(", "X", ")", "\n", "", "Y", "=", "np", ".", "array", "(", "data_dict", "[", "'labels'", "]", ")", "\n", "Y", "=", "np", ".", "expand_dims", "(", "Y", ",", "1", ")", "\n", "Y", "=", "enc", ".", "fit_transform", "(", "Y", ")", ".", "todense", "(", ")", "\n", "\n", "print", "(", "'X.shape, Y.shape: '", ",", "X", ".", "shape", ",", "Y", ".", "shape", ")", "\n", "return", "X", ",", "Y", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.misc.projections.kth_diag_indices": [[7, 15], ["numpy.diag_indices_from"], "function", ["None"], ["def", "kth_diag_indices", "(", "A", ",", "k", ")", ":", "\n", "    ", "rows", ",", "cols", "=", "np", ".", "diag_indices_from", "(", "A", ")", "\n", "if", "k", "<", "0", ":", "\n", "        ", "return", "rows", "[", "-", "k", ":", "]", ",", "cols", "[", ":", "k", "]", "\n", "", "elif", "k", ">", "0", ":", "\n", "        ", "return", "rows", "[", ":", "-", "k", "]", ",", "cols", "[", "k", ":", "]", "\n", "", "else", ":", "\n", "        ", "return", "rows", ",", "cols", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.misc.projections.toeplitz_project_frob": [[17, 30], ["numpy.zeros", "numpy.arange", "projections.kth_diag_indices", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.misc.projections.kth_diag_indices"], ["", "", "def", "toeplitz_project_frob", "(", "A", ")", ":", "\n", "\t", "assert", "A", ".", "shape", "[", "0", "]", "==", "A", ".", "shape", "[", "1", "]", "\n", "\n", "A_proj", "=", "np", ".", "zeros", "(", "A", ".", "shape", ")", "\n", "\n", "# Get indices of each diagonal", "\n", "for", "diag_idx", "in", "np", ".", "arange", "(", "-", "(", "A", ".", "shape", "[", "0", "]", "-", "1", ")", ",", "A", ".", "shape", "[", "0", "]", ")", ":", "\n", "\t\t", "this_idx", "=", "kth_diag_indices", "(", "A", ",", "diag_idx", ")", "\n", "# Get average", "\n", "avg", "=", "np", ".", "mean", "(", "A", "[", "this_idx", "]", ")", "\n", "A_proj", "[", "this_idx", "]", "=", "avg", "\n", "\n", "", "return", "A_proj", "\n", "\n"]], "home.repos.pwc.inspect_result.HazyResearch_structured-nets.misc.projections.hankel_project_frob": [[32, 38], ["numpy.flipud", "projections.toeplitz_project_frob", "numpy.flipud"], "function", ["home.repos.pwc.inspect_result.HazyResearch_structured-nets.misc.projections.toeplitz_project_frob"], ["", "def", "hankel_project_frob", "(", "A", ")", ":", "\n", "\t", "A_flip", "=", "np", ".", "flipud", "(", "A", ")", "\n", "\n", "A_flip_proj", "=", "toeplitz_project_frob", "(", "A_flip", ")", "\n", "\n", "return", "np", ".", "flipud", "(", "A_flip_proj", ")", "\n", "\n"]]}