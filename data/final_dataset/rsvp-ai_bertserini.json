{"home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_new.get_best_answer": [[8, 12], ["ans.aggregate_score", "sorted"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.base.Answer.aggregate_score"], ["def", "get_best_answer", "(", "candidates", ",", "weight", "=", "0.5", ")", ":", "\n", "    ", "for", "ans", "in", "candidates", ":", "\n", "        ", "ans", ".", "aggregate_score", "(", "weight", ")", "\n", "", "return", "sorted", "(", "candidates", ",", "key", "=", "lambda", "x", ":", "x", ".", "total_score", ",", "reverse", "=", "True", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_new.extract_squad_questions": [[14, 29], ["json.load", "open", "questions.append", "bertserini.utils.utils.strip_accents", "hanziconv.HanziConv.toSimplified", "bertserini.reader.base.Question"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.strip_accents"], ["", "def", "extract_squad_questions", "(", "squad_filename", ",", "do_strip_accents", "=", "False", ",", "language", "=", "\"en\"", ")", ":", "\n", "    ", "data", "=", "json", ".", "load", "(", "open", "(", "squad_filename", ",", "'r'", ")", ")", "\n", "data", "=", "data", "[", "\"data\"", "]", "\n", "questions", "=", "[", "]", "\n", "for", "article", "in", "data", ":", "\n", "        ", "for", "paragraph", "in", "article", "[", "\"paragraphs\"", "]", ":", "\n", "            ", "for", "qa", "in", "paragraph", "[", "\"qas\"", "]", ":", "\n", "                ", "id_", "=", "qa", "[", "\"id\"", "]", "\n", "question", "=", "qa", "[", "\"question\"", "]", "\n", "if", "do_strip_accents", ":", "\n", "                    ", "question", "=", "strip_accents", "(", "question", ")", "\n", "", "if", "language", "==", "\"zh\"", ":", "\n", "                    ", "HanziConv", ".", "toSimplified", "(", "question", ")", "\n", "", "questions", ".", "append", "(", "Question", "(", "question", ",", "id_", ",", "language", ")", ")", "\n", "", "", "", "return", "questions", "", "", ""]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.normalize_answer": [[36, 54], ["utils_squad_metrics.normalize_answer.white_space_fix"], "function", ["None"], ["def", "normalize_answer", "(", "s", ")", ":", "\n", "    ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "regex", "=", "re", ".", "compile", "(", "r\"\\b(a|an|the)\\b\"", ",", "re", ".", "UNICODE", ")", "\n", "return", "re", ".", "sub", "(", "regex", ",", "\" \"", ",", "text", ")", "\n", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "\" \"", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "\"\"", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.get_tokens": [[56, 60], ["normalize_answer().split", "utils_squad_metrics.normalize_answer"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.normalize_answer"], ["", "def", "get_tokens", "(", "s", ")", ":", "\n", "    ", "if", "not", "s", ":", "\n", "        ", "return", "[", "]", "\n", "", "return", "normalize_answer", "(", "s", ")", ".", "split", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.compute_exact": [[62, 64], ["int", "utils_squad_metrics.normalize_answer", "utils_squad_metrics.normalize_answer"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.normalize_answer", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.normalize_answer"], ["", "def", "compute_exact", "(", "a_gold", ",", "a_pred", ")", ":", "\n", "    ", "return", "int", "(", "normalize_answer", "(", "a_gold", ")", "==", "normalize_answer", "(", "a_pred", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.compute_f1": [[66, 80], ["utils_squad_metrics.get_tokens", "utils_squad_metrics.get_tokens", "sum", "collections.Counter", "collections.Counter", "common.values", "int", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.get_tokens", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.get_tokens"], ["", "def", "compute_f1", "(", "a_gold", ",", "a_pred", ")", ":", "\n", "    ", "gold_toks", "=", "get_tokens", "(", "a_gold", ")", "\n", "pred_toks", "=", "get_tokens", "(", "a_pred", ")", "\n", "common", "=", "collections", ".", "Counter", "(", "gold_toks", ")", "&", "collections", ".", "Counter", "(", "pred_toks", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "len", "(", "gold_toks", ")", "==", "0", "or", "len", "(", "pred_toks", ")", "==", "0", ":", "\n", "# If either is no-answer, then F1 is 1 if they agree, 0 otherwise", "\n", "        ", "return", "int", "(", "gold_toks", "==", "pred_toks", ")", "\n", "", "if", "num_same", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "pred_toks", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "gold_toks", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.get_raw_scores": [[82, 106], ["max", "max", "print", "utils_squad_metrics.normalize_answer", "utils_squad_metrics.compute_exact", "utils_squad_metrics.compute_f1"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.normalize_answer", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.compute_exact", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.compute_f1"], ["", "def", "get_raw_scores", "(", "examples", ",", "preds", ")", ":", "\n", "    ", "\"\"\"\n    Computes the exact and f1 scores from the examples and the model predictions\n    \"\"\"", "\n", "exact_scores", "=", "{", "}", "\n", "f1_scores", "=", "{", "}", "\n", "\n", "for", "example", "in", "examples", ":", "\n", "        ", "qas_id", "=", "example", ".", "qas_id", "\n", "gold_answers", "=", "[", "answer", "[", "\"text\"", "]", "for", "answer", "in", "example", ".", "answers", "if", "normalize_answer", "(", "answer", "[", "\"text\"", "]", ")", "]", "\n", "\n", "if", "not", "gold_answers", ":", "\n", "# For unanswerable questions, only correct answer is empty string", "\n", "            ", "gold_answers", "=", "[", "\"\"", "]", "\n", "\n", "", "if", "qas_id", "not", "in", "preds", ":", "\n", "            ", "print", "(", "f\"Missing prediction for {qas_id}\"", ")", "\n", "continue", "\n", "\n", "", "prediction", "=", "preds", "[", "qas_id", "]", "\n", "exact_scores", "[", "qas_id", "]", "=", "max", "(", "compute_exact", "(", "a", ",", "prediction", ")", "for", "a", "in", "gold_answers", ")", "\n", "f1_scores", "[", "qas_id", "]", "=", "max", "(", "compute_f1", "(", "a", ",", "prediction", ")", "for", "a", "in", "gold_answers", ")", "\n", "\n", "", "return", "exact_scores", ",", "f1_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.apply_no_ans_threshold": [[108, 117], ["scores.items", "float"], "function", ["None"], ["", "def", "apply_no_ans_threshold", "(", "scores", ",", "na_probs", ",", "qid_to_has_ans", ",", "na_prob_thresh", ")", ":", "\n", "    ", "new_scores", "=", "{", "}", "\n", "for", "qid", ",", "s", "in", "scores", ".", "items", "(", ")", ":", "\n", "        ", "pred_na", "=", "na_probs", "[", "qid", "]", ">", "na_prob_thresh", "\n", "if", "pred_na", ":", "\n", "            ", "new_scores", "[", "qid", "]", "=", "float", "(", "not", "qid_to_has_ans", "[", "qid", "]", ")", "\n", "", "else", ":", "\n", "            ", "new_scores", "[", "qid", "]", "=", "s", "\n", "", "", "return", "new_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.make_eval_dict": [[119, 136], ["len", "collections.OrderedDict", "len", "collections.OrderedDict", "sum", "sum", "sum", "sum", "exact_scores.values", "f1_scores.values"], "function", ["None"], ["", "def", "make_eval_dict", "(", "exact_scores", ",", "f1_scores", ",", "qid_list", "=", "None", ")", ":", "\n", "    ", "if", "not", "qid_list", ":", "\n", "        ", "total", "=", "len", "(", "exact_scores", ")", "\n", "return", "collections", ".", "OrderedDict", "(", "\n", "[", "\n", "(", "\"exact\"", ",", "100.0", "*", "sum", "(", "exact_scores", ".", "values", "(", ")", ")", "/", "total", ")", ",", "\n", "(", "\"f1\"", ",", "100.0", "*", "sum", "(", "f1_scores", ".", "values", "(", ")", ")", "/", "total", ")", ",", "\n", "(", "\"total\"", ",", "total", ")", ",", "\n", "]", "\n", ")", "\n", "", "else", ":", "\n", "        ", "total", "=", "len", "(", "qid_list", ")", "\n", "return", "collections", ".", "OrderedDict", "(", "\n", "[", "\n", "(", "\"exact\"", ",", "100.0", "*", "sum", "(", "exact_scores", "[", "k", "]", "for", "k", "in", "qid_list", ")", "/", "total", ")", ",", "\n", "(", "\"f1\"", ",", "100.0", "*", "sum", "(", "f1_scores", "[", "k", "]", "for", "k", "in", "qid_list", ")", "/", "total", ")", ",", "\n", "(", "\"total\"", ",", "total", ")", ",", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.merge_eval": [[140, 143], ["None"], "function", ["None"], ["", "", "def", "merge_eval", "(", "main_eval", ",", "new_eval", ",", "prefix", ")", ":", "\n", "    ", "for", "k", "in", "new_eval", ":", "\n", "        ", "main_eval", "[", "f\"{prefix}_{k}\"", "]", "=", "new_eval", "[", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.find_best_thresh_v2": [[145, 177], ["sum", "sorted", "enumerate", "len"], "function", ["None"], ["", "", "def", "find_best_thresh_v2", "(", "preds", ",", "scores", ",", "na_probs", ",", "qid_to_has_ans", ")", ":", "\n", "    ", "num_no_ans", "=", "sum", "(", "1", "for", "k", "in", "qid_to_has_ans", "if", "not", "qid_to_has_ans", "[", "k", "]", ")", "\n", "cur_score", "=", "num_no_ans", "\n", "best_score", "=", "cur_score", "\n", "best_thresh", "=", "0.0", "\n", "qid_list", "=", "sorted", "(", "na_probs", ",", "key", "=", "lambda", "k", ":", "na_probs", "[", "k", "]", ")", "\n", "for", "i", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n", "        ", "if", "qid", "not", "in", "scores", ":", "\n", "            ", "continue", "\n", "", "if", "qid_to_has_ans", "[", "qid", "]", ":", "\n", "            ", "diff", "=", "scores", "[", "qid", "]", "\n", "", "else", ":", "\n", "            ", "if", "preds", "[", "qid", "]", ":", "\n", "                ", "diff", "=", "-", "1", "\n", "", "else", ":", "\n", "                ", "diff", "=", "0", "\n", "", "", "cur_score", "+=", "diff", "\n", "if", "cur_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "cur_score", "\n", "best_thresh", "=", "na_probs", "[", "qid", "]", "\n", "\n", "", "", "has_ans_score", ",", "has_ans_cnt", "=", "0", ",", "0", "\n", "for", "qid", "in", "qid_list", ":", "\n", "        ", "if", "not", "qid_to_has_ans", "[", "qid", "]", ":", "\n", "            ", "continue", "\n", "", "has_ans_cnt", "+=", "1", "\n", "\n", "if", "qid", "not", "in", "scores", ":", "\n", "            ", "continue", "\n", "", "has_ans_score", "+=", "scores", "[", "qid", "]", "\n", "\n", "", "return", "100.0", "*", "best_score", "/", "len", "(", "scores", ")", ",", "best_thresh", ",", "1.0", "*", "has_ans_score", "/", "has_ans_cnt", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.find_all_best_thresh_v2": [[179, 188], ["utils_squad_metrics.find_best_thresh_v2", "utils_squad_metrics.find_best_thresh_v2"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.find_best_thresh_v2", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.find_best_thresh_v2"], ["", "def", "find_all_best_thresh_v2", "(", "main_eval", ",", "preds", ",", "exact_raw", ",", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", ":", "\n", "    ", "best_exact", ",", "exact_thresh", ",", "has_ans_exact", "=", "find_best_thresh_v2", "(", "preds", ",", "exact_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", "\n", "best_f1", ",", "f1_thresh", ",", "has_ans_f1", "=", "find_best_thresh_v2", "(", "preds", ",", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", "\n", "main_eval", "[", "\"best_exact\"", "]", "=", "best_exact", "\n", "main_eval", "[", "\"best_exact_thresh\"", "]", "=", "exact_thresh", "\n", "main_eval", "[", "\"best_f1\"", "]", "=", "best_f1", "\n", "main_eval", "[", "\"best_f1_thresh\"", "]", "=", "f1_thresh", "\n", "main_eval", "[", "\"has_ans_exact\"", "]", "=", "has_ans_exact", "\n", "main_eval", "[", "\"has_ans_f1\"", "]", "=", "has_ans_f1", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.find_best_thresh": [[190, 211], ["sum", "sorted", "enumerate", "len"], "function", ["None"], ["", "def", "find_best_thresh", "(", "preds", ",", "scores", ",", "na_probs", ",", "qid_to_has_ans", ")", ":", "\n", "    ", "num_no_ans", "=", "sum", "(", "1", "for", "k", "in", "qid_to_has_ans", "if", "not", "qid_to_has_ans", "[", "k", "]", ")", "\n", "cur_score", "=", "num_no_ans", "\n", "best_score", "=", "cur_score", "\n", "best_thresh", "=", "0.0", "\n", "qid_list", "=", "sorted", "(", "na_probs", ",", "key", "=", "lambda", "k", ":", "na_probs", "[", "k", "]", ")", "\n", "for", "_", ",", "qid", "in", "enumerate", "(", "qid_list", ")", ":", "\n", "        ", "if", "qid", "not", "in", "scores", ":", "\n", "            ", "continue", "\n", "", "if", "qid_to_has_ans", "[", "qid", "]", ":", "\n", "            ", "diff", "=", "scores", "[", "qid", "]", "\n", "", "else", ":", "\n", "            ", "if", "preds", "[", "qid", "]", ":", "\n", "                ", "diff", "=", "-", "1", "\n", "", "else", ":", "\n", "                ", "diff", "=", "0", "\n", "", "", "cur_score", "+=", "diff", "\n", "if", "cur_score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "cur_score", "\n", "best_thresh", "=", "na_probs", "[", "qid", "]", "\n", "", "", "return", "100.0", "*", "best_score", "/", "len", "(", "scores", ")", ",", "best_thresh", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.find_all_best_thresh": [[213, 221], ["utils_squad_metrics.find_best_thresh", "utils_squad_metrics.find_best_thresh"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.find_best_thresh", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.find_best_thresh"], ["", "def", "find_all_best_thresh", "(", "main_eval", ",", "preds", ",", "exact_raw", ",", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", ":", "\n", "    ", "best_exact", ",", "exact_thresh", "=", "find_best_thresh", "(", "preds", ",", "exact_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", "\n", "best_f1", ",", "f1_thresh", "=", "find_best_thresh", "(", "preds", ",", "f1_raw", ",", "na_probs", ",", "qid_to_has_ans", ")", "\n", "\n", "main_eval", "[", "\"best_exact\"", "]", "=", "best_exact", "\n", "main_eval", "[", "\"best_exact_thresh\"", "]", "=", "exact_thresh", "\n", "main_eval", "[", "\"best_f1\"", "]", "=", "best_f1", "\n", "main_eval", "[", "\"best_f1_thresh\"", "]", "=", "f1_thresh", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.squad_evaluate": [[223, 252], ["utils_squad_metrics.get_raw_scores", "utils_squad_metrics.apply_no_ans_threshold", "utils_squad_metrics.apply_no_ans_threshold", "utils_squad_metrics.make_eval_dict", "bool", "utils_squad_metrics.make_eval_dict", "utils_squad_metrics.merge_eval", "utils_squad_metrics.make_eval_dict", "utils_squad_metrics.merge_eval", "utils_squad_metrics.find_all_best_thresh", "qas_id_to_has_answer.items", "qas_id_to_has_answer.items"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.get_raw_scores", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.apply_no_ans_threshold", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.apply_no_ans_threshold", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.make_eval_dict", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.make_eval_dict", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.merge_eval", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.make_eval_dict", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.merge_eval", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.find_all_best_thresh"], ["", "def", "squad_evaluate", "(", "examples", ",", "preds", ",", "no_answer_probs", "=", "None", ",", "no_answer_probability_threshold", "=", "1.0", ")", ":", "\n", "    ", "qas_id_to_has_answer", "=", "{", "example", ".", "qas_id", ":", "bool", "(", "example", ".", "answers", ")", "for", "example", "in", "examples", "}", "\n", "has_answer_qids", "=", "[", "qas_id", "for", "qas_id", ",", "has_answer", "in", "qas_id_to_has_answer", ".", "items", "(", ")", "if", "has_answer", "]", "\n", "no_answer_qids", "=", "[", "qas_id", "for", "qas_id", ",", "has_answer", "in", "qas_id_to_has_answer", ".", "items", "(", ")", "if", "not", "has_answer", "]", "\n", "\n", "if", "no_answer_probs", "is", "None", ":", "\n", "        ", "no_answer_probs", "=", "{", "k", ":", "0.0", "for", "k", "in", "preds", "}", "\n", "\n", "", "exact", ",", "f1", "=", "get_raw_scores", "(", "examples", ",", "preds", ")", "\n", "\n", "exact_threshold", "=", "apply_no_ans_threshold", "(", "\n", "exact", ",", "no_answer_probs", ",", "qas_id_to_has_answer", ",", "no_answer_probability_threshold", "\n", ")", "\n", "f1_threshold", "=", "apply_no_ans_threshold", "(", "f1", ",", "no_answer_probs", ",", "qas_id_to_has_answer", ",", "no_answer_probability_threshold", ")", "\n", "\n", "evaluation", "=", "make_eval_dict", "(", "exact_threshold", ",", "f1_threshold", ")", "\n", "\n", "if", "has_answer_qids", ":", "\n", "        ", "has_ans_eval", "=", "make_eval_dict", "(", "exact_threshold", ",", "f1_threshold", ",", "qid_list", "=", "has_answer_qids", ")", "\n", "merge_eval", "(", "evaluation", ",", "has_ans_eval", ",", "\"HasAns\"", ")", "\n", "\n", "", "if", "no_answer_qids", ":", "\n", "        ", "no_ans_eval", "=", "make_eval_dict", "(", "exact_threshold", ",", "f1_threshold", ",", "qid_list", "=", "no_answer_qids", ")", "\n", "merge_eval", "(", "evaluation", ",", "no_ans_eval", ",", "\"NoAns\"", ")", "\n", "\n", "", "if", "no_answer_probs", ":", "\n", "        ", "find_all_best_thresh", "(", "evaluation", ",", "preds", ",", "exact", ",", "f1", ",", "no_answer_probs", ",", "qas_id_to_has_answer", ")", "\n", "\n", "", "return", "evaluation", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.get_final_text": [[254, 349], ["transformers.AutoTokenizer.from_pretrained", "tok_text.find", "utils_squad_metrics.get_final_text._strip_spaces"], "function", ["None"], ["", "def", "get_final_text", "(", "pred_text", ",", "orig_text", ",", "do_lower_case", ",", "verbose_logging", "=", "False", ",", "language", "=", "\"en\"", ",", "tokenizer_name", "=", "\"rsvp-ai/bertserini-bert-base-squad\"", ")", ":", "\n", "    ", "\"\"\"Project the tokenized prediction back to the original text.\"\"\"", "\n", "\n", "# When we created the data, we kept track of the alignment between original", "\n", "# (whitespace tokenized) tokens and our WordPiece tokenized tokens. So", "\n", "# now `orig_text` contains the span of our original text corresponding to the", "\n", "# span that we predicted.", "\n", "#", "\n", "# However, `orig_text` may contain extra characters that we don't want in", "\n", "# our prediction.", "\n", "#", "\n", "# For example, let's say:", "\n", "#   pred_text = steve smith", "\n", "#   orig_text = Steve Smith's", "\n", "#", "\n", "# We don't want to return `orig_text` because it contains the extra \"'s\".", "\n", "#", "\n", "# We don't want to return `pred_text` because it's already been normalized", "\n", "# (the SQuAD eval script also does punctuation stripping/lower casing but", "\n", "# our tokenizer does additional normalization like stripping accent", "\n", "# characters).", "\n", "#", "\n", "# What we really want to return is \"Steve Smith\".", "\n", "#", "\n", "# Therefore, we have to apply a semi-complicated alignment heuristic between", "\n", "# `pred_text` and `orig_text` to get a character-to-character alignment. This", "\n", "# can fail in certain cases in which case we just return `orig_text`.", "\n", "\n", "def", "_strip_spaces", "(", "text", ")", ":", "\n", "        ", "ns_chars", "=", "[", "]", "\n", "ns_to_s_map", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "(", "i", ",", "c", ")", "in", "enumerate", "(", "text", ")", ":", "\n", "            ", "if", "c", "==", "\" \"", ":", "\n", "                ", "continue", "\n", "", "ns_to_s_map", "[", "len", "(", "ns_chars", ")", "]", "=", "i", "\n", "ns_chars", ".", "append", "(", "c", ")", "\n", "", "ns_text", "=", "\"\"", ".", "join", "(", "ns_chars", ")", "\n", "return", "(", "ns_text", ",", "ns_to_s_map", ")", "\n", "\n", "# We first tokenize `orig_text`, strip whitespace from the result", "\n", "# and `pred_text`, and check if they are the same length. If they are", "\n", "# NOT the same length, the heuristic has failed. If they are the same", "\n", "# length, we assume the characters are one-to-one aligned.", "\n", "\n", "", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "tokenizer_name", ",", "use_fast", "=", "False", ")", "\n", "if", "language", "==", "\"zh\"", ":", "\n", "        ", "tok_text", "=", "\"\"", ".", "join", "(", "tokenizer", ".", "tokenize", "(", "orig_text", ")", ")", "\n", "", "else", ":", "\n", "        ", "tok_text", "=", "\" \"", ".", "join", "(", "tokenizer", ".", "tokenize", "(", "orig_text", ")", ")", "\n", "\n", "", "start_position", "=", "tok_text", ".", "find", "(", "pred_text", ")", "\n", "if", "start_position", "==", "-", "1", ":", "\n", "        ", "if", "verbose_logging", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Unable to find text: '{pred_text}' in '{orig_text}'\"", ")", "\n", "", "return", "orig_text", "\n", "", "end_position", "=", "start_position", "+", "len", "(", "pred_text", ")", "-", "1", "\n", "\n", "(", "orig_ns_text", ",", "orig_ns_to_s_map", ")", "=", "_strip_spaces", "(", "orig_text", ")", "\n", "(", "tok_ns_text", ",", "tok_ns_to_s_map", ")", "=", "_strip_spaces", "(", "tok_text", ")", "\n", "\n", "if", "len", "(", "orig_ns_text", ")", "!=", "len", "(", "tok_ns_text", ")", ":", "\n", "        ", "if", "verbose_logging", ":", "\n", "            ", "logger", ".", "info", "(", "f\"Length not equal after stripping spaces: '{orig_ns_text}' vs '{tok_ns_text}'\"", ")", "\n", "", "return", "orig_text", "\n", "\n", "# We then project the characters in `pred_text` back to `orig_text` using", "\n", "# the character-to-character alignment.", "\n", "", "tok_s_to_ns_map", "=", "{", "}", "\n", "for", "(", "i", ",", "tok_index", ")", "in", "tok_ns_to_s_map", ".", "items", "(", ")", ":", "\n", "        ", "tok_s_to_ns_map", "[", "tok_index", "]", "=", "i", "\n", "\n", "", "orig_start_position", "=", "None", "\n", "if", "start_position", "in", "tok_s_to_ns_map", ":", "\n", "        ", "ns_start_position", "=", "tok_s_to_ns_map", "[", "start_position", "]", "\n", "if", "ns_start_position", "in", "orig_ns_to_s_map", ":", "\n", "            ", "orig_start_position", "=", "orig_ns_to_s_map", "[", "ns_start_position", "]", "\n", "\n", "", "", "if", "orig_start_position", "is", "None", ":", "\n", "        ", "if", "verbose_logging", ":", "\n", "            ", "logger", ".", "info", "(", "\"Couldn't map start position\"", ")", "\n", "", "return", "orig_text", "\n", "\n", "", "orig_end_position", "=", "None", "\n", "if", "end_position", "in", "tok_s_to_ns_map", ":", "\n", "        ", "ns_end_position", "=", "tok_s_to_ns_map", "[", "end_position", "]", "\n", "if", "ns_end_position", "in", "orig_ns_to_s_map", ":", "\n", "            ", "orig_end_position", "=", "orig_ns_to_s_map", "[", "ns_end_position", "]", "\n", "\n", "", "", "if", "orig_end_position", "is", "None", ":", "\n", "        ", "if", "verbose_logging", ":", "\n", "            ", "logger", ".", "info", "(", "\"Couldn't map end position\"", ")", "\n", "", "return", "orig_text", "\n", "\n", "", "output_text", "=", "orig_text", "[", "orig_start_position", ":", "(", "orig_end_position", "+", "1", ")", "]", "\n", "return", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics._get_best_indexes": [[351, 361], ["sorted", "range", "enumerate", "len", "best_indexes.append"], "function", ["None"], ["", "def", "_get_best_indexes", "(", "logits", ",", "n_best_size", ")", ":", "\n", "    ", "\"\"\"Get the n-best logits from a list.\"\"\"", "\n", "index_and_score", "=", "sorted", "(", "enumerate", "(", "logits", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "best_indexes", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "index_and_score", ")", ")", ":", "\n", "        ", "if", "i", ">=", "n_best_size", ":", "\n", "            ", "break", "\n", "", "best_indexes", ".", "append", "(", "index_and_score", "[", "i", "]", "[", "0", "]", ")", "\n", "", "return", "best_indexes", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics._compute_softmax": [[363, 384], ["math.exp", "exp_scores.append", "probs.append"], "function", ["None"], ["", "def", "_compute_softmax", "(", "scores", ")", ":", "\n", "    ", "\"\"\"Compute softmax probability over raw logits.\"\"\"", "\n", "if", "not", "scores", ":", "\n", "        ", "return", "[", "]", "\n", "\n", "", "max_score", "=", "None", "\n", "for", "score", "in", "scores", ":", "\n", "        ", "if", "max_score", "is", "None", "or", "score", ">", "max_score", ":", "\n", "            ", "max_score", "=", "score", "\n", "\n", "", "", "exp_scores", "=", "[", "]", "\n", "total_sum", "=", "0.0", "\n", "for", "score", "in", "scores", ":", "\n", "        ", "x", "=", "math", ".", "exp", "(", "score", "-", "max_score", ")", "\n", "exp_scores", ".", "append", "(", "x", ")", "\n", "total_sum", "+=", "x", "\n", "\n", "", "probs", "=", "[", "]", "\n", "for", "score", "in", "exp_scores", ":", "\n", "        ", "probs", ".", "append", "(", "score", "/", "total_sum", ")", "\n", "", "return", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.compute_predictions_logits": [[386, 605], ["collections.defaultdict", "collections.namedtuple", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "enumerate", "logger.info", "logger.info", "logger.info", "example_index_to_features[].append", "enumerate", "sorted", "collections.namedtuple", "enumerate", "utils_squad_metrics._get_best_indexes", "utils_squad_metrics._get_best_indexes", "sorted.append", "nbest.append", "nbest.append", "len", "total_scores.append", "collections.OrderedDict", "nbest_json.append", "len", "open", "writer.write", "open", "writer.write", "open", "writer.write", "collections.namedtuple.", "len", "tokenizer.convert_tokens_to_string", "tok_text.strip.strip", "utils_squad_metrics.get_final_text", "collections.namedtuple.", "nbest.append", "len", "nbest.insert", "collections.namedtuple.", "output[].item", "output[].item", "sorted.append", "print", "collections.namedtuple.", "collections.namedtuple.", "json.dumps", "json.dumps", "json.dumps", "len", "len", "feature.token_is_max_context.get", "collections.namedtuple.", "tok_text.strip.split", "tok_text.strip.split"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics._get_best_indexes", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics._get_best_indexes", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.get_final_text"], ["", "def", "compute_predictions_logits", "(", "\n", "all_examples", ",", "\n", "all_features", ",", "\n", "all_results", ",", "\n", "n_best_size", ",", "\n", "max_answer_length", ",", "\n", "do_lower_case", ",", "\n", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "\n", "output_null_log_odds_file", ",", "\n", "verbose_logging", ",", "\n", "version_2_with_negative", ",", "\n", "null_score_diff_threshold", ",", "\n", "tokenizer", ",", "\n", "language", "=", "\"en\"", ",", "\n", ")", ":", "\n", "    ", "\"\"\"Write final predictions to the json file and log-odds of null if needed.\"\"\"", "\n", "if", "output_prediction_file", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Writing predictions to: {output_prediction_file}\"", ")", "\n", "", "if", "output_nbest_file", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Writing nbest to: {output_nbest_file}\"", ")", "\n", "", "if", "output_null_log_odds_file", "and", "version_2_with_negative", ":", "\n", "        ", "logger", ".", "info", "(", "f\"Writing null_log_odds to: {output_null_log_odds_file}\"", ")", "\n", "\n", "", "example_index_to_features", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "feature", "in", "all_features", ":", "\n", "        ", "example_index_to_features", "[", "feature", ".", "example_index", "]", ".", "append", "(", "feature", ")", "\n", "\n", "", "unique_id_to_result", "=", "{", "}", "\n", "for", "result", "in", "all_results", ":", "\n", "        ", "unique_id_to_result", "[", "result", ".", "unique_id", "]", "=", "result", "\n", "\n", "", "_PrelimPrediction", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"PrelimPrediction\"", ",", "[", "\"feature_index\"", ",", "\"start_index\"", ",", "\"end_index\"", ",", "\"start_logit\"", ",", "\"end_logit\"", "]", "\n", ")", "\n", "\n", "all_predictions", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "all_nbest_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "scores_diff_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "\n", "for", "(", "example_index", ",", "example", ")", "in", "enumerate", "(", "all_examples", ")", ":", "\n", "        ", "features", "=", "example_index_to_features", "[", "example_index", "]", "\n", "\n", "prelim_predictions", "=", "[", "]", "\n", "# keep track of the minimum score of null start+end of position 0", "\n", "score_null", "=", "1000000", "# large and positive", "\n", "min_null_feature_index", "=", "0", "# the paragraph slice with min null score", "\n", "null_start_logit", "=", "0", "# the start logit at the slice with min null score", "\n", "null_end_logit", "=", "0", "# the end logit at the slice with min null score", "\n", "for", "(", "feature_index", ",", "feature", ")", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "result", "=", "unique_id_to_result", "[", "feature", ".", "unique_id", "]", "\n", "start_indexes", "=", "_get_best_indexes", "(", "result", ".", "start_logits", ",", "n_best_size", ")", "\n", "end_indexes", "=", "_get_best_indexes", "(", "result", ".", "end_logits", ",", "n_best_size", ")", "\n", "# if we could have irrelevant answers, get the min score of irrelevant", "\n", "if", "version_2_with_negative", ":", "\n", "                ", "feature_null_score", "=", "result", ".", "start_logits", "[", "0", "]", "+", "result", ".", "end_logits", "[", "0", "]", "\n", "if", "feature_null_score", "<", "score_null", ":", "\n", "                    ", "score_null", "=", "feature_null_score", "\n", "min_null_feature_index", "=", "feature_index", "\n", "null_start_logit", "=", "result", ".", "start_logits", "[", "0", "]", "\n", "null_end_logit", "=", "result", ".", "end_logits", "[", "0", "]", "\n", "", "", "for", "start_index", "in", "start_indexes", ":", "\n", "                ", "for", "end_index", "in", "end_indexes", ":", "\n", "# We could hypothetically create invalid predictions, e.g., predict", "\n", "# that the start of the span is in the question. We throw out all", "\n", "# invalid predictions.", "\n", "                    ", "if", "start_index", ">=", "len", "(", "feature", ".", "tokens", ")", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", ">=", "len", "(", "feature", ".", "tokens", ")", ":", "\n", "                        ", "continue", "\n", "", "if", "start_index", "not", "in", "feature", ".", "token_to_orig_map", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", "not", "in", "feature", ".", "token_to_orig_map", ":", "\n", "                        ", "continue", "\n", "", "if", "not", "feature", ".", "token_is_max_context", ".", "get", "(", "start_index", ",", "False", ")", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", "<", "start_index", ":", "\n", "                        ", "continue", "\n", "", "length", "=", "end_index", "-", "start_index", "+", "1", "\n", "if", "length", ">", "max_answer_length", ":", "\n", "                        ", "continue", "\n", "", "prelim_predictions", ".", "append", "(", "\n", "_PrelimPrediction", "(", "\n", "feature_index", "=", "feature_index", ",", "\n", "start_index", "=", "start_index", ",", "\n", "end_index", "=", "end_index", ",", "\n", "start_logit", "=", "result", ".", "start_logits", "[", "start_index", "]", ",", "\n", "end_logit", "=", "result", ".", "end_logits", "[", "end_index", "]", ",", "\n", ")", "\n", ")", "\n", "", "", "", "if", "version_2_with_negative", ":", "\n", "            ", "prelim_predictions", ".", "append", "(", "\n", "_PrelimPrediction", "(", "\n", "feature_index", "=", "min_null_feature_index", ",", "\n", "start_index", "=", "0", ",", "\n", "end_index", "=", "0", ",", "\n", "start_logit", "=", "null_start_logit", ",", "\n", "end_logit", "=", "null_end_logit", ",", "\n", ")", "\n", ")", "\n", "", "prelim_predictions", "=", "sorted", "(", "prelim_predictions", ",", "key", "=", "lambda", "x", ":", "(", "x", ".", "start_logit", "+", "x", ".", "end_logit", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "_NbestPrediction", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"NbestPrediction\"", ",", "[", "\"text\"", ",", "\"start_logit\"", ",", "\"end_logit\"", "]", "\n", ")", "\n", "\n", "seen_predictions", "=", "{", "}", "\n", "nbest", "=", "[", "]", "\n", "for", "pred", "in", "prelim_predictions", ":", "\n", "            ", "if", "len", "(", "nbest", ")", ">=", "n_best_size", ":", "\n", "                ", "break", "\n", "", "feature", "=", "features", "[", "pred", ".", "feature_index", "]", "\n", "if", "pred", ".", "start_index", ">", "0", ":", "# this is a non-null prediction", "\n", "                ", "tok_tokens", "=", "feature", ".", "tokens", "[", "pred", ".", "start_index", ":", "(", "pred", ".", "end_index", "+", "1", ")", "]", "\n", "orig_doc_start", "=", "feature", ".", "token_to_orig_map", "[", "pred", ".", "start_index", "]", "\n", "orig_doc_end", "=", "feature", ".", "token_to_orig_map", "[", "pred", ".", "end_index", "]", "\n", "orig_tokens", "=", "example", ".", "doc_tokens", "[", "orig_doc_start", ":", "(", "orig_doc_end", "+", "1", ")", "]", "\n", "\n", "tok_text", "=", "tokenizer", ".", "convert_tokens_to_string", "(", "tok_tokens", ")", "\n", "\n", "# tok_text = \" \".join(tok_tokens)", "\n", "#", "\n", "# # De-tokenize WordPieces that have been split off.", "\n", "# tok_text = tok_text.replace(\" ##\", \"\")", "\n", "# tok_text = tok_text.replace(\"##\", \"\")", "\n", "\n", "# Clean whitespace", "\n", "tok_text", "=", "tok_text", ".", "strip", "(", ")", "\n", "if", "language", "==", "\"zh\"", ":", "\n", "                    ", "tok_text", "=", "\"\"", ".", "join", "(", "tok_text", ".", "split", "(", ")", ")", "\n", "orig_text", "=", "\"\"", ".", "join", "(", "orig_tokens", ")", "\n", "", "else", ":", "\n", "                    ", "tok_text", "=", "\" \"", ".", "join", "(", "tok_text", ".", "split", "(", ")", ")", "\n", "orig_text", "=", "\" \"", ".", "join", "(", "orig_tokens", ")", "\n", "\n", "", "final_text", "=", "get_final_text", "(", "tok_text", ",", "orig_text", ",", "do_lower_case", ",", "verbose_logging", ",", "language", "=", "language", ")", "\n", "if", "\"##\"", "in", "final_text", "or", "\"[UNK]\"", "in", "final_text", ":", "\n", "                    ", "print", "(", "final_text", ",", "\"||\"", ",", "tok_text", ",", "\"||\"", ",", "orig_text", ")", "\n", "\n", "", "if", "final_text", "in", "seen_predictions", ":", "\n", "                    ", "continue", "\n", "\n", "", "seen_predictions", "[", "final_text", "]", "=", "True", "\n", "", "else", ":", "\n", "                ", "final_text", "=", "\"\"", "\n", "seen_predictions", "[", "final_text", "]", "=", "True", "\n", "\n", "", "nbest", ".", "append", "(", "_NbestPrediction", "(", "text", "=", "final_text", ",", "start_logit", "=", "pred", ".", "start_logit", ",", "end_logit", "=", "pred", ".", "end_logit", ")", ")", "\n", "# if we didn't include the empty option in the n-best, include it", "\n", "", "if", "version_2_with_negative", ":", "\n", "            ", "if", "\"\"", "not", "in", "seen_predictions", ":", "\n", "                ", "nbest", ".", "append", "(", "_NbestPrediction", "(", "text", "=", "\"\"", ",", "start_logit", "=", "null_start_logit", ",", "end_logit", "=", "null_end_logit", ")", ")", "\n", "\n", "# In very rare edge cases we could only have single null prediction.", "\n", "# So we just create a nonce prediction in this case to avoid failure.", "\n", "", "if", "len", "(", "nbest", ")", "==", "1", ":", "\n", "                ", "nbest", ".", "insert", "(", "0", ",", "_NbestPrediction", "(", "text", "=", "\"empty\"", ",", "start_logit", "=", "0.0", ",", "end_logit", "=", "0.0", ")", ")", "\n", "\n", "# In very rare edge cases we could have no valid predictions. So we", "\n", "# just create a nonce prediction in this case to avoid failure.", "\n", "", "", "if", "not", "nbest", ":", "\n", "            ", "nbest", ".", "append", "(", "_NbestPrediction", "(", "text", "=", "\"empty\"", ",", "start_logit", "=", "0.0", ",", "end_logit", "=", "0.0", ")", ")", "\n", "\n", "", "assert", "len", "(", "nbest", ")", ">=", "1", ",", "\"No valid predictions\"", "\n", "\n", "total_scores", "=", "[", "]", "\n", "best_non_null_entry", "=", "None", "\n", "for", "entry", "in", "nbest", ":", "\n", "            ", "total_scores", ".", "append", "(", "entry", ".", "start_logit", "+", "entry", ".", "end_logit", ")", "\n", "if", "not", "best_non_null_entry", ":", "\n", "                ", "if", "entry", ".", "text", ":", "\n", "                    ", "best_non_null_entry", "=", "entry", "\n", "\n", "", "", "", "probs", "=", "total_scores", "\n", "\n", "nbest_json", "=", "[", "]", "\n", "for", "(", "i", ",", "entry", ")", "in", "enumerate", "(", "nbest", ")", ":", "\n", "            ", "output", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "output", "[", "\"text\"", "]", "=", "entry", ".", "text", "\n", "output", "[", "\"probability\"", "]", "=", "probs", "[", "i", "]", "\n", "output", "[", "\"start_logit\"", "]", "=", "entry", ".", "start_logit", "\n", "output", "[", "\"end_logit\"", "]", "=", "entry", ".", "end_logit", "\n", "try", ":", "\n", "                ", "output", "[", "\"start_logit\"", "]", "=", "output", "[", "\"start_logit\"", "]", ".", "item", "(", ")", "\n", "output", "[", "\"end_logit\"", "]", "=", "output", "[", "\"end_logit\"", "]", ".", "item", "(", ")", "\n", "", "except", ":", "\n", "                ", "pass", "\n", "", "nbest_json", ".", "append", "(", "output", ")", "\n", "\n", "", "assert", "len", "(", "nbest_json", ")", ">=", "1", ",", "\"No valid predictions\"", "\n", "\n", "if", "not", "version_2_with_negative", ":", "\n", "            ", "all_predictions", "[", "example", ".", "qas_id", "]", "=", "(", "nbest_json", "[", "0", "]", "[", "\"text\"", "]", ",", "\n", "nbest_json", "[", "0", "]", "[", "'probability'", "]", ")", "\n", "", "else", ":", "\n", "# predict \"\" iff the null score - the score of best non-null > threshold", "\n", "            ", "score_diff", "=", "score_null", "-", "best_non_null_entry", ".", "start_logit", "-", "(", "best_non_null_entry", ".", "end_logit", ")", "\n", "scores_diff_json", "[", "example", ".", "qas_id", "]", "=", "score_diff", "\n", "if", "score_diff", ">", "null_score_diff_threshold", ":", "\n", "                ", "all_predictions", "[", "example", ".", "qas_id", "]", "=", "(", "\"\"", ",", "0", ")", "\n", "", "else", ":", "\n", "                ", "all_predictions", "[", "example", ".", "qas_id", "]", "=", "(", "\n", "best_non_null_entry", ".", "text", ",", "\n", "best_non_null_entry", ".", "start_logit", "+", "best_non_null_entry", ".", "end_logit", ")", "\n", "", "", "all_nbest_json", "[", "example", ".", "qas_id", "]", "=", "nbest_json", "\n", "\n", "", "if", "output_prediction_file", ":", "\n", "        ", "with", "open", "(", "output_prediction_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_predictions", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "if", "output_nbest_file", ":", "\n", "        ", "with", "open", "(", "output_nbest_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_nbest_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "if", "output_null_log_odds_file", "and", "version_2_with_negative", ":", "\n", "        ", "with", "open", "(", "output_null_log_odds_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "scores_diff_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "return", "all_predictions", ",", "all_nbest_json", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.compute_predictions_log_probs": [[607, 795], ["collections.namedtuple", "collections.namedtuple", "logger.info", "collections.defaultdict", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "enumerate", "example_index_to_features[].append", "enumerate", "sorted", "utils_squad_metrics._compute_softmax", "enumerate", "open", "writer.write", "open", "writer.write", "min", "range", "tokenizer.convert_tokens_to_string", "tok_text.strip.strip", "hasattr", "utils_squad_metrics.get_final_text", "nbest.append", "nbest.append", "total_scores.append", "collections.OrderedDict", "nbest_json.append", "len", "open", "writer.write", "range", "len", "tok_text.strip.split", "collections.namedtuple.", "collections.namedtuple.", "json.dumps", "json.dumps", "sorted.append", "json.dumps", "feature.token_is_max_context.get", "collections.namedtuple."], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics._compute_softmax", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.get_final_text"], ["", "def", "compute_predictions_log_probs", "(", "\n", "all_examples", ",", "\n", "all_features", ",", "\n", "all_results", ",", "\n", "n_best_size", ",", "\n", "max_answer_length", ",", "\n", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "\n", "output_null_log_odds_file", ",", "\n", "start_n_top", ",", "\n", "end_n_top", ",", "\n", "version_2_with_negative", ",", "\n", "tokenizer", ",", "\n", "verbose_logging", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    XLNet write prediction logic (more complex than Bert's). Write final predictions to the json file and log-odds of\n    null if needed.\n\n    Requires utils_squad_evaluate.py\n    \"\"\"", "\n", "_PrelimPrediction", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"PrelimPrediction\"", ",", "[", "\"feature_index\"", ",", "\"start_index\"", ",", "\"end_index\"", ",", "\"start_log_prob\"", ",", "\"end_log_prob\"", "]", "\n", ")", "\n", "\n", "_NbestPrediction", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"NbestPrediction\"", ",", "[", "\"text\"", ",", "\"start_log_prob\"", ",", "\"end_log_prob\"", "]", "\n", ")", "\n", "\n", "logger", ".", "info", "(", "f\"Writing predictions to: {output_prediction_file}\"", ")", "\n", "\n", "example_index_to_features", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "feature", "in", "all_features", ":", "\n", "        ", "example_index_to_features", "[", "feature", ".", "example_index", "]", ".", "append", "(", "feature", ")", "\n", "\n", "", "unique_id_to_result", "=", "{", "}", "\n", "for", "result", "in", "all_results", ":", "\n", "        ", "unique_id_to_result", "[", "result", ".", "unique_id", "]", "=", "result", "\n", "\n", "", "all_predictions", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "all_nbest_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "scores_diff_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "\n", "for", "(", "example_index", ",", "example", ")", "in", "enumerate", "(", "all_examples", ")", ":", "\n", "        ", "features", "=", "example_index_to_features", "[", "example_index", "]", "\n", "\n", "prelim_predictions", "=", "[", "]", "\n", "# keep track of the minimum score of null start+end of position 0", "\n", "score_null", "=", "1000000", "# large and positive", "\n", "\n", "for", "(", "feature_index", ",", "feature", ")", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "result", "=", "unique_id_to_result", "[", "feature", ".", "unique_id", "]", "\n", "\n", "cur_null_score", "=", "result", ".", "cls_logits", "\n", "\n", "# if we could have irrelevant answers, get the min score of irrelevant", "\n", "score_null", "=", "min", "(", "score_null", ",", "cur_null_score", ")", "\n", "\n", "for", "i", "in", "range", "(", "start_n_top", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "end_n_top", ")", ":", "\n", "                    ", "start_log_prob", "=", "result", ".", "start_logits", "[", "i", "]", "\n", "start_index", "=", "result", ".", "start_top_index", "[", "i", "]", "\n", "\n", "j_index", "=", "i", "*", "end_n_top", "+", "j", "\n", "\n", "end_log_prob", "=", "result", ".", "end_logits", "[", "j_index", "]", "\n", "end_index", "=", "result", ".", "end_top_index", "[", "j_index", "]", "\n", "\n", "# We could hypothetically create invalid predictions, e.g., predict", "\n", "# that the start of the span is in the question. We throw out all", "\n", "# invalid predictions.", "\n", "if", "start_index", ">=", "feature", ".", "paragraph_len", "-", "1", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", ">=", "feature", ".", "paragraph_len", "-", "1", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "feature", ".", "token_is_max_context", ".", "get", "(", "start_index", ",", "False", ")", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", "<", "start_index", ":", "\n", "                        ", "continue", "\n", "", "length", "=", "end_index", "-", "start_index", "+", "1", "\n", "if", "length", ">", "max_answer_length", ":", "\n", "                        ", "continue", "\n", "\n", "", "prelim_predictions", ".", "append", "(", "\n", "_PrelimPrediction", "(", "\n", "feature_index", "=", "feature_index", ",", "\n", "start_index", "=", "start_index", ",", "\n", "end_index", "=", "end_index", ",", "\n", "start_log_prob", "=", "start_log_prob", ",", "\n", "end_log_prob", "=", "end_log_prob", ",", "\n", ")", "\n", ")", "\n", "\n", "", "", "", "prelim_predictions", "=", "sorted", "(", "\n", "prelim_predictions", ",", "key", "=", "lambda", "x", ":", "(", "x", ".", "start_log_prob", "+", "x", ".", "end_log_prob", ")", ",", "reverse", "=", "True", "\n", ")", "\n", "\n", "seen_predictions", "=", "{", "}", "\n", "nbest", "=", "[", "]", "\n", "for", "pred", "in", "prelim_predictions", ":", "\n", "            ", "if", "len", "(", "nbest", ")", ">=", "n_best_size", ":", "\n", "                ", "break", "\n", "", "feature", "=", "features", "[", "pred", ".", "feature_index", "]", "\n", "\n", "# XLNet un-tokenizer", "\n", "# Let's keep it simple for now and see if we need all this later.", "\n", "#", "\n", "# tok_start_to_orig_index = feature.tok_start_to_orig_index", "\n", "# tok_end_to_orig_index = feature.tok_end_to_orig_index", "\n", "# start_orig_pos = tok_start_to_orig_index[pred.start_index]", "\n", "# end_orig_pos = tok_end_to_orig_index[pred.end_index]", "\n", "# paragraph_text = example.paragraph_text", "\n", "# final_text = paragraph_text[start_orig_pos: end_orig_pos + 1].strip()", "\n", "\n", "# Previously used Bert untokenizer", "\n", "tok_tokens", "=", "feature", ".", "tokens", "[", "pred", ".", "start_index", ":", "(", "pred", ".", "end_index", "+", "1", ")", "]", "\n", "orig_doc_start", "=", "feature", ".", "token_to_orig_map", "[", "pred", ".", "start_index", "]", "\n", "orig_doc_end", "=", "feature", ".", "token_to_orig_map", "[", "pred", ".", "end_index", "]", "\n", "orig_tokens", "=", "example", ".", "doc_tokens", "[", "orig_doc_start", ":", "(", "orig_doc_end", "+", "1", ")", "]", "\n", "tok_text", "=", "tokenizer", ".", "convert_tokens_to_string", "(", "tok_tokens", ")", "\n", "\n", "# Clean whitespace", "\n", "tok_text", "=", "tok_text", ".", "strip", "(", ")", "\n", "tok_text", "=", "\" \"", ".", "join", "(", "tok_text", ".", "split", "(", ")", ")", "\n", "orig_text", "=", "\" \"", ".", "join", "(", "orig_tokens", ")", "\n", "\n", "if", "hasattr", "(", "tokenizer", ",", "\"do_lower_case\"", ")", ":", "\n", "                ", "do_lower_case", "=", "tokenizer", ".", "do_lower_case", "\n", "", "else", ":", "\n", "                ", "do_lower_case", "=", "tokenizer", ".", "do_lowercase_and_remove_accent", "\n", "\n", "", "final_text", "=", "get_final_text", "(", "tok_text", ",", "orig_text", ",", "do_lower_case", ",", "verbose_logging", ")", "\n", "\n", "if", "final_text", "in", "seen_predictions", ":", "\n", "                ", "continue", "\n", "\n", "", "seen_predictions", "[", "final_text", "]", "=", "True", "\n", "\n", "nbest", ".", "append", "(", "\n", "_NbestPrediction", "(", "text", "=", "final_text", ",", "start_log_prob", "=", "pred", ".", "start_log_prob", ",", "end_log_prob", "=", "pred", ".", "end_log_prob", ")", "\n", ")", "\n", "\n", "# In very rare edge cases we could have no valid predictions. So we", "\n", "# just create a nonce prediction in this case to avoid failure.", "\n", "", "if", "not", "nbest", ":", "\n", "            ", "nbest", ".", "append", "(", "_NbestPrediction", "(", "text", "=", "\"\"", ",", "start_log_prob", "=", "-", "1e6", ",", "end_log_prob", "=", "-", "1e6", ")", ")", "\n", "\n", "", "total_scores", "=", "[", "]", "\n", "best_non_null_entry", "=", "None", "\n", "for", "entry", "in", "nbest", ":", "\n", "            ", "total_scores", ".", "append", "(", "entry", ".", "start_log_prob", "+", "entry", ".", "end_log_prob", ")", "\n", "if", "not", "best_non_null_entry", ":", "\n", "                ", "best_non_null_entry", "=", "entry", "\n", "\n", "", "", "probs", "=", "_compute_softmax", "(", "total_scores", ")", "\n", "\n", "nbest_json", "=", "[", "]", "\n", "for", "(", "i", ",", "entry", ")", "in", "enumerate", "(", "nbest", ")", ":", "\n", "            ", "output", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "output", "[", "\"text\"", "]", "=", "entry", ".", "text", "\n", "output", "[", "\"probability\"", "]", "=", "probs", "[", "i", "]", "\n", "output", "[", "\"start_log_prob\"", "]", "=", "entry", ".", "start_log_prob", "\n", "output", "[", "\"end_log_prob\"", "]", "=", "entry", ".", "end_log_prob", "\n", "nbest_json", ".", "append", "(", "output", ")", "\n", "\n", "", "assert", "len", "(", "nbest_json", ")", ">=", "1", ",", "\"No valid predictions\"", "\n", "assert", "best_non_null_entry", "is", "not", "None", ",", "\"No valid predictions\"", "\n", "\n", "score_diff", "=", "score_null", "\n", "scores_diff_json", "[", "example", ".", "qas_id", "]", "=", "score_diff", "\n", "# note(zhiliny): always predict best_non_null_entry", "\n", "# and the evaluation script will search for the best threshold", "\n", "all_predictions", "[", "example", ".", "qas_id", "]", "=", "best_non_null_entry", ".", "text", "\n", "\n", "all_nbest_json", "[", "example", ".", "qas_id", "]", "=", "nbest_json", "\n", "\n", "", "with", "open", "(", "output_prediction_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_predictions", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "with", "open", "(", "output_nbest_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_nbest_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "if", "version_2_with_negative", ":", "\n", "        ", "with", "open", "(", "output_null_log_odds_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "scores_diff_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "return", "all_predictions", "\n", "", ""]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.strip_accents": [[10, 13], ["unicodedata.normalize", "unicodedata.category"], "function", ["None"], ["def", "strip_accents", "(", "text", ")", ":", "\n", "    ", "return", "\"\"", ".", "join", "(", "char", "for", "char", "in", "unicodedata", ".", "normalize", "(", "'NFKD'", ",", "text", ")", "\n", "if", "unicodedata", ".", "category", "(", "char", ")", "!=", "'Mn'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.choose_best_answer": [[15, 22], ["utils.get_voted_answers", "sorted"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.get_voted_answers"], ["", "def", "choose_best_answer", "(", "final_answers", ",", "score_computer", ",", "\n", "paragraph_score_weight", ",", "phrase_score_weight", ",", "mode", "=", "\"origin\"", ")", ":", "\n", "    ", "scored_answers", "=", "get_voted_answers", "(", "final_answers", ",", "score_computer", ",", "\n", "paragraph_score_weight", ",", "phrase_score_weight", ",", "mode", ")", "\n", "sorted_answers", "=", "sorted", "(", "scored_answers", ",", "key", "=", "lambda", "k", ":", "k", "[", "'total_score'", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "return", "sorted_answers", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.weighted_score": [[24, 26], ["None"], "function", ["None"], ["", "def", "weighted_score", "(", "paragraph_score", ",", "phrase_score", ",", "paragraph_weight", "=", "0.5", ",", "phrase_weight", "=", "0.5", ")", ":", "\n", "    ", "return", "paragraph_score", "*", "paragraph_weight", "+", "phrase_score", "*", "phrase_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.get_type": [[28, 38], ["sent.split", "token.lower().startswith", "t.lower", "token.lower"], "function", ["None"], ["", "def", "get_type", "(", "sent", ")", ":", "\n", "    ", "ts", "=", "[", "'Who'", ",", "'Why'", ",", "'What'", ",", "'Which'", ",", "'When'", ",", "'How'", ",", "'Where'", "]", "\n", "tp", "=", "'others'", "\n", "\n", "for", "token", "in", "sent", ".", "split", "(", ")", ":", "\n", "        ", "for", "t", "in", "ts", ":", "\n", "            ", "if", "token", ".", "lower", "(", ")", ".", "startswith", "(", "t", ".", "lower", "(", ")", ")", ":", "\n", "                ", "tp", "=", "t", "\n", "return", "tp", "\n", "", "", "", "return", "tp", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.get_voted_answers": [[40, 82], ["utils.get_scored_answers", "utils.get_scored_answers", "utils.get_scored_answers", "combined_answers.append", "[].append", "[].append", "[].append", "numpy.sum", "numpy.max"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.get_scored_answers", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.get_scored_answers", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.get_scored_answers"], ["", "def", "get_voted_answers", "(", "answerlist", ",", "score_computer", ",", "paragraph_score_weight", ",", "phrase_score_weight", ",", "mode", "=", "\"origin\"", ")", ":", "\n", "    ", "if", "mode", "==", "\"origin\"", ":", "\n", "        ", "return", "get_scored_answers", "(", "answerlist", ",", "score_computer", ",", "paragraph_score_weight", ",", "phrase_score_weight", ")", "\n", "", "elif", "mode", "==", "\"ext_origin\"", ":", "\n", "        ", "return", "get_scored_answers", "(", "answerlist", "[", "0", "]", ",", "score_computer", ",", "paragraph_score_weight", ",", "phrase_score_weight", ")", "\n", "", "else", ":", "\n", "        ", "answer_dict", "=", "{", "}", "\n", "# base_ans = get_scored_answers(answerlist[0], score_computer, paragraph_score_weight, phrase_score_weight)", "\n", "# print(base_ans)", "\n", "answerlist", "=", "answerlist", "\n", "# answerlist = [answerlist[0]]", "\n", "answers", "=", "get_scored_answers", "(", "answerlist", "[", "0", "]", ",", "score_computer", ",", "paragraph_score_weight", ",", "phrase_score_weight", ")", "\n", "for", "ans", "in", "answers", ":", "\n", "            ", "answer_text", "=", "ans", "[", "'answer'", "]", "\n", "answer_sentence", "=", "ans", "[", "'sentence'", "]", "\n", "answer_score", "=", "ans", "[", "'total_score'", "]", "\n", "if", "answer_text", "not", "in", "answer_dict", ":", "\n", "                ", "answer_dict", "[", "answer_text", "]", "=", "{", "\n", "\"count\"", ":", "1", ",", "\n", "\"total_scores\"", ":", "[", "1", "*", "answer_score", "]", ",", "\n", "\"sentences\"", ":", "[", "answer_sentence", "]", ",", "\n", "\"answer_text\"", ":", "[", "answer_text", "]", "\n", "}", "\n", "", "else", ":", "\n", "                ", "answer_dict", "[", "answer_text", "]", "[", "'count'", "]", "+=", "1", "\n", "answer_dict", "[", "answer_text", "]", "[", "'total_scores'", "]", ".", "append", "(", "1", "*", "answer_score", ")", "\n", "answer_dict", "[", "answer_text", "]", "[", "'sentences'", "]", ".", "append", "(", "answer_sentence", ")", "\n", "answer_dict", "[", "answer_text", "]", "[", "'answer_text'", "]", ".", "append", "(", "answer_text", ")", "\n", "\n", "", "", "combined_answers", "=", "[", "]", "\n", "for", "ans", "in", "answer_dict", ":", "\n", "            ", "new_answer", "=", "{", "\n", "\"answer\"", ":", "answer_dict", "[", "ans", "]", "[", "'answer_text'", "]", "[", "0", "]", ",", "\n", "# \"count\": answer_dict[ans]['count'],", "\n", "# \"total_score\": answer_dict[ans]['count'], ", "\n", "\"total_score\"", ":", "np", ".", "sum", "(", "answer_dict", "[", "ans", "]", "[", "'total_scores'", "]", ")", ",", "\n", "\"sentence\"", ":", "answer_dict", "[", "ans", "]", "[", "'sentences'", "]", ",", "\n", "\"best_score\"", ":", "np", ".", "max", "(", "answer_dict", "[", "ans", "]", "[", "'total_scores'", "]", ")", "\n", "}", "\n", "combined_answers", ".", "append", "(", "new_answer", ")", "\n", "\n", "", "return", "combined_answers", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.get_scored_answers": [[84, 96], ["enumerate", "score_computer", "scored_answers.append"], "function", ["None"], ["", "", "def", "get_scored_answers", "(", "final_answers", ",", "score_computer", ",", "paragraph_score_weight", ",", "phrase_score_weight", ")", ":", "\n", "    ", "scored_answers", "=", "[", "]", "\n", "for", "ans_id", ",", "ans", "in", "enumerate", "(", "final_answers", ")", ":", "\n", "# print(ans)", "\n", "        ", "paragraph_score", "=", "ans", "[", "'paragraph_score'", "]", "\n", "phrase_score", "=", "ans", "[", "'phrase_score'", "]", "\n", "total_score", "=", "score_computer", "(", "paragraph_score", ",", "phrase_score", ",", "paragraph_score_weight", ",", "phrase_score_weight", ")", "\n", "new_answer", "=", "ans", "\n", "new_answer", "[", "'total_score'", "]", "=", "total_score", "\n", "scored_answers", ".", "append", "(", "new_answer", ")", "\n", "# break", "\n", "", "return", "scored_answers", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.convert_squad_to_list": [[98, 111], ["json.load", "open", "converted_data.append"], "function", ["None"], ["", "def", "convert_squad_to_list", "(", "squad_filename", ")", ":", "\n", "    ", "data", "=", "json", ".", "load", "(", "open", "(", "squad_filename", ",", "'r'", ")", ")", "\n", "data", "=", "data", "[", "\"data\"", "]", "\n", "converted_data", "=", "[", "]", "\n", "for", "article", "in", "data", ":", "\n", "        ", "for", "paragraph", "in", "article", "[", "\"paragraphs\"", "]", ":", "\n", "            ", "text", "=", "paragraph", "[", "\"context\"", "]", "\n", "for", "qa", "in", "paragraph", "[", "\"qas\"", "]", ":", "\n", "                ", "id_", "=", "qa", "[", "\"id\"", "]", "\n", "question", "=", "qa", "[", "\"question\"", "]", "\n", "answers", "=", "qa", "[", "\"answers\"", "]", "\n", "converted_data", ".", "append", "(", "{", "\"id\"", ":", "id_", ",", "\"question\"", ":", "question", ",", "\"answers\"", ":", "answers", ",", "\"context\"", ":", "text", "}", ")", "\n", "", "", "", "return", "converted_data", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.init_logger": [[113, 132], ["logging.getLogger", "logging.getLogger.setLevel", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.Formatter", "logging.FileHandler.setFormatter", "logging.StreamHandler.setFormatter", "logging.getLogger.addHandler", "logging.getLogger.addHandler"], "function", ["None"], ["", "def", "init_logger", "(", "bot", ")", ":", "\n", "# create logger with 'spam_application'", "\n", "# bot = 'server_cn' if args.chinese else 'server_en'", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "'{} log'", ".", "format", "(", "bot", ")", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "# create file handler which logs even debug messages", "\n", "fh", "=", "logging", ".", "FileHandler", "(", "'{}.log'", ".", "format", "(", "bot", ")", ")", "\n", "fh", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "# create console handler with a higher log level", "\n", "ch", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "ch", ".", "setLevel", "(", "logging", ".", "ERROR", ")", "\n", "# create formatter and add it to the handlers", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "'%(asctime)s - %(name)s - %(levelname)s - %(message)s'", ")", "\n", "fh", ".", "setFormatter", "(", "formatter", ")", "\n", "ch", ".", "setFormatter", "(", "formatter", ")", "\n", "# add the handlers to the logger", "\n", "logger", ".", "addHandler", "(", "fh", ")", "\n", "logger", ".", "addHandler", "(", "ch", ")", "\n", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.split_title": [[134, 139], ["paragraph.split", "sents[].strip"], "function", ["None"], ["", "def", "split_title", "(", "paragraph", ")", ":", "\n", "    ", "sents", "=", "paragraph", ".", "split", "(", "\".\"", ")", "\n", "text", "=", "\".\"", ".", "join", "(", "sents", "[", "1", ":", "]", ")", ".", "strip", "(", ")", "\n", "title", "=", "sents", "[", "0", "]", ".", "strip", "(", ")", "\n", "return", "title", ",", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.normalize_answer": [[141, 158], ["utils.normalize_answer.white_space_fix"], "function", ["None"], ["", "def", "normalize_answer", "(", "s", ")", ":", "\n", "    ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "        ", "return", "re", ".", "sub", "(", "r'\\b(a|an|the)\\b'", ",", "' '", ",", "text", ")", "\n", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "        ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.normalize_text": [[160, 169], ["utils.normalize_answer.remove_punc"], "function", ["None"], ["", "def", "normalize_text", "(", "s", ")", ":", "\n", "    ", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "        ", "return", "text", ".", "lower", "(", ")", "\n", "\n", "", "return", "remove_punc", "(", "lower", "(", "s", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.normalize_chinese_text": [[171, 177], ["utils.normalize_answer.remove_punc"], "function", ["None"], ["", "def", "normalize_chinese_text", "(", "s", ")", ":", "\n", "    ", "def", "remove_punc", "(", "text", ")", ":", "\n", "        ", "exclude", "=", "set", "(", "zhon", ".", "hanzi", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "\n", "", "return", "remove_punc", "(", "s", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.experiments.evaluate.get_score_with_results": [[12, 56], ["enumerate", "json.dump", "json.dump", "print", "bertserini.utils.utils.choose_best_answer", "best_answer[].replace", "open", "open", "bertserini.experiments.eval.evaluate_v1.squad_v1_eval", "bertserini.experiments.eval.evaluate_v1_cmrc.evaluate", "bertserini.experiments.eval.evaluate_v1_drcd.evaluation", "bertserini.experiments.eval.evaluate_v1.squad_v1_eval", "[].split"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.choose_best_answer", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.squad_v1_eval", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.train.run_squad.evaluate", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.evaluation", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.squad_v1_eval"], ["def", "get_score_with_results", "(", "eval_data", ",", "predictions", ",", "mu", ",", "dataset", ")", ":", "\n", "    ", "answers", "=", "{", "}", "\n", "score", "=", "{", "}", "\n", "\n", "for", "predict_id", ",", "predict", "in", "enumerate", "(", "predictions", ")", ":", "\n", "\n", "        ", "try", ":", "\n", "            ", "if", "dataset", "==", "\"trivia\"", ":", "\n", "                ", "id_", "=", "predict", "[", "0", "]", "[", "'id'", "]", ".", "split", "(", "\"--\"", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "id_", "=", "predict", "[", "0", "]", "[", "'id'", "]", "\n", "", "", "except", "IndexError", "as", "e", ":", "\n", "            ", "pass", "\n", "\n", "", "if", "not", "predict", ":", "\n", "            ", "continue", "\n", "\n", "", "best_answer", "=", "choose_best_answer", "(", "\n", "predict", ",", "\n", "weighted_score", ",", "\n", "1", "-", "mu", ",", "mu", ")", "\n", "\n", "answers", "[", "id_", "]", "=", "best_answer", "[", "'answer'", "]", ".", "replace", "(", "\"##\"", ",", "\"\"", ")", "\n", "\n", "score", "[", "id_", "]", "=", "best_answer", "[", "\"total_score\"", "]", "\n", "\n", "", "json", ".", "dump", "(", "answers", ",", "open", "(", "\"tmp.answer\"", ",", "'w'", ")", ")", "\n", "json", ".", "dump", "(", "score", ",", "open", "(", "\"tmp.score\"", ",", "'w'", ")", ")", "\n", "\n", "if", "dataset", "==", "\"squad\"", ":", "\n", "        ", "eval_result", "=", "squad_evaluation", "(", "eval_data", ",", "\"tmp.answer\"", ")", "\n", "", "elif", "dataset", "==", "\"cmrc\"", ":", "\n", "        ", "eval_result", "=", "cmrc_evaluation", "(", "eval_data", ",", "\"tmp.answer\"", ")", "\n", "eval_result", "=", "{", "\"f1_score\"", ":", "eval_result", "[", "0", "]", ",", "\n", "\"exact_match\"", ":", "eval_result", "[", "1", "]", ",", "\n", "\"total_count\"", ":", "eval_result", "[", "2", "]", ",", "\n", "\"skip_count\"", ":", "eval_result", "[", "3", "]", "}", "\n", "", "elif", "args", ".", "dataset", "==", "\"drcd\"", ":", "\n", "        ", "eval_result", "=", "drcd_evaluation", "(", "eval_data", ",", "\"tmp.answer\"", ")", "\n", "", "else", ":", "\n", "        ", "eval_result", "=", "squad_evaluation", "(", "eval_data", ",", "\"tmp.answer\"", ")", "\n", "\n", "", "print", "(", "\"mu:{}, result:{}\"", ".", "format", "(", "mu", ",", "eval_result", ")", ")", "\n", "return", "eval_result", ",", "answers", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.experiments.evaluate.get_best_mu_with_scores": [[58, 73], ["json.dump", "evaluate.get_score_with_results", "open", "json.dump", "open"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.experiments.evaluate.get_score_with_results"], ["", "def", "get_best_mu_with_scores", "(", "eval_data", ",", "predictions", ",", "mu_range", ",", "dataset", ",", "output_path", ",", "metric", "=", "\"f1\"", ")", ":", "\n", "# metric = \"f1\" or \"exact_match\"", "\n", "    ", "score_test", "=", "{", "}", "\n", "best_mu", "=", "0", "\n", "best_score", "=", "0", "\n", "for", "mu", "in", "mu_range", ":", "\n", "        ", "eval_result", ",", "answers", "=", "get_score_with_results", "(", "eval_data", ",", "predictions", ",", "mu", ",", "dataset", ")", "\n", "score_test", "[", "mu", "]", "=", "eval_result", "\n", "if", "eval_result", "[", "metric", "]", ">", "best_score", ":", "\n", "            ", "best_mu", "=", "mu", "\n", "best_score", "=", "eval_result", "[", "metric", "]", "\n", "json", ".", "dump", "(", "answers", ",", "open", "(", "output_path", "+", "\"/prediction.json\"", ",", "'w'", ")", ")", "\n", "\n", "", "", "json", ".", "dump", "(", "score_test", ",", "open", "(", "output_path", "+", "\"/score.json\"", ",", "'w'", ")", ")", "\n", "return", "best_mu", ",", "score_test", "[", "best_mu", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.cover_score": [[12, 16], ["bertserini.utils.utils.normalize_answer", "bertserini.utils.utils.normalize_answer"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.normalize_answer", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.normalize_answer"], ["def", "cover_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "prediction", "=", "normalize_answer", "(", "prediction", ")", "\n", "ground_truth", "=", "normalize_answer", "(", "ground_truth", ")", "\n", "return", "ground_truth", "in", "prediction", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.f1_score": [[18, 29], ["bertserini.utils.utils.normalize_answer().split", "bertserini.utils.utils.normalize_answer().split", "sum", "collections.Counter", "collections.Counter", "common.values", "len", "len", "bertserini.utils.utils.normalize_answer", "bertserini.utils.utils.normalize_answer"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.normalize_answer", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.normalize_answer"], ["", "def", "f1_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "prediction_tokens", "=", "normalize_answer", "(", "prediction", ")", ".", "split", "(", ")", "\n", "ground_truth_tokens", "=", "normalize_answer", "(", "ground_truth", ")", ".", "split", "(", ")", "\n", "common", "=", "Counter", "(", "prediction_tokens", ")", "&", "Counter", "(", "ground_truth_tokens", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "num_same", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "prediction_tokens", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "ground_truth_tokens", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.precision_score": [[31, 42], ["bertserini.utils.utils.normalize_answer().split", "bertserini.utils.utils.normalize_answer().split", "sum", "collections.Counter", "collections.Counter", "common.values", "len", "len", "bertserini.utils.utils.normalize_answer", "bertserini.utils.utils.normalize_answer"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.normalize_answer", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.normalize_answer"], ["", "def", "precision_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "prediction_tokens", "=", "normalize_answer", "(", "prediction", ")", ".", "split", "(", ")", "\n", "ground_truth_tokens", "=", "normalize_answer", "(", "ground_truth", ")", ".", "split", "(", ")", "\n", "common", "=", "Counter", "(", "prediction_tokens", ")", "&", "Counter", "(", "ground_truth_tokens", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "num_same", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "prediction_tokens", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "ground_truth_tokens", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "precision", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.recall_score": [[44, 55], ["bertserini.utils.utils.normalize_answer().split", "bertserini.utils.utils.normalize_answer().split", "sum", "collections.Counter", "collections.Counter", "common.values", "len", "len", "bertserini.utils.utils.normalize_answer", "bertserini.utils.utils.normalize_answer"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.normalize_answer", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.normalize_answer"], ["", "def", "recall_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "prediction_tokens", "=", "normalize_answer", "(", "prediction", ")", ".", "split", "(", ")", "\n", "ground_truth_tokens", "=", "normalize_answer", "(", "ground_truth", ")", ".", "split", "(", ")", "\n", "common", "=", "Counter", "(", "prediction_tokens", ")", "&", "Counter", "(", "ground_truth_tokens", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "num_same", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "prediction_tokens", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "ground_truth_tokens", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "recall", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.overlap_score": [[56, 65], ["bertserini.utils.utils.normalize_answer().split", "bertserini.utils.utils.normalize_answer().split", "sum", "collections.Counter", "collections.Counter", "common.values", "bertserini.utils.utils.normalize_answer", "bertserini.utils.utils.normalize_answer"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.normalize_answer", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.normalize_answer"], ["", "def", "overlap_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "prediction_tokens", "=", "normalize_answer", "(", "prediction", ")", ".", "split", "(", ")", "\n", "ground_truth_tokens", "=", "normalize_answer", "(", "ground_truth", ")", ".", "split", "(", ")", "\n", "common", "=", "Counter", "(", "prediction_tokens", ")", "&", "Counter", "(", "ground_truth_tokens", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "num_same", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "else", ":", "\n", "        ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.exact_match_score": [[67, 69], ["bertserini.utils.utils.normalize_answer", "bertserini.utils.utils.normalize_answer"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.normalize_answer", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils.normalize_answer"], ["", "", "def", "exact_match_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "    ", "return", "normalize_answer", "(", "prediction", ")", "==", "normalize_answer", "(", "ground_truth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.metric_max_over_ground_truths": [[71, 77], ["max", "metric_fn", "scores_for_ground_truths.append"], "function", ["None"], ["", "def", "metric_max_over_ground_truths", "(", "metric_fn", ",", "prediction", ",", "ground_truths", ")", ":", "\n", "    ", "scores_for_ground_truths", "=", "[", "]", "\n", "for", "ground_truth", "in", "ground_truths", ":", "\n", "        ", "score", "=", "metric_fn", "(", "prediction", ",", "ground_truth", ")", "\n", "scores_for_ground_truths", ".", "append", "(", "score", ")", "\n", "", "return", "max", "(", "scores_for_ground_truths", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.metric_max_recall": [[79, 92], ["score_recall.append", "max", "score_ground_truth.append", "max", "evaluate_v1.cover_score", "evaluate_v1.exact_match_score", "evaluate_v1.f1_score", "evaluate_v1.overlap_score", "evaluate_v1.precision_score", "evaluate_v1.recall_score"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.cover_score", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.exact_match_score", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.f1_score", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.overlap_score", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.precision_score", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.recall_score"], ["", "def", "metric_max_recall", "(", "metric_fn", ",", "prediction", ",", "ground_truths", ")", ":", "\n", "    ", "score_recall", "=", "[", "]", "\n", "for", "ground_truth", "in", "ground_truths", ":", "\n", "        ", "score_ground_truth", "=", "[", "]", "\n", "for", "predict", "in", "prediction", ":", "\n", "            ", "score", "=", "metric_fn", "(", "predict", ",", "ground_truth", ")", "\n", "score_ground_truth", ".", "append", "(", "score", ")", "\n", "", "score_recall", ".", "append", "(", "score_ground_truth", ")", "\n", "# print(score_recall) TODO: have empty score?", "\n", "", "try", ":", "\n", "        ", "return", "max", "(", "max", "(", "score_recall", ")", ")", "\n", "", "except", "ValueError", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.evaluate": [[94, 133], ["logger.info", "list", "evaluate_v1.metric_max_recall", "evaluate_v1.metric_max_recall", "evaluate_v1.metric_max_recall", "evaluate_v1.metric_max_recall", "evaluate_v1.metric_max_recall", "evaluate_v1.metric_max_recall", "logger.error", "map", "str"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.metric_max_recall", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.metric_max_recall", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.metric_max_recall", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.metric_max_recall", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.metric_max_recall", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.metric_max_recall"], ["", "", "def", "evaluate", "(", "dataset", ",", "predictions", ")", ":", "\n", "    ", "sentence_cover", "=", "precision", "=", "cover", "=", "sentence_recall", "=", "recall", "=", "f1", "=", "exact_match", "=", "total", "=", "overlap", "=", "0", "\n", "for", "article", "in", "dataset", ":", "\n", "        ", "for", "paragraph", "in", "article", "[", "'paragraphs'", "]", ":", "\n", "            ", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "                ", "total", "+=", "1", "\n", "if", "qa", "[", "'id'", "]", "not", "in", "predictions", ":", "\n", "                    ", "message", "=", "'Unanswered question '", "+", "str", "(", "qa", "[", "'id'", "]", ")", "+", "' will receive score 0.'", "\n", "logger", ".", "error", "(", "message", ")", "\n", "continue", "\n", "", "ground_truths", "=", "list", "(", "map", "(", "lambda", "x", ":", "x", "[", "'text'", "]", ",", "qa", "[", "'answers'", "]", ")", ")", "\n", "prediction", "=", "[", "predictions", "[", "qa", "[", "'id'", "]", "]", "]", "\n", "#prediction_sentence = predictions[qa['id']]['sentences']", "\n", "cover", "+=", "metric_max_recall", "(", "cover_score", ",", "prediction", ",", "ground_truths", ")", "\n", "exact_match", "+=", "metric_max_recall", "(", "\n", "exact_match_score", ",", "prediction", ",", "ground_truths", ")", "\n", "f1", "+=", "metric_max_recall", "(", "\n", "f1_score", ",", "prediction", ",", "ground_truths", ")", "\n", "overlap", "+=", "metric_max_recall", "(", "\n", "overlap_score", ",", "prediction", ",", "ground_truths", ")", "\n", "precision", "+=", "metric_max_recall", "(", "\n", "precision_score", ",", "prediction", ",", "ground_truths", ")", "\n", "recall", "+=", "metric_max_recall", "(", "\n", "recall_score", ",", "prediction", ",", "ground_truths", ")", "\n", "#sentence_recall += metric_max_recall(recall_score, prediction_sentence, ground_truths)", "\n", "#sentence_cover += metric_max_recall(cover_score, prediction_sentence, ground_truths)", "\n", "", "", "", "logger", ".", "info", "(", "\"total: {}\"", ".", "format", "(", "total", ")", ")", "\n", "exact_match", "=", "100.0", "*", "exact_match", "/", "total", "\n", "f1", "=", "100.0", "*", "f1", "/", "total", "\n", "recall", "=", "100.0", "*", "recall", "/", "total", "\n", "overlap", "=", "100.0", "*", "overlap", "/", "total", "\n", "cover", "=", "100.0", "*", "cover", "/", "total", "\n", "precision", "=", "100.0", "*", "precision", "/", "total", "\n", "#sentence_recall = 100.0 * sentence_recall / total", "\n", "#sentence_cover = 100.0 * sentence_cover / total", "\n", "\n", "return", "{", "'exact_match'", ":", "exact_match", ",", "'f1'", ":", "f1", ",", "\"recall\"", ":", "recall", ",", "\n", "#\"sentence_recall\": sentence_recall, \"sentence_cover\": sentence_cover,", "\n", "\"precision\"", ":", "precision", ",", "\"cover\"", ":", "cover", ",", "\"overlap\"", ":", "overlap", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1.squad_v1_eval": [[135, 147], ["evaluate_v1.evaluate", "open", "json.load", "open", "json.load", "logger.error"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.train.run_squad.evaluate"], ["", "def", "squad_v1_eval", "(", "dataset_filename", ",", "prediction_filename", ")", ":", "\n", "    ", "expected_version", "=", "'1.1'", "\n", "with", "open", "(", "dataset_filename", ")", "as", "dataset_file", ":", "\n", "        ", "dataset_json", "=", "json", ".", "load", "(", "dataset_file", ")", "\n", "if", "dataset_json", "[", "'version'", "]", "!=", "expected_version", ":", "\n", "            ", "logger", ".", "error", "(", "'Evaluation expects v-{}, but got dataset with v-{}'", ".", "format", "(", "\n", "expected_version", ",", "dataset_json", "[", "'version'", "]", ")", ")", "\n", "", "dataset", "=", "dataset_json", "[", "'data'", "]", "\n", "", "with", "open", "(", "prediction_filename", ")", "as", "prediction_file", ":", "\n", "        ", "predictions", "=", "json", ".", "load", "(", "prediction_file", ")", "\n", "", "ans", "=", "evaluate", "(", "dataset", ",", "predictions", ")", "\n", "return", "ans", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_cmrc.mixed_segmentation": [[21, 46], ["str().lower().strip", "nltk.word_tokenize", "segs_out.extend", "str().lower", "re.search", "segs_out.append", "nltk.word_tokenize", "segs_out.extend", "str"], "function", ["None"], ["def", "mixed_segmentation", "(", "in_str", ",", "rm_punc", "=", "False", ")", ":", "\n", "\t", "in_str", "=", "str", "(", "in_str", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "segs_out", "=", "[", "]", "\n", "temp_str", "=", "\"\"", "\n", "sp_char", "=", "[", "'-'", ",", "':'", ",", "'_'", ",", "'*'", ",", "'^'", ",", "'/'", ",", "'\\\\'", ",", "'~'", ",", "'`'", ",", "'+'", ",", "'='", ",", "\n", "'\uff0c'", ",", "'\u3002'", ",", "'\uff1a'", ",", "'\uff1f'", ",", "'\uff01'", ",", "'\u201c'", ",", "'\u201d'", ",", "'\uff1b'", ",", "'\u2019'", ",", "'\u300a'", ",", "'\u300b'", ",", "'\u2026\u2026'", ",", "'\u00b7'", ",", "'\u3001'", ",", "\n", "'\u300c'", ",", "'\u300d'", ",", "'\uff08'", ",", "'\uff09'", ",", "'\uff0d'", ",", "'\uff5e'", ",", "'\u300e'", ",", "'\u300f'", "]", "\n", "for", "char", "in", "in_str", ":", "\n", "\t\t", "if", "rm_punc", "and", "char", "in", "sp_char", ":", "\n", "\t\t\t", "continue", "\n", "", "if", "re", ".", "search", "(", "u'[\\u4e00-\\u9fa5]'", ",", "char", ")", "or", "char", "in", "sp_char", ":", "\n", "\t\t\t", "if", "temp_str", "!=", "\"\"", ":", "\n", "\t\t\t\t", "ss", "=", "nltk", ".", "word_tokenize", "(", "temp_str", ")", "\n", "segs_out", ".", "extend", "(", "ss", ")", "\n", "temp_str", "=", "\"\"", "\n", "", "segs_out", ".", "append", "(", "char", ")", "\n", "", "else", ":", "\n", "\t\t\t", "temp_str", "+=", "char", "\n", "\n", "#handling last part", "\n", "", "", "if", "temp_str", "!=", "\"\"", ":", "\n", "\t\t", "ss", "=", "nltk", ".", "word_tokenize", "(", "temp_str", ")", "\n", "segs_out", ".", "extend", "(", "ss", ")", "\n", "\n", "", "return", "segs_out", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_cmrc.remove_punctuation": [[49, 61], ["str().lower().strip", "str().lower", "out_segs.append", "str"], "function", ["None"], ["", "def", "remove_punctuation", "(", "in_str", ")", ":", "\n", "\t", "in_str", "=", "str", "(", "in_str", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "sp_char", "=", "[", "'-'", ",", "':'", ",", "'_'", ",", "'*'", ",", "'^'", ",", "'/'", ",", "'\\\\'", ",", "'~'", ",", "'`'", ",", "'+'", ",", "'='", ",", "\n", "'\uff0c'", ",", "'\u3002'", ",", "'\uff1a'", ",", "'\uff1f'", ",", "'\uff01'", ",", "'\u201c'", ",", "'\u201d'", ",", "'\uff1b'", ",", "'\u2019'", ",", "'\u300a'", ",", "'\u300b'", ",", "'\u2026\u2026'", ",", "'\u00b7'", ",", "'\u3001'", ",", "\n", "'\u300c'", ",", "'\u300d'", ",", "'\uff08'", ",", "'\uff09'", ",", "'\uff0d'", ",", "'\uff5e'", ",", "'\u300e'", ",", "'\u300f'", "]", "\n", "out_segs", "=", "[", "]", "\n", "for", "char", "in", "in_str", ":", "\n", "\t\t", "if", "char", "in", "sp_char", ":", "\n", "\t\t\t", "continue", "\n", "", "else", ":", "\n", "\t\t\t", "out_segs", ".", "append", "(", "char", ")", "\n", "", "", "return", "''", ".", "join", "(", "out_segs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_cmrc.find_lcs": [[64, 76], ["range", "len", "range", "range", "len", "range", "len", "len"], "function", ["None"], ["", "def", "find_lcs", "(", "s1", ",", "s2", ")", ":", "\n", "\t", "m", "=", "[", "[", "0", "for", "i", "in", "range", "(", "len", "(", "s2", ")", "+", "1", ")", "]", "for", "j", "in", "range", "(", "len", "(", "s1", ")", "+", "1", ")", "]", "\n", "mmax", "=", "0", "\n", "p", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "s1", ")", ")", ":", "\n", "\t\t", "for", "j", "in", "range", "(", "len", "(", "s2", ")", ")", ":", "\n", "\t\t\t", "if", "s1", "[", "i", "]", "==", "s2", "[", "j", "]", ":", "\n", "\t\t\t\t", "m", "[", "i", "+", "1", "]", "[", "j", "+", "1", "]", "=", "m", "[", "i", "]", "[", "j", "]", "+", "1", "\n", "if", "m", "[", "i", "+", "1", "]", "[", "j", "+", "1", "]", ">", "mmax", ":", "\n", "\t\t\t\t\t", "mmax", "=", "m", "[", "i", "+", "1", "]", "[", "j", "+", "1", "]", "\n", "p", "=", "i", "+", "1", "\n", "", "", "", "", "return", "s1", "[", "p", "-", "mmax", ":", "p", "]", ",", "mmax", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_cmrc.evaluate": [[78, 109], ["json.load", "json.load", "open", "open", "instance[].strip", "instance[].strip", "qas[].strip", "qas[].strip", "evaluate_v1_cmrc.calc_f1_score", "evaluate_v1_cmrc.calc_em_score", "sys.stderr.write"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.calc_f1_score", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.calc_em_score"], ["", "def", "evaluate", "(", "ground_truth_file_name", ",", "prediction_file_name", ")", ":", "\n", "    ", "ground_truth_file", "=", "json", ".", "load", "(", "open", "(", "ground_truth_file_name", ",", "'r'", ")", ")", "\n", "prediction_file", "=", "json", ".", "load", "(", "open", "(", "prediction_file_name", ",", "'r'", ")", ")", "\n", "f1", "=", "0", "\n", "em", "=", "0", "\n", "total_count", "=", "0", "\n", "skip_count", "=", "0", "\n", "for", "instance", "in", "ground_truth_file", ":", "\n", "        ", "context_id", "=", "instance", "[", "'context_id'", "]", ".", "strip", "(", ")", "\n", "context_text", "=", "instance", "[", "'context_text'", "]", ".", "strip", "(", ")", "\n", "for", "qas", "in", "instance", "[", "'qas'", "]", ":", "\n", "            ", "total_count", "+=", "1", "\n", "query_id", "=", "qas", "[", "'query_id'", "]", ".", "strip", "(", ")", "\n", "query_text", "=", "qas", "[", "'query_text'", "]", ".", "strip", "(", ")", "\n", "answers", "=", "qas", "[", "'answers'", "]", "\n", "\n", "if", "query_id", "not", "in", "prediction_file", ":", "\n", "                ", "sys", ".", "stderr", ".", "write", "(", "'Unanswered question: {}\\n'", ".", "format", "(", "query_id", ")", ")", "\n", "skip_count", "+=", "1", "\n", "continue", "\n", "", "prediction", "=", "prediction_file", "[", "query_id", "]", "\n", "f1_now", "=", "calc_f1_score", "(", "answers", ",", "prediction", ")", "\n", "em_now", "=", "calc_em_score", "(", "answers", ",", "prediction", ")", "\n", "f1", "+=", "f1_now", "\n", "em", "+=", "em_now", "\n", "# print(\"Q:{}\\tG:{}\\tP:{}\".format(query_text, answers, prediction))", "\n", "#     print(\"Q:{}\\tG:{}\\tP:{}\\tf1:{}\".format(query_text, answers, prediction, f1_now))", "\n", "\n", "", "", "f1_score", "=", "100.0", "*", "f1", "/", "total_count", "\n", "em_score", "=", "100.0", "*", "em", "/", "total_count", "\n", "return", "f1_score", ",", "em_score", ",", "total_count", ",", "skip_count", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_cmrc.evaluate_general": [[110, 137], ["str", "evaluate_v1_cmrc.calc_f1_score", "evaluate_v1_cmrc.calc_em_score", "sys.stderr.write"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.calc_f1_score", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.calc_em_score"], ["", "def", "evaluate_general", "(", "ground_truth_file", ",", "prediction_file", ")", ":", "\n", "\t", "f1", "=", "0", "\n", "em", "=", "0", "\n", "total_count", "=", "0", "\n", "skip_count", "=", "0", "\n", "# for instance in ground_truth_file:", "\n", "# context_id   = instance['context_id'].strip()", "\n", "# context_text = instance['context_text'].strip()", "\n", "for", "qas", "in", "ground_truth_file", ":", "\n", "\t\t", "total_count", "+=", "1", "\n", "query_id", "=", "str", "(", "qas", "[", "'id'", "]", ")", "\n", "query_text", "=", "qas", "[", "'questions'", "]", "\n", "answers", "=", "qas", "[", "'answers'", "]", "\n", "\n", "if", "query_id", "not", "in", "prediction_file", ":", "\n", "\t\t\t", "sys", ".", "stderr", ".", "write", "(", "'Unanswered question: {}\\n'", ".", "format", "(", "query_id", ")", ")", "\n", "skip_count", "+=", "1", "\n", "continue", "\n", "\n", "", "prediction", "=", "[", "prediction_file", "[", "query_id", "]", "]", "\n", "#logger.info(\"Q:{} G:{} P:{}\".format(query_text, answers, prediction))", "\n", "f1", "+=", "calc_f1_score", "(", "answers", ",", "prediction", ")", "\n", "em", "+=", "calc_em_score", "(", "answers", ",", "prediction", ")", "\n", "\n", "", "f1_score", "=", "100.0", "*", "f1", "/", "total_count", "\n", "em_score", "=", "100.0", "*", "em", "/", "total_count", "\n", "return", "f1_score", ",", "em_score", ",", "total_count", ",", "skip_count", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_cmrc.calc_f1_score": [[139, 153], ["max", "evaluate_v1_cmrc.mixed_segmentation", "evaluate_v1_cmrc.mixed_segmentation", "evaluate_v1_cmrc.find_lcs", "f1_scores.append", "f1_scores.append", "len", "len"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.mixed_segmentation", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.mixed_segmentation", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.find_lcs"], ["", "def", "calc_f1_score", "(", "answers", ",", "prediction", ")", ":", "\n", "\t", "f1_scores", "=", "[", "]", "\n", "for", "ans", "in", "answers", ":", "\n", "\t\t", "ans_segs", "=", "mixed_segmentation", "(", "ans", ",", "rm_punc", "=", "True", ")", "\n", "prediction_segs", "=", "mixed_segmentation", "(", "prediction", ",", "rm_punc", "=", "True", ")", "\n", "lcs", ",", "lcs_len", "=", "find_lcs", "(", "ans_segs", ",", "prediction_segs", ")", "\n", "if", "lcs_len", "==", "0", ":", "\n", "\t\t\t", "f1_scores", ".", "append", "(", "0", ")", "\n", "continue", "\n", "", "precision", "=", "1.0", "*", "lcs_len", "/", "len", "(", "prediction_segs", ")", "\n", "recall", "=", "1.0", "*", "lcs_len", "/", "len", "(", "ans_segs", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "f1_scores", ".", "append", "(", "f1", ")", "\n", "", "return", "max", "(", "f1_scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_cmrc.calc_em_score": [[155, 166], ["evaluate_v1_cmrc.remove_punctuation", "evaluate_v1_cmrc.remove_punctuation"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.remove_punctuation", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.remove_punctuation"], ["", "def", "calc_em_score", "(", "answers", ",", "prediction", ")", ":", "\n", "\t", "em", "=", "0", "\n", "for", "ans", "in", "answers", ":", "\n", "\t\t", "ans_", "=", "remove_punctuation", "(", "ans", ")", "\n", "prediction_", "=", "remove_punctuation", "(", "prediction", ")", "\n", "if", "ans_", "==", "prediction_", ":", "\n", "\t\t\t", "em", "=", "1", "\n", "break", "\n", "#else:", "\n", "#\tprint(\"{} {}\".format(ans_, prediction_)) #logger.info(\"{} {}\".format(ans_, prediction_))", "\n", "", "", "return", "em", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.mixed_segmentation": [[15, 40], ["str().lower().strip", "nltk.word_tokenize", "segs_out.extend", "str().lower", "re.search", "segs_out.append", "nltk.word_tokenize", "segs_out.extend", "str"], "function", ["None"], ["def", "mixed_segmentation", "(", "in_str", ",", "rm_punc", "=", "False", ")", ":", "\n", "\t", "in_str", "=", "str", "(", "in_str", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "segs_out", "=", "[", "]", "\n", "temp_str", "=", "\"\"", "\n", "sp_char", "=", "[", "'-'", ",", "':'", ",", "'_'", ",", "'*'", ",", "'^'", ",", "'/'", ",", "'\\\\'", ",", "'~'", ",", "'`'", ",", "'+'", ",", "'='", ",", "\n", "'\uff0c'", ",", "'\u3002'", ",", "'\uff1a'", ",", "'\uff1f'", ",", "'\uff01'", ",", "'\u201c'", ",", "'\u201d'", ",", "'\uff1b'", ",", "'\u2019'", ",", "'\u300a'", ",", "'\u300b'", ",", "'\u2026\u2026'", ",", "'\u00b7'", ",", "'\u3001'", ",", "\n", "'\u300c'", ",", "'\u300d'", ",", "'\uff08'", ",", "'\uff09'", ",", "'\uff0d'", ",", "'\uff5e'", ",", "'\u300e'", ",", "'\u300f'", "]", "\n", "for", "char", "in", "in_str", ":", "\n", "\t\t", "if", "rm_punc", "and", "char", "in", "sp_char", ":", "\n", "\t\t\t", "continue", "\n", "", "if", "re", ".", "search", "(", "u'[\\u4e00-\\u9fa5]'", ",", "char", ")", "or", "char", "in", "sp_char", ":", "\n", "\t\t\t", "if", "temp_str", "!=", "\"\"", ":", "\n", "\t\t\t\t", "ss", "=", "nltk", ".", "word_tokenize", "(", "temp_str", ")", "\n", "segs_out", ".", "extend", "(", "ss", ")", "\n", "temp_str", "=", "\"\"", "\n", "", "segs_out", ".", "append", "(", "char", ")", "\n", "", "else", ":", "\n", "\t\t\t", "temp_str", "+=", "char", "\n", "\n", "#handling last part", "\n", "", "", "if", "temp_str", "!=", "\"\"", ":", "\n", "\t\t", "ss", "=", "nltk", ".", "word_tokenize", "(", "temp_str", ")", "\n", "segs_out", ".", "extend", "(", "ss", ")", "\n", "\n", "", "return", "segs_out", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.remove_punctuation": [[43, 55], ["str().lower().strip", "str().lower", "out_segs.append", "str"], "function", ["None"], ["", "def", "remove_punctuation", "(", "in_str", ")", ":", "\n", "\t", "in_str", "=", "str", "(", "in_str", ")", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "sp_char", "=", "[", "'-'", ",", "':'", ",", "'_'", ",", "'*'", ",", "'^'", ",", "'/'", ",", "'\\\\'", ",", "'~'", ",", "'`'", ",", "'+'", ",", "'='", ",", "\n", "'\uff0c'", ",", "'\u3002'", ",", "'\uff1a'", ",", "'\uff1f'", ",", "'\uff01'", ",", "'\u201c'", ",", "'\u201d'", ",", "'\uff1b'", ",", "'\u2019'", ",", "'\u300a'", ",", "'\u300b'", ",", "'\u2026\u2026'", ",", "'\u00b7'", ",", "'\u3001'", ",", "\n", "'\u300c'", ",", "'\u300d'", ",", "'\uff08'", ",", "'\uff09'", ",", "'\uff0d'", ",", "'\uff5e'", ",", "'\u300e'", ",", "'\u300f'", "]", "\n", "out_segs", "=", "[", "]", "\n", "for", "char", "in", "in_str", ":", "\n", "\t\t", "if", "char", "in", "sp_char", ":", "\n", "\t\t\t", "continue", "\n", "", "else", ":", "\n", "\t\t\t", "out_segs", ".", "append", "(", "char", ")", "\n", "", "", "return", "''", ".", "join", "(", "out_segs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.find_lcs": [[58, 70], ["range", "len", "range", "range", "len", "range", "len", "len"], "function", ["None"], ["", "def", "find_lcs", "(", "s1", ",", "s2", ")", ":", "\n", "\t", "m", "=", "[", "[", "0", "for", "i", "in", "range", "(", "len", "(", "s2", ")", "+", "1", ")", "]", "for", "j", "in", "range", "(", "len", "(", "s1", ")", "+", "1", ")", "]", "\n", "mmax", "=", "0", "\n", "p", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "s1", ")", ")", ":", "\n", "\t\t", "for", "j", "in", "range", "(", "len", "(", "s2", ")", ")", ":", "\n", "\t\t\t", "if", "s1", "[", "i", "]", "==", "s2", "[", "j", "]", ":", "\n", "\t\t\t\t", "m", "[", "i", "+", "1", "]", "[", "j", "+", "1", "]", "=", "m", "[", "i", "]", "[", "j", "]", "+", "1", "\n", "if", "m", "[", "i", "+", "1", "]", "[", "j", "+", "1", "]", ">", "mmax", ":", "\n", "\t\t\t\t\t", "mmax", "=", "m", "[", "i", "+", "1", "]", "[", "j", "+", "1", "]", "\n", "p", "=", "i", "+", "1", "\n", "", "", "", "", "return", "s1", "[", "p", "-", "mmax", ":", "p", "]", ",", "mmax", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.calc_overlap_score": [[71, 82], ["max", "evaluate_v1_drcd.mixed_segmentation", "evaluate_v1_drcd.mixed_segmentation", "evaluate_v1_drcd.find_lcs", "overlap_scores.append", "overlap_scores.append"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.mixed_segmentation", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.mixed_segmentation", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.find_lcs"], ["", "def", "calc_overlap_score", "(", "answers", ",", "prediction", ")", ":", "\n", "\t", "overlap_scores", "=", "[", "]", "\n", "for", "ans", "in", "answers", ":", "\n", "\t\t", "ans_segs", "=", "mixed_segmentation", "(", "ans", ",", "rm_punc", "=", "True", ")", "\n", "prediction_segs", "=", "mixed_segmentation", "(", "prediction", ",", "rm_punc", "=", "True", ")", "\n", "lcs", ",", "lcs_len", "=", "find_lcs", "(", "ans_segs", ",", "prediction_segs", ")", "\n", "if", "lcs_len", "==", "0", ":", "\n", "\t\t\t", "overlap_scores", ".", "append", "(", "0", ")", "\n", "", "else", ":", "\n", "\t\t\t", "overlap_scores", ".", "append", "(", "1", ")", "\n", "", "", "return", "max", "(", "overlap_scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.calc_f1_score": [[83, 97], ["max", "evaluate_v1_drcd.mixed_segmentation", "evaluate_v1_drcd.mixed_segmentation", "evaluate_v1_drcd.find_lcs", "f1_scores.append", "f1_scores.append", "len", "len"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.mixed_segmentation", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.mixed_segmentation", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.find_lcs"], ["", "def", "calc_f1_score", "(", "answers", ",", "prediction", ")", ":", "\n", "\t", "f1_scores", "=", "[", "]", "\n", "for", "ans", "in", "answers", ":", "\n", "\t\t", "ans_segs", "=", "mixed_segmentation", "(", "ans", ",", "rm_punc", "=", "True", ")", "\n", "prediction_segs", "=", "mixed_segmentation", "(", "prediction", ",", "rm_punc", "=", "True", ")", "\n", "lcs", ",", "lcs_len", "=", "find_lcs", "(", "ans_segs", ",", "prediction_segs", ")", "\n", "if", "lcs_len", "==", "0", ":", "\n", "\t\t\t", "f1_scores", ".", "append", "(", "0", ")", "\n", "continue", "\n", "", "precision", "=", "1.0", "*", "lcs_len", "/", "len", "(", "prediction_segs", ")", "\n", "recall", "=", "1.0", "*", "lcs_len", "/", "len", "(", "ans_segs", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "f1_scores", ".", "append", "(", "f1", ")", "\n", "", "return", "max", "(", "f1_scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.calc_em_score": [[99, 108], ["evaluate_v1_drcd.remove_punctuation", "evaluate_v1_drcd.remove_punctuation"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.remove_punctuation", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.remove_punctuation"], ["", "def", "calc_em_score", "(", "answers", ",", "prediction", ")", ":", "\n", "\t", "em", "=", "0", "\n", "for", "ans", "in", "answers", ":", "\n", "\t\t", "ans_", "=", "remove_punctuation", "(", "ans", ")", "\n", "prediction_", "=", "remove_punctuation", "(", "prediction", ")", "\n", "if", "ans_", "==", "prediction_", ":", "\n", "\t\t\t", "em", "=", "1", "\n", "break", "\n", "", "", "return", "em", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.evaluate": [[109, 143], ["list", "hanziconv.HanziConv.toSimplified", "evaluate_v1_drcd.calc_em_score", "evaluate_v1_drcd.calc_f1_score", "evaluate_v1_drcd.calc_overlap_score", "map", "hanziconv.HanziConv.toSimplified"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.calc_em_score", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.calc_f1_score", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.calc_overlap_score"], ["", "def", "evaluate", "(", "dataset", ",", "predictions", ")", ":", "\n", "\t", "cover", "=", "precision", "=", "recall", "=", "f1", "=", "exact_match", "=", "total", "=", "overlap", "=", "0", "\n", "for", "article", "in", "dataset", ":", "\n", "\t\t", "for", "paragraph", "in", "article", "[", "'paragraphs'", "]", ":", "\n", "\t\t\t", "for", "qa", "in", "paragraph", "[", "'qas'", "]", ":", "\n", "\t\t\t\t", "total", "+=", "1", "\n", "if", "qa", "[", "'id'", "]", "not", "in", "predictions", ":", "\n", "\t\t\t\t\t", "message", "=", "'Unanswered question '", "+", "qa", "[", "'id'", "]", "+", "' will receive score 0.'", "\n", "# print(message, file=sys.stderr)", "\n", "continue", "\n", "", "ground_truths", "=", "list", "(", "map", "(", "lambda", "x", ":", "HanziConv", ".", "toSimplified", "(", "x", "[", "'text'", "]", ")", ",", "qa", "[", "'answers'", "]", ")", ")", "\n", "prediction", "=", "HanziConv", ".", "toSimplified", "(", "predictions", "[", "qa", "[", "'id'", "]", "]", ")", "\n", "# cover += metric_max_recall(cover_score, prediction, ground_truths)", "\n", "exact_match", "+=", "calc_em_score", "(", "ground_truths", ",", "prediction", ")", "\n", "f1_now", "=", "calc_f1_score", "(", "ground_truths", ",", "prediction", ")", "\n", "# if (f1_now == 1):", "\n", "#     print(\"Q: \", qa['question'], \"\\tGT: \", ground_truths, \"\\tP: \", prediction, \"\\tF1: \", f1_now)", "\n", "f1", "+=", "f1_now", "\n", "overlap", "+=", "calc_overlap_score", "(", "ground_truths", ",", "prediction", ")", "\n", "# precision += metric_max_recall(", "\n", "# \tprecision_score, prediction, ground_truths)", "\n", "# recall += metric_max_recall(", "\n", "# \trecall_score, prediction, ground_truths)", "\n", "\n", "# print(\"evaluation total: \", total)", "\n", "", "", "", "exact_match", "=", "100.0", "*", "exact_match", "/", "total", "\n", "f1", "=", "100.0", "*", "f1", "/", "total", "\n", "# recall = 100.0 * recall / total", "\n", "overlap", "=", "100.0", "*", "overlap", "/", "total", "\n", "# cover = 100.0 * cover / total", "\n", "# precision = 100.0 * precision / total", "\n", "\n", "return", "{", "'exact_match'", ":", "exact_match", ",", "'f1'", ":", "f1", ",", "\"overlap\"", ":", "overlap", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.eval.evaluate_v1_drcd.evaluation": [[145, 159], ["evaluate_v1_drcd.evaluate", "print", "open", "json.load", "open", "json.load", "json.dumps"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.train.run_squad.evaluate"], ["", "def", "evaluation", "(", "dataset_filename", ",", "prediction_filename", ")", ":", "\n", "# expected_version = '1.1'", "\n", "\t", "with", "open", "(", "dataset_filename", ")", "as", "dataset_file", ":", "\n", "\t\t", "dataset_json", "=", "json", ".", "load", "(", "dataset_file", ")", "\n", "# if dataset_json['version'] != expected_version:", "\n", "#     print('Evaluation expects v-' + expected_version +", "\n", "#           ', but got dataset with v-' + dataset_json['version'],", "\n", "#           file=sys.stderr)", "\n", "dataset", "=", "dataset_json", "[", "'data'", "]", "\n", "", "with", "open", "(", "prediction_filename", ")", "as", "prediction_file", ":", "\n", "\t\t", "predictions", "=", "json", ".", "load", "(", "prediction_file", ")", "\n", "", "ans", "=", "evaluate", "(", "dataset", ",", "predictions", ")", "\n", "print", "(", "json", ".", "dumps", "(", "ans", ")", ")", "\n", "return", "ans", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.base.Question.__init__": [[21, 25], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "text", ":", "str", ",", "id", ":", "Optional", "[", "str", "]", "=", "None", ",", "language", ":", "str", "=", "\"en\"", ")", ":", "\n", "        ", "self", ".", "text", "=", "text", "\n", "self", ".", "id", "=", "id", "\n", "self", ".", "language", "=", "language", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.base.Question.__repr__": [[26, 28], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.base.Question.__str__": [[29, 31], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"<Question:{}>\"", ".", "format", "(", "self", ".", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.base.Context.__init__": [[50, 63], ["dict"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "text", ":", "str", ",", "\n", "title", ":", "Optional", "[", "str", "]", "=", "\"\"", ",", "\n", "language", ":", "str", "=", "\"en\"", ",", "\n", "metadata", ":", "Mapping", "[", "str", ",", "Any", "]", "=", "None", ",", "\n", "score", ":", "Optional", "[", "float", "]", "=", "0", ")", ":", "\n", "        ", "self", ".", "text", "=", "text", "\n", "self", ".", "title", "=", "title", "\n", "self", ".", "language", "=", "language", "\n", "if", "metadata", "is", "None", ":", "\n", "            ", "metadata", "=", "dict", "(", ")", "\n", "", "self", ".", "metadata", "=", "metadata", "\n", "self", ".", "score", "=", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.base.Context.__repr__": [[64, 66], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.base.Context.__str__": [[67, 69], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"<Passage:{},\\n score:{}>\"", ".", "format", "(", "self", ".", "text", ",", "self", ".", "score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.base.Answer.__init__": [[88, 103], ["dict"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "text", ":", "str", ",", "\n", "language", ":", "str", "=", "\"en\"", ",", "\n", "metadata", ":", "Mapping", "[", "str", ",", "Any", "]", "=", "None", ",", "\n", "score", ":", "Optional", "[", "float", "]", "=", "0", ",", "\n", "ctx_score", ":", "Optional", "[", "float", "]", "=", "0", ",", "\n", "total_score", ":", "Optional", "[", "float", "]", "=", "0", ")", ":", "\n", "        ", "self", ".", "text", "=", "text", "\n", "self", ".", "language", "=", "language", "\n", "if", "metadata", "is", "None", ":", "\n", "            ", "metadata", "=", "dict", "(", ")", "\n", "", "self", ".", "metadata", "=", "metadata", "\n", "self", ".", "score", "=", "score", "\n", "self", ".", "ctx_score", "=", "ctx_score", "\n", "self", ".", "total_score", "=", "total_score", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.base.Answer.__repr__": [[104, 106], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.base.Answer.__str__": [[107, 109], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "\"<Answer: {}, score:{}, ctx_score:{}, total_score:{}>\"", ".", "format", "(", "self", ".", "text", ",", "self", ".", "score", ",", "self", ".", "ctx_score", ",", "self", ".", "total_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.base.Answer.aggregate_score": [[110, 112], ["None"], "methods", ["None"], ["", "def", "aggregate_score", "(", "self", ",", "weight", ")", ":", "\n", "        ", "self", ".", "total_score", "=", "weight", "*", "self", ".", "score", "+", "(", "1", "-", "weight", ")", "*", "self", ".", "ctx_score", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.base.Reader.predict": [[119, 135], ["None"], "methods", ["None"], ["@", "abc", ".", "abstractmethod", "\n", "def", "predict", "(", "self", ",", "query", ":", "Question", ",", "texts", ":", "List", "[", "Context", "]", ")", "->", "List", "[", "Answer", "]", ":", "\n", "        ", "\"\"\"\n            Find answers from a list of Contexts with respect to a question.\n            Parameters\n            ----------\n            query : Question\n                The question.\n            texts : List[Context]\n                The list of context.\n            Returns\n            -------\n            List[Answer]\n                Predicted list of answer.\n        \"\"\"", "\n", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.dpr_reader.DPR.__init__": [[33, 55], ["torch.device", "transformers.models.dpr.DPRReader.from_pretrained().to().eval", "transformers.models.dpr.DPRReaderTokenizer.from_pretrained", "torch.cuda.is_available", "transformers.models.dpr.DPRReader.from_pretrained().to", "transformers.models.dpr.DPRReader.from_pretrained"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "model_args", "=", "args", "\n", "if", "self", ".", "model_args", ".", "tokenizer_name", "is", "None", ":", "\n", "            ", "self", ".", "model_args", ".", "tokenizer_name", "=", "self", ".", "model_args", ".", "model_name_or_path", "\n", "", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "self", ".", "model", "=", "DPRReader", ".", "from_pretrained", "(", "self", ".", "model_args", ".", "model_name_or_path", ")", ".", "to", "(", "self", ".", "device", ")", ".", "eval", "(", ")", "\n", "self", ".", "tokenizer", "=", "DPRReaderTokenizer", ".", "from_pretrained", "(", "self", ".", "model_args", ".", "tokenizer_name", ",", "do_lower_case", "=", "True", ",", "use_fast", "=", "False", ")", "\n", "self", ".", "args", "=", "{", "\n", "\"max_seq_length\"", ":", "384", ",", "\n", "\"doc_stride\"", ":", "128", ",", "\n", "\"max_query_length\"", ":", "64", ",", "\n", "\"threads\"", ":", "1", ",", "\n", "\"tqdm_enabled\"", ":", "False", ",", "\n", "\"n_best_size\"", ":", "20", ",", "\n", "\"max_answer_length\"", ":", "30", ",", "\n", "\"do_lower_case\"", ":", "True", ",", "\n", "\"output_prediction_file\"", ":", "False", ",", "\n", "\"output_nbest_file\"", ":", "self", ".", "model_args", ".", "output_nbest_file", ",", "\n", "\"output_null_log_odds_file\"", ":", "None", ",", "\n", "\"verbose_logging\"", ":", "False", ",", "\n", "\"version_2_with_negative\"", ":", "True", ",", "\n", "\"null_score_diff_threshold\"", ":", "0", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.dpr_reader.DPR.update_args": [[57, 60], ["None"], "methods", ["None"], ["", "def", "update_args", "(", "self", ",", "args_to_change", ")", ":", "\n", "        ", "for", "key", "in", "args_to_change", ":", "\n", "            ", "self", ".", "args", "[", "key", "]", "=", "args_to_change", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.dpr_reader.DPR.predict": [[61, 136], ["dpr_reader.craft_squad_examples", "transformers.data.processors.squad.squad_convert_examples_to_features", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "bertserini.utils.utils_squad_metrics.compute_predictions_logits", "enumerate", "dpr_reader.DPR.model.eval", "tuple", "enumerate", "all_answers.append", "torch.no_grad", "dpr_reader.DPR.model", "int", "transformers.data.processors.squad.SquadResult", "all_results.append", "bertserini.reader.base.Answer", "t.to", "start_logits.item.item.item", "end_logits.item.item.item", "feature_index.item"], "methods", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.bert_reader.craft_squad_examples", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.compute_predictions_logits"], ["", "", "def", "predict", "(", "self", ",", "question", ":", "Question", ",", "contexts", ":", "List", "[", "Context", "]", ")", "->", "List", "[", "Answer", "]", ":", "\n", "        ", "examples", "=", "craft_squad_examples", "(", "question", ",", "contexts", ")", "\n", "\n", "features", ",", "dataset", "=", "squad_convert_examples_to_features", "(", "\n", "examples", "=", "examples", ",", "\n", "tokenizer", "=", "self", ".", "tokenizer", ",", "\n", "max_seq_length", "=", "self", ".", "args", "[", "\"max_seq_length\"", "]", ",", "\n", "doc_stride", "=", "self", ".", "args", "[", "\"doc_stride\"", "]", ",", "\n", "max_query_length", "=", "self", ".", "args", "[", "\"max_query_length\"", "]", ",", "\n", "is_training", "=", "False", ",", "\n", "return_dataset", "=", "\"pt\"", ",", "\n", "threads", "=", "self", ".", "args", "[", "\"threads\"", "]", ",", "\n", "tqdm_enabled", "=", "self", ".", "args", "[", "\"tqdm_enabled\"", "]", "\n", ")", "\n", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "self", ".", "model_args", ".", "eval_batch_size", ")", "\n", "\n", "all_results", "=", "[", "]", "\n", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "            ", "self", ".", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "self", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "}", "\n", "feature_indices", "=", "batch", "[", "3", "]", "\n", "outputs", "=", "self", ".", "model", "(", "**", "inputs", ")", "\n", "\n", "", "for", "i", ",", "feature_index", "in", "enumerate", "(", "feature_indices", ")", ":", "\n", "                ", "eval_feature", "=", "features", "[", "feature_index", ".", "item", "(", ")", "]", "\n", "unique_id", "=", "int", "(", "eval_feature", ".", "unique_id", ")", "\n", "\n", "output", "=", "[", "outputs", "[", "oname", "]", "[", "i", "]", "for", "oname", "in", "outputs", "]", "\n", "start_logits", "=", "outputs", ".", "start_logits", "[", "i", "]", "\n", "end_logits", "=", "outputs", ".", "end_logits", "[", "i", "]", "\n", "try", ":", "\n", "                    ", "start_logits", "=", "start_logits", ".", "item", "(", ")", "\n", "end_logits", "=", "end_logits", ".", "item", "(", ")", "\n", "", "except", ":", "\n", "                    ", "pass", "\n", "\n", "", "result", "=", "SquadResult", "(", "unique_id", ",", "start_logits", ",", "end_logits", ")", "\n", "\n", "all_results", ".", "append", "(", "result", ")", "\n", "\n", "", "", "answers", ",", "nbest", "=", "compute_predictions_logits", "(", "\n", "all_examples", "=", "examples", ",", "\n", "all_features", "=", "features", ",", "\n", "all_results", "=", "all_results", ",", "\n", "n_best_size", "=", "self", ".", "args", "[", "\"n_best_size\"", "]", ",", "\n", "max_answer_length", "=", "self", ".", "args", "[", "\"max_answer_length\"", "]", ",", "\n", "do_lower_case", "=", "self", ".", "args", "[", "\"do_lower_case\"", "]", ",", "\n", "output_prediction_file", "=", "self", ".", "args", "[", "\"output_prediction_file\"", "]", ",", "\n", "output_nbest_file", "=", "self", ".", "args", "[", "\"output_nbest_file\"", "]", ",", "\n", "output_null_log_odds_file", "=", "self", ".", "args", "[", "\"output_null_log_odds_file\"", "]", ",", "\n", "verbose_logging", "=", "self", ".", "args", "[", "\"verbose_logging\"", "]", ",", "\n", "version_2_with_negative", "=", "self", ".", "args", "[", "\"version_2_with_negative\"", "]", ",", "\n", "null_score_diff_threshold", "=", "self", ".", "args", "[", "\"null_score_diff_threshold\"", "]", ",", "\n", "tokenizer", "=", "self", ".", "tokenizer", ",", "\n", "language", "=", "question", ".", "language", "\n", ")", "\n", "\n", "all_answers", "=", "[", "]", "\n", "for", "idx", ",", "ans", "in", "enumerate", "(", "nbest", ")", ":", "\n", "            ", "all_answers", ".", "append", "(", "Answer", "(", "\n", "text", "=", "nbest", "[", "ans", "]", "[", "0", "]", "[", "\"text\"", "]", ",", "\n", "score", "=", "nbest", "[", "ans", "]", "[", "0", "]", "[", "\"start_logit\"", "]", "+", "nbest", "[", "ans", "]", "[", "0", "]", "[", "\"end_logit\"", "]", ",", "\n", "ctx_score", "=", "contexts", "[", "idx", "]", ".", "score", ",", "\n", "language", "=", "question", ".", "language", "\n", ")", ")", "\n", "", "return", "all_answers", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.dpr_reader.craft_squad_examples": [[14, 30], ["enumerate", "examples.append", "transformers.SquadExample"], "function", ["None"], ["def", "craft_squad_examples", "(", "question", ":", "Question", ",", "contexts", ":", "List", "[", "Context", "]", ")", "->", "List", "[", "SquadExample", "]", ":", "\n", "    ", "examples", "=", "[", "]", "\n", "for", "idx", ",", "ctx", "in", "enumerate", "(", "contexts", ")", ":", "\n", "        ", "examples", ".", "append", "(", "\n", "SquadExample", "(", "\n", "qas_id", "=", "idx", ",", "\n", "question_text", "=", "question", ".", "text", ",", "\n", "context_text", "=", "ctx", ".", "text", ",", "\n", "answer_text", "=", "None", ",", "\n", "start_position_character", "=", "None", ",", "\n", "title", "=", "\"\"", ",", "\n", "is_impossible", "=", "False", ",", "\n", "answers", "=", "[", "]", ",", "\n", ")", "\n", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.bert_reader.BERT.__init__": [[34, 56], ["torch.device", "transformers.AutoModelForQuestionAnswering.from_pretrained().to().eval", "transformers.AutoTokenizer.from_pretrained", "torch.cuda.is_available", "transformers.AutoModelForQuestionAnswering.from_pretrained().to", "transformers.AutoModelForQuestionAnswering.from_pretrained"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "self", ".", "model_args", "=", "args", "\n", "if", "self", ".", "model_args", ".", "tokenizer_name", "is", "None", ":", "\n", "            ", "self", ".", "model_args", ".", "tokenizer_name", "=", "self", ".", "model_args", ".", "model_name_or_path", "\n", "", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "self", ".", "model", "=", "AutoModelForQuestionAnswering", ".", "from_pretrained", "(", "self", ".", "model_args", ".", "model_name_or_path", ")", ".", "to", "(", "self", ".", "device", ")", ".", "eval", "(", ")", "\n", "self", ".", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "self", ".", "model_args", ".", "tokenizer_name", ",", "do_lower_case", "=", "True", ",", "use_fast", "=", "False", ")", "\n", "self", ".", "args", "=", "{", "\n", "\"max_seq_length\"", ":", "384", ",", "\n", "\"doc_stride\"", ":", "128", ",", "\n", "\"max_query_length\"", ":", "64", ",", "\n", "\"threads\"", ":", "1", ",", "\n", "\"tqdm_enabled\"", ":", "False", ",", "\n", "\"n_best_size\"", ":", "20", ",", "\n", "\"max_answer_length\"", ":", "30", ",", "\n", "\"do_lower_case\"", ":", "True", ",", "\n", "\"output_prediction_file\"", ":", "False", ",", "\n", "\"output_nbest_file\"", ":", "self", ".", "model_args", ".", "output_nbest_file", ",", "\n", "\"output_null_log_odds_file\"", ":", "None", ",", "\n", "\"verbose_logging\"", ":", "False", ",", "\n", "\"version_2_with_negative\"", ":", "True", ",", "\n", "\"null_score_diff_threshold\"", ":", "0", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.bert_reader.BERT.update_args": [[58, 61], ["None"], "methods", ["None"], ["", "def", "update_args", "(", "self", ",", "args_to_change", ")", ":", "\n", "        ", "for", "key", "in", "args_to_change", ":", "\n", "            ", "self", ".", "args", "[", "key", "]", "=", "args_to_change", "[", "key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.bert_reader.BERT.predict": [[62, 138], ["bert_reader.craft_squad_examples", "transformers.squad_convert_examples_to_features", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "bertserini.utils.utils_squad_metrics.compute_predictions_logits", "enumerate", "bert_reader.BERT.model.eval", "tuple", "enumerate", "all_answers.append", "torch.no_grad", "bert_reader.BERT.model", "int", "transformers.data.processors.squad.SquadResult", "all_results.append", "bertserini.reader.base.Answer", "t.to", "start_logits.item.item.item", "end_logits.item.item.item", "feature_index.item"], "methods", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.bert_reader.craft_squad_examples", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.compute_predictions_logits"], ["", "", "def", "predict", "(", "self", ",", "question", ":", "Question", ",", "contexts", ":", "List", "[", "Context", "]", ")", "->", "List", "[", "Answer", "]", ":", "\n", "        ", "examples", "=", "craft_squad_examples", "(", "question", ",", "contexts", ")", "\n", "\n", "features", ",", "dataset", "=", "squad_convert_examples_to_features", "(", "\n", "examples", "=", "examples", ",", "\n", "tokenizer", "=", "self", ".", "tokenizer", ",", "\n", "max_seq_length", "=", "self", ".", "args", "[", "\"max_seq_length\"", "]", ",", "\n", "doc_stride", "=", "self", ".", "args", "[", "\"doc_stride\"", "]", ",", "\n", "max_query_length", "=", "self", ".", "args", "[", "\"max_query_length\"", "]", ",", "\n", "is_training", "=", "False", ",", "\n", "return_dataset", "=", "\"pt\"", ",", "\n", "threads", "=", "self", ".", "args", "[", "\"threads\"", "]", ",", "\n", "tqdm_enabled", "=", "self", ".", "args", "[", "\"tqdm_enabled\"", "]", "\n", ")", "\n", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "self", ".", "model_args", ".", "eval_batch_size", ")", "\n", "\n", "all_results", "=", "[", "]", "\n", "\n", "for", "batch", "in", "eval_dataloader", ":", "\n", "            ", "self", ".", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "self", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", ",", "\n", "}", "\n", "feature_indices", "=", "batch", "[", "3", "]", "\n", "outputs", "=", "self", ".", "model", "(", "**", "inputs", ")", "\n", "\n", "", "for", "i", ",", "feature_index", "in", "enumerate", "(", "feature_indices", ")", ":", "\n", "                ", "eval_feature", "=", "features", "[", "feature_index", ".", "item", "(", ")", "]", "\n", "unique_id", "=", "int", "(", "eval_feature", ".", "unique_id", ")", "\n", "\n", "output", "=", "[", "outputs", "[", "oname", "]", "[", "i", "]", "for", "oname", "in", "outputs", "]", "\n", "start_logits", "=", "outputs", ".", "start_logits", "[", "i", "]", "\n", "end_logits", "=", "outputs", ".", "end_logits", "[", "i", "]", "\n", "try", ":", "\n", "                    ", "start_logits", "=", "start_logits", ".", "item", "(", ")", "\n", "end_logits", "=", "end_logits", ".", "item", "(", ")", "\n", "", "except", ":", "\n", "                    ", "pass", "\n", "\n", "", "result", "=", "SquadResult", "(", "unique_id", ",", "start_logits", ",", "end_logits", ")", "\n", "all_results", ".", "append", "(", "result", ")", "\n", "\n", "", "", "answers", ",", "nbest", "=", "compute_predictions_logits", "(", "\n", "all_examples", "=", "examples", ",", "\n", "all_features", "=", "features", ",", "\n", "all_results", "=", "all_results", ",", "\n", "n_best_size", "=", "self", ".", "args", "[", "\"n_best_size\"", "]", ",", "\n", "max_answer_length", "=", "self", ".", "args", "[", "\"max_answer_length\"", "]", ",", "\n", "do_lower_case", "=", "self", ".", "args", "[", "\"do_lower_case\"", "]", ",", "\n", "output_prediction_file", "=", "self", ".", "args", "[", "\"output_prediction_file\"", "]", ",", "\n", "output_nbest_file", "=", "self", ".", "args", "[", "\"output_nbest_file\"", "]", ",", "\n", "output_null_log_odds_file", "=", "self", ".", "args", "[", "\"output_null_log_odds_file\"", "]", ",", "\n", "verbose_logging", "=", "self", ".", "args", "[", "\"verbose_logging\"", "]", ",", "\n", "version_2_with_negative", "=", "self", ".", "args", "[", "\"version_2_with_negative\"", "]", ",", "\n", "null_score_diff_threshold", "=", "self", ".", "args", "[", "\"null_score_diff_threshold\"", "]", ",", "\n", "tokenizer", "=", "self", ".", "tokenizer", ",", "\n", "language", "=", "question", ".", "language", "\n", ")", "\n", "\n", "all_answers", "=", "[", "]", "\n", "\n", "for", "idx", ",", "ans", "in", "enumerate", "(", "nbest", ")", ":", "\n", "            ", "all_answers", ".", "append", "(", "Answer", "(", "\n", "text", "=", "nbest", "[", "ans", "]", "[", "0", "]", "[", "\"text\"", "]", ",", "\n", "score", "=", "nbest", "[", "ans", "]", "[", "0", "]", "[", "\"start_logit\"", "]", "+", "nbest", "[", "ans", "]", "[", "0", "]", "[", "\"end_logit\"", "]", ",", "\n", "ctx_score", "=", "contexts", "[", "idx", "]", ".", "score", ",", "\n", "language", "=", "question", ".", "language", "\n", ")", ")", "\n", "", "return", "all_answers", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.reader.bert_reader.craft_squad_examples": [[15, 31], ["enumerate", "examples.append", "transformers.SquadExample"], "function", ["None"], ["def", "craft_squad_examples", "(", "question", ":", "Question", ",", "contexts", ":", "List", "[", "Context", "]", ")", "->", "List", "[", "SquadExample", "]", ":", "\n", "    ", "examples", "=", "[", "]", "\n", "for", "idx", ",", "ctx", "in", "enumerate", "(", "contexts", ")", ":", "\n", "        ", "examples", ".", "append", "(", "\n", "SquadExample", "(", "\n", "qas_id", "=", "idx", ",", "\n", "question_text", "=", "question", ".", "text", ",", "\n", "context_text", "=", "ctx", ".", "text", ",", "\n", "answer_text", "=", "None", ",", "\n", "start_position_character", "=", "None", ",", "\n", "title", "=", "\"\"", ",", "\n", "is_impossible", "=", "False", ",", "\n", "answers", "=", "[", "]", ",", "\n", ")", "\n", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.train.run_squad.set_seed": [[61, 67], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.train.run_squad.to_list": [[69, 71], ["tensor.detach().cpu().tolist", "tensor.detach().cpu", "tensor.detach"], "function", ["None"], ["", "", "def", "to_list", "(", "tensor", ")", ":", "\n", "    ", "return", "tensor", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.train.run_squad.train": [[73, 265], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "os.path.exists", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_squad.set_seed", "SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "os.path.isfile", "os.path.isfile", "transformers.AdamW.load_state_dict", "transformers.get_linear_schedule_with_warmup.load_state_dict", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "int", "tqdm.tqdm", "enumerate", "SummaryWriter.close", "os.path.join", "os.path.join", "torch.load", "torch.load", "int", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "tqdm.trange.close", "len", "os.path.join", "os.path.join", "ImportError", "torch.distributed.get_world_size", "[].split", "logger.info", "inputs.update", "loss.mean.mean", "loss.mean.backward", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "len", "len", "t.to", "inputs.update", "hasattr", "hasattr", "inputs.update", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "os.path.join", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "torch.save", "torch.save", "logger.info", "any", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "run_squad.evaluate", "evaluate.items", "hasattr", "os.path.join", "transformers.AdamW.state_dict", "os.path.join", "transformers.get_linear_schedule_with_warmup.state_dict", "os.path.join", "args.model_name_or_path.split", "SummaryWriter.add_scalar", "transformers.get_linear_schedule_with_warmup.get_lr", "torch.ones"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.train.run_squad.set_seed", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.train.run_squad.train", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.train.run_squad.evaluate"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "# Check if saved optimizer or scheduler states exist", "\n", "if", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", "and", "os", ".", "path", ".", "isfile", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", "\n", ")", ":", "\n", "# Load in optimizer and scheduler states", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", ")", "\n", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", ")", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\n", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "\n", "*", "args", ".", "gradient_accumulation_steps", "\n", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "1", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "# Check if continuing training from a checkpoint", "\n", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "model_name_or_path", ")", ":", "\n", "        ", "try", ":", "\n", "# set global_step to gobal_step of last saved checkpoint from model path", "\n", "            ", "checkpoint_suffix", "=", "args", ".", "model_name_or_path", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"/\"", ")", "[", "0", "]", "\n", "global_step", "=", "int", "(", "checkpoint_suffix", ")", "\n", "epochs_trained", "=", "global_step", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "steps_trained_in_current_epoch", "=", "global_step", "%", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "\n", "logger", ".", "info", "(", "\"  Continuing training from checkpoint, will skip to saved global_step\"", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from epoch %d\"", ",", "epochs_trained", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from global step %d\"", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\"  Will skip the first %d steps in the first epoch\"", ",", "steps_trained_in_current_epoch", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "logger", ".", "info", "(", "\"  Starting fine-tuning.\"", ")", "\n", "\n", "", "", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "\n", ")", "\n", "# Added here for reproductibility", "\n", "set_seed", "(", "args", ")", "\n", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "# Skip past any already trained steps if resuming training", "\n", "            ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "                ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", ",", "\n", "\"start_positions\"", ":", "batch", "[", "3", "]", ",", "\n", "\"end_positions\"", ":", "batch", "[", "4", "]", ",", "\n", "}", "\n", "\n", "if", "args", ".", "model_type", "in", "[", "\"xlm\"", ",", "\"roberta\"", ",", "\"distilbert\"", ",", "\"camembert\"", "]", ":", "\n", "                ", "del", "inputs", "[", "\"token_type_ids\"", "]", "\n", "\n", "", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", ",", "\"xlm\"", "]", ":", "\n", "                ", "inputs", ".", "update", "(", "{", "\"cls_index\"", ":", "batch", "[", "5", "]", ",", "\"p_mask\"", ":", "batch", "[", "6", "]", "}", ")", "\n", "if", "args", ".", "version_2_with_negative", ":", "\n", "                    ", "inputs", ".", "update", "(", "{", "\"is_impossible\"", ":", "batch", "[", "7", "]", "}", ")", "\n", "", "if", "hasattr", "(", "model", ",", "\"config\"", ")", "and", "hasattr", "(", "model", ".", "config", ",", "\"lang2id\"", ")", ":", "\n", "                    ", "inputs", ".", "update", "(", "\n", "{", "\"langs\"", ":", "(", "torch", ".", "ones", "(", "batch", "[", "0", "]", ".", "shape", ",", "dtype", "=", "torch", ".", "int64", ")", "*", "args", ".", "lang_id", ")", ".", "to", "(", "args", ".", "device", ")", "}", "\n", ")", "\n", "\n", "", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "# model outputs are always tuple in transformers (see doc)", "\n", "loss", "=", "outputs", "[", "0", "]", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel (not distributed) training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "# Log metrics", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "tb_writer", ".", "add_scalar", "(", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "", "tb_writer", ".", "add_scalar", "(", "\"lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"loss\"", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "# Save model checkpoint", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"checkpoint-{}\"", ".", "format", "(", "global_step", ")", ")", "\n", "# Take care of distributed/parallel training", "\n", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.train.run_squad.evaluate": [[267, 400], ["run_squad.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "timeit.default_timer", "tqdm.tqdm", "logger.info", "os.path.join", "os.path.join", "transformers.data.metrics.squad_metrics.squad_evaluate", "os.makedirs", "max", "torch.nn.DataParallel", "len", "torch.nn.DataParallel.eval", "tuple", "enumerate", "timeit.default_timer", "os.path.join", "transformers.data.metrics.squad_metrics.compute_predictions_log_probs", "transformers.data.metrics.squad_metrics.compute_predictions_logits", "os.path.exists", "isinstance", "torch.no_grad", "torch.nn.DataParallel.", "int", "all_results.append", "len", "hasattr", "hasattr", "t.to", "inputs.update", "run_squad.to_list", "len", "transformers.data.processors.squad.SquadResult", "transformers.data.processors.squad.SquadResult", "hasattr", "hasattr", "inputs.update", "feature_index.item", "torch.ones"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.train.run_squad.load_and_cache_examples", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.squad_evaluate", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.compute_predictions_log_probs", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.utils.utils_squad_metrics.compute_predictions_logits", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.train.run_squad.to_list"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "dataset", ",", "examples", ",", "features", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "True", ",", "output_examples", "=", "True", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", "and", "not", "isinstance", "(", "model", ",", "torch", ".", "nn", ".", "DataParallel", ")", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "\n", "all_results", "=", "[", "]", "\n", "start_time", "=", "timeit", ".", "default_timer", "(", ")", "\n", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "\n", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"token_type_ids\"", ":", "batch", "[", "2", "]", ",", "\n", "}", "\n", "\n", "if", "args", ".", "model_type", "in", "[", "\"xlm\"", ",", "\"roberta\"", ",", "\"distilbert\"", ",", "\"camembert\"", "]", ":", "\n", "                ", "del", "inputs", "[", "\"token_type_ids\"", "]", "\n", "\n", "", "feature_indices", "=", "batch", "[", "3", "]", "\n", "\n", "# XLNet and XLM use more arguments for their predictions", "\n", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", ",", "\"xlm\"", "]", ":", "\n", "                ", "inputs", ".", "update", "(", "{", "\"cls_index\"", ":", "batch", "[", "4", "]", ",", "\"p_mask\"", ":", "batch", "[", "5", "]", "}", ")", "\n", "# for lang_id-sensitive xlm models", "\n", "if", "hasattr", "(", "model", ",", "\"config\"", ")", "and", "hasattr", "(", "model", ".", "config", ",", "\"lang2id\"", ")", ":", "\n", "                    ", "inputs", ".", "update", "(", "\n", "{", "\"langs\"", ":", "(", "torch", ".", "ones", "(", "batch", "[", "0", "]", ".", "shape", ",", "dtype", "=", "torch", ".", "int64", ")", "*", "args", ".", "lang_id", ")", ".", "to", "(", "args", ".", "device", ")", "}", "\n", ")", "\n", "\n", "", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "", "for", "i", ",", "feature_index", "in", "enumerate", "(", "feature_indices", ")", ":", "\n", "            ", "eval_feature", "=", "features", "[", "feature_index", ".", "item", "(", ")", "]", "\n", "unique_id", "=", "int", "(", "eval_feature", ".", "unique_id", ")", "\n", "\n", "output", "=", "[", "to_list", "(", "output", "[", "i", "]", ")", "for", "output", "in", "outputs", "]", "\n", "\n", "# Some models (XLNet, XLM) use 5 arguments for their predictions, while the other \"simpler\"", "\n", "# models only use two.", "\n", "if", "len", "(", "output", ")", ">=", "5", ":", "\n", "                ", "start_logits", "=", "output", "[", "0", "]", "\n", "start_top_index", "=", "output", "[", "1", "]", "\n", "end_logits", "=", "output", "[", "2", "]", "\n", "end_top_index", "=", "output", "[", "3", "]", "\n", "cls_logits", "=", "output", "[", "4", "]", "\n", "\n", "result", "=", "SquadResult", "(", "\n", "unique_id", ",", "\n", "start_logits", ",", "\n", "end_logits", ",", "\n", "start_top_index", "=", "start_top_index", ",", "\n", "end_top_index", "=", "end_top_index", ",", "\n", "cls_logits", "=", "cls_logits", ",", "\n", ")", "\n", "\n", "", "else", ":", "\n", "                ", "start_logits", ",", "end_logits", "=", "output", "\n", "result", "=", "SquadResult", "(", "unique_id", ",", "start_logits", ",", "end_logits", ")", "\n", "\n", "", "all_results", ".", "append", "(", "result", ")", "\n", "\n", "", "", "evalTime", "=", "timeit", ".", "default_timer", "(", ")", "-", "start_time", "\n", "logger", ".", "info", "(", "\"  Evaluation done in total %f secs (%f sec per example)\"", ",", "evalTime", ",", "evalTime", "/", "len", "(", "dataset", ")", ")", "\n", "\n", "# Compute predictions", "\n", "output_prediction_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"predictions_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "output_nbest_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"nbest_predictions_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "\n", "if", "args", ".", "version_2_with_negative", ":", "\n", "        ", "output_null_log_odds_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"null_odds_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "", "else", ":", "\n", "        ", "output_null_log_odds_file", "=", "None", "\n", "\n", "# XLNet and XLM use a more complex post-processing procedure", "\n", "", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", ",", "\"xlm\"", "]", ":", "\n", "        ", "start_n_top", "=", "model", ".", "config", ".", "start_n_top", "if", "hasattr", "(", "model", ",", "\"config\"", ")", "else", "model", ".", "module", ".", "config", ".", "start_n_top", "\n", "end_n_top", "=", "model", ".", "config", ".", "end_n_top", "if", "hasattr", "(", "model", ",", "\"config\"", ")", "else", "model", ".", "module", ".", "config", ".", "end_n_top", "\n", "\n", "predictions", "=", "compute_predictions_log_probs", "(", "\n", "examples", ",", "\n", "features", ",", "\n", "all_results", ",", "\n", "args", ".", "n_best_size", ",", "\n", "args", ".", "max_answer_length", ",", "\n", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "\n", "output_null_log_odds_file", ",", "\n", "start_n_top", ",", "\n", "end_n_top", ",", "\n", "args", ".", "version_2_with_negative", ",", "\n", "tokenizer", ",", "\n", "args", ".", "verbose_logging", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "predictions", "=", "compute_predictions_logits", "(", "\n", "examples", ",", "\n", "features", ",", "\n", "all_results", ",", "\n", "args", ".", "n_best_size", ",", "\n", "args", ".", "max_answer_length", ",", "\n", "args", ".", "do_lower_case", ",", "\n", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "\n", "output_null_log_odds_file", ",", "\n", "args", ".", "verbose_logging", ",", "\n", "args", ".", "version_2_with_negative", ",", "\n", "args", ".", "null_score_diff_threshold", ",", "\n", "tokenizer", ",", "\n", ")", "\n", "\n", "# Compute the F1 and exact scores.", "\n", "", "results", "=", "squad_evaluate", "(", "examples", ",", "predictions", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.train.run_squad.load_and_cache_examples": [[401, 469], ["os.path.join", "torch.distributed.barrier", "os.path.exists", "logger.info", "torch.load", "logger.info", "transformers.squad_convert_examples_to_features", "torch.distributed.barrier", "list().pop", "str", "tfds.load", "transformers.data.processors.squad.SquadV1Processor().get_examples_from_dataset", "logger.info", "torch.save", "logger.warn", "transformers.data.processors.squad.SquadV2Processor", "transformers.data.processors.squad.SquadV1Processor", "processor.get_dev_examples", "processor.get_train_examples", "list", "ImportError", "transformers.data.processors.squad.SquadV1Processor", "filter", "args.model_name_or_path.split"], "function", ["None"], ["", "def", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ",", "output_examples", "=", "False", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "and", "not", "evaluate", ":", "\n", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "# Load data features from cache or dataset file", "\n", "", "input_dir", "=", "args", ".", "data_dir", "if", "args", ".", "data_dir", "else", "\".\"", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "\n", "input_dir", ",", "\n", "\"cached_{}_{}_{}\"", ".", "format", "(", "\n", "\"dev\"", "if", "evaluate", "else", "\"train\"", ",", "\n", "list", "(", "filter", "(", "None", ",", "args", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ",", "\n", ")", ",", "\n", ")", "\n", "\n", "# Init features and dataset from cache if it exists", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "features_and_dataset", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "features", ",", "dataset", ",", "examples", "=", "(", "\n", "features_and_dataset", "[", "\"features\"", "]", ",", "\n", "features_and_dataset", "[", "\"dataset\"", "]", ",", "\n", "features_and_dataset", "[", "\"examples\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "input_dir", ")", "\n", "\n", "if", "not", "args", ".", "data_dir", "and", "(", "(", "evaluate", "and", "not", "args", ".", "predict_file", ")", "or", "(", "not", "evaluate", "and", "not", "args", ".", "train_file", ")", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "import", "tensorflow_datasets", "as", "tfds", "\n", "", "except", "ImportError", ":", "\n", "                ", "raise", "ImportError", "(", "\"If not data_dir is specified, tensorflow_datasets needs to be installed.\"", ")", "\n", "\n", "", "if", "args", ".", "version_2_with_negative", ":", "\n", "                ", "logger", ".", "warn", "(", "\"tensorflow_datasets does not handle version 2 of SQuAD.\"", ")", "\n", "\n", "", "tfds_examples", "=", "tfds", ".", "load", "(", "\"squad\"", ")", "\n", "examples", "=", "SquadV1Processor", "(", ")", ".", "get_examples_from_dataset", "(", "tfds_examples", ",", "evaluate", "=", "evaluate", ")", "\n", "", "else", ":", "\n", "            ", "processor", "=", "SquadV2Processor", "(", ")", "if", "args", ".", "version_2_with_negative", "else", "SquadV1Processor", "(", ")", "\n", "if", "evaluate", ":", "\n", "                ", "examples", "=", "processor", ".", "get_dev_examples", "(", "args", ".", "data_dir", ",", "filename", "=", "args", ".", "predict_file", ")", "\n", "", "else", ":", "\n", "                ", "examples", "=", "processor", ".", "get_train_examples", "(", "args", ".", "data_dir", ",", "filename", "=", "args", ".", "train_file", ")", "\n", "\n", "", "", "features", ",", "dataset", "=", "squad_convert_examples_to_features", "(", "\n", "examples", "=", "examples", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "max_seq_length", "=", "args", ".", "max_seq_length", ",", "\n", "doc_stride", "=", "args", ".", "doc_stride", ",", "\n", "max_query_length", "=", "args", ".", "max_query_length", ",", "\n", "is_training", "=", "not", "evaluate", ",", "\n", "return_dataset", "=", "\"pt\"", ",", "\n", "threads", "=", "args", ".", "threads", ",", "\n", ")", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "{", "\"features\"", ":", "features", ",", "\"dataset\"", ":", "dataset", ",", "\"examples\"", ":", "examples", "}", ",", "cached_features_file", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", "and", "not", "evaluate", ":", "\n", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "if", "output_examples", ":", "\n", "        ", "return", "dataset", ",", "examples", ",", "features", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.train.run_squad.main": [[471, 816], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "logging.basicConfig", "logger.warning", "run_squad.set_seed", "parser.parse_args.model_type.lower", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForQuestionAnswering.from_pretrained", "AutoModelForQuestionAnswering.from_pretrained.to", "logger.info", "logger.info", "logger.warning", "os.path.exists", "os.listdir", "ValueError", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.distributed.barrier", "torch.distributed.barrier", "run_squad.load_and_cache_examples", "run_squad.train", "logger.info", "logger.info", "model_to_save.save_pretrained", "AutoTokenizer.from_pretrained.save_pretrained", "torch.save", "transformers.AutoModelForQuestionAnswering.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "AutoModelForQuestionAnswering.from_pretrained.to", "logger.info", "torch.cuda.device_count", "bool", "apex.amp.register_half_function", "hasattr", "os.path.join", "logger.info", "logger.info", "transformers.AutoModelForQuestionAnswering.from_pretrained", "AutoModelForQuestionAnswering.from_pretrained.to", "run_squad.evaluate", "dict", "results.update", "ImportError", "torch.distributed.get_rank", "list", "logging.getLogger().setLevel", "torch.cuda.is_available", "len", "checkpoint.split", "os.path.dirname", "logging.getLogger", "dict.items", "sorted", "glob.glob"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.train.run_squad.set_seed", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.train.run_squad.load_and_cache_examples", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.train.run_squad.train", "home.repos.pwc.inspect_result.rsvp-ai_bertserini.train.run_squad.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_TYPES", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pretrained model or model identifier from huggingface.co/models\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model checkpoints and predictions will be written.\"", ",", "\n", ")", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The input data dir. Should contain the .json files for the task.\"", "\n", "+", "\"If no data dir or train/predict files are specified, will run with tensorflow_datasets.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The input training file. If a data dir is specified, will look for the file there\"", "\n", "+", "\"If no data dir or train/predict files are specified, will run with tensorflow_datasets.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--predict_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The input evaluation file. If a data dir is specified, will look for the file there\"", "\n", "+", "\"If no data dir or train/predict files are specified, will run with tensorflow_datasets.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "\"\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--version_2_with_negative\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, the SQuAD examples contain some that do not have an answer.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--null_score_diff_threshold\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.0", ",", "\n", "help", "=", "\"If null_score - best_non_null is greater than the threshold predict null.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_seq_length\"", ",", "\n", "default", "=", "384", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after WordPiece tokenization. Sequences \"", "\n", "\"longer than this will be truncated, and sequences shorter than this will be padded.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--doc_stride\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"When splitting up a long document into chunks, how much stride to take between chunks.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_query_length\"", ",", "\n", "default", "=", "64", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum number of tokens for the question. Questions longer than this will \"", "\n", "\"be truncated to this length.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Run evaluation during training at each logging step.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--do_lower_case\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Set this flag if you are using an uncased model.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--n_best_size\"", ",", "\n", "default", "=", "20", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The total number of n-best predictions to generate in the nbest_predictions.json output file.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_answer_length\"", ",", "\n", "default", "=", "30", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum length of an answer that can be generated. This is needed because the start \"", "\n", "\"and end predictions are not conditioned on one another.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--verbose_logging\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, all of the warnings related to data processing will be printed. \"", "\n", "\"A number of warnings are expected for a normal SQuAD evaluation.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lang_id\"", ",", "\n", "default", "=", "0", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"language id of input for language-specific xlm models (see tokenization_xlm.PRETRAINED_INIT_CONFIGURATION)\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_all_checkpoints\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether not to use CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_output_dir\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the content of the output directory\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"local_rank for distributed training on gpus\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_ip\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"Can be used for distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--server_port\"", ",", "type", "=", "str", ",", "default", "=", "\"\"", ",", "help", "=", "\"Can be used for distant debugging.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--threads\"", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "\"multiple threads for converting example to features\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "args", ".", "doc_stride", ">=", "args", ".", "max_seq_length", "-", "args", ".", "max_query_length", ":", "\n", "        ", "logger", ".", "warning", "(", "\n", "\"WARNING - You've set a doc stride which may be superior to the document length in some \"", "\n", "\"examples. This could result in errors when building features from the examples. Please reduce the doc \"", "\n", "\"stride or increase the maximum length to ensure the features are correctly built.\"", "\n", ")", "\n", "\n", "", "if", "(", "\n", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "\n", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "\n", "and", "args", ".", "do_train", "\n", "and", "not", "args", ".", "overwrite_output_dir", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", "\n", ")", "\n", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "# Make sure only the first process in distributed training will download model & vocab", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "model", "=", "AutoModelForQuestionAnswering", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ",", "\n", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "# Make sure only the first process in distributed training will download model & vocab", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Before we do anything with models, we want to ensure that we get fp16 execution of torch.einsum if args.fp16 is set.", "\n", "# Otherwise it'll default to \"promote\" mode, and we'll get fp32 operations. Note that running `--fp16_opt_level=\"O2\"` will", "\n", "# remove the need for this code, but it is still valid.", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "import", "apex", "\n", "\n", "apex", ".", "amp", ".", "register_half_function", "(", "torch", ",", "\"einsum\"", ")", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "\n", "# Training", "\n", "", "", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ",", "output_examples", "=", "False", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Save the trained model and the tokenizer", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "# Take care of distributed/parallel training", "\n", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "model", "=", "AutoModelForQuestionAnswering", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "# , force_download=True)", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Evaluation - we can ask to evaluate all the checkpoints (sub-directories) in a directory", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "if", "args", ".", "do_train", ":", "\n", "            ", "logger", ".", "info", "(", "\"Loading checkpoints saved during training for evaluation\"", ")", "\n", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "                ", "checkpoints", "=", "list", "(", "\n", "os", ".", "path", ".", "dirname", "(", "c", ")", "\n", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "\"/**/\"", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", "\n", ")", "\n", "logging", ".", "getLogger", "(", "\"transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce model loading logs", "\n", "", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"Loading checkpoint %s for evaluation\"", ",", "args", ".", "model_name_or_path", ")", "\n", "checkpoints", "=", "[", "args", ".", "model_name_or_path", "]", "\n", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "# Reload the model", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "model", "=", "AutoModelForQuestionAnswering", ".", "from_pretrained", "(", "checkpoint", ")", "# , force_download=True)", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "# Evaluate", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "global_step", ")", "\n", "\n", "result", "=", "dict", "(", "(", "k", "+", "(", "\"_{}\"", ".", "format", "(", "global_step", ")", "if", "global_step", "else", "\"\"", ")", ",", "v", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"Results: {}\"", ".", "format", "(", "results", ")", ")", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.retriever.pyserini_retriever.build_searcher": [[12, 28], ["pyserini.search.lucene.LuceneSearcher", "pyserini.search.FaissSearcher.set_bm25", "pyserini.search.FaissSearcher.object.setLanguage", "pyserini.search.DprQueryEncoder", "pyserini.search.FaissSearcher", "pyserini.search.lucene.LuceneSearcher", "Exception"], "function", ["None"], ["def", "build_searcher", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "retriever", "==", "\"bm25\"", ":", "\n", "        ", "searcher", "=", "LuceneSearcher", "(", "args", ".", "index_path", ")", "\n", "searcher", ".", "set_bm25", "(", "args", ".", "k1", ",", "args", ".", "b", ")", "\n", "searcher", ".", "object", ".", "setLanguage", "(", "args", ".", "language", ")", "\n", "", "elif", "args", ".", "retriever", "==", "\"dpr\"", ":", "\n", "        ", "query_encoder", "=", "DprQueryEncoder", "(", "\n", "encoder_dir", "=", "args", ".", "encoder", ",", "\n", "tokenizer_name", "=", "args", ".", "query_tokenizer_name", ",", "\n", "device", "=", "args", ".", "device", ")", "\n", "searcher", "=", "FaissSearcher", "(", "args", ".", "index_path", ",", "query_encoder", ")", "\n", "ssearcher", "=", "LuceneSearcher", "(", "args", ".", "sparse_index", ")", "\n", "searcher", ".", "ssearcher", "=", "ssearcher", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"Non-Defined Retriever:\"", ",", "args", ".", "retriever", ")", "\n", "", "return", "searcher", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.retriever.pyserini_retriever.build_searcher_from_prebuilt_index": [[29, 37], ["pyserini.search.lucene.LuceneSearcher.from_prebuilt_index", "LuceneSearcher.from_prebuilt_index.set_bm25", "LuceneSearcher.from_prebuilt_index.object.setLanguage", "Exception"], "function", ["None"], ["", "def", "build_searcher_from_prebuilt_index", "(", "args", ")", ":", "\n", "    ", "if", "args", ".", "retriever", "==", "\"bm25\"", ":", "\n", "        ", "searcher", "=", "LuceneSearcher", ".", "from_prebuilt_index", "(", "args", ".", "index_path", ")", "\n", "searcher", ".", "set_bm25", "(", "args", ".", "k1", ",", "args", ".", "b", ")", "\n", "searcher", ".", "object", ".", "setLanguage", "(", "args", ".", "language", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"Not implemented regriever from prebuilt index:\"", ",", "args", ".", "retirever", ")", "\n", "", "return", "searcher", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.retriever.pyserini_retriever.retriever": [[39, 58], ["pyserini_retriever.hits_to_contexts", "type", "searcher.search", "searcher.doc().get", "searcher.search.append", "searcher.search", "searcher.search", "logger.error", "searcher.doc", "question.text.encode"], "function", ["home.repos.pwc.inspect_result.rsvp-ai_bertserini.retriever.pyserini_retriever.hits_to_contexts"], ["", "def", "retriever", "(", "question", ",", "searcher", ",", "para_num", "=", "20", ")", ":", "\n", "    ", "language", "=", "question", ".", "language", "\n", "if", "type", "(", "searcher", ")", "==", "FaissSearcher", ":", "\n", "        ", "results", "=", "searcher", ".", "search", "(", "question", ".", "text", ",", "k", "=", "para_num", ")", "\n", "hits", "=", "[", "]", "\n", "for", "r", "in", "results", ":", "\n", "            ", "hit", "=", "searcher", ".", "doc", "(", "r", ".", "docid", ")", ".", "get", "(", "\"raw\"", ")", "\n", "hits", ".", "append", "(", "(", "hit", ",", "r", ".", "score", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "try", ":", "\n", "            ", "if", "language", "==", "\"zh\"", ":", "\n", "                ", "hits", "=", "searcher", ".", "search", "(", "question", ".", "text", ".", "encode", "(", "\"utf-8\"", ")", ",", "k", "=", "para_num", ")", "\n", "", "else", ":", "\n", "                ", "hits", "=", "searcher", ".", "search", "(", "question", ".", "text", ",", "k", "=", "para_num", ")", "\n", "", "", "except", "ValueError", "as", "e", ":", "\n", "            ", "logger", ".", "error", "(", "\"Search failure: {}, {}\"", ".", "format", "(", "question", ".", "text", ",", "e", ")", ")", "\n", "return", "[", "]", "\n", "", "hits", "=", "[", "(", "h", ".", "raw", ",", "h", ".", "score", ")", "for", "h", "in", "hits", "]", "\n", "", "return", "hits_to_contexts", "(", "hits", ",", "language", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.rsvp-ai_bertserini.retriever.pyserini_retriever.hits_to_contexts": [[60, 91], ["range", "len", "contexts.append", "bertserini.reader.base.Context", "json.loads"], "function", ["None"], ["", "def", "hits_to_contexts", "(", "hits", ":", "List", "[", "JLuceneSearcherResult", "]", ",", "language", "=", "\"en\"", ",", "field", "=", "'raw'", ",", "blacklist", "=", "[", "]", ")", "->", "List", "[", "Context", "]", ":", "\n", "    ", "\"\"\"\n        Converts hits from Pyserini into a list of texts.\n        Parameters\n        ----------\n        hits : List[JLuceneSearcherResult]\n            The hits.\n        field : str\n            Field to use.\n        language : str\n            Language of corpus\n        blacklist : List[str]\n            strings that should not contained\n        Returns\n        -------\n        List[Text]\n            List of texts.\n     \"\"\"", "\n", "contexts", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "len", "(", "hits", ")", ")", ":", "\n", "        ", "hit", ",", "score", "=", "hits", "[", "i", "]", "\n", "try", ":", "# the previous chinese index stores the contents as \"raw\", while the english index stores the json string.", "\n", "            ", "t", "=", "json", ".", "loads", "(", "hit", ")", "[", "\"contents\"", "]", "\n", "", "except", ":", "\n", "            ", "t", "=", "hit", "\n", "", "for", "s", "in", "blacklist", ":", "\n", "            ", "if", "s", "in", "t", ":", "\n", "                ", "continue", "\n", "", "", "metadata", "=", "{", "}", "\n", "contexts", ".", "append", "(", "Context", "(", "t", ",", "language", ",", "metadata", ",", "score", ")", ")", "\n", "", "return", "contexts", "\n", "", ""]]}