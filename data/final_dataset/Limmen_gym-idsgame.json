{"home.repos.pwc.inspect_result.Limmen_gym-idsgame.it_tests.run.default_output_dir": [[14, 17], ["os.path.dirname"], "function", ["None"], ["def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.it_tests.run.test_sim_attack_maximal_vs_defend_minimal": [[19, 26], ["gym_idsgame.simulation.dao.simulation_config.SimulationConfig", "gym_idsgame.config.client_config.ClientConfig", "gym_idsgame.runnner.Runner.run", "str", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.it_tests.run.test_sim_attack_maximal_vs_random": [[28, 35], ["gym_idsgame.simulation.dao.simulation_config.SimulationConfig", "gym_idsgame.config.client_config.ClientConfig", "gym_idsgame.runnner.Runner.run", "str", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "test_sim_attack_maximal_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.it_tests.run.test_sim_random_vs_defend_minimal": [[37, 44], ["gym_idsgame.simulation.dao.simulation_config.SimulationConfig", "gym_idsgame.config.client_config.ClientConfig", "gym_idsgame.runnner.Runner.run", "str", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.it_tests.run.test_sim_random_vs_random": [[46, 54], ["gym_idsgame.simulation.dao.simulation_config.SimulationConfig", "gym_idsgame.config.client_config.ClientConfig", "gym_idsgame.runnner.Runner.run", "str", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.it_tests.run.test_train_maximal_attack_tabular_q_learning": [[56, 63], ["gym_idsgame.agents.training_agents.q_learning.q_agent_config.QAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "gym_idsgame.runnner.Runner.run", "str", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.it_tests.run.test_train_minimal_defense_tabular_q_learning": [[65, 72], ["gym_idsgame.agents.training_agents.q_learning.q_agent_config.QAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "gym_idsgame.runnner.Runner.run", "str", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.it_tests.run.test_train_random_attack_tabular_q_learning": [[74, 81], ["gym_idsgame.agents.training_agents.q_learning.q_agent_config.QAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "gym_idsgame.runnner.Runner.run", "str", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.it_tests.run.test_train_random_defense_tabular_q_learning": [[83, 90], ["gym_idsgame.agents.training_agents.q_learning.q_agent_config.QAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "gym_idsgame.runnner.Runner.run", "str", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.it_tests.run.test_train_tabular_q_learning_tabular_q_learning": [[91, 99], ["gym_idsgame.agents.training_agents.q_learning.q_agent_config.QAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "gym_idsgame.runnner.Runner.run", "str", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER_AND_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v2.plot_summary.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v2.plot_summary.default_output_dir": [[15, 21], ["plot_summary.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v2.plot_summary.default_config_path": [[23, 29], ["os.path.join", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "default_config_path", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default path to configuration file\n    \"\"\"", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./config.json'", ")", "\n", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v2.plot_summary.plot_summary": [[31, 96], ["experiments.util.plotting_util.plot_all_averages", "plot_summary.default_output_dir", "maximal_attack_train_csv_paths.append", "maximal_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths.append", "minimal_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths.append", "random_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths.append", "random_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths.append", "two_agents_eval_csv_paths.append", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "plot_summary.default_output_dir", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "plot_summary", "(", "algorithm", ":", "str", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ")", ":", "\n", "    ", "seeds", "=", "[", "0", ",", "999", ",", "299", ",", "399", ",", "499", "]", "\n", "base_dir", "=", "default_output_dir", "(", ")", "\n", "try", ":", "\n", "# V0", "\n", "        ", "maximal_attack_train_csv_paths_v0", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v0", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v0", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v0", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v0", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v0", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v0", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v0", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v0", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v0", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v0", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v0", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v0", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v0", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v0", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "\n", "# V2", "\n", "\n", "", "maximal_attack_train_csv_paths_v2", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v2.plot_summary.plot": [[98, 125], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "pandas.read_csv", "plot_summary.plot_summary", "pandas.read_csv", "plot_summary.plot_summary", "glob.glob", "int", "int", "print", "print", "glob.glob", "int", "int", "print", "print", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "str", "str", "plot_summary.default_output_dir", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v2", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v2", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v2", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v2", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v2", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v2", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v2", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v2", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.attack_maximal_vs_random.run.default_output_dir": [[10, 16], ["os.path.dirname"], "function", ["None"], ["from", "gym_idsgame", ".", "agents", ".", "training_agents", ".", "q_learning", ".", "q_agent_config", "import", "QAgentConfig", "\n", "from", "gym_idsgame", ".", "runnner", "import", "Runner", "\n", "\n", "\n", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.attack_maximal_vs_random.run.default_config_path": [[18, 24], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.attack_maximal_vs_random.run.default_config": [[26, 39], ["gym_idsgame.simulation.dao.simulation_config.SimulationConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\n", "\n", "", "def", "test_sim_attack_maximal_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.attack_maximal_vs_random.run.write_default_config": [[41, 52], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.attack_maximal_vs_random.run.plot_csv": [[54, 69], ["experiments.util.plotting_util.read_data", "experiments.util.plotting_util.plot_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_results"], ["\n", "\n", "", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.random_vs_defend_minimal.run.default_output_dir": [[10, 16], ["os.path.dirname"], "function", ["None"], ["from", "gym_idsgame", ".", "agents", ".", "training_agents", ".", "q_learning", ".", "q_agent_config", "import", "QAgentConfig", "\n", "from", "gym_idsgame", ".", "runnner", "import", "Runner", "\n", "\n", "\n", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.random_vs_defend_minimal.run.default_config_path": [[18, 24], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.random_vs_defend_minimal.run.default_config": [[26, 39], ["gym_idsgame.simulation.dao.simulation_config.SimulationConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\n", "\n", "", "def", "test_sim_attack_maximal_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.random_vs_defend_minimal.run.write_default_config": [[41, 52], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.random_vs_defend_minimal.run.plot_csv": [[54, 69], ["experiments.util.plotting_util.read_data", "experiments.util.plotting_util.plot_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_results"], ["\n", "\n", "", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.random_vs_random.run.default_output_dir": [[10, 16], ["os.path.dirname"], "function", ["None"], ["from", "gym_idsgame", ".", "agents", ".", "training_agents", ".", "q_learning", ".", "q_agent_config", "import", "QAgentConfig", "\n", "from", "gym_idsgame", ".", "runnner", "import", "Runner", "\n", "\n", "\n", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.random_vs_random.run.default_config_path": [[18, 24], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.random_vs_random.run.default_config": [[26, 39], ["gym_idsgame.simulation.dao.simulation_config.SimulationConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\n", "\n", "", "def", "test_sim_attack_maximal_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.random_vs_random.run.write_default_config": [[41, 52], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.random_vs_random.run.plot_csv": [[54, 69], ["experiments.util.plotting_util.read_data", "experiments.util.plotting_util.plot_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_results"], ["\n", "\n", "", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.attack_maximal_vs_defend_minimal.run.default_output_dir": [[10, 16], ["os.path.dirname"], "function", ["None"], ["from", "gym_idsgame", ".", "agents", ".", "training_agents", ".", "q_learning", ".", "q_agent_config", "import", "QAgentConfig", "\n", "from", "gym_idsgame", ".", "runnner", "import", "Runner", "\n", "\n", "\n", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.attack_maximal_vs_defend_minimal.run.default_config_path": [[18, 24], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.attack_maximal_vs_defend_minimal.run.default_config": [[26, 39], ["gym_idsgame.simulation.dao.simulation_config.SimulationConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\n", "\n", "", "def", "test_sim_attack_maximal_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.attack_maximal_vs_defend_minimal.run.write_default_config": [[41, 52], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.attack_maximal_vs_defend_minimal.run.plot_csv": [[54, 69], ["experiments.util.plotting_util.read_data", "experiments.util.plotting_util.plot_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_results"], ["\n", "\n", "", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v3.plot_summary.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v3.plot_summary.default_output_dir": [[15, 21], ["plot_summary.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v3.plot_summary.default_config_path": [[23, 29], ["os.path.join", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "default_config_path", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default path to configuration file\n    \"\"\"", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./config.json'", ")", "\n", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v3.plot_summary.plot_summary": [[31, 96], ["experiments.util.plotting_util.plot_all_averages", "plot_summary.default_output_dir", "maximal_attack_train_csv_paths.append", "maximal_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths.append", "minimal_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths.append", "random_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths.append", "random_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths.append", "two_agents_eval_csv_paths.append", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "plot_summary.default_output_dir", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "plot_summary", "(", "algorithm", ":", "str", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ")", ":", "\n", "    ", "seeds", "=", "[", "0", ",", "999", ",", "299", ",", "399", ",", "499", "]", "\n", "base_dir", "=", "default_output_dir", "(", ")", "\n", "try", ":", "\n", "# V0", "\n", "        ", "maximal_attack_train_csv_paths_v0", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v0", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v0", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v0", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v0", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v0", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v0", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v0", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v0", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v0", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v0", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v0", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v0", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v0", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v0", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "\n", "# V2", "\n", "\n", "", "maximal_attack_train_csv_paths_v2", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v3.plot_summary.plot": [[98, 125], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "pandas.read_csv", "plot_summary.plot_summary", "pandas.read_csv", "plot_summary.plot_summary", "glob.glob", "int", "int", "print", "print", "glob.glob", "int", "int", "print", "print", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "str", "str", "plot_summary.default_output_dir", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v2", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v2", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v2", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v2", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v2", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v2", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v2", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v2", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_agent_vs_tabular_q_agent.run.default_output_dir": [[12, 18], ["os.path.dirname"], "function", ["None"], ["\n", "\n", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_agent_vs_tabular_q_agent.run.default_config_path": [[20, 26], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_agent_vs_tabular_q_agent.run.default_config": [[28, 46], ["gym_idsgame.simulation.dao.simulation_config.SimulationConfig", "gym_idsgame.agents.training_agents.q_learning.q_agent_config.QAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "test_sim_attack_maximal_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_agent_vs_tabular_q_agent.run.write_default_config": [[48, 59], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_agent_vs_tabular_q_agent.run.plot_csv": [[61, 76], ["experiments.util.plotting_util.read_data", "experiments.util.plotting_util.plot_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_results"], ["q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_attack-v\"", "+", "str", "(", "version", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v0.plot_summary.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v0.plot_summary.default_output_dir": [[15, 21], ["plot_summary.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v0.plot_summary.default_config_path": [[23, 29], ["os.path.join", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "default_config_path", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default path to configuration file\n    \"\"\"", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./config.json'", ")", "\n", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v0.plot_summary.plot_summary": [[31, 96], ["experiments.util.plotting_util.plot_all_averages", "plot_summary.default_output_dir", "maximal_attack_train_csv_paths.append", "maximal_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths.append", "minimal_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths.append", "random_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths.append", "random_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths.append", "two_agents_eval_csv_paths.append", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "plot_summary.default_output_dir", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "plot_summary", "(", "algorithm", ":", "str", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ")", ":", "\n", "    ", "seeds", "=", "[", "0", ",", "999", ",", "299", ",", "399", ",", "499", "]", "\n", "base_dir", "=", "default_output_dir", "(", ")", "\n", "try", ":", "\n", "# V0", "\n", "        ", "maximal_attack_train_csv_paths_v0", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v0", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v0", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v0", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v0", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v0", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v0", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v0", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v0", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v0", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v0", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v0", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v0", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v0", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v0", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "\n", "# V2", "\n", "\n", "", "maximal_attack_train_csv_paths_v2", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v0.plot_summary.plot": [[98, 125], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "pandas.read_csv", "plot_summary.plot_summary", "pandas.read_csv", "plot_summary.plot_summary", "glob.glob", "int", "int", "print", "print", "glob.glob", "int", "int", "print", "print", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "str", "str", "plot_summary.default_output_dir", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v2", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v2", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v2", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v2", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v2", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v2", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v2", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v2", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_agent_vs_random.run.default_output_dir": [[11, 17], ["os.path.dirname"], "function", ["None"], ["from", "gym_idsgame", ".", "runnner", "import", "Runner", "\n", "\n", "\n", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_agent_vs_random.run.default_config_path": [[19, 25], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_agent_vs_random.run.default_config": [[27, 43], ["gym_idsgame.simulation.dao.simulation_config.SimulationConfig", "gym_idsgame.agents.training_agents.q_learning.q_agent_config.QAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\n", "", "def", "test_sim_attack_maximal_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_agent_vs_random.run.write_default_config": [[45, 56], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_agent_vs_random.run.plot_csv": [[58, 73], ["experiments.util.plotting_util.read_data", "experiments.util.plotting_util.plot_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_results"], ["env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.random_vs_tabular_q_agent.run.default_output_dir": [[11, 17], ["os.path.dirname"], "function", ["None"], ["from", "gym_idsgame", ".", "runnner", "import", "Runner", "\n", "\n", "\n", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.random_vs_tabular_q_agent.run.default_config_path": [[19, 25], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.random_vs_tabular_q_agent.run.default_config": [[27, 43], ["gym_idsgame.simulation.dao.simulation_config.SimulationConfig", "gym_idsgame.agents.training_agents.q_learning.q_agent_config.QAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\n", "", "def", "test_sim_attack_maximal_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.random_vs_tabular_q_agent.run.write_default_config": [[45, 56], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.random_vs_tabular_q_agent.run.plot_csv": [[58, 73], ["experiments.util.plotting_util.read_data", "experiments.util.plotting_util.plot_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_results"], ["env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v1.plot_summary.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v1.plot_summary.default_output_dir": [[15, 21], ["plot_summary.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v1.plot_summary.default_config_path": [[23, 29], ["os.path.join", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "default_config_path", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default path to configuration file\n    \"\"\"", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./config.json'", ")", "\n", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v1.plot_summary.plot_summary": [[31, 96], ["experiments.util.plotting_util.plot_all_averages", "plot_summary.default_output_dir", "maximal_attack_train_csv_paths.append", "maximal_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths.append", "minimal_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths.append", "random_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths.append", "random_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths.append", "two_agents_eval_csv_paths.append", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "plot_summary.default_output_dir", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "plot_summary", "(", "algorithm", ":", "str", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ")", ":", "\n", "    ", "seeds", "=", "[", "0", ",", "999", ",", "299", ",", "399", ",", "499", "]", "\n", "base_dir", "=", "default_output_dir", "(", ")", "\n", "try", ":", "\n", "# V0", "\n", "        ", "maximal_attack_train_csv_paths_v0", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v0", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v0", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v0", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v0", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v0", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v0", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v0", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v0", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v0", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v0", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v0", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v0", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v0", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v0", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "\n", "# V2", "\n", "\n", "", "maximal_attack_train_csv_paths_v2", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v1.plot_summary.plot": [[98, 125], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "pandas.read_csv", "plot_summary.plot_summary", "pandas.read_csv", "plot_summary.plot_summary", "glob.glob", "int", "int", "print", "print", "glob.glob", "int", "int", "print", "print", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "str", "str", "plot_summary.default_output_dir", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v2", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v2", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v2", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v2", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v2", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v2", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v2", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v2", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_agent_vs_defend_minimal.run.default_output_dir": [[12, 18], ["os.path.dirname"], "function", ["None"], ["\n", "\n", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_agent_vs_defend_minimal.run.default_config_path": [[20, 26], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_agent_vs_defend_minimal.run.default_config": [[28, 44], ["gym_idsgame.simulation.dao.simulation_config.SimulationConfig", "gym_idsgame.agents.training_agents.q_learning.q_agent_config.QAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "test_sim_attack_maximal_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_agent_vs_defend_minimal.run.write_default_config": [[46, 57], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_agent_vs_defend_minimal.run.plot_csv": [[59, 74], ["experiments.util.plotting_util.read_data", "experiments.util.plotting_util.plot_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_results"], ["client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v14.plot_summary.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v14.plot_summary.default_output_dir": [[15, 21], ["plot_summary.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v14.plot_summary.default_config_path": [[23, 29], ["os.path.join", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "default_config_path", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default path to configuration file\n    \"\"\"", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./config.json'", ")", "\n", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v14.plot_summary.plot_summary": [[31, 96], ["experiments.util.plotting_util.plot_all_averages", "plot_summary.default_output_dir", "maximal_attack_train_csv_paths.append", "maximal_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths.append", "minimal_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths.append", "random_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths.append", "random_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths.append", "two_agents_eval_csv_paths.append", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "plot_summary.default_output_dir", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "plot_summary", "(", "algorithm", ":", "str", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ")", ":", "\n", "    ", "seeds", "=", "[", "0", ",", "999", ",", "299", ",", "399", ",", "499", "]", "\n", "base_dir", "=", "default_output_dir", "(", ")", "\n", "try", ":", "\n", "# V0", "\n", "        ", "maximal_attack_train_csv_paths_v0", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v0", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v0", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v0", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v0", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v0", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v0", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v0", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v0", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v0", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v0", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v0", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v0", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v0", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v0", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "\n", "# V2", "\n", "\n", "", "maximal_attack_train_csv_paths_v2", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v14.plot_summary.plot": [[98, 125], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "pandas.read_csv", "plot_summary.plot_summary", "pandas.read_csv", "plot_summary.plot_summary", "glob.glob", "int", "int", "print", "print", "glob.glob", "int", "int", "print", "print", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "str", "str", "plot_summary.default_output_dir", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v2", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v2", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v2", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v2", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v2", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v2", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v2", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v2", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.manual_vs_reinforce.run.default_output_dir": [[9, 15], ["os.path.dirname"], "function", ["None"], ["from", "gym_idsgame", ".", "config", ".", "client_config", "import", "ClientConfig", "\n", "from", "gym_idsgame", ".", "agents", ".", "training_agents", ".", "q_learning", ".", "q_agent_config", "import", "QAgentConfig", "\n", "from", "gym_idsgame", ".", "runnner", "import", "Runner", "\n", "\n", "\n", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.manual_vs_reinforce.run.default_config_path": [[17, 23], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\n", "\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.manual_vs_reinforce.run.default_config": [[25, 55], ["gym_idsgame.agents.training_agents.policy_gradient.pg_agent_config.PolicyGradientAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.manual_vs_reinforce.run.write_default_config": [[57, 68], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v18.plot_summary.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v18.plot_summary.default_output_dir": [[15, 21], ["plot_summary.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v18.plot_summary.default_config_path": [[23, 29], ["os.path.join", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "default_config_path", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default path to configuration file\n    \"\"\"", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./config.json'", ")", "\n", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v18.plot_summary.plot_summary": [[31, 96], ["experiments.util.plotting_util.plot_all_averages", "plot_summary.default_output_dir", "maximal_attack_train_csv_paths.append", "maximal_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths.append", "minimal_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths.append", "random_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths.append", "random_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths.append", "two_agents_eval_csv_paths.append", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "plot_summary.default_output_dir", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "plot_summary", "(", "algorithm", ":", "str", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ")", ":", "\n", "    ", "seeds", "=", "[", "0", ",", "999", ",", "299", ",", "399", ",", "499", "]", "\n", "base_dir", "=", "default_output_dir", "(", ")", "\n", "try", ":", "\n", "# V0", "\n", "        ", "maximal_attack_train_csv_paths_v0", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v0", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v0", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v0", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v0", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v0", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v0", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v0", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v0", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v0", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v0", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v0", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v0", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v0", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v0", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "\n", "# V2", "\n", "\n", "", "maximal_attack_train_csv_paths_v2", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v18.plot_summary.plot": [[98, 125], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "pandas.read_csv", "plot_summary.plot_summary", "pandas.read_csv", "plot_summary.plot_summary", "glob.glob", "int", "int", "print", "print", "glob.glob", "int", "int", "print", "print", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "str", "str", "plot_summary.default_output_dir", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v2", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v2", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v2", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v2", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v2", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v2", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v2", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v2", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.random_vs_manual.run.default_output_dir": [[8, 14], ["os.path.dirname"], "function", ["None"], ["from", "gym_idsgame", ".", "agents", ".", "dao", ".", "agent_type", "import", "AgentType", "\n", "from", "gym_idsgame", ".", "config", ".", "client_config", "import", "ClientConfig", "\n", "from", "gym_idsgame", ".", "agents", ".", "training_agents", ".", "q_learning", ".", "q_agent_config", "import", "QAgentConfig", "\n", "from", "gym_idsgame", ".", "runnner", "import", "Runner", "\n", "\n", "\n", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.random_vs_manual.run.default_config_path": [[16, 22], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["return", "script_dir", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.random_vs_manual.run.default_config": [[24, 33], ["gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.random_vs_manual.run.write_default_config": [[35, 46], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["\n", "\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.maximal_vs_manual.run.default_output_dir": [[8, 14], ["os.path.dirname"], "function", ["None"], ["from", "gym_idsgame", ".", "agents", ".", "dao", ".", "agent_type", "import", "AgentType", "\n", "from", "gym_idsgame", ".", "config", ".", "client_config", "import", "ClientConfig", "\n", "from", "gym_idsgame", ".", "agents", ".", "training_agents", ".", "q_learning", ".", "q_agent_config", "import", "QAgentConfig", "\n", "from", "gym_idsgame", ".", "runnner", "import", "Runner", "\n", "\n", "\n", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.maximal_vs_manual.run.default_config_path": [[16, 22], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["return", "script_dir", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.maximal_vs_manual.run.default_config": [[24, 33], ["gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.maximal_vs_manual.run.write_default_config": [[35, 46], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["\n", "\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.manual_vs_openai_ppo.run.default_output_dir": [[9, 15], ["os.path.dirname"], "function", ["None"], ["from", "gym_idsgame", ".", "config", ".", "client_config", "import", "ClientConfig", "\n", "from", "gym_idsgame", ".", "agents", ".", "training_agents", ".", "q_learning", ".", "q_agent_config", "import", "QAgentConfig", "\n", "from", "gym_idsgame", ".", "runnner", "import", "Runner", "\n", "\n", "\n", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.manual_vs_openai_ppo.run.default_config_path": [[17, 23], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\n", "\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.manual_vs_openai_ppo.run.default_config": [[25, 64], ["gym_idsgame.agents.training_agents.policy_gradient.pg_agent_config.PolicyGradientAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.manual_vs_openai_ppo.run.write_default_config": [[66, 77], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.manual_vs_minimal_defense.run.default_output_dir": [[8, 14], ["os.path.dirname"], "function", ["None"], ["from", "gym_idsgame", ".", "agents", ".", "dao", ".", "agent_type", "import", "AgentType", "\n", "from", "gym_idsgame", ".", "config", ".", "client_config", "import", "ClientConfig", "\n", "from", "gym_idsgame", ".", "agents", ".", "training_agents", ".", "q_learning", ".", "q_agent_config", "import", "QAgentConfig", "\n", "from", "gym_idsgame", ".", "runnner", "import", "Runner", "\n", "\n", "\n", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.manual_vs_minimal_defense.run.default_config_path": [[16, 22], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["return", "script_dir", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.manual_vs_minimal_defense.run.default_config": [[24, 33], ["gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.manual_vs_minimal_defense.run.write_default_config": [[35, 46], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["\n", "\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v12.plot_summary.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v12.plot_summary.default_output_dir": [[15, 21], ["plot_summary.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v12.plot_summary.default_config_path": [[23, 29], ["os.path.join", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "default_config_path", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default path to configuration file\n    \"\"\"", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./config.json'", ")", "\n", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v12.plot_summary.plot_summary": [[31, 96], ["experiments.util.plotting_util.plot_all_averages", "plot_summary.default_output_dir", "maximal_attack_train_csv_paths.append", "maximal_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths.append", "minimal_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths.append", "random_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths.append", "random_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths.append", "two_agents_eval_csv_paths.append", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "plot_summary.default_output_dir", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "plot_summary", "(", "algorithm", ":", "str", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ")", ":", "\n", "    ", "seeds", "=", "[", "0", ",", "999", ",", "299", ",", "399", ",", "499", "]", "\n", "base_dir", "=", "default_output_dir", "(", ")", "\n", "try", ":", "\n", "# V0", "\n", "        ", "maximal_attack_train_csv_paths_v0", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v0", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v0", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v0", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v0", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v0", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v0", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v0", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v0", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v0", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v0", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v0", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v0", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v0", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v0", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "\n", "# V2", "\n", "\n", "", "maximal_attack_train_csv_paths_v2", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v12.plot_summary.plot": [[98, 125], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "pandas.read_csv", "plot_summary.plot_summary", "pandas.read_csv", "plot_summary.plot_summary", "glob.glob", "int", "int", "print", "print", "glob.glob", "int", "int", "print", "print", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "str", "str", "plot_summary.default_output_dir", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v2", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v2", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v2", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v2", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v2", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v2", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v2", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v2", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.manual_vs_random.run.default_output_dir": [[8, 14], ["os.path.dirname"], "function", ["None"], ["from", "gym_idsgame", ".", "agents", ".", "dao", ".", "agent_type", "import", "AgentType", "\n", "from", "gym_idsgame", ".", "config", ".", "client_config", "import", "ClientConfig", "\n", "from", "gym_idsgame", ".", "agents", ".", "training_agents", ".", "q_learning", ".", "q_agent_config", "import", "QAgentConfig", "\n", "from", "gym_idsgame", ".", "runnner", "import", "Runner", "\n", "\n", "\n", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.manual_vs_random.run.default_config_path": [[16, 22], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["return", "script_dir", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.manual_vs_random.run.default_config": [[24, 33], ["gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.manual_vs_random.run.write_default_config": [[35, 46], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["\n", "\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v11.plot_summary.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v11.plot_summary.default_output_dir": [[15, 21], ["plot_summary.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v11.plot_summary.default_config_path": [[23, 29], ["os.path.join", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "default_config_path", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default path to configuration file\n    \"\"\"", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./config.json'", ")", "\n", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v11.plot_summary.plot_summary": [[31, 96], ["experiments.util.plotting_util.plot_all_averages", "plot_summary.default_output_dir", "maximal_attack_train_csv_paths.append", "maximal_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths.append", "minimal_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths.append", "random_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths.append", "random_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths.append", "two_agents_eval_csv_paths.append", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "plot_summary.default_output_dir", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "plot_summary", "(", "algorithm", ":", "str", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ")", ":", "\n", "    ", "seeds", "=", "[", "0", ",", "999", ",", "299", ",", "399", ",", "499", "]", "\n", "base_dir", "=", "default_output_dir", "(", ")", "\n", "try", ":", "\n", "# V0", "\n", "        ", "maximal_attack_train_csv_paths_v0", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v0", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v0", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v0", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v0", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v0", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v0", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v0", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v0", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v0", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v0", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v0", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v0", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v0", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v0", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "\n", "# V2", "\n", "\n", "", "maximal_attack_train_csv_paths_v2", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v11.plot_summary.plot": [[98, 125], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "pandas.read_csv", "plot_summary.plot_summary", "pandas.read_csv", "plot_summary.plot_summary", "glob.glob", "int", "int", "print", "print", "glob.glob", "int", "int", "print", "print", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "str", "str", "plot_summary.default_output_dir", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v2", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v2", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v2", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v2", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v2", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v2", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v2", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v2", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v19.plot_summary.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v19.plot_summary.default_output_dir": [[15, 21], ["plot_summary.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v19.plot_summary.default_config_path": [[23, 29], ["os.path.join", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "default_config_path", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default path to configuration file\n    \"\"\"", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./config.json'", ")", "\n", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v19.plot_summary.plot_summary": [[31, 96], ["experiments.util.plotting_util.plot_all_averages", "plot_summary.default_output_dir", "maximal_attack_train_csv_paths.append", "maximal_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths.append", "minimal_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths.append", "random_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths.append", "random_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths.append", "two_agents_eval_csv_paths.append", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "plot_summary.default_output_dir", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "plot_summary", "(", "algorithm", ":", "str", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ")", ":", "\n", "    ", "seeds", "=", "[", "0", ",", "999", ",", "299", ",", "399", ",", "499", "]", "\n", "base_dir", "=", "default_output_dir", "(", ")", "\n", "try", ":", "\n", "# V0", "\n", "        ", "maximal_attack_train_csv_paths_v0", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v0", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v0", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v0", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v0", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v0", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v0", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v0", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v0", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v0", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v0", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v0", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v0", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v0", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v0", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "\n", "# V2", "\n", "\n", "", "maximal_attack_train_csv_paths_v2", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v19.plot_summary.plot": [[98, 125], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "pandas.read_csv", "plot_summary.plot_summary", "pandas.read_csv", "plot_summary.plot_summary", "glob.glob", "int", "int", "print", "print", "glob.glob", "int", "int", "print", "print", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "str", "str", "plot_summary.default_output_dir", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v2", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v2", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v2", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v2", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v2", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v2", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v2", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v2", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v16.plot_summary.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v16.plot_summary.default_output_dir": [[15, 21], ["plot_summary.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v16.plot_summary.default_config_path": [[23, 29], ["os.path.join", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "default_config_path", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default path to configuration file\n    \"\"\"", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./config.json'", ")", "\n", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v16.plot_summary.plot_summary": [[31, 96], ["experiments.util.plotting_util.plot_all_averages", "plot_summary.default_output_dir", "maximal_attack_train_csv_paths.append", "maximal_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths.append", "minimal_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths.append", "random_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths.append", "random_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths.append", "two_agents_eval_csv_paths.append", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "plot_summary.default_output_dir", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "plot_summary", "(", "algorithm", ":", "str", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ")", ":", "\n", "    ", "seeds", "=", "[", "0", ",", "999", ",", "299", ",", "399", ",", "499", "]", "\n", "base_dir", "=", "default_output_dir", "(", ")", "\n", "try", ":", "\n", "# V0", "\n", "        ", "maximal_attack_train_csv_paths_v0", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v0", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v0", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v0", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v0", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v0", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v0", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v0", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v0", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v0", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v0", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v0", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v0", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v0", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v0", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "\n", "# V2", "\n", "\n", "", "maximal_attack_train_csv_paths_v2", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v16.plot_summary.plot": [[98, 125], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "pandas.read_csv", "plot_summary.plot_summary", "pandas.read_csv", "plot_summary.plot_summary", "glob.glob", "int", "int", "print", "print", "glob.glob", "int", "int", "print", "print", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "str", "str", "plot_summary.default_output_dir", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v2", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v2", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v2", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v2", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v2", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v2", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v2", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v2", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.training.plot_summary.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.training.plot_summary.default_output_dir": [[15, 21], ["plot_summary.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.training.plot_summary.default_config_path": [[23, 29], ["os.path.join", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "default_config_path", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default path to configuration file\n    \"\"\"", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./config.json'", ")", "\n", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.training.plot_summary.plot_summary": [[31, 476], ["plot_summary.default_output_dir", "experiments.util.plotting_util.plot_all_averages_multiple_versions", "experiments.util.plotting_util.plot_all_averages_multiple_versions", "experiments.util.plotting_util.plot_sparse_dense_difference", "experiments.util.plotting_util.plot_loss_functions_summary", "maximal_attack_train_csv_paths_v0.append", "maximal_attack_eval_csv_paths_v0.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths_v0.append", "minimal_defense_eval_csv_paths_v0.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths_v0.append", "random_attack_eval_csv_paths_v0.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths_v0.append", "random_defense_eval_csv_paths_v0.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths_v0.append", "two_agents_eval_csv_paths_v0.append", "maximal_attack_train_csv_paths_v2.append", "maximal_attack_eval_csv_paths_v2.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths_v2.append", "minimal_defense_eval_csv_paths_v2.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths_v2.append", "random_attack_eval_csv_paths_v2.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths_v2.append", "random_defense_eval_csv_paths_v2.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths_v2.append", "two_agents_eval_csv_paths_v2.append", "maximal_attack_train_csv_paths_v3.append", "maximal_attack_eval_csv_paths_v3.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths_v3.append", "minimal_defense_eval_csv_paths_v3.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths_v3.append", "random_attack_eval_csv_paths_v3.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths_v3.append", "random_defense_eval_csv_paths_v3.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths_v3.append", "two_agents_eval_csv_paths_v3.append", "print", "print", "maximal_attack_train_csv_paths_v7.append", "maximal_attack_eval_csv_paths_v7.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths_v7.append", "minimal_defense_eval_csv_paths_v7.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths_v7.append", "random_attack_eval_csv_paths_v7.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths_v7.append", "random_defense_eval_csv_paths_v7.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths_v7.append", "two_agents_eval_csv_paths_v7.append", "maximal_attack_train_csv_paths_v8.append", "maximal_attack_eval_csv_paths_v8.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths_v8.append", "minimal_defense_eval_csv_paths_v8.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths_v8.append", "random_attack_eval_csv_paths_v8.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths_v8.append", "random_defense_eval_csv_paths_v8.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths_v8.append", "two_agents_eval_csv_paths_v8.append", "maximal_attack_train_csv_paths_v9.append", "maximal_attack_eval_csv_paths_v9.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths_v9.append", "minimal_defense_eval_csv_paths_v9.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths_v9.append", "random_attack_eval_csv_paths_v9.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths_v9.append", "random_defense_eval_csv_paths_v9.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths_v9.append", "two_agents_eval_csv_paths_v9.append", "print", "print", "print", "print", "print", "print", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "plot_summary.default_output_dir", "str", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "plot_summary.default_output_dir", "str", "plot_summary.default_output_dir", "str", "plot_summary.default_output_dir", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages_multiple_versions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages_multiple_versions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_sparse_dense_difference", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_loss_functions_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "plot_summary", "(", "algorithm", ":", "str", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ")", ":", "\n", "    ", "seeds", "=", "[", "0", ",", "999", ",", "299", ",", "399", ",", "499", "]", "\n", "base_dir", "=", "default_output_dir", "(", ")", "\n", "try", ":", "\n", "# V0", "\n", "        ", "maximal_attack_train_csv_paths_v0", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v0", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v0", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v0", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v0", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v0", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v0", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v0", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v0", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v0", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v0", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v0", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v0", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v0", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v0", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "\n", "# V2", "\n", "\n", "", "maximal_attack_train_csv_paths_v2", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v2", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v2", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v2", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v2", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v2", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v2", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v2", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v2", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v2", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v2", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v2", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v2", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v2", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v2", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "# V3", "\n", "", "maximal_attack_train_csv_paths_v3", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v3", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v3/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v3/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v3", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v3", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v3", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v3", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v3/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v3/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v3", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v3", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v3", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v3", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v3/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v3/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v3", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v3", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v3", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v3", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v3/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v3/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v3", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v3", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v3", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v3", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v3/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v3/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v3", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v3", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "", "plotting_util", ".", "plot_all_averages_multiple_versions", "(", "\n", "maximal_attack_train_csv_paths_v0", ",", "maximal_attack_eval_csv_paths_v0", ",", "minimal_defense_train_csv_paths_v0", ",", "\n", "minimal_defense_eval_csv_paths_v0", ",", "random_attack_train_csv_paths_v0", ",", "random_attack_eval_csv_paths_v0", ",", "\n", "random_defense_train_csv_paths_v0", ",", "random_defense_eval_csv_paths_v0", ",", "\n", "two_agents_train_csv_paths_v0", ",", "two_agents_eval_csv_paths_v0", ",", "\n", "maximal_attack_train_csv_paths_v2", ",", "maximal_attack_eval_csv_paths_v2", ",", "\n", "minimal_defense_train_csv_paths_v2", ",", "minimal_defense_eval_csv_paths_v2", ",", "\n", "random_attack_train_csv_paths_v2", ",", "random_attack_eval_csv_paths_v2", ",", "\n", "random_defense_train_csv_paths_v2", ",", "random_defense_eval_csv_paths_v2", ",", "\n", "two_agents_train_csv_paths_v2", ",", "two_agents_eval_csv_paths_v2", ",", "\n", "maximal_attack_train_csv_paths_v3", ",", "maximal_attack_eval_csv_paths_v3", ",", "\n", "minimal_defense_train_csv_paths_v3", ",", "minimal_defense_eval_csv_paths_v3", ",", "\n", "random_attack_train_csv_paths_v3", ",", "random_attack_eval_csv_paths_v3", ",", "\n", "random_defense_train_csv_paths_v3", ",", "random_defense_eval_csv_paths_v3", ",", "\n", "two_agents_train_csv_paths_v3", ",", "two_agents_eval_csv_paths_v3", ",", "\n", "algorithm", ",", "default_output_dir", "(", ")", "+", "\"/plots\"", ",", "eval_freq", ",", "train_log_freq", ",", "[", "0", ",", "1", ",", "2", "]", ",", "\n", "wspace", "=", "0.28", ",", "file_name", "=", "\"combined_plot_mult_versions_\"", "+", "algorithm", "+", "\"_\"", ".", "join", "(", "[", "\"0\"", ",", "\"2\"", ",", "\"3\"", "]", ")", ")", "\n", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "str", "(", "e", ")", ")", "\n", "print", "(", "\"Could not plot v0,v2,v3\"", ")", "\n", "\n", "", "try", ":", "\n", "# V7", "\n", "        ", "maximal_attack_train_csv_paths_v7", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v7", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v7/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v7/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v7", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v7", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v7", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v7", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v7/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v7/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v7", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v7", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v7", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v7", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v7/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v7/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v7", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v7", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v7", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v7", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v7/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v7/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v7", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v7", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v7", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v7", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v7/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v7/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v7", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v7", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "# V8", "\n", "", "maximal_attack_train_csv_paths_v8", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v8", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v8/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v8/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v8", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v8", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v8", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v8", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v8/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v8/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v8", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v8", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v8", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v8", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v8/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v8/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v8", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v8", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v8", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v8", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v8/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v8/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v8", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v8", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v8", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v8", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v8/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v8/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v8", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v8", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "# V9", "\n", "\n", "", "maximal_attack_train_csv_paths_v9", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v9", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v9/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v9/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v9", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v9", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v9", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v9", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v9/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v9/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v9", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v9", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v9", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v9", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v9/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v9/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v9", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v9", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v9", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v9", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v9/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v9/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v9", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v9", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v9", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v9", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v9/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v9/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v9", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v9", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "", "plotting_util", ".", "plot_all_averages_multiple_versions", "(", "\n", "maximal_attack_train_csv_paths_v8", ",", "maximal_attack_eval_csv_paths_v8", ",", "minimal_defense_train_csv_paths_v8", ",", "\n", "minimal_defense_eval_csv_paths_v8", ",", "random_attack_train_csv_paths_v8", ",", "random_attack_eval_csv_paths_v8", ",", "\n", "random_defense_train_csv_paths_v8", ",", "random_defense_eval_csv_paths_v8", ",", "\n", "two_agents_train_csv_paths_v8", ",", "two_agents_eval_csv_paths_v8", ",", "\n", "maximal_attack_train_csv_paths_v9", ",", "maximal_attack_eval_csv_paths_v9", ",", "\n", "minimal_defense_train_csv_paths_v9", ",", "minimal_defense_eval_csv_paths_v9", ",", "\n", "random_attack_train_csv_paths_v9", ",", "random_attack_eval_csv_paths_v9", ",", "\n", "random_defense_train_csv_paths_v9", ",", "random_defense_eval_csv_paths_v9", ",", "\n", "two_agents_train_csv_paths_v9", ",", "two_agents_eval_csv_paths_v9", ",", "\n", "maximal_attack_train_csv_paths_v7", ",", "maximal_attack_eval_csv_paths_v7", ",", "\n", "minimal_defense_train_csv_paths_v7", ",", "minimal_defense_eval_csv_paths_v7", ",", "\n", "random_attack_train_csv_paths_v7", ",", "random_attack_eval_csv_paths_v7", ",", "\n", "random_defense_train_csv_paths_v7", ",", "random_defense_eval_csv_paths_v7", ",", "\n", "two_agents_train_csv_paths_v7", ",", "two_agents_eval_csv_paths_v7", ",", "\n", "algorithm", ",", "default_output_dir", "(", ")", "+", "\"/plots\"", ",", "eval_freq", ",", "train_log_freq", ",", "[", "0", ",", "1", ",", "2", "]", ",", "\n", "wspace", "=", "0.35", ",", "file_name", "=", "\"combined_plot_mult_versions_\"", "+", "algorithm", "+", "\"_\"", ".", "join", "(", "[", "\"7\"", ",", "\"8\"", ",", "\"9\"", "]", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "\"could not plot v7,v8,v9\"", ")", "\n", "print", "(", "str", "(", "e", ")", ")", "\n", "\n", "", "try", ":", "\n", "        ", "plotting_util", ".", "plot_sparse_dense_difference", "(", "\n", "maximal_attack_train_csv_paths_v0", ",", "maximal_attack_eval_csv_paths_v0", ",", "minimal_defense_train_csv_paths_v0", ",", "\n", "minimal_defense_eval_csv_paths_v0", ",", "random_attack_train_csv_paths_v0", ",", "random_attack_eval_csv_paths_v0", ",", "\n", "random_defense_train_csv_paths_v0", ",", "random_defense_eval_csv_paths_v0", ",", "\n", "two_agents_train_csv_paths_v0", ",", "two_agents_eval_csv_paths_v0", ",", "\n", "maximal_attack_train_csv_paths_v2", ",", "maximal_attack_eval_csv_paths_v2", ",", "\n", "minimal_defense_train_csv_paths_v2", ",", "minimal_defense_eval_csv_paths_v2", ",", "\n", "random_attack_train_csv_paths_v2", ",", "random_attack_eval_csv_paths_v2", ",", "\n", "random_defense_train_csv_paths_v2", ",", "random_defense_eval_csv_paths_v2", ",", "\n", "two_agents_train_csv_paths_v2", ",", "two_agents_eval_csv_paths_v2", ",", "\n", "maximal_attack_train_csv_paths_v3", ",", "maximal_attack_eval_csv_paths_v3", ",", "\n", "minimal_defense_train_csv_paths_v3", ",", "minimal_defense_eval_csv_paths_v3", ",", "\n", "random_attack_train_csv_paths_v3", ",", "random_attack_eval_csv_paths_v3", ",", "\n", "random_defense_train_csv_paths_v3", ",", "random_defense_eval_csv_paths_v3", ",", "\n", "two_agents_train_csv_paths_v3", ",", "two_agents_eval_csv_paths_v3", ",", "\n", "\n", "maximal_attack_train_csv_paths_v8", ",", "maximal_attack_eval_csv_paths_v8", ",", "minimal_defense_train_csv_paths_v8", ",", "\n", "minimal_defense_eval_csv_paths_v8", ",", "random_attack_train_csv_paths_v8", ",", "random_attack_eval_csv_paths_v8", ",", "\n", "random_defense_train_csv_paths_v8", ",", "random_defense_eval_csv_paths_v8", ",", "\n", "two_agents_train_csv_paths_v8", ",", "two_agents_eval_csv_paths_v8", ",", "\n", "maximal_attack_train_csv_paths_v9", ",", "maximal_attack_eval_csv_paths_v9", ",", "\n", "minimal_defense_train_csv_paths_v9", ",", "minimal_defense_eval_csv_paths_v9", ",", "\n", "random_attack_train_csv_paths_v9", ",", "random_attack_eval_csv_paths_v9", ",", "\n", "random_defense_train_csv_paths_v9", ",", "random_defense_eval_csv_paths_v9", ",", "\n", "two_agents_train_csv_paths_v9", ",", "two_agents_eval_csv_paths_v9", ",", "\n", "maximal_attack_train_csv_paths_v7", ",", "maximal_attack_eval_csv_paths_v7", ",", "\n", "minimal_defense_train_csv_paths_v7", ",", "minimal_defense_eval_csv_paths_v7", ",", "\n", "random_attack_train_csv_paths_v7", ",", "random_attack_eval_csv_paths_v7", ",", "\n", "random_defense_train_csv_paths_v7", ",", "random_defense_eval_csv_paths_v7", ",", "\n", "two_agents_train_csv_paths_v7", ",", "two_agents_eval_csv_paths_v7", ",", "\n", "\n", "algorithm", ",", "default_output_dir", "(", ")", "+", "\"/plots\"", ",", "eval_freq", ",", "train_log_freq", ",", "[", "0", ",", "1", ",", "2", "]", ",", "\n", "wspace", "=", "0.20", ",", "file_name", "=", "\"comparison_\"", "+", "algorithm", "+", "\"_dense_sparse_rewards_mult_versions\"", "+", "\"_\"", ".", "join", "(", "[", "\"0\"", ",", "\"2\"", ",", "\"3\"", ",", "\"7\"", ",", "\"8\"", ",", "\"9\"", "]", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "str", "(", "e", ")", ")", "\n", "print", "(", "\"Could not plot dense and sparse reward comparison\"", ")", "\n", "\n", "", "try", ":", "\n", "        ", "plotting_util", ".", "plot_loss_functions_summary", "(", "\n", "maximal_attack_train_csv_paths_v8", ",", "maximal_attack_eval_csv_paths_v8", ",", "minimal_defense_train_csv_paths_v8", ",", "\n", "minimal_defense_eval_csv_paths_v8", ",", "random_attack_train_csv_paths_v8", ",", "random_attack_eval_csv_paths_v8", ",", "\n", "random_defense_train_csv_paths_v8", ",", "random_defense_eval_csv_paths_v8", ",", "\n", "two_agents_train_csv_paths_v8", ",", "two_agents_eval_csv_paths_v8", ",", "\n", "maximal_attack_train_csv_paths_v9", ",", "maximal_attack_eval_csv_paths_v9", ",", "\n", "minimal_defense_train_csv_paths_v9", ",", "minimal_defense_eval_csv_paths_v9", ",", "\n", "random_attack_train_csv_paths_v9", ",", "random_attack_eval_csv_paths_v9", ",", "\n", "random_defense_train_csv_paths_v9", ",", "random_defense_eval_csv_paths_v9", ",", "\n", "two_agents_train_csv_paths_v9", ",", "two_agents_eval_csv_paths_v9", ",", "\n", "maximal_attack_train_csv_paths_v7", ",", "maximal_attack_eval_csv_paths_v7", ",", "\n", "minimal_defense_train_csv_paths_v7", ",", "minimal_defense_eval_csv_paths_v7", ",", "\n", "random_attack_train_csv_paths_v7", ",", "random_attack_eval_csv_paths_v7", ",", "\n", "random_defense_train_csv_paths_v7", ",", "random_defense_eval_csv_paths_v7", ",", "\n", "two_agents_train_csv_paths_v7", ",", "two_agents_eval_csv_paths_v7", ",", "\n", "\n", "algorithm", ",", "default_output_dir", "(", ")", "+", "\"/plots\"", ",", "eval_freq", ",", "train_log_freq", ",", "[", "0", ",", "1", ",", "2", "]", ",", "\n", "wspace", "=", "0.20", ",", "\n", "file_name", "=", "\"loss_functions_\"", "+", "algorithm", "+", "\"_mult_versions\"", "+", "\"_\"", ".", "join", "(", "[", "\"7\"", ",", "\"8\"", ",", "\"9\"", "]", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "str", "(", "e", ")", ")", "\n", "print", "(", "\"Could not plot loss functions\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.training.plot_summary.plot": [[479, 502], ["os.path.exists", "os.makedirs", "pandas.read_csv", "plot_summary.plot_summary", "plot_summary.plot_summary", "glob.glob", "pandas.read_csv", "int", "int", "print", "print", "int", "int", "print", "print", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "glob.glob", "str", "str", "plot_summary.default_output_dir", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "", "def", "plot", "(", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "default_output_dir", "(", ")", "+", "\"/plots\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "default_output_dir", "(", ")", "+", "\"/plots\"", ")", "\n", "", "try", ":", "\n", "        ", "hyperparam_csv_path", "=", "glob", ".", "glob", "(", "default_output_dir", "(", ")", "+", "\n", "\"/v0/random_defense/tabular_q_learning/results/hyperparameters/0/*.csv\"", ")", "[", "0", "]", "\n", "hyperparameters", "=", "pd", ".", "read_csv", "(", "hyperparam_csv_path", ")", "\n", "", "except", ":", "\n", "        ", "hyperparam_csv_path", "=", "glob", ".", "glob", "(", "default_output_dir", "(", ")", "+", "\n", "\"/v8/random_defense/tabular_q_learning/results/hyperparameters/0/*.csv\"", ")", "[", "0", "]", "\n", "hyperparameters", "=", "pd", ".", "read_csv", "(", "hyperparam_csv_path", ")", "\n", "", "eval_freq", "=", "hyperparameters", ".", "loc", "[", "hyperparameters", "[", "'parameter'", "]", "==", "\"eval_frequency\"", "]", "[", "\"value\"", "]", ".", "values", "[", "0", "]", "\n", "train_log_freq", "=", "hyperparameters", ".", "loc", "[", "hyperparameters", "[", "'parameter'", "]", "==", "\"train_log_frequency\"", "]", "[", "\"value\"", "]", ".", "values", "[", "0", "]", "\n", "try", ":", "\n", "        ", "plot_summary", "(", "\"tabular_q_learning\"", ",", "int", "(", "eval_freq", ")", ",", "int", "(", "train_log_freq", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "\"there was an error plotting summary of tabular Q learning results\"", ")", "\n", "print", "(", "str", "(", "e", ")", ")", "\n", "", "try", ":", "\n", "        ", "plot_summary", "(", "\"dqn\"", ",", "int", "(", "eval_freq", ")", ",", "int", "(", "train_log_freq", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "\"there was an error plotting summary of DQN results\"", ")", "\n", "print", "(", "str", "(", "e", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce.run.get_script_path": [[14, 19], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce.run.default_output_dir": [[21, 27], ["run.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce.run.default_config_path": [[29, 35], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce.run.hp_tuning_config": [[36, 49], ["gym_idsgame.config.hp_tuning_config.HpTuningConfig"], "function", ["None"], ["\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce.run.default_config": [[50, 81], ["gym_idsgame.agents.training_agents.policy_gradient.pg_agent_config.PolicyGradientAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce.run.write_default_config": [[82, 93], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["\n", "", "def", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "", "def", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce.run.plot_csv": [[95, 109], ["experiments.util.plotting_util.read_and_plot_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_results"], ["defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER_AND_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "# Program entrypoint", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "versions", "=", "list", "(", "range", "(", "6", ")", ")", "\n", "for", "version", "in", "versions", ":", "\n", "        ", "print", "(", "\"Test Version: {}\"", ".", "format", "(", "version", ")", ")", "\n", "\n", "print", "(", "\"test_sim_attack_maximal_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", "\n", "print", "(", "\"test_sim_attack_maximal_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce.run.plot_average_results": [[111, 127], ["experiments.util.plotting_util.read_and_plot_average_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_average_results"], ["print", "(", "\"test_sim_random_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_random_vs_defend_minimal", "(", "version", ")", "\n", "print", "(", "\"test_sim_random_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_random_vs_random", "(", "version", ")", "\n", "print", "(", "\"test_train_maximal_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_minimal_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_tabular_q_learning_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "\n", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce.run.run_experiment": [[128, 171], ["str", "experiments.util.util.create_artefact_dirs", "experiments.util.util.setup_logger", "default_config.pg_agent_config.to_csv", "experiments.util.util.read_config", "run.default_config", "time.time", "experiments.util.hp_tuning.hype_grid", "gym_idsgame.runnner.Runner.run", "os.path.exists", "run.write_default_config", "str", "str", "str", "str", "train_result.to_csv", "eval_result.to_csv", "run.plot_csv", "str", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "len", "len", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.create_artefact_dirs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.setup_logger", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.read_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.hp_tuning.hype_grid", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.write_default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.plot_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce.reinforce_attacker_bot_agent.ReinforceAttackerBotAgent.__init__": [[20, 32], ["gym_idsgame.agents.bot_agents.bot_agent.BotAgent.__init__", "reinforce_attacker_bot_agent.ReinforceAttackerBotAgent.initialize_models", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.initialize_models"], ["def", "__init__", "(", "self", ",", "pg_config", ":", "PolicyGradientAgentConfig", ",", "game_config", ":", "GameConfig", ",", "model_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Constructor, initializes the policy\n\n        :param game_config: the game configuration\n        \"\"\"", "\n", "super", "(", "ReinforceAttackerBotAgent", ",", "self", ")", ".", "__init__", "(", "game_config", ")", "\n", "if", "model_path", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot create a ReinforceAttackerbotAgent without specifying the path to the Q-table\"", ")", "\n", "", "self", ".", "config", "=", "pg_config", "\n", "self", ".", "model_path", "=", "model_path", "\n", "self", ".", "initialize_models", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce.reinforce_attacker_bot_agent.ReinforceAttackerBotAgent.initialize_models": [[34, 57], ["gym_idsgame.agents.training_agents.models.fnn_w_softmax.FNNwithSoftmax", "reinforce_attacker_bot_agent.ReinforceAttackerBotAgent.attacker_policy_network.to", "reinforce_attacker_bot_agent.ReinforceAttackerBotAgent.attacker_policy_network.load_state_dict", "reinforce_attacker_bot_agent.ReinforceAttackerBotAgent.attacker_policy_network.eval", "torch.cuda.is_available", "torch.device", "torch.device", "torch.load", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.eval", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load"], ["", "def", "initialize_models", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Initialize models\n        :return: None\n        \"\"\"", "\n", "\n", "# Initialize models", "\n", "self", ".", "attacker_policy_network", "=", "FNNwithSoftmax", "(", "self", ".", "config", ".", "input_dim_attacker", ",", "self", ".", "config", ".", "output_dim_attacker", ",", "\n", "self", ".", "config", ".", "hidden_dim", ",", "\n", "num_hidden_layers", "=", "self", ".", "config", ".", "num_hidden_layers", ",", "\n", "hidden_activation", "=", "self", ".", "config", ".", "hidden_activation", ")", "\n", "\n", "# Specify device", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "self", ".", "config", ".", "gpu", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "\"cuda:\"", "+", "str", "(", "self", ".", "config", ".", "gpu_id", ")", ")", "\n", "#self.config.logger.info(\"Running on the GPU\")", "\n", "", "else", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "#self.config.logger.info(\"Running on the CPU\")", "\n", "", "self", ".", "attacker_policy_network", ".", "to", "(", "device", ")", "\n", "\n", "self", ".", "attacker_policy_network", ".", "load_state_dict", "(", "torch", ".", "load", "(", "self", ".", "model_path", ")", ")", "\n", "self", ".", "attacker_policy_network", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce.reinforce_attacker_bot_agent.ReinforceAttackerBotAgent.action": [[58, 107], ["game_state.get_attacker_observation", "game_state.get_defender_observation", "numpy.zeros", "range", "enumerate", "numpy.array", "torch.from_numpy().float", "reinforce_attacker_bot_agent.ReinforceAttackerBotAgent.get_legal_attacker_actions", "reinforce_attacker_bot_agent.ReinforceAttackerBotAgent.attacker_policy_network", "reinforce_attacker_bot_agent.ReinforceAttackerBotAgent.clone", "torch.distributions.Categorical", "torch.distributions.Categorical.sample", "gym_idsgame.agents.training_agents.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global", "row.tolist", "row.tolist.append", "row.tolist.append", "row.tolist.append", "numpy.array.append", "torch.cuda.is_available", "torch.device", "state.to.to.to", "torch.distributions.Categorical.sample.item", "int", "int", "torch.from_numpy", "len", "len", "len", "numpy.array.flatten", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.get_attacker_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.get_defender_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_legal_attacker_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global"], ["", "def", "action", "(", "self", ",", "game_state", ":", "GameState", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Samples an action from the policy.\n\n        :param game_state: the game state\n        :return: action_id\n        \"\"\"", "\n", "\n", "# Feature engineering", "\n", "attacker_obs", "=", "game_state", ".", "get_attacker_observation", "(", "self", ".", "game_config", ".", "network_config", ",", "local_view", "=", "True", ",", "\n", "reconnaissance", "=", "self", ".", "game_config", ".", "reconnaissance_actions", ")", "\n", "defender_obs", "=", "game_state", ".", "get_defender_observation", "(", "self", ".", "game_config", ".", "network_config", ")", "\n", "neighbor_defense_attributes", "=", "np", ".", "zeros", "(", "(", "attacker_obs", ".", "shape", "[", "0", "]", ",", "defender_obs", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "node", "in", "range", "(", "attacker_obs", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "if", "int", "(", "attacker_obs", "[", "node", "]", "[", "-", "1", "]", ")", "==", "1", ":", "\n", "                ", "id", "=", "int", "(", "attacker_obs", "[", "node", "]", "[", "-", "2", "]", ")", "\n", "neighbor_defense_attributes", "[", "node", "]", "=", "defender_obs", "[", "id", "]", "\n", "", "", "node_ids", "=", "attacker_obs", "[", ":", ",", "-", "2", "]", "\n", "node_reachable", "=", "attacker_obs", "[", ":", ",", "-", "1", "]", "\n", "det_values", "=", "neighbor_defense_attributes", "[", ":", ",", "-", "1", "]", "\n", "temp", "=", "neighbor_defense_attributes", "[", ":", ",", "0", ":", "-", "1", "]", "-", "attacker_obs", "[", ":", ",", "0", ":", "-", "2", "]", "\n", "features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "temp", ")", ":", "\n", "            ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "t", ".", "append", "(", "node_ids", "[", "idx", "]", ")", "\n", "t", ".", "append", "(", "node_reachable", "[", "idx", "]", ")", "\n", "t", ".", "append", "(", "det_values", "[", "idx", "]", ")", "\n", "features", ".", "append", "(", "t", ")", "\n", "", "features", "=", "np", ".", "array", "(", "features", ")", "\n", "\n", "state", "=", "torch", ".", "from_numpy", "(", "features", ".", "flatten", "(", ")", ")", ".", "float", "(", ")", "\n", "# Move to GPU if using GPU", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "self", ".", "config", ".", "gpu", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "\"cuda:\"", "+", "str", "(", "self", ".", "config", ".", "gpu_id", ")", ")", "\n", "state", "=", "state", ".", "to", "(", "device", ")", "\n", "", "legal_actions", ",", "non_legal_actions", "=", "self", ".", "get_legal_attacker_actions", "(", "attacker_obs", ",", "game_state", ")", "\n", "# Forward pass using the current policy network to predict P(a|s)", "\n", "action_probs", "=", "self", ".", "attacker_policy_network", "(", "state", ")", "\n", "# Set probability of non-legal actions to 0", "\n", "action_probs_1", "=", "action_probs", ".", "clone", "(", ")", "\n", "if", "len", "(", "legal_actions", ")", ">", "0", "and", "len", "(", "non_legal_actions", ")", "<", "len", "(", "action_probs_1", ")", ":", "\n", "            ", "action_probs_1", "[", "non_legal_actions", "]", "=", "0", "\n", "# Use torch.distributions package to create a parameterizable probability distribution of the learned policy", "\n", "", "policy_dist", "=", "Categorical", "(", "action_probs_1", ")", "\n", "# Sample an action from the probability distribution", "\n", "action", "=", "policy_dist", ".", "sample", "(", ")", "\n", "\n", "global_action", "=", "PolicyGradientAgent", ".", "convert_local_attacker_action_to_global", "(", "action", ".", "item", "(", ")", ",", "attacker_obs", ")", "\n", "return", "global_action", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce.reinforce_attacker_bot_agent.ReinforceAttackerBotAgent.get_legal_attacker_actions": [[108, 127], ["range", "len", "gym_idsgame.agents.training_agents.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global", "gym_idsgame.is_attack_id_legal", "int", "range", "range", "legal_actions_2.append", "illegal_actions.append", "legal_actions.append", "illegal_actions.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_attack_id_legal"], ["", "def", "get_legal_attacker_actions", "(", "self", ",", "attacker_obs", ",", "state", ")", ":", "\n", "        ", "legal_actions", "=", "[", "]", "\n", "illegal_actions", "=", "[", "]", "\n", "num_attack_types", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "2", "]", ".", "shape", "[", "1", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "attacker_obs", ")", ")", ":", "\n", "            ", "if", "int", "(", "attacker_obs", "[", "i", "]", "[", "-", "1", "]", ")", "==", "1", ":", "\n", "                ", "for", "ac", "in", "range", "(", "num_attack_types", ")", ":", "\n", "                    ", "legal_actions", ".", "append", "(", "i", "*", "num_attack_types", "+", "ac", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "ac", "in", "range", "(", "num_attack_types", ")", ":", "\n", "                    ", "illegal_actions", ".", "append", "(", "i", "*", "num_attack_types", "+", "ac", ")", "\n", "", "", "", "legal_actions_2", "=", "[", "]", "\n", "for", "action", "in", "legal_actions", ":", "\n", "            ", "global_action", "=", "PolicyGradientAgent", ".", "convert_local_attacker_action_to_global", "(", "action", ",", "attacker_obs", ")", "\n", "if", "util", ".", "is_attack_id_legal", "(", "global_action", ",", "self", ".", "game_config", ",", "state", ".", "attacker_pos", ",", "state", ",", "[", "]", ")", ":", "\n", "                ", "legal_actions_2", ".", "append", "(", "global_action", ")", "\n", "", "else", ":", "\n", "                ", "illegal_actions", ".", "append", "(", "action", ")", "\n", "", "", "return", "legal_actions_2", ",", "illegal_actions", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce.reinforce.ReinforceAgent.__init__": [[24, 44], ["gym_idsgame.agents.training_agents.policy_gradient.pg_agent.PolicyGradientAgent.__init__", "torch.utils.tensorboard.SummaryWriter", "reinforce.ReinforceAgent.initialize_models", "reinforce.ReinforceAgent.tensorboard_writer.add_hparams", "numpy.finfo().eps.item", "reinforce.ReinforceAgent.config.hparams_dict", "numpy.finfo"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.initialize_models", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.hparams_dict"], ["    ", "random_seed", "=", "0", "\n", "util", ".", "create_artefact_dirs", "(", "default_output_dir", "(", ")", ",", "random_seed", ")", "\n", "pg_agent_config", "=", "PolicyGradientAgentConfig", "(", "gamma", "=", "0.999", ",", "alpha_attacker", "=", "0.00001", ",", "epsilon", "=", "1", ",", "render", "=", "False", ",", "\n", "eval_sleep", "=", "0.9", ",", "\n", "min_epsilon", "=", "0.01", ",", "eval_episodes", "=", "100", ",", "train_log_frequency", "=", "100", ",", "\n", "epsilon_decay", "=", "0.9999", ",", "video", "=", "True", ",", "eval_log_frequency", "=", "1", ",", "\n", "video_fps", "=", "5", ",", "video_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/videos/\"", "+", "str", "(", "random_seed", ")", ",", "\n", "num_episodes", "=", "200001", ",", "\n", "eval_render", "=", "False", ",", "gifs", "=", "True", ",", "\n", "gif_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/gifs/\"", "+", "str", "(", "random_seed", ")", ",", "\n", "eval_frequency", "=", "10000", ",", "attacker", "=", "True", ",", "defender", "=", "False", ",", "\n", "video_frequency", "=", "101", ",", "\n", "save_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/data/\"", "+", "str", "(", "random_seed", ")", ",", "\n", "checkpoint_freq", "=", "5000", ",", "input_dim_attacker", "=", "44", ",", "output_dim_attacker", "=", "40", ",", "\n", "hidden_dim", "=", "64", ",", "\n", "num_hidden_layers", "=", "1", ",", "batch_size", "=", "32", ",", "\n", "gpu", "=", "False", ",", "tensorboard", "=", "True", ",", "\n", "tensorboard_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/tensorboard/\"", "+", "str", "(", "random_seed", ")", ",", "\n", "optimizer", "=", "\"Adam\"", ",", "lr_exp_decay", "=", "False", ",", "lr_decay_rate", "=", "0.999", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v9\"", "\n", "env", "=", "gym", ".", "make", "(", "env_name", ",", "save_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/data/\"", "+", "str", "(", "random_seed", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce.reinforce.ReinforceAgent.initialize_models": [[45, 107], ["reinforce.ReinforceAgent.attacker_policy_network.to", "reinforce.ReinforceAgent.defender_policy_network.to", "gym_idsgame.agents.training_agents.models.lstm_w_softmax.LSTMwithSoftmax", "gym_idsgame.agents.training_agents.models.lstm_w_softmax.LSTMwithSoftmax", "gym_idsgame.agents.training_agents.models.fnn_w_softmax.FNNwithSoftmax", "gym_idsgame.agents.training_agents.models.fnn_w_softmax.FNNwithSoftmax", "torch.cuda.is_available", "torch.device", "reinforce.ReinforceAgent.config.logger.info", "torch.device", "reinforce.ReinforceAgent.config.logger.info", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.ExponentialLR", "torch.optim.lr_scheduler.ExponentialLR", "reinforce.ReinforceAgent.attacker_policy_network.parameters", "reinforce.ReinforceAgent.defender_policy_network.parameters", "torch.optim.SGD", "torch.optim.SGD", "ValueError", "str", "reinforce.ReinforceAgent.attacker_policy_network.parameters", "reinforce.ReinforceAgent.defender_policy_network.parameters"], "methods", ["None"], ["attacker_agent", "=", "ReinforceAgent", "(", "env", ",", "pg_agent_config", ")", "\n", "attacker_agent", ".", "train", "(", ")", "\n", "train_result", "=", "attacker_agent", ".", "train_result", "\n", "eval_result", "=", "attacker_agent", ".", "eval_result", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce.reinforce.ReinforceAgent.training_step": [[109, 177], ["len", "range", "len", "torch.tensor", "torch.tensor.std", "zip", "reinforce.ReinforceAgent.attacker_optimizer.zero_grad", "torch.stack().sum", "policy_loss.backward", "reinforce.ReinforceAgent.attacker_optimizer.step", "reinforce.ReinforceAgent.defender_optimizer.zero_grad", "torch.stack().sum", "policy_loss.backward", "reinforce.ReinforceAgent.defender_optimizer.step", "torch.tensor.insert", "policy_loss.append", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.tensor.mean", "torch.stack", "reinforce.ReinforceAgent.attacker_policy_network.parameters", "torch.stack", "reinforce.ReinforceAgent.defender_policy_network.parameters"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce.reinforce.ReinforceAgent.get_action": [[179, 254], ["torch.distributions.Categorical", "torch.distributions.Categorical.log_prob", "torch.from_numpy().float", "torch.from_numpy().float", "torch.cuda.is_available", "torch.device", "state.to.to.to", "list", "list", "list", "list", "reinforce.ReinforceAgent.attacker_policy_network().squeeze", "reinforce.ReinforceAgent.clone", "reinforce.ReinforceAgent.defender_policy_network().squeeze", "reinforce.ReinforceAgent.clone", "torch.distributions.Categorical.sample", "torch.tensor().type.item", "range", "list", "list", "range", "filter", "filter", "print", "print", "print", "print", "print", "print", "print", "torch.tensor().type", "torch.from_numpy", "torch.from_numpy", "str", "reinforce.ReinforceAgent.env.local_view_features", "filter", "filter", "reinforce.ReinforceAgent.attacker_policy_network", "len", "len", "reinforce.ReinforceAgent.defender_policy_network", "len", "len", "state.to.to.reshape", "state.to.to.flatten", "reinforce.ReinforceAgent.env.is_defense_legal", "torch.tensor", "reinforce.ReinforceAgent.env.is_attack_legal", "reinforce.ReinforceAgent.env.is_defense_legal", "reinforce.ReinforceAgent.env.is_attack_legal"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.log_prob", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce.reinforce.ReinforceAgent.train": [[256, 492], ["reinforce.ReinforceAgent.config.logger.info", "reinforce.ReinforceAgent.config.logger.info", "reinforce.ReinforceAgent.env.reset", "reinforce.ReinforceAgent.update_state", "reinforce.ReinforceAgent.update_state", "reinforce.ReinforceAgent.outer_train.set_description_str", "range", "reinforce.ReinforceAgent.config.logger.info", "reinforce.ReinforceAgent.eval", "reinforce.ReinforceAgent.save_model", "reinforce.ReinforceAgent.env.save_trajectories", "reinforce.ReinforceAgent.env.save_attack_data", "reinforce.ReinforceAgent.config.to_str", "len", "reinforce.ReinforceAgent.config.logger.warning", "range", "reinforce.ReinforceAgent.outer_train.update", "reinforce.ReinforceAgent.anneal_epsilon", "str", "reinforce.ReinforceAgent.train_result.to_csv", "reinforce.ReinforceAgent.eval_result.to_csv", "saved_attacker_log_probs_batch.append", "saved_attacker_rewards_batch.append", "saved_defender_log_probs_batch.append", "saved_defender_rewards_batch.append", "episode_attacker_rewards.append", "episode_defender_rewards.append", "episode_steps.append", "reinforce.ReinforceAgent.env.reset", "reinforce.ReinforceAgent.update_state", "reinforce.ReinforceAgent.update_state", "reinforce.ReinforceAgent.training_step", "reinforce.ReinforceAgent.item", "reinforce.ReinforceAgent.training_step", "reinforce.ReinforceAgent.item", "reinforce.ReinforceAgent.attacker_lr_decay.step", "reinforce.ReinforceAgent.defender_lr_decay.step", "reinforce.ReinforceAgent.log_metrics", "reinforce.ReinforceAgent.eval", "reinforce.ReinforceAgent.save_model", "reinforce.ReinforceAgent.env.save_trajectories", "reinforce.ReinforceAgent.env.save_attack_data", "time.time", "reinforce.ReinforceAgent.env.step", "saved_attacker_rewards.append", "saved_defender_rewards.append", "reinforce.ReinforceAgent.update_state", "reinforce.ReinforceAgent.update_state", "reinforce.ReinforceAgent.env.render", "episode_avg_attacker_loss.append", "episode_avg_defender_loss.append", "episode_avg_attacker_loss.append", "episode_avg_defender_loss.append", "reinforce.ReinforceAgent.attacker_lr_decay.get_lr", "reinforce.ReinforceAgent.defender_lr_decay.get_lr", "reinforce.ReinforceAgent.attacker_policy_network.named_parameters", "reinforce.ReinforceAgent.defender_policy_network.named_parameters", "str", "reinforce.ReinforceAgent.train_result.to_csv", "reinforce.ReinforceAgent.eval_result.to_csv", "reinforce.ReinforceAgent.env.render", "AssertionError", "reinforce.ReinforceAgent.env.local_view_features", "reinforce.ReinforceAgent.get_action", "reinforce.ReinforceAgent.env.local_view_features", "saved_attacker_log_probs.append", "reinforce.ReinforceAgent.get_action", "saved_defender_log_probs.append", "tag.replace.replace.replace", "reinforce.ReinforceAgent.tensorboard_writer.add_histogram", "reinforce.ReinforceAgent.tensorboard_writer.add_histogram", "tag.replace.replace.replace", "reinforce.ReinforceAgent.tensorboard_writer.add_histogram", "reinforce.ReinforceAgent.tensorboard_writer.add_histogram", "time.time", "reinforce.ReinforceAgent.get_legal_attacker_actions", "gym_idsgame.agents.training_agents.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global", "value.data.cpu().numpy", "value.grad.data.cpu().numpy", "value.data.cpu().numpy", "value.grad.data.cpu().numpy", "value.data.cpu", "value.grad.data.cpu", "value.data.cpu", "value.grad.data.cpu"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.eval", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.save_model", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_trajectories", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_attack_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_str", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.anneal_epsilon", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.training_step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.training_step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_metrics", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.eval", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.save_model", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_trajectories", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_attack_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_legal_attacker_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce.reinforce.ReinforceAgent.eval": [[493, 651], ["reinforce.ReinforceAgent.config.logger.info", "str", "tqdm.tqdm", "reinforce.ReinforceAgent.outer_eval.set_description_str", "reinforce.ReinforceAgent.env.reset", "reinforce.ReinforceAgent.update_state", "reinforce.ReinforceAgent.update_state", "range", "reinforce.ReinforceAgent.env.close", "reinforce.ReinforceAgent.config.logger.info", "time.time", "len", "reinforce.ReinforceAgent.config.logger.warning", "gym_idsgame.envs.rendering.video.idsgame_monitor.IdsGameMonitor", "reinforce.ReinforceAgent.config.logger.info", "episode_attacker_rewards.append", "episode_defender_rewards.append", "episode_steps.append", "reinforce.ReinforceAgent.env.reset", "reinforce.ReinforceAgent.update_state", "reinforce.ReinforceAgent.update_state", "reinforce.ReinforceAgent.outer_eval.update", "reinforce.ReinforceAgent.log_metrics", "AssertionError", "reinforce.ReinforceAgent.env.step", "reinforce.ReinforceAgent.update_state", "reinforce.ReinforceAgent.update_state", "reinforce.ReinforceAgent.env.render", "time.sleep", "reinforce.ReinforceAgent.log_metrics", "reinforce.ReinforceAgent.env.generate_gif", "enumerate", "reinforce.ReinforceAgent.env.render", "time.sleep", "reinforce.ReinforceAgent.env.local_view_features", "reinforce.ReinforceAgent.get_action", "reinforce.ReinforceAgent.env.local_view_features", "reinforce.ReinforceAgent.get_action", "reinforce.ReinforceAgent.tensorboard_writer.add_image", "float", "float", "float", "float", "reinforce.ReinforceAgent.get_legal_attacker_actions", "gym_idsgame.agents.training_agents.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global", "float", "float", "float", "float", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_metrics", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_metrics", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.generate_gif", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_legal_attacker_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce.reinforce.ReinforceAgent.save_model": [[652, 670], ["str", "time.time", "reinforce.ReinforceAgent.config.logger.warning", "reinforce.ReinforceAgent.config.logger.info", "torch.save", "reinforce.ReinforceAgent.config.logger.info", "torch.save", "reinforce.ReinforceAgent.attacker_policy_network.state_dict", "reinforce.ReinforceAgent.defender_policy_network.state_dict"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.run.get_script_path": [[14, 19], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.run.default_output_dir": [[21, 27], ["run.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.run.default_config_path": [[29, 35], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.run.hp_tuning_config": [[36, 49], ["gym_idsgame.config.hp_tuning_config.HpTuningConfig"], "function", ["None"], ["\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.run.default_config": [[50, 77], ["gym_idsgame.agents.training_agents.policy_gradient.pg_agent_config.PolicyGradientAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.run.write_default_config": [[78, 89], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.run.plot_csv": [[91, 105], ["experiments.util.plotting_util.read_and_plot_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_results"], ["", "def", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER_AND_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "# Program entrypoint", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "versions", "=", "list", "(", "range", "(", "6", ")", ")", "\n", "for", "version", "in", "versions", ":", "\n", "        ", "print", "(", "\"Test Version: {}\"", ".", "format", "(", "version", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.run.plot_average_results": [[107, 123], ["experiments.util.plotting_util.read_and_plot_average_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_average_results"], ["print", "(", "\"test_sim_attack_maximal_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", "\n", "print", "(", "\"test_sim_attack_maximal_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_random", "(", "version", ")", "\n", "print", "(", "\"test_sim_random_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_random_vs_defend_minimal", "(", "version", ")", "\n", "print", "(", "\"test_sim_random_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_random_vs_random", "(", "version", ")", "\n", "print", "(", "\"test_train_maximal_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_minimal_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_tabular_q_learning_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.run.run_experiment": [[124, 167], ["str", "experiments.util.util.create_artefact_dirs", "experiments.util.util.setup_logger", "default_config.pg_agent_config.to_csv", "experiments.util.util.read_config", "run.default_config", "time.time", "experiments.util.hp_tuning.hype_grid", "gym_idsgame.runnner.Runner.run", "os.path.exists", "run.write_default_config", "str", "str", "str", "str", "train_result.to_csv", "eval_result.to_csv", "run.plot_csv", "str", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "len", "len", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.create_artefact_dirs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.setup_logger", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.read_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.hp_tuning.hype_grid", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.write_default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.plot_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "\n", "\n", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.actor_critic.ActorCriticAgent.__init__": [[26, 51], ["gym_idsgame.agents.training_agents.policy_gradient.pg_agent.PolicyGradientAgent.__init__", "torch.utils.tensorboard.SummaryWriter", "actor_critic.ActorCriticAgent.initialize_models", "actor_critic.ActorCriticAgent.tensorboard_writer.add_hparams", "numpy.finfo().eps.item", "actor_critic.ActorCriticAgent.config.hparams_dict", "numpy.finfo"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.initialize_models", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.hparams_dict"], ["def", "__init__", "(", "self", ",", "env", ":", "IdsGameEnv", ",", "config", ":", "PolicyGradientAgentConfig", ")", ":", "\n", "        ", "\"\"\"\n        Initialize environment and hyperparameters\n\n        :param config: the configuration\n        \"\"\"", "\n", "super", "(", "ActorCriticAgent", ",", "self", ")", ".", "__init__", "(", "env", ",", "config", ")", "\n", "self", ".", "attacker_policy_network", "=", "None", "\n", "self", ".", "defender_policy_network", "=", "None", "\n", "self", ".", "critic_loss_fn", "=", "None", "\n", "self", ".", "attacker_optimizer", "=", "None", "\n", "self", ".", "defender_optimizer", "=", "None", "\n", "self", ".", "attacker_lr_decay", "=", "None", "\n", "self", ".", "defender_lr_decay", "=", "None", "\n", "self", ".", "tensorboard_writer", "=", "SummaryWriter", "(", "self", ".", "config", ".", "tensorboard_dir", ")", "\n", "if", "self", ".", "config", ".", "opponent_pool", "and", "self", ".", "config", ".", "opponent_pool_config", "is", "not", "None", ":", "\n", "            ", "self", ".", "attacker_pool", "=", "[", "]", "\n", "self", ".", "defender_pool", "=", "[", "]", "\n", "", "self", ".", "initialize_models", "(", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_hparams", "(", "self", ".", "config", ".", "hparams_dict", "(", ")", ",", "{", "}", ")", "\n", "self", ".", "machine_eps", "=", "np", ".", "finfo", "(", "np", ".", "float32", ")", ".", "eps", ".", "item", "(", ")", "\n", "self", ".", "env", ".", "idsgame_config", ".", "save_trajectories", "=", "False", "\n", "self", ".", "env", ".", "idsgame_config", ".", "save_attack_stats", "=", "False", "\n", "self", ".", "train_attacker", "=", "True", "\n", "self", ".", "train_defender", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.actor_critic.ActorCriticAgent.initialize_models": [[52, 107], ["gym_idsgame.agents.training_agents.models.fnn_actor_critic.FFNActorCritic", "gym_idsgame.agents.training_agents.models.fnn_actor_critic.FFNActorCritic", "actor_critic.ActorCriticAgent.attacker_policy_network.to", "actor_critic.ActorCriticAgent.defender_policy_network.to", "actor_critic.ActorCriticAgent.add_model_to_pool", "actor_critic.ActorCriticAgent.add_model_to_pool", "torch.cuda.is_available", "torch.device", "actor_critic.ActorCriticAgent.config.logger.info", "torch.device", "actor_critic.ActorCriticAgent.config.logger.info", "torch.nn.MSELoss", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.ExponentialLR", "torch.optim.lr_scheduler.ExponentialLR", "torch.nn.SmoothL1Loss", "ValueError", "actor_critic.ActorCriticAgent.attacker_policy_network.parameters", "actor_critic.ActorCriticAgent.defender_policy_network.parameters", "torch.optim.SGD", "torch.optim.SGD", "ValueError", "str", "actor_critic.ActorCriticAgent.attacker_policy_network.parameters", "actor_critic.ActorCriticAgent.defender_policy_network.parameters"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.add_model_to_pool", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.add_model_to_pool"], ["", "def", "initialize_models", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Initialize models\n        :return: None\n        \"\"\"", "\n", "\n", "# Initialize models", "\n", "self", ".", "attacker_policy_network", "=", "FFNActorCritic", "(", "self", ".", "config", ".", "input_dim_attacker", ",", "self", ".", "config", ".", "output_dim_attacker", ",", "\n", "self", ".", "config", ".", "hidden_dim", ",", "\n", "num_hidden_layers", "=", "self", ".", "config", ".", "num_hidden_layers", ",", "\n", "hidden_activation", "=", "self", ".", "config", ".", "hidden_activation", ")", "\n", "self", ".", "defender_policy_network", "=", "FFNActorCritic", "(", "self", ".", "config", ".", "input_dim_defender", ",", "self", ".", "config", ".", "output_dim_defender", ",", "\n", "self", ".", "config", ".", "hidden_dim", ",", "\n", "num_hidden_layers", "=", "self", ".", "config", ".", "num_hidden_layers", ",", "\n", "hidden_activation", "=", "self", ".", "config", ".", "hidden_activation", ")", "\n", "\n", "# Specify device", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "self", ".", "config", ".", "gpu", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "\"cuda:\"", "+", "str", "(", "self", ".", "config", ".", "gpu_id", ")", ")", "\n", "self", ".", "config", ".", "logger", ".", "info", "(", "\"Running on the GPU\"", ")", "\n", "", "else", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "self", ".", "config", ".", "logger", ".", "info", "(", "\"Running on the CPU\"", ")", "\n", "\n", "", "self", ".", "attacker_policy_network", ".", "to", "(", "device", ")", "\n", "self", ".", "defender_policy_network", ".", "to", "(", "device", ")", "\n", "\n", "# Construct loss function", "\n", "if", "self", ".", "config", ".", "critic_loss_fn", "==", "\"MSE\"", ":", "\n", "            ", "self", ".", "critic_loss_fn", "=", "torch", ".", "nn", ".", "MSELoss", "(", ")", "\n", "", "elif", "self", ".", "config", ".", "critic_loss_fn", "==", "\"Huber\"", ":", "\n", "            ", "self", ".", "critic_loss_fn", "=", "torch", ".", "nn", ".", "SmoothL1Loss", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Loss function not recognized\"", ")", "\n", "\n", "# Define Optimizer. The call to model.parameters() in the optimizer constructor will contain the learnable", "\n", "# parameters of the layers in the model", "\n", "", "if", "self", ".", "config", ".", "optimizer", "==", "\"Adam\"", ":", "\n", "            ", "self", ".", "attacker_optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "attacker_policy_network", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "config", ".", "alpha_attacker", ")", "\n", "self", ".", "defender_optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "defender_policy_network", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "config", ".", "alpha_defender", ")", "\n", "", "elif", "self", ".", "config", ".", "optimizer", "==", "\"SGD\"", ":", "\n", "            ", "self", ".", "attacker_optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "attacker_policy_network", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "config", ".", "alpha_attacker", ")", "\n", "self", ".", "defender_optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "self", ".", "defender_policy_network", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "config", ".", "alpha_defender", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Optimizer not recognized\"", ")", "\n", "\n", "# LR decay", "\n", "", "if", "self", ".", "config", ".", "lr_exp_decay", ":", "\n", "            ", "self", ".", "attacker_lr_decay", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "ExponentialLR", "(", "optimizer", "=", "self", ".", "attacker_optimizer", ",", "\n", "gamma", "=", "self", ".", "config", ".", "lr_decay_rate", ")", "\n", "self", ".", "defender_lr_decay", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "ExponentialLR", "(", "optimizer", "=", "self", ".", "defender_optimizer", ",", "\n", "gamma", "=", "self", ".", "config", ".", "lr_decay_rate", ")", "\n", "\n", "", "self", ".", "add_model_to_pool", "(", "attacker", "=", "True", ")", "\n", "self", ".", "add_model_to_pool", "(", "attacker", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.actor_critic.ActorCriticAgent.add_model_to_pool": [[108, 142], ["copy.deepcopy", "copy.deepcopy", "len", "actor_critic.ActorCriticAgent.attacker_pool.pop", "actor_critic.ActorCriticAgent.attacker_pool.append", "len", "actor_critic.ActorCriticAgent.defender_pool.pop", "actor_critic.ActorCriticAgent.defender_pool.append", "len", "actor_critic.ActorCriticAgent.attacker_pool.append", "len", "actor_critic.ActorCriticAgent.defender_pool.append", "len", "actor_critic.ActorCriticAgent.get_attacker_pool_quality_scores", "max", "actor_critic.ActorCriticAgent.attacker_pool.append", "len", "actor_critic.ActorCriticAgent.get_defender_pool_quality_scores", "max", "actor_critic.ActorCriticAgent.defender_pool.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_attacker_pool_quality_scores", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_defender_pool_quality_scores"], ["", "def", "add_model_to_pool", "(", "self", ",", "attacker", "=", "True", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Adds a model to the pool of opponents\n\n        :param attacker: boolean flag indicating whether adding attacker model or defender model\n        :return: None\n        \"\"\"", "\n", "if", "self", ".", "config", ".", "opponent_pool", "and", "self", ".", "config", ".", "opponent_pool_config", "is", "not", "None", ":", "\n", "            ", "if", "attacker", ":", "\n", "                ", "model_copy", "=", "copy", ".", "deepcopy", "(", "self", ".", "attacker_policy_network", ")", "\n", "if", "len", "(", "self", ".", "attacker_pool", ")", ">=", "self", ".", "config", ".", "opponent_pool_config", ".", "pool_maxsize", ":", "\n", "                    ", "self", ".", "attacker_pool", ".", "pop", "(", "0", ")", "\n", "", "if", "self", ".", "config", ".", "opponent_pool_config", ".", "quality_scores", ":", "\n", "                    ", "if", "len", "(", "self", ".", "attacker_pool", ")", "==", "0", ":", "\n", "                        ", "self", ".", "attacker_pool", ".", "append", "(", "[", "model_copy", ",", "self", ".", "config", ".", "opponent_pool_config", ".", "initial_quality", "]", ")", "\n", "", "elif", "len", "(", "self", ".", "attacker_pool", ")", ">", "0", ":", "\n", "                        ", "qualities", "=", "self", ".", "get_attacker_pool_quality_scores", "(", ")", "\n", "max_q", "=", "max", "(", "qualities", ")", "\n", "self", ".", "attacker_pool", ".", "append", "(", "[", "model_copy", ",", "max_q", "]", ")", "\n", "", "", "else", ":", "\n", "                    ", "self", ".", "attacker_pool", ".", "append", "(", "model_copy", ")", "\n", "", "", "else", ":", "\n", "                ", "model_copy", "=", "copy", ".", "deepcopy", "(", "self", ".", "defender_policy_network", ")", "\n", "if", "len", "(", "self", ".", "defender_pool", ")", ">=", "self", ".", "config", ".", "opponent_pool_config", ".", "pool_maxsize", ":", "\n", "                    ", "self", ".", "defender_pool", ".", "pop", "(", "0", ")", "\n", "", "if", "self", ".", "config", ".", "opponent_pool_config", ".", "quality_scores", ":", "\n", "                    ", "if", "len", "(", "self", ".", "defender_pool", ")", "==", "0", ":", "\n", "                        ", "self", ".", "defender_pool", ".", "append", "(", "[", "model_copy", ",", "self", ".", "config", ".", "opponent_pool_config", ".", "initial_quality", "]", ")", "\n", "", "elif", "len", "(", "self", ".", "defender_pool", ")", ">", "0", ":", "\n", "                        ", "qualities", "=", "self", ".", "get_defender_pool_quality_scores", "(", ")", "\n", "max_q", "=", "max", "(", "qualities", ")", "\n", "self", ".", "defender_pool", ".", "append", "(", "[", "model_copy", ",", "max_q", "]", ")", "\n", "", "", "else", ":", "\n", "                    ", "self", ".", "defender_pool", ".", "append", "(", "model_copy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.actor_critic.ActorCriticAgent.sample_opponent": [[143, 158], ["actor_critic.ActorCriticAgent.get_attacker_pool_quality_scores", "actor_critic.ActorCriticAgent.get_softmax_distribution", "actor_critic.ActorCriticAgent.get_defender_pool_quality_scores", "actor_critic.ActorCriticAgent.get_softmax_distribution", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "list", "list", "list", "list", "range", "range", "range", "range", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_attacker_pool_quality_scores", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_softmax_distribution", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_defender_pool_quality_scores", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_softmax_distribution"], ["", "", "", "", "def", "sample_opponent", "(", "self", ",", "attacker", "=", "True", ")", ":", "\n", "        ", "if", "attacker", ":", "\n", "            ", "if", "self", ".", "config", ".", "opponent_pool_config", ".", "quality_scores", ":", "\n", "                ", "quality_scores", "=", "self", ".", "get_attacker_pool_quality_scores", "(", ")", "\n", "softmax_dist", "=", "self", ".", "get_softmax_distribution", "(", "quality_scores", ")", "\n", "return", "np", ".", "random", ".", "choice", "(", "list", "(", "range", "(", "len", "(", "self", ".", "attacker_pool", ")", ")", ")", ",", "size", "=", "1", ",", "p", "=", "softmax_dist", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "return", "np", ".", "random", ".", "choice", "(", "list", "(", "range", "(", "len", "(", "self", ".", "attacker_pool", ")", ")", ")", ",", "size", "=", "1", ")", "[", "0", "]", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "config", ".", "opponent_pool_config", ".", "quality_scores", ":", "\n", "                ", "quality_scores", "=", "self", ".", "get_defender_pool_quality_scores", "(", ")", "\n", "softmax_dist", "=", "self", ".", "get_softmax_distribution", "(", "quality_scores", ")", "\n", "return", "np", ".", "random", ".", "choice", "(", "list", "(", "range", "(", "len", "(", "self", ".", "defender_pool", ")", ")", ")", ",", "size", "=", "1", ",", "p", "=", "softmax_dist", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "return", "np", ".", "random", ".", "choice", "(", "list", "(", "range", "(", "len", "(", "self", ".", "defender_pool", ")", ")", ")", ",", "size", "=", "1", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.actor_critic.ActorCriticAgent.get_softmax_distribution": [[159, 167], ["scipy.special.softmax"], "methods", ["None"], ["", "", "", "def", "get_softmax_distribution", "(", "self", ",", "qualities", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Converts a list of quality scores into a distribution with softmax\n\n        :param qualities: the list of quality scores\n        :return: the softmax distribution\n        \"\"\"", "\n", "return", "softmax", "(", "qualities", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.actor_critic.ActorCriticAgent.get_attacker_pool_quality_scores": [[168, 173], ["list", "map"], "methods", ["None"], ["", "def", "get_attacker_pool_quality_scores", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        :return: Returns the quality scores from the attacker pool\n        \"\"\"", "\n", "return", "list", "(", "map", "(", "lambda", "x", ":", "x", "[", "1", "]", ",", "self", ".", "attacker_pool", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.actor_critic.ActorCriticAgent.get_defender_pool_quality_scores": [[174, 179], ["list", "map"], "methods", ["None"], ["", "def", "get_defender_pool_quality_scores", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        :return: Returns the quality scores from the defender pool\n        \"\"\"", "\n", "return", "list", "(", "map", "(", "lambda", "x", ":", "x", "[", "1", "]", ",", "self", ".", "defender_pool", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.actor_critic.ActorCriticAgent.training_step": [[180, 268], ["len", "range", "len", "torch.tensor", "torch.tensor.std", "zip", "actor_critic.ActorCriticAgent.attacker_optimizer.zero_grad", "loss.backward", "actor_critic.ActorCriticAgent.attacker_optimizer.step", "actor_critic.ActorCriticAgent.defender_optimizer.zero_grad", "loss.backward", "actor_critic.ActorCriticAgent.defender_optimizer.step", "torch.tensor.insert", "policy_loss.append", "torch.tensor", "value_loss.append", "torch.stack().sum", "torch.stack().sum", "torch.nn.utils.clip_grad_norm_", "torch.stack().sum", "torch.stack().sum", "torch.nn.utils.clip_grad_norm_", "torch.tensor.mean", "state_value.to.to.item", "torch.cuda.is_available", "torch.device", "state_value.to.to.to", "R_tensor.to.to.to", "actor_critic.ActorCriticAgent.critic_loss_fn", "actor_critic.ActorCriticAgent.attacker_policy_network.parameters", "actor_critic.ActorCriticAgent.defender_policy_network.parameters", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step"], ["", "def", "training_step", "(", "self", ",", "saved_rewards", ":", "List", "[", "List", "[", "float", "]", "]", ",", "saved_log_probs", ":", "List", "[", "List", "[", "torch", ".", "Tensor", "]", "]", ",", "\n", "saved_state_values", ":", "List", "[", "List", "[", "torch", ".", "Tensor", "]", "]", ",", "attacker", "=", "True", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Performs a training step of the Deep-Q-learning algorithm (implemented in PyTorch)\n\n        :param saved_rewards list of rewards encountered in the latest episode trajectory\n        :param saved_log_probs list of log-action probabilities (log p(a|s)) encountered in the latest episode trajectory\n        :param saved_state_values list of state values encountered in the latest episode trajectory\n        :return: loss\n        \"\"\"", "\n", "\n", "policy_loss", "=", "[", "]", "# list to save actor (policy) loss", "\n", "value_loss", "=", "[", "]", "# list to save critic (value) loss", "\n", "num_batches", "=", "len", "(", "saved_rewards", ")", "\n", "\n", "for", "batch", "in", "range", "(", "num_batches", ")", ":", "\n", "            ", "R", "=", "0", "\n", "returns", "=", "[", "]", "# list to save the true (observed) values", "\n", "# Create discounted returns. When episode is finished we can go back and compute the observed cumulative", "\n", "# discounted reward by using the observed rewards", "\n", "for", "r", "in", "saved_rewards", "[", "batch", "]", "[", ":", ":", "-", "1", "]", ":", "\n", "                ", "R", "=", "r", "+", "self", ".", "config", ".", "gamma", "*", "R", "\n", "returns", ".", "insert", "(", "0", ",", "R", ")", "\n", "", "num_rewards", "=", "len", "(", "returns", ")", "\n", "\n", "# convert list to torch tensor", "\n", "returns", "=", "torch", ".", "tensor", "(", "returns", ")", "\n", "\n", "# normalize", "\n", "std", "=", "returns", ".", "std", "(", ")", "\n", "if", "num_rewards", "<", "2", ":", "\n", "                ", "std", "=", "0", "\n", "", "returns", "=", "(", "returns", "-", "returns", ".", "mean", "(", ")", ")", "/", "(", "std", "+", "self", ".", "machine_eps", ")", "\n", "\n", "# Compute PG \"loss\" which in reality is the expected reward, which we want to maximize with gradient ascent", "\n", "for", "log_prob", ",", "state_value", ",", "R", "in", "zip", "(", "saved_log_probs", "[", "batch", "]", ",", "saved_state_values", "[", "batch", "]", ",", "returns", ")", ":", "\n", "# Compute the advantage which will be used as a baseline in REINFORCE to reduce the gradient variance", "\n", "# Intuitively, the advantage tells us how much better the observed reward was compared to the expected reward", "\n", "# If the advantage of an action is high, it means that the current policy should be modified to reinforce", "\n", "# that action. That is, the advantage tells us for every action much better that action is than", "\n", "# the average action.", "\n", "                ", "advantage", "=", "R", "-", "state_value", ".", "item", "(", ")", "\n", "\n", "# negative log probsince we are doing gradient descent (not ascent)", "\n", "policy_loss", ".", "append", "(", "-", "log_prob", "*", "advantage", ")", "\n", "\n", "R_tensor", "=", "torch", ".", "tensor", "(", "[", "R", "]", ")", "\n", "\n", "# Move to GPU if using GPU", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "self", ".", "config", ".", "gpu", ":", "\n", "                    ", "device", "=", "torch", ".", "device", "(", "\"cuda:\"", "+", "str", "(", "self", ".", "config", ".", "gpu_id", ")", ")", "\n", "state_value", "=", "state_value", ".", "to", "(", "device", ")", "\n", "R_tensor", "=", "R_tensor", ".", "to", "(", "device", ")", "\n", "\n", "\n", "# calculate critic loss using Huber loss", "\n", "", "value_loss", ".", "append", "(", "self", ".", "critic_loss_fn", "(", "state_value", ",", "R_tensor", ")", ")", "\n", "\n", "\n", "# Compute gradient and update models", "\n", "", "", "if", "attacker", ":", "\n", "# reset gradients", "\n", "            ", "self", ".", "attacker_optimizer", ".", "zero_grad", "(", ")", "\n", "# sum up all the values of policy losses and value losses", "\n", "total_loss", "=", "(", "torch", ".", "stack", "(", "policy_loss", ")", ".", "sum", "(", ")", "+", "torch", ".", "stack", "(", "value_loss", ")", ".", "sum", "(", ")", ")", "\n", "loss", "=", "total_loss", "/", "num_batches", "\n", "# perform backprop", "\n", "loss", ".", "backward", "(", ")", "\n", "# maybe clip gradient", "\n", "if", "self", ".", "config", ".", "clip_gradient", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "attacker_policy_network", ".", "parameters", "(", ")", ",", "1", ")", "\n", "# gradient descent step", "\n", "", "self", ".", "attacker_optimizer", ".", "step", "(", ")", "\n", "", "else", ":", "\n", "# reset gradients", "\n", "            ", "self", ".", "defender_optimizer", ".", "zero_grad", "(", ")", "\n", "# sum up all the values of policy losses and value losses", "\n", "total_loss", "=", "torch", ".", "stack", "(", "policy_loss", ")", ".", "sum", "(", ")", "+", "torch", ".", "stack", "(", "value_loss", ")", ".", "sum", "(", ")", "\n", "loss", "=", "total_loss", "/", "num_batches", "\n", "# perform backprop", "\n", "loss", ".", "backward", "(", ")", "\n", "# maybe clip gradient", "\n", "if", "self", ".", "config", ".", "clip_gradient", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "defender_policy_network", ".", "parameters", "(", ")", ",", "1", ")", "\n", "# gradient descent step", "\n", "", "self", ".", "defender_optimizer", ".", "step", "(", ")", "\n", "\n", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.actor_critic.ActorCriticAgent.get_action": [[270, 334], ["torch.from_numpy().float", "action_probs.clone", "torch.distributions.Categorical", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.log_prob", "torch.cuda.is_available", "torch.device", "state.to.to.to", "list", "list", "list", "list", "len", "torch.distributions.Categorical.sample.item", "torch.from_numpy", "range", "list", "list", "range", "filter", "filter", "actor_critic.ActorCriticAgent.attacker_opponent", "actor_critic.ActorCriticAgent.attacker_policy_network", "actor_critic.ActorCriticAgent.defender_opponent", "actor_critic.ActorCriticAgent.defender_policy_network", "state.to.to.flatten", "str", "actor_critic.ActorCriticAgent.env.local_view_features", "filter", "filter", "actor_critic.ActorCriticAgent.env.is_defense_legal", "actor_critic.ActorCriticAgent.env.is_attack_legal", "actor_critic.ActorCriticAgent.env.is_defense_legal", "actor_critic.ActorCriticAgent.env.is_attack_legal"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.log_prob", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal"], ["", "def", "get_action", "(", "self", ",", "state", ":", "np", ".", "ndarray", ",", "attacker", ":", "bool", "=", "True", ",", "opponent_pool", "=", "False", ",", "\n", "legal_actions", ":", "List", "=", "None", ",", "non_legal_actions", ":", "List", "=", "None", ")", "->", "Union", "[", "int", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "np", ".", "ndarray", "]", ":", "\n", "        ", "\"\"\"\n        Samples an action from the policy network\n\n        :param state: the state to sample an action for\n        :param attacker: boolean flag whether running in attacker mode (if false assume defender)\n        :param opponent_pool: boolean flag, if true get model from opponent pool\n        :param legal_actions: list of allowed actions\n        :param non_legal_actions: list of disallowed actions\n        :return: The sampled action id, log probability of action id, state value, action distribution\n        \"\"\"", "\n", "state", "=", "torch", ".", "from_numpy", "(", "state", ".", "flatten", "(", ")", ")", ".", "float", "(", ")", "\n", "\n", "# Move to GPU if using GPU", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "self", ".", "config", ".", "gpu", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "\"cuda:\"", "+", "str", "(", "self", ".", "config", ".", "gpu_id", ")", ")", "\n", "state", "=", "state", ".", "to", "(", "device", ")", "\n", "\n", "# Calculate legal actions", "\n", "", "if", "attacker", ":", "\n", "            ", "actions", "=", "list", "(", "range", "(", "self", ".", "env", ".", "num_attack_actions", ")", ")", "\n", "if", "not", "self", ".", "env", ".", "local_view_features", "(", ")", "or", "(", "legal_actions", "is", "None", "or", "non_legal_actions", "is", "None", ")", ":", "\n", "                ", "legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "self", ".", "env", ".", "is_attack_legal", "(", "action", ")", ",", "actions", ")", ")", "\n", "non_legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "not", "self", ".", "env", ".", "is_attack_legal", "(", "action", ")", ",", "actions", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "actions", "=", "list", "(", "range", "(", "self", ".", "env", ".", "num_defense_actions", ")", ")", "\n", "legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "self", ".", "env", ".", "is_defense_legal", "(", "action", ")", ",", "actions", ")", ")", "\n", "non_legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "not", "self", ".", "env", ".", "is_defense_legal", "(", "action", ")", ",", "actions", ")", ")", "\n", "\n", "# Forward pass using the current policy network to predict P(a|s)", "\n", "", "if", "attacker", ":", "\n", "            ", "if", "opponent_pool", ":", "\n", "                ", "action_probs", ",", "state_value", "=", "self", ".", "attacker_opponent", "(", "state", ")", "\n", "", "else", ":", "\n", "                ", "action_probs", ",", "state_value", "=", "self", ".", "attacker_policy_network", "(", "state", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "opponent_pool", ":", "\n", "                ", "action_probs", ",", "state_value", "=", "self", ".", "defender_opponent", "(", "state", ")", "\n", "", "else", ":", "\n", "                ", "action_probs", ",", "state_value", "=", "self", ".", "defender_policy_network", "(", "state", ")", "\n", "\n", "# Set probability of non-legal actions to 0", "\n", "", "", "action_probs_1", "=", "action_probs", ".", "clone", "(", ")", "\n", "if", "len", "(", "legal_actions", ")", ">", "0", ":", "\n", "            ", "action_probs_1", "[", "non_legal_actions", "]", "=", "0", "\n", "\n", "# Use torch.distributions package to create a parameterizable probability distribution of the learned policy", "\n", "# PG uses a trick to turn the gradient into a stochastic gradient which we can sample from in order to", "\n", "# approximate the true gradient (which we can\u2019t compute directly). It can be seen as an alternative to the", "\n", "# reparameterization trick", "\n", "", "policy_dist", "=", "Categorical", "(", "action_probs_1", ")", "\n", "\n", "# Sample an action from the probability distribution", "\n", "action", "=", "policy_dist", ".", "sample", "(", ")", "\n", "\n", "# log_prob returns the log of the probability density/mass function evaluated at value.", "\n", "# save the log_prob as it will use later on for computing the policy gradient", "\n", "# policy gradient theorem says that the stochastic gradient of the expected return of the current policy is", "\n", "# the log gradient of the policy times the expected return, therefore we save the log of the policy distribution", "\n", "# now and use it later to compute the gradient once the episode has finished.", "\n", "log_prob", "=", "policy_dist", ".", "log_prob", "(", "action", ")", "\n", "\n", "return", "action", ".", "item", "(", ")", ",", "log_prob", ",", "state_value", ",", "action_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.actor_critic.ActorCriticAgent.train": [[336, 720], ["actor_critic.ActorCriticAgent.config.logger.info", "actor_critic.ActorCriticAgent.config.logger.info", "actor_critic.ActorCriticAgent.env.reset", "actor_critic.ActorCriticAgent.update_state", "actor_critic.ActorCriticAgent.update_state", "actor_critic.ActorCriticAgent.outer_train.set_description_str", "numpy.zeros", "numpy.zeros", "range", "actor_critic.ActorCriticAgent.config.logger.info", "actor_critic.ActorCriticAgent.eval", "actor_critic.ActorCriticAgent.save_model", "actor_critic.ActorCriticAgent.env.save_trajectories", "actor_critic.ActorCriticAgent.env.save_attack_data", "actor_critic.ActorCriticAgent.config.to_str", "len", "actor_critic.ActorCriticAgent.config.logger.warning", "range", "actor_critic.ActorCriticAgent.anneal_epsilon", "actor_critic.ActorCriticAgent.outer_train.update", "str", "actor_critic.ActorCriticAgent.train_result.to_csv", "actor_critic.ActorCriticAgent.eval_result.to_csv", "saved_attacker_log_probs_batch.append", "saved_attacker_rewards_batch.append", "saved_attacker_state_values_batch.append", "saved_defender_log_probs_batch.append", "saved_defender_rewards_batch.append", "saved_defender_state_values_batch.append", "episode_attacker_rewards.append", "episode_defender_rewards.append", "episode_steps.append", "actor_critic.ActorCriticAgent.env.reset", "actor_critic.ActorCriticAgent.update_state", "actor_critic.ActorCriticAgent.update_state", "actor_critic.ActorCriticAgent.attacker_policy_network.named_parameters", "actor_critic.ActorCriticAgent.defender_policy_network.named_parameters", "actor_critic.ActorCriticAgent.attacker_lr_decay.step", "actor_critic.ActorCriticAgent.defender_lr_decay.step", "actor_critic.ActorCriticAgent.log_metrics", "actor_critic.ActorCriticAgent.eval", "actor_critic.ActorCriticAgent.save_model", "actor_critic.ActorCriticAgent.env.save_trajectories", "actor_critic.ActorCriticAgent.env.save_attack_data", "time.time", "numpy.random.rand", "actor_critic.ActorCriticAgent.sample_opponent", "numpy.random.rand", "actor_critic.ActorCriticAgent.sample_opponent", "actor_critic.ActorCriticAgent.env.step", "saved_attacker_rewards.append", "saved_defender_rewards.append", "actor_critic.ActorCriticAgent.update_state", "actor_critic.ActorCriticAgent.update_state", "actor_critic.ActorCriticAgent.env.render", "actor_critic.ActorCriticAgent.training_step", "actor_critic.ActorCriticAgent.item", "actor_critic.ActorCriticAgent.training_step", "actor_critic.ActorCriticAgent.item", "tag.replace.replace.replace", "actor_critic.ActorCriticAgent.tensorboard_writer.add_histogram", "actor_critic.ActorCriticAgent.tensorboard_writer.add_histogram", "tag.replace.replace.replace", "actor_critic.ActorCriticAgent.tensorboard_writer.add_histogram", "actor_critic.ActorCriticAgent.tensorboard_writer.add_histogram", "episode_avg_attacker_loss.append", "episode_avg_defender_loss.append", "episode_avg_attacker_loss.append", "episode_avg_defender_loss.append", "actor_critic.ActorCriticAgent.attacker_lr_decay.get_lr", "actor_critic.ActorCriticAgent.defender_lr_decay.get_lr", "actor_critic.ActorCriticAgent.update_quality_score", "actor_critic.ActorCriticAgent.update_quality_score", "len", "len", "actor_critic.ActorCriticAgent.log_action_dist", "actor_critic.ActorCriticAgent.log_action_dist", "str", "actor_critic.ActorCriticAgent.train_result.to_csv", "actor_critic.ActorCriticAgent.eval_result.to_csv", "actor_critic.ActorCriticAgent.create_policy_plot", "actor_critic.ActorCriticAgent.create_policy_plot", "actor_critic.ActorCriticAgent.env.render", "AssertionError", "actor_critic.ActorCriticAgent.env.local_view_features", "actor_critic.ActorCriticAgent.env.local_view_features", "saved_attacker_log_probs.append", "saved_attacker_state_values.append", "saved_defender_log_probs.append", "saved_defender_state_values.append", "value.data.cpu().numpy", "value.grad.data.cpu().numpy", "value.data.cpu().numpy", "value.grad.data.cpu().numpy", "time.time", "numpy.zeros.data.cpu().numpy", "numpy.zeros.data.cpu().numpy", "actor_critic.ActorCriticAgent.get_legal_attacker_actions", "actor_critic.ActorCriticAgent.get_action", "actor_critic.ActorCriticAgent.get_action", "gym_idsgame.agents.training_agents.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global", "actor_critic.ActorCriticAgent.get_action", "actor_critic.ActorCriticAgent.get_action", "actor_critic.ActorCriticAgent.add_model_to_pool", "actor_critic.ActorCriticAgent.add_model_to_pool", "numpy.random.rand", "actor_critic.ActorCriticAgent.sample_opponent", "numpy.random.rand", "actor_critic.ActorCriticAgent.sample_opponent", "value.data.cpu", "value.grad.data.cpu", "value.data.cpu", "value.grad.data.cpu", "numpy.zeros.data.cpu", "numpy.zeros.data.cpu"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.eval", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.save_model", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_trajectories", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_attack_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_str", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.anneal_epsilon", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_metrics", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.eval", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.save_model", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_trajectories", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_attack_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.sample_opponent", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.sample_opponent", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.training_step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.training_step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.update_quality_score", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.update_quality_score", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_action_dist", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_action_dist", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.create_policy_plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.create_policy_plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_legal_attacker_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.add_model_to_pool", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.add_model_to_pool", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.sample_opponent", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.sample_opponent"], ["", "def", "train", "(", "self", ")", "->", "ExperimentResult", ":", "\n", "        ", "\"\"\"\n        Runs the REINFORCE with Baseline algorithm\n\n        :return: Experiment result\n        \"\"\"", "\n", "self", ".", "config", ".", "logger", ".", "info", "(", "\"Starting Training\"", ")", "\n", "self", ".", "config", ".", "logger", ".", "info", "(", "self", ".", "config", ".", "to_str", "(", ")", ")", "\n", "if", "len", "(", "self", ".", "train_result", ".", "avg_episode_steps", ")", ">", "0", ":", "\n", "            ", "self", ".", "config", ".", "logger", ".", "warning", "(", "\"starting training with non-empty result object\"", ")", "\n", "", "done", "=", "False", "\n", "obs", "=", "self", ".", "env", ".", "reset", "(", "update_stats", "=", "False", ")", "\n", "attacker_obs", ",", "defender_obs", "=", "obs", "\n", "\n", "attacker_state", "=", "self", ".", "update_state", "(", "attacker_obs", "=", "attacker_obs", ",", "defender_obs", "=", "defender_obs", ",", "state", "=", "[", "]", ",", "attacker", "=", "True", ")", "\n", "defender_state", "=", "self", ".", "update_state", "(", "defender_obs", "=", "defender_obs", ",", "attacker_obs", "=", "attacker_obs", ",", "state", "=", "[", "]", ",", "attacker", "=", "False", ")", "\n", "\n", "# Tracking metrics", "\n", "episode_attacker_rewards", "=", "[", "]", "\n", "episode_defender_rewards", "=", "[", "]", "\n", "episode_steps", "=", "[", "]", "\n", "episode_avg_attacker_loss", "=", "[", "]", "\n", "episode_avg_defender_loss", "=", "[", "]", "\n", "\n", "# Logging", "\n", "self", ".", "outer_train", ".", "set_description_str", "(", "\"[Train] epsilon:{:.2f},avg_a_R:{:.2f},avg_d_R:{:.2f},\"", "\n", "\"avg_t:{:.2f},avg_h:{:.2f},acc_A_R:{:.2f},\"", "\"acc_D_R:{:.2f}\"", ".", "format", "(", "self", ".", "config", ".", "epsilon", ",", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ")", ")", "\n", "\n", "train_attacker", "=", "True", "\n", "train_defender", "=", "True", "\n", "if", "self", ".", "config", ".", "alternating_optimization", ":", "\n", "            ", "train_attacker", "=", "False", "\n", "if", "self", ".", "config", ".", "opponent_pool", "and", "self", ".", "config", ".", "opponent_pool_config", "is", "not", "None", ":", "\n", "                ", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "config", ".", "opponent_pool_config", ".", "pool_prob", ":", "\n", "                    ", "self", ".", "defender_opponent_idx", "=", "self", ".", "sample_opponent", "(", "attacker", "=", "False", ")", "\n", "if", "self", ".", "config", ".", "opponent_pool_config", ".", "quality_scores", ":", "\n", "                        ", "self", ".", "defender_opponent", "=", "self", ".", "defender_pool", "[", "self", ".", "defender_opponent_idx", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "                        ", "self", ".", "defender_opponent", "=", "self", ".", "defender_pool", "[", "self", ".", "defender_opponent_idx", "]", "\n", "", "", "else", ":", "\n", "                    ", "self", ".", "defender_opponent", "=", "self", ".", "defender_policy_network", "\n", "self", ".", "defender_opponent_idx", "=", "None", "\n", "\n", "", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "config", ".", "opponent_pool_config", ".", "pool_prob", ":", "\n", "                    ", "self", ".", "attacker_opponent_idx", "=", "self", ".", "sample_opponent", "(", "attacker", "=", "True", ")", "\n", "if", "self", ".", "config", ".", "opponent_pool_config", ".", "quality_scores", ":", "\n", "                        ", "self", ".", "attacker_opponent", "=", "self", ".", "attacker_pool", "[", "self", ".", "attacker_opponent_idx", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "                        ", "self", ".", "attacker_opponent", "=", "self", ".", "attacker_pool", "[", "self", ".", "attacker_opponent_idx", "]", "\n", "", "", "else", ":", "\n", "                    ", "self", ".", "attacker_opponent", "=", "self", ".", "attacker_policy_network", "\n", "self", ".", "attacker_opponent_idx", "=", "None", "\n", "\n", "", "", "", "num_alt_iterations", "=", "0", "\n", "num_attacker_pool_iterations", "=", "0", "\n", "num_defender_pool_iterations", "=", "0", "\n", "num_attacker_opponent_iterations", "=", "0", "\n", "num_defender_opponent_iterations", "=", "0", "\n", "\n", "attacker_initial_state_action_dist", "=", "np", ".", "zeros", "(", "self", ".", "config", ".", "output_dim_attacker", ")", "\n", "defender_initial_state_action_dist", "=", "np", ".", "zeros", "(", "self", ".", "config", ".", "output_dim_defender", ")", "\n", "\n", "saved_attacker_log_probs_batch", "=", "[", "]", "\n", "saved_attacker_rewards_batch", "=", "[", "]", "\n", "saved_attacker_state_values_batch", "=", "[", "]", "\n", "saved_defender_log_probs_batch", "=", "[", "]", "\n", "saved_defender_rewards_batch", "=", "[", "]", "\n", "saved_defender_state_values_batch", "=", "[", "]", "\n", "\n", "total_num_episodes", "=", "0", "\n", "\n", "# Training", "\n", "for", "iter", "in", "range", "(", "self", ".", "config", ".", "num_episodes", ")", ":", "\n", "# Batch", "\n", "            ", "for", "episode", "in", "range", "(", "self", ".", "config", ".", "batch_size", ")", ":", "\n", "                ", "episode_attacker_reward", "=", "0", "\n", "episode_defender_reward", "=", "0", "\n", "episode_step", "=", "0", "\n", "episode_attacker_loss", "=", "0.0", "\n", "episode_defender_loss", "=", "0.0", "\n", "saved_attacker_log_probs", "=", "[", "]", "\n", "saved_attacker_rewards", "=", "[", "]", "\n", "saved_attacker_state_values", "=", "[", "]", "\n", "saved_defender_log_probs", "=", "[", "]", "\n", "saved_defender_rewards", "=", "[", "]", "\n", "saved_defender_state_values", "=", "[", "]", "\n", "while", "not", "done", ":", "\n", "                    ", "if", "self", ".", "config", ".", "render", ":", "\n", "                        ", "self", ".", "env", ".", "render", "(", "mode", "=", "\"human\"", ")", "\n", "\n", "", "if", "not", "self", ".", "config", ".", "attacker", "and", "not", "self", ".", "config", ".", "defender", ":", "\n", "                        ", "raise", "AssertionError", "(", "\"Must specify whether training an attacker agent or defender agent\"", ")", "\n", "\n", "# Default initialization", "\n", "", "attacker_action", "=", "0", "\n", "defender_action", "=", "0", "\n", "\n", "# Get attacker and defender actions", "\n", "if", "self", ".", "config", ".", "attacker", ":", "\n", "                        ", "legal_actions", "=", "None", "\n", "illegal_actions", "=", "None", "\n", "if", "self", ".", "env", ".", "local_view_features", "(", ")", ":", "\n", "                            ", "legal_actions", ",", "illegal_actions", "=", "self", ".", "get_legal_attacker_actions", "(", "attacker_obs", ")", "\n", "", "if", "self", ".", "config", ".", "alternating_optimization", "and", "not", "train_attacker", "and", "self", ".", "config", ".", "opponent_pool", "and", "self", ".", "config", ".", "opponent_pool_config", "is", "not", "None", ":", "\n", "                            ", "attacker_action", ",", "attacker_log_prob", ",", "attacker_state_value", ",", "attacker_action_dist", "=", "self", ".", "get_action", "(", "\n", "attacker_state", ",", "attacker", "=", "True", ",", "opponent_pool", "=", "True", ",", "legal_actions", "=", "legal_actions", ",", "\n", "non_legal_actions", "=", "illegal_actions", ")", "\n", "", "else", ":", "\n", "                            ", "attacker_action", ",", "attacker_log_prob", ",", "attacker_state_value", ",", "attacker_action_dist", "=", "self", ".", "get_action", "(", "attacker_state", ",", "attacker", "=", "True", ",", "opponent_pool", "=", "False", ",", "\n", "legal_actions", "=", "legal_actions", ",", "non_legal_actions", "=", "illegal_actions", ")", "\n", "", "if", "self", ".", "env", ".", "local_view_features", "(", ")", ":", "\n", "                            ", "attacker_action", "=", "PolicyGradientAgent", ".", "convert_local_attacker_action_to_global", "(", "attacker_action", ",", "attacker_obs", ")", "\n", "", "saved_attacker_log_probs", ".", "append", "(", "attacker_log_prob", ")", "\n", "saved_attacker_state_values", ".", "append", "(", "attacker_state_value", ")", "\n", "if", "episode_step", "==", "0", ":", "\n", "                            ", "attacker_initial_state_action_dist", "=", "attacker_action_dist", "\n", "\n", "", "", "if", "self", ".", "config", ".", "defender", ":", "\n", "                        ", "if", "self", ".", "config", ".", "alternating_optimization", "and", "not", "train_defender", "and", "self", ".", "config", ".", "opponent_pool", "and", "self", ".", "config", ".", "opponent_pool_config", "is", "not", "None", ":", "\n", "                            ", "defender_action", ",", "defender_log_prob", ",", "defender_state_value", ",", "defender_action_dist", "=", "self", ".", "get_action", "(", "\n", "defender_state", ",", "attacker", "=", "False", ",", "opponent_pool", "=", "True", ")", "\n", "", "else", ":", "\n", "                            ", "defender_action", ",", "defender_log_prob", ",", "defender_state_value", ",", "defender_action_dist", "=", "self", ".", "get_action", "(", "defender_state", ",", "attacker", "=", "False", ",", "opponent_pool", "=", "False", ")", "\n", "", "saved_defender_log_probs", ".", "append", "(", "defender_log_prob", ")", "\n", "saved_defender_state_values", ".", "append", "(", "defender_state_value", ")", "\n", "if", "episode_step", "==", "0", ":", "\n", "                            ", "defender_initial_state_action_dist", "=", "defender_action_dist", "\n", "\n", "", "", "action", "=", "(", "attacker_action", ",", "defender_action", ")", "\n", "\n", "# Take a step in the environment", "\n", "obs_prime", ",", "reward", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "\n", "# Update metrics", "\n", "attacker_reward", ",", "defender_reward", "=", "reward", "\n", "obs_prime_attacker", ",", "obs_prime_defender", "=", "obs_prime", "\n", "episode_attacker_reward", "+=", "attacker_reward", "\n", "saved_attacker_rewards", ".", "append", "(", "attacker_reward", ")", "\n", "episode_defender_reward", "+=", "defender_reward", "\n", "saved_defender_rewards", ".", "append", "(", "defender_reward", ")", "\n", "episode_step", "+=", "1", "\n", "\n", "# Move to the next state", "\n", "obs", "=", "obs_prime", "\n", "attacker_obs", "=", "obs_prime_attacker", "\n", "defender_obs", "=", "obs_prime_defender", "\n", "attacker_state", "=", "self", ".", "update_state", "(", "attacker_obs", "=", "attacker_obs", ",", "defender_obs", "=", "defender_obs", ",", "state", "=", "attacker_state", ",", "attacker", "=", "True", ")", "\n", "defender_state", "=", "self", ".", "update_state", "(", "defender_obs", "=", "defender_obs", ",", "attacker_obs", "=", "attacker_obs", ",", "state", "=", "defender_state", ",", "attacker", "=", "False", ")", "\n", "\n", "\n", "# Render final frame", "\n", "", "if", "self", ".", "config", ".", "render", ":", "\n", "                    ", "self", ".", "env", ".", "render", "(", "mode", "=", "\"human\"", ")", "\n", "\n", "# Accumulate batch", "\n", "", "saved_attacker_log_probs_batch", ".", "append", "(", "saved_attacker_log_probs", ")", "\n", "saved_attacker_rewards_batch", ".", "append", "(", "saved_attacker_rewards", ")", "\n", "saved_attacker_state_values_batch", ".", "append", "(", "saved_attacker_state_values", ")", "\n", "saved_defender_log_probs_batch", ".", "append", "(", "saved_defender_log_probs", ")", "\n", "saved_defender_rewards_batch", ".", "append", "(", "saved_defender_rewards", ")", "\n", "saved_defender_state_values_batch", ".", "append", "(", "saved_defender_state_values", ")", "\n", "\n", "# Record episode metrics", "\n", "self", ".", "num_train_games", "+=", "1", "\n", "self", ".", "num_train_games_total", "+=", "1", "\n", "if", "self", ".", "env", ".", "state", ".", "hacked", ":", "\n", "                    ", "self", ".", "num_train_hacks", "+=", "1", "\n", "self", ".", "num_train_hacks_total", "+=", "1", "\n", "\n", "", "episode_attacker_rewards", ".", "append", "(", "episode_attacker_reward", ")", "\n", "episode_defender_rewards", ".", "append", "(", "episode_defender_reward", ")", "\n", "episode_steps", ".", "append", "(", "episode_step", ")", "\n", "\n", "# Reset environment for the next episode and update game stats", "\n", "done", "=", "False", "\n", "attacker_obs", ",", "defender_obs", "=", "self", ".", "env", ".", "reset", "(", "update_stats", "=", "True", ")", "\n", "attacker_state", "=", "self", ".", "update_state", "(", "attacker_obs", "=", "attacker_obs", ",", "defender_obs", "=", "defender_obs", ",", "state", "=", "[", "]", ",", "\n", "attacker", "=", "True", ")", "\n", "defender_state", "=", "self", ".", "update_state", "(", "defender_obs", "=", "defender_obs", ",", "attacker_obs", "=", "attacker_obs", ",", "state", "=", "[", "]", ",", "\n", "attacker", "=", "False", ")", "\n", "\n", "# If using opponent pool, update the pool", "\n", "if", "self", ".", "config", ".", "opponent_pool", "and", "self", ".", "config", ".", "opponent_pool_config", "is", "not", "None", ":", "\n", "                    ", "if", "train_attacker", ":", "\n", "                        ", "if", "num_attacker_pool_iterations", ">", "self", ".", "config", ".", "opponent_pool_config", ".", "pool_increment_period", ":", "\n", "                            ", "self", ".", "add_model_to_pool", "(", "attacker", "=", "True", ")", "\n", "num_attacker_pool_iterations", "=", "0", "\n", "\n", "", "if", "num_defender_opponent_iterations", ">", "self", ".", "config", ".", "opponent_pool_config", ".", "head_to_head_period", ":", "\n", "                            ", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "config", ".", "opponent_pool_config", ".", "pool_prob", ":", "\n", "                                ", "self", ".", "defender_opponent_idx", "=", "self", ".", "sample_opponent", "(", "attacker", "=", "False", ")", "\n", "if", "self", ".", "config", ".", "opponent_pool_config", ".", "quality_scores", ":", "\n", "                                    ", "self", ".", "defender_opponent", "=", "self", ".", "defender_pool", "[", "self", ".", "defender_opponent_idx", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "                                    ", "self", ".", "defender_opponent", "=", "self", ".", "defender_pool", "[", "self", ".", "defender_opponent_idx", "]", "\n", "", "", "else", ":", "\n", "                                ", "self", ".", "defender_opponent", "=", "self", ".", "defender_policy_network", "\n", "self", ".", "defender_opponent_idx", "=", "None", "\n", "", "num_defender_opponent_iterations", "=", "0", "\n", "\n", "", "", "if", "train_defender", ":", "\n", "                        ", "if", "num_defender_pool_iterations", ">", "self", ".", "config", ".", "opponent_pool_config", ".", "pool_increment_period", ":", "\n", "                            ", "self", ".", "add_model_to_pool", "(", "attacker", "=", "False", ")", "\n", "num_defender_pool_iterations", "=", "0", "\n", "\n", "", "if", "num_attacker_opponent_iterations", ">", "self", ".", "config", ".", "opponent_pool_config", ".", "head_to_head_period", ":", "\n", "                            ", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "config", ".", "opponent_pool_config", ".", "pool_prob", ":", "\n", "                                ", "self", ".", "attacker_opponent_idx", "=", "self", ".", "sample_opponent", "(", "attacker", "=", "True", ")", "\n", "if", "self", ".", "config", ".", "opponent_pool_config", ".", "quality_scores", ":", "\n", "                                    ", "self", ".", "attacker_opponent", "=", "self", ".", "attacker_pool", "[", "self", ".", "attacker_opponent_idx", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "                                    ", "self", ".", "attacker_opponent", "=", "self", ".", "attacker_pool", "[", "self", ".", "attacker_opponent_idx", "]", "\n", "", "", "else", ":", "\n", "                                ", "self", ".", "attacker_opponent", "=", "self", ".", "attacker_policy_network", "\n", "self", ".", "attacker_opponent_idx", "=", "None", "\n", "\n", "", "num_attacker_opponent_iterations", "=", "0", "\n", "total_num_episodes", "+=", "1", "\n", "\n", "# End Batch", "\n", "\n", "# Perform Policy Gradient updates", "\n", "", "", "", "", "if", "self", ".", "config", ".", "attacker", ":", "\n", "                ", "if", "not", "self", ".", "config", ".", "alternating_optimization", "or", "(", "self", ".", "config", ".", "alternating_optimization", "and", "train_attacker", ")", ":", "\n", "                    ", "loss", "=", "self", ".", "training_step", "(", "saved_attacker_rewards_batch", ",", "saved_attacker_log_probs_batch", ",", "\n", "saved_attacker_state_values_batch", ",", "attacker", "=", "True", ")", "\n", "episode_attacker_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "", "", "if", "self", ".", "config", ".", "defender", ":", "\n", "                ", "if", "not", "self", ".", "config", ".", "alternating_optimization", "or", "(", "self", ".", "config", ".", "alternating_optimization", "and", "train_defender", ")", ":", "\n", "                    ", "loss", "=", "self", ".", "training_step", "(", "saved_defender_rewards_batch", ",", "saved_defender_log_probs_batch", ",", "\n", "saved_defender_state_values_batch", ",", "attacker", "=", "False", ")", "\n", "episode_defender_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "# Reset batch", "\n", "", "", "saved_attacker_log_probs_batch", "=", "[", "]", "\n", "saved_attacker_rewards_batch", "=", "[", "]", "\n", "saved_attacker_state_values_batch", "=", "[", "]", "\n", "saved_defender_log_probs_batch", "=", "[", "]", "\n", "saved_defender_rewards_batch", "=", "[", "]", "\n", "saved_defender_state_values_batch", "=", "[", "]", "\n", "\n", "# Log values and gradients of the parameters (histogram summary) to tensorboard", "\n", "if", "self", ".", "config", ".", "attacker", "and", "train_attacker", ":", "\n", "                ", "for", "tag", ",", "value", "in", "self", ".", "attacker_policy_network", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "tag", "=", "tag", ".", "replace", "(", "'.'", ",", "'/'", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_histogram", "(", "tag", ",", "value", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "iter", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_histogram", "(", "tag", "+", "'_attacker/grad'", ",", "\n", "value", ".", "grad", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "iter", ")", "\n", "\n", "", "", "if", "self", ".", "config", ".", "defender", "and", "train_defender", ":", "\n", "                ", "for", "tag", ",", "value", "in", "self", ".", "defender_policy_network", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "tag", "=", "tag", ".", "replace", "(", "'.'", ",", "'/'", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_histogram", "(", "tag", ",", "value", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "iter", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_histogram", "(", "tag", "+", "'_defender/grad'", ",", "\n", "value", ".", "grad", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "iter", ")", "\n", "", "", "num_alt_iterations", "+=", "1", "\n", "\n", "if", "self", ".", "config", ".", "batch_size", ">", "0", ":", "\n", "                ", "if", "self", ".", "config", ".", "attacker", ":", "\n", "                    ", "episode_avg_attacker_loss", ".", "append", "(", "episode_attacker_loss", "/", "self", ".", "config", ".", "batch_size", ")", "\n", "", "if", "self", ".", "config", ".", "defender", ":", "\n", "                    ", "episode_avg_defender_loss", ".", "append", "(", "episode_defender_loss", "/", "self", ".", "config", ".", "batch_size", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "config", ".", "attacker", ":", "\n", "                    ", "episode_avg_attacker_loss", ".", "append", "(", "episode_attacker_loss", ")", "\n", "", "if", "self", ".", "config", ".", "defender", ":", "\n", "                    ", "episode_avg_defender_loss", ".", "append", "(", "episode_defender_loss", ")", "\n", "\n", "# Decay LR after every iteration", "\n", "", "", "lr_attacker", "=", "self", ".", "config", ".", "alpha_attacker", "\n", "if", "self", ".", "config", ".", "lr_exp_decay", ":", "\n", "                ", "self", ".", "attacker_lr_decay", ".", "step", "(", ")", "\n", "lr_attacker", "=", "self", ".", "attacker_lr_decay", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "\n", "# Decay LR after every iter", "\n", "", "lr_defender", "=", "self", ".", "config", ".", "alpha_attacker", "\n", "if", "self", ".", "config", ".", "lr_exp_decay", ":", "\n", "                ", "self", ".", "defender_lr_decay", ".", "step", "(", ")", "\n", "lr_defender", "=", "self", ".", "defender_lr_decay", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "\n", "", "if", "self", ".", "config", ".", "alternating_optimization", "and", "self", ".", "config", ".", "opponent_pool", ":", "\n", "                ", "if", "train_attacker", ":", "\n", "                    ", "num_attacker_pool_iterations", "+=", "1", "\n", "num_defender_opponent_iterations", "+=", "1", "\n", "\n", "", "if", "train_defender", ":", "\n", "                    ", "num_defender_pool_iterations", "+=", "1", "\n", "num_attacker_opponent_iterations", "+=", "1", "\n", "\n", "\n", "# Update opponent pool qualities", "\n", "", "", "if", "self", ".", "config", ".", "opponent_pool", "and", "self", ".", "config", ".", "opponent_pool_config", "is", "not", "None", "and", "self", ".", "config", ".", "opponent_pool_config", ".", "quality_scores", ":", "\n", "                ", "if", "train_attacker", "and", "self", ".", "defender_opponent_idx", "is", "not", "None", "and", "self", ".", "env", ".", "state", ".", "hacked", ":", "\n", "                    ", "self", ".", "update_quality_score", "(", "self", ".", "defender_opponent_idx", ",", "attacker", "=", "False", ")", "\n", "", "if", "train_defender", "and", "self", ".", "attacker_opponent_idx", "is", "not", "None", "and", "not", "self", ".", "env", ".", "state", ".", "hacked", ":", "\n", "                    ", "self", ".", "update_quality_score", "(", "self", ".", "attacker_opponent_idx", ",", "attacker", "=", "True", ")", "\n", "\n", "# Log average metrics every <self.config.train_log_frequency> iterations", "\n", "", "", "if", "iter", "%", "self", ".", "config", ".", "train_log_frequency", "==", "0", ":", "\n", "                ", "if", "self", ".", "num_train_games", ">", "0", "and", "self", ".", "num_train_games_total", ">", "0", ":", "\n", "                    ", "self", ".", "train_hack_probability", "=", "self", ".", "num_train_hacks", "/", "self", ".", "num_train_games", "\n", "self", ".", "train_cumulative_hack_probability", "=", "self", ".", "num_train_hacks_total", "/", "self", ".", "num_train_games_total", "\n", "", "else", ":", "\n", "                    ", "self", ".", "train_hack_probability", "=", "0.0", "\n", "self", ".", "train_cumulative_hack_probability", "=", "0.0", "\n", "", "a_pool", "=", "None", "\n", "d_pool", "=", "None", "\n", "if", "self", ".", "config", ".", "opponent_pool", "and", "self", ".", "config", ".", "opponent_pool_config", "is", "not", "None", ":", "\n", "                    ", "a_pool", "=", "len", "(", "self", ".", "attacker_pool", ")", "\n", "d_pool", "=", "len", "(", "self", ".", "defender_pool", ")", "\n", "", "self", ".", "log_metrics", "(", "iter", ",", "self", ".", "train_result", ",", "episode_attacker_rewards", ",", "episode_defender_rewards", ",", "episode_steps", ",", "\n", "episode_avg_attacker_loss", ",", "episode_avg_defender_loss", ",", "lr_attacker", "=", "lr_attacker", ",", "\n", "lr_defender", "=", "lr_defender", ",", "\n", "train_attacker", "=", "(", "self", ".", "config", ".", "attacker", "and", "train_attacker", ")", ",", "\n", "train_defender", "=", "(", "self", ".", "config", ".", "defender", "and", "train_defender", ")", ",", "\n", "a_pool", "=", "a_pool", ",", "d_pool", "=", "d_pool", ",", "total_num_episodes", "=", "total_num_episodes", ")", "\n", "\n", "episode_attacker_rewards", "=", "[", "]", "\n", "episode_defender_rewards", "=", "[", "]", "\n", "episode_steps", "=", "[", "]", "\n", "self", ".", "num_train_games", "=", "0", "\n", "self", ".", "num_train_hacks", "=", "0", "\n", "\n", "# Run evaluation every <self.config.eval_frequency> iterations", "\n", "", "if", "iter", "%", "self", ".", "config", ".", "eval_frequency", "==", "0", ":", "\n", "                ", "self", ".", "eval", "(", "iter", ")", "\n", "if", "self", ".", "config", ".", "opponent_pool", "and", "self", ".", "config", ".", "opponent_pool_config", "is", "not", "None", ":", "\n", "                    ", "self", ".", "log_action_dist", "(", "attacker_initial_state_action_dist", ",", "attacker", "=", "True", ")", "\n", "self", ".", "log_action_dist", "(", "defender_initial_state_action_dist", ",", "attacker", "=", "False", ")", "\n", "\n", "# Save models and other state every <self.config.checkpoint_frequency> iterations", "\n", "", "", "if", "iter", "%", "self", ".", "config", ".", "checkpoint_freq", "==", "0", ":", "\n", "                ", "self", ".", "save_model", "(", ")", "\n", "self", ".", "env", ".", "save_trajectories", "(", ")", "\n", "self", ".", "env", ".", "save_attack_data", "(", "checkpoint", "=", "True", ")", "\n", "if", "self", ".", "config", ".", "save_dir", "is", "not", "None", ":", "\n", "                    ", "time_str", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "self", ".", "train_result", ".", "to_csv", "(", "self", ".", "config", ".", "save_dir", "+", "\"/\"", "+", "time_str", "+", "\"_train_results_checkpoint.csv\"", ")", "\n", "self", ".", "eval_result", ".", "to_csv", "(", "self", ".", "config", ".", "save_dir", "+", "\"/\"", "+", "time_str", "+", "\"_eval_results_checkpoint.csv\"", ")", "\n", "", "if", "self", ".", "config", ".", "opponent_pool", "and", "self", ".", "config", ".", "opponent_pool_config", "is", "not", "None", ":", "\n", "                    ", "self", ".", "create_policy_plot", "(", "attacker_initial_state_action_dist", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "iter", ",", "\n", "attacker", "=", "True", ")", "\n", "self", ".", "create_policy_plot", "(", "defender_initial_state_action_dist", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "iter", ",", "\n", "attacker", "=", "False", ")", "\n", "\n", "# If doing alternating optimization and the alternating period is up, change agent that is optimized", "\n", "", "", "if", "self", ".", "config", ".", "alternating_optimization", "and", "num_alt_iterations", ">", "self", ".", "config", ".", "alternating_period", ":", "\n", "                ", "train_defender", "=", "not", "train_defender", "\n", "train_attacker", "=", "not", "train_attacker", "\n", "num_alt_iterations", "=", "0", "\n", "\n", "# Anneal epsilon linearly", "\n", "", "self", ".", "anneal_epsilon", "(", ")", "\n", "\n", "self", ".", "outer_train", ".", "update", "(", "1", ")", "\n", "\n", "", "self", ".", "config", ".", "logger", ".", "info", "(", "\"Training Complete\"", ")", "\n", "\n", "# Final evaluation (for saving Gifs etc)", "\n", "self", ".", "eval", "(", "self", ".", "config", ".", "num_episodes", "-", "1", ",", "log", "=", "False", ")", "\n", "\n", "# Save networks", "\n", "self", ".", "save_model", "(", ")", "\n", "\n", "# Save other game data", "\n", "self", ".", "env", ".", "save_trajectories", "(", "checkpoint", "=", "False", ")", "\n", "self", ".", "env", ".", "save_attack_data", "(", "checkpoint", "=", "False", ")", "\n", "if", "self", ".", "config", ".", "save_dir", "is", "not", "None", ":", "\n", "            ", "time_str", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "self", ".", "train_result", ".", "to_csv", "(", "self", ".", "config", ".", "save_dir", "+", "\"/\"", "+", "time_str", "+", "\"_train_results_checkpoint.csv\"", ")", "\n", "self", ".", "eval_result", ".", "to_csv", "(", "self", ".", "config", ".", "save_dir", "+", "\"/\"", "+", "time_str", "+", "\"_eval_results_checkpoint.csv\"", ")", "\n", "\n", "", "return", "self", ".", "train_result", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.actor_critic.ActorCriticAgent.create_policy_plot": [[721, 741], ["numpy.random.choice", "gym_idsgame.envs.util.idsgame_util.action_dist_hist", "actor_critic.ActorCriticAgent.tensorboard_writer.add_image", "list", "range", "len", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.action_dist_hist"], ["", "def", "create_policy_plot", "(", "self", ",", "distribution", ",", "episode", ",", "attacker", "=", "True", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Utility function for creating a density plot of the policy distribution p(a|s) and add to Tensorboard\n\n        :param distribution: the distribution to plot\n        :param episode: the episode when the distribution was recorded\n        :param attacker: boolean flag whether it is the attacker or defender\n        :return: None\n        \"\"\"", "\n", "sample", "=", "np", ".", "random", ".", "choice", "(", "list", "(", "range", "(", "len", "(", "distribution", ")", ")", ")", ",", "size", "=", "1000", ",", "p", "=", "distribution", ")", "\n", "tag", "=", "\"Attacker\"", "\n", "file_suffix", "=", "\"initial_state_policy_attacker\"", "\n", "if", "not", "attacker", ":", "\n", "            ", "tag", "=", "\"Defender\"", "\n", "file_suffix", "=", "\"initial_state_policy_defender\"", "\n", "", "title", "=", "tag", "+", "\" Initial State Policy\"", "\n", "data", "=", "idsgame_util", ".", "action_dist_hist", "(", "sample", ",", "title", "=", "title", ",", "xlabel", "=", "\"Action\"", ",", "ylabel", "=", "r\"$\\mathbb{P}(a|s)$\"", ",", "\n", "file_name", "=", "self", ".", "config", ".", "save_dir", "+", "\"/\"", "+", "file_suffix", "+", "\"_\"", "+", "str", "(", "episode", ")", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_image", "(", "str", "(", "episode", ")", "+", "\"_initial_state_policy/\"", "+", "tag", ",", "\n", "data", ",", "global_step", "=", "episode", ",", "dataformats", "=", "\"HWC\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.actor_critic.ActorCriticAgent.update_quality_score": [[742, 765], ["len", "actor_critic.ActorCriticAgent.get_attacker_pool_quality_scores", "actor_critic.ActorCriticAgent.get_softmax_distribution", "len", "actor_critic.ActorCriticAgent.get_defender_pool_quality_scores", "actor_critic.ActorCriticAgent.get_softmax_distribution"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_attacker_pool_quality_scores", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_softmax_distribution", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_defender_pool_quality_scores", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_softmax_distribution"], ["", "def", "update_quality_score", "(", "self", ",", "opponent_idx", ":", "int", ",", "attacker", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Updates the quality score of an opponent in the opponent pool. Using same update rule as was used in\n        \"Dota 2 with Large Scale Deep Reinforcement Learning\" by Berner et. al.\n\n        :param opponent_idx: the index of the opponent in the pool\n        :param attacker: boolean flag whether attacker or defender pool to be updated\n        :return: None\n        \"\"\"", "\n", "if", "attacker", ":", "\n", "            ", "N", "=", "len", "(", "self", ".", "attacker_pool", ")", "\n", "qualities", "=", "self", ".", "get_attacker_pool_quality_scores", "(", ")", "\n", "dist", "=", "self", ".", "get_softmax_distribution", "(", "qualities", ")", "\n", "p", "=", "dist", "[", "opponent_idx", "]", "\n", "self", ".", "attacker_pool", "[", "opponent_idx", "]", "[", "1", "]", "=", "self", ".", "attacker_pool", "[", "opponent_idx", "]", "[", "1", "]", "-", "(", "self", ".", "config", ".", "opponent_pool_config", ".", "quality_score_eta", "/", "(", "N", "*", "p", ")", ")", "\n", "", "else", ":", "\n", "            ", "N", "=", "len", "(", "self", ".", "defender_pool", ")", "\n", "qualities", "=", "self", ".", "get_defender_pool_quality_scores", "(", ")", "\n", "dist", "=", "self", ".", "get_softmax_distribution", "(", "qualities", ")", "\n", "p", "=", "dist", "[", "opponent_idx", "]", "\n", "self", ".", "defender_pool", "[", "opponent_idx", "]", "[", "1", "]", "=", "self", ".", "defender_pool", "[", "opponent_idx", "]", "[", "1", "]", "-", "(", "self", ".", "config", ".", "opponent_pool_config", ".", "quality_score_eta", "/", "(", "N", "*", "p", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.actor_critic.ActorCriticAgent.eval": [[767, 925], ["actor_critic.ActorCriticAgent.config.logger.info", "str", "tqdm.tqdm", "actor_critic.ActorCriticAgent.outer_eval.set_description_str", "actor_critic.ActorCriticAgent.env.reset", "actor_critic.ActorCriticAgent.update_state", "actor_critic.ActorCriticAgent.update_state", "range", "actor_critic.ActorCriticAgent.env.close", "actor_critic.ActorCriticAgent.config.logger.info", "time.time", "len", "actor_critic.ActorCriticAgent.config.logger.warning", "gym_idsgame.envs.rendering.video.idsgame_monitor.IdsGameMonitor", "actor_critic.ActorCriticAgent.config.logger.info", "episode_attacker_rewards.append", "episode_defender_rewards.append", "episode_steps.append", "actor_critic.ActorCriticAgent.env.reset", "actor_critic.ActorCriticAgent.update_state", "actor_critic.ActorCriticAgent.update_state", "actor_critic.ActorCriticAgent.outer_eval.update", "actor_critic.ActorCriticAgent.log_metrics", "AssertionError", "actor_critic.ActorCriticAgent.env.step", "actor_critic.ActorCriticAgent.update_state", "actor_critic.ActorCriticAgent.update_state", "actor_critic.ActorCriticAgent.env.render", "time.sleep", "actor_critic.ActorCriticAgent.log_metrics", "actor_critic.ActorCriticAgent.env.generate_gif", "enumerate", "actor_critic.ActorCriticAgent.env.render", "time.sleep", "actor_critic.ActorCriticAgent.env.local_view_features", "actor_critic.ActorCriticAgent.get_action", "actor_critic.ActorCriticAgent.env.local_view_features", "actor_critic.ActorCriticAgent.get_action", "len", "len", "actor_critic.ActorCriticAgent.tensorboard_writer.add_image", "float", "float", "float", "float", "actor_critic.ActorCriticAgent.get_legal_attacker_actions", "gym_idsgame.agents.training_agents.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global", "float", "float", "float", "float", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_metrics", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_metrics", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.generate_gif", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_legal_attacker_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global"], ["", "", "def", "eval", "(", "self", ",", "train_episode", ",", "log", "=", "True", ")", "->", "ExperimentResult", ":", "\n", "        ", "\"\"\"\n        Performs evaluation with the greedy policy with respect to the learned Q-values\n\n        :param train_episode: the train episode to keep track of logging\n        :param log: whether to log the result\n        :return: None\n        \"\"\"", "\n", "self", ".", "config", ".", "logger", ".", "info", "(", "\"Starting Evaluation\"", ")", "\n", "time_str", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "\n", "self", ".", "num_eval_games", "=", "0", "\n", "self", ".", "num_eval_hacks", "=", "0", "\n", "\n", "if", "len", "(", "self", ".", "eval_result", ".", "avg_episode_steps", ")", ">", "0", ":", "\n", "            ", "self", ".", "config", ".", "logger", ".", "warning", "(", "\"starting eval with non-empty result object\"", ")", "\n", "", "if", "self", ".", "config", ".", "eval_episodes", "<", "1", ":", "\n", "            ", "return", "\n", "", "done", "=", "False", "\n", "\n", "# Video config", "\n", "if", "self", ".", "config", ".", "video", ":", "\n", "            ", "if", "self", ".", "config", ".", "video_dir", "is", "None", ":", "\n", "                ", "raise", "AssertionError", "(", "\"Video is set to True but no video_dir is provided, please specify \"", "\n", "\"the video_dir argument\"", ")", "\n", "", "self", ".", "env", "=", "IdsGameMonitor", "(", "self", ".", "env", ",", "self", ".", "config", ".", "video_dir", "+", "\"/\"", "+", "time_str", ",", "force", "=", "True", ",", "\n", "video_frequency", "=", "self", ".", "config", ".", "video_frequency", ")", "\n", "self", ".", "env", ".", "metadata", "[", "\"video.frames_per_second\"", "]", "=", "self", ".", "config", ".", "video_fps", "\n", "\n", "# Tracking metrics", "\n", "", "episode_attacker_rewards", "=", "[", "]", "\n", "episode_defender_rewards", "=", "[", "]", "\n", "episode_steps", "=", "[", "]", "\n", "\n", "# Logging", "\n", "self", ".", "outer_eval", "=", "tqdm", ".", "tqdm", "(", "total", "=", "self", ".", "config", ".", "eval_episodes", ",", "desc", "=", "'Eval Episode'", ",", "position", "=", "1", ")", "\n", "self", ".", "outer_eval", ".", "set_description_str", "(", "\n", "\"[Eval] avg_a_R:{:.2f},avg_d_R:{:.2f},avg_t:{:.2f},avg_h:{:.2f},acc_A_R:{:.2f},\"", "\"acc_D_R:{:.2f}\"", ".", "format", "(", "0.0", ",", "0", ",", "0", ",", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ")", ")", "\n", "\n", "# Eval", "\n", "attacker_obs", ",", "defender_obs", "=", "self", ".", "env", ".", "reset", "(", "update_stats", "=", "False", ")", "\n", "attacker_state", "=", "self", ".", "update_state", "(", "attacker_obs", "=", "attacker_obs", ",", "defender_obs", "=", "defender_obs", ",", "state", "=", "[", "]", ",", "attacker", "=", "True", ")", "\n", "defender_state", "=", "self", ".", "update_state", "(", "defender_obs", "=", "defender_obs", ",", "attacker_obs", "=", "attacker_obs", ",", "state", "=", "[", "]", ",", "attacker", "=", "False", ")", "\n", "\n", "for", "episode", "in", "range", "(", "self", ".", "config", ".", "eval_episodes", ")", ":", "\n", "            ", "episode_attacker_reward", "=", "0", "\n", "episode_defender_reward", "=", "0", "\n", "episode_step", "=", "0", "\n", "while", "not", "done", ":", "\n", "                ", "if", "self", ".", "config", ".", "eval_render", ":", "\n", "                    ", "self", ".", "env", ".", "render", "(", ")", "\n", "time", ".", "sleep", "(", "self", ".", "config", ".", "eval_sleep", ")", "\n", "\n", "# Default initialization", "\n", "", "attacker_action", "=", "0", "\n", "defender_action", "=", "0", "\n", "\n", "# Get attacker and defender actions", "\n", "if", "self", ".", "config", ".", "attacker", ":", "\n", "                    ", "legal_actions", "=", "None", "\n", "illegal_actions", "=", "None", "\n", "if", "self", ".", "env", ".", "local_view_features", "(", ")", ":", "\n", "                        ", "legal_actions", ",", "illegal_actions", "=", "self", ".", "get_legal_attacker_actions", "(", "attacker_obs", ")", "\n", "", "attacker_action", ",", "_", ",", "_", ",", "_", "=", "self", ".", "get_action", "(", "attacker_state", ",", "attacker", "=", "True", ",", "\n", "legal_actions", "=", "legal_actions", ",", "\n", "non_legal_actions", "=", "illegal_actions", ")", "\n", "if", "self", ".", "env", ".", "local_view_features", "(", ")", ":", "\n", "                        ", "attacker_action", "=", "PolicyGradientAgent", ".", "convert_local_attacker_action_to_global", "(", "attacker_action", ",", "attacker_obs", ")", "\n", "", "", "if", "self", ".", "config", ".", "defender", ":", "\n", "                    ", "defender_action", ",", "_", ",", "_", ",", "_", "=", "self", ".", "get_action", "(", "defender_state", ",", "attacker", "=", "False", ")", "\n", "", "action", "=", "(", "attacker_action", ",", "defender_action", ")", "\n", "\n", "# Take a step in the environment", "\n", "obs_prime", ",", "reward", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "\n", "# Update state information and metrics", "\n", "attacker_reward", ",", "defender_reward", "=", "reward", "\n", "obs_prime_attacker", ",", "obs_prime_defender", "=", "obs_prime", "\n", "episode_attacker_reward", "+=", "attacker_reward", "\n", "episode_defender_reward", "+=", "defender_reward", "\n", "episode_step", "+=", "1", "\n", "attacker_obs", "=", "obs_prime_attacker", "\n", "defender_obs", "=", "obs_prime_defender", "\n", "attacker_state", "=", "self", ".", "update_state", "(", "attacker_obs", "=", "attacker_obs", ",", "defender_obs", "=", "defender_obs", ",", "state", "=", "attacker_state", ",", "attacker", "=", "True", ")", "\n", "defender_state", "=", "self", ".", "update_state", "(", "defender_obs", "=", "defender_obs", ",", "attacker_obs", "=", "attacker_obs", ",", "state", "=", "defender_state", ",", "attacker", "=", "False", ")", "\n", "\n", "# Render final frame when game completed", "\n", "", "if", "self", ".", "config", ".", "eval_render", ":", "\n", "                ", "self", ".", "env", ".", "render", "(", ")", "\n", "time", ".", "sleep", "(", "self", ".", "config", ".", "eval_sleep", ")", "\n", "", "self", ".", "config", ".", "logger", ".", "info", "(", "\"Eval episode: {}, Game ended after {} steps\"", ".", "format", "(", "episode", ",", "episode_step", ")", ")", "\n", "\n", "# Record episode metrics", "\n", "episode_attacker_rewards", ".", "append", "(", "episode_attacker_reward", ")", "\n", "episode_defender_rewards", ".", "append", "(", "episode_defender_reward", ")", "\n", "episode_steps", ".", "append", "(", "episode_step", ")", "\n", "\n", "# Update eval stats", "\n", "self", ".", "num_eval_games", "+=", "1", "\n", "self", ".", "num_eval_games_total", "+=", "1", "\n", "if", "self", ".", "env", ".", "state", ".", "detected", ":", "\n", "                ", "self", ".", "eval_attacker_cumulative_reward", "-=", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", "\n", "self", ".", "eval_defender_cumulative_reward", "+=", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", "\n", "", "if", "self", ".", "env", ".", "state", ".", "hacked", ":", "\n", "                ", "self", ".", "eval_attacker_cumulative_reward", "+=", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", "\n", "self", ".", "eval_defender_cumulative_reward", "-=", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", "\n", "self", ".", "num_eval_hacks", "+=", "1", "\n", "self", ".", "num_eval_hacks_total", "+=", "1", "\n", "\n", "# Log average metrics every <self.config.eval_log_frequency> episodes", "\n", "", "if", "episode", "%", "self", ".", "config", ".", "eval_log_frequency", "==", "0", "and", "log", ":", "\n", "                ", "if", "self", ".", "num_eval_hacks", ">", "0", ":", "\n", "                    ", "self", ".", "eval_hack_probability", "=", "float", "(", "self", ".", "num_eval_hacks", ")", "/", "float", "(", "self", ".", "num_eval_games", ")", "\n", "", "if", "self", ".", "num_eval_games_total", ">", "0", ":", "\n", "                    ", "self", ".", "eval_cumulative_hack_probability", "=", "float", "(", "self", ".", "num_eval_hacks_total", ")", "/", "float", "(", "\n", "self", ".", "num_eval_games_total", ")", "\n", "", "a_pool", "=", "None", "\n", "d_pool", "=", "None", "\n", "if", "self", ".", "config", ".", "opponent_pool", "and", "self", ".", "config", ".", "opponent_pool_config", "is", "not", "None", ":", "\n", "                    ", "a_pool", "=", "len", "(", "self", ".", "attacker_pool", ")", "\n", "d_pool", "=", "len", "(", "self", ".", "defender_pool", ")", "\n", "", "self", ".", "log_metrics", "(", "episode", ",", "self", ".", "eval_result", ",", "episode_attacker_rewards", ",", "episode_defender_rewards", ",", "episode_steps", ",", "\n", "eval", "=", "True", ",", "update_stats", "=", "False", ",", "a_pool", "=", "a_pool", ",", "d_pool", "=", "d_pool", ")", "\n", "\n", "# Save gifs", "\n", "", "if", "self", ".", "config", ".", "gifs", "and", "self", ".", "config", ".", "video", ":", "\n", "                ", "self", ".", "env", ".", "generate_gif", "(", "self", ".", "config", ".", "gif_dir", "+", "\"/episode_\"", "+", "str", "(", "train_episode", ")", "+", "\"_\"", "\n", "+", "time_str", "+", "\".gif\"", ",", "self", ".", "config", ".", "video_fps", ")", "\n", "\n", "# Add frames to tensorboard", "\n", "for", "idx", ",", "frame", "in", "enumerate", "(", "self", ".", "env", ".", "episode_frames", ")", ":", "\n", "                    ", "self", ".", "tensorboard_writer", ".", "add_image", "(", "str", "(", "train_episode", ")", "+", "\"_eval_frames/\"", "+", "str", "(", "idx", ")", ",", "\n", "frame", ",", "global_step", "=", "train_episode", ",", "\n", "dataformats", "=", "\"HWC\"", ")", "\n", "\n", "\n", "# Reset for new eval episode", "\n", "", "", "done", "=", "False", "\n", "attacker_obs", ",", "defender_obs", "=", "self", ".", "env", ".", "reset", "(", "update_stats", "=", "False", ")", "\n", "attacker_state", "=", "self", ".", "update_state", "(", "attacker_obs", "=", "attacker_obs", ",", "defender_obs", "=", "defender_obs", ",", "state", "=", "attacker_state", ",", "attacker", "=", "True", ")", "\n", "defender_state", "=", "self", ".", "update_state", "(", "defender_obs", "=", "defender_obs", ",", "attacker_obs", "=", "attacker_obs", ",", "state", "=", "defender_state", ",", "attacker", "=", "False", ")", "\n", "self", ".", "outer_eval", ".", "update", "(", "1", ")", "\n", "\n", "# Log average eval statistics", "\n", "", "if", "log", ":", "\n", "            ", "if", "self", ".", "num_eval_hacks", ">", "0", ":", "\n", "                ", "self", ".", "eval_hack_probability", "=", "float", "(", "self", ".", "num_eval_hacks", ")", "/", "float", "(", "self", ".", "num_eval_games", ")", "\n", "", "if", "self", ".", "num_eval_games_total", ">", "0", ":", "\n", "                ", "self", ".", "eval_cumulative_hack_probability", "=", "float", "(", "self", ".", "num_eval_hacks_total", ")", "/", "float", "(", "\n", "self", ".", "num_eval_games_total", ")", "\n", "\n", "", "self", ".", "log_metrics", "(", "train_episode", ",", "self", ".", "eval_result", ",", "episode_attacker_rewards", ",", "episode_defender_rewards", ",", "\n", "episode_steps", ",", "eval", "=", "True", ",", "update_stats", "=", "True", ")", "\n", "\n", "", "self", ".", "env", ".", "close", "(", ")", "\n", "self", ".", "config", ".", "logger", ".", "info", "(", "\"Evaluation Complete\"", ")", "\n", "return", "self", ".", "eval_result", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic.actor_critic.ActorCriticAgent.save_model": [[926, 944], ["str", "time.time", "actor_critic.ActorCriticAgent.config.logger.warning", "actor_critic.ActorCriticAgent.config.logger.info", "torch.save", "actor_critic.ActorCriticAgent.config.logger.info", "torch.save", "actor_critic.ActorCriticAgent.attacker_policy_network.state_dict", "actor_critic.ActorCriticAgent.defender_policy_network.state_dict"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save"], ["", "def", "save_model", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Saves the PyTorch Model Weights\n\n        :return: None\n        \"\"\"", "\n", "time_str", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "if", "self", ".", "config", ".", "save_dir", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "config", ".", "attacker", ":", "\n", "                ", "path", "=", "self", ".", "config", ".", "save_dir", "+", "\"/\"", "+", "time_str", "+", "\"_attacker_policy_network.pt\"", "\n", "self", ".", "config", ".", "logger", ".", "info", "(", "\"Saving policy-network to: {}\"", ".", "format", "(", "path", ")", ")", "\n", "torch", ".", "save", "(", "self", ".", "attacker_policy_network", ".", "state_dict", "(", ")", ",", "path", ")", "\n", "", "if", "self", ".", "config", ".", "defender", ":", "\n", "                ", "path", "=", "self", ".", "config", ".", "save_dir", "+", "\"/\"", "+", "time_str", "+", "\"_defender_policy_network.pt\"", "\n", "self", ".", "config", ".", "logger", ".", "info", "(", "\"Saving policy-network to: {}\"", ".", "format", "(", "path", ")", ")", "\n", "torch", ".", "save", "(", "self", ".", "defender_policy_network", ".", "state_dict", "(", ")", ",", "path", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "config", ".", "logger", ".", "warning", "(", "\"Save path not defined, not saving policy-networks to disk\"", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.run.get_script_path": [[14, 19], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.run.default_output_dir": [[21, 27], ["run.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.run.default_config_path": [[29, 35], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.run.hp_tuning_config": [[36, 49], ["gym_idsgame.config.hp_tuning_config.HpTuningConfig"], "function", ["None"], ["\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.run.default_config": [[50, 79], ["gym_idsgame.agents.training_agents.policy_gradient.pg_agent_config.PolicyGradientAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.run.write_default_config": [[80, 91], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "", "def", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.run.plot_csv": [[93, 107], ["experiments.util.plotting_util.read_and_plot_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_results"], ["env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER_AND_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "# Program entrypoint", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "versions", "=", "list", "(", "range", "(", "6", ")", ")", "\n", "for", "version", "in", "versions", ":", "\n", "        ", "print", "(", "\"Test Version: {}\"", ".", "format", "(", "version", ")", ")", "\n", "\n", "print", "(", "\"test_sim_attack_maximal_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.run.plot_average_results": [[109, 125], ["experiments.util.plotting_util.read_and_plot_average_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_average_results"], ["print", "(", "\"test_sim_attack_maximal_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_random", "(", "version", ")", "\n", "print", "(", "\"test_sim_random_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_random_vs_defend_minimal", "(", "version", ")", "\n", "print", "(", "\"test_sim_random_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_random_vs_random", "(", "version", ")", "\n", "print", "(", "\"test_train_maximal_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_minimal_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_tabular_q_learning_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.run.run_experiment": [[126, 169], ["str", "experiments.util.util.create_artefact_dirs", "experiments.util.util.setup_logger", "default_config.pg_agent_config.to_csv", "experiments.util.util.read_config", "run.default_config", "time.time", "experiments.util.hp_tuning.hype_grid", "gym_idsgame.runnner.Runner.run", "os.path.exists", "run.write_default_config", "str", "str", "str", "str", "train_result.to_csv", "eval_result.to_csv", "run.plot_csv", "str", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "len", "len", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.create_artefact_dirs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.setup_logger", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.read_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.hp_tuning.hype_grid", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.write_default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.plot_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.__init__": [[22, 37], ["gym_idsgame.agents.bot_agents.bot_agent.BotAgent.__init__", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.initialize_models", "ValueError", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.initialize_models"], ["def", "__init__", "(", "self", ",", "pg_config", ":", "PolicyGradientAgentConfig", ",", "game_config", ":", "GameConfig", ",", "model_path", ":", "str", "=", "None", ",", "\n", "env", ":", "IdsGameEnv", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Constructor, initializes the policy\n\n        :param game_config: the game configuration\n        \"\"\"", "\n", "super", "(", "PPOBaselineAttackerBotAgent", ",", "self", ")", ".", "__init__", "(", "game_config", ")", "\n", "if", "model_path", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot create a PPOBaselineAttackerBotAgent without specifying the path to the model\"", ")", "\n", "", "self", ".", "idsgame_env", "=", "env", "\n", "self", ".", "config", "=", "pg_config", "\n", "self", ".", "model_path", "=", "model_path", "\n", "self", ".", "initialize_models", "(", ")", "\n", "self", ".", "device", "=", "\"cpu\"", "if", "not", "self", ".", "config", ".", "gpu", "else", "\"cuda:\"", "+", "str", "(", "self", ".", "config", ".", "gpu_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.initialize_models": [[39, 49], ["gym_idsgame.agents.training_agents.openai_baselines.common.ppo.ppo.PPO.load"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load"], ["", "def", "initialize_models", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Initialize models\n        :return: None\n        \"\"\"", "\n", "policy", "=", "\"MlpPolicy\"", "\n", "if", "self", ".", "config", ".", "cnn_feature_extractor", ":", "\n", "            ", "policy", "=", "\"CnnPolicy\"", "\n", "# Initialize models", "\n", "", "self", ".", "model", "=", "PPO", ".", "load", "(", "self", ".", "config", ".", "attacker_load_path", ",", "policy", ",", "pg_agent_config", "=", "self", ".", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.action": [[50, 105], ["ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.idsgame_env.local_view_features", "game_state.get_attacker_observation", "game_state.get_defender_observation", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.update_state", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.convert_local_attacker_action_to_global", "list", "list", "torch.as_tensor().to", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.model.attacker_policy.forward", "list", "list", "torch.as_tensor().to", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.model.attacker_node_policy.forward", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.model.attacker_node_policy.get_action_dist", "attacker_node_actions.cpu().numpy.cpu().numpy.cpu().numpy", "torch.as_tensor().to.reshape", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.model.attacker_at_policy.forward", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.model.attacker_at_policy.get_action_dist", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.create_policy_plot", "attacker_at_actions.cpu().numpy.cpu().numpy.cpu().numpy", "gym_idsgame.get_attack_action_id", "print", "traceback.print_exc", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.idsgame_env.local_view_features", "range", "filter", "attacker_actions.cpu().numpy", "range", "filter", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.detach().cpu().numpy", "str", "torch.as_tensor", "torch.as_tensor", "attacker_node_actions.cpu().numpy.cpu().numpy.cpu", "attacker_at_actions.cpu().numpy.cpu().numpy.cpu", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.flatten", "attacker_actions.cpu", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.flatten", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.detach().cpu", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.is_attack_legal", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.is_attack_legal", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.detach"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.get_attacker_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.get_defender_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.get_action_dist", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.get_action_dist", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.create_policy_plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.get_attack_action_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal"], ["", "def", "action", "(", "self", ",", "game_state", ":", "GameState", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Samples an action from the policy.\n\n        :param game_state: the game state\n        :return: action_id\n        \"\"\"", "\n", "try", ":", "\n", "# Feature engineering", "\n", "            ", "attacker_obs", "=", "game_state", ".", "get_attacker_observation", "(", "\n", "self", ".", "game_config", ".", "network_config", ",", "local_view", "=", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", ",", "\n", "reconnaissance", "=", "self", ".", "game_config", ".", "reconnaissance_actions", ",", "\n", "reconnaissance_bool_features", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ")", "\n", "defender_obs", "=", "game_state", ".", "get_defender_observation", "(", "self", ".", "game_config", ".", "network_config", ")", "\n", "attacker_state", "=", "self", ".", "update_state", "(", "attacker_obs", "=", "attacker_obs", ",", "defender_obs", "=", "defender_obs", ",", "state", "=", "[", "]", ",", "\n", "attacker", "=", "True", ")", "\n", "if", "not", "self", ".", "config", ".", "ar_policy", ":", "\n", "                ", "actions", "=", "list", "(", "range", "(", "self", ".", "idsgame_env", ".", "num_attack_actions", ")", ")", "\n", "non_legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "not", "self", ".", "is_attack_legal", "(", "action", ",", "attacker_obs", ",", "game_state", ")", ",", "actions", ")", ")", "\n", "obs_tensor_a", "=", "torch", ".", "as_tensor", "(", "attacker_state", ".", "flatten", "(", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "attacker_actions", ",", "attacker_values", ",", "attacker_log_probs", "=", "self", ".", "model", ".", "attacker_policy", ".", "forward", "(", "\n", "obs_tensor_a", ",", "self", ".", "idsgame_env", ",", "device", "=", "self", ".", "device", ",", "attacker", "=", "True", ",", "non_legal_actions", "=", "non_legal_actions", ")", "\n", "attacker_action", "=", "attacker_actions", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "actions", "=", "list", "(", "range", "(", "self", ".", "config", ".", "attacker_node_net_output_dim", ")", ")", "\n", "non_legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "not", "self", ".", "is_attack_legal", "(", "action", ",", "attacker_obs", ",", "game_state", ",", "node", "=", "True", ")", ",", "actions", ")", ")", "\n", "obs_tensor_a", "=", "torch", ".", "as_tensor", "(", "attacker_state", ".", "flatten", "(", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "attacker_node_actions", ",", "attacker_node_values", ",", "attacker_node_log_probs", ",", "attacker_node_lstm_state", "=", "self", ".", "model", ".", "attacker_node_policy", ".", "forward", "(", "\n", "obs_tensor_a", ",", "self", ".", "idsgame_env", ",", "device", "=", "self", ".", "device", ",", "attacker", "=", "True", ",", "non_legal_actions", "=", "non_legal_actions", ")", "\n", "attacker_node_probs", "=", "self", ".", "model", ".", "attacker_node_policy", ".", "get_action_dist", "(", "obs_tensor_a", ",", "self", ".", "idsgame_env", ",", "device", "=", "self", ".", "device", ",", "attacker", "=", "True", ",", "\n", "non_legal_actions", "=", "non_legal_actions", ")", "\n", "attacker_node_actions", "=", "attacker_node_actions", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "node", "=", "attacker_node_actions", "[", "0", "]", "\n", "obs_tensor_a_1", "=", "obs_tensor_a", ".", "reshape", "(", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_nodes", ",", "self", ".", "config", ".", "attacker_at_net_input_dim", ")", "\n", "obs_tensor_a_at", "=", "obs_tensor_a_1", "[", "node", "]", "\n", "attacker_at_actions", ",", "attacker_at_values", ",", "attacker_at_log_probs", ",", "attacker_at_lstm_state", "=", "self", ".", "model", ".", "attacker_at_policy", ".", "forward", "(", "\n", "obs_tensor_a_at", ",", "self", ".", "idsgame_env", ",", "device", "=", "self", ".", "device", ",", "attacker", "=", "True", ",", "non_legal_actions", "=", "non_legal_actions", ")", "\n", "attacker_at_probs", "=", "self", ".", "model", ".", "attacker_at_policy", ".", "get_action_dist", "(", "obs_tensor_a_at", ",", "self", ".", "idsgame_env", ",", "\n", "device", "=", "self", ".", "device", ",", "attacker", "=", "True", ",", "\n", "non_legal_actions", "=", "non_legal_actions", ")", "\n", "# print(\"attacker node probs:{}\".format(attacker_node_probs.detach().cpu().numpy()))", "\n", "# print(\"attacker at probs:{}\".format(attacker_at_probs.detach().cpu().numpy()))", "\n", "self", ".", "create_policy_plot", "(", "attacker_at_probs", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "0", ",", "attacker", "=", "True", ")", "\n", "attacker_at_actions", "=", "attacker_at_actions", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "attack_id", "=", "util", ".", "get_attack_action_id", "(", "node", ",", "attacker_at_actions", "[", "0", "]", ",", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ")", "\n", "attacker_action", "=", "attack_id", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "str", "(", "e", ")", ")", "\n", "traceback", ".", "print_exc", "(", ")", "\n", "\n", "", "if", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", ":", "\n", "            ", "attack", "=", "self", ".", "convert_local_attacker_action_to_global", "(", "attacker_action", ",", "attacker_obs", ")", "\n", "return", "attack", "\n", "", "else", ":", "\n", "            ", "return", "attacker_action", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.is_attack_legal": [[106, 126], ["ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.idsgame_env.local_view_features", "gym_idsgame.is_attack_id_legal", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.convert_local_attacker_action_to_global", "gym_idsgame.is_node_attack_legal"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_attack_id_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_node_attack_legal"], ["", "", "def", "is_attack_legal", "(", "self", ",", "action", ",", "obs", ",", "game_state", ",", "node", ":", "bool", "=", "False", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Check if a given attack is legal or not.\n\n        :param attack_action: the attack to verify\n        :return: True if legal otherwise False\n        \"\"\"", "\n", "if", "not", "self", ".", "config", ".", "ar_policy", ":", "\n", "            ", "if", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", ":", "\n", "                ", "action", "=", "self", ".", "convert_local_attacker_action_to_global", "(", "action", ",", "obs", ")", "\n", "if", "action", "==", "-", "1", ":", "\n", "                    ", "return", "False", "\n", "", "", "return", "util", ".", "is_attack_id_legal", "(", "action", ",", "self", ".", "game_config", ",", "\n", "game_state", ".", "attacker_pos", ",", "game_state", ",", "[", "]", ")", "\n", "", "else", ":", "\n", "            ", "if", "node", ":", "\n", "                ", "return", "util", ".", "is_node_attack_legal", "(", "action", ",", "game_state", ".", "attacker_pos", ",", "\n", "self", ".", "game_config", ".", "network_config", ")", "\n", "", "else", ":", "\n", "                ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.convert_local_attacker_action_to_global": [[127, 136], ["int"], "methods", ["None"], ["", "", "", "def", "convert_local_attacker_action_to_global", "(", "self", ",", "action_id", ",", "attacker_obs", ")", ":", "\n", "        ", "num_attack_types", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "\n", "neighbor", "=", "action_id", "//", "(", "num_attack_types", "+", "1", ")", "\n", "attack_type", "=", "action_id", "%", "(", "num_attack_types", "+", "1", ")", "\n", "target_id", "=", "int", "(", "attacker_obs", "[", "neighbor", "]", "[", "num_attack_types", "]", ")", "\n", "if", "target_id", "==", "-", "1", ":", "\n", "            ", "return", "-", "1", "\n", "", "attacker_action", "=", "target_id", "*", "(", "num_attack_types", "+", "1", ")", "+", "attack_type", "\n", "return", "attacker_action", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.update_state": [[137, 363], ["ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.idsgame_env.local_view_features", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.idsgame_env.state.get_attacker_observation", "enumerate", "enumerate", "numpy.array", "numpy.array", "enumerate", "enumerate", "numpy.array", "numpy.array", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.idsgame_env.local_view_features", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.idsgame_env.fully_observed", "numpy.mean", "numpy.isnan().any", "zero_mean_attacker_features.append", "numpy.mean", "numpy.isnan().any", "zero_mean_defender_features.append", "numpy.isnan().any", "normalized_attacker_features.append", "numpy.isnan().any", "normalized_defender_features.append", "numpy.zeros", "range", "numpy.array", "numpy.append", "numpy.append", "len", "numpy.append", "numpy.append", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.idsgame_env.local_view_features", "row.tolist.tolist", "row.tolist.tolist", "row.tolist.append", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.idsgame_env.local_view_features", "numpy.linalg.norm", "numpy.linalg.norm", "row.tolist", "numpy.linalg.norm", "numpy.linalg.norm", "int", "enumerate", "enumerate", "numpy.zeros", "range", "len", "numpy.array", "numpy.array", "len", "numpy.array", "numpy.append", "numpy.append", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.isnan", "row.tolist.append", "row.tolist.append", "row.tolist.append", "numpy.isnan", "numpy.isnan", "row.tolist.append", "row.tolist.append", "row.tolist.append", "numpy.isnan", "row.tolist", "row.tolist.append", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.idsgame_env.local_view_features", "row.tolist", "row.tolist.append", "numpy.array.append", "numpy.full", "range", "row.tolist", "row.tolist.append", "numpy.array.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.idsgame_env.local_view_features", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.idsgame_env.local_view_features", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.idsgame_env.local_view_features", "row.tolist.append", "len", "row.tolist.append", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.idsgame_env.local_view_features", "enumerate", "numpy.array", "numpy.zeros", "range", "numpy.zeros", "range", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.idsgame_env.local_view_features", "numpy.sum", "numpy.append", "numpy.array.append", "numpy.array", "numpy.zeros", "range", "numpy.append", "numpy.append", "numpy.append", "numpy.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.get_attacker_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.fully_observed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features"], ["", "def", "update_state", "(", "self", ",", "attacker_obs", ":", "np", ".", "ndarray", "=", "None", ",", "defender_obs", ":", "np", ".", "ndarray", "=", "None", ",", "\n", "state", ":", "np", ".", "ndarray", "=", "None", ",", "attacker", ":", "bool", "=", "True", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Update approximative Markov state\n\n        :param attacker_obs: attacker obs\n        :param defender_obs: defender observation\n        :param state: current state\n        :param attacker: boolean flag whether it is attacker or not\n        :return: new state\n        \"\"\"", "\n", "if", "attacker", "and", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "            ", "a_obs_len", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", "\n", "defender_obs", "=", "attacker_obs", "[", ":", ",", "\n", "a_obs_len", ":", "a_obs_len", "+", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "]", "\n", "if", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ":", "\n", "                ", "d_bool_features", "=", "attacker_obs", "[", ":", ",", "\n", "a_obs_len", "+", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ":", "]", "\n", "", "attacker_obs", "=", "attacker_obs", "[", ":", ",", "0", ":", "a_obs_len", "]", "\n", "\n", "", "if", "not", "attacker", "and", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", ":", "\n", "            ", "attacker_obs", "=", "self", ".", "idsgame_env", ".", "state", ".", "get_attacker_observation", "(", "\n", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "network_config", ",", "\n", "local_view", "=", "False", ",", "\n", "reconnaissance", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_actions", ")", "\n", "\n", "# Zero mean", "\n", "", "if", "self", ".", "config", ".", "zero_mean_features", ":", "\n", "            ", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                ", "attacker_obs_1", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "attacker_obs_1", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "2", "]", "\n", "", "zero_mean_attacker_features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "attacker_obs_1", ")", ":", "\n", "                ", "mean", "=", "np", ".", "mean", "(", "row", ")", "\n", "if", "mean", "!=", "0", ":", "\n", "                    ", "t", "=", "row", "-", "mean", "\n", "", "else", ":", "\n", "                    ", "t", "=", "row", "\n", "", "if", "np", ".", "isnan", "(", "t", ")", ".", "any", "(", ")", ":", "\n", "                    ", "t", "=", "attacker_obs", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "t", "=", "t", ".", "tolist", "(", ")", "\n", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                        ", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                        ", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "2", "]", ")", "\n", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "", "zero_mean_attacker_features", ".", "append", "(", "t", ")", "\n", "\n", "", "defender_obs_1", "=", "defender_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "zero_mean_defender_features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "defender_obs_1", ")", ":", "\n", "                ", "mean", "=", "np", ".", "mean", "(", "row", ")", "\n", "if", "mean", "!=", "0", ":", "\n", "                    ", "t", "=", "row", "-", "mean", "\n", "", "else", ":", "\n", "                    ", "t", "=", "row", "\n", "", "if", "np", ".", "isnan", "(", "t", ")", ".", "any", "(", ")", ":", "\n", "                    ", "t", "=", "defender_obs", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "t", "=", "t", ".", "tolist", "(", ")", "\n", "t", ".", "append", "(", "defender_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "zero_mean_defender_features", ".", "append", "(", "t", ")", "\n", "\n", "", "attacker_obs", "=", "np", ".", "array", "(", "zero_mean_attacker_features", ")", "\n", "defender_obs", "=", "np", ".", "array", "(", "zero_mean_defender_features", ")", "\n", "\n", "# Normalize", "\n", "", "if", "self", ".", "config", ".", "normalize_features", ":", "\n", "            ", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                ", "attacker_obs_1", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "/", "np", ".", "linalg", ".", "norm", "(", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "attacker_obs_1", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "2", "]", "/", "np", ".", "linalg", ".", "norm", "(", "attacker_obs", "[", ":", ",", "0", ":", "-", "2", "]", ")", "\n", "", "normalized_attacker_features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "attacker_obs_1", ")", ":", "\n", "                ", "if", "np", ".", "isnan", "(", "attacker_obs_1", ")", ".", "any", "(", ")", ":", "\n", "                    ", "t", "=", "attacker_obs", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                        ", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                        ", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "2", "]", ")", "\n", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "", "normalized_attacker_features", ".", "append", "(", "t", ")", "\n", "\n", "", "if", "attacker", "and", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                ", "defender_obs_1", "=", "defender_obs", "[", ":", ",", "0", ":", "-", "1", "]", "/", "np", ".", "linalg", ".", "norm", "(", "defender_obs", "[", ":", ",", "0", ":", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "defender_obs_1", "=", "defender_obs", "/", "np", ".", "linalg", ".", "norm", "(", "defender_obs", ")", "\n", "", "normalized_defender_features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "defender_obs_1", ")", ":", "\n", "                ", "if", "np", ".", "isnan", "(", "defender_obs_1", ")", ".", "any", "(", ")", ":", "\n", "                    ", "t", "=", "defender_obs", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "if", "attacker", "and", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "t", ".", "append", "(", "defender_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                        ", "t", "=", "row", "\n", "\n", "", "", "normalized_defender_features", ".", "append", "(", "t", ")", "\n", "\n", "", "attacker_obs", "=", "np", ".", "array", "(", "normalized_attacker_features", ")", "\n", "defender_obs", "=", "np", ".", "array", "(", "normalized_defender_features", ")", "\n", "\n", "", "if", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "and", "attacker", ":", "\n", "            ", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                ", "neighbor_defense_attributes", "=", "np", ".", "zeros", "(", "(", "attacker_obs", ".", "shape", "[", "0", "]", ",", "defender_obs", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "node", "in", "range", "(", "attacker_obs", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "id", "=", "int", "(", "attacker_obs", "[", "node", "]", "[", "-", "1", "]", ")", "\n", "neighbor_defense_attributes", "[", "node", "]", "=", "defender_obs", "[", "id", "]", "\n", "", "", "else", ":", "\n", "                ", "neighbor_defense_attributes", "=", "defender_obs", "\n", "\n", "", "", "if", "self", ".", "idsgame_env", ".", "fully_observed", "(", ")", "or", "(", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", "and", "attacker", ")", ":", "\n", "            ", "if", "self", ".", "config", ".", "merged_ad_features", ":", "\n", "                ", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                    ", "a_pos", "=", "attacker_obs", "[", ":", ",", "-", "1", "]", "\n", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "det_values", "=", "defender_obs", "[", ":", ",", "-", "1", "]", "\n", "temp", "=", "defender_obs", "[", ":", ",", "0", ":", "-", "1", "]", "-", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                        ", "temp", "=", "defender_obs", "[", ":", ",", "0", ":", "]", "-", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "temp", ")", ":", "\n", "                        ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "t", ".", "append", "(", "a_pos", "[", "idx", "]", ")", "\n", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                            ", "t", ".", "append", "(", "det_values", "[", "idx", "]", ")", "\n", "", "features", ".", "append", "(", "t", ")", "\n", "", "", "else", ":", "\n", "                    ", "node_ids", "=", "attacker_obs", "[", ":", ",", "-", "1", "]", "\n", "# node_reachable = attacker_obs[:, -1]", "\n", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "det_values", "=", "neighbor_defense_attributes", "[", ":", ",", "-", "1", "]", "\n", "", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "temp", "=", "neighbor_defense_attributes", "[", ":", ",", "0", ":", "-", "1", "]", "-", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                        ", "temp", "=", "np", ".", "full", "(", "neighbor_defense_attributes", ".", "shape", ",", "-", "1", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "neighbor_defense_attributes", ")", ")", ":", "\n", "                            ", "if", "np", ".", "sum", "(", "neighbor_defense_attributes", "[", "i", "]", ")", ">", "0", ":", "\n", "                                ", "temp", "[", "i", "]", "=", "neighbor_defense_attributes", "[", "i", "]", "-", "attacker_obs", "[", "i", ",", "0", ":", "-", "1", "]", "\n", "", "", "", "features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "temp", ")", ":", "\n", "                        ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "t", ".", "append", "(", "node_ids", "[", "idx", "]", ")", "\n", "# t.append(node_reachable[idx])", "\n", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                            ", "t", ".", "append", "(", "det_values", "[", "idx", "]", ")", "\n", "", "features", ".", "append", "(", "t", ")", "\n", "", "", "features", "=", "np", ".", "array", "(", "features", ")", "\n", "if", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ":", "\n", "                    ", "f", "=", "np", ".", "zeros", "(", "(", "features", ".", "shape", "[", "0", "]", ",", "features", ".", "shape", "[", "1", "]", "+", "d_bool_features", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "features", ".", "shape", "[", "0", "]", ")", ":", "\n", "                        ", "f", "[", "i", "]", "=", "np", ".", "append", "(", "features", "[", "i", "]", ",", "d_bool_features", "[", "i", "]", ")", "\n", "", "features", "=", "f", "\n", "", "if", "self", ".", "config", ".", "state_length", "==", "1", ":", "\n", "                    ", "return", "features", "\n", "", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "s", "=", "np", ".", "array", "(", "[", "features", "]", "*", "self", ".", "config", ".", "state_length", ")", "\n", "return", "s", "\n", "", "state", "=", "np", ".", "append", "(", "state", "[", "1", ":", "]", ",", "np", ".", "array", "(", "[", "features", "]", ")", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "config", ".", "state_length", "==", "1", ":", "\n", "                    ", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                        ", "if", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", "and", "attacker", ":", "\n", "                            ", "combined_features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "attacker_obs", ")", ":", "\n", "                                ", "combined_row", "=", "np", ".", "append", "(", "row", ",", "defender_obs", "[", "idx", "]", ")", "\n", "combined_features", ".", "append", "(", "combined_row", ")", "\n", "", "if", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ":", "\n", "                                ", "combined_features", "=", "np", ".", "array", "(", "combined_features", ")", "\n", "f", "=", "np", ".", "zeros", "(", "\n", "(", "combined_features", ".", "shape", "[", "0", "]", ",", "combined_features", ".", "shape", "[", "1", "]", "+", "d_bool_features", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "combined_features", ".", "shape", "[", "0", "]", ")", ":", "\n", "                                    ", "f", "[", "i", "]", "=", "np", ".", "append", "(", "combined_features", "[", "i", "]", ",", "d_bool_features", "[", "i", "]", ")", "\n", "", "combined_features", "=", "f", "\n", "", "return", "np", ".", "array", "(", "combined_features", ")", "\n", "\n", "", "return", "np", ".", "append", "(", "attacker_obs", ",", "defender_obs", ")", "\n", "", "else", ":", "\n", "                        ", "if", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ":", "\n", "                            ", "f", "=", "np", ".", "zeros", "(", "(", "attacker_obs", ".", "shape", "[", "0", "]", ",", "\n", "attacker_obs", ".", "shape", "[", "1", "]", "+", "neighbor_defense_attributes", ".", "shape", "[", "1", "]", "+", "\n", "d_bool_features", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "f", ".", "shape", "[", "0", "]", ")", ":", "\n", "                                ", "f", "[", "i", "]", "=", "np", ".", "append", "(", "np", ".", "append", "(", "attacker_obs", "[", "i", "]", ",", "neighbor_defense_attributes", "[", "i", "]", ")", ",", "\n", "d_bool_features", "[", "i", "]", ")", "\n", "", "", "else", ":", "\n", "                            ", "f", "=", "np", ".", "zeros", "(", "(", "attacker_obs", ".", "shape", "[", "0", "]", ",", "\n", "attacker_obs", ".", "shape", "[", "1", "]", "+", "neighbor_defense_attributes", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "f", ".", "shape", "[", "0", "]", ")", ":", "\n", "                                ", "f", "[", "i", "]", "=", "np", ".", "append", "(", "attacker_obs", "[", "i", "]", ",", "neighbor_defense_attributes", "[", "i", "]", ")", "\n", "", "", "return", "f", "\n", "", "", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                        ", "temp", "=", "np", ".", "append", "(", "attacker_obs", ",", "defender_obs", ")", "\n", "", "else", ":", "\n", "                        ", "temp", "=", "np", ".", "append", "(", "attacker_obs", ",", "neighbor_defense_attributes", ")", "\n", "", "s", "=", "np", ".", "array", "(", "[", "temp", "]", "*", "self", ".", "config", ".", "state_length", ")", "\n", "return", "s", "\n", "", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                    ", "temp", "=", "np", ".", "append", "(", "attacker_obs", ",", "defender_obs", ")", "\n", "", "else", ":", "\n", "                    ", "temp", "=", "np", ".", "append", "(", "attacker_obs", ",", "neighbor_defense_attributes", ")", "\n", "", "state", "=", "np", ".", "append", "(", "state", "[", "1", ":", "]", ",", "np", ".", "array", "(", "[", "temp", "]", ")", ",", "axis", "=", "0", ")", "\n", "", "return", "state", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "config", ".", "state_length", "==", "1", ":", "\n", "                ", "if", "attacker", ":", "\n", "                    ", "return", "np", ".", "array", "(", "attacker_obs", ")", "\n", "", "else", ":", "\n", "                    ", "return", "np", ".", "array", "(", "defender_obs", ")", "\n", "", "", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                ", "if", "attacker", ":", "\n", "                    ", "return", "np", ".", "array", "(", "[", "attacker_obs", "]", "*", "self", ".", "config", ".", "state_length", ")", "\n", "", "else", ":", "\n", "                    ", "return", "np", ".", "array", "(", "[", "defender_obs", "]", "*", "self", ".", "config", ".", "state_length", ")", "\n", "", "", "if", "attacker", ":", "\n", "                ", "state", "=", "np", ".", "append", "(", "state", "[", "1", ":", "]", ",", "np", ".", "array", "(", "[", "attacker_obs", "]", ")", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "state", "=", "np", ".", "append", "(", "state", "[", "1", ":", "]", ",", "np", ".", "array", "(", "[", "defender_obs", "]", ")", ",", "axis", "=", "0", ")", "\n", "", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.grid_obs": [[364, 434], ["numpy.zeros", "enumerate", "numpy.zeros", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.idsgame_env.idsgame_config.game_config.network_config.get_adjacency_matrix_id", "range", "numpy.zeros", "range", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.idsgame_env.fully_observed", "sklearn.preprocessing.normalize", "sklearn.preprocessing.normalize", "numpy.full", "len", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.idsgame_env.idsgame_config.game_config.network_config.get_node_pos", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.idsgame_env.idsgame_config.game_config.network_config.get_adjacency_matrix_id", "numpy.full", "len", "ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.idsgame_env.idsgame_config.game_config.network_config.get_node_pos", "numpy.full", "sklearn.preprocessing.normalize", "sklearn.preprocessing.normalize", "numpy.stack", "numpy.stack", "int"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_adjacency_matrix_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.fully_observed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_pos", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_adjacency_matrix_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_pos"], ["", "", "def", "grid_obs", "(", "self", ",", "attacker_obs", ",", "defender_obs", ",", "attacker", "=", "True", ")", ":", "\n", "        ", "if", "attacker", "and", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "            ", "a_obs_len", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", "\n", "defender_obs", "=", "attacker_obs", "[", ":", ",", "a_obs_len", ":", "]", "\n", "attacker_obs", "=", "attacker_obs", "[", ":", ",", "0", ":", "a_obs_len", "]", "\n", "attacker_position", "=", "attacker_obs", "[", ":", ",", "-", "1", "]", "\n", "attacker_obs", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "elif", "self", ".", "idsgame_env", ".", "fully_observed", "(", ")", ":", "\n", "            ", "a_obs_len", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", "\n", "attacker_position", "=", "attacker_obs", "[", ":", ",", "-", "1", "]", "\n", "attacker_obs", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "defender_obs", "=", "defender_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "\n", "", "attack_plane", "=", "attacker_obs", "\n", "if", "self", ".", "config", ".", "normalize_features", ":", "\n", "            ", "normalized_attack_plane", "=", "preprocessing", ".", "normalize", "(", "attack_plane", ")", "\n", "\n", "", "defense_plane", "=", "defender_obs", "\n", "if", "self", ".", "config", ".", "normalize_features", ":", "\n", "            ", "normalized_defense_plane", "=", "preprocessing", ".", "normalize", "(", "defense_plane", ")", "\n", "\n", "", "position_plane", "=", "np", ".", "zeros", "(", "attack_plane", ".", "shape", ")", "\n", "for", "idx", ",", "present", "in", "enumerate", "(", "attacker_position", ")", ":", "\n", "            ", "position_plane", "[", "idx", "]", "=", "np", ".", "full", "(", "position_plane", ".", "shape", "[", "1", "]", ",", "present", ")", "\n", "\n", "", "reachable_plane", "=", "np", ".", "zeros", "(", "attack_plane", ".", "shape", ")", "\n", "attacker_row", ",", "attacker_col", "=", "self", ".", "idsgame_env", ".", "state", ".", "attacker_pos", "\n", "attacker_matrix_id", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "get_adjacency_matrix_id", "(", "\n", "attacker_row", ",", "attacker_col", ")", "\n", "for", "node_id", "in", "range", "(", "len", "(", "attack_plane", ")", ")", ":", "\n", "            ", "node_row", ",", "node_col", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "get_node_pos", "(", "node_id", ")", "\n", "adj_matrix_id", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "get_adjacency_matrix_id", "(", "node_row", ",", "\n", "node_col", ")", "\n", "reachable", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "adjacency_matrix", "[", "attacker_matrix_id", "]", "[", "\n", "adj_matrix_id", "]", "==", "int", "(", "1", ")", "\n", "if", "reachable", ":", "\n", "                ", "val", "=", "1", "\n", "", "else", ":", "\n", "                ", "val", "=", "0", "\n", "", "reachable_plane", "[", "node_id", "]", "=", "np", ".", "full", "(", "reachable_plane", ".", "shape", "[", "1", "]", ",", "val", ")", "\n", "\n", "", "row_difference_plane", "=", "np", ".", "zeros", "(", "attack_plane", ".", "shape", ")", "\n", "for", "node_id", "in", "range", "(", "len", "(", "attack_plane", ")", ")", ":", "\n", "            ", "node_row", ",", "node_col", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "get_node_pos", "(", "node_id", ")", "\n", "row_difference", "=", "attacker_row", "-", "node_row", "\n", "row_difference_plane", "[", "node_id", "]", "=", "np", ".", "full", "(", "row_difference_plane", ".", "shape", "[", "1", "]", ",", "row_difference", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "normalize_features", ":", "\n", "            ", "normalized_row_difference_plance", "=", "preprocessing", ".", "normalize", "(", "row_difference_plane", ")", "\n", "\n", "", "attack_defense_difference_plane", "=", "attacker_obs", "-", "defender_obs", "\n", "if", "self", ".", "config", ".", "normalize_features", ":", "\n", "            ", "normalized_attack_defense_difference_plane", "=", "preprocessing", ".", "normalize", "(", "attack_defense_difference_plane", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "normalize_features", ":", "\n", "            ", "feature_frames", "=", "np", ".", "stack", "(", "\n", "[", "normalized_attack_plane", ",", "normalized_defense_plane", ",", "position_plane", ",", "reachable_plane", ",", "\n", "normalized_row_difference_plance", ",", "\n", "normalized_attack_defense_difference_plane", "]", ",", "\n", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "feature_frames", "=", "np", ".", "stack", "(", "\n", "[", "attack_plane", ",", "defense_plane", ",", "position_plane", ",", "reachable_plane", ",", "\n", "row_difference_plane", ",", "\n", "attack_defense_difference_plane", "]", ",", "\n", "axis", "=", "0", ")", "\n", "# print(\"feature_frames:\")", "\n", "# print(feature_frames)", "\n", "# raise AssertionError(\"test\")", "\n", "", "return", "feature_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent.create_policy_plot": [[435, 455], ["numpy.sum", "numpy.random.choice", "gym_idsgame.action_dist_hist", "list", "range", "len", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.action_dist_hist"], ["", "def", "create_policy_plot", "(", "self", ",", "distribution", ",", "episode", ",", "attacker", "=", "True", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Utility function for creating a density plot of the policy distribution p(a|s) and add to Tensorboard\n\n        :param distribution: the distribution to plot\n        :param episode: the episode when the distribution was recorded\n        :param attacker: boolean flag whether it is the attacker or defender\n        :return: None\n        \"\"\"", "\n", "#distribution = distribution/np.linalg.norm(distribution, ord=np.inf, axis=0, keepdims=True)", "\n", "distribution", "/=", "np", ".", "sum", "(", "distribution", ")", "\n", "sample", "=", "np", ".", "random", ".", "choice", "(", "list", "(", "range", "(", "len", "(", "distribution", ")", ")", ")", ",", "size", "=", "1000", ",", "p", "=", "distribution", ")", "\n", "tag", "=", "\"Attacker\"", "\n", "file_suffix", "=", "\"initial_state_policy_attacker\"", "\n", "if", "not", "attacker", ":", "\n", "            ", "tag", "=", "\"Defender\"", "\n", "file_suffix", "=", "\"initial_state_policy_defender\"", "\n", "", "title", "=", "tag", "+", "\" Initial State Policy\"", "\n", "data", "=", "util", ".", "action_dist_hist", "(", "sample", ",", "title", "=", "title", ",", "xlabel", "=", "\"Action\"", ",", "ylabel", "=", "r\"$\\mathbb{P}(a|s)$\"", ",", "\n", "file_name", "=", "self", ".", "config", ".", "save_dir", "+", "\"/\"", "+", "file_suffix", "+", "\"_\"", "+", "str", "(", "episode", ")", ")", "\n", "# self.tensorboard_writer.add_image(str(episode) + \"_initial_state_policy/\" + tag,", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.__init__": [[21, 36], ["gym_idsgame.agents.bot_agents.bot_agent.BotAgent.__init__", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.initialize_models", "ValueError", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.initialize_models"], ["def", "__init__", "(", "self", ",", "pg_config", ":", "PolicyGradientAgentConfig", ",", "game_config", ":", "GameConfig", ",", "model_path", ":", "str", "=", "None", ",", "\n", "env", ":", "IdsGameEnv", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Constructor, initializes the policy\n\n        :param game_config: the game configuration\n        \"\"\"", "\n", "super", "(", "PPOBaselineDefenderBotAgent", ",", "self", ")", ".", "__init__", "(", "game_config", ")", "\n", "if", "model_path", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot create a PPOBaselineDefenderBotAgent without specifying the path to the model\"", ")", "\n", "", "self", ".", "idsgame_env", "=", "env", "\n", "self", ".", "config", "=", "pg_config", "\n", "self", ".", "model_path", "=", "model_path", "\n", "self", ".", "initialize_models", "(", ")", "\n", "self", ".", "device", "=", "\"cpu\"", "if", "not", "self", ".", "config", ".", "gpu", "else", "\"cuda:\"", "+", "str", "(", "self", ".", "config", ".", "gpu_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.initialize_models": [[38, 48], ["gym_idsgame.agents.training_agents.openai_baselines.common.ppo.ppo.PPO.load"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load"], ["", "def", "initialize_models", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Initialize models\n        :return: None\n        \"\"\"", "\n", "policy", "=", "\"MlpPolicy\"", "\n", "if", "self", ".", "config", ".", "cnn_feature_extractor", ":", "\n", "            ", "policy", "=", "\"CnnPolicy\"", "\n", "# Initialize models", "\n", "", "self", ".", "model", "=", "PPO", ".", "load", "(", "self", ".", "config", ".", "defender_load_path", ",", "policy", ",", "pg_agent_config", "=", "self", ".", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.action": [[49, 102], ["game_state.get_attacker_observation", "game_state.get_defender_observation", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.update_state", "list", "list", "torch.as_tensor().to", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.model.defender_policy.forward", "defender_actions.item.item.item", "list", "list", "torch.as_tensor().to", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.model.defender_node_policy.forward", "defender_node_actions.cpu().numpy.cpu().numpy.cpu().numpy", "torch.as_tensor().to.reshape", "list", "list", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.model.defender_at_policy.forward", "defender_at_actions.cpu().numpy.cpu().numpy.cpu().numpy", "gym_idsgame.get_defense_action_id", "print", "traceback.print_exc", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.idsgame_env.local_view_features", "range", "filter", "range", "filter", "len", "len", "range", "filter", "len", "len", "str", "torch.as_tensor", "torch.as_tensor", "defender_node_actions.cpu().numpy.cpu().numpy.cpu", "defender_at_actions.cpu().numpy.cpu().numpy.cpu", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.flatten", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.flatten", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.idsgame_env.is_defense_legal", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.is_defense_legal", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.is_defense_legal"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.get_attacker_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.get_defender_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.get_defense_action_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal"], ["", "def", "action", "(", "self", ",", "game_state", ":", "GameState", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Samples an action from the policy.\n\n        :param game_state: the game state\n        :return: action_id\n        \"\"\"", "\n", "try", ":", "\n", "# Feature engineering", "\n", "            ", "attacker_obs", "=", "game_state", ".", "get_attacker_observation", "(", "\n", "self", ".", "game_config", ".", "network_config", ",", "local_view", "=", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", ",", "\n", "reconnaissance", "=", "self", ".", "game_config", ".", "reconnaissance_actions", ",", "\n", "reconnaissance_bool_features", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ")", "\n", "defender_obs", "=", "game_state", ".", "get_defender_observation", "(", "self", ".", "game_config", ".", "network_config", ")", "\n", "defender_state", "=", "self", ".", "update_state", "(", "attacker_obs", "=", "attacker_obs", ",", "defender_obs", "=", "defender_obs", ",", "state", "=", "[", "]", ",", "\n", "attacker", "=", "False", ")", "\n", "if", "not", "self", ".", "config", ".", "ar_policy", ":", "\n", "                ", "actions", "=", "list", "(", "range", "(", "self", ".", "idsgame_env", ".", "num_defense_actions", ")", ")", "\n", "non_legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "not", "self", ".", "idsgame_env", ".", "is_defense_legal", "(", "action", ")", ",", "actions", ")", ")", "\n", "obs_tensor_d", "=", "torch", ".", "as_tensor", "(", "defender_state", ".", "flatten", "(", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "defender_actions", ",", "defender_values", ",", "defender_log_probs", "=", "self", ".", "model", ".", "defender_policy", ".", "forward", "(", "\n", "obs_tensor_d", ",", "self", ".", "idsgame_env", ",", "device", "=", "self", ".", "device", ",", "attacker", "=", "False", ",", "non_legal_actions", "=", "non_legal_actions", ")", "\n", "defender_actions", "=", "defender_actions", ".", "item", "(", ")", "\n", "", "else", ":", "\n", "                ", "actions", "=", "list", "(", "range", "(", "self", ".", "config", ".", "defender_node_net_output_dim", ")", ")", "\n", "non_legal_actions", "=", "list", "(", "\n", "filter", "(", "lambda", "action", ":", "not", "self", ".", "is_defense_legal", "(", "action", ",", "node", "=", "True", ",", "game_state", "=", "game_state", ")", ",", "actions", ")", ")", "\n", "if", "len", "(", "non_legal_actions", ")", "==", "len", "(", "actions", ")", ":", "\n", "                    ", "non_legal_actions", "=", "[", "]", "\n", "", "obs_tensor_d", "=", "torch", ".", "as_tensor", "(", "defender_state", ".", "flatten", "(", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "defender_node_actions", ",", "defender_node_values", ",", "defender_node_log_probs", ",", "defender_node_lstm_state", "=", "self", ".", "model", ".", "defender_node_policy", ".", "forward", "(", "\n", "obs_tensor_d", ",", "self", ".", "idsgame_env", ",", "device", "=", "self", ".", "device", ",", "attacker", "=", "False", ",", "\n", "non_legal_actions", "=", "non_legal_actions", ")", "\n", "defender_node_actions", "=", "defender_node_actions", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "node", "=", "defender_node_actions", "[", "0", "]", "\n", "obs_tensor_d_1", "=", "obs_tensor_d", ".", "reshape", "(", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_nodes", ",", "\n", "self", ".", "config", ".", "defender_at_net_input_dim", ")", "\n", "obs_tensor_d_at", "=", "obs_tensor_d_1", "[", "node", "]", "\n", "actions", "=", "list", "(", "range", "(", "self", ".", "config", ".", "defender_at_net_output_dim", ")", ")", "\n", "non_legal_actions", "=", "list", "(", "\n", "filter", "(", "lambda", "action", ":", "not", "self", ".", "is_defense_legal", "(", "action", ",", "node", "=", "False", ",", "game_state", "=", "game_state", ",", "obs", "=", "obs_tensor_d_at", ")", ",", "actions", ")", ")", "\n", "if", "len", "(", "non_legal_actions", ")", "==", "len", "(", "actions", ")", ":", "\n", "                    ", "non_legal_actions", "=", "[", "]", "\n", "", "defender_at_actions", ",", "defender_at_values", ",", "defender_at_log_probs", ",", "defender_at_lstm_state", "=", "self", ".", "model", ".", "defender_at_policy", ".", "forward", "(", "\n", "obs_tensor_d_at", ",", "self", ".", "idsgame_env", ",", "device", "=", "self", ".", "device", ",", "attacker", "=", "False", ",", "non_legal_actions", "=", "non_legal_actions", ")", "\n", "defender_at_actions", "=", "defender_at_actions", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "attack_id", "=", "util", ".", "get_defense_action_id", "(", "node", ",", "defender_at_actions", "[", "0", "]", ",", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ")", "\n", "defender_actions", "=", "attack_id", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "str", "(", "e", ")", ")", "\n", "traceback", ".", "print_exc", "(", ")", "\n", "\n", "", "return", "defender_actions", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.is_defense_legal": [[103, 122], ["ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.idsgame_env.is_defense_legal", "gym_idsgame.is_node_defense_legal"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_node_defense_legal"], ["", "def", "is_defense_legal", "(", "self", ",", "defense_action", ":", "int", ",", "node", ":", "bool", "=", "False", ",", "obs", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "game_state", ":", "GameState", "=", "None", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Check if a given defense is legal or not.\n\n        :param defense_action: the defense action to verify\n        :return: True if legal otherwise False\n        \"\"\"", "\n", "if", "not", "self", ".", "config", ".", "ar_policy", ":", "\n", "            ", "return", "self", ".", "idsgame_env", ".", "is_defense_legal", "(", "defense_action", ")", "\n", "", "else", ":", "\n", "            ", "if", "node", ":", "\n", "                ", "return", "util", ".", "is_node_defense_legal", "(", "defense_action", ",", "self", ".", "game_config", ".", "network_config", ",", "game_state", ",", "\n", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "max_value", ")", "\n", "", "else", ":", "\n", "                ", "if", "obs", "is", "not", "None", ":", "\n", "                    ", "if", "obs", "[", "defense_action", "]", ">=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "max_value", ":", "\n", "                        ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.update_state": [[123, 349], ["ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.idsgame_env.local_view_features", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.idsgame_env.state.get_attacker_observation", "enumerate", "enumerate", "numpy.array", "numpy.array", "enumerate", "enumerate", "numpy.array", "numpy.array", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.idsgame_env.local_view_features", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.idsgame_env.fully_observed", "numpy.mean", "numpy.isnan().any", "zero_mean_attacker_features.append", "numpy.mean", "numpy.isnan().any", "zero_mean_defender_features.append", "numpy.isnan().any", "normalized_attacker_features.append", "numpy.isnan().any", "normalized_defender_features.append", "numpy.zeros", "range", "numpy.array", "numpy.append", "numpy.append", "len", "numpy.append", "numpy.append", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.idsgame_env.local_view_features", "row.tolist.tolist", "row.tolist.tolist", "row.tolist.append", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.idsgame_env.local_view_features", "numpy.linalg.norm", "numpy.linalg.norm", "row.tolist", "numpy.linalg.norm", "numpy.linalg.norm", "int", "enumerate", "enumerate", "numpy.zeros", "range", "len", "numpy.array", "numpy.array", "len", "numpy.array", "numpy.append", "numpy.append", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.isnan", "row.tolist.append", "row.tolist.append", "row.tolist.append", "numpy.isnan", "numpy.isnan", "row.tolist.append", "row.tolist.append", "row.tolist.append", "numpy.isnan", "row.tolist", "row.tolist.append", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.idsgame_env.local_view_features", "row.tolist", "row.tolist.append", "numpy.array.append", "numpy.full", "range", "row.tolist", "row.tolist.append", "numpy.array.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.idsgame_env.local_view_features", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.idsgame_env.local_view_features", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.idsgame_env.local_view_features", "row.tolist.append", "len", "row.tolist.append", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.idsgame_env.local_view_features", "enumerate", "numpy.array", "numpy.zeros", "range", "numpy.zeros", "range", "ppo_defender_bot_agent.PPOBaselineDefenderBotAgent.idsgame_env.local_view_features", "numpy.sum", "numpy.append", "numpy.array.append", "numpy.array", "numpy.zeros", "range", "numpy.append", "numpy.append", "numpy.append", "numpy.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.get_attacker_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.fully_observed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features"], ["", "", "", "def", "update_state", "(", "self", ",", "attacker_obs", ":", "np", ".", "ndarray", "=", "None", ",", "defender_obs", ":", "np", ".", "ndarray", "=", "None", ",", "\n", "state", ":", "np", ".", "ndarray", "=", "None", ",", "attacker", ":", "bool", "=", "True", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Update approximative Markov state\n\n        :param attacker_obs: attacker obs\n        :param defender_obs: defender observation\n        :param state: current state\n        :param attacker: boolean flag whether it is attacker or not\n        :return: new state\n        \"\"\"", "\n", "if", "attacker", "and", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "            ", "a_obs_len", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", "\n", "defender_obs", "=", "attacker_obs", "[", ":", ",", "\n", "a_obs_len", ":", "a_obs_len", "+", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "]", "\n", "if", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ":", "\n", "                ", "d_bool_features", "=", "attacker_obs", "[", ":", ",", "\n", "a_obs_len", "+", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ":", "]", "\n", "", "attacker_obs", "=", "attacker_obs", "[", ":", ",", "0", ":", "a_obs_len", "]", "\n", "\n", "", "if", "not", "attacker", "and", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", ":", "\n", "            ", "attacker_obs", "=", "self", ".", "idsgame_env", ".", "state", ".", "get_attacker_observation", "(", "\n", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "network_config", ",", "\n", "local_view", "=", "False", ",", "\n", "reconnaissance", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_actions", ")", "\n", "\n", "# Zero mean", "\n", "", "if", "self", ".", "config", ".", "zero_mean_features", ":", "\n", "            ", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                ", "attacker_obs_1", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "attacker_obs_1", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "2", "]", "\n", "", "zero_mean_attacker_features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "attacker_obs_1", ")", ":", "\n", "                ", "mean", "=", "np", ".", "mean", "(", "row", ")", "\n", "if", "mean", "!=", "0", ":", "\n", "                    ", "t", "=", "row", "-", "mean", "\n", "", "else", ":", "\n", "                    ", "t", "=", "row", "\n", "", "if", "np", ".", "isnan", "(", "t", ")", ".", "any", "(", ")", ":", "\n", "                    ", "t", "=", "attacker_obs", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "t", "=", "t", ".", "tolist", "(", ")", "\n", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                        ", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                        ", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "2", "]", ")", "\n", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "", "zero_mean_attacker_features", ".", "append", "(", "t", ")", "\n", "\n", "", "defender_obs_1", "=", "defender_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "zero_mean_defender_features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "defender_obs_1", ")", ":", "\n", "                ", "mean", "=", "np", ".", "mean", "(", "row", ")", "\n", "if", "mean", "!=", "0", ":", "\n", "                    ", "t", "=", "row", "-", "mean", "\n", "", "else", ":", "\n", "                    ", "t", "=", "row", "\n", "", "if", "np", ".", "isnan", "(", "t", ")", ".", "any", "(", ")", ":", "\n", "                    ", "t", "=", "defender_obs", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "t", "=", "t", ".", "tolist", "(", ")", "\n", "t", ".", "append", "(", "defender_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "zero_mean_defender_features", ".", "append", "(", "t", ")", "\n", "\n", "", "attacker_obs", "=", "np", ".", "array", "(", "zero_mean_attacker_features", ")", "\n", "defender_obs", "=", "np", ".", "array", "(", "zero_mean_defender_features", ")", "\n", "\n", "# Normalize", "\n", "", "if", "self", ".", "config", ".", "normalize_features", ":", "\n", "            ", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                ", "attacker_obs_1", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "/", "np", ".", "linalg", ".", "norm", "(", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "attacker_obs_1", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "2", "]", "/", "np", ".", "linalg", ".", "norm", "(", "attacker_obs", "[", ":", ",", "0", ":", "-", "2", "]", ")", "\n", "", "normalized_attacker_features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "attacker_obs_1", ")", ":", "\n", "                ", "if", "np", ".", "isnan", "(", "attacker_obs_1", ")", ".", "any", "(", ")", ":", "\n", "                    ", "t", "=", "attacker_obs", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                        ", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                        ", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "2", "]", ")", "\n", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "", "normalized_attacker_features", ".", "append", "(", "t", ")", "\n", "\n", "", "if", "attacker", "and", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                ", "defender_obs_1", "=", "defender_obs", "[", ":", ",", "0", ":", "-", "1", "]", "/", "np", ".", "linalg", ".", "norm", "(", "defender_obs", "[", ":", ",", "0", ":", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "defender_obs_1", "=", "defender_obs", "/", "np", ".", "linalg", ".", "norm", "(", "defender_obs", ")", "\n", "", "normalized_defender_features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "defender_obs_1", ")", ":", "\n", "                ", "if", "np", ".", "isnan", "(", "defender_obs_1", ")", ".", "any", "(", ")", ":", "\n", "                    ", "t", "=", "defender_obs", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "if", "attacker", "and", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "t", ".", "append", "(", "defender_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                        ", "t", "=", "row", "\n", "\n", "", "", "normalized_defender_features", ".", "append", "(", "t", ")", "\n", "\n", "", "attacker_obs", "=", "np", ".", "array", "(", "normalized_attacker_features", ")", "\n", "defender_obs", "=", "np", ".", "array", "(", "normalized_defender_features", ")", "\n", "\n", "", "if", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "and", "attacker", ":", "\n", "            ", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                ", "neighbor_defense_attributes", "=", "np", ".", "zeros", "(", "(", "attacker_obs", ".", "shape", "[", "0", "]", ",", "defender_obs", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "node", "in", "range", "(", "attacker_obs", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "id", "=", "int", "(", "attacker_obs", "[", "node", "]", "[", "-", "1", "]", ")", "\n", "neighbor_defense_attributes", "[", "node", "]", "=", "defender_obs", "[", "id", "]", "\n", "", "", "else", ":", "\n", "                ", "neighbor_defense_attributes", "=", "defender_obs", "\n", "\n", "", "", "if", "self", ".", "idsgame_env", ".", "fully_observed", "(", ")", "or", "(", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", "and", "attacker", ")", ":", "\n", "            ", "if", "self", ".", "config", ".", "merged_ad_features", ":", "\n", "                ", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                    ", "a_pos", "=", "attacker_obs", "[", ":", ",", "-", "1", "]", "\n", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "det_values", "=", "defender_obs", "[", ":", ",", "-", "1", "]", "\n", "temp", "=", "defender_obs", "[", ":", ",", "0", ":", "-", "1", "]", "-", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                        ", "temp", "=", "defender_obs", "[", ":", ",", "0", ":", "]", "-", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "temp", ")", ":", "\n", "                        ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "t", ".", "append", "(", "a_pos", "[", "idx", "]", ")", "\n", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                            ", "t", ".", "append", "(", "det_values", "[", "idx", "]", ")", "\n", "", "features", ".", "append", "(", "t", ")", "\n", "", "", "else", ":", "\n", "                    ", "node_ids", "=", "attacker_obs", "[", ":", ",", "-", "1", "]", "\n", "# node_reachable = attacker_obs[:, -1]", "\n", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "det_values", "=", "neighbor_defense_attributes", "[", ":", ",", "-", "1", "]", "\n", "", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "temp", "=", "neighbor_defense_attributes", "[", ":", ",", "0", ":", "-", "1", "]", "-", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                        ", "temp", "=", "np", ".", "full", "(", "neighbor_defense_attributes", ".", "shape", ",", "-", "1", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "neighbor_defense_attributes", ")", ")", ":", "\n", "                            ", "if", "np", ".", "sum", "(", "neighbor_defense_attributes", "[", "i", "]", ")", ">", "0", ":", "\n", "                                ", "temp", "[", "i", "]", "=", "neighbor_defense_attributes", "[", "i", "]", "-", "attacker_obs", "[", "i", ",", "0", ":", "-", "1", "]", "\n", "", "", "", "features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "temp", ")", ":", "\n", "                        ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "t", ".", "append", "(", "node_ids", "[", "idx", "]", ")", "\n", "# t.append(node_reachable[idx])", "\n", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                            ", "t", ".", "append", "(", "det_values", "[", "idx", "]", ")", "\n", "", "features", ".", "append", "(", "t", ")", "\n", "", "", "features", "=", "np", ".", "array", "(", "features", ")", "\n", "if", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ":", "\n", "                    ", "f", "=", "np", ".", "zeros", "(", "(", "features", ".", "shape", "[", "0", "]", ",", "features", ".", "shape", "[", "1", "]", "+", "d_bool_features", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "features", ".", "shape", "[", "0", "]", ")", ":", "\n", "                        ", "f", "[", "i", "]", "=", "np", ".", "append", "(", "features", "[", "i", "]", ",", "d_bool_features", "[", "i", "]", ")", "\n", "", "features", "=", "f", "\n", "", "if", "self", ".", "config", ".", "state_length", "==", "1", ":", "\n", "                    ", "return", "features", "\n", "", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "s", "=", "np", ".", "array", "(", "[", "features", "]", "*", "self", ".", "config", ".", "state_length", ")", "\n", "return", "s", "\n", "", "state", "=", "np", ".", "append", "(", "state", "[", "1", ":", "]", ",", "np", ".", "array", "(", "[", "features", "]", ")", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "config", ".", "state_length", "==", "1", ":", "\n", "                    ", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                        ", "if", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", "and", "attacker", ":", "\n", "                            ", "combined_features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "attacker_obs", ")", ":", "\n", "                                ", "combined_row", "=", "np", ".", "append", "(", "row", ",", "defender_obs", "[", "idx", "]", ")", "\n", "combined_features", ".", "append", "(", "combined_row", ")", "\n", "", "if", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ":", "\n", "                                ", "combined_features", "=", "np", ".", "array", "(", "combined_features", ")", "\n", "f", "=", "np", ".", "zeros", "(", "\n", "(", "combined_features", ".", "shape", "[", "0", "]", ",", "combined_features", ".", "shape", "[", "1", "]", "+", "d_bool_features", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "combined_features", ".", "shape", "[", "0", "]", ")", ":", "\n", "                                    ", "f", "[", "i", "]", "=", "np", ".", "append", "(", "combined_features", "[", "i", "]", ",", "d_bool_features", "[", "i", "]", ")", "\n", "", "combined_features", "=", "f", "\n", "", "return", "np", ".", "array", "(", "combined_features", ")", "\n", "\n", "", "return", "np", ".", "append", "(", "attacker_obs", ",", "defender_obs", ")", "\n", "", "else", ":", "\n", "                        ", "if", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ":", "\n", "                            ", "f", "=", "np", ".", "zeros", "(", "(", "attacker_obs", ".", "shape", "[", "0", "]", ",", "\n", "attacker_obs", ".", "shape", "[", "1", "]", "+", "neighbor_defense_attributes", ".", "shape", "[", "1", "]", "+", "\n", "d_bool_features", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "f", ".", "shape", "[", "0", "]", ")", ":", "\n", "                                ", "f", "[", "i", "]", "=", "np", ".", "append", "(", "np", ".", "append", "(", "attacker_obs", "[", "i", "]", ",", "neighbor_defense_attributes", "[", "i", "]", ")", ",", "\n", "d_bool_features", "[", "i", "]", ")", "\n", "", "", "else", ":", "\n", "                            ", "f", "=", "np", ".", "zeros", "(", "(", "attacker_obs", ".", "shape", "[", "0", "]", ",", "\n", "attacker_obs", ".", "shape", "[", "1", "]", "+", "neighbor_defense_attributes", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "f", ".", "shape", "[", "0", "]", ")", ":", "\n", "                                ", "f", "[", "i", "]", "=", "np", ".", "append", "(", "attacker_obs", "[", "i", "]", ",", "neighbor_defense_attributes", "[", "i", "]", ")", "\n", "", "", "return", "f", "\n", "", "", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                        ", "temp", "=", "np", ".", "append", "(", "attacker_obs", ",", "defender_obs", ")", "\n", "", "else", ":", "\n", "                        ", "temp", "=", "np", ".", "append", "(", "attacker_obs", ",", "neighbor_defense_attributes", ")", "\n", "", "s", "=", "np", ".", "array", "(", "[", "temp", "]", "*", "self", ".", "config", ".", "state_length", ")", "\n", "return", "s", "\n", "", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                    ", "temp", "=", "np", ".", "append", "(", "attacker_obs", ",", "defender_obs", ")", "\n", "", "else", ":", "\n", "                    ", "temp", "=", "np", ".", "append", "(", "attacker_obs", ",", "neighbor_defense_attributes", ")", "\n", "", "state", "=", "np", ".", "append", "(", "state", "[", "1", ":", "]", ",", "np", ".", "array", "(", "[", "temp", "]", ")", ",", "axis", "=", "0", ")", "\n", "", "return", "state", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "config", ".", "state_length", "==", "1", ":", "\n", "                ", "if", "attacker", ":", "\n", "                    ", "return", "np", ".", "array", "(", "attacker_obs", ")", "\n", "", "else", ":", "\n", "                    ", "return", "np", ".", "array", "(", "defender_obs", ")", "\n", "", "", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                ", "if", "attacker", ":", "\n", "                    ", "return", "np", ".", "array", "(", "[", "attacker_obs", "]", "*", "self", ".", "config", ".", "state_length", ")", "\n", "", "else", ":", "\n", "                    ", "return", "np", ".", "array", "(", "[", "defender_obs", "]", "*", "self", ".", "config", ".", "state_length", ")", "\n", "", "", "if", "attacker", ":", "\n", "                ", "state", "=", "np", ".", "append", "(", "state", "[", "1", ":", "]", ",", "np", ".", "array", "(", "[", "attacker_obs", "]", ")", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "state", "=", "np", ".", "append", "(", "state", "[", "1", ":", "]", ",", "np", ".", "array", "(", "[", "defender_obs", "]", ")", ",", "axis", "=", "0", ")", "\n", "", "return", "state", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.OpenAiPPOAgent.__init__": [[19, 26], ["gym_idsgame.agents.training_agents.policy_gradient.pg_agent.PolicyGradientAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n", "# Program entrypoint", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "random_seed", "=", "0", "\n", "util", ".", "create_artefact_dirs", "(", "default_output_dir", "(", ")", ",", "random_seed", ")", "\n", "pg_agent_config", "=", "PolicyGradientAgentConfig", "(", "gamma", "=", "1", ",", "alpha_attacker", "=", "0.0001", ",", "epsilon", "=", "1", ",", "render", "=", "False", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.OpenAiPPOAgent.train": [[28, 113], ["range", "range", "range", "net_arch.append", "dict", "print", "gym_idsgame.agents.training_agents.openai_baselines.common.ppo.ppo.PPO", "gym_idsgame.agents.training_agents.openai_baselines.common.ppo.ppo.PPO.learn", "ppo.OpenAiPPOAgent.config.logger.info", "gym_idsgame.agents.training_agents.openai_baselines.common.ppo.ppo.PPO.save_model", "net_arch.append", "pi_arch.append", "vf_arch.append", "gym_idsgame.agents.training_agents.openai_baselines.common.ppo.ppo.PPO.load", "str", "gym_idsgame.envs.rendering.video.idsgame_monitor.IdsGameMonitor", "str", "gym_idsgame.agents.training_agents.openai_baselines.common.ppo.ppo.PPO.train_result.to_csv", "gym_idsgame.agents.training_agents.openai_baselines.common.ppo.ppo.PPO.eval_result.to_csv", "ppo.OpenAiPPOAgent.get_hidden_activation", "str", "time.time", "AssertionError", "time.time", "math.pow"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.learn", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.save_model", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.get_hidden_activation"], ["eval_sleep", "=", "0.9", ",", "\n", "min_epsilon", "=", "0.01", ",", "eval_episodes", "=", "1000", ",", "train_log_frequency", "=", "1", ",", "\n", "epsilon_decay", "=", "0.9999", ",", "video", "=", "True", ",", "eval_log_frequency", "=", "500", ",", "\n", "video_fps", "=", "5", ",", "video_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/videos\"", ",", "\n", "num_episodes", "=", "100000000", ",", "\n", "eval_render", "=", "False", ",", "gifs", "=", "True", ",", "\n", "gif_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/gifs/\"", "+", "str", "(", "random_seed", ")", ",", "\n", "eval_frequency", "=", "55000", ",", "attacker", "=", "True", ",", "defender", "=", "False", ",", "\n", "video_frequency", "=", "1001", ",", "\n", "save_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/data/\"", "+", "str", "(", "random_seed", ")", ",", "\n", "checkpoint_freq", "=", "250", ",", "\n", "input_dim_attacker", "=", "(", "(", "4", "+", "2", ")", "*", "4", ")", ",", "\n", "output_dim_attacker", "=", "(", "4", "+", "1", ")", "*", "4", ",", "\n", "input_dim_defender", "=", "(", "(", "4", "+", "1", ")", "*", "4", ")", ",", "\n", "output_dim_defender", "=", "5", "*", "4", ",", "\n", "hidden_dim", "=", "128", ",", "num_hidden_layers", "=", "2", ",", "\n", "pi_hidden_layers", "=", "1", ",", "pi_hidden_dim", "=", "128", ",", "vf_hidden_layers", "=", "1", ",", "\n", "vf_hidden_dim", "=", "128", ",", "\n", "batch_size", "=", "2000", ",", "\n", "gpu", "=", "False", ",", "tensorboard", "=", "True", ",", "\n", "tensorboard_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/tensorboard/\"", "+", "str", "(", "random_seed", ")", ",", "\n", "optimizer", "=", "\"Adam\"", ",", "lr_exp_decay", "=", "False", ",", "lr_decay_rate", "=", "0.999", ",", "\n", "state_length", "=", "1", ",", "normalize_features", "=", "False", ",", "merged_ad_features", "=", "True", ",", "\n", "zero_mean_features", "=", "False", ",", "gpu_id", "=", "0", ",", "lstm_network", "=", "False", ",", "\n", "lstm_seq_length", "=", "4", ",", "num_lstm_layers", "=", "2", ",", "optimization_iterations", "=", "10", ",", "\n", "eps_clip", "=", "0.2", ",", "max_gradient_norm", "=", "0.5", ",", "gae_lambda", "=", "0.95", ",", "\n", "cnn_feature_extractor", "=", "False", ",", "features_dim", "=", "512", ",", "\n", "flatten_feature_planes", "=", "False", ",", "cnn_type", "=", "5", ",", "vf_coef", "=", "0.5", ",", "ent_coef", "=", "0.001", ",", "\n", "render_attacker_view", "=", "True", ",", "lr_progress_power_decay", "=", "4", ",", "\n", "lr_progress_decay", "=", "True", ",", "use_sde", "=", "False", ",", "sde_sample_freq", "=", "4", ",", "\n", "one_hot_obs", "=", "False", ",", "lstm_core", "=", "False", ",", "lstm_hidden_dim", "=", "32", ",", "\n", "multi_channel_obs", "=", "False", ",", "\n", "channel_1_dim", "=", "32", ",", "channel_1_layers", "=", "2", ",", "channel_1_input_dim", "=", "16", ",", "\n", "channel_2_dim", "=", "32", ",", "channel_2_layers", "=", "2", ",", "channel_2_input_dim", "=", "16", ",", "\n", "channel_3_dim", "=", "32", ",", "channel_3_layers", "=", "2", ",", "channel_3_input_dim", "=", "4", ",", "\n", "channel_4_dim", "=", "32", ",", "channel_4_layers", "=", "2", ",", "channel_4_input_dim", "=", "4", ",", "\n", "mini_batch_size", "=", "64", ",", "ar_policy", "=", "True", ",", "\n", "attacker_node_input_dim", "=", "(", "(", "4", "+", "2", ")", "*", "4", ")", ",", "\n", "attacker_at_net_input_dim", "=", "(", "4", "+", "2", ")", ",", "attacker_at_net_output_dim", "=", "(", "4", "+", "1", ")", ",", "\n", "attacker_node_net_output_dim", "=", "4", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v19\"", "\n", "wrapper_env", "=", "BaselineEnvWrapper", "(", "env_name", ",", "idsgame_config", "=", "None", ",", "\n", "save_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/data/\"", "+", "str", "(", "random_seed", ")", ",", "\n", "pg_agent_config", "=", "pg_agent_config", ")", "\n", "attacker_agent", "=", "OpenAiPPOAgent", "(", "wrapper_env", ",", "pg_agent_config", ")", "\n", "\n", "attacker_agent", ".", "train", "(", ")", "\n", "train_result", "=", "attacker_agent", ".", "train_result", "\n", "eval_result", "=", "attacker_agent", ".", "eval_result", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.OpenAiPPOAgent.linear_schedule": [[114, 133], ["isinstance", "float", "print"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.OpenAiPPOAgent.get_hidden_activation": [[135, 157], ["ValueError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.OpenAiPPOAgent.get_action": [[158, 160], ["NotImplemented"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.OpenAiPPOAgent.eval": [[161, 163], ["NotImplemented"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.__init__": [[54, 153], ["gym_idsgame.agents.training_agents.openai_baselines.common.common_policies.BasePolicy.__init__", "features_extractor_class", "gym_idsgame.agents.training_agents.openai_baselines.common.distributions.make_proba_distribution", "ppo_policies.PPOPolicy._build", "gym.spaces.Discrete", "gym.spaces.Discrete", "gym.spaces.Discrete", "gym.spaces.Discrete", "dict"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.make_proba_distribution", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy._build"], ["def", "__init__", "(", "self", ",", "\n", "observation_space", ":", "gym", ".", "spaces", ".", "Space", ",", "\n", "action_space", ":", "gym", ".", "spaces", ".", "Space", ",", "\n", "lr_schedule", ":", "Callable", ",", "\n", "net_arch", ":", "Optional", "[", "List", "[", "Union", "[", "int", ",", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "]", "]", "]", "=", "None", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "'auto'", ",", "\n", "activation_fn", ":", "Type", "[", "nn", ".", "Module", "]", "=", "nn", ".", "Tanh", ",", "\n", "ortho_init", ":", "bool", "=", "True", ",", "\n", "use_sde", ":", "bool", "=", "False", ",", "\n", "log_std_init", ":", "float", "=", "0.0", ",", "\n", "full_std", ":", "bool", "=", "True", ",", "\n", "sde_net_arch", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "None", ",", "\n", "use_expln", ":", "bool", "=", "False", ",", "\n", "squash_output", ":", "bool", "=", "False", ",", "\n", "features_extractor_class", ":", "Type", "[", "BaseFeaturesExtractor", "]", "=", "FlattenExtractor", ",", "\n", "features_extractor_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "normalize_images", ":", "bool", "=", "False", ",", "\n", "optimizer_class", ":", "Type", "[", "th", ".", "optim", ".", "Optimizer", "]", "=", "th", ".", "optim", ".", "Adam", ",", "\n", "optimizer_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "pg_agent_config", ":", "PolicyGradientAgentConfig", "=", "None", ",", "\n", "node_net", ":", "bool", "=", "False", ",", "\n", "at_net", ":", "bool", "=", "False", ",", "\n", "attacker", ":", "bool", "=", "False", ")", ":", "\n", "\n", "        ", "if", "optimizer_kwargs", "is", "None", ":", "\n", "            ", "optimizer_kwargs", "=", "{", "}", "\n", "# Small values to avoid NaN in ADAM optimizer", "\n", "if", "optimizer_class", "==", "th", ".", "optim", ".", "Adam", ":", "\n", "                ", "optimizer_kwargs", "[", "'eps'", "]", "=", "1e-5", "\n", "", "", "super", "(", "PPOPolicy", ",", "self", ")", ".", "__init__", "(", "pg_agent_config", ",", "observation_space", ",", "action_space", ",", "\n", "device", ",", "\n", "features_extractor_class", ",", "\n", "features_extractor_kwargs", ",", "\n", "optimizer_class", "=", "optimizer_class", ",", "\n", "optimizer_kwargs", "=", "optimizer_kwargs", ",", "\n", "squash_output", "=", "squash_output", ",", "\n", "at_net", "=", "at_net", ",", "\n", "node_net", "=", "node_net", ")", "\n", "\n", "# Default network architecture, from stable-baselines", "\n", "if", "net_arch", "is", "None", ":", "\n", "            ", "if", "features_extractor_class", "==", "FlattenExtractor", ":", "\n", "                ", "net_arch", "=", "[", "dict", "(", "pi", "=", "[", "64", ",", "64", "]", ",", "vf", "=", "[", "64", ",", "64", "]", ")", "]", "\n", "", "else", ":", "\n", "                ", "net_arch", "=", "[", "]", "\n", "", "", "self", ".", "net_arch", "=", "net_arch", "\n", "self", ".", "activation_fn", "=", "activation_fn", "\n", "self", ".", "ortho_init", "=", "ortho_init", "\n", "self", ".", "pg_agent_config", "=", "pg_agent_config", "\n", "self", ".", "features_extractor", "=", "features_extractor_class", "(", "self", ".", "pg_agent_config", ",", "self", ".", "observation_space", ",", "\n", "**", "self", ".", "features_extractor_kwargs", ")", "\n", "self", ".", "features_dim", "=", "self", ".", "features_extractor", ".", "features_dim", "\n", "if", "at_net", ":", "\n", "            ", "if", "attacker", ":", "\n", "                ", "self", ".", "features_dim", "=", "self", ".", "pg_agent_config", ".", "attacker_at_net_input_dim", "\n", "", "else", ":", "\n", "                ", "self", ".", "features_dim", "=", "self", ".", "pg_agent_config", ".", "defender_at_net_input_dim", "\n", "", "", "if", "node_net", ":", "\n", "            ", "if", "attacker", ":", "\n", "                ", "self", ".", "features_dim", "=", "self", ".", "pg_agent_config", ".", "attacker_node_net_input_dim", "\n", "", "else", ":", "\n", "                ", "self", ".", "features_dim", "=", "self", ".", "pg_agent_config", ".", "defender_node_net_input_dim", "\n", "\n", "", "", "self", ".", "node_net", "=", "node_net", "\n", "self", ".", "at_net", "=", "at_net", "\n", "\n", "self", ".", "normalize_images", "=", "normalize_images", "\n", "self", ".", "log_std_init", "=", "log_std_init", "\n", "dist_kwargs", "=", "None", "\n", "# Keyword arguments for gSDE distribution", "\n", "if", "use_sde", ":", "\n", "            ", "dist_kwargs", "=", "{", "\n", "'full_std'", ":", "full_std", ",", "\n", "'squash_output'", ":", "squash_output", ",", "\n", "'use_expln'", ":", "use_expln", ",", "\n", "'learn_features'", ":", "sde_net_arch", "is", "not", "None", "\n", "}", "\n", "\n", "", "self", ".", "sde_features_extractor", "=", "None", "\n", "self", ".", "sde_net_arch", "=", "sde_net_arch", "\n", "self", ".", "use_sde", "=", "use_sde", "\n", "self", ".", "dist_kwargs", "=", "dist_kwargs", "\n", "\n", "if", "node_net", ":", "\n", "            ", "if", "attacker", ":", "\n", "                ", "action_space", "=", "gym", ".", "spaces", ".", "Discrete", "(", "self", ".", "pg_agent_config", ".", "attacker_node_net_output_dim", ")", "\n", "", "else", ":", "\n", "                ", "action_space", "=", "gym", ".", "spaces", ".", "Discrete", "(", "self", ".", "pg_agent_config", ".", "defender_node_net_output_dim", ")", "\n", "", "", "if", "at_net", ":", "\n", "            ", "if", "attacker", ":", "\n", "                ", "action_space", "=", "gym", ".", "spaces", ".", "Discrete", "(", "self", ".", "pg_agent_config", ".", "attacker_at_net_output_dim", ")", "\n", "", "else", ":", "\n", "                ", "action_space", "=", "gym", ".", "spaces", ".", "Discrete", "(", "self", ".", "pg_agent_config", ".", "defender_at_net_output_dim", ")", "\n", "\n", "# Action distribution", "\n", "", "", "self", ".", "action_dist", "=", "make_proba_distribution", "(", "action_space", ",", "use_sde", "=", "use_sde", ",", "dist_kwargs", "=", "dist_kwargs", ")", "\n", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "_build", "(", "lr_schedule", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy._get_data": [[154, 174], ["super()._get_data", "super()._get_data.update", "dict"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy._get_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update"], ["", "def", "_get_data", "(", "self", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "data", "=", "super", "(", ")", ".", "_get_data", "(", ")", "\n", "\n", "data", ".", "update", "(", "dict", "(", "\n", "net_arch", "=", "self", ".", "net_arch", ",", "\n", "activation_fn", "=", "self", ".", "activation_fn", ",", "\n", "use_sde", "=", "self", ".", "use_sde", ",", "\n", "log_std_init", "=", "self", ".", "log_std_init", ",", "\n", "squash_output", "=", "self", ".", "dist_kwargs", "[", "'squash_output'", "]", "if", "self", ".", "dist_kwargs", "else", "None", ",", "\n", "full_std", "=", "self", ".", "dist_kwargs", "[", "'full_std'", "]", "if", "self", ".", "dist_kwargs", "else", "None", ",", "\n", "sde_net_arch", "=", "self", ".", "dist_kwargs", "[", "'sde_net_arch'", "]", "if", "self", ".", "dist_kwargs", "else", "None", ",", "\n", "use_expln", "=", "self", ".", "dist_kwargs", "[", "'use_expln'", "]", "if", "self", ".", "dist_kwargs", "else", "None", ",", "\n", "lr_schedule", "=", "self", ".", "_dummy_schedule", ",", "# dummy lr schedule, not needed for loading policy alone", "\n", "ortho_init", "=", "self", ".", "ortho_init", ",", "\n", "optimizer_class", "=", "self", ".", "optimizer_class", ",", "\n", "optimizer_kwargs", "=", "self", ".", "optimizer_kwargs", ",", "\n", "features_extractor_class", "=", "self", ".", "features_extractor_class", ",", "\n", "features_extractor_kwargs", "=", "self", ".", "features_extractor_kwargs", "\n", ")", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise": [[175, 184], ["isinstance", "ppo_policies.PPOPolicy.action_dist.sample_weights"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.sample_weights"], ["", "def", "reset_noise", "(", "self", ",", "n_envs", ":", "int", "=", "1", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Sample new weights for the exploration matrix.\n\n        :param n_envs: (int)\n        \"\"\"", "\n", "assert", "isinstance", "(", "self", ".", "action_dist", ",", "\n", "StateDependentNoiseDistribution", ")", ",", "'reset_noise() is only available when using gSDE'", "\n", "self", ".", "action_dist", ".", "sample_weights", "(", "self", ".", "log_std", ",", "batch_size", "=", "n_envs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy._build": [[185, 234], ["gym_idsgame.agents.training_agents.openai_baselines.common.common_policies.MlpExtractor", "isinstance", "torch.Linear", "torch.Linear", "ppo_policies.PPOPolicy.optimizer_class", "gym_idsgame.agents.training_agents.openai_baselines.common.common_policies.create_sde_features_extractor", "ppo_policies.PPOPolicy.action_dist.proba_distribution_net", "isinstance", "ppo_policies.PPOPolicy.parameters", "ppo_policies.PPOPolicy.action_dist.proba_distribution_net", "isinstance", "lr_schedule", "ppo_policies.PPOPolicy.action_dist.proba_distribution_net", "module.apply", "numpy.sqrt", "numpy.sqrt", "functools.partial"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.create_sde_features_extractor", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.proba_distribution_net", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.proba_distribution_net", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.proba_distribution_net"], ["", "def", "_build", "(", "self", ",", "lr_schedule", ":", "Callable", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Create the networks and the optimizer.\n\n        :param lr_schedule: (Callable) Learning rate schedule\n            lr_schedule(1) is the initial learning rate\n        \"\"\"", "\n", "self", ".", "mlp_extractor", "=", "MlpExtractor", "(", "self", ".", "features_dim", ",", "net_arch", "=", "self", ".", "net_arch", ",", "\n", "activation_fn", "=", "self", ".", "activation_fn", ",", "device", "=", "self", ".", "device", ",", "\n", "pg_agent_config", "=", "self", ".", "pg_agent_config", ",", "\n", "at_net", "=", "self", ".", "at_net", ",", "node_net", "=", "self", ".", "node_net", ")", "\n", "\n", "latent_dim_pi", "=", "self", ".", "mlp_extractor", ".", "latent_dim_pi", "\n", "\n", "# Separate feature extractor for gSDE", "\n", "if", "self", ".", "sde_net_arch", "is", "not", "None", ":", "\n", "            ", "self", ".", "sde_features_extractor", ",", "latent_sde_dim", "=", "create_sde_features_extractor", "(", "self", ".", "features_dim", ",", "\n", "self", ".", "sde_net_arch", ",", "\n", "self", ".", "activation_fn", ")", "\n", "\n", "", "if", "isinstance", "(", "self", ".", "action_dist", ",", "DiagGaussianDistribution", ")", ":", "\n", "            ", "self", ".", "action_net", ",", "self", ".", "log_std", "=", "self", ".", "action_dist", ".", "proba_distribution_net", "(", "latent_dim", "=", "latent_dim_pi", ",", "\n", "log_std_init", "=", "self", ".", "log_std_init", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "action_dist", ",", "StateDependentNoiseDistribution", ")", ":", "\n", "            ", "latent_sde_dim", "=", "latent_dim_pi", "if", "self", ".", "sde_net_arch", "is", "None", "else", "latent_sde_dim", "\n", "self", ".", "action_net", ",", "self", ".", "log_std", "=", "self", ".", "action_dist", ".", "proba_distribution_net", "(", "latent_dim", "=", "latent_dim_pi", ",", "\n", "latent_sde_dim", "=", "latent_sde_dim", ",", "\n", "log_std_init", "=", "self", ".", "log_std_init", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "action_dist", ",", "CategoricalDistribution", ")", ":", "\n", "            ", "self", ".", "action_net", "=", "self", ".", "action_dist", ".", "proba_distribution_net", "(", "latent_dim", "=", "latent_dim_pi", ")", "\n", "\n", "", "self", ".", "value_net", "=", "nn", ".", "Linear", "(", "self", ".", "mlp_extractor", ".", "latent_dim_vf", ",", "1", ")", "\n", "# Init weights: use orthogonal initialization", "\n", "# with small initial weight for the output", "\n", "if", "self", ".", "ortho_init", ":", "\n", "# TODO: check for features_extractor", "\n", "            ", "for", "module", "in", "[", "self", ".", "features_extractor", ",", "self", ".", "mlp_extractor", ",", "\n", "self", ".", "action_net", ",", "self", ".", "value_net", "]", ":", "\n", "# Values from stable-baselines, TODO: check why", "\n", "                ", "gain", "=", "{", "\n", "self", ".", "features_extractor", ":", "np", ".", "sqrt", "(", "2", ")", ",", "\n", "self", ".", "mlp_extractor", ":", "np", ".", "sqrt", "(", "2", ")", ",", "\n", "self", ".", "action_net", ":", "0.01", ",", "\n", "self", ".", "value_net", ":", "1", "\n", "}", "[", "module", "]", "\n", "if", "self", ".", "pg_agent_config", ".", "cnn_type", "!=", "4", ":", "\n", "                    ", "module", ".", "apply", "(", "partial", "(", "self", ".", "init_weights", ",", "gain", "=", "gain", ")", ")", "\n", "# Setup optimizer with initial learning rate", "\n", "", "", "", "self", ".", "optimizer", "=", "self", ".", "optimizer_class", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "lr_schedule", "(", "1", ")", ",", "**", "self", ".", "optimizer_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.forward": [[235, 316], ["ppo_policies.PPOPolicy.value_net", "ppo_policies.PPOPolicy._get_action_dist_from_latent", "ppo_policies.PPOPolicy.get_actions", "torch.tensor", "torch.tensor", "list.to", "ppo_policies.PPOPolicy.log_prob", "c_1_f.to.to.to", "c_2_f.to.to.to", "c_3_f.to.to.to", "c_4_f.to.to.to", "ppo_policies.PPOPolicy._get_latent", "ppo_policies.PPOPolicy._get_latent", "obs.cpu().numpy", "numpy.array().astype", "obs.to", "obs.cpu", "list", "list", "list", "list", "list", "list", "numpy.array", "list", "list", "filter", "len", "len", "range", "list", "list", "list", "list", "list", "range", "filter", "len", "len", "range", "filter", "len", "len", "range", "range", "filter", "filter", "filter", "filter", "filter", "len", "list", "filter", "env.is_attack_legal", "env.is_attack_legal", "env.is_attack_legal", "env.is_defense_legal", "env.is_defense_legal", "wrapper_env.convert_local_attacker_action_to_global", "env.is_attack_legal", "env.is_attack_legal", "env.is_attack_legal", "env.is_reconnaissance", "wrapper_env.convert_local_attacker_action_to_global", "env.is_attack_legal", "env.is_reconnaissance"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy._get_action_dist_from_latent", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.Distribution.get_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.log_prob", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy._get_latent", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy._get_latent", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_reconnaissance", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_reconnaissance"], ["", "def", "forward", "(", "self", ",", "obs", ":", "th", ".", "Tensor", ",", "env", ":", "IdsGameEnv", ",", "\n", "deterministic", ":", "bool", "=", "False", ",", "device", ":", "str", "=", "\"cpu\"", ",", "attacker", "=", "True", ",", "\n", "non_legal_actions", "=", "None", ",", "wrapper_env", ":", "BaselineEnvWrapper", "=", "None", ",", "force_rec", ":", "bool", "=", "False", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass in all the networks (actor and critic)\n\n        :param obs: (th.Tensor) Observation\n        :param deterministic: (bool) Whether to sample or use deterministic actions\n        :return: (Tuple[th.Tensor, th.Tensor, th.Tensor]) action, value and log probability of the action\n        \"\"\"", "\n", "if", "(", "self", ".", "pg_agent_config", ".", "multi_channel_obs", "and", "not", "self", ".", "pg_agent_config", ".", "ar_policy", ")", "or", "(", "self", ".", "pg_agent_config", ".", "ar_policy", "and", "self", ".", "node_net", "and", "self", ".", "pg_agent_config", ".", "attacker_node_net_multi_channel", ")", ":", "\n", "            ", "c_1_f", ",", "c_2_f", ",", "c_3_f", ",", "c_4_f", "=", "obs", "\n", "c_1_f", "=", "c_1_f", ".", "to", "(", "device", ")", "\n", "c_2_f", "=", "c_2_f", ".", "to", "(", "device", ")", "\n", "c_3_f", "=", "c_3_f", ".", "to", "(", "device", ")", "\n", "c_4_f", "=", "c_4_f", ".", "to", "(", "device", ")", "\n", "latent_pi", ",", "latent_vf", ",", "latent_sde", ",", "lstm_state", "=", "self", ".", "_get_latent", "(", "None", ",", "channel_1_features", "=", "c_1_f", ",", "\n", "channel_2_features", "=", "c_2_f", ",", "\n", "channel_3_features", "=", "c_3_f", ",", "\n", "channel_4_features", "=", "c_4_f", ")", "\n", "", "else", ":", "\n", "            ", "latent_pi", ",", "latent_vf", ",", "latent_sde", ",", "lstm_state", "=", "self", ".", "_get_latent", "(", "obs", ".", "to", "(", "device", ")", ")", "\n", "# Evaluate the values for the given observations", "\n", "", "values", "=", "self", ".", "value_net", "(", "latent_vf", ")", "\n", "if", "wrapper_env", "is", "not", "None", ":", "\n", "            ", "np_obs", "=", "obs", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "# Masking", "\n", "", "if", "non_legal_actions", "is", "None", ":", "\n", "            ", "if", "attacker", ":", "\n", "                ", "if", "self", ".", "pg_agent_config", ".", "ar_policy", ":", "\n", "                    ", "if", "self", ".", "node_net", ":", "\n", "                        ", "actions", "=", "list", "(", "range", "(", "self", ".", "pg_agent_config", ".", "attacker_node_net_output_dim", ")", ")", "\n", "", "else", ":", "\n", "                        ", "actions", "=", "list", "(", "range", "(", "self", ".", "pg_agent_config", ".", "attacker_at_net_output_dim", ")", ")", "\n", "", "non_legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "not", "env", ".", "is_attack_legal", "(", "action", ",", "node", "=", "self", ".", "node_net", ")", ",", "actions", ")", ")", "\n", "if", "len", "(", "non_legal_actions", ")", "==", "len", "(", "actions", ")", ":", "\n", "                        ", "non_legal_actions", "=", "[", "]", "\n", "", "", "else", ":", "\n", "                    ", "actions", "=", "list", "(", "range", "(", "env", ".", "num_attack_actions", ")", ")", "\n", "if", "wrapper_env", "is", "not", "None", ":", "\n", "                        ", "legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "env", ".", "is_attack_legal", "(", "\n", "wrapper_env", ".", "convert_local_attacker_action_to_global", "(", "action", ",", "np_obs", ")", ",", "node", "=", "self", ".", "node_net", ")", ",", "actions", ")", ")", "\n", "", "else", ":", "\n", "                        ", "legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "env", ".", "is_attack_legal", "(", "action", ",", "node", "=", "self", ".", "node_net", ")", ",", "actions", ")", ")", "\n", "", "if", "wrapper_env", "is", "not", "None", ":", "\n", "                        ", "non_legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "not", "env", ".", "is_attack_legal", "(", "\n", "wrapper_env", ".", "convert_local_attacker_action_to_global", "(", "action", ",", "np_obs", ")", ",", "node", "=", "self", ".", "node_net", ")", ",", "actions", ")", ")", "\n", "", "else", ":", "\n", "                        ", "non_legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "not", "env", ".", "is_attack_legal", "(", "action", ",", "node", "=", "self", ".", "node_net", ")", ",", "actions", ")", ")", "\n", "", "if", "force_rec", ":", "\n", "                        ", "legal_rec", "=", "list", "(", "filter", "(", "lambda", "action", ":", "env", ".", "is_attack_legal", "(", "action", ",", "node", "=", "self", ".", "node_net", ")", "and", "env", ".", "is_reconnaissance", "(", "action", ")", ",", "actions", ")", ")", "\n", "if", "len", "(", "legal_rec", ")", ">", "0", ":", "\n", "                            ", "non_legal_no_rec", "=", "list", "(", "\n", "filter", "(", "lambda", "action", ":", "not", "env", ".", "is_attack_legal", "(", "action", ",", "node", "=", "self", ".", "node_net", ")", "or", "not", "env", ".", "is_reconnaissance", "(", "action", ")", ",", "\n", "actions", ")", ")", "\n", "# print(\"force reconnaissance, before force:{}, after:{}\".format(", "\n", "#     len(non_legal_actions), len(non_legal_no_rec)))", "\n", "non_legal_actions", "=", "non_legal_no_rec", "\n", "\n", "", "", "", "", "else", ":", "\n", "                ", "if", "self", ".", "pg_agent_config", ".", "ar_policy", ":", "\n", "                    ", "actions", "=", "list", "(", "range", "(", "self", ".", "pg_agent_config", ".", "defender_node_net_output_dim", ")", ")", "\n", "non_legal_actions", "=", "list", "(", "\n", "filter", "(", "lambda", "action", ":", "not", "env", ".", "is_defense_legal", "(", "action", ",", "node", "=", "self", ".", "node_net", ",", "obs", "=", "obs", ")", ",", "actions", ")", ")", "\n", "if", "len", "(", "non_legal_actions", ")", "==", "len", "(", "actions", ")", ":", "\n", "                        ", "non_legal_actions", "=", "[", "]", "\n", "", "", "else", ":", "\n", "                    ", "actions", "=", "list", "(", "range", "(", "env", ".", "num_defense_actions", ")", ")", "\n", "non_legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "not", "env", ".", "is_defense_legal", "(", "action", ")", ",", "actions", ")", ")", "\n", "if", "len", "(", "non_legal_actions", ")", "==", "len", "(", "actions", ")", ":", "\n", "                        ", "non_legal_actions", "=", "[", "]", "\n", "\n", "", "", "", "", "distribution", "=", "self", ".", "_get_action_dist_from_latent", "(", "latent_pi", ",", "latent_sde", "=", "latent_sde", ",", "device", "=", "device", ",", "\n", "non_legal_actions", "=", "non_legal_actions", ")", "\n", "actions", "=", "distribution", ".", "get_actions", "(", "deterministic", "=", "deterministic", ")", "\n", "actions", "=", "th", ".", "tensor", "(", "np", ".", "array", "(", "[", "actions", "]", ")", ".", "astype", "(", "np", ".", "int32", ")", ")", "\n", "actions", "=", "actions", ".", "to", "(", "self", ".", "device", ")", "\n", "log_prob", "=", "distribution", ".", "log_prob", "(", "actions", ")", "\n", "return", "actions", ",", "values", ",", "log_prob", ",", "lstm_state", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.get_action_dist": [[317, 390], ["ppo_policies.PPOPolicy.value_net", "ppo_policies.PPOPolicy._get_action_dist_from_latent", "c_1_f.to.to.to", "c_2_f.to.to.to", "c_3_f.to.to.to", "c_4_f.to.to.to", "ppo_policies.PPOPolicy._get_latent", "ppo_policies.PPOPolicy._get_latent", "obs.cpu().numpy", "obs.to", "obs.cpu", "list", "list", "list", "list", "list", "list", "list", "list", "filter", "len", "len", "range", "list", "list", "list", "list", "range", "filter", "len", "len", "range", "filter", "len", "len", "range", "range", "filter", "filter", "filter", "filter", "env.is_attack_legal", "env.is_attack_legal", "env.is_attack_legal", "env.is_defense_legal", "env.is_defense_legal", "wrapper_env.convert_local_attacker_action_to_global", "env.is_attack_legal", "env.is_attack_legal", "wrapper_env.convert_local_attacker_action_to_global"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy._get_action_dist_from_latent", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy._get_latent", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy._get_latent", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global"], ["", "def", "get_action_dist", "(", "self", ",", "obs", ":", "th", ".", "Tensor", ",", "env", ":", "IdsGameEnv", ",", "\n", "device", ":", "str", "=", "\"cpu\"", ",", "attacker", "=", "True", ",", "\n", "non_legal_actions", "=", "None", ",", "wrapper_env", ":", "BaselineEnvWrapper", "=", "None", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Forward pass in all the networks (actor and critic)\n\n        :param obs: (th.Tensor) Observation\n        :return: (Tuple[th.Tensor, th.Tensor, th.Tensor]) action, value and log probability of the action\n        \"\"\"", "\n", "if", "(", "self", ".", "pg_agent_config", ".", "multi_channel_obs", "and", "not", "self", ".", "pg_agent_config", ".", "ar_policy", ")", "or", "(", "\n", "self", ".", "pg_agent_config", ".", "ar_policy", "and", "self", ".", "node_net", "and", "self", ".", "pg_agent_config", ".", "attacker_node_net_multi_channel", ")", ":", "\n", "            ", "c_1_f", ",", "c_2_f", ",", "c_3_f", ",", "c_4_f", "=", "obs", "\n", "c_1_f", "=", "c_1_f", ".", "to", "(", "device", ")", "\n", "c_2_f", "=", "c_2_f", ".", "to", "(", "device", ")", "\n", "c_3_f", "=", "c_3_f", ".", "to", "(", "device", ")", "\n", "c_4_f", "=", "c_4_f", ".", "to", "(", "device", ")", "\n", "latent_pi", ",", "latent_vf", ",", "latent_sde", ",", "lstm_state", "=", "self", ".", "_get_latent", "(", "None", ",", "channel_1_features", "=", "c_1_f", ",", "\n", "channel_2_features", "=", "c_2_f", ",", "\n", "channel_3_features", "=", "c_3_f", ",", "\n", "channel_4_features", "=", "c_4_f", ")", "\n", "", "else", ":", "\n", "            ", "latent_pi", ",", "latent_vf", ",", "latent_sde", ",", "lstm_state", "=", "self", ".", "_get_latent", "(", "obs", ".", "to", "(", "device", ")", ")", "\n", "# Evaluate the values for the given observations", "\n", "", "values", "=", "self", ".", "value_net", "(", "latent_vf", ")", "\n", "if", "wrapper_env", "is", "not", "None", ":", "\n", "            ", "np_obs", "=", "obs", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "# Masking", "\n", "", "if", "non_legal_actions", "is", "None", ":", "\n", "            ", "if", "attacker", ":", "\n", "                ", "if", "self", ".", "pg_agent_config", ".", "ar_policy", ":", "\n", "                    ", "if", "self", ".", "node_net", ":", "\n", "                        ", "actions", "=", "list", "(", "range", "(", "self", ".", "pg_agent_config", ".", "attacker_node_net_output_dim", ")", ")", "\n", "", "else", ":", "\n", "                        ", "actions", "=", "list", "(", "range", "(", "self", ".", "pg_agent_config", ".", "attacker_at_net_output_dim", ")", ")", "\n", "", "non_legal_actions", "=", "list", "(", "\n", "filter", "(", "lambda", "action", ":", "not", "env", ".", "is_attack_legal", "(", "action", ",", "node", "=", "self", ".", "node_net", ")", ",", "actions", ")", ")", "\n", "if", "len", "(", "non_legal_actions", ")", "==", "len", "(", "actions", ")", ":", "\n", "                        ", "non_legal_actions", "=", "[", "]", "\n", "", "", "else", ":", "\n", "                    ", "actions", "=", "list", "(", "range", "(", "env", ".", "num_attack_actions", ")", ")", "\n", "if", "wrapper_env", "is", "not", "None", ":", "\n", "                        ", "legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "env", ".", "is_attack_legal", "(", "\n", "wrapper_env", ".", "convert_local_attacker_action_to_global", "(", "action", ",", "np_obs", ")", ",", "node", "=", "self", ".", "node_net", ")", ",", "\n", "actions", ")", ")", "\n", "", "else", ":", "\n", "                        ", "legal_actions", "=", "list", "(", "\n", "filter", "(", "lambda", "action", ":", "env", ".", "is_attack_legal", "(", "action", ",", "node", "=", "self", ".", "node_net", ")", ",", "actions", ")", ")", "\n", "", "if", "wrapper_env", "is", "not", "None", ":", "\n", "                        ", "non_legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "not", "env", ".", "is_attack_legal", "(", "\n", "wrapper_env", ".", "convert_local_attacker_action_to_global", "(", "action", ",", "np_obs", ")", ",", "node", "=", "self", ".", "node_net", ")", ",", "\n", "actions", ")", ")", "\n", "", "else", ":", "\n", "                        ", "non_legal_actions", "=", "list", "(", "\n", "filter", "(", "lambda", "action", ":", "not", "env", ".", "is_attack_legal", "(", "action", ",", "node", "=", "self", ".", "node_net", ")", ",", "actions", ")", ")", "\n", "\n", "", "", "", "else", ":", "\n", "                ", "if", "self", ".", "pg_agent_config", ".", "ar_policy", ":", "\n", "                    ", "actions", "=", "list", "(", "range", "(", "self", ".", "pg_agent_config", ".", "defender_node_net_output_dim", ")", ")", "\n", "non_legal_actions", "=", "list", "(", "\n", "filter", "(", "lambda", "action", ":", "not", "env", ".", "is_defense_legal", "(", "action", ",", "node", "=", "self", ".", "node_net", ",", "obs", "=", "obs", ")", ",", "actions", ")", ")", "\n", "if", "len", "(", "non_legal_actions", ")", "==", "len", "(", "actions", ")", ":", "\n", "                        ", "non_legal_actions", "=", "[", "]", "\n", "", "", "else", ":", "\n", "                    ", "actions", "=", "list", "(", "range", "(", "env", ".", "num_defense_actions", ")", ")", "\n", "non_legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "not", "env", ".", "is_defense_legal", "(", "action", ")", ",", "actions", ")", ")", "\n", "if", "len", "(", "non_legal_actions", ")", "==", "len", "(", "actions", ")", ":", "\n", "                        ", "non_legal_actions", "=", "[", "]", "\n", "\n", "", "", "", "", "action_probs", "=", "self", ".", "_get_action_dist_from_latent", "(", "latent_pi", ",", "latent_sde", "=", "latent_sde", ",", "device", "=", "device", ",", "\n", "non_legal_actions", "=", "non_legal_actions", ",", "get_action_probs", "=", "True", ")", "\n", "return", "action_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy._get_latent": [[391, 418], ["ppo_policies.PPOPolicy.mlp_extractor", "ppo_policies.PPOPolicy.extract_features", "ppo_policies.PPOPolicy.sde_features_extractor"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.extract_features"], ["", "def", "_get_latent", "(", "self", ",", "obs", ":", "th", ".", "Tensor", ",", "lstm_state", "=", "None", ",", "masks", "=", "None", ",", "\n", "channel_1_features", "=", "None", ",", "\n", "channel_2_features", "=", "None", ",", "channel_3_features", "=", "None", ",", "channel_4_features", "=", "None", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Get the latent code (i.e., activations of the last layer of each network)\n        for the different networks.\n\n        :param obs: (th.Tensor) Observation\n        :return: (Tuple[th.Tensor, th.Tensor, th.Tensor]) Latent codes\n            for the actor, the value function and for gSDE function\n        \"\"\"", "\n", "# Preprocess the observation if needed", "\n", "if", "not", "self", ".", "pg_agent_config", ".", "multi_channel_obs", ":", "\n", "            ", "features", "=", "self", ".", "extract_features", "(", "obs", ")", "\n", "", "else", ":", "\n", "            ", "features", "=", "obs", "\n", "", "latent_pi", ",", "latent_vf", ",", "lstm_state", "=", "self", ".", "mlp_extractor", "(", "features", ",", "lstm_state", "=", "lstm_state", ",", "masks", "=", "masks", ",", "\n", "channel_1_features", "=", "channel_1_features", ",", "\n", "channel_2_features", "=", "channel_2_features", ",", "\n", "channel_3_features", "=", "channel_3_features", ",", "\n", "channel_4_features", "=", "channel_4_features", ")", "\n", "\n", "# Features for sde", "\n", "latent_sde", "=", "latent_pi", "\n", "if", "self", ".", "sde_features_extractor", "is", "not", "None", ":", "\n", "            ", "latent_sde", "=", "self", ".", "sde_features_extractor", "(", "features", ")", "\n", "", "return", "latent_pi", ",", "latent_vf", ",", "latent_sde", ",", "lstm_state", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy._get_action_dist_from_latent": [[419, 469], ["torch.nn.functional.softmax().squeeze.to", "torch.nn.functional.softmax().squeeze.clone", "action_probs_1.to.to.to", "isinstance", "len", "torch.nn.functional.softmax().squeeze", "torch.nn.functional.softmax().squeeze", "ppo_policies.PPOPolicy.action_dist.proba_distribution", "isinstance", "len", "torch.nn.functional.softmax().squeeze", "torch.nn.functional.softmax().squeeze", "len", "len", "ppo_policies.PPOPolicy.action_dist.proba_distribution", "isinstance", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "len", "torch.nn.functional.softmax().squeeze", "torch.nn.functional.softmax().squeeze", "AssertionError", "len", "AssertionError", "ppo_policies.PPOPolicy.action_dist.proba_distribution", "isinstance", "ppo_policies.PPOPolicy.action_net", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "ppo_policies.PPOPolicy.action_dist.proba_distribution", "isinstance", "ppo_policies.PPOPolicy.action_net", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "ppo_policies.PPOPolicy.action_dist.proba_distribution", "ValueError", "ppo_policies.PPOPolicy.action_net", "latent_pi.squeeze"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.proba_distribution", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.proba_distribution", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.proba_distribution", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.proba_distribution", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.proba_distribution"], ["", "def", "_get_action_dist_from_latent", "(", "self", ",", "latent_pi", ":", "th", ".", "Tensor", ",", "latent_sde", ":", "Optional", "[", "th", ".", "Tensor", "]", "=", "None", ",", "\n", "non_legal_actions", ":", "List", "=", "None", ",", "device", "=", "\"cpu\"", ",", "get_action_probs", "=", "False", ")", "->", "Distribution", ":", "\n", "        ", "\"\"\"\n        Retrieve action distribution given the latent codes.\n\n        :param latent_pi: (th.Tensor) Latent code for the actor\n        :param latent_sde: (Optional[th.Tensor]) Latent code for the gSDE exploration function\n        :return: (Distribution) Action distribution\n        \"\"\"", "\n", "#mean_actions = self.action_net(latent_pi)", "\n", "\n", "if", "len", "(", "latent_pi", ".", "shape", ")", "==", "2", ":", "\n", "            ", "mean_actions", "=", "th", ".", "nn", ".", "functional", ".", "softmax", "(", "self", ".", "action_net", "(", "latent_pi", ")", ",", "dim", "=", "1", ")", ".", "squeeze", "(", ")", "\n", "", "elif", "len", "(", "latent_pi", ".", "shape", ")", "==", "1", ":", "\n", "            ", "mean_actions", "=", "th", ".", "nn", ".", "functional", ".", "softmax", "(", "self", ".", "action_net", "(", "latent_pi", ")", ",", "dim", "=", "0", ")", ".", "squeeze", "(", ")", "\n", "", "elif", "len", "(", "latent_pi", ".", "shape", ")", "==", "3", ":", "\n", "            ", "mean_actions", "=", "th", ".", "nn", ".", "functional", ".", "softmax", "(", "self", ".", "action_net", "(", "latent_pi", ".", "squeeze", "(", ")", ")", ",", "dim", "=", "0", ")", ".", "squeeze", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Shape not recognized: {}\"", ".", "format", "(", "latent_pi", ".", "shape", ")", ")", "\n", "", "mean_actions", "=", "mean_actions", ".", "to", "(", "device", ")", "\n", "action_probs_1", "=", "mean_actions", ".", "clone", "(", ")", "\n", "if", "non_legal_actions", "is", "not", "None", "and", "len", "(", "non_legal_actions", ")", ">", "0", ":", "\n", "            ", "if", "len", "(", "action_probs_1", ".", "shape", ")", "==", "1", ":", "\n", "#action_probs_1[non_legal_actions] = 0.00000000000001 # Don't set to zero due to invalid distribution errors", "\n", "                ", "action_probs_1", "[", "non_legal_actions", "]", "=", "0.0", "\n", "", "elif", "len", "(", "action_probs_1", ".", "shape", ")", "==", "2", ":", "\n", "#action_probs_1[:, non_legal_actions] = 0.00000000000001  # Don't set to zero due to invalid distribution errors", "\n", "                ", "action_probs_1", "[", ":", ",", "non_legal_actions", "]", "=", "0.0", "\n", "", "else", ":", "\n", "                ", "raise", "AssertionError", "(", "\"Invalid shape of action probabilties\"", ")", "\n", "", "", "action_probs_1", "=", "action_probs_1", ".", "to", "(", "device", ")", "\n", "\n", "if", "get_action_probs", ":", "\n", "            ", "return", "action_probs_1", "\n", "\n", "", "if", "isinstance", "(", "self", ".", "action_dist", ",", "DiagGaussianDistribution", ")", ":", "\n", "            ", "return", "self", ".", "action_dist", ".", "proba_distribution", "(", "mean_actions", ",", "self", ".", "log_std", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "action_dist", ",", "CategoricalDistribution", ")", ":", "\n", "# Here mean_actions are the logits before the softmax", "\n", "            ", "return", "self", ".", "action_dist", ".", "proba_distribution", "(", "action_logits", "=", "action_probs_1", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "action_dist", ",", "MultiCategoricalDistribution", ")", ":", "\n", "# Here mean_actions are the flattened logits", "\n", "            ", "return", "self", ".", "action_dist", ".", "proba_distribution", "(", "action_logits", "=", "mean_actions", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "action_dist", ",", "BernoulliDistribution", ")", ":", "\n", "# Here mean_actions are the logits (before rounding to get the binary actions)", "\n", "            ", "return", "self", ".", "action_dist", ".", "proba_distribution", "(", "action_logits", "=", "mean_actions", ")", "\n", "", "elif", "isinstance", "(", "self", ".", "action_dist", ",", "StateDependentNoiseDistribution", ")", ":", "\n", "            ", "return", "self", ".", "action_dist", ".", "proba_distribution", "(", "mean_actions", ",", "self", ".", "log_std", ",", "latent_sde", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Invalid action distribution'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy._predict": [[470, 526], ["ppo_policies.PPOPolicy._get_latent", "ppo_policies.PPOPolicy._get_action_dist_from_latent", "ppo_policies.PPOPolicy.get_actions", "list", "list", "list", "list", "list", "list", "list", "filter", "len", "len", "range", "list", "list", "list", "list", "range", "filter", "len", "len", "list", "list", "filter", "len", "len", "range", "range", "filter", "filter", "filter", "filter", "range", "range", "env.is_attack_legal", "env.is_attack_legal", "env.is_attack_legal", "env.is_defense_legal", "env.is_defense_legal", "wrapper_env.convert_local_attacker_action_to_global", "env.is_attack_legal", "env.is_attack_legal", "wrapper_env.convert_local_attacker_action_to_global"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy._get_latent", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy._get_action_dist_from_latent", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.Distribution.get_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global"], ["", "", "def", "_predict", "(", "self", ",", "observation", ":", "th", ".", "Tensor", ",", "env", ":", "IdsGameEnv", ",", "deterministic", ":", "bool", "=", "False", ",", "\n", "device", ":", "str", "=", "\"cpu\"", ",", "attacker", "=", "True", ",", "wrapper_env", ":", "BaselineEnvWrapper", "=", "None", ",", "\n", "channel_1_features", "=", "None", ",", "\n", "channel_2_features", "=", "None", ",", "channel_3_features", "=", "None", ",", "channel_4_features", "=", "None", "\n", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Get the action according to the policy for a given observation.\n\n        :param observation: (th.Tensor)\n        :param deterministic: (bool) Whether to use stochastic or deterministic actions\n        :return: (th.Tensor) Taken action according to the policy\n        \"\"\"", "\n", "latent_pi", ",", "_", ",", "latent_sde", ",", "lstm_state", "=", "self", ".", "_get_latent", "(", "observation", ",", "channel_1_features", "=", "channel_1_features", ",", "\n", "channel_2_features", "=", "channel_2_features", ",", "\n", "channel_3_features", "=", "channel_3_features", ",", "\n", "channel_4_features", "=", "channel_4_features", ")", "\n", "\n", "# Masking", "\n", "if", "attacker", ":", "\n", "            ", "if", "self", ".", "pg_agent_config", ".", "ar_policy", ":", "\n", "                ", "if", "self", ".", "node_net", ":", "\n", "                    ", "actions", "=", "list", "(", "range", "(", "self", ".", "pg_agent_config", ".", "attacker_node_net_output_dim", ")", ")", "\n", "", "else", ":", "\n", "                    ", "actions", "=", "list", "(", "range", "(", "self", ".", "pg_agent_config", ".", "attacker_at_net_output_dim", ")", ")", "\n", "", "non_legal_actions", "=", "list", "(", "\n", "filter", "(", "lambda", "action", ":", "not", "env", ".", "is_attack_legal", "(", "action", ",", "node", "=", "self", ".", "node_net", ")", ",", "actions", ")", ")", "\n", "if", "len", "(", "non_legal_actions", ")", "==", "len", "(", "actions", ")", ":", "\n", "                    ", "non_legal_actions", "=", "[", "]", "\n", "", "", "else", ":", "\n", "                ", "actions", "=", "list", "(", "range", "(", "env", ".", "num_attack_actions", ")", ")", "\n", "if", "wrapper_env", "is", "not", "None", ":", "\n", "                    ", "legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "env", ".", "is_attack_legal", "(", "wrapper_env", ".", "convert_local_attacker_action_to_global", "(", "action", ",", "observation", ")", ",", "node", "=", "self", ".", "node_net", ")", ",", "actions", ")", ")", "\n", "", "else", ":", "\n", "                    ", "legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "env", ".", "is_attack_legal", "(", "action", ",", "node", "=", "self", ".", "node_net", ")", ",", "actions", ")", ")", "\n", "", "if", "wrapper_env", "is", "not", "None", ":", "\n", "                    ", "non_legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "not", "env", ".", "is_attack_legal", "(", "wrapper_env", ".", "convert_local_attacker_action_to_global", "(", "action", ",", "observation", ")", ",", "node", "=", "self", ".", "node_net", ")", ",", "actions", ")", ")", "\n", "", "else", ":", "\n", "                    ", "non_legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "not", "env", ".", "is_attack_legal", "(", "action", ",", "node", "=", "self", ".", "node_net", ")", ",", "actions", ")", ")", "\n", "", "", "", "else", ":", "\n", "            ", "if", "not", "self", ".", "pg_agent_config", ".", "ar_policy", ":", "\n", "                ", "actions", "=", "list", "(", "range", "(", "env", ".", "num_defense_actions", ")", ")", "\n", "non_legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "not", "env", ".", "is_defense_legal", "(", "action", ")", ",", "actions", ")", ")", "\n", "if", "len", "(", "non_legal_actions", ")", "==", "len", "(", "actions", ")", ":", "\n", "                    ", "non_legal_actions", "=", "[", "]", "\n", "", "", "else", ":", "\n", "                ", "if", "self", ".", "node_net", ":", "\n", "                    ", "actions", "=", "list", "(", "range", "(", "self", ".", "pg_agent_config", ".", "defender_node_net_output_dim", ")", ")", "\n", "", "else", ":", "\n", "                    ", "actions", "=", "list", "(", "range", "(", "self", ".", "pg_agent_config", ".", "defender_at_net_output_dim", ")", ")", "\n", "", "non_legal_actions", "=", "list", "(", "\n", "filter", "(", "lambda", "action", ":", "not", "env", ".", "is_defense_legal", "(", "action", ",", "node", "=", "self", ".", "node_net", ",", "obs", "=", "observation", ")", ",", "actions", ")", ")", "\n", "if", "len", "(", "non_legal_actions", ")", "==", "len", "(", "actions", ")", ":", "\n", "                    ", "non_legal_actions", "=", "[", "]", "\n", "", "", "", "distribution", "=", "self", ".", "_get_action_dist_from_latent", "(", "latent_pi", ",", "latent_sde", ",", "device", "=", "device", ",", "\n", "non_legal_actions", "=", "non_legal_actions", ")", "\n", "return", "distribution", ".", "get_actions", "(", "deterministic", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.evaluate_actions": [[527, 596], ["ppo_policies.PPOPolicy._get_action_dist_from_latent", "ppo_policies.PPOPolicy.log_prob", "ppo_policies.PPOPolicy.value_net", "ppo_policies.PPOPolicy._get_latent", "ppo_policies.PPOPolicy._get_latent", "ppo_policies.PPOPolicy.entropy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy._get_action_dist_from_latent", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.log_prob", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy._get_latent", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy._get_latent", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.entropy"], ["", "def", "evaluate_actions", "(", "self", ",", "obs", ":", "th", ".", "Tensor", ",", "\n", "actions", ":", "th", ".", "Tensor", ",", "env", ":", "IdsGameEnv", ",", "attacker", "=", "False", ",", "\n", "wrapper_env", ":", "BaselineEnvWrapper", "=", "None", ",", "\n", "states", "=", "None", ",", "masks", "=", "None", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Evaluate actions according to the current policy,\n        given the observations.\n\n        :param obs: (th.Tensor)\n        :param actions: (th.Tensor)\n        :return: (th.Tensor, th.Tensor, th.Tensor) estimated value, log likelihood of taking those actions\n            and entropy of the action distribution.\n        \"\"\"", "\n", "if", "(", "self", ".", "pg_agent_config", ".", "multi_channel_obs", "and", "not", "self", ".", "pg_agent_config", ".", "ar_policy", ")", "or", "(", "self", ".", "pg_agent_config", ".", "ar_policy", "and", "self", ".", "node_net", "and", "self", ".", "pg_agent_config", ".", "attacker_node_net_multi_channel", ")", ":", "\n", "            ", "c_1_f", ",", "c_2_f", ",", "c_3_f", ",", "c_4_f", "=", "obs", "\n", "latent_pi", ",", "latent_vf", ",", "latent_sde", ",", "lstm_state", "=", "self", ".", "_get_latent", "(", "obs", ",", "lstm_state", "=", "states", ",", "masks", "=", "masks", ",", "\n", "channel_1_features", "=", "c_1_f", ",", "\n", "channel_2_features", "=", "c_2_f", ",", "\n", "channel_3_features", "=", "c_3_f", ",", "\n", "channel_4_features", "=", "c_4_f", ")", "\n", "", "else", ":", "\n", "            ", "latent_pi", ",", "latent_vf", ",", "latent_sde", ",", "lstm_state", "=", "self", ".", "_get_latent", "(", "obs", ",", "lstm_state", "=", "states", ",", "masks", "=", "masks", ")", "\n", "\n", "# # Masking", "\n", "# if attacker:", "\n", "#     if self.pg_agent_config.ar_policy:", "\n", "#         if self.node_net:", "\n", "#             all_actions = list(range(self.pg_agent_config.attacker_node_net_output_dim))", "\n", "#         else:", "\n", "#             all_actions = list(range(self.pg_agent_config.attacker_at_net_output_dim))", "\n", "#         non_legal_actions = list(", "\n", "#             filter(lambda action: not env.is_attack_legal(action, node=self.node_net), all_actions))", "\n", "#         if len(non_legal_actions) == len(all_actions):", "\n", "#             non_legal_actions = []", "\n", "#     else:", "\n", "#         all_actions = list(range(env.num_attack_actions))", "\n", "#         if wrapper_env is not None:", "\n", "#             legal_actions = list(filter(lambda action: env.is_attack_legal(", "\n", "#                 wrapper_env.convert_local_attacker_action_to_global(action, obs), node=self.node_net), actions))", "\n", "#         else:", "\n", "#             legal_actions = list(filter(lambda action: env.is_attack_legal(action, node=self.node_net), actions))", "\n", "#         if wrapper_env is not None:", "\n", "#             non_legal_actions = list(filter(lambda action: not env.is_attack_legal(", "\n", "#                 wrapper_env.convert_local_attacker_action_to_global(action, obs), node=self.node_net), actions))", "\n", "#         else:", "\n", "#             non_legal_actions = list(filter(lambda action: not env.is_attack_legal(action, node=self.node_net), actions))", "\n", "# else:", "\n", "#     if not self.pg_agent_config.ar_policy:", "\n", "#         all_actions = list(range(env.num_defense_actions))", "\n", "#         non_legal_actions = list(filter(lambda action: not env.is_defense_legal(action), all_actions))", "\n", "#         if len(non_legal_actions) == len(actions):", "\n", "#             non_legal_actions = []", "\n", "#     else:", "\n", "#         if self.node_net:", "\n", "#             all_actions = list(range(self.pg_agent_config.defender_node_net_output_dim))", "\n", "#         else:", "\n", "#             all_actions = list(range(self.pg_agent_config.defender_at_net_output_dim))", "\n", "#         non_legal_actions = list(", "\n", "#             filter(lambda action: not env.is_defense_legal(action, node=self.node_net, obs=obs),", "\n", "#                    all_actions))", "\n", "#         if len(non_legal_actions) == len(all_actions):", "\n", "#             non_legal_actions = []", "\n", "", "non_legal_actions", "=", "[", "]", "\n", "distribution", "=", "self", ".", "_get_action_dist_from_latent", "(", "latent_pi", ",", "latent_sde", ",", "device", "=", "self", ".", "device", ",", "\n", "non_legal_actions", "=", "non_legal_actions", ")", "\n", "log_prob", "=", "distribution", ".", "log_prob", "(", "actions", ")", "\n", "values", "=", "self", ".", "value_net", "(", "latent_vf", ")", "\n", "return", "values", ",", "log_prob", ",", "distribution", ".", "entropy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.CnnPolicy.__init__": [[635, 672], ["ppo_policies.PPOPolicy.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "observation_space", ":", "gym", ".", "spaces", ".", "Space", ",", "\n", "action_space", ":", "gym", ".", "spaces", ".", "Space", ",", "\n", "lr_schedule", ":", "Callable", ",", "\n", "net_arch", ":", "Optional", "[", "List", "[", "Union", "[", "int", ",", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "]", "]", "]", "=", "None", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "'auto'", ",", "\n", "activation_fn", ":", "Type", "[", "nn", ".", "Module", "]", "=", "nn", ".", "Tanh", ",", "\n", "ortho_init", ":", "bool", "=", "True", ",", "\n", "use_sde", ":", "bool", "=", "False", ",", "\n", "log_std_init", ":", "float", "=", "0.0", ",", "\n", "full_std", ":", "bool", "=", "True", ",", "\n", "sde_net_arch", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "None", ",", "\n", "use_expln", ":", "bool", "=", "False", ",", "\n", "squash_output", ":", "bool", "=", "False", ",", "\n", "features_extractor_class", ":", "Type", "[", "BaseFeaturesExtractor", "]", "=", "NatureCNN", ",", "\n", "features_extractor_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "normalize_images", ":", "bool", "=", "False", ",", "\n", "optimizer_class", ":", "Type", "[", "th", ".", "optim", ".", "Optimizer", "]", "=", "th", ".", "optim", ".", "Adam", ",", "\n", "optimizer_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ")", ":", "\n", "        ", "super", "(", "CnnPolicy", ",", "self", ")", ".", "__init__", "(", "observation_space", ",", "\n", "action_space", ",", "\n", "lr_schedule", ",", "\n", "net_arch", ",", "\n", "device", ",", "\n", "activation_fn", ",", "\n", "ortho_init", ",", "\n", "use_sde", ",", "\n", "log_std_init", ",", "\n", "full_std", ",", "\n", "sde_net_arch", ",", "\n", "use_expln", ",", "\n", "squash_output", ",", "\n", "features_extractor_class", ",", "\n", "features_extractor_kwargs", ",", "\n", "normalize_images", ",", "\n", "optimizer_class", ",", "\n", "optimizer_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPO.__init__": [[88, 166], ["gym_idsgame.agents.training_agents.openai_baselines.common.base_class.BaseRLModel.__init__", "torch.utils.tensorboard.SummaryWriter", "torch.utils.tensorboard.SummaryWriter", "ppo.PPO.tensorboard_writer.add_hparams", "ppo.PPO._setup_model", "ppo.PPO.pg_agent_config.hparams_dict", "ppo.PPO.defender_pool.append", "ppo.PPO.defender_pool.append", "ppo.PPO.attacker_pool.append", "ppo.PPO.attacker_pool.append", "ppo.PPO.defender_pool.append", "ppo.PPO.defender_pool.append", "ppo.PPO.attacker_pool.append", "gym_idsgame.agents.bot_agents.defend_minimal_value_bot_agent.DefendMinimalValueBotAgent", "gym_idsgame.agents.bot_agents.random_attack_bot_agent.RandomAttackBotAgent", "gym_idsgame.agents.bot_agents.defend_minimal_value_bot_agent.DefendMinimalValueBotAgent", "gym_idsgame.agents.bot_agents.random_defense_bot_agent.RandomDefenseBotAgent", "gym_idsgame.agents.bot_agents.attack_maximal_value_bot_agent.AttackMaximalValueBotAgent", "gym_idsgame.agents.bot_agents.random_attack_bot_agent.RandomAttackBotAgent", "gym_idsgame.agents.bot_agents.random_defense_bot_agent.RandomDefenseBotAgent"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.OffPolicyRLModel._setup_model", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.hparams_dict"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPO._setup_model": [[167, 359], ["ppo.PPO._setup_lr_schedule", "ppo.PPO.set_random_seed", "gym_idsgame.agents.training_agents.openai_baselines.common.utils.get_schedule_fn", "gym_idsgame.agents.training_agents.openai_baselines.common.ppo.ppo_policies.PPOPolicy", "ppo.PPO.defender_policy.to", "gym_idsgame.agents.training_agents.openai_baselines.common.ppo.ppo_policies.PPOPolicy", "ppo.PPO.defender_node_policy.to", "gym_idsgame.agents.training_agents.openai_baselines.common.ppo.ppo_policies.PPOPolicy", "ppo.PPO.defender_node_policy_opponent.to", "gym_idsgame.agents.training_agents.openai_baselines.common.ppo.ppo_policies.PPOPolicy", "ppo.PPO.defender_at_policy.to", "gym_idsgame.agents.training_agents.openai_baselines.common.ppo.ppo_policies.PPOPolicy", "ppo.PPO.defender_at_policy_opponent.to", "gym_idsgame.agents.training_agents.openai_baselines.common.ppo.ppo_policies.PPOPolicy", "ppo.PPO.attacker_policy.to", "gym_idsgame.agents.training_agents.openai_baselines.common.ppo.ppo_policies.PPOPolicy", "ppo.PPO.attacker_node_policy.to", "gym_idsgame.agents.training_agents.openai_baselines.common.ppo.ppo_policies.PPOPolicy", "ppo.PPO.attacker_node_policy_opponent.to", "gym_idsgame.agents.training_agents.openai_baselines.common.ppo.ppo_policies.PPOPolicy", "ppo.PPO.attacker_at_policy.to", "gym_idsgame.agents.training_agents.openai_baselines.common.ppo.ppo_policies.PPOPolicy", "ppo.PPO.attacker_at_policy_opponent.to", "isinstance", "gym_idsgame.agents.training_agents.openai_baselines.common.utils.get_schedule_fn", "ppo.PPO.add_model_to_pool", "ppo.PPO.add_model_to_pool", "ppo.PPO.sample_opponent", "ppo.PPO.sample_opponent", "gym_idsgame.agents.training_agents.openai_baselines.common.buffers.RolloutBuffer", "gym_idsgame.agents.training_agents.openai_baselines.common.buffers.RolloutBuffer", "gym_idsgame.agents.training_agents.openai_baselines.common.buffers.RolloutBufferAR", "gym_idsgame.agents.training_agents.openai_baselines.common.buffers.RolloutBufferAR", "gym_idsgame.agents.training_agents.openai_baselines.common.buffers.RolloutBufferRecurrent", "gym_idsgame.agents.training_agents.openai_baselines.common.buffers.RolloutBufferRecurrent", "gym_idsgame.agents.training_agents.openai_baselines.common.buffers.RolloutBufferRecurrentMultiHead", "gym_idsgame.agents.training_agents.openai_baselines.common.buffers.RolloutBufferRecurrentMultiHead", "gym_idsgame.agents.training_agents.openai_baselines.common.buffers.RolloutBufferARRecurrent", "gym_idsgame.agents.training_agents.openai_baselines.common.buffers.RolloutBufferARRecurrent", "gym_idsgame.agents.training_agents.openai_baselines.common.buffers.RolloutBufferARRecurrentMultiHead", "gym_idsgame.agents.training_agents.openai_baselines.common.buffers.RolloutBufferARRecurrentMultiHead"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._setup_lr_schedule", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.set_random_seed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.get_schedule_fn", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.get_schedule_fn", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.add_model_to_pool", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.add_model_to_pool", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.sample_opponent", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.sample_opponent"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPO.predict": [[361, 440], ["ppo.PPO.attacker_policy._predict", "ppo.PPO.attacker_node_policy._predict", "attacker_node_actions.cpu().numpy.cpu().numpy.cpu().numpy", "observation.reshape", "ppo.PPO.attacker_at_policy._predict", "attacker_at_actions.cpu().numpy.cpu().numpy.cpu().numpy", "gym_idsgame.get_attack_action_id", "numpy.array", "ppo.PPO.defender_policy._predict", "ppo.PPO.defender_node_policy._predict", "defender_node_actions.cpu().numpy.cpu().numpy.cpu().numpy", "observation.reshape", "ppo.PPO.defender_at_policy._predict", "defender_at_actions.cpu().numpy.cpu().numpy.cpu().numpy", "gym_idsgame.get_defense_action_id", "numpy.array", "attacker_node_actions.cpu().numpy.cpu().numpy.cpu", "attacker_at_actions.cpu().numpy.cpu().numpy.cpu", "defender_node_actions.cpu().numpy.cpu().numpy.cpu", "defender_at_actions.cpu().numpy.cpu().numpy.cpu"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy._predict", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy._predict", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy._predict", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.get_attack_action_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy._predict", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy._predict", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy._predict", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.get_defense_action_id"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPO.collect_rollouts": [[441, 875], ["callback.on_rollout_start", "callback.on_rollout_end", "attacker_rollout_buffer.reset", "defender_rollout_buffer.reset", "isinstance", "numpy.array", "env.step", "ppo.PPO._update_info_buffer", "isinstance", "torch.no_grad", "torch.no_grad", "numpy.clip", "numpy.clip", "callback.on_step", "episode_attacker_rewards.append", "episode_defender_rewards.append", "episode_steps.append", "ppo.PPO.attacker_policy.reset_noise", "ppo.PPO.attacker_node_policy.reset_noise", "ppo.PPO.attacker_at_policy.reset_noise", "ppo.PPO.defender_policy.reset_noise", "ppo.PPO.defender_node_policy.reset_noise", "ppo.PPO.defender_at_policy.reset_noise", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "torch.as_tensor().to", "numpy.random.rand", "numpy.array.reshape", "numpy.array.reshape", "attacker_rollout_buffer.compute_returns_and_advantage", "attacker_rollout_buffer.compute_returns_and_advantage", "attacker_rollout_buffer.compute_returns_and_advantage", "defender_rollout_buffer.compute_returns_and_advantage", "defender_rollout_buffer.compute_returns_and_advantage", "defender_rollout_buffer.compute_returns_and_advantage", "ppo.PPO.attacker_policy.reset_noise", "ppo.PPO.attacker_node_policy.reset_noise", "ppo.PPO.attacker_at_policy.reset_noise", "ppo.PPO.defender_policy.reset_noise", "ppo.PPO.defender_node_policy.reset_noise", "ppo.PPO.defender_at_policy.reset_noise", "numpy.array.cpu().numpy", "attacker_node_actions.cpu().numpy.cpu().numpy.cpu().numpy", "torch.as_tensor().to.reshape", "obs_tensor_a_1[].float", "ppo.PPO.attacker_at_policy.forward", "attacker_at_actions.cpu().numpy.cpu().numpy.cpu().numpy", "gym_idsgame.get_attack_action_id", "numpy.array", "isinstance", "ppo.PPO.defender_policy.forward", "numpy.array.cpu().numpy", "ppo.PPO.defender_node_policy.forward", "defender_node_actions.cpu().numpy.cpu().numpy.cpu().numpy", "torch.as_tensor().to.reshape", "obs_tensor_d_1[].float", "ppo.PPO.defender_at_policy.forward", "defender_at_actions.cpu().numpy.cpu().numpy.cpu().numpy", "gym_idsgame.get_defense_action_id", "numpy.array", "isinstance", "defender_rollout_buffer.add", "ppo.PPO.update_quality_score", "ppo.PPO.update_quality_score", "attacker_rollout_buffer.compute_returns_and_advantage", "attacker_rollout_buffer.compute_returns_and_advantage", "attacker_rollout_buffer.compute_returns_and_advantage", "defender_rollout_buffer.compute_returns_and_advantage", "defender_rollout_buffer.compute_returns_and_advantage", "defender_rollout_buffer.compute_returns_and_advantage", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "torch.as_tensor", "ppo.PPO.attacker_policy.forward", "ppo.PPO.attacker_policy.forward", "ppo.PPO.attacker_node_policy.forward", "ppo.PPO.attacker_node_policy.forward", "ppo.PPO.defender_opponent.forward", "numpy.array.cpu().numpy", "numpy.array.cpu().numpy", "attacker_rollout_buffer.add", "attacker_rollout_buffer.add", "defender_rollout_buffer.add", "defender_rollout_buffer.add", "obs_tensor_d_1[].float.cpu", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "numpy.random.rand", "ppo.PPO.sample_opponent", "numpy.random.rand", "ppo.PPO.sample_opponent", "numpy.array.cpu", "attacker_node_actions.cpu().numpy.cpu().numpy.cpu", "attacker_at_actions.cpu().numpy.cpu().numpy.cpu", "isinstance", "isinstance", "ppo.PPO.defender_opponent[].forward", "defender_node_actions.cpu().numpy.cpu().numpy.cpu().numpy", "torch.as_tensor().to.reshape", "obs_tensor_d_1[].float", "ppo.PPO.defender_opponent[].forward", "defender_at_actions.cpu().numpy.cpu().numpy.cpu().numpy", "gym_idsgame.get_defense_action_id", "numpy.array", "ppo.PPO.defender_opponent.action", "numpy.array", "numpy.array.cpu", "defender_node_actions.cpu().numpy.cpu().numpy.cpu", "defender_at_actions.cpu().numpy.cpu().numpy.cpu", "ppo.PPO.attacker_opponent.forward", "ppo.PPO.attacker_opponent.forward", "isinstance", "isinstance", "attacker_node_actions.cpu().numpy.cpu().numpy.cpu().numpy", "torch.as_tensor().to.reshape", "obs_tensor_a_1[].float", "ppo.PPO.attacker_opponent[].forward", "attacker_at_actions.cpu().numpy.cpu().numpy.cpu().numpy", "gym_idsgame.get_attack_action_id", "numpy.array", "ppo.PPO.attacker_opponent.action", "numpy.array", "attacker_rollout_buffer.add", "attacker_rollout_buffer.add", "attacker_rollout_buffer.add", "attacker_rollout_buffer.add", "obs_tensor_a_1[].float.cpu", "attacker_rollout_buffer.add", "attacker_rollout_buffer.add", "defender_rollout_buffer.add", "obs_tensor_d_1[].float.cpu", "defender_rollout_buffer.add", "AssertionError", "numpy.array.cpu", "numpy.array.cpu", "ppo.PPO.attacker_opponent[].forward", "ppo.PPO.attacker_opponent[].forward", "attacker_rollout_buffer.add", "attacker_rollout_buffer.add", "obs_tensor_a_1[].float.cpu", "attacker_rollout_buffer.add", "attacker_rollout_buffer.add", "obs_tensor_a_1[].float.cpu", "obs_tensor_a_1[].float.cpu", "defender_rollout_buffer.add", "AssertionError", "defender_node_actions.cpu().numpy.cpu().numpy.cpu", "defender_at_actions.cpu().numpy.cpu().numpy.cpu", "attacker_node_actions.cpu().numpy.cpu().numpy.cpu", "attacker_at_actions.cpu().numpy.cpu().numpy.cpu", "obs_tensor_a_1[].float.cpu", "obs_tensor_a_1[].float.cpu"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.on_rollout_start", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.on_rollout_end", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._update_info_buffer", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.on_step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.compute_returns_and_advantage", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.compute_returns_and_advantage", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.compute_returns_and_advantage", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.compute_returns_and_advantage", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.compute_returns_and_advantage", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.compute_returns_and_advantage", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.get_attack_action_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.get_defense_action_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.update_quality_score", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.update_quality_score", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.compute_returns_and_advantage", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.compute_returns_and_advantage", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.compute_returns_and_advantage", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.compute_returns_and_advantage", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.compute_returns_and_advantage", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.compute_returns_and_advantage", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.sample_opponent", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.sample_opponent", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.get_defense_action_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.random_defense_bot_agent.RandomDefenseBotAgent.action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.get_attack_action_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.random_defense_bot_agent.RandomDefenseBotAgent.action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPO.train": [[876, 1164], ["ppo.PPO.clip_range", "range", "ppo.PPO.clip_range_vf", "rollout_buffer.get", "all_kl_divs.append", "numpy.mean", "numpy.mean", "numpy.mean", "ppo.PPO._update_learning_rate", "ppo.PPO._update_learning_rate", "ppo.PPO._update_learning_rate", "ppo.PPO._update_learning_rate", "ppo.PPO._update_learning_rate", "ppo.PPO._update_learning_rate", "numpy.mean", "print", "isinstance", "rollout_data.node_actions.long().flatten", "rollout_data.at_actions.long().flatten", "values.flatten.flatten.flatten", "torch.exp", "torch.exp", "pg_losses.append", "torch.mean().item", "torch.mean().item", "clip_fractions.append", "node_values.flatten.flatten.flatten", "at_values.flatten.flatten.flatten", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "pg_losses.append", "torch.mean().item", "torch.mean().item", "clip_fractions.append", "torch.mse_loss", "torch.mse_loss", "value_losses.append", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "torch.mse_loss", "value_losses.append", "entropy_losses.append", "entropy_losses.append", "loss.backward", "approx_kl_divs.append", "node_loss.backward", "at_loss.backward", "approx_kl_divs.append", "numpy.mean", "rollout_data.actions.long().flatten", "torch.clamp", "torch.clamp", "torch.min().mean", "torch.min().mean", "policy_loss.item", "torch.clamp", "torch.clamp", "torch.min().mean", "torch.min().mean", "torch.clamp", "torch.clamp", "torch.min().mean", "torch.min().mean", "torch.mse_loss.item", "entropy_loss.item", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "ppo.PPO.attacker_policy.optimizer.zero_grad", "ppo.PPO.attacker_node_policy.optimizer.zero_grad", "ppo.PPO.attacker_at_policy.optimizer.zero_grad", "ppo.PPO.defender_policy.optimizer.zero_grad", "ppo.PPO.defender_node_policy.optimizer.zero_grad", "ppo.PPO.defender_at_policy.optimizer.zero_grad", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "ppo.PPO.attacker_policy.optimizer.step", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "ppo.PPO.defender_policy.optimizer.step", "torch.mean().detach().cpu().numpy", "torch.mean().detach().cpu().numpy", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "ppo.PPO.attacker_node_policy.optimizer.step", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "ppo.PPO.defender_node_policy.optimizer.step", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "ppo.PPO.attacker_at_policy.optimizer.step", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "ppo.PPO.defender_at_policy.optimizer.step", "torch.mean().detach().cpu().numpy", "torch.mean().detach().cpu().numpy", "rollout_data.node_actions.long", "rollout_data.at_actions.long", "ppo.PPO.attacker_policy.reset_noise", "ppo.PPO.attacker_node_policy.reset_noise", "ppo.PPO.attacker_at_policy.reset_noise", "ppo.PPO.defender_policy.reset_noise", "ppo.PPO.defender_node_policy.reset_noise", "ppo.PPO.defender_at_policy.reset_noise", "ppo.PPO.attacker_policy.evaluate_actions", "ppo.PPO.attacker_node_policy.evaluate_actions", "ppo.PPO.attacker_at_policy.evaluate_actions", "ppo.PPO.defender_policy.evaluate_actions", "ppo.PPO.defender_node_policy.evaluate_actions", "ppo.PPO.defender_at_policy.evaluate_actions", "advantages.mean", "advantages.std", "torch.mean", "torch.mean", "node_advantages.mean", "node_advantages.std", "at_advantages.mean", "at_advantages.std", "node_loss.item", "at_loss.item", "torch.mean", "torch.mean", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.mse_loss.item", "torch.mse_loss.item", "log_prob.mean", "torch.mean", "torch.mean", "entropy_loss_node.item", "entropy_loss_at.item", "ppo.PPO.attacker_policy.parameters", "ppo.PPO.defender_policy.parameters", "ppo.PPO.attacker_node_policy.parameters", "ppo.PPO.defender_node_policy.parameters", "ppo.PPO.attacker_at_policy.parameters", "ppo.PPO.defender_at_policy.parameters", "numpy.mean", "rollout_data.actions.long", "ppo.PPO.attacker_policy.evaluate_actions", "ppo.PPO.attacker_policy.evaluate_actions", "ppo.PPO.attacker_node_policy.evaluate_actions", "ppo.PPO.attacker_at_policy.evaluate_actions", "ppo.PPO.attacker_node_policy.evaluate_actions", "ppo.PPO.attacker_at_policy.evaluate_actions", "ppo.PPO.defender_policy.evaluate_actions", "ppo.PPO.defender_policy.evaluate_actions", "ppo.PPO.defender_node_policy.evaluate_actions", "ppo.PPO.defender_at_policy.evaluate_actions", "ppo.PPO.defender_node_policy.evaluate_actions", "ppo.PPO.defender_at_policy.evaluate_actions", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.mean().detach().cpu", "torch.mean().detach().cpu", "torch.mean().detach().cpu", "torch.mean().detach().cpu", "torch.mean().detach", "torch.mean().detach", "torch.mean().detach", "torch.mean().detach", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.get", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._update_learning_rate", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._update_learning_rate", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._update_learning_rate", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._update_learning_rate", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._update_learning_rate", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._update_learning_rate", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.evaluate_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.evaluate_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.evaluate_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.evaluate_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.evaluate_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.evaluate_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.evaluate_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.evaluate_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.evaluate_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.evaluate_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.evaluate_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.evaluate_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.evaluate_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.evaluate_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.evaluate_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.evaluate_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.evaluate_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.evaluate_actions"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPO.learn": [[1165, 1310], ["ppo.PPO.pg_agent_config.logger.info", "print", "ppo.PPO._setup_learn", "ppo.PPO.on_training_start", "ppo.PPO.pg_agent_config.logger.info", "print", "ppo.PPO.pg_agent_config.logger.info", "ppo.PPO.on_training_end", "locals", "globals", "ppo.PPO.pg_agent_config.to_str", "ppo.PPO.collect_rollouts", "episode_attacker_rewards.extend", "episode_defender_rewards.extend", "episode_steps.extend", "ppo.PPO._update_current_progress", "ppo.PPO.log_metrics", "ppo.PPO.save_model", "ppo.PPO.train", "episode_avg_attacker_loss.append", "ppo.PPO.train", "episode_avg_defender_loss.append", "print", "len", "len", "str", "ppo.PPO.train_result.to_csv", "ppo.PPO.eval_result.to_csv", "print", "ppo.PPO.lr_schedule_a", "ppo.PPO.lr_schedule_d", "time.time", "print", "ppo.PPO.add_model_to_pool", "ppo.PPO.add_model_to_pool"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._setup_learn", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.on_training_start", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.on_training_end", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_str", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.OffPolicyRLModel.collect_rollouts", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._update_current_progress", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_metrics", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.save_model", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.train", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.train", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.add_model_to_pool", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.add_model_to_pool"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPO.get_torch_variables": [[1311, 1327], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPO.save_model": [[1328, 1357], ["str", "time.time", "ppo.PPO.pg_agent_config.logger.warning", "print", "ppo.PPO.pg_agent_config.logger.info", "ppo.PPO.save", "ppo.PPO.pg_agent_config.logger.info", "ppo.PPO.save", "ppo.PPO.pg_agent_config.logger.info", "ppo.PPO.save", "ppo.PPO.pg_agent_config.logger.info", "ppo.PPO.save"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPO.add_model_to_pool": [[1359, 1407], ["copy.deepcopy", "ppo.PPO.attacker_node_policy_opponent.load_state_dict", "ppo.PPO.attacker_at_policy_opponent.load_state_dict", "len", "ppo.PPO.attacker_pool.pop", "ppo.PPO.attacker_pool.append", "copy.deepcopy", "ppo.PPO.defender_node_policy_opponent.load_state_dict", "ppo.PPO.defender_at_policy_opponent.load_state_dict", "len", "ppo.PPO.defender_pool.pop", "ppo.PPO.defender_pool.append", "ppo.PPO.attacker_node_policy.state_dict", "ppo.PPO.attacker_at_policy.state_dict", "copy.deepcopy", "copy.deepcopy", "len", "ppo.PPO.attacker_pool.append", "ppo.PPO.defender_node_policy.state_dict", "ppo.PPO.defender_at_policy.state_dict", "copy.deepcopy", "copy.deepcopy", "len", "ppo.PPO.defender_pool.append", "len", "ppo.PPO.get_attacker_pool_quality_scores", "max", "ppo.PPO.attacker_pool.append", "len", "ppo.PPO.get_defender_pool_quality_scores", "max", "ppo.PPO.defender_pool.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_attacker_pool_quality_scores", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_defender_pool_quality_scores"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPO.sample_opponent": [[1408, 1423], ["ppo.PPO.get_attacker_pool_quality_scores", "ppo.PPO.get_softmax_distribution", "ppo.PPO.get_defender_pool_quality_scores", "ppo.PPO.get_softmax_distribution", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "list", "list", "list", "list", "range", "range", "range", "range", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_attacker_pool_quality_scores", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_softmax_distribution", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_defender_pool_quality_scores", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_softmax_distribution"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPO.get_attacker_pool_quality_scores": [[1424, 1429], ["list", "map"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPO.get_defender_pool_quality_scores": [[1430, 1435], ["list", "map"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPO.get_softmax_distribution": [[1436, 1444], ["scipy.special.softmax"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPO.update_quality_score": [[1445, 1468], ["len", "ppo.PPO.get_attacker_pool_quality_scores", "ppo.PPO.get_softmax_distribution", "len", "ppo.PPO.get_defender_pool_quality_scores", "ppo.PPO.get_softmax_distribution"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_attacker_pool_quality_scores", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_softmax_distribution", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_defender_pool_quality_scores", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_softmax_distribution"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.__init__": [[26, 51], ["gym_idsgame.agents.training_agents.policy_gradient.pg_agent.PolicyGradientAgent.__init__", "torch.utils.tensorboard.SummaryWriter", "ppo.PPOAgent.initialize_models", "ppo.PPOAgent.tensorboard_writer.add_hparams", "numpy.finfo().eps.item", "ppo.PPOAgent.config.hparams_dict", "numpy.finfo"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.initialize_models", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.hparams_dict"], ["pg_agent_config", "=", "PolicyGradientAgentConfig", "(", "gamma", "=", "1", ",", "alpha_attacker", "=", "0.0001", ",", "epsilon", "=", "1", ",", "render", "=", "False", ",", "\n", "alpha_defender", "=", "0.0001", ",", "\n", "eval_sleep", "=", "0.9", ",", "\n", "min_epsilon", "=", "0.01", ",", "eval_episodes", "=", "1000", ",", "train_log_frequency", "=", "1", ",", "\n", "epsilon_decay", "=", "0.9999", ",", "video", "=", "True", ",", "eval_log_frequency", "=", "500", ",", "\n", "video_fps", "=", "5", ",", "video_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/videos\"", ",", "\n", "num_episodes", "=", "100000000", ",", "\n", "eval_render", "=", "False", ",", "gifs", "=", "True", ",", "\n", "gif_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/gifs/\"", "+", "str", "(", "random_seed", ")", ",", "\n", "eval_frequency", "=", "55000", ",", "attacker", "=", "True", ",", "defender", "=", "False", ",", "\n", "video_frequency", "=", "1001", ",", "\n", "save_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/data/\"", "+", "str", "(", "random_seed", ")", ",", "\n", "checkpoint_freq", "=", "250", ",", "\n", "input_dim_attacker", "=", "(", "(", "4", "+", "2", ")", "*", "4", ")", ",", "\n", "output_dim_attacker", "=", "(", "4", "+", "1", ")", "*", "4", ",", "\n", "input_dim_defender", "=", "(", "(", "4", "+", "1", ")", "*", "4", ")", ",", "\n", "output_dim_defender", "=", "5", "*", "4", ",", "\n", "hidden_dim", "=", "128", ",", "num_hidden_layers", "=", "2", ",", "\n", "pi_hidden_layers", "=", "1", ",", "pi_hidden_dim", "=", "128", ",", "vf_hidden_layers", "=", "1", ",", "\n", "vf_hidden_dim", "=", "128", ",", "\n", "batch_size", "=", "2000", ",", "\n", "gpu", "=", "False", ",", "tensorboard", "=", "True", ",", "\n", "tensorboard_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/tensorboard/\"", "+", "str", "(", "random_seed", ")", ",", "\n", "optimizer", "=", "\"Adam\"", ",", "lr_exp_decay", "=", "False", ",", "lr_decay_rate", "=", "0.999", ",", "\n", "state_length", "=", "1", ",", "normalize_features", "=", "False", ",", "merged_ad_features", "=", "True", ",", "\n", "zero_mean_features", "=", "False", ",", "gpu_id", "=", "0", ",", "lstm_network", "=", "False", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.initialize_models": [[52, 121], ["gym_idsgame.agents.training_agents.models.fnn_actor_critic.FFNActorCritic", "gym_idsgame.agents.training_agents.models.fnn_actor_critic.FFNActorCritic", "gym_idsgame.agents.training_agents.models.fnn_actor_critic.FFNActorCritic", "gym_idsgame.agents.training_agents.models.fnn_actor_critic.FFNActorCritic", "ppo.PPOAgent.attacker_policy_network.to", "ppo.PPOAgent.attacker_policy_network_old.to", "ppo.PPOAgent.defender_policy_network.to", "ppo.PPOAgent.defender_policy_network_old.to", "ppo.PPOAgent.attacker_policy_network_old.load_state_dict", "ppo.PPOAgent.defender_policy_network_old.load_state_dict", "ppo.PPOAgent.add_model_to_pool", "ppo.PPOAgent.add_model_to_pool", "torch.cuda.is_available", "torch.device", "ppo.PPOAgent.config.logger.info", "torch.device", "ppo.PPOAgent.config.logger.info", "ppo.PPOAgent.attacker_policy_network.state_dict", "ppo.PPOAgent.defender_policy_network.state_dict", "torch.nn.MSELoss", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.ExponentialLR", "torch.optim.lr_scheduler.ExponentialLR", "torch.nn.SmoothL1Loss", "ValueError", "ppo.PPOAgent.attacker_policy_network.parameters", "ppo.PPOAgent.defender_policy_network.parameters", "torch.optim.SGD", "torch.optim.SGD", "ValueError", "str", "ppo.PPOAgent.attacker_policy_network.parameters", "ppo.PPOAgent.defender_policy_network.parameters"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.add_model_to_pool", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.add_model_to_pool"], ["lstm_seq_length", "=", "4", ",", "num_lstm_layers", "=", "2", ",", "optimization_iterations", "=", "10", ",", "\n", "eps_clip", "=", "0.2", ",", "max_gradient_norm", "=", "0.5", ",", "gae_lambda", "=", "0.95", ",", "\n", "cnn_feature_extractor", "=", "False", ",", "features_dim", "=", "512", ",", "\n", "flatten_feature_planes", "=", "False", ",", "cnn_type", "=", "5", ",", "vf_coef", "=", "0.5", ",", "ent_coef", "=", "0.001", ",", "\n", "render_attacker_view", "=", "True", ",", "lr_progress_power_decay", "=", "4", ",", "\n", "lr_progress_decay", "=", "True", ",", "use_sde", "=", "False", ",", "sde_sample_freq", "=", "4", ",", "\n", "one_hot_obs", "=", "False", ",", "lstm_core", "=", "False", ",", "lstm_hidden_dim", "=", "32", ",", "\n", "multi_channel_obs", "=", "False", ",", "\n", "channel_1_dim", "=", "32", ",", "channel_1_layers", "=", "2", ",", "channel_1_input_dim", "=", "16", ",", "\n", "channel_2_dim", "=", "32", ",", "channel_2_layers", "=", "2", ",", "channel_2_input_dim", "=", "16", ",", "\n", "channel_3_dim", "=", "32", ",", "channel_3_layers", "=", "2", ",", "channel_3_input_dim", "=", "4", ",", "\n", "channel_4_dim", "=", "32", ",", "channel_4_layers", "=", "2", ",", "channel_4_input_dim", "=", "4", ",", "\n", "mini_batch_size", "=", "64", ",", "ar_policy", "=", "True", ",", "\n", "attacker_node_input_dim", "=", "(", "(", "4", "+", "2", ")", "*", "4", ")", ",", "\n", "attacker_at_net_input_dim", "=", "(", "4", "+", "2", ")", ",", "attacker_at_net_output_dim", "=", "(", "4", "+", "1", ")", ",", "\n", "attacker_node_net_output_dim", "=", "4", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v19\"", "\n", "wrapper_env", "=", "BaselineEnvWrapper", "(", "env_name", ",", "idsgame_config", "=", "None", ",", "\n", "save_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/data/\"", "+", "str", "(", "random_seed", ")", ",", "\n", "pg_agent_config", "=", "pg_agent_config", ")", "\n", "attacker_agent", "=", "OpenAiPPOAgent", "(", "wrapper_env", ",", "pg_agent_config", ")", "\n", "\n", "attacker_agent", ".", "train", "(", ")", "\n", "train_result", "=", "attacker_agent", ".", "train_result", "\n", "eval_result", "=", "attacker_agent", ".", "eval_result", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.add_model_to_pool": [[122, 156], ["copy.deepcopy", "copy.deepcopy", "len", "ppo.PPOAgent.attacker_pool.pop", "ppo.PPOAgent.attacker_pool.append", "len", "ppo.PPOAgent.defender_pool.pop", "ppo.PPOAgent.defender_pool.append", "len", "ppo.PPOAgent.attacker_pool.append", "len", "ppo.PPOAgent.defender_pool.append", "len", "ppo.PPOAgent.get_attacker_pool_quality_scores", "max", "ppo.PPOAgent.attacker_pool.append", "len", "ppo.PPOAgent.get_defender_pool_quality_scores", "max", "ppo.PPOAgent.defender_pool.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_attacker_pool_quality_scores", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_defender_pool_quality_scores"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.sample_opponent": [[157, 172], ["ppo.PPOAgent.get_attacker_pool_quality_scores", "ppo.PPOAgent.get_softmax_distribution", "ppo.PPOAgent.get_defender_pool_quality_scores", "ppo.PPOAgent.get_softmax_distribution", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "list", "list", "list", "list", "range", "range", "range", "range", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_attacker_pool_quality_scores", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_softmax_distribution", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_defender_pool_quality_scores", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_softmax_distribution"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_softmax_distribution": [[173, 181], ["scipy.special.softmax"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_attacker_pool_quality_scores": [[182, 187], ["list", "map"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_defender_pool_quality_scores": [[188, 193], ["list", "map"], "methods", ["None"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.training_step": [[194, 279], ["len", "range", "loss.mean", "torch.cuda.is_available", "torch.device", "ppo.PPOAgent.config.logger.info", "torch.device", "enumerate", "len", "torch.tensor().to", "torch.tensor().to.std", "torch.stack().to().detach", "torch.stack().to().detach", "torch.stack().to().detach", "range", "torch.tensor().to.insert", "ppo.PPOAgent.policy_prediction", "torch.exp", "ppo.PPOAgent.attacker_policy_network_old.load_state_dict", "ppo.PPOAgent.defender_policy_network_old.load_state_dict", "str", "torch.tensor", "torch.tensor().to.mean", "torch.stack().to", "torch.stack().to", "torch.stack().to", "state_values.detach", "torch.clamp", "ppo.PPOAgent.attacker_optimizer.zero_grad", "loss.mean().backward", "ppo.PPOAgent.attacker_optimizer.step", "ppo.PPOAgent.defender_optimizer.zero_grad", "loss.mean().backward", "ppo.PPOAgent.defender_optimizer.step", "ppo.PPOAgent.attacker_policy_network.state_dict", "ppo.PPOAgent.defender_policy_network.state_dict", "torch.stack().to().detach.detach", "torch.stack", "torch.stack", "torch.stack", "torch.min", "ppo.PPOAgent.critic_loss_fn", "loss.mean", "loss.mean"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.policy_prediction", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.policy_prediction": [[280, 326], ["torch.distributions.Categorical", "torch.distributions.Categorical.log_prob", "torch.distributions.Categorical.entropy", "torch.cuda.is_available", "torch.device", "states.to.to.to", "ppo.PPOAgent.attacker_policy_network", "ppo.PPOAgent.defender_policy_network", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.log_prob", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.entropy"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_action": [[327, 387], ["torch.from_numpy().float", "action_probs.clone", "torch.distributions.Categorical", "torch.distributions.Categorical.sample", "torch.distributions.Categorical.log_prob", "torch.cuda.is_available", "torch.device", "state.to.to.to", "list", "list", "list", "list", "list", "list", "len", "torch.distributions.Categorical.sample.item", "torch.from_numpy", "range", "filter", "filter", "range", "filter", "filter", "ppo.PPOAgent.attacker_opponent", "ppo.PPOAgent.attacker_policy_network_old", "ppo.PPOAgent.defender_opponent", "ppo.PPOAgent.defender_policy_network_old", "state.to.to.flatten", "str", "ppo.PPOAgent.env.is_attack_legal", "ppo.PPOAgent.env.is_defense_legal", "ppo.PPOAgent.env.is_attack_legal", "ppo.PPOAgent.env.is_defense_legal"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.log_prob", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.train": [[389, 796], ["ppo.PPOAgent.config.logger.info", "ppo.PPOAgent.config.logger.info", "ppo.PPOAgent.env.reset", "ppo.PPOAgent.update_state", "ppo.PPOAgent.update_state", "ppo.PPOAgent.outer_train.set_description_str", "numpy.zeros", "numpy.zeros", "range", "ppo.PPOAgent.config.logger.info", "ppo.PPOAgent.eval", "ppo.PPOAgent.save_model", "ppo.PPOAgent.env.save_trajectories", "ppo.PPOAgent.env.save_attack_data", "ppo.PPOAgent.config.to_str", "len", "ppo.PPOAgent.config.logger.warning", "saved_attacker_log_probs_batch.append", "saved_attacker_rewards_batch.append", "saved_attacker_state_values_batch.append", "saved_attacker_actions_batch.append", "saved_attacker_is_terminals_batch.append", "saved_attacker_states_batch.append", "saved_defender_log_probs_batch.append", "saved_defender_rewards_batch.append", "saved_defender_state_values_batch.append", "saved_defender_actions_batch.append", "saved_defender_is_terminals_batch.append", "saved_defender_states_batch.append", "episode_attacker_rewards.append", "episode_defender_rewards.append", "episode_steps.append", "ppo.PPOAgent.env.reset", "ppo.PPOAgent.update_state", "ppo.PPOAgent.update_state", "ppo.PPOAgent.outer_train.update", "ppo.PPOAgent.anneal_epsilon", "str", "ppo.PPOAgent.train_result.to_csv", "ppo.PPOAgent.eval_result.to_csv", "ppo.PPOAgent.env.step", "saved_attacker_rewards.append", "saved_defender_rewards.append", "saved_attacker_is_terminals.append", "saved_defender_is_terminals.append", "ppo.PPOAgent.update_state", "ppo.PPOAgent.update_state", "ppo.PPOAgent.env.render", "ppo.PPOAgent.attacker_lr_decay.step", "ppo.PPOAgent.defender_lr_decay.step", "ppo.PPOAgent.log_metrics", "ppo.PPOAgent.eval", "ppo.PPOAgent.save_model", "ppo.PPOAgent.env.save_trajectories", "ppo.PPOAgent.env.save_attack_data", "time.time", "numpy.random.rand", "ppo.PPOAgent.sample_opponent", "numpy.random.rand", "ppo.PPOAgent.sample_opponent", "ppo.PPOAgent.env.render", "AssertionError", "saved_attacker_actions.append", "saved_attacker_log_probs.append", "saved_attacker_state_values.append", "saved_attacker_states.append", "saved_defender_actions.append", "saved_defender_log_probs.append", "saved_defender_state_values.append", "saved_attacker_states.append", "ppo.PPOAgent.attacker_policy_network.named_parameters", "ppo.PPOAgent.defender_policy_network.named_parameters", "ppo.PPOAgent.attacker_lr_decay.get_lr", "ppo.PPOAgent.defender_lr_decay.get_lr", "ppo.PPOAgent.update_quality_score", "ppo.PPOAgent.update_quality_score", "len", "len", "ppo.PPOAgent.log_action_dist", "ppo.PPOAgent.log_action_dist", "str", "ppo.PPOAgent.train_result.to_csv", "ppo.PPOAgent.eval_result.to_csv", "ppo.PPOAgent.create_policy_plot", "ppo.PPOAgent.create_policy_plot", "ppo.PPOAgent.get_action", "ppo.PPOAgent.get_action", "torch.tensor", "torch.from_numpy().float", "ppo.PPOAgent.get_action", "ppo.PPOAgent.get_action", "torch.tensor", "torch.from_numpy().float", "ppo.PPOAgent.training_step", "ppo.PPOAgent.item", "ppo.PPOAgent.training_step", "ppo.PPOAgent.item", "tag.replace.replace.replace", "ppo.PPOAgent.tensorboard_writer.add_histogram", "ppo.PPOAgent.tensorboard_writer.add_histogram", "tag.replace.replace.replace", "ppo.PPOAgent.tensorboard_writer.add_histogram", "ppo.PPOAgent.tensorboard_writer.add_histogram", "episode_avg_attacker_loss.append", "episode_avg_defender_loss.append", "episode_avg_attacker_loss.append", "episode_avg_defender_loss.append", "time.time", "numpy.zeros.data.cpu().numpy", "numpy.zeros.data.cpu().numpy", "ppo.PPOAgent.add_model_to_pool", "ppo.PPOAgent.add_model_to_pool", "value.data.cpu().numpy", "value.grad.data.cpu().numpy", "value.data.cpu().numpy", "value.grad.data.cpu().numpy", "numpy.random.rand", "ppo.PPOAgent.sample_opponent", "numpy.random.rand", "ppo.PPOAgent.sample_opponent", "torch.from_numpy", "torch.from_numpy", "numpy.zeros.data.cpu", "numpy.zeros.data.cpu", "ppo.PPOAgent.flatten", "ppo.PPOAgent.flatten", "value.data.cpu", "value.grad.data.cpu", "value.data.cpu", "value.grad.data.cpu"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.eval", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.save_model", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_trajectories", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_attack_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_str", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.anneal_epsilon", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_metrics", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.eval", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.save_model", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_trajectories", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_attack_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.sample_opponent", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.sample_opponent", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.update_quality_score", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.update_quality_score", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_action_dist", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_action_dist", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.create_policy_plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.create_policy_plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.training_step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.training_step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.add_model_to_pool", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.add_model_to_pool", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.sample_opponent", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.sample_opponent"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.create_policy_plot": [[797, 817], ["numpy.random.choice", "gym_idsgame.envs.util.idsgame_util.action_dist_hist", "ppo.PPOAgent.tensorboard_writer.add_image", "list", "range", "len", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.action_dist_hist"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.update_quality_score": [[818, 841], ["len", "ppo.PPOAgent.get_attacker_pool_quality_scores", "ppo.PPOAgent.get_softmax_distribution", "len", "ppo.PPOAgent.get_defender_pool_quality_scores", "ppo.PPOAgent.get_softmax_distribution"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_attacker_pool_quality_scores", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_softmax_distribution", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_defender_pool_quality_scores", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.get_softmax_distribution"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.update_state": [[842, 923], ["ppo.PPOAgent.env.fully_observed", "enumerate", "numpy.array", "numpy.append", "numpy.append", "numpy.append", "enumerate", "enumerate", "numpy.array", "numpy.array", "len", "numpy.append", "numpy.append", "row.tolist", "defender_obs_1.tolist.append", "defender_obs_1.tolist.append", "numpy.array.append", "len", "numpy.array", "numpy.array", "numpy.append", "len", "numpy.append", "numpy.array", "numpy.array", "numpy.linalg.norm", "numpy.isnan().any", "normalized_attacker_features.append", "numpy.linalg.norm", "numpy.isnan().any", "normalized_defender_features.append", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.linalg.norm", "numpy.linalg.norm", "attacker_obs_1.tolist", "defender_obs_1.tolist.append", "defender_obs_1.tolist", "defender_obs_1.tolist.append", "numpy.isnan", "numpy.isnan"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.fully_observed"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.eval": [[924, 1075], ["ppo.PPOAgent.config.logger.info", "str", "print", "tqdm.tqdm", "ppo.PPOAgent.outer_eval.set_description_str", "ppo.PPOAgent.env.reset", "ppo.PPOAgent.update_state", "ppo.PPOAgent.update_state", "range", "ppo.PPOAgent.env.close", "ppo.PPOAgent.config.logger.info", "time.time", "len", "ppo.PPOAgent.config.logger.warning", "gym_idsgame.envs.rendering.video.idsgame_monitor.IdsGameMonitor", "ppo.PPOAgent.config.logger.info", "episode_attacker_rewards.append", "episode_defender_rewards.append", "episode_steps.append", "ppo.PPOAgent.env.reset", "ppo.PPOAgent.update_state", "ppo.PPOAgent.update_state", "ppo.PPOAgent.outer_eval.update", "ppo.PPOAgent.log_metrics", "AssertionError", "ppo.PPOAgent.env.step", "ppo.PPOAgent.update_state", "ppo.PPOAgent.update_state", "ppo.PPOAgent.env.render", "time.sleep", "ppo.PPOAgent.log_metrics", "ppo.PPOAgent.env.generate_gif", "enumerate", "ppo.PPOAgent.env.render", "time.sleep", "ppo.PPOAgent.get_action", "ppo.PPOAgent.get_action", "len", "len", "ppo.PPOAgent.tensorboard_writer.add_image", "float", "float", "float", "float", "float", "float", "float", "float", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_metrics", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_metrics", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.generate_gif", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo.PPOAgent.save_model": [[1076, 1094], ["str", "time.time", "ppo.PPOAgent.config.logger.warning", "ppo.PPOAgent.config.logger.info", "torch.save", "ppo.PPOAgent.config.logger.info", "torch.save", "ppo.PPOAgent.attacker_policy_network.state_dict", "ppo.PPOAgent.defender_policy_network.state_dict"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v9.plot_summary.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v9.plot_summary.default_output_dir": [[15, 21], ["plot_summary.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v9.plot_summary.default_config_path": [[23, 29], ["os.path.join", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "default_config_path", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default path to configuration file\n    \"\"\"", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./config.json'", ")", "\n", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v9.plot_summary.plot_summary": [[31, 96], ["experiments.util.plotting_util.plot_all_averages", "plot_summary.default_output_dir", "maximal_attack_train_csv_paths.append", "maximal_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths.append", "minimal_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths.append", "random_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths.append", "random_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths.append", "two_agents_eval_csv_paths.append", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "plot_summary.default_output_dir", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "plot_summary", "(", "algorithm", ":", "str", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ")", ":", "\n", "    ", "seeds", "=", "[", "0", ",", "999", ",", "299", ",", "399", ",", "499", "]", "\n", "base_dir", "=", "default_output_dir", "(", ")", "\n", "try", ":", "\n", "# V0", "\n", "        ", "maximal_attack_train_csv_paths_v0", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v0", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v0", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v0", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v0", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v0", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v0", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v0", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v0", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v0", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v0", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v0", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v0", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v0", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v0", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "\n", "# V2", "\n", "\n", "", "maximal_attack_train_csv_paths_v2", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v9.plot_summary.plot": [[98, 125], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "pandas.read_csv", "plot_summary.plot_summary", "pandas.read_csv", "plot_summary.plot_summary", "glob.glob", "int", "int", "print", "print", "glob.glob", "int", "int", "print", "print", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "str", "str", "plot_summary.default_output_dir", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v2", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v2", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v2", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v2", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v2", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v2", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v2", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v2", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.run.get_script_path": [[14, 19], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.run.default_output_dir": [[21, 27], ["run.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.run.default_config_path": [[29, 35], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.run.default_config": [[37, 61], ["gym_idsgame.agents.training_agents.q_learning.dqn.dqn_config.DQNConfig", "gym_idsgame.agents.training_agents.q_learning.q_agent_config.QAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.run.write_default_config": [[62, 73], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.run.plot_csv": [[75, 92], ["experiments.util.plotting_util.read_and_plot_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_results"], ["    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "", "def", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "True", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.run.plot_average_results": [[94, 110], ["experiments.util.plotting_util.read_and_plot_average_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_average_results"], ["client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER_AND_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "# Program entrypoint", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "versions", "=", "list", "(", "range", "(", "6", ")", ")", "\n", "for", "version", "in", "versions", ":", "\n", "        ", "print", "(", "\"Test Version: {}\"", ".", "format", "(", "version", ")", ")", "\n", "\n", "print", "(", "\"test_sim_attack_maximal_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", "\n", "print", "(", "\"test_sim_attack_maximal_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_random", "(", "version", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.run.run_experiment": [[111, 151], ["str", "experiments.util.util.create_artefact_dirs", "experiments.util.util.setup_logger", "default_config.q_agent_config.to_csv", "gym_idsgame.runnner.Runner.run", "experiments.util.util.read_config", "run.default_config", "time.time", "train_result.to_csv", "eval_result.to_csv", "run.plot_csv", "os.path.exists", "run.write_default_config", "str", "str", "str", "str", "len", "len", "str", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.create_artefact_dirs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.setup_logger", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.read_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.plot_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.write_default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["print", "(", "\"test_sim_random_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_random_vs_defend_minimal", "(", "version", ")", "\n", "print", "(", "\"test_sim_random_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_random_vs_random", "(", "version", ")", "\n", "print", "(", "\"test_train_maximal_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_minimal_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_tabular_q_learning_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "\n", "\n", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.__init__": [[26, 48], ["gym_idsgame.agents.training_agents.q_learning.q_agent.QAgent.__init__", "torch.utils.tensorboard.SummaryWriter", "gym_idsgame.agents.training_agents.q_learning.experience_replay.replay_buffer.ReplayBuffer", "dqn.DQNAgent.initialize_models", "dqn.DQNAgent.tensorboard_writer.add_hparams", "dqn.DQNAgent.config.hparams_dict"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.initialize_models", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.hparams_dict"], ["util", ".", "create_artefact_dirs", "(", "default_output_dir", "(", ")", ",", "random_seed", ")", "\n", "dqn_config", "=", "DQNConfig", "(", "input_dim", "=", "88", ",", "defender_output_dim", "=", "88", ",", "hidden_dim", "=", "64", ",", "replay_memory_size", "=", "10000", ",", "\n", "num_hidden_layers", "=", "1", ",", "\n", "replay_start_size", "=", "1000", ",", "batch_size", "=", "32", ",", "target_network_update_freq", "=", "1000", ",", "\n", "gpu", "=", "True", ",", "tensorboard", "=", "True", ",", "tensorboard_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/tensorboard/\"", "+", "str", "(", "random_seed", ")", ",", "\n", "loss_fn", "=", "\"Huber\"", ",", "optimizer", "=", "\"Adam\"", ",", "lr_exp_decay", "=", "True", ",", "lr_decay_rate", "=", "0.9999", ")", "\n", "q_agent_config", "=", "QAgentConfig", "(", "gamma", "=", "0.999", ",", "alpha", "=", "0.00001", ",", "epsilon", "=", "1", ",", "render", "=", "False", ",", "eval_sleep", "=", "0.9", ",", "\n", "min_epsilon", "=", "0.01", ",", "eval_episodes", "=", "100", ",", "train_log_frequency", "=", "100", ",", "\n", "epsilon_decay", "=", "0.9999", ",", "video", "=", "True", ",", "eval_log_frequency", "=", "1", ",", "\n", "video_fps", "=", "5", ",", "video_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/videos/\"", "+", "str", "(", "random_seed", ")", ",", "num_episodes", "=", "20001", ",", "\n", "eval_render", "=", "False", ",", "gifs", "=", "True", ",", "gif_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/gifs/\"", "+", "str", "(", "random_seed", ")", ",", "\n", "eval_frequency", "=", "1000", ",", "attacker", "=", "False", ",", "defender", "=", "True", ",", "video_frequency", "=", "101", ",", "\n", "save_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/data/\"", "+", "str", "(", "random_seed", ")", ",", "dqn_config", "=", "dqn_config", ",", "\n", "checkpoint_freq", "=", "5000", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v3\"", "\n", "env", "=", "gym", ".", "make", "(", "env_name", ",", "save_dir", "=", "default_output_dir", "(", ")", "+", "\"/results/data/\"", "+", "str", "(", "random_seed", ")", ")", "\n", "defender_agent", "=", "DQNAgent", "(", "env", ",", "q_agent_config", ")", "\n", "defender_agent", ".", "train", "(", ")", "\n", "train_result", "=", "defender_agent", ".", "train_result", "\n", "eval_result", "=", "defender_agent", ".", "eval_result", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.warmup": [[49, 136], ["tqdm.tqdm", "tqdm.tqdm.set_description_str", "dqn.DQNAgent.env.reset", "dqn.DQNAgent.update_state", "dqn.DQNAgent.update_state", "dqn.DQNAgent.config.logger.info", "range", "dqn.DQNAgent.config.logger.info", "dqn.DQNAgent.env.close", "list", "list", "list", "list", "numpy.random.choice", "numpy.random.choice", "dqn.DQNAgent.env.step", "dqn.DQNAgent.update_state", "dqn.DQNAgent.update_state", "dqn.DQNAgent.buffer.add_tuple", "tqdm.tqdm.update", "dqn.DQNAgent.buffer.sample", "tqdm.tqdm.set_description_str", "dqn.DQNAgent.config.logger.info", "range", "range", "filter", "filter", "dqn.DQNAgent.env.reset", "dqn.DQNAgent.update_state", "dqn.DQNAgent.update_state", "dqn.DQNAgent.buffer.size", "torch.tensor().float", "dqn.DQNAgent.tensorboard_writer.add_graph", "torch.tensor().float", "dqn.DQNAgent.tensorboard_writer.add_graph", "dqn.DQNAgent.config.logger.warning", "dqn.DQNAgent.buffer.size", "torch.cuda.is_available", "torch.device", "s_1.to.to.to", "torch.cuda.is_available", "torch.device", "s_1.to.to.to", "dqn.DQNAgent.env.is_attack_legal", "dqn.DQNAgent.env.is_defense_legal", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.add_tuple", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.size", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.size", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.initialize_models": [[137, 207], ["gym_idsgame.agents.training_agents.models.fnn_w_linear.FNNwithLinear", "gym_idsgame.agents.training_agents.models.fnn_w_linear.FNNwithLinear", "gym_idsgame.agents.training_agents.models.fnn_w_linear.FNNwithLinear", "gym_idsgame.agents.training_agents.models.fnn_w_linear.FNNwithLinear", "dqn.DQNAgent.attacker_q_network.to", "dqn.DQNAgent.attacker_target_network.to", "dqn.DQNAgent.defender_q_network.to", "dqn.DQNAgent.defender_target_network.to", "dqn.DQNAgent.attacker_target_network.load_state_dict", "dqn.DQNAgent.defender_target_network.load_state_dict", "dqn.DQNAgent.attacker_target_network.eval", "dqn.DQNAgent.defender_target_network.eval", "torch.cuda.is_available", "torch.device", "dqn.DQNAgent.config.logger.info", "torch.device", "dqn.DQNAgent.config.logger.info", "dqn.DQNAgent.attacker_q_network.state_dict", "dqn.DQNAgent.defender_q_network.state_dict", "torch.nn.MSELoss", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.lr_scheduler.ExponentialLR", "torch.optim.lr_scheduler.ExponentialLR", "torch.nn.SmoothL1Loss", "ValueError", "dqn.DQNAgent.attacker_q_network.parameters", "dqn.DQNAgent.defender_q_network.parameters", "torch.optim.SGD", "torch.optim.SGD", "ValueError", "dqn.DQNAgent.attacker_q_network.parameters", "dqn.DQNAgent.defender_q_network.parameters"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.eval", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.eval"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.training_step": [[209, 296], ["range", "dqn.DQNAgent.loss_fn", "dqn.DQNAgent.attacker_q_network.train", "dqn.DQNAgent.attacker_target_network.eval", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "dqn.DQNAgent.defender_q_network.train", "dqn.DQNAgent.defender_q_network.eval", "torch.tensor().float", "torch.tensor().float", "torch.tensor().float", "torch.cuda.is_available", "torch.device", "r_1.to.to.to", "s_1.to.to.to", "s_2.to.to.to", "dqn.DQNAgent.attacker_q_network", "dqn.DQNAgent.defender_q_network", "torch.no_grad", "dqn.DQNAgent.attacker_q_network", "dqn.DQNAgent.defender_q_network", "dqn.DQNAgent.attacker_optimizer.zero_grad", "dqn.DQNAgent.backward", "dqn.DQNAgent.attacker_optimizer.step", "dqn.DQNAgent.defender_optimizer.zero_grad", "dqn.DQNAgent.backward", "dqn.DQNAgent.defender_optimizer.step", "dqn.DQNAgent.attacker_target_network().detach", "dqn.DQNAgent.defender_target_network().detach", "torch.argmax().detach", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "dqn.DQNAgent.attacker_target_network", "dqn.DQNAgent.defender_target_network", "torch.argmax"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.train", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.eval", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.train", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.eval", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.get_action": [[297, 331], ["torch.from_numpy().float", "torch.cuda.is_available", "torch.device", "state.to.to.to", "list", "list", "list", "list", "numpy.random.choice", "torch.no_grad", "torch.from_numpy", "range", "filter", "range", "filter", "dqn.DQNAgent.attacker_q_network", "dqn.DQNAgent.defender_q_network", "torch.argmax().item", "state.to.to.flatten", "numpy.random.rand", "numpy.random.random", "dqn.DQNAgent.env.is_attack_legal", "dqn.DQNAgent.env.is_defense_legal", "torch.argmax"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.train": [[332, 537], ["dqn.DQNAgent.config.logger.info", "dqn.DQNAgent.warmup", "dqn.DQNAgent.config.logger.info", "dqn.DQNAgent.config.logger.info", "dqn.DQNAgent.env.reset", "dqn.DQNAgent.update_state", "dqn.DQNAgent.update_state", "dqn.DQNAgent.outer_train.set_description_str", "range", "dqn.DQNAgent.config.logger.info", "dqn.DQNAgent.eval", "dqn.DQNAgent.save_model", "dqn.DQNAgent.env.save_trajectories", "dqn.DQNAgent.env.save_attack_data", "dqn.DQNAgent.config.to_str", "len", "dqn.DQNAgent.config.logger.warning", "episode_attacker_rewards.append", "episode_defender_rewards.append", "episode_steps.append", "dqn.DQNAgent.env.reset", "dqn.DQNAgent.update_state", "dqn.DQNAgent.update_state", "dqn.DQNAgent.outer_train.update", "dqn.DQNAgent.anneal_epsilon", "str", "dqn.DQNAgent.train_result.to_csv", "dqn.DQNAgent.eval_result.to_csv", "dqn.DQNAgent.env.step", "dqn.DQNAgent.update_state", "dqn.DQNAgent.update_state", "dqn.DQNAgent.buffer.add_tuple", "dqn.DQNAgent.buffer.sample", "dqn.DQNAgent.env.render", "dqn.DQNAgent.attacker_lr_decay.step", "dqn.DQNAgent.log_metrics", "dqn.DQNAgent.update_target_network", "dqn.DQNAgent.eval", "dqn.DQNAgent.save_model", "dqn.DQNAgent.env.save_trajectories", "dqn.DQNAgent.env.save_attack_data", "time.time", "dqn.DQNAgent.env.render", "AssertionError", "dqn.DQNAgent.get_action", "dqn.DQNAgent.get_action", "dqn.DQNAgent.training_step", "dqn.DQNAgent.item", "dqn.DQNAgent.training_step", "dqn.DQNAgent.item", "dqn.DQNAgent.attacker_lr_decay.get_lr", "episode_avg_attacker_loss.append", "episode_avg_defender_loss.append", "episode_avg_attacker_loss.append", "episode_avg_defender_loss.append", "dqn.DQNAgent.attacker_q_network.named_parameters", "dqn.DQNAgent.defender_q_network.named_parameters", "str", "dqn.DQNAgent.train_result.to_csv", "dqn.DQNAgent.eval_result.to_csv", "tag.replace.replace.replace", "dqn.DQNAgent.tensorboard_writer.add_histogram", "dqn.DQNAgent.tensorboard_writer.add_histogram", "tag.replace.replace.replace", "dqn.DQNAgent.tensorboard_writer.add_histogram", "dqn.DQNAgent.tensorboard_writer.add_histogram", "time.time", "value.data.cpu().numpy", "value.grad.data.cpu().numpy", "value.data.cpu().numpy", "value.grad.data.cpu().numpy", "value.data.cpu", "value.grad.data.cpu", "value.data.cpu", "value.grad.data.cpu"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.warmup", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.eval", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.save_model", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_trajectories", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_attack_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_str", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.anneal_epsilon", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.add_tuple", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_metrics", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.update_target_network", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.eval", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.save_model", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_trajectories", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_attack_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.training_step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.training_step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.update_target_network": [[538, 554], ["dqn.DQNAgent.config.logger.info", "dqn.DQNAgent.attacker_target_network.load_state_dict", "dqn.DQNAgent.attacker_target_network.eval", "dqn.DQNAgent.defender_target_network.load_state_dict", "dqn.DQNAgent.defender_target_network.eval", "dqn.DQNAgent.attacker_q_network.state_dict", "dqn.DQNAgent.defender_q_network.state_dict"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.eval", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.eval"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.eval": [[555, 708], ["dqn.DQNAgent.config.logger.info", "str", "tqdm.tqdm", "dqn.DQNAgent.outer_eval.set_description_str", "dqn.DQNAgent.env.reset", "dqn.DQNAgent.update_state", "dqn.DQNAgent.update_state", "range", "dqn.DQNAgent.env.close", "dqn.DQNAgent.config.logger.info", "time.time", "len", "dqn.DQNAgent.config.logger.warning", "gym_idsgame.envs.rendering.video.idsgame_monitor.IdsGameMonitor", "dqn.DQNAgent.config.logger.info", "episode_attacker_rewards.append", "episode_defender_rewards.append", "episode_steps.append", "dqn.DQNAgent.env.reset", "dqn.DQNAgent.update_state", "dqn.DQNAgent.update_state", "dqn.DQNAgent.outer_eval.update", "dqn.DQNAgent.log_metrics", "AssertionError", "dqn.DQNAgent.env.step", "dqn.DQNAgent.update_state", "dqn.DQNAgent.update_state", "dqn.DQNAgent.env.render", "time.sleep", "dqn.DQNAgent.log_metrics", "dqn.DQNAgent.env.generate_gif", "enumerate", "dqn.DQNAgent.env.render", "time.sleep", "dqn.DQNAgent.get_action", "dqn.DQNAgent.get_action", "dqn.DQNAgent.tensorboard_writer.add_image", "float", "float", "float", "float", "float", "float", "float", "float", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_metrics", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_metrics", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.generate_gif", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.save_model": [[709, 727], ["str", "time.time", "dqn.DQNAgent.config.logger.warning", "dqn.DQNAgent.config.logger.info", "torch.save", "dqn.DQNAgent.config.logger.info", "torch.save", "dqn.DQNAgent.attacker_q_network.state_dict", "dqn.DQNAgent.defender_q_network.state_dict"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn.DQNAgent.update_state": [[729, 959], ["dqn.DQNAgent.env.local_view_features", "dqn.DQNAgent.env.state.get_attacker_observation", "enumerate", "enumerate", "numpy.array", "numpy.array", "enumerate", "enumerate", "numpy.array", "numpy.array", "dqn.DQNAgent.env.local_view_features", "dqn.DQNAgent.env.fully_observed", "numpy.mean", "numpy.isnan().any", "zero_mean_attacker_features.append", "numpy.mean", "numpy.isnan().any", "zero_mean_defender_features.append", "numpy.isnan().any", "normalized_attacker_features.append", "numpy.isnan().any", "normalized_defender_features.append", "numpy.zeros", "range", "numpy.array", "numpy.append", "numpy.append", "len", "numpy.append", "numpy.append", "dqn.DQNAgent.env.local_view_features", "row.tolist.tolist", "row.tolist.tolist", "row.tolist.append", "dqn.DQNAgent.env.local_view_features", "numpy.linalg.norm", "numpy.linalg.norm", "row.tolist", "numpy.linalg.norm", "numpy.linalg.norm", "int", "enumerate", "enumerate", "numpy.zeros", "range", "len", "numpy.array", "numpy.array", "numpy.append", "len", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.isnan", "row.tolist.append", "row.tolist.append", "row.tolist.append", "numpy.isnan", "numpy.isnan", "row.tolist.append", "row.tolist.append", "row.tolist.append", "numpy.isnan", "row.tolist", "row.tolist.append", "dqn.DQNAgent.env.local_view_features", "row.tolist", "row.tolist.append", "dqn.DQNAgent.env.fully_observed", "numpy.array.append", "numpy.full", "range", "row.tolist", "row.tolist.append", "numpy.array.append", "numpy.append", "dqn.DQNAgent.env.local_view_features", "enumerate", "numpy.array", "numpy.zeros", "range", "numpy.zeros", "range", "dqn.DQNAgent.env.local_view_features", "dqn.DQNAgent.env.local_view_features", "row.tolist.append", "len", "row.tolist.append", "numpy.append", "numpy.array.append", "numpy.array", "numpy.zeros", "range", "numpy.append", "numpy.append", "numpy.sum", "numpy.append", "numpy.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.get_attacker_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.fully_observed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.fully_observed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn_config.DQNConfig.__init__": [[12, 66], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_dim", ":", "int", ",", "attacker_output_dim", ":", "int", "=", "33", ",", "hidden_dim", ":", "int", "=", "64", ",", "replay_memory_size", ":", "int", "=", "100000", ",", "\n", "replay_start_size", ":", "int", "=", "10000", ",", "batch_size", ":", "int", "=", "64", ",", "num_hidden_layers", "=", "2", ",", "\n", "target_network_update_freq", ":", "int", "=", "10", ",", "\n", "gpu", ":", "bool", "=", "False", ",", "tensorboard", ":", "bool", "=", "False", ",", "tensorboard_dir", ":", "str", "=", "\"\"", ",", "\n", "loss_fn", ":", "str", "=", "\"MSE\"", ",", "optimizer", ":", "str", "=", "\"Adam\"", ",", "lr_exp_decay", ":", "bool", "=", "False", ",", "\n", "lr_decay_rate", ":", "float", "=", "0.96", ",", "hidden_activation", ":", "str", "=", "\"ReLU\"", ",", "defender_output_dim", ":", "int", "=", "33", ",", "\n", "state_length", "=", "1", ",", "merged_ad_features", ":", "bool", "=", "False", ",", "normalize_features", ":", "bool", "=", "False", ",", "\n", "zero_mean_features", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Initializes the config\n\n        :param input_dim: input dimension of the DQN networks\n        :param attacker_output_dim: output dimensions of the DQN networks for the attacker\n        :param defender_output_dim: output dimensions of the DQN networks for the defender\n        :param hidden_dim: hidden dimension of the DQN networks\n        :param num_hidden_layers: number of hidden layers\n        :param replay_memory_size: replay memory size\n        :param replay_start_size: start size of the replay memory (populated with warmup)\n        :param batch_size: the batch size during training\n        :param target_network_update_freq: the frequency (in episodes) of updating the target network\n        :param gpu: boolean flag whether using GPU or not\n        :param tensorboard: boolean flag whether using tensorboard logging or not\n        :param tensorboard_dir: tensorboard logdir\n        :param loss_fn: loss function\n        :param optimizer: optimizer\n        :param lr_exp_decay: whether to use exponential decay of learning rate or not\n        :param lr_decay_rate: decay rate of lr\n        :param hidden_activation: the activation function for hidden units\n        :param state_length: length of state (Whether stacking observations or not)\n        :param merged_ad_features: boolean flag inidicating whether defense and attack features should be merged\n        :param normalize_features: boolean flag whether features should be normalized or not\n        :param zero_mean_features: boolean flag whether features should be converted to zero-mean vectors\n        \"\"\"", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "attacker_output_dim", "=", "attacker_output_dim", "\n", "self", ".", "defender_output_dim", "=", "defender_output_dim", "\n", "self", ".", "replay_memory_size", "=", "replay_memory_size", "\n", "self", ".", "replay_start_size", "=", "replay_start_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "target_network_update_freq", "=", "target_network_update_freq", "\n", "self", ".", "gpu", "=", "gpu", "\n", "self", ".", "tensorboard", "=", "tensorboard", "\n", "self", ".", "tensorboard_dir", "=", "tensorboard_dir", "\n", "self", ".", "loss_fn", "=", "loss_fn", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "self", ".", "lr_exp_decay", "=", "lr_exp_decay", "\n", "self", ".", "lr_decay_rate", "=", "lr_decay_rate", "\n", "self", ".", "hidden_activation", "=", "hidden_activation", "\n", "self", ".", "state_length", "=", "state_length", "\n", "self", ".", "merged_ad_features", "=", "merged_ad_features", "\n", "self", ".", "normalize_features", "=", "normalize_features", "\n", "self", ".", "zero_mean_features", "=", "zero_mean_features", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn_config.DQNConfig.to_str": [[67, 83], ["None"], "methods", ["None"], ["", "def", "to_str", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        :return: a string with information about all of the parameters\n        \"\"\"", "\n", "return", "\"DQN Hyperparameters: input_dim:{0},attacker_output_dim:{1},hidden_dim:{2},replay_memory_size:{3},\"", "\"replay_start_size:{4},\"", "\"batch_size:{5},target_network_update_freq:{6},gpu:{7},tensorboard:{8},\"", "\"tensorboard_dir:{9},loss_fn:{10},optimizer:{11},num_hidden_layers:{12},\"", "\"lr_exp_decay:{13},lr_decay_rate:{14},hidden_activation:{15},defender_output_dim:{16},\"", "\"state_length:{17},merged_ad_features:{18},normalize_features:{19},zero_mean_features:{20}\"", ".", "format", "(", "\n", "self", ".", "input_dim", ",", "self", ".", "attacker_output_dim", ",", "self", ".", "hidden_dim", ",", "self", ".", "replay_memory_size", ",", "\n", "self", ".", "replay_start_size", ",", "self", ".", "batch_size", ",", "self", ".", "target_network_update_freq", ",", "\n", "self", ".", "batch_size", ",", "self", ".", "target_network_update_freq", ",", "self", ".", "gpu", ",", "self", ".", "tensorboard", ",", "self", ".", "tensorboard_dir", ",", "\n", "self", ".", "loss_fn", ",", "self", ".", "optimizer", ",", "self", ".", "num_hidden_layers", ",", "self", ".", "lr_exp_decay", ",", "self", ".", "lr_decay_rate", ",", "\n", "self", ".", "hidden_activation", ",", "self", ".", "defender_output_dim", ",", "self", ".", "state_length", ",", "self", ".", "merged_ad_features", ",", "\n", "self", ".", "normalize_features", ",", "self", ".", "zero_mean_features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dqn.dqn_config.DQNConfig.to_csv": [[84, 115], ["open", "csv.writer", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "def", "to_csv", "(", "self", ",", "file_path", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Write parameters to csv file\n\n        :param file_path: path to the file\n        :return: None\n        \"\"\"", "\n", "with", "open", "(", "file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"parameter\"", ",", "\"value\"", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"input_dim\"", ",", "str", "(", "self", ".", "input_dim", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"attacker_output_dim\"", ",", "str", "(", "self", ".", "attacker_output_dim", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"defender_output_dim\"", ",", "str", "(", "self", ".", "defender_output_dim", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hidden_dim\"", ",", "str", "(", "self", ".", "hidden_dim", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"replay_memory_size\"", ",", "str", "(", "self", ".", "replay_memory_size", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"replay_start_size\"", ",", "str", "(", "self", ".", "replay_start_size", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"batch_size\"", ",", "str", "(", "self", ".", "batch_size", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"target_network_update_freq\"", ",", "str", "(", "self", ".", "target_network_update_freq", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"gpu\"", ",", "str", "(", "self", ".", "gpu", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"tensorboard\"", ",", "str", "(", "self", ".", "tensorboard", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"tensorboard_dir\"", ",", "str", "(", "self", ".", "tensorboard_dir", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"loss_fn\"", ",", "str", "(", "self", ".", "loss_fn", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"optimizer\"", ",", "str", "(", "self", ".", "optimizer", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"num_hidden_layers\"", ",", "str", "(", "self", ".", "num_hidden_layers", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"lr_exp_decay\"", ",", "str", "(", "self", ".", "lr_exp_decay", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"lr_decay_rate\"", ",", "str", "(", "self", ".", "lr_decay_rate", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hidden_activation\"", ",", "str", "(", "self", ".", "hidden_activation", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"state_length\"", ",", "str", "(", "self", ".", "state_length", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"merged_ad_features\"", ",", "str", "(", "self", ".", "merged_ad_features", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"normalize_features\"", ",", "str", "(", "self", ".", "normalize_features", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"zero_mean_features\"", ",", "str", "(", "self", ".", "zero_mean_features", ")", "]", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.run.get_script_path": [[13, 18], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["\n", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.run.default_output_dir": [[20, 26], ["run.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.run.default_config_path": [[28, 34], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "test_sim_attack_maximal_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.run.default_config": [[36, 54], ["gym_idsgame.agents.training_agents.q_learning.q_agent_config.QAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.run.write_default_config": [[56, 67], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.run.plot_csv": [[69, 86], ["experiments.util.plotting_util.read_and_plot_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_results"], ["mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.run.plot_average_results": [[88, 103], ["experiments.util.plotting_util.read_and_plot_average_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_average_results"], ["q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "", "def", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER_AND_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "# Program entrypoint", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "versions", "=", "list", "(", "range", "(", "6", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.run.run_experiment": [[104, 142], ["str", "experiments.util.util.create_artefact_dirs", "experiments.util.util.setup_logger", "default_config.q_agent_config.to_csv", "gym_idsgame.runnner.Runner.run", "experiments.util.util.read_config", "run.default_config", "time.time", "train_result.to_csv", "eval_result.to_csv", "run.plot_csv", "os.path.exists", "run.write_default_config", "str", "str", "str", "len", "len", "str", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.create_artefact_dirs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.setup_logger", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.read_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.plot_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.write_default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["for", "version", "in", "versions", ":", "\n", "        ", "print", "(", "\"Test Version: {}\"", ".", "format", "(", "version", ")", ")", "\n", "\n", "print", "(", "\"test_sim_attack_maximal_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", "\n", "print", "(", "\"test_sim_attack_maximal_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_random", "(", "version", ")", "\n", "print", "(", "\"test_sim_random_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_random_vs_defend_minimal", "(", "version", ")", "\n", "print", "(", "\"test_sim_random_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_random_vs_random", "(", "version", ")", "\n", "print", "(", "\"test_train_maximal_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_minimal_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_tabular_q_learning_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "\n", "\n", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.tabular_q_defender_bot_agent.TabularQDefenderBotAgent.__init__": [[15, 26], ["gym_idsgame.agents.bot_agents.bot_agent.BotAgent.__init__", "numpy.load", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load"], ["def", "__init__", "(", "self", ",", "game_config", ":", "GameConfig", ",", "q_table_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Constructor, initializes the policy\n\n        :param game_config: the game configuration\n        \"\"\"", "\n", "super", "(", "BotAgent", ",", "self", ")", ".", "__init__", "(", "game_config", ")", "\n", "if", "q_table_path", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot create a TabularQDefenderBotAgent without specifying the path to the Q-table\"", ")", "\n", "", "self", ".", "q_table_path", "=", "q_table_path", "\n", "self", ".", "Q", "=", "np", ".", "load", "(", "q_table_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.tabular_q_defender_bot_agent.TabularQDefenderBotAgent.action": [[27, 47], ["list", "list", "float", "float", "range", "range", "filter", "len", "AssertionError", "float", "float", "gym_idsgame.is_defense_id_legal"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_defense_id_legal"], ["", "def", "action", "(", "self", ",", "game_state", ":", "GameState", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Samples an action from the policy.\n\n        :param game_state: the game state\n        :return: action_id\n        \"\"\"", "\n", "actions", "=", "list", "(", "range", "(", "self", ".", "game_config", ".", "num_defense_actions", ")", ")", "\n", "legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "util", ".", "is_defense_id_legal", "(", "action", ",", "\n", "self", ".", "game_config", ",", "game_state", ")", ",", "actions", ")", ")", "\n", "s", "=", "0", "\n", "max_legal_action_value", "=", "float", "(", "\"-inf\"", ")", "\n", "max_legal_action", "=", "float", "(", "\"-inf\"", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "Q", "[", "s", "]", ")", ")", ":", "\n", "            ", "if", "i", "in", "legal_actions", "and", "self", ".", "Q", "[", "s", "]", "[", "i", "]", ">", "max_legal_action_value", ":", "\n", "                ", "max_legal_action_value", "=", "self", ".", "Q", "[", "s", "]", "[", "i", "]", "\n", "max_legal_action", "=", "i", "\n", "", "", "if", "max_legal_action", "==", "float", "(", "\"-inf\"", ")", "or", "max_legal_action_value", "==", "float", "(", "\"-inf\"", ")", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Error when selecting action greedily according to the Q-function\"", ")", "\n", "", "return", "max_legal_action", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.tabular_q_agent.TabularQAgent.__init__": [[20, 39], ["gym_idsgame.agents.training_agents.q_learning.q_agent.QAgent.__init__", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "tabular_q_agent.TabularQAgent.env._build_state_to_idx_map", "numpy.array().flatten().max", "numpy.array().flatten", "numpy.array", "list", "map", "tabular_q_agent.TabularQAgent.state_to_idx.keys", "list"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv._build_state_to_idx_map"], ["def", "__init__", "(", "self", ",", "env", ":", "IdsGameEnv", ",", "config", ":", "QAgentConfig", ")", ":", "\n", "        ", "\"\"\"\n        Initialize environment and hyperparameters\n\n        :param config: the configuration\n        \"\"\"", "\n", "super", "(", "TabularQAgent", ",", "self", ")", ".", "__init__", "(", "env", ",", "config", ")", "\n", "if", "not", "self", ".", "config", ".", "tab_full_state_space", ":", "\n", "            ", "self", ".", "Q_attacker", "=", "np", ".", "zeros", "(", "(", "self", ".", "env", ".", "num_states", ",", "self", ".", "env", ".", "num_attack_actions", ")", ")", "\n", "self", ".", "Q_defender", "=", "np", ".", "zeros", "(", "(", "1", ",", "self", ".", "env", ".", "num_defense_actions", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "Q_attacker", "=", "np", ".", "zeros", "(", "(", "self", ".", "env", ".", "num_states_full", ",", "self", ".", "env", ".", "num_attack_actions", ")", ")", "\n", "self", ".", "Q_defender", "=", "np", ".", "zeros", "(", "(", "self", ".", "env", ".", "num_states_full", ",", "self", ".", "env", ".", "num_defense_actions", ")", ")", "\n", "if", "self", ".", "env", ".", "num_states_full", "<", "10000", ":", "\n", "                ", "self", ".", "state_to_idx", "=", "self", ".", "env", ".", "_build_state_to_idx_map", "(", ")", "\n", "self", ".", "max_value", "=", "np", ".", "array", "(", "list", "(", "map", "(", "lambda", "x", ":", "list", "(", "x", ")", ",", "self", ".", "state_to_idx", ".", "keys", "(", ")", ")", ")", ")", ".", "flatten", "(", ")", ".", "max", "(", ")", "\n", "\n", "", "", "self", ".", "env", ".", "idsgame_config", ".", "save_trajectories", "=", "False", "\n", "self", ".", "env", ".", "idsgame_config", ".", "save_attack_stats", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.tabular_q_agent.TabularQAgent.get_action": [[40, 73], ["float", "float", "list", "list", "list", "list", "numpy.random.choice", "range", "range", "AssertionError", "range", "filter", "range", "filter", "len", "len", "float", "float", "numpy.random.rand", "numpy.random.random", "tabular_q_agent.TabularQAgent.env.is_attack_legal", "tabular_q_agent.TabularQAgent.env.is_defense_legal"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal"], ["", "def", "get_action", "(", "self", ",", "s", ",", "eval", "=", "False", ",", "attacker", "=", "True", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Sample an action using an epsilon-greedy policy with respect to the current Q-values\n\n        :param s: the state to sample an action for\n        :param eval: whether sampling an action in eval mode (greedy without exploration)\n        :param attacker: if true, sample action from attacker, else use defender\n        :return: a sampled action\n        \"\"\"", "\n", "if", "attacker", ":", "\n", "            ", "actions", "=", "list", "(", "range", "(", "self", ".", "env", ".", "num_attack_actions", ")", ")", "\n", "legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "self", ".", "env", ".", "is_attack_legal", "(", "action", ")", ",", "actions", ")", ")", "\n", "", "else", ":", "\n", "            ", "actions", "=", "list", "(", "range", "(", "self", ".", "env", ".", "num_defense_actions", ")", ")", "\n", "legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "self", ".", "env", ".", "is_defense_legal", "(", "action", ")", ",", "actions", ")", ")", "\n", "", "if", "(", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "config", ".", "epsilon", "and", "not", "eval", ")", "or", "(", "eval", "and", "np", ".", "random", ".", "random", "(", ")", "<", "self", ".", "config", ".", "eval_epsilon", ")", ":", "\n", "            ", "return", "np", ".", "random", ".", "choice", "(", "legal_actions", ")", "\n", "", "max_legal_action_value", "=", "float", "(", "\"-inf\"", ")", "\n", "max_legal_action", "=", "float", "(", "\"-inf\"", ")", "\n", "if", "attacker", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "Q_attacker", "[", "s", "]", ")", ")", ":", "\n", "                ", "if", "i", "in", "legal_actions", "and", "self", ".", "Q_attacker", "[", "s", "]", "[", "i", "]", ">", "max_legal_action_value", ":", "\n", "                    ", "max_legal_action_value", "=", "self", ".", "Q_attacker", "[", "s", "]", "[", "i", "]", "\n", "max_legal_action", "=", "i", "\n", "", "", "", "else", ":", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "Q_defender", "[", "s", "]", ")", ")", ":", "\n", "                ", "if", "i", "in", "legal_actions", "and", "self", ".", "Q_defender", "[", "s", "]", "[", "i", "]", ">", "max_legal_action_value", ":", "\n", "                    ", "max_legal_action_value", "=", "self", ".", "Q_defender", "[", "s", "]", "[", "i", "]", "\n", "max_legal_action", "=", "i", "\n", "", "", "", "if", "max_legal_action", "==", "float", "(", "\"-inf\"", ")", "or", "max_legal_action_value", "==", "float", "(", "\"-inf\"", ")", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Error when selecting action greedily according to the Q-function\"", ")", "\n", "", "return", "max_legal_action", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.tabular_q_agent.TabularQAgent.train": [[74, 223], ["tabular_q_agent.TabularQAgent.config.logger.info", "tabular_q_agent.TabularQAgent.config.logger.info", "tabular_q_agent.TabularQAgent.env.reset", "tabular_q_agent.TabularQAgent.outer_train.set_description_str", "range", "tabular_q_agent.TabularQAgent.config.logger.info", "tabular_q_agent.TabularQAgent.eval", "tabular_q_agent.TabularQAgent.log_state_values", "tabular_q_agent.TabularQAgent.save_q_table", "tabular_q_agent.TabularQAgent.env.save_trajectories", "tabular_q_agent.TabularQAgent.env.save_attack_data", "tabular_q_agent.TabularQAgent.config.to_str", "len", "tabular_q_agent.TabularQAgent.config.logger.warning", "episode_attacker_rewards.append", "episode_defender_rewards.append", "episode_steps.append", "tabular_q_agent.TabularQAgent.env.reset", "tabular_q_agent.TabularQAgent.outer_train.update", "tabular_q_agent.TabularQAgent.anneal_epsilon", "str", "tabular_q_agent.TabularQAgent.train_result.to_csv", "tabular_q_agent.TabularQAgent.eval_result.to_csv", "tabular_q_agent.TabularQAgent.step_and_update", "tabular_q_agent.TabularQAgent.env.render", "tabular_q_agent.TabularQAgent.log_metrics", "tabular_q_agent.TabularQAgent.eval", "tabular_q_agent.TabularQAgent.save_q_table", "tabular_q_agent.TabularQAgent.env.save_trajectories", "tabular_q_agent.TabularQAgent.env.save_attack_data", "time.time", "tabular_q_agent.TabularQAgent.env.render", "AssertionError", "tabular_q_agent.TabularQAgent.env.get_attacker_node_from_observation", "tabular_q_agent.TabularQAgent.get_action", "tabular_q_agent.TabularQAgent.get_action", "str", "tabular_q_agent.TabularQAgent.train_result.to_csv", "tabular_q_agent.TabularQAgent.eval_result.to_csv", "tabular_q_agent.TabularQAgent.env.fully_observed", "tuple", "tuple", "tabular_q_agent.TabularQAgent.env.fully_observed", "tuple", "tuple", "time.time", "numpy.append", "numpy.append.astype().flatten().tolist", "map", "numpy.append", "numpy.append.astype().flatten().tolist", "map", "numpy.append.astype().flatten", "min", "numpy.append.astype().flatten", "min", "numpy.append.astype", "numpy.append.astype"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.eval", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.tabular_q_agent.TabularQAgent.log_state_values", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.tabular_q_agent.TabularQAgent.save_q_table", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_trajectories", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_attack_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_str", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.anneal_epsilon", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.tabular_q_agent.TabularQAgent.step_and_update", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_metrics", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.eval", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.tabular_q_agent.TabularQAgent.save_q_table", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_trajectories", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_attack_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_attacker_node_from_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.fully_observed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.fully_observed"], ["", "def", "train", "(", "self", ")", "->", "ExperimentResult", ":", "\n", "        ", "\"\"\"\n        Runs the Q(0)-learning algorithm\n\n        :return: Experiment result\n        \"\"\"", "\n", "self", ".", "config", ".", "logger", ".", "info", "(", "\"Starting Training\"", ")", "\n", "self", ".", "config", ".", "logger", ".", "info", "(", "self", ".", "config", ".", "to_str", "(", ")", ")", "\n", "if", "len", "(", "self", ".", "train_result", ".", "avg_episode_steps", ")", ">", "0", ":", "\n", "            ", "self", ".", "config", ".", "logger", ".", "warning", "(", "\"starting training with non-empty result object\"", ")", "\n", "", "done", "=", "False", "\n", "attacker_obs", ",", "defender_obs", "=", "self", ".", "env", ".", "reset", "(", "update_stats", "=", "False", ")", "\n", "\n", "# Tracking metrics", "\n", "episode_attacker_rewards", "=", "[", "]", "\n", "episode_defender_rewards", "=", "[", "]", "\n", "episode_steps", "=", "[", "]", "\n", "\n", "# Logging", "\n", "self", ".", "outer_train", ".", "set_description_str", "(", "\"[Train] epsilon:{:.2f},avg_a_R:{:.2f},avg_d_R:{:.2f},\"", "\n", "\"avg_t:{:.2f},avg_h:{:.2f},acc_A_R:{:.2f},\"", "\"acc_D_R:{:.2f}\"", ".", "format", "(", "self", ".", "config", ".", "epsilon", ",", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ")", ")", "\n", "\n", "# Training", "\n", "for", "episode", "in", "range", "(", "self", ".", "config", ".", "num_episodes", ")", ":", "\n", "            ", "episode_attacker_reward", "=", "0", "\n", "episode_defender_reward", "=", "0", "\n", "episode_step", "=", "0", "\n", "while", "not", "done", ":", "\n", "                ", "if", "self", ".", "config", ".", "render", ":", "\n", "                    ", "self", ".", "env", ".", "render", "(", "mode", "=", "\"human\"", ")", "\n", "\n", "", "if", "not", "self", ".", "config", ".", "attacker", "and", "not", "self", ".", "config", ".", "defender", ":", "\n", "                    ", "raise", "AssertionError", "(", "\"Must specify whether training an attacker agent or defender agent\"", ")", "\n", "\n", "# Default initialization", "\n", "", "s_idx_a", "=", "0", "\n", "defender_state_node_id", "=", "0", "\n", "s_idx_d", "=", "defender_state_node_id", "\n", "attacker_action", "=", "0", "\n", "defender_action", "=", "0", "\n", "\n", "# Get attacker and defender actions", "\n", "if", "self", ".", "config", ".", "attacker", ":", "\n", "                    ", "s_idx_a", "=", "self", ".", "env", ".", "get_attacker_node_from_observation", "(", "attacker_obs", ")", "\n", "if", "self", ".", "config", ".", "tab_full_state_space", ":", "\n", "                        ", "if", "self", ".", "env", ".", "fully_observed", "(", ")", ":", "\n", "                            ", "attacker_obs", "=", "np", ".", "append", "(", "attacker_obs", ",", "defender_obs", ")", "\n", "", "t", "=", "tuple", "(", "attacker_obs", ".", "astype", "(", "int", ")", ".", "flatten", "(", ")", ".", "tolist", "(", ")", ")", "\n", "t", "=", "tuple", "(", "map", "(", "lambda", "x", ":", "min", "(", "x", ",", "self", ".", "max_value", ")", ",", "t", ")", ")", "\n", "s_idx_a", "=", "self", ".", "state_to_idx", "[", "t", "]", "\n", "", "attacker_action", "=", "self", ".", "get_action", "(", "s_idx_a", ",", "attacker", "=", "True", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "defender", ":", "\n", "                    ", "s_idx_d", "=", "defender_state_node_id", "\n", "if", "self", ".", "config", ".", "tab_full_state_space", ":", "\n", "                        ", "if", "self", ".", "env", ".", "fully_observed", "(", ")", ":", "\n", "                            ", "defender_obs", "=", "np", ".", "append", "(", "attacker_obs", ",", "defender_obs", ")", "\n", "", "t", "=", "tuple", "(", "defender_obs", ".", "astype", "(", "int", ")", ".", "flatten", "(", ")", ".", "tolist", "(", ")", ")", "\n", "t", "=", "tuple", "(", "map", "(", "lambda", "x", ":", "min", "(", "x", ",", "self", ".", "max_value", ")", ",", "t", ")", ")", "\n", "s_idx_d", "=", "self", ".", "state_to_idx", "[", "t", "]", "\n", "", "defender_action", "=", "self", ".", "get_action", "(", "s_idx_d", ",", "attacker", "=", "False", ")", "\n", "\n", "", "action", "=", "(", "attacker_action", ",", "defender_action", ")", "\n", "\n", "# Take a step in the environment", "\n", "reward", ",", "obs_prime", ",", "done", "=", "self", ".", "step_and_update", "(", "action", ",", "s_idx_a", ",", "s_idx_d", ")", "\n", "\n", "# Update state information and metrics", "\n", "attacker_reward", ",", "defender_reward", "=", "reward", "\n", "obs_prime_attacker", ",", "obs_prime_defender", "=", "obs_prime", "\n", "episode_attacker_reward", "+=", "attacker_reward", "\n", "episode_defender_reward", "+=", "defender_reward", "\n", "episode_step", "+=", "1", "\n", "attacker_obs", "=", "obs_prime_attacker", "\n", "defender_obs", "=", "obs_prime_defender", "\n", "\n", "# Render final frame", "\n", "", "if", "self", ".", "config", ".", "render", ":", "\n", "                ", "self", ".", "env", ".", "render", "(", "mode", "=", "\"human\"", ")", "\n", "\n", "# Record episode metrics", "\n", "", "self", ".", "num_train_games", "+=", "1", "\n", "self", ".", "num_train_games_total", "+=", "1", "\n", "if", "self", ".", "env", ".", "state", ".", "hacked", ":", "\n", "                ", "self", ".", "num_train_hacks", "+=", "1", "\n", "self", ".", "num_train_hacks_total", "+=", "1", "\n", "", "episode_attacker_rewards", ".", "append", "(", "episode_attacker_reward", ")", "\n", "episode_defender_rewards", ".", "append", "(", "episode_defender_reward", ")", "\n", "episode_steps", ".", "append", "(", "episode_step", ")", "\n", "\n", "# Log average metrics every <self.config.train_log_frequency> episodes", "\n", "if", "episode", "%", "self", ".", "config", ".", "train_log_frequency", "==", "0", ":", "\n", "                ", "if", "self", ".", "num_train_games", ">", "0", "and", "self", ".", "num_train_games_total", ">", "0", ":", "\n", "                    ", "self", ".", "train_hack_probability", "=", "self", ".", "num_train_hacks", "/", "self", ".", "num_train_games", "\n", "self", ".", "train_cumulative_hack_probability", "=", "self", ".", "num_train_hacks_total", "/", "self", ".", "num_train_games_total", "\n", "", "else", ":", "\n", "                    ", "self", ".", "train_hack_probability", "=", "0.0", "\n", "self", ".", "train_cumulative_hack_probability", "=", "0.0", "\n", "", "self", ".", "log_metrics", "(", "episode", ",", "self", ".", "train_result", ",", "episode_attacker_rewards", ",", "episode_defender_rewards", ",", "\n", "episode_steps", ",", "None", ",", "None", ",", "lr", "=", "self", ".", "config", ".", "alpha", ")", "\n", "episode_attacker_rewards", "=", "[", "]", "\n", "episode_defender_rewards", "=", "[", "]", "\n", "episode_steps", "=", "[", "]", "\n", "self", ".", "num_train_games", "=", "0", "\n", "self", ".", "num_train_hacks", "=", "0", "\n", "\n", "# Run evaluation every <self.config.eval_frequency> episodes", "\n", "", "if", "episode", "%", "self", ".", "config", ".", "eval_frequency", "==", "0", ":", "\n", "                ", "self", ".", "eval", "(", "episode", ")", "\n", "\n", "# Save Q table every <self.config.checkpoint_frequency> episodes", "\n", "", "if", "episode", "%", "self", ".", "config", ".", "checkpoint_freq", "==", "0", ":", "\n", "                ", "self", ".", "save_q_table", "(", ")", "\n", "self", ".", "env", ".", "save_trajectories", "(", "checkpoint", "=", "True", ")", "\n", "self", ".", "env", ".", "save_attack_data", "(", "checkpoint", "=", "True", ")", "\n", "if", "self", ".", "config", ".", "save_dir", "is", "not", "None", ":", "\n", "                    ", "time_str", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "self", ".", "train_result", ".", "to_csv", "(", "self", ".", "config", ".", "save_dir", "+", "\"/\"", "+", "time_str", "+", "\"_train_results_checkpoint.csv\"", ")", "\n", "self", ".", "eval_result", ".", "to_csv", "(", "self", ".", "config", ".", "save_dir", "+", "\"/\"", "+", "time_str", "+", "\"_eval_results_checkpoint.csv\"", ")", "\n", "\n", "# Reset environment for the next episode and update game stats", "\n", "", "", "done", "=", "False", "\n", "attacker_obs", ",", "defender_obs", "=", "self", ".", "env", ".", "reset", "(", "update_stats", "=", "True", ")", "\n", "self", ".", "outer_train", ".", "update", "(", "1", ")", "\n", "\n", "# Anneal epsilon linearly", "\n", "self", ".", "anneal_epsilon", "(", ")", "\n", "\n", "", "self", ".", "config", ".", "logger", ".", "info", "(", "\"Training Complete\"", ")", "\n", "\n", "# Final evaluation (for saving Gifs etc)", "\n", "self", ".", "eval", "(", "self", ".", "config", ".", "num_episodes", ",", "log", "=", "False", ")", "\n", "\n", "# Log and return", "\n", "self", ".", "log_state_values", "(", ")", "\n", "\n", "# Save Q Table", "\n", "self", ".", "save_q_table", "(", ")", "\n", "\n", "# Save other game data", "\n", "self", ".", "env", ".", "save_trajectories", "(", "checkpoint", "=", "False", ")", "\n", "self", ".", "env", ".", "save_attack_data", "(", "checkpoint", "=", "False", ")", "\n", "if", "self", ".", "config", ".", "save_dir", "is", "not", "None", ":", "\n", "            ", "time_str", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "self", ".", "train_result", ".", "to_csv", "(", "self", ".", "config", ".", "save_dir", "+", "\"/\"", "+", "time_str", "+", "\"_train_results_checkpoint.csv\"", ")", "\n", "self", ".", "eval_result", ".", "to_csv", "(", "self", ".", "config", ".", "save_dir", "+", "\"/\"", "+", "time_str", "+", "\"_eval_results_checkpoint.csv\"", ")", "\n", "\n", "", "return", "self", ".", "train_result", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.tabular_q_agent.TabularQAgent.step_and_update": [[224, 253], ["tabular_q_agent.TabularQAgent.env.step", "tabular_q_agent.TabularQAgent.env.get_attacker_node_from_observation", "tabular_q_agent.TabularQAgent.q_learning_update", "tabular_q_agent.TabularQAgent.q_learning_update", "tabular_q_agent.TabularQAgent.env.fully_observed", "tuple", "tuple", "tabular_q_agent.TabularQAgent.env.fully_observed", "tuple", "tuple", "numpy.append", "numpy.append.astype().flatten().tolist", "map", "numpy.append", "numpy.append.astype().flatten().tolist", "map", "numpy.append.astype().flatten", "min", "numpy.append.astype().flatten", "min", "numpy.append.astype", "numpy.append.astype"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_attacker_node_from_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.tabular_q_agent.TabularQAgent.q_learning_update", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.tabular_q_agent.TabularQAgent.q_learning_update", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.fully_observed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.fully_observed"], ["", "def", "step_and_update", "(", "self", ",", "action", ",", "s_idx_a", ",", "defender_state_node_id", ")", "->", "Union", "[", "float", ",", "np", ".", "ndarray", ",", "bool", "]", ":", "\n", "        ", "obs_prime", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "attacker_reward", ",", "defender_reward", "=", "reward", "\n", "attacker_obs_prime", ",", "defender_obs_prime", "=", "obs_prime", "\n", "attacker_action", ",", "defender_action", "=", "action", "\n", "\n", "if", "self", ".", "config", ".", "attacker", ":", "\n", "            ", "s_prime_idx", "=", "self", ".", "env", ".", "get_attacker_node_from_observation", "(", "attacker_obs_prime", ")", "\n", "if", "self", ".", "config", ".", "tab_full_state_space", ":", "\n", "                ", "if", "self", ".", "env", ".", "fully_observed", "(", ")", ":", "\n", "                    ", "attacker_obs_prime", "=", "np", ".", "append", "(", "attacker_obs_prime", ",", "defender_obs_prime", ")", "\n", "", "t", "=", "tuple", "(", "attacker_obs_prime", ".", "astype", "(", "int", ")", ".", "flatten", "(", ")", ".", "tolist", "(", ")", ")", "\n", "t", "=", "tuple", "(", "map", "(", "lambda", "x", ":", "min", "(", "x", ",", "self", ".", "max_value", ")", ",", "t", ")", ")", "\n", "s_prime_idx", "=", "self", ".", "state_to_idx", "[", "t", "]", "\n", "", "self", ".", "q_learning_update", "(", "s_idx_a", ",", "attacker_action", ",", "attacker_reward", ",", "s_prime_idx", ",", "\n", "attacker", "=", "True", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "defender", ":", "\n", "            ", "s_prime_idx", "=", "0", "\n", "if", "self", ".", "config", ".", "tab_full_state_space", ":", "\n", "                ", "if", "self", ".", "env", ".", "fully_observed", "(", ")", ":", "\n", "                    ", "defender_obs_prime", "=", "np", ".", "append", "(", "attacker_obs_prime", ",", "defender_obs_prime", ")", "\n", "", "t", "=", "tuple", "(", "defender_obs_prime", ".", "astype", "(", "int", ")", ".", "flatten", "(", ")", ".", "tolist", "(", ")", ")", "\n", "t", "=", "tuple", "(", "map", "(", "lambda", "x", ":", "min", "(", "x", ",", "self", ".", "max_value", ")", ",", "t", ")", ")", "\n", "s_prime_idx", "=", "self", ".", "state_to_idx", "[", "t", "]", "\n", "", "self", ".", "q_learning_update", "(", "defender_state_node_id", ",", "defender_action", ",", "defender_reward", ",", "s_prime_idx", ",", "\n", "attacker", "=", "False", ")", "\n", "\n", "", "return", "reward", ",", "obs_prime", ",", "done", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.tabular_q_agent.TabularQAgent.q_learning_update": [[254, 272], ["numpy.max", "numpy.max"], "methods", ["None"], ["", "def", "q_learning_update", "(", "self", ",", "s", ":", "int", ",", "a", ":", "int", ",", "r", ":", "float", ",", "s_prime", ":", "int", ",", "attacker", "=", "True", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Performs a q_learning update\n\n        :param s: the state id\n        :param a: the action id\n        :param r: the reward\n        :param s_prime: the result state id\n        :param attacker: boolean flag, if True update attacker Q, otherwise update defender Q\n        :return: None\n        \"\"\"", "\n", "if", "attacker", ":", "\n", "            ", "self", ".", "Q_attacker", "[", "s", "]", "[", "a", "]", "=", "self", ".", "Q_attacker", "[", "s", "]", "[", "a", "]", "+", "self", ".", "config", ".", "alpha", "*", "(", "\n", "r", "+", "self", ".", "config", ".", "gamma", "*", "np", ".", "max", "(", "self", ".", "Q_attacker", "[", "s_prime", "]", ")", "-", "self", ".", "Q_attacker", "[", "s", "]", "[", "a", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "Q_defender", "[", "s", "]", "[", "a", "]", "=", "self", ".", "Q_defender", "[", "s", "]", "[", "a", "]", "+", "self", ".", "config", ".", "alpha", "*", "(", "\n", "r", "+", "self", ".", "config", ".", "gamma", "*", "np", ".", "max", "(", "self", ".", "Q_defender", "[", "s_prime", "]", ")", "\n", "-", "self", ".", "Q_defender", "[", "s", "]", "[", "a", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.tabular_q_agent.TabularQAgent.eval": [[273, 478], ["tabular_q_agent.TabularQAgent.config.logger.info", "str", "tqdm.tqdm", "tabular_q_agent.TabularQAgent.outer_eval.set_description_str", "tabular_q_agent.TabularQAgent.env.reset", "range", "tabular_q_agent.TabularQAgent.env.close", "tabular_q_agent.TabularQAgent.config.logger.info", "time.time", "len", "tabular_q_agent.TabularQAgent.config.logger.warning", "gym_idsgame.envs.rendering.video.idsgame_monitor.IdsGameMonitor", "tabular_q_agent.TabularQAgent.env.episode_frames.append", "tabular_q_agent.TabularQAgent.config.logger.info", "episode_attacker_rewards.append", "episode_defender_rewards.append", "episode_steps.append", "tabular_q_agent.TabularQAgent.env.reset", "tabular_q_agent.TabularQAgent.outer_eval.update", "tabular_q_agent.TabularQAgent.log_metrics", "AssertionError", "tabular_q_agent.TabularQAgent.env.render", "tabular_q_agent.TabularQAgent.env.get_attacker_node_from_observation", "attacker_state_values.append", "attacker_states.append", "attacker_frames.append", "defender_state_values.append", "defender_states.append", "defender_frames.append", "tabular_q_agent.TabularQAgent.env.step", "tabular_q_agent.TabularQAgent.env.render", "time.sleep", "tabular_q_agent.TabularQAgent.log_metrics", "tabular_q_agent.TabularQAgent.env.generate_gif", "len", "numpy.save", "numpy.save", "numpy.save", "len", "numpy.save", "numpy.save", "numpy.save", "tabular_q_agent.TabularQAgent.env.episode_frames.append", "sum", "sum", "tabular_q_agent.TabularQAgent.env.render", "time.sleep", "tabular_q_agent.TabularQAgent.env.get_attacker_node_from_observation", "tabular_q_agent.TabularQAgent.get_action", "tabular_q_agent.TabularQAgent.get_action", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "numpy.array", "numpy.array", "numpy.array", "tabular_q_agent.TabularQAgent.env.render", "float", "float", "float", "float", "tabular_q_agent.TabularQAgent.env.fully_observed", "tuple", "tuple", "tabular_q_agent.TabularQAgent.env.fully_observed", "tuple", "tuple", "len", "tabular_q_agent.TabularQAgent.env.get_attacker_node_from_observation", "attacker_state_values.append", "attacker_states.append", "attacker_frames.append", "defender_state_values.append", "defender_states.append", "defender_frames.append", "float", "float", "float", "float", "str", "str", "numpy.append", "numpy.append.astype().flatten().tolist", "map", "numpy.append", "numpy.append.astype().flatten().tolist", "map", "sum", "sum", "numpy.append.astype().flatten", "min", "numpy.append.astype().flatten", "min", "str", "numpy.append.astype", "numpy.append.astype"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_metrics", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_attacker_node_from_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_metrics", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.generate_gif", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_attacker_node_from_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.fully_observed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.fully_observed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_attacker_node_from_observation"], ["", "", "def", "eval", "(", "self", ",", "train_episode", ",", "log", "=", "True", ")", "->", "ExperimentResult", ":", "\n", "        ", "\"\"\"\n        Performs evaluation with the greedy policy with respect to the learned Q-values\n\n        :param log: whether to log the result\n        :param train_episode: train episode to keep track of logs and plots\n        :return: None\n        \"\"\"", "\n", "self", ".", "config", ".", "logger", ".", "info", "(", "\"Starting Evaluation\"", ")", "\n", "time_str", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "\n", "self", ".", "num_eval_games", "=", "0", "\n", "self", ".", "num_eval_hacks", "=", "0", "\n", "\n", "if", "len", "(", "self", ".", "eval_result", ".", "avg_episode_steps", ")", ">", "0", ":", "\n", "            ", "self", ".", "config", ".", "logger", ".", "warning", "(", "\"starting eval with non-empty result object\"", ")", "\n", "", "if", "self", ".", "config", ".", "eval_episodes", "<", "1", ":", "\n", "            ", "return", "\n", "", "done", "=", "False", "\n", "\n", "# Video config", "\n", "if", "self", ".", "config", ".", "video", ":", "\n", "            ", "if", "self", ".", "config", ".", "video_dir", "is", "None", ":", "\n", "                ", "raise", "AssertionError", "(", "\"Video is set to True but no video_dir is provided, please specify \"", "\n", "\"the video_dir argument\"", ")", "\n", "", "self", ".", "env", "=", "IdsGameMonitor", "(", "self", ".", "env", ",", "self", ".", "config", ".", "video_dir", "+", "\"/\"", "+", "time_str", ",", "force", "=", "True", ",", "\n", "video_frequency", "=", "self", ".", "config", ".", "video_frequency", ")", "\n", "self", ".", "env", ".", "metadata", "[", "\"video.frames_per_second\"", "]", "=", "self", ".", "config", ".", "video_fps", "\n", "\n", "# Tracking metrics", "\n", "", "episode_attacker_rewards", "=", "[", "]", "\n", "episode_defender_rewards", "=", "[", "]", "\n", "episode_steps", "=", "[", "]", "\n", "\n", "# Logging", "\n", "self", ".", "outer_eval", "=", "tqdm", ".", "tqdm", "(", "total", "=", "self", ".", "config", ".", "eval_episodes", ",", "desc", "=", "'Eval Episode'", ",", "position", "=", "1", ")", "\n", "self", ".", "outer_eval", ".", "set_description_str", "(", "\n", "\"[Eval] avg_a_R:{:.2f},avg_d_R:{:.2f},avg_t:{:.2f},avg_h:{:.2f},acc_A_R:{:.2f},\"", "\"acc_D_R:{:.2f}\"", ".", "format", "(", "0.0", ",", "0", ",", "0", ",", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ")", ")", "\n", "\n", "# Eval", "\n", "attacker_obs", ",", "defender_obs", "=", "self", ".", "env", ".", "reset", "(", "update_stats", "=", "False", ")", "\n", "\n", "# Get initial frame", "\n", "if", "self", ".", "config", ".", "video", "or", "self", ".", "config", ".", "gifs", ":", "\n", "            ", "initial_frame", "=", "self", ".", "env", ".", "render", "(", "mode", "=", "\"rgb_array\"", ")", "[", "0", "]", "\n", "self", ".", "env", ".", "episode_frames", ".", "append", "(", "initial_frame", ")", "\n", "\n", "", "for", "episode", "in", "range", "(", "self", ".", "config", ".", "eval_episodes", ")", ":", "\n", "            ", "episode_attacker_reward", "=", "0", "\n", "episode_defender_reward", "=", "0", "\n", "episode_step", "=", "0", "\n", "attacker_state_values", "=", "[", "]", "\n", "attacker_states", "=", "[", "]", "\n", "attacker_frames", "=", "[", "]", "\n", "defender_state_values", "=", "[", "]", "\n", "defender_states", "=", "[", "]", "\n", "defender_frames", "=", "[", "]", "\n", "\n", "if", "self", ".", "config", ".", "video", "or", "self", ".", "config", ".", "gifs", ":", "\n", "                ", "attacker_state_node_id", "=", "self", ".", "env", ".", "get_attacker_node_from_observation", "(", "attacker_obs", ")", "\n", "attacker_state_values", ".", "append", "(", "sum", "(", "self", ".", "Q_attacker", "[", "attacker_state_node_id", "]", ")", ")", "\n", "attacker_states", ".", "append", "(", "attacker_state_node_id", ")", "\n", "attacker_frames", ".", "append", "(", "initial_frame", ")", "\n", "defender_state_node_id", "=", "0", "\n", "defender_state_values", ".", "append", "(", "sum", "(", "self", ".", "Q_defender", "[", "defender_state_node_id", "]", ")", ")", "\n", "defender_states", ".", "append", "(", "defender_state_node_id", ")", "\n", "defender_frames", ".", "append", "(", "initial_frame", ")", "\n", "\n", "", "while", "not", "done", ":", "\n", "                ", "if", "self", ".", "config", ".", "eval_render", ":", "\n", "                    ", "self", ".", "env", ".", "render", "(", ")", "\n", "time", ".", "sleep", "(", "self", ".", "config", ".", "eval_sleep", ")", "\n", "\n", "# Default initialization", "\n", "", "attacker_state_node_id", "=", "0", "\n", "defender_state_node_id", "=", "0", "\n", "attacker_action", "=", "0", "\n", "defender_action", "=", "0", "\n", "\n", "# Get attacker and defender actions", "\n", "if", "self", ".", "config", ".", "attacker", ":", "\n", "                    ", "s_idx_a", "=", "self", ".", "env", ".", "get_attacker_node_from_observation", "(", "attacker_obs", ")", "\n", "if", "self", ".", "config", ".", "tab_full_state_space", ":", "\n", "                        ", "if", "self", ".", "env", ".", "fully_observed", "(", ")", ":", "\n", "                            ", "attacker_obs", "=", "np", ".", "append", "(", "attacker_obs", ",", "defender_obs", ")", "\n", "", "t", "=", "tuple", "(", "attacker_obs", ".", "astype", "(", "int", ")", ".", "flatten", "(", ")", ".", "tolist", "(", ")", ")", "\n", "t", "=", "tuple", "(", "map", "(", "lambda", "x", ":", "min", "(", "x", ",", "self", ".", "max_value", ")", ",", "t", ")", ")", "\n", "s_idx_a", "=", "self", ".", "state_to_idx", "[", "t", "]", "\n", "", "attacker_action", "=", "self", ".", "get_action", "(", "s_idx_a", ",", "attacker", "=", "True", ",", "eval", "=", "True", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "defender", ":", "\n", "                    ", "s_idx_d", "=", "defender_state_node_id", "\n", "if", "self", ".", "config", ".", "tab_full_state_space", ":", "\n", "                        ", "if", "self", ".", "env", ".", "fully_observed", "(", ")", ":", "\n", "                            ", "defender_obs", "=", "np", ".", "append", "(", "attacker_obs", ",", "defender_obs", ")", "\n", "", "t", "=", "tuple", "(", "defender_obs", ".", "astype", "(", "int", ")", ".", "flatten", "(", ")", ".", "tolist", "(", ")", ")", "\n", "t", "=", "tuple", "(", "map", "(", "lambda", "x", ":", "min", "(", "x", ",", "self", ".", "max_value", ")", ",", "t", ")", ")", "\n", "s_idx_d", "=", "self", ".", "state_to_idx", "[", "t", "]", "\n", "", "defender_action", "=", "self", ".", "get_action", "(", "s_idx_d", ",", "attacker", "=", "False", ",", "eval", "=", "True", ")", "\n", "\n", "", "action", "=", "(", "attacker_action", ",", "defender_action", ")", "\n", "\n", "# Take a step in the environment", "\n", "obs_prime", ",", "reward", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "\n", "# Update state information and metrics", "\n", "attacker_reward", ",", "defender_reward", "=", "reward", "\n", "obs_prime_attacker", ",", "obs_prime_defender", "=", "obs_prime", "\n", "episode_attacker_reward", "+=", "attacker_reward", "\n", "episode_defender_reward", "+=", "defender_reward", "\n", "episode_step", "+=", "1", "\n", "attacker_obs", "=", "obs_prime_attacker", "\n", "defender_obs", "=", "obs_prime_defender", "\n", "\n", "# Save state values for analysis later", "\n", "if", "self", ".", "config", ".", "video", "and", "len", "(", "self", ".", "env", ".", "episode_frames", ")", ">", "1", ":", "\n", "                    ", "if", "self", ".", "config", ".", "attacker", ":", "\n", "                        ", "attacker_state_node_id", "=", "self", ".", "env", ".", "get_attacker_node_from_observation", "(", "attacker_obs", ")", "\n", "attacker_state_values", ".", "append", "(", "sum", "(", "self", ".", "Q_attacker", "[", "attacker_state_node_id", "]", ")", ")", "\n", "attacker_states", ".", "append", "(", "attacker_state_node_id", ")", "\n", "attacker_frames", ".", "append", "(", "self", ".", "env", ".", "episode_frames", "[", "-", "1", "]", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "defender", ":", "\n", "                        ", "defender_state_node_id", "=", "0", "\n", "defender_state_values", ".", "append", "(", "sum", "(", "self", ".", "Q_defender", "[", "defender_state_node_id", "]", ")", ")", "\n", "defender_states", ".", "append", "(", "defender_state_node_id", ")", "\n", "defender_frames", ".", "append", "(", "self", ".", "env", ".", "episode_frames", "[", "-", "1", "]", ")", "\n", "\n", "# Render final frame when game completed", "\n", "", "", "", "if", "self", ".", "config", ".", "eval_render", ":", "\n", "                ", "self", ".", "env", ".", "render", "(", ")", "\n", "time", ".", "sleep", "(", "self", ".", "config", ".", "eval_sleep", ")", "\n", "", "self", ".", "config", ".", "logger", ".", "info", "(", "\"Eval episode: {}, Game ended after {} steps\"", ".", "format", "(", "episode", ",", "episode_step", ")", ")", "\n", "\n", "# Record episode metrics", "\n", "episode_attacker_rewards", ".", "append", "(", "episode_attacker_reward", ")", "\n", "episode_defender_rewards", ".", "append", "(", "episode_defender_reward", ")", "\n", "episode_steps", ".", "append", "(", "episode_step", ")", "\n", "\n", "# Update eval stats", "\n", "self", ".", "num_eval_games", "+=", "1", "\n", "self", ".", "num_eval_games_total", "+=", "1", "\n", "self", ".", "eval_attacker_cumulative_reward", "+=", "episode_attacker_reward", "\n", "self", ".", "eval_defender_cumulative_reward", "+=", "episode_defender_reward", "\n", "if", "self", ".", "env", ".", "state", ".", "hacked", ":", "\n", "                ", "self", ".", "num_eval_hacks", "+=", "1", "\n", "self", ".", "num_eval_hacks_total", "+=", "1", "\n", "\n", "# Log average metrics every <self.config.eval_log_frequency> episodes", "\n", "", "if", "episode", "%", "self", ".", "config", ".", "eval_log_frequency", "==", "0", "and", "log", ":", "\n", "                ", "if", "self", ".", "num_eval_games", ">", "0", ":", "\n", "                    ", "self", ".", "eval_hack_probability", "=", "float", "(", "self", ".", "num_eval_hacks", ")", "/", "float", "(", "self", ".", "num_eval_games", ")", "\n", "", "if", "self", ".", "num_eval_games_total", ">", "0", ":", "\n", "                    ", "self", ".", "eval_cumulative_hack_probability", "=", "float", "(", "self", ".", "num_eval_hacks_total", ")", "/", "float", "(", "\n", "self", ".", "num_eval_games_total", ")", "\n", "", "self", ".", "log_metrics", "(", "episode", ",", "self", ".", "eval_result", ",", "episode_attacker_rewards", ",", "episode_defender_rewards", ",", "\n", "episode_steps", ",", "update_stats", "=", "False", ",", "eval", "=", "True", ")", "\n", "\n", "# Save gifs", "\n", "", "if", "self", ".", "config", ".", "gifs", "and", "self", ".", "config", ".", "video", ":", "\n", "                ", "self", ".", "env", ".", "generate_gif", "(", "self", ".", "config", ".", "gif_dir", "+", "\"/episode_\"", "+", "str", "(", "train_episode", ")", "+", "\"_\"", "\n", "+", "time_str", "+", "\".gif\"", ",", "self", ".", "config", ".", "video_fps", ")", "\n", "\n", "", "if", "len", "(", "attacker_frames", ")", ">", "1", ":", "\n", "# Save state values analysis for final state", "\n", "                ", "base_path", "=", "self", ".", "config", ".", "save_dir", "+", "\"/state_values/\"", "+", "str", "(", "train_episode", ")", "+", "\"/\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "base_path", ")", ":", "\n", "                    ", "os", ".", "makedirs", "(", "base_path", ")", "\n", "", "np", ".", "save", "(", "base_path", "+", "\"attacker_states.npy\"", ",", "attacker_states", ")", "\n", "np", ".", "save", "(", "base_path", "+", "\"attacker_state_values.npy\"", ",", "attacker_state_values", ")", "\n", "np", ".", "save", "(", "base_path", "+", "\"attacker_frames.npy\"", ",", "attacker_frames", ")", "\n", "\n", "\n", "", "if", "len", "(", "defender_frames", ")", ">", "1", ":", "\n", "# Save state values analysis for final state", "\n", "                ", "base_path", "=", "self", ".", "config", ".", "save_dir", "+", "\"/state_values/\"", "+", "str", "(", "train_episode", ")", "+", "\"/\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "base_path", ")", ":", "\n", "                    ", "os", ".", "makedirs", "(", "base_path", ")", "\n", "", "np", ".", "save", "(", "base_path", "+", "\"defender_states.npy\"", ",", "np", ".", "array", "(", "defender_states", ")", ")", "\n", "np", ".", "save", "(", "base_path", "+", "\"defender_state_values.npy\"", ",", "np", ".", "array", "(", "defender_state_values", ")", ")", "\n", "np", ".", "save", "(", "base_path", "+", "\"defender_frames.npy\"", ",", "np", ".", "array", "(", "defender_frames", ")", ")", "\n", "\n", "# Reset for new eval episode", "\n", "", "done", "=", "False", "\n", "attacker_obs", ",", "defender_obs", "=", "self", ".", "env", ".", "reset", "(", "update_stats", "=", "False", ")", "\n", "# Get initial frame", "\n", "if", "self", ".", "config", ".", "video", "or", "self", ".", "config", ".", "gifs", ":", "\n", "                ", "initial_frame", "=", "self", ".", "env", ".", "render", "(", "mode", "=", "\"rgb_array\"", ")", "[", "0", "]", "\n", "self", ".", "env", ".", "episode_frames", ".", "append", "(", "initial_frame", ")", "\n", "\n", "", "self", ".", "outer_eval", ".", "update", "(", "1", ")", "\n", "\n", "# Log average eval statistics", "\n", "", "if", "log", ":", "\n", "            ", "if", "self", ".", "num_eval_games", ">", "0", ":", "\n", "                ", "self", ".", "eval_hack_probability", "=", "float", "(", "self", ".", "num_eval_hacks", ")", "/", "float", "(", "self", ".", "num_eval_games", ")", "\n", "", "if", "self", ".", "num_eval_games_total", ">", "0", ":", "\n", "                ", "self", ".", "eval_cumulative_hack_probability", "=", "float", "(", "self", ".", "num_eval_hacks_total", ")", "/", "float", "(", "self", ".", "num_eval_games_total", ")", "\n", "", "self", ".", "log_metrics", "(", "train_episode", ",", "self", ".", "eval_result", ",", "episode_attacker_rewards", ",", "episode_defender_rewards", ",", "\n", "episode_steps", ",", "update_stats", "=", "True", ",", "eval", "=", "True", ")", "\n", "\n", "", "self", ".", "env", ".", "close", "(", ")", "\n", "self", ".", "config", ".", "logger", ".", "info", "(", "\"Evaluation Complete\"", ")", "\n", "return", "self", ".", "eval_result", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.tabular_q_agent.TabularQAgent.log_state_values": [[479, 500], ["tabular_q_agent.TabularQAgent.config.logger.info", "range", "tabular_q_agent.TabularQAgent.config.logger.info", "tabular_q_agent.TabularQAgent.config.logger.info", "range", "tabular_q_agent.TabularQAgent.config.logger.info", "len", "sum", "tabular_q_agent.TabularQAgent.config.logger.info", "len", "sum", "tabular_q_agent.TabularQAgent.config.logger.info"], "methods", ["None"], ["", "def", "log_state_values", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Utility function for printing the state-values according to the learned Q-function\n\n        :return: None\n        \"\"\"", "\n", "if", "self", ".", "config", ".", "attacker", ":", "\n", "            ", "self", ".", "config", ".", "logger", ".", "info", "(", "\"--- Attacker State Values ---\"", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "Q_attacker", ")", ")", ":", "\n", "                ", "state_value", "=", "sum", "(", "self", ".", "Q_attacker", "[", "i", "]", ")", "\n", "node_id", "=", "i", "\n", "self", ".", "config", ".", "logger", ".", "info", "(", "\"s:{},V(s):{}\"", ".", "format", "(", "node_id", ",", "state_value", ")", ")", "\n", "", "self", ".", "config", ".", "logger", ".", "info", "(", "\"--------------------\"", ")", "\n", "\n", "", "if", "self", ".", "config", ".", "defender", ":", "\n", "            ", "self", ".", "config", ".", "logger", ".", "info", "(", "\"--- Defender State Values ---\"", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "Q_defender", ")", ")", ":", "\n", "                ", "state_value", "=", "sum", "(", "self", ".", "Q_defender", "[", "i", "]", ")", "\n", "node_id", "=", "i", "\n", "self", ".", "config", ".", "logger", ".", "info", "(", "\"s:{},V(s):{}\"", ".", "format", "(", "node_id", ",", "state_value", ")", ")", "\n", "", "self", ".", "config", ".", "logger", ".", "info", "(", "\"--------------------\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.tabular_q_agent.TabularQAgent.save_q_table": [[501, 519], ["str", "time.time", "tabular_q_agent.TabularQAgent.config.logger.warning", "tabular_q_agent.TabularQAgent.config.logger.info", "numpy.save", "tabular_q_agent.TabularQAgent.config.logger.info", "numpy.save"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save"], ["", "", "def", "save_q_table", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Saves Q table to disk in binary npy format\n\n        :return: None\n        \"\"\"", "\n", "time_str", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "if", "self", ".", "config", ".", "save_dir", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "config", ".", "attacker", ":", "\n", "                ", "path", "=", "self", ".", "config", ".", "save_dir", "+", "\"/\"", "+", "time_str", "+", "\"_attacker_q_table.npy\"", "\n", "self", ".", "config", ".", "logger", ".", "info", "(", "\"Saving Q-table to: {}\"", ".", "format", "(", "path", ")", ")", "\n", "np", ".", "save", "(", "path", ",", "self", ".", "Q_attacker", ")", "\n", "", "if", "self", ".", "config", ".", "defender", ":", "\n", "                ", "path", "=", "self", ".", "config", ".", "save_dir", "+", "\"/\"", "+", "time_str", "+", "\"_defender_q_table.npy\"", "\n", "self", ".", "config", ".", "logger", ".", "info", "(", "\"Saving Q-table to: {}\"", ".", "format", "(", "path", ")", ")", "\n", "np", ".", "save", "(", "path", ",", "self", ".", "Q_defender", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "config", ".", "logger", ".", "warning", "(", "\"Save path not defined, not saving Q table to disk\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.tabular_q_attacker_bot_agent.TabularQAttackerBotAgent.__init__": [[15, 26], ["gym_idsgame.agents.bot_agents.bot_agent.BotAgent.__init__", "numpy.load", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load"], ["def", "__init__", "(", "self", ",", "game_config", ":", "GameConfig", ",", "q_table_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Constructor, initializes the policy\n\n        :param game_config: the game configuration\n        \"\"\"", "\n", "super", "(", "TabularQAttackerBotAgent", ",", "self", ")", ".", "__init__", "(", "game_config", ")", "\n", "if", "q_table_path", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot create a TabularQAttackerBotAgent without specifying the path to the Q-table\"", ")", "\n", "", "self", ".", "q_table_path", "=", "q_table_path", "\n", "self", ".", "Q", "=", "np", ".", "load", "(", "q_table_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tabular_q_learning.tabular_q_attacker_bot_agent.TabularQAttackerBotAgent.action": [[27, 47], ["list", "list", "tabular_q_attacker_bot_agent.TabularQAttackerBotAgent.game_config.network_config.get_node_id", "float", "float", "range", "range", "filter", "len", "AssertionError", "float", "float", "gym_idsgame.is_attack_id_legal"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_attack_id_legal"], ["", "def", "action", "(", "self", ",", "game_state", ":", "GameState", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Samples an action from the policy.\n\n        :param game_state: the game state\n        :return: action_id\n        \"\"\"", "\n", "actions", "=", "list", "(", "range", "(", "self", ".", "game_config", ".", "num_attack_actions", ")", ")", "\n", "legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "util", ".", "is_attack_id_legal", "(", "\n", "action", ",", "self", ".", "game_config", ",", "game_state", ".", "attacker_pos", ",", "game_state", ")", ",", "actions", ")", ")", "\n", "s", "=", "self", ".", "game_config", ".", "network_config", ".", "get_node_id", "(", "game_state", ".", "attacker_pos", ")", "\n", "max_legal_action_value", "=", "float", "(", "\"-inf\"", ")", "\n", "max_legal_action", "=", "float", "(", "\"-inf\"", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "Q", "[", "s", "]", ")", ")", ":", "\n", "            ", "if", "i", "in", "legal_actions", "and", "self", ".", "Q", "[", "s", "]", "[", "i", "]", ">", "max_legal_action_value", ":", "\n", "                ", "max_legal_action_value", "=", "self", ".", "Q", "[", "s", "]", "[", "i", "]", "\n", "max_legal_action", "=", "i", "\n", "", "", "if", "max_legal_action", "==", "float", "(", "\"-inf\"", ")", "or", "max_legal_action_value", "==", "float", "(", "\"-inf\"", ")", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Error when selecting action greedily according to the Q-function\"", ")", "\n", "", "return", "max_legal_action", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo_openai.run.get_script_path": [[14, 19], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo_openai.run.default_output_dir": [[21, 27], ["run.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo_openai.run.default_config_path": [[29, 35], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo_openai.run.hp_tuning_config": [[36, 49], ["gym_idsgame.config.hp_tuning_config.HpTuningConfig"], "function", ["None"], ["\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo_openai.run.default_config": [[50, 102], ["gym_idsgame.agents.training_agents.policy_gradient.pg_agent_config.PolicyGradientAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "", "def", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER_AND_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "# Program entrypoint", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo_openai.run.write_default_config": [[103, 114], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["    ", "versions", "=", "list", "(", "range", "(", "6", ")", ")", "\n", "for", "version", "in", "versions", ":", "\n", "        ", "print", "(", "\"Test Version: {}\"", ".", "format", "(", "version", ")", ")", "\n", "\n", "print", "(", "\"test_sim_attack_maximal_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", "\n", "print", "(", "\"test_sim_attack_maximal_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_random", "(", "version", ")", "\n", "print", "(", "\"test_sim_random_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_random_vs_defend_minimal", "(", "version", ")", "\n", "print", "(", "\"test_sim_random_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_random_vs_random", "(", "version", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo_openai.run.plot_csv": [[116, 130], ["experiments.util.plotting_util.read_and_plot_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_results"], ["test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_minimal_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_tabular_q_learning_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "\n", "\n", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo_openai.run.plot_average_results": [[132, 148], ["experiments.util.plotting_util.read_and_plot_average_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_average_results"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo_openai.run.run_experiment": [[149, 192], ["str", "experiments.util.util.create_artefact_dirs", "experiments.util.util.setup_logger", "default_config.pg_agent_config.to_csv", "experiments.util.util.read_config", "run.default_config", "time.time", "experiments.util.hp_tuning.hype_grid", "gym_idsgame.runnner.Runner.run", "os.path.exists", "run.write_default_config", "str", "str", "str", "str", "train_result.to_csv", "eval_result.to_csv", "run.plot_csv", "str", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "len", "len", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.create_artefact_dirs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.setup_logger", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.read_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.hp_tuning.hype_grid", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.write_default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.plot_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v15.plot_summary.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v15.plot_summary.default_output_dir": [[15, 21], ["plot_summary.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v15.plot_summary.default_config_path": [[23, 29], ["os.path.join", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "default_config_path", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default path to configuration file\n    \"\"\"", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./config.json'", ")", "\n", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v15.plot_summary.plot_summary": [[31, 96], ["experiments.util.plotting_util.plot_all_averages", "plot_summary.default_output_dir", "maximal_attack_train_csv_paths.append", "maximal_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths.append", "minimal_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths.append", "random_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths.append", "random_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths.append", "two_agents_eval_csv_paths.append", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "plot_summary.default_output_dir", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "plot_summary", "(", "algorithm", ":", "str", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ")", ":", "\n", "    ", "seeds", "=", "[", "0", ",", "999", ",", "299", ",", "399", ",", "499", "]", "\n", "base_dir", "=", "default_output_dir", "(", ")", "\n", "try", ":", "\n", "# V0", "\n", "        ", "maximal_attack_train_csv_paths_v0", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v0", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v0", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v0", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v0", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v0", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v0", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v0", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v0", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v0", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v0", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v0", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v0", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v0", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v0", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "\n", "# V2", "\n", "\n", "", "maximal_attack_train_csv_paths_v2", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v15.plot_summary.plot": [[98, 125], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "pandas.read_csv", "plot_summary.plot_summary", "pandas.read_csv", "plot_summary.plot_summary", "glob.glob", "int", "int", "print", "print", "glob.glob", "int", "int", "print", "print", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "str", "str", "plot_summary.default_output_dir", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v2", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v2", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v2", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v2", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v2", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v2", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v2", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v2", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v10.plot_summary.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v10.plot_summary.default_output_dir": [[15, 21], ["plot_summary.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v10.plot_summary.default_config_path": [[23, 29], ["os.path.join", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "default_config_path", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default path to configuration file\n    \"\"\"", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./config.json'", ")", "\n", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v10.plot_summary.plot_summary": [[31, 96], ["experiments.util.plotting_util.plot_all_averages", "plot_summary.default_output_dir", "maximal_attack_train_csv_paths.append", "maximal_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths.append", "minimal_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths.append", "random_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths.append", "random_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths.append", "two_agents_eval_csv_paths.append", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "plot_summary.default_output_dir", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "plot_summary", "(", "algorithm", ":", "str", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ")", ":", "\n", "    ", "seeds", "=", "[", "0", ",", "999", ",", "299", ",", "399", ",", "499", "]", "\n", "base_dir", "=", "default_output_dir", "(", ")", "\n", "try", ":", "\n", "# V0", "\n", "        ", "maximal_attack_train_csv_paths_v0", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v0", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v0", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v0", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v0", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v0", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v0", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v0", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v0", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v0", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v0", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v0", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v0", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v0", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v0", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "\n", "# V2", "\n", "\n", "", "maximal_attack_train_csv_paths_v2", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v10.plot_summary.plot": [[98, 125], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "pandas.read_csv", "plot_summary.plot_summary", "pandas.read_csv", "plot_summary.plot_summary", "glob.glob", "int", "int", "print", "print", "glob.glob", "int", "int", "print", "print", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "str", "str", "plot_summary.default_output_dir", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v2", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v2", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v2", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v2", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v2", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v2", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v2", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v2", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v17.plot_summary.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v17.plot_summary.default_output_dir": [[15, 21], ["plot_summary.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v17.plot_summary.default_config_path": [[23, 29], ["os.path.join", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "default_config_path", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default path to configuration file\n    \"\"\"", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./config.json'", ")", "\n", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v17.plot_summary.plot_summary": [[31, 96], ["experiments.util.plotting_util.plot_all_averages", "plot_summary.default_output_dir", "maximal_attack_train_csv_paths.append", "maximal_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths.append", "minimal_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths.append", "random_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths.append", "random_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths.append", "two_agents_eval_csv_paths.append", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "plot_summary.default_output_dir", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "plot_summary", "(", "algorithm", ":", "str", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ")", ":", "\n", "    ", "seeds", "=", "[", "0", ",", "999", ",", "299", ",", "399", ",", "499", "]", "\n", "base_dir", "=", "default_output_dir", "(", ")", "\n", "try", ":", "\n", "# V0", "\n", "        ", "maximal_attack_train_csv_paths_v0", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v0", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v0", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v0", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v0", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v0", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v0", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v0", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v0", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v0", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v0", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v0", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v0", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v0", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v0", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "\n", "# V2", "\n", "\n", "", "maximal_attack_train_csv_paths_v2", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v17.plot_summary.plot": [[98, 125], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "pandas.read_csv", "plot_summary.plot_summary", "pandas.read_csv", "plot_summary.plot_summary", "glob.glob", "int", "int", "print", "print", "glob.glob", "int", "int", "print", "print", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "str", "str", "plot_summary.default_output_dir", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v2", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v2", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v2", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v2", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v2", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v2", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v2", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v2", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_2.run.get_script_path": [[14, 19], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_2.run.default_output_dir": [[21, 27], ["run.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_2.run.default_config_path": [[29, 35], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_2.run.hp_tuning_config": [[36, 49], ["gym_idsgame.config.hp_tuning_config.HpTuningConfig"], "function", ["None"], ["\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_2.run.default_config": [[50, 86], ["gym_idsgame.agents.training_agents.policy_gradient.pg_agent_config.PolicyGradientAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "run.hp_tuning_config", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.hp_tuning_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_2.run.write_default_config": [[87, 98], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "", "def", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER_AND_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_2.run.plot_csv": [[100, 114], ["experiments.util.plotting_util.read_and_plot_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_results"], ["\n", "# Program entrypoint", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "versions", "=", "list", "(", "range", "(", "6", ")", ")", "\n", "for", "version", "in", "versions", ":", "\n", "        ", "print", "(", "\"Test Version: {}\"", ".", "format", "(", "version", ")", ")", "\n", "\n", "print", "(", "\"test_sim_attack_maximal_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", "\n", "print", "(", "\"test_sim_attack_maximal_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_random", "(", "version", ")", "\n", "print", "(", "\"test_sim_random_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_random_vs_defend_minimal", "(", "version", ")", "\n", "print", "(", "\"test_sim_random_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_random_vs_random", "(", "version", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_2.run.plot_average_results": [[116, 132], ["experiments.util.plotting_util.read_and_plot_average_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_average_results"], ["test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_minimal_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_tabular_q_learning_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "\n", "\n", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_2.run.run_experiment": [[133, 176], ["str", "experiments.util.util.create_artefact_dirs", "experiments.util.util.setup_logger", "default_config.pg_agent_config.to_csv", "experiments.util.util.read_config", "run.default_config", "time.time", "experiments.util.hp_tuning.hype_grid", "gym_idsgame.runnner.Runner.run", "os.path.exists", "run.write_default_config", "str", "str", "str", "str", "train_result.to_csv", "eval_result.to_csv", "run.plot_csv", "str", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "len", "len", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.create_artefact_dirs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.setup_logger", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.read_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.hp_tuning.hype_grid", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.write_default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.plot_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo_2.run.get_script_path": [[15, 20], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo_2.run.default_output_dir": [[22, 28], ["run.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo_2.run.default_config_path": [[30, 36], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo_2.run.hp_tuning_config": [[37, 50], ["gym_idsgame.config.hp_tuning_config.HpTuningConfig"], "function", ["None"], ["", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo_2.run.default_config": [[51, 121], ["gym_idsgame.agents.training_agents.common.opponent_pool_config.OpponentPoolConfig", "gym_idsgame.agents.training_agents.policy_gradient.pg_agent_config.PolicyGradientAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "", "def", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER_AND_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "# Program entrypoint", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "versions", "=", "list", "(", "range", "(", "6", ")", ")", "\n", "for", "version", "in", "versions", ":", "\n", "        ", "print", "(", "\"Test Version: {}\"", ".", "format", "(", "version", ")", ")", "\n", "\n", "print", "(", "\"test_sim_attack_maximal_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", "\n", "print", "(", "\"test_sim_attack_maximal_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_random", "(", "version", ")", "\n", "print", "(", "\"test_sim_random_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_random_vs_defend_minimal", "(", "version", ")", "\n", "print", "(", "\"test_sim_random_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_random_vs_random", "(", "version", ")", "\n", "print", "(", "\"test_train_maximal_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_minimal_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo_2.run.write_default_config": [[122, 133], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["test_train_random_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_tabular_q_learning_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "\n", "\n", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo_2.run.plot_csv": [[135, 149], ["experiments.util.plotting_util.read_and_plot_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_results"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo_2.run.plot_average_results": [[151, 167], ["experiments.util.plotting_util.read_and_plot_average_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_average_results"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo_2.run.run_experiment": [[168, 211], ["str", "experiments.util.util.create_artefact_dirs", "experiments.util.util.setup_logger", "default_config.pg_agent_config.to_csv", "experiments.util.util.read_config", "run.default_config", "time.time", "experiments.util.hp_tuning.hype_grid", "gym_idsgame.runnner.Runner.run", "os.path.exists", "run.write_default_config", "str", "str", "str", "str", "train_result.to_csv", "eval_result.to_csv", "run.plot_csv", "str", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "len", "len", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.create_artefact_dirs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.setup_logger", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.read_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.hp_tuning.hype_grid", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.write_default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.plot_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v20.plot_summary.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v20.plot_summary.default_output_dir": [[15, 21], ["plot_summary.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v20.plot_summary.default_config_path": [[23, 29], ["os.path.join", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "default_config_path", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default path to configuration file\n    \"\"\"", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./config.json'", ")", "\n", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v20.plot_summary.plot_summary": [[31, 96], ["experiments.util.plotting_util.plot_all_averages", "plot_summary.default_output_dir", "maximal_attack_train_csv_paths.append", "maximal_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths.append", "minimal_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths.append", "random_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths.append", "random_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths.append", "two_agents_eval_csv_paths.append", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "plot_summary.default_output_dir", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "plot_summary", "(", "algorithm", ":", "str", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ")", ":", "\n", "    ", "seeds", "=", "[", "0", ",", "999", ",", "299", ",", "399", ",", "499", "]", "\n", "base_dir", "=", "default_output_dir", "(", ")", "\n", "try", ":", "\n", "# V0", "\n", "        ", "maximal_attack_train_csv_paths_v0", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v0", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v0", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v0", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v0", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v0", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v0", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v0", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v0", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v0", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v0", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v0", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v0", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v0", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v0", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "\n", "# V2", "\n", "\n", "", "maximal_attack_train_csv_paths_v2", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v20.plot_summary.plot": [[98, 125], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "pandas.read_csv", "plot_summary.plot_summary", "pandas.read_csv", "plot_summary.plot_summary", "glob.glob", "int", "int", "print", "print", "glob.glob", "int", "int", "print", "print", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "str", "str", "plot_summary.default_output_dir", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v2", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v2", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v2", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v2", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v2", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v2", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v2", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v2", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic_2.run.get_script_path": [[15, 20], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic_2.run.default_output_dir": [[22, 28], ["run.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic_2.run.default_config_path": [[30, 36], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic_2.run.hp_tuning_config": [[37, 50], ["gym_idsgame.config.hp_tuning_config.HpTuningConfig"], "function", ["None"], ["", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic_2.run.default_config": [[51, 98], ["gym_idsgame.agents.training_agents.common.opponent_pool_config.OpponentPoolConfig", "gym_idsgame.agents.training_agents.policy_gradient.pg_agent_config.PolicyGradientAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "", "def", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER_AND_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic_2.run.write_default_config": [[99, 110], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["\n", "\n", "# Program entrypoint", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "versions", "=", "list", "(", "range", "(", "6", ")", ")", "\n", "for", "version", "in", "versions", ":", "\n", "        ", "print", "(", "\"Test Version: {}\"", ".", "format", "(", "version", ")", ")", "\n", "\n", "print", "(", "\"test_sim_attack_maximal_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", "\n", "print", "(", "\"test_sim_attack_maximal_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_random", "(", "version", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic_2.run.plot_csv": [[112, 126], ["experiments.util.plotting_util.read_and_plot_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_results"], ["test_sim_random_vs_defend_minimal", "(", "version", ")", "\n", "print", "(", "\"test_sim_random_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_random_vs_random", "(", "version", ")", "\n", "print", "(", "\"test_train_maximal_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_minimal_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_tabular_q_learning_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic_2.run.plot_average_results": [[128, 144], ["experiments.util.plotting_util.read_and_plot_average_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_average_results"], ["", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.actor_critic_2.run.run_experiment": [[145, 188], ["str", "experiments.util.util.create_artefact_dirs", "experiments.util.util.setup_logger", "default_config.pg_agent_config.to_csv", "experiments.util.util.read_config", "run.default_config", "time.time", "experiments.util.hp_tuning.hype_grid", "gym_idsgame.runnner.Runner.run", "os.path.exists", "run.write_default_config", "str", "str", "str", "str", "train_result.to_csv", "eval_result.to_csv", "run.plot_csv", "str", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "len", "len", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.create_artefact_dirs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.setup_logger", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.read_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.hp_tuning.hype_grid", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.write_default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.plot_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v4.run.get_script_path": [[14, 19], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v4.run.default_output_dir": [[21, 27], ["run.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v4.run.default_config_path": [[29, 35], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v4.run.hp_tuning_config": [[36, 49], ["gym_idsgame.config.hp_tuning_config.HpTuningConfig"], "function", ["None"], ["\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v4.run.default_config": [[50, 84], ["gym_idsgame.agents.training_agents.policy_gradient.pg_agent_config.PolicyGradientAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v4.run.write_default_config": [[85, 96], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "", "def", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER_AND_ATTACKER", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v4.run.plot_csv": [[98, 112], ["experiments.util.plotting_util.read_and_plot_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_results"], ["Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "# Program entrypoint", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "versions", "=", "list", "(", "range", "(", "6", ")", ")", "\n", "for", "version", "in", "versions", ":", "\n", "        ", "print", "(", "\"Test Version: {}\"", ".", "format", "(", "version", ")", ")", "\n", "\n", "print", "(", "\"test_sim_attack_maximal_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", "\n", "print", "(", "\"test_sim_attack_maximal_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_random", "(", "version", ")", "\n", "print", "(", "\"test_sim_random_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_random_vs_defend_minimal", "(", "version", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v4.run.plot_average_results": [[114, 130], ["experiments.util.plotting_util.read_and_plot_average_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_average_results"], ["test_sim_random_vs_random", "(", "version", ")", "\n", "print", "(", "\"test_train_maximal_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_minimal_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_tabular_q_learning_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "\n", "\n", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v4.run.run_experiment": [[131, 174], ["str", "experiments.util.util.create_artefact_dirs", "experiments.util.util.setup_logger", "default_config.pg_agent_config.to_csv", "experiments.util.util.read_config", "run.default_config", "time.time", "experiments.util.hp_tuning.hype_grid", "gym_idsgame.runnner.Runner.run", "os.path.exists", "run.write_default_config", "str", "str", "str", "str", "train_result.to_csv", "eval_result.to_csv", "run.plot_csv", "str", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "len", "len", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.create_artefact_dirs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.setup_logger", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.read_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.hp_tuning.hype_grid", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.write_default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.plot_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v2.run.get_script_path": [[14, 19], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v2.run.default_output_dir": [[21, 27], ["run.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v2.run.default_config_path": [[29, 35], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v2.run.hp_tuning_config": [[36, 49], ["gym_idsgame.config.hp_tuning_config.HpTuningConfig"], "function", ["None"], ["\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v2.run.default_config": [[50, 84], ["gym_idsgame.agents.training_agents.policy_gradient.pg_agent_config.PolicyGradientAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v2.run.write_default_config": [[85, 96], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "", "def", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER_AND_ATTACKER", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v2.run.plot_csv": [[98, 112], ["experiments.util.plotting_util.read_and_plot_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_results"], ["Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "# Program entrypoint", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "versions", "=", "list", "(", "range", "(", "6", ")", ")", "\n", "for", "version", "in", "versions", ":", "\n", "        ", "print", "(", "\"Test Version: {}\"", ".", "format", "(", "version", ")", ")", "\n", "\n", "print", "(", "\"test_sim_attack_maximal_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", "\n", "print", "(", "\"test_sim_attack_maximal_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_random", "(", "version", ")", "\n", "print", "(", "\"test_sim_random_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_random_vs_defend_minimal", "(", "version", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v2.run.plot_average_results": [[114, 130], ["experiments.util.plotting_util.read_and_plot_average_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_average_results"], ["test_sim_random_vs_random", "(", "version", ")", "\n", "print", "(", "\"test_train_maximal_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_minimal_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_tabular_q_learning_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "\n", "\n", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v2.run.run_experiment": [[131, 174], ["str", "experiments.util.util.create_artefact_dirs", "experiments.util.util.setup_logger", "default_config.pg_agent_config.to_csv", "experiments.util.util.read_config", "run.default_config", "time.time", "experiments.util.hp_tuning.hype_grid", "gym_idsgame.runnner.Runner.run", "os.path.exists", "run.write_default_config", "str", "str", "str", "str", "train_result.to_csv", "eval_result.to_csv", "run.plot_csv", "str", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "len", "len", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.create_artefact_dirs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.setup_logger", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.read_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.hp_tuning.hype_grid", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.write_default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.plot_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.get_script_path": [[14, 19], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "return", "script_dir", "\n", "\n", "\n", "", "def", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_output_dir": [[21, 27], ["run.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config_path": [[29, 35], ["os.path.join", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.hp_tuning_config": [[36, 49], ["gym_idsgame.config.hp_tuning_config.HpTuningConfig"], "function", ["None"], ["\n", "", "def", "test_sim_random_vs_defend_minimal", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_sim_random_vs_random", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "simulation_config", "=", "SimulationConfig", "(", "log_frequency", "=", "1", ",", "num_episodes", "=", "10", ")", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config": [[50, 84], ["gym_idsgame.agents.training_agents.policy_gradient.pg_agent_config.PolicyGradientAgentConfig", "gym_idsgame.config.client_config.ClientConfig", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["defender_type", "=", "AgentType", ".", "RANDOM", ".", "value", ",", "mode", "=", "RunnerMode", ".", "SIMULATE", ".", "value", ",", "\n", "simulation_config", "=", "simulation_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ",", "\n", "title", "=", "\"RandomAttacker vs RandomDefender\"", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "False", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_attack-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "", "def", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "False", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.write_default_config": [[85, 96], ["run.default_config", "experiments.util.util.write_config_file", "run.default_config_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path"], ["env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ",", "\n", "q_agent_config", "=", "q_agent_config", ",", "output_dir", "=", "default_output_dir", "(", ")", ")", "\n", "Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "", "def", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "->", "ClientConfig", ":", "\n", "    ", "q_agent_config", "=", "QAgentConfig", "(", "num_episodes", "=", "10", ",", "eval_frequency", "=", "100", ",", "attacker", "=", "True", ",", "defender", "=", "True", ")", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "client_config", "=", "ClientConfig", "(", "env_name", "=", "env_name", ",", "attacker_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "defender_type", "=", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ",", "\n", "mode", "=", "RunnerMode", ".", "TRAIN_DEFENDER_AND_ATTACKER", ".", "value", ",", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.plot_csv": [[98, 112], ["experiments.util.plotting_util.read_and_plot_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_results"], ["Runner", ".", "run", "(", "client_config", ")", "\n", "\n", "\n", "# Program entrypoint", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "versions", "=", "list", "(", "range", "(", "6", ")", ")", "\n", "for", "version", "in", "versions", ":", "\n", "        ", "print", "(", "\"Test Version: {}\"", ".", "format", "(", "version", ")", ")", "\n", "\n", "print", "(", "\"test_sim_attack_maximal_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_defend_minimal", "(", "version", ")", "\n", "print", "(", "\"test_sim_attack_maximal_vs_random, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_attack_maximal_vs_random", "(", "version", ")", "\n", "print", "(", "\"test_sim_random_vs_defend_minimal, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_sim_random_vs_defend_minimal", "(", "version", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.plot_average_results": [[114, 130], ["experiments.util.plotting_util.read_and_plot_average_results"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_average_results"], ["test_sim_random_vs_random", "(", "version", ")", "\n", "print", "(", "\"test_train_maximal_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_maximal_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_minimal_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_minimal_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_attack_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_attack_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_random_defense_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_random_defense_tabular_q_learning", "(", "version", ")", "\n", "print", "(", "\"test_train_tabular_q_learning_tabular_q_learning, version:{}\"", ".", "format", "(", "version", ")", ")", "\n", "test_train_tabular_q_learning_tabular_q_learning", "(", "version", ")", "\n", "\n", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.run_experiment": [[131, 174], ["str", "experiments.util.util.create_artefact_dirs", "experiments.util.util.setup_logger", "default_config.pg_agent_config.to_csv", "experiments.util.util.read_config", "run.default_config", "time.time", "experiments.util.hp_tuning.hype_grid", "gym_idsgame.runnner.Runner.run", "os.path.exists", "run.write_default_config", "str", "str", "str", "str", "train_result.to_csv", "eval_result.to_csv", "run.plot_csv", "str", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "run.default_output_dir", "len", "len", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.create_artefact_dirs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.setup_logger", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.read_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.hp_tuning.hype_grid", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.write_default_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.reinforce_v3.run.plot_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v21.plot_summary.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v21.plot_summary.default_output_dir": [[15, 21], ["plot_summary.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v21.plot_summary.default_config_path": [[23, 29], ["os.path.join", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "default_config_path", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default path to configuration file\n    \"\"\"", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./config.json'", ")", "\n", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v21.plot_summary.plot_summary": [[31, 96], ["experiments.util.plotting_util.plot_all_averages", "plot_summary.default_output_dir", "maximal_attack_train_csv_paths.append", "maximal_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths.append", "minimal_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths.append", "random_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths.append", "random_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths.append", "two_agents_eval_csv_paths.append", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "plot_summary.default_output_dir", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "plot_summary", "(", "algorithm", ":", "str", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ")", ":", "\n", "    ", "seeds", "=", "[", "0", ",", "999", ",", "299", ",", "399", ",", "499", "]", "\n", "base_dir", "=", "default_output_dir", "(", ")", "\n", "try", ":", "\n", "# V0", "\n", "        ", "maximal_attack_train_csv_paths_v0", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v0", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v0", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v0", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v0", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v0", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v0", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v0", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v0", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v0", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v0", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v0", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v0", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v0", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v0", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "\n", "# V2", "\n", "\n", "", "maximal_attack_train_csv_paths_v2", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v21.plot_summary.plot": [[98, 125], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "pandas.read_csv", "plot_summary.plot_summary", "pandas.read_csv", "plot_summary.plot_summary", "glob.glob", "int", "int", "print", "print", "glob.glob", "int", "int", "print", "print", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "str", "str", "plot_summary.default_output_dir", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v2", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v2", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v2", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v2", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v2", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v2", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v2", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v2", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v7.plot_summary.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v7.plot_summary.default_output_dir": [[15, 21], ["plot_summary.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v7.plot_summary.default_config_path": [[23, 29], ["os.path.join", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "default_config_path", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default path to configuration file\n    \"\"\"", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./config.json'", ")", "\n", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v7.plot_summary.plot_summary": [[31, 96], ["experiments.util.plotting_util.plot_all_averages", "plot_summary.default_output_dir", "maximal_attack_train_csv_paths.append", "maximal_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths.append", "minimal_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths.append", "random_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths.append", "random_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths.append", "two_agents_eval_csv_paths.append", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "plot_summary.default_output_dir", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "plot_summary", "(", "algorithm", ":", "str", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ")", ":", "\n", "    ", "seeds", "=", "[", "0", ",", "999", ",", "299", ",", "399", ",", "499", "]", "\n", "base_dir", "=", "default_output_dir", "(", ")", "\n", "try", ":", "\n", "# V0", "\n", "        ", "maximal_attack_train_csv_paths_v0", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v0", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v0", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v0", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v0", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v0", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v0", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v0", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v0", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v0", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v0", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v0", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v0", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v0", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v0", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "\n", "# V2", "\n", "\n", "", "maximal_attack_train_csv_paths_v2", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v7.plot_summary.plot": [[98, 125], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "pandas.read_csv", "plot_summary.plot_summary", "pandas.read_csv", "plot_summary.plot_summary", "glob.glob", "int", "int", "print", "print", "glob.glob", "int", "int", "print", "print", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "str", "str", "plot_summary.default_output_dir", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v2", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v2", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v2", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v2", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v2", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v2", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v2", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v2", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_output_dir": [[15, 21], ["plot_summary.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.default_config_path": [[23, 29], ["os.path.join", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "default_config_path", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default path to configuration file\n    \"\"\"", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "default_output_dir", "(", ")", ",", "'./config.json'", ")", "\n", "return", "config_path", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary": [[31, 96], ["experiments.util.plotting_util.plot_all_averages", "plot_summary.default_output_dir", "maximal_attack_train_csv_paths.append", "maximal_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "minimal_defense_train_csv_paths.append", "minimal_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "random_attack_train_csv_paths.append", "random_attack_eval_csv_paths.append", "plot_summary.default_output_dir", "random_defense_train_csv_paths.append", "random_defense_eval_csv_paths.append", "plot_summary.default_output_dir", "two_agents_train_csv_paths.append", "two_agents_eval_csv_paths.append", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "plot_summary.default_output_dir", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["", "def", "plot_summary", "(", "algorithm", ":", "str", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ")", ":", "\n", "    ", "seeds", "=", "[", "0", ",", "999", ",", "299", ",", "399", ",", "499", "]", "\n", "base_dir", "=", "default_output_dir", "(", ")", "\n", "try", ":", "\n", "# V0", "\n", "        ", "maximal_attack_train_csv_paths_v0", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "maximal_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v0", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v0", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v0", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v0", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v0", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v0", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v0", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v0", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n", "", "random_defense_train_csv_paths_v0", "=", "[", "]", "\n", "random_defense_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/random_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_defense_train_csv_paths_v0", ".", "append", "(", "random_defense_train_csv_path", ")", "\n", "random_defense_eval_csv_paths_v0", ".", "append", "(", "random_defense_eval_csv_path", ")", "\n", "\n", "", "two_agents_train_csv_paths_v0", "=", "[", "]", "\n", "two_agents_eval_csv_paths_v0", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "two_agents_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "two_agents_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v0/two_agents/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "two_agents_train_csv_paths_v0", ".", "append", "(", "two_agents_train_csv_path", ")", "\n", "two_agents_eval_csv_paths_v0", ".", "append", "(", "two_agents_eval_csv_path", ")", "\n", "\n", "\n", "\n", "# V2", "\n", "\n", "", "maximal_attack_train_csv_paths_v2", "=", "[", "]", "\n", "maximal_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot": [[98, 125], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "pandas.read_csv", "plot_summary.plot_summary", "pandas.read_csv", "plot_summary.plot_summary", "glob.glob", "int", "int", "print", "print", "glob.glob", "int", "int", "print", "print", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "plot_summary.default_output_dir", "str", "str", "plot_summary.default_output_dir", "plot_summary.default_output_dir"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir"], ["\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/maximal_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "maximal_attack_train_csv_paths_v2", ".", "append", "(", "maximal_attack_train_csv_path", ")", "\n", "maximal_attack_eval_csv_paths_v2", ".", "append", "(", "maximal_attack_eval_csv_path", ")", "\n", "\n", "", "minimal_defense_train_csv_paths_v2", "=", "[", "]", "\n", "minimal_defense_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "minimal_defense_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/minimal_defense/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "minimal_defense_train_csv_paths_v2", ".", "append", "(", "minimal_defense_train_csv_path", ")", "\n", "minimal_defense_eval_csv_paths_v2", ".", "append", "(", "minimal_defense_eval_csv_path", ")", "\n", "\n", "", "random_attack_train_csv_paths_v2", "=", "[", "]", "\n", "random_attack_eval_csv_paths_v2", "=", "[", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "            ", "base_dir", "=", "default_output_dir", "(", ")", "\n", "random_attack_train_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_train.csv\"", ")", "[", "0", "]", "\n", "random_attack_eval_csv_path", "=", "glob", ".", "glob", "(", "base_dir", "+", "\"/v2/random_attack/\"", "+", "algorithm", "+", "\n", "\"/results/data/\"", "+", "str", "(", "seed", ")", "+", "\"/*_eval.csv\"", ")", "[", "0", "]", "\n", "random_attack_train_csv_paths_v2", ".", "append", "(", "random_attack_train_csv_path", ")", "\n", "random_attack_eval_csv_paths_v2", ".", "append", "(", "random_attack_eval_csv_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.hp_tuning.create_dirs": [[10, 20], ["os.path.exists", "os.makedirs"], "function", ["None"], ["def", "create_dirs", "(", "output_dir", ":", "str", ",", "hparam_str", ":", "str", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Creates directories for hparam tuning results if they do not already exist\n\n    :param output_dir: the base directory\n    :param hparam_str: a string describing the hparam trial\n    :return: None\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "\"/\"", "+", "hparam_str", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/\"", "+", "hparam_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.hp_tuning.hype_grid": [[22, 86], ["getattr", "getattr", "getattr", "getattr", "open", "csv.writer", "csv.writer.writerow", "str", "hp_tuning.create_dirs", "gym_idsgame.runnner.Runner.run", "summary_results.append", "csv.writer.writerow", "time.time", "client_config.logger.info", "setattr", "setattr", "client_config.logger.info", "train_result.to_csv", "eval_result.to_csv", "len", "len", "client_config.q_agent_config.to_csv", "client_config.pg_agent_config.to_csv", "setattr", "setattr", "setattr", "setattr", "ValueError"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.hp_tuning.create_dirs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv"], ["", "", "def", "hype_grid", "(", "client_config", ":", "ClientConfig", ")", ":", "\n", "    ", "\"\"\"\n    Grid search for hyperparameter tuning\n\n    :param client_config: client config for the experiment\n    :param param_1: the name of the first hyperparameter\n    :param param_2: the name of the second hyperparameter\n    :return: None\n    \"\"\"", "\n", "assert", "client_config", ".", "hp_tuning", "\n", "assert", "client_config", ".", "hp_tuning_config", "is", "not", "None", "\n", "assert", "getattr", "(", "client_config", ".", "hp_tuning_config", ",", "client_config", ".", "hp_tuning_config", ".", "param_1", ")", "is", "not", "None", "\n", "assert", "getattr", "(", "client_config", ".", "hp_tuning_config", ",", "client_config", ".", "hp_tuning_config", ".", "param_2", ")", "is", "not", "None", "\n", "summary_results", "=", "[", "]", "\n", "for", "p_1", "in", "getattr", "(", "client_config", ".", "hp_tuning_config", ",", "client_config", ".", "hp_tuning_config", ".", "param_1", ")", ":", "\n", "        ", "for", "p_2", "in", "getattr", "(", "client_config", ".", "hp_tuning_config", ",", "client_config", ".", "hp_tuning_config", ".", "param_2", ")", ":", "\n", "            ", "time_str", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "if", "client_config", ".", "logger", "is", "not", "None", ":", "\n", "                ", "client_config", ".", "logger", ".", "info", "(", "\"Starting Hyperparameter tuning with p_1: {}, eps_decay: {}\"", ".", "format", "(", "p_1", ",", "p_2", ")", ")", "\n", "", "hparam_str", "=", "\"{}={},{}={}\"", ".", "format", "(", "client_config", ".", "hp_tuning_config", ".", "param_1", ",", "p_1", ",", "\n", "client_config", ".", "hp_tuning_config", ".", "param_2", ",", "p_2", ")", "\n", "create_dirs", "(", "client_config", ".", "output_dir", "+", "\"/results/hpo\"", ",", "hparam_str", ")", "\n", "\n", "try", ":", "\n", "                ", "setattr", "(", "client_config", ".", "q_agent_config", ",", "client_config", ".", "hp_tuning_config", ".", "param_1", ",", "p_1", ")", "\n", "setattr", "(", "client_config", ".", "q_agent_config", ",", "client_config", ".", "hp_tuning_config", ".", "param_2", ",", "p_2", ")", "\n", "", "except", ":", "\n", "                ", "try", ":", "\n", "                    ", "setattr", "(", "client_config", ".", "q_agent_config", ".", "dqn_config", ",", "client_config", ".", "hp_tuning_config", ".", "param_1", ",", "p_1", ")", "\n", "setattr", "(", "client_config", ".", "q_agent_config", ".", "dqn_config", ",", "client_config", ".", "hp_tuning_config", ".", "param_2", ",", "p_2", ")", "\n", "", "except", ":", "\n", "                    ", "try", ":", "\n", "                        ", "setattr", "(", "client_config", ".", "pg_agent_config", ",", "client_config", ".", "hp_tuning_config", ".", "param_1", ",", "p_1", ")", "\n", "setattr", "(", "client_config", ".", "pg_agent_config", ",", "client_config", ".", "hp_tuning_config", ".", "param_2", ",", "p_2", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                        ", "raise", "ValueError", "(", "\"Could not find hparams\"", ")", "\n", "", "", "", "train_result", ",", "eval_result", "=", "Runner", ".", "run", "(", "client_config", ")", "\n", "if", "client_config", ".", "logger", "is", "not", "None", ":", "\n", "                ", "client_config", ".", "logger", ".", "info", "(", "\"Hyperparameter tuning with {}: {}, {}: {}, yielded hack prob:{}\"", ".", "format", "(", "\n", "client_config", ".", "hp_tuning_config", ".", "param_1", ",", "p_1", ",", "client_config", ".", "hp_tuning_config", ".", "param_2", ",", "\n", "p_2", ",", "eval_result", ".", "hack_probability", "[", "-", "1", "]", ")", ")", "\n", "", "if", "len", "(", "train_result", ".", "avg_episode_steps", ")", ">", "0", "and", "len", "(", "eval_result", ".", "avg_episode_steps", ")", ">", "0", ":", "\n", "                ", "train_csv_path", "=", "client_config", ".", "output_dir", "+", "\"/results/hpo/\"", "+", "hparam_str", "+", "\"/\"", "+", "time_str", "+", "\"_train\"", "+", "\".csv\"", "\n", "train_result", ".", "to_csv", "(", "train_csv_path", ")", "\n", "eval_csv_path", "=", "client_config", ".", "output_dir", "+", "\"/results/hpo/\"", "+", "hparam_str", "+", "\"/\"", "+", "time_str", "+", "\"_eval\"", "+", "\".csv\"", "\n", "eval_result", ".", "to_csv", "(", "eval_csv_path", ")", "\n", "if", "client_config", ".", "q_agent_config", "is", "not", "None", ":", "\n", "                    ", "client_config", ".", "q_agent_config", ".", "to_csv", "(", "\n", "client_config", ".", "output_dir", "+", "\"/results/hpo/\"", "+", "hparam_str", "+", "\"/hparams_\"", "+", "time_str", "+", "\".csv\"", ")", "\n", "", "if", "client_config", ".", "pg_agent_config", "is", "not", "None", ":", "\n", "                    ", "client_config", ".", "pg_agent_config", ".", "to_csv", "(", "\n", "client_config", ".", "output_dir", "+", "\"/results/hpo/\"", "+", "hparam_str", "+", "\"/hparams_\"", "+", "time_str", "+", "\".csv\"", ")", "\n", "", "", "summary_results", ".", "append", "(", "[", "p_1", ",", "p_2", ",", "eval_result", ".", "hack_probability", "[", "-", "1", "]", ",", "\n", "train_result", ".", "cumulative_hack_probability", "[", "-", "1", "]", "]", ")", "\n", "\n", "", "", "file_name", "=", "client_config", ".", "output_dir", "+", "\"/results/hpo/\"", "+", "\"grid_\"", "+", "client_config", ".", "hp_tuning_config", ".", "param_1", "+", "\"_\"", "+", "client_config", ".", "hp_tuning_config", ".", "param_2", "+", "\"_summary.csv\"", "\n", "with", "open", "(", "file_name", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "client_config", ".", "hp_tuning_config", ".", "param_1", ",", "client_config", ".", "hp_tuning_config", ".", "param_2", ",", "\"eval_hp\"", ",", "\n", "\"cumulative_hp\"", "]", ")", "\n", "for", "row_d", "in", "summary_results", ":", "\n", "            ", "writer", ".", "writerow", "(", "row_d", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.create_artefact_dirs": [[13, 33], ["os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["None"], ["def", "create_artefact_dirs", "(", "output_dir", ":", "str", ",", "random_seed", ":", "int", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Creates artefact directories if they do not already exist\n\n    :param output_dir: the base directory\n    :param random_seed: the random seed of the experiment\n    :return: None\n    \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "\"/results/logs/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/results/logs/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "\"/results/data/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/results/data/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "\"/results/hyperparameters/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/results/hyperparameters/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "\"/results/gifs/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/results/gifs/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "\"/results/tensorboard/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/results/tensorboard/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.setup_logger": [[35, 64], ["logging.Formatter", "logging.StreamHandler", "logging.StreamHandler.setLevel", "logging.StreamHandler.setFormatter", "logging.getLogger", "logging.getLogger.setLevel", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler", "str", "time.time"], "function", ["None"], ["", "", "def", "setup_logger", "(", "name", ":", "str", ",", "logdir", ":", "str", ",", "time_str", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Configures the logger for writing log-data of experiments\n\n    :param name: name of the logger\n    :param logdir: directory to save log files\n    :param time_str: time string for file names\n    :return: None\n    \"\"\"", "\n", "# create formatter", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "'%(asctime)s,%(message)s'", ")", "\n", "# log to console", "\n", "ch", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "ch", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "ch", ".", "setFormatter", "(", "formatter", ")", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "name", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "# log to file", "\n", "if", "time_str", "is", "None", ":", "\n", "        ", "time_str", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "", "fh", "=", "logging", ".", "FileHandler", "(", "logdir", "+", "\"/\"", "+", "time_str", "+", "\"_\"", "+", "name", "+", "\".log\"", ",", "mode", "=", "\"w\"", ")", "\n", "fh", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "fh", ".", "setFormatter", "(", "formatter", ")", "\n", "\n", "# add the handlers to the logger", "\n", "logger", ".", "addHandler", "(", "fh", ")", "\n", "#logger.addHandler(ch)", "\n", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.write_config_file": [[65, 76], ["json.dumps", "json.loads", "io.open", "f.write", "jsonpickle.encode"], "function", ["None"], ["", "def", "write_config_file", "(", "config", ":", "ClientConfig", ",", "path", ":", "str", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Writes a config object to a config file\n\n    :param config: the config to write\n    :param path: the path to write the file\n    :return: None\n    \"\"\"", "\n", "json_str", "=", "json", ".", "dumps", "(", "json", ".", "loads", "(", "jsonpickle", ".", "encode", "(", "config", ")", ")", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "with", "io", ".", "open", "(", "path", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "json_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.read_config": [[78, 89], ["jsonpickle.decode", "io.open", "f.read"], "function", ["None"], ["", "", "def", "read_config", "(", "config_path", ")", "->", "ClientConfig", ":", "\n", "    ", "\"\"\"\n    Reads configuration of the experiment from a json file\n\n    :param config_path: the path to the configuration file\n    :return: the configuration\n    \"\"\"", "\n", "with", "io", ".", "open", "(", "config_path", ",", "'r'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "json_str", "=", "f", ".", "read", "(", ")", "\n", "", "client_config", ":", "ClientConfig", "=", "jsonpickle", ".", "decode", "(", "json_str", ")", "\n", "return", "client_config", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.parse_args": [[91, 106], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.util.parse_args"], ["", "def", "parse_args", "(", "default_config_path", ")", ":", "\n", "    ", "\"\"\"\n    Parses the commandline arguments with argparse\n\n    :param default_config_path: default path to config file\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Parse flags to configure the json parsing'", ")", "\n", "parser", ".", "add_argument", "(", "\"-cp\"", ",", "\"--configpath\"", ",", "help", "=", "\"Path to configuration file\"", ",", "\n", "default", "=", "default_config_path", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\"-po\"", ",", "\"--plotonly\"", ",", "help", "=", "\"Boolean parameter, if true, only plot\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "parser", ".", "add_argument", "(", "\"-nc\"", ",", "\"--noconfig\"", ",", "help", "=", "\"Boolean parameter, if true always override config\"", ",", "\n", "action", "=", "\"store_true\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data": [[14, 22], ["pandas.read_csv"], "function", ["None"], ["def", "read_data", "(", "file", ")", "->", "pd", ".", "DataFrame", ":", "\n", "    ", "\"\"\"\n    Utility function for reading csv files into pandas dataframes\n\n    :param file: path to the csv file\n    :return: df\n    \"\"\"", "\n", "return", "pd", ".", "read_csv", "(", "file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all": [[23, 297], ["matplotlib.rc", "matplotlib.rc", "matplotlib.subplots", "[].errorbar", "[].errorbar", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "[].spines[].set_color", "[].spines[].set_color", "[].legend", "[].errorbar", "[].errorbar", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "[].spines[].set_color", "[].spines[].set_color", "[].legend", "ax[].hist", "ax[].hist", "ax[].set_title", "ax[].set_xlabel", "ax[].set_ylabel", "ax[].legend", "ax[].grid", "ax[].xaxis.set_tick_params", "ax[].yaxis.set_tick_params", "ax[].spines[].set_color", "ax[].spines[].set_color", "ax[].xaxis.get_label", "ax[].yaxis.get_label", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "[].fill_between", "[].set_xlabel", "[].set_ylabel", "[].set_title", "[].grid", "[].fill_between.set_facecolors", "[].fill_between.set_edgecolors", "[].fill_between.set_linewidths", "[].xaxis.set_tick_params", "[].yaxis.set_tick_params", "[].spines[].set_color", "[].spines[].set_color", "[].xaxis.get_label", "[].yaxis.get_label", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "[].fill_between", "[].set_xlabel", "[].set_ylabel", "[].set_title", "[].grid", "[].fill_between.set_facecolors", "[].fill_between.set_edgecolors", "[].fill_between.set_linewidths", "[].xaxis.set_tick_params", "[].yaxis.set_tick_params", "[].spines[].set_color", "[].spines[].set_color", "[].xaxis.get_label", "[].yaxis.get_label", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "[].errorbar", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "[].spines[].set_color", "[].spines[].set_color", "[].errorbar", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "[].spines[].set_color", "[].spines[].set_color", "[].errorbar", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "[].spines[].set_color", "[].spines[].set_color", "[].fill_between", "[].set_xlabel", "[].set_ylabel", "[].set_title", "[].grid", "[].fill_between.set_facecolors", "[].fill_between.set_edgecolors", "[].fill_between.set_linewidths", "[].xaxis.set_tick_params", "[].yaxis.set_tick_params", "[].spines[].set_color", "[].spines[].set_color", "[].xaxis.get_label", "[].yaxis.get_label", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "fig.tight_layout", "fig.savefig", "fig.savefig", "matplotlib.close", "min", "max", "min", "max", "numpy.array", "min", "max", "min", "max", "numpy.array", "numpy.array", "numpy.ones_like", "float", "numpy.ones_like", "float", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "min", "min", "max", "max", "min", "min", "max", "max", "list", "numpy.array", "min", "min", "max", "max", "min", "min", "max", "max", "list", "list", "len", "len", "list", "numpy.array", "list", "list", "list", "list", "numpy.array", "numpy.array", "range", "list", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "range", "range", "range", "list", "range", "range", "range", "range", "list", "numpy.array", "list", "numpy.array", "len", "range", "list", "list", "list", "list", "len", "len", "len", "range", "len", "len", "len", "len", "range", "list", "range", "list", "len", "range", "range", "range", "range", "len", "len", "range", "len", "range", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "plot_all", "(", "train_df", ",", "eval_df", ",", "eval_step", ",", "a_state_values", ",", "file_name", ")", ":", "\n", "    ", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "3", ",", "ncols", "=", "3", ",", "figsize", "=", "(", "16", ",", "6", ")", ")", "\n", "\n", "# Plot avg_episode_steps", "\n", "xlims", "=", "(", "min", "(", "min", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "train_df", "[", "\"avg_episode_steps\"", "]", ")", ")", ")", ")", ")", ",", "\n", "min", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "eval_df", "[", "\"avg_episode_steps\"", "]", ")", ")", ")", ")", "*", "eval_step", ")", ")", ",", "\n", "max", "(", "max", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "train_df", "[", "\"avg_episode_steps\"", "]", ")", ")", ")", ")", ")", ",", "\n", "max", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "eval_df", "[", "\"avg_episode_steps\"", "]", ")", ")", ")", ")", "*", "eval_step", ")", ")", ")", "\n", "ylims", "=", "(", "min", "(", "min", "(", "train_df", "[", "\"avg_episode_steps\"", "]", ")", ",", "min", "(", "eval_df", "[", "\"avg_episode_steps\"", "]", ")", ")", ",", "\n", "max", "(", "max", "(", "train_df", "[", "\"avg_episode_steps\"", "]", ")", ",", "max", "(", "eval_df", "[", "\"avg_episode_steps\"", "]", ")", ")", ")", "\n", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "errorbar", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "train_df", "[", "\"avg_episode_steps\"", "]", ")", ")", ")", ")", ",", "\n", "train_df", "[", "\"avg_episode_steps\"", "]", ",", "yerr", "=", "None", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "label", "=", "\"Train\"", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "errorbar", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "eval_df", "[", "\"avg_episode_steps\"", "]", ")", ")", ")", ")", "*", "eval_step", ",", "\n", "eval_df", "[", "\"avg_episode_steps\"", "]", ",", "yerr", "=", "None", ",", "ls", "=", "'--'", ",", "color", "=", "'#f9a65a'", ",", "label", "=", "\"Eval\"", ")", "\n", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_title", "(", "\"Avg Episode Lengths\"", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_xlabel", "(", "\"Episode \\#\"", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_ylabel", "(", "\"Avg Length (num steps)\"", ")", "\n", "\n", "# set the grid on", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "0", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "0", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "legend", "(", "loc", "=", "\"upper right\"", ")", "\n", "\n", "# Plot Cumulative Reward", "\n", "xlims", "=", "(", "min", "(", "min", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "train_df", "[", "\"attacker_cumulative_reward\"", "]", ")", ")", ")", ")", ")", ",", "\n", "min", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "train_df", "[", "\"defender_cumulative_reward\"", "]", ")", ")", ")", ")", ")", ")", ",", "\n", "max", "(", "max", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "train_df", "[", "\"attacker_cumulative_reward\"", "]", ")", ")", ")", ")", ")", ",", "\n", "max", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "train_df", "[", "\"defender_cumulative_reward\"", "]", ")", ")", ")", ")", ")", ")", ")", "\n", "ylims", "=", "(", "min", "(", "min", "(", "train_df", "[", "\"attacker_cumulative_reward\"", "]", ")", ",", "min", "(", "train_df", "[", "\"defender_cumulative_reward\"", "]", ")", ")", ",", "\n", "max", "(", "max", "(", "train_df", "[", "\"attacker_cumulative_reward\"", "]", ")", ",", "max", "(", "train_df", "[", "\"defender_cumulative_reward\"", "]", ")", ")", ")", "\n", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "errorbar", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "train_df", "[", "\"attacker_cumulative_reward\"", "]", ")", ")", ")", ")", ",", "\n", "train_df", "[", "\"attacker_cumulative_reward\"", "]", ",", "yerr", "=", "None", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "label", "=", "\"Attacker\"", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "errorbar", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "train_df", "[", "\"defender_cumulative_reward\"", "]", ")", ")", ")", ")", ",", "\n", "train_df", "[", "\"defender_cumulative_reward\"", "]", ",", "yerr", "=", "None", ",", "ls", "=", "'--'", ",", "color", "=", "'#f9a65a'", ",", "label", "=", "\"Defender\"", ")", "\n", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_title", "(", "\"Cumulative Reward\"", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_xlabel", "(", "\"Episode \\#\"", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_ylabel", "(", "\"Cumulative Reward\"", ")", "\n", "\n", "# set the grid on", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "0", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "0", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "legend", "(", "loc", "=", "\"upper left\"", ")", "\n", "\n", "# Plot histogram of average episode lengths", "\n", "\n", "weights_1", "=", "np", ".", "ones_like", "(", "train_df", "[", "\"avg_episode_steps\"", "]", ".", "values", ")", "/", "float", "(", "len", "(", "train_df", "[", "\"avg_episode_steps\"", "]", ".", "values", ")", ")", "\n", "weights_2", "=", "np", ".", "ones_like", "(", "eval_df", "[", "\"avg_episode_steps\"", "]", ".", "values", ")", "/", "float", "(", "len", "(", "eval_df", "[", "\"avg_episode_steps\"", "]", ".", "values", ")", ")", "\n", "ax", "[", "0", ",", "2", "]", ".", "hist", "(", "train_df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "alpha", "=", "0.5", ",", "bins", "=", "5", ",", "weights", "=", "weights_1", ",", "\n", "color", "=", "\"#599ad3\"", ",", "label", "=", "\"Train\"", ",", "\n", "stacked", "=", "True", ")", "\n", "ax", "[", "0", ",", "2", "]", ".", "hist", "(", "eval_df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "alpha", "=", "0.5", ",", "bins", "=", "5", ",", "weights", "=", "weights_2", ",", "\n", "color", "=", "'#f9a65a'", ",", "label", "=", "\"Eval\"", ",", "\n", "stacked", "=", "True", ")", "\n", "ax", "[", "0", ",", "2", "]", ".", "set_title", "(", "\"Avg Episode Lengths\"", ")", "\n", "ax", "[", "0", ",", "2", "]", ".", "set_xlabel", "(", "\"Avg Length (num steps)\"", ")", "\n", "ax", "[", "0", ",", "2", "]", ".", "set_ylabel", "(", "\"Normalized Frequency\"", ")", "\n", "ax", "[", "0", ",", "2", "]", ".", "legend", "(", ")", "\n", "\n", "# set the grid on", "\n", "ax", "[", "0", ",", "2", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# remove tick marks", "\n", "ax", "[", "0", ",", "2", "]", ".", "xaxis", ".", "set_tick_params", "(", "size", "=", "0", ")", "\n", "ax", "[", "0", ",", "2", "]", ".", "yaxis", ".", "set_tick_params", "(", "size", "=", "0", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "0", ",", "2", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "0", ",", "2", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "0", ",", "2", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "0", ",", "2", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "# Plot Hack Probability (Train)", "\n", "\n", "l", "=", "ax", "[", "1", "]", "[", "0", "]", ".", "fill_between", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "train_df", "[", "\"hack_probability\"", "]", ".", "values", ")", ")", ")", ")", ",", "\n", "train_df", "[", "\"hack_probability\"", "]", ".", "values", ")", "\n", "\n", "# set the basic properties", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_xlabel", "(", "\"Episode \\#\"", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_ylabel", "(", "\"$\\mathbb{P}[Hacked]$\"", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_title", "(", "\"Likelihood of Successful Hack (Train)\"", ")", "\n", "\n", "#ax[1][0].set_ylim(0, 1)", "\n", "\n", "# set the grid on", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# change the fill into a blueish color with opacity .3", "\n", "l", ".", "set_facecolors", "(", "[", "[", ".5", ",", ".5", ",", ".8", ",", ".3", "]", "]", ")", "\n", "\n", "# change the edge color (bluish and transparentish) and thickness", "\n", "l", ".", "set_edgecolors", "(", "[", "[", "0", ",", "0", ",", ".5", ",", ".3", "]", "]", ")", "\n", "l", ".", "set_linewidths", "(", "[", "3", "]", ")", "\n", "\n", "# remove tick marks", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "xaxis", ".", "set_tick_params", "(", "size", "=", "0", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "yaxis", ".", "set_tick_params", "(", "size", "=", "0", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "1", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "# Plot Hack Probability (Eval)", "\n", "l", "=", "ax", "[", "1", "]", "[", "1", "]", ".", "fill_between", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "eval_df", "[", "\"hack_probability\"", "]", ".", "values", ")", ")", ")", ")", "*", "eval_step", ",", "\n", "eval_df", "[", "\"hack_probability\"", "]", ".", "values", ")", "\n", "\n", "# set the basic properties", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_xlabel", "(", "\"Episode \\#\"", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_ylabel", "(", "\"$\\mathbb{P}[Hacked]$\"", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_title", "(", "\"Likelihood of Successful Hack (Eval)\"", ")", "\n", "\n", "#ax[1][1].set_ylim(0, 1)", "\n", "\n", "# set the grid on", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# change the fill into a blueish color with opacity .3", "\n", "l", ".", "set_facecolors", "(", "[", "[", ".5", ",", ".5", ",", ".8", ",", ".3", "]", "]", ")", "\n", "\n", "# change the edge color (bluish and transparentish) and thickness", "\n", "l", ".", "set_edgecolors", "(", "[", "[", "0", ",", "0", ",", ".5", ",", ".3", "]", "]", ")", "\n", "l", ".", "set_linewidths", "(", "[", "3", "]", ")", "\n", "\n", "# remove tick marks", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "xaxis", ".", "set_tick_params", "(", "size", "=", "0", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "yaxis", ".", "set_tick_params", "(", "size", "=", "0", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "1", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "# Plot loss", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "errorbar", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "train_df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ")", ")", ")", ")", ",", "\n", "train_df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "yerr", "=", "None", ",", "mfc", "=", "[", ".5", ",", ".5", ",", ".8", ",", ".3", "]", ",", "\n", "mec", "=", "[", "0", ",", "0", ",", ".5", ",", ".3", "]", ",", "ls", "=", "'-'", ",", "ecolor", "=", "'black'", ")", "\n", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "set_title", "(", "\"Avg Episode Loss (Attacker)\"", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "set_xlabel", "(", "\"Episode \\#\"", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "set_ylabel", "(", "\"Loss\"", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "1", "]", "[", "2", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", "[", "2", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# Plot learning rate", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "errorbar", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "train_df", "[", "\"lr_list\"", "]", ".", "values", ")", ")", ")", ")", ",", "\n", "train_df", "[", "\"lr_list\"", "]", ".", "values", ",", "yerr", "=", "None", ",", "mfc", "=", "[", ".5", ",", ".5", ",", ".8", ",", ".3", "]", ",", "\n", "mec", "=", "[", "0", ",", "0", ",", ".5", ",", ".3", "]", ",", "ls", "=", "'-'", ",", "ecolor", "=", "'black'", ")", "\n", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "set_title", "(", "\"Learning rate (Eta) (Train)\"", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "set_xlabel", "(", "\"Episode \\#\"", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "set_ylabel", "(", "\"Learning Rate\"", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "2", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "2", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# Plot exploration rate", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "errorbar", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "train_df", "[", "\"epsilon_values\"", "]", ".", "values", ")", ")", ")", ")", ",", "\n", "train_df", "[", "\"epsilon_values\"", "]", ".", "values", ",", "yerr", "=", "None", ",", "mfc", "=", "[", ".5", ",", ".5", ",", ".8", ",", ".3", "]", ",", "\n", "mec", "=", "[", "0", ",", "0", ",", ".5", ",", ".3", "]", ",", "ls", "=", "'-'", ",", "ecolor", "=", "'black'", ")", "\n", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "set_title", "(", "\"Exploration rate (Epsilon)\"", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "set_xlabel", "(", "\"Episode \\#\"", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "set_ylabel", "(", "\"Epsilon\"", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "2", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "2", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# Plot Attack State Values for Final Trajectory", "\n", "l", "=", "ax", "[", "2", "]", "[", "2", "]", ".", "fill_between", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_state_values", ")", ")", ")", ")", ",", "\n", "a_state_values", ")", "\n", "\n", "# set the basic properties", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "set_xlabel", "(", "\"Time step (t)\"", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "set_ylabel", "(", "\"$V(s_t)$\"", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "set_title", "(", "\"Attacker State Values\"", ")", "\n", "\n", "# ax[2][2].set_ylim(0,1)", "\n", "\n", "# set the grid on", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# change the fill into a blueish color with opacity .3", "\n", "l", ".", "set_facecolors", "(", "[", "[", ".5", ",", ".5", ",", ".8", ",", ".3", "]", "]", ")", "\n", "\n", "# change the edge color (bluish and transparentish) and thickness", "\n", "l", ".", "set_edgecolors", "(", "[", "[", "0", ",", "0", ",", ".5", ",", ".3", "]", "]", ")", "\n", "l", ".", "set_linewidths", "(", "[", "3", "]", ")", "\n", "\n", "# remove tick marks", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "xaxis", ".", "set_tick_params", "(", "size", "=", "0", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "yaxis", ".", "set_tick_params", "(", "size", "=", "0", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "2", "]", "[", "2", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "2", "]", "[", "2", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "#plt.subplots_adjust(wspace=0, hspace=0)", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_two_histograms": [[299, 358], ["matplotlib.rc", "matplotlib.rc", "matplotlib.subplots", "matplotlib.hist", "matplotlib.hist", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.legend", "ax.grid", "ax.xaxis.set_tick_params", "ax.yaxis.set_tick_params", "ax.spines[].set_color", "ax.spines[].set_color", "ax.xaxis.get_label", "ax.yaxis.get_label", "ax.xaxis.get_label.set_size", "ax.yaxis.get_label.set_size", "fig.tight_layout", "fig.savefig", "fig.savefig", "matplotlib.close", "numpy.ones_like", "float", "numpy.ones_like", "float", "len", "len"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "plot_two_histograms", "(", "d_1", ":", "np", ".", "ndarray", ",", "d_2", ":", "np", ".", "ndarray", ",", "title", ":", "str", "=", "\"Test\"", ",", "xlabel", ":", "str", "=", "\"test\"", ",", "\n", "ylabel", ":", "str", "=", "\"test\"", ",", "file_name", ":", "str", "=", "\"test.eps\"", ",", "\n", "hist1_label", "=", "\"Train\"", ",", "hist2_label", "=", "\"Eval\"", ",", "\n", "num_bins", "=", "5", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Plots two histograms\n\n    :param x: data for x-axis\n    :param y: data for y-axis\n    :param title: title of the plot\n    :param xlabel: label of x-axis\n    :param ylabel: label of y-axis\n    :param file_name: name of the file to save the plot\n    :param xlims: limits for the x-axis\n    :param ylims: limits for the y-axis\n    :param log: whether to log-scale the y-axis\n    :return: None\n    \"\"\"", "\n", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "\n", "# let us make a simple graph", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "1", ",", "figsize", "=", "(", "8", ",", "3", ")", ")", "\n", "\n", "weights_1", "=", "np", ".", "ones_like", "(", "d_1", ")", "/", "float", "(", "len", "(", "d_1", ")", ")", "\n", "weights_2", "=", "np", ".", "ones_like", "(", "d_2", ")", "/", "float", "(", "len", "(", "d_2", ")", ")", "\n", "plt", ".", "hist", "(", "d_1", ",", "alpha", "=", "0.5", ",", "bins", "=", "num_bins", ",", "weights", "=", "weights_1", ",", "color", "=", "\"#599ad3\"", ",", "label", "=", "hist1_label", ",", "\n", "stacked", "=", "True", ")", "\n", "plt", ".", "hist", "(", "d_2", ",", "alpha", "=", "0.5", ",", "bins", "=", "num_bins", ",", "weights", "=", "weights_2", ",", "color", "=", "'#f9a65a'", ",", "label", "=", "hist2_label", ",", "\n", "stacked", "=", "True", ")", "\n", "plt", ".", "title", "(", "title", ")", "\n", "plt", ".", "xlabel", "(", "xlabel", ")", "\n", "plt", ".", "ylabel", "(", "ylabel", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "\n", "# set the grid on", "\n", "ax", ".", "grid", "(", "'on'", ")", "\n", "\n", "# remove tick marks", "\n", "ax", ".", "xaxis", ".", "set_tick_params", "(", "size", "=", "0", ")", "\n", "ax", ".", "yaxis", ".", "set_tick_params", "(", "size", "=", "0", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# xlab.set_style('italic')", "\n", "# ylab.set_style('italic')", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.two_line_plot": [[359, 418], ["matplotlib.rc", "matplotlib.rc", "matplotlib.subplots", "ax.errorbar", "ax.errorbar", "ax.set_xlim", "ax.set_title", "ax.set_xlabel", "ax.set_ylabel", "ax.grid", "ax.xaxis.get_label", "ax.yaxis.get_label", "ax.xaxis.get_label.set_size", "ax.yaxis.get_label.set_size", "ax.spines[].set_color", "ax.spines[].set_color", "matplotlib.legend", "fig.tight_layout", "fig.savefig", "fig.savefig", "matplotlib.close", "min", "max", "min", "max", "min", "min", "max", "max", "min", "min", "max", "max"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "two_line_plot", "(", "x_1", ":", "np", ".", "ndarray", ",", "y_1", ":", "np", ".", "ndarray", ",", "x_2", ":", "np", ".", "ndarray", ",", "y_2", ":", "np", ".", "ndarray", ",", "\n", "title", ":", "str", "=", "\"Test\"", ",", "xlabel", ":", "str", "=", "\"test\"", ",", "ylabel", ":", "str", "=", "\"test\"", ",", "\n", "file_name", ":", "str", "=", "\"test.eps\"", ",", "xlims", ":", "Union", "[", "float", ",", "float", "]", "=", "None", ",", "ylims", ":", "Union", "[", "float", ",", "float", "]", "=", "None", ",", "\n", "line1_label", "=", "\"Train\"", ",", "line2_label", "=", "\"Eval\"", ",", "legend_loc", "=", "'upper right'", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Plots two lines\n\n    :param x: data for x-axis\n    :param y: data for y-axis\n    :param title: title of the plot\n    :param xlabel: label of x-axis\n    :param ylabel: label of y-axis\n    :param file_name: name of the file to save the plot\n    :param xlims: limits for the x-axis\n    :param ylims: limits for the y-axis\n    :param log: whether to log-scale the y-axis\n    :return: None\n    \"\"\"", "\n", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "1", ",", "figsize", "=", "(", "8", ",", "3", ")", ")", "\n", "if", "xlims", "is", "None", ":", "\n", "        ", "xlims", "=", "(", "min", "(", "min", "(", "x_1", ")", ",", "min", "(", "x_2", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1", ")", ",", "max", "(", "x_2", ")", ")", ")", "\n", "", "if", "ylims", "is", "None", ":", "\n", "        ", "ylims", "=", "(", "min", "(", "min", "(", "y_1", ")", ",", "min", "(", "y_2", ")", ")", ",", "\n", "max", "(", "max", "(", "y_1", ")", ",", "max", "(", "y_2", ")", ")", ")", "\n", "\n", "", "ax", ".", "errorbar", "(", "x_1", ",", "y_1", ",", "yerr", "=", "None", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "label", "=", "line1_label", ")", "\n", "ax", ".", "errorbar", "(", "x_2", ",", "y_2", ",", "yerr", "=", "None", ",", "ls", "=", "'--'", ",", "color", "=", "'#f9a65a'", ",", "label", "=", "line2_label", ")", "\n", "\n", "ax", ".", "set_xlim", "(", "xlims", ")", "\n", "#ax.set_ylim(ylims)", "\n", "\n", "ax", ".", "set_title", "(", "title", ")", "\n", "ax", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# xlab.set_style('italic')", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "# ylab.set_style('italic')", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "plt", ".", "legend", "(", "loc", "=", "legend_loc", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.simple_line_plot": [[420, 477], ["matplotlib.subplots", "ax.errorbar", "ax.set_xlim", "ax.set_title", "ax.set_xlabel", "ax.set_ylabel", "ax.grid", "ax.xaxis.get_label", "ax.yaxis.get_label", "ax.xaxis.get_label.set_size", "ax.yaxis.get_label.set_size", "ax.spines[].set_color", "ax.spines[].set_color", "fig.tight_layout", "fig.savefig", "fig.savefig", "matplotlib.close", "scipy.interpolate.interp1d", "numpy.linspace", "ax.errorbar", "ax.set_yscale", "min", "max", "min", "max", "min", "max", "scipy.interpolate.interp1d.", "len"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "simple_line_plot", "(", "x", ":", "np", ".", "ndarray", ",", "y", ":", "np", ".", "ndarray", ",", "title", ":", "str", "=", "\"Test\"", ",", "xlabel", ":", "str", "=", "\"test\"", ",", "ylabel", ":", "str", "=", "\"test\"", ",", "\n", "file_name", ":", "str", "=", "\"test.eps\"", ",", "xlims", ":", "Union", "[", "float", ",", "float", "]", "=", "None", ",", "ylims", ":", "Union", "[", "float", ",", "float", "]", "=", "None", ",", "\n", "log", ":", "bool", "=", "False", ",", "smooth", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Plots a line plot with a raw line and a smooth line (optionally)\n\n    :param x: data for x-axis\n    :param y: data for y-axis\n    :param title: title of the plot\n    :param xlabel: label of x-axis\n    :param ylabel: label of y-axis\n    :param file_name: name of the file to save the plot\n    :param xlims: limits for the x-axis\n    :param ylims: limits for the y-axis\n    :param log: whether to log-scale the y-axis\n    :return: None\n    \"\"\"", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "1", ",", "figsize", "=", "(", "8", ",", "3", ")", ")", "\n", "if", "xlims", "is", "None", ":", "\n", "        ", "xlims", "=", "(", "min", "(", "x", ")", ",", "max", "(", "x", ")", ")", "\n", "", "if", "ylims", "is", "None", ":", "\n", "        ", "ylims", "=", "(", "min", "(", "y", ")", ",", "max", "(", "y", ")", ")", "\n", "", "ax", ".", "errorbar", "(", "x", ",", "y", ",", "yerr", "=", "None", ",", "mfc", "=", "[", ".5", ",", ".5", ",", ".8", ",", ".3", "]", ",", "mec", "=", "[", "0", ",", "0", ",", ".5", ",", ".3", "]", ",", "ls", "=", "'-'", ",", "ecolor", "=", "'black'", ")", "\n", "\n", "if", "smooth", ":", "\n", "        ", "smooth", "=", "interp1d", "(", "x", ",", "y", ")", "\n", "x_smooth", "=", "np", ".", "linspace", "(", "min", "(", "x", ")", ",", "max", "(", "x", ")", ",", "len", "(", "x", ")", "//", "10", ")", "\n", "ax", ".", "errorbar", "(", "x_smooth", ",", "smooth", "(", "x_smooth", ")", ",", "yerr", "=", "None", ",", "color", "=", "\"black\"", ",", "ls", "=", "'-'", ",", "ecolor", "=", "'black'", ")", "\n", "\n", "", "ax", ".", "set_xlim", "(", "xlims", ")", "\n", "#ax.set_ylim(ylims)", "\n", "\n", "ax", ".", "set_title", "(", "title", ")", "\n", "ax", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# xlab.set_style('italic')", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "# ylab.set_style('italic')", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "if", "log", ":", "\n", "        ", "ax", ".", "set_yscale", "(", "\"log\"", ")", "\n", "", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.probability_plot": [[479, 543], ["matplotlib.rc", "matplotlib.rc", "matplotlib.figure", "matplotlib.subplot", "plt.subplot.fill_between", "plt.subplot.set_xlabel", "plt.subplot.set_ylabel", "plt.subplot.set_title", "plt.subplot.set_xlim", "plt.subplot.grid", "ax.fill_between.set_facecolors", "ax.fill_between.set_edgecolors", "ax.fill_between.set_linewidths", "plt.subplot.xaxis.set_tick_params", "plt.subplot.yaxis.set_tick_params", "plt.subplot.spines[].set_color", "plt.subplot.spines[].set_color", "plt.subplot.xaxis.get_label", "plt.subplot.yaxis.get_label", "ax.xaxis.get_label.set_size", "ax.yaxis.get_label.set_size", "plt.figure.tight_layout", "plt.figure.savefig", "plt.figure.savefig", "matplotlib.close"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "probability_plot", "(", "x", ":", "np", ".", "ndarray", ",", "y", ":", "np", ".", "ndarray", ",", "title", ":", "str", "=", "\"Test\"", ",", "xlabel", ":", "str", "=", "\"test\"", ",", "ylabel", ":", "str", "=", "\"test\"", ",", "\n", "file_name", ":", "str", "=", "\"test.eps\"", ",", "xlims", ":", "Union", "[", "float", ",", "float", "]", "=", "None", ",", "\n", "ylims", ":", "Union", "[", "float", ",", "float", "]", "=", "None", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Plots a CDF-like probability plot\n\n    :param x: data for x-axis\n    :param y: data for y-axis\n    :param title: title of the plot\n    :param xlabel: label of x-axis\n    :param ylabel: label of y-axis\n    :param file_name: name of the file to save the plot\n    :param xlims: limits for the x-axis\n    :param ylims: limits for the y-axis\n    :param log: whether to log-scale the y-axis\n    :return: None\n    \"\"\"", "\n", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "\n", "# let us make a simple graph", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "[", "8", ",", "3", "]", ")", "\n", "ax", "=", "plt", ".", "subplot", "(", "111", ")", "\n", "l", "=", "ax", ".", "fill_between", "(", "x", ",", "y", ")", "\n", "\n", "# set the basic properties", "\n", "ax", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", ".", "set_ylabel", "(", "ylabel", ")", "\n", "ax", ".", "set_title", "(", "title", ")", "\n", "\n", "ax", ".", "set_xlim", "(", "xlims", ")", "\n", "#ax.set_ylim(ylims)", "\n", "\n", "# set the grid on", "\n", "ax", ".", "grid", "(", "'on'", ")", "\n", "\n", "# change the fill into a blueish color with opacity .3", "\n", "l", ".", "set_facecolors", "(", "[", "[", ".5", ",", ".5", ",", ".8", ",", ".3", "]", "]", ")", "\n", "\n", "# change the edge color (bluish and transparentish) and thickness", "\n", "l", ".", "set_edgecolors", "(", "[", "[", "0", ",", "0", ",", ".5", ",", ".3", "]", "]", ")", "\n", "l", ".", "set_linewidths", "(", "[", "3", "]", ")", "\n", "\n", "# remove tick marks", "\n", "ax", ".", "xaxis", ".", "set_tick_params", "(", "size", "=", "0", ")", "\n", "ax", ".", "yaxis", ".", "set_tick_params", "(", "size", "=", "0", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# xlab.set_style('italic')", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "# ylab.set_style('italic')", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.two_line_plot_w_shades": [[545, 619], ["matplotlib.rc", "matplotlib.rc", "matplotlib.subplots", "ax.plot", "ax.fill_between", "ax.plot", "ax.fill_between", "ax.set_xlim", "ax.set_title", "ax.set_xlabel", "ax.set_ylabel", "ax.grid", "ax.xaxis.get_label", "ax.yaxis.get_label", "ax.xaxis.get_label.set_size", "ax.yaxis.get_label.set_size", "ax.spines[].set_color", "ax.spines[].set_color", "matplotlib.legend", "fig.tight_layout", "fig.savefig", "fig.savefig", "matplotlib.close", "min", "max", "min", "max", "min", "min", "max", "max", "min", "min", "max", "max"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "two_line_plot_w_shades", "(", "x_1", ":", "np", ".", "ndarray", ",", "y_1", ":", "np", ".", "ndarray", ",", "\n", "x_2", ":", "np", ".", "ndarray", ",", "y_2", ":", "np", ".", "ndarray", ",", "\n", "stds_1", ",", "stds_2", ",", "\n", "title", ":", "str", "=", "\"Test\"", ",", "xlabel", ":", "str", "=", "\"test\"", ",", "ylabel", ":", "str", "=", "\"test\"", ",", "\n", "file_name", ":", "str", "=", "\"test.eps\"", ",", "xlims", ":", "Union", "[", "float", ",", "float", "]", "=", "None", ",", "\n", "ylims", ":", "Union", "[", "float", ",", "float", "]", "=", "None", ",", "\n", "line1_label", "=", "\"Train\"", ",", "line2_label", "=", "\"Eval\"", ",", "legend_loc", "=", "'upper right'", ",", "\n", "markevery_1", "=", "5", ",", "markevery_2", "=", "5", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Plot two line plots with shaded error bars\n\n    :param x_1: x data of line 1\n    :param y_1: y data of line 1\n    :param x_2: x data of line 2\n    :param y_2: y data of line 2\n    :param stds_1: standard deviations of line 1\n    :param stds_2: standard deviations of line 2\n    :param title: plot title\n    :param xlabel: label on x axis\n    :param ylabel: label on y axis\n    :param file_name: name of file to save\n    :param xlims: limits on x axis\n    :param ylims: limits on y axis\n    :param line1_label: legend for line 1\n    :param line2_label: legend for line 2\n    :param legend_loc: location of the legend\n    :param markevery_1: marker frequency for line 1\n    :param markevery_2: marker frequency for line 2\n    :return:\n    \"\"\"", "\n", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "1", ",", "figsize", "=", "(", "8", ",", "3", ")", ")", "\n", "if", "xlims", "is", "None", ":", "\n", "        ", "xlims", "=", "(", "min", "(", "min", "(", "x_1", ")", ",", "min", "(", "x_2", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1", ")", ",", "max", "(", "x_2", ")", ")", ")", "\n", "", "if", "ylims", "is", "None", ":", "\n", "        ", "ylims", "=", "(", "min", "(", "min", "(", "y_1", "-", "stds_1", ")", ",", "min", "(", "y_2", "-", "stds_1", ")", ")", ",", "\n", "max", "(", "max", "(", "y_1", "+", "stds_1", ")", ",", "max", "(", "y_2", "+", "stds_1", ")", ")", ")", "\n", "\n", "", "ax", ".", "plot", "(", "x_1", ",", "y_1", ",", "label", "=", "line1_label", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "markevery", "=", "markevery_1", ")", "\n", "ax", ".", "fill_between", "(", "x_1", ",", "y_1", "-", "stds_1", ",", "y_1", "+", "stds_1", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", ".", "plot", "(", "x_2", ",", "y_2", ",", "label", "=", "line2_label", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "markevery", "=", "markevery_2", ")", "\n", "ax", ".", "fill_between", "(", "x_2", ",", "y_2", "-", "stds_2", ",", "y_2", "+", "stds_2", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", ".", "set_xlim", "(", "xlims", ")", "\n", "#ax.set_ylim(ylims)", "\n", "\n", "ax", ".", "set_title", "(", "title", ")", "\n", "ax", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# xlab.set_style('italic')", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "# ylab.set_style('italic')", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "plt", ".", "legend", "(", "loc", "=", "legend_loc", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.three_line_plot_w_shades": [[621, 703], ["matplotlib.rc", "matplotlib.rc", "matplotlib.subplots", "ax.plot", "ax.fill_between", "ax.plot", "ax.fill_between", "ax.plot", "ax.fill_between", "ax.set_xlim", "ax.set_title", "ax.set_xlabel", "ax.set_ylabel", "ax.grid", "ax.xaxis.get_label", "ax.yaxis.get_label", "ax.xaxis.get_label.set_size", "ax.yaxis.get_label.set_size", "ax.spines[].set_color", "ax.spines[].set_color", "matplotlib.legend", "fig.tight_layout", "fig.savefig", "fig.savefig", "matplotlib.close", "min", "max", "min", "max", "min", "min", "min", "max", "max", "max", "min", "min", "min", "max", "max", "max"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "three_line_plot_w_shades", "(", "x_1", ":", "np", ".", "ndarray", ",", "y_1", ":", "np", ".", "ndarray", ",", "\n", "x_2", ":", "np", ".", "ndarray", ",", "y_2", ":", "np", ".", "ndarray", ",", "\n", "x_3", ":", "np", ".", "ndarray", ",", "y_3", ":", "np", ".", "ndarray", ",", "\n", "stds_1", ",", "stds_2", ",", "stds_3", ",", "\n", "title", ":", "str", "=", "\"Test\"", ",", "xlabel", ":", "str", "=", "\"test\"", ",", "ylabel", ":", "str", "=", "\"test\"", ",", "\n", "file_name", ":", "str", "=", "\"test.eps\"", ",", "xlims", ":", "Union", "[", "float", ",", "float", "]", "=", "None", ",", "\n", "ylims", ":", "Union", "[", "float", ",", "float", "]", "=", "None", ",", "\n", "line1_label", "=", "\"Train\"", ",", "line2_label", "=", "\"Eval\"", ",", "line3_label", "=", "\"Eval\"", ",", "legend_loc", "=", "'upper right'", ",", "\n", "markevery_1", "=", "5", ",", "markevery_2", "=", "5", ",", "markevery_3", "=", "5", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Plot two line plots with shaded error bars\n\n    :param x_1: x data of line 1\n    :param y_1: y data of line 1\n    :param x_2: x data of line 2\n    :param y_2: y data of line 2\n    :param x_3: x data of line 3\n    :param y_3: y data of line 3\n    :param stds_1: standard deviations of line 1\n    :param stds_2: standard deviations of line 2\n    :param stds_3: standard deviations of line 3\n    :param title: plot title\n    :param xlabel: label on x axis\n    :param ylabel: label on y axis\n    :param file_name: name of file to save\n    :param xlims: limits on x axis\n    :param ylims: limits on y axis\n    :param line1_label: legend for line 1\n    :param line2_label: legend for line 2\n    :param legend_loc: location of the legend\n    :param markevery_1: marker frequency for line 1\n    :param markevery_2: marker frequency for line 2\n    :param markevery_3: marker frequency for line 3\n    :return:\n    \"\"\"", "\n", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "1", ",", "figsize", "=", "(", "8", ",", "3", ")", ")", "\n", "if", "xlims", "is", "None", ":", "\n", "        ", "xlims", "=", "(", "min", "(", "min", "(", "x_1", ")", ",", "min", "(", "x_2", ")", ",", "min", "(", "x_3", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1", ")", ",", "max", "(", "x_2", ")", ",", "max", "(", "x_3", ")", ")", ")", "\n", "", "if", "ylims", "is", "None", ":", "\n", "        ", "ylims", "=", "(", "min", "(", "min", "(", "y_1", "-", "stds_2", ")", ",", "min", "(", "y_2", "-", "stds_2", ")", ",", "min", "(", "y_3", "-", "stds_3", ")", ")", ",", "\n", "max", "(", "max", "(", "y_1", "+", "stds_1", ")", ",", "max", "(", "y_2", "+", "stds_2", ")", ",", "max", "(", "y_3", "+", "stds_3", ")", ")", ")", "\n", "\n", "", "ax", ".", "plot", "(", "x_1", ",", "y_1", ",", "label", "=", "line1_label", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "markevery", "=", "markevery_1", ")", "\n", "ax", ".", "fill_between", "(", "x_1", ",", "y_1", "-", "stds_1", ",", "y_1", "+", "stds_1", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", ".", "plot", "(", "x_2", ",", "y_2", ",", "label", "=", "line2_label", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "markevery", "=", "markevery_2", ")", "\n", "ax", ".", "fill_between", "(", "x_2", ",", "y_2", "-", "stds_2", ",", "y_2", "+", "stds_2", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", ".", "plot", "(", "x_3", ",", "y_3", ",", "label", "=", "line3_label", ",", "marker", "=", "\"p\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#9e66ab'", ",", "markevery", "=", "markevery_3", ")", "\n", "ax", ".", "fill_between", "(", "x_3", ",", "y_3", "-", "stds_3", ",", "y_3", "+", "stds_3", ",", "alpha", "=", "0.35", ",", "color", "=", "'#9e66ab'", ")", "\n", "\n", "ax", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax.set_ylim(ylims)", "\n", "\n", "ax", ".", "set_title", "(", "title", ")", "\n", "ax", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# xlab.set_style('italic')", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "# ylab.set_style('italic')", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "plt", ".", "legend", "(", "loc", "=", "legend_loc", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.one_line_plot_w_shades": [[705, 770], ["matplotlib.rc", "matplotlib.rc", "matplotlib.subplots", "ax.plot", "ax.fill_between", "ax.set_xlim", "ax.set_title", "ax.set_xlabel", "ax.set_ylabel", "ax.grid", "ax.xaxis.get_label", "ax.yaxis.get_label", "ax.xaxis.get_label.set_size", "ax.yaxis.get_label.set_size", "ax.spines[].set_color", "ax.spines[].set_color", "matplotlib.legend", "fig.tight_layout", "fig.savefig", "fig.savefig", "matplotlib.close", "min", "max", "min", "max"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "one_line_plot_w_shades", "(", "x_1", ":", "np", ".", "ndarray", ",", "y_1", ":", "np", ".", "ndarray", ",", "\n", "stds_1", ",", "title", ":", "str", "=", "\"Test\"", ",", "xlabel", ":", "str", "=", "\"test\"", ",", "ylabel", ":", "str", "=", "\"test\"", ",", "\n", "file_name", ":", "str", "=", "\"test.eps\"", ",", "xlims", ":", "Union", "[", "float", ",", "float", "]", "=", "None", ",", "\n", "ylims", ":", "Union", "[", "float", ",", "float", "]", "=", "None", ",", "\n", "line1_label", "=", "\"Train\"", ",", "legend_loc", "=", "'upper right'", ",", "\n", "markevery_1", "=", "5", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Plot two line plots with shaded error bars\n\n    :param x_1: x data of line 1\n    :param y_1: y data of line 1\n    :param stds_1: standard deviations of line 1\n    :param title: plot title\n    :param xlabel: label on x axis\n    :param ylabel: label on y axis\n    :param file_name: name of file to save\n    :param xlims: limits on x axis\n    :param ylims: limits on y axis\n    :param line1_label: legend for line 1\n    :param line2_label: legend for line 2\n    :param legend_loc: location of the legend\n    :param markevery_1: marker frequency for line 1\n    :return:\n    \"\"\"", "\n", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "1", ",", "figsize", "=", "(", "8", ",", "3", ")", ")", "\n", "if", "xlims", "is", "None", ":", "\n", "        ", "xlims", "=", "(", "min", "(", "x_1", ")", ",", "\n", "max", "(", "x_1", ")", ")", "\n", "", "if", "ylims", "is", "None", ":", "\n", "        ", "ylims", "=", "(", "min", "(", "y_1", "-", "stds_1", ")", ",", "\n", "max", "(", "y_1", "+", "stds_1", ")", ")", "\n", "\n", "", "ax", ".", "plot", "(", "x_1", ",", "y_1", ",", "label", "=", "line1_label", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "markevery", "=", "markevery_1", ")", "\n", "ax", ".", "fill_between", "(", "x_1", ",", "y_1", "-", "stds_1", ",", "y_1", "+", "stds_1", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax.set_ylim(ylims)", "\n", "\n", "ax", ".", "set_title", "(", "title", ")", "\n", "ax", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# xlab.set_style('italic')", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "# ylab.set_style('italic')", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "plt", ".", "legend", "(", "loc", "=", "legend_loc", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.five_line_plot_w_shades": [[772, 848], ["matplotlib.rc", "matplotlib.rc", "matplotlib.subplots", "ax.plot", "ax.fill_between", "ax.plot", "ax.fill_between", "ax.plot", "ax.fill_between", "ax.plot", "ax.fill_between", "ax.plot", "ax.fill_between", "ax.set_xlim", "ax.set_title", "ax.set_xlabel", "ax.set_ylabel", "ax.grid", "ax.xaxis.get_label", "ax.yaxis.get_label", "ax.xaxis.get_label.set_size", "ax.yaxis.get_label.set_size", "ax.spines[].set_color", "ax.spines[].set_color", "ax.get_position", "ax.set_position", "ax.legend", "fig.tight_layout", "fig.savefig", "fig.savefig", "matplotlib.close", "min", "max", "min", "max", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "five_line_plot_w_shades", "(", "x_1", ":", "np", ".", "ndarray", ",", "y_1", ":", "np", ".", "ndarray", ",", "\n", "x_2", ":", "np", ".", "ndarray", ",", "y_2", ":", "np", ".", "ndarray", ",", "\n", "x_3", ":", "np", ".", "ndarray", ",", "y_3", ":", "np", ".", "ndarray", ",", "\n", "x_4", ":", "np", ".", "ndarray", ",", "y_4", ":", "np", ".", "ndarray", ",", "\n", "x_5", ":", "np", ".", "ndarray", ",", "y_5", ":", "np", ".", "ndarray", ",", "\n", "stds_1", ",", "stds_2", ",", "stds_3", ",", "stds_4", ",", "stds_5", ",", "\n", "title", ":", "str", "=", "\"Test\"", ",", "xlabel", ":", "str", "=", "\"test\"", ",", "ylabel", ":", "str", "=", "\"test\"", ",", "\n", "file_name", ":", "str", "=", "\"test.eps\"", ",", "xlims", ":", "Union", "[", "float", ",", "float", "]", "=", "None", ",", "\n", "ylims", ":", "Union", "[", "float", ",", "float", "]", "=", "None", ",", "\n", "line1_label", "=", "\"Train\"", ",", "line2_label", "=", "\"Eval\"", ",", "line3_label", "=", "\"Eval\"", ",", "\n", "line4_label", "=", "\"Eval\"", ",", "line5_label", "=", "\"Eval\"", ",", "\n", "legend_loc", "=", "'upper right'", ",", "\n", "markevery_1", "=", "5", ",", "markevery_2", "=", "5", ",", "markevery_3", "=", "5", ",", "markevery_4", "=", "5", ",", "\n", "markevery_5", "=", "5", ")", "->", "None", ":", "\n", "    ", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "1", ",", "figsize", "=", "(", "8", ",", "4", ")", ")", "\n", "if", "xlims", "is", "None", ":", "\n", "        ", "xlims", "=", "(", "min", "(", "min", "(", "x_1", ")", ",", "min", "(", "x_2", ")", ",", "min", "(", "x_3", ")", ",", "min", "(", "x_4", ")", ",", "min", "(", "x_5", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1", ")", ",", "max", "(", "x_2", ")", ",", "max", "(", "x_3", ")", ",", "max", "(", "x_4", ")", ",", "max", "(", "x_5", ")", ")", ")", "\n", "", "if", "ylims", "is", "None", ":", "\n", "        ", "ylims", "=", "(", "min", "(", "min", "(", "y_1", ")", ",", "min", "(", "y_2", ")", ",", "min", "(", "y_3", ")", ",", "min", "(", "y_4", ")", ",", "min", "(", "y_5", ")", ")", ",", "\n", "max", "(", "max", "(", "y_1", ")", ",", "max", "(", "y_2", ")", ",", "max", "(", "y_3", ")", ",", "max", "(", "y_4", ")", ",", "max", "(", "y_5", ")", ")", ")", "\n", "\n", "", "ax", ".", "plot", "(", "x_1", ",", "y_1", ",", "label", "=", "line1_label", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "markevery", "=", "markevery_1", ")", "\n", "ax", ".", "fill_between", "(", "x_1", ",", "y_1", "-", "stds_1", ",", "y_1", "+", "stds_1", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", ".", "plot", "(", "x_2", ",", "y_2", ",", "label", "=", "line2_label", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "markevery", "=", "markevery_2", ")", "\n", "ax", ".", "fill_between", "(", "x_2", ",", "y_2", "-", "stds_2", ",", "y_2", "+", "stds_2", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", ".", "plot", "(", "x_3", ",", "y_3", ",", "label", "=", "line3_label", ",", "marker", "=", "\"p\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#9e66ab\"", ",", "markevery", "=", "markevery_3", ")", "\n", "ax", ".", "fill_between", "(", "x_3", ",", "y_3", "-", "stds_3", ",", "y_3", "+", "stds_3", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#9e66ab\"", ")", "\n", "\n", "ax", ".", "plot", "(", "x_4", ",", "y_4", ",", "label", "=", "line4_label", ",", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "'g'", ",", "markevery", "=", "markevery_4", ")", "\n", "ax", ".", "fill_between", "(", "x_4", ",", "y_4", "-", "stds_4", ",", "y_4", "+", "stds_4", ",", "alpha", "=", "0.35", ",", "color", "=", "'g'", ")", "\n", "\n", "ax", ".", "plot", "(", "x_5", ",", "y_5", ",", "label", "=", "line5_label", ",", "marker", "=", "\"^\"", ",", "ls", "=", "'-'", ",", "color", "=", "'r'", ",", "markevery", "=", "markevery_5", ")", "\n", "ax", ".", "fill_between", "(", "x_5", ",", "y_5", "-", "stds_5", ",", "y_5", "+", "stds_5", ",", "alpha", "=", "0.35", ",", "color", "=", "'r'", ")", "\n", "\n", "ax", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax.set_ylim(ylims)", "\n", "\n", "ax", ".", "set_title", "(", "title", ")", "\n", "ax", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# xlab.set_style('italic')", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "# ylab.set_style('italic')", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# plt.legend(loc=legend_loc)", "\n", "\n", "# Shrink current axis's height by 10% on the bottom", "\n", "box", "=", "ax", ".", "get_position", "(", ")", "\n", "ax", ".", "set_position", "(", "[", "box", ".", "x0", ",", "box", ".", "y0", "+", "box", ".", "height", "*", "0.05", ",", "\n", "box", ".", "width", ",", "box", ".", "height", "*", "0.95", "]", ")", "\n", "\n", "# Put a legend below current axis", "\n", "ax", ".", "legend", "(", "loc", "=", "'upper center'", ",", "bbox_to_anchor", "=", "(", "0.5", ",", "-", "0.2", ")", ",", "\n", "fancybox", "=", "True", ",", "shadow", "=", "True", ",", "ncol", "=", "2", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_hist_prob_attack_stats": [[850, 908], ["matplotlib.rc", "matplotlib.rc", "set", "numpy.array", "list", "list", "matplotlib.subplots", "range", "ax.set_ylabel", "ax.set_title", "ax.set_xticks", "ax.set_xticklabels", "matplotlib.xlim", "ax.legend", "matplotlib.grid", "fig.tight_layout", "fig.savefig", "fig.savefig", "matplotlib.close", "len", "len", "np.array.append", "range", "range", "labels.append", "matplotlib.bar", "len", "len", "min", "max", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "plot_hist_prob_attack_stats", "(", "stats_df", ",", "file_name", ")", ":", "\n", "    ", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "cat_1", "=", "\"successful attack\"", "\n", "cat_2", "=", "\"blocked attack\"", "\n", "nodes", "=", "set", "(", "stats_df", "[", "\"target_node\"", "]", ")", "\n", "plot_data", "=", "[", "]", "\n", "for", "node", "in", "nodes", ":", "\n", "        ", "data", "=", "stats_df", ".", "loc", "[", "stats_df", "[", "'target_node'", "]", "==", "node", "]", "\n", "total_len", "=", "len", "(", "data", ".", "values", ")", "\n", "num_success", "=", "len", "(", "data", ".", "loc", "[", "data", "[", "'attack_outcome'", "]", "==", "True", "]", ".", "values", ")", "\n", "emp_success_p", "=", "0.0", "\n", "if", "total_len", ">", "0", ":", "\n", "            ", "emp_success_p", "=", "num_success", "/", "total_len", "\n", "", "emp_blocked_p", "=", "1", "-", "emp_success_p", "\n", "plot_data", ".", "append", "(", "[", "emp_success_p", ",", "emp_blocked_p", "]", ")", "\n", "", "plot_data", "=", "np", ".", "array", "(", "plot_data", ")", "\n", "\n", "width", "=", "0.25", "\n", "\n", "nodes", "=", "list", "(", "range", "(", "len", "(", "plot_data", ")", ")", ")", "\n", "pos", "=", "list", "(", "range", "(", "len", "(", "nodes", ")", ")", ")", "\n", "\n", "labels", "=", "[", "]", "\n", "for", "node", "in", "nodes", ":", "\n", "        ", "labels", ".", "append", "(", "\"node \"", "+", "str", "(", "node", ")", ")", "\n", "\n", "", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "figsize", "=", "(", "10", ",", "5", ")", ")", "\n", "\n", "for", "cat", "in", "range", "(", "2", ")", ":", "\n", "        ", "plt", ".", "bar", "(", "[", "p", "+", "width", "*", "cat", "for", "p", "in", "pos", "]", ",", "\n", "plot_data", "[", ":", ",", "cat", "]", ",", "\n", "width", ",", "\n", "alpha", "=", "0.5", ")", "\n", "\n", "# Set the y axis label", "\n", "", "ax", ".", "set_ylabel", "(", "r'Empirical $\\mathbb{P}$'", ")", "\n", "\n", "# Set the chart's title", "\n", "ax", ".", "set_title", "(", "'Attack success rates'", ")", "\n", "\n", "# Set the position of the x ticks", "\n", "ax", ".", "set_xticks", "(", "[", "p", "+", "1.5", "*", "width", "for", "p", "in", "pos", "]", ")", "\n", "\n", "# Set the labels for the x ticks", "\n", "ax", ".", "set_xticklabels", "(", "labels", ")", "\n", "\n", "# Setting the x-axis and y-axis limits", "\n", "plt", ".", "xlim", "(", "min", "(", "pos", ")", "-", "width", ",", "max", "(", "pos", ")", "+", "width", "*", "4", ")", "\n", "\n", "ax", ".", "legend", "(", "[", "cat_1", ",", "cat_2", "]", ",", "loc", "=", "'upper center'", ",", "bbox_to_anchor", "=", "(", "0.5", ",", "-", "0.1", ")", ",", "\n", "fancybox", "=", "True", ",", "shadow", "=", "True", ",", "ncol", "=", "2", ")", "\n", "\n", "plt", ".", "grid", "(", ")", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_avg_summary_1": [[909, 1141], ["matplotlib.rc", "matplotlib.rc", "hack_prob_ax1.plot", "hack_prob_ax1.fill_between", "hack_prob_ax1.plot", "hack_prob_ax1.fill_between", "hack_prob_ax1.plot", "hack_prob_ax1.fill_between", "hack_prob_ax1.plot", "hack_prob_ax1.fill_between", "hack_prob_ax1.plot", "hack_prob_ax1.fill_between", "hack_prob_ax1.set_xlim", "hack_prob_ax1.set_title", "hack_prob_ax1.set_xlabel", "hack_prob_ax1.set_ylabel", "hack_prob_ax1.grid", "hack_prob_ax1.spines[].set_color", "hack_prob_ax1.spines[].set_color", "hack_prob_ax2.plot", "hack_prob_ax2.fill_between", "hack_prob_ax2.plot", "hack_prob_ax2.fill_between", "hack_prob_ax2.plot", "hack_prob_ax2.fill_between", "hack_prob_ax2.plot", "hack_prob_ax2.fill_between", "hack_prob_ax2.plot", "hack_prob_ax2.fill_between", "hack_prob_ax2.set_xlim", "hack_prob_ax2.set_title", "hack_prob_ax2.set_xlabel", "hack_prob_ax2.set_ylabel", "hack_prob_ax2.grid", "hack_prob_ax2.spines[].set_color", "hack_prob_ax2.spines[].set_color", "hack_prob_ax2.get_position", "hack_prob_ax2.set_position", "hack_prob_ax3.plot", "hack_prob_ax3.fill_between", "hack_prob_ax3.plot", "hack_prob_ax3.fill_between", "hack_prob_ax3.plot", "hack_prob_ax3.fill_between", "hack_prob_ax3.plot", "hack_prob_ax3.fill_between", "hack_prob_ax3.plot", "hack_prob_ax3.fill_between", "hack_prob_ax3.set_xlim", "hack_prob_ax3.set_title", "hack_prob_ax3.set_xlabel", "hack_prob_ax3.set_ylabel", "hack_prob_ax3.grid", "hack_prob_ax3.spines[].set_color", "hack_prob_ax3.spines[].set_color", "hack_prob_ax3.get_position", "hack_prob_ax3.set_position", "hack_prob_ax3.get_yaxis().set_major_formatter", "fig.tight_layout", "matplotlib.subplots_adjust", "fig.savefig", "fig.savefig", "matplotlib.subplots", "matplotlib.subplots", "min", "max", "min", "max", "min", "max", "min", "max", "matplotlib.FuncFormatter", "hack_prob_ax3.legend", "hack_prob_ax3.legend", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].spines[].set_color", "[].spines[].set_color", "fig.subplots_adjust", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "hack_prob_ax3.get_yaxis", "min", "max", "min", "max", "min", "max", "min", "max", "min", "min", "min", "max", "max", "max", "min", "min", "min", "max", "max", "max", "min", "min", "min", "max", "max", "max", "min", "min", "max", "max"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot"], ["", "def", "plot_all_avg_summary_1", "(", "x_1_1", ",", "y_1_1", ",", "x_1_2", ",", "y_1_2", ",", "x_1_3", ",", "y_1_3", ",", "x_1_4", ",", "y_1_4", ",", "x_1_5", ",", "y_1_5", ",", "\n", "std_1_1", ",", "std_1_2", ",", "std_1_3", ",", "std_1_4", ",", "std_1_5", ",", "\n", "line_1_1_label", ",", "line_1_2_label", ",", "line_1_3_label", ",", "line_1_4_label", ",", "\n", "line_1_5_label", ",", "title_1", ",", "xlabel_1", ",", "ylabel_1", ",", "\n", "markevery_1_1", ",", "markevery_1_2", ",", "markevery_1_3", ",", "markevery_1_4", ",", "markevery_1_5", ",", "\n", "x_2_1", ",", "y_2_1", ",", "x_2_2", ",", "y_2_2", ",", "x_2_3", ",", "y_2_3", ",", "x_2_4", ",", "y_2_4", ",", "x_2_5", ",", "y_2_5", ",", "\n", "std_2_1", ",", "std_2_2", ",", "std_2_3", ",", "std_2_4", ",", "std_2_5", ",", "\n", "line_2_1_label", ",", "line_2_2_label", ",", "line_2_3_label", ",", "line_2_4_label", ",", "\n", "line_2_5_label", ",", "title_2", ",", "xlabel_2", ",", "ylabel_2", ",", "\n", "markevery_2_1", ",", "markevery_2_2", ",", "markevery_2_3", ",", "markevery_2_4", ",", "markevery_2_5", ",", "\n", "x_3_1", ",", "y_3_1", ",", "x_3_2", ",", "y_3_2", ",", "x_3_3", ",", "y_3_3", ",", "x_3_4", ",", "y_3_4", ",", "x_3_5", ",", "y_3_5", ",", "\n", "std_3_1", ",", "std_3_2", ",", "std_3_3", ",", "std_3_4", ",", "std_3_5", ",", "\n", "line_3_1_label", ",", "line_3_2_label", ",", "line_3_3_label", ",", "line_3_4_label", ",", "\n", "line_3_5_label", ",", "title_3", ",", "xlabel_3", ",", "ylabel_3", ",", "\n", "markevery_3_1", ",", "markevery_3_2", ",", "markevery_3_3", ",", "markevery_3_4", ",", "markevery_3_5", ",", "\n", "\n", "x_4_1", ",", "y_4_1", ",", "x_4_2", ",", "y_4_2", ",", "x_4_3", ",", "y_4_3", ",", "\n", "std_4_1", ",", "std_4_2", ",", "std_4_3", ",", "\n", "line_4_1_label", ",", "line_4_2_label", ",", "line_4_3_label", ",", "\n", "title_4", ",", "xlabel_4", ",", "ylabel_4", ",", "\n", "markevery_4_1", ",", "markevery_4_2", ",", "markevery_4_3", ",", "\n", "\n", "x_5_1", ",", "y_5_1", ",", "x_5_2", ",", "y_5_2", ",", "x_5_3", ",", "y_5_3", ",", "\n", "std_5_1", ",", "std_5_2", ",", "std_5_3", ",", "\n", "line_5_1_label", ",", "line_5_2_label", ",", "line_5_3_label", ",", "\n", "title_5", ",", "xlabel_5", ",", "ylabel_5", ",", "\n", "markevery_5_1", ",", "markevery_5_2", ",", "markevery_5_3", ",", "\n", "\n", "file_name", ",", "plot_loss", "=", "False", "\n", ")", ":", "\n", "    ", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "if", "plot_loss", ":", "\n", "        ", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "2", ",", "ncols", "=", "3", ",", "figsize", "=", "(", "11", ",", "5.5", ")", ")", "\n", "", "else", ":", "\n", "        ", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "3", ",", "figsize", "=", "(", "11", ",", "2.75", ")", ")", "\n", "#gs1 = gridspec.GridSpec(1, 4)", "\n", "#gs1.update(wspace=0.005, hspace=0.05)", "\n", "\n", "# Plot avg hack_probability train", "\n", "", "xlims", "=", "(", "min", "(", "min", "(", "x_1_1", ")", ",", "min", "(", "x_1_2", ")", ",", "min", "(", "x_1_3", ")", ",", "min", "(", "x_1_4", ")", ",", "min", "(", "x_1_5", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1_1", ")", ",", "max", "(", "x_1_2", ")", ",", "max", "(", "x_1_3", ")", ",", "max", "(", "x_1_4", ")", ",", "max", "(", "x_1_5", ")", ")", ")", "\n", "ylims", "=", "(", "0", ",", "1", ")", "\n", "\n", "if", "plot_loss", ":", "\n", "        ", "hack_prob_ax1", "=", "ax", "[", "0", "]", "[", "0", "]", "\n", "hack_prob_ax2", "=", "ax", "[", "0", "]", "[", "1", "]", "\n", "hack_prob_ax3", "=", "ax", "[", "0", "]", "[", "2", "]", "\n", "", "else", ":", "\n", "        ", "hack_prob_ax1", "=", "ax", "[", "0", "]", "\n", "hack_prob_ax2", "=", "ax", "[", "1", "]", "\n", "hack_prob_ax3", "=", "ax", "[", "2", "]", "\n", "\n", "", "hack_prob_ax1", ".", "plot", "(", "x_1_1", ",", "y_1_1", ",", "label", "=", "line_1_1_label", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "markevery", "=", "markevery_1_1", ")", "\n", "hack_prob_ax1", ".", "fill_between", "(", "x_1_1", ",", "y_1_1", "-", "std_1_1", ",", "y_1_1", "+", "std_1_1", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "hack_prob_ax1", ".", "plot", "(", "x_1_2", ",", "y_1_2", ",", "label", "=", "line_1_2_label", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "markevery", "=", "markevery_1_2", ")", "\n", "hack_prob_ax1", ".", "fill_between", "(", "x_1_2", ",", "y_1_2", "-", "std_1_2", ",", "y_1_2", "+", "std_1_2", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "hack_prob_ax1", ".", "plot", "(", "x_1_3", ",", "y_1_3", ",", "label", "=", "line_1_3_label", ",", "marker", "=", "\"p\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#9e66ab\"", ",", "markevery", "=", "markevery_1_3", ")", "\n", "hack_prob_ax1", ".", "fill_between", "(", "x_1_3", ",", "y_1_3", "-", "std_1_3", ",", "y_1_3", "+", "std_1_3", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#9e66ab\"", ")", "\n", "\n", "hack_prob_ax1", ".", "plot", "(", "x_1_4", ",", "y_1_4", ",", "label", "=", "line_1_4_label", ",", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "'g'", ",", "markevery", "=", "markevery_1_4", ")", "\n", "hack_prob_ax1", ".", "fill_between", "(", "x_1_4", ",", "y_1_4", "-", "std_1_4", ",", "y_1_4", "+", "std_1_4", ",", "alpha", "=", "0.35", ",", "color", "=", "'g'", ")", "\n", "\n", "hack_prob_ax1", ".", "plot", "(", "x_1_5", ",", "y_1_5", ",", "label", "=", "line_1_5_label", ",", "marker", "=", "\"^\"", ",", "ls", "=", "'-'", ",", "color", "=", "'r'", ",", "markevery", "=", "markevery_1_5", ")", "\n", "hack_prob_ax1", ".", "fill_between", "(", "x_1_5", ",", "y_1_5", "-", "std_1_5", ",", "y_1_5", "+", "std_1_5", ",", "alpha", "=", "0.35", ",", "color", "=", "'r'", ")", "\n", "\n", "hack_prob_ax1", ".", "set_xlim", "(", "xlims", ")", "\n", "# hack_prob_ax1.set_ylim(ylims)", "\n", "\n", "hack_prob_ax1", ".", "set_title", "(", "title_1", ")", "\n", "hack_prob_ax1", ".", "set_xlabel", "(", "xlabel_1", ")", "\n", "hack_prob_ax1", ".", "set_ylabel", "(", "ylabel_1", ")", "\n", "# set the grid on", "\n", "hack_prob_ax1", ".", "grid", "(", "'on'", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "hack_prob_ax1", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "hack_prob_ax1", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# Plot avg hack_probability eval", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_2_1", ")", ",", "min", "(", "x_2_2", ")", ",", "min", "(", "x_2_3", ")", ",", "min", "(", "x_2_4", ")", ",", "min", "(", "x_2_5", ")", ")", ",", "\n", "max", "(", "max", "(", "x_2_1", ")", ",", "max", "(", "x_2_2", ")", ",", "max", "(", "x_2_3", ")", ",", "max", "(", "x_2_4", ")", ",", "max", "(", "x_2_5", ")", ")", ")", "\n", "ylims", "=", "(", "0", ",", "1", ")", "\n", "\n", "hack_prob_ax2", ".", "plot", "(", "x_2_1", ",", "y_2_1", ",", "label", "=", "line_2_1_label", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "markevery", "=", "markevery_2_1", ")", "\n", "hack_prob_ax2", ".", "fill_between", "(", "x_2_1", ",", "y_2_1", "-", "std_2_1", ",", "y_2_1", "+", "std_2_1", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "hack_prob_ax2", ".", "plot", "(", "x_2_2", ",", "y_2_2", ",", "label", "=", "line_2_2_label", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "markevery", "=", "markevery_2_2", ")", "\n", "hack_prob_ax2", ".", "fill_between", "(", "x_2_2", ",", "y_2_2", "-", "std_2_2", ",", "y_2_2", "+", "std_2_2", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "hack_prob_ax2", ".", "plot", "(", "x_2_3", ",", "y_2_3", ",", "label", "=", "line_2_3_label", ",", "marker", "=", "\"p\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#9e66ab\"", ",", "markevery", "=", "markevery_2_3", ")", "\n", "hack_prob_ax2", ".", "fill_between", "(", "x_2_3", ",", "y_2_3", "-", "std_2_3", ",", "y_2_3", "+", "std_2_3", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#9e66ab\"", ")", "\n", "\n", "hack_prob_ax2", ".", "plot", "(", "x_2_4", ",", "y_2_4", ",", "label", "=", "line_2_4_label", ",", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "'g'", ",", "markevery", "=", "markevery_2_4", ")", "\n", "hack_prob_ax2", ".", "fill_between", "(", "x_2_4", ",", "y_2_4", "-", "std_2_4", ",", "y_2_4", "+", "std_2_4", ",", "alpha", "=", "0.35", ",", "color", "=", "'g'", ")", "\n", "\n", "hack_prob_ax2", ".", "plot", "(", "x_2_5", ",", "y_2_5", ",", "label", "=", "line_2_5_label", ",", "marker", "=", "\"^\"", ",", "ls", "=", "'-'", ",", "color", "=", "'r'", ",", "markevery", "=", "markevery_2_5", ")", "\n", "hack_prob_ax2", ".", "fill_between", "(", "x_2_5", ",", "y_2_5", "-", "std_2_5", ",", "y_2_5", "+", "std_2_5", ",", "alpha", "=", "0.35", ",", "color", "=", "'r'", ")", "\n", "\n", "hack_prob_ax2", ".", "set_xlim", "(", "xlims", ")", "\n", "# hack_prob_ax2.set_ylim(ylims)", "\n", "\n", "hack_prob_ax2", ".", "set_title", "(", "title_2", ")", "\n", "hack_prob_ax2", ".", "set_xlabel", "(", "xlabel_2", ")", "\n", "hack_prob_ax2", ".", "set_ylabel", "(", "ylabel_2", ")", "\n", "# set the grid on", "\n", "hack_prob_ax2", ".", "grid", "(", "'on'", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "hack_prob_ax2", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "hack_prob_ax2", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# plt.legend(loc=legend_loc)", "\n", "\n", "# Shrink current axis's height by 10% on the bottom", "\n", "box", "=", "hack_prob_ax2", ".", "get_position", "(", ")", "\n", "hack_prob_ax2", ".", "set_position", "(", "[", "box", ".", "x0", ",", "box", ".", "y0", "+", "box", ".", "height", "*", "0.03", ",", "\n", "box", ".", "width", ",", "box", ".", "height", "*", "0.9", "]", ")", "\n", "\n", "# Plot attacker cumulative reward", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_3_1", ")", ",", "min", "(", "x_3_2", ")", ",", "min", "(", "x_3_3", ")", ",", "min", "(", "x_3_4", ")", ",", "min", "(", "x_3_5", ")", ")", ",", "\n", "max", "(", "max", "(", "x_3_1", ")", ",", "max", "(", "x_3_2", ")", ",", "max", "(", "x_3_3", ")", ",", "max", "(", "x_3_4", ")", ",", "max", "(", "x_3_5", ")", ")", ")", "\n", "ylims", "=", "(", "min", "(", "min", "(", "y_3_1", ")", ",", "min", "(", "y_3_2", ")", ",", "min", "(", "y_3_3", ")", ",", "min", "(", "y_3_4", ")", ",", "min", "(", "y_3_5", ")", ")", ",", "\n", "max", "(", "max", "(", "y_3_1", ")", ",", "max", "(", "y_3_2", ")", ",", "max", "(", "y_3_3", ")", ",", "max", "(", "y_3_4", ")", ",", "max", "(", "y_3_5", ")", ")", ")", "\n", "\n", "hack_prob_ax3", ".", "plot", "(", "x_3_1", ",", "y_3_1", ",", "label", "=", "line_3_1_label", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "markevery", "=", "markevery_3_1", ")", "\n", "hack_prob_ax3", ".", "fill_between", "(", "x_3_1", ",", "y_3_1", "-", "std_3_1", ",", "y_3_1", "+", "std_3_1", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "hack_prob_ax3", ".", "plot", "(", "x_3_2", ",", "y_3_2", ",", "label", "=", "line_3_2_label", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "markevery", "=", "markevery_3_2", ")", "\n", "hack_prob_ax3", ".", "fill_between", "(", "x_3_2", ",", "y_3_2", "-", "std_3_2", ",", "y_3_2", "+", "std_3_2", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "hack_prob_ax3", ".", "plot", "(", "x_3_3", ",", "y_3_3", ",", "label", "=", "line_3_3_label", ",", "marker", "=", "\"p\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#9e66ab\"", ",", "markevery", "=", "markevery_3_3", ")", "\n", "hack_prob_ax3", ".", "fill_between", "(", "x_3_3", ",", "y_3_3", "-", "std_3_3", ",", "y_3_3", "+", "std_3_3", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#9e66ab\"", ")", "\n", "\n", "hack_prob_ax3", ".", "plot", "(", "x_3_4", ",", "y_3_4", ",", "label", "=", "line_3_4_label", ",", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "'g'", ",", "markevery", "=", "markevery_3_4", ")", "\n", "hack_prob_ax3", ".", "fill_between", "(", "x_3_4", ",", "y_3_4", "-", "std_3_4", ",", "y_3_4", "+", "std_3_4", ",", "alpha", "=", "0.35", ",", "color", "=", "'g'", ")", "\n", "\n", "hack_prob_ax3", ".", "plot", "(", "x_3_5", ",", "y_3_5", ",", "label", "=", "line_3_5_label", ",", "marker", "=", "\"^\"", ",", "ls", "=", "'-'", ",", "color", "=", "'r'", ",", "markevery", "=", "markevery_3_5", ")", "\n", "hack_prob_ax3", ".", "fill_between", "(", "x_3_5", ",", "y_3_5", "-", "std_3_5", ",", "y_3_5", "+", "std_3_5", ",", "alpha", "=", "0.35", ",", "color", "=", "'r'", ")", "\n", "\n", "hack_prob_ax3", ".", "set_xlim", "(", "xlims", ")", "\n", "# hack_prob_ax3.set_ylim(ylims)", "\n", "\n", "hack_prob_ax3", ".", "set_title", "(", "title_3", ")", "\n", "hack_prob_ax3", ".", "set_xlabel", "(", "xlabel_3", ")", "\n", "hack_prob_ax3", ".", "set_ylabel", "(", "ylabel_3", ")", "\n", "# set the grid on", "\n", "hack_prob_ax3", ".", "grid", "(", "'on'", ")", "\n", "\n", "hack_prob_ax3", ".", "yaxis", ".", "labelpad", "=", "-", "5", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "hack_prob_ax3", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "hack_prob_ax3", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# plt.legend(loc=legend_loc)", "\n", "\n", "# Shrink current axis's height by 10% on the bottom", "\n", "box", "=", "hack_prob_ax3", ".", "get_position", "(", ")", "\n", "hack_prob_ax3", ".", "set_position", "(", "[", "box", ".", "x0", ",", "box", ".", "y0", "+", "box", ".", "height", "*", "0.03", ",", "\n", "box", ".", "width", ",", "box", ".", "height", "*", "0.9", "]", ")", "\n", "\n", "hack_prob_ax3", ".", "get_yaxis", "(", ")", ".", "set_major_formatter", "(", "tkr", ".", "FuncFormatter", "(", "lambda", "x", ",", "p", ":", "\"${:1.0f}K$\"", ".", "format", "(", "x", "*", "1e-3", ")", ")", ")", "\n", "\n", "if", "not", "plot_loss", ":", "\n", "        ", "hack_prob_ax3", ".", "legend", "(", "loc", "=", "'upper center'", ",", "bbox_to_anchor", "=", "(", "-", "0.5", ",", "-", "0.35", ")", ",", "fancybox", "=", "True", ",", "shadow", "=", "True", ",", "ncol", "=", "3", ")", "\n", "", "else", ":", "\n", "        ", "hack_prob_ax3", ".", "legend", "(", "loc", "=", "'upper center'", ",", "bbox_to_anchor", "=", "(", "-", "0.7", ",", "-", "1.65", ")", ",", "fancybox", "=", "True", ",", "shadow", "=", "True", ",", "ncol", "=", "3", ")", "\n", "\n", "", "if", "plot_loss", ":", "\n", "        ", "xlims", "=", "(", "min", "(", "min", "(", "x_4_1", ")", ",", "min", "(", "x_4_2", ")", ",", "min", "(", "x_4_3", ")", ")", ",", "\n", "max", "(", "max", "(", "x_4_1", ")", ",", "max", "(", "x_4_2", ")", ",", "max", "(", "x_4_3", ")", ")", ")", "\n", "ylims", "=", "(", "min", "(", "min", "(", "y_4_1", "-", "std_4_1", ")", ",", "min", "(", "y_4_2", "-", "std_4_2", ")", ",", "min", "(", "y_4_3", "-", "std_4_3", ")", ")", ",", "\n", "max", "(", "max", "(", "y_4_1", "+", "std_4_1", ")", ",", "max", "(", "y_4_2", "+", "std_4_2", ")", ",", "max", "(", "y_4_3", "+", "std_4_3", ")", ")", ")", "\n", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "plot", "(", "x_4_1", ",", "y_4_1", ",", "label", "=", "line_4_1_label", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "markevery", "=", "markevery_4_1", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "fill_between", "(", "x_4_1", ",", "y_4_1", "-", "std_4_1", ",", "y_4_1", "+", "std_4_1", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "plot", "(", "x_4_2", ",", "y_4_2", ",", "label", "=", "line_4_2_label", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "markevery", "=", "markevery_4_2", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "fill_between", "(", "x_4_2", ",", "y_4_2", "-", "std_4_2", ",", "y_4_2", "+", "std_4_2", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "plot", "(", "x_4_3", ",", "y_4_3", ",", "label", "=", "line_4_3_label", ",", "marker", "=", "\"^\"", ",", "ls", "=", "'-'", ",", "color", "=", "'r'", ",", "markevery", "=", "markevery_4_3", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "fill_between", "(", "x_4_3", ",", "y_4_3", "-", "std_4_3", ",", "y_4_3", "+", "std_4_3", ",", "alpha", "=", "0.35", ",", "color", "=", "'r'", ")", "\n", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[1][0].set_ylim(ylims)", "\n", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_title", "(", "title_4", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_xlabel", "(", "xlabel_4", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_ylabel", "(", "ylabel_4", ")", "\n", "# set the grid on", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_5_1", ")", ",", "min", "(", "x_5_2", ")", ",", "min", "(", "x_5_3", ")", ")", ",", "\n", "max", "(", "max", "(", "x_5_1", ")", ",", "max", "(", "x_5_2", ")", ",", "max", "(", "x_5_3", ")", ")", ")", "\n", "ylims", "=", "(", "min", "(", "min", "(", "y_5_2", "-", "std_5_2", ")", ",", "min", "(", "y_5_3", "-", "std_5_3", ")", ")", ",", "\n", "max", "(", "max", "(", "y_5_2", "+", "std_5_2", ")", ",", "max", "(", "y_5_3", "+", "std_5_3", ")", ")", ")", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "plot", "(", "x_5_1", ",", "y_5_1", ",", "label", "=", "line_5_1_label", ",", "marker", "=", "\"p\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#9e66ab\"", ",", "markevery", "=", "markevery_5_1", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "fill_between", "(", "x_5_1", ",", "y_5_1", "-", "std_5_1", ",", "y_5_1", "+", "std_5_1", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#9e66ab\"", ")", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "plot", "(", "x_5_2", ",", "y_5_2", ",", "label", "=", "line_5_2_label", ",", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "'g'", ",", "markevery", "=", "markevery_5_2", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "fill_between", "(", "x_5_2", ",", "y_5_2", "-", "std_5_2", ",", "y_5_2", "+", "std_5_2", ",", "alpha", "=", "0.35", ",", "color", "=", "'g'", ")", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "plot", "(", "x_5_3", ",", "y_5_3", ",", "label", "=", "line_5_3_label", ",", "marker", "=", "\"^\"", ",", "ls", "=", "'-'", ",", "color", "=", "'r'", ",", "markevery", "=", "markevery_5_3", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "fill_between", "(", "x_5_3", ",", "y_5_3", "-", "std_5_3", ",", "y_5_3", "+", "std_5_3", ",", "alpha", "=", "0.35", ",", "color", "=", "'r'", ")", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[1][1].set_ylim(ylims)", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_title", "(", "title_5", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_xlabel", "(", "xlabel_5", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_ylabel", "(", "ylabel_5", ")", "\n", "# set the grid on", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "", "fig", ".", "tight_layout", "(", ")", "\n", "plt", ".", "subplots_adjust", "(", "wspace", "=", "0.2", ",", "hspace", "=", "0.4", ")", "\n", "if", "plot_loss", ":", "\n", "        ", "fig", ".", "subplots_adjust", "(", "bottom", "=", "0.2", ")", "\n", "", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_avg_summary_2": [[1144, 1342], ["matplotlib.rc", "matplotlib.rc", "matplotlib.subplots", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].set_xlim", "ax[].set_title", "ax[].set_xlabel", "ax[].set_ylabel", "ax[].grid", "ax[].xaxis.get_label", "ax[].yaxis.get_label", "ax[].spines[].set_color", "ax[].spines[].set_color", "fig.subplots_adjust", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].set_xlim", "ax[].set_title", "ax[].set_xlabel", "ax[].set_ylabel", "ax[].grid", "ax[].xaxis.get_label", "ax[].yaxis.get_label", "ax[].spines[].set_color", "ax[].spines[].set_color", "ax[].get_position", "ax[].set_position", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].set_xlim", "ax[].set_title", "ax[].set_xlabel", "ax[].set_ylabel", "ax[].grid", "ax[].spines[].set_color", "ax[].spines[].set_color", "ax[].legend", "fig.tight_layout", "matplotlib.subplots_adjust", "fig.subplots_adjust", "fig.savefig", "fig.savefig", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "len", "len", "len", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot"], ["", "def", "plot_all_avg_summary_2", "(", "x_1_1", ",", "y_1_1", ",", "x_1_2", ",", "y_1_2", ",", "x_1_3", ",", "y_1_3", ",", "x_1_4", ",", "y_1_4", ",", "x_1_5", ",", "y_1_5", ",", "\n", "std_1_1", ",", "std_1_2", ",", "std_1_3", ",", "std_1_4", ",", "std_1_5", ",", "\n", "line_1_1_label", ",", "line_1_2_label", ",", "line_1_3_label", ",", "line_1_4_label", ",", "\n", "line_1_5_label", ",", "title_1", ",", "xlabel_1", ",", "ylabel_1", ",", "\n", "markevery_1_1", ",", "markevery_1_2", ",", "markevery_1_3", ",", "markevery_1_4", ",", "markevery_1_5", ",", "\n", "x_2_1", ",", "y_2_1", ",", "x_2_2", ",", "y_2_2", ",", "x_2_3", ",", "y_2_3", ",", "x_2_4", ",", "y_2_4", ",", "x_2_5", ",", "y_2_5", ",", "\n", "std_2_1", ",", "std_2_2", ",", "std_2_3", ",", "std_2_4", ",", "std_2_5", ",", "\n", "line_2_1_label", ",", "line_2_2_label", ",", "line_2_3_label", ",", "line_2_4_label", ",", "\n", "line_2_5_label", ",", "title_2", ",", "xlabel_2", ",", "ylabel_2", ",", "\n", "markevery_2_1", ",", "markevery_2_2", ",", "markevery_2_3", ",", "markevery_2_4", ",", "markevery_2_5", ",", "\n", "x_3_1", ",", "y_3_1", ",", "x_3_2", ",", "y_3_2", ",", "x_3_3", ",", "y_3_3", ",", "x_3_4", ",", "y_3_4", ",", "x_3_5", ",", "y_3_5", ",", "\n", "std_3_1", ",", "std_3_2", ",", "std_3_3", ",", "std_3_4", ",", "std_3_5", ",", "\n", "line_3_1_label", ",", "line_3_2_label", ",", "line_3_3_label", ",", "line_3_4_label", ",", "\n", "line_3_5_label", ",", "title_3", ",", "xlabel_3", ",", "ylabel_3", ",", "\n", "markevery_3_1", ",", "markevery_3_2", ",", "markevery_3_3", ",", "markevery_3_4", ",", "markevery_3_5", ",", "\n", "x_4_1", ",", "y_4_1", ",", "x_4_2", ",", "y_4_2", ",", "x_4_3", ",", "y_4_3", ",", "x_4_4", ",", "y_4_4", ",", "x_4_5", ",", "y_4_5", ",", "\n", "std_4_1", ",", "std_4_2", ",", "std_4_3", ",", "std_4_4", ",", "std_4_5", ",", "\n", "line_4_1_label", ",", "line_4_2_label", ",", "line_4_3_label", ",", "line_4_4_label", ",", "\n", "line_4_5_label", ",", "title_4", ",", "xlabel_4", ",", "ylabel_4", ",", "\n", "markevery_4_1", ",", "markevery_4_2", ",", "markevery_4_3", ",", "markevery_4_4", ",", "markevery_4_5", ",", "\n", "file_name", "\n", ")", ":", "\n", "    ", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "3", ",", "figsize", "=", "(", "9", ",", "3", ")", ")", "\n", "#gs1 = gridspec.GridSpec(1, 4)", "\n", "#gs1.update(wspace=0.005, hspace=0.05)", "\n", "\n", "if", "len", "(", "x_1_1", ")", "/", "markevery_1_1", ">", "15", ":", "\n", "        ", "markevery_1_1", "=", "3", "\n", "markevery_1_2", "=", "3", "\n", "markevery_1_3", "=", "3", "\n", "markevery_1_4", "=", "3", "\n", "markevery_1_5", "=", "3", "\n", "\n", "", "if", "len", "(", "x_2_1", ")", "/", "markevery_2_1", ">", "15", ":", "\n", "        ", "markevery_2_1", "=", "3", "\n", "markevery_2_2", "=", "3", "\n", "markevery_2_3", "=", "3", "\n", "markevery_2_4", "=", "3", "\n", "markevery_2_5", "=", "3", "\n", "\n", "", "if", "len", "(", "x_3_1", ")", "/", "markevery_3_1", ">", "15", ":", "\n", "        ", "markevery_3_1", "=", "3", "\n", "markevery_3_2", "=", "3", "\n", "markevery_3_3", "=", "3", "\n", "markevery_3_4", "=", "3", "\n", "markevery_3_5", "=", "3", "\n", "\n", "# Plot avg hack_probability train", "\n", "", "xlims", "=", "(", "min", "(", "min", "(", "x_1_1", ")", ",", "min", "(", "x_1_2", ")", ",", "min", "(", "x_1_3", ")", ",", "min", "(", "x_1_4", ")", ",", "min", "(", "x_1_5", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1_1", ")", ",", "max", "(", "x_1_2", ")", ",", "max", "(", "x_1_3", ")", ",", "max", "(", "x_1_4", ")", ",", "max", "(", "x_1_5", ")", ")", ")", "\n", "ylims", "=", "(", "min", "(", "min", "(", "y_1_1", ")", ",", "min", "(", "y_1_2", ")", ",", "min", "(", "y_1_3", ")", ",", "min", "(", "y_1_4", ")", ",", "min", "(", "y_1_5", ")", ")", ",", "\n", "max", "(", "max", "(", "y_1_1", ")", ",", "max", "(", "y_1_2", ")", ",", "max", "(", "y_1_3", ")", ",", "max", "(", "y_1_4", ")", ",", "max", "(", "y_1_5", ")", ")", ")", "\n", "\n", "ax", "[", "0", "]", ".", "plot", "(", "x_1_1", ",", "y_1_1", ",", "label", "=", "line_1_1_label", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "markevery", "=", "markevery_1_1", ")", "\n", "ax", "[", "0", "]", ".", "fill_between", "(", "x_1_1", ",", "y_1_1", "-", "std_1_1", ",", "y_1_1", "+", "std_1_1", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "0", "]", ".", "plot", "(", "x_1_2", ",", "y_1_2", ",", "label", "=", "line_1_2_label", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "markevery", "=", "markevery_1_2", ")", "\n", "ax", "[", "0", "]", ".", "fill_between", "(", "x_1_2", ",", "y_1_2", "-", "std_1_2", ",", "y_1_2", "+", "std_1_2", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "0", "]", ".", "plot", "(", "x_1_3", ",", "y_1_3", ",", "label", "=", "line_1_3_label", ",", "marker", "=", "\"p\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#9e66ab\"", ",", "markevery", "=", "markevery_1_3", ")", "\n", "ax", "[", "0", "]", ".", "fill_between", "(", "x_1_3", ",", "y_1_3", "-", "std_1_3", ",", "y_1_3", "+", "std_1_3", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#9e66ab\"", ")", "\n", "\n", "ax", "[", "0", "]", ".", "plot", "(", "x_1_4", ",", "y_1_4", ",", "label", "=", "line_1_4_label", ",", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "'g'", ",", "markevery", "=", "markevery_1_4", ")", "\n", "ax", "[", "0", "]", ".", "fill_between", "(", "x_1_4", ",", "y_1_4", "-", "std_1_4", ",", "y_1_4", "+", "std_1_4", ",", "alpha", "=", "0.35", ",", "color", "=", "'g'", ")", "\n", "\n", "ax", "[", "0", "]", ".", "plot", "(", "x_1_5", ",", "y_1_5", ",", "label", "=", "line_1_5_label", ",", "marker", "=", "\"^\"", ",", "ls", "=", "'-'", ",", "color", "=", "'r'", ",", "markevery", "=", "markevery_1_5", ")", "\n", "ax", "[", "0", "]", ".", "fill_between", "(", "x_1_5", ",", "y_1_5", "-", "std_1_5", ",", "y_1_5", "+", "std_1_5", ",", "alpha", "=", "0.35", ",", "color", "=", "'r'", ")", "\n", "\n", "ax", "[", "0", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[0].set_ylim(ylims)", "\n", "\n", "ax", "[", "0", "]", ".", "set_title", "(", "title_1", ")", "\n", "ax", "[", "0", "]", ".", "set_xlabel", "(", "xlabel_1", ")", "\n", "ax", "[", "0", "]", ".", "set_ylabel", "(", "ylabel_1", ")", "\n", "# set the grid on", "\n", "ax", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# xlab.set_style('italic')", "\n", "#xlab.set_size(8)", "\n", "# ylab.set_style('italic')", "\n", "#ylab.set_size(8)", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "0", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "0", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# plt.legend(loc=legend_loc)", "\n", "\n", "# Shrink current axis's height by 10% on the bottom", "\n", "# box = ax[0].get_position()", "\n", "# ax[0].set_position([box.x0, 0.8*box.y0,", "\n", "#                     box.width, box.height * 0.99])", "\n", "fig", ".", "subplots_adjust", "(", "bottom", "=", "0.4", ")", "\n", "\n", "# Put a legend below current axis", "\n", "# ax[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.25),", "\n", "#              fancybox=True, shadow=True, ncol=2)", "\n", "\n", "# Plot avg hack_probability eval", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_2_1", ")", ",", "min", "(", "x_2_2", ")", ",", "min", "(", "x_2_3", ")", ",", "min", "(", "x_2_4", ")", ",", "min", "(", "x_2_5", ")", ")", ",", "\n", "max", "(", "max", "(", "x_2_1", ")", ",", "max", "(", "x_2_2", ")", ",", "max", "(", "x_2_3", ")", ",", "max", "(", "x_2_4", ")", ",", "max", "(", "x_2_5", ")", ")", ")", "\n", "ylims", "=", "(", "min", "(", "min", "(", "y_2_1", ")", ",", "min", "(", "y_2_2", ")", ",", "min", "(", "y_2_3", ")", ",", "min", "(", "y_2_4", ")", ",", "min", "(", "y_2_5", ")", ")", ",", "\n", "max", "(", "max", "(", "y_2_1", ")", ",", "max", "(", "y_2_2", ")", ",", "max", "(", "y_2_3", ")", ",", "max", "(", "y_2_4", ")", ",", "max", "(", "y_2_5", ")", ")", ")", "\n", "\n", "ax", "[", "1", "]", ".", "plot", "(", "x_2_1", ",", "y_2_1", ",", "label", "=", "line_2_1_label", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "markevery", "=", "markevery_2_1", ")", "\n", "ax", "[", "1", "]", ".", "fill_between", "(", "x_2_1", ",", "y_2_1", "-", "std_2_1", ",", "y_2_1", "+", "std_2_1", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "1", "]", ".", "plot", "(", "x_2_2", ",", "y_2_2", ",", "label", "=", "line_2_2_label", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "markevery", "=", "markevery_2_2", ")", "\n", "ax", "[", "1", "]", ".", "fill_between", "(", "x_2_2", ",", "y_2_2", "-", "std_2_2", ",", "y_2_2", "+", "std_2_2", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "1", "]", ".", "plot", "(", "x_2_3", ",", "y_2_3", ",", "label", "=", "line_2_3_label", ",", "marker", "=", "\"p\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#9e66ab\"", ",", "markevery", "=", "markevery_2_3", ")", "\n", "ax", "[", "1", "]", ".", "fill_between", "(", "x_2_3", ",", "y_2_3", "-", "std_2_3", ",", "y_2_3", "+", "std_2_3", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#9e66ab\"", ")", "\n", "\n", "ax", "[", "1", "]", ".", "plot", "(", "x_2_4", ",", "y_2_4", ",", "label", "=", "line_2_4_label", ",", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "'g'", ",", "markevery", "=", "markevery_2_4", ")", "\n", "ax", "[", "1", "]", ".", "fill_between", "(", "x_2_4", ",", "y_2_4", "-", "std_2_4", ",", "y_2_4", "+", "std_2_4", ",", "alpha", "=", "0.35", ",", "color", "=", "'g'", ")", "\n", "\n", "ax", "[", "1", "]", ".", "plot", "(", "x_2_5", ",", "y_2_5", ",", "label", "=", "line_2_5_label", ",", "marker", "=", "\"^\"", ",", "ls", "=", "'-'", ",", "color", "=", "'r'", ",", "markevery", "=", "markevery_2_5", ")", "\n", "ax", "[", "1", "]", ".", "fill_between", "(", "x_2_5", ",", "y_2_5", "-", "std_2_5", ",", "y_2_5", "+", "std_2_5", ",", "alpha", "=", "0.35", ",", "color", "=", "'r'", ")", "\n", "\n", "ax", "[", "1", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[1].set_ylim(ylims)", "\n", "\n", "ax", "[", "1", "]", ".", "set_title", "(", "title_2", ")", "\n", "ax", "[", "1", "]", ".", "set_xlabel", "(", "xlabel_2", ")", "\n", "ax", "[", "1", "]", ".", "set_ylabel", "(", "ylabel_2", ")", "\n", "# set the grid on", "\n", "ax", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# xlab.set_style('italic')", "\n", "#xlab.set_size(10)", "\n", "# ylab.set_style('italic')", "\n", "#ylab.set_size(10)", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "1", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "1", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# plt.legend(loc=legend_loc)", "\n", "\n", "# Shrink current axis's height by 10% on the bottom", "\n", "box", "=", "ax", "[", "1", "]", ".", "get_position", "(", ")", "\n", "ax", "[", "1", "]", ".", "set_position", "(", "[", "box", ".", "x0", ",", "box", ".", "y0", "+", "box", ".", "height", "*", "0.03", ",", "\n", "box", ".", "width", ",", "box", ".", "height", "*", "0.9", "]", ")", "\n", "\n", "# Plot attacker cumulative reward", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_3_1", ")", ",", "min", "(", "x_3_2", ")", ",", "min", "(", "x_3_3", ")", ",", "min", "(", "x_3_4", ")", ",", "min", "(", "x_3_5", ")", ")", ",", "\n", "max", "(", "max", "(", "x_3_1", ")", ",", "max", "(", "x_3_2", ")", ",", "max", "(", "x_3_3", ")", ",", "max", "(", "x_3_4", ")", ",", "max", "(", "x_3_5", ")", ")", ")", "\n", "ylims", "=", "(", "min", "(", "min", "(", "y_3_1", ")", ",", "min", "(", "y_3_2", ")", ",", "min", "(", "y_3_3", ")", ",", "min", "(", "y_3_4", ")", ",", "min", "(", "y_3_5", ")", ")", ",", "\n", "max", "(", "max", "(", "y_3_1", ")", ",", "max", "(", "y_3_2", ")", ",", "max", "(", "y_3_3", ")", ",", "max", "(", "y_3_4", ")", ",", "max", "(", "y_3_5", ")", ")", ")", "\n", "\n", "ax", "[", "2", "]", ".", "plot", "(", "x_3_1", ",", "y_3_1", ",", "label", "=", "line_3_1_label", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "markevery", "=", "markevery_3_1", ")", "\n", "ax", "[", "2", "]", ".", "fill_between", "(", "x_3_1", ",", "y_3_1", "-", "std_3_1", ",", "y_3_1", "+", "std_3_1", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "2", "]", ".", "plot", "(", "x_3_2", ",", "y_3_2", ",", "label", "=", "line_3_2_label", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "markevery", "=", "markevery_3_2", ")", "\n", "ax", "[", "2", "]", ".", "fill_between", "(", "x_3_2", ",", "y_3_2", "-", "std_3_2", ",", "y_3_2", "+", "std_3_2", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "2", "]", ".", "plot", "(", "x_3_3", ",", "y_3_3", ",", "label", "=", "line_3_3_label", ",", "marker", "=", "\"p\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#9e66ab\"", ",", "markevery", "=", "markevery_3_3", ")", "\n", "ax", "[", "2", "]", ".", "fill_between", "(", "x_3_3", ",", "y_3_3", "-", "std_3_3", ",", "y_3_3", "+", "std_3_3", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#9e66ab\"", ")", "\n", "\n", "ax", "[", "2", "]", ".", "plot", "(", "x_3_4", ",", "y_3_4", ",", "label", "=", "line_3_4_label", ",", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "'g'", ",", "markevery", "=", "markevery_3_4", ")", "\n", "ax", "[", "2", "]", ".", "fill_between", "(", "x_3_4", ",", "y_3_4", "-", "std_3_4", ",", "y_3_4", "+", "std_3_4", ",", "alpha", "=", "0.35", ",", "color", "=", "'g'", ")", "\n", "\n", "ax", "[", "2", "]", ".", "plot", "(", "x_3_5", ",", "y_3_5", ",", "label", "=", "line_3_5_label", ",", "marker", "=", "\"^\"", ",", "ls", "=", "'-'", ",", "color", "=", "'r'", ",", "markevery", "=", "markevery_3_5", ")", "\n", "ax", "[", "2", "]", ".", "fill_between", "(", "x_3_5", ",", "y_3_5", "-", "std_3_5", ",", "y_3_5", "+", "std_3_5", ",", "alpha", "=", "0.35", ",", "color", "=", "'r'", ")", "\n", "\n", "ax", "[", "2", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[2].set_ylim(ylims)", "\n", "\n", "ax", "[", "2", "]", ".", "set_title", "(", "title_3", ")", "\n", "ax", "[", "2", "]", ".", "set_xlabel", "(", "xlabel_3", ")", "\n", "ax", "[", "2", "]", ".", "set_ylabel", "(", "ylabel_3", ")", "\n", "# set the grid on", "\n", "ax", "[", "2", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "#ax[2].yaxis.labelpad = -5", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "2", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "2", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "\n", "ax", "[", "1", "]", ".", "legend", "(", "loc", "=", "'upper center'", ",", "bbox_to_anchor", "=", "(", "0.5", ",", "-", "0.22", ")", ",", "fancybox", "=", "True", ",", "shadow", "=", "True", ",", "ncol", "=", "2", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "plt", ".", "subplots_adjust", "(", "wspace", "=", "0.2", ",", "hspace", "=", "0", ")", "\n", "fig", ".", "subplots_adjust", "(", "bottom", "=", "0.37", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_avg_summary_3": [[1345, 1955], ["matplotlib.rc", "matplotlib.rc", "matplotlib.subplots", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].get_position", "[].set_position", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].get_position", "[].set_position", "[].get_yaxis().set_major_formatter", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].get_position", "[].set_position", "[].get_yaxis().set_major_formatter", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].get_position", "[].set_position", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].get_position", "[].set_position", "[].get_yaxis().set_major_formatter", "fig.tight_layout", "matplotlib.subplots_adjust", "fig.subplots_adjust", "fig.savefig", "fig.savefig", "min", "max", "numpy.maximum", "numpy.maximum", "numpy.maximum", "numpy.maximum", "numpy.maximum", "min", "max", "numpy.maximum", "numpy.maximum", "numpy.maximum", "numpy.maximum", "numpy.maximum", "min", "max", "min", "max", "matplotlib.FuncFormatter", "min", "max", "numpy.maximum", "numpy.maximum", "numpy.maximum", "numpy.maximum", "numpy.maximum", "min", "max", "numpy.maximum", "numpy.maximum", "numpy.maximum", "numpy.maximum", "numpy.maximum", "min", "max", "min", "max", "matplotlib.FuncFormatter", "min", "max", "numpy.maximum", "numpy.maximum", "numpy.maximum", "numpy.maximum", "numpy.maximum", "min", "max", "numpy.maximum", "numpy.maximum", "numpy.maximum", "numpy.maximum", "numpy.maximum", "min", "max", "min", "max", "matplotlib.FuncFormatter", "[].get_legend_handles_labels", "sum", "fig.legend", "fig.legend", "len", "len", "len", "len", "len", "len", "len", "len", "len", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "[].get_yaxis", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "[].get_yaxis", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "min", "min", "min", "min", "min", "max", "max", "max", "max", "max", "[].get_yaxis", "zip", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot"], ["", "def", "plot_all_avg_summary_3", "(", "x_1_1_v0", ",", "y_1_1_v0", ",", "x_1_2_v0", ",", "y_1_2_v0", ",", "x_1_3_v0", ",", "y_1_3_v0", ",", "x_1_4_v0", ",", "y_1_4_v0", ",", "\n", "x_1_5_v0", ",", "y_1_5_v0", ",", "\n", "std_1_1_v0", ",", "std_1_2_v0", ",", "std_1_3_v0", ",", "std_1_4_v0", ",", "std_1_5_v0", ",", "\n", "line_1_1_label_v0", ",", "line_1_2_label_v0", ",", "line_1_3_label_v0", ",", "line_1_4_label_v0", ",", "\n", "line_1_5_label_v0", ",", "title_1_v0", ",", "xlabel_1_v0", ",", "ylabel_1_v0", ",", "\n", "markevery_1_1_v0", ",", "markevery_1_2_v0", ",", "markevery_1_3_v0", ",", "markevery_1_4_v0", ",", "markevery_1_5_v0", ",", "\n", "x_2_1_v0", ",", "y_2_1_v0", ",", "x_2_2_v0", ",", "y_2_2_v0", ",", "x_2_3_v0", ",", "y_2_3_v0", ",", "x_2_4_v0", ",", "y_2_4_v0", ",", "x_2_5_v0", ",", "\n", "y_2_5_v0", ",", "std_2_1_v0", ",", "std_2_2_v0", ",", "std_2_3_v0", ",", "std_2_4_v0", ",", "std_2_5_v0", ",", "\n", "line_2_1_label_v0", ",", "line_2_2_label_v0", ",", "line_2_3_label_v0", ",", "line_2_4_label_v0", ",", "\n", "line_2_5_label_v0", ",", "title_2_v0", ",", "xlabel_2_v0", ",", "ylabel_2_v0", ",", "\n", "markevery_2_1_v0", ",", "markevery_2_2_v0", ",", "markevery_2_3_v0", ",", "markevery_2_4_v0", ",", "markevery_2_5_v0", ",", "\n", "x_3_1_v0", ",", "y_3_1_v0", ",", "x_3_2_v0", ",", "y_3_2_v0", ",", "x_3_3_v0", ",", "y_3_3_v0", ",", "x_3_4_v0", ",", "y_3_4_v0", ",", "x_3_5_v0", ",", "\n", "y_3_5_v0", ",", "\n", "std_3_1_v0", ",", "std_3_2_v0", ",", "std_3_3_v0", ",", "std_3_4_v0", ",", "std_3_5_v0", ",", "\n", "line_3_1_label_v0", ",", "line_3_2_label_v0", ",", "line_3_3_label_v0", ",", "line_3_4_label_v0", ",", "\n", "line_3_5_label_v0", ",", "title_3_v0", ",", "xlabel_3_v0", ",", "ylabel_3_v0", ",", "\n", "markevery_3_1_v0", ",", "markevery_3_2_v0", ",", "markevery_3_3_v0", ",", "markevery_3_4_v0", ",", "markevery_3_5_v0", ",", "\n", "\n", "x_1_1_v2", ",", "y_1_1_v2", ",", "x_1_2_v2", ",", "y_1_2_v2", ",", "x_1_3_v2", ",", "y_1_3_v2", ",", "x_1_4_v2", ",", "y_1_4_v2", ",", "\n", "x_1_5_v2", ",", "y_1_5_v2", ",", "\n", "std_1_1_v2", ",", "std_1_2_v2", ",", "std_1_3_v2", ",", "std_1_4_v2", ",", "std_1_5_v2", ",", "\n", "line_1_1_label_v2", ",", "line_1_2_label_v2", ",", "line_1_3_label_v2", ",", "line_1_4_label_v2", ",", "\n", "line_1_5_label_v2", ",", "title_1_v2", ",", "xlabel_1_v2", ",", "ylabel_1_v2", ",", "\n", "markevery_1_1_v2", ",", "markevery_1_2_v2", ",", "markevery_1_3_v2", ",", "markevery_1_4_v2", ",", "markevery_1_5_v2", ",", "\n", "x_2_1_v2", ",", "y_2_1_v2", ",", "x_2_2_v2", ",", "y_2_2_v2", ",", "x_2_3_v2", ",", "y_2_3_v2", ",", "x_2_4_v2", ",", "y_2_4_v2", ",", "x_2_5_v2", ",", "\n", "y_2_5_v2", ",", "std_2_1_v2", ",", "std_2_2_v2", ",", "std_2_3_v2", ",", "std_2_4_v2", ",", "std_2_5_v2", ",", "\n", "line_2_1_label_v2", ",", "line_2_2_label_v2", ",", "line_2_3_label_v2", ",", "line_2_4_label_v2", ",", "\n", "line_2_5_label_v2", ",", "title_2_v2", ",", "xlabel_2_v2", ",", "ylabel_2_v2", ",", "\n", "markevery_2_1_v2", ",", "markevery_2_2_v2", ",", "markevery_2_3_v2", ",", "markevery_2_4_v2", ",", "markevery_2_5_v2", ",", "\n", "x_3_1_v2", ",", "y_3_1_v2", ",", "x_3_2_v2", ",", "y_3_2_v2", ",", "x_3_3_v2", ",", "y_3_3_v2", ",", "x_3_4_v2", ",", "y_3_4_v2", ",", "x_3_5_v2", ",", "\n", "y_3_5_v2", ",", "\n", "std_3_1_v2", ",", "std_3_2_v2", ",", "std_3_3_v2", ",", "std_3_4_v2", ",", "std_3_5_v2", ",", "\n", "line_3_1_label_v2", ",", "line_3_2_label_v2", ",", "line_3_3_label_v2", ",", "line_3_4_label_v2", ",", "\n", "line_3_5_label_v2", ",", "title_3_v2", ",", "xlabel_3_v2", ",", "ylabel_3_v2", ",", "\n", "markevery_3_1_v2", ",", "markevery_3_2_v2", ",", "markevery_3_3_v2", ",", "markevery_3_4_v2", ",", "markevery_3_5_v2", ",", "\n", "\n", "x_1_1_v3", ",", "y_1_1_v3", ",", "x_1_2_v3", ",", "y_1_2_v3", ",", "x_1_3_v3", ",", "y_1_3_v3", ",", "x_1_4_v3", ",", "y_1_4_v3", ",", "\n", "x_1_5_v3", ",", "y_1_5_v3", ",", "\n", "std_1_1_v3", ",", "std_1_2_v3", ",", "std_1_3_v3", ",", "std_1_4_v3", ",", "std_1_5_v3", ",", "\n", "line_1_1_label_v3", ",", "line_1_2_label_v3", ",", "line_1_3_label_v3", ",", "line_1_4_label_v3", ",", "\n", "line_1_5_label_v3", ",", "title_1_v3", ",", "xlabel_1_v3", ",", "ylabel_1_v3", ",", "\n", "markevery_1_1_v3", ",", "markevery_1_2_v3", ",", "markevery_1_3_v3", ",", "markevery_1_4_v3", ",", "markevery_1_5_v3", ",", "\n", "x_2_1_v3", ",", "y_2_1_v3", ",", "x_2_2_v3", ",", "y_2_2_v3", ",", "x_2_3_v3", ",", "y_2_3_v3", ",", "x_2_4_v3", ",", "y_2_4_v3", ",", "x_2_5_v3", ",", "\n", "y_2_5_v3", ",", "std_2_1_v3", ",", "std_2_2_v3", ",", "std_2_3_v3", ",", "std_2_4_v3", ",", "std_2_5_v3", ",", "\n", "line_2_1_label_v3", ",", "line_2_2_label_v3", ",", "line_2_3_label_v3", ",", "line_2_4_label_v3", ",", "\n", "line_2_5_label_v3", ",", "title_2_v3", ",", "xlabel_2_v3", ",", "ylabel_2_v3", ",", "\n", "markevery_2_1_v3", ",", "markevery_2_2_v3", ",", "markevery_2_3_v3", ",", "markevery_2_4_v3", ",", "markevery_2_5_v3", ",", "\n", "x_3_1_v3", ",", "y_3_1_v3", ",", "x_3_2_v3", ",", "y_3_2_v3", ",", "x_3_3_v3", ",", "y_3_3_v3", ",", "x_3_4_v3", ",", "y_3_4_v3", ",", "x_3_5_v3", ",", "\n", "y_3_5_v3", ",", "\n", "std_3_1_v3", ",", "std_3_2_v3", ",", "std_3_3_v3", ",", "std_3_4_v3", ",", "std_3_5_v3", ",", "\n", "line_3_1_label_v3", ",", "line_3_2_label_v3", ",", "line_3_3_label_v3", ",", "line_3_4_label_v3", ",", "\n", "line_3_5_label_v3", ",", "title_3_v3", ",", "xlabel_3_v3", ",", "ylabel_3_v3", ",", "\n", "markevery_3_1_v3", ",", "markevery_3_2_v3", ",", "markevery_3_3_v3", ",", "markevery_3_4_v3", ",", "markevery_3_5_v3", ",", "\n", "\n", "file_name", ",", "algorithm", ",", "\n", "wspace", "=", "0.28", ",", "\n", ")", ":", "\n", "    ", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "#plt.rcParams.update({'font.size': 6})", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "3", ",", "ncols", "=", "3", ",", "figsize", "=", "(", "9", ",", "6.8", ")", ")", "\n", "#gs1 = gridspec.GridSpec(1, 4)", "\n", "#gs1.update(wspace=0.005, hspace=0.05)", "\n", "\n", "if", "len", "(", "x_1_1_v0", ")", "/", "markevery_1_1_v0", ">", "15", ":", "\n", "        ", "markevery_1_1_v0", "=", "2", "\n", "markevery_1_2_v0", "=", "2", "\n", "markevery_1_3_v0", "=", "2", "\n", "markevery_1_4_v0", "=", "2", "\n", "markevery_1_5_v0", "=", "2", "\n", "\n", "", "if", "len", "(", "x_1_1_v2", ")", "/", "markevery_1_1_v2", ">", "15", ":", "\n", "        ", "markevery_1_1_v2", "=", "2", "\n", "markevery_1_2_v2", "=", "2", "\n", "markevery_1_3_v2", "=", "2", "\n", "markevery_1_4_v2", "=", "2", "\n", "markevery_1_5_v2", "=", "2", "\n", "\n", "", "if", "len", "(", "x_1_1_v3", ")", "/", "markevery_1_1_v3", ">", "15", ":", "\n", "        ", "markevery_1_1_v3", "=", "2", "\n", "markevery_1_2_v3", "=", "2", "\n", "markevery_1_3_v3", "=", "2", "\n", "markevery_1_4_v3", "=", "2", "\n", "markevery_1_5_v3", "=", "2", "\n", "\n", "\n", "# 2", "\n", "", "if", "len", "(", "x_2_1_v0", ")", "/", "markevery_2_1_v0", ">", "15", ":", "\n", "        ", "markevery_2_1_v0", "=", "2", "\n", "markevery_2_2_v0", "=", "2", "\n", "markevery_2_3_v0", "=", "2", "\n", "markevery_2_4_v0", "=", "2", "\n", "markevery_2_5_v0", "=", "2", "\n", "\n", "", "if", "len", "(", "x_2_1_v2", ")", "/", "markevery_2_1_v2", ">", "15", ":", "\n", "        ", "markevery_2_1_v2", "=", "2", "\n", "markevery_2_2_v2", "=", "2", "\n", "markevery_2_3_v2", "=", "2", "\n", "markevery_2_4_v2", "=", "2", "\n", "markevery_2_5_v2", "=", "2", "\n", "\n", "", "if", "len", "(", "x_2_1_v3", ")", "/", "markevery_2_1_v3", ">", "15", ":", "\n", "        ", "markevery_2_1_v3", "=", "2", "\n", "markevery_2_2_v3", "=", "2", "\n", "markevery_2_3_v3", "=", "2", "\n", "markevery_2_4_v3", "=", "2", "\n", "markevery_2_5_v3", "=", "2", "\n", "\n", "# 3", "\n", "", "if", "len", "(", "x_3_1_v0", ")", "/", "markevery_3_1_v0", ">", "15", ":", "\n", "        ", "markevery_3_1_v0", "=", "2", "\n", "markevery_3_2_v0", "=", "2", "\n", "markevery_3_3_v0", "=", "2", "\n", "markevery_3_4_v0", "=", "2", "\n", "markevery_3_5_v0", "=", "2", "\n", "\n", "", "if", "len", "(", "x_3_1_v2", ")", "/", "markevery_3_1_v2", ">", "15", ":", "\n", "        ", "markevery_3_1_v2", "=", "2", "\n", "markevery_3_2_v2", "=", "2", "\n", "markevery_3_3_v2", "=", "2", "\n", "markevery_3_4_v2", "=", "2", "\n", "markevery_3_5_v2", "=", "2", "\n", "\n", "", "if", "len", "(", "x_3_1_v3", ")", "/", "markevery_3_1_v3", ">", "15", ":", "\n", "        ", "markevery_3_1_v3", "=", "2", "\n", "markevery_3_2_v3", "=", "2", "\n", "markevery_3_3_v3", "=", "2", "\n", "markevery_3_4_v3", "=", "2", "\n", "markevery_3_5_v3", "=", "2", "\n", "\n", "# Plot avg hack_probability train", "\n", "", "xlims", "=", "(", "min", "(", "min", "(", "x_1_1_v0", ")", ",", "min", "(", "x_1_2_v0", ")", ",", "min", "(", "x_1_3_v0", ")", ",", "min", "(", "x_1_4_v0", ")", ",", "min", "(", "x_1_5_v0", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1_1_v0", ")", ",", "max", "(", "x_1_2_v0", ")", ",", "max", "(", "x_1_3_v0", ")", ",", "max", "(", "x_1_4_v0", ")", ",", "max", "(", "x_1_5_v0", ")", ")", ")", "\n", "ylims", "=", "(", "0", ",", "1", ")", "\n", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "plot", "(", "x_1_1_v0", ",", "y_1_1_v0", ",", "label", "=", "line_1_1_label_v0", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "markevery", "=", "markevery_1_1_v0", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_1_v0", ",", "np", ".", "maximum", "(", "y_1_1_v0", "-", "std_1_1_v0", ",", "np", ".", "zeros", "(", "len", "(", "y_1_1_v0", ")", ")", ")", ",", "y_1_1_v0", "+", "std_1_1_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "plot", "(", "x_1_2_v0", ",", "y_1_2_v0", ",", "label", "=", "line_1_2_label_v0", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "markevery", "=", "markevery_1_2_v0", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_2_v0", ",", "np", ".", "maximum", "(", "y_1_2_v0", "-", "std_1_2_v0", ",", "np", ".", "zeros", "(", "len", "(", "y_1_2_v0", ")", ")", ")", ",", "y_1_2_v0", "+", "std_1_2_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "plot", "(", "x_1_3_v0", ",", "y_1_3_v0", ",", "label", "=", "line_1_3_label_v0", ",", "marker", "=", "\"p\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#9e66ab\"", ",", "markevery", "=", "markevery_1_3_v0", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_3_v0", ",", "np", ".", "maximum", "(", "y_1_3_v0", "-", "std_1_3_v0", ",", "np", ".", "zeros", "(", "len", "(", "y_1_3_v0", ")", ")", ")", ",", "y_1_3_v0", "+", "std_1_3_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#9e66ab\"", ")", "\n", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "plot", "(", "x_1_4_v0", ",", "y_1_4_v0", ",", "label", "=", "line_1_4_label_v0", ",", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "'g'", ",", "markevery", "=", "markevery_1_4_v0", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_4_v0", ",", "np", ".", "maximum", "(", "y_1_4_v0", "-", "std_1_4_v0", ",", "np", ".", "zeros", "(", "len", "(", "y_1_4_v0", ")", ")", ")", ",", "y_1_4_v0", "+", "std_1_4_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "'g'", ")", "\n", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "plot", "(", "x_1_5_v0", ",", "y_1_5_v0", ",", "label", "=", "line_1_5_label_v0", ",", "marker", "=", "\"^\"", ",", "ls", "=", "'-'", ",", "color", "=", "'r'", ",", "markevery", "=", "markevery_1_5_v0", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_5_v0", ",", "np", ".", "maximum", "(", "y_1_5_v0", "-", "std_1_5_v0", ",", "np", ".", "zeros", "(", "len", "(", "y_1_5_v0", ")", ")", ")", ",", "y_1_5_v0", "+", "std_1_5_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "'r'", ")", "\n", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "#ax[0][0].set_ylim(ylims)", "\n", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_title", "(", "title_1_v0", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_xlabel", "(", "xlabel_1_v0", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_ylabel", "(", "ylabel_1_v0", ")", "\n", "# set the grid on", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "0", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "0", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# xlab.set_style('italic')", "\n", "#xlab.set_size(8)", "\n", "# ylab.set_style('italic')", "\n", "#ylab.set_size(8)", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# plt.legend(loc=legend_loc)", "\n", "\n", "# Shrink current axis's height by 10% on the bottom", "\n", "# box = ax[0].get_position()", "\n", "# ax[0].set_position([box.x0, 0.8*box.y0,", "\n", "#                     box.width, box.height * 0.99])", "\n", "#fig.subplots_adjust(bottom=0.4)", "\n", "\n", "# Put a legend below current axis", "\n", "# ax[0].legend(loc='upper center', bbox_to_anchor=(0.5, -0.25),", "\n", "#              fancybox=True, shadow=True, ncol=2)", "\n", "\n", "# Plot avg hack_probability eval", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_2_1_v0", ")", ",", "min", "(", "x_2_2_v0", ")", ",", "min", "(", "x_2_3_v0", ")", ",", "min", "(", "x_2_4_v0", ")", ",", "min", "(", "x_2_5_v0", ")", ")", ",", "\n", "max", "(", "max", "(", "x_2_1_v0", ")", ",", "max", "(", "x_2_2_v0", ")", ",", "max", "(", "x_2_3_v0", ")", ",", "max", "(", "x_2_4_v0", ")", ",", "max", "(", "x_2_5_v0", ")", ")", ")", "\n", "ylims", "=", "(", "0", ",", "1", ")", "\n", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "plot", "(", "x_2_1_v0", ",", "y_2_1_v0", ",", "label", "=", "line_2_1_label_v0", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "markevery", "=", "markevery_2_1_v0", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_1_v0", ",", "np", ".", "maximum", "(", "y_2_1_v0", "-", "std_2_1_v0", ",", "np", ".", "zeros", "(", "len", "(", "y_2_1_v0", ")", ")", ")", ",", "y_2_1_v0", "+", "std_2_1_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "plot", "(", "x_2_2_v0", ",", "y_2_2_v0", ",", "label", "=", "line_2_2_label_v0", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "markevery", "=", "markevery_2_2_v0", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_2_v0", ",", "np", ".", "maximum", "(", "y_2_2_v0", "-", "std_2_2_v0", ",", "np", ".", "zeros", "(", "len", "(", "y_2_2_v0", ")", ")", ")", ",", "y_2_2_v0", "+", "std_2_2_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "plot", "(", "x_2_3_v0", ",", "y_2_3_v0", ",", "label", "=", "line_2_3_label_v0", ",", "marker", "=", "\"p\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#9e66ab\"", ",", "markevery", "=", "markevery_2_3_v0", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_3_v0", ",", "np", ".", "maximum", "(", "y_2_3_v0", "-", "std_2_3_v0", ",", "np", ".", "zeros", "(", "len", "(", "y_2_3_v0", ")", ")", ")", ",", "y_2_3_v0", "+", "std_2_3_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#9e66ab\"", ")", "\n", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "plot", "(", "x_2_4_v0", ",", "y_2_4_v0", ",", "label", "=", "line_2_4_label_v0", ",", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "'g'", ",", "markevery", "=", "markevery_2_4_v0", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_4_v0", ",", "np", ".", "maximum", "(", "y_2_4_v0", "-", "std_2_4_v0", ",", "np", ".", "zeros", "(", "len", "(", "y_2_4_v0", ")", ")", ")", ",", "y_2_4_v0", "+", "std_2_4_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "'g'", ")", "\n", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "plot", "(", "x_2_5_v0", ",", "y_2_5_v0", ",", "label", "=", "line_2_5_label_v0", ",", "marker", "=", "\"^\"", ",", "ls", "=", "'-'", ",", "color", "=", "'r'", ",", "markevery", "=", "markevery_2_5_v0", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_5_v0", ",", "np", ".", "maximum", "(", "y_2_5_v0", "-", "std_2_5_v0", ",", "np", ".", "zeros", "(", "len", "(", "y_2_5_v0", ")", ")", ")", ",", "y_2_5_v0", "+", "std_2_5_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "'r'", ")", "\n", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "#ax[0][1].set_ylim(ylims)", "\n", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_title", "(", "title_2_v0", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_xlabel", "(", "xlabel_2_v0", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_ylabel", "(", "ylabel_2_v0", ")", "\n", "# set the grid on", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "0", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "0", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# xlab.set_style('italic')", "\n", "#xlab.set_size(10)", "\n", "# ylab.set_style('italic')", "\n", "#ylab.set_size(10)", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# plt.legend(loc=legend_loc)", "\n", "\n", "# Shrink current axis's height by 10% on the bottom", "\n", "box", "=", "ax", "[", "0", "]", "[", "1", "]", ".", "get_position", "(", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_position", "(", "[", "box", ".", "x0", ",", "box", ".", "y0", "+", "box", ".", "height", "*", "0.03", ",", "\n", "box", ".", "width", ",", "box", ".", "height", "*", "0.9", "]", ")", "\n", "\n", "# Put a legend below current axis", "\n", "\n", "# Plot attacker cumulative reward", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_3_1_v0", ")", ",", "min", "(", "x_3_2_v0", ")", ",", "min", "(", "x_3_3_v0", ")", ",", "min", "(", "x_3_4_v0", ")", ",", "min", "(", "x_3_5_v0", ")", ")", ",", "\n", "max", "(", "max", "(", "x_3_1_v0", ")", ",", "max", "(", "x_3_2_v0", ")", ",", "max", "(", "x_3_3_v0", ")", ",", "max", "(", "x_3_4_v0", ")", ",", "max", "(", "x_3_5_v0", ")", ")", ")", "\n", "ylims", "=", "(", "min", "(", "min", "(", "y_3_1_v0", ")", ",", "min", "(", "y_3_2_v0", ")", ",", "min", "(", "y_3_3_v0", ")", ",", "min", "(", "y_3_4_v0", ")", ",", "min", "(", "y_3_5_v0", ")", ")", ",", "\n", "max", "(", "max", "(", "y_3_1_v0", ")", ",", "max", "(", "y_3_2_v0", ")", ",", "max", "(", "y_3_3_v0", ")", ",", "max", "(", "y_3_4_v0", ")", ",", "max", "(", "y_3_5_v0", ")", ")", ")", "\n", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "plot", "(", "x_3_1_v0", ",", "y_3_1_v0", ",", "label", "=", "line_3_1_label_v0", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "markevery", "=", "markevery_3_1_v0", ")", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_1_v0", ",", "y_3_1_v0", "-", "std_3_1_v0", ",", "y_3_1_v0", "+", "std_3_1_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "plot", "(", "x_3_2_v0", ",", "y_3_2_v0", ",", "label", "=", "line_3_2_label_v0", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "markevery", "=", "markevery_3_2_v0", ")", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_2_v0", ",", "y_3_2_v0", "-", "std_3_2_v0", ",", "y_3_2_v0", "+", "std_3_2_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "plot", "(", "x_3_3_v0", ",", "y_3_3_v0", ",", "label", "=", "line_3_3_label_v0", ",", "marker", "=", "\"p\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#9e66ab\"", ",", "markevery", "=", "markevery_3_3_v0", ")", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_3_v0", ",", "y_3_3_v0", "-", "std_3_3_v0", ",", "y_3_3_v0", "+", "std_3_3_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#9e66ab\"", ")", "\n", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "plot", "(", "x_3_4_v0", ",", "y_3_4_v0", ",", "label", "=", "line_3_4_label_v0", ",", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "'g'", ",", "markevery", "=", "markevery_3_4_v0", ")", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_4_v0", ",", "y_3_4_v0", "-", "std_3_4_v0", ",", "y_3_4_v0", "+", "std_3_4_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "'g'", ")", "\n", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "plot", "(", "x_3_5_v0", ",", "y_3_5_v0", ",", "label", "=", "line_3_5_label_v0", ",", "marker", "=", "\"^\"", ",", "ls", "=", "'-'", ",", "color", "=", "'r'", ",", "markevery", "=", "markevery_3_5_v0", ")", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_5_v0", ",", "y_3_5_v0", "-", "std_3_5_v0", ",", "y_3_5_v0", "+", "std_3_5_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "'r'", ")", "\n", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "#ax[0][2].set_ylim(ylims)", "\n", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "set_title", "(", "title_3_v0", ")", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "set_xlabel", "(", "xlabel_3_v0", ")", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "set_ylabel", "(", "ylabel_3_v0", ")", "\n", "# set the grid on", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "0", "]", "[", "2", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "0", "]", "[", "2", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "yaxis", ".", "labelpad", "=", "-", "5", "\n", "\n", "# xlab.set_style('italic')", "\n", "#xlab.set_size(10)", "\n", "# ylab.set_style('italic')", "\n", "#ylab.set_size(10)", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "\n", "# Shrink current axis's height by 10% on the bottom", "\n", "box", "=", "ax", "[", "0", "]", "[", "2", "]", ".", "get_position", "(", ")", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "set_position", "(", "[", "box", ".", "x0", ",", "box", ".", "y0", "+", "box", ".", "height", "*", "0.03", ",", "\n", "box", ".", "width", ",", "box", ".", "height", "*", "0.9", "]", ")", "\n", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "get_yaxis", "(", ")", ".", "set_major_formatter", "(", "tkr", ".", "FuncFormatter", "(", "lambda", "x", ",", "p", ":", "\"${:1.0f}K$\"", ".", "format", "(", "x", "*", "1e-3", ")", ")", ")", "\n", "\n", "\n", "# V2", "\n", "\n", "# Plot avg hack_probability train", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_1_1_v2", ")", ",", "min", "(", "x_1_2_v2", ")", ",", "min", "(", "x_1_3_v2", ")", ",", "min", "(", "x_1_4_v2", ")", ",", "min", "(", "x_1_5_v2", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1_1_v2", ")", ",", "max", "(", "x_1_2_v2", ")", ",", "max", "(", "x_1_3_v2", ")", ",", "max", "(", "x_1_4_v2", ")", ",", "max", "(", "x_1_5_v2", ")", ")", ")", "\n", "ylims", "=", "(", "0", ",", "1", ")", "\n", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "plot", "(", "x_1_1_v2", ",", "y_1_1_v2", ",", "label", "=", "line_1_1_label_v2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery_1_1_v2", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_1_v2", ",", "np", ".", "maximum", "(", "y_1_1_v2", "-", "std_1_1_v2", ",", "np", ".", "zeros", "(", "len", "(", "y_1_1_v2", ")", ")", ")", ",", "y_1_1_v2", "+", "std_1_1_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "plot", "(", "x_1_2_v2", ",", "y_1_2_v2", ",", "label", "=", "line_1_2_label_v2", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery_1_2_v2", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_2_v2", ",", "np", ".", "maximum", "(", "y_1_2_v2", "-", "std_1_2_v2", ",", "np", ".", "zeros", "(", "len", "(", "y_1_2_v2", ")", ")", ")", ",", "y_1_2_v2", "+", "std_1_2_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "plot", "(", "x_1_3_v2", ",", "y_1_3_v2", ",", "label", "=", "line_1_3_label_v2", ",", "marker", "=", "\"p\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#9e66ab\"", ",", "\n", "markevery", "=", "markevery_1_3_v2", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_3_v2", ",", "np", ".", "maximum", "(", "y_1_3_v2", "-", "std_1_3_v2", ",", "np", ".", "zeros", "(", "len", "(", "y_1_3_v2", ")", ")", ")", ",", "y_1_3_v2", "+", "std_1_3_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#9e66ab\"", ")", "\n", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "plot", "(", "x_1_4_v2", ",", "y_1_4_v2", ",", "label", "=", "line_1_4_label_v2", ",", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "'g'", ",", "\n", "markevery", "=", "markevery_1_4_v2", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_4_v2", ",", "np", ".", "maximum", "(", "y_1_4_v2", "-", "std_1_4_v2", ",", "np", ".", "zeros", "(", "len", "(", "y_1_4_v2", ")", ")", ")", ",", "y_1_4_v2", "+", "std_1_4_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "'g'", ")", "\n", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "plot", "(", "x_1_5_v2", ",", "y_1_5_v2", ",", "label", "=", "line_1_5_label_v2", ",", "marker", "=", "\"^\"", ",", "ls", "=", "'-'", ",", "color", "=", "'r'", ",", "\n", "markevery", "=", "markevery_1_5_v2", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_5_v2", ",", "np", ".", "maximum", "(", "y_1_5_v2", "-", "std_1_5_v2", ",", "np", ".", "zeros", "(", "len", "(", "y_1_5_v2", ")", ")", ")", ",", "y_1_5_v2", "+", "std_1_5_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "'r'", ")", "\n", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "#ax[1][0].set_ylim(ylims)", "\n", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_title", "(", "title_1_v2", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_xlabel", "(", "xlabel_1_v2", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_ylabel", "(", "ylabel_1_v2", ")", "\n", "# set the grid on", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "1", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "\n", "# Plot avg hack_probability eval", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_2_1_v2", ")", ",", "min", "(", "x_2_2_v2", ")", ",", "min", "(", "x_2_3_v2", ")", ",", "min", "(", "x_2_4_v2", ")", ",", "min", "(", "x_2_5_v2", ")", ")", ",", "\n", "max", "(", "max", "(", "x_2_1_v2", ")", ",", "max", "(", "x_2_2_v2", ")", ",", "max", "(", "x_2_3_v2", ")", ",", "max", "(", "x_2_4_v2", ")", ",", "max", "(", "x_2_5_v2", ")", ")", ")", "\n", "ylims", "=", "(", "0", ",", "1", ")", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "plot", "(", "x_2_1_v2", ",", "y_2_1_v2", ",", "label", "=", "line_2_1_label_v2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery_2_1_v2", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_1_v2", ",", "np", ".", "maximum", "(", "y_2_1_v2", "-", "std_2_1_v2", ",", "np", ".", "zeros", "(", "len", "(", "y_2_1_v2", ")", ")", ")", ",", "y_2_1_v2", "+", "std_2_1_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "plot", "(", "x_2_2_v2", ",", "y_2_2_v2", ",", "label", "=", "line_2_2_label_v2", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery_2_2_v2", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_2_v2", ",", "np", ".", "maximum", "(", "y_2_2_v2", "-", "std_2_2_v2", ",", "np", ".", "zeros", "(", "len", "(", "y_2_2_v2", ")", ")", ")", ",", "y_2_2_v2", "+", "std_2_2_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "plot", "(", "x_2_3_v2", ",", "y_2_3_v2", ",", "label", "=", "line_2_3_label_v2", ",", "marker", "=", "\"p\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#9e66ab\"", ",", "\n", "markevery", "=", "markevery_2_3_v2", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_3_v2", ",", "np", ".", "maximum", "(", "y_2_3_v2", "-", "std_2_3_v2", ",", "np", ".", "zeros", "(", "len", "(", "y_2_3_v2", ")", ")", ")", ",", "y_2_3_v2", "+", "std_2_3_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#9e66ab\"", ")", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "plot", "(", "x_2_4_v2", ",", "y_2_4_v2", ",", "label", "=", "line_2_4_label_v2", ",", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "'g'", ",", "\n", "markevery", "=", "markevery_2_4_v2", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_4_v2", ",", "np", ".", "maximum", "(", "y_2_4_v2", "-", "std_2_4_v2", ",", "np", ".", "zeros", "(", "len", "(", "y_2_4_v2", ")", ")", ")", ",", "y_2_4_v2", "+", "std_2_4_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "'g'", ")", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "plot", "(", "x_2_5_v2", ",", "y_2_5_v2", ",", "label", "=", "line_2_5_label_v2", ",", "marker", "=", "\"^\"", ",", "ls", "=", "'-'", ",", "color", "=", "'r'", ",", "\n", "markevery", "=", "markevery_2_5_v2", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_5_v2", ",", "np", ".", "maximum", "(", "y_2_5_v2", "-", "std_2_5_v2", ",", "np", ".", "zeros", "(", "len", "(", "y_2_5_v2", ")", ")", ")", ",", "y_2_5_v2", "+", "std_2_5_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "'r'", ")", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "#ax[1][1].set_ylim(ylims)", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_title", "(", "title_2_v2", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_xlabel", "(", "xlabel_2_v2", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_ylabel", "(", "ylabel_2_v2", ")", "\n", "# set the grid on", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "1", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# xlab.set_style('italic')", "\n", "# xlab.set_size(10)", "\n", "# ylab.set_style('italic')", "\n", "# ylab.set_size(10)", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# Plot attacker cumulative reward", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_3_1_v2", ")", ",", "min", "(", "x_3_2_v2", ")", ",", "min", "(", "x_3_3_v2", ")", ",", "min", "(", "x_3_4_v2", ")", ",", "min", "(", "x_3_5_v2", ")", ")", ",", "\n", "max", "(", "max", "(", "x_3_1_v2", ")", ",", "max", "(", "x_3_2_v2", ")", ",", "max", "(", "x_3_3_v2", ")", ",", "max", "(", "x_3_4_v2", ")", ",", "max", "(", "x_3_5_v2", ")", ")", ")", "\n", "ylims", "=", "(", "min", "(", "min", "(", "y_3_1_v2", ")", ",", "min", "(", "y_3_2_v2", ")", ",", "min", "(", "y_3_3_v2", ")", ",", "min", "(", "y_3_4_v2", ")", ",", "min", "(", "y_3_5_v2", ")", ")", ",", "\n", "max", "(", "max", "(", "y_3_1_v2", ")", ",", "max", "(", "y_3_2_v2", ")", ",", "max", "(", "y_3_3_v2", ")", ",", "max", "(", "y_3_4_v2", ")", ",", "max", "(", "y_3_5_v2", ")", ")", ")", "\n", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "plot", "(", "x_3_1_v2", ",", "y_3_1_v2", ",", "label", "=", "line_3_1_label_v2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery_3_1_v2", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_1_v2", ",", "y_3_1_v2", "-", "std_3_1_v2", ",", "y_3_1_v2", "+", "std_3_1_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "plot", "(", "x_3_2_v2", ",", "y_3_2_v2", ",", "label", "=", "line_3_2_label_v2", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery_3_2_v2", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_2_v2", ",", "y_3_2_v2", "-", "std_3_2_v2", ",", "y_3_2_v2", "+", "std_3_2_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "plot", "(", "x_3_3_v2", ",", "y_3_3_v2", ",", "label", "=", "line_3_3_label_v2", ",", "marker", "=", "\"p\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#9e66ab\"", ",", "\n", "markevery", "=", "markevery_3_3_v2", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_3_v2", ",", "y_3_3_v2", "-", "std_3_3_v2", ",", "y_3_3_v2", "+", "std_3_3_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#9e66ab\"", ")", "\n", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "plot", "(", "x_3_4_v2", ",", "y_3_4_v2", ",", "label", "=", "line_3_4_label_v2", ",", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "'g'", ",", "\n", "markevery", "=", "markevery_3_4_v2", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_4_v2", ",", "y_3_4_v2", "-", "std_3_4_v2", ",", "y_3_4_v2", "+", "std_3_4_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "'g'", ")", "\n", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "plot", "(", "x_3_5_v2", ",", "y_3_5_v2", ",", "label", "=", "line_3_5_label_v2", ",", "marker", "=", "\"^\"", ",", "ls", "=", "'-'", ",", "color", "=", "'r'", ",", "\n", "markevery", "=", "markevery_3_5_v2", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_5_v2", ",", "y_3_5_v2", "-", "std_3_5_v2", ",", "y_3_5_v2", "+", "std_3_5_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "'r'", ")", "\n", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "#ax[1][2].set_ylim(ylims)", "\n", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "set_title", "(", "title_3_v2", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "set_xlabel", "(", "xlabel_3_v2", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "set_ylabel", "(", "ylabel_3_v2", ")", "\n", "# set the grid on", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "1", "]", "[", "2", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", "[", "2", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "yaxis", ".", "labelpad", "=", "-", "5", "\n", "\n", "# xlab.set_style('italic')", "\n", "# xlab.set_size(10)", "\n", "# ylab.set_style('italic')", "\n", "# ylab.set_size(10)", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# Shrink current axis's height by 10% on the bottom", "\n", "box", "=", "ax", "[", "1", "]", "[", "2", "]", ".", "get_position", "(", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "set_position", "(", "[", "box", ".", "x0", ",", "box", ".", "y0", "+", "box", ".", "height", "*", "0.03", ",", "\n", "box", ".", "width", ",", "box", ".", "height", "*", "0.9", "]", ")", "\n", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "get_yaxis", "(", ")", ".", "set_major_formatter", "(", "tkr", ".", "FuncFormatter", "(", "lambda", "x", ",", "p", ":", "\"${:1.0f}K$\"", ".", "format", "(", "x", "*", "1e-3", ")", ")", ")", "\n", "\n", "\n", "# V3", "\n", "\n", "# Plot avg hack_probability train", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_1_1_v3", ")", ",", "min", "(", "x_1_2_v3", ")", ",", "min", "(", "x_1_3_v3", ")", ",", "min", "(", "x_1_4_v3", ")", ",", "min", "(", "x_1_5_v3", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1_1_v3", ")", ",", "max", "(", "x_1_2_v3", ")", ",", "max", "(", "x_1_3_v3", ")", ",", "max", "(", "x_1_4_v3", ")", ",", "max", "(", "x_1_5_v3", ")", ")", ")", "\n", "ylims", "=", "(", "0", ",", "1", ")", "\n", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "plot", "(", "x_1_1_v3", ",", "y_1_1_v3", ",", "label", "=", "line_1_1_label_v3", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery_1_1_v3", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_1_v3", ",", "np", ".", "maximum", "(", "y_1_1_v3", "-", "std_1_1_v3", ",", "np", ".", "zeros", "(", "len", "(", "y_1_1_v3", ")", ")", ")", ",", "y_1_1_v3", "+", "std_1_1_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "plot", "(", "x_1_2_v3", ",", "y_1_2_v3", ",", "label", "=", "line_1_2_label_v3", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery_1_2_v3", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_2_v3", ",", "np", ".", "maximum", "(", "y_1_2_v3", "-", "std_1_2_v3", ",", "np", ".", "zeros", "(", "len", "(", "y_1_2_v3", ")", ")", ")", ",", "y_1_2_v3", "+", "std_1_2_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "plot", "(", "x_1_3_v3", ",", "y_1_3_v3", ",", "label", "=", "line_1_3_label_v3", ",", "marker", "=", "\"p\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#9e66ab\"", ",", "\n", "markevery", "=", "markevery_1_3_v3", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_3_v3", ",", "np", ".", "maximum", "(", "y_1_3_v3", "-", "std_1_3_v3", ",", "np", ".", "zeros", "(", "len", "(", "y_1_3_v3", ")", ")", ")", ",", "y_1_3_v3", "+", "std_1_3_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#9e66ab\"", ")", "\n", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "plot", "(", "x_1_4_v3", ",", "y_1_4_v3", ",", "label", "=", "line_1_4_label_v3", ",", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "'g'", ",", "\n", "markevery", "=", "markevery_1_4_v3", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_4_v3", ",", "np", ".", "maximum", "(", "y_1_4_v3", "-", "std_1_4_v3", ",", "np", ".", "zeros", "(", "len", "(", "y_1_4_v3", ")", ")", ")", ",", "y_1_4_v3", "+", "std_1_4_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "'g'", ")", "\n", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "plot", "(", "x_1_5_v3", ",", "y_1_5_v3", ",", "label", "=", "line_1_5_label_v3", ",", "marker", "=", "\"^\"", ",", "ls", "=", "'-'", ",", "color", "=", "'r'", ",", "\n", "markevery", "=", "markevery_1_5_v3", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_5_v3", ",", "np", ".", "maximum", "(", "y_1_5_v3", "-", "std_1_5_v3", ",", "np", ".", "zeros", "(", "len", "(", "y_1_5_v3", ")", ")", ")", ",", "y_1_5_v3", "+", "std_1_5_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "'r'", ")", "\n", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "#ax[2][0].set_ylim(ylims)", "\n", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "set_title", "(", "title_1_v3", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "set_xlabel", "(", "xlabel_1_v3", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "set_ylabel", "(", "ylabel_1_v3", ")", "\n", "# set the grid on", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "2", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "2", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# xlab.set_style('italic')", "\n", "# xlab.set_size(8)", "\n", "# ylab.set_style('italic')", "\n", "# ylab.set_size(8)", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# Plot avg hack_probability eval", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_2_1_v3", ")", ",", "min", "(", "x_2_2_v3", ")", ",", "min", "(", "x_2_3_v3", ")", ",", "min", "(", "x_2_4_v3", ")", ",", "min", "(", "x_2_5_v3", ")", ")", ",", "\n", "max", "(", "max", "(", "x_2_1_v3", ")", ",", "max", "(", "x_2_2_v3", ")", ",", "max", "(", "x_2_3_v3", ")", ",", "max", "(", "x_2_4_v3", ")", ",", "max", "(", "x_2_5_v3", ")", ")", ")", "\n", "ylims", "=", "(", "0", ",", "1", ")", "\n", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "plot", "(", "x_2_1_v3", ",", "y_2_1_v3", ",", "label", "=", "line_2_1_label_v3", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery_2_1_v3", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_1_v3", ",", "np", ".", "maximum", "(", "y_2_1_v3", "-", "std_2_1_v3", ",", "np", ".", "zeros", "(", "len", "(", "y_2_1_v3", ")", ")", ")", ",", "y_2_1_v3", "+", "std_2_1_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "plot", "(", "x_2_2_v3", ",", "y_2_2_v3", ",", "label", "=", "line_2_2_label_v3", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery_2_2_v3", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_2_v3", ",", "np", ".", "maximum", "(", "y_2_2_v3", "-", "std_2_2_v3", ",", "np", ".", "zeros", "(", "len", "(", "y_2_1_v3", ")", ")", ")", ",", "y_2_2_v3", "+", "std_2_2_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "plot", "(", "x_2_3_v3", ",", "y_2_3_v3", ",", "label", "=", "line_2_3_label_v3", ",", "marker", "=", "\"p\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#9e66ab\"", ",", "\n", "markevery", "=", "markevery_2_3_v3", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_3_v3", ",", "np", ".", "maximum", "(", "y_2_3_v3", "-", "std_2_3_v3", ",", "np", ".", "zeros", "(", "len", "(", "y_2_1_v3", ")", ")", ")", ",", "y_2_3_v3", "+", "std_2_3_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#9e66ab\"", ")", "\n", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "plot", "(", "x_2_4_v3", ",", "y_2_4_v3", ",", "label", "=", "line_2_4_label_v3", ",", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "'g'", ",", "\n", "markevery", "=", "markevery_2_4_v3", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_4_v3", ",", "np", ".", "maximum", "(", "y_2_4_v3", "-", "std_2_4_v3", ",", "np", ".", "zeros", "(", "len", "(", "y_2_1_v3", ")", ")", ")", ",", "y_2_4_v3", "+", "std_2_4_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "'g'", ")", "\n", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "plot", "(", "x_2_5_v3", ",", "y_2_5_v3", ",", "label", "=", "line_2_5_label_v3", ",", "marker", "=", "\"^\"", ",", "ls", "=", "'-'", ",", "color", "=", "'r'", ",", "\n", "markevery", "=", "markevery_2_5_v3", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_5_v3", ",", "np", ".", "maximum", "(", "y_2_5_v3", "-", "std_2_5_v3", ",", "np", ".", "zeros", "(", "len", "(", "y_2_1_v3", ")", ")", ")", ",", "y_2_5_v3", "+", "std_2_5_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "'r'", ")", "\n", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "#ax[2][1].set_ylim(ylims)", "\n", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "set_title", "(", "title_2_v3", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "set_xlabel", "(", "xlabel_2_v3", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "set_ylabel", "(", "ylabel_2_v3", ")", "\n", "# set the grid on", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "2", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "2", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "\n", "# Shrink current axis's height by 10% on the bottom", "\n", "box", "=", "ax", "[", "2", "]", "[", "1", "]", ".", "get_position", "(", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "set_position", "(", "[", "box", ".", "x0", ",", "box", ".", "y0", "+", "box", ".", "height", "*", "0.03", ",", "\n", "box", ".", "width", ",", "box", ".", "height", "*", "0.9", "]", ")", "\n", "\n", "\n", "# Plot attacker cumulative reward", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_3_1_v3", ")", ",", "min", "(", "x_3_2_v3", ")", ",", "min", "(", "x_3_3_v3", ")", ",", "min", "(", "x_3_4_v3", ")", ",", "min", "(", "x_3_5_v3", ")", ")", ",", "\n", "max", "(", "max", "(", "x_3_1_v3", ")", ",", "max", "(", "x_3_2_v3", ")", ",", "max", "(", "x_3_3_v3", ")", ",", "max", "(", "x_3_4_v3", ")", ",", "max", "(", "x_3_5_v3", ")", ")", ")", "\n", "ylims", "=", "(", "min", "(", "min", "(", "y_3_1_v3", ")", ",", "min", "(", "y_3_2_v3", ")", ",", "min", "(", "y_3_3_v3", ")", ",", "min", "(", "y_3_4_v3", ")", ",", "min", "(", "y_3_5_v3", ")", ")", ",", "\n", "max", "(", "max", "(", "y_3_1_v3", ")", ",", "max", "(", "y_3_2_v3", ")", ",", "max", "(", "y_3_3_v3", ")", ",", "max", "(", "y_3_4_v3", ")", ",", "max", "(", "y_3_5_v3", ")", ")", ")", "\n", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "plot", "(", "x_3_1_v3", ",", "y_3_1_v3", ",", "label", "=", "line_3_1_label_v3", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery_3_1_v3", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_1_v3", ",", "y_3_1_v3", "-", "std_3_1_v3", ",", "y_3_1_v3", "+", "std_3_1_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "plot", "(", "x_3_2_v3", ",", "y_3_2_v3", ",", "label", "=", "line_3_2_label_v3", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery_3_2_v3", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_2_v3", ",", "y_3_2_v3", "-", "std_3_2_v3", ",", "y_3_2_v3", "+", "std_3_2_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "plot", "(", "x_3_3_v3", ",", "y_3_3_v3", ",", "label", "=", "line_3_3_label_v3", ",", "marker", "=", "\"p\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#9e66ab\"", ",", "\n", "markevery", "=", "markevery_3_3_v3", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_3_v3", ",", "y_3_3_v3", "-", "std_3_3_v3", ",", "y_3_3_v3", "+", "std_3_3_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#9e66ab\"", ")", "\n", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "plot", "(", "x_3_4_v3", ",", "y_3_4_v3", ",", "label", "=", "line_3_4_label_v3", ",", "marker", "=", "\"d\"", ",", "ls", "=", "'-'", ",", "color", "=", "'g'", ",", "\n", "markevery", "=", "markevery_3_4_v3", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_4_v3", ",", "y_3_4_v3", "-", "std_3_4_v3", ",", "y_3_4_v3", "+", "std_3_4_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "'g'", ")", "\n", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "plot", "(", "x_3_5_v3", ",", "y_3_5_v3", ",", "label", "=", "line_3_5_label_v3", ",", "marker", "=", "\"^\"", ",", "ls", "=", "'-'", ",", "color", "=", "'r'", ",", "\n", "markevery", "=", "markevery_3_5_v3", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_5_v3", ",", "y_3_5_v3", "-", "std_3_5_v3", ",", "y_3_5_v3", "+", "std_3_5_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "'r'", ")", "\n", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "#ax[2][2].set_ylim(ylims)", "\n", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "set_title", "(", "title_3_v3", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "set_xlabel", "(", "xlabel_3_v3", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "set_ylabel", "(", "ylabel_3_v3", ")", "\n", "# set the grid on", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "2", "]", "[", "2", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "2", "]", "[", "2", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "yaxis", ".", "labelpad", "=", "-", "5", "\n", "\n", "# xlab.set_style('italic')", "\n", "# xlab.set_size(10)", "\n", "# ylab.set_style('italic')", "\n", "# ylab.set_size(10)", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "\n", "# Shrink current axis's height by 10% on the bottom", "\n", "box", "=", "ax", "[", "2", "]", "[", "2", "]", ".", "get_position", "(", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "set_position", "(", "[", "box", ".", "x0", ",", "box", ".", "y0", "+", "box", ".", "height", "*", "0.03", ",", "\n", "box", ".", "width", ",", "box", ".", "height", "*", "0.9", "]", ")", "\n", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "get_yaxis", "(", ")", ".", "set_major_formatter", "(", "tkr", ".", "FuncFormatter", "(", "lambda", "x", ",", "p", ":", "\"${:1.0f}K$\"", ".", "format", "(", "x", "*", "1e-3", ")", ")", ")", "\n", "\n", "#handles, labels = ax.get_legend_handles_labels()", "\n", "lines_labels", "=", "[", "ax", "[", "2", "]", "[", "2", "]", ".", "get_legend_handles_labels", "(", ")", "]", "\n", "lines", ",", "labels", "=", "[", "sum", "(", "lol", ",", "[", "]", ")", "for", "lol", "in", "zip", "(", "*", "lines_labels", ")", "]", "\n", "#ax = fig.add_axes([0.1, 0.1, 0.6, 0.75])", "\n", "if", "algorithm", "!=", "\"dqn\"", ":", "\n", "        ", "fig", ".", "legend", "(", "lines", ",", "labels", ",", "loc", "=", "(", "0.16", ",", "0.01", ")", ",", "ncol", "=", "2", ",", "borderaxespad", "=", "0.", ")", "\n", "", "else", ":", "\n", "        ", "fig", ".", "legend", "(", "lines", ",", "labels", ",", "loc", "=", "(", "0.26", ",", "0.01", ")", ",", "ncol", "=", "2", ",", "borderaxespad", "=", "0.", ")", "\n", "\n", "", "fig", ".", "tight_layout", "(", ")", "\n", "plt", ".", "subplots_adjust", "(", "wspace", "=", "wspace", ",", "hspace", "=", "0.47", ")", "\n", "fig", ".", "subplots_adjust", "(", "bottom", "=", "0.17", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_avg_summary_5": [[1957, 2408], ["matplotlib.rc", "matplotlib.rc", "matplotlib.rcParams.update", "matplotlib.subplots", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "fig.legend", "fig.tight_layout", "matplotlib.subplots_adjust", "fig.subplots_adjust", "fig.savefig", "fig.savefig", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "[].get_legend_handles_labels", "sum", "zip"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot"], ["", "def", "plot_all_avg_summary_5", "(", "x_1_a_v0", ",", "x_1_d_v0", ",", "y_1_a_v0", ",", "y_1_d_v0", ",", "x_2_a_v0", ",", "x_2_d_v0", ",", "y_2_a_v0", ",", "y_2_d_v0", ",", "\n", "x_3_a_v0", ",", "x_3_d_v0", ",", "y_3_a_v0", ",", "y_3_d_v0", ",", "\n", "std_1_a_v0", ",", "std_1_d_v0", ",", "std_2_a_v0", ",", "std_2_d_v0", ",", "std_3_a_v0", ",", "std_3_d_v0", ",", "\n", "\n", "x_1_a_v1", ",", "x_1_d_v1", ",", "y_1_a_v1", ",", "y_1_d_v1", ",", "x_2_a_v1", ",", "x_2_d_v1", ",", "y_2_a_v1", ",", "y_2_d_v1", ",", "\n", "x_3_a_v1", ",", "x_3_d_v1", ",", "y_3_a_v1", ",", "y_3_d_v1", ",", "\n", "std_1_a_v1", ",", "std_1_d_v1", ",", "std_2_a_v1", ",", "std_2_d_v1", ",", "std_3_a_v1", ",", "std_3_d_v1", ",", "\n", "\n", "x_1_a_v2", ",", "x_1_d_v2", ",", "y_1_a_v2", ",", "y_1_d_v2", ",", "x_2_a_v2", ",", "x_2_d_v2", ",", "y_2_a_v2", ",", "y_2_d_v2", ",", "\n", "x_3_a_v2", ",", "x_3_d_v2", ",", "y_3_a_v2", ",", "y_3_d_v2", ",", "\n", "std_1_a_v2", ",", "std_1_d_v2", ",", "std_2_a_v2", ",", "std_2_d_v2", ",", "std_3_a_v2", ",", "std_3_d_v2", ",", "\n", "\n", "x_1_a_v3", ",", "x_1_d_v3", ",", "y_1_a_v3", ",", "y_1_d_v3", ",", "x_2_a_v3", ",", "x_2_d_v3", ",", "y_2_a_v3", ",", "y_2_d_v3", ",", "\n", "x_3_a_v3", ",", "x_3_d_v3", ",", "y_3_a_v3", ",", "y_3_d_v3", ",", "\n", "std_1_a_v3", ",", "std_1_d_v3", ",", "std_2_a_v3", ",", "std_2_d_v3", ",", "std_3_a_v3", ",", "std_3_d_v3", ",", "\n", "\n", "x_1_a_v4", ",", "x_1_d_v4", ",", "y_1_a_v4", ",", "y_1_d_v4", ",", "x_2_a_v4", ",", "x_2_d_v4", ",", "y_2_a_v4", ",", "y_2_d_v4", ",", "\n", "x_3_a_v4", ",", "x_3_d_v4", ",", "y_3_a_v4", ",", "y_3_d_v4", ",", "\n", "std_1_a_v4", ",", "std_1_d_v4", ",", "std_2_a_v4", ",", "std_2_d_v4", ",", "std_3_a_v4", ",", "std_3_d_v4", ",", "\n", "\n", "markevery", ",", "line_label_1", ",", "line_label_2", ",", "title_1", ",", "title_2", ",", "title_3", ",", "title_4", ",", "title_5", ",", "\n", "xlabel", ",", "ylabel", ",", "\n", "file_name", ",", "\n", "wspace", "=", "0.28", "\n", ")", ":", "\n", "\n", "    ", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "plt", ".", "rcParams", ".", "update", "(", "{", "'font.size'", ":", "6", "}", ")", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "5", ",", "ncols", "=", "3", ",", "figsize", "=", "(", "8", ",", "7", ")", ")", "\n", "\n", "# MaxAttack vs DQN", "\n", "# V8", "\n", "xlims", "=", "(", "min", "(", "x_1_d_v0", ")", ",", "max", "(", "x_1_d_v0", ")", ")", "\n", "ylims", "=", "(", "min", "(", "y_1_d_v0", "-", "std_1_d_v0", ")", ",", "max", "(", "y_1_d_v0", "+", "std_1_d_v0", ")", ")", "\n", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "plot", "(", "x_1_d_v0", ",", "y_1_d_v0", ",", "label", "=", "line_label_2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_d_v0", ",", "y_1_d_v0", "-", "std_1_d_v0", ",", "y_1_d_v0", "+", "std_1_d_v0", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "#ax[0][0].set_ylim(ylims)", "\n", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_title", "(", "title_1", "+", "\" v0\"", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "0", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "0", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# V9", "\n", "xlims", "=", "(", "min", "(", "x_2_d_v0", ")", ",", "max", "(", "x_2_d_v0", ")", ")", "\n", "ylims", "=", "(", "min", "(", "y_2_d_v0", "-", "std_2_d_v0", ")", ",", "max", "(", "y_2_d_v0", "+", "std_2_d_v0", ")", ")", "\n", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "plot", "(", "x_2_d_v0", ",", "y_2_d_v0", ",", "label", "=", "line_label_2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_d_v0", ",", "y_2_d_v0", "-", "std_2_d_v0", ",", "y_2_d_v0", "+", "std_2_d_v0", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "#ax[0][1].set_ylim(ylims)", "\n", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_title", "(", "title_1", "+", "\" v1\"", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "0", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "0", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# V7", "\n", "xlims", "=", "(", "min", "(", "x_3_d_v0", ")", ",", "max", "(", "x_3_d_v0", ")", ")", "\n", "ylims", "=", "(", "min", "(", "y_3_d_v0", "-", "std_3_d_v0", ")", ",", "max", "(", "y_3_d_v0", "+", "std_3_d_v0", ")", ")", "\n", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "plot", "(", "x_3_d_v0", ",", "y_3_d_v0", ",", "label", "=", "line_label_2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery", ")", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_d_v0", ",", "y_3_d_v0", "-", "std_3_d_v0", ",", "y_3_d_v0", "+", "std_3_d_v0", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[0][2].set_ylim(ylims)", "\n", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "set_title", "(", "title_1", "+", "\" v2\"", ")", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "0", "]", "[", "2", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "0", "]", "[", "2", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# DQN vs MinDefense", "\n", "# V8", "\n", "xlims", "=", "(", "min", "(", "x_1_a_v1", ")", ",", "max", "(", "x_1_a_v1", ")", ")", "\n", "ylims", "=", "(", "min", "(", "y_1_a_v1", "-", "std_1_a_v1", ")", ",", "max", "(", "y_1_a_v1", "+", "std_1_a_v1", ")", ")", "\n", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "plot", "(", "x_1_a_v1", ",", "y_1_a_v1", ",", "label", "=", "line_label_2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#599ad3'", ",", "\n", "markevery", "=", "markevery", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_a_v1", ",", "y_1_a_v1", "-", "std_1_a_v1", ",", "y_1_a_v1", "+", "std_1_a_v1", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "'#599ad3'", ")", "\n", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[1][0].set_ylim(ylims)", "\n", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_title", "(", "title_2", "+", "\" v0\"", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "1", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# V9", "\n", "xlims", "=", "(", "min", "(", "x_2_a_v1", ")", ",", "max", "(", "x_2_a_v1", ")", ")", "\n", "ylims", "=", "(", "min", "(", "y_2_a_v1", "-", "std_2_a_v1", ")", ",", "max", "(", "y_2_a_v1", "+", "std_2_a_v1", ")", ")", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "plot", "(", "x_2_a_v1", ",", "y_2_a_v1", ",", "label", "=", "line_label_2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#599ad3'", ",", "\n", "markevery", "=", "markevery", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_a_v1", ",", "y_2_a_v1", "-", "std_2_a_v1", ",", "y_2_a_v1", "+", "std_2_a_v1", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "'#599ad3'", ")", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[1][1].set_ylim(ylims)", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_title", "(", "title_2", "+", "\" v1\"", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "1", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# V7", "\n", "xlims", "=", "(", "min", "(", "x_3_a_v1", ")", ",", "max", "(", "x_3_a_v1", ")", ")", "\n", "ylims", "=", "(", "min", "(", "y_3_a_v1", "-", "std_3_a_v1", ")", ",", "max", "(", "y_3_a_v1", "+", "std_3_a_v1", ")", ")", "\n", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "plot", "(", "x_3_a_v1", ",", "y_3_a_v1", ",", "label", "=", "line_label_2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#599ad3'", ",", "\n", "markevery", "=", "markevery", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_a_v1", ",", "y_3_a_v1", "-", "std_3_a_v1", ",", "y_3_a_v1", "+", "std_3_a_v1", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "'#599ad3'", ")", "\n", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[1][2].set_ylim(ylims)", "\n", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "set_title", "(", "title_2", "+", "\" v2\"", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "1", "]", "[", "2", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", "[", "2", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# RandomAttack vs DQN", "\n", "# V8", "\n", "xlims", "=", "(", "min", "(", "x_1_d_v2", ")", ",", "max", "(", "x_1_d_v2", ")", ")", "\n", "ylims", "=", "(", "min", "(", "y_1_d_v2", "-", "std_1_d_v2", ")", ",", "max", "(", "y_1_d_v2", "+", "std_1_d_v2", ")", ")", "\n", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "plot", "(", "x_1_d_v2", ",", "y_1_d_v2", ",", "label", "=", "line_label_2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_d_v2", ",", "y_1_d_v2", "-", "std_1_d_v2", ",", "y_1_d_v2", "+", "std_1_d_v2", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[2][0].set_ylim(ylims)", "\n", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "set_title", "(", "title_3", "+", "\" v0\"", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "2", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "2", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# V9", "\n", "xlims", "=", "(", "min", "(", "x_2_d_v2", ")", ",", "max", "(", "x_2_d_v2", ")", ")", "\n", "ylims", "=", "(", "min", "(", "y_2_d_v2", "-", "std_2_d_v2", ")", ",", "max", "(", "y_2_d_v2", "+", "std_2_d_v2", ")", ")", "\n", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "plot", "(", "x_2_d_v2", ",", "y_2_d_v2", ",", "label", "=", "line_label_2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_d_v2", ",", "y_2_d_v2", "-", "std_2_d_v2", ",", "y_2_d_v2", "+", "std_2_d_v2", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[2][1].set_ylim(ylims)", "\n", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "set_title", "(", "title_3", "+", "\" v1\"", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "2", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "2", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# V7", "\n", "xlims", "=", "(", "min", "(", "x_3_d_v2", ")", ",", "max", "(", "x_3_d_v2", ")", ")", "\n", "ylims", "=", "(", "min", "(", "y_3_d_v2", "-", "std_3_d_v2", ")", ",", "max", "(", "y_3_d_v2", "+", "std_3_d_v2", ")", ")", "\n", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "plot", "(", "x_3_d_v2", ",", "y_3_d_v2", ",", "label", "=", "line_label_2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_d_v2", ",", "y_3_d_v2", "-", "std_3_d_v2", ",", "y_3_d_v2", "+", "std_3_d_v2", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[2][2].set_ylim(ylims)", "\n", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "set_title", "(", "title_3", "+", "\" v2\"", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "2", "]", "[", "2", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "2", "]", "[", "2", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# DQN vs RandomDefense", "\n", "# V8", "\n", "xlims", "=", "(", "min", "(", "x_1_a_v3", ")", ",", "max", "(", "x_1_a_v3", ")", ")", "\n", "ylims", "=", "(", "min", "(", "y_1_a_v3", "-", "std_1_a_v3", ")", ",", "max", "(", "y_1_a_v3", "+", "std_1_a_v3", ")", ")", "\n", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "plot", "(", "x_1_a_v3", ",", "y_1_a_v3", ",", "label", "=", "line_label_2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#599ad3'", ",", "\n", "markevery", "=", "markevery", ")", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_a_v3", ",", "y_1_a_v3", "-", "std_1_a_v3", ",", "y_1_a_v3", "+", "std_1_a_v3", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "'#599ad3'", ")", "\n", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[3][0].set_ylim(ylims)", "\n", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "set_title", "(", "title_4", "+", "\" v0\"", ")", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "3", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "3", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# V9", "\n", "xlims", "=", "(", "min", "(", "x_2_a_v3", ")", ",", "max", "(", "x_2_a_v3", ")", ")", "\n", "#ylims = (min(y_2_a_v3 - std_2_a_v3), max(y_2_a_v3 + std_2_a_v3))", "\n", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "plot", "(", "x_2_a_v3", ",", "y_2_a_v3", ",", "label", "=", "line_label_2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#599ad3'", ",", "\n", "markevery", "=", "markevery", ")", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_a_v3", ",", "y_2_a_v3", "-", "std_2_a_v3", ",", "y_2_a_v3", "+", "std_2_a_v3", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "'#599ad3'", ")", "\n", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[3][1].set_ylim(ylims)", "\n", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "set_title", "(", "title_4", "+", "\" v1\"", ")", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "3", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "3", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# V7", "\n", "xlims", "=", "(", "min", "(", "x_3_a_v3", ")", ",", "max", "(", "x_3_a_v3", ")", ")", "\n", "ylims", "=", "(", "min", "(", "y_3_a_v3", "-", "std_3_a_v3", ")", ",", "max", "(", "y_3_a_v3", "+", "std_3_a_v3", ")", ")", "\n", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "plot", "(", "x_3_a_v3", ",", "y_3_a_v3", ",", "label", "=", "line_label_2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#599ad3'", ",", "\n", "markevery", "=", "markevery", ")", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_a_v3", ",", "y_3_a_v3", "-", "std_3_a_v3", ",", "y_3_a_v3", "+", "std_3_a_v4", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "'#599ad3'", ")", "\n", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[3][2].set_ylim(ylims)", "\n", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "set_title", "(", "title_4", "+", "\" v2\"", ")", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "3", "]", "[", "2", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "3", "]", "[", "2", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# DQN vs DQN", "\n", "# V8", "\n", "xlims", "=", "(", "min", "(", "x_1_a_v4", ")", ",", "max", "(", "x_1_a_v4", ")", ")", "\n", "ylims", "=", "(", "min", "(", "y_1_a_v4", "-", "std_1_a_v4", ")", ",", "max", "(", "y_1_a_v4", "+", "std_1_a_v4", ")", ")", "\n", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "plot", "(", "x_1_a_v4", ",", "y_1_a_v4", ",", "label", "=", "line_label_1", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#599ad3'", ",", "\n", "markevery", "=", "markevery", ")", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_a_v4", ",", "y_1_a_v4", "-", "std_1_a_v4", ",", "y_1_a_v4", "+", "std_1_a_v4", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "'#599ad3'", ")", "\n", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "plot", "(", "x_1_d_v4", ",", "y_1_d_v4", ",", "label", "=", "line_label_2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery", ")", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_d_v4", ",", "y_1_d_v4", "-", "std_1_d_v4", ",", "y_1_d_v4", "+", "std_1_d_v4", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[4][0].set_ylim(ylims)", "\n", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "set_title", "(", "title_4", "+", "\" v0\"", ")", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "4", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "4", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# V9", "\n", "xlims", "=", "(", "min", "(", "x_2_a_v4", ")", ",", "max", "(", "x_2_a_v4", ")", ")", "\n", "ylims", "=", "(", "min", "(", "y_2_a_v4", "-", "std_2_a_v4", ")", ",", "max", "(", "y_2_a_v4", "+", "std_2_a_v4", ")", ")", "\n", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "plot", "(", "x_2_a_v4", ",", "y_2_a_v4", ",", "label", "=", "line_label_1", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#599ad3'", ",", "\n", "markevery", "=", "markevery", ")", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_a_v4", ",", "y_2_a_v4", "-", "std_2_a_v4", ",", "y_2_a_v4", "+", "std_2_a_v4", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "'#599ad3'", ")", "\n", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "plot", "(", "x_2_d_v4", ",", "y_2_d_v4", ",", "label", "=", "line_label_2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery", ")", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "fill_between", "(", "x_2_d_v4", ",", "y_2_d_v4", "-", "std_2_d_v4", ",", "y_2_d_v4", "+", "std_2_d_v4", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[4][1].set_ylim(ylims)", "\n", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "set_title", "(", "title_4", "+", "\" v1\"", ")", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "4", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "4", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# V7", "\n", "xlims", "=", "(", "min", "(", "x_3_a_v4", ")", ",", "max", "(", "x_3_a_v4", ")", ")", "\n", "ylims", "=", "(", "min", "(", "y_3_a_v4", "-", "std_3_a_v4", ")", ",", "max", "(", "y_3_a_v4", "+", "std_3_a_v4", ")", ")", "\n", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "plot", "(", "x_3_a_v4", ",", "y_3_a_v4", ",", "label", "=", "line_label_1", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#599ad3'", ",", "\n", "markevery", "=", "markevery", ")", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_a_v4", ",", "y_3_a_v4", "-", "std_3_a_v4", ",", "y_3_a_v4", "+", "std_3_a_v4", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "'#599ad3'", ")", "\n", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "plot", "(", "x_3_d_v4", ",", "y_3_d_v4", ",", "label", "=", "line_label_2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery", ")", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "fill_between", "(", "x_3_d_v4", ",", "y_3_d_v4", "-", "std_3_d_v4", ",", "y_3_d_v4", "+", "std_3_d_v4", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[4][2].set_ylim(ylims)", "\n", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "set_title", "(", "title_4", "+", "\" v2\"", ")", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "4", "]", "[", "2", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "4", "]", "[", "2", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "lines_labels", "=", "[", "ax", "[", "4", "]", "[", "1", "]", ".", "get_legend_handles_labels", "(", ")", "]", "\n", "lines", ",", "labels", "=", "[", "sum", "(", "lol", ",", "[", "]", ")", "for", "lol", "in", "zip", "(", "*", "lines_labels", ")", "]", "\n", "# ax = fig.add_axes([0.1, 0.1, 0.6, 0.75])", "\n", "fig", ".", "legend", "(", "lines", ",", "labels", ",", "loc", "=", "(", "0.4", ",", "0.012", ")", ",", "ncol", "=", "2", ",", "borderaxespad", "=", "0.", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "plt", ".", "subplots_adjust", "(", "wspace", "=", "wspace", ",", "hspace", "=", "0.7", ")", "\n", "fig", ".", "subplots_adjust", "(", "bottom", "=", "0.08", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_avg_summary_4": [[2409, 2986], ["matplotlib.rc", "matplotlib.rc", "matplotlib.rcParams.update", "matplotlib.subplots", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].xaxis.get_label.set_size", "[].yaxis.get_label.set_size", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "[].plot", "[].fill_between", "[].plot", "[].fill_between", "[].set_xlim", "[].set_title", "[].set_xlabel", "[].set_ylabel", "[].grid", "[].xaxis.get_label", "[].yaxis.get_label", "[].spines[].set_color", "[].spines[].set_color", "fig.legend", "fig.tight_layout", "matplotlib.subplots_adjust", "fig.subplots_adjust", "fig.savefig", "fig.savefig", "min", "max", "max", "max", "numpy.maximum", "numpy.maximum", "min", "max", "max", "max", "numpy.maximum", "numpy.maximum", "min", "max", "min", "max", "numpy.maximum", "numpy.maximum", "min", "max", "max", "max", "numpy.maximum", "numpy.maximum", "min", "max", "max", "max", "numpy.maximum", "numpy.maximum", "min", "max", "max", "max", "numpy.maximum", "numpy.maximum", "min", "max", "max", "max", "numpy.maximum", "numpy.maximum", "min", "max", "min", "max", "numpy.maximum", "numpy.maximum", "min", "max", "max", "max", "numpy.maximum", "numpy.maximum", "min", "max", "min", "max", "numpy.maximum", "numpy.maximum", "min", "max", "max", "max", "numpy.maximum", "numpy.maximum", "min", "max", "max", "max", "numpy.maximum", "numpy.maximum", "min", "max", "max", "max", "numpy.maximum", "numpy.maximum", "min", "max", "min", "max", "numpy.maximum", "numpy.maximum", "min", "max", "min", "max", "numpy.maximum", "numpy.maximum", "[].get_legend_handles_labels", "sum", "len", "len", "len", "len", "len", "min", "min", "max", "max", "min", "max", "max", "numpy.zeros", "numpy.zeros", "min", "min", "max", "max", "min", "max", "max", "numpy.zeros", "numpy.zeros", "min", "min", "max", "max", "min", "min", "max", "max", "numpy.zeros", "numpy.zeros", "min", "min", "max", "max", "min", "max", "max", "numpy.zeros", "numpy.zeros", "min", "min", "max", "max", "min", "max", "max", "numpy.zeros", "numpy.zeros", "min", "min", "max", "max", "min", "max", "max", "numpy.zeros", "numpy.zeros", "min", "min", "max", "max", "min", "max", "max", "numpy.zeros", "numpy.zeros", "min", "min", "max", "max", "min", "min", "max", "max", "numpy.zeros", "numpy.zeros", "min", "min", "max", "max", "min", "max", "max", "numpy.zeros", "numpy.zeros", "min", "min", "max", "max", "min", "min", "max", "max", "numpy.zeros", "numpy.zeros", "min", "min", "max", "max", "min", "max", "max", "numpy.zeros", "numpy.zeros", "min", "min", "max", "max", "min", "max", "max", "numpy.zeros", "numpy.zeros", "min", "min", "max", "max", "min", "max", "max", "numpy.zeros", "numpy.zeros", "min", "min", "max", "max", "min", "min", "max", "max", "numpy.zeros", "numpy.zeros", "min", "min", "max", "max", "min", "min", "max", "max", "numpy.zeros", "numpy.zeros", "zip", "min", "min", "len", "len", "min", "min", "len", "len", "len", "len", "min", "min", "len", "len", "min", "min", "len", "len", "min", "min", "len", "len", "min", "min", "len", "len", "len", "len", "min", "min", "len", "len", "len", "len", "min", "min", "len", "len", "min", "min", "len", "len", "min", "min", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot"], ["", "def", "plot_all_avg_summary_4", "(", "x_1_1_v0", ",", "y_1_1_v0", ",", "x_1_2_v0", ",", "y_1_2_v0", ",", "x_1_3_v0", ",", "y_1_3_v0", ",", "x_1_4_v0", ",", "y_1_4_v0", ",", "\n", "x_1_5_v0", ",", "y_1_5_v0", ",", "x_1_6_v0", ",", "y_1_6_v0", ",", "\n", "std_1_1_v0", ",", "std_1_2_v0", ",", "std_1_3_v0", ",", "std_1_4_v0", ",", "std_1_5_v0", ",", "std_1_6_v0", ",", "\n", "line_1_1_label_v0", ",", "line_1_2_label_v0", ",", "line_1_3_label_v0", ",", "line_1_4_label_v0", ",", "\n", "line_1_5_label_v0", ",", "line_1_6_label_v0", ",", "title_1_v0", ",", "xlabel_1_v0", ",", "ylabel_1_v0", ",", "\n", "markevery_1_1_v0", ",", "markevery_1_2_v0", ",", "markevery_1_3_v0", ",", "markevery_1_4_v0", ",", "markevery_1_5_v0", ",", "\n", "markevery_1_6_v0", ",", "\n", "\n", "x_1_1_v1", ",", "y_1_1_v1", ",", "x_1_2_v1", ",", "y_1_2_v1", ",", "x_1_3_v1", ",", "y_1_3_v1", ",", "x_1_4_v1", ",", "y_1_4_v1", ",", "\n", "x_1_5_v1", ",", "y_1_5_v1", ",", "x_1_6_v1", ",", "y_1_6_v1", ",", "\n", "std_1_1_v1", ",", "std_1_2_v1", ",", "std_1_3_v1", ",", "std_1_4_v1", ",", "std_1_5_v1", ",", "std_1_6_v1", ",", "\n", "line_1_1_label_v1", ",", "line_1_2_label_v1", ",", "line_1_3_label_v1", ",", "line_1_4_label_v1", ",", "\n", "line_1_5_label_v1", ",", "line_1_6_label_v1", ",", "title_1_v1", ",", "xlabel_1_v1", ",", "ylabel_1_v1", ",", "\n", "markevery_1_1_v1", ",", "markevery_1_2_v1", ",", "markevery_1_3_v1", ",", "markevery_1_4_v1", ",", "markevery_1_5_v1", ",", "\n", "markevery_1_6_v1", ",", "\n", "\n", "x_1_1_v2", ",", "y_1_1_v2", ",", "x_1_2_v2", ",", "y_1_2_v2", ",", "x_1_3_v2", ",", "y_1_3_v2", ",", "x_1_4_v2", ",", "y_1_4_v2", ",", "\n", "x_1_5_v2", ",", "y_1_5_v2", ",", "x_1_6_v2", ",", "y_1_6_v2", ",", "\n", "std_1_1_v2", ",", "std_1_2_v2", ",", "std_1_3_v2", ",", "std_1_4_v2", ",", "std_1_5_v2", ",", "std_1_6_v2", ",", "\n", "line_1_1_label_v2", ",", "line_1_2_label_v2", ",", "line_1_3_label_v2", ",", "line_1_4_label_v2", ",", "\n", "line_1_5_label_v2", ",", "line_1_6_label_v2", ",", "title_1_v2", ",", "xlabel_1_v2", ",", "ylabel_1_v2", ",", "\n", "markevery_1_1_v2", ",", "markevery_1_2_v2", ",", "markevery_1_3_v2", ",", "markevery_1_4_v2", ",", "markevery_1_5_v2", ",", "\n", "markevery_1_6_v2", ",", "\n", "\n", "x_1_1_v3", ",", "y_1_1_v3", ",", "x_1_2_v3", ",", "y_1_2_v3", ",", "x_1_3_v3", ",", "y_1_3_v3", ",", "x_1_4_v3", ",", "y_1_4_v3", ",", "\n", "x_1_5_v3", ",", "y_1_5_v3", ",", "x_1_6_v3", ",", "y_1_6_v3", ",", "\n", "std_1_1_v3", ",", "std_1_2_v3", ",", "std_1_3_v3", ",", "std_1_4_v3", ",", "std_1_5_v3", ",", "std_1_6_v3", ",", "\n", "line_1_1_label_v3", ",", "line_1_2_label_v3", ",", "line_1_3_label_v3", ",", "line_1_4_label_v3", ",", "\n", "line_1_5_label_v3", ",", "line_1_6_label_v3", ",", "title_1_v3", ",", "xlabel_1_v3", ",", "ylabel_1_v3", ",", "\n", "markevery_1_1_v3", ",", "markevery_1_2_v3", ",", "markevery_1_3_v3", ",", "markevery_1_4_v3", ",", "markevery_1_5_v3", ",", "\n", "markevery_1_6_v3", ",", "\n", "\n", "x_1_1_v4", ",", "y_1_1_v4", ",", "x_1_2_v4", ",", "y_1_2_v4", ",", "x_1_3_v4", ",", "y_1_3_v4", ",", "x_1_4_v4", ",", "y_1_4_v4", ",", "\n", "x_1_5_v4", ",", "y_1_5_v4", ",", "x_1_6_v4", ",", "y_1_6_v4", ",", "\n", "std_1_1_v4", ",", "std_1_2_v4", ",", "std_1_3_v4", ",", "std_1_4_v4", ",", "std_1_5_v4", ",", "std_1_6_v4", ",", "\n", "line_1_1_label_v4", ",", "line_1_2_label_v4", ",", "line_1_3_label_v4", ",", "line_1_4_label_v4", ",", "\n", "line_1_5_label_v4", ",", "line_1_6_label_v4", ",", "title_1_v4", ",", "xlabel_1_v4", ",", "ylabel_1_v4", ",", "\n", "markevery_1_1_v4", ",", "markevery_1_2_v4", ",", "markevery_1_3_v4", ",", "markevery_1_4_v4", ",", "markevery_1_5_v4", ",", "\n", "markevery_1_6_v4", ",", "\n", "\n", "file_name", ",", "\n", "wspace", "=", "0.28", "\n", ")", ":", "\n", "    ", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "plt", ".", "rcParams", ".", "update", "(", "{", "'font.size'", ":", "6", "}", ")", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "5", ",", "ncols", "=", "3", ",", "figsize", "=", "(", "8", ",", "7", ")", ")", "\n", "#gs1 = gridspec.GridSpec(1, 4)", "\n", "#gs1.update(wspace=0.005, hspace=0.05)", "\n", "\n", "if", "len", "(", "x_1_1_v0", ")", "/", "markevery_1_1_v0", ">", "15", ":", "\n", "        ", "markevery_1_1_v0", "=", "2", "\n", "markevery_1_2_v0", "=", "2", "\n", "markevery_1_3_v0", "=", "2", "\n", "markevery_1_4_v0", "=", "2", "\n", "markevery_1_5_v0", "=", "2", "\n", "markevery_1_6_v0", "=", "2", "\n", "\n", "", "if", "len", "(", "x_1_1_v1", ")", "/", "markevery_1_1_v1", ">", "15", ":", "\n", "        ", "markevery_1_1_v1", "=", "2", "\n", "markevery_1_2_v1", "=", "2", "\n", "markevery_1_3_v1", "=", "2", "\n", "markevery_1_4_v1", "=", "2", "\n", "markevery_1_5_v1", "=", "2", "\n", "markevery_1_6_v1", "=", "2", "\n", "\n", "", "if", "len", "(", "x_1_1_v2", ")", "/", "markevery_1_1_v2", ">", "15", ":", "\n", "        ", "markevery_1_1_v2", "=", "2", "\n", "markevery_1_2_v2", "=", "2", "\n", "markevery_1_3_v2", "=", "2", "\n", "markevery_1_4_v2", "=", "2", "\n", "markevery_1_5_v2", "=", "2", "\n", "markevery_1_6_v2", "=", "2", "\n", "\n", "", "if", "len", "(", "x_1_1_v3", ")", "/", "markevery_1_1_v3", ">", "15", ":", "\n", "        ", "markevery_1_1_v3", "=", "2", "\n", "markevery_1_2_v3", "=", "2", "\n", "markevery_1_3_v3", "=", "2", "\n", "markevery_1_4_v3", "=", "2", "\n", "markevery_1_5_v3", "=", "2", "\n", "markevery_1_6_v3", "=", "2", "\n", "\n", "", "if", "len", "(", "x_1_1_v4", ")", "/", "markevery_1_1_v4", ">", "15", ":", "\n", "        ", "markevery_1_1_v4", "=", "2", "\n", "markevery_1_2_v4", "=", "2", "\n", "markevery_1_3_v4", "=", "2", "\n", "markevery_1_4_v4", "=", "2", "\n", "markevery_1_5_v4", "=", "2", "\n", "markevery_1_6_v4", "=", "2", "\n", "\n", "# if len(x_1_1_v5) / markevery_1_1_v5 > 15:", "\n", "#     markevery_1_1_v5 = 2", "\n", "#     markevery_1_2_v5 = 2", "\n", "#     markevery_1_3_v5 = 2", "\n", "#     markevery_1_4_v5 = 2", "\n", "#     markevery_1_5_v5 = 2", "\n", "#     markevery_1_6_v5 = 2", "\n", "\n", "\n", "# TabQ vs TabQ", "\n", "# Plot avg hack_probability", "\n", "", "xlims", "=", "(", "min", "(", "min", "(", "x_1_1_v0", ")", ",", "min", "(", "x_1_4_v0", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1_1_v0", ")", ",", "max", "(", "x_1_4_v0", ")", ")", ")", "\n", "ylims", "=", "(", "max", "(", "min", "(", "min", "(", "y_1_1_v0", "-", "std_1_1_v0", ")", ",", "min", "(", "y_1_4_v0", "-", "std_1_4_v0", ")", ")", ",", "0", ")", ",", "\n", "max", "(", "max", "(", "y_1_1_v0", "+", "std_1_1_v0", ")", ",", "max", "(", "y_1_4_v0", "+", "std_1_4_v0", ")", ")", ")", "\n", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "plot", "(", "x_1_1_v0", ",", "y_1_1_v0", ",", "label", "=", "line_1_1_label_v0", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "markevery", "=", "markevery_1_1_v0", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_1_v0", ",", "np", ".", "maximum", "(", "y_1_1_v0", "-", "std_1_1_v0", ",", "np", ".", "zeros", "(", "len", "(", "y_1_1_v0", ")", ")", ")", ",", "y_1_1_v0", "+", "std_1_1_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "plot", "(", "x_1_4_v0", ",", "y_1_4_v0", ",", "label", "=", "line_1_4_label_v0", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "markevery", "=", "markevery_1_4_v0", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_4_v0", ",", "np", ".", "maximum", "(", "y_1_4_v0", "-", "std_1_4_v0", ",", "np", ".", "zeros", "(", "len", "(", "y_1_4_v0", ")", ")", ")", ",", "y_1_4_v0", "+", "std_1_4_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[0][0].set_ylim(ylims)", "\n", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_title", "(", "title_1_v0", "+", "\" v0\"", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_xlabel", "(", "xlabel_1_v0", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_ylabel", "(", "ylabel_1_v0", ")", "\n", "# set the grid on", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "0", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "0", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# # Plot avg hack_probability", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_1_2_v0", ")", ",", "min", "(", "x_1_5_v0", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1_2_v0", ")", ",", "max", "(", "x_1_5_v0", ")", ")", ")", "\n", "ylims", "=", "(", "max", "(", "min", "(", "min", "(", "y_1_2_v0", "-", "std_1_2_v0", ")", ",", "min", "(", "y_1_5_v0", "-", "std_1_5_v0", ")", ")", ",", "0", ")", ",", "\n", "max", "(", "max", "(", "y_1_2_v0", "+", "std_1_2_v0", ")", ",", "max", "(", "y_1_5_v0", "+", "std_1_5_v0", ")", ")", ")", "\n", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "plot", "(", "x_1_2_v0", ",", "y_1_2_v0", ",", "label", "=", "line_1_2_label_v0", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "markevery", "=", "markevery_1_2_v0", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "fill_between", "(", "x_1_2_v0", ",", "np", ".", "maximum", "(", "y_1_2_v0", "-", "std_1_2_v0", ",", "np", ".", "zeros", "(", "len", "(", "y_1_2_v0", ")", ")", ")", ",", "y_1_2_v0", "+", "std_1_2_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "plot", "(", "x_1_5_v0", ",", "y_1_5_v0", ",", "label", "=", "line_1_5_label_v0", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "markevery", "=", "markevery_1_5_v0", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "fill_between", "(", "x_1_5_v0", ",", "np", ".", "maximum", "(", "y_1_5_v0", "-", "std_1_5_v0", ",", "np", ".", "zeros", "(", "len", "(", "y_1_5_v0", ")", ")", ")", ",", "y_1_5_v0", "+", "std_1_5_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[0][1].set_ylim(ylims)", "\n", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_title", "(", "title_1_v0", "+", "\" v1\"", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_xlabel", "(", "xlabel_1_v0", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "set_ylabel", "(", "ylabel_1_v0", ")", "\n", "# set the grid on", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "0", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "0", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "0", "]", "[", "1", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# Plot", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_1_3_v0", ")", ",", "min", "(", "x_1_6_v0", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1_3_v0", ")", ",", "max", "(", "x_1_6_v0", ")", ")", ")", "\n", "ylims", "=", "(", "min", "(", "min", "(", "y_1_3_v0", "-", "std_1_3_v0", ")", ",", "min", "(", "y_1_6_v0", "-", "std_1_6_v0", ")", ")", ",", "\n", "max", "(", "max", "(", "y_1_3_v0", "+", "std_1_3_v0", ")", ",", "max", "(", "y_1_6_v0", "+", "std_1_6_v0", ")", ")", ")", "\n", "\n", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "plot", "(", "x_1_3_v0", ",", "y_1_3_v0", ",", "label", "=", "line_1_3_label_v0", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "markevery", "=", "markevery_1_3_v0", ")", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "fill_between", "(", "x_1_3_v0", ",", "np", ".", "maximum", "(", "y_1_3_v0", "-", "std_1_3_v0", ",", "np", ".", "zeros", "(", "len", "(", "y_1_3_v0", ")", ")", ")", ",", "y_1_3_v0", "+", "std_1_3_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "plot", "(", "x_1_6_v0", ",", "y_1_6_v0", ",", "label", "=", "line_1_6_label_v0", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "markevery", "=", "markevery_1_4_v0", ")", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "fill_between", "(", "x_1_6_v0", ",", "np", ".", "maximum", "(", "y_1_6_v0", "-", "std_1_6_v0", ",", "np", ".", "zeros", "(", "len", "(", "y_1_6_v0", ")", ")", ")", ",", "y_1_6_v0", "+", "std_1_6_v0", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[0][2].set_ylim(ylims)", "\n", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "set_title", "(", "title_1_v0", "+", "\" v2\"", ")", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "set_xlabel", "(", "xlabel_1_v0", ")", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "set_ylabel", "(", "ylabel_1_v0", ")", "\n", "# set the grid on", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "0", "]", "[", "2", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "0", "]", "[", "2", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "0", "]", "[", "2", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# MaxA vs TabQ", "\n", "# Plot avg hack_probability", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_1_1_v1", ")", ",", "min", "(", "x_1_4_v1", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1_1_v1", ")", ",", "max", "(", "x_1_4_v1", ")", ")", ")", "\n", "ylims", "=", "(", "max", "(", "min", "(", "min", "(", "y_1_1_v1", "-", "std_1_1_v1", ")", ",", "min", "(", "y_1_4_v1", "-", "std_1_4_v1", ")", ")", ",", "0", ")", ",", "\n", "max", "(", "max", "(", "y_1_1_v1", "+", "std_1_1_v1", ")", ",", "max", "(", "y_1_4_v1", "+", "std_1_4_v1", ")", ")", ")", "\n", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "plot", "(", "x_1_1_v1", ",", "y_1_1_v1", ",", "label", "=", "line_1_1_label_v1", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery_1_1_v1", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_1_v1", ",", "np", ".", "maximum", "(", "y_1_1_v1", "-", "std_1_1_v1", ",", "np", ".", "zeros", "(", "len", "(", "y_1_1_v1", ")", ")", ")", ",", "y_1_1_v1", "+", "std_1_1_v1", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "plot", "(", "x_1_4_v1", ",", "y_1_4_v1", ",", "label", "=", "line_1_4_label_v1", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery_1_4_v1", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_4_v1", ",", "np", ".", "maximum", "(", "y_1_4_v1", "-", "std_1_4_v1", ",", "np", ".", "zeros", "(", "len", "(", "y_1_4_v1", ")", ")", ")", ",", "y_1_4_v1", "+", "std_1_4_v1", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[1][0].set_ylim(ylims)", "\n", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_title", "(", "title_1_v1", "+", "\" v0\"", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_xlabel", "(", "xlabel_1_v1", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_ylabel", "(", "ylabel_1_v1", ")", "\n", "# set the grid on", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "1", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# # Plot avg hack_probability", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_1_2_v1", ")", ",", "min", "(", "x_1_5_v1", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1_2_v1", ")", ",", "max", "(", "x_1_5_v1", ")", ")", ")", "\n", "ylims", "=", "(", "max", "(", "min", "(", "min", "(", "y_1_2_v1", "-", "std_1_2_v1", ")", ",", "min", "(", "y_1_5_v1", "-", "std_1_5_v1", ")", ")", ",", "0", ")", ",", "\n", "max", "(", "max", "(", "y_1_2_v1", "+", "std_1_2_v1", ")", ",", "max", "(", "y_1_5_v1", "+", "std_1_5_v1", ")", ")", ")", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "plot", "(", "x_1_2_v1", ",", "y_1_2_v1", ",", "label", "=", "line_1_2_label_v1", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery_1_2_v1", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "fill_between", "(", "x_1_2_v1", ",", "np", ".", "maximum", "(", "y_1_2_v1", "-", "std_1_2_v1", ",", "np", ".", "zeros", "(", "len", "(", "y_1_2_v1", ")", ")", ")", ",", "y_1_2_v1", "+", "std_1_2_v1", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "plot", "(", "x_1_5_v1", ",", "y_1_5_v1", ",", "label", "=", "line_1_5_label_v1", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery_1_5_v1", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "fill_between", "(", "x_1_5_v1", ",", "np", ".", "maximum", "(", "y_1_5_v1", "-", "std_1_5_v1", ",", "np", ".", "zeros", "(", "len", "(", "y_1_5_v1", ")", ")", ")", ",", "y_1_5_v1", "+", "std_1_5_v1", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[1][1].set_ylim(ylims)", "\n", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_title", "(", "title_1_v1", "+", "\" v1\"", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_xlabel", "(", "xlabel_1_v1", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_ylabel", "(", "ylabel_1_v1", ")", "\n", "# set the grid on", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "1", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# Plot", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_1_3_v1", ")", ",", "min", "(", "x_1_6_v1", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1_3_v1", ")", ",", "max", "(", "x_1_6_v1", ")", ")", ")", "\n", "ylims", "=", "(", "max", "(", "min", "(", "min", "(", "y_1_3_v1", "-", "std_1_3_v1", ")", ",", "min", "(", "y_1_6_v1", "-", "std_1_6_v1", ")", ")", ",", "0", ")", ",", "\n", "max", "(", "max", "(", "y_1_3_v1", "+", "std_1_3_v1", ")", ",", "max", "(", "y_1_6_v1", "+", "std_1_6_v1", ")", ")", ")", "\n", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "plot", "(", "x_1_3_v1", ",", "y_1_3_v1", ",", "label", "=", "line_1_3_label_v1", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery_1_3_v1", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "fill_between", "(", "x_1_3_v1", ",", "np", ".", "maximum", "(", "y_1_3_v1", "-", "std_1_3_v1", ",", "np", ".", "zeros", "(", "len", "(", "y_1_3_v1", ")", ")", ")", ",", "y_1_3_v1", "+", "std_1_3_v1", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "plot", "(", "x_1_6_v1", ",", "y_1_6_v1", ",", "label", "=", "line_1_6_label_v1", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery_1_4_v1", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "fill_between", "(", "x_1_6_v1", ",", "np", ".", "maximum", "(", "y_1_6_v1", "-", "std_1_6_v1", ",", "np", ".", "zeros", "(", "len", "(", "y_1_6_v1", ")", ")", ")", ",", "y_1_6_v1", "+", "std_1_6_v1", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[1][2].set_ylim(ylims)", "\n", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "set_title", "(", "title_1_v1", "+", "\" v2\"", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "set_xlabel", "(", "xlabel_1_v1", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "set_ylabel", "(", "ylabel_1_v1", ")", "\n", "# set the grid on", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "1", "]", "[", "2", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", "[", "2", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "1", "]", "[", "2", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# RandomAttack vs TabQ", "\n", "# Plot avg hack_probability", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_1_1_v2", ")", ",", "min", "(", "x_1_4_v2", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1_1_v2", ")", ",", "max", "(", "x_1_4_v2", ")", ")", ")", "\n", "ylims", "=", "(", "max", "(", "0", ",", "min", "(", "min", "(", "y_1_1_v2", "-", "std_1_1_v2", ")", ",", "min", "(", "y_1_4_v2", "-", "std_1_4_v2", ")", ")", ",", "0", ")", ",", "\n", "max", "(", "max", "(", "y_1_1_v2", "+", "std_1_1_v2", ")", ",", "max", "(", "y_1_4_v2", "+", "std_1_4_v2", ")", ")", ")", "\n", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "plot", "(", "x_1_1_v2", ",", "y_1_1_v2", ",", "label", "=", "line_1_1_label_v2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery_1_1_v2", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_1_v2", ",", "np", ".", "maximum", "(", "y_1_1_v2", "-", "std_1_1_v2", ",", "np", ".", "zeros", "(", "len", "(", "y_1_1_v2", ")", ")", ")", ",", "y_1_1_v2", "+", "std_1_1_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "plot", "(", "x_1_4_v2", ",", "y_1_4_v2", ",", "label", "=", "line_1_4_label_v2", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery_1_4_v2", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_4_v2", ",", "np", ".", "maximum", "(", "y_1_4_v2", "-", "std_1_4_v2", ",", "np", ".", "zeros", "(", "len", "(", "y_1_4_v2", ")", ")", ")", ",", "y_1_4_v2", "+", "std_1_4_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[2][0].set_ylim(ylims)", "\n", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "set_title", "(", "title_1_v2", "+", "\" v0\"", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "set_xlabel", "(", "xlabel_1_v2", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "set_ylabel", "(", "ylabel_1_v2", ")", "\n", "# set the grid on", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "2", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "2", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# # Plot avg hack_probability", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_1_2_v2", ")", ",", "min", "(", "x_1_5_v2", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1_2_v2", ")", ",", "max", "(", "x_1_5_v2", ")", ")", ")", "\n", "ylims", "=", "(", "min", "(", "min", "(", "y_1_2_v2", "-", "std_1_2_v2", ")", ",", "min", "(", "y_1_5_v2", "-", "std_1_5_v2", ")", ")", ",", "\n", "max", "(", "max", "(", "y_1_2_v2", "+", "std_1_2_v2", ")", ",", "max", "(", "y_1_5_v2", "+", "std_1_5_v2", ")", ")", ")", "\n", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "plot", "(", "x_1_2_v2", ",", "y_1_2_v2", ",", "label", "=", "line_1_2_label_v2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery_1_2_v2", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "fill_between", "(", "x_1_2_v2", ",", "np", ".", "maximum", "(", "y_1_2_v2", "-", "std_1_2_v2", ",", "np", ".", "zeros", "(", "len", "(", "y_1_2_v2", ")", ")", ")", ",", "y_1_2_v2", "+", "std_1_2_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "plot", "(", "x_1_5_v2", ",", "y_1_5_v2", ",", "label", "=", "line_1_5_label_v2", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery_1_5_v2", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "fill_between", "(", "x_1_5_v2", ",", "np", ".", "maximum", "(", "y_1_5_v2", "-", "std_1_5_v2", ",", "np", ".", "zeros", "(", "len", "(", "y_1_5_v2", ")", ")", ")", ",", "y_1_5_v2", "+", "std_1_5_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[2][1].set_ylim(ylims)", "\n", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "set_title", "(", "title_1_v2", "+", "\" v1\"", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "set_xlabel", "(", "xlabel_1_v2", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "set_ylabel", "(", "ylabel_1_v2", ")", "\n", "# set the grid on", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "2", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "2", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# Plot", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_1_3_v2", ")", ",", "min", "(", "x_1_6_v2", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1_3_v2", ")", ",", "max", "(", "x_1_6_v2", ")", ")", ")", "\n", "ylims", "=", "(", "max", "(", "0", ",", "min", "(", "min", "(", "y_1_3_v2", "-", "std_1_3_v2", ")", ",", "min", "(", "y_1_6_v2", "-", "std_1_6_v2", ")", ")", ")", ",", "\n", "max", "(", "max", "(", "y_1_3_v2", "+", "std_1_3_v2", ")", ",", "max", "(", "y_1_6_v2", "+", "std_1_6_v2", ")", ")", ")", "\n", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "plot", "(", "x_1_3_v2", ",", "y_1_3_v2", ",", "label", "=", "line_1_3_label_v2", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery_1_3_v2", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "fill_between", "(", "x_1_3_v2", ",", "np", ".", "maximum", "(", "y_1_3_v2", "-", "std_1_3_v2", ",", "np", ".", "zeros", "(", "len", "(", "y_1_3_v2", ")", ")", ")", ",", "y_1_3_v2", "+", "std_1_3_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "plot", "(", "x_1_6_v2", ",", "y_1_6_v2", ",", "label", "=", "line_1_6_label_v2", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery_1_4_v2", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "fill_between", "(", "x_1_6_v2", ",", "np", ".", "maximum", "(", "y_1_6_v2", "-", "std_1_6_v2", ",", "np", ".", "zeros", "(", "len", "(", "y_1_6_v2", ")", ")", ")", ",", "y_1_6_v2", "+", "std_1_6_v2", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[2][2].set_ylim(ylims)", "\n", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "set_title", "(", "title_1_v2", "+", "\" v2\"", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "set_xlabel", "(", "xlabel_1_v2", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "set_ylabel", "(", "ylabel_1_v2", ")", "\n", "# set the grid on", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "2", "]", "[", "2", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "2", "]", "[", "2", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# TabQ vs RandomDefense", "\n", "# Plot avg hack_probability", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_1_1_v3", ")", ",", "min", "(", "x_1_4_v3", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1_1_v3", ")", ",", "max", "(", "x_1_4_v3", ")", ")", ")", "\n", "ylims", "=", "(", "min", "(", "min", "(", "y_1_1_v3", "-", "std_1_1_v3", ")", ",", "min", "(", "y_1_4_v3", "-", "std_1_4_v3", ")", ")", ",", "\n", "max", "(", "max", "(", "y_1_1_v3", "+", "std_1_1_v3", ")", ",", "max", "(", "y_1_4_v3", "+", "std_1_4_v3", ")", ")", ")", "\n", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "plot", "(", "x_1_1_v3", ",", "y_1_1_v3", ",", "label", "=", "line_1_1_label_v3", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery_1_1_v3", ")", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_1_v3", ",", "np", ".", "maximum", "(", "y_1_1_v3", "-", "std_1_1_v3", ",", "np", ".", "zeros", "(", "len", "(", "y_1_1_v3", ")", ")", ")", ",", "y_1_1_v3", "+", "std_1_1_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "plot", "(", "x_1_4_v3", ",", "y_1_4_v3", ",", "label", "=", "line_1_4_label_v3", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery_1_4_v3", ")", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_4_v3", ",", "np", ".", "maximum", "(", "y_1_4_v3", "-", "std_1_4_v3", ",", "np", ".", "zeros", "(", "len", "(", "y_1_4_v3", ")", ")", ")", ",", "y_1_4_v3", "+", "std_1_4_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[3][0].set_ylim(ylims)", "\n", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "set_title", "(", "title_1_v3", "+", "\" v0\"", ")", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "set_xlabel", "(", "xlabel_1_v3", ")", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "set_ylabel", "(", "ylabel_1_v3", ")", "\n", "# set the grid on", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "3", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "3", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# # Plot avg hack_probability", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_1_2_v3", ")", ",", "min", "(", "x_1_5_v3", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1_2_v3", ")", ",", "max", "(", "x_1_5_v3", ")", ")", ")", "\n", "ylims", "=", "(", "max", "(", "min", "(", "min", "(", "y_1_2_v3", "-", "std_1_2_v3", ")", ",", "min", "(", "y_1_5_v3", "-", "std_1_5_v3", ")", ")", ",", "0", ")", ",", "\n", "max", "(", "max", "(", "y_1_2_v3", "+", "std_1_2_v3", ")", ",", "max", "(", "y_1_5_v3", "+", "std_1_5_v3", ")", ")", ")", "\n", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "plot", "(", "x_1_2_v3", ",", "y_1_2_v3", ",", "label", "=", "line_1_2_label_v3", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery_1_2_v3", ")", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "fill_between", "(", "x_1_2_v3", ",", "np", ".", "maximum", "(", "y_1_2_v3", "-", "std_1_2_v3", ",", "np", ".", "zeros", "(", "len", "(", "y_1_2_v3", ")", ")", ")", ",", "y_1_2_v3", "+", "std_1_2_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "plot", "(", "x_1_5_v3", ",", "y_1_5_v3", ",", "label", "=", "line_1_5_label_v3", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery_1_5_v3", ")", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "fill_between", "(", "x_1_5_v3", ",", "np", ".", "maximum", "(", "y_1_5_v3", "-", "std_1_5_v3", ",", "np", ".", "zeros", "(", "len", "(", "y_1_5_v3", ")", ")", ")", ",", "y_1_5_v3", "+", "std_1_5_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[3][1].set_ylim(ylims)", "\n", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "set_title", "(", "title_1_v3", "+", "\" v1\"", ")", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "set_xlabel", "(", "xlabel_1_v3", ")", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "set_ylabel", "(", "ylabel_1_v3", ")", "\n", "# set the grid on", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "3", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "3", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# Plot", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_1_3_v3", ")", ",", "min", "(", "x_1_6_v3", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1_3_v3", ")", ",", "max", "(", "x_1_6_v3", ")", ")", ")", "\n", "ylims", "=", "(", "max", "(", "0", ",", "min", "(", "min", "(", "y_1_3_v3", "-", "std_1_3_v3", ")", ",", "min", "(", "y_1_6_v3", "-", "std_1_6_v3", ")", ")", ")", ",", "\n", "max", "(", "max", "(", "y_1_3_v3", "+", "std_1_3_v3", ")", ",", "max", "(", "y_1_6_v3", "+", "std_1_6_v3", ")", ")", ")", "\n", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "plot", "(", "x_1_3_v3", ",", "y_1_3_v3", ",", "label", "=", "line_1_3_label_v3", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery_1_3_v3", ")", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "fill_between", "(", "x_1_3_v3", ",", "np", ".", "maximum", "(", "y_1_3_v3", "-", "std_1_3_v3", ",", "np", ".", "zeros", "(", "len", "(", "y_1_3_v3", ")", ")", ")", ",", "y_1_3_v3", "+", "std_1_3_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "plot", "(", "x_1_6_v3", ",", "y_1_6_v3", ",", "label", "=", "line_1_6_label_v3", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery_1_4_v3", ")", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "fill_between", "(", "x_1_6_v3", ",", "np", ".", "maximum", "(", "y_1_6_v3", "-", "std_1_6_v3", ",", "np", ".", "zeros", "(", "len", "(", "y_1_6_v3", ")", ")", ")", ",", "y_1_6_v3", "+", "std_1_6_v3", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[3][2].set_ylim(ylims)", "\n", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "set_title", "(", "title_1_v3", "+", "\" v2\"", ")", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "set_xlabel", "(", "xlabel_1_v3", ")", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "set_ylabel", "(", "ylabel_1_v3", ")", "\n", "# set the grid on", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "3", "]", "[", "2", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "3", "]", "[", "2", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "6", ")", "\n", "ylab", ".", "set_size", "(", "6", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# TabQ vs TabQ", "\n", "# Plot avg hack_probability", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_1_1_v4", ")", ",", "min", "(", "x_1_4_v4", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1_1_v4", ")", ",", "max", "(", "x_1_4_v4", ")", ")", ")", "\n", "ylims", "=", "(", "max", "(", "min", "(", "min", "(", "y_1_1_v4", "-", "std_1_1_v4", ")", ",", "min", "(", "y_1_4_v4", "-", "std_1_4_v4", ")", ")", ",", "0", ")", ",", "\n", "max", "(", "max", "(", "y_1_1_v4", "+", "std_1_1_v4", ")", ",", "max", "(", "y_1_4_v4", "+", "std_1_4_v4", ")", ")", ")", "\n", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "plot", "(", "x_1_1_v4", ",", "y_1_1_v4", ",", "label", "=", "line_1_1_label_v4", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery_1_1_v4", ")", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_1_v4", ",", "np", ".", "maximum", "(", "y_1_1_v4", "-", "std_1_1_v4", ",", "np", ".", "zeros", "(", "len", "(", "y_1_1_v4", ")", ")", ")", ",", "y_1_1_v4", "+", "std_1_1_v4", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "plot", "(", "x_1_4_v4", ",", "y_1_4_v4", ",", "label", "=", "line_1_4_label_v4", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery_1_4_v4", ")", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "fill_between", "(", "x_1_4_v4", ",", "np", ".", "maximum", "(", "y_1_4_v4", "-", "std_1_4_v4", ",", "np", ".", "zeros", "(", "len", "(", "y_1_4_v4", ")", ")", ")", ",", "y_1_4_v4", "+", "std_1_4_v4", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[4][0].set_ylim(ylims)", "\n", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "set_title", "(", "title_1_v4", "+", "\" v0\"", ")", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "set_xlabel", "(", "xlabel_1_v4", ")", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "set_ylabel", "(", "ylabel_1_v4", ")", "\n", "# set the grid on", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "4", "]", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "4", "]", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "4", "]", "[", "0", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# # Plot avg hack_probability", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_1_2_v4", ")", ",", "min", "(", "x_1_5_v4", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1_2_v4", ")", ",", "max", "(", "x_1_5_v4", ")", ")", ")", "\n", "ylims", "=", "(", "min", "(", "min", "(", "y_1_2_v4", "-", "std_1_2_v4", ")", ",", "min", "(", "y_1_5_v4", "-", "std_1_5_v4", ")", ")", ",", "\n", "max", "(", "max", "(", "y_1_2_v4", "+", "std_1_2_v4", ")", ",", "max", "(", "y_1_5_v4", "+", "std_1_5_v4", ")", ")", ")", "\n", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "plot", "(", "x_1_2_v4", ",", "y_1_2_v4", ",", "label", "=", "line_1_2_label_v4", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery_1_2_v4", ")", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "fill_between", "(", "x_1_2_v4", ",", "np", ".", "maximum", "(", "y_1_2_v4", "-", "std_1_2_v4", ",", "np", ".", "zeros", "(", "len", "(", "y_1_2_v4", ")", ")", ")", ",", "y_1_2_v4", "+", "std_1_2_v4", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "plot", "(", "x_1_5_v4", ",", "y_1_5_v4", ",", "label", "=", "line_1_5_label_v4", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery_1_5_v4", ")", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "fill_between", "(", "x_1_5_v4", ",", "np", ".", "maximum", "(", "y_1_5_v4", "-", "std_1_5_v4", ",", "np", ".", "zeros", "(", "len", "(", "y_1_5_v4", ")", ")", ")", ",", "y_1_5_v4", "+", "std_1_5_v4", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[4][1].set_ylim(ylims)", "\n", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "set_title", "(", "title_1_v4", "+", "\" v1\"", ")", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "set_xlabel", "(", "xlabel_1_v4", ")", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "set_ylabel", "(", "ylabel_1_v4", ")", "\n", "# set the grid on", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "4", "]", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "4", "]", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "4", "]", "[", "1", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "# Plot", "\n", "xlims", "=", "(", "min", "(", "min", "(", "x_1_3_v4", ")", ",", "min", "(", "x_1_6_v4", ")", ")", ",", "\n", "max", "(", "max", "(", "x_1_3_v4", ")", ",", "max", "(", "x_1_6_v4", ")", ")", ")", "\n", "ylims", "=", "(", "min", "(", "min", "(", "y_1_3_v4", "-", "std_1_3_v4", ")", ",", "min", "(", "y_1_6_v4", "-", "std_1_6_v4", ")", ")", ",", "\n", "max", "(", "max", "(", "y_1_3_v4", "+", "std_1_3_v4", ")", ",", "max", "(", "y_1_6_v4", "+", "std_1_6_v4", ")", ")", ")", "\n", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "plot", "(", "x_1_3_v4", ",", "y_1_3_v4", ",", "label", "=", "line_1_3_label_v4", ",", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "markevery_1_3_v4", ")", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "fill_between", "(", "x_1_3_v4", ",", "np", ".", "maximum", "(", "y_1_3_v4", "-", "std_1_3_v4", ",", "np", ".", "zeros", "(", "len", "(", "y_1_3_v4", ")", ")", ")", ",", "y_1_3_v4", "+", "std_1_3_v4", ",", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "plot", "(", "x_1_6_v4", ",", "y_1_6_v4", ",", "label", "=", "line_1_6_label_v4", ",", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "\n", "markevery", "=", "markevery_1_4_v4", ")", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "fill_between", "(", "x_1_6_v4", ",", "np", ".", "maximum", "(", "y_1_6_v4", "-", "std_1_6_v4", ",", "np", ".", "zeros", "(", "len", "(", "y_1_6_v4", ")", ")", ")", ",", "y_1_6_v4", "+", "std_1_6_v4", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "# ax[4][2].set_ylim(ylims)", "\n", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "set_title", "(", "title_1_v4", "+", "\" v2\"", ")", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "set_xlabel", "(", "xlabel_1_v4", ")", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "set_ylabel", "(", "ylabel_1_v4", ")", "\n", "# set the grid on", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "4", "]", "[", "2", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "4", "]", "[", "2", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "4", "]", "[", "2", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "lines_labels", "=", "[", "ax", "[", "4", "]", "[", "1", "]", ".", "get_legend_handles_labels", "(", ")", "]", "\n", "lines", ",", "labels", "=", "[", "sum", "(", "lol", ",", "[", "]", ")", "for", "lol", "in", "zip", "(", "*", "lines_labels", ")", "]", "\n", "# ax = fig.add_axes([0.1, 0.1, 0.6, 0.75])", "\n", "fig", ".", "legend", "(", "lines", ",", "labels", ",", "loc", "=", "(", "0.35", ",", "0.012", ")", ",", "ncol", "=", "2", ",", "borderaxespad", "=", "0.", ")", "\n", "\n", "#fig.subplots_adjust(bottom=0.2)", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "plt", ".", "subplots_adjust", "(", "wspace", "=", "wspace", ",", "hspace", "=", "0.7", ")", "\n", "fig", ".", "subplots_adjust", "(", "bottom", "=", "0.08", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_sparse_dense_difference": [[2988, 3570], ["list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "plotting_util.plot_all_avg_summary_4", "plotting_util.read_data", "train_max_attack_dfs_v0.append", "plotting_util.read_data", "eval_max_attack_dfs_v0.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_min_defense_dfs_v0.append", "plotting_util.read_data", "eval_min_defense_dfs_v0.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_attack_dfs_v0.append", "plotting_util.read_data", "eval_random_attack_dfs_v0.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_defense_dfs_v0.append", "plotting_util.read_data", "eval_random_defense_dfs_v0.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_two_agents_dfs_v0.append", "plotting_util.read_data", "eval_two_agents_dfs_v0.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_max_attack_dfs_v2.append", "plotting_util.read_data", "eval_max_attack_dfs_v2.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_min_defense_dfs_v2.append", "plotting_util.read_data", "eval_min_defense_dfs_v2.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_attack_dfs_v2.append", "plotting_util.read_data", "eval_random_attack_dfs_v2.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_defense_dfs_v2.append", "plotting_util.read_data", "eval_random_defense_dfs_v2.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_two_agents_dfs_v2.append", "plotting_util.read_data", "eval_two_agents_dfs_v2.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_max_attack_dfs_v3.append", "plotting_util.read_data", "eval_max_attack_dfs_v3.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_min_defense_dfs_v3.append", "plotting_util.read_data", "eval_min_defense_dfs_v3.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_attack_dfs_v3.append", "plotting_util.read_data", "eval_random_attack_dfs_v3.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_defense_dfs_v3.append", "plotting_util.read_data", "eval_random_defense_dfs_v3.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_two_agents_dfs_v3.append", "plotting_util.read_data", "eval_two_agents_dfs_v3.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_max_attack_dfs_v8.append", "plotting_util.read_data", "eval_max_attack_dfs_v8.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_min_defense_dfs_v8.append", "plotting_util.read_data", "eval_min_defense_dfs_v8.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_attack_dfs_v8.append", "plotting_util.read_data", "eval_random_attack_dfs_v8.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_defense_dfs_v8.append", "plotting_util.read_data", "eval_random_defense_dfs_v8.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_two_agents_dfs_v8.append", "plotting_util.read_data", "eval_two_agents_dfs_v8.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_max_attack_dfs_v9.append", "plotting_util.read_data", "eval_max_attack_dfs_v9.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_min_defense_dfs_v9.append", "plotting_util.read_data", "eval_min_defense_dfs_v9.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_attack_dfs_v9.append", "plotting_util.read_data", "eval_random_attack_dfs_v9.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_defense_dfs_v9.append", "plotting_util.read_data", "eval_random_defense_dfs_v9.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_two_agents_dfs_v9.append", "plotting_util.read_data", "eval_two_agents_dfs_v9.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_max_attack_dfs_v7.append", "plotting_util.read_data", "eval_max_attack_dfs_v7.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_min_defense_dfs_v7.append", "plotting_util.read_data", "eval_min_defense_dfs_v7.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_attack_dfs_v7.append", "plotting_util.read_data", "eval_random_attack_dfs_v7.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_defense_dfs_v7.append", "plotting_util.read_data", "eval_random_defense_dfs_v7.append", "map", "tuple", "tuple", "plotting_util.read_data", "train_two_agents_dfs_v7.append", "plotting_util.read_data", "eval_two_agents_dfs_v7.append", "map", "tuple", "tuple", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "str", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_avg_summary_4", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data"], ["", "def", "plot_sparse_dense_difference", "(", "maximal_attack_train_csv_paths_v0", ",", "maximal_attack_eval_csv_paths_v0", ",", "\n", "minimal_defense_train_csv_paths_v0", ",", "minimal_defense_eval_csv_paths_v0", ",", "\n", "random_attack_train_csv_paths_v0", ",", "random_attack_eval_csv_paths_v0", ",", "\n", "random_defense_train_csv_paths_v0", ",", "random_defense_eval_csv_paths_v0", ",", "\n", "two_agents_train_csv_paths_v0", ",", "two_agents_eval_csv_paths_v0", ",", "\n", "\n", "maximal_attack_train_csv_paths_v2", ",", "maximal_attack_eval_csv_paths_v2", ",", "\n", "minimal_defense_train_csv_paths_v2", ",", "minimal_defense_eval_csv_paths_v2", ",", "\n", "random_attack_train_csv_paths_v2", ",", "random_attack_eval_csv_paths_v2", ",", "\n", "random_defense_train_csv_paths_v2", ",", "random_defense_eval_csv_paths_v2", ",", "\n", "two_agents_train_csv_paths_v2", ",", "two_agents_eval_csv_paths_v2", ",", "\n", "\n", "maximal_attack_train_csv_paths_v3", ",", "maximal_attack_eval_csv_paths_v3", ",", "\n", "minimal_defense_train_csv_paths_v3", ",", "minimal_defense_eval_csv_paths_v3", ",", "\n", "random_attack_train_csv_paths_v3", ",", "random_attack_eval_csv_paths_v3", ",", "\n", "random_defense_train_csv_paths_v3", ",", "random_defense_eval_csv_paths_v3", ",", "\n", "two_agents_train_csv_paths_v3", ",", "two_agents_eval_csv_paths_v3", ",", "\n", "\n", "maximal_attack_train_csv_paths_v8", ",", "maximal_attack_eval_csv_paths_v8", ",", "\n", "minimal_defense_train_csv_paths_v8", ",", "minimal_defense_eval_csv_paths_v8", ",", "\n", "random_attack_train_csv_paths_v8", ",", "random_attack_eval_csv_paths_v8", ",", "\n", "random_defense_train_csv_paths_v8", ",", "random_defense_eval_csv_paths_v8", ",", "\n", "two_agents_train_csv_paths_v8", ",", "two_agents_eval_csv_paths_v8", ",", "\n", "\n", "maximal_attack_train_csv_paths_v9", ",", "maximal_attack_eval_csv_paths_v9", ",", "\n", "minimal_defense_train_csv_paths_v9", ",", "minimal_defense_eval_csv_paths_v9", ",", "\n", "random_attack_train_csv_paths_v9", ",", "random_attack_eval_csv_paths_v9", ",", "\n", "random_defense_train_csv_paths_v9", ",", "random_defense_eval_csv_paths_v9", ",", "\n", "two_agents_train_csv_paths_v9", ",", "two_agents_eval_csv_paths_v9", ",", "\n", "\n", "maximal_attack_train_csv_paths_v7", ",", "maximal_attack_eval_csv_paths_v7", ",", "\n", "minimal_defense_train_csv_paths_v7", ",", "minimal_defense_eval_csv_paths_v7", ",", "\n", "random_attack_train_csv_paths_v7", ",", "random_attack_eval_csv_paths_v7", ",", "\n", "random_defense_train_csv_paths_v7", ",", "random_defense_eval_csv_paths_v7", ",", "\n", "two_agents_train_csv_paths_v7", ",", "two_agents_eval_csv_paths_v7", ",", "\n", "\n", "algorithm", ",", "output_dir", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ",", "versions", ":", "list", ",", "\n", "wspace", "=", "0.28", ",", "file_name", "=", "\"combined_plot_mult_versions_\"", ")", ":", "\n", "# V0", "\n", "    ", "train_max_attack_dfs_v0", "=", "[", "]", "\n", "eval_max_attack_dfs_v0", "=", "[", "]", "\n", "for", "csv_path", "in", "maximal_attack_train_csv_paths_v0", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_max_attack_dfs_v0", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "maximal_attack_eval_csv_paths_v0", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_max_attack_dfs_v0", ".", "append", "(", "df", ")", "\n", "", "hack_prob_eval_max_attack_data_v0", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_max_attack_dfs_v0", ")", ")", "\n", "hack_prob_eval_max_attack_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_max_attack_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_max_attack_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_max_attack_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_min_defense_dfs_v0", "=", "[", "]", "\n", "eval_min_defense_dfs_v0", "=", "[", "]", "\n", "for", "csv_path", "in", "minimal_defense_train_csv_paths_v0", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_min_defense_dfs_v0", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "minimal_defense_eval_csv_paths_v0", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_min_defense_dfs_v0", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_min_defense_data_v0", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_min_defense_dfs_v0", ")", ")", "\n", "hack_prob_eval_min_defense_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_min_defense_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_min_defense_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_min_defense_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_attack_dfs_v0", "=", "[", "]", "\n", "eval_random_attack_dfs_v0", "=", "[", "]", "\n", "for", "csv_path", "in", "random_attack_train_csv_paths_v0", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_attack_dfs_v0", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_attack_eval_csv_paths_v0", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_attack_dfs_v0", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_random_attack_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_random_attack_dfs_v0", ")", ")", "\n", "hack_prob_eval_random_attack_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_random_attack_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_random_attack_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_random_attack_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_defense_dfs_v0", "=", "[", "]", "\n", "eval_random_defense_dfs_v0", "=", "[", "]", "\n", "for", "csv_path", "in", "random_defense_train_csv_paths_v0", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_defense_dfs_v0", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_defense_eval_csv_paths_v0", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_defense_dfs_v0", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_random_defense_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_random_defense_dfs_v0", ")", ")", "\n", "hack_prob_eval_random_defense_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_random_defense_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_random_defense_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_random_defense_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_two_agents_dfs_v0", "=", "[", "]", "\n", "eval_two_agents_dfs_v0", "=", "[", "]", "\n", "for", "csv_path", "in", "two_agents_train_csv_paths_v0", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_two_agents_dfs_v0", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "two_agents_eval_csv_paths_v0", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_two_agents_dfs_v0", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_two_agents_data_v0", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_two_agents_dfs_v0", ")", ")", "\n", "hack_prob_eval_two_agents_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_two_agents_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_two_agents_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_two_agents_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "# V2", "\n", "train_max_attack_dfs_v2", "=", "[", "]", "\n", "eval_max_attack_dfs_v2", "=", "[", "]", "\n", "for", "csv_path", "in", "maximal_attack_train_csv_paths_v2", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_max_attack_dfs_v2", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "maximal_attack_eval_csv_paths_v2", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_max_attack_dfs_v2", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_max_attack_data_v2", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_max_attack_dfs_v2", ")", ")", "\n", "hack_prob_eval_max_attack_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_max_attack_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_max_attack_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_max_attack_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_min_defense_dfs_v2", "=", "[", "]", "\n", "eval_min_defense_dfs_v2", "=", "[", "]", "\n", "for", "csv_path", "in", "minimal_defense_train_csv_paths_v2", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_min_defense_dfs_v2", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "minimal_defense_eval_csv_paths_v2", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_min_defense_dfs_v2", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_min_defense_data_v2", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_min_defense_dfs_v2", ")", ")", "\n", "hack_prob_eval_min_defense_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_min_defense_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_min_defense_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_min_defense_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_attack_dfs_v2", "=", "[", "]", "\n", "eval_random_attack_dfs_v2", "=", "[", "]", "\n", "for", "csv_path", "in", "random_attack_train_csv_paths_v2", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_attack_dfs_v2", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_attack_eval_csv_paths_v2", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_attack_dfs_v2", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_random_attack_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_random_attack_dfs_v2", ")", ")", "\n", "hack_prob_eval_random_attack_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_random_attack_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_random_attack_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_random_attack_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_defense_dfs_v2", "=", "[", "]", "\n", "eval_random_defense_dfs_v2", "=", "[", "]", "\n", "for", "csv_path", "in", "random_defense_train_csv_paths_v2", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_defense_dfs_v2", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_defense_eval_csv_paths_v2", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_defense_dfs_v2", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_random_defense_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_random_defense_dfs_v2", ")", ")", "\n", "hack_prob_eval_random_defense_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_random_defense_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_random_defense_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_random_defense_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_two_agents_dfs_v2", "=", "[", "]", "\n", "eval_two_agents_dfs_v2", "=", "[", "]", "\n", "for", "csv_path", "in", "two_agents_train_csv_paths_v2", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_two_agents_dfs_v2", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "two_agents_eval_csv_paths_v2", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_two_agents_dfs_v2", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_two_agents_data_v2", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_two_agents_dfs_v2", ")", ")", "\n", "hack_prob_eval_two_agents_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_two_agents_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_two_agents_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_two_agents_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "# V3", "\n", "train_max_attack_dfs_v3", "=", "[", "]", "\n", "eval_max_attack_dfs_v3", "=", "[", "]", "\n", "for", "csv_path", "in", "maximal_attack_train_csv_paths_v3", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_max_attack_dfs_v3", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "maximal_attack_eval_csv_paths_v3", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_max_attack_dfs_v3", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_max_attack_data_v3", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_max_attack_dfs_v3", ")", ")", "\n", "hack_prob_eval_max_attack_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_max_attack_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_max_attack_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_max_attack_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_min_defense_dfs_v3", "=", "[", "]", "\n", "eval_min_defense_dfs_v3", "=", "[", "]", "\n", "for", "csv_path", "in", "minimal_defense_train_csv_paths_v3", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_min_defense_dfs_v3", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "minimal_defense_eval_csv_paths_v3", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_min_defense_dfs_v3", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_min_defense_data_v3", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_min_defense_dfs_v3", ")", ")", "\n", "hack_prob_eval_min_defense_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_min_defense_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_min_defense_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_min_defense_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_attack_dfs_v3", "=", "[", "]", "\n", "eval_random_attack_dfs_v3", "=", "[", "]", "\n", "for", "csv_path", "in", "random_attack_train_csv_paths_v3", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_attack_dfs_v3", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_attack_eval_csv_paths_v3", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_attack_dfs_v3", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_random_attack_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_random_attack_dfs_v3", ")", ")", "\n", "hack_prob_eval_random_attack_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_random_attack_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_random_attack_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_random_attack_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_defense_dfs_v3", "=", "[", "]", "\n", "eval_random_defense_dfs_v3", "=", "[", "]", "\n", "for", "csv_path", "in", "random_defense_train_csv_paths_v3", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_defense_dfs_v3", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_defense_eval_csv_paths_v3", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_defense_dfs_v3", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_random_defense_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_random_defense_dfs_v3", ")", ")", "\n", "hack_prob_eval_random_defense_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_random_defense_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_random_defense_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_random_defense_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_two_agents_dfs_v3", "=", "[", "]", "\n", "eval_two_agents_dfs_v3", "=", "[", "]", "\n", "for", "csv_path", "in", "two_agents_train_csv_paths_v3", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_two_agents_dfs_v3", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "two_agents_eval_csv_paths_v3", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_two_agents_dfs_v3", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_two_agents_data_v3", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_two_agents_dfs_v3", ")", ")", "\n", "hack_prob_eval_two_agents_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_two_agents_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_two_agents_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_two_agents_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "# V8", "\n", "train_max_attack_dfs_v8", "=", "[", "]", "\n", "eval_max_attack_dfs_v8", "=", "[", "]", "\n", "for", "csv_path", "in", "maximal_attack_train_csv_paths_v8", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_max_attack_dfs_v8", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "maximal_attack_eval_csv_paths_v8", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_max_attack_dfs_v8", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_max_attack_data_v8", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_max_attack_dfs_v8", ")", ")", "\n", "hack_prob_eval_max_attack_means_v8", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_max_attack_data_v8", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_max_attack_stds_v8", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_max_attack_data_v8", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_min_defense_dfs_v8", "=", "[", "]", "\n", "eval_min_defense_dfs_v8", "=", "[", "]", "\n", "for", "csv_path", "in", "minimal_defense_train_csv_paths_v8", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_min_defense_dfs_v8", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "minimal_defense_eval_csv_paths_v8", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_min_defense_dfs_v8", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_min_defense_data_v8", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_min_defense_dfs_v8", ")", ")", "\n", "hack_prob_eval_min_defense_means_v8", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_min_defense_data_v8", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_min_defense_stds_v8", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_min_defense_data_v8", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_attack_dfs_v8", "=", "[", "]", "\n", "eval_random_attack_dfs_v8", "=", "[", "]", "\n", "for", "csv_path", "in", "random_attack_train_csv_paths_v8", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_attack_dfs_v8", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_attack_eval_csv_paths_v8", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_attack_dfs_v8", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_random_attack_data_v8", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_random_attack_dfs_v8", ")", ")", "\n", "hack_prob_eval_random_attack_means_v8", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_random_attack_data_v8", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_random_attack_stds_v8", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_random_attack_data_v8", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_defense_dfs_v8", "=", "[", "]", "\n", "eval_random_defense_dfs_v8", "=", "[", "]", "\n", "for", "csv_path", "in", "random_defense_train_csv_paths_v8", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_defense_dfs_v8", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_defense_eval_csv_paths_v8", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_defense_dfs_v8", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_random_defense_data_v8", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_random_defense_dfs_v8", ")", ")", "\n", "hack_prob_eval_random_defense_means_v8", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_random_defense_data_v8", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_random_defense_stds_v8", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_random_defense_data_v8", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_two_agents_dfs_v8", "=", "[", "]", "\n", "eval_two_agents_dfs_v8", "=", "[", "]", "\n", "for", "csv_path", "in", "two_agents_train_csv_paths_v8", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_two_agents_dfs_v8", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "two_agents_eval_csv_paths_v8", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_two_agents_dfs_v8", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_two_agents_data_v8", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_two_agents_dfs_v8", ")", ")", "\n", "hack_prob_eval_two_agents_means_v8", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_two_agents_data_v8", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_two_agents_stds_v8", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_two_agents_data_v8", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "# V9", "\n", "train_max_attack_dfs_v9", "=", "[", "]", "\n", "eval_max_attack_dfs_v9", "=", "[", "]", "\n", "for", "csv_path", "in", "maximal_attack_train_csv_paths_v9", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_max_attack_dfs_v9", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "maximal_attack_eval_csv_paths_v9", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_max_attack_dfs_v9", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_max_attack_data_v9", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_max_attack_dfs_v9", ")", ")", "\n", "hack_prob_eval_max_attack_means_v9", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_max_attack_data_v9", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_max_attack_stds_v9", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_max_attack_data_v9", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_min_defense_dfs_v9", "=", "[", "]", "\n", "eval_min_defense_dfs_v9", "=", "[", "]", "\n", "for", "csv_path", "in", "minimal_defense_train_csv_paths_v9", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_min_defense_dfs_v9", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "minimal_defense_eval_csv_paths_v9", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_min_defense_dfs_v9", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_min_defense_data_v9", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_min_defense_dfs_v9", ")", ")", "\n", "hack_prob_eval_min_defense_means_v9", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_min_defense_data_v9", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_min_defense_stds_v9", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_min_defense_data_v9", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_attack_dfs_v9", "=", "[", "]", "\n", "eval_random_attack_dfs_v9", "=", "[", "]", "\n", "for", "csv_path", "in", "random_attack_train_csv_paths_v9", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_attack_dfs_v9", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_attack_eval_csv_paths_v9", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_attack_dfs_v9", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_random_attack_data_v9", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_random_attack_dfs_v9", ")", ")", "\n", "hack_prob_eval_random_attack_means_v9", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_random_attack_data_v9", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_random_attack_stds_v9", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_random_attack_data_v9", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_defense_dfs_v9", "=", "[", "]", "\n", "eval_random_defense_dfs_v9", "=", "[", "]", "\n", "for", "csv_path", "in", "random_defense_train_csv_paths_v9", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_defense_dfs_v9", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_defense_eval_csv_paths_v9", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_defense_dfs_v9", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_random_defense_data_v9", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_random_defense_dfs_v9", ")", ")", "\n", "hack_prob_eval_random_defense_means_v9", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_random_defense_data_v9", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_random_defense_stds_v9", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_random_defense_data_v9", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_two_agents_dfs_v9", "=", "[", "]", "\n", "eval_two_agents_dfs_v9", "=", "[", "]", "\n", "for", "csv_path", "in", "two_agents_train_csv_paths_v9", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_two_agents_dfs_v9", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "two_agents_eval_csv_paths_v9", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_two_agents_dfs_v9", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_two_agents_data_v9", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_two_agents_dfs_v9", ")", ")", "\n", "hack_prob_eval_two_agents_means_v9", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_two_agents_data_v9", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_two_agents_stds_v9", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_two_agents_data_v9", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "# V7", "\n", "train_max_attack_dfs_v7", "=", "[", "]", "\n", "eval_max_attack_dfs_v7", "=", "[", "]", "\n", "for", "csv_path", "in", "maximal_attack_train_csv_paths_v7", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_max_attack_dfs_v7", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "maximal_attack_eval_csv_paths_v7", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_max_attack_dfs_v7", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_max_attack_data_v7", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_max_attack_dfs_v7", ")", ")", "\n", "hack_prob_eval_max_attack_means_v7", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_max_attack_data_v7", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_max_attack_stds_v7", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_max_attack_data_v7", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_min_defense_dfs_v7", "=", "[", "]", "\n", "eval_min_defense_dfs_v7", "=", "[", "]", "\n", "for", "csv_path", "in", "minimal_defense_train_csv_paths_v7", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_min_defense_dfs_v7", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "minimal_defense_eval_csv_paths_v7", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_min_defense_dfs_v7", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_min_defense_data_v7", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_min_defense_dfs_v7", ")", ")", "\n", "hack_prob_eval_min_defense_means_v7", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_min_defense_data_v7", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_min_defense_stds_v7", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_min_defense_data_v7", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_attack_dfs_v7", "=", "[", "]", "\n", "eval_random_attack_dfs_v7", "=", "[", "]", "\n", "for", "csv_path", "in", "random_attack_train_csv_paths_v7", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_attack_dfs_v7", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_attack_eval_csv_paths_v7", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_attack_dfs_v7", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_random_attack_data_v7", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_random_attack_dfs_v7", ")", ")", "\n", "hack_prob_eval_random_attack_means_v7", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_random_attack_data_v7", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_random_attack_stds_v7", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_random_attack_data_v7", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_defense_dfs_v7", "=", "[", "]", "\n", "eval_random_defense_dfs_v7", "=", "[", "]", "\n", "for", "csv_path", "in", "random_defense_train_csv_paths_v7", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_defense_dfs_v7", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_defense_eval_csv_paths_v7", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_defense_dfs_v7", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_random_defense_data_v7", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_random_defense_dfs_v7", ")", ")", "\n", "hack_prob_eval_random_defense_means_v7", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_random_defense_data_v7", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_random_defense_stds_v7", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_random_defense_data_v7", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_two_agents_dfs_v7", "=", "[", "]", "\n", "eval_two_agents_dfs_v7", "=", "[", "]", "\n", "for", "csv_path", "in", "two_agents_train_csv_paths_v7", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_two_agents_dfs_v7", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "two_agents_eval_csv_paths_v7", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_two_agents_dfs_v7", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_eval_two_agents_data_v7", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_two_agents_dfs_v7", ")", ")", "\n", "hack_prob_eval_two_agents_means_v7", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_two_agents_data_v7", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_two_agents_stds_v7", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_two_agents_data_v7", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "plot_all_avg_summary_4", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_min_defense_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_min_defense_means_v0", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_min_defense_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_min_defense_means_v2", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_min_defense_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_min_defense_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_min_defense_data_v8", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_min_defense_means_v8", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_min_defense_data_v9", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_min_defense_means_v9", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_min_defense_data_v7", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_min_defense_means_v7", ",", "\n", "hack_prob_eval_min_defense_stds_v0", ",", "hack_prob_eval_min_defense_stds_v2", ",", "\n", "hack_prob_eval_min_defense_stds_v3", ",", "hack_prob_eval_min_defense_stds_v8", ",", "\n", "hack_prob_eval_min_defense_stds_v9", ",", "hack_prob_eval_min_defense_stds_v7", ",", "\n", "r\"Sparse $\\mathcal{R}$\"", ",", "r\"Sparse $\\mathcal{R}$\"", ",", "\n", "r\"Sparse $\\mathcal{R}$\"", ",", "r\"Dense $\\mathcal{R}$\"", ",", "\n", "r\"Dense $\\mathcal{R}$\"", ",", "r\"Dense $\\mathcal{R}$\"", ",", "\n", "r\"\\textsc{TabularQLearning} vs \\textsc{MinDefense}\"", ",", "\n", "r\"Episode \\#\"", ",", "r\"$\\mathbb{P}[Hacked]$\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_max_attack_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_max_attack_means_v0", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_max_attack_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_max_attack_means_v2", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_max_attack_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_max_attack_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_max_attack_data_v8", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_max_attack_means_v8", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_max_attack_data_v9", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_max_attack_means_v9", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_max_attack_data_v7", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_max_attack_means_v7", ",", "\n", "hack_prob_eval_max_attack_stds_v0", ",", "hack_prob_eval_max_attack_stds_v2", ",", "\n", "hack_prob_eval_max_attack_stds_v3", ",", "hack_prob_eval_max_attack_stds_v8", ",", "\n", "hack_prob_eval_max_attack_stds_v9", ",", "hack_prob_eval_max_attack_stds_v7", ",", "\n", "r\"Sparse $\\mathcal{R}$\"", ",", "r\"Sparse $\\mathcal{R}$\"", ",", "\n", "r\"Sparse $\\mathcal{R}$\"", ",", "r\"Dense $\\mathcal{R}$\"", ",", "\n", "r\"Dense $\\mathcal{R}$\"", ",", "r\"Dense $\\mathcal{R}$\"", ",", "\n", "r\"\\textsc{MaxAttack} vs \\textsc{TabularQLearning}\"", ",", "\n", "r\"Episode \\#\"", ",", "r\"$\\mathbb{P}[Hacked]$\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_attack_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_attack_means_v0", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_attack_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_attack_means_v2", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_attack_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_attack_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_attack_data_v8", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_attack_means_v8", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_attack_data_v9", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_attack_means_v9", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_attack_data_v7", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_attack_means_v7", ",", "\n", "hack_prob_eval_random_attack_stds_v0", ",", "hack_prob_eval_random_attack_stds_v2", ",", "\n", "hack_prob_eval_random_attack_stds_v3", ",", "hack_prob_eval_random_attack_stds_v8", ",", "\n", "hack_prob_eval_random_attack_stds_v9", ",", "hack_prob_eval_random_attack_stds_v7", ",", "\n", "r\"Sparse $\\mathcal{R}$\"", ",", "r\"Sparse $\\mathcal{R}$\"", ",", "\n", "r\"Sparse $\\mathcal{R}$\"", ",", "r\"Dense $\\mathcal{R}$\"", ",", "\n", "r\"Dense $\\mathcal{R}$\"", ",", "r\"Dense $\\mathcal{R}$\"", ",", "\n", "r\"\\textsc{RandomAttack} vs \\textsc{TabularQLearning}\"", ",", "\n", "r\"Episode \\#\"", ",", "r\"$\\mathbb{P}[Hacked]$\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_defense_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_defense_means_v0", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_defense_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_defense_means_v2", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_defense_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_defense_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_defense_data_v8", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_defense_means_v8", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_defense_data_v9", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_defense_means_v9", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_defense_data_v7", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_defense_means_v7", ",", "\n", "hack_prob_eval_random_defense_stds_v0", ",", "hack_prob_eval_random_defense_stds_v2", ",", "\n", "hack_prob_eval_random_defense_stds_v3", ",", "hack_prob_eval_random_defense_stds_v8", ",", "\n", "hack_prob_eval_random_defense_stds_v9", ",", "hack_prob_eval_random_defense_stds_v7", ",", "\n", "r\"Sparse $\\mathcal{R}_{sparse}$\"", ",", "r\"Sparse $\\mathcal{R}_{sparse}$\"", ",", "\n", "r\"Sparse $\\mathcal{R}_{sparse}$\"", ",", "r\"Dense $\\mathcal{R}_{dense}$\"", ",", "\n", "r\"Dense $\\mathcal{R}_{dense}$\"", ",", "r\"Dense $\\mathcal{R}_{dense}$\"", ",", "\n", "r\"\\textsc{TabularQLearning} vs \\textsc{RandomDefense}\"", ",", "\n", "r\"Episode \\#\"", ",", "r\"$\\mathbb{P}[Hacked]$\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_two_agents_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_two_agents_means_v0", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_two_agents_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_two_agents_means_v2", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_two_agents_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_two_agents_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_two_agents_data_v8", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_two_agents_means_v8", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_two_agents_data_v9", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_two_agents_means_v9", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_two_agents_data_v7", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_two_agents_means_v7", ",", "\n", "hack_prob_eval_two_agents_stds_v0", ",", "hack_prob_eval_two_agents_stds_v2", ",", "\n", "hack_prob_eval_two_agents_stds_v3", ",", "hack_prob_eval_two_agents_stds_v8", ",", "\n", "hack_prob_eval_two_agents_stds_v9", ",", "hack_prob_eval_two_agents_stds_v7", ",", "\n", "r\"Sparse Reward Function $\\mathcal{R}_{sparse}$\"", ",", "r\"Sparse Reward Function $\\mathcal{R}_{sparse}$\"", ",", "\n", "r\"Sparse Reward Function $\\mathcal{R}_{sparse}$\"", ",", "r\"Dense Reward Function $\\mathcal{R}_{dense}$\"", ",", "\n", "r\"Dense Reward Function $\\mathcal{R}_{dense}$\"", ",", "r\"Dense Reward Function $\\mathcal{R}_{dense}$\"", ",", "\n", "r\"\\textsc{TabularQLearning} vs \\textsc{TabularQLearning}\"", ",", "\n", "r\"Episode \\#\"", ",", "r\"$\\mathbb{P}[Hacked]$\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "output_dir", "+", "\"/\"", "+", "file_name", "+", "algorithm", "+", "\"_\"", "+", "str", "(", "0", ")", ",", "\n", "wspace", "=", "wspace", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_loss_functions_summary": [[3573, 3962], ["list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "plotting_util.plot_all_avg_summary_5", "plotting_util.read_data", "train_max_attack_dfs_v8.append", "plotting_util.read_data", "eval_max_attack_dfs_v8.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_min_defense_dfs_v8.append", "plotting_util.read_data", "eval_min_defense_dfs_v8.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_attack_dfs_v8.append", "plotting_util.read_data", "eval_random_attack_dfs_v8.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_defense_dfs_v8.append", "plotting_util.read_data", "eval_random_defense_dfs_v8.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_two_agents_dfs_v8.append", "plotting_util.read_data", "eval_two_agents_dfs_v8.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_max_attack_dfs_v9.append", "plotting_util.read_data", "eval_max_attack_dfs_v9.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_min_defense_dfs_v9.append", "plotting_util.read_data", "eval_min_defense_dfs_v9.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_attack_dfs_v9.append", "plotting_util.read_data", "eval_random_attack_dfs_v9.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_defense_dfs_v9.append", "plotting_util.read_data", "eval_random_defense_dfs_v9.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_two_agents_dfs_v9.append", "plotting_util.read_data", "eval_two_agents_dfs_v9.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_max_attack_dfs_v7.append", "plotting_util.read_data", "eval_max_attack_dfs_v7.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_min_defense_dfs_v7.append", "plotting_util.read_data", "eval_min_defense_dfs_v7.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_attack_dfs_v7.append", "plotting_util.read_data", "eval_random_attack_dfs_v7.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_defense_dfs_v7.append", "plotting_util.read_data", "eval_random_defense_dfs_v7.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_two_agents_dfs_v7.append", "plotting_util.read_data", "eval_two_agents_dfs_v7.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "str", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_avg_summary_5", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data"], ["", "def", "plot_loss_functions_summary", "(", "maximal_attack_train_csv_paths_v8", ",", "maximal_attack_eval_csv_paths_v8", ",", "\n", "minimal_defense_train_csv_paths_v8", ",", "minimal_defense_eval_csv_paths_v8", ",", "\n", "random_attack_train_csv_paths_v8", ",", "random_attack_eval_csv_paths_v8", ",", "\n", "random_defense_train_csv_paths_v8", ",", "random_defense_eval_csv_paths_v8", ",", "\n", "two_agents_train_csv_paths_v8", ",", "two_agents_eval_csv_paths_v8", ",", "\n", "\n", "maximal_attack_train_csv_paths_v9", ",", "maximal_attack_eval_csv_paths_v9", ",", "\n", "minimal_defense_train_csv_paths_v9", ",", "minimal_defense_eval_csv_paths_v9", ",", "\n", "random_attack_train_csv_paths_v9", ",", "random_attack_eval_csv_paths_v9", ",", "\n", "random_defense_train_csv_paths_v9", ",", "random_defense_eval_csv_paths_v9", ",", "\n", "two_agents_train_csv_paths_v9", ",", "two_agents_eval_csv_paths_v9", ",", "\n", "\n", "maximal_attack_train_csv_paths_v7", ",", "maximal_attack_eval_csv_paths_v7", ",", "\n", "minimal_defense_train_csv_paths_v7", ",", "minimal_defense_eval_csv_paths_v7", ",", "\n", "random_attack_train_csv_paths_v7", ",", "random_attack_eval_csv_paths_v7", ",", "\n", "random_defense_train_csv_paths_v7", ",", "random_defense_eval_csv_paths_v7", ",", "\n", "two_agents_train_csv_paths_v7", ",", "two_agents_eval_csv_paths_v7", ",", "\n", "\n", "algorithm", ",", "output_dir", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ",", "versions", ":", "list", ",", "\n", "wspace", "=", "0.28", ",", "file_name", "=", "\"combined_plot_mult_versions_\"", ")", ":", "\n", "\n", "# V8", "\n", "    ", "train_max_attack_dfs_v8", "=", "[", "]", "\n", "eval_max_attack_dfs_v8", "=", "[", "]", "\n", "for", "csv_path", "in", "maximal_attack_train_csv_paths_v8", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_max_attack_dfs_v8", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "maximal_attack_eval_csv_paths_v8", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_max_attack_dfs_v8", ".", "append", "(", "df", ")", "\n", "\n", "", "a_loss_train_max_attack_data_v8", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "train_max_attack_dfs_v8", ")", ")", "\n", "a_loss_train_max_attack_means_v8", "=", "np", ".", "mean", "(", "tuple", "(", "a_loss_train_max_attack_data_v8", ")", ",", "axis", "=", "0", ")", "\n", "a_loss_train_max_attack_stds_v8", "=", "np", ".", "std", "(", "tuple", "(", "a_loss_train_max_attack_data_v8", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_loss_train_max_attack_data_v8", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_defender\"", "]", ".", "values", ",", "train_max_attack_dfs_v8", ")", ")", "\n", "d_loss_train_max_attack_means_v8", "=", "np", ".", "mean", "(", "tuple", "(", "d_loss_train_max_attack_data_v8", ")", ",", "axis", "=", "0", ")", "\n", "d_loss_train_max_attack_stds_v8", "=", "np", ".", "std", "(", "tuple", "(", "d_loss_train_max_attack_data_v8", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_min_defense_dfs_v8", "=", "[", "]", "\n", "eval_min_defense_dfs_v8", "=", "[", "]", "\n", "for", "csv_path", "in", "minimal_defense_train_csv_paths_v8", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_min_defense_dfs_v8", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "minimal_defense_eval_csv_paths_v8", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_min_defense_dfs_v8", ".", "append", "(", "df", ")", "\n", "\n", "", "a_loss_train_min_defense_data_v8", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "train_min_defense_dfs_v8", ")", ")", "\n", "a_loss_train_min_defense_means_v8", "=", "np", ".", "mean", "(", "tuple", "(", "a_loss_train_min_defense_data_v8", ")", ",", "axis", "=", "0", ")", "\n", "a_loss_train_min_defense_stds_v8", "=", "np", ".", "std", "(", "tuple", "(", "a_loss_train_min_defense_data_v8", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_loss_train_min_defense_data_v8", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_defender\"", "]", ".", "values", ",", "train_min_defense_dfs_v8", ")", ")", "\n", "d_loss_train_min_defense_means_v8", "=", "np", ".", "mean", "(", "tuple", "(", "d_loss_train_min_defense_data_v8", ")", ",", "axis", "=", "0", ")", "\n", "d_loss_train_min_defense_stds_v8", "=", "np", ".", "std", "(", "tuple", "(", "d_loss_train_min_defense_data_v8", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_attack_dfs_v8", "=", "[", "]", "\n", "eval_random_attack_dfs_v8", "=", "[", "]", "\n", "for", "csv_path", "in", "random_attack_train_csv_paths_v8", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_attack_dfs_v8", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_attack_eval_csv_paths_v8", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_attack_dfs_v8", ".", "append", "(", "df", ")", "\n", "\n", "", "a_loss_train_random_attack_data_v8", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "train_random_attack_dfs_v8", ")", ")", "\n", "a_loss_train_random_attack_means_v8", "=", "np", ".", "mean", "(", "tuple", "(", "a_loss_train_random_attack_data_v8", ")", ",", "axis", "=", "0", ")", "\n", "a_loss_train_random_attack_stds_v8", "=", "np", ".", "std", "(", "tuple", "(", "a_loss_train_random_attack_data_v8", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_loss_train_random_attack_data_v8", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_defender\"", "]", ".", "values", ",", "train_random_attack_dfs_v8", ")", ")", "\n", "d_loss_train_random_attack_means_v8", "=", "np", ".", "mean", "(", "tuple", "(", "d_loss_train_random_attack_data_v8", ")", ",", "axis", "=", "0", ")", "\n", "d_loss_train_random_attack_stds_v8", "=", "np", ".", "std", "(", "tuple", "(", "d_loss_train_random_attack_data_v8", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_defense_dfs_v8", "=", "[", "]", "\n", "eval_random_defense_dfs_v8", "=", "[", "]", "\n", "for", "csv_path", "in", "random_defense_train_csv_paths_v8", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_defense_dfs_v8", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_defense_eval_csv_paths_v8", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_defense_dfs_v8", ".", "append", "(", "df", ")", "\n", "\n", "", "a_loss_train_random_defense_data_v8", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "train_random_defense_dfs_v8", ")", ")", "\n", "a_loss_train_random_defense_means_v8", "=", "np", ".", "mean", "(", "tuple", "(", "a_loss_train_random_defense_data_v8", ")", ",", "axis", "=", "0", ")", "\n", "a_loss_train_random_defense_stds_v8", "=", "np", ".", "std", "(", "tuple", "(", "a_loss_train_random_defense_data_v8", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_loss_train_random_defense_data_v8", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_defender\"", "]", ".", "values", ",", "train_random_defense_dfs_v8", ")", ")", "\n", "d_loss_train_random_defense_means_v8", "=", "np", ".", "mean", "(", "tuple", "(", "d_loss_train_random_defense_data_v8", ")", ",", "axis", "=", "0", ")", "\n", "d_loss_train_random_defense_stds_v8", "=", "np", ".", "std", "(", "tuple", "(", "d_loss_train_random_defense_data_v8", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_two_agents_dfs_v8", "=", "[", "]", "\n", "eval_two_agents_dfs_v8", "=", "[", "]", "\n", "for", "csv_path", "in", "two_agents_train_csv_paths_v8", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_two_agents_dfs_v8", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "two_agents_eval_csv_paths_v8", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_two_agents_dfs_v8", ".", "append", "(", "df", ")", "\n", "\n", "", "a_loss_train_two_agents_data_v8", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "train_two_agents_dfs_v8", ")", ")", "\n", "a_loss_train_two_agents_means_v8", "=", "np", ".", "mean", "(", "tuple", "(", "a_loss_train_two_agents_data_v8", ")", ",", "axis", "=", "0", ")", "\n", "a_loss_train_two_agents_stds_v8", "=", "np", ".", "std", "(", "tuple", "(", "a_loss_train_two_agents_data_v8", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_loss_train_two_agents_data_v8", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_defender\"", "]", ".", "values", ",", "train_two_agents_dfs_v8", ")", ")", "\n", "d_loss_train_two_agents_means_v8", "=", "np", ".", "mean", "(", "tuple", "(", "d_loss_train_two_agents_data_v8", ")", ",", "axis", "=", "0", ")", "\n", "d_loss_train_two_agents_stds_v8", "=", "np", ".", "std", "(", "tuple", "(", "d_loss_train_two_agents_data_v8", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "# V9", "\n", "train_max_attack_dfs_v9", "=", "[", "]", "\n", "eval_max_attack_dfs_v9", "=", "[", "]", "\n", "for", "csv_path", "in", "maximal_attack_train_csv_paths_v9", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_max_attack_dfs_v9", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "maximal_attack_eval_csv_paths_v9", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_max_attack_dfs_v9", ".", "append", "(", "df", ")", "\n", "\n", "", "a_loss_train_max_attack_data_v9", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "train_max_attack_dfs_v9", ")", ")", "\n", "a_loss_train_max_attack_means_v9", "=", "np", ".", "mean", "(", "tuple", "(", "a_loss_train_max_attack_data_v9", ")", ",", "axis", "=", "0", ")", "\n", "a_loss_train_max_attack_stds_v9", "=", "np", ".", "std", "(", "tuple", "(", "a_loss_train_max_attack_data_v9", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_loss_train_max_attack_data_v9", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_defender\"", "]", ".", "values", ",", "train_max_attack_dfs_v9", ")", ")", "\n", "d_loss_train_max_attack_means_v9", "=", "np", ".", "mean", "(", "tuple", "(", "d_loss_train_max_attack_data_v9", ")", ",", "axis", "=", "0", ")", "\n", "d_loss_train_max_attack_stds_v9", "=", "np", ".", "std", "(", "tuple", "(", "d_loss_train_max_attack_data_v9", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_min_defense_dfs_v9", "=", "[", "]", "\n", "eval_min_defense_dfs_v9", "=", "[", "]", "\n", "for", "csv_path", "in", "minimal_defense_train_csv_paths_v9", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_min_defense_dfs_v9", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "minimal_defense_eval_csv_paths_v9", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_min_defense_dfs_v9", ".", "append", "(", "df", ")", "\n", "\n", "", "a_loss_train_min_defense_data_v9", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "train_min_defense_dfs_v9", ")", ")", "\n", "a_loss_train_min_defense_means_v9", "=", "np", ".", "mean", "(", "tuple", "(", "a_loss_train_min_defense_data_v9", ")", ",", "axis", "=", "0", ")", "\n", "a_loss_train_min_defense_stds_v9", "=", "np", ".", "std", "(", "tuple", "(", "a_loss_train_min_defense_data_v9", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_loss_train_min_defense_data_v9", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_defender\"", "]", ".", "values", ",", "train_min_defense_dfs_v9", ")", ")", "\n", "d_loss_train_min_defense_means_v9", "=", "np", ".", "mean", "(", "tuple", "(", "d_loss_train_min_defense_data_v9", ")", ",", "axis", "=", "0", ")", "\n", "d_loss_train_min_defense_stds_v9", "=", "np", ".", "std", "(", "tuple", "(", "d_loss_train_min_defense_data_v9", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_attack_dfs_v9", "=", "[", "]", "\n", "eval_random_attack_dfs_v9", "=", "[", "]", "\n", "for", "csv_path", "in", "random_attack_train_csv_paths_v9", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_attack_dfs_v9", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_attack_eval_csv_paths_v9", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_attack_dfs_v9", ".", "append", "(", "df", ")", "\n", "\n", "", "a_loss_train_random_attack_data_v9", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "train_random_attack_dfs_v9", ")", ")", "\n", "a_loss_train_random_attack_means_v9", "=", "np", ".", "mean", "(", "tuple", "(", "a_loss_train_random_attack_data_v9", ")", ",", "axis", "=", "0", ")", "\n", "a_loss_train_random_attack_stds_v9", "=", "np", ".", "std", "(", "tuple", "(", "a_loss_train_random_attack_data_v9", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_loss_train_random_attack_data_v9", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_defender\"", "]", ".", "values", ",", "train_random_attack_dfs_v9", ")", ")", "\n", "d_loss_train_random_attack_means_v9", "=", "np", ".", "mean", "(", "tuple", "(", "d_loss_train_random_attack_data_v9", ")", ",", "axis", "=", "0", ")", "\n", "d_loss_train_random_attack_stds_v9", "=", "np", ".", "std", "(", "tuple", "(", "d_loss_train_random_attack_data_v9", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_defense_dfs_v9", "=", "[", "]", "\n", "eval_random_defense_dfs_v9", "=", "[", "]", "\n", "for", "csv_path", "in", "random_defense_train_csv_paths_v9", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_defense_dfs_v9", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_defense_eval_csv_paths_v9", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_defense_dfs_v9", ".", "append", "(", "df", ")", "\n", "\n", "", "a_loss_train_random_defense_data_v9", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "train_random_defense_dfs_v9", ")", ")", "\n", "a_loss_train_random_defense_means_v9", "=", "np", ".", "mean", "(", "tuple", "(", "a_loss_train_random_defense_data_v9", ")", ",", "axis", "=", "0", ")", "\n", "a_loss_train_random_defense_stds_v9", "=", "np", ".", "std", "(", "tuple", "(", "a_loss_train_random_defense_data_v9", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_loss_train_random_defense_data_v9", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_defender\"", "]", ".", "values", ",", "train_random_defense_dfs_v9", ")", ")", "\n", "d_loss_train_random_defense_means_v9", "=", "np", ".", "mean", "(", "tuple", "(", "d_loss_train_random_defense_data_v9", ")", ",", "axis", "=", "0", ")", "\n", "d_loss_train_random_defense_stds_v9", "=", "np", ".", "std", "(", "tuple", "(", "d_loss_train_random_defense_data_v9", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_two_agents_dfs_v9", "=", "[", "]", "\n", "eval_two_agents_dfs_v9", "=", "[", "]", "\n", "for", "csv_path", "in", "two_agents_train_csv_paths_v9", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_two_agents_dfs_v9", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "two_agents_eval_csv_paths_v9", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_two_agents_dfs_v9", ".", "append", "(", "df", ")", "\n", "\n", "", "a_loss_train_two_agents_data_v9", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "train_two_agents_dfs_v9", ")", ")", "\n", "a_loss_train_two_agents_means_v9", "=", "np", ".", "mean", "(", "tuple", "(", "a_loss_train_two_agents_data_v9", ")", ",", "axis", "=", "0", ")", "\n", "a_loss_train_two_agents_stds_v9", "=", "np", ".", "std", "(", "tuple", "(", "a_loss_train_two_agents_data_v9", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_loss_train_two_agents_data_v9", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_defender\"", "]", ".", "values", ",", "train_two_agents_dfs_v9", ")", ")", "\n", "d_loss_train_two_agents_means_v9", "=", "np", ".", "mean", "(", "tuple", "(", "d_loss_train_two_agents_data_v9", ")", ",", "axis", "=", "0", ")", "\n", "d_loss_train_two_agents_stds_v9", "=", "np", ".", "std", "(", "tuple", "(", "d_loss_train_two_agents_data_v9", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "# V7", "\n", "train_max_attack_dfs_v7", "=", "[", "]", "\n", "eval_max_attack_dfs_v7", "=", "[", "]", "\n", "for", "csv_path", "in", "maximal_attack_train_csv_paths_v7", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_max_attack_dfs_v7", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "maximal_attack_eval_csv_paths_v7", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_max_attack_dfs_v7", ".", "append", "(", "df", ")", "\n", "\n", "", "a_loss_train_max_attack_data_v7", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "train_max_attack_dfs_v7", ")", ")", "\n", "a_loss_train_max_attack_means_v7", "=", "np", ".", "mean", "(", "tuple", "(", "a_loss_train_max_attack_data_v7", ")", ",", "axis", "=", "0", ")", "\n", "a_loss_train_max_attack_stds_v7", "=", "np", ".", "std", "(", "tuple", "(", "a_loss_train_max_attack_data_v7", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_loss_train_max_attack_data_v7", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_defender\"", "]", ".", "values", ",", "train_max_attack_dfs_v7", ")", ")", "\n", "d_loss_train_max_attack_means_v7", "=", "np", ".", "mean", "(", "tuple", "(", "d_loss_train_max_attack_data_v7", ")", ",", "axis", "=", "0", ")", "\n", "d_loss_train_max_attack_stds_v7", "=", "np", ".", "std", "(", "tuple", "(", "d_loss_train_max_attack_data_v7", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "\n", "train_min_defense_dfs_v7", "=", "[", "]", "\n", "eval_min_defense_dfs_v7", "=", "[", "]", "\n", "for", "csv_path", "in", "minimal_defense_train_csv_paths_v7", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_min_defense_dfs_v7", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "minimal_defense_eval_csv_paths_v7", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_min_defense_dfs_v7", ".", "append", "(", "df", ")", "\n", "\n", "", "a_loss_train_min_defense_data_v7", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "train_min_defense_dfs_v7", ")", ")", "\n", "a_loss_train_min_defense_means_v7", "=", "np", ".", "mean", "(", "tuple", "(", "a_loss_train_min_defense_data_v7", ")", ",", "axis", "=", "0", ")", "\n", "a_loss_train_min_defense_stds_v7", "=", "np", ".", "std", "(", "tuple", "(", "a_loss_train_min_defense_data_v7", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_loss_train_min_defense_data_v7", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_defender\"", "]", ".", "values", ",", "train_min_defense_dfs_v7", ")", ")", "\n", "d_loss_train_min_defense_means_v7", "=", "np", ".", "mean", "(", "tuple", "(", "d_loss_train_min_defense_data_v7", ")", ",", "axis", "=", "0", ")", "\n", "d_loss_train_min_defense_stds_v7", "=", "np", ".", "std", "(", "tuple", "(", "d_loss_train_min_defense_data_v7", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_attack_dfs_v7", "=", "[", "]", "\n", "eval_random_attack_dfs_v7", "=", "[", "]", "\n", "for", "csv_path", "in", "random_attack_train_csv_paths_v7", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_attack_dfs_v7", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_attack_eval_csv_paths_v7", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_attack_dfs_v7", ".", "append", "(", "df", ")", "\n", "\n", "", "a_loss_train_random_attack_data_v7", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "train_random_attack_dfs_v7", ")", ")", "\n", "a_loss_train_random_attack_means_v7", "=", "np", ".", "mean", "(", "tuple", "(", "a_loss_train_random_attack_data_v7", ")", ",", "axis", "=", "0", ")", "\n", "a_loss_train_random_attack_stds_v7", "=", "np", ".", "std", "(", "tuple", "(", "a_loss_train_random_attack_data_v7", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_loss_train_random_attack_data_v7", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_defender\"", "]", ".", "values", ",", "train_random_attack_dfs_v7", ")", ")", "\n", "d_loss_train_random_attack_means_v7", "=", "np", ".", "mean", "(", "tuple", "(", "d_loss_train_random_attack_data_v7", ")", ",", "axis", "=", "0", ")", "\n", "d_loss_train_random_attack_stds_v7", "=", "np", ".", "std", "(", "tuple", "(", "d_loss_train_random_attack_data_v7", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_defense_dfs_v7", "=", "[", "]", "\n", "eval_random_defense_dfs_v7", "=", "[", "]", "\n", "for", "csv_path", "in", "random_defense_train_csv_paths_v7", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_defense_dfs_v7", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_defense_eval_csv_paths_v7", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_defense_dfs_v7", ".", "append", "(", "df", ")", "\n", "\n", "", "a_loss_train_random_defense_data_v7", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "train_random_defense_dfs_v7", ")", ")", "\n", "a_loss_train_random_defense_means_v7", "=", "np", ".", "mean", "(", "tuple", "(", "a_loss_train_random_defense_data_v7", ")", ",", "axis", "=", "0", ")", "\n", "a_loss_train_random_defense_stds_v7", "=", "np", ".", "std", "(", "tuple", "(", "a_loss_train_random_defense_data_v7", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_loss_train_random_defense_data_v7", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_defender\"", "]", ".", "values", ",", "train_random_defense_dfs_v7", ")", ")", "\n", "d_loss_train_random_defense_means_v7", "=", "np", ".", "mean", "(", "tuple", "(", "d_loss_train_random_defense_data_v7", ")", ",", "axis", "=", "0", ")", "\n", "d_loss_train_random_defense_stds_v7", "=", "np", ".", "std", "(", "tuple", "(", "d_loss_train_random_defense_data_v7", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_two_agents_dfs_v7", "=", "[", "]", "\n", "eval_two_agents_dfs_v7", "=", "[", "]", "\n", "for", "csv_path", "in", "two_agents_train_csv_paths_v7", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_two_agents_dfs_v7", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "two_agents_eval_csv_paths_v7", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_two_agents_dfs_v7", ".", "append", "(", "df", ")", "\n", "\n", "", "a_loss_train_two_agents_data_v7", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "train_two_agents_dfs_v7", ")", ")", "\n", "a_loss_train_two_agents_means_v7", "=", "np", ".", "mean", "(", "tuple", "(", "a_loss_train_two_agents_data_v7", ")", ",", "axis", "=", "0", ")", "\n", "a_loss_train_two_agents_stds_v7", "=", "np", ".", "std", "(", "tuple", "(", "a_loss_train_two_agents_data_v7", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_loss_train_two_agents_data_v7", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_defender\"", "]", ".", "values", ",", "train_two_agents_dfs_v7", ")", ")", "\n", "d_loss_train_two_agents_means_v7", "=", "np", ".", "mean", "(", "tuple", "(", "d_loss_train_two_agents_data_v7", ")", ",", "axis", "=", "0", ")", "\n", "d_loss_train_two_agents_stds_v7", "=", "np", ".", "std", "(", "tuple", "(", "d_loss_train_two_agents_data_v7", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "plot_all_avg_summary_5", "(", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_loss_train_max_attack_data_v8", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_loss_train_max_attack_data_v8", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_max_attack_means_v8", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_max_attack_means_v8", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_loss_train_max_attack_data_v9", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_loss_train_max_attack_data_v9", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_max_attack_means_v9", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_max_attack_means_v9", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_loss_train_max_attack_data_v7", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_loss_train_max_attack_data_v7", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_max_attack_means_v7", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_max_attack_means_v7", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_max_attack_stds_v8", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_max_attack_stds_v8", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_max_attack_stds_v9", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_max_attack_stds_v9", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_max_attack_stds_v7", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_max_attack_stds_v7", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_loss_train_min_defense_data_v8", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_loss_train_min_defense_data_v8", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_min_defense_means_v8", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_min_defense_means_v8", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_loss_train_min_defense_data_v9", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_loss_train_min_defense_data_v9", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_min_defense_means_v9", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_min_defense_means_v9", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_loss_train_min_defense_data_v7", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_loss_train_min_defense_data_v7", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_min_defense_means_v7", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_min_defense_means_v7", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_min_defense_stds_v8", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_min_defense_stds_v8", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_min_defense_stds_v9", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_min_defense_stds_v9", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_min_defense_stds_v7", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_min_defense_stds_v7", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_loss_train_random_attack_data_v8", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_loss_train_random_attack_data_v8", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_random_attack_means_v8", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_random_attack_means_v8", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_loss_train_random_attack_data_v9", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_loss_train_random_attack_data_v9", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_random_attack_means_v9", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_random_attack_means_v9", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_loss_train_random_attack_data_v7", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_loss_train_random_attack_data_v7", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_random_attack_means_v7", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_random_attack_means_v7", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_random_attack_stds_v8", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_random_attack_stds_v8", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_random_attack_stds_v9", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_random_attack_stds_v9", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_random_attack_stds_v7", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_random_attack_stds_v7", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_loss_train_random_defense_data_v8", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_loss_train_random_defense_data_v8", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_random_defense_means_v8", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_random_defense_means_v8", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_loss_train_random_defense_data_v9", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_loss_train_random_defense_data_v9", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_random_defense_means_v9", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_random_defense_means_v9", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_loss_train_random_defense_data_v7", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_loss_train_random_defense_data_v7", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_random_defense_means_v7", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_random_defense_means_v7", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_random_defense_stds_v8", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_random_defense_stds_v8", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_random_defense_stds_v9", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_random_defense_stds_v9", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_random_defense_stds_v7", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_random_defense_stds_v7", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_loss_train_two_agents_data_v8", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_loss_train_two_agents_data_v8", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_two_agents_means_v8", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_two_agents_means_v8", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_loss_train_two_agents_data_v9", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_loss_train_two_agents_data_v9", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_two_agents_means_v9", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_two_agents_means_v9", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_loss_train_two_agents_data_v7", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_loss_train_two_agents_data_v7", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_two_agents_means_v7", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_two_agents_means_v7", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_two_agents_stds_v8", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_two_agents_stds_v8", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_two_agents_stds_v9", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_two_agents_stds_v9", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_loss_train_two_agents_stds_v7", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "d_loss_train_two_agents_stds_v7", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "\n", "2", ",", "r\"Attacker Loss\"", ",", "r\"Defender Loss\"", ",", "\n", "r\"\\textsc{MaxAttack} vs \\textsc{DQN}\"", ",", "\n", "r\"\\textsc{DQN} vs \\textsc{MinDefense}\"", ",", "\n", "r\"\\textsc{RandomAttack} vs \\textsc{DQN}\"", ",", "\n", "r\"\\textsc{DQN} vs \\textsc{RandomDefense}\"", ",", "\n", "r\"\\textsc{DQN} vs \\textsc{DQN}\"", ",", "\n", "r\"Episode \\#\"", ",", "\"Loss\"", ",", "output_dir", "+", "\"/\"", "+", "file_name", "+", "algorithm", "+", "\"_\"", "+", "str", "(", "0", ")", ",", "wspace", "=", "wspace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages_multiple_versions": [[3965, 4982], ["list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "plotting_util.plot_all_avg_summary_3", "plotting_util.five_line_plot_w_shades", "plotting_util.five_line_plot_w_shades", "plotting_util.five_line_plot_w_shades", "plotting_util.plot_all_avg_summary_2", "plotting_util.read_data", "train_max_attack_dfs_v0.append", "plotting_util.read_data", "eval_max_attack_dfs_v0.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_min_defense_dfs_v0.append", "plotting_util.read_data", "eval_min_defense_dfs_v0.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_attack_dfs_v0.append", "plotting_util.read_data", "eval_random_attack_dfs_v0.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_defense_dfs_v0.append", "plotting_util.read_data", "eval_random_defense_dfs_v0.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_two_agents_dfs_v0.append", "plotting_util.read_data", "eval_two_agents_dfs_v0.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_max_attack_dfs_v2.append", "plotting_util.read_data", "eval_max_attack_dfs_v2.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_min_defense_dfs_v2.append", "plotting_util.read_data", "eval_min_defense_dfs_v2.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_attack_dfs_v2.append", "plotting_util.read_data", "eval_random_attack_dfs_v2.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_defense_dfs_v2.append", "plotting_util.read_data", "eval_random_defense_dfs_v2.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_two_agents_dfs_v2.append", "plotting_util.read_data", "eval_two_agents_dfs_v2.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_max_attack_dfs_v3.append", "plotting_util.read_data", "eval_max_attack_dfs_v3.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_min_defense_dfs_v3.append", "plotting_util.read_data", "eval_min_defense_dfs_v3.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_attack_dfs_v3.append", "plotting_util.read_data", "eval_random_attack_dfs_v3.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_random_defense_dfs_v3.append", "plotting_util.read_data", "eval_random_defense_dfs_v3.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "plotting_util.read_data", "train_two_agents_dfs_v3.append", "plotting_util.read_data", "eval_two_agents_dfs_v3.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "str", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "str", "list", "list", "list", "list", "list", "str", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "str", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "str", "list", "list", "list", "list", "list", "str", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "str", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "str", "list", "list", "list", "list", "list", "str", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "str", "list", "list", "list", "list", "list", "str", "list", "list", "list", "list", "list", "str", "list", "list", "list", "list", "list", "str", "list", "list", "list", "list", "list", "str", "list", "list", "list", "list", "list", "str", "list", "list", "list", "list", "list", "str", "list", "list", "list", "list", "list", "str", "list", "list", "list", "list", "list", "range", "range", "range", "range", "range", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "range", "range", "range", "range", "range", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "range", "range", "range", "range", "range", "list", "list", "list", "list", "list", "range", "range", "range", "range", "range", "str", "range", "range", "range", "range", "range", "str", "range", "range", "range", "range", "range", "str", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "len", "len", "len", "len", "len", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "len", "len", "len", "len", "len", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "len", "len", "len", "len", "len", "range", "range", "range", "range", "range", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_avg_summary_3", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.five_line_plot_w_shades", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.five_line_plot_w_shades", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.five_line_plot_w_shades", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_avg_summary_2", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data"], ["", "def", "plot_all_averages_multiple_versions", "(", "maximal_attack_train_csv_paths_v0", ",", "maximal_attack_eval_csv_paths_v0", ",", "\n", "minimal_defense_train_csv_paths_v0", ",", "minimal_defense_eval_csv_paths_v0", ",", "\n", "random_attack_train_csv_paths_v0", ",", "random_attack_eval_csv_paths_v0", ",", "\n", "random_defense_train_csv_paths_v0", ",", "random_defense_eval_csv_paths_v0", ",", "\n", "two_agents_train_csv_paths_v0", ",", "two_agents_eval_csv_paths_v0", ",", "\n", "\n", "maximal_attack_train_csv_paths_v2", ",", "maximal_attack_eval_csv_paths_v2", ",", "\n", "minimal_defense_train_csv_paths_v2", ",", "minimal_defense_eval_csv_paths_v2", ",", "\n", "random_attack_train_csv_paths_v2", ",", "random_attack_eval_csv_paths_v2", ",", "\n", "random_defense_train_csv_paths_v2", ",", "random_defense_eval_csv_paths_v2", ",", "\n", "two_agents_train_csv_paths_v2", ",", "two_agents_eval_csv_paths_v2", ",", "\n", "\n", "maximal_attack_train_csv_paths_v3", ",", "maximal_attack_eval_csv_paths_v3", ",", "\n", "minimal_defense_train_csv_paths_v3", ",", "minimal_defense_eval_csv_paths_v3", ",", "\n", "random_attack_train_csv_paths_v3", ",", "random_attack_eval_csv_paths_v3", ",", "\n", "random_defense_train_csv_paths_v3", ",", "random_defense_eval_csv_paths_v3", ",", "\n", "two_agents_train_csv_paths_v3", ",", "two_agents_eval_csv_paths_v3", ",", "\n", "\n", "algorithm", ",", "output_dir", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ",", "versions", ":", "list", ",", "\n", "wspace", "=", "0.28", ",", "file_name", "=", "\"combined_plot_mult_versions_\"", ")", ":", "\n", "\n", "# V0", "\n", "    ", "train_max_attack_dfs_v0", "=", "[", "]", "\n", "eval_max_attack_dfs_v0", "=", "[", "]", "\n", "for", "csv_path", "in", "maximal_attack_train_csv_paths_v0", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_max_attack_dfs_v0", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "maximal_attack_eval_csv_paths_v0", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_max_attack_dfs_v0", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_train_max_attack_data_v0", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_max_attack_dfs_v0", ")", ")", "\n", "hack_prob_train_max_attack_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_max_attack_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_max_attack_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_max_attack_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_max_attack_data_v0", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_max_attack_dfs_v0", ")", ")", "\n", "hack_prob_eval_max_attack_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_max_attack_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_max_attack_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_max_attack_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "a_cum_reward_train_max_attack_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_max_attack_dfs_v0", ")", ")", "\n", "a_cum_reward_train_max_attack_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_train_max_attack_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_train_max_attack_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_train_max_attack_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "a_cum_reward_eval_max_attack_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "eval_max_attack_dfs_v0", ")", ")", "\n", "a_cum_reward_eval_max_attack_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_eval_max_attack_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_eval_max_attack_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_eval_max_attack_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_cum_reward_train_max_attack_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_max_attack_dfs_v0", ")", ")", "\n", "d_cum_reward_train_max_attack_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_train_max_attack_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_train_max_attack_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_train_max_attack_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "d_cum_reward_eval_max_attack_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "eval_max_attack_dfs_v0", ")", ")", "\n", "d_cum_reward_eval_max_attack_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_eval_max_attack_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_eval_max_attack_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_eval_max_attack_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "episode_len_train_max_attack_data_v0", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "train_max_attack_dfs_v0", ")", ")", "\n", "episode_len_train_max_attack_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_train_max_attack_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_train_max_attack_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_train_max_attack_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "episode_len_eval_max_attack_data_v0", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "eval_max_attack_dfs_v0", ")", ")", "\n", "episode_len_eval_max_attack_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_eval_max_attack_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_eval_max_attack_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_eval_max_attack_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_min_defense_dfs_v0", "=", "[", "]", "\n", "eval_min_defense_dfs_v0", "=", "[", "]", "\n", "for", "csv_path", "in", "minimal_defense_train_csv_paths_v0", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_min_defense_dfs_v0", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "minimal_defense_eval_csv_paths_v0", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_min_defense_dfs_v0", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_train_min_defense_data_v0", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_min_defense_dfs_v0", ")", ")", "\n", "hack_prob_train_min_defense_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_min_defense_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_min_defense_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_min_defense_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_min_defense_data_v0", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_min_defense_dfs_v0", ")", ")", "\n", "hack_prob_eval_min_defense_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_min_defense_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_min_defense_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_min_defense_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "a_cum_reward_train_min_defense_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_min_defense_dfs_v0", ")", ")", "\n", "a_cum_reward_train_min_defense_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_train_min_defense_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_train_min_defense_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_train_min_defense_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "a_cum_reward_eval_min_defense_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "eval_min_defense_dfs_v0", ")", ")", "\n", "a_cum_reward_eval_min_defense_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_eval_min_defense_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_eval_min_defense_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_eval_min_defense_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_cum_reward_train_min_defense_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_min_defense_dfs_v0", ")", ")", "\n", "d_cum_reward_train_min_defense_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_train_min_defense_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_train_min_defense_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_train_min_defense_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "d_cum_reward_eval_min_defense_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "eval_min_defense_dfs_v0", ")", ")", "\n", "d_cum_reward_eval_min_defense_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_eval_min_defense_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_eval_min_defense_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_eval_min_defense_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "episode_len_train_min_defense_data_v0", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "train_min_defense_dfs_v0", ")", ")", "\n", "episode_len_train_min_defense_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_train_min_defense_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_train_min_defense_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_train_min_defense_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "episode_len_eval_min_defense_data_v0", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "eval_min_defense_dfs_v0", ")", ")", "\n", "episode_len_eval_min_defense_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_eval_min_defense_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_eval_min_defense_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_eval_min_defense_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_attack_dfs_v0", "=", "[", "]", "\n", "eval_random_attack_dfs_v0", "=", "[", "]", "\n", "for", "csv_path", "in", "random_attack_train_csv_paths_v0", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_attack_dfs_v0", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_attack_eval_csv_paths_v0", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_attack_dfs_v0", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_train_random_attack_data_v0", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_random_attack_dfs_v0", ")", ")", "\n", "hack_prob_train_random_attack_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_random_attack_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_random_attack_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_random_attack_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_random_attack_data_v0", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_random_attack_dfs_v0", ")", ")", "\n", "hack_prob_eval_random_attack_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_random_attack_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_random_attack_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_random_attack_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "a_cum_reward_train_random_attack_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_random_attack_dfs_v0", ")", ")", "\n", "a_cum_reward_train_random_attack_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_train_random_attack_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_train_random_attack_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_train_random_attack_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "a_cum_reward_eval_random_attack_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "eval_random_attack_dfs_v0", ")", ")", "\n", "a_cum_reward_eval_random_attack_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_eval_random_attack_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_eval_random_attack_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_eval_random_attack_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_cum_reward_train_random_attack_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_random_attack_dfs_v0", ")", ")", "\n", "d_cum_reward_train_random_attack_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_train_random_attack_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_train_random_attack_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_train_random_attack_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "d_cum_reward_eval_random_attack_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "eval_random_attack_dfs_v0", ")", ")", "\n", "d_cum_reward_eval_random_attack_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_eval_random_attack_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_eval_random_attack_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_eval_random_attack_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "episode_len_train_random_attack_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "train_random_attack_dfs_v0", ")", ")", "\n", "episode_len_train_random_attack_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_train_random_attack_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_train_random_attack_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_train_random_attack_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "episode_len_eval_random_attack_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "eval_random_attack_dfs_v0", ")", ")", "\n", "episode_len_eval_random_attack_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_eval_random_attack_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_eval_random_attack_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_eval_random_attack_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_defense_dfs_v0", "=", "[", "]", "\n", "eval_random_defense_dfs_v0", "=", "[", "]", "\n", "for", "csv_path", "in", "random_defense_train_csv_paths_v0", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_defense_dfs_v0", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_defense_eval_csv_paths_v0", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_defense_dfs_v0", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_train_random_defense_data_v0", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_random_defense_dfs_v0", ")", ")", "\n", "hack_prob_train_random_defense_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_random_defense_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_random_defense_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_random_defense_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_random_defense_data_v0", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_random_defense_dfs_v0", ")", ")", "\n", "hack_prob_eval_random_defense_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_random_defense_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_random_defense_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_random_defense_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "a_cum_reward_train_random_defense_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_random_defense_dfs_v0", ")", ")", "\n", "a_cum_reward_train_random_defense_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_train_random_defense_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_train_random_defense_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_train_random_defense_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "a_cum_reward_eval_random_defense_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "eval_random_defense_dfs_v0", ")", ")", "\n", "a_cum_reward_eval_random_defense_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_eval_random_defense_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_eval_random_defense_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_eval_random_defense_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_cum_reward_train_random_defense_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_random_defense_dfs_v0", ")", ")", "\n", "d_cum_reward_train_random_defense_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_train_random_defense_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_train_random_defense_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_train_random_defense_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "d_cum_reward_eval_random_defense_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "eval_random_defense_dfs_v0", ")", ")", "\n", "d_cum_reward_eval_random_defense_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_eval_random_defense_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_eval_random_defense_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_eval_random_defense_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "episode_len_train_random_defense_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "train_random_defense_dfs_v0", ")", ")", "\n", "episode_len_train_random_defense_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_train_random_defense_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_train_random_defense_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_train_random_defense_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "episode_len_eval_random_defense_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "eval_random_defense_dfs_v0", ")", ")", "\n", "episode_len_eval_random_defense_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_eval_random_defense_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_eval_random_defense_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_eval_random_defense_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_two_agents_dfs_v0", "=", "[", "]", "\n", "eval_two_agents_dfs_v0", "=", "[", "]", "\n", "for", "csv_path", "in", "two_agents_train_csv_paths_v0", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_two_agents_dfs_v0", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "two_agents_eval_csv_paths_v0", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_two_agents_dfs_v0", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_train_two_agents_data_v0", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_two_agents_dfs_v0", ")", ")", "\n", "hack_prob_train_two_agents_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_two_agents_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_two_agents_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_two_agents_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_two_agents_data_v0", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_two_agents_dfs_v0", ")", ")", "\n", "hack_prob_eval_two_agents_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_two_agents_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_two_agents_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_two_agents_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "a_cum_reward_train_two_agents_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_two_agents_dfs_v0", ")", ")", "\n", "a_cum_reward_train_two_agents_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_train_two_agents_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_train_two_agents_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_train_two_agents_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "a_cum_reward_eval_two_agents_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "eval_two_agents_dfs_v0", ")", ")", "\n", "a_cum_reward_eval_two_agents_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_eval_two_agents_data", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_eval_two_agents_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_eval_two_agents_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_cum_reward_train_two_agents_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_two_agents_dfs_v0", ")", ")", "\n", "d_cum_reward_train_two_agents_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_train_two_agents_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_train_two_agents_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_train_two_agents_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "d_cum_reward_eval_two_agents_data_v0", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "eval_two_agents_dfs_v0", ")", ")", "\n", "d_cum_reward_eval_two_agents_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_eval_two_agents_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_eval_two_agents_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_eval_two_agents_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "episode_len_train_two_agents_data_v0", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "train_two_agents_dfs_v0", ")", ")", "\n", "episode_len_train_two_agents_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_train_two_agents_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_train_two_agents_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_train_two_agents_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "episode_len_eval_two_agents_data_v0", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "eval_two_agents_dfs_v0", ")", ")", "\n", "episode_len_eval_two_agents_means_v0", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_eval_two_agents_data_v0", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_eval_two_agents_stds_v0", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_eval_two_agents_data_v0", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "\n", "\n", "# V2", "\n", "train_max_attack_dfs_v2", "=", "[", "]", "\n", "eval_max_attack_dfs_v2", "=", "[", "]", "\n", "for", "csv_path", "in", "maximal_attack_train_csv_paths_v2", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_max_attack_dfs_v2", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "maximal_attack_eval_csv_paths_v2", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_max_attack_dfs_v2", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_train_max_attack_data_v2", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_max_attack_dfs_v2", ")", ")", "\n", "hack_prob_train_max_attack_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_max_attack_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_max_attack_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_max_attack_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_max_attack_data_v2", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_max_attack_dfs_v2", ")", ")", "\n", "hack_prob_eval_max_attack_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_max_attack_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_max_attack_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_max_attack_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "a_cum_reward_train_max_attack_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_max_attack_dfs_v2", ")", ")", "\n", "a_cum_reward_train_max_attack_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_train_max_attack_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_train_max_attack_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_train_max_attack_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "a_cum_reward_eval_max_attack_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "eval_max_attack_dfs_v2", ")", ")", "\n", "a_cum_reward_eval_max_attack_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_eval_max_attack_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_eval_max_attack_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_eval_max_attack_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_cum_reward_train_max_attack_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_max_attack_dfs_v2", ")", ")", "\n", "d_cum_reward_train_max_attack_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_train_max_attack_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_train_max_attack_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_train_max_attack_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "d_cum_reward_eval_max_attack_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "eval_max_attack_dfs_v2", ")", ")", "\n", "d_cum_reward_eval_max_attack_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_eval_max_attack_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_eval_max_attack_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_eval_max_attack_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "episode_len_train_max_attack_data_v2", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "train_max_attack_dfs_v2", ")", ")", "\n", "episode_len_train_max_attack_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_train_max_attack_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_train_max_attack_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_train_max_attack_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "episode_len_eval_max_attack_data_v2", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "eval_max_attack_dfs_v2", ")", ")", "\n", "episode_len_eval_max_attack_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_eval_max_attack_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_eval_max_attack_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_eval_max_attack_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_min_defense_dfs_v2", "=", "[", "]", "\n", "eval_min_defense_dfs_v2", "=", "[", "]", "\n", "for", "csv_path", "in", "minimal_defense_train_csv_paths_v2", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_min_defense_dfs_v2", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "minimal_defense_eval_csv_paths_v2", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_min_defense_dfs_v2", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_train_min_defense_data_v2", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_min_defense_dfs_v2", ")", ")", "\n", "hack_prob_train_min_defense_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_min_defense_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_min_defense_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_min_defense_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_min_defense_data_v2", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_min_defense_dfs_v2", ")", ")", "\n", "hack_prob_eval_min_defense_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_min_defense_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_min_defense_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_min_defense_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "a_cum_reward_train_min_defense_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_min_defense_dfs_v2", ")", ")", "\n", "a_cum_reward_train_min_defense_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_train_min_defense_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_train_min_defense_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_train_min_defense_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "a_cum_reward_eval_min_defense_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "eval_min_defense_dfs_v2", ")", ")", "\n", "a_cum_reward_eval_min_defense_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_eval_min_defense_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_eval_min_defense_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_eval_min_defense_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_cum_reward_train_min_defense_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_min_defense_dfs_v2", ")", ")", "\n", "d_cum_reward_train_min_defense_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_train_min_defense_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_train_min_defense_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_train_min_defense_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "d_cum_reward_eval_min_defense_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "eval_min_defense_dfs_v2", ")", ")", "\n", "d_cum_reward_eval_min_defense_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_eval_min_defense_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_eval_min_defense_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_eval_min_defense_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "episode_len_train_min_defense_data_v2", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "train_min_defense_dfs_v2", ")", ")", "\n", "episode_len_train_min_defense_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_train_min_defense_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_train_min_defense_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_train_min_defense_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "episode_len_eval_min_defense_data_v2", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "eval_min_defense_dfs_v2", ")", ")", "\n", "episode_len_eval_min_defense_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_eval_min_defense_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_eval_min_defense_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_eval_min_defense_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_attack_dfs_v2", "=", "[", "]", "\n", "eval_random_attack_dfs_v2", "=", "[", "]", "\n", "for", "csv_path", "in", "random_attack_train_csv_paths_v2", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_attack_dfs_v2", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_attack_eval_csv_paths_v2", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_attack_dfs_v2", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_train_random_attack_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_random_attack_dfs_v2", ")", ")", "\n", "hack_prob_train_random_attack_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_random_attack_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_random_attack_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_random_attack_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_random_attack_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_random_attack_dfs_v2", ")", ")", "\n", "hack_prob_eval_random_attack_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_random_attack_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_random_attack_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_random_attack_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "a_cum_reward_train_random_attack_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_random_attack_dfs_v2", ")", ")", "\n", "a_cum_reward_train_random_attack_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_train_random_attack_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_train_random_attack_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_train_random_attack_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "a_cum_reward_eval_random_attack_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "eval_random_attack_dfs_v2", ")", ")", "\n", "a_cum_reward_eval_random_attack_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_eval_random_attack_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_eval_random_attack_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_eval_random_attack_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_cum_reward_train_random_attack_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_random_attack_dfs_v2", ")", ")", "\n", "d_cum_reward_train_random_attack_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_train_random_attack_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_train_random_attack_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_train_random_attack_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "d_cum_reward_eval_random_attack_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "eval_random_attack_dfs_v2", ")", ")", "\n", "d_cum_reward_eval_random_attack_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_eval_random_attack_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_eval_random_attack_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_eval_random_attack_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "episode_len_train_random_attack_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "train_random_attack_dfs_v2", ")", ")", "\n", "episode_len_train_random_attack_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_train_random_attack_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_train_random_attack_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_train_random_attack_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "episode_len_eval_random_attack_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "eval_random_attack_dfs_v2", ")", ")", "\n", "episode_len_eval_random_attack_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_eval_random_attack_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_eval_random_attack_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_eval_random_attack_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_defense_dfs_v2", "=", "[", "]", "\n", "eval_random_defense_dfs_v2", "=", "[", "]", "\n", "for", "csv_path", "in", "random_defense_train_csv_paths_v2", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_defense_dfs_v2", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_defense_eval_csv_paths_v2", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_defense_dfs_v2", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_train_random_defense_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_random_defense_dfs_v2", ")", ")", "\n", "hack_prob_train_random_defense_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_random_defense_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_random_defense_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_random_defense_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_random_defense_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_random_defense_dfs_v2", ")", ")", "\n", "hack_prob_eval_random_defense_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_random_defense_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_random_defense_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_random_defense_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "a_cum_reward_train_random_defense_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_random_defense_dfs_v2", ")", ")", "\n", "a_cum_reward_train_random_defense_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_train_random_defense_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_train_random_defense_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_train_random_defense_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "a_cum_reward_eval_random_defense_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "eval_random_defense_dfs_v2", ")", ")", "\n", "a_cum_reward_eval_random_defense_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_eval_random_defense_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_eval_random_defense_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_eval_random_defense_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_cum_reward_train_random_defense_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_random_defense_dfs_v2", ")", ")", "\n", "d_cum_reward_train_random_defense_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_train_random_defense_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_train_random_defense_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_train_random_defense_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "d_cum_reward_eval_random_defense_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "eval_random_defense_dfs_v2", ")", ")", "\n", "d_cum_reward_eval_random_defense_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_eval_random_defense_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_eval_random_defense_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_eval_random_defense_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "episode_len_train_random_defense_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "train_random_defense_dfs_v2", ")", ")", "\n", "episode_len_train_random_defense_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_train_random_defense_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_train_random_defense_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_train_random_defense_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "episode_len_eval_random_defense_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "eval_random_defense_dfs_v2", ")", ")", "\n", "episode_len_eval_random_defense_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_eval_random_defense_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_eval_random_defense_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_eval_random_defense_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_two_agents_dfs_v2", "=", "[", "]", "\n", "eval_two_agents_dfs_v2", "=", "[", "]", "\n", "for", "csv_path", "in", "two_agents_train_csv_paths_v2", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_two_agents_dfs_v2", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "two_agents_eval_csv_paths_v2", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_two_agents_dfs_v2", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_train_two_agents_data_v2", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_two_agents_dfs_v2", ")", ")", "\n", "hack_prob_train_two_agents_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_two_agents_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_two_agents_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_two_agents_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_two_agents_data_v2", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_two_agents_dfs_v2", ")", ")", "\n", "hack_prob_eval_two_agents_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_two_agents_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_two_agents_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_two_agents_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "a_cum_reward_train_two_agents_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_two_agents_dfs_v2", ")", ")", "\n", "a_cum_reward_train_two_agents_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_train_two_agents_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_train_two_agents_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_train_two_agents_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "a_cum_reward_eval_two_agents_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "eval_two_agents_dfs_v2", ")", ")", "\n", "a_cum_reward_eval_two_agents_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_eval_two_agents_data", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_eval_two_agents_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_eval_two_agents_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_cum_reward_train_two_agents_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_two_agents_dfs_v2", ")", ")", "\n", "d_cum_reward_train_two_agents_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_train_two_agents_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_train_two_agents_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_train_two_agents_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "d_cum_reward_eval_two_agents_data_v2", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "eval_two_agents_dfs_v2", ")", ")", "\n", "d_cum_reward_eval_two_agents_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_eval_two_agents_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_eval_two_agents_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_eval_two_agents_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "episode_len_train_two_agents_data_v2", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "train_two_agents_dfs_v2", ")", ")", "\n", "episode_len_train_two_agents_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_train_two_agents_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_train_two_agents_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_train_two_agents_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "episode_len_eval_two_agents_data_v2", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "eval_two_agents_dfs_v2", ")", ")", "\n", "episode_len_eval_two_agents_means_v2", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_eval_two_agents_data_v2", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_eval_two_agents_stds_v2", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_eval_two_agents_data_v2", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "# V3", "\n", "train_max_attack_dfs_v3", "=", "[", "]", "\n", "eval_max_attack_dfs_v3", "=", "[", "]", "\n", "for", "csv_path", "in", "maximal_attack_train_csv_paths_v3", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_max_attack_dfs_v3", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "maximal_attack_eval_csv_paths_v3", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_max_attack_dfs_v3", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_train_max_attack_data_v3", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_max_attack_dfs_v3", ")", ")", "\n", "hack_prob_train_max_attack_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_max_attack_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_max_attack_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_max_attack_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_max_attack_data_v3", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_max_attack_dfs_v3", ")", ")", "\n", "hack_prob_eval_max_attack_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_max_attack_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_max_attack_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_max_attack_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "a_cum_reward_train_max_attack_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_max_attack_dfs_v3", ")", ")", "\n", "a_cum_reward_train_max_attack_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_train_max_attack_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_train_max_attack_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_train_max_attack_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "a_cum_reward_eval_max_attack_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "eval_max_attack_dfs_v3", ")", ")", "\n", "a_cum_reward_eval_max_attack_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_eval_max_attack_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_eval_max_attack_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_eval_max_attack_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_cum_reward_train_max_attack_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_max_attack_dfs_v3", ")", ")", "\n", "d_cum_reward_train_max_attack_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_train_max_attack_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_train_max_attack_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_train_max_attack_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "d_cum_reward_eval_max_attack_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "eval_max_attack_dfs_v3", ")", ")", "\n", "d_cum_reward_eval_max_attack_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_eval_max_attack_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_eval_max_attack_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_eval_max_attack_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "episode_len_train_max_attack_data_v3", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "train_max_attack_dfs_v3", ")", ")", "\n", "episode_len_train_max_attack_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_train_max_attack_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_train_max_attack_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_train_max_attack_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "episode_len_eval_max_attack_data_v3", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "eval_max_attack_dfs_v3", ")", ")", "\n", "episode_len_eval_max_attack_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_eval_max_attack_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_eval_max_attack_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_eval_max_attack_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_min_defense_dfs_v3", "=", "[", "]", "\n", "eval_min_defense_dfs_v3", "=", "[", "]", "\n", "for", "csv_path", "in", "minimal_defense_train_csv_paths_v3", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_min_defense_dfs_v3", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "minimal_defense_eval_csv_paths_v3", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_min_defense_dfs_v3", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_train_min_defense_data_v3", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_min_defense_dfs_v3", ")", ")", "\n", "hack_prob_train_min_defense_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_min_defense_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_min_defense_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_min_defense_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_min_defense_data_v3", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_min_defense_dfs_v3", ")", ")", "\n", "hack_prob_eval_min_defense_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_min_defense_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_min_defense_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_min_defense_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "a_cum_reward_train_min_defense_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_min_defense_dfs_v3", ")", ")", "\n", "a_cum_reward_train_min_defense_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_train_min_defense_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_train_min_defense_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_train_min_defense_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "a_cum_reward_eval_min_defense_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "eval_min_defense_dfs_v3", ")", ")", "\n", "a_cum_reward_eval_min_defense_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_eval_min_defense_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_eval_min_defense_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_eval_min_defense_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_cum_reward_train_min_defense_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_min_defense_dfs_v3", ")", ")", "\n", "d_cum_reward_train_min_defense_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_train_min_defense_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_train_min_defense_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_train_min_defense_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "d_cum_reward_eval_min_defense_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "eval_min_defense_dfs_v3", ")", ")", "\n", "d_cum_reward_eval_min_defense_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_eval_min_defense_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_eval_min_defense_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_eval_min_defense_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "episode_len_train_min_defense_data_v3", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "train_min_defense_dfs_v3", ")", ")", "\n", "episode_len_train_min_defense_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_train_min_defense_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_train_min_defense_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_train_min_defense_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "episode_len_eval_min_defense_data_v3", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "eval_min_defense_dfs_v3", ")", ")", "\n", "episode_len_eval_min_defense_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_eval_min_defense_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_eval_min_defense_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_eval_min_defense_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_attack_dfs_v3", "=", "[", "]", "\n", "eval_random_attack_dfs_v3", "=", "[", "]", "\n", "for", "csv_path", "in", "random_attack_train_csv_paths_v3", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_attack_dfs_v3", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_attack_eval_csv_paths_v3", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_attack_dfs_v3", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_train_random_attack_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_random_attack_dfs_v3", ")", ")", "\n", "hack_prob_train_random_attack_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_random_attack_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_random_attack_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_random_attack_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_random_attack_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_random_attack_dfs_v3", ")", ")", "\n", "hack_prob_eval_random_attack_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_random_attack_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_random_attack_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_random_attack_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "a_cum_reward_train_random_attack_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_random_attack_dfs_v3", ")", ")", "\n", "a_cum_reward_train_random_attack_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_train_random_attack_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_train_random_attack_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_train_random_attack_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "a_cum_reward_eval_random_attack_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "eval_random_attack_dfs_v3", ")", ")", "\n", "a_cum_reward_eval_random_attack_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_eval_random_attack_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_eval_random_attack_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_eval_random_attack_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_cum_reward_train_random_attack_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_random_attack_dfs_v3", ")", ")", "\n", "d_cum_reward_train_random_attack_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_train_random_attack_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_train_random_attack_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_train_random_attack_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "d_cum_reward_eval_random_attack_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "eval_random_attack_dfs_v3", ")", ")", "\n", "d_cum_reward_eval_random_attack_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_eval_random_attack_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_eval_random_attack_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_eval_random_attack_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "episode_len_train_random_attack_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "train_random_attack_dfs_v3", ")", ")", "\n", "episode_len_train_random_attack_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_train_random_attack_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_train_random_attack_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_train_random_attack_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "episode_len_eval_random_attack_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "eval_random_attack_dfs_v3", ")", ")", "\n", "episode_len_eval_random_attack_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_eval_random_attack_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_eval_random_attack_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_eval_random_attack_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_random_defense_dfs_v3", "=", "[", "]", "\n", "eval_random_defense_dfs_v3", "=", "[", "]", "\n", "for", "csv_path", "in", "random_defense_train_csv_paths_v3", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_defense_dfs_v3", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_defense_eval_csv_paths_v3", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_defense_dfs_v3", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_train_random_defense_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_random_defense_dfs_v3", ")", ")", "\n", "hack_prob_train_random_defense_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_random_defense_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_random_defense_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_random_defense_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_random_defense_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_random_defense_dfs_v3", ")", ")", "\n", "hack_prob_eval_random_defense_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_random_defense_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_random_defense_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_random_defense_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "a_cum_reward_train_random_defense_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_random_defense_dfs_v3", ")", ")", "\n", "a_cum_reward_train_random_defense_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_train_random_defense_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_train_random_defense_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_train_random_defense_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "a_cum_reward_eval_random_defense_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "eval_random_defense_dfs_v3", ")", ")", "\n", "a_cum_reward_eval_random_defense_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_eval_random_defense_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_eval_random_defense_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_eval_random_defense_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_cum_reward_train_random_defense_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_random_defense_dfs_v3", ")", ")", "\n", "d_cum_reward_train_random_defense_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_train_random_defense_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_train_random_defense_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_train_random_defense_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "d_cum_reward_eval_random_defense_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "eval_random_defense_dfs_v3", ")", ")", "\n", "d_cum_reward_eval_random_defense_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_eval_random_defense_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_eval_random_defense_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_eval_random_defense_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "episode_len_train_random_defense_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "train_random_defense_dfs_v3", ")", ")", "\n", "episode_len_train_random_defense_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_train_random_defense_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_train_random_defense_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_train_random_defense_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "episode_len_eval_random_defense_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "eval_random_defense_dfs_v3", ")", ")", "\n", "episode_len_eval_random_defense_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_eval_random_defense_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_eval_random_defense_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_eval_random_defense_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "train_two_agents_dfs_v3", "=", "[", "]", "\n", "eval_two_agents_dfs_v3", "=", "[", "]", "\n", "for", "csv_path", "in", "two_agents_train_csv_paths_v3", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_two_agents_dfs_v3", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "two_agents_eval_csv_paths_v3", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_two_agents_dfs_v3", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_train_two_agents_data_v3", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_two_agents_dfs_v3", ")", ")", "\n", "hack_prob_train_two_agents_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_two_agents_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_two_agents_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_two_agents_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_two_agents_data_v3", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_two_agents_dfs_v3", ")", ")", "\n", "hack_prob_eval_two_agents_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_two_agents_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_two_agents_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_two_agents_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "a_cum_reward_train_two_agents_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_two_agents_dfs_v3", ")", ")", "\n", "a_cum_reward_train_two_agents_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_train_two_agents_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_train_two_agents_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_train_two_agents_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "a_cum_reward_eval_two_agents_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "eval_two_agents_dfs_v3", ")", ")", "\n", "a_cum_reward_eval_two_agents_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_eval_two_agents_data", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_eval_two_agents_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_eval_two_agents_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_cum_reward_train_two_agents_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_two_agents_dfs_v3", ")", ")", "\n", "d_cum_reward_train_two_agents_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_train_two_agents_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_train_two_agents_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_train_two_agents_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "d_cum_reward_eval_two_agents_data_v3", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "eval_two_agents_dfs_v3", ")", ")", "\n", "d_cum_reward_eval_two_agents_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_eval_two_agents_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_eval_two_agents_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_eval_two_agents_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "episode_len_train_two_agents_data_v3", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "train_two_agents_dfs_v3", ")", ")", "\n", "episode_len_train_two_agents_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_train_two_agents_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_train_two_agents_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_train_two_agents_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "episode_len_eval_two_agents_data_v3", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "eval_two_agents_dfs_v3", ")", ")", "\n", "episode_len_eval_two_agents_means_v3", "=", "np", ".", "mean", "(", "tuple", "(", "episode_len_eval_two_agents_data_v3", ")", ",", "axis", "=", "0", ")", "\n", "episode_len_eval_two_agents_stds_v3", "=", "np", ".", "std", "(", "tuple", "(", "episode_len_eval_two_agents_data_v3", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "algorithm_label", "=", "\"TabularQLearning\"", "\n", "if", "algorithm", "==", "\"dqn\"", ":", "\n", "        ", "algorithm_label", "=", "\"DQN\"", "\n", "\n", "", "plot_all_avg_summary_3", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_min_defense_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_min_defense_means_v0", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_random_defense_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_defense_means_v0", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_max_attack_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_max_attack_means_v0", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_random_attack_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_attack_means_v0", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_two_agents_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_two_agents_means_v0", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "hack_prob_train_min_defense_stds_v0", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_defense_stds_v0", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "hack_prob_train_max_attack_stds_v0", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_attack_stds_v0", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "hack_prob_train_two_agents_stds_v0", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{MinDefense}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{RandomDefense}\"", ",", "\n", "r\"\\textsc{MaxAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{RandomAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"Hack probability (train, v\"", "+", "str", "(", "versions", "[", "0", "]", ")", "+", "\")\"", ",", "\n", "r\"Episode \\#\"", ",", "r\"$\\mathbb{P}[Hacked]$\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_min_defense_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_min_defense_means_v0", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_defense_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_defense_means_v0", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_max_attack_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_max_attack_means_v0", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_attack_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_attack_means_v0", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_two_agents_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_two_agents_means_v0", ",", "hack_prob_eval_min_defense_stds_v0", ",", "\n", "hack_prob_eval_random_defense_stds_v0", ",", "hack_prob_eval_max_attack_stds_v0", ",", "\n", "hack_prob_eval_random_attack_stds_v0", ",", "hack_prob_eval_two_agents_stds_v0", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{MinDefense}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{RandomDefense}\"", ",", "\n", "r\"\\textsc{MaxAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{RandomAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"Hack probability (eval v\"", "+", "str", "(", "versions", "[", "0", "]", ")", "+", "\")\"", ",", "\n", "r\"Episode \\#\"", ",", "r\"$\\mathbb{P}[Hacked]$\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_min_defense_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_min_defense_means_v0", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_random_defense_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_defense_means_v0", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_max_attack_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_max_attack_means_v0", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_random_attack_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_attack_means_v0", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_two_agents_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_two_agents_means_v0", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "a_cum_reward_train_min_defense_stds_v0", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_defense_stds_v0", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "a_cum_reward_train_max_attack_stds_v0", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_attack_stds_v0", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "a_cum_reward_train_two_agents_stds_v0", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{MinDefense}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{RandomDefense}\"", ",", "\n", "r\"\\textsc{MaxAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{RandomAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"Attacker reward (train v\"", "+", "str", "(", "versions", "[", "0", "]", ")", "+", "\")\"", ",", "\n", "r\"Episode \\#\"", ",", "r\"Cumulative Reward\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_min_defense_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_min_defense_means_v2", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_random_defense_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_defense_means_v2", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_max_attack_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_max_attack_means_v2", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_random_attack_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_attack_means_v2", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_two_agents_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_two_agents_means_v2", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "hack_prob_train_min_defense_stds_v2", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_defense_stds_v2", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "hack_prob_train_max_attack_stds_v2", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_attack_stds_v2", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "hack_prob_train_two_agents_stds_v2", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{MinDefense}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{RandomDefense}\"", ",", "\n", "r\"\\textsc{MaxAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{RandomAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"Hack probability (train, v\"", "+", "str", "(", "versions", "[", "1", "]", ")", "+", "\")\"", ",", "\n", "r\"Episode \\#\"", ",", "r\"$\\mathbb{P}[Hacked]$\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_min_defense_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_min_defense_means_v2", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_defense_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_defense_means_v2", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_max_attack_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_max_attack_means_v2", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_attack_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_attack_means_v2", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_two_agents_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_two_agents_means_v2", ",", "hack_prob_eval_min_defense_stds_v2", ",", "\n", "hack_prob_eval_random_defense_stds_v2", ",", "hack_prob_eval_max_attack_stds_v2", ",", "\n", "hack_prob_eval_random_attack_stds_v2", ",", "hack_prob_eval_two_agents_stds_v2", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{MinDefense}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{RandomDefense}\"", ",", "\n", "r\"\\textsc{MaxAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{RandomAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"Hack probability (eval v\"", "+", "str", "(", "versions", "[", "1", "]", ")", "+", "\")\"", ",", "\n", "r\"Episode \\#\"", ",", "r\"$\\mathbb{P}[Hacked]$\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_min_defense_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_min_defense_means_v2", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_random_defense_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_defense_means_v2", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_max_attack_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_max_attack_means_v2", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_random_attack_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_attack_means_v2", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_two_agents_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_two_agents_means_v2", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "a_cum_reward_train_min_defense_stds_v2", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_defense_stds_v2", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "a_cum_reward_train_max_attack_stds_v2", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_attack_stds_v2", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "a_cum_reward_train_two_agents_stds_v2", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{MinDefense}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{RandomDefense}\"", ",", "\n", "r\"\\textsc{MaxAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{RandomAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"Attacker reward (train v\"", "+", "str", "(", "versions", "[", "1", "]", ")", "+", "\")\"", ",", "\n", "r\"Episode \\#\"", ",", "r\"Cumulative Reward\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_min_defense_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_min_defense_means_v3", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_random_defense_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_defense_means_v3", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_max_attack_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_max_attack_means_v3", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_random_attack_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_attack_means_v3", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_two_agents_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_two_agents_means_v3", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "hack_prob_train_min_defense_stds_v3", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_defense_stds_v3", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "hack_prob_train_max_attack_stds_v3", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_attack_stds_v3", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "hack_prob_train_two_agents_stds_v3", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{MinDefense}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{RandomDefense}\"", ",", "\n", "r\"\\textsc{MaxAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{RandomAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"Hack probability (train, v\"", "+", "str", "(", "versions", "[", "2", "]", ")", "+", "\")\"", ",", "\n", "r\"Episode \\#\"", ",", "r\"$\\mathbb{P}[Hacked]$\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_min_defense_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_min_defense_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_defense_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_defense_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_max_attack_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_max_attack_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_attack_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_attack_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_two_agents_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_two_agents_means_v3", ",", "hack_prob_eval_min_defense_stds_v3", ",", "\n", "hack_prob_eval_random_defense_stds_v3", ",", "hack_prob_eval_max_attack_stds_v3", ",", "\n", "hack_prob_eval_random_attack_stds_v3", ",", "hack_prob_eval_two_agents_stds_v3", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{MinDefense}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{RandomDefense}\"", ",", "\n", "r\"\\textsc{MaxAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{RandomAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"Hack probability (eval v\"", "+", "str", "(", "versions", "[", "2", "]", ")", "+", "\")\"", ",", "\n", "r\"Episode \\#\"", ",", "r\"$\\mathbb{P}[Hacked]$\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_min_defense_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_min_defense_means_v3", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_random_defense_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_defense_means_v3", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_max_attack_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_max_attack_means_v3", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_random_attack_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_attack_means_v3", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_two_agents_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_two_agents_means_v3", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "a_cum_reward_train_min_defense_stds_v3", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_defense_stds_v3", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "a_cum_reward_train_max_attack_stds_v3", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_attack_stds_v3", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "a_cum_reward_train_two_agents_stds_v3", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{MinDefense}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{RandomDefense}\"", ",", "\n", "r\"\\textsc{MaxAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{RandomAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"Attacker reward (train v\"", "+", "str", "(", "versions", "[", "2", "]", ")", "+", "\")\"", ",", "\n", "r\"Episode \\#\"", ",", "r\"Cumulative Reward\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "\n", "output_dir", "+", "\"/\"", "+", "file_name", "+", "algorithm", "+", "\"_\"", "+", "str", "(", "0", ")", ",", "algorithm", ",", "\n", "wspace", "=", "wspace", "\n", ")", "\n", "five_line_plot_w_shades", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_max_attack_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_max_attack_means_v0", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_min_defense_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_min_defense_means_v0", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_random_attack_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_random_attack_means_v0", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_random_defense_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_random_defense_means_v0", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_two_agents_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_two_agents_means_v0", ",", "stds_1", "=", "episode_len_eval_max_attack_stds_v0", ",", "\n", "stds_2", "=", "episode_len_eval_min_defense_stds_v0", ",", "stds_3", "=", "episode_len_eval_random_attack_stds_v0", ",", "\n", "stds_4", "=", "episode_len_eval_random_defense_stds_v0", ",", "stds_5", "=", "episode_len_eval_two_agents_stds_v0", ",", "\n", "title", "=", "r\"Avg Episode Lengths [Eval] (v\"", "+", "str", "(", "versions", "[", "0", "]", ")", "+", "\")\"", ",", "\n", "xlabel", "=", "r\"Episode \\#\"", ",", "ylabel", "=", "r\"Avg Length (num steps)\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/avg_episode_length_eval_\"", "+", "algorithm", "+", "\"_\"", "+", "str", "(", "0", ")", ",", "\n", "line1_label", "=", "r\"\\textsc{MaxAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "line2_label", "=", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{MinDefense}\"", ",", "\n", "line3_label", "=", "r\"\\textsc{RandomAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "line4_label", "=", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{RandomDefense}\"", ",", "\n", "line5_label", "=", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "legend_loc", "=", "\"lower right\"", ",", "markevery_1", "=", "1", ",", "markevery_2", "=", "1", ",", "markevery_3", "=", "1", ",", "\n", "markevery_4", "=", "1", ",", "markevery_5", "=", "1", ")", "\n", "\n", "five_line_plot_w_shades", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_max_attack_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_max_attack_means_v2", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_min_defense_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_min_defense_means_v2", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_random_attack_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_random_attack_means_v2", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_random_defense_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_random_defense_means_v2", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_two_agents_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_two_agents_means_v2", ",", "stds_1", "=", "episode_len_eval_max_attack_stds_v2", ",", "\n", "stds_2", "=", "episode_len_eval_min_defense_stds_v2", ",", "stds_3", "=", "episode_len_eval_random_attack_stds_v2", ",", "\n", "stds_4", "=", "episode_len_eval_random_defense_stds_v2", ",", "stds_5", "=", "episode_len_eval_two_agents_stds_v2", ",", "\n", "title", "=", "r\"Avg Episode Lengths [Eval] (v\"", "+", "str", "(", "versions", "[", "1", "]", ")", "+", "\")\"", ",", "\n", "xlabel", "=", "r\"Episode \\#\"", ",", "ylabel", "=", "r\"Avg Length (num steps)\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/avg_episode_length_eval_\"", "+", "algorithm", "+", "\"_\"", "+", "str", "(", "1", ")", ",", "\n", "line1_label", "=", "r\"\\textsc{MaxAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "line2_label", "=", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{MinDefense}\"", ",", "\n", "line3_label", "=", "r\"\\textsc{RandomAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "line4_label", "=", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{RandomDefense}\"", ",", "\n", "line5_label", "=", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "legend_loc", "=", "\"lower right\"", ",", "\n", "markevery_1", "=", "1", ",", "markevery_2", "=", "1", ",", "markevery_3", "=", "1", ",", "\n", "markevery_4", "=", "1", ",", "markevery_5", "=", "1", ")", "\n", "\n", "five_line_plot_w_shades", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_max_attack_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_max_attack_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_min_defense_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_min_defense_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_random_attack_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_random_attack_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_random_defense_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_random_defense_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_two_agents_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_two_agents_means_v3", ",", "stds_1", "=", "episode_len_eval_max_attack_stds_v3", ",", "\n", "stds_2", "=", "episode_len_eval_min_defense_stds_v3", ",", "stds_3", "=", "episode_len_eval_random_attack_stds_v3", ",", "\n", "stds_4", "=", "episode_len_eval_random_defense_stds_v3", ",", "stds_5", "=", "episode_len_eval_two_agents_stds_v3", ",", "\n", "title", "=", "r\"Avg Episode Lengths [Eval] (v\"", "+", "str", "(", "versions", "[", "2", "]", ")", "+", "\")\"", ",", "\n", "xlabel", "=", "r\"Episode \\#\"", ",", "ylabel", "=", "r\"Avg Length (num steps)\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/avg_episode_length_eval_\"", "+", "algorithm", "+", "\"_\"", "+", "str", "(", "2", ")", ",", "\n", "line1_label", "=", "r\"\\textsc{MaxAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "line2_label", "=", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{MinDefense}\"", ",", "\n", "line3_label", "=", "r\"\\textsc{RandomAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "line4_label", "=", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{RandomDefense}\"", ",", "\n", "line5_label", "=", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "legend_loc", "=", "\"lower right\"", ",", "\n", "markevery_1", "=", "1", ",", "markevery_2", "=", "1", ",", "markevery_3", "=", "1", ",", "\n", "markevery_4", "=", "1", ",", "markevery_5", "=", "1", ")", "\n", "\n", "plot_all_avg_summary_2", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_min_defense_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_min_defense_means_v0", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_random_defense_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_random_defense_means_v0", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_max_attack_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_max_attack_means_v0", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_random_attack_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_random_attack_means_v0", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_two_agents_data_v0", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_two_agents_means_v0", ",", "episode_len_eval_min_defense_stds_v0", ",", "\n", "episode_len_eval_random_defense_stds_v0", ",", "episode_len_eval_max_attack_stds_v0", ",", "\n", "episode_len_eval_random_attack_stds_v0", ",", "episode_len_eval_two_agents_stds_v0", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{MinDefense}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{RandomDefense}\"", ",", "\n", "r\"\\textsc{MaxAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{RandomAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"Avg Episode Lengths [Eval] (v\"", "+", "str", "(", "versions", "[", "0", "]", ")", "+", "\")\"", ",", "\n", "r\"Episode \\#\"", ",", "r\"Avg Length (num steps)\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_min_defense_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_min_defense_means_v2", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_random_defense_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_random_defense_means_v2", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_max_attack_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_max_attack_means_v2", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_random_attack_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_random_attack_means_v2", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_two_agents_data_v2", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_two_agents_means_v2", ",", "episode_len_eval_min_defense_stds_v2", ",", "\n", "episode_len_eval_random_defense_stds_v2", ",", "episode_len_eval_max_attack_stds_v2", ",", "\n", "episode_len_eval_random_attack_stds_v2", ",", "episode_len_eval_two_agents_stds_v2", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{MinDefense}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{RandomDefense}\"", ",", "\n", "r\"\\textsc{MaxAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{RandomAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"Avg Episode Lengths [Eval] (v\"", "+", "str", "(", "versions", "[", "1", "]", ")", "+", "\")\"", ",", "\n", "r\"Episode \\#\"", ",", "r\"Avg Length (num steps)\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_min_defense_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_min_defense_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_random_defense_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_random_defense_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_max_attack_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_max_attack_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_random_attack_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_random_attack_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_two_agents_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_two_agents_means_v3", ",", "episode_len_eval_min_defense_stds_v3", ",", "\n", "episode_len_eval_random_defense_stds_v3", ",", "episode_len_eval_max_attack_stds_v3", ",", "\n", "episode_len_eval_random_attack_stds_v3", ",", "episode_len_eval_two_agents_stds_v3", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{MinDefense}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{RandomDefense}\"", ",", "\n", "r\"\\textsc{MaxAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{RandomAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"Avg Episode Lengths [Eval] (v\"", "+", "str", "(", "versions", "[", "2", "]", ")", "+", "\")\"", ",", "\n", "r\"Episode \\#\"", ",", "r\"Avg Length (num steps)\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_min_defense_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_min_defense_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_random_defense_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_random_defense_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_max_attack_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_max_attack_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_random_attack_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_random_attack_means_v3", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "episode_len_eval_two_agents_data_v3", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "episode_len_eval_two_agents_means_v3", ",", "episode_len_eval_min_defense_stds_v3", ",", "\n", "episode_len_eval_random_defense_stds_v3", ",", "episode_len_eval_max_attack_stds_v3", ",", "\n", "episode_len_eval_random_attack_stds_v3", ",", "episode_len_eval_two_agents_stds_v3", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{MinDefense}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{RandomDefense}\"", ",", "\n", "r\"\\textsc{MaxAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{RandomAttack} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"\\textsc{\"", "+", "algorithm_label", "+", "r\"} vs \\textsc{\"", "+", "algorithm_label", "+", "r\"}\"", ",", "\n", "r\"Avg Episode Lengths [Eval] (v\"", "+", "str", "(", "versions", "[", "2", "]", ")", "+", "\")\"", ",", "\n", "r\"Episode \\#\"", ",", "r\"Avg Length (num steps)\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "output_dir", "+", "\"/\"", "+", "file_name", "+", "\"_avg_length_\"", "+", "algorithm", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_averages": [[5007, 5630], ["list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "plotting_util.five_line_plot_w_shades", "plotting_util.five_line_plot_w_shades", "plotting_util.five_line_plot_w_shades", "plotting_util.five_line_plot_w_shades", "plotting_util.read_data", "train_max_attack_dfs.append", "plotting_util.read_data", "eval_max_attack_dfs.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "list", "numpy.mean", "numpy.std", "plotting_util.read_data", "train_min_defense_dfs.append", "plotting_util.read_data", "eval_min_defense_dfs.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "list", "numpy.mean", "numpy.std", "plotting_util.read_data", "train_random_attack_dfs.append", "plotting_util.read_data", "eval_random_attack_dfs.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "list", "numpy.mean", "numpy.std", "plotting_util.read_data", "train_random_defense_dfs.append", "plotting_util.read_data", "eval_random_defense_dfs.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "list", "numpy.mean", "numpy.std", "plotting_util.read_data", "train_two_agents_dfs.append", "plotting_util.read_data", "eval_two_agents_dfs.append", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "plotting_util.three_line_plot_w_shades", "plotting_util.three_line_plot_w_shades", "plotting_util.plot_all_avg_summary_1", "open", "csv.writer", "csv.writer.writerow", "np.mean.tolist", "open", "csv.writer", "csv.writer.writerow", "np.std.tolist", "open", "csv.writer", "csv.writer.writerow", "np.mean.tolist", "open", "csv.writer", "csv.writer.writerow", "np.std.tolist", "open", "csv.writer", "csv.writer.writerow", "np.mean.tolist", "open", "csv.writer", "csv.writer.writerow", "np.std.tolist", "open", "csv.writer", "csv.writer.writerow", "np.mean.tolist", "open", "csv.writer", "csv.writer.writerow", "np.std.tolist", "open", "csv.writer", "csv.writer.writerow", "np.mean.tolist", "open", "csv.writer", "csv.writer.writerow", "np.std.tolist", "open", "csv.writer", "csv.writer.writerow", "np.mean.tolist", "open", "csv.writer", "csv.writer.writerow", "np.std.tolist", "open", "csv.writer", "csv.writer.writerow", "np.mean.tolist", "open", "csv.writer", "csv.writer.writerow", "np.std.tolist", "open", "csv.writer", "csv.writer.writerow", "np.mean.tolist", "open", "csv.writer", "csv.writer.writerow", "np.std.tolist", "open", "csv.writer", "csv.writer.writerow", "np.mean.tolist", "open", "csv.writer", "csv.writer.writerow", "np.std.tolist", "open", "csv.writer", "csv.writer.writerow", "np.mean.tolist", "open", "csv.writer", "csv.writer.writerow", "np.std.tolist", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "plotting_util.plot_all_avg_summary_1", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "str", "list", "list", "list", "list", "list", "str", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "str", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "str", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "str", "numpy.array", "numpy.array", "numpy.array", "str", "numpy.array", "numpy.array", "numpy.array", "str", "list", "list", "list", "list", "list", "str", "range", "range", "range", "range", "range", "str", "list", "list", "list", "list", "list", "str", "list", "list", "list", "list", "list", "str", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "str", "list", "list", "list", "list", "list", "str", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "str", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "str", "list", "list", "list", "list", "list", "list", "range", "range", "range", "range", "range", "len", "len", "len", "len", "len", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "list", "list", "list", "list", "list", "range", "range", "range", "range", "range", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "str", "list", "list", "list", "list", "list", "str", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "str", "numpy.array", "numpy.array", "numpy.array", "str", "numpy.array", "numpy.array", "numpy.array", "str", "range", "range", "range", "range", "range", "range", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "range", "range", "range", "range", "range", "len", "len", "len", "len", "len", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "list", "list", "list", "list", "list", "range", "range", "range", "range", "range", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "list", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "range", "range", "range", "range", "range", "len", "len", "len", "len", "len", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "range", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.five_line_plot_w_shades", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.five_line_plot_w_shades", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.five_line_plot_w_shades", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.five_line_plot_w_shades", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.three_line_plot_w_shades", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.three_line_plot_w_shades", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_avg_summary_1", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all_avg_summary_1"], ["", "def", "plot_all_averages", "(", "maximal_attack_train_csv_paths", ",", "maximal_attack_eval_csv_paths", ",", "\n", "minimal_defense_train_csv_paths", ",", "minimal_defense_eval_csv_paths", ",", "\n", "random_attack_train_csv_paths", ",", "random_attack_eval_csv_paths", ",", "\n", "random_defense_train_csv_paths", ",", "random_defense_eval_csv_paths", ",", "\n", "two_agents_train_csv_paths", ",", "two_agents_eval_csv_paths", ",", "\n", "version", ",", "algorithm", ",", "output_dir", ",", "eval_freq", ":", "int", ",", "train_log_freq", ":", "int", ",", "\n", "plot_loss", "=", "False", ")", ":", "\n", "    ", "train_max_attack_dfs", "=", "[", "]", "\n", "eval_max_attack_dfs", "=", "[", "]", "\n", "for", "csv_path", "in", "maximal_attack_train_csv_paths", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_max_attack_dfs", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "maximal_attack_eval_csv_paths", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_max_attack_dfs", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_train_max_attack_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_max_attack_dfs", ")", ")", "\n", "hack_prob_train_max_attack_means", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_max_attack_data", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_max_attack_stds", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_max_attack_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_max_attack_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_max_attack_dfs", ")", ")", "\n", "hack_prob_eval_max_attack_means", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_max_attack_data", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_max_attack_stds", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_max_attack_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "a_cum_reward_train_max_attack_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_max_attack_dfs", ")", ")", "\n", "a_cum_reward_train_max_attack_means", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_train_max_attack_data", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_train_max_attack_stds", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_train_max_attack_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "a_cum_reward_eval_max_attack_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "eval_max_attack_dfs", ")", ")", "\n", "a_cum_reward_eval_max_attack_means", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_eval_max_attack_data", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_eval_max_attack_stds", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_eval_max_attack_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_cum_reward_train_max_attack_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_max_attack_dfs", ")", ")", "\n", "d_cum_reward_train_max_attack_means", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_train_max_attack_data", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_train_max_attack_stds", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_train_max_attack_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "d_cum_reward_eval_max_attack_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "eval_max_attack_dfs", ")", ")", "\n", "d_cum_reward_eval_max_attack_means", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_eval_max_attack_data", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_eval_max_attack_stds", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_eval_max_attack_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "if", "plot_loss", ":", "\n", "        ", "defender_loss_train_max_attack_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_defender\"", "]", ".", "values", ",", "train_max_attack_dfs", ")", ")", "\n", "defender_loss_train_max_attack_means", "=", "np", ".", "mean", "(", "tuple", "(", "defender_loss_train_max_attack_data", ")", ",", "axis", "=", "0", ")", "\n", "defender_loss_train_max_attack_stds", "=", "np", ".", "std", "(", "tuple", "(", "defender_loss_train_max_attack_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "", "train_min_defense_dfs", "=", "[", "]", "\n", "eval_min_defense_dfs", "=", "[", "]", "\n", "for", "csv_path", "in", "minimal_defense_train_csv_paths", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_min_defense_dfs", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "minimal_defense_eval_csv_paths", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_min_defense_dfs", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_train_min_defense_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_min_defense_dfs", ")", ")", "\n", "hack_prob_train_min_defense_means", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_min_defense_data", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_min_defense_stds", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_min_defense_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_min_defense_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_min_defense_dfs", ")", ")", "\n", "hack_prob_eval_min_defense_means", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_min_defense_data", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_min_defense_stds", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_min_defense_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "a_cum_reward_train_min_defense_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_min_defense_dfs", ")", ")", "\n", "a_cum_reward_train_min_defense_means", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_train_min_defense_data", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_train_min_defense_stds", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_train_min_defense_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "a_cum_reward_eval_min_defense_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "eval_min_defense_dfs", ")", ")", "\n", "a_cum_reward_eval_min_defense_means", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_eval_min_defense_data", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_eval_min_defense_stds", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_eval_min_defense_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_cum_reward_train_min_defense_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_min_defense_dfs", ")", ")", "\n", "d_cum_reward_train_min_defense_means", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_train_min_defense_data", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_train_min_defense_stds", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_train_min_defense_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "d_cum_reward_eval_min_defense_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "eval_min_defense_dfs", ")", ")", "\n", "d_cum_reward_eval_min_defense_means", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_eval_min_defense_data", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_eval_min_defense_stds", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_eval_min_defense_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "if", "plot_loss", ":", "\n", "        ", "attacker_loss_train_min_defense_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "train_min_defense_dfs", ")", ")", "\n", "attacker_loss_train_min_defense_means", "=", "np", ".", "mean", "(", "tuple", "(", "attacker_loss_train_min_defense_data", ")", ",", "axis", "=", "0", ")", "\n", "attacker_loss_train_min_defense_stds", "=", "np", ".", "std", "(", "tuple", "(", "attacker_loss_train_min_defense_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "", "train_random_attack_dfs", "=", "[", "]", "\n", "eval_random_attack_dfs", "=", "[", "]", "\n", "for", "csv_path", "in", "random_attack_train_csv_paths", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_attack_dfs", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_attack_eval_csv_paths", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_attack_dfs", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_train_random_attack_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_random_attack_dfs", ")", ")", "\n", "hack_prob_train_random_attack_means", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_random_attack_data", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_random_attack_stds", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_random_attack_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_random_attack_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_random_attack_dfs", ")", ")", "\n", "hack_prob_eval_random_attack_means", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_random_attack_data", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_random_attack_stds", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_random_attack_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "a_cum_reward_train_random_attack_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_random_attack_dfs", ")", ")", "\n", "a_cum_reward_train_random_attack_means", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_train_random_attack_data", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_train_random_attack_stds", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_train_random_attack_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "a_cum_reward_eval_random_attack_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "eval_random_attack_dfs", ")", ")", "\n", "a_cum_reward_eval_random_attack_means", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_eval_random_attack_data", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_eval_random_attack_stds", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_eval_random_attack_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_cum_reward_train_random_attack_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_random_attack_dfs", ")", ")", "\n", "d_cum_reward_train_random_attack_means", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_train_random_attack_data", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_train_random_attack_stds", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_train_random_attack_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "d_cum_reward_eval_random_attack_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "eval_random_attack_dfs", ")", ")", "\n", "d_cum_reward_eval_random_attack_means", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_eval_random_attack_data", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_eval_random_attack_stds", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_eval_random_attack_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "if", "plot_loss", ":", "\n", "        ", "defender_loss_train_random_attack_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_defender\"", "]", ".", "values", ",", "train_random_attack_dfs", ")", ")", "\n", "defender_loss_train_random_attack_means", "=", "np", ".", "mean", "(", "tuple", "(", "defender_loss_train_random_attack_data", ")", ",", "axis", "=", "0", ")", "\n", "defender_loss_train_random_attack_stds", "=", "np", ".", "std", "(", "tuple", "(", "defender_loss_train_random_attack_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "", "train_random_defense_dfs", "=", "[", "]", "\n", "eval_random_defense_dfs", "=", "[", "]", "\n", "for", "csv_path", "in", "random_defense_train_csv_paths", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_random_defense_dfs", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "random_defense_eval_csv_paths", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_random_defense_dfs", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_train_random_defense_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_random_defense_dfs", ")", ")", "\n", "hack_prob_train_random_defense_means", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_random_defense_data", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_random_defense_stds", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_random_defense_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_random_defense_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_random_defense_dfs", ")", ")", "\n", "hack_prob_eval_random_defense_means", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_random_defense_data", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_random_defense_stds", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_random_defense_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "a_cum_reward_train_random_defense_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_random_defense_dfs", ")", ")", "\n", "a_cum_reward_train_random_defense_means", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_train_random_defense_data", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_train_random_defense_stds", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_train_random_defense_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "a_cum_reward_eval_random_defense_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "eval_random_defense_dfs", ")", ")", "\n", "a_cum_reward_eval_random_defense_means", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_eval_random_defense_data", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_eval_random_defense_stds", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_eval_random_defense_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_cum_reward_train_random_defense_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_random_defense_dfs", ")", ")", "\n", "d_cum_reward_train_random_defense_means", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_train_random_defense_data", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_train_random_defense_stds", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_train_random_defense_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "d_cum_reward_eval_random_defense_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "eval_random_defense_dfs", ")", ")", "\n", "d_cum_reward_eval_random_defense_means", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_eval_random_defense_data", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_eval_random_defense_stds", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_eval_random_defense_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "if", "plot_loss", ":", "\n", "        ", "attacker_loss_train_random_defense_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "train_random_defense_dfs", ")", ")", "\n", "attacker_loss_train_random_defense_means", "=", "np", ".", "mean", "(", "tuple", "(", "attacker_loss_train_random_defense_data", ")", ",", "axis", "=", "0", ")", "\n", "attacker_loss_train_random_defense_stds", "=", "np", ".", "std", "(", "tuple", "(", "attacker_loss_train_random_defense_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "", "train_two_agents_dfs", "=", "[", "]", "\n", "eval_two_agents_dfs", "=", "[", "]", "\n", "for", "csv_path", "in", "two_agents_train_csv_paths", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "train_two_agents_dfs", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "csv_path", "in", "two_agents_eval_csv_paths", ":", "\n", "        ", "df", "=", "read_data", "(", "csv_path", ")", "\n", "eval_two_agents_dfs", ".", "append", "(", "df", ")", "\n", "\n", "", "hack_prob_train_two_agents_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_two_agents_dfs", ")", ")", "\n", "hack_prob_train_two_agents_means", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_two_agents_data", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_two_agents_stds", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_two_agents_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_two_agents_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_two_agents_dfs", ")", ")", "\n", "hack_prob_eval_two_agents_means", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_two_agents_data", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_two_agents_stds", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_two_agents_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "a_cum_reward_train_two_agents_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_two_agents_dfs", ")", ")", "\n", "a_cum_reward_train_two_agents_means", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_train_two_agents_data", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_train_two_agents_stds", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_train_two_agents_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "a_cum_reward_eval_two_agents_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "eval_two_agents_dfs", ")", ")", "\n", "a_cum_reward_eval_two_agents_means", "=", "np", ".", "mean", "(", "tuple", "(", "a_cum_reward_eval_two_agents_data", ")", ",", "axis", "=", "0", ")", "\n", "a_cum_reward_eval_two_agents_stds", "=", "np", ".", "std", "(", "tuple", "(", "a_cum_reward_eval_two_agents_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "d_cum_reward_train_two_agents_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_two_agents_dfs", ")", ")", "\n", "d_cum_reward_train_two_agents_means", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_train_two_agents_data", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_train_two_agents_stds", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_train_two_agents_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "d_cum_reward_eval_two_agents_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "eval_two_agents_dfs", ")", ")", "\n", "d_cum_reward_eval_two_agents_means", "=", "np", ".", "mean", "(", "tuple", "(", "d_cum_reward_eval_two_agents_data", ")", ",", "axis", "=", "0", ")", "\n", "d_cum_reward_eval_two_agents_stds", "=", "np", ".", "std", "(", "tuple", "(", "d_cum_reward_eval_two_agents_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "if", "plot_loss", ":", "\n", "        ", "attacker_loss_train_two_agents_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "train_two_agents_dfs", ")", ")", "\n", "attacker_loss_train_two_agents_means", "=", "np", ".", "mean", "(", "tuple", "(", "attacker_loss_train_two_agents_data", ")", ",", "axis", "=", "0", ")", "\n", "attacker_loss_train_two_agents_stds", "=", "np", ".", "std", "(", "tuple", "(", "attacker_loss_train_two_agents_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "defender_loss_train_two_agents_data", "=", "list", "(", "\n", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_defender\"", "]", ".", "values", ",", "train_two_agents_dfs", ")", ")", "\n", "defender_loss_train_two_agents_means", "=", "np", ".", "mean", "(", "tuple", "(", "defender_loss_train_two_agents_data", ")", ",", "axis", "=", "0", ")", "\n", "defender_loss_train_two_agents_stds", "=", "np", ".", "std", "(", "tuple", "(", "defender_loss_train_two_agents_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "", "algorithm_pp", "=", "algorithm", "\n", "if", "algorithm", "==", "\"dqn\"", ":", "\n", "        ", "algorithm_pp", "=", "\"DQN\"", "\n", "", "if", "algorithm", "==", "\"tabular_q_learning\"", ":", "\n", "        ", "algorithm_pp", "=", "\"Q-learning\"", "\n", "\n", "", "if", "plot_loss", ":", "\n", "# Attacker loss", "\n", "        ", "three_line_plot_w_shades", "(", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "attacker_loss_train_min_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "attacker_loss_train_min_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "attacker_loss_train_random_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "attacker_loss_train_random_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "attacker_loss_train_two_agents_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "attacker_loss_train_two_agents_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "stds_1", "=", "attacker_loss_train_min_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "stds_2", "=", "attacker_loss_train_random_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "stds_3", "=", "attacker_loss_train_two_agents_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "title", "=", "\"Avg Episode Loss [Attacker]\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Loss\"", ",", "\n", "line1_label", "=", "algorithm_pp", "+", "\" vs minimal defense\"", ",", "\n", "line2_label", "=", "algorithm_pp", "+", "\" vs random defense\"", ",", "\n", "line3_label", "=", "algorithm_pp", "+", "\" vs \"", "+", "algorithm_pp", ",", "\n", "legend_loc", "=", "\"upper left\"", ",", "\n", "markevery_1", "=", "1", ",", "markevery_2", "=", "1", ",", "markevery_3", "=", "1", ",", "\n", "file_name", "=", "output_dir", "+", "\"/avg_attacker_loss_\"", "+", "algorithm", "+", "\"_\"", "+", "str", "(", "version", ")", "\n", ")", "\n", "\n", "# Defender loss", "\n", "three_line_plot_w_shades", "(", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "defender_loss_train_max_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "defender_loss_train_max_attack_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "defender_loss_train_random_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "defender_loss_train_random_attack_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "defender_loss_train_two_agents_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "defender_loss_train_two_agents_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "stds_1", "=", "defender_loss_train_max_attack_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "stds_2", "=", "defender_loss_train_random_attack_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "stds_3", "=", "defender_loss_train_two_agents_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "title", "=", "\"Avg Episode Loss [Defender]\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Loss\"", ",", "\n", "line1_label", "=", "\"maximal attack vs \"", "+", "algorithm_pp", ",", "\n", "line2_label", "=", "\"random attack vs \"", "+", "algorithm_pp", ",", "\n", "line3_label", "=", "algorithm_pp", "+", "\" vs \"", "+", "algorithm_pp", ",", "\n", "legend_loc", "=", "\"upper left\"", ",", "\n", "markevery_1", "=", "1", ",", "markevery_2", "=", "1", ",", "markevery_3", "=", "1", ",", "\n", "file_name", "=", "output_dir", "+", "\"/avg_defender_loss_\"", "+", "algorithm", "+", "\"_\"", "+", "str", "(", "version", ")", "\n", ")", "\n", "\n", "", "five_line_plot_w_shades", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_min_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_min_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_random_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_max_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_max_attack_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_random_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_attack_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_two_agents_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_two_agents_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "stds_1", "=", "hack_prob_train_min_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "stds_2", "=", "hack_prob_train_random_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "stds_3", "=", "hack_prob_train_max_attack_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "stds_4", "=", "hack_prob_train_random_attack_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "stds_5", "=", "hack_prob_train_two_agents_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "title", "=", "\"Likelihood of Successful Hack [Train] (v\"", "+", "str", "(", "version", ")", "+", "\")\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"$\\mathbb{P}[Hacked]$\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/avg_hack_prob_train_\"", "+", "algorithm", "+", "\"_\"", "+", "str", "(", "version", ")", ",", "\n", "line1_label", "=", "algorithm_pp", "+", "\" vs minimal defense\"", ",", "line2_label", "=", "algorithm_pp", "+", "\" vs random defense\"", ",", "\n", "line3_label", "=", "\"maximal attack vs \"", "+", "algorithm_pp", ",", "line4_label", "=", "\"random attack vs \"", "+", "algorithm_pp", ",", "\n", "line5_label", "=", "algorithm_pp", "+", "\" vs \"", "+", "algorithm_pp", ",", "legend_loc", "=", "\"lower right\"", ",", "\n", "ylims", "=", "(", "0", ",", "1", ")", ",", "markevery_1", "=", "1", ",", "markevery_2", "=", "1", ",", "markevery_3", "=", "1", ",", "\n", "markevery_4", "=", "1", ",", "markevery_5", "=", "1", ")", "\n", "\n", "five_line_plot_w_shades", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_min_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_min_defense_means", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_defense_means", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_max_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_max_attack_means", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_attack_means", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_two_agents_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_two_agents_means", ",", "stds_1", "=", "hack_prob_eval_min_defense_stds", ",", "\n", "stds_2", "=", "hack_prob_eval_random_defense_stds", ",", "stds_3", "=", "hack_prob_eval_max_attack_stds", ",", "\n", "stds_4", "=", "hack_prob_eval_random_attack_stds", ",", "stds_5", "=", "hack_prob_eval_two_agents_stds", ",", "\n", "title", "=", "\"Likelihood of Successful Hack [Eval] (v\"", "+", "str", "(", "version", ")", "+", "\")\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"$\\mathbb{P}[Hacked]$\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/avg_hack_prob_eval_\"", "+", "algorithm", "+", "\"_\"", "+", "str", "(", "version", ")", ",", "\n", "line1_label", "=", "algorithm_pp", "+", "\" vs minimal defense\"", ",", "line2_label", "=", "algorithm_pp", "+", "\" vs random defense\"", ",", "\n", "line3_label", "=", "\"maximal attack vs \"", "+", "algorithm_pp", ",", "line4_label", "=", "\"random attack vs \"", "+", "algorithm_pp", ",", "\n", "line5_label", "=", "algorithm_pp", "+", "\" vs \"", "+", "algorithm_pp", ",", "legend_loc", "=", "\"lower right\"", ",", "\n", "ylims", "=", "(", "0", ",", "1", ")", ",", "markevery_1", "=", "1", ",", "markevery_2", "=", "1", ",", "markevery_3", "=", "1", ",", "markevery_4", "=", "1", ",", "\n", "markevery_5", "=", "1", ")", "\n", "\n", "five_line_plot_w_shades", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_min_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_min_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_random_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_max_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_max_attack_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_random_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_attack_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_two_agents_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_two_agents_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "stds_1", "=", "a_cum_reward_train_min_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "stds_2", "=", "a_cum_reward_train_random_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "stds_3", "=", "a_cum_reward_train_max_attack_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "stds_4", "=", "a_cum_reward_train_random_attack_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "stds_5", "=", "a_cum_reward_train_two_agents_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "title", "=", "\"Cumulative Reward for Attacker [Train] (v\"", "+", "str", "(", "version", ")", "+", "\")\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Cumulative Reward\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/avg_a_cum_reward_train_\"", "+", "algorithm", "+", "\"_\"", "+", "str", "(", "version", ")", ",", "\n", "line1_label", "=", "algorithm_pp", "+", "\" vs minimal defense\"", ",", "line2_label", "=", "algorithm_pp", "+", "\" vs random defense\"", ",", "\n", "line3_label", "=", "\"maximal attack vs \"", "+", "algorithm_pp", ",", "line4_label", "=", "\"random attack vs \"", "+", "algorithm_pp", ",", "\n", "line5_label", "=", "algorithm_pp", "+", "\" vs \"", "+", "algorithm_pp", ",", "legend_loc", "=", "\"lower right\"", ",", "\n", "markevery_1", "=", "1", ",", "markevery_2", "=", "1", ",", "markevery_3", "=", "1", ",", "\n", "markevery_4", "=", "1", ",", "markevery_5", "=", "1", ")", "\n", "\n", "five_line_plot_w_shades", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_cum_reward_train_min_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "d_cum_reward_train_min_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_cum_reward_train_random_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "d_cum_reward_train_random_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_cum_reward_train_max_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "d_cum_reward_train_max_attack_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_cum_reward_train_random_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "d_cum_reward_train_random_attack_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_cum_reward_train_two_agents_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "d_cum_reward_train_two_agents_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "stds_1", "=", "d_cum_reward_train_min_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "stds_2", "=", "d_cum_reward_train_random_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "stds_3", "=", "d_cum_reward_train_max_attack_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "stds_4", "=", "d_cum_reward_train_random_attack_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "stds_5", "=", "d_cum_reward_train_two_agents_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "title", "=", "\"Cumulative Reward for Defender [Train] (v\"", "+", "str", "(", "version", ")", "+", "\")\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Cumulative Reward\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/avg_d_cum_reward_train_\"", "+", "algorithm", "+", "\"_\"", "+", "str", "(", "version", ")", ",", "\n", "line1_label", "=", "algorithm_pp", "+", "\" vs minimal defense\"", ",", "line2_label", "=", "algorithm_pp", "+", "\" vs random defense\"", ",", "\n", "line3_label", "=", "\"maximal attack vs \"", "+", "algorithm_pp", ",", "line4_label", "=", "\"random attack vs \"", "+", "algorithm_pp", ",", "\n", "line5_label", "=", "algorithm_pp", "+", "\" vs \"", "+", "algorithm_pp", ",", "legend_loc", "=", "\"lower right\"", ",", "\n", "markevery_1", "=", "1", ",", "markevery_2", "=", "1", ",", "markevery_3", "=", "1", ",", "\n", "markevery_4", "=", "1", ",", "markevery_5", "=", "1", ")", "\n", "try", ":", "\n", "        ", "plot_all_avg_summary_1", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_min_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_min_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_random_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_max_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_max_attack_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_random_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_attack_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_two_agents_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_two_agents_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "hack_prob_train_min_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "hack_prob_train_max_attack_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_attack_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "hack_prob_train_two_agents_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "algorithm_pp", "+", "\" vs minimal defense\"", ",", "algorithm_pp", "+", "\" vs random defense\"", ",", "\n", "\"maximal attack vs \"", "+", "algorithm_pp", ",", "\"random attack vs \"", "+", "algorithm_pp", ",", "\n", "algorithm_pp", "+", "\" vs \"", "+", "algorithm_pp", ",", "\"Hack probability (train, v\"", "+", "str", "(", "version", ")", "+", "\")\"", ",", "\n", "\"Episode \\#\"", ",", "\"$\\mathbb{P}[Hacked]$\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_min_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_min_defense_means", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_defense_means", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_max_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_max_attack_means", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_attack_means", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_two_agents_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_two_agents_means", ",", "hack_prob_eval_min_defense_stds", ",", "\n", "hack_prob_eval_random_defense_stds", ",", "hack_prob_eval_max_attack_stds", ",", "\n", "hack_prob_eval_random_attack_stds", ",", "hack_prob_eval_two_agents_stds", ",", "\n", "algorithm_pp", "+", "\" vs minimal defense\"", ",", "algorithm_pp", "+", "\" vs random defense\"", ",", "\n", "\"maximal attack vs \"", "+", "algorithm_pp", ",", "\"random attack vs \"", "+", "algorithm_pp", ",", "\n", "algorithm_pp", "+", "\" vs \"", "+", "algorithm_pp", ",", "\"Hack probability (eval v\"", "+", "str", "(", "version", ")", "+", "\")\"", ",", "\n", "\"Episode \\#\"", ",", "\"$\\mathbb{P}[Hacked]$\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_min_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_min_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_random_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_max_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_max_attack_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_random_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_attack_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_two_agents_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_two_agents_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "a_cum_reward_train_min_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "a_cum_reward_train_max_attack_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_attack_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "a_cum_reward_train_two_agents_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "algorithm_pp", "+", "\" vs minimal defense\"", ",", "algorithm_pp", "+", "\" vs random defense\"", ",", "\n", "\"maximal attack vs \"", "+", "algorithm_pp", ",", "\"random attack vs \"", "+", "algorithm_pp", ",", "\n", "algorithm_pp", "+", "\" vs \"", "+", "algorithm_pp", ",", "\"Attacker reward (train v\"", "+", "str", "(", "version", ")", "+", "\")\"", ",", "\n", "\"Episode \\#\"", ",", "\"Cumulative Reward\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "attacker_loss_train_min_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "attacker_loss_train_min_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "attacker_loss_train_random_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "attacker_loss_train_random_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "attacker_loss_train_two_agents_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "attacker_loss_train_two_agents_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "attacker_loss_train_min_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "attacker_loss_train_random_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "attacker_loss_train_two_agents_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "algorithm_pp", "+", "\" vs minimal defense\"", ",", "algorithm_pp", "+", "\" vs random defense\"", ",", "\n", "algorithm_pp", "+", "\" vs \"", "+", "algorithm_pp", ",", "\n", "\"Avg Episode Loss [Attacker]\"", ",", "\"Episode \\#\"", ",", "\"Loss\"", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "defender_loss_train_max_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "defender_loss_train_max_attack_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "defender_loss_train_random_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "defender_loss_train_random_attack_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "defender_loss_train_two_agents_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "defender_loss_train_two_agents_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "defender_loss_train_max_attack_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "defender_loss_train_random_attack_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "defender_loss_train_two_agents_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "\"maximal attack vs \"", "+", "algorithm_pp", ",", "\"random attack vs \"", "+", "algorithm_pp", ",", "\n", "algorithm_pp", "+", "\" vs \"", "+", "algorithm_pp", ",", "\n", "\"Avg Episode Loss [Defender]\"", ",", "\"Episode \\#\"", ",", "\"Loss\"", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "output_dir", "+", "\"/combined_plot_\"", "+", "algorithm", "+", "\"_\"", "+", "str", "(", "version", ")", ",", "plot_loss", "=", "plot_loss", "\n", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "plot_all_avg_summary_1", "(", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_min_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_min_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_random_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_max_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_max_attack_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_random_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_attack_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_two_agents_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_two_agents_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "hack_prob_train_min_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "hack_prob_train_max_attack_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "hack_prob_train_random_attack_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "hack_prob_train_two_agents_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "algorithm_pp", "+", "\" vs minimal defense\"", ",", "algorithm_pp", "+", "\" vs random defense\"", ",", "\n", "\"maximal attack vs \"", "+", "algorithm_pp", ",", "\"random attack vs \"", "+", "algorithm_pp", ",", "\n", "algorithm_pp", "+", "\" vs \"", "+", "algorithm_pp", ",", "\"Hack probability (train, v\"", "+", "str", "(", "version", ")", "+", "\")\"", ",", "\n", "\"Episode \\#\"", ",", "\"$\\mathbb{P}[Hacked]$\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_min_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_min_defense_means", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_defense_means", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_max_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_max_attack_means", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_random_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_random_attack_means", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_two_agents_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_freq", ",", "\n", "hack_prob_eval_two_agents_means", ",", "hack_prob_eval_min_defense_stds", ",", "\n", "hack_prob_eval_random_defense_stds", ",", "hack_prob_eval_max_attack_stds", ",", "\n", "hack_prob_eval_random_attack_stds", ",", "hack_prob_eval_two_agents_stds", ",", "\n", "algorithm_pp", "+", "\" vs minimal defense\"", ",", "algorithm_pp", "+", "\" vs random defense\"", ",", "\n", "\"maximal attack vs \"", "+", "algorithm_pp", ",", "\"random attack vs \"", "+", "algorithm_pp", ",", "\n", "algorithm_pp", "+", "\" vs \"", "+", "algorithm_pp", ",", "\"Hack probability (eval v\"", "+", "str", "(", "version", ")", "+", "\")\"", ",", "\n", "\"Episode \\#\"", ",", "\"$\\mathbb{P}[Hacked]$\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_min_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_min_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_random_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_max_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_max_attack_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_random_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_attack_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_two_agents_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_two_agents_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "a_cum_reward_train_min_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "a_cum_reward_train_max_attack_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_attack_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "a_cum_reward_train_two_agents_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "algorithm_pp", "+", "\" vs minimal defense\"", ",", "algorithm_pp", "+", "\" vs random defense\"", ",", "\n", "\"maximal attack vs \"", "+", "algorithm_pp", ",", "\"random attack vs \"", "+", "algorithm_pp", ",", "\n", "algorithm_pp", "+", "\" vs \"", "+", "algorithm_pp", ",", "\"Attacker reward (train v\"", "+", "str", "(", "version", ")", "+", "\")\"", ",", "\n", "\"Episode \\#\"", ",", "\"Cumulative Reward\"", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_min_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_min_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_random_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_max_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_max_attack_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_min_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "a_cum_reward_train_max_attack_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "algorithm_pp", "+", "\" vs minimal defense\"", ",", "algorithm_pp", "+", "\" vs random defense\"", ",", "\n", "\"maximal attack vs \"", "+", "algorithm_pp", ",", "\"Attacker reward (train v\"", "+", "str", "(", "version", ")", "+", "\")\"", ",", "\n", "\"Episode \\#\"", ",", "\"Cumulative Reward\"", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_min_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_min_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_random_defense_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_defense_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_cum_reward_train_max_attack_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_freq", ")", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_attack_means", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_min_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "a_cum_reward_train_random_defense_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "a_cum_reward_train_max_attack_stds", "[", ":", ":", "eval_freq", "//", "train_log_freq", "]", ",", "\n", "algorithm_pp", "+", "\" vs minimal defense\"", ",", "algorithm_pp", "+", "\" vs random defense\"", ",", "\n", "\"maximal attack vs \"", "+", "algorithm_pp", ",", "\"Attacker reward (train v\"", "+", "str", "(", "version", ")", "+", "\")\"", ",", "\n", "\"Episode \\#\"", ",", "\"Cumulative Reward\"", ",", "1", ",", "1", ",", "1", ",", "\n", "\n", "output_dir", "+", "\"/combined_plot_\"", "+", "algorithm", "+", "\"_\"", "+", "str", "(", "version", ")", ",", "plot_loss", "=", "plot_loss", "\n", ")", "\n", "\n", "# Save mean and std data", "\n", "", "with", "open", "(", "output_dir", "+", "\"/data/hack_prob_train_min_defense_means_\"", "+", "algorithm", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hack_prob_train_min_defense_means\"", "]", ")", "\n", "for", "row", "in", "hack_prob_train_min_defense_means", ".", "tolist", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "row", "]", ")", "\n", "\n", "", "", "with", "open", "(", "output_dir", "+", "\"/data/hack_prob_train_min_defense_stds_\"", "+", "algorithm", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hack_prob_train_min_defense_stds\"", "]", ")", "\n", "for", "row", "in", "hack_prob_train_min_defense_stds", ".", "tolist", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "row", "]", ")", "\n", "\n", "", "", "with", "open", "(", "output_dir", "+", "\"/data/hack_prob_train_random_defense_means_\"", "+", "algorithm", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hack_prob_train_random_defense_means\"", "]", ")", "\n", "for", "row", "in", "hack_prob_train_random_defense_means", ".", "tolist", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "row", "]", ")", "\n", "\n", "", "", "with", "open", "(", "output_dir", "+", "\"/data/hack_prob_train_random_defense_stds_\"", "+", "algorithm", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hack_prob_train_random_defense_stds\"", "]", ")", "\n", "for", "row", "in", "hack_prob_train_random_defense_stds", ".", "tolist", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "row", "]", ")", "\n", "\n", "", "", "with", "open", "(", "output_dir", "+", "\"/data/hack_prob_train_max_attack_means_\"", "+", "algorithm", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hack_prob_train_max_attack_means\"", "]", ")", "\n", "for", "row", "in", "hack_prob_train_max_attack_means", ".", "tolist", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "row", "]", ")", "\n", "\n", "", "", "with", "open", "(", "output_dir", "+", "\"/data/hack_prob_train_max_attack_stds_\"", "+", "algorithm", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hack_prob_train_max_attack_stds\"", "]", ")", "\n", "for", "row", "in", "hack_prob_train_max_attack_stds", ".", "tolist", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "row", "]", ")", "\n", "\n", "", "", "with", "open", "(", "output_dir", "+", "\"/data/hack_prob_train_random_attack_means_\"", "+", "algorithm", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hack_prob_train_random_attack_means\"", "]", ")", "\n", "for", "row", "in", "hack_prob_train_random_attack_means", ".", "tolist", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "row", "]", ")", "\n", "\n", "", "", "with", "open", "(", "output_dir", "+", "\"/data/hack_prob_train_random_attack_stds_\"", "+", "algorithm", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hack_prob_train_random_attack_stds\"", "]", ")", "\n", "for", "row", "in", "hack_prob_train_random_attack_stds", ".", "tolist", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "row", "]", ")", "\n", "\n", "", "", "with", "open", "(", "output_dir", "+", "\"/data/hack_prob_train_two_agents_means_\"", "+", "algorithm", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hack_prob_train_two_agents_means\"", "]", ")", "\n", "for", "row", "in", "hack_prob_train_two_agents_means", ".", "tolist", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "row", "]", ")", "\n", "\n", "", "", "with", "open", "(", "output_dir", "+", "\"/data/hack_prob_train_two_agents_stds_\"", "+", "algorithm", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hack_prob_train_two_agents_stds\"", "]", ")", "\n", "for", "row", "in", "hack_prob_train_two_agents_stds", ".", "tolist", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "row", "]", ")", "\n", "\n", "", "", "with", "open", "(", "output_dir", "+", "\"/data/hack_prob_eval_min_defense_means_\"", "+", "algorithm", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hack_prob_eval_min_defense_means\"", "]", ")", "\n", "for", "row", "in", "hack_prob_eval_min_defense_means", ".", "tolist", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "row", "]", ")", "\n", "\n", "", "", "with", "open", "(", "output_dir", "+", "\"/data/hack_prob_eval_min_defense_stds_\"", "+", "algorithm", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hack_prob_eval_min_defense_stds\"", "]", ")", "\n", "for", "row", "in", "hack_prob_eval_min_defense_stds", ".", "tolist", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "row", "]", ")", "\n", "\n", "", "", "with", "open", "(", "output_dir", "+", "\"/data/hack_prob_eval_random_defense_means_\"", "+", "algorithm", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hack_prob_eval_random_defense_means\"", "]", ")", "\n", "for", "row", "in", "hack_prob_eval_random_defense_means", ".", "tolist", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "row", "]", ")", "\n", "\n", "", "", "with", "open", "(", "output_dir", "+", "\"/data/hack_prob_eval_random_defense_stds_\"", "+", "algorithm", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hack_prob_eval_random_defense_stds\"", "]", ")", "\n", "for", "row", "in", "hack_prob_eval_random_defense_stds", ".", "tolist", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "row", "]", ")", "\n", "\n", "", "", "with", "open", "(", "output_dir", "+", "\"/data/hack_prob_eval_max_attack_means_\"", "+", "algorithm", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hack_prob_eval_max_attack_means\"", "]", ")", "\n", "for", "row", "in", "hack_prob_eval_max_attack_means", ".", "tolist", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "row", "]", ")", "\n", "\n", "", "", "with", "open", "(", "output_dir", "+", "\"/data/hack_prob_eval_max_attack_stds_\"", "+", "algorithm", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hack_prob_eval_max_attack_stds\"", "]", ")", "\n", "for", "row", "in", "hack_prob_eval_max_attack_stds", ".", "tolist", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "row", "]", ")", "\n", "\n", "", "", "with", "open", "(", "output_dir", "+", "\"/data/hack_prob_eval_random_attack_means_\"", "+", "algorithm", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hack_prob_eval_random_attack_means\"", "]", ")", "\n", "for", "row", "in", "hack_prob_eval_random_attack_means", ".", "tolist", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "row", "]", ")", "\n", "\n", "", "", "with", "open", "(", "output_dir", "+", "\"/data/hack_prob_eval_random_attack_stds_\"", "+", "algorithm", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hack_prob_eval_random_attack_stds\"", "]", ")", "\n", "for", "row", "in", "hack_prob_eval_random_attack_stds", ".", "tolist", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "row", "]", ")", "\n", "\n", "", "", "with", "open", "(", "output_dir", "+", "\"/data/hack_prob_eval_two_agents_means_\"", "+", "algorithm", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hack_prob_eval_two_agents_means\"", "]", ")", "\n", "for", "row", "in", "hack_prob_eval_two_agents_means", ".", "tolist", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "row", "]", ")", "\n", "\n", "", "", "with", "open", "(", "output_dir", "+", "\"/data/hack_prob_eval_two_agents_stds_\"", "+", "algorithm", "+", "\".csv\"", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hack_prob_eval_two_agents_stds\"", "]", ")", "\n", "for", "row", "in", "hack_prob_eval_two_agents_stds", ".", "tolist", "(", ")", ":", "\n", "            ", "writer", ".", "writerow", "(", "[", "row", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_average_results": [[5632, 5740], ["list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "plotting_util.two_line_plot_w_shades", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "plotting_util.two_line_plot_w_shades", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "plotting_util.two_line_plot_w_shades", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "map", "tuple", "tuple", "list", "numpy.mean", "numpy.std", "plotting_util.one_line_plot_w_shades", "list", "numpy.mean", "numpy.std", "plotting_util.one_line_plot_w_shades", "plotting_util.two_line_plot_w_shades", "numpy.array", "numpy.array", "map", "tuple", "tuple", "map", "tuple", "tuple", "numpy.array", "list", "numpy.array", "numpy.array", "numpy.array", "list", "list", "range", "list", "list", "list", "range", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "range", "len", "range", "range", "range", "len", "list", "list", "list", "list", "len", "len", "len", "len", "range", "range", "range", "range", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.two_line_plot_w_shades", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.two_line_plot_w_shades", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.two_line_plot_w_shades", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.one_line_plot_w_shades", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.one_line_plot_w_shades", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.two_line_plot_w_shades"], ["", "", "", "def", "plot_average_results", "(", "train_dfs", ",", "eval_dfs", ",", "train_log_frequency", ",", "eval_frequency", ",", "experiment_title", ",", "output_dir", ",", "\n", "plot_attacker_loss", ":", "bool", "=", "False", ",", "plot_defender_loss", ":", "bool", "=", "False", ")", ":", "\n", "    ", "hack_prob_train_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_dfs", ")", ")", "\n", "hack_prob_train_means", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_data", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_stds", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_dfs", ")", ")", "\n", "hack_prob_eval_means", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_data", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_stds", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "two_line_plot_w_shades", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "hack_prob_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_frequency", ",", "\n", "hack_prob_eval_means", ",", "\n", "stds_1", "=", "hack_prob_train_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "stds_2", "=", "hack_prob_eval_stds", ",", "\n", "title", "=", "\"Likelihood of Successful Hack\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"$\\mathbb{P}[Hacked]$\"", ",", "\n", "line1_label", "=", "experiment_title", "+", "\" [Train]\"", ",", "\n", "line2_label", "=", "experiment_title", "+", "\" [Eval]\"", ",", "legend_loc", "=", "\"lower right\"", ",", "\n", "ylims", "=", "(", "0", ",", "1", ")", ",", "markevery_1", "=", "1", ",", "markevery_2", "=", "1", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/avg_hack_probability\"", "\n", ")", "\n", "\n", "cumulative_reward_attacker_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_dfs", ")", ")", "\n", "cumulative_reward_attacker_means", "=", "np", ".", "mean", "(", "tuple", "(", "cumulative_reward_attacker_data", ")", ",", "axis", "=", "0", ")", "\n", "cumulative_reward_attacker_stds", "=", "np", ".", "std", "(", "tuple", "(", "cumulative_reward_attacker_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "cumulative_reward_defender_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_dfs", ")", ")", "\n", "cumulative_reward_defender_means", "=", "np", ".", "mean", "(", "tuple", "(", "cumulative_reward_defender_data", ")", ",", "axis", "=", "0", ")", "\n", "cumulative_reward_defender_stds", "=", "np", ".", "std", "(", "tuple", "(", "cumulative_reward_defender_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "two_line_plot_w_shades", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "cumulative_reward_attacker_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "cumulative_reward_attacker_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "cumulative_reward_defender_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "cumulative_reward_defender_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "stds_1", "=", "cumulative_reward_attacker_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "stds_2", "=", "cumulative_reward_defender_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "title", "=", "\"Cumulative Reward (Train)\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Cumulative Reward\"", ",", "\n", "line1_label", "=", "experiment_title", "+", "\" [Attacker]\"", ",", "\n", "line2_label", "=", "experiment_title", "+", "\" [Defender]\"", ",", "legend_loc", "=", "\"upper left\"", ",", "\n", "markevery_1", "=", "1", ",", "markevery_2", "=", "1", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/avg_cumulative_rewards\"", "\n", ")", "\n", "\n", "avg_episode_len_train_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "train_dfs", ")", ")", "\n", "avg_episode_len_train_means", "=", "np", ".", "mean", "(", "tuple", "(", "avg_episode_len_train_data", ")", ",", "axis", "=", "0", ")", "\n", "avg_episode_len_train_stds", "=", "np", ".", "std", "(", "tuple", "(", "avg_episode_len_train_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "avg_episode_len_eval_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "eval_dfs", ")", ")", "\n", "avg_episode_len_eval_means", "=", "np", ".", "mean", "(", "tuple", "(", "avg_episode_len_eval_data", ")", ",", "axis", "=", "0", ")", "\n", "avg_episode_len_eval_stds", "=", "np", ".", "std", "(", "tuple", "(", "avg_episode_len_eval_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "two_line_plot_w_shades", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_len_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "avg_episode_len_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_len_eval_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_frequency", ",", "\n", "avg_episode_len_eval_means", ",", "\n", "stds_1", "=", "avg_episode_len_train_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "stds_2", "=", "avg_episode_len_eval_stds", ",", "\n", "title", "=", "\"Avg Episode Lengths\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Avg Length (num steps)\"", ",", "\n", "line1_label", "=", "experiment_title", "+", "\" [Train]\"", ",", "\n", "line2_label", "=", "experiment_title", "+", "\" [Eval]\"", ",", "legend_loc", "=", "\"upper left\"", ",", "\n", "markevery_1", "=", "1", ",", "markevery_2", "=", "1", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/avg_episode_length\"", "\n", ")", "\n", "if", "plot_attacker_loss", ":", "\n", "        ", "avg_episode_loss_attacker_train_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "train_dfs", ")", ")", "\n", "avg_episode_loss_attacker_train_means", "=", "np", ".", "mean", "(", "tuple", "(", "avg_episode_loss_attacker_train_data", ")", ",", "axis", "=", "0", ")", "\n", "avg_episode_loss_attacker_train_stds", "=", "np", ".", "std", "(", "tuple", "(", "avg_episode_loss_attacker_train_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "one_line_plot_w_shades", "(", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_attacker_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "avg_episode_loss_attacker_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "stds_1", "=", "avg_episode_loss_attacker_train_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "title", "=", "\"Avg Episode Loss\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Loss\"", ",", "\n", "line1_label", "=", "experiment_title", "+", "\" [Attacker]\"", ",", "legend_loc", "=", "\"upper left\"", ",", "\n", "markevery_1", "=", "1", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/avg_episode_loss_attacker\"", "\n", ")", "\n", "\n", "", "if", "plot_defender_loss", ":", "\n", "        ", "avg_episode_loss_defender_train_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_defender\"", "]", ".", "values", ",", "train_dfs", ")", ")", "\n", "avg_episode_loss_defender_train_means", "=", "np", ".", "mean", "(", "tuple", "(", "avg_episode_loss_defender_train_data", ")", ",", "axis", "=", "0", ")", "\n", "avg_episode_loss_defender_train_stds", "=", "np", ".", "std", "(", "tuple", "(", "avg_episode_loss_defender_train_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "one_line_plot_w_shades", "(", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_defender_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "avg_episode_loss_defender_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "stds_1", "=", "avg_episode_loss_defender_train_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "title", "=", "\"Avg Episode Loss\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Loss\"", ",", "\n", "line1_label", "=", "experiment_title", "+", "\" [defender]\"", ",", "legend_loc", "=", "\"upper left\"", ",", "\n", "markevery_1", "=", "1", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/avg_episode_loss_defender\"", "\n", ")", "\n", "\n", "", "if", "plot_attacker_loss", "and", "plot_defender_loss", ":", "\n", "        ", "two_line_plot_w_shades", "(", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_attacker_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "avg_episode_loss_attacker_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_defender_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "avg_episode_loss_defender_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "stds_1", "=", "avg_episode_loss_attacker_train_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "stds_2", "=", "avg_episode_loss_defender_train_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "title", "=", "\"Avg Episode Loss\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Loss\"", ",", "\n", "line1_label", "=", "experiment_title", "+", "\" [Attacker]\"", ",", "\n", "line2_label", "=", "experiment_title", "+", "\" [Defender]\"", ",", "legend_loc", "=", "\"upper left\"", ",", "\n", "markevery_1", "=", "1", ",", "markevery_2", "=", "1", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/avg_episode_loss_attacker_and_defender\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_avg_summary": [[5743, 6043], ["matplotlib.rc", "matplotlib.rc", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].set_xlim", "ax[].set_title", "ax[].set_xlabel", "ax[].set_ylabel", "ax[].grid", "ax[].xaxis.get_label", "ax[].yaxis.get_label", "ax[].xaxis.get_label.set_size", "ax[].yaxis.get_label.set_size", "ax[].spines[].set_color", "ax[].spines[].set_color", "ax[].legend", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].set_xlim", "ax[].set_title", "ax[].set_xlabel", "ax[].set_ylabel", "ax[].grid", "ax[].xaxis.get_label", "ax[].yaxis.get_label", "ax[].xaxis.get_label.set_size", "ax[].yaxis.get_label.set_size", "ax[].spines[].set_color", "ax[].spines[].set_color", "ax[].legend", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].set_xlim", "ax[].set_title", "ax[].set_xlabel", "ax[].set_ylabel", "ax[].grid", "ax[].xaxis.get_label", "ax[].yaxis.get_label", "ax[].xaxis.get_label.set_size", "ax[].yaxis.get_label.set_size", "ax[].spines[].set_color", "ax[].spines[].set_color", "ax[].legend", "fig.tight_layout", "fig.savefig", "fig.savefig", "matplotlib.close", "matplotlib.subplots", "matplotlib.subplots", "map", "tuple", "tuple", "map", "tuple", "tuple", "min", "max", "map", "tuple", "tuple", "map", "tuple", "tuple", "min", "max", "min", "max", "map", "tuple", "tuple", "map", "tuple", "tuple", "min", "max", "min", "max", "list", "numpy.mean", "numpy.std", "list", "numpy.mean", "numpy.std", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].plot", "ax[].fill_between", "ax[].set_xlim", "ax[].set_title", "ax[].set_xlabel", "ax[].set_ylabel", "ax[].grid", "ax[].xaxis.get_label", "ax[].yaxis.get_label", "ax[].xaxis.get_label.set_size", "ax[].yaxis.get_label.set_size", "ax[].spines[].set_color", "ax[].spines[].set_color", "ax[].legend", "min", "min", "max", "max", "numpy.array", "numpy.array", "min", "min", "max", "max", "min", "min", "max", "max", "min", "min", "max", "max", "min", "min", "max", "max", "numpy.array", "numpy.array", "map", "tuple", "tuple", "map", "tuple", "tuple", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "min", "max", "numpy.array", "numpy.array", "list", "list", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "list", "list", "min", "min", "max", "max", "min", "min", "max", "max", "numpy.array", "numpy.array", "list", "list", "range", "range", "list", "list", "list", "list", "numpy.array", "numpy.array", "list", "list", "range", "range", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "list", "numpy.array", "list", "range", "range", "len", "len", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "range", "range", "range", "range", "numpy.array", "list", "numpy.array", "list", "range", "range", "len", "len", "list", "list", "list", "list", "numpy.array", "numpy.array", "list", "list", "numpy.array", "numpy.array", "list", "list", "list", "range", "list", "range", "len", "len", "list", "list", "list", "list", "len", "len", "len", "len", "list", "range", "list", "range", "len", "len", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "range", "range", "range", "range", "list", "list", "range", "range", "list", "list", "range", "range", "range", "len", "range", "len", "range", "range", "range", "range", "range", "len", "range", "len", "list", "list", "list", "list", "len", "len", "len", "len", "range", "range", "len", "len", "range", "range", "len", "len", "len", "len", "len", "len", "len", "len", "len", "len", "range", "range", "range", "range", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.v8.plot_summary.plot"], ["", "", "def", "plot_avg_summary", "(", "train_dfs", ",", "eval_dfs", ",", "train_log_frequency", ",", "eval_frequency", ",", "experiment_title", ",", "file_name", ",", "\n", "plot_attacker_loss", ":", "bool", "=", "False", ",", "plot_defender_loss", ":", "bool", "=", "False", ")", ":", "\n", "    ", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "if", "plot_attacker_loss", "or", "plot_defender_loss", ":", "\n", "        ", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "4", ",", "ncols", "=", "1", ",", "figsize", "=", "(", "6", ",", "10", ")", ")", "\n", "", "else", ":", "\n", "        ", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "3", ",", "ncols", "=", "1", ",", "figsize", "=", "(", "6", ",", "8", ")", ")", "\n", "\n", "# Plot avg hack_probability", "\n", "\n", "", "hack_prob_train_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "train_dfs", ")", ")", "\n", "hack_prob_train_means", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_train_data", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_train_stds", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_train_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "hack_prob_eval_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"hack_probability\"", "]", ".", "values", ",", "eval_dfs", ")", ")", "\n", "hack_prob_eval_means", "=", "np", ".", "mean", "(", "tuple", "(", "hack_prob_eval_data", ")", ",", "axis", "=", "0", ")", "\n", "hack_prob_eval_stds", "=", "np", ".", "std", "(", "tuple", "(", "hack_prob_eval_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "xlims", "=", "(", "min", "(", "min", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ",", "\n", "min", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_frequency", ")", ")", ",", "\n", "max", "(", "max", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ",", "\n", "max", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_frequency", ")", ")", ")", "\n", "ylims", "=", "(", "0", ",", "1", ")", "\n", "\n", "ax", "[", "0", "]", ".", "plot", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "hack_prob_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "label", "=", "experiment_title", "+", "\" [Train]\"", ",", "\n", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "1", ")", "\n", "ax", "[", "0", "]", ".", "fill_between", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "hack_prob_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "-", "hack_prob_train_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "hack_prob_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "+", "hack_prob_train_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "0", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_frequency", ",", "\n", "hack_prob_eval_means", ",", "label", "=", "experiment_title", "+", "\" [Eval]\"", ",", "\n", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "markevery", "=", "1", ")", "\n", "ax", "[", "0", "]", ".", "fill_between", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_prob_eval_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_frequency", ",", "\n", "hack_prob_eval_means", "-", "hack_prob_eval_stds", ",", "\n", "hack_prob_eval_means", "+", "hack_prob_eval_stds", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "0", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "#ax[0].set_ylim(ylims)", "\n", "\n", "ax", "[", "0", "]", ".", "set_title", "(", "\"Likelihood of Successful Hack\"", ")", "\n", "ax", "[", "0", "]", ".", "set_xlabel", "(", "\"Episode \\#\"", ")", "\n", "ax", "[", "0", "]", ".", "set_ylabel", "(", "\"$\\mathbb{P}[Hacked]$\"", ")", "\n", "# set the grid on", "\n", "ax", "[", "0", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "0", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "0", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "0", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "0", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "ax", "[", "0", "]", ".", "legend", "(", "loc", "=", "\"lower right\"", ")", "\n", "\n", "# Plot Cumulative Reward", "\n", "\n", "cumulative_reward_attacker_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "train_dfs", ")", ")", "\n", "cumulative_reward_attacker_means", "=", "np", ".", "mean", "(", "tuple", "(", "cumulative_reward_attacker_data", ")", ",", "axis", "=", "0", ")", "\n", "cumulative_reward_attacker_stds", "=", "np", ".", "std", "(", "tuple", "(", "cumulative_reward_attacker_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "cumulative_reward_defender_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "train_dfs", ")", ")", "\n", "cumulative_reward_defender_means", "=", "np", ".", "mean", "(", "tuple", "(", "cumulative_reward_defender_data", ")", ",", "axis", "=", "0", ")", "\n", "cumulative_reward_defender_stds", "=", "np", ".", "std", "(", "tuple", "(", "cumulative_reward_defender_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "xlims", "=", "(", "min", "(", "min", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "cumulative_reward_attacker_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ",", "\n", "min", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "cumulative_reward_defender_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ")", ",", "\n", "max", "(", "max", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "cumulative_reward_attacker_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ",", "\n", "max", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "cumulative_reward_defender_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ")", ")", "\n", "ylims", "=", "(", "min", "(", "min", "(", "cumulative_reward_attacker_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "-", "cumulative_reward_attacker_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ",", "\n", "min", "(", "cumulative_reward_defender_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "-", "cumulative_reward_defender_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ")", ",", "\n", "max", "(", "max", "(", "cumulative_reward_attacker_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "+", "cumulative_reward_attacker_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ",", "\n", "max", "(", "cumulative_reward_defender_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "+", "cumulative_reward_defender_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ")", ")", "\n", "\n", "ax", "[", "1", "]", ".", "plot", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "cumulative_reward_attacker_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "cumulative_reward_attacker_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "label", "=", "experiment_title", "+", "\" [Attacker]\"", ",", "\n", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "1", ")", "\n", "ax", "[", "1", "]", ".", "fill_between", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "cumulative_reward_attacker_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "cumulative_reward_attacker_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "-", "cumulative_reward_attacker_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "cumulative_reward_attacker_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "+", "cumulative_reward_attacker_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "1", "]", ".", "plot", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "cumulative_reward_defender_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "cumulative_reward_defender_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "label", "=", "experiment_title", "+", "\" [Defender]\"", ",", "\n", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "markevery", "=", "1", ")", "\n", "ax", "[", "1", "]", ".", "fill_between", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "cumulative_reward_defender_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "cumulative_reward_defender_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "-", "cumulative_reward_defender_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "cumulative_reward_defender_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "+", "cumulative_reward_defender_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "1", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "#ax[1].set_ylim(ylims)", "\n", "\n", "ax", "[", "1", "]", ".", "set_title", "(", "\"Cumulative Reward (Train)\"", ")", "\n", "ax", "[", "1", "]", ".", "set_xlabel", "(", "\"Episode \\#\"", ")", "\n", "ax", "[", "1", "]", ".", "set_ylabel", "(", "\"Cumulative Reward\"", ")", "\n", "# set the grid on", "\n", "ax", "[", "1", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "1", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "1", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "1", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "1", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "ax", "[", "1", "]", ".", "legend", "(", "loc", "=", "\"upper left\"", ")", "\n", "\n", "# Plot Average Episode Length", "\n", "avg_episode_len_train_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "train_dfs", ")", ")", "\n", "avg_episode_len_train_means", "=", "np", ".", "mean", "(", "tuple", "(", "avg_episode_len_train_data", ")", ",", "axis", "=", "0", ")", "\n", "avg_episode_len_train_stds", "=", "np", ".", "std", "(", "tuple", "(", "avg_episode_len_train_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "avg_episode_len_eval_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "eval_dfs", ")", ")", "\n", "avg_episode_len_eval_means", "=", "np", ".", "mean", "(", "tuple", "(", "avg_episode_len_eval_data", ")", ",", "axis", "=", "0", ")", "\n", "avg_episode_len_eval_stds", "=", "np", ".", "std", "(", "tuple", "(", "avg_episode_len_eval_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "\n", "xlims", "=", "(", "min", "(", "min", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_len_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ",", "\n", "min", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_len_eval_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_frequency", ")", ")", ",", "\n", "max", "(", "max", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_len_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ",", "\n", "max", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_len_eval_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_frequency", ")", ")", ")", "\n", "ylims", "=", "(", "min", "(", "min", "(", "avg_episode_len_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "-", "avg_episode_len_train_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ",", "\n", "min", "(", "avg_episode_len_eval_means", "-", "avg_episode_len_eval_stds", ")", ")", ",", "\n", "max", "(", "max", "(", "avg_episode_len_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "+", "avg_episode_len_train_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ",", "\n", "max", "(", "avg_episode_len_eval_means", "+", "avg_episode_len_eval_stds", ")", ")", ")", "\n", "\n", "ax", "[", "2", "]", ".", "plot", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_len_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "avg_episode_len_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "label", "=", "experiment_title", "+", "\" [Train]\"", ",", "\n", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "1", ")", "\n", "ax", "[", "2", "]", ".", "fill_between", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_len_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "avg_episode_len_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "-", "avg_episode_len_train_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "avg_episode_len_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "+", "avg_episode_len_train_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "2", "]", ".", "plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_len_eval_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_frequency", ",", "\n", "avg_episode_len_eval_means", ",", "label", "=", "experiment_title", "+", "\" [Eval]\"", ",", "\n", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "markevery", "=", "1", ")", "\n", "ax", "[", "2", "]", ".", "fill_between", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_len_eval_data", "[", "0", "]", ")", ")", ")", ")", "*", "eval_frequency", ",", "\n", "avg_episode_len_eval_means", "-", "avg_episode_len_eval_stds", ",", "\n", "avg_episode_len_eval_means", "+", "avg_episode_len_eval_stds", ",", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "\n", "ax", "[", "2", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "#ax[2].set_ylim(ylims)", "\n", "\n", "ax", "[", "2", "]", ".", "set_title", "(", "\"Avg Episode Lengths\"", ")", "\n", "ax", "[", "2", "]", ".", "set_xlabel", "(", "\"Episode \\#\"", ")", "\n", "ax", "[", "2", "]", ".", "set_ylabel", "(", "\"Avg Length (num steps)\"", ")", "\n", "# set the grid on", "\n", "ax", "[", "2", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "2", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "2", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "2", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "2", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "ax", "[", "2", "]", ".", "legend", "(", "loc", "=", "\"upper right\"", ")", "\n", "\n", "# Plot loss", "\n", "\n", "if", "plot_attacker_loss", ":", "\n", "        ", "avg_episode_loss_attacker_train_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_attacker\"", "]", ".", "values", ",", "train_dfs", ")", ")", "\n", "avg_episode_loss_attacker_train_means", "=", "np", ".", "mean", "(", "tuple", "(", "avg_episode_loss_attacker_train_data", ")", ",", "axis", "=", "0", ")", "\n", "avg_episode_loss_attacker_train_stds", "=", "np", ".", "std", "(", "tuple", "(", "avg_episode_loss_attacker_train_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "", "if", "plot_defender_loss", ":", "\n", "        ", "avg_episode_loss_defender_train_data", "=", "list", "(", "map", "(", "lambda", "df", ":", "df", "[", "\"avg_episode_loss_defender\"", "]", ".", "values", ",", "train_dfs", ")", ")", "\n", "avg_episode_loss_defender_train_means", "=", "np", ".", "mean", "(", "tuple", "(", "avg_episode_loss_defender_train_data", ")", ",", "axis", "=", "0", ")", "\n", "avg_episode_loss_defender_train_stds", "=", "np", ".", "std", "(", "tuple", "(", "avg_episode_loss_defender_train_data", ")", ",", "axis", "=", "0", ",", "ddof", "=", "1", ")", "\n", "", "if", "plot_attacker_loss", "and", "plot_defender_loss", ":", "\n", "        ", "xlims", "=", "(", "min", "(", "min", "(", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_attacker_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ",", "\n", "min", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_defender_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", "\n", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ")", ",", "\n", "max", "(", "max", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_attacker_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", "\n", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ",", "\n", "max", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_defender_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", "\n", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ")", ")", "\n", "ylims", "=", "(", "\n", "min", "(", "min", "(", "avg_episode_loss_attacker_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "-", "avg_episode_loss_attacker_train_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ",", "\n", "min", "(", "avg_episode_loss_defender_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "-", "avg_episode_loss_defender_train_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ")", ",", "\n", "max", "(", "max", "(", "avg_episode_loss_attacker_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "+", "avg_episode_loss_attacker_train_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ",", "\n", "max", "(", "avg_episode_loss_defender_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "+", "avg_episode_loss_defender_train_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ")", ")", "\n", "\n", "ax", "[", "3", "]", ".", "plot", "(", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_attacker_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "avg_episode_loss_attacker_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "label", "=", "experiment_title", "+", "\" [Attacker]\"", ",", "\n", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "1", ")", "\n", "ax", "[", "3", "]", ".", "fill_between", "(", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_attacker_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "avg_episode_loss_attacker_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "-", "avg_episode_loss_attacker_train_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "avg_episode_loss_attacker_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "+", "avg_episode_loss_attacker_train_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "ax", "[", "3", "]", ".", "plot", "(", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_defender_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "avg_episode_loss_defender_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "label", "=", "experiment_title", "+", "\" [Defender]\"", ",", "\n", "marker", "=", "\"o\"", ",", "ls", "=", "'-'", ",", "color", "=", "'#f9a65a'", ",", "markevery", "=", "1", ")", "\n", "ax", "[", "3", "]", ".", "fill_between", "(", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_defender_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "avg_episode_loss_defender_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "-", "avg_episode_loss_defender_train_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "avg_episode_loss_defender_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "+", "avg_episode_loss_defender_train_stds", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "'#f9a65a'", ")", "\n", "", "if", "plot_attacker_loss", "and", "not", "plot_defender_loss", ":", "\n", "        ", "xlims", "=", "(", "min", "(", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_attacker_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", "\n", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ",", "\n", "max", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_attacker_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", "\n", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ")", "\n", "ylims", "=", "(", "\n", "min", "(", "avg_episode_loss_attacker_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "-", "avg_episode_loss_attacker_train_stds", "[", "\n", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ",", "\n", "max", "(", "avg_episode_loss_attacker_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "+", "avg_episode_loss_attacker_train_stds", "[", "\n", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ")", "\n", "\n", "ax", "[", "3", "]", ".", "plot", "(", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_attacker_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", "\n", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "avg_episode_loss_attacker_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "label", "=", "experiment_title", "+", "\" [Attacker]\"", ",", "\n", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "1", ")", "\n", "ax", "[", "3", "]", ".", "fill_between", "(", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_attacker_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", "\n", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "avg_episode_loss_attacker_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "-", "avg_episode_loss_attacker_train_stds", "[", "\n", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "avg_episode_loss_attacker_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "+", "avg_episode_loss_attacker_train_stds", "[", "\n", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "", "if", "plot_defender_loss", "and", "not", "plot_attacker_loss", ":", "\n", "        ", "xlims", "=", "(", "min", "(", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_defender_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", "\n", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ",", "\n", "max", "(", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_defender_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", "\n", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ")", "\n", "ylims", "=", "(", "\n", "min", "(", "avg_episode_loss_defender_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "-", "avg_episode_loss_defender_train_stds", "[", "\n", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ",", "\n", "max", "(", "avg_episode_loss_defender_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "+", "avg_episode_loss_defender_train_stds", "[", "\n", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ")", ")", "\n", "\n", "ax", "[", "3", "]", ".", "plot", "(", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_defender_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", "\n", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "avg_episode_loss_defender_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "label", "=", "experiment_title", "+", "\" [Defender]\"", ",", "\n", "marker", "=", "\"s\"", ",", "ls", "=", "'-'", ",", "color", "=", "\"#599ad3\"", ",", "\n", "markevery", "=", "1", ")", "\n", "ax", "[", "3", "]", ".", "fill_between", "(", "\n", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_defender_train_data", "[", "0", "]", ")", ")", ")", ")", "*", "train_log_frequency", ")", "[", "\n", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "avg_episode_loss_defender_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "-", "avg_episode_loss_defender_train_stds", "[", "\n", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "avg_episode_loss_defender_train_means", "[", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", "+", "avg_episode_loss_defender_train_stds", "[", "\n", ":", ":", "eval_frequency", "//", "train_log_frequency", "]", ",", "\n", "alpha", "=", "0.35", ",", "color", "=", "\"#599ad3\"", ")", "\n", "\n", "", "if", "plot_attacker_loss", "or", "plot_defender_loss", ":", "\n", "        ", "ax", "[", "3", "]", ".", "set_xlim", "(", "xlims", ")", "\n", "#ax[3].set_ylim(ylims)", "\n", "\n", "ax", "[", "3", "]", ".", "set_title", "(", "\"Avg Episode Loss\"", ")", "\n", "ax", "[", "3", "]", ".", "set_xlabel", "(", "\"Episode \\#\"", ")", "\n", "ax", "[", "3", "]", ".", "set_ylabel", "(", "\"Loss\"", ")", "\n", "# set the grid on", "\n", "ax", "[", "3", "]", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", "[", "3", "]", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", "[", "3", "]", ".", "yaxis", ".", "get_label", "(", ")", "\n", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", "[", "3", "]", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", "[", "3", "]", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "ax", "[", "3", "]", ".", "legend", "(", "loc", "=", "\"upper left\"", ")", "\n", "\n", "", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_average_results": [[6044, 6062], ["plotting_util.plot_average_results", "plotting_util.plot_avg_summary", "plotting_util.read_data", "train_dfs.append", "plotting_util.read_data", "eval_dfs.append"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_average_results", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_avg_summary", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data"], ["", "def", "read_and_plot_average_results", "(", "experiment_title", ":", "str", ",", "train_csv_paths", ":", "list", ",", "eval_csv_paths", ":", "list", ",", "\n", "train_log_frequency", ":", "int", ",", "eval_frequency", ":", "int", ",", "output_dir", ":", "str", ",", "\n", "plot_attacker_loss", ":", "bool", "=", "False", ",", "plot_defender_loss", ":", "bool", "=", "False", ")", ":", "\n", "    ", "eval_dfs", "=", "[", "]", "\n", "train_dfs", "=", "[", "]", "\n", "for", "train_path", "in", "train_csv_paths", ":", "\n", "        ", "df", "=", "read_data", "(", "train_path", ")", "\n", "train_dfs", ".", "append", "(", "df", ")", "\n", "\n", "", "for", "eval_path", "in", "eval_csv_paths", ":", "\n", "        ", "df", "=", "read_data", "(", "eval_path", ")", "\n", "eval_dfs", ".", "append", "(", "df", ")", "\n", "\n", "", "plot_average_results", "(", "train_dfs", ",", "eval_dfs", ",", "train_log_frequency", ",", "eval_frequency", ",", "experiment_title", ",", "output_dir", ",", "\n", "plot_attacker_loss", "=", "plot_attacker_loss", ",", "plot_defender_loss", "=", "plot_defender_loss", ")", "\n", "plot_avg_summary", "(", "train_dfs", ",", "eval_dfs", ",", "train_log_frequency", ",", "eval_frequency", ",", "experiment_title", ",", "\n", "output_dir", "+", "\"/results/plots/avg_summary\"", ",", "\n", "plot_attacker_loss", "=", "plot_attacker_loss", ",", "plot_defender_loss", "=", "plot_defender_loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_and_plot_results": [[6064, 6195], ["plotting_util.read_data", "plotting_util.read_data", "list", "list", "plotting_util.plot_results", "plotting_util.plot_results", "x[].replace", "filter", "map", "len", "max", "plotting_util.plot_two_histograms", "plotting_util.plot_two_histograms", "plotting_util.plot_two_histograms", "plotting_util.two_line_plot", "plotting_util.two_line_plot", "print", "os.walk", "numpy.load", "range", "numpy.load", "plotting_util.probability_plot", "plotting_util.plot_all", "numpy.load", "range", "numpy.load", "plotting_util.probability_plot", "plotting_util.plot_all", "numpy.array", "str", "x.isnumeric", "int", "plotting_util.save_image", "numpy.array", "print", "plotting_util.save_image", "numpy.array", "print", "numpy.array", "numpy.array", "numpy.array", "list", "plotting_util.read_data", "plotting_util.plot_hist_prob_attack_stats", "str", "list", "list", "list", "list", "list", "range", "print", "str", "str", "str", "str", "range", "str", "str", "str", "str", "str", "range", "str", "str", "str", "str", "str", "range", "range", "str", "range", "len", "str", "len", "str", "len", "str", "len", "len", "len", "str", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_results", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_results", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_two_histograms", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_two_histograms", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_two_histograms", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.two_line_plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.two_line_plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.probability_plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.probability_plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_all", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.save_image", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.save_image", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.read_data", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_hist_prob_attack_stats"], ["", "def", "read_and_plot_results", "(", "train_csv_path", ":", "str", ",", "eval_csv_path", ":", "str", ",", "train_log_frequency", ":", "int", ",", "\n", "eval_frequency", ":", "int", ",", "eval_log_frequency", ":", "int", ",", "eval_episodes", ":", "int", ",", "output_dir", ":", "str", ",", "sim", "=", "False", ",", "\n", "random_seed", ":", "int", "=", "0", ",", "attack_stats_csv_path", ":", "str", "=", "None", ")", ":", "\n", "    ", "eval_df", "=", "read_data", "(", "eval_csv_path", ")", "\n", "train_df", "=", "read_data", "(", "train_csv_path", ")", "\n", "avg_episode_loss_attacker", "=", "None", "\n", "avg_episode_loss_defender", "=", "None", "\n", "if", "\"avg_episode_loss_attacker\"", "in", "train_df", ":", "\n", "        ", "avg_episode_loss_attacker", "=", "train_df", "[", "\"avg_episode_loss_attacker\"", "]", "\n", "", "if", "\"avg_episode_loss_defender\"", "in", "train_df", ":", "\n", "        ", "avg_episode_loss_defender", "=", "train_df", "[", "\"avg_episode_loss_defender\"", "]", "\n", "", "try", ":", "\n", "        ", "plot_results", "(", "train_df", "[", "\"avg_attacker_episode_rewards\"", "]", ".", "values", ",", "\n", "train_df", "[", "\"avg_defender_episode_rewards\"", "]", ".", "values", ",", "\n", "train_df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "\n", "train_df", "[", "\"epsilon_values\"", "]", ",", "train_df", "[", "\"hack_probability\"", "]", ",", "\n", "train_df", "[", "\"attacker_cumulative_reward\"", "]", ",", "train_df", "[", "\"defender_cumulative_reward\"", "]", ",", "\n", "avg_episode_loss_attacker", ",", "avg_episode_loss_defender", ",", "\n", "train_df", "[", "\"lr_list\"", "]", ",", "\n", "train_log_frequency", ",", "eval_frequency", ",", "eval_log_frequency", ",", "eval_episodes", ",", "\n", "output_dir", ",", "eval", "=", "False", ",", "sim", "=", "sim", ",", "random_seed", "=", "random_seed", ")", "\n", "plot_results", "(", "eval_df", "[", "\"avg_attacker_episode_rewards\"", "]", ".", "values", ",", "\n", "eval_df", "[", "\"avg_defender_episode_rewards\"", "]", ".", "values", ",", "\n", "eval_df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "\n", "eval_df", "[", "\"epsilon_values\"", "]", ",", "eval_df", "[", "\"hack_probability\"", "]", ",", "\n", "eval_df", "[", "\"attacker_cumulative_reward\"", "]", ",", "eval_df", "[", "\"defender_cumulative_reward\"", "]", ",", "None", ",", "None", ",", "\n", "eval_df", "[", "\"lr_list\"", "]", ",", "\n", "train_log_frequency", ",", "\n", "eval_frequency", ",", "eval_log_frequency", ",", "eval_episodes", ",", "output_dir", ",", "eval", "=", "True", ",", "sim", "=", "sim", ",", "\n", "random_seed", "=", "random_seed", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "print", "(", "str", "(", "e", ")", ")", "\n", "\n", "", "dirs", "=", "[", "x", "[", "0", "]", ".", "replace", "(", "\"./results/data/\"", "+", "str", "(", "random_seed", ")", "+", "\"/state_values/\"", ",", "\"\"", ")", "\n", "for", "x", "in", "os", ".", "walk", "(", "\"./results/data/\"", "+", "str", "(", "random_seed", ")", "+", "\"/state_values\"", ")", "]", "\n", "f_dirs", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", ".", "isnumeric", "(", ")", ",", "dirs", ")", ")", "\n", "f_dirs2", "=", "list", "(", "map", "(", "lambda", "x", ":", "int", "(", "x", ")", ",", "f_dirs", ")", ")", "\n", "if", "len", "(", "f_dirs2", ")", ">", "0", ":", "\n", "        ", "last_episode", "=", "max", "(", "f_dirs2", ")", "\n", "\n", "try", ":", "\n", "            ", "a_state_plot_frames", "=", "np", ".", "load", "(", "\"./results/data/\"", "+", "str", "(", "random_seed", ")", "+", "\"/state_values/\"", "+", "\n", "str", "(", "last_episode", ")", "+", "\"/attacker_frames.npy\"", ")", "\n", "for", "i", "in", "range", "(", "a_state_plot_frames", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "save_image", "(", "a_state_plot_frames", "[", "i", "]", ",", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\n", "\"/final_frame_attacker\"", "+", "str", "(", "i", ")", ")", "\n", "\n", "", "a_state_values", "=", "np", ".", "load", "(", "\"./results/data/\"", "+", "str", "(", "random_seed", ")", "+", "\"/state_values/\"", "+", "str", "(", "last_episode", ")", "+", "\n", "\"/attacker_state_values.npy\"", ")", "\n", "probability_plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "a_state_values", ")", ")", ")", ")", ",", "a_state_values", ",", "\n", "title", "=", "\"Attacker State Values\"", ",", "\n", "xlabel", "=", "\"Time step (t)\"", ",", "ylabel", "=", "\"$V(s_t)$\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\n", "\"/final_state_values_attacker\"", ")", "\n", "\n", "plot_all", "(", "train_df", ",", "eval_df", ",", "eval_frequency", ",", "a_state_values", ",", "\n", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\"/summary\"", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "\"Warning: \"", "+", "str", "(", "e", ")", ")", "\n", "\n", "", "try", ":", "\n", "            ", "a_state_plot_frames", "=", "np", ".", "load", "(", "\"./results/data/\"", "+", "str", "(", "random_seed", ")", "+", "\"/state_values/\"", "+", "str", "(", "last_episode", ")", "\n", "+", "\"/defender_frames.npy\"", ")", "\n", "for", "i", "in", "range", "(", "a_state_plot_frames", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "save_image", "(", "a_state_plot_frames", "[", "i", "]", ",", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "\n", "+", "\"/final_frame_defender\"", "+", "str", "(", "i", ")", ")", "\n", "\n", "", "d_state_values", "=", "np", ".", "load", "(", "\"./results/data/\"", "+", "str", "(", "random_seed", ")", "+", "\"/state_values/\"", "+", "str", "(", "last_episode", ")", "+", "\n", "\"/defender_state_values.npy\"", ")", "\n", "probability_plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "d_state_values", ")", ")", ")", ")", ",", "d_state_values", ",", "\n", "title", "=", "\"Defender State Values\"", ",", "\n", "xlabel", "=", "\"Time step (t)\"", ",", "ylabel", "=", "\"$V(s_t)$\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\n", "\"/final_state_values_defender\"", ")", "\n", "\n", "plot_all", "(", "train_df", ",", "eval_df", ",", "eval_frequency", ",", "d_state_values", ",", "\n", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\"/summary\"", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "\"Warning: \"", "+", "str", "(", "e", ")", ")", "\n", "\n", "\n", "", "plot_two_histograms", "(", "train_df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "eval_df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "\n", "title", "=", "\"Avg Episode Lengths\"", ",", "\n", "xlabel", "=", "\"Avg Length (num steps)\"", ",", "ylabel", "=", "\"Normalized Frequency\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\n", "\"/train_eval_avg_episode_length\"", ",", "\n", "hist1_label", "=", "\"Train\"", ",", "hist2_label", "=", "\"Eval\"", ")", "\n", "\n", "plot_two_histograms", "(", "train_df", "[", "\"avg_attacker_episode_rewards\"", "]", ".", "values", ",", "\n", "train_df", "[", "\"avg_defender_episode_rewards\"", "]", ".", "values", ",", "\n", "title", "=", "\"Avg Episode Returns (Train)\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Avg Return (num steps)\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\n", "\"/attack_defend_avg_episode_return_train\"", ",", "\n", "hist1_label", "=", "\"Attacker\"", ",", "hist2_label", "=", "\"Defender\"", ",", "num_bins", "=", "3", ")", "\n", "\n", "plot_two_histograms", "(", "eval_df", "[", "\"avg_attacker_episode_rewards\"", "]", ".", "values", ",", "\n", "eval_df", "[", "\"avg_defender_episode_rewards\"", "]", ".", "values", ",", "\n", "title", "=", "\"Avg Episode Returns (Eval)\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Avg Return (num steps)\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\n", "\"/attack_defend_avg_episode_return_eval\"", ",", "\n", "hist1_label", "=", "\"Attacker\"", ",", "hist2_label", "=", "\"Defender\"", ",", "num_bins", "=", "3", ")", "\n", "\n", "two_line_plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "train_df", "[", "\"avg_episode_steps\"", "]", ")", ")", ")", ")", "*", "1", ",", "\n", "train_df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "eval_df", "[", "\"avg_episode_steps\"", "]", ")", ")", ")", ")", "*", "1000", ",", "\n", "eval_df", "[", "\"avg_episode_steps\"", "]", ".", "values", ",", "\n", "title", "=", "\"Avg Episode Lengths\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Avg Length (num steps)\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\n", "\"/avg_episode_length_train_eval\"", ",", "\n", "line1_label", "=", "\"Train\"", ",", "line2_label", "=", "\"Eval\"", ",", "legend_loc", "=", "\"upper right\"", ")", "\n", "\n", "two_line_plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "train_df", "[", "\"attacker_cumulative_reward\"", "]", ")", ")", ")", ")", "*", "1", ",", "\n", "train_df", "[", "\"attacker_cumulative_reward\"", "]", ".", "values", ",", "\n", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "train_df", "[", "\"defender_cumulative_reward\"", "]", ")", ")", ")", ")", ",", "\n", "train_df", "[", "\"defender_cumulative_reward\"", "]", ".", "values", ",", "\n", "title", "=", "\"Cumulative Reward (Train)\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Cumulative Reward\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\n", "\"/cumulative_reward_train_attack_defend\"", ",", "\n", "line1_label", "=", "\"Attacker\"", ",", "line2_label", "=", "\"Defender\"", ",", "legend_loc", "=", "\"upper left\"", ")", "\n", "\n", "if", "attack_stats_csv_path", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "attack_stats_df", "=", "read_data", "(", "attack_stats_csv_path", ")", "\n", "plot_hist_prob_attack_stats", "(", "attack_stats_df", ",", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\n", "\"/attack_attempts_hist\"", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "\"could not plot attack stats: {}\"", ".", "format", "(", "str", "(", "e", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.save_image": [[6197, 6213], ["numpy.shape", "matplotlib.figure", "matplotlib.Axes", "plt.Axes.set_axis_off", "plt.figure.add_axes", "plt.Axes.imshow", "matplotlib.savefig", "matplotlib.close"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "", "", "", "def", "save_image", "(", "data", ",", "filename", ")", ":", "\n", "    ", "\"\"\"\n    Utility function for saving an image from a numpy array\n\n    :param data: the image data\n    :param filename: the filename to save it to\n    :return: None\n    \"\"\"", "\n", "sizes", "=", "np", ".", "shape", "(", "data", ")", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "1", ",", "1", ")", ")", "\n", "ax", "=", "plt", ".", "Axes", "(", "fig", ",", "[", "0.", ",", "0.", ",", "1.", ",", "1.", "]", ")", "\n", "ax", ".", "set_axis_off", "(", ")", "\n", "fig", ".", "add_axes", "(", "ax", ")", "\n", "ax", ".", "imshow", "(", "data", ")", "\n", "plt", ".", "savefig", "(", "filename", ",", "dpi", "=", "sizes", "[", "0", "]", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.plot_results": [[6215, 6323], ["plotting_util.simple_line_plot", "plotting_util.simple_line_plot", "plotting_util.simple_line_plot", "plotting_util.simple_line_plot", "plotting_util.probability_plot", "plotting_util.simple_line_plot", "plotting_util.simple_line_plot", "plotting_util.simple_line_plot", "len", "plotting_util.simple_line_plot", "len", "plotting_util.simple_line_plot", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "print", "print", "numpy.array", "list", "list", "list", "list", "list", "list", "list", "numpy.array", "str", "numpy.array", "str", "list", "range", "range", "range", "range", "range", "range", "range", "list", "list", "range", "len", "str", "len", "str", "len", "str", "len", "str", "len", "str", "len", "str", "len", "str", "range", "range", "len", "str", "len", "str", "len", "str"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.simple_line_plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.simple_line_plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.simple_line_plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.simple_line_plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.probability_plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.simple_line_plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.simple_line_plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.simple_line_plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.simple_line_plot", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.plotting_util.simple_line_plot"], ["", "def", "plot_results", "(", "avg_attacker_episode_rewards", ":", "np", ".", "ndarray", "=", "None", ",", "avg_defender_episode_rewards", ":", "np", ".", "ndarray", "=", "None", ",", "\n", "avg_episode_steps", ":", "np", ".", "ndarray", "=", "None", ",", "\n", "epsilon_values", ":", "np", ".", "ndarray", "=", "None", ",", "\n", "hack_probability", ":", "np", ".", "ndarray", "=", "None", ",", "attacker_cumulative_reward", ":", "np", ".", "ndarray", "=", "None", ",", "\n", "defender_cumulative_reward", ":", "np", ".", "ndarray", "=", "None", ",", "avg_episode_loss_attacker", ":", "np", ".", "ndarray", "=", "None", ",", "\n", "avg_episode_loss_defender", ":", "np", ".", "ndarray", "=", "None", ",", "learning_rate_values", ":", "np", ".", "ndarray", "=", "None", ",", "\n", "log_frequency", ":", "int", "=", "None", ",", "\n", "eval_frequency", ":", "int", "=", "None", ",", "eval_log_frequency", ":", "int", "=", "None", ",", "eval_episodes", ":", "int", "=", "None", ",", "\n", "output_dir", ":", "str", "=", "None", ",", "\n", "eval", ":", "bool", "=", "False", ",", "sim", ":", "bool", "=", "False", ",", "random_seed", ":", "int", "=", "0", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Utility function for plotting results of an experiment in the idsgame environment\n\n    :param avg_attacker_episode_rewards: list of average episode rewards recorded every <log_frequency> of attacker\n    :param avg_defender_episode_rewards: list of average episode rewards recorded every <log_frequency> of defender\n    :param avg_episode_steps:  list of average episode steps recorded every <log_frequency>\n    :param epsilon_values: list of epsilon values recorded every <log_frequency>\n    :param hack_probability: list of hack probabilities recorded every <log_frequency>\n    :param attacker_cumulative_reward: list of attacker cumulative rewards recorded every <log_frequency>\n    :param defender_cumulative_reward: list of defender cumulative rewards recorded every <log_frequency>\n    :param avg_episode_loss_attacker: avg episode loss for attacker\n    :param avg_episode_loss_defender: avg episode loss for defender\n    :param learning_rate_values: learning rate values\n    :param log_frequency: frequency that the metrics were recorded\n    :param eval_frequency: frequency of evaluation\n    :param eval_frequency: number of evaluation episodes\n    :param eval_log_frequency: log-frequency of evaluation\n    :param output_dir: base directory to save the plots\n    :param eval: if True save plots with \"eval\" suffix.\n    :param sim: if True save plots with \"sim\" suffix.\n    :param random_seed: the random seed of the experiment\n    :return: None\n    \"\"\"", "\n", "step", "=", "log_frequency", "\n", "suffix", "=", "\"train\"", "\n", "if", "eval", ":", "\n", "        ", "suffix", "=", "\"eval\"", "\n", "step", "=", "eval_frequency", "\n", "", "elif", "sim", ":", "\n", "        ", "suffix", "=", "\"simulation\"", "\n", "", "if", "avg_attacker_episode_rewards", "is", "not", "None", ":", "\n", "        ", "simple_line_plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_attacker_episode_rewards", ")", ")", ")", ")", "*", "step", ",", "avg_attacker_episode_rewards", ",", "\n", "title", "=", "\"Avg Attacker Episodic Returns\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Avg Return\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\n", "\"/avg_attacker_episode_returns_\"", "+", "suffix", ")", "\n", "", "if", "avg_defender_episode_rewards", "is", "not", "None", ":", "\n", "        ", "simple_line_plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_defender_episode_rewards", ")", ")", ")", ")", "*", "step", ",", "avg_defender_episode_rewards", ",", "\n", "title", "=", "\"Avg Defender Episodic Returns\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Avg Return\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\n", "\"/avg_defender_episode_returns_\"", "+", "suffix", ")", "\n", "", "if", "avg_episode_steps", "is", "not", "None", ":", "\n", "        ", "simple_line_plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_steps", ")", ")", ")", ")", "*", "step", ",", "avg_episode_steps", ",", "\n", "title", "=", "\"Avg Episode Lengths\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Avg Length (num steps)\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\n", "\"/avg_episode_lengths_\"", "+", "suffix", ")", "\n", "", "if", "epsilon_values", "is", "not", "None", ":", "\n", "        ", "simple_line_plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "epsilon_values", ")", ")", ")", ")", "*", "step", ",", "epsilon_values", ",", "\n", "title", "=", "\"Exploration rate (Epsilon)\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Epsilon\"", ",", "file_name", "=", "output_dir", "+", "\"/results/plots/\"", "+", "\n", "str", "(", "random_seed", ")", "+", "\"/epsilon_\"", "+", "suffix", ")", "\n", "", "if", "hack_probability", "is", "not", "None", ":", "\n", "        ", "probability_plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "hack_probability", ")", ")", ")", ")", "*", "step", ",", "\n", "hack_probability", ",", "\n", "title", "=", "\"Likelihood of Successful Hack\"", ",", "ylims", "=", "(", "0", ",", "1", ")", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"$\\mathbb{P}[Hacked]$\"", ",", "file_name", "=", "output_dir", "+", "\n", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\n", "\"/hack_probability_\"", "+", "suffix", ")", "\n", "", "if", "attacker_cumulative_reward", "is", "not", "None", ":", "\n", "        ", "simple_line_plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "attacker_cumulative_reward", ")", ")", ")", ")", "*", "step", ",", "attacker_cumulative_reward", ",", "\n", "title", "=", "\"Attacker Cumulative Reward\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Cumulative Reward\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\n", "\"/attacker_cumulative_reward_\"", "+", "suffix", ")", "\n", "", "if", "defender_cumulative_reward", "is", "not", "None", ":", "\n", "        ", "simple_line_plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "defender_cumulative_reward", ")", ")", ")", ")", "*", "step", ",", "\n", "defender_cumulative_reward", ",", "\n", "title", "=", "\"Defender Cumulative Reward\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Cumulative Reward\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\n", "\"/defender_cumulative_reward_\"", "+", "suffix", ")", "\n", "", "if", "avg_episode_loss_attacker", "is", "not", "None", "and", "len", "(", "avg_episode_loss_attacker", ")", ">", "0", ":", "\n", "        ", "try", ":", "\n", "            ", "simple_line_plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_attacker", ")", ")", ")", ")", "*", "step", ",", "\n", "avg_episode_loss_attacker", ",", "\n", "title", "=", "\"Avg Episode Loss (Attacker)\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Loss\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\n", "\"/avg_episode_loss_attacker_\"", "+", "suffix", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "str", "(", "e", ")", ")", "\n", "", "", "if", "avg_episode_loss_defender", "is", "not", "None", "and", "len", "(", "avg_episode_loss_defender", ")", ">", "0", ":", "\n", "        ", "try", ":", "\n", "            ", "simple_line_plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "avg_episode_loss_defender", ")", ")", ")", ")", "*", "step", ",", "\n", "avg_episode_loss_defender", ",", "\n", "title", "=", "\"Avg Episode Loss (Defender)\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Loss\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\n", "\"/avg_episode_loss_defender_\"", "+", "suffix", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "str", "(", "e", ")", ")", "\n", "", "", "if", "learning_rate_values", "is", "not", "None", ":", "\n", "        ", "simple_line_plot", "(", "np", ".", "array", "(", "list", "(", "range", "(", "len", "(", "learning_rate_values", ")", ")", ")", ")", "*", "step", ",", "learning_rate_values", ",", "\n", "title", "=", "\"Learning rate (Eta)\"", ",", "\n", "xlabel", "=", "\"Episode \\#\"", ",", "ylabel", "=", "\"Learning Rate\"", ",", "\n", "file_name", "=", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\"/lr_\"", "+", "suffix", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.create_circle": [[9, 27], ["render_util.create_indexed_vertices", "batch.add_indexed", "len"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.create_indexed_vertices"], ["def", "create_circle", "(", "x", ",", "y", ",", "radius", ",", "batch", ",", "group", ",", "color", ")", ":", "\n", "    ", "\"\"\"\n    Creates a circle that can be rendered in OpenGL batch mode\n\n    :param x: the x-coordinate of the circle center\n    :param y: the y-coordinate of the circle center\n    :param radius: the radius of the circle\n    :param batch: the batch to render the circle in\n    :param group: the group (e.g foreground or background)\n    :param color: the color to fill the circle with\n    :return: None\n    \"\"\"", "\n", "circle", ",", "indices", "=", "create_indexed_vertices", "(", "x", ",", "y", ",", "radius", ")", "\n", "vertex_count", "=", "len", "(", "circle", ")", "//", "2", "\n", "batch", ".", "add_indexed", "(", "vertex_count", ",", "pyglet", ".", "gl", ".", "GL_TRIANGLES", ",", "group", ",", "\n", "indices", ",", "\n", "(", "'v2f'", ",", "circle", ")", ",", "\n", "(", "'c3B'", ",", "color", "*", "vertex_count", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.create_indexed_vertices": [[29, 54], ["range", "vertices.append", "vertices.append", "range", "vertices.append", "vertices.append", "indices.append", "indices.append", "indices.append", "math.cos", "math.sin", "math.cos", "math.sin"], "function", ["None"], ["", "def", "create_indexed_vertices", "(", "x", ",", "y", ",", "radius", ",", "sides", "=", "24", ")", ":", "\n", "    ", "\"\"\"\n    Utility function  that generates a vertex list for rendering a circle with openGL\n\n    :param x: the x coordinate of the circle center\n    :param y: the y coordinate of the circle center\n    :param radius: the radius of the circle\n    :param sides: the number of sides for the circle\n    :return: the vertex list and their indices\n    \"\"\"", "\n", "vertices", "=", "[", "x", ",", "y", "]", "\n", "for", "side", "in", "range", "(", "sides", ")", ":", "\n", "        ", "angle", "=", "side", "*", "2.0", "*", "math", ".", "pi", "/", "sides", "\n", "vertices", ".", "append", "(", "x", "+", "math", ".", "cos", "(", "angle", ")", "*", "radius", ")", "\n", "vertices", ".", "append", "(", "y", "+", "math", ".", "sin", "(", "angle", ")", "*", "radius", ")", "\n", "# Add a degenerated vertex", "\n", "", "vertices", ".", "append", "(", "x", "+", "math", ".", "cos", "(", "0", ")", "*", "radius", ")", "\n", "vertices", ".", "append", "(", "y", "+", "math", ".", "sin", "(", "0", ")", "*", "radius", ")", "\n", "\n", "indices", "=", "[", "]", "\n", "for", "side", "in", "range", "(", "1", ",", "sides", "+", "1", ")", ":", "\n", "        ", "indices", ".", "append", "(", "0", ")", "\n", "indices", ".", "append", "(", "side", ")", "\n", "indices", ".", "append", "(", "side", "+", "1", ")", "\n", "", "return", "vertices", ",", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_line": [[56, 75], ["pyglet.gl.glLineWidth", "pyglet.gl.glLineWidth", "batch.add", "list", "list", "tuple"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add"], ["", "def", "batch_line", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ",", "color", ",", "batch", ",", "group", ",", "line_width", ")", ":", "\n", "    ", "\"\"\"\n    Creates a line that can be rendered in OpenGL batch mode\n\n    :param x1: the starting x coordinate of the line\n    :param y1: the starting y coordinate of the line\n    :param x2: the ending x coordinate of the line\n    :param y2: the ending y coordinate of the line\n    :param color: the color of the line\n    :param batch: the batch to render the line in\n    :param group: the group (e.g foreground or background)\n    :param line_width: the width of the line\n    :return: vertexlist of the created line\n    \"\"\"", "\n", "color_list", "=", "list", "(", "color", ")", "+", "list", "(", "color", ")", "\n", "pyglet", ".", "gl", ".", "glLineWidth", "(", "line_width", ")", "\n", "return", "batch", ".", "add", "(", "2", ",", "pyglet", ".", "gl", ".", "GL_LINES", ",", "group", ",", "\n", "(", "'v2f'", ",", "(", "x1", ",", "y1", ",", "x2", ",", "y2", ")", ")", ",", "\n", "(", "'c3B'", ",", "tuple", "(", "color_list", ")", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_label": [[78, 108], ["pyglet.text.Label", "pyglet.text.Label"], "function", ["None"], ["", "def", "batch_label", "(", "text", ",", "x", ",", "y", ",", "font_size", ",", "color", ",", "batch", ",", "group", ",", "font_name", "=", "'Times New Roman'", ",", "multiline", "=", "False", ",", "\n", "width", "=", "None", ",", "bold", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Creates a text-label that can be rendered in OpenGL batch mode\n\n    :param text: the text of the label\n    :param bold: boolean flag whether to render the text as bold or not\n    :param x: the x coordinate\n    :param y: the y coordinate\n    :param font_size: the font size\n    :param color: the color of the label\n    :param batch: the batch to render the label in\n    :param group: the batch group (e.g. foreground or background)\n    :param font_name: the font type\n    :param multiline: whether it is a multiline label or not\n    :param width: width of the layout\n    :return: a reference to the label object (in case the label has to be updated later on)\n    \"\"\"", "\n", "label", "=", "pyglet", ".", "text", ".", "Label", "(", "text", ",", "\n", "font_name", "=", "font_name", ",", "\n", "font_size", "=", "font_size", ",", "\n", "x", "=", "x", ",", "y", "=", "y", ",", "\n", "anchor_x", "=", "'center'", ",", "anchor_y", "=", "'center'", ",", "\n", "color", "=", "color", ",", "\n", "batch", "=", "batch", ",", "\n", "group", "=", "group", ",", "\n", "multiline", "=", "multiline", ",", "\n", "width", "=", "width", ",", "\n", "bold", "=", "bold", ")", "\n", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_rect_fill": [[110, 132], ["batch.add", "list", "list", "tuple", "list", "list"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add"], ["", "def", "batch_rect_fill", "(", "x", ",", "y", ",", "width", ",", "height", ",", "color", ",", "batch", ",", "group", ")", ":", "\n", "    ", "\"\"\"\n    Method for rendering a filled rectangle in batch mode\n\n    :param x: the x coordinate of the lower-left  corner of the rectangle\n    :param y: the y coordinate of the lower-left  corner of the rectangle\n    :param width: the width of the rectangle\n    :param height: the height of the rectangle\n    :param color: RGB color to fill the rectangle with [R,G,B] scaled between [0,1]\n    :param batch: the batch to render the rectangle with\n    :param group: the batch group (e.g. foreground or background)\n    :return: None\n    \"\"\"", "\n", "color_list", "=", "list", "(", "color", ")", "+", "list", "(", "color", ")", "+", "list", "(", "color", ")", "+", "list", "(", "color", ")", "\n", "# Renders a \"quad\" (i.e. a shape with four sides, such as a rectangle).", "\n", "# 4 is the number of vertices (the four corners of the Quad)", "\n", "# \"v2i\" is the vertex format, which is 2 integers", "\n", "# the tuple list specifies four vertices (8 numbers)", "\n", "# \"c3B\" is the format of the color, which means RGB format 0-255", "\n", "# the color list is a list of 4*3 with a RGB color for each side of the quad", "\n", "batch", ".", "add", "(", "4", ",", "pyglet", ".", "gl", ".", "GL_QUADS", ",", "group", ",", "(", "'v2i'", ",", "(", "x", ",", "y", ",", "x", "+", "width", ",", "y", ",", "x", "+", "width", ",", "y", "+", "height", ",", "x", ",", "y", "+", "height", ")", ")", ",", "\n", "(", "'c3B'", ",", "tuple", "(", "color_list", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_rect_border": [[134, 165], ["batch.add", "batch.add", "list", "list", "tuple", "tuple", "list", "list"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add"], ["", "def", "batch_rect_border", "(", "x", ",", "y", ",", "width", ",", "height", ",", "color", ",", "batch", ",", "group", ")", ":", "\n", "    ", "\"\"\"\n    Method for rendering a the border of a rectangle in batch mode\n\n    :param x: the x coordinate of the lower-left  corner of the rectangle\n    :param y: the y coordinate of the lower-left  corner of the rectangle\n    :param width: the width of the rectangle\n    :param height: the height of the rectangle\n    :param color: RGB color to fill the rectangle with [R,G,B] scaled between [0,1]\n    :param batch: the batch to render the rectangle with\n    :param group: the batch group (e.g. foreground or background)\n    :return: None\n    \"\"\"", "\n", "\n", "color_list", "=", "list", "(", "color", ")", "+", "list", "(", "color", ")", "+", "list", "(", "color", ")", "+", "list", "(", "color", ")", "\n", "# Renders the lines of a rectangle", "\n", "# 4 is the number of vertices (the four corners of the rectangle)", "\n", "# \"v2i\" is the vertex format, which is 2 integers", "\n", "# the tuple list specifies four vertices (8 numbers)", "\n", "# \"c3B\" is the format of the color, which means RGB format 0-255", "\n", "# the color list is a list of 4*3 with a RGB color for each side of the quad", "\n", "\n", "# Draw vertical lines (x,y)-->(x,y+height) and (x+width, y)-->(x+width, y+height)", "\n", "batch", ".", "add", "(", "4", ",", "pyglet", ".", "gl", ".", "GL_LINES", ",", "group", ",", "\n", "(", "'v2f'", ",", "(", "x", ",", "y", ",", "x", ",", "y", "+", "height", ",", "x", "+", "width", ",", "y", "+", "height", ",", "x", "+", "width", ",", "y", ")", ")", ",", "\n", "(", "'c3B'", ",", "tuple", "(", "color_list", ")", ")", ")", "\n", "\n", "# Draw Horizontal lines (x,y)-->(x+width,y) and (x, y+height)-->(x+width, y+height)", "\n", "batch", ".", "add", "(", "4", ",", "pyglet", ".", "gl", ".", "GL_LINES", ",", "group", ",", "\n", "(", "'v2i'", ",", "(", "x", ",", "y", ",", "x", "+", "width", ",", "y", ",", "x", ",", "y", "+", "height", ",", "x", "+", "width", ",", "y", "+", "height", ")", ")", ",", "\n", "(", "'c3B'", ",", "tuple", "(", "color_list", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.draw_and_fill_rect": [[167, 179], ["render_util.__rect"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.__rect"], ["", "def", "draw_and_fill_rect", "(", "x", ",", "y", ",", "width", ",", "height", ",", "color", ")", ":", "\n", "    ", "\"\"\"\n    Draws and fills a rectangle\n\n    :param x: the x coordinate of the lower-left  corner of the rectangle\n    :param y: the y coordinate of the lower-left  corner of the rectangle\n    :param width: the width of the rectangle\n    :param height: the height of the rectangle\n    :param color: RGB color to fill the rectangle with [R,G,B] scaled between [0,1]\n    :return: None\n    \"\"\"", "\n", "__rect", "(", "x", ",", "y", ",", "width", ",", "height", ",", "color", ",", "fill", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.draw_rect_border": [[181, 193], ["render_util.__rect"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.__rect"], ["", "def", "draw_rect_border", "(", "x", ",", "y", ",", "width", ",", "height", ",", "color", ")", ":", "\n", "    ", "\"\"\"\n    Draws a rectangle with a border\n\n    :param x: the x coordinate of the lower-left  corner of the rectangle\n    :param y: the y coordinate of the lower-left  corner of the rectangle\n    :param width: the width of the rectangle\n    :param height: the height of the rectangle\n    :param color: RGB color of the border [R,G,B] scaled between [0,1]\n    :return: None\n    \"\"\"", "\n", "__rect", "(", "x", ",", "y", ",", "width", ",", "height", ",", "color", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.__rect": [[195, 223], ["pyglet.glColor3f", "pyglet.glPolygonMode", "render_util.__rect_vertices", "pyglet.glEnd", "pyglet.glBegin", "pyglet.glBegin"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.__rect_vertices"], ["", "def", "__rect", "(", "x", ",", "y", ",", "width", ",", "height", ",", "color", ",", "fill", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Draws a rectangle\n\n    :param x: the x coordinate of the lower-left  corner of the rectangle\n    :param y: the y coordinate of the lower-left  corner of the rectangle\n    :param width: the width of the rectangle\n    :param height: the height of the rectangle\n    :param color: RGB color of the rectangle [R,G,B] scaled between [0,1]\n    :param fill: whether to fill the rectangle or just stroke it\n    :return: None\n    \"\"\"", "\n", "# Set the color in the OpenGL Context (State)", "\n", "gl", ".", "glColor3f", "(", "color", "[", "0", "]", ",", "color", "[", "1", "]", ",", "color", "[", "2", "]", ")", "\n", "gl", ".", "glPolygonMode", "(", "gl", ".", "GL_FRONT_AND_BACK", ",", "gl", ".", "GL_FILL", ")", "\n", "# Configure rectangle (fill or not)", "\n", "if", "fill", ":", "\n", "# Delimits the vertices of a primitive or group of primitives", "\n", "        ", "gl", ".", "glBegin", "(", "gl", ".", "GL_POLYGON", ")", "\n", "\n", "", "else", ":", "\n", "# Delimits the vertices of a primitive or group of primitives", "\n", "        ", "gl", ".", "glBegin", "(", "gl", ".", "GL_LINES", ")", "\n", "\n", "# Draw the vertices of the rectangle", "\n", "", "__rect_vertices", "(", "x", ",", "y", ",", "width", ",", "height", ")", "\n", "# Delimits the vertices of a primitive or group of primitives", "\n", "gl", ".", "glEnd", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.__rect_vertices": [[225, 243], ["pyglet.glVertex2f", "pyglet.glVertex2f", "pyglet.glVertex2f", "pyglet.glVertex2f", "pyglet.glVertex2f", "pyglet.glVertex2f", "pyglet.glVertex2f", "pyglet.glVertex2f"], "function", ["None"], ["", "def", "__rect_vertices", "(", "x", ",", "y", ",", "width", ",", "height", ")", ":", "\n", "    ", "\"\"\"\n    Uses the OpenGL API to create vertices to form a rectangle of a primitive\n\n    :param x: the x coordinate of the lower-left  corner of the rectangle\n    :param y: the y coordinate of the lower-left  corner of the rectangle\n    :param width: the width of the rectangle\n    :param height: the height of the rectangle\n    :return: None\n    \"\"\"", "\n", "gl", ".", "glVertex2f", "(", "x", ",", "y", ")", "# coordinate A", "\n", "gl", ".", "glVertex2f", "(", "x", ",", "y", "+", "height", ")", "# coordinate B and line AB", "\n", "gl", ".", "glVertex2f", "(", "x", ",", "y", "+", "height", ")", "# coordinate B", "\n", "gl", ".", "glVertex2f", "(", "x", "+", "width", ",", "y", "+", "height", ")", "# coordinate C and line BC", "\n", "gl", ".", "glVertex2f", "(", "x", "+", "width", ",", "y", "+", "height", ")", "# coordinate C", "\n", "gl", ".", "glVertex2f", "(", "x", "+", "width", ",", "y", ")", "# coordinate D and line CD", "\n", "gl", ".", "glVertex2f", "(", "x", "+", "width", ",", "y", ")", "# coordinate D", "\n", "gl", ".", "glVertex2f", "(", "x", ",", "y", ")", "# coordinate A and line DA", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_defense_id_legal": [[31, 54], ["idsgame_util.interpret_defense_action"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.interpret_defense_action"], ["def", "is_defense_id_legal", "(", "defense_id", ":", "int", ",", "game_config", ",", "state", ")", "->", "bool", ":", "\n", "    ", "\"\"\"\n    Check if a given defense is legal or not.\n\n    :param defense_id: the defense to verify\n    :param game_config: the game config\n    :param state: the game state\n    :return: True if legal otherwise False\n    \"\"\"", "\n", "server_id", ",", "server_pos", ",", "defense_type", "=", "interpret_defense_action", "(", "defense_id", ",", "game_config", ")", "\n", "\n", "# if defense_type < game_config.num_attack_types:", "\n", "#     if state.defense_values[server_id][defense_type] >= game_config.max_value:", "\n", "#         return False", "\n", "\n", "# if defense_type >= game_config.num_attack_types:", "\n", "#     if state.defense_det[server_id] >= game_config.max_value:", "\n", "#         return False", "\n", "\n", "if", "(", "game_config", ".", "network_config", ".", "node_list", "[", "server_id", "]", "==", "NodeType", ".", "SERVER", ".", "value", "\n", "or", "game_config", ".", "network_config", ".", "node_list", "[", "server_id", "]", "==", "NodeType", ".", "DATA", ".", "value", ")", ":", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_attack_legal": [[105, 129], ["int"], "function", ["None"], ["", "def", "is_attack_legal", "(", "target_pos", ":", "Union", "[", "int", ",", "int", "]", ",", "attacker_pos", ":", "Union", "[", "int", ",", "int", "]", ",", "network_config", ",", "\n", "past_positions", ":", "List", "[", "int", "]", "=", "None", ")", "->", "bool", ":", "\n", "    ", "\"\"\"\n    Checks whether an attack is legal. That is, can the attacker reach the target node from its current\n    position in 1 step given the network configuration?\n\n    :param attacker_pos: the position of the attacker\n    :param target_pos: the position of the target node\n    :param network_config: the network configuration\n    :param past_positions: if not None, used to check whether the agent is in a periodic policy, e.g. a circle.\n    :return: True if the attack is legal, otherwise False\n    \"\"\"", "\n", "if", "target_pos", "==", "attacker_pos", ":", "\n", "        ", "return", "False", "\n", "", "target_row", ",", "target_col", "=", "target_pos", "\n", "attacker_row", ",", "attacker_col", "=", "attacker_pos", "\n", "if", "target_row", ">", "attacker_row", ":", "\n", "        ", "return", "False", "\n", "# if past_positions is not None and len(past_positions) >=2:", "\n", "#     if target_pos in past_positions[-3:]:", "\n", "#         return False", "\n", "", "attacker_adjacency_matrix_id", "=", "attacker_row", "*", "network_config", ".", "num_cols", "+", "attacker_col", "\n", "target_adjacency_matrix_id", "=", "target_row", "*", "network_config", ".", "num_cols", "+", "target_col", "\n", "return", "network_config", ".", "adjacency_matrix", "[", "attacker_adjacency_matrix_id", "]", "[", "target_adjacency_matrix_id", "]", "==", "int", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_node_attack_legal": [[82, 92], ["network_config.get_node_pos", "int"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_pos"], ["", "def", "is_node_attack_legal", "(", "target_node", ":", "int", ",", "attacker_pos", ":", "Union", "[", "int", ",", "int", "]", ",", "network_config", ")", "->", "bool", ":", "\n", "    ", "target_pos", "=", "network_config", ".", "get_node_pos", "(", "target_node", ")", "\n", "\n", "target_row", ",", "target_col", "=", "target_pos", "\n", "attacker_row", ",", "attacker_col", "=", "attacker_pos", "\n", "\n", "attacker_adjacency_matrix_id", "=", "attacker_row", "*", "network_config", ".", "num_cols", "+", "attacker_col", "\n", "target_adjacency_matrix_id", "=", "target_row", "*", "network_config", ".", "num_cols", "+", "target_col", "\n", "\n", "return", "network_config", ".", "adjacency_matrix", "[", "attacker_adjacency_matrix_id", "]", "[", "target_adjacency_matrix_id", "]", "==", "int", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_node_defense_legal": [[94, 104], ["range", "len"], "function", ["None"], ["", "def", "is_node_defense_legal", "(", "target_node", ":", "int", ",", "network_config", ",", "state", ",", "max_value", ":", "int", ")", "->", "bool", ":", "\n", "    ", "if", "(", "network_config", ".", "node_list", "[", "target_node", "]", "==", "NodeType", ".", "SERVER", ".", "value", "\n", "or", "network_config", ".", "node_list", "[", "target_node", "]", "==", "NodeType", ".", "DATA", ".", "value", ")", ":", "\n", "        ", "if", "state", ".", "defense_det", "[", "target_node", "]", "<", "max_value", ":", "\n", "            ", "return", "True", "\n", "", "for", "i", "in", "range", "(", "len", "(", "state", ".", "defense_values", "[", "target_node", "]", ")", ")", ":", "\n", "            ", "if", "state", ".", "defense_values", "[", "target_node", "]", "[", "i", "]", "<", "max_value", ":", "\n", "                ", "return", "True", "\n", "", "", "return", "False", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_attack_id_legal": [[131, 154], ["idsgame_util.interpret_attack_action", "idsgame_util.is_attack_legal"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.interpret_attack_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal"], ["", "def", "is_attack_id_legal", "(", "attack_id", ":", "int", ",", "game_config", ",", "attacker_pos", ":", "Union", "[", "int", ",", "int", "]", ",", "game_state", ",", "\n", "past_positions", ":", "List", "[", "int", "]", "=", "None", ",", "past_reconnaissance_activities", ":", "List", "=", "None", ")", "->", "bool", ":", "\n", "    ", "\"\"\"\n    Check if a given attack is legal or not.\n\n    :param attack_id: the attack to verify\n    :param game_config: game configuration\n    :param attacker_pos: the current position of the attacker\n    :param game_state: the game state\n    :param past_positions: if not None, used to check whether the agent is in a periodic policy, e.g. a circle.\n    :return: True if legal otherwise False\n    \"\"\"", "\n", "server_id", ",", "server_pos", ",", "attack_type", ",", "reconnaissance", "=", "interpret_attack_action", "(", "attack_id", ",", "game_config", ")", "\n", "if", "not", "reconnaissance", ":", "\n", "        ", "if", "game_state", ".", "attack_values", "[", "server_id", "]", "[", "attack_type", "]", ">=", "game_config", ".", "max_value", ":", "\n", "            ", "return", "False", "\n", "# if reconnaissance and past_reconnaissance_activities is not None:", "\n", "#     for rec_act in past_reconnaissance_activities[-5:]:", "\n", "#         node_id, rec_type = rec_act", "\n", "#         if node_id == server_id and rec_type == attack_type:", "\n", "#             #print(\"illegal rec type, past:{}\".format(past_reconnaissance_activities))", "\n", "#             return False", "\n", "", "", "return", "is_attack_legal", "(", "server_pos", ",", "attacker_pos", ",", "game_config", ".", "network_config", ",", "past_positions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.interpret_attack_action": [[156, 177], ["game_config.network_config.get_node_pos", "idsgame_util.get_attack_type"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_pos", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.get_attack_type"], ["", "def", "interpret_attack_action", "(", "action", ":", "int", ",", "game_config", ")", "->", "Union", "[", "int", ",", "Union", "[", "int", ",", "int", "]", ",", "int", ",", "bool", "]", ":", "\n", "    ", "\"\"\"\n    Utility method for interpreting the given attack action, converting it into server_id,pos,type\n\n    :param action: the attack action-id\n    :param game_config: game configuration\n    :return: server-id, server-position, attack-type\n    \"\"\"", "\n", "if", "not", "game_config", ".", "reconnaissance_actions", ":", "\n", "        ", "server_id", "=", "action", "//", "game_config", ".", "num_attack_types", "\n", "", "else", ":", "\n", "        ", "server_id", "=", "action", "//", "(", "game_config", ".", "num_attack_types", "+", "1", ")", "\n", "#server_id = action // (game_config.num_attack_types*2)", "\n", "\n", "", "server_pos", "=", "game_config", ".", "network_config", ".", "get_node_pos", "(", "server_id", ")", "\n", "attack_type", "=", "get_attack_type", "(", "action", ",", "game_config", ")", "\n", "reconnaissance", "=", "attack_type", ">=", "game_config", ".", "num_attack_types", "\n", "if", "reconnaissance", ":", "\n", "        ", "attack_type", "=", "attack_type", "-", "game_config", ".", "num_attack_types", "\n", "#print(\"server:{},pos:{},a_type:{},rec:{}\".format(server_id, server_pos, attack_type, reconnaissance))", "\n", "", "return", "server_id", ",", "server_pos", ",", "attack_type", ",", "reconnaissance", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.interpret_defense_action": [[178, 190], ["game_config.network_config.get_node_pos", "idsgame_util.get_defense_type"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_pos", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.get_defense_type"], ["", "def", "interpret_defense_action", "(", "action", ":", "int", ",", "game_config", ")", "->", "Union", "[", "int", ",", "Union", "[", "int", ",", "int", "]", ",", "int", "]", ":", "\n", "    ", "\"\"\"\n    Utility method for interpreting the given action, converting it into server_id,pos,type\n\n    :param action: the attack action-id\n    :param game_config: game configuration\n    :return: server-id, server-position, attack-type\n    \"\"\"", "\n", "server_id", "=", "action", "//", "(", "game_config", ".", "num_attack_types", "+", "1", ")", "# +1 for detection type attack", "\n", "server_pos", "=", "game_config", ".", "network_config", ".", "get_node_pos", "(", "server_id", ")", "\n", "defense_type", "=", "get_defense_type", "(", "action", ",", "game_config", ")", "\n", "return", "server_id", ",", "server_pos", ",", "defense_type", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.get_attack_action_id": [[192, 206], ["None"], "function", ["None"], ["", "def", "get_attack_action_id", "(", "server_id", ",", "attack_type", ",", "game_config", ")", ":", "\n", "    ", "\"\"\"\n    Gets the attack action id from a given server position, attack_type, and game config\n\n    :param server_id: id of the server\n    :param attack_type: attack type\n    :param game_config: game config\n    :return: attack id\n    \"\"\"", "\n", "if", "not", "game_config", ".", "reconnaissance_actions", ":", "\n", "        ", "action_id", "=", "server_id", "*", "game_config", ".", "num_attack_types", "+", "attack_type", "\n", "", "else", ":", "\n", "        ", "action_id", "=", "server_id", "*", "(", "game_config", ".", "num_attack_types", "+", "1", ")", "+", "attack_type", "\n", "", "return", "action_id", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.get_defense_action_id": [[208, 219], ["None"], "function", ["None"], ["", "def", "get_defense_action_id", "(", "server_id", ",", "defense_type", ",", "game_config", ")", ":", "\n", "    ", "\"\"\"\n    Gets the defense action id from a given server position, defense_type, and game config\n\n    :param server_id: id of the server\n    :param defense_type: defense type\n    :param game_config: game config\n    :return: attack id\n    \"\"\"", "\n", "action_id", "=", "server_id", "*", "(", "game_config", ".", "num_attack_types", "+", "1", ")", "+", "defense_type", "\n", "return", "action_id", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.get_attack_type": [[221, 234], ["None"], "function", ["None"], ["", "def", "get_attack_type", "(", "action", ":", "int", ",", "game_config", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Utility method for getting the attack type of action-id\n\n    :param action: action-id\n  :param game_config: game configuration\n      :return: action type\n    \"\"\"", "\n", "if", "not", "game_config", ".", "reconnaissance_actions", ":", "\n", "        ", "attack_defense_type", "=", "action", "%", "game_config", ".", "num_attack_types", "\n", "", "else", ":", "\n", "        ", "attack_defense_type", "=", "action", "%", "(", "game_config", ".", "num_attack_types", "+", "1", ")", "\n", "", "return", "attack_defense_type", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.get_defense_type": [[236, 246], ["None"], "function", ["None"], ["", "def", "get_defense_type", "(", "action", ":", "int", ",", "game_config", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    Utility method for getting the defense type of action-id\n\n    :param action: action-id\n    :param game_config: game configuration\n    :return: action type\n    \"\"\"", "\n", "defense_type", "=", "action", "%", "(", "game_config", ".", "num_attack_types", "+", "1", ")", "# +1 for detection", "\n", "return", "defense_type", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.get_img_from_fig": [[248, 265], ["io.BytesIO", "fig.savefig", "io.BytesIO.seek", "numpy.frombuffer", "io.BytesIO.close", "cv2.imdecode", "cv2.cvtColor", "io.BytesIO.getvalue"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "get_img_from_fig", "(", "fig", ",", "dpi", "=", "180", ")", ":", "\n", "    ", "\"\"\"\n    Convert matplotlib fig to numpy array\n\n    :param fig: fig to convert\n    :param dpi: dpi of conversion\n    :return: np array of the image\n    \"\"\"", "\n", "buf", "=", "io", ".", "BytesIO", "(", ")", "\n", "fig", ".", "savefig", "(", "buf", ",", "format", "=", "\"png\"", ",", "dpi", "=", "dpi", ")", "\n", "buf", ".", "seek", "(", "0", ")", "\n", "img_arr", "=", "np", ".", "frombuffer", "(", "buf", ".", "getvalue", "(", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "buf", ".", "close", "(", ")", "\n", "img", "=", "cv2", ".", "imdecode", "(", "img_arr", ",", "1", ")", "\n", "img", "=", "cv2", ".", "cvtColor", "(", "img", ",", "cv2", ".", "COLOR_BGR2RGB", ")", "\n", "\n", "return", "img", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.action_dist_hist": [[266, 317], ["matplotlib.rc", "matplotlib.rc", "matplotlib.subplots", "seaborn.distplot", "ax.set_xlim", "ax.set_xticks", "ax.set_title", "ax.set_xlabel", "ax.set_ylabel", "ax.grid", "ax.xaxis.get_label", "ax.yaxis.get_label", "ax.xaxis.get_label.set_size", "ax.yaxis.get_label.set_size", "ax.spines[].set_color", "ax.spines[].set_color", "fig.tight_layout", "fig.savefig", "fig.savefig", "idsgame_util.get_img_from_fig", "matplotlib.close", "list", "min", "max", "range"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.get_img_from_fig", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "action_dist_hist", "(", "data", ":", "np", ".", "ndarray", ",", "\n", "title", ":", "str", "=", "\"Test\"", ",", "xlabel", ":", "str", "=", "\"test\"", ",", "ylabel", ":", "str", "=", "\"test\"", ",", "\n", "file_name", ":", "str", "=", "\"test.eps\"", ",", "xlims", ":", "Union", "[", "float", ",", "float", "]", "=", "None", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Plot a distribution of the policy\n\n    :param data: the data to plot\n    :param title: title of the plot\n    :param xlabel: xlabel\n    :param ylabel: ylabel\n    :param file_name: path where to save file\n    :param xlims: xlimits (optional)\n    :return: numpy array of the figure\n    \"\"\"", "\n", "plt", ".", "rc", "(", "'text'", ",", "usetex", "=", "True", ")", "\n", "plt", ".", "rc", "(", "'text.latex'", ",", "preamble", "=", "r'\\usepackage{amsfonts}'", ")", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "1", ",", "figsize", "=", "(", "8", ",", "3", ")", ")", "\n", "if", "xlims", "is", "None", ":", "\n", "        ", "xlims", "=", "(", "min", "(", "data", ")", ",", "\n", "max", "(", "data", ")", ")", "\n", "\n", "", "sns", ".", "distplot", "(", "data", ",", "kde", "=", "True", ",", "\n", "color", "=", "'darkblue'", ",", "\n", "hist_kws", "=", "{", "'edgecolor'", ":", "'black'", "}", ",", "\n", "kde_kws", "=", "{", "'linewidth'", ":", "0.5", "}", ",", "bins", "=", "xlims", "[", "1", "]", ",", "fit", "=", "None", ")", "\n", "\n", "ax", ".", "set_xlim", "(", "xlims", ")", "\n", "ax", ".", "set_xticks", "(", "list", "(", "range", "(", "xlims", "[", "1", "]", "+", "1", ")", ")", ")", "\n", "\n", "ax", ".", "set_title", "(", "title", ")", "\n", "ax", ".", "set_xlabel", "(", "xlabel", ")", "\n", "ax", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# set the grid on", "\n", "ax", ".", "grid", "(", "'on'", ")", "\n", "\n", "# tweak the axis labels", "\n", "xlab", "=", "ax", ".", "xaxis", ".", "get_label", "(", ")", "\n", "ylab", "=", "ax", ".", "yaxis", ".", "get_label", "(", ")", "\n", "xlab", ".", "set_size", "(", "10", ")", "\n", "ylab", ".", "set_size", "(", "10", ")", "\n", "\n", "# change the color of the top and right spines to opaque gray", "\n", "ax", ".", "spines", "[", "'right'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "ax", ".", "spines", "[", "'top'", "]", ".", "set_color", "(", "(", ".8", ",", ".8", ",", ".8", ")", ")", "\n", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".png\"", ",", "format", "=", "\"png\"", ",", "dpi", "=", "600", ")", "\n", "fig", ".", "savefig", "(", "file_name", "+", "\".pdf\"", ",", "format", "=", "'pdf'", ",", "dpi", "=", "600", ",", "bbox_inches", "=", "'tight'", ",", "transparent", "=", "True", ")", "\n", "data", "=", "get_img_from_fig", "(", "fig", ",", "dpi", "=", "100", ")", "\n", "plt", ".", "close", "(", "fig", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.defense_score": [[319, 335], ["range", "float", "range", "network_config.get_node_id", "numpy.min"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_id"], ["", "def", "defense_score", "(", "game_sate", ",", "network_config", ",", "game_config", ")", ":", "\n", "    ", "total_min_def", "=", "0", "\n", "for", "row", "in", "range", "(", "network_config", ".", "num_rows", ")", ":", "\n", "        ", "min_def", "=", "float", "(", "\"inf\"", ")", "\n", "for", "col", "in", "range", "(", "network_config", ".", "num_cols", ")", ":", "\n", "            ", "node_id", "=", "network_config", ".", "get_node_id", "(", "(", "row", ",", "col", ")", ")", "\n", "if", "(", "game_config", ".", "network_config", ".", "node_list", "[", "node_id", "]", "==", "NodeType", ".", "SERVER", ".", "value", "\n", "or", "game_config", ".", "network_config", ".", "node_list", "[", "node_id", "]", "==", "NodeType", ".", "DATA", ".", "value", ")", ":", "\n", "                ", "d", "=", "np", ".", "min", "(", "game_sate", ".", "defense_values", "[", "node_id", "]", ")", "\n", "if", "d", "<", "min_def", ":", "\n", "                    ", "min_def", "=", "d", "\n", "#print(\"row:{}, col:{}, node_id:{}, type:{}, min_def:{}\".format(row, col, node_id, game_config.network_config.node_list[node_id], min_def))", "\n", "", "", "", "total_min_def", "=", "total_min_def", "+", "min_def", "\n", "if", "min_def", "<", "game_config", ".", "max_value", ":", "\n", "            ", "return", "total_min_def", "\n", "", "", "return", "total_min_def", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.dqn.get_script_path": [[9, 14], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.dqn.default_output_dir": [[16, 22], ["dqn.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.hello_world.attack_against_baseline_defense_env": [[4, 15], ["range", "gym.make", "str", "gym.make.attacker_action_space.sample", "gym.make.step"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step"], ["def", "attack_against_baseline_defense_env", "(", ")", ":", "\n", "    ", "versions", "=", "range", "(", "0", ",", "20", ")", "\n", "version", "=", "versions", "[", "0", "]", "\n", "env_name", "=", "\"idsgame-minimal_defense-v\"", "+", "str", "(", "version", ")", "\n", "env", "=", "gym", ".", "make", "(", "env_name", ")", "\n", "done", "=", "False", "\n", "while", "not", "done", ":", "\n", "        ", "attack_action", "=", "env", ".", "attacker_action_space", ".", "sample", "(", ")", "\n", "defense_action", "=", "None", "\n", "a", "=", "(", "attack_action", ",", "defense_action", ")", "\n", "obs", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.hello_world.attack_against_random_defense_env": [[17, 28], ["range", "gym.make", "str", "gym.make.attacker_action_space.sample", "gym.make.step"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step"], ["", "", "def", "attack_against_random_defense_env", "(", ")", ":", "\n", "    ", "versions", "=", "range", "(", "0", ",", "20", ")", "\n", "version", "=", "versions", "[", "0", "]", "\n", "env_name", "=", "\"idsgame-random_defense-v\"", "+", "str", "(", "version", ")", "\n", "env", "=", "gym", ".", "make", "(", "env_name", ")", "\n", "done", "=", "False", "\n", "while", "not", "done", ":", "\n", "        ", "attack_action", "=", "env", ".", "attacker_action_space", ".", "sample", "(", ")", "\n", "defense_action", "=", "None", "\n", "a", "=", "(", "attack_action", ",", "defense_action", ")", "\n", "obs", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.hello_world.defense_against_baseline_attack_env": [[29, 40], ["range", "gym.make", "str", "gym.make.defender_action_space.sample", "gym.make.step"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step"], ["", "", "def", "defense_against_baseline_attack_env", "(", ")", ":", "\n", "    ", "versions", "=", "range", "(", "0", ",", "20", ")", "\n", "version", "=", "versions", "[", "0", "]", "\n", "env_name", "=", "\"idsgame-maximal_attack-v\"", "+", "str", "(", "version", ")", "\n", "env", "=", "gym", ".", "make", "(", "env_name", ")", "\n", "done", "=", "False", "\n", "while", "not", "done", ":", "\n", "        ", "attack_action", "=", "None", "\n", "defense_action", "=", "env", ".", "defender_action_space", ".", "sample", "(", ")", "\n", "a", "=", "(", "attack_action", ",", "defense_action", ")", "\n", "obs", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.hello_world.defense_against_random_attack_env": [[42, 53], ["range", "gym.make", "str", "gym.make.defender_action_space.sample", "gym.make.step"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step"], ["", "", "def", "defense_against_random_attack_env", "(", ")", ":", "\n", "    ", "versions", "=", "range", "(", "0", ",", "20", ")", "\n", "version", "=", "versions", "[", "0", "]", "\n", "env_name", "=", "\"idsgame-random_attack-v\"", "+", "str", "(", "version", ")", "\n", "env", "=", "gym", ".", "make", "(", "env_name", ")", "\n", "done", "=", "False", "\n", "while", "not", "done", ":", "\n", "        ", "attack_action", "=", "None", "\n", "defense_action", "=", "env", ".", "defender_action_space", ".", "sample", "(", ")", "\n", "a", "=", "(", "attack_action", ",", "defense_action", ")", "\n", "obs", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.hello_world.two_agents_env": [[54, 65], ["range", "gym.make", "str", "gym.make.attacker_action_space.sample", "gym.make.defender_action_space.sample", "gym.make.step"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step"], ["", "", "def", "two_agents_env", "(", ")", ":", "\n", "    ", "versions", "=", "range", "(", "0", ",", "20", ")", "\n", "version", "=", "versions", "[", "0", "]", "\n", "env_name", "=", "\"idsgame-v\"", "+", "str", "(", "version", ")", "\n", "env", "=", "gym", ".", "make", "(", "env_name", ")", "\n", "done", "=", "False", "\n", "while", "not", "done", ":", "\n", "        ", "attack_action", "=", "env", ".", "attacker_action_space", ".", "sample", "(", ")", "\n", "defense_action", "=", "env", ".", "defender_action_space", ".", "sample", "(", ")", "\n", "a", "=", "(", "attack_action", ",", "defense_action", ")", "\n", "obs", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.hello_world.main": [[66, 69], ["hello_world.attack_against_random_defense_env"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.hello_world.attack_against_random_defense_env"], ["", "", "def", "main", "(", ")", ":", "\n", "#attack_against_baseline_defense_env()", "\n", "    ", "attack_against_random_defense_env", "(", ")", "\n", "#defense_against_baseline_attack_env()", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.tabular_q_learning.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.tabular_q_learning.default_output_dir": [[15, 21], ["tabular_q_learning.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.manual_play.get_script_path": [[6, 11], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.manual_play.default_output_dir": [[13, 19], ["manual_play.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.reinforce.get_script_path": [[8, 13], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.reinforce.default_output_dir": [[15, 21], ["reinforce.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path": [[9, 14], ["os.path.dirname", "os.path.realpath"], "function", ["None"], ["def", "get_script_path", "(", ")", ":", "\n", "    ", "\"\"\"\n    :return: the script path\n    \"\"\"", "\n", "return", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.default_output_dir": [[15, 21], ["ppo.get_script_path"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.examples.ppo.get_script_path"], ["", "def", "default_output_dir", "(", ")", "->", "str", ":", "\n", "    ", "\"\"\"\n    :return: the default output dir\n    \"\"\"", "\n", "script_dir", "=", "get_script_path", "(", ")", "\n", "return", "script_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_game_state.TestGameStateSuite.test_initialization": [[14, 16], ["gym_idsgame.envs.dao.game_state.GameState"], "methods", ["None"], ["def", "test_initialization", "(", "self", ")", ":", "\n", "        ", "GameState", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_game_state.TestGameStateSuite.test_default_state": [[17, 34], ["gym_idsgame.envs.dao.game_state.GameState", "gym_idsgame.envs.dao.network_config.NetworkConfig", "len", "gym_idsgame.envs.dao.game_state.GameState.default_state", "list", "range"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.default_state"], ["", "def", "test_default_state", "(", "self", ")", ":", "\n", "        ", "state", "=", "GameState", "(", ")", "\n", "rows", "=", "4", "\n", "cols", "=", "4", "\n", "network_config", "=", "NetworkConfig", "(", "rows", ",", "cols", ")", "\n", "num_nodes", "=", "len", "(", "network_config", ".", "node_list", ")", "\n", "num_attack_types", "=", "10", "\n", "state", ".", "default_state", "(", "list", "(", "range", "(", "num_nodes", ")", ")", ",", "(", "3", ",", "1", ")", ",", "num_attack_types", ",", "network_config", ")", "\n", "assert", "state", ".", "attack_values", ".", "shape", "==", "(", "num_nodes", ",", "10", ")", "\n", "assert", "state", ".", "defense_values", ".", "shape", "==", "(", "num_nodes", ",", "10", ")", "\n", "assert", "state", ".", "defense_det", ".", "shape", "==", "(", "num_nodes", ",", ")", "\n", "assert", "state", ".", "attacker_pos", "==", "(", "3", ",", "1", ")", "\n", "assert", "state", ".", "done", "==", "False", "\n", "assert", "state", ".", "hacked", "==", "False", "\n", "assert", "state", ".", "num_hacks", "==", "0", "\n", "assert", "state", ".", "detected", "==", "False", "\n", "assert", "state", ".", "num_games", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_game_state.TestGameStateSuite.test_copy": [[35, 48], ["gym_idsgame.envs.dao.game_state.GameState", "gym_idsgame.envs.dao.network_config.NetworkConfig", "len", "gym_idsgame.envs.dao.game_state.GameState.default_state", "gym_idsgame.envs.dao.game_state.GameState.copy", "numpy.array_equal", "numpy.array_equal", "numpy.array_equal", "list", "range"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.default_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy"], ["", "def", "test_copy", "(", "self", ")", ":", "\n", "        ", "state", "=", "GameState", "(", ")", "\n", "num_attack_types", "=", "10", "\n", "rows", "=", "4", "\n", "cols", "=", "4", "\n", "network_config", "=", "NetworkConfig", "(", "rows", ",", "cols", ")", "\n", "num_nodes", "=", "len", "(", "network_config", ".", "node_list", ")", "\n", "state", ".", "default_state", "(", "list", "(", "range", "(", "num_nodes", ")", ")", ",", "(", "3", ",", "1", ")", ",", "num_attack_types", ",", "network_config", ")", "\n", "copy", "=", "state", ".", "copy", "(", ")", "\n", "assert", "copy", ".", "num_hacks", "==", "state", ".", "num_hacks", "\n", "assert", "np", ".", "array_equal", "(", "copy", ".", "attack_values", ",", "state", ".", "attack_values", ")", "\n", "assert", "np", ".", "array_equal", "(", "copy", ".", "defense_det", ",", "state", ".", "defense_det", ")", "\n", "assert", "np", ".", "array_equal", "(", "copy", ".", "defense_values", ",", "state", ".", "defense_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_game_state.TestGameStateSuite.test_new_game": [[49, 69], ["gym_idsgame.envs.dao.network_config.NetworkConfig", "gym_idsgame.envs.dao.game_state.GameState", "len", "gym_idsgame.envs.dao.game_state.GameState.default_state", "gym_idsgame.envs.dao.game_state.GameState.copy", "gym_idsgame.envs.dao.game_state.GameState.new_game", "gym_idsgame.envs.dao.game_state.GameState.default_state", "gym_idsgame.envs.dao.game_state.GameState.copy", "gym_idsgame.envs.dao.game_state.GameState.new_game", "list", "list", "range", "range"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.default_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.new_game", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.default_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.new_game"], ["", "def", "test_new_game", "(", "self", ")", ":", "\n", "        ", "rows", "=", "4", "\n", "cols", "=", "4", "\n", "network_config", "=", "NetworkConfig", "(", "rows", ",", "cols", ")", "\n", "state", "=", "GameState", "(", ")", "\n", "num_nodes", "=", "len", "(", "network_config", ".", "node_list", ")", "\n", "num_attack_types", "=", "10", "\n", "state", ".", "default_state", "(", "list", "(", "range", "(", "num_nodes", ")", ")", ",", "(", "3", ",", "1", ")", ",", "num_attack_types", ",", "network_config", ")", "\n", "init_state", "=", "state", ".", "copy", "(", ")", "\n", "old_game_count", "=", "state", ".", "num_games", "\n", "state", ".", "new_game", "(", "init_state", ")", "\n", "assert", "state", ".", "num_games", "==", "old_game_count", "+", "1", "\n", "assert", "state", ".", "done", "==", "False", "\n", "assert", "state", ".", "detected", "==", "False", "\n", "state", ".", "default_state", "(", "list", "(", "range", "(", "num_nodes", ")", ")", ",", "(", "3", ",", "1", ")", ",", "num_attack_types", ",", "network_config", ")", "\n", "init_state", "=", "state", ".", "copy", "(", ")", "\n", "state", ".", "hacked", "=", "True", "\n", "old_hacked_count", "=", "0", "\n", "state", ".", "new_game", "(", "init_state", ")", "\n", "assert", "state", ".", "num_hacks", "==", "old_hacked_count", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_game_state.TestGameStateSuite.test_attack": [[70, 88], ["gym_idsgame.envs.dao.game_state.GameState", "gym_idsgame.envs.dao.network_config.NetworkConfig", "len", "gym_idsgame.envs.dao.game_state.GameState.default_state", "gym_idsgame.envs.dao.game_state.GameState.attack", "gym_idsgame.envs.dao.game_state.GameState.attack", "list", "range"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.default_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.attack", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.attack"], ["", "def", "test_attack", "(", "self", ")", ":", "\n", "        ", "state", "=", "GameState", "(", ")", "\n", "rows", "=", "4", "\n", "cols", "=", "4", "\n", "network_config", "=", "NetworkConfig", "(", "rows", ",", "cols", ")", "\n", "num_nodes", "=", "len", "(", "network_config", ".", "node_list", ")", "\n", "num_attack_types", "=", "10", "\n", "state", ".", "default_state", "(", "list", "(", "range", "(", "num_nodes", ")", ")", ",", "(", "3", ",", "1", ")", ",", "num_attack_types", ",", "network_config", ")", "\n", "attack_node_id", "=", "3", "\n", "attack_type", "=", "4", "\n", "max_value", "=", "10", "\n", "old_count", "=", "state", ".", "attack_values", "[", "attack_node_id", "]", "[", "attack_type", "]", "\n", "state", ".", "attack", "(", "attack_node_id", ",", "attack_type", ",", "max_value", ",", "network_config", ")", "\n", "assert", "state", ".", "attack_values", "[", "attack_node_id", "]", "[", "attack_type", "]", "<", "max_value", "\n", "assert", "state", ".", "attack_values", "[", "attack_node_id", "]", "[", "attack_type", "]", "==", "old_count", "+", "1", "\n", "state", ".", "attack_values", "[", "attack_node_id", "]", "[", "attack_type", "]", "=", "10", "\n", "state", ".", "attack", "(", "attack_node_id", ",", "attack_type", ",", "max_value", ",", "network_config", ")", "\n", "assert", "state", ".", "attack_values", "[", "attack_node_id", "]", "[", "attack_type", "]", "==", "max_value", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_game_state.TestGameStateSuite.test_defend": [[89, 107], ["gym_idsgame.envs.dao.game_state.GameState", "gym_idsgame.envs.dao.network_config.NetworkConfig", "len", "gym_idsgame.envs.dao.game_state.GameState.default_state", "gym_idsgame.envs.dao.game_state.GameState.defend", "gym_idsgame.envs.dao.game_state.GameState.defend", "list", "range"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.default_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.defend", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.defend"], ["", "def", "test_defend", "(", "self", ")", ":", "\n", "        ", "state", "=", "GameState", "(", ")", "\n", "rows", "=", "4", "\n", "cols", "=", "4", "\n", "network_config", "=", "NetworkConfig", "(", "rows", ",", "cols", ")", "\n", "num_nodes", "=", "len", "(", "network_config", ".", "node_list", ")", "\n", "num_attack_types", "=", "10", "\n", "state", ".", "default_state", "(", "list", "(", "range", "(", "num_nodes", ")", ")", ",", "(", "3", ",", "1", ")", ",", "num_attack_types", ",", "network_config", ")", "\n", "defend_node_id", "=", "3", "\n", "defense_type", "=", "4", "\n", "max_value", "=", "10", "\n", "old_count", "=", "state", ".", "defense_values", "[", "defend_node_id", "]", "[", "defense_type", "]", "\n", "state", ".", "defend", "(", "defend_node_id", ",", "defense_type", ",", "max_value", ",", "network_config", ")", "\n", "assert", "state", ".", "defense_values", "[", "defend_node_id", "]", "[", "defense_type", "]", "<", "max_value", "\n", "assert", "state", ".", "defense_values", "[", "defend_node_id", "]", "[", "defense_type", "]", "==", "old_count", "+", "1", "\n", "state", ".", "defense_values", "[", "defend_node_id", "]", "[", "defense_type", "]", "=", "10", "\n", "state", ".", "defend", "(", "defend_node_id", ",", "defense_type", ",", "max_value", ",", "network_config", ")", "\n", "assert", "state", ".", "defense_values", "[", "defend_node_id", "]", "[", "defense_type", "]", "==", "max_value", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_game_state.TestGameStateSuite.test_simulate_attack": [[108, 124], ["gym_idsgame.envs.dao.network_config.NetworkConfig", "len", "gym_idsgame.envs.dao.game_state.GameState", "gym_idsgame.envs.dao.game_state.GameState.default_state", "gym_idsgame.envs.dao.game_state.GameState.simulate_attack", "list", "gym_idsgame.envs.dao.game_state.GameState.simulate_attack", "range"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.default_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.simulate_attack", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.simulate_attack"], ["", "def", "test_simulate_attack", "(", "self", ")", ":", "\n", "        ", "rows", "=", "4", "\n", "cols", "=", "4", "\n", "network_config", "=", "NetworkConfig", "(", "rows", ",", "cols", ")", "\n", "num_nodes", "=", "len", "(", "network_config", ".", "node_list", ")", "\n", "state", "=", "GameState", "(", ")", "\n", "num_attack_types", "=", "10", "\n", "state", ".", "default_state", "(", "list", "(", "range", "(", "num_nodes", ")", ")", ",", "(", "3", ",", "1", ")", ",", "num_attack_types", ",", "network_config", ")", "\n", "attack_node_id", "=", "3", "\n", "attack_type", "=", "4", "\n", "state", ".", "defense_values", "[", "attack_node_id", "]", "[", "attack_type", "]", "=", "5", "\n", "state", ".", "attack_values", "[", "attack_node_id", "]", "[", "attack_type", "]", "=", "5", "\n", "assert", "not", "state", ".", "simulate_attack", "(", "attack_node_id", ",", "attack_type", ",", "network_config", ")", "\n", "state", ".", "defense_values", "[", "attack_node_id", "]", "[", "attack_type", "]", "=", "5", "\n", "state", ".", "attack_values", "[", "attack_node_id", "]", "[", "attack_type", "]", "=", "6", "\n", "assert", "state", ".", "simulate_attack", "(", "attack_node_id", ",", "attack_type", ",", "network_config", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_idsgame_config.TestIdsGameConfigSuite.test_initialization": [[12, 15], ["gym_idsgame.envs.dao.idsgame_config.IdsGameConfig"], "methods", ["None"], ["def", "test_initialization", "(", "self", ")", ":", "\n", "        ", "idsgame_config", "=", "IdsGameConfig", "(", ")", "\n", "assert", "idsgame_config", ".", "render_config", "is", "not", "None", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_network_config.TestIdsGameConfigSuite.test_initialization": [[12, 24], ["gym_idsgame.envs.dao.network_config.NetworkConfig", "range", "range", "range", "range"], "methods", ["None"], ["def", "test_initialization", "(", "self", ")", ":", "\n", "        ", "num_rows", "=", "2", "\n", "num_cols", "=", "3", "\n", "network_config", "=", "NetworkConfig", "(", "num_rows", ",", "num_cols", ")", "\n", "assert", "network_config", ".", "graph_layout", ".", "shape", "==", "(", "num_rows", ",", "num_cols", ")", "\n", "for", "i", "in", "range", "(", "network_config", ".", "num_rows", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "network_config", ".", "num_cols", ")", ":", "\n", "                ", "assert", "network_config", ".", "graph_layout", "[", "i", "]", "[", "j", "]", "is", "not", "None", "\n", "", "", "assert", "network_config", ".", "adjacency_matrix", ".", "shape", "==", "(", "num_rows", "*", "num_cols", ",", "num_rows", "*", "num_cols", ")", "\n", "for", "i", "in", "range", "(", "network_config", ".", "num_rows", "*", "network_config", ".", "num_cols", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "network_config", ".", "num_cols", "*", "network_config", ".", "num_rows", ")", ":", "\n", "                ", "assert", "network_config", ".", "adjacency_matrix", "[", "i", "]", "[", "j", "]", "==", "1", "or", "network_config", ".", "adjacency_matrix", "[", "i", "]", "[", "j", "]", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_network_config.TestIdsGameConfigSuite.test_get_coords_of_adjacency_matrix_id": [[25, 35], ["gym_idsgame.envs.dao.network_config.NetworkConfig", "gym_idsgame.envs.dao.network_config.NetworkConfig.get_coords_of_adjacency_matrix_id", "gym_idsgame.envs.dao.network_config.NetworkConfig.get_coords_of_adjacency_matrix_id", "gym_idsgame.envs.dao.network_config.NetworkConfig.get_coords_of_adjacency_matrix_id", "gym_idsgame.envs.dao.network_config.NetworkConfig.get_coords_of_adjacency_matrix_id", "gym_idsgame.envs.dao.network_config.NetworkConfig.get_coords_of_adjacency_matrix_id", "gym_idsgame.envs.dao.network_config.NetworkConfig.get_coords_of_adjacency_matrix_id"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_coords_of_adjacency_matrix_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_coords_of_adjacency_matrix_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_coords_of_adjacency_matrix_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_coords_of_adjacency_matrix_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_coords_of_adjacency_matrix_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_coords_of_adjacency_matrix_id"], ["", "", "", "def", "test_get_coords_of_adjacency_matrix_id", "(", "self", ")", ":", "\n", "        ", "num_rows", "=", "2", "\n", "num_cols", "=", "3", "\n", "network_config", "=", "NetworkConfig", "(", "num_rows", ",", "num_cols", ")", "\n", "assert", "network_config", ".", "get_coords_of_adjacency_matrix_id", "(", "0", ")", "==", "(", "0", ",", "0", ")", "\n", "assert", "network_config", ".", "get_coords_of_adjacency_matrix_id", "(", "1", ")", "==", "(", "0", ",", "1", ")", "\n", "assert", "network_config", ".", "get_coords_of_adjacency_matrix_id", "(", "2", ")", "==", "(", "0", ",", "2", ")", "\n", "assert", "network_config", ".", "get_coords_of_adjacency_matrix_id", "(", "3", ")", "==", "(", "1", ",", "0", ")", "\n", "assert", "network_config", ".", "get_coords_of_adjacency_matrix_id", "(", "4", ")", "==", "(", "1", ",", "1", ")", "\n", "assert", "network_config", ".", "get_coords_of_adjacency_matrix_id", "(", "5", ")", "==", "(", "1", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_network_config.TestIdsGameConfigSuite.test_start_pos": [[37, 42], ["gym_idsgame.envs.dao.network_config.NetworkConfig"], "methods", ["None"], ["", "def", "test_start_pos", "(", "self", ")", ":", "\n", "        ", "num_rows", "=", "2", "\n", "num_cols", "=", "3", "\n", "network_config", "=", "NetworkConfig", "(", "num_rows", ",", "num_cols", ")", "\n", "assert", "network_config", ".", "start_pos", "==", "(", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_network_config.TestIdsGameConfigSuite.test_start_row": [[43, 48], ["gym_idsgame.envs.dao.network_config.NetworkConfig"], "methods", ["None"], ["", "def", "test_start_row", "(", "self", ")", ":", "\n", "        ", "num_rows", "=", "2", "\n", "num_cols", "=", "3", "\n", "network_config", "=", "NetworkConfig", "(", "num_rows", ",", "num_cols", ")", "\n", "assert", "network_config", ".", "start_row", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_network_config.TestIdsGameConfigSuite.test_start_col": [[49, 54], ["gym_idsgame.envs.dao.network_config.NetworkConfig"], "methods", ["None"], ["", "def", "test_start_col", "(", "self", ")", ":", "\n", "        ", "num_rows", "=", "2", "\n", "num_cols", "=", "3", "\n", "network_config", "=", "NetworkConfig", "(", "num_rows", ",", "num_cols", ")", "\n", "assert", "network_config", ".", "start_col", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_network_config.TestIdsGameConfigSuite.test_data_pos": [[55, 60], ["gym_idsgame.envs.dao.network_config.NetworkConfig"], "methods", ["None"], ["", "def", "test_data_pos", "(", "self", ")", ":", "\n", "        ", "num_rows", "=", "2", "\n", "num_cols", "=", "3", "\n", "network_config", "=", "NetworkConfig", "(", "num_rows", ",", "num_cols", ")", "\n", "assert", "network_config", ".", "data_pos", "==", "(", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_network_config.TestIdsGameConfigSuite.test_data_row": [[61, 66], ["gym_idsgame.envs.dao.network_config.NetworkConfig"], "methods", ["None"], ["", "def", "test_data_row", "(", "self", ")", ":", "\n", "        ", "num_rows", "=", "2", "\n", "num_cols", "=", "3", "\n", "network_config", "=", "NetworkConfig", "(", "num_rows", ",", "num_cols", ")", "\n", "assert", "network_config", ".", "data_row", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_network_config.TestIdsGameConfigSuite.test_data_col": [[67, 72], ["gym_idsgame.envs.dao.network_config.NetworkConfig"], "methods", ["None"], ["", "def", "test_data_col", "(", "self", ")", ":", "\n", "        ", "num_rows", "=", "2", "\n", "num_cols", "=", "3", "\n", "network_config", "=", "NetworkConfig", "(", "num_rows", ",", "num_cols", ")", "\n", "assert", "network_config", ".", "data_col", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_network_config.TestIdsGameConfigSuite.test_node_list": [[73, 81], ["gym_idsgame.envs.dao.network_config.NetworkConfig", "range", "len", "len"], "methods", ["None"], ["", "def", "test_node_list", "(", "self", ")", ":", "\n", "        ", "num_rows", "=", "3", "\n", "num_cols", "=", "3", "\n", "network_config", "=", "NetworkConfig", "(", "num_rows", ",", "num_cols", ")", "\n", "node_list", "=", "network_config", ".", "node_list", "\n", "assert", "len", "(", "node_list", ")", "==", "num_rows", "*", "num_cols", "-", "4", "\n", "for", "i", "in", "range", "(", "len", "(", "node_list", ")", ")", ":", "\n", "            ", "assert", "node_list", "[", "i", "]", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_network_config.TestIdsGameConfigSuite.test_get_node_pos": [[82, 91], ["gym_idsgame.envs.dao.network_config.NetworkConfig", "gym_idsgame.envs.dao.network_config.NetworkConfig.get_node_pos", "gym_idsgame.envs.dao.network_config.NetworkConfig.get_node_pos", "gym_idsgame.envs.dao.network_config.NetworkConfig.get_node_pos", "gym_idsgame.envs.dao.network_config.NetworkConfig.get_node_pos", "gym_idsgame.envs.dao.network_config.NetworkConfig.get_node_pos"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_pos", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_pos", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_pos", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_pos", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_pos"], ["", "", "def", "test_get_node_pos", "(", "self", ")", ":", "\n", "        ", "num_rows", "=", "3", "\n", "num_cols", "=", "3", "\n", "network_config", "=", "NetworkConfig", "(", "num_rows", ",", "num_cols", ")", "\n", "assert", "network_config", ".", "get_node_pos", "(", "0", ")", "==", "(", "0", ",", "1", ")", "\n", "assert", "network_config", ".", "get_node_pos", "(", "1", ")", "==", "(", "1", ",", "0", ")", "\n", "assert", "network_config", ".", "get_node_pos", "(", "2", ")", "==", "(", "1", ",", "1", ")", "\n", "assert", "network_config", ".", "get_node_pos", "(", "3", ")", "==", "(", "1", ",", "2", ")", "\n", "assert", "network_config", ".", "get_node_pos", "(", "4", ")", "==", "(", "2", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_network_config.TestIdsGameConfigSuite.test_get_node_id": [[93, 106], ["gym_idsgame.envs.dao.network_config.NetworkConfig", "gym_idsgame.envs.dao.network_config.NetworkConfig.get_node_id", "gym_idsgame.envs.dao.network_config.NetworkConfig.get_node_id", "gym_idsgame.envs.dao.network_config.NetworkConfig.get_node_id", "gym_idsgame.envs.dao.network_config.NetworkConfig.get_node_id", "gym_idsgame.envs.dao.network_config.NetworkConfig.get_node_id", "gym_idsgame.envs.dao.network_config.NetworkConfig.get_node_id", "gym_idsgame.envs.dao.network_config.NetworkConfig.get_node_id", "gym_idsgame.envs.dao.network_config.NetworkConfig.get_node_id", "gym_idsgame.envs.dao.network_config.NetworkConfig.get_node_id"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_id"], ["", "def", "test_get_node_id", "(", "self", ")", ":", "\n", "        ", "num_rows", "=", "3", "\n", "num_cols", "=", "3", "\n", "network_config", "=", "NetworkConfig", "(", "num_rows", ",", "num_cols", ")", "\n", "assert", "network_config", ".", "get_node_id", "(", "(", "0", ",", "1", ")", ")", "==", "0", "\n", "assert", "network_config", ".", "get_node_id", "(", "(", "1", ",", "0", ")", ")", "==", "1", "\n", "assert", "network_config", ".", "get_node_id", "(", "(", "1", ",", "1", ")", ")", "==", "2", "\n", "assert", "network_config", ".", "get_node_id", "(", "(", "1", ",", "2", ")", ")", "==", "3", "\n", "assert", "network_config", ".", "get_node_id", "(", "(", "2", ",", "1", ")", ")", "==", "4", "\n", "assert", "network_config", ".", "get_node_id", "(", "(", "2", ",", "2", ")", ")", "==", "-", "1", "\n", "assert", "network_config", ".", "get_node_id", "(", "(", "2", ",", "0", ")", ")", "==", "-", "1", "\n", "assert", "network_config", ".", "get_node_id", "(", "(", "0", ",", "0", ")", ")", "==", "-", "1", "\n", "assert", "network_config", ".", "get_node_id", "(", "(", "0", ",", "2", ")", ")", "==", "-", "1", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_game_config.TestConfigSuite.test_initialization": [[12, 16], ["gym_idsgame.envs.dao.game_config.GameConfig"], "methods", ["None"], ["def", "test_initialization", "(", "self", ")", ":", "\n", "        ", "game_config", "=", "GameConfig", "(", ")", "\n", "assert", "game_config", ".", "initial_state", "is", "not", "None", "\n", "assert", "game_config", ".", "network_config", "is", "not", "None", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.tests.test_render_config.TestIdsGameConfigSuite.test_initialization": [[12, 35], ["gym_idsgame.envs.dao.render_config.RenderConfig"], "methods", ["None"], ["def", "test_initialization", "(", "self", ")", ":", "\n", "        ", "render_config", "=", "RenderConfig", "(", ")", "\n", "assert", "render_config", ".", "rect_size", "is", "not", "None", "\n", "assert", "render_config", ".", "bg_color", "is", "not", "None", "\n", "assert", "render_config", ".", "attacker_filename", "is", "not", "None", "\n", "assert", "render_config", ".", "server_filename", "is", "not", "None", "\n", "assert", "render_config", ".", "data_filename", "is", "not", "None", "\n", "assert", "render_config", ".", "cage_filename", "is", "not", "None", "\n", "assert", "render_config", ".", "attacker_scale", "is", "not", "None", "\n", "assert", "render_config", ".", "server_scale", "is", "not", "None", "\n", "assert", "render_config", ".", "data_scale", "is", "not", "None", "\n", "assert", "render_config", ".", "cage_scale", "is", "not", "None", "\n", "assert", "render_config", ".", "line_width", "is", "not", "None", "\n", "assert", "render_config", ".", "caption", "is", "not", "None", "\n", "assert", "render_config", ".", "resources_dir", "is", "not", "None", "\n", "assert", "render_config", ".", "blink_interval", "is", "not", "None", "\n", "assert", "render_config", ".", "num_blinks", "is", "not", "None", "\n", "assert", "render_config", ".", "batch", "is", "not", "None", "\n", "assert", "render_config", ".", "background", "is", "not", "None", "\n", "assert", "render_config", ".", "first_foreground", "is", "not", "None", "\n", "assert", "render_config", ".", "second_foreground", "is", "not", "None", "\n", "assert", "render_config", ".", "height", "is", "not", "None", "\n", "assert", "render_config", ".", "width", "is", "not", "None", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run": [[44, 66], ["runnner.Runner.train_attacker", "runnner.Runner.train_defender", "runnner.Runner.train_attacker_and_defender", "runnner.Runner.simulate", "runnner.Runner.manual_play_attacker", "runnner.Runner.manual_play_defender", "AssertionError"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.train_attacker", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.train_defender", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.train_attacker_and_defender", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.simulation.simulator.Simulator.simulate", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.manual_play_attacker", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.manual_play_defender"], ["@", "staticmethod", "\n", "def", "run", "(", "config", ":", "ClientConfig", ")", ":", "\n", "        ", "\"\"\"\n        Run entrypoint\n\n        :param config: configuration for the run\n        :return: the result\n        \"\"\"", "\n", "if", "config", ".", "mode", "==", "RunnerMode", ".", "TRAIN_ATTACKER", ".", "value", ":", "\n", "            ", "return", "Runner", ".", "train_attacker", "(", "config", ")", "\n", "", "elif", "config", ".", "mode", "==", "RunnerMode", ".", "TRAIN_DEFENDER", ".", "value", ":", "\n", "            ", "return", "Runner", ".", "train_defender", "(", "config", ")", "\n", "", "elif", "config", ".", "mode", "==", "RunnerMode", ".", "TRAIN_DEFENDER_AND_ATTACKER", ".", "value", ":", "\n", "            ", "return", "Runner", ".", "train_attacker_and_defender", "(", "config", ")", "\n", "", "elif", "config", ".", "mode", "==", "RunnerMode", ".", "SIMULATE", ".", "value", ":", "\n", "            ", "return", "Runner", ".", "simulate", "(", "config", ")", "\n", "", "elif", "config", ".", "mode", "==", "RunnerMode", ".", "MANUAL_ATTACKER", ".", "value", ":", "\n", "            ", "return", "Runner", ".", "manual_play_attacker", "(", "config", ")", "\n", "", "elif", "config", ".", "mode", "==", "RunnerMode", ".", "MANUAL_DEFENDER", ".", "value", ":", "\n", "            ", "return", "Runner", ".", "manual_play_defender", "(", "config", ")", "\n", "", "else", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Runner mode not recognized: {}\"", ".", "format", "(", "config", ".", "mode", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.train_attacker": [[67, 106], ["gym.make", "gym_idsgame.agents.training_agents.openai_baselines.ppo.ppo.OpenAiPPOAgent.train", "gym_idsgame.agents.training_agents.q_learning.tabular_q_learning.tabular_q_agent.TabularQAgent", "gym_idsgame.agents.training_agents.q_learning.dqn.dqn.DQNAgent", "str", "gym_idsgame.agents.training_agents.policy_gradient.reinforce.reinforce.ReinforceAgent", "gym_idsgame.agents.training_agents.policy_gradient.actor_critic.actor_critic.ActorCriticAgent", "gym_idsgame.agents.training_agents.policy_gradient.ppo.ppo.PPOAgent", "gym_idsgame.agents.training_agents.openai_baselines.common.baseline_env_wrapper.BaselineEnvWrapper", "gym_idsgame.agents.training_agents.openai_baselines.ppo.ppo.OpenAiPPOAgent", "AssertionError", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.train"], ["", "", "@", "staticmethod", "\n", "def", "train_attacker", "(", "config", ":", "ClientConfig", ")", "->", "Union", "[", "ExperimentResult", ",", "ExperimentResult", "]", ":", "\n", "        ", "\"\"\"\n        Trains an attacker agent in the environment\n\n        :param config: Training configuration\n        :return: trainresult, evalresult\n        \"\"\"", "\n", "env", ":", "IdsGameEnv", "=", "None", "\n", "env", "=", "gym", ".", "make", "(", "config", ".", "env_name", ",", "idsgame_config", "=", "config", ".", "idsgame_config", ",", "\n", "save_dir", "=", "config", ".", "output_dir", "+", "\"/results/data/\"", "+", "str", "(", "config", ".", "random_seed", ")", ",", "\n", "initial_state_path", "=", "config", ".", "initial_state_path", ")", "\n", "if", "config", ".", "title", "is", "not", "None", ":", "\n", "            ", "env", ".", "idsgame_config", ".", "render_config", ".", "title", "=", "config", ".", "title", "\n", "", "attacker", ":", "TrainAgent", "=", "None", "\n", "if", "config", ".", "attacker_type", "==", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ":", "\n", "            ", "attacker", "=", "TabularQAgent", "(", "env", ",", "config", ".", "q_agent_config", ")", "\n", "", "elif", "config", ".", "attacker_type", "==", "AgentType", ".", "DQN_AGENT", ".", "value", ":", "\n", "            ", "attacker", "=", "DQNAgent", "(", "env", ",", "config", ".", "q_agent_config", ")", "\n", "", "elif", "config", ".", "attacker_type", "==", "AgentType", ".", "REINFORCE_AGENT", ".", "value", ":", "\n", "            ", "attacker", "=", "ReinforceAgent", "(", "env", ",", "config", ".", "pg_agent_config", ")", "\n", "", "elif", "config", ".", "attacker_type", "==", "AgentType", ".", "ACTOR_CRITIC_AGENT", ".", "value", ":", "\n", "            ", "attacker", "=", "ActorCriticAgent", "(", "env", ",", "config", ".", "pg_agent_config", ")", "\n", "", "elif", "config", ".", "attacker_type", "==", "AgentType", ".", "PPO_AGENT", ".", "value", ":", "\n", "            ", "attacker", "=", "PPOAgent", "(", "env", ",", "config", ".", "pg_agent_config", ")", "\n", "", "elif", "config", ".", "attacker_type", "==", "AgentType", ".", "PPO_OPENAI_AGENT", ".", "value", ":", "\n", "            ", "wrapper_env", "=", "BaselineEnvWrapper", "(", "config", ".", "env_name", ",", "idsgame_config", "=", "config", ".", "idsgame_config", ",", "\n", "save_dir", "=", "config", ".", "output_dir", "+", "\"/results/data/\"", "+", "str", "(", "config", ".", "random_seed", ")", ",", "\n", "initial_state_path", "=", "config", ".", "initial_state_path", ",", "\n", "pg_agent_config", "=", "config", ".", "pg_agent_config", ")", "\n", "if", "config", ".", "title", "is", "not", "None", ":", "\n", "                ", "wrapper_env", ".", "idsgame_env", ".", "idsgame_config", ".", "render_config", ".", "title", "=", "config", ".", "title", "\n", "", "attacker", "=", "OpenAiPPOAgent", "(", "wrapper_env", ",", "config", ".", "pg_agent_config", ")", "\n", "", "else", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Attacker train agent type not recognized: {}\"", ".", "format", "(", "config", ".", "attacker_type", ")", ")", "\n", "", "attacker", ".", "train", "(", ")", "\n", "train_result", "=", "attacker", ".", "train_result", "\n", "eval_result", "=", "attacker", ".", "eval_result", "\n", "return", "train_result", ",", "eval_result", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.train_defender": [[107, 145], ["gym.make", "gym_idsgame.agents.training_agents.openai_baselines.ppo.ppo.OpenAiPPOAgent.train", "gym_idsgame.agents.training_agents.q_learning.tabular_q_learning.tabular_q_agent.TabularQAgent", "gym_idsgame.agents.training_agents.q_learning.dqn.dqn.DQNAgent", "str", "gym_idsgame.agents.training_agents.policy_gradient.reinforce.reinforce.ReinforceAgent", "gym_idsgame.agents.training_agents.policy_gradient.actor_critic.actor_critic.ActorCriticAgent", "gym_idsgame.agents.training_agents.policy_gradient.ppo.ppo.PPOAgent", "gym_idsgame.agents.training_agents.openai_baselines.common.baseline_env_wrapper.BaselineEnvWrapper", "gym_idsgame.agents.training_agents.openai_baselines.ppo.ppo.OpenAiPPOAgent", "AssertionError", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.train"], ["", "@", "staticmethod", "\n", "def", "train_defender", "(", "config", ":", "ClientConfig", ")", "->", "Union", "[", "ExperimentResult", ",", "ExperimentResult", "]", ":", "\n", "        ", "\"\"\"\n        Trains a defender agent in the environment\n\n        :param config: the training configuration\n        :return: trainresult, evalresult\n        \"\"\"", "\n", "env", "=", "gym", ".", "make", "(", "config", ".", "env_name", ",", "idsgame_config", "=", "config", ".", "idsgame_config", ",", "\n", "save_dir", "=", "config", ".", "output_dir", "+", "\"/results/data/\"", "+", "str", "(", "config", ".", "random_seed", ")", ",", "\n", "initial_state_path", "=", "config", ".", "initial_state_path", ")", "\n", "if", "config", ".", "title", "is", "not", "None", ":", "\n", "            ", "env", ".", "idsgame_config", ".", "render_config", ".", "title", "=", "config", ".", "title", "\n", "", "defender", ":", "TrainAgent", "=", "None", "\n", "if", "config", ".", "defender_type", "==", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ":", "\n", "            ", "defender", "=", "TabularQAgent", "(", "env", ",", "config", ".", "q_agent_config", ")", "\n", "", "elif", "config", ".", "defender_type", "==", "AgentType", ".", "DQN_AGENT", ".", "value", ":", "\n", "            ", "defender", "=", "DQNAgent", "(", "env", ",", "config", ".", "q_agent_config", ")", "\n", "", "elif", "config", ".", "defender_type", "==", "AgentType", ".", "REINFORCE_AGENT", ".", "value", ":", "\n", "            ", "defender", "=", "ReinforceAgent", "(", "env", ",", "config", ".", "pg_agent_config", ")", "\n", "", "elif", "config", ".", "defender_type", "==", "AgentType", ".", "ACTOR_CRITIC_AGENT", ".", "value", ":", "\n", "            ", "defender", "=", "ActorCriticAgent", "(", "env", ",", "config", ".", "pg_agent_config", ")", "\n", "", "elif", "config", ".", "defender_type", "==", "AgentType", ".", "PPO_AGENT", ".", "value", ":", "\n", "            ", "defender", "=", "PPOAgent", "(", "env", ",", "config", ".", "pg_agent_config", ")", "\n", "", "elif", "config", ".", "defender_type", "==", "AgentType", ".", "PPO_OPENAI_AGENT", ".", "value", ":", "\n", "            ", "wrapper_env", "=", "BaselineEnvWrapper", "(", "config", ".", "env_name", ",", "idsgame_config", "=", "config", ".", "idsgame_config", ",", "\n", "save_dir", "=", "config", ".", "output_dir", "+", "\"/results/data/\"", "+", "str", "(", "config", ".", "random_seed", ")", ",", "\n", "initial_state_path", "=", "config", ".", "initial_state_path", ",", "\n", "pg_agent_config", "=", "config", ".", "pg_agent_config", ")", "\n", "if", "config", ".", "title", "is", "not", "None", ":", "\n", "                ", "wrapper_env", ".", "idsgame_env", ".", "idsgame_config", ".", "render_config", ".", "title", "=", "config", ".", "title", "\n", "", "defender", "=", "OpenAiPPOAgent", "(", "wrapper_env", ",", "config", ".", "pg_agent_config", ")", "\n", "", "else", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Defender train agent type not recognized: {}\"", ".", "format", "(", "config", ".", "defender_type", ")", ")", "\n", "", "defender", ".", "train", "(", ")", "\n", "train_result", "=", "defender", ".", "train_result", "\n", "eval_result", "=", "defender", ".", "eval_result", "\n", "return", "train_result", ",", "eval_result", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.train_attacker_and_defender": [[147, 186], ["gym.make", "gym_idsgame.agents.training_agents.openai_baselines.ppo.ppo.OpenAiPPOAgent.train", "gym_idsgame.agents.training_agents.q_learning.tabular_q_learning.tabular_q_agent.TabularQAgent", "gym_idsgame.agents.training_agents.q_learning.dqn.dqn.DQNAgent", "str", "gym_idsgame.agents.training_agents.policy_gradient.reinforce.reinforce.ReinforceAgent", "gym_idsgame.agents.training_agents.policy_gradient.actor_critic.actor_critic.ActorCriticAgent", "gym_idsgame.agents.training_agents.policy_gradient.ppo.ppo.PPOAgent", "gym_idsgame.agents.training_agents.openai_baselines.common.baseline_env_wrapper.BaselineEnvWrapper", "gym_idsgame.agents.training_agents.openai_baselines.ppo.ppo.OpenAiPPOAgent", "AssertionError", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.train"], ["", "@", "staticmethod", "\n", "def", "train_attacker_and_defender", "(", "config", ":", "ClientConfig", ")", "->", "Union", "[", "ExperimentResult", ",", "ExperimentResult", "]", ":", "\n", "        ", "\"\"\"\n        Trains an attacker agent and a defender agent simultaneously in the environment\n\n        :param config: Training configuration\n        :return: trainresult, evalresult\n        \"\"\"", "\n", "env", ":", "IdsGameEnv", "=", "None", "\n", "env", "=", "gym", ".", "make", "(", "config", ".", "env_name", ",", "idsgame_config", "=", "config", ".", "idsgame_config", ",", "\n", "save_dir", "=", "config", ".", "output_dir", "+", "\"/results/data/\"", "+", "str", "(", "config", ".", "random_seed", ")", ",", "\n", "initial_state_path", "=", "config", ".", "initial_state_path", ")", "\n", "if", "config", ".", "title", "is", "not", "None", ":", "\n", "            ", "env", ".", "idsgame_config", ".", "render_config", ".", "title", "=", "config", ".", "title", "\n", "", "agent", ":", "TrainAgent", "=", "None", "\n", "if", "config", ".", "attacker_type", "==", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ":", "\n", "            ", "agent", "=", "TabularQAgent", "(", "env", ",", "config", ".", "q_agent_config", ")", "\n", "", "elif", "config", ".", "attacker_type", "==", "AgentType", ".", "DQN_AGENT", ".", "value", ":", "\n", "            ", "agent", "=", "DQNAgent", "(", "env", ",", "config", ".", "q_agent_config", ")", "\n", "", "elif", "config", ".", "attacker_type", "==", "AgentType", ".", "REINFORCE_AGENT", ".", "value", ":", "\n", "            ", "agent", "=", "ReinforceAgent", "(", "env", ",", "config", ".", "pg_agent_config", ")", "\n", "", "elif", "config", ".", "attacker_type", "==", "AgentType", ".", "ACTOR_CRITIC_AGENT", ".", "value", ":", "\n", "            ", "agent", "=", "ActorCriticAgent", "(", "env", ",", "config", ".", "pg_agent_config", ")", "\n", "", "elif", "config", ".", "attacker_type", "==", "AgentType", ".", "PPO_AGENT", ".", "value", ":", "\n", "            ", "agent", "=", "PPOAgent", "(", "env", ",", "config", ".", "pg_agent_config", ")", "\n", "", "elif", "config", ".", "attacker_type", "==", "AgentType", ".", "PPO_OPENAI_AGENT", ".", "value", ":", "\n", "            ", "wrapper_env", "=", "BaselineEnvWrapper", "(", "config", ".", "env_name", ",", "idsgame_config", "=", "config", ".", "idsgame_config", ",", "\n", "save_dir", "=", "config", ".", "output_dir", "+", "\"/results/data/\"", "+", "str", "(", "config", ".", "random_seed", ")", ",", "\n", "initial_state_path", "=", "config", ".", "initial_state_path", ",", "\n", "pg_agent_config", "=", "config", ".", "pg_agent_config", ")", "\n", "if", "config", ".", "title", "is", "not", "None", ":", "\n", "                ", "wrapper_env", ".", "idsgame_env", ".", "idsgame_config", ".", "render_config", ".", "title", "=", "config", ".", "title", "\n", "", "agent", "=", "OpenAiPPOAgent", "(", "wrapper_env", ",", "config", ".", "pg_agent_config", ")", "\n", "", "else", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Train agent type not recognized: {}\"", ".", "format", "(", "config", ".", "attacker_type", ")", ")", "\n", "", "agent", ".", "train", "(", ")", "\n", "train_result", "=", "agent", ".", "train_result", "\n", "eval_result", "=", "agent", ".", "eval_result", "\n", "return", "train_result", ",", "eval_result", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.simulate": [[187, 234], ["gym.make", "gym_idsgame.simulation.simulator.Simulator", "gym_idsgame.simulation.simulator.Simulator.simulate", "issubclass", "AssertionError", "gym_idsgame.agents.bot_agents.random_defense_bot_agent.RandomDefenseBotAgent", "gym_idsgame.agents.training_agents.q_learning.tabular_q_learning.tabular_q_attacker_bot_agent.TabularQAttackerBotAgent", "type", "gym_idsgame.agents.bot_agents.defend_minimal_value_bot_agent.DefendMinimalValueBotAgent", "ValueError", "gym_idsgame.agents.bot_agents.random_attack_bot_agent.RandomAttackBotAgent", "gym_idsgame.agents.training_agents.q_learning.tabular_q_learning.tabular_q_defender_bot_agent.TabularQDefenderBotAgent", "AssertionError", "gym_idsgame.agents.bot_agents.attack_maximal_value_bot_agent.AttackMaximalValueBotAgent", "AssertionError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.simulation.simulator.Simulator.simulate", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type"], ["", "@", "staticmethod", "\n", "def", "simulate", "(", "config", ":", "ClientConfig", ")", "->", "ExperimentResult", ":", "\n", "        ", "\"\"\"\n        Runs a simulation with two pre-defined policies against each other\n\n        :param config: the simulation config\n        :return: experiment result\n        \"\"\"", "\n", "env", ":", "IdsGameEnv", "=", "None", "\n", "env", "=", "gym", ".", "make", "(", "config", ".", "env_name", ",", "idsgame_config", "=", "config", ".", "idsgame_config", ",", "\n", "save_dir", "=", "config", ".", "output_dir", "+", "\"/results/data\"", ",", "\n", "initial_state_path", "=", "config", ".", "initial_state_path", ")", "\n", "if", "config", ".", "title", "is", "not", "None", ":", "\n", "            ", "env", ".", "idsgame_config", ".", "render_config", ".", "title", "=", "config", ".", "title", "\n", "", "if", "not", "issubclass", "(", "type", "(", "env", ")", ",", "AttackDefenseEnv", ")", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Simulations can only be run for Attack-Defense environments\"", ")", "\n", "\n", "", "defender", ":", "BotAgent", "=", "None", "\n", "if", "config", ".", "defender_type", "==", "AgentType", ".", "RANDOM", ".", "value", ":", "\n", "            ", "defender", "=", "RandomDefenseBotAgent", "(", "env", ".", "idsgame_config", ".", "game_config", ")", "\n", "", "elif", "config", ".", "defender_type", "==", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ":", "\n", "            ", "defender", "=", "DefendMinimalValueBotAgent", "(", "env", ".", "idsgame_config", ".", "game_config", ")", "\n", "", "elif", "config", ".", "defender_type", "==", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ":", "\n", "            ", "if", "config", ".", "q_agent_config", "is", "None", "or", "config", ".", "q_agent_config", ".", "defender_load_path", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"To run a simulation with a tabular Q-agent, the path to the saved \"", "\n", "\"Q-table must be specified\"", ")", "\n", "", "defender", "=", "TabularQDefenderBotAgent", "(", "env", ".", "idsgame_config", ".", "game_config", ",", "config", ".", "q_agent_config", ".", "defender_load_path", ")", "\n", "", "else", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Defender type not recognized: {}\"", ".", "format", "(", "config", ".", "defender_type", ")", ")", "\n", "\n", "", "attacker", ":", "BotAgent", "=", "None", "\n", "if", "config", ".", "attacker_type", "==", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ":", "\n", "            ", "if", "config", ".", "q_agent_config", "is", "None", "or", "config", ".", "q_agent_config", ".", "attacker_load_path", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"To run a simulation with a tabular Q-agent, the path to the saved \"", "\n", "\"Q-table must be specified\"", ")", "\n", "", "attacker", "=", "TabularQAttackerBotAgent", "(", "env", ".", "idsgame_config", ".", "game_config", ",", "\n", "config", ".", "q_agent_config", ".", "attacker_load_path", ")", "\n", "", "elif", "config", ".", "attacker_type", "==", "AgentType", ".", "RANDOM", ".", "value", ":", "\n", "            ", "attacker", "=", "RandomAttackBotAgent", "(", "env", ".", "idsgame_config", ".", "game_config", ",", "env", ")", "\n", "", "elif", "config", ".", "attacker_type", "==", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ":", "\n", "            ", "attacker", "=", "AttackMaximalValueBotAgent", "(", "env", ".", "idsgame_config", ".", "game_config", ",", "env", ")", "\n", "", "else", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Attacker type not recognized: {}\"", ".", "format", "(", "config", ".", "attacker_type", ")", ")", "\n", "", "env", ".", "idsgame_config", ".", "defender_agent", "=", "defender", "\n", "env", ".", "idsgame_config", ".", "attacker_agent", "=", "attacker", "\n", "simulator", "=", "Simulator", "(", "env", ",", "config", ".", "simulation_config", ")", "\n", "return", "simulator", ".", "simulate", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.manual_play_attacker": [[235, 274], ["gym.make", "ManualAttackAgent", "issubclass", "AssertionError", "gym_idsgame.agents.training_agents.q_learning.tabular_q_learning.tabular_q_attacker_bot_agent.TabularQAttackerBotAgent", "type", "ValueError", "gym_idsgame.agents.bot_agents.random_defense_bot_agent.RandomDefenseBotAgent", "gym_idsgame.agents.bot_agents.defend_minimal_value_bot_agent.DefendMinimalValueBotAgent", "gym_idsgame.agents.training_agents.openai_baselines.ppo.ppo_defender_bot_agent.PPOBaselineDefenderBotAgent", "AssertionError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type"], ["", "@", "staticmethod", "\n", "def", "manual_play_attacker", "(", "config", ":", "ClientConfig", ")", "->", "IdsGameEnv", ":", "\n", "        ", "\"\"\"\n        Starts an experiment with a manual defender player against some bot\n\n        :param config: configuration of the experiment\n        :return: the created environment\n        \"\"\"", "\n", "env", ":", "IdsGameEnv", "=", "gym", ".", "make", "(", "config", ".", "env_name", ",", "idsgame_config", "=", "config", ".", "idsgame_config", ",", "\n", "save_dir", "=", "config", ".", "output_dir", "+", "\"/results/data\"", ",", "initial_state_path", "=", "config", ".", "initial_state_path", ")", "\n", "if", "config", ".", "title", "is", "not", "None", ":", "\n", "            ", "env", ".", "idsgame_config", ".", "render_config", ".", "title", "=", "config", ".", "title", "\n", "", "if", "not", "config", ".", "bot_defender", ":", "\n", "            ", "if", "not", "issubclass", "(", "type", "(", "env", ")", ",", "AttackerEnv", ")", ":", "\n", "                ", "raise", "AssertionError", "(", "\"Manual attacker play is only supported for defender-envs\"", ")", "\n", "", "", "env", ".", "idsgame_config", ".", "game_config", ".", "manual_attacker", "=", "True", "\n", "if", "config", ".", "bot_defender", ":", "\n", "            ", "defender", ":", "BotAgent", "=", "None", "\n", "if", "config", ".", "defender_type", "==", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ":", "\n", "                ", "if", "config", ".", "q_agent_config", "is", "None", "or", "config", ".", "q_agent_config", ".", "defender_load_path", "is", "None", ":", "\n", "                    ", "raise", "ValueError", "(", "\"To run a simulation with a tabular Q-agent, the path to the saved \"", "\n", "\"Q-table must be specified\"", ")", "\n", "", "defender", "=", "TabularQAttackerBotAgent", "(", "env", ".", "idsgame_config", ".", "game_config", ",", "\n", "config", ".", "q_agent_config", ".", "defender_load_path", ")", "\n", "", "elif", "config", ".", "defender_type", "==", "AgentType", ".", "RANDOM", ".", "value", ":", "\n", "                ", "defender", "=", "RandomDefenseBotAgent", "(", "env", ".", "idsgame_config", ".", "game_config", ")", "\n", "", "elif", "config", ".", "defender_type", "==", "AgentType", ".", "DEFEND_MINIMAL_VALUE", ".", "value", ":", "\n", "                ", "defender", "=", "DefendMinimalValueBotAgent", "(", "env", ".", "idsgame_config", ".", "game_config", ")", "\n", "", "elif", "config", ".", "defender_type", "==", "AgentType", ".", "PPO_OPENAI_AGENT", ".", "value", ":", "\n", "                ", "if", "config", ".", "pg_agent_config", "is", "None", "or", "config", ".", "pg_agent_config", ".", "defender_load_path", "is", "None", ":", "\n", "                    ", "raise", "ValueError", "(", "\"To run a simulation with a pretrained OpenAIPPO agent, the path to the saved \"", "\n", "\"model must be specified\"", ")", "\n", "", "defender", "=", "PPOBaselineDefenderBotAgent", "(", "config", ".", "pg_agent_config", ",", "env", ".", "idsgame_config", ".", "game_config", ",", "\n", "config", ".", "pg_agent_config", ".", "defender_load_path", ",", "env", "=", "env", ")", "\n", "", "else", ":", "\n", "                ", "raise", "AssertionError", "(", "\"Defender type not recognized: {}\"", ".", "format", "(", "config", ".", "defender_type", ")", ")", "\n", "", "env", ".", "idsgame_config", ".", "defender_agent", "=", "defender", "\n", "", "ManualAttackAgent", "(", "env", ".", "idsgame_config", ")", "\n", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.manual_play_defender": [[275, 321], ["gym.make", "ManualDefenseAgent", "issubclass", "AssertionError", "gym_idsgame.agents.training_agents.q_learning.tabular_q_learning.tabular_q_attacker_bot_agent.TabularQAttackerBotAgent", "type", "ValueError", "gym_idsgame.agents.bot_agents.random_attack_bot_agent.RandomAttackBotAgent", "gym_idsgame.agents.bot_agents.attack_maximal_value_bot_agent.AttackMaximalValueBotAgent", "gym_idsgame.agents.training_agents.policy_gradient.reinforce.reinforce_attacker_bot_agent.ReinforceAttackerBotAgent", "ValueError", "gym_idsgame.agents.training_agents.openai_baselines.ppo.ppo_attacker_bot_agent.PPOBaselineAttackerBotAgent", "AssertionError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type"], ["", "@", "staticmethod", "\n", "def", "manual_play_defender", "(", "config", ":", "ClientConfig", ")", "->", "IdsGameEnv", ":", "\n", "        ", "\"\"\"\n        Starts an experiment with a manual defender player against some bot\n\n        :param config: the configuration of the experiment\n        :return: the created environment\n        \"\"\"", "\n", "env", ":", "IdsGameEnv", "=", "gym", ".", "make", "(", "config", ".", "env_name", ",", "idsgame_config", "=", "config", ".", "idsgame_config", ",", "\n", "save_dir", "=", "config", ".", "output_dir", "+", "\"/results/data\"", ",", "\n", "initial_state_path", "=", "config", ".", "initial_state_path", ")", "\n", "if", "config", ".", "title", "is", "not", "None", ":", "\n", "            ", "env", ".", "idsgame_config", ".", "render_config", ".", "title", "=", "config", ".", "title", "\n", "", "if", "not", "config", ".", "bot_attacker", ":", "\n", "            ", "if", "not", "issubclass", "(", "type", "(", "env", ")", ",", "DefenderEnv", ")", ":", "\n", "                ", "raise", "AssertionError", "(", "\"Manual defender play is only supported for defender-envs\"", ")", "\n", "", "", "env", ".", "idsgame_config", ".", "game_config", ".", "manual_defender", "=", "True", "\n", "if", "config", ".", "bot_attacker", ":", "\n", "            ", "attacker", ":", "BotAgent", "=", "None", "\n", "if", "config", ".", "attacker_type", "==", "AgentType", ".", "TABULAR_Q_AGENT", ".", "value", ":", "\n", "                ", "if", "config", ".", "q_agent_config", "is", "None", "or", "config", ".", "q_agent_config", ".", "attacker_load_path", "is", "None", ":", "\n", "                    ", "raise", "ValueError", "(", "\"To run a simulation with a tabular Q-agent, the path to the saved \"", "\n", "\"Q-table must be specified\"", ")", "\n", "", "attacker", "=", "TabularQAttackerBotAgent", "(", "env", ".", "idsgame_config", ".", "game_config", ",", "\n", "config", ".", "q_agent_config", ".", "attacker_load_path", ")", "\n", "", "elif", "config", ".", "attacker_type", "==", "AgentType", ".", "RANDOM", ".", "value", ":", "\n", "                ", "attacker", "=", "RandomAttackBotAgent", "(", "env", ".", "idsgame_config", ".", "game_config", ",", "env", ")", "\n", "", "elif", "config", ".", "attacker_type", "==", "AgentType", ".", "ATTACK_MAXIMAL_VALUE", ".", "value", ":", "\n", "                ", "attacker", "=", "AttackMaximalValueBotAgent", "(", "env", ".", "idsgame_config", ".", "game_config", ",", "env", ")", "\n", "", "elif", "config", ".", "attacker_type", "==", "AgentType", ".", "REINFORCE_AGENT", ".", "value", ":", "\n", "                ", "if", "config", ".", "pg_agent_config", "is", "None", "or", "config", ".", "pg_agent_config", ".", "attacker_load_path", "is", "None", ":", "\n", "                    ", "raise", "ValueError", "(", "\"To run a simulation with a pretrained REINFORCE agent, the path to the saved \"", "\n", "\"model must be specified\"", ")", "\n", "", "attacker", "=", "ReinforceAttackerBotAgent", "(", "config", ".", "pg_agent_config", ",", "env", ".", "idsgame_config", ".", "game_config", ",", "\n", "config", ".", "pg_agent_config", ".", "attacker_load_path", ")", "\n", "", "elif", "config", ".", "attacker_type", "==", "AgentType", ".", "PPO_OPENAI_AGENT", ".", "value", ":", "\n", "                ", "if", "config", ".", "pg_agent_config", "is", "None", "or", "config", ".", "pg_agent_config", ".", "attacker_load_path", "is", "None", ":", "\n", "                    ", "raise", "ValueError", "(", "\"To run a simulation with a pretrained OpenAIPPO agent, the path to the saved \"", "\n", "\"model must be specified\"", ")", "\n", "", "attacker", "=", "PPOBaselineAttackerBotAgent", "(", "config", ".", "pg_agent_config", ",", "env", ".", "idsgame_config", ".", "game_config", ",", "\n", "config", ".", "pg_agent_config", ".", "attacker_load_path", ",", "env", "=", "env", ")", "\n", "", "else", ":", "\n", "                ", "raise", "AssertionError", "(", "\"Attacker type not recognized: {}\"", ".", "format", "(", "config", ".", "attacker_type", ")", ")", "\n", "", "env", ".", "idsgame_config", ".", "attacker_agent", "=", "attacker", "\n", "", "ManualDefenseAgent", "(", "env", ".", "idsgame_config", ")", "\n", "return", "env", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.simulation.simulator.Simulator.__init__": [[18, 33], ["gym_idsgame.agents.dao.experiment_result.ExperimentResult", "tqdm.tqdm", "logging.getLogger"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "env", ":", "IdsGameEnv", ",", "config", ":", "SimulationConfig", ")", ":", "\n", "        ", "\"\"\"\n        Class constructor, initializes the class with a given environment and simulation config\n\n        :param env: the openAIGym environment for the simulation\n        :param config: the simulation configuration\n        \"\"\"", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "env", "=", "env", "\n", "self", ".", "experiment_result", "=", "ExperimentResult", "(", ")", "\n", "self", ".", "outer", "=", "tqdm", ".", "tqdm", "(", "total", "=", "self", ".", "config", ".", "num_episodes", ",", "desc", "=", "'Episode'", ",", "position", "=", "0", ")", "\n", "if", "self", ".", "config", ".", "logger", "is", "None", ":", "\n", "            ", "self", ".", "config", ".", "logger", "=", "logging", ".", "getLogger", "(", "'Simulation'", ")", "\n", "", "self", ".", "attacker", "=", "self", ".", "env", ".", "idsgame_config", ".", "attacker_agent", "\n", "self", ".", "defender", "=", "self", ".", "env", ".", "idsgame_config", ".", "defender_agent", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.simulation.simulator.Simulator.simulate": [[34, 97], ["simulator.Simulator.config.logger.info", "str", "simulator.Simulator.env.reset", "range", "simulator.Simulator.env.close", "simulator.Simulator.config.logger.info", "time.time", "len", "simulator.Simulator.config.logger.warning", "gym_idsgame.envs.rendering.video.idsgame_monitor.IdsGameMonitor", "simulator.Simulator.config.logger.info", "episode_steps.append", "simulator.Simulator.env.reset", "simulator.Simulator.outer.update", "AssertionError", "simulator.Simulator.defender.action", "simulator.Simulator.attacker.action", "simulator.Simulator.env.step", "simulator.Simulator.env.render", "time.sleep", "simulator.Simulator.log_metrics", "simulator.Simulator.env.generate_gif", "simulator.Simulator.env.render", "time.sleep", "str"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.random_defense_bot_agent.RandomDefenseBotAgent.action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.random_defense_bot_agent.RandomDefenseBotAgent.action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_metrics", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.generate_gif", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render"], ["", "def", "simulate", "(", "self", ")", "->", "ExperimentResult", ":", "\n", "        ", "\"\"\"\n        Runs a simulation using the defined config and environment\n\n        :return: the simulation result\n        \"\"\"", "\n", "self", ".", "config", ".", "logger", ".", "info", "(", "\"Starting Simulation\"", ")", "\n", "time_str", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "\n", "if", "len", "(", "self", ".", "experiment_result", ".", "avg_episode_steps", ")", ">", "0", ":", "\n", "            ", "self", ".", "config", ".", "logger", ".", "warning", "(", "\"starting simulation with a non-empty result object\"", ")", "\n", "", "if", "self", ".", "config", ".", "num_episodes", "<", "1", ":", "\n", "            ", "return", "\n", "", "done", "=", "False", "\n", "\n", "# Video config", "\n", "if", "self", ".", "config", ".", "video", ":", "\n", "            ", "if", "self", ".", "config", ".", "video_dir", "is", "None", ":", "\n", "                ", "raise", "AssertionError", "(", "\"Video is set to True but no video_dir is provided, please specify \"", "\n", "\"the video_dir argument\"", ")", "\n", "", "self", ".", "env", "=", "IdsGameMonitor", "(", "self", ".", "env", ",", "self", ".", "config", ".", "video_dir", "+", "\"/\"", "+", "time_str", ",", "force", "=", "True", ",", "\n", "video_frequency", "=", "self", ".", "config", ".", "video_frequency", ")", "\n", "self", ".", "env", ".", "metadata", "[", "\"video.frames_per_second\"", "]", "=", "self", ".", "config", ".", "video_fps", "\n", "\n", "# Tracking metrics", "\n", "", "episode_steps", "=", "[", "]", "\n", "\n", "# Simulate", "\n", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "for", "episode", "in", "range", "(", "self", ".", "config", ".", "num_episodes", ")", ":", "\n", "            ", "i", "=", "0", "\n", "episode_step", "=", "0", "\n", "while", "not", "done", ":", "\n", "                ", "if", "self", ".", "config", ".", "render", ":", "\n", "                    ", "self", ".", "env", ".", "render", "(", ")", "\n", "time", ".", "sleep", "(", "self", ".", "config", ".", "sleep", ")", "\n", "", "i", "=", "i", "+", "1", "\n", "defense_id", "=", "self", ".", "defender", ".", "action", "(", "self", ".", "env", ".", "state", ")", "\n", "attack_id", "=", "self", ".", "attacker", ".", "action", "(", "self", ".", "env", ".", "state", ")", "\n", "action", "=", "(", "attack_id", ",", "defense_id", ")", "\n", "obs", ",", "_", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "episode_step", "+=", "1", "\n", "", "if", "self", ".", "config", ".", "render", ":", "\n", "                ", "self", ".", "env", ".", "render", "(", ")", "\n", "time", ".", "sleep", "(", "self", ".", "config", ".", "sleep", ")", "\n", "", "self", ".", "config", ".", "logger", ".", "info", "(", "\"Simulation episode: {}, Game ended after {} steps\"", ".", "format", "(", "episode", ",", "i", ")", ")", "\n", "episode_steps", ".", "append", "(", "episode_step", ")", "\n", "\n", "# Log average metrics every <self.config.eval_log_frequency> episodes", "\n", "if", "episode", "%", "self", ".", "config", ".", "log_frequency", "==", "0", ":", "\n", "                ", "self", ".", "log_metrics", "(", "self", ".", "experiment_result", ",", "episode_steps", ")", "\n", "episode_steps", "=", "[", "]", "\n", "", "if", "self", ".", "config", ".", "gifs", "and", "self", ".", "config", ".", "video", ":", "\n", "                ", "self", ".", "env", ".", "generate_gif", "(", "self", ".", "config", ".", "gif_dir", "+", "\"/episode_\"", "+", "str", "(", "episode", ")", "+", "\"_\"", "\n", "+", "time_str", "+", "\".gif\"", ",", "self", ".", "config", ".", "video_fps", ")", "\n", "\n", "", "done", "=", "False", "\n", "obs", "=", "self", ".", "env", ".", "reset", "(", "update_stats", "=", "True", ")", "\n", "self", ".", "outer", ".", "update", "(", "1", ")", "\n", "\n", "", "self", ".", "env", ".", "close", "(", ")", "\n", "self", ".", "config", ".", "logger", ".", "info", "(", "\"Simulation Complete\"", ")", "\n", "return", "self", ".", "experiment_result", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.simulation.simulator.Simulator.log_metrics": [[98, 118], ["numpy.mean", "simulator.Simulator.outer.set_description_str", "simulator.Simulator.config.logger.info", "result.avg_episode_steps.append", "result.hack_probability.append", "result.attacker_cumulative_reward.append", "result.defender_cumulative_reward.append", "simulator.Simulator.env.hack_probability", "simulator.Simulator.env.hack_probability"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.hack_probability", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.hack_probability"], ["", "def", "log_metrics", "(", "self", ",", "result", ":", "ExperimentResult", ",", "episode_steps", ":", "list", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Logs average metrics for the last <self.config.log_frequency> episodes\n\n        :param result: the result object to add the results to\n        :param episode_steps: list of episode steps for the last <self.config.log_frequency> episodes\n        :return: None\n        \"\"\"", "\n", "avg_episode_steps", "=", "np", ".", "mean", "(", "episode_steps", ")", "\n", "log_str", "=", "\"avg_t:{:.2f},avg_h:{:.2f},acc_A_R:{:.2f},\"", "\"acc_D_R:{:.2f}\"", ".", "format", "(", "avg_episode_steps", ",", "\n", "self", ".", "env", ".", "hack_probability", "(", ")", ",", "\n", "self", ".", "env", ".", "state", ".", "attacker_cumulative_reward", ",", "\n", "self", ".", "env", ".", "state", ".", "defender_cumulative_reward", ")", "\n", "self", ".", "outer", ".", "set_description_str", "(", "log_str", ")", "\n", "self", ".", "config", ".", "logger", ".", "info", "(", "log_str", ")", "\n", "result", ".", "avg_episode_steps", ".", "append", "(", "avg_episode_steps", ")", "\n", "result", ".", "hack_probability", ".", "append", "(", "self", ".", "env", ".", "hack_probability", "(", ")", ")", "\n", "result", ".", "attacker_cumulative_reward", ".", "append", "(", "self", ".", "env", ".", "state", ".", "attacker_cumulative_reward", ")", "\n", "result", ".", "defender_cumulative_reward", ".", "append", "(", "self", ".", "env", ".", "state", ".", "defender_cumulative_reward", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.simulation_config.SimulationConfig.__init__": [[5, 19], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num_episodes", ":", "int", "=", "10", ",", "video_fps", "=", "5", ",", "\n", "video", "=", "False", ",", "gif_dir", "=", "None", ",", "video_dir", "=", "None", ",", "gifs", "=", "False", ",", "render", "=", "False", ",", "sleep", "=", "0.35", ",", "\n", "log_frequency", "=", "1", ",", "video_frequency", "=", "100", ")", ":", "\n", "        ", "self", ".", "num_episodes", "=", "num_episodes", "\n", "self", ".", "video_fps", "=", "video_fps", "\n", "self", ".", "video", "=", "video", "\n", "self", ".", "gif_dir", "=", "gif_dir", "\n", "self", ".", "video_dir", "=", "video_dir", "\n", "self", ".", "gifs", "=", "gifs", "\n", "self", ".", "render", "=", "render", "\n", "self", ".", "sleep", "=", "sleep", "\n", "self", ".", "log_frequency", "=", "log_frequency", "\n", "self", ".", "logger", "=", "None", "\n", "self", ".", "video_frequency", "=", "video_frequency", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.simulation_config.SimulationConfig.to_str": [[20, 32], ["None"], "methods", ["None"], ["", "def", "to_str", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        :return: a string with information about all of the parameters\n        \"\"\"", "\n", "return", "\"Hyperparameters: render:{0},sleep:{1},\"", "\"log_frequency:{2},\"", "\"video:{3},video_fps:{4},\"", "\"video_dir:{5},num_episodes:{6},gifs:{7},\"", "\"gifdir:{8},video_frequency:{9}\"", ".", "format", "(", "\n", "self", ".", "render", ",", "self", ".", "sleep", ",", "\n", "self", ".", "log_frequency", ",", "self", ".", "video", ",", "\n", "self", ".", "video_fps", ",", "self", ".", "video_dir", ",", "self", ".", "num_episodes", ",", "self", ".", "gifs", ",", "self", ".", "gif_dir", ",", "self", ".", "video_frequency", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.simulation_config.SimulationConfig.to_csv": [[33, 53], ["open", "csv.writer", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "def", "to_csv", "(", "self", ",", "file_path", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Write parameters to csv file\n\n        :param file_path: path to the file\n        :return: None\n        \"\"\"", "\n", "with", "open", "(", "file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"parameter\"", ",", "\"value\"", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"render\"", ",", "str", "(", "self", ".", "render", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"sleep\"", ",", "str", "(", "self", ".", "sleep", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"log_frequency\"", ",", "str", "(", "self", ".", "log_frequency", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"video\"", ",", "str", "(", "self", ".", "video", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"video_fps\"", ",", "str", "(", "self", ".", "video_fps", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"video_dir\"", ",", "str", "(", "self", ".", "video_dir", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"num_episodes\"", ",", "str", "(", "self", ".", "num_episodes", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"gifs\"", ",", "str", "(", "self", ".", "gifs", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"gifdir\"", ",", "str", "(", "self", ".", "gif_dir", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"video_frequency\"", ",", "str", "(", "self", ".", "video_frequency", ")", "]", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.experiment_result.ExperimentResult.__init__": [[12, 77], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "avg_attacker_episode_rewards", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "avg_defender_episode_rewards", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "avg_episode_steps", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "epsilon_values", ":", "List", "[", "float", "]", "=", "None", ",", "hack_probability", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "attacker_cumulative_reward", ":", "List", "[", "int", "]", "=", "None", ",", "defender_cumulative_reward", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "attacker_wins", ":", "List", "[", "int", "]", "=", "None", ",", "defender_wins", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "avg_episode_loss_attacker", ":", "List", "[", "float", "]", "=", "None", ",", "avg_episode_loss_defender", ":", "List", "[", "float", "]", "=", "None", ",", "\n", "lr_list", ":", "List", "[", "float", "]", "=", "None", ",", "cumulative_hack_probability", ":", "List", "[", "float", "]", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Constructor, initializes the DTO\n\n        :param avg_attacker_episode_rewards: list of episode rewards for attacker\n        :param avg_defender_episode_rewards: list of episode rewards for defender\n        :param avg_episode_steps: list of episode steps\n        :param epsilon_values: list of epsilon values\n        :param hack_probability: list of hack probabilities\n        :param attacker_cumulative_reward: list of attacker cumulative rewards\n        :param defender_cumulative_reward: list of defender cumulative rewards\n        :param attacker_wins: num episodes won by the attacker\n        :param defender_wins: num episodes won by the defender\n        :param avg_episode_loss_attacker: average loss for attacker\n        :param avg_episode_loss_defender: average loss for defender\n        :param lr_list: learning rates\n        :param random_seed: the random seed for reproducibility\n        :param cumulative_hack_probability: list of cumulative hack probabilities\n        \"\"\"", "\n", "self", ".", "avg_attacker_episode_rewards", "=", "avg_attacker_episode_rewards", "\n", "self", ".", "avg_defender_episode_rewards", "=", "avg_defender_episode_rewards", "\n", "self", ".", "avg_episode_steps", "=", "avg_episode_steps", "\n", "self", ".", "epsilon_values", "=", "epsilon_values", "\n", "self", ".", "hack_probability", "=", "hack_probability", "\n", "self", ".", "attacker_cumulative_reward", "=", "attacker_cumulative_reward", "\n", "self", ".", "defender_cumulative_reward", "=", "defender_cumulative_reward", "\n", "self", ".", "attacker_wins", "=", "attacker_wins", "\n", "self", ".", "defender_wins", "=", "defender_wins", "\n", "self", ".", "avg_episode_loss_attacker", "=", "avg_episode_loss_attacker", "\n", "self", ".", "avg_episode_loss_defender", "=", "avg_episode_loss_defender", "\n", "self", ".", "lr_list", "=", "lr_list", "\n", "self", ".", "cumulative_hack_probabiltiy", "=", "cumulative_hack_probability", "\n", "if", "avg_episode_steps", "is", "None", ":", "\n", "            ", "self", ".", "avg_episode_steps", "=", "[", "]", "\n", "", "if", "avg_attacker_episode_rewards", "is", "None", ":", "\n", "            ", "self", ".", "avg_attacker_episode_rewards", "=", "[", "]", "\n", "", "if", "avg_defender_episode_rewards", "is", "None", ":", "\n", "            ", "self", ".", "avg_defender_episode_rewards", "=", "[", "]", "\n", "", "if", "epsilon_values", "is", "None", ":", "\n", "            ", "self", ".", "epsilon_values", "=", "[", "]", "\n", "", "if", "hack_probability", "is", "None", ":", "\n", "            ", "self", ".", "hack_probability", "=", "[", "]", "\n", "", "if", "attacker_cumulative_reward", "is", "None", ":", "\n", "            ", "self", ".", "attacker_cumulative_reward", "=", "[", "]", "\n", "", "if", "defender_cumulative_reward", "is", "None", ":", "\n", "            ", "self", ".", "defender_cumulative_reward", "=", "[", "]", "\n", "", "if", "attacker_wins", "is", "None", ":", "\n", "            ", "self", ".", "attacker_wins", "=", "[", "]", "\n", "", "if", "defender_wins", "is", "None", ":", "\n", "            ", "self", ".", "defender_wins", "=", "[", "]", "\n", "", "if", "avg_episode_loss_attacker", "is", "None", ":", "\n", "            ", "self", ".", "avg_episode_loss_attacker", "=", "[", "]", "\n", "", "if", "avg_episode_loss_defender", "is", "None", ":", "\n", "            ", "self", ".", "avg_episode_loss_defender", "=", "[", "]", "\n", "", "if", "lr_list", "is", "None", ":", "\n", "            ", "self", ".", "lr_list", "=", "[", "]", "\n", "", "if", "cumulative_hack_probability", "is", "None", ":", "\n", "            ", "self", ".", "cumulative_hack_probabiltiy", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.experiment_result.ExperimentResult.to_csv": [[79, 107], ["range", "zip", "len", "open", "csv.writer", "csv.writer.writerow", "len", "filtered_metrics.append", "filtered_metric_labels.append", "csv.writer.writerow"], "methods", ["None"], ["", "", "def", "to_csv", "(", "self", ",", "file_path", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Save result to csv\n\n        :param file_path: path to save the csv file\n        :return: None\n        \"\"\"", "\n", "metrics", "=", "[", "self", ".", "avg_attacker_episode_rewards", ",", "self", ".", "avg_defender_episode_rewards", ",", "\n", "self", ".", "avg_episode_steps", ",", "self", ".", "epsilon_values", ",", "self", ".", "hack_probability", ",", "\n", "self", ".", "attacker_cumulative_reward", ",", "self", ".", "defender_cumulative_reward", ",", "self", ".", "attacker_wins", ",", "\n", "self", ".", "defender_wins", ",", "self", ".", "avg_episode_loss_attacker", ",", "self", ".", "avg_episode_loss_defender", ",", "self", ".", "lr_list", ",", "\n", "self", ".", "cumulative_hack_probabiltiy", "]", "\n", "metric_labels", "=", "[", "\"avg_attacker_episode_rewards\"", ",", "\"avg_defender_episode_rewards\"", ",", "\"avg_episode_steps\"", ",", "\n", "\"epsilon_values\"", ",", "\"hack_probability\"", ",", "\"attacker_cumulative_reward\"", ",", "\n", "\"defender_cumulative_reward\"", ",", "\"attacker_wins\"", ",", "\"defender_wins\"", ",", "\"avg_episode_loss_attacker\"", ",", "\n", "\"avg_episode_loss_defender\"", ",", "\"lr_list\"", ",", "\"cumulative_hack_probability\"", "]", "\n", "filtered_metric_labels", "=", "[", "]", "\n", "filtered_metrics", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "metrics", ")", ")", ":", "\n", "            ", "if", "len", "(", "metrics", "[", "i", "]", ")", ">", "0", ":", "\n", "                ", "filtered_metrics", ".", "append", "(", "metrics", "[", "i", "]", ")", "\n", "filtered_metric_labels", ".", "append", "(", "metric_labels", "[", "i", "]", ")", "\n", "", "", "rows", "=", "zip", "(", "*", "filtered_metrics", ")", "\n", "with", "open", "(", "file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "filtered_metric_labels", ")", "\n", "for", "row", "in", "rows", ":", "\n", "                ", "writer", ".", "writerow", "(", "row", ")", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.attack_defense_event.AttackDefenseEvent.__init__": [[10, 24], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "target_pos", ":", "Union", "[", "int", ",", "int", "]", ",", "attack_defense_type", ":", "int", ",", "attacker_pos", ":", "Union", "[", "int", ",", "int", "]", "=", "None", ",", "\n", "reconnaissance", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Class constructor, initializes the DTO\n\n        :param target_pos: the position of the target node of the event\n        :param attack_defense_type: the type of the event\n        :param attacker_pos: the position of the attacker\n        :param reconnaissance: boolean flag indicating whether it is a reconnaissance activity\n        \"\"\"", "\n", "self", ".", "target_row", ",", "self", ".", "target_col", "=", "target_pos", "\n", "self", ".", "attack_defense_type", "=", "attack_defense_type", "\n", "self", ".", "attacker_pos", "=", "attacker_pos", "\n", "self", ".", "reconnaissance", "=", "reconnaissance", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.render_config.RenderConfig.__init__": [[16, 53], ["render_config.RenderConfig.new_window"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.render_config.RenderConfig.new_window"], ["def", "__init__", "(", "self", ",", "resources_dir", ":", "str", "=", "constants", ".", "RENDERING", ".", "RESOURCES_DIR", ",", "\n", "blink_interval", ":", "float", "=", "constants", ".", "RENDERING", ".", "AGENT_BLINK_INTERVAL", ",", "\n", "num_blinks", ":", "int", "=", "constants", ".", "RENDERING", ".", "AGENT_NUM_BLINKS", ",", "title", "=", "\"IdsGame\"", ",", "\n", "attacker_view", ":", "bool", "=", "False", ",", "defender_view", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Constructor, initializes the DTO\n\n        :param resources_dir: directory with resources for rendering\n        :param blink_interval: the interval for blinking when simulating attack/defense operations\n        :param num_blinks: the number of blinks when simulating attack/defense operations\n        :param attacker_view: boolean flag whether to show the attacker's view (otherwise fully observed view is shown)\n        :param defender_view: boolean flag whether to show the defender's view (otherwise fully observed view is shown)\n        \"\"\"", "\n", "self", ".", "rect_size", "=", "constants", ".", "RENDERING", ".", "RECT_SIZE", "\n", "self", ".", "bg_color", "=", "constants", ".", "RENDERING", ".", "WHITE", "\n", "self", ".", "border_color", "=", "constants", ".", "RENDERING", ".", "BLACK", "\n", "self", ".", "attacker_filename", "=", "constants", ".", "RENDERING", ".", "HACKER_AVATAR_FILENAME", "\n", "self", ".", "server_filename", "=", "constants", ".", "RENDERING", ".", "SERVER_AVATAR_FILENAME", "\n", "self", ".", "data_filename", "=", "constants", ".", "RENDERING", ".", "DATA_AVATAR_FILENAME", "\n", "self", ".", "cage_filename", "=", "constants", ".", "RENDERING", ".", "CAGE_AVATAR_FILENAME", "\n", "self", ".", "glass_filename", "=", "constants", ".", "RENDERING", ".", "GLASS_AVATAR_FILENAME", "\n", "self", ".", "minimum_width", "=", "constants", ".", "RENDERING", ".", "MIN_WIDTH", "\n", "self", ".", "attacker_scale", "=", "constants", ".", "RENDERING", ".", "ATTACKER_AVATAR_SCALE", "\n", "self", ".", "server_scale", "=", "constants", ".", "RENDERING", ".", "SERVER_AVATAR_SCALE", "\n", "self", ".", "data_scale", "=", "constants", ".", "RENDERING", ".", "DATA_AVATAR_SCALE", "\n", "self", ".", "cage_scale", "=", "constants", ".", "RENDERING", ".", "CAGE_AVATAR_SCALE", "\n", "self", ".", "line_width", "=", "constants", ".", "RENDERING", ".", "LINE_WIDTH", "\n", "self", ".", "caption", "=", "constants", ".", "RENDERING", ".", "CAPTION", "\n", "self", ".", "resources_dir", "=", "resources_dir", "\n", "self", ".", "blink_interval", "=", "blink_interval", "\n", "self", ".", "num_blinks", "=", "num_blinks", "\n", "self", ".", "new_window", "(", ")", "\n", "self", ".", "height", "=", "constants", ".", "RENDERING", ".", "DEFAULT_HEIGHT", "\n", "self", ".", "width", "=", "constants", ".", "RENDERING", ".", "MIN_WIDTH", "\n", "self", ".", "title", "=", "title", "\n", "self", ".", "attacker_view", "=", "attacker_view", "\n", "self", ".", "defender_view", "=", "defender_view", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.render_config.RenderConfig.new_window": [[55, 64], ["pyglet.graphics.Batch", "pyglet.graphics.OrderedGroup", "pyglet.graphics.OrderedGroup", "pyglet.graphics.OrderedGroup"], "methods", ["None"], ["", "def", "new_window", "(", "self", ")", ":", "\n", "# in case on a server without pyglet", "\n", "        ", "try", ":", "\n", "            ", "self", ".", "batch", "=", "pyglet", ".", "graphics", ".", "Batch", "(", ")", "\n", "self", ".", "background", "=", "pyglet", ".", "graphics", ".", "OrderedGroup", "(", "0", ")", "\n", "self", ".", "first_foreground", "=", "pyglet", ".", "graphics", ".", "OrderedGroup", "(", "1", ")", "\n", "self", ".", "second_foreground", "=", "pyglet", ".", "graphics", ".", "OrderedGroup", "(", "2", ")", "\n", "", "except", ":", "\n", "            ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.render_config.RenderConfig.manual_default": [[66, 73], ["None"], "methods", ["None"], ["", "", "def", "manual_default", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        default settings for manual rendering\n        :return:  None\n        \"\"\"", "\n", "self", ".", "num_blinks", "=", "constants", ".", "RENDERING", ".", "MANUAL_NUM_BLINKS", "\n", "self", ".", "blink_interval", "=", "constants", ".", "RENDERING", ".", "MANUAL_BLINK_INTERVAL", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.render_config.RenderConfig.set_height": [[75, 83], ["int"], "methods", ["None"], ["", "def", "set_height", "(", "self", ",", "num_rows", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Sets the height for the main gameframe\n\n        :param num_rows: number of rows in the network\n        :return: None\n        \"\"\"", "\n", "self", ".", "height", "=", "constants", ".", "RENDERING", ".", "PANEL_HEIGHT", "+", "int", "(", "(", "self", ".", "rect_size", "/", "1.5", ")", ")", "*", "num_rows", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.render_config.RenderConfig.set_width": [[85, 93], ["max"], "methods", ["None"], ["", "def", "set_width", "(", "self", ",", "num_cols", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Sets the width for the main gameframe\n\n        :param num_cols: the number of columns in the network\n        :return: None\n        \"\"\"", "\n", "self", ".", "width", "=", "max", "(", "self", ".", "minimum_width", ",", "self", ".", "rect_size", "*", "num_cols", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.__init__": [[12, 32], ["network_config.NetworkConfig.__default_graph_layout", "network_config.NetworkConfig.__default_adjacency_matrix", "network_config.NetworkConfig.__max_num_neighbors"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.__default_graph_layout", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.__default_adjacency_matrix", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.__max_num_neighbors"], ["def", "__init__", "(", "self", ",", "num_rows", ":", "int", ",", "num_cols", ":", "int", ",", "connected_layers", ":", "bool", "=", "False", ",", "fully_observed", "=", "False", ",", "\n", "relative_neighbor_positions", ":", "List", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Constructor\n\n        :param num_rows: the number of rows in the network layout (think like a grid)\n        :param num_cols: the number of columns in the network layout\n        :param connected_layers: whether layers are connected with horizontal links or not\n        :param fully_observed: boolean flag that indicates whether the environment\n                              is fully observed or not (by default the environment is partially observed)\n        :param relative_neighbor_positions: max num neighbors and their positions\n        \"\"\"", "\n", "self", ".", "num_rows", "=", "num_rows", "\n", "self", ".", "num_cols", "=", "num_cols", "\n", "self", ".", "connected_layers", "=", "connected_layers", "\n", "self", ".", "graph_layout", "=", "self", ".", "__default_graph_layout", "(", ")", "\n", "self", ".", "adjacency_matrix", "=", "self", ".", "__default_adjacency_matrix", "(", ")", "\n", "self", ".", "fully_observed", "=", "fully_observed", "\n", "self", ".", "relative_neighbor_positions", "=", "relative_neighbor_positions", "\n", "self", ".", "max_neighbors", "=", "self", ".", "__max_num_neighbors", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.__max_num_neighbors": [[33, 39], ["range", "len", "network_config.NetworkConfig.adjacency_matrix[].sum", "max"], "methods", ["None"], ["", "def", "__max_num_neighbors", "(", "self", ")", ":", "\n", "        ", "max_neighbors", "=", "0", "\n", "for", "node", "in", "range", "(", "len", "(", "self", ".", "node_list", ")", ")", ":", "\n", "            ", "num_neighbors", "=", "self", ".", "adjacency_matrix", "[", "node", "]", ".", "sum", "(", ")", "\n", "max_neighbors", "=", "max", "(", "max_neighbors", ",", "num_neighbors", ")", "\n", "", "return", "max_neighbors", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.__default_graph_layout": [[40, 63], ["numpy.zeros", "range", "range"], "methods", ["None"], ["", "def", "__default_graph_layout", "(", "self", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Creates a default graph layout with a specific set of rows\n\n        :return: Numpy array with a grid and in each position in the grid there is a node-type:\n                START, EMPTY, SERVER, or DATA\n        \"\"\"", "\n", "graph_layout", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_rows", ",", "self", ".", "num_cols", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_rows", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "num_cols", ")", ":", "\n", "                ", "if", "i", "==", "self", ".", "num_rows", "-", "1", ":", "\n", "                    ", "if", "j", "==", "self", ".", "num_cols", "//", "2", ":", "\n", "                        ", "graph_layout", "[", "i", "]", "[", "j", "]", "=", "NodeType", ".", "START", ".", "value", "\n", "", "else", ":", "\n", "                        ", "graph_layout", "[", "i", "]", "[", "j", "]", "=", "NodeType", ".", "EMPTY", ".", "value", "\n", "", "", "elif", "i", "==", "0", ":", "\n", "                    ", "if", "j", "==", "self", ".", "num_cols", "//", "2", ":", "\n", "                        ", "graph_layout", "[", "i", "]", "[", "j", "]", "=", "NodeType", ".", "DATA", ".", "value", "\n", "", "else", ":", "\n", "                        ", "graph_layout", "[", "i", "]", "[", "j", "]", "=", "NodeType", ".", "EMPTY", ".", "value", "\n", "", "", "else", ":", "\n", "                    ", "graph_layout", "[", "i", "]", "[", "j", "]", "=", "NodeType", ".", "SERVER", ".", "value", "\n", "", "", "", "return", "graph_layout", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.__default_adjacency_matrix": [[64, 94], ["numpy.zeros", "range", "numpy.zeros.astype", "range"], "methods", ["None"], ["", "def", "__default_adjacency_matrix", "(", "self", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Creates a default adjacency matrix for a given graph layout\n\n        :return: a numpy matrix representing the adjacency matrix with dimension (num_rows*num_cols, num_rows*num_cols)\n        \"\"\"", "\n", "adjacency_matrix", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_rows", "*", "self", ".", "num_cols", ",", "\n", "self", ".", "num_cols", "*", "self", ".", "num_rows", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_rows", "*", "self", ".", "num_cols", ")", ":", "\n", "            ", "row_1", "=", "i", "//", "self", ".", "num_cols", "\n", "col_1", "=", "i", "%", "self", ".", "num_cols", "\n", "for", "j", "in", "range", "(", "self", ".", "num_rows", "*", "self", ".", "num_cols", ")", ":", "\n", "                ", "row_2", "=", "j", "//", "self", ".", "num_cols", "\n", "col_2", "=", "j", "%", "self", ".", "num_cols", "\n", "if", "row_1", "==", "self", ".", "data_row", ":", "\n", "                    ", "if", "row_2", "==", "self", ".", "data_row", "+", "1", "and", "col_1", "==", "self", ".", "data_col", ":", "\n", "                        ", "adjacency_matrix", "[", "i", "]", "[", "j", "]", "=", "1", "\n", "adjacency_matrix", "[", "j", "]", "[", "i", "]", "=", "1", "\n", "", "", "elif", "row_1", "==", "self", ".", "start_row", ":", "\n", "                    ", "if", "row_2", "==", "self", ".", "start_row", "-", "1", "and", "col_1", "==", "self", ".", "start_col", ":", "\n", "                        ", "adjacency_matrix", "[", "i", "]", "[", "j", "]", "=", "1", "\n", "adjacency_matrix", "[", "j", "]", "[", "i", "]", "=", "1", "\n", "", "", "elif", "row_2", "==", "(", "row_1", "+", "1", ")", "and", "col_1", "==", "col_2", "and", "row_1", "!=", "self", ".", "start_row", "and", "row_2", "!=", "self", ".", "start_row", ":", "\n", "                    ", "adjacency_matrix", "[", "i", "]", "[", "j", "]", "=", "1", "\n", "adjacency_matrix", "[", "j", "]", "[", "i", "]", "=", "1", "\n", "", "elif", "self", ".", "connected_layers", ":", "\n", "                    ", "if", "row_2", "==", "row_1", "and", "col_1", "==", "col_2", "+", "1", "and", "row_1", "!=", "self", ".", "start_row", "and", "row_1", "!=", "self", ".", "data_row", ":", "\n", "                        ", "adjacency_matrix", "[", "i", "]", "[", "j", "]", "=", "1", "\n", "adjacency_matrix", "[", "j", "]", "[", "i", "]", "=", "1", "\n", "", "", "", "", "return", "adjacency_matrix", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_coords_of_adjacency_matrix_id": [[96, 106], ["None"], "methods", ["None"], ["", "def", "get_coords_of_adjacency_matrix_id", "(", "self", ",", "node_id", ":", "int", ")", "->", "Union", "[", "int", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Gets the grid-coordinates of a node id\n\n        :param node_id: the id of the node in the adjacency matrix\n        :return: (row,col)\n        \"\"\"", "\n", "row", "=", "node_id", "//", "self", ".", "num_cols", "\n", "col", "=", "node_id", "%", "self", ".", "num_cols", "\n", "return", "row", ",", "col", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_adjacency_matrix_id": [[107, 116], ["None"], "methods", ["None"], ["", "def", "get_adjacency_matrix_id", "(", "self", ",", "row", ":", "int", ",", "col", ":", "int", ")", "->", "Union", "[", "int", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Get the adjacency matrix id from a set of coordinates in the grid\n\n        :param row: the row\n        :param col: the col\n        :return: (row,col)\n        \"\"\"", "\n", "return", "row", "*", "self", ".", "num_cols", "+", "col", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.start_row": [[117, 124], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "start_row", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        :return: the starting row of the attacker\n        \"\"\"", "\n", "start_row", ",", "_", "=", "self", ".", "start_pos", "\n", "return", "start_row", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.data_row": [[125, 132], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "data_row", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        :return: the row of the data node\n        \"\"\"", "\n", "data_row", ",", "_", "=", "self", ".", "data_pos", "\n", "return", "data_row", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.start_col": [[133, 140], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "start_col", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        :return: the starting col of the attacker\n        \"\"\"", "\n", "_", ",", "start_col", "=", "self", ".", "start_pos", "\n", "return", "start_col", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.data_col": [[141, 148], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "data_col", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        :return: the column of the data node\n        \"\"\"", "\n", "_", ",", "data_col", "=", "self", ".", "data_pos", "\n", "return", "data_col", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.start_pos": [[149, 159], ["range", "AssertionError", "range"], "methods", ["None"], ["", "@", "property", "\n", "def", "start_pos", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        :return: the starting position of the attacker\n        \"\"\"", "\n", "for", "i", "in", "range", "(", "self", ".", "num_rows", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "num_cols", ")", ":", "\n", "                ", "if", "self", ".", "graph_layout", "[", "i", "]", "[", "j", "]", "==", "NodeType", ".", "START", ".", "value", ":", "\n", "                    ", "return", "i", ",", "j", "\n", "", "", "", "raise", "AssertionError", "(", "\"Could not find start node in graph layout\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.data_pos": [[160, 170], ["range", "AssertionError", "range"], "methods", ["None"], ["", "@", "property", "\n", "def", "data_pos", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        :return: the position of the data node in the graph\n        \"\"\"", "\n", "for", "i", "in", "range", "(", "self", ".", "num_rows", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "num_cols", ")", ":", "\n", "                ", "if", "self", ".", "graph_layout", "[", "i", "]", "[", "j", "]", "==", "NodeType", ".", "DATA", ".", "value", ":", "\n", "                    ", "return", "i", ",", "j", "\n", "", "", "", "raise", "AssertionError", "(", "\"Could not find data node in graph layout\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.node_list": [[172, 183], ["range", "range", "node_list.append"], "methods", ["None"], ["", "@", "property", "\n", "def", "node_list", "(", "self", ")", "->", "List", "[", "int", "]", ":", "\n", "        ", "\"\"\"\n        :return: a list of node-types where the index in the list corresponds to the node id.\n        \"\"\"", "\n", "node_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_rows", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "num_cols", ")", ":", "\n", "                ", "if", "self", ".", "graph_layout", "[", "i", "]", "[", "j", "]", "!=", "NodeType", ".", "EMPTY", ".", "value", ":", "\n", "                    ", "node_list", ".", "append", "(", "self", ".", "graph_layout", "[", "i", "]", "[", "j", "]", ")", "\n", "", "", "", "return", "node_list", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_pos": [[184, 201], ["range", "ValueError", "range"], "methods", ["None"], ["", "def", "get_node_pos", "(", "self", ",", "node_id", ":", "int", ")", "->", "Union", "[", "int", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Utility function for getting the position in the network of a node id.\n\n        :param node_id: the id of the node\n        :return: the row,col position in the network\n\n        :raises ValueError when the node id cannot be recognized\n        \"\"\"", "\n", "count", "=", "0", "\n", "for", "i", "in", "range", "(", "self", ".", "num_rows", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "num_cols", ")", ":", "\n", "                ", "if", "node_id", "==", "count", "and", "self", ".", "graph_layout", "[", "i", "]", "[", "j", "]", "!=", "NodeType", ".", "EMPTY", ".", "value", ":", "\n", "                    ", "return", "(", "i", ",", "j", ")", "\n", "", "if", "self", ".", "graph_layout", "[", "i", "]", "[", "j", "]", "!=", "NodeType", ".", "EMPTY", ".", "value", ":", "\n", "                    ", "count", "+=", "1", "\n", "", "", "", "raise", "ValueError", "(", "\"Invalid node id: {}\"", ".", "format", "(", "node_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_id": [[202, 222], ["range", "ValueError", "range"], "methods", ["None"], ["", "def", "get_node_id", "(", "self", ",", "pos", ":", "Union", "[", "int", ",", "int", "]", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Gets the node-id of a position in the grid\n\n        :param pos: row,col in the grid\n        :return: the id of the node in the grid, -1 if the node is empty\n\n        :raises ValueError when the position could not be found\n        \"\"\"", "\n", "row", ",", "col", "=", "pos", "\n", "count", "=", "0", "\n", "for", "i", "in", "range", "(", "self", ".", "num_rows", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "num_cols", ")", ":", "\n", "                ", "if", "row", "==", "i", "and", "col", "==", "j", ":", "\n", "                    ", "if", "self", ".", "graph_layout", "[", "i", "]", "[", "j", "]", "==", "NodeType", ".", "EMPTY", ".", "value", ":", "\n", "                        ", "return", "-", "1", "\n", "", "return", "count", "\n", "", "if", "self", ".", "graph_layout", "[", "i", "]", "[", "j", "]", "!=", "NodeType", ".", "EMPTY", ".", "value", ":", "\n", "                    ", "count", "+=", "1", "\n", "", "", "", "raise", "ValueError", "(", "\"Invalid node position\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_row_ids": [[224, 232], ["range", "ids.append"], "methods", ["None"], ["", "def", "get_row_ids", "(", "self", ",", "row", ")", ":", "\n", "        ", "ids", "=", "[", "]", "\n", "count", "=", "0", "\n", "for", "j", "in", "range", "(", "self", ".", "num_cols", ")", ":", "\n", "            ", "if", "self", ".", "graph_layout", "[", "row", "]", "[", "j", "]", "!=", "NodeType", ".", "EMPTY", ".", "value", ":", "\n", "                ", "ids", ".", "append", "(", "count", ")", "\n", "count", "+=", "1", "\n", "", "", "return", "ids", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.__init__": [[13, 79], ["game_config.GameConfig.set_attack_actions", "gym_idsgame.envs.dao.network_config.NetworkConfig", "gym_idsgame.envs.dao.game_state.GameState.load", "gym_idsgame.envs.dao.game_state.GameState", "game_config.GameConfig.initial_state.default_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_attack_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.default_state"], ["def", "__init__", "(", "self", ",", "network_config", ":", "NetworkConfig", "=", "None", ",", "manual_attacker", ":", "bool", "=", "True", ",", "num_layers", ":", "int", "=", "1", ",", "\n", "num_servers_per_layer", ":", "int", "=", "2", ",", "num_attack_types", ":", "int", "=", "10", ",", "max_value", ":", "int", "=", "9", ",", "\n", "initial_state", ":", "GameState", "=", "None", ",", "manual_defender", ":", "bool", "=", "False", ",", "initial_state_path", ":", "str", "=", "None", ",", "\n", "dense_rewards", "=", "False", ",", "min_random_a_val", ":", "int", "=", "0", ",", "min_random_d_val", ":", "int", "=", "0", ",", "\n", "min_random_det_val", ":", "int", "=", "0", ",", "dense_rewards_v2", "=", "False", ",", "reconnaissance_actions", ":", "bool", "=", "False", ",", "\n", "max_random_v_val", ":", "int", "=", "1", ",", "dense_rewards_v3", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Class constructor, initializes the DTO\n\n        :param network_config: the network configuration of the game (e.g. number of nodes and their connectivity)\n        :param manual_attacker: whether the attacker is controlled manually or by an agent\n        :param manual_attacker: whether the defender is controlled manually or by an agent\n        :param num_layers: the number of layers in the network\n        :param num_servers_per_layer: the number of servers per layer in the network\n        :param num_attack_types: the number of attack types\n        :param max_value: max value for a defense/attack attribute\n        :param initial_state: the initial state\n        :param initial_state_path: path to the initial state saved on disk\n        :param dense_rewards: if true, give hacker dense rewards (reward for each intermediate server hacked)\n        :param dense_rewards_v2: if true, give defender reward only when blocking\n        :param min_random_a_val: minimum attack value when randomizing the state\n        :param min_random_d_val: minimum defense value when randomizing the state\n        :param min_random_det_val: minimum detection value when randomizing the state\n        :param reconnaissance_actions: a boolean flag that indicates whether reconnaissance activities are enabled for\n                                       the attacker\n        :param max_random_v_val: maximum random vulnerability value when usign randomized environment\n        \"\"\"", "\n", "self", ".", "reconnaissance_actions", "=", "reconnaissance_actions", "\n", "self", ".", "manual_attacker", "=", "manual_attacker", "\n", "self", ".", "manual_defender", "=", "manual_defender", "\n", "self", ".", "num_layers", "=", "num_layers", "\n", "self", ".", "num_servers_per_layer", "=", "num_servers_per_layer", "\n", "self", ".", "num_attack_types", "=", "num_attack_types", "\n", "self", ".", "max_value", "=", "max_value", "\n", "self", ".", "min_random_a_val", "=", "min_random_a_val", "\n", "self", ".", "min_random_d_val", "=", "min_random_d_val", "\n", "self", ".", "min_random_det_val", "=", "min_random_det_val", "\n", "self", ".", "num_rows", "=", "self", ".", "num_layers", "+", "2", "\n", "self", ".", "num_nodes", "=", "self", ".", "num_layers", "*", "self", ".", "num_servers_per_layer", "+", "2", "# +2 for Start and Data Nodes", "\n", "self", ".", "num_cols", "=", "self", ".", "num_servers_per_layer", "\n", "self", ".", "set_attack_actions", "(", ")", "\n", "self", ".", "num_defense_actions", "=", "(", "self", ".", "num_attack_types", "+", "1", ")", "*", "self", ".", "num_nodes", "\n", "self", ".", "num_states", "=", "self", ".", "num_nodes", "\n", "self", ".", "network_config", "=", "network_config", "\n", "self", ".", "initial_state_path", "=", "initial_state_path", "\n", "self", ".", "defense_val", "=", "2", "\n", "self", ".", "attack_val", "=", "0", "\n", "self", ".", "num_vulnerabilities_per_node", "=", "1", "\n", "self", ".", "det_val", "=", "2", "\n", "self", ".", "dense_rewards_v2", "=", "dense_rewards_v2", "\n", "self", ".", "dense_rewards_v3", "=", "dense_rewards_v3", "\n", "self", ".", "vulnerabilitiy_val", "=", "0", "\n", "self", ".", "max_random_v_val", "=", "max_random_v_val", "\n", "self", ".", "num_vulnerabilities_per_layer", "=", "None", "\n", "if", "network_config", "is", "None", ":", "\n", "            ", "self", ".", "network_config", "=", "NetworkConfig", "(", "self", ".", "num_rows", ",", "self", ".", "num_cols", ",", "connected_layers", "=", "False", ")", "\n", "", "self", ".", "initial_state", "=", "initial_state", "\n", "if", "self", ".", "initial_state", "is", "None", "and", "self", ".", "initial_state_path", "is", "not", "None", ":", "\n", "            ", "self", ".", "initial_state", "=", "GameState", ".", "load", "(", "self", ".", "initial_state", ")", "\n", "", "if", "self", ".", "initial_state", "is", "None", "and", "self", ".", "initial_state_path", "is", "None", ":", "\n", "            ", "self", ".", "initial_state", "=", "GameState", "(", "min_random_a_val", "=", "min_random_a_val", ",", "min_random_det_val", "=", "min_random_det_val", ",", "\n", "min_random_d_val", "=", "min_random_d_val", ",", "max_value", "=", "self", ".", "max_value", ",", "\n", "max_random_v_val", "=", "self", ".", "max_random_v_val", ")", "\n", "self", ".", "initial_state", ".", "default_state", "(", "self", ".", "network_config", ".", "node_list", ",", "self", ".", "network_config", ".", "start_pos", ",", "\n", "self", ".", "num_attack_types", ",", "network_config", "=", "self", ".", "network_config", ",", ")", "\n", "", "self", ".", "dense_rewards", "=", "dense_rewards", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_attack_actions": [[80, 88], ["None"], "methods", ["None"], ["", "def", "set_attack_actions", "(", "self", ",", "local_view", ":", "bool", "=", "False", ")", ":", "\n", "        ", "if", "not", "self", ".", "reconnaissance_actions", ":", "\n", "            ", "self", ".", "num_attack_actions", "=", "self", ".", "num_attack_types", "*", "self", ".", "num_nodes", "\n", "", "else", ":", "\n", "            ", "if", "not", "local_view", ":", "\n", "                ", "self", ".", "num_attack_actions", "=", "(", "self", ".", "num_attack_types", "+", "1", ")", "*", "self", ".", "num_nodes", "\n", "", "else", ":", "\n", "                ", "self", ".", "num_attack_actions", "=", "(", "self", ".", "num_attack_types", "+", "1", ")", "*", "self", ".", "network_config", ".", "max_neighbors", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state": [[89, 97], ["gym_idsgame.envs.dao.game_state.GameState.load"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load"], ["", "", "", "def", "set_load_initial_state", "(", "self", ",", "initial_state_path", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Sets the initial state by loading it from disk\n\n        :param initial_state_path:\n        :return: None\n        \"\"\"", "\n", "self", ".", "initial_state", "=", "GameState", ".", "load", "(", "initial_state_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state": [[98, 131], ["game_config.GameConfig.initial_state.set_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.set_state"], ["", "def", "set_initial_state", "(", "self", ",", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "\n", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "vulnerability_val", "=", "0", ",", "\n", "num_vulnerabilities_per_layer", "=", "None", ",", "randomize_visibility", ":", "bool", "=", "False", ",", "\n", "visibility_p", ":", "float", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"\n        Utility function for setting the initial game state\n\n        :param defense_val: defense value for defense types that are not vulnerable\n        :param attack_val: attack value for attack types\n        :param num_vulnerabilities_per_node: number of vulnerabilities per node\n        :param det_val: detection value per node\n        :param vulnerability_val: defense value for defense types that are vulnerable\n        :param num_vulnerabilities_per_layer: number of vulnerabilities per layer\n        :param min_random_val: minimum val when randomizing the state\n        :param randomize_state: boolean flag whether to create the state randomly\n        :param randomize_visibility: boolean flag whether to randomize visibility for partially observed envs\n        :return:\n        \"\"\"", "\n", "if", "num_vulnerabilities_per_layer", "is", "None", ":", "\n", "            ", "num_vulnerabilities_per_layer", "=", "self", ".", "num_servers_per_layer", "\n", "", "self", ".", "defense_val", "=", "defense_val", "\n", "self", ".", "attack_val", "=", "attack_val", "\n", "self", ".", "num_vulnerabilities_per_layer", "=", "num_vulnerabilities_per_layer", "\n", "self", ".", "det_val", "=", "det_val", "\n", "self", ".", "vulnerabilitiy_val", "=", "vulnerability_val", "\n", "self", ".", "num_vulnerabilities_per_node", "=", "num_vulnerabilities_per_node", "\n", "self", ".", "initial_state", ".", "set_state", "(", "self", ".", "network_config", ".", "node_list", ",", "self", ".", "num_attack_types", ",", "defense_val", "=", "defense_val", ",", "\n", "attack_val", "=", "attack_val", ",", "num_vulnerabilities_per_node", "=", "num_vulnerabilities_per_node", ",", "\n", "det_val", "=", "det_val", ",", "vulnerability_val", "=", "vulnerability_val", ",", "\n", "network_config", "=", "self", ".", "network_config", ",", "\n", "num_vulnerabilities_per_layer", "=", "num_vulnerabilities_per_layer", ",", "\n", "randomize_visibility", "=", "randomize_visibility", ",", "\n", "visibility_p", "=", "visibility_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.get_attacker_observation_space": [[132, 147], ["numpy.array", "gym.spaces.Box", "numpy.array", "numpy.zeros", "numpy.array", "numpy.zeros"], "methods", ["None"], ["", "def", "get_attacker_observation_space", "(", "self", ")", "->", "gym", ".", "spaces", ".", "Box", ":", "\n", "        ", "\"\"\"\n        Creates an OpenAI-Gym Space for the game observation\n\n        :return: observation space\n        \"\"\"", "\n", "if", "not", "self", ".", "reconnaissance_actions", ":", "\n", "            ", "high_row", "=", "np", ".", "array", "(", "[", "self", ".", "max_value", "]", "*", "(", "self", ".", "num_attack_types", "+", "1", ")", ")", "\n", "low", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_nodes", ",", "self", ".", "num_attack_types", "+", "1", ")", ")", "\n", "", "else", ":", "\n", "            ", "high_row", "=", "np", ".", "array", "(", "[", "self", ".", "max_value", "]", "*", "(", "self", ".", "num_attack_types", "*", "2", "+", "1", ")", ")", "\n", "low", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_nodes", ",", "self", ".", "num_attack_types", "*", "2", "+", "1", ")", ")", "\n", "", "high", "=", "np", ".", "array", "(", "[", "high_row", "]", "*", "self", ".", "num_nodes", ")", "\n", "observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "low", "=", "low", ",", "high", "=", "high", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "return", "observation_space", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.get_defender_observation_space": [[148, 159], ["numpy.array", "numpy.array", "numpy.zeros", "gym.spaces.Box"], "methods", ["None"], ["", "def", "get_defender_observation_space", "(", "self", ")", "->", "gym", ".", "spaces", ".", "Box", ":", "\n", "        ", "\"\"\"\n        Creates an OpenAI-Gym Space for the game observation\n\n        :return: observation space\n        \"\"\"", "\n", "high_row", "=", "np", ".", "array", "(", "[", "self", ".", "max_value", "]", "*", "(", "self", ".", "num_attack_types", "+", "1", ")", ")", "\n", "high", "=", "np", ".", "array", "(", "[", "high_row", "]", "*", "1", ")", "\n", "low", "=", "np", ".", "zeros", "(", "(", "1", ",", "self", ".", "num_attack_types", "+", "1", ")", ")", "\n", "observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "low", "=", "low", ",", "high", "=", "high", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "return", "observation_space", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.get_action_space": [[160, 171], ["gym.spaces.Discrete", "gym.spaces.Discrete"], "methods", ["None"], ["", "def", "get_action_space", "(", "self", ",", "defender", ":", "bool", "=", "False", ")", "->", "gym", ".", "spaces", ".", "Discrete", ":", "\n", "        ", "\"\"\"\n        Creates an OpenAi-Gym space for the actions in the environment\n\n        :param defender: boolean flag if defender or not\n        :return: action space\n        \"\"\"", "\n", "if", "defender", ":", "\n", "            ", "return", "gym", ".", "spaces", ".", "Discrete", "(", "self", ".", "num_defense_actions", ")", "\n", "", "else", ":", "\n", "            ", "return", "gym", ".", "spaces", ".", "Discrete", "(", "self", ".", "num_attack_actions", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.__init__": [[17, 80], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "attack_values", ":", "np", ".", "ndarray", "=", "None", ",", "defense_values", ":", "np", ".", "ndarray", "=", "None", ",", "\n", "defense_det", ":", "np", ".", "ndarray", "=", "None", ",", "\n", "attacker_pos", ":", "Union", "[", "int", ",", "int", "]", "=", "(", "0", ",", "0", ")", ",", "game_step", ":", "int", "=", "0", ",", "attacker_cumulative_reward", ":", "int", "=", "0", ",", "\n", "defender_cumulative_reward", ":", "int", "=", "0", ",", "\n", "num_games", ":", "int", "=", "0", ",", "attack_events", ":", "List", "[", "AttackDefenseEvent", "]", "=", "None", ",", "\n", "defense_events", ":", "List", "[", "AttackDefenseEvent", "]", "=", "None", ",", "\n", "done", ":", "bool", "=", "False", ",", "detected", ":", "bool", "=", "False", ",", "attack_type", ":", "int", "=", "0", ",", "num_hacks", ":", "int", "=", "0", ",", "\n", "hacked", ":", "bool", "=", "False", ",", "min_random_a_val", ":", "int", "=", "0", ",", "min_random_d_val", ":", "int", "=", "0", ",", "\n", "min_random_det_val", ":", "int", "=", "0", ",", "\n", "max_value", ":", "int", "=", "9", ",", "reconnaissance_state", ":", "np", ".", "ndarray", "=", "None", ",", "max_random_v_val", "=", "2", ")", ":", "\n", "        ", "\"\"\"\n        Constructor, initializes the DTO\n\n        :param attack_values: the attack values for resource nodes in the network\n        :param defense_values: the defense values for resource nodes in the network\n        :param defense_det: detection values for resource nodes in the network\n        :param attacker_pos: position of attacker in the network\n        :param game_step: the number of steps of the current game\n        :param attacker_cumulative_reward: the cumulative reward over all games of the attacker\n        :param defender_cumulative_reward: the cumulative reward over all games of the defender\n        :param num_games: the number of games played\n        :param attack_events: attack events that are in queue to be simulated\n        :param defense_events: defense events that are in queue to be simulated\n        :param done: True if the game is over and otherwise False\n        :param detected: True if the attacker is in a detected state, otherwise False\n        :param attack_type: the type of the last attack\n        :param num_hacks: number of wins for the attacker\n        :param hacked: True if the attacker hacked the data node otherwise False\n        :param min_random_a_val: minimum attack value when randomizing the state\n        :param min_random_d_val: minimum defense value when randomizing the state\n        :param min_random_det_val: minimum detection value when randomizing the state\n        :param max_value: the maximum value of attack/defense attributes\n        :param reconnaissance_state: the state of the reconnaissance activities by the attacker\n        :param max_random_v_val\n        \"\"\"", "\n", "self", ".", "attack_values", "=", "attack_values", "\n", "self", ".", "defense_values", "=", "defense_values", "\n", "self", ".", "defense_det", "=", "defense_det", "\n", "self", ".", "attacker_pos", "=", "attacker_pos", "\n", "self", ".", "reconnaissance_state", "=", "reconnaissance_state", "\n", "self", ".", "game_step", "=", "game_step", "\n", "self", ".", "attacker_cumulative_reward", "=", "attacker_cumulative_reward", "\n", "self", ".", "defender_cumulative_reward", "=", "defender_cumulative_reward", "\n", "self", ".", "num_games", "=", "num_games", "\n", "self", ".", "attack_events", "=", "attack_events", "\n", "self", ".", "defense_events", "=", "defense_events", "\n", "self", ".", "min_random_a_val", "=", "min_random_a_val", "\n", "self", ".", "min_random_d_val", "=", "min_random_d_val", "\n", "self", ".", "min_random_det_val", "=", "min_random_det_val", "\n", "self", ".", "max_value", "=", "max_value", "\n", "if", "self", ".", "attack_events", "is", "None", ":", "\n", "            ", "self", ".", "attack_events", "=", "[", "]", "\n", "", "if", "self", ".", "defense_events", "is", "None", ":", "\n", "            ", "self", ".", "defense_events", "=", "[", "]", "\n", "", "self", ".", "done", "=", "done", "\n", "self", ".", "detected", "=", "detected", "\n", "self", ".", "attack_defense_type", "=", "attack_type", "\n", "self", ".", "num_hacks", "=", "num_hacks", "\n", "self", ".", "hacked", "=", "hacked", "\n", "self", ".", "action_descriptors", "=", "[", "\"Injection\"", ",", "\"Authentication\"", ",", "\"CrossSite\"", ",", "\"References\"", ",", "\"Misssconfiguration\"", ",", "\n", "\"Exposure\"", ",", "\"Access\"", ",", "\"Forgery\"", ",", "\"Vulnerabilities\"", ",", "\"Redirects\"", "]", "\n", "self", ".", "reconnaissance_actions", "=", "[", "]", "\n", "self", ".", "max_random_v_val", "=", "max_random_v_val", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.default_state": [[81, 112], ["game_state.GameState.set_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.set_state"], ["", "def", "default_state", "(", "self", ",", "node_list", ":", "List", "[", "int", "]", ",", "attacker_pos", ":", "Union", "[", "int", ",", "int", "]", ",", "num_attack_types", ":", "int", ",", "\n", "network_config", ":", "NetworkConfig", ",", "randomize_state", ":", "bool", "=", "False", ",", "\n", "randomize_visibility", ":", "bool", "=", "False", ",", "visibility_p", ":", "float", "=", "0.5", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Creates a default state\n\n        :param graph_layout: the layout of the network to create a default state for\n        :param num_rows: the number of rows in the grid network\n        :param num_cols: the number of columns in the grid network\n        :param num_attack_types: the number of attack types\n        :param network_config: network config\n        :param randomize_state: boolean flag whether to create the state randomly\n        :param randomize_state: boolean flag whether to create the state randomly\n        :param randomize_visibility: boolean flag whether to randomize visibility for partially observed envs\n        :return: None\n        \"\"\"", "\n", "self", ".", "set_state", "(", "node_list", ",", "num_attack_types", ",", "network_config", "=", "network_config", ",", "\n", "num_vulnerabilities_per_layer", "=", "network_config", ".", "num_cols", ",", "randomize_state", "=", "randomize_state", ",", "\n", "randomize_visibility", "=", "randomize_visibility", ",", "visibility_p", "=", "visibility_p", ")", "\n", "self", ".", "attacker_pos", "=", "attacker_pos", "\n", "self", ".", "game_step", "=", "0", "\n", "self", ".", "attacker_cumulative_reward", "=", "0", "\n", "self", ".", "defender_cumulative_reward", "=", "0", "\n", "self", ".", "num_games", "=", "0", "\n", "self", ".", "attack_events", "=", "[", "]", "\n", "self", ".", "defense_events", "=", "[", "]", "\n", "self", ".", "done", "=", "False", "\n", "self", ".", "detected", "=", "False", "\n", "self", ".", "attack_defense_type", "=", "0", "\n", "self", ".", "num_hacks", "=", "0", "\n", "self", ".", "hacked", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.set_state": [[114, 188], ["len", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.full", "numpy.zeros", "range", "range", "numpy.zeros.astype", "numpy.zeros.astype", "numpy.zeros.astype", "numpy.full.astype", "numpy.random.choice", "network_config.get_node_pos", "min", "range", "numpy.random.choice", "range", "len", "d_vals.append", "a_vals.append", "numpy.random.rand", "game_state.GameState.reconnaissance_actions.append", "max", "max", "max", "max", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "numpy.random.choice", "list", "list", "list", "list", "range", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_pos"], ["", "def", "set_state", "(", "self", ",", "node_list", ":", "List", ",", "num_attack_types", ":", "int", ",", "defense_val", ":", "int", "=", "2", ",", "attack_val", ":", "int", "=", "0", ",", "\n", "num_vulnerabilities_per_node", ":", "int", "=", "1", ",", "det_val", ":", "int", "=", "2", ",", "vulnerability_val", ":", "int", "=", "0", ",", "\n", "num_vulnerabilities_per_layer", ":", "int", "=", "1", ",", "\n", "network_config", ":", "NetworkConfig", "=", "None", ",", "randomize_state", ":", "bool", "=", "False", ",", "\n", "randomize_visibility", ":", "bool", "=", "False", ",", "visibility_p", ":", "float", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"\n        Sets the state\n\n        :param node_list: list of nodes\n        :param num_attack_types:  number of attack types\n        :param defense_val: defense value for defense types that are not vulnerable\n        :param attack_val: attack value for attack types\n        :param num_vulnerabilities_per_node: number of vulnerabilities per node\n        :param det_val: detection value per node\n        :param vulnerability_val: defense value for defense types that are vulnerable\n        :param num_vulnerabilities_per_layer: number of vulnerabilities per layer\n        :param network_config: network configuration\n        :param randomize_state: boolean flag whether to create the state randomly\n        :param randomize_visibility: boolean flag whether to randomize visibility for partially observed envs\n        :return: None\n        \"\"\"", "\n", "num_nodes", "=", "len", "(", "node_list", ")", "\n", "attack_values", "=", "np", ".", "zeros", "(", "(", "num_nodes", ",", "num_attack_types", ")", ")", "\n", "defense_values", "=", "np", ".", "zeros", "(", "(", "num_nodes", ",", "num_attack_types", ")", ")", "\n", "det_values", "=", "np", ".", "zeros", "(", "num_nodes", ")", "\n", "reconnaissance_state", "=", "np", ".", "full", "(", "(", "num_nodes", ",", "num_attack_types", ")", ",", "constants", ".", "GAME_CONFIG", ".", "INITIAL_RECONNAISSANCE_STATE", ")", "\n", "\n", "d_val", "=", "defense_val", "\n", "a_val", "=", "attack_val", "\n", "de_val", "=", "det_val", "\n", "v_val", "=", "vulnerability_val", "\n", "\n", "vulnerabilities_per_layer", "=", "np", ".", "zeros", "(", "(", "network_config", ".", "num_rows", ",", "network_config", ".", "num_cols", ")", ")", "\n", "for", "row", "in", "range", "(", "1", ",", "network_config", ".", "num_rows", "-", "1", ")", ":", "\n", "            ", "vulnerabilities", "=", "np", ".", "random", ".", "choice", "(", "network_config", ".", "num_cols", ",", "size", "=", "num_vulnerabilities_per_layer", ",", "\n", "replace", "=", "False", ")", "\n", "vulnerabilities_per_layer", "[", "row", "]", "[", "vulnerabilities", "]", "=", "1", "\n", "\n", "", "for", "node_id", "in", "range", "(", "num_nodes", ")", ":", "\n", "            ", "row", ",", "col", "=", "network_config", ".", "get_node_pos", "(", "node_id", ")", "\n", "num_vuln", "=", "min", "(", "num_vulnerabilities_per_node", ",", "num_attack_types", ")", "\n", "vulnerabilities", "=", "[", "]", "\n", "if", "vulnerabilities_per_layer", "[", "row", "]", "[", "col", "]", "==", "1", "or", "node_list", "[", "node_id", "]", "==", "NodeType", ".", "DATA", ".", "value", ":", "\n", "                ", "vulnerabilities", "=", "np", ".", "random", ".", "choice", "(", "num_attack_types", ",", "size", "=", "num_vuln", ")", "# random vulnerability per node", "\n", "", "if", "node_list", "[", "node_id", "]", "==", "NodeType", ".", "DATA", ".", "value", "or", "node_list", "[", "node_id", "]", "==", "NodeType", ".", "SERVER", ".", "value", ":", "\n", "                ", "d_vals", "=", "[", "]", "\n", "a_vals", "=", "[", "]", "\n", "for", "at", "in", "range", "(", "num_attack_types", ")", ":", "\n", "                    ", "if", "randomize_state", ":", "\n", "                        ", "d_val", "=", "max", "(", "self", ".", "min_random_d_val", ",", "\n", "np", ".", "random", ".", "choice", "(", "list", "(", "range", "(", "self", ".", "min_random_d_val", ",", "defense_val", "+", "1", ")", ")", ")", ")", "\n", "a_val", "=", "max", "(", "self", ".", "min_random_a_val", ",", "\n", "np", ".", "random", ".", "choice", "(", "list", "(", "range", "(", "self", ".", "min_random_a_val", ",", "attack_val", "+", "1", ")", ")", ")", ")", "\n", "de_val", "=", "max", "(", "self", ".", "min_random_det_val", ",", "\n", "np", ".", "random", ".", "choice", "(", "list", "(", "range", "(", "self", ".", "min_random_det_val", ",", "det_val", "+", "1", ")", ")", ")", ")", "\n", "v_val", "=", "max", "(", "vulnerability_val", ",", "\n", "np", ".", "random", ".", "choice", "(", "list", "(", "range", "(", "vulnerability_val", ",", "self", ".", "max_random_v_val", "+", "1", ")", ")", ")", ")", "\n", "", "d_vals", ".", "append", "(", "d_val", ")", "\n", "a_vals", ".", "append", "(", "a_val", ")", "\n", "", "defense_values", "[", "node_id", "]", "=", "d_vals", "\n", "det_values", "[", "node_id", "]", "=", "de_val", "\n", "attack_values", "[", "node_id", "]", "=", "a_vals", "\n", "for", "vuln_id", "in", "vulnerabilities", ":", "\n", "                    ", "defense_values", "[", "node_id", "]", "[", "vuln_id", "]", "=", "v_val", "# vulnerability (lower defense)", "\n", "\n", "", "", "", "if", "randomize_visibility", ":", "\n", "            ", "for", "node_id", "in", "range", "(", "len", "(", "reconnaissance_state", ")", ")", ":", "\n", "                ", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "visibility_p", ":", "\n", "                    ", "reconnaissance_state", "[", "node_id", "]", "=", "defense_values", "[", "node_id", "]", "\n", "self", ".", "reconnaissance_actions", ".", "append", "(", "node_id", ")", "\n", "", "", "", "self", ".", "attack_values", "=", "attack_values", ".", "astype", "(", "np", ".", "int32", ")", "\n", "self", ".", "defense_values", "=", "defense_values", ".", "astype", "(", "np", ".", "int32", ")", "\n", "self", ".", "defense_det", "=", "det_values", ".", "astype", "(", "np", ".", "int32", ")", "\n", "self", ".", "reconnaissance_state", "=", "reconnaissance_state", ".", "astype", "(", "np", ".", "int32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.new_game": [[190, 244], ["numpy.copy", "numpy.copy", "numpy.copy", "numpy.copy", "game_state.GameState.set_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.set_state"], ["", "def", "new_game", "(", "self", ",", "init_state", ":", "\"GameState\"", ",", "a_reward", ":", "int", "=", "0", ",", "d_reward", ":", "int", "=", "0", ",", "\n", "update_stats", "=", "True", ",", "randomize_state", ":", "bool", "=", "False", ",", "network_config", ":", "NetworkConfig", "=", "None", ",", "\n", "num_attack_types", ":", "int", "=", "None", ",", "defense_val", ":", "int", "=", "None", ",", "attack_val", ":", "int", "=", "None", ",", "\n", "det_val", ":", "int", "=", "None", ",", "vulnerability_val", ":", "int", "=", "None", ",", "\n", "num_vulnerabilities_per_layer", ":", "int", "=", "None", ",", "num_vulnerabilities_per_node", ":", "int", "=", "None", ",", "\n", "randomize_visibility", ":", "bool", "=", "False", ",", "visibility_p", ":", "float", "=", "0.5", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Updates the current state for a new game\n\n        :param init_state: the initial state of the first game\n        :param a_reward: the reward delta to increment or decrement the attacker cumulative reward with\n        :param d_reward: the reward delta to increment or decrement the defender cumulative reward with\n        :param randomize_state: boolean flag whether to create the state randomly\n        :param network_config: network config (necessary if randomizing the state every game)\n        :param defense_val: defense value for defense types that are not vulnerable\n        :param attack_val: attack value for attack types\n        :param num_vulnerabilities_per_node: number of vulnerabilities per node\n        :param det_val: detection value per node\n        :param vulnerability_val: defense value for defense types that are vulnerable\n        :param num_vulnerabilities_per_layer: number of vulnerabilities per layer\n        :param randomize_state: boolean flag whether to create the state randomly\n        :param randomize_visibility: boolean flag whether to randomize visibility for partially observed envs\n        :return: None\n        \"\"\"", "\n", "if", "update_stats", ":", "\n", "            ", "self", ".", "num_games", "+=", "1", "\n", "if", "self", ".", "hacked", ":", "\n", "                ", "self", ".", "attacker_cumulative_reward", "+=", "a_reward", "\n", "self", ".", "defender_cumulative_reward", "+=", "d_reward", "\n", "self", ".", "num_hacks", "+=", "1", "\n", "", "if", "self", ".", "detected", ":", "\n", "                ", "self", ".", "attacker_cumulative_reward", "+=", "a_reward", "\n", "self", ".", "defender_cumulative_reward", "+=", "d_reward", "\n", "", "", "self", ".", "done", "=", "False", "\n", "self", ".", "attack_defense_type", "=", "0", "\n", "self", ".", "game_step", "=", "0", "\n", "self", ".", "attack_events", "=", "[", "]", "\n", "self", ".", "defense_events", "=", "[", "]", "\n", "self", ".", "reconnaissance_actions", "=", "[", "]", "\n", "self", ".", "attacker_pos", "=", "init_state", ".", "attacker_pos", "\n", "if", "not", "randomize_state", ":", "\n", "            ", "self", ".", "attack_values", "=", "np", ".", "copy", "(", "init_state", ".", "attack_values", ")", "\n", "self", ".", "defense_values", "=", "np", ".", "copy", "(", "init_state", ".", "defense_values", ")", "\n", "self", ".", "defense_det", "=", "np", ".", "copy", "(", "init_state", ".", "defense_det", ")", "\n", "self", ".", "reconnaissance_state", "=", "np", ".", "copy", "(", "init_state", ".", "reconnaissance_state", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "set_state", "(", "network_config", ".", "node_list", ",", "num_attack_types", ",", "network_config", "=", "network_config", ",", "\n", "num_vulnerabilities_per_layer", "=", "num_vulnerabilities_per_layer", ",", "randomize_state", "=", "randomize_state", ",", "\n", "defense_val", "=", "defense_val", ",", "\n", "attack_val", "=", "attack_val", ",", "num_vulnerabilities_per_node", "=", "num_vulnerabilities_per_node", ",", "\n", "det_val", "=", "det_val", ",", "vulnerability_val", "=", "vulnerability_val", ",", "\n", "randomize_visibility", "=", "randomize_visibility", ",", "visibility_p", "=", "visibility_p", ")", "\n", "", "self", ".", "detected", "=", "False", "\n", "self", ".", "hacked", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy": [[245, 272], ["game_state.GameState", "numpy.copy", "numpy.copy", "numpy.copy", "numpy.copy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy"], ["", "def", "copy", "(", "self", ")", "->", "\"GameState\"", ":", "\n", "        ", "\"\"\"\n        Creates a copy of the state\n\n        :return: a copy of the current state\n        \"\"\"", "\n", "new_state", "=", "GameState", "(", "min_random_a_val", "=", "self", ".", "min_random_a_val", ",", "min_random_d_val", "=", "self", ".", "min_random_d_val", ",", "\n", "min_random_det_val", "=", "self", ".", "min_random_det_val", ",", "max_value", "=", "self", ".", "max_value", ",", "\n", "max_random_v_val", "=", "self", ".", "max_random_v_val", ")", "\n", "new_state", ".", "attack_values", "=", "np", ".", "copy", "(", "self", ".", "attack_values", ")", "\n", "new_state", ".", "defense_values", "=", "np", ".", "copy", "(", "self", ".", "defense_values", ")", "\n", "new_state", ".", "defense_det", "=", "np", ".", "copy", "(", "self", ".", "defense_det", ")", "\n", "new_state", ".", "reconnaissance_state", "=", "np", ".", "copy", "(", "self", ".", "reconnaissance_state", ")", "\n", "new_state", ".", "attacker_pos", "=", "self", ".", "attacker_pos", "\n", "new_state", ".", "game_step", "=", "self", ".", "game_step", "\n", "new_state", ".", "attacker_cumulative_reward", "=", "self", ".", "attacker_cumulative_reward", "\n", "new_state", ".", "defender_cumulative_reward", "=", "self", ".", "defender_cumulative_reward", "\n", "new_state", ".", "num_games", "=", "self", ".", "num_games", "\n", "new_state", ".", "attack_events", "=", "self", ".", "attack_events", "\n", "new_state", ".", "defense_events", "=", "self", ".", "defense_events", "\n", "new_state", ".", "done", "=", "self", ".", "done", "\n", "new_state", ".", "detected", "=", "self", ".", "detected", "\n", "new_state", ".", "attack_defense_type", "=", "self", ".", "attack_defense_type", "\n", "new_state", ".", "num_hacks", "=", "self", ".", "num_hacks", "\n", "new_state", ".", "hacked", "=", "self", ".", "hacked", "\n", "new_state", ".", "reconnaissance_actions", "=", "self", ".", "reconnaissance_actions", "\n", "return", "new_state", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.attack": [[273, 291], ["None"], "methods", ["None"], ["", "def", "attack", "(", "self", ",", "node_id", ":", "int", ",", "attack_type", ":", "int", ",", "max_value", ":", "int", ",", "network_config", ":", "NetworkConfig", ",", "\n", "reconnaissance_enabled", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Increments the attack value of the specified node and attack type\n\n        :param node_id: id of the node to defend\n        :param attack_type: the type of attack attribute to increment\n        :param max_value: the maximum defense value\n        :param network_config: NetworkConfig\n        :param reconnaissance_enabled: boolean flag indicating whether reconnaissance actions are enabled or not\n        :return: None\n        \"\"\"", "\n", "if", "network_config", ".", "node_list", "[", "node_id", "]", "!=", "NodeType", ".", "START", "and", "self", ".", "attack_values", "[", "node_id", "]", "[", "attack_type", "]", "<", "max_value", ":", "\n", "            ", "self", ".", "attack_values", "[", "node_id", "]", "[", "attack_type", "]", "+=", "1", "\n", "", "if", "reconnaissance_enabled", ":", "\n", "            ", "if", "network_config", ".", "node_list", "[", "node_id", "]", "!=", "NodeType", ".", "START", "and", "self", ".", "attack_values", "[", "node_id", "]", "[", "attack_type", "]", ">", "self", ".", "reconnaissance_state", "[", "node_id", "]", "[", "attack_type", "]", ":", "\n", "                ", "self", ".", "reconnaissance_state", "[", "node_id", "]", "[", "attack_type", "]", "=", "self", ".", "attack_values", "[", "node_id", "]", "[", "attack_type", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.min_attack_type": [[292, 305], ["float", "range", "range", "min_ats.append"], "methods", ["None"], ["", "", "", "def", "min_attack_type", "(", "self", ",", "node", ",", "row_ids", ")", ":", "\n", "        ", "min_val", "=", "float", "(", "'inf'", ")", "\n", "for", "n", "in", "row_ids", ":", "\n", "            ", "for", "at", "in", "range", "(", "self", ".", "defense_values", ".", "shape", "[", "1", "]", ")", ":", "\n", "                ", "val", "=", "self", ".", "defense_values", "[", "n", "]", "[", "at", "]", "\n", "if", "val", "<=", "min_val", ":", "\n", "                    ", "min_val", "=", "val", "\n", "", "", "", "min_ats", "=", "[", "]", "\n", "for", "at", "in", "range", "(", "self", ".", "defense_values", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "val", "=", "self", ".", "defense_values", "[", "node", "]", "[", "at", "]", "\n", "if", "val", "<=", "min_val", ":", "\n", "                ", "min_ats", ".", "append", "(", "at", ")", "\n", "", "", "return", "min_ats", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.reconnaissance": [[307, 326], ["game_state.GameState.reconnaissance_actions.append"], "methods", ["None"], ["", "def", "reconnaissance", "(", "self", ",", "node_id", ":", "int", ",", "attack_type", ":", "int", ",", "reconnaissance_reward", ":", "bool", "=", "False", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Performs a reconnaissance activity for the attacker\n\n        :param node_id: id of the node to defend\n        :param attack_type: the type of attack attribute to increment\n        :param max_value: the maximum defense value\n        :param network_config: NetworkConfig\n        :return: reward\n        \"\"\"", "\n", "if", "reconnaissance_reward", ":", "\n", "            ", "reward", "=", "-", "0.5", "*", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", "if", "(", "self", ".", "reconnaissance_state", "[", "node_id", "]", "==", "self", ".", "defense_values", "[", "node_id", "]", ")", ".", "all", "(", ")", "else", "0.5", "*", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", "\n", "", "else", ":", "\n", "            ", "reward", "=", "0", "\n", "", "self", ".", "reconnaissance_state", "[", "node_id", "]", "=", "self", ".", "defense_values", "[", "node_id", "]", "\n", "self", ".", "reconnaissance_actions", ".", "append", "(", "node_id", ")", "\n", "return", "reward", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.defend": [[327, 349], ["None"], "methods", ["None"], ["", "def", "defend", "(", "self", ",", "node_id", ":", "int", ",", "defense_type", ":", "int", ",", "max_value", ":", "int", ",", "network_config", ":", "NetworkConfig", ",", "\n", "detect", ":", "bool", "=", "False", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Increments the defense value of the specified node and defense type\n\n        :param node_id: id of the node to defend\n        :param defense_type: the type of defense attribute to increment\n        :param max_value: the maximum defense value\n        :param network_config: NetworkConfig\n        :param detect: True if it is a detect action otherwise False\n        :return: True if update had effect, otherwise False\n        \"\"\"", "\n", "if", "detect", "or", "defense_type", ">=", "self", ".", "defense_values", ".", "shape", "[", "1", "]", ":", "\n", "            ", "if", "network_config", ".", "node_list", "[", "node_id", "]", "!=", "NodeType", ".", "START", "and", "self", ".", "defense_det", "[", "node_id", "]", "<", "max_value", ":", "\n", "                ", "self", ".", "defense_det", "[", "node_id", "]", "+=", "1", "\n", "return", "True", "\n", "", "", "else", ":", "\n", "            ", "if", "network_config", ".", "node_list", "[", "node_id", "]", "!=", "NodeType", ".", "START", "and", "self", ".", "defense_values", "[", "node_id", "]", "[", "defense_type", "]", "<", "max_value", ":", "\n", "                ", "self", ".", "defense_values", "[", "node_id", "]", "[", "defense_type", "]", "+=", "1", "\n", "return", "True", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.simulate_attack": [[350, 362], ["None"], "methods", ["None"], ["", "def", "simulate_attack", "(", "self", ",", "attacked_node_id", ":", "int", ",", "attack_type", ":", "int", ",", "network_config", ":", "NetworkConfig", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Simulates an attack operation\n\n        :param attacked_node_id: the id of the node that is attacked\n        :param attack_type: the type of the attack\n        :param network_config: NetworkConfig\n        :return: True if the attack was successful otherwise False\n        \"\"\"", "\n", "if", "network_config", ".", "node_list", "[", "attacked_node_id", "]", "==", "NodeType", ".", "START", ":", "\n", "            ", "return", "True", "\n", "", "return", "self", ".", "attack_values", "[", "attacked_node_id", "]", "[", "attack_type", "]", ">", "self", ".", "defense_values", "[", "attacked_node_id", "]", "[", "attack_type", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.simulate_detection": [[363, 376], ["numpy.random.rand", "numpy.random.rand"], "methods", ["None"], ["", "def", "simulate_detection", "(", "self", ",", "node_id", ":", "int", ",", "reconnaissance", ":", "bool", ",", "reconnaissance_detection_factor", ":", "float", "=", "1", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Simulates detection for a unsuccessful attack\n\n        :param node_id: the id of the node to simulate deteciton of\n        :param reconnaissance: boolean flag, if true simulate detection of reconnaissance activity\n        :return: True if the node was detected, otherwise False\n        \"\"\"", "\n", "if", "not", "reconnaissance", ":", "\n", "            ", "return", "np", ".", "random", ".", "rand", "(", ")", "<", "self", ".", "defense_det", "[", "node_id", "]", "/", "10", "\n", "", "else", ":", "\n", "            ", "det_prob", "=", "(", "self", ".", "defense_det", "[", "node_id", "]", "/", "10", ")", "*", "reconnaissance_detection_factor", "\n", "return", "np", ".", "random", ".", "rand", "(", ")", "<", "det_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.get_attacker_observation": [[377, 490], ["network_config.get_node_id", "network_config.get_adjacency_matrix_id", "range", "numpy.zeros", "len", "network_config.get_node_pos", "network_config.get_adjacency_matrix_id", "sorted", "numpy.array", "range", "numpy.array", "numpy.zeros", "numpy.zeros", "list", "numpy.full", "range", "len", "network_config.get_node_pos", "neighbors.append", "map", "numpy.full", "numpy.full", "len", "network_config.get_node_pos", "len", "len", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "numpy.zeros", "numpy.append", "numpy.zeros", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append", "numpy.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_adjacency_matrix_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_pos", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_adjacency_matrix_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_pos", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_pos"], ["", "", "def", "get_attacker_observation", "(", "self", ",", "network_config", ":", "NetworkConfig", ",", "local_view", "=", "False", ",", "reconnaissance", "=", "False", ",", "\n", "reconnaissance_bool_features", "=", "False", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Converts the state of the dynamical system into an observation for the attacker. As the environment\n        is a partially observed markov decision process, the attacker observation is only a subset of the game state\n\n        :param network_config: the network configuration of the game\n        :param local_view: boolean flag indicating whether observations are provided in a local view or not\n        :param reconnaissance: boolean flag indicating whether reconnaissance states should be included\n        :param reconnaissance_bool_features: boolean flag whether to include boolean features that indicate if\n                                             reconnaissance have been done for a certain defense type\n        :return: An observation of the environment\n        \"\"\"", "\n", "if", "not", "reconnaissance", ":", "\n", "# +1 to have an extra feature that indicates if this is the node that the attacker is currently in", "\n", "            ", "attack_observation", "=", "np", ".", "zeros", "(", "(", "len", "(", "network_config", ".", "node_list", ")", ",", "self", ".", "attack_values", ".", "shape", "[", "1", "]", "+", "1", ")", ")", "\n", "", "elif", "reconnaissance", "and", "not", "reconnaissance_bool_features", ":", "\n", "# +1 to have an extra feature that indicates if this is the node that the attacker is currently in", "\n", "            ", "attack_observation", "=", "np", ".", "zeros", "(", "(", "len", "(", "network_config", ".", "node_list", ")", ",", "(", "self", ".", "attack_values", ".", "shape", "[", "1", "]", "*", "2", "+", "1", ")", ")", ")", "\n", "", "else", ":", "\n", "# +2 to have an extra feature that indicates if this is the node that the attacker is currently in and reconnaissance bool feature", "\n", "            ", "attack_observation", "=", "np", ".", "zeros", "(", "(", "len", "(", "network_config", ".", "node_list", ")", ",", "(", "self", ".", "attack_values", ".", "shape", "[", "1", "]", "*", "2", "+", "2", ")", ")", ")", "\n", "\n", "", "current_pos", "=", "self", ".", "attacker_pos", "\n", "current_node_id", "=", "network_config", ".", "get_node_id", "(", "current_pos", ")", "\n", "current_row", ",", "current_col", "=", "current_pos", "\n", "current_adjacency_matrix_id", "=", "network_config", ".", "get_adjacency_matrix_id", "(", "current_row", ",", "current_col", ")", "\n", "\n", "if", "local_view", ":", "\n", "            ", "neighbors", "=", "[", "]", "\n", "\n", "", "for", "node_id", "in", "range", "(", "len", "(", "network_config", ".", "node_list", ")", ")", ":", "\n", "            ", "pos", "=", "network_config", ".", "get_node_pos", "(", "node_id", ")", "\n", "node_row", ",", "node_col", "=", "pos", "\n", "node_adjacency_matrix_id", "=", "network_config", ".", "get_adjacency_matrix_id", "(", "node_row", ",", "node_col", ")", "\n", "if", "local_view", ":", "\n", "                ", "if", "network_config", ".", "adjacency_matrix", "[", "current_adjacency_matrix_id", "]", "[", "node_adjacency_matrix_id", "]", "and", "node_id", "!=", "current_node_id", ":", "\n", "                    ", "if", "not", "reconnaissance", ":", "\n", "                        ", "neighbor_data", "=", "np", ".", "append", "(", "self", ".", "attack_values", "[", "node_id", "]", ",", "node_id", ")", "\n", "", "elif", "reconnaissance", "and", "not", "reconnaissance_bool_features", ":", "\n", "                        ", "neighbor_data", "=", "np", ".", "append", "(", "np", ".", "append", "(", "self", ".", "attack_values", "[", "node_id", "]", ",", "node_id", ")", ",", "self", ".", "reconnaissance_state", "[", "node_id", "]", ")", ",", "\n", "", "else", ":", "\n", "                        ", "reconaissance_bool", "=", "[", "0", "]", "\n", "if", "node_id", "in", "self", ".", "reconnaissance_actions", ":", "\n", "                            ", "reconaissance_bool", "=", "[", "1", "]", "\n", "", "neighbor_data", "=", "np", ".", "append", "(", "np", ".", "append", "(", "\n", "np", ".", "append", "(", "self", ".", "attack_values", "[", "node_id", "]", ",", "node_id", ")", ",", "self", ".", "reconnaissance_state", "[", "node_id", "]", ")", ",", "\n", "reconaissance_bool", ")", "\n", "", "neighbor_row", ",", "neighbor_col", "=", "network_config", ".", "get_node_pos", "(", "node_id", ")", "\n", "neighbors", ".", "append", "(", "(", "neighbor_row", ",", "neighbor_col", ",", "neighbor_data", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "node_id", "==", "current_node_id", ":", "\n", "                    ", "if", "not", "reconnaissance", ":", "\n", "                        ", "attack_observation", "[", "node_id", "]", "=", "np", ".", "append", "(", "self", ".", "attack_values", "[", "node_id", "]", ",", "1", ")", "\n", "", "elif", "reconnaissance", "and", "not", "reconnaissance_bool_features", ":", "\n", "                        ", "attack_observation", "[", "node_id", "]", "=", "np", ".", "append", "(", "np", ".", "append", "(", "self", ".", "attack_values", "[", "node_id", "]", ",", "1", ")", ",", "\n", "self", ".", "reconnaissance_state", "[", "node_id", "]", ")", "\n", "", "else", ":", "\n", "                        ", "reconaissance_bool", "=", "[", "0", "]", "\n", "if", "node_id", "in", "self", ".", "reconnaissance_actions", ":", "\n", "                            ", "reconaissance_bool", "=", "[", "1", "]", "\n", "", "attack_observation", "[", "node_id", "]", "=", "np", ".", "append", "(", "np", ".", "append", "(", "np", ".", "append", "(", "self", ".", "attack_values", "[", "node_id", "]", ",", "1", ")", ",", "\n", "self", ".", "reconnaissance_state", "[", "node_id", "]", ")", ",", "reconaissance_bool", ")", "\n", "", "", "elif", "network_config", ".", "fully_observed", ":", "\n", "                    ", "attack_observation", "[", "node_id", "]", "=", "np", ".", "append", "(", "self", ".", "attack_values", "[", "node_id", "]", ",", "0", ")", "\n", "", "elif", "network_config", ".", "adjacency_matrix", "[", "current_adjacency_matrix_id", "]", "[", "node_adjacency_matrix_id", "]", ":", "\n", "                    ", "if", "not", "reconnaissance", ":", "\n", "                        ", "attack_observation", "[", "node_id", "]", "=", "np", ".", "append", "(", "self", ".", "attack_values", "[", "node_id", "]", ",", "0", ")", "\n", "", "elif", "reconnaissance", "and", "not", "reconnaissance_bool_features", ":", "\n", "                        ", "attack_observation", "[", "node_id", "]", "=", "np", ".", "append", "(", "np", ".", "append", "(", "self", ".", "attack_values", "[", "node_id", "]", ",", "0", ")", ",", "\n", "self", ".", "reconnaissance_state", "[", "node_id", "]", ")", "\n", "", "else", ":", "\n", "                        ", "reconaissance_bool", "=", "[", "0", "]", "\n", "if", "node_id", "in", "self", ".", "reconnaissance_actions", ":", "\n", "                            ", "reconaissance_bool", "=", "[", "1", "]", "\n", "", "attack_observation", "[", "node_id", "]", "=", "np", ".", "append", "(", "np", ".", "append", "(", "np", ".", "append", "(", "self", ".", "attack_values", "[", "node_id", "]", ",", "0", ")", ",", "\n", "self", ".", "reconnaissance_state", "[", "node_id", "]", ")", ",", "\n", "reconaissance_bool", ")", "\n", "", "", "elif", "reconnaissance", ":", "\n", "                    ", "if", "not", "reconnaissance_bool_features", ":", "\n", "                        ", "attack_values", "=", "np", ".", "zeros", "(", "(", "self", ".", "attack_values", ".", "shape", "[", "1", "]", ")", ")", "\n", "attack_observation", "[", "node_id", "]", "=", "np", ".", "append", "(", "np", ".", "append", "(", "attack_values", ",", "0", ")", ",", "\n", "self", ".", "reconnaissance_state", "[", "node_id", "]", ")", "\n", "", "else", ":", "\n", "                        ", "reconaissance_bool", "=", "[", "0", "]", "\n", "if", "node_id", "in", "self", ".", "reconnaissance_actions", ":", "\n", "                            ", "reconaissance_bool", "=", "[", "1", "]", "\n", "", "attack_values", "=", "np", ".", "zeros", "(", "(", "self", ".", "attack_values", ".", "shape", "[", "1", "]", ")", ")", "\n", "attack_observation", "[", "node_id", "]", "=", "np", ".", "append", "(", "np", ".", "append", "(", "np", ".", "append", "(", "attack_values", ",", "0", ")", ",", "\n", "self", ".", "reconnaissance_state", "[", "node_id", "]", ")", ",", "reconaissance_bool", ")", "\n", "\n", "", "", "", "", "if", "local_view", ":", "\n", "# sort by row then col", "\n", "            ", "sorted_neighbors", "=", "sorted", "(", "neighbors", ",", "key", "=", "lambda", "x", ":", "(", "x", "[", "0", "]", ",", "x", "[", "1", "]", ")", ")", "\n", "neighbor_data", "=", "np", ".", "array", "(", "list", "(", "map", "(", "lambda", "x", ":", "x", "[", "2", "]", ",", "sorted_neighbors", ")", ")", ")", "\n", "neighbor_ids", "=", "neighbor_data", "[", ":", ",", "self", ".", "attack_values", ".", "shape", "[", "1", "]", "]", "\n", "if", "not", "reconnaissance", ":", "\n", "                ", "local_view_obs", "=", "np", ".", "full", "(", "(", "network_config", ".", "max_neighbors", ",", "self", ".", "attack_values", ".", "shape", "[", "1", "]", "+", "1", ")", ",", "-", "1", ")", "\n", "", "elif", "reconnaissance", "and", "not", "reconnaissance_bool_features", ":", "\n", "                ", "local_view_obs", "=", "np", ".", "full", "(", "(", "network_config", ".", "max_neighbors", ",", "self", ".", "attack_values", ".", "shape", "[", "1", "]", "*", "2", "+", "1", ")", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "local_view_obs", "=", "np", ".", "full", "(", "(", "network_config", ".", "max_neighbors", ",", "self", ".", "attack_values", ".", "shape", "[", "1", "]", "*", "2", "+", "2", ")", ",", "-", "1", ")", "\n", "", "for", "n", "in", "range", "(", "network_config", ".", "max_neighbors", ")", ":", "\n", "                ", "rel_neighbor_pos", "=", "network_config", ".", "relative_neighbor_positions", "[", "n", "]", "\n", "neighbor_pos", "=", "(", "current_row", "+", "rel_neighbor_pos", "[", "0", "]", ",", "current_col", "+", "rel_neighbor_pos", "[", "1", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "neighbor_ids", ")", ")", ":", "\n", "                    ", "node_id", "=", "neighbor_ids", "[", "i", "]", "\n", "node_pos", "=", "network_config", ".", "get_node_pos", "(", "node_id", ")", "\n", "if", "node_pos", "==", "neighbor_pos", "and", "node_pos", "[", "0", "]", "<=", "current_row", ":", "\n", "                        ", "local_view_obs", "[", "n", "]", "=", "neighbor_data", "[", "i", "]", "\n", "", "", "", "attack_observation", "=", "np", ".", "array", "(", "local_view_obs", ")", "\n", "", "return", "attack_observation", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.get_attacker_node_from_observation": [[491, 508], ["range", "AssertionError", "len"], "methods", ["None"], ["", "def", "get_attacker_node_from_observation", "(", "self", ",", "observation", ":", "np", ".", "ndarray", ",", "reconnaissance", ":", "bool", "=", "False", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Extracts which node the attacker is currently at from the observation representation\n\n        :param observation: the observation representation emitted from the environment\n        :param reconnaissance: boolean flag indicating whether the observation is from an env with reconnaissance state\n        :return: the id of the node that the attacker is in\n        \"\"\"", "\n", "\n", "for", "node_id", "in", "range", "(", "len", "(", "observation", ")", ")", ":", "\n", "            ", "if", "not", "reconnaissance", ":", "\n", "                ", "if", "observation", "[", "node_id", "]", "[", "-", "1", "]", "==", "1", ":", "\n", "                    ", "return", "node_id", "\n", "", "", "else", ":", "\n", "                ", "if", "observation", "[", "node_id", "]", "[", "self", ".", "attack_values", ".", "shape", "[", "1", "]", "]", "==", "1", ":", "\n", "                    ", "return", "node_id", "\n", "", "", "", "raise", "AssertionError", "(", "\"Could not find the node that the attacker is in\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.add_attack_event": [[509, 523], ["gym_idsgame.envs.dao.attack_defense_event.AttackDefenseEvent", "game_state.GameState.attack_events.append"], "methods", ["None"], ["", "def", "add_attack_event", "(", "self", ",", "target_pos", ":", "Union", "[", "int", ",", "int", "]", ",", "attack_type", ":", "int", ",", "attacker_pos", ":", "Union", "[", "int", ",", "int", "]", ",", "\n", "reconnaissance", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Adds an attack event to the state\n\n        :param target_pos: position in the grid of the target node\n        :param attack_type: the type of the attack\n        :param attacker_pos: position of the attacker\n        :param reconnaissance: boolean flag indicating whether it is a reconnaissance event\n        :return: None\n        \"\"\"", "\n", "attack_event", "=", "AttackDefenseEvent", "(", "target_pos", ",", "attack_type", ",", "attacker_pos", "=", "attacker_pos", ",", "\n", "reconnaissance", "=", "reconnaissance", ")", "\n", "self", ".", "attack_events", ".", "append", "(", "attack_event", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.add_defense_event": [[524, 534], ["gym_idsgame.envs.dao.attack_defense_event.AttackDefenseEvent", "game_state.GameState.defense_events.append"], "methods", ["None"], ["", "def", "add_defense_event", "(", "self", ",", "target_pos", ":", "Union", "[", "int", ",", "int", "]", ",", "defense_type", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Adds a defense event to the state\n\n        :param target_pos: the position in the grid of the target node\n        :param defense_type: the type of the defense\n        :return: None\n        \"\"\"", "\n", "defense_event", "=", "AttackDefenseEvent", "(", "target_pos", ",", "defense_type", ")", "\n", "self", ".", "defense_events", ".", "append", "(", "defense_event", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.get_defender_observation": [[535, 548], ["numpy.zeros", "range", "len", "numpy.append", "len"], "methods", ["None"], ["", "def", "get_defender_observation", "(", "self", ",", "network_config", ":", "NetworkConfig", ")", ":", "\n", "        ", "\"\"\"\n        Converts the state of the dynamical system into an observation for the defender. As the environment\n        is a partially observed markov decision process, the defender observation is only a subset of the game state\n\n        :param network_config: the network configuration of the game\n        :return: An observation of the environment\n        \"\"\"", "\n", "# +1 for the detection value", "\n", "defense_observation", "=", "np", ".", "zeros", "(", "(", "len", "(", "network_config", ".", "node_list", ")", ",", "self", ".", "defense_values", ".", "shape", "[", "1", "]", "+", "1", ")", ")", "\n", "for", "node_id", "in", "range", "(", "len", "(", "network_config", ".", "node_list", ")", ")", ":", "\n", "            ", "defense_observation", "[", "node_id", "]", "=", "np", ".", "append", "(", "self", ".", "defense_values", "[", "node_id", "]", ",", "self", ".", "defense_det", "[", "node_id", "]", ")", "\n", "", "return", "defense_observation", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.randomize_attacker_position": [[549, 565], ["list", "list", "numpy.random.choice", "network_config.get_node_id", "range", "range", "list", "network_config.get_node_id", "range", "positions.append", "len"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_id"], ["", "def", "randomize_attacker_position", "(", "self", ",", "network_config", ":", "NetworkConfig", ")", ":", "\n", "        ", "temp_rows", "=", "list", "(", "range", "(", "1", ",", "network_config", ".", "num_rows", ")", ")", "\n", "temp_cols", "=", "list", "(", "range", "(", "0", ",", "network_config", ".", "num_cols", ")", ")", "\n", "positions", "=", "[", "]", "\n", "for", "r", "in", "temp_rows", ":", "\n", "            ", "for", "c", "in", "temp_cols", ":", "\n", "                ", "node_id", "=", "network_config", ".", "get_node_id", "(", "(", "r", ",", "c", ")", ")", "\n", "if", "network_config", ".", "node_list", "[", "node_id", "]", "==", "NodeType", ".", "SERVER", ".", "value", "or", "network_config", ".", "node_list", "[", "node_id", "]", "==", "NodeType", ".", "START", ".", "value", ":", "\n", "                    ", "positions", ".", "append", "(", "(", "r", ",", "c", ")", ")", "\n", "", "", "", "rnd_idx", "=", "np", ".", "random", ".", "choice", "(", "list", "(", "range", "(", "len", "(", "positions", ")", ")", ")", ")", "\n", "rnd_pos", "=", "positions", "[", "rnd_idx", "]", "\n", "id", "=", "network_config", ".", "get_node_id", "(", "rnd_pos", ")", "\n", "if", "network_config", ".", "node_list", "[", "id", "]", "==", "NodeType", ".", "START", ".", "value", ":", "\n", "            ", "rnd_pos", "=", "network_config", ".", "start_pos", "\n", "", "self", ".", "attacker_pos", "=", "rnd_pos", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.restart": [[566, 575], ["None"], "methods", ["None"], ["", "def", "restart", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the game state, clears up all the history\n        :return: Noen\n        \"\"\"", "\n", "self", ".", "num_games", "=", "0", "\n", "self", ".", "num_hacks", "=", "0", "\n", "self", ".", "defender_cumulative_reward", "=", "0", "\n", "self", ".", "attacker_cumulative_reward", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.load": [[576, 580], ["open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load"], ["", "@", "staticmethod", "\n", "def", "load", "(", "path", ")", ":", "\n", "        ", "filehandler", "=", "open", "(", "path", ",", "'rb'", ")", "\n", "return", "pickle", ".", "load", "(", "filehandler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.save": [[581, 585], ["open", "pickle.dump"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "save", "(", "path", ",", "state", ")", ":", "\n", "        ", "filehandler", "=", "open", "(", "path", "+", "\"/initial_state.pkl\"", ",", "'wb'", ")", "\n", "pickle", ".", "dump", "(", "state", ",", "filehandler", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.idsgame_config.IdsGameConfig.__init__": [[13, 67], ["idsgame_config.IdsGameConfig.render_config.set_height", "idsgame_config.IdsGameConfig.render_config.set_width", "gym_idsgame.envs.dao.render_config.RenderConfig", "gym_idsgame.envs.dao.game_config.GameConfig"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.render_config.RenderConfig.set_height", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.render_config.RenderConfig.set_width"], ["def", "__init__", "(", "self", ",", "render_config", ":", "RenderConfig", "=", "None", ",", "game_config", ":", "GameConfig", "=", "None", ",", "\n", "defender_agent", ":", "Agent", "=", "None", ",", "attacker_agent", ":", "Agent", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ",", "\n", "save_trajectories", ":", "bool", "=", "False", ",", "save_attack_stats", ":", "bool", "=", "False", ",", "\n", "randomize_env", ":", "bool", "=", "False", ",", "local_view_observations", ":", "bool", "=", "False", ",", "\n", "reconnaissance_actions", ":", "bool", "=", "False", ",", "randomize_starting_position", ":", "bool", "=", "False", ",", "\n", "reconnaissance_bool_features", ":", "bool", "=", "False", ",", "extra_reconnaissance_reward", ":", "bool", "=", "False", ",", "\n", "reconnaissance_reward", ":", "bool", "=", "False", ",", "randomize_visibility", ":", "bool", "=", "True", ",", "\n", "visibility_p", ":", "float", "=", "0.5", ",", "reconnaissance_detection_factor", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Constructor, initializes the config\n\n        :param render_config: render config, e.g colors, size, line width etc.\n        :param game_config: game configuration, e.g. number of nodes\n        :param defender_agent: the defender agent\n        :param attacker_agent: the attacker agent\n        :param initial_state_path: path to the initial state\n        :param save_trajectories: boolean flag whether trajectories should be saved to create a self-play-dataset\n        :param save_attack_stats: boolean flag whether to save attack statistics or not\n        :param randomize_env: boolean flag whether to randomize the environment creation before each episode\n        :param local_view_observations: boolean flag whether features are provided in a \"local view\" mode\n        :param reconnaissance_actions: a boolean flag that indicates whether reconnaissance activities are enabled for\n                                       the attacker\n        :param randomize_starting_position: if true, the starting position of the attacker is randomized\n        :param reconnaissance_bool_features: boolean flag whether to include boolean features that indicate if\n                                             reconnaissance have been done for a certain defense type\n        :param extra_reconnaissance_reward: boolean flag whether to give the agent extra reward when doing\n                                            \"informed hacks\" as opposed to guessing\n        :param reconnaissance_reward: whether to give a reward for reconnaissance actions when new info is found\n        :param randomize_visibility: whether to randomize visibilty during training (for partailly observed envs only)\n        :param visibility_p: when randomizing visibility, set to visible with this probability\n        :param reconnaissance_detection_factor: factor to multiple reconnaissance probabiltiy with\n        \"\"\"", "\n", "self", ".", "render_config", "=", "render_config", "\n", "self", ".", "game_config", "=", "game_config", "\n", "self", ".", "defender_agent", "=", "defender_agent", "\n", "self", ".", "attacker_agent", "=", "attacker_agent", "\n", "if", "self", ".", "render_config", "is", "None", ":", "\n", "            ", "self", ".", "render_config", "=", "RenderConfig", "(", ")", "\n", "", "if", "self", ".", "game_config", "is", "None", ":", "\n", "            ", "self", ".", "game_config", "=", "GameConfig", "(", "initial_state_path", "=", "initial_state_path", ")", "\n", "", "self", ".", "render_config", ".", "set_height", "(", "self", ".", "game_config", ".", "num_rows", ")", "\n", "self", ".", "render_config", ".", "set_width", "(", "self", ".", "game_config", ".", "num_cols", ")", "\n", "self", ".", "save_trajectories", "=", "save_trajectories", "\n", "self", ".", "save_attack_stats", "=", "save_attack_stats", "\n", "self", ".", "randomize_env", "=", "randomize_env", "\n", "self", ".", "local_view_observations", "=", "local_view_observations", "\n", "self", ".", "reconnaissance_actions", "=", "reconnaissance_actions", "\n", "self", ".", "randomize_starting_position", "=", "randomize_starting_position", "\n", "self", ".", "reconnaissance_bool_features", "=", "reconnaissance_bool_features", "\n", "self", ".", "extra_reconnaissance_reward", "=", "extra_reconnaissance_reward", "\n", "self", ".", "reconnaissance_reward", "=", "reconnaissance_reward", "\n", "self", ".", "randomize_visibility", "=", "randomize_visibility", "\n", "self", ".", "visibility_p", "=", "visibility_p", "\n", "self", ".", "reconnaissance_detection_factor", "=", "reconnaissance_detection_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.agents.agent.Agent.__init__": [[12, 19], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "game_config", ")", ":", "\n", "        ", "\"\"\"\n        Class constructor\n\n        :param game_config: the game configuration\n        \"\"\"", "\n", "self", ".", "game_config", "=", "game_config", "\n", "# if self.game_config is None:", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.agents.attacker.Attacker.__init__": [[16, 42], ["pyglet.resource.image", "super().__init__", "pyglet.resource.image", "pyglet.sprite.Sprite", "attacker.Attacker.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", ",", "col", ":", "int", ",", "row", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Constructor, initializes the attacker\n\n        :param idsgame_config: configuration for IdsGameEnv\n        :param col: the column in the grid where the attacker is currently\n        :param row: the row in the grid where the attacker is currently\n        \"\"\"", "\n", "self", ".", "idsgame_config", "=", "idsgame_config", "\n", "self", ".", "avatar", "=", "pyglet", ".", "resource", ".", "image", "(", "idsgame_config", ".", "render_config", ".", "attacker_filename", ")", "\n", "super", "(", "Attacker", ",", "self", ")", ".", "__init__", "(", "self", ".", "avatar", ",", "batch", "=", "idsgame_config", ".", "render_config", ".", "batch", ",", "\n", "group", "=", "idsgame_config", ".", "render_config", ".", "first_foreground", ")", "\n", "self", ".", "x", "=", "0", "\n", "self", ".", "y", "=", "0", "\n", "self", ".", "col", "=", "col", "\n", "self", ".", "row", "=", "row", "\n", "self", ".", "starting_col", "=", "col", "\n", "self", ".", "starting_row", "=", "row", "\n", "self", ".", "scale", "=", "idsgame_config", ".", "render_config", ".", "attacker_scale", "\n", "self", ".", "cage_avatar", "=", "pyglet", ".", "resource", ".", "image", "(", "self", ".", "idsgame_config", ".", "render_config", ".", "cage_filename", ")", "\n", "self", ".", "cage", "=", "pyglet", ".", "sprite", ".", "Sprite", "(", "self", ".", "cage_avatar", ",", "x", "=", "self", ".", "x", ",", "y", "=", "self", ".", "y", ",", "batch", "=", "idsgame_config", ".", "render_config", ".", "batch", ",", "\n", "group", "=", "idsgame_config", ".", "render_config", ".", "second_foreground", ")", "\n", "self", ".", "cage", ".", "scale", "=", "self", ".", "idsgame_config", ".", "render_config", ".", "cage_scale", "\n", "self", ".", "cage", ".", "visible", "=", "False", "\n", "self", ".", "hidden", "=", "False", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.agents.attacker.Attacker.__center_avatar": [[43, 61], ["int"], "methods", ["None"], ["", "def", "__center_avatar", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Utiltiy function for centering the avatar inside a cell\n\n        :return: None\n        \"\"\"", "\n", "if", "self", ".", "col", "<", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "num_cols", "//", "2", ")", ":", "\n", "            ", "self", ".", "x", "=", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "-", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "num_cols", "//", "2", "-", "(", "self", ".", "col", ")", ")", "*", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "-", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "20", "\n", "", "elif", "self", ".", "col", ">", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "num_cols", "//", "2", ")", ":", "\n", "            ", "self", ".", "x", "=", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "+", "(", "self", ".", "col", "-", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "num_cols", "//", "2", ")", ")", "*", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "-", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "20", "\n", "", "else", ":", "\n", "            ", "self", ".", "x", "=", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "-", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "20", "\n", "", "self", ".", "y", "=", "int", "(", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "1.5", ")", "*", "self", ".", "row", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "4.5", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.agents.attacker.Attacker.move_to_pos": [[62, 77], ["attacker.Attacker.__center_avatar"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.agents.attacker.Attacker.__center_avatar"], ["", "def", "move_to_pos", "(", "self", ",", "pos", ":", "Union", "[", "int", ",", "int", "]", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Moves the attacker to a specific position in the grid\n\n        :param pos: the poition to move the attacker to\n        :return: None\n        \"\"\"", "\n", "row", ",", "col", "=", "pos", "\n", "self", ".", "col", "=", "col", "\n", "self", ".", "row", "=", "row", "\n", "self", ".", "__center_avatar", "(", ")", "\n", "# If moving to a server node, move a little bit to the right so it does not cover the text", "\n", "if", "not", "(", "self", ".", "row", "==", "self", ".", "starting_row", "and", "self", ".", "col", "==", "self", ".", "starting_col", ")", ":", "\n", "            ", "self", ".", "x", "=", "self", ".", "x", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "5", "\n", "self", ".", "y", "=", "self", ".", "y", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "15", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.agents.attacker.Attacker.move_to_coords": [[78, 92], ["None"], "methods", ["None"], ["", "", "def", "move_to_coords", "(", "self", ",", "x", ":", "float", ",", "y", ":", "float", ",", "col", ":", "int", ",", "row", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Moves the attacker to a specific set of coordinates\n\n        :param x: the x coordinate\n        :param y: the y coordinate\n        :param col: the column in the grid\n        :param row: the row in the grid\n        :return: None\n        \"\"\"", "\n", "self", ".", "x", "=", "x", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "5", "\n", "self", ".", "y", "=", "y", "\n", "self", ".", "col", "=", "col", "\n", "self", ".", "row", "=", "row", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.agents.attacker.Attacker.reset": [[93, 105], ["attacker.Attacker.__center_avatar"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.agents.attacker.Attacker.__center_avatar"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the attacker, moves the attacker back to the start-node and removes the cage\n\n        :return: None\n        \"\"\"", "\n", "self", ".", "col", "=", "self", ".", "starting_col", "\n", "self", ".", "row", "=", "self", ".", "starting_row", "\n", "if", "self", ".", "hidden", ":", "\n", "            ", "self", ".", "visible", "=", "False", "\n", "", "self", ".", "cage", ".", "visible", "=", "False", "\n", "self", ".", "__center_avatar", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.agents.attacker.Attacker.detected": [[106, 116], ["None"], "methods", ["None"], ["", "def", "detected", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Called when the attacker was detected, shows a cage over the attacker on the screen\n\n        :return: None\n        \"\"\"", "\n", "self", ".", "cage", ".", "x", "=", "self", ".", "x", "\n", "self", ".", "cage", ".", "y", "=", "self", ".", "y", "\n", "self", ".", "cage", ".", "visible", "=", "True", "\n", "self", ".", "visible", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.agents.attacker.Attacker.undetect": [[117, 126], ["None"], "methods", ["None"], ["", "def", "undetect", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Removes the cage from the attacker\n\n        :return: None\n        \"\"\"", "\n", "self", ".", "cage", ".", "visible", "=", "False", "\n", "if", "self", ".", "hidden", ":", "\n", "            ", "self", ".", "visible", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.agents.attacker.Attacker.hide": [[128, 131], ["None"], "methods", ["None"], ["", "", "def", "hide", "(", "self", ")", ":", "\n", "        ", "self", ".", "visible", "=", "False", "\n", "self", ".", "hidden", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.agents.attacker.Attacker.show": [[132, 135], ["None"], "methods", ["None"], ["", "def", "show", "(", "self", ")", ":", "\n", "        ", "self", ".", "visible", "=", "True", "\n", "self", ".", "hidden", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.agents.attacker.Attacker.pos": [[136, 142], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "pos", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        :return: the grid position of the attacker\n        \"\"\"", "\n", "return", "(", "self", ".", "row", ",", "self", ".", "col", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.attack_maximal_value_bot_agent.AttackMaximalValueBotAgent.__init__": [[16, 24], ["gym_idsgame.agents.bot_agents.bot_agent.BotAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "game_config", ":", "GameConfig", ",", "env", ")", ":", "\n", "        ", "\"\"\"\n        Constructor, initializes the policy\n\n        :param game_config: the game configuration\n        \"\"\"", "\n", "super", "(", "AttackMaximalValueBotAgent", ",", "self", ")", ".", "__init__", "(", "game_config", ")", "\n", "self", ".", "idsgame_env", "=", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.attack_maximal_value_bot_agent.AttackMaximalValueBotAgent.action": [[25, 36], ["attack_maximal_value_bot_agent.AttackMaximalValueBotAgent.non_rec_action", "attack_maximal_value_bot_agent.AttackMaximalValueBotAgent.rec_action"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.attack_maximal_value_bot_agent.AttackMaximalValueBotAgent.non_rec_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.attack_maximal_value_bot_agent.AttackMaximalValueBotAgent.rec_action"], ["", "def", "action", "(", "self", ",", "game_state", ":", "GameState", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Samples an action from the policy.\n\n        :param game_state: the game state\n        :return: action_id\n        \"\"\"", "\n", "if", "not", "self", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "            ", "return", "self", ".", "non_rec_action", "(", "game_state", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "rec_action", "(", "game_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.attack_maximal_value_bot_agent.AttackMaximalValueBotAgent.rec_action": [[37, 69], ["game_state.get_attacker_observation", "list", "list", "float", "range", "filter", "attack_maximal_value_bot_agent.AttackMaximalValueBotAgent.idsgame_env.local_view_features", "util.interpret_attack_action", "attack_maximal_value_bot_agent.AttackMaximalValueBotAgent.idsgame_env.local_view_features", "attack_maximal_value_bot_agent.AttackMaximalValueBotAgent.convert_local_attacker_action_to_global", "len", "numpy.random.choice", "numpy.random.choice", "attack_maximal_value_bot_agent.AttackMaximalValueBotAgent.is_attack_legal"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.get_attacker_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.interpret_attack_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal"], ["", "", "def", "rec_action", "(", "self", ",", "game_state", ":", "GameState", ")", "->", "int", ":", "\n", "        ", "import", "gym_idsgame", ".", "envs", ".", "util", ".", "idsgame_util", "as", "util", "\n", "attacker_obs", "=", "game_state", ".", "get_attacker_observation", "(", "\n", "self", ".", "game_config", ".", "network_config", ",", "local_view", "=", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", ",", "\n", "reconnaissance", "=", "self", ".", "game_config", ".", "reconnaissance_actions", ",", "\n", "reconnaissance_bool_features", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ")", "\n", "actions", "=", "list", "(", "range", "(", "self", ".", "idsgame_env", ".", "num_attack_actions", ")", ")", "\n", "# non_legal_actions = list(", "\n", "#     filter(lambda action: not self.is_attack_legal(action, attacker_obs, game_state), actions))", "\n", "legal_actions", "=", "list", "(", "\n", "filter", "(", "lambda", "action", ":", "self", ".", "is_attack_legal", "(", "action", ",", "attacker_obs", ",", "game_state", ")", ",", "actions", ")", ")", "\n", "min_attack_value", "=", "float", "(", "\"inf\"", ")", "\n", "min_action_id", "=", "-", "1", "\n", "for", "action", "in", "legal_actions", ":", "\n", "            ", "if", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", ":", "\n", "                ", "global_action_id", "=", "self", ".", "convert_local_attacker_action_to_global", "(", "action", ",", "attacker_obs", ")", "\n", "", "else", ":", "\n", "                ", "global_action_id", "=", "action", "\n", "", "server_id", ",", "server_pos", ",", "attack_type", ",", "reconnaissance", "=", "util", ".", "interpret_attack_action", "(", "global_action_id", ",", "self", ".", "game_config", ")", "\n", "if", "reconnaissance", "and", "server_id", "not", "in", "game_state", ".", "reconnaissance_actions", ":", "\n", "                ", "return", "global_action_id", "\n", "", "if", "not", "reconnaissance", "and", "server_id", "in", "game_state", ".", "reconnaissance_actions", ":", "\n", "                ", "attack_value", "=", "game_state", ".", "reconnaissance_state", "[", "server_id", "]", "[", "attack_type", "]", "-", "game_state", ".", "attack_values", "[", "server_id", "]", "[", "attack_type", "]", "\n", "if", "attack_value", "<", "min_attack_value", ":", "\n", "                    ", "min_action_id", "=", "global_action_id", "\n", "min_attack_value", "=", "attack_value", "\n", "", "", "", "if", "min_action_id", "==", "-", "1", ":", "\n", "            ", "if", "len", "(", "legal_actions", ")", ">", "0", ":", "\n", "                ", "min_action_id", "=", "np", ".", "random", ".", "choice", "(", "legal_actions", ")", "\n", "", "else", ":", "\n", "                ", "min_action_id", "=", "np", ".", "random", ".", "choice", "(", "actions", ")", "\n", "", "", "return", "min_action_id", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.attack_maximal_value_bot_agent.AttackMaximalValueBotAgent.is_attack_legal": [[70, 78], ["attack_maximal_value_bot_agent.AttackMaximalValueBotAgent.idsgame_env.local_view_features", "util.is_attack_id_legal", "attack_maximal_value_bot_agent.AttackMaximalValueBotAgent.convert_local_attacker_action_to_global"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_attack_id_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global"], ["", "def", "is_attack_legal", "(", "self", ",", "action", ",", "obs", ",", "game_state", ")", ":", "\n", "        ", "import", "gym_idsgame", ".", "envs", ".", "util", ".", "idsgame_util", "as", "util", "\n", "if", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", ":", "\n", "            ", "action", "=", "self", ".", "convert_local_attacker_action_to_global", "(", "action", ",", "obs", ")", "\n", "if", "action", "==", "-", "1", ":", "\n", "                ", "return", "False", "\n", "", "", "return", "util", ".", "is_attack_id_legal", "(", "action", ",", "self", ".", "game_config", ",", "\n", "game_state", ".", "attacker_pos", ",", "game_state", ",", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.attack_maximal_value_bot_agent.AttackMaximalValueBotAgent.convert_local_attacker_action_to_global": [[79, 88], ["int"], "methods", ["None"], ["", "def", "convert_local_attacker_action_to_global", "(", "self", ",", "action_id", ",", "attacker_obs", ")", ":", "\n", "        ", "num_attack_types", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "\n", "neighbor", "=", "action_id", "//", "(", "num_attack_types", "+", "1", ")", "\n", "attack_type", "=", "action_id", "%", "(", "num_attack_types", "+", "1", ")", "\n", "target_id", "=", "int", "(", "attacker_obs", "[", "neighbor", "]", "[", "num_attack_types", "]", ")", "\n", "if", "target_id", "==", "-", "1", ":", "\n", "            ", "return", "-", "1", "\n", "", "attacker_action", "=", "target_id", "*", "(", "num_attack_types", "+", "1", ")", "+", "attack_type", "\n", "return", "attacker_action", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.attack_maximal_value_bot_agent.AttackMaximalValueBotAgent.non_rec_action": [[89, 119], ["list", "list", "float", "enumerate", "range", "filter", "numpy.argmax", "util.get_attack_action_id", "attack_maximal_value_bot_agent.AttackMaximalValueBotAgent.game_config.network_config.get_node_pos", "len", "numpy.random.choice", "numpy.random.choice", "util.is_attack_id_legal"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.get_attack_action_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_pos", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_attack_id_legal"], ["", "def", "non_rec_action", "(", "self", ",", "game_state", ":", "GameState", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Samples an action from the policy.\n\n        :param game_state: the game state\n        :return: action_id\n        \"\"\"", "\n", "import", "gym_idsgame", ".", "envs", ".", "util", ".", "idsgame_util", "as", "util", "\n", "actions", "=", "list", "(", "range", "(", "self", ".", "game_config", ".", "num_attack_actions", ")", ")", "\n", "legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "util", ".", "is_attack_id_legal", "(", "action", ",", "self", ".", "game_config", ",", "\n", "game_state", ".", "attacker_pos", ",", "\n", "game_state", ")", ",", "actions", ")", ")", "\n", "attacker_row", ",", "attacker_col", "=", "game_state", ".", "attacker_pos", "\n", "max_node_value", "=", "float", "(", "\"-inf\"", ")", "\n", "max_action_id", "=", "-", "1", "\n", "for", "id", ",", "node", "in", "enumerate", "(", "self", ".", "game_config", ".", "network_config", ".", "node_list", ")", ":", "\n", "            ", "if", "node", "==", "NodeType", ".", "SERVER", ".", "value", "or", "node", "==", "NodeType", ".", "DATA", ".", "value", ":", "\n", "                ", "max_idx", "=", "np", ".", "argmax", "(", "game_state", ".", "attack_values", "[", "id", "]", ")", "\n", "action_id", "=", "util", ".", "get_attack_action_id", "(", "id", ",", "max_idx", ",", "self", ".", "game_config", ")", "\n", "node_row", ",", "node_col", "=", "self", ".", "game_config", ".", "network_config", ".", "get_node_pos", "(", "id", ")", "\n", "if", "game_state", ".", "attack_values", "[", "id", "]", "[", "max_idx", "]", ">", "max_node_value", "and", "action_id", "in", "legal_actions", "and", "node_row", "<", "attacker_row", ":", "\n", "                    ", "max_node_value", "=", "game_state", ".", "attack_values", "[", "id", "]", "[", "max_idx", "]", "\n", "max_action_id", "=", "action_id", "\n", "", "", "", "if", "max_action_id", "==", "-", "1", ":", "\n", "            ", "if", "len", "(", "legal_actions", ")", ">", "0", ":", "\n", "                ", "max_action_id", "=", "np", ".", "random", ".", "choice", "(", "legal_actions", ")", "\n", "", "else", ":", "\n", "                ", "max_action_id", "=", "np", ".", "random", ".", "choice", "(", "actions", ")", "\n", "", "", "return", "max_action_id", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.defend_minimal_value_bot_agent.DefendMinimalValueBotAgent.__init__": [[16, 23], ["gym_idsgame.agents.bot_agents.bot_agent.BotAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "game_config", ":", "GameConfig", ")", ":", "\n", "        ", "\"\"\"\n        Constructor, initializes the policy\n\n        :param game_config: the game configuration\n        \"\"\"", "\n", "super", "(", "DefendMinimalValueBotAgent", ",", "self", ")", ".", "__init__", "(", "game_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.defend_minimal_value_bot_agent.DefendMinimalValueBotAgent.action": [[24, 67], ["list", "list", "float", "enumerate", "range", "filter", "numpy.random.choice", "numpy.argmin", "len", "idsgame_util.is_defense_id_legal", "idsgame_util.get_defense_action_id", "idsgame_util.get_defense_action_id", "len", "numpy.random.choice", "numpy.random.choice", "min_action_ids.append", "min_action_ids.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_defense_id_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.get_defense_action_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.get_defense_action_id"], ["", "def", "action", "(", "self", ",", "game_state", ":", "GameState", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Samples an action from the policy.\n\n        :param game_state: the game state\n        :return: action_id\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "envs", ".", "util", "import", "idsgame_util", "\n", "actions", "=", "list", "(", "range", "(", "self", ".", "game_config", ".", "num_defense_actions", ")", ")", "\n", "legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "idsgame_util", ".", "is_defense_id_legal", "(", "action", ",", "self", ".", "game_config", ",", "\n", "game_state", ")", ",", "actions", ")", ")", "\n", "min_node_value", "=", "float", "(", "\"inf\"", ")", "\n", "min_action_id", "=", "-", "1", "\n", "min_action_ids", "=", "[", "]", "\n", "for", "id", ",", "node", "in", "enumerate", "(", "self", ".", "game_config", ".", "network_config", ".", "node_list", ")", ":", "\n", "            ", "if", "node", "==", "NodeType", ".", "SERVER", ".", "value", "or", "node", "==", "NodeType", ".", "DATA", ".", "value", ":", "\n", "                ", "min_idx", "=", "np", ".", "argmin", "(", "game_state", ".", "defense_values", "[", "id", "]", ")", "\n", "if", "game_state", ".", "defense_det", "[", "id", "]", "<", "game_state", ".", "defense_values", "[", "id", "]", "[", "min_idx", "]", ":", "\n", "                    ", "action_id", "=", "idsgame_util", ".", "get_defense_action_id", "(", "id", ",", "self", ".", "game_config", ".", "num_attack_types", ",", "\n", "self", ".", "game_config", ")", "\n", "if", "game_state", ".", "defense_det", "[", "id", "]", "<", "min_node_value", "and", "action_id", "in", "legal_actions", ":", "\n", "                        ", "min_node_value", "=", "game_state", ".", "defense_det", "[", "id", "]", "\n", "min_action_id", "=", "action_id", "\n", "min_action_ids", "=", "[", "]", "\n", "", "elif", "game_state", ".", "defense_det", "[", "id", "]", "<", "min_node_value", "and", "action_id", "in", "legal_actions", ":", "\n", "                        ", "min_action_ids", ".", "append", "(", "action_id", ")", "\n", "\n", "", "", "else", ":", "\n", "                    ", "action_id", "=", "idsgame_util", ".", "get_defense_action_id", "(", "id", ",", "min_idx", ",", "self", ".", "game_config", ")", "\n", "if", "game_state", ".", "defense_values", "[", "id", "]", "[", "min_idx", "]", "<", "min_node_value", "and", "action_id", "in", "legal_actions", ":", "\n", "                        ", "min_node_value", "=", "game_state", ".", "defense_values", "[", "id", "]", "[", "min_idx", "]", "\n", "min_action_id", "=", "action_id", "\n", "min_action_ids", "=", "[", "]", "\n", "", "elif", "game_state", ".", "defense_values", "[", "id", "]", "[", "min_idx", "]", "==", "min_node_value", "and", "action_id", "in", "legal_actions", ":", "\n", "                        ", "min_action_ids", ".", "append", "(", "action_id", ")", "\n", "", "", "", "", "if", "min_action_ids", "!=", "-", "1", "and", "len", "(", "min_action_ids", ")", ">", "1", ":", "\n", "          ", "min_action_id", "=", "np", ".", "random", ".", "choice", "(", "min_action_ids", ")", "\n", "", "elif", "min_action_id", "==", "-", "1", ":", "\n", "            ", "if", "len", "(", "legal_actions", ")", "==", "0", ":", "\n", "                ", "min_action_id", "=", "np", ".", "random", ".", "choice", "(", "actions", ")", "\n", "", "else", ":", "\n", "                ", "min_action_id", "=", "np", ".", "random", ".", "choice", "(", "legal_actions", ")", "\n", "", "", "return", "min_action_id", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.random_attack_bot_agent.RandomAttackBotAgent.__init__": [[15, 23], ["gym_idsgame.agents.bot_agents.bot_agent.BotAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "game_config", ":", "GameConfig", ",", "env", ")", ":", "\n", "        ", "\"\"\"\n        Constructor, initializes the policy\n\n        :param game_config: the game configuration\n        \"\"\"", "\n", "super", "(", "RandomAttackBotAgent", ",", "self", ")", ".", "__init__", "(", "game_config", ")", "\n", "self", ".", "idsgame_env", "=", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.random_attack_bot_agent.RandomAttackBotAgent.action": [[24, 56], ["list", "range", "list", "game_state.get_attacker_observation", "list", "random_attack_bot_agent.RandomAttackBotAgent.idsgame_env.local_view_features", "filter", "len", "numpy.random.choice", "numpy.random.choice", "filter", "len", "numpy.random.choice", "numpy.random.choice", "random_attack_bot_agent.RandomAttackBotAgent.convert_local_attacker_action_to_global", "random_attack_bot_agent.RandomAttackBotAgent.idsgame_env.local_view_features", "idsgame_util.is_attack_id_legal", "random_attack_bot_agent.RandomAttackBotAgent.is_attack_legal"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.get_attacker_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_attack_id_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal"], ["", "def", "action", "(", "self", ",", "game_state", ":", "GameState", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Samples an action from the policy\n\n        :param game_state: the game state\n        :return: action_id\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "envs", ".", "util", "import", "idsgame_util", "\n", "actions", "=", "list", "(", "range", "(", "self", ".", "game_config", ".", "num_attack_actions", ")", ")", "\n", "if", "not", "self", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "            ", "legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "idsgame_util", ".", "is_attack_id_legal", "(", "action", ",", "\n", "self", ".", "game_config", ",", "\n", "game_state", ".", "attacker_pos", ",", "\n", "game_state", ")", ",", "actions", ")", ")", "\n", "if", "len", "(", "legal_actions", ")", ">", "0", ":", "\n", "                ", "action", "=", "np", ".", "random", ".", "choice", "(", "legal_actions", ")", "\n", "", "else", ":", "\n", "                ", "action", "=", "np", ".", "random", ".", "choice", "(", "actions", ")", "\n", "", "", "else", ":", "\n", "            ", "attacker_obs", "=", "game_state", ".", "get_attacker_observation", "(", "\n", "self", ".", "game_config", ".", "network_config", ",", "local_view", "=", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", ",", "\n", "reconnaissance", "=", "self", ".", "game_config", ".", "reconnaissance_actions", ",", "\n", "reconnaissance_bool_features", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ")", "\n", "legal_actions", "=", "list", "(", "\n", "filter", "(", "lambda", "action", ":", "self", ".", "is_attack_legal", "(", "action", ",", "attacker_obs", ",", "game_state", ")", ",", "actions", ")", ")", "\n", "if", "len", "(", "legal_actions", ")", ">", "0", ":", "\n", "                ", "action", "=", "np", ".", "random", ".", "choice", "(", "legal_actions", ")", "\n", "", "else", ":", "\n", "                ", "action", "=", "np", ".", "random", ".", "choice", "(", "actions", ")", "\n", "", "if", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", ":", "\n", "                ", "action", "=", "self", ".", "convert_local_attacker_action_to_global", "(", "action", ",", "attacker_obs", ")", "\n", "", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.random_attack_bot_agent.RandomAttackBotAgent.is_attack_legal": [[57, 64], ["random_attack_bot_agent.RandomAttackBotAgent.idsgame_env.local_view_features", "idsgame_util.is_attack_id_legal", "random_attack_bot_agent.RandomAttackBotAgent.convert_local_attacker_action_to_global"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_attack_id_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global"], ["", "def", "is_attack_legal", "(", "self", ",", "action", ",", "obs", ",", "game_state", ")", ":", "\n", "        ", "if", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", ":", "\n", "            ", "action", "=", "self", ".", "convert_local_attacker_action_to_global", "(", "action", ",", "obs", ")", "\n", "if", "action", "==", "-", "1", ":", "\n", "                ", "return", "False", "\n", "", "", "return", "idsgame_util", ".", "is_attack_id_legal", "(", "action", ",", "self", ".", "game_config", ",", "\n", "game_state", ".", "attacker_pos", ",", "game_state", ",", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.random_attack_bot_agent.RandomAttackBotAgent.convert_local_attacker_action_to_global": [[65, 74], ["int"], "methods", ["None"], ["", "def", "convert_local_attacker_action_to_global", "(", "self", ",", "action_id", ",", "attacker_obs", ")", ":", "\n", "        ", "num_attack_types", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "\n", "neighbor", "=", "action_id", "//", "(", "num_attack_types", "+", "1", ")", "\n", "attack_type", "=", "action_id", "%", "(", "num_attack_types", "+", "1", ")", "\n", "target_id", "=", "int", "(", "attacker_obs", "[", "neighbor", "]", "[", "num_attack_types", "]", ")", "\n", "if", "target_id", "==", "-", "1", ":", "\n", "            ", "return", "-", "1", "\n", "", "attacker_action", "=", "target_id", "*", "(", "num_attack_types", "+", "1", ")", "+", "attack_type", "\n", "return", "attacker_action", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.bot_agent.BotAgent.__init__": [[14, 16], ["gym_idsgame.agents.agent.Agent.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "game_config", ":", "GameConfig", ")", ":", "\n", "        ", "super", "(", "BotAgent", ",", "self", ")", ".", "__init__", "(", "game_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.bot_agent.BotAgent.action": [[17, 27], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "action", "(", "self", ",", "game_state", ":", "GameState", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Abstract method to be implemented by sub-classes.\n        A method that takes in the current state and outputs an action\n\n        :param game_state: the current state\n        :return: action_id\n        \"\"\"", "\n", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.random_defense_bot_agent.RandomDefenseBotAgent.__init__": [[15, 22], ["gym_idsgame.agents.bot_agents.bot_agent.BotAgent.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "game_config", ":", "GameConfig", ")", ":", "\n", "        ", "\"\"\"\n        Constructor, initializes the policy\n\n        :param game_config: the game configuration\n        \"\"\"", "\n", "super", "(", "RandomDefenseBotAgent", ",", "self", ")", ".", "__init__", "(", "game_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.random_defense_bot_agent.RandomDefenseBotAgent.action": [[23, 39], ["list", "list", "range", "filter", "len", "numpy.random.choice", "numpy.random.choice", "idsgame_util.is_defense_id_legal"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_defense_id_legal"], ["", "def", "action", "(", "self", ",", "game_state", ":", "GameState", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Samples an action from the policy\n\n        :param game_state: the game state\n        :return: action_id\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "envs", ".", "util", "import", "idsgame_util", "\n", "actions", "=", "list", "(", "range", "(", "self", ".", "game_config", ".", "num_defense_actions", ")", ")", "\n", "legal_actions", "=", "list", "(", "filter", "(", "lambda", "action", ":", "idsgame_util", ".", "is_defense_id_legal", "(", "action", ",", "self", ".", "game_config", ",", "\n", "game_state", ")", ",", "actions", ")", ")", "\n", "if", "len", "(", "legal_actions", ")", ">", "0", ":", "\n", "            ", "action_id", "=", "np", ".", "random", ".", "choice", "(", "legal_actions", ")", "\n", "", "else", ":", "\n", "            ", "action_id", "=", "np", ".", "random", ".", "choice", "(", "actions", ")", "\n", "", "return", "action_id", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.training_agents.train_agent.TrainAgent.train": [[11, 14], ["None"], "methods", ["None"], ["@", "abstractmethod", "\n", "def", "train", "(", "self", ")", "->", "ExperimentResult", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.training_agents.train_agent.TrainAgent.eval": [[15, 18], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "eval", "(", "self", ")", "->", "ExperimentResult", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.__init__": [[20, 59], ["gym.Env.__init__", "gym.make", "gym.spaces.Box", "gym.spaces.Box", "type", "type"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type"], ["def", "__init__", "(", "self", ",", "env_name", ":", "str", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "\n", "initial_state_path", ":", "str", "=", "None", ",", "\n", "pg_agent_config", ":", "PolicyGradientAgentConfig", "=", "None", ")", ":", "\n", "        ", "super", "(", "BaselineEnvWrapper", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "idsgame_env", "=", "gym", ".", "make", "(", "env_name", ",", "idsgame_config", "=", "idsgame_config", ",", "\n", "save_dir", "=", "save_dir", ",", "\n", "initial_state_path", "=", "initial_state_path", ")", "\n", "self", ".", "pg_agent_config", "=", "pg_agent_config", "\n", "self", ".", "attacker_action_space", "=", "self", ".", "idsgame_env", ".", "attacker_action_space", "\n", "self", ".", "defender_action_space", "=", "self", ".", "idsgame_env", ".", "defender_action_space", "\n", "attacker_obs_shape", "=", "self", ".", "pg_agent_config", ".", "input_dim_attacker", "\n", "defender_obs_shape", "=", "self", ".", "pg_agent_config", ".", "input_dim_defender", "\n", "if", "self", ".", "pg_agent_config", ".", "multi_channel_obs", ":", "\n", "            ", "attacker_obs_shape", "=", "4", "\n", "defender_obs_shape", "=", "4", "\n", "", "if", "type", "(", "attacker_obs_shape", ")", "!=", "tuple", ":", "\n", "            ", "attacker_obs_shape", "=", "(", "attacker_obs_shape", ",", ")", "\n", "", "if", "type", "(", "defender_obs_shape", ")", "!=", "tuple", ":", "\n", "            ", "defender_obs_shape", "=", "(", "defender_obs_shape", ",", ")", "\n", "", "self", ".", "attacker_observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "low", "=", "0", ",", "\n", "high", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "max_value", ",", "\n", "shape", "=", "attacker_obs_shape", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "observation_space", "=", "self", ".", "attacker_observation_space", "\n", "self", ".", "defender_observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "low", "=", "0", ",", "\n", "high", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "max_value", ",", "\n", "shape", "=", "defender_obs_shape", ",", "\n", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "prev_episode_hacked", "=", "False", "\n", "self", ".", "prev_episode_detected", "=", "False", "\n", "self", ".", "metadata", "=", "{", "\n", "'render.modes'", ":", "[", "'human'", ",", "'rgb_array'", "]", ",", "\n", "'video.frames_per_second'", ":", "50", "# Video rendering speed", "\n", "}", "\n", "self", ".", "num_attack_actions", "=", "self", ".", "pg_agent_config", ".", "output_dim_attacker", "\n", "self", ".", "num_defense_actions", "=", "self", ".", "idsgame_env", ".", "num_defense_actions", "\n", "self", ".", "latest_obs", "=", "False", "\n", "self", ".", "attacker_state", "=", "[", "]", "\n", "self", ".", "defender_state", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.step": [[60, 104], ["baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.local_view_features", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.step", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.get_observation", "baseline_env_wrapper.BaselineEnvWrapper.convert_local_attacker_action_to_global", "baseline_env_wrapper.BaselineEnvWrapper.grid_obs", "baseline_env_wrapper.BaselineEnvWrapper.grid_obs", "baseline_env_wrapper.BaselineEnvWrapper.grid_obs", "baseline_env_wrapper.BaselineEnvWrapper.grid_obs", "baseline_env_wrapper.BaselineEnvWrapper.grid_seq_obs", "baseline_env_wrapper.BaselineEnvWrapper.grid_seq_obs", "baseline_env_wrapper.BaselineEnvWrapper.flatten", "baseline_env_wrapper.BaselineEnvWrapper.flatten", "baseline_env_wrapper.BaselineEnvWrapper.one_hot_obs", "baseline_env_wrapper.BaselineEnvWrapper.one_hot_obs", "baseline_env_wrapper.BaselineEnvWrapper.image_grid_obs", "baseline_env_wrapper.BaselineEnvWrapper.flatten", "baseline_env_wrapper.BaselineEnvWrapper.flatten", "baseline_env_wrapper.BaselineEnvWrapper.multi_channel_obs", "baseline_env_wrapper.BaselineEnvWrapper.update_state", "baseline_env_wrapper.BaselineEnvWrapper.update_state", "baseline_env_wrapper.BaselineEnvWrapper.flatten", "baseline_env_wrapper.BaselineEnvWrapper.flatten"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.grid_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.grid_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.grid_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.grid_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.grid_seq_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.grid_seq_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.one_hot_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.one_hot_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.image_grid_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.multi_channel_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "attacker_action", "=", "action", "[", "0", "]", "[", "0", "]", "\n", "defender_action", "=", "action", "[", "1", "]", "[", "0", "]", "\n", "if", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", ":", "\n", "            ", "attacker_obs", ",", "_", "=", "self", ".", "idsgame_env", ".", "get_observation", "(", ")", "\n", "attacker_action", "=", "self", ".", "convert_local_attacker_action_to_global", "(", "attacker_action", ",", "attacker_obs", ")", "\n", "", "joint_action", "=", "(", "attacker_action", ",", "defender_action", ")", "\n", "obs_prime", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "idsgame_env", ".", "step", "(", "joint_action", ")", "\n", "self", ".", "latest_obs", "=", "obs_prime", "\n", "attacker_reward", ",", "defender_reward", "=", "reward", "\n", "obs_prime_attacker", ",", "obs_prime_defender", "=", "obs_prime", "\n", "if", "self", ".", "pg_agent_config", ".", "cnn_feature_extractor", "and", "not", "self", ".", "pg_agent_config", ".", "flatten_feature_planes", "and", "not", "self", ".", "pg_agent_config", ".", "seq_cnn", "and", "not", "self", ".", "pg_agent_config", ".", "grid_image_obs", ":", "\n", "            ", "attacker_state", "=", "self", ".", "grid_obs", "(", "obs_prime_attacker", ",", "obs_prime_defender", ",", "attacker", "=", "True", ")", "\n", "defender_state", "=", "self", ".", "grid_obs", "(", "obs_prime_attacker", ",", "obs_prime_defender", ",", "attacker", "=", "True", ")", "\n", "return", "[", "attacker_state", ",", "defender_state", "]", ",", "[", "attacker_reward", ",", "defender_reward", "]", ",", "done", ",", "info", "\n", "", "elif", "self", ".", "pg_agent_config", ".", "flatten_feature_planes", "and", "not", "self", ".", "pg_agent_config", ".", "seq_cnn", "and", "not", "self", ".", "pg_agent_config", ".", "grid_image_obs", ":", "\n", "            ", "attacker_state", "=", "self", ".", "grid_obs", "(", "obs_prime_attacker", ",", "obs_prime_defender", ",", "attacker", "=", "True", ")", "\n", "defender_state", "=", "self", ".", "grid_obs", "(", "obs_prime_attacker", ",", "obs_prime_defender", ",", "attacker", "=", "True", ")", "\n", "return", "[", "attacker_state", ".", "flatten", "(", ")", ",", "defender_state", ".", "flatten", "(", ")", "]", ",", "[", "attacker_reward", ",", "defender_reward", "]", ",", "done", ",", "info", "\n", "", "elif", "self", ".", "pg_agent_config", ".", "seq_cnn", "and", "not", "self", ".", "pg_agent_config", ".", "grid_image_obs", ":", "\n", "            ", "attacker_state", "=", "self", ".", "grid_seq_obs", "(", "obs_prime_attacker", ",", "obs_prime_defender", ",", "self", ".", "attacker_state", ",", "self", ".", "defender_state", ",", "attacker", "=", "True", ")", "\n", "defender_state", "=", "self", ".", "grid_seq_obs", "(", "obs_prime_attacker", ",", "obs_prime_defender", ",", "self", ".", "attacker_state", ",", "self", ".", "defender_state", ",", "attacker", "=", "True", ")", "\n", "self", ".", "attacker_state", "=", "attacker_state", "\n", "self", ".", "defender_state", "=", "defender_state", "\n", "return", "[", "attacker_state", ",", "defender_state", "]", ",", "[", "attacker_reward", ",", "defender_reward", "]", ",", "done", ",", "info", "\n", "", "elif", "self", ".", "pg_agent_config", ".", "one_hot_obs", ":", "\n", "            ", "attacker_state", "=", "self", ".", "one_hot_obs", "(", "attacker_obs", "=", "obs_prime_attacker", ",", "defender_obs", "=", "obs_prime_defender", ",", "attacker", "=", "True", ")", "\n", "defender_state", "=", "self", ".", "one_hot_obs", "(", "attacker_obs", "=", "obs_prime_attacker", ",", "defender_obs", "=", "obs_prime_defender", ",", "attacker", "=", "False", ")", "\n", "return", "[", "attacker_state", ".", "flatten", "(", ")", ",", "defender_state", ".", "flatten", "(", ")", "]", ",", "[", "attacker_reward", ",", "defender_reward", "]", ",", "done", ",", "info", "\n", "", "elif", "self", ".", "pg_agent_config", ".", "grid_image_obs", ":", "\n", "            ", "attacker_state", "=", "self", ".", "image_grid_obs", "(", "attacker_obs", "=", "obs_prime_attacker", ",", "defender_obs", "=", "obs_prime_defender", ",", "attacker", "=", "True", ")", "\n", "#defender_state = self.image_grid_obs(attacker_obs= obs_prime_attacker, defender_obs=obs_prime_defender, attacker=False)", "\n", "return", "[", "attacker_state", ",", "attacker_state", "]", ",", "[", "attacker_reward", ",", "defender_reward", "]", ",", "done", ",", "info", "\n", "", "elif", "self", ".", "pg_agent_config", ".", "multi_channel_obs", ":", "\n", "            ", "attacker_state", "=", "self", ".", "multi_channel_obs", "(", "attacker_obs", "=", "obs_prime_attacker", ",", "defender_obs", "=", "obs_prime_defender", ",", "attacker", "=", "True", ")", "\n", "return", "[", "attacker_state", ",", "attacker_state", "]", ",", "[", "attacker_reward", ",", "defender_reward", "]", ",", "done", ",", "info", "\n", "", "else", ":", "\n", "            ", "attacker_state", "=", "self", ".", "update_state", "(", "attacker_obs", "=", "obs_prime_attacker", ",", "defender_obs", "=", "obs_prime_defender", ",", "state", "=", "self", ".", "attacker_state", ",", "\n", "attacker", "=", "True", ")", "\n", "defender_state", "=", "self", ".", "update_state", "(", "defender_obs", "=", "obs_prime_defender", ",", "attacker_obs", "=", "obs_prime_attacker", ",", "state", "=", "self", ".", "defender_state", ",", "\n", "attacker", "=", "False", ")", "\n", "self", ".", "attacker_state", "=", "attacker_state", "\n", "self", ".", "defender_state", "=", "defender_state", "\n", "return", "[", "attacker_state", ".", "flatten", "(", ")", ",", "defender_state", ".", "flatten", "(", ")", "]", ",", "[", "attacker_reward", ",", "defender_reward", "]", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.reset": [[105, 149], ["baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.reset", "baseline_env_wrapper.BaselineEnvWrapper.grid_obs", "baseline_env_wrapper.BaselineEnvWrapper.grid_obs", "baseline_env_wrapper.BaselineEnvWrapper.grid_obs", "baseline_env_wrapper.BaselineEnvWrapper.grid_obs", "baseline_env_wrapper.BaselineEnvWrapper.flatten", "baseline_env_wrapper.BaselineEnvWrapper.flatten", "baseline_env_wrapper.BaselineEnvWrapper.grid_seq_obs", "baseline_env_wrapper.BaselineEnvWrapper.grid_seq_obs", "baseline_env_wrapper.BaselineEnvWrapper.one_hot_obs", "baseline_env_wrapper.BaselineEnvWrapper.one_hot_obs", "baseline_env_wrapper.BaselineEnvWrapper.flatten", "baseline_env_wrapper.BaselineEnvWrapper.flatten", "baseline_env_wrapper.BaselineEnvWrapper.image_grid_obs", "baseline_env_wrapper.BaselineEnvWrapper.multi_channel_obs", "baseline_env_wrapper.BaselineEnvWrapper.update_state", "baseline_env_wrapper.BaselineEnvWrapper.update_state", "baseline_env_wrapper.BaselineEnvWrapper.flatten", "baseline_env_wrapper.BaselineEnvWrapper.flatten"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.grid_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.grid_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.grid_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.grid_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.grid_seq_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.grid_seq_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.one_hot_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.one_hot_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.image_grid_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.multi_channel_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state"], ["", "", "def", "reset", "(", "self", ",", "update_stats", ":", "False", ")", ":", "\n", "        ", "self", ".", "prev_episode_hacked", "=", "self", ".", "idsgame_env", ".", "state", ".", "hacked", "\n", "self", ".", "prev_episode_detected", "=", "self", ".", "idsgame_env", ".", "state", ".", "detected", "\n", "self", ".", "attacker_state", "=", "[", "]", "\n", "self", ".", "defender_state", "=", "[", "]", "\n", "obs", "=", "self", ".", "idsgame_env", ".", "reset", "(", "update_stats", "=", "update_stats", ")", "\n", "obs_attacker", ",", "obs_defender", "=", "obs", "\n", "self", ".", "latest_obs", "=", "obs", "\n", "\n", "if", "self", ".", "pg_agent_config", ".", "cnn_feature_extractor", "and", "not", "self", ".", "pg_agent_config", ".", "flatten_feature_planes", "and", "not", "self", ".", "pg_agent_config", ".", "seq_cnn", "and", "not", "self", ".", "pg_agent_config", ".", "grid_image_obs", ":", "\n", "            ", "attacker_state", "=", "self", ".", "grid_obs", "(", "obs_attacker", ",", "obs_defender", ",", "attacker", "=", "True", ")", "\n", "defender_state", "=", "self", ".", "grid_obs", "(", "obs_attacker", ",", "obs_defender", ",", "attacker", "=", "True", ")", "\n", "return", "[", "attacker_state", ",", "defender_state", "]", "\n", "", "elif", "self", ".", "pg_agent_config", ".", "flatten_feature_planes", "and", "not", "self", ".", "pg_agent_config", ".", "seq_cnn", "and", "not", "self", ".", "pg_agent_config", ".", "grid_image_obs", ":", "\n", "            ", "attacker_state", "=", "self", ".", "grid_obs", "(", "obs_attacker", ",", "obs_defender", ",", "attacker", "=", "True", ")", "\n", "defender_state", "=", "self", ".", "grid_obs", "(", "obs_attacker", ",", "obs_defender", ",", "attacker", "=", "True", ")", "\n", "return", "[", "attacker_state", ".", "flatten", "(", ")", ",", "defender_state", ".", "flatten", "(", ")", "]", "\n", "", "elif", "self", ".", "pg_agent_config", ".", "seq_cnn", "and", "not", "self", ".", "pg_agent_config", ".", "grid_image_obs", ":", "\n", "            ", "attacker_state", "=", "self", ".", "grid_seq_obs", "(", "obs_attacker", ",", "obs_defender", ",", "self", ".", "attacker_state", ",", "\n", "self", ".", "defender_state", ",", "attacker", "=", "True", ")", "\n", "defender_state", "=", "self", ".", "grid_seq_obs", "(", "obs_attacker", ",", "obs_defender", ",", "self", ".", "attacker_state", ",", "\n", "self", ".", "defender_state", ",", "attacker", "=", "True", ")", "\n", "self", ".", "attacker_state", "=", "attacker_state", "\n", "self", ".", "defender_state", "=", "defender_state", "\n", "return", "[", "self", ".", "attacker_state", ",", "self", ".", "defender_state", "]", "\n", "", "elif", "self", ".", "pg_agent_config", ".", "one_hot_obs", ":", "\n", "            ", "attacker_state", "=", "self", ".", "one_hot_obs", "(", "attacker_obs", "=", "obs_attacker", ",", "defender_obs", "=", "obs_defender", ",", "attacker", "=", "True", ")", "\n", "defender_state", "=", "self", ".", "one_hot_obs", "(", "attacker_obs", "=", "obs_attacker", ",", "defender_obs", "=", "obs_defender", ",", "attacker", "=", "False", ")", "\n", "return", "[", "attacker_state", ".", "flatten", "(", ")", ",", "defender_state", ".", "flatten", "(", ")", "]", "\n", "", "elif", "self", ".", "pg_agent_config", ".", "grid_image_obs", ":", "\n", "            ", "attacker_state", "=", "self", ".", "image_grid_obs", "(", "attacker_obs", "=", "obs_attacker", ",", "defender_obs", "=", "obs_defender", ",", "attacker", "=", "True", ")", "\n", "#defender_state = self.image_grid_obs(attacker_obs=obs_attacker, defender_obs=obs_defender, attacker=False)", "\n", "return", "[", "attacker_state", ",", "attacker_state", "]", "\n", "", "elif", "self", ".", "pg_agent_config", ".", "multi_channel_obs", ":", "\n", "            ", "attacker_state", "=", "self", ".", "multi_channel_obs", "(", "attacker_obs", "=", "obs_attacker", ",", "defender_obs", "=", "obs_defender", ",", "attacker", "=", "True", ")", "\n", "return", "[", "attacker_state", ",", "attacker_state", "]", "\n", "", "else", ":", "\n", "            ", "attacker_state", "=", "self", ".", "update_state", "(", "attacker_obs", "=", "obs_attacker", ",", "defender_obs", "=", "obs_defender", ",", "state", "=", "self", ".", "attacker_state", ",", "\n", "attacker", "=", "True", ")", "\n", "defender_state", "=", "self", ".", "update_state", "(", "defender_obs", "=", "obs_defender", ",", "attacker_obs", "=", "obs_attacker", ",", "state", "=", "self", ".", "defender_state", ",", "\n", "attacker", "=", "False", ")", "\n", "self", ".", "attacker_state", "=", "attacker_state", "\n", "self", ".", "defender_state", "=", "defender_state", "\n", "return", "[", "attacker_state", ".", "flatten", "(", ")", ",", "defender_state", ".", "flatten", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.render": [[150, 152], ["baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.render"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render"], ["", "", "def", "render", "(", "self", ",", "mode", "=", "'human'", ")", ":", "\n", "        ", "return", "self", ".", "idsgame_env", ".", "render", "(", "mode", "=", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.close": [[153, 155], ["baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "idsgame_env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.convert_local_attacker_action_to_global": [[156, 165], ["int"], "methods", ["None"], ["", "def", "convert_local_attacker_action_to_global", "(", "self", ",", "action_id", ",", "attacker_obs", ")", ":", "\n", "        ", "num_attack_types", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "\n", "neighbor", "=", "action_id", "//", "(", "num_attack_types", "+", "1", ")", "\n", "attack_type", "=", "action_id", "%", "(", "num_attack_types", "+", "1", ")", "\n", "target_id", "=", "int", "(", "attacker_obs", "[", "neighbor", "]", "[", "num_attack_types", "]", ")", "\n", "if", "target_id", "==", "-", "1", ":", "\n", "            ", "return", "-", "1", "\n", "", "attacker_action", "=", "target_id", "*", "(", "num_attack_types", "+", "1", ")", "+", "attack_type", "\n", "return", "attacker_action", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.is_attack_legal": [[166, 185], ["baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.local_view_features", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.is_attack_legal", "baseline_env_wrapper.BaselineEnvWrapper.convert_local_attacker_action_to_global", "gym_idsgame.is_node_attack_legal"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_node_attack_legal"], ["", "def", "is_attack_legal", "(", "self", ",", "attack_action", ":", "int", ",", "node", ":", "bool", "=", "False", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Check if a given attack is legal or not.\n\n        :param attack_action: the attack to verify\n        :return: True if legal otherwise False\n        \"\"\"", "\n", "if", "not", "self", ".", "pg_agent_config", ".", "ar_policy", ":", "\n", "            ", "if", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", ":", "\n", "#attacker_obs, _ = self.idsgame_env.get_observation()", "\n", "                ", "attack_action", "=", "self", ".", "convert_local_attacker_action_to_global", "(", "attack_action", ",", "self", ".", "latest_obs", "[", "0", "]", ")", "\n", "if", "attack_action", "==", "-", "1", ":", "\n", "                    ", "return", "False", "\n", "", "", "return", "self", ".", "idsgame_env", ".", "is_attack_legal", "(", "attack_action", ")", "\n", "", "else", ":", "\n", "            ", "if", "node", ":", "\n", "                ", "return", "util", ".", "is_node_attack_legal", "(", "attack_action", ",", "self", ".", "idsgame_env", ".", "state", ".", "attacker_pos", ",", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "network_config", ")", "\n", "", "else", ":", "\n", "                ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.is_defense_legal": [[187, 207], ["baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.is_defense_legal", "gym_idsgame.is_node_defense_legal"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_node_defense_legal"], ["", "", "", "def", "is_defense_legal", "(", "self", ",", "defense_action", ":", "int", ",", "node", ":", "bool", "=", "False", ",", "obs", ":", "th", ".", "Tensor", "=", "None", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Check if a given defense is legal or not.\n\n        :param defense_action: the defense action to verify\n        :return: True if legal otherwise False\n        \"\"\"", "\n", "if", "not", "self", ".", "pg_agent_config", ".", "ar_policy", ":", "\n", "            ", "return", "self", ".", "idsgame_env", ".", "is_defense_legal", "(", "defense_action", ")", "\n", "", "else", ":", "\n", "            ", "if", "node", ":", "\n", "                ", "return", "util", ".", "is_node_defense_legal", "(", "defense_action", ",", "\n", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "network_config", ",", "\n", "self", ".", "idsgame_env", ".", "state", ",", "\n", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "max_value", ")", "\n", "", "else", ":", "\n", "                ", "if", "obs", "is", "not", "None", ":", "\n", "                    ", "if", "obs", "[", "defense_action", "]", ">=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "max_value", ":", "\n", "                        ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.hack_probability": [[208, 213], ["None"], "methods", ["None"], ["", "", "", "def", "hack_probability", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "num_games", ">", "0", ":", "\n", "            ", "return", "self", ".", "num_hacks", "/", "self", ".", "num_games", "\n", "", "else", ":", "\n", "            ", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.is_reconnaissance": [[214, 218], ["baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.local_view_features", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.is_reconnaissance", "baseline_env_wrapper.BaselineEnvWrapper.convert_local_attacker_action_to_global"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_reconnaissance", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global"], ["", "", "def", "is_reconnaissance", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", ":", "\n", "            ", "action", "=", "self", ".", "convert_local_attacker_action_to_global", "(", "action", ",", "self", ".", "latest_obs", "[", "0", "]", ")", "\n", "", "return", "self", ".", "idsgame_env", ".", "is_reconnaissance", "(", "action", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.games": [[219, 221], ["None"], "methods", ["None"], ["", "def", "games", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_games", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.update_state": [[222, 442], ["baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.local_view_features", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.state.get_attacker_observation", "enumerate", "enumerate", "numpy.array", "numpy.array", "enumerate", "enumerate", "numpy.array", "numpy.array", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.local_view_features", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.fully_observed", "numpy.mean", "numpy.isnan().any", "zero_mean_attacker_features.append", "numpy.mean", "numpy.isnan().any", "zero_mean_defender_features.append", "numpy.isnan().any", "normalized_attacker_features.append", "numpy.isnan().any", "normalized_defender_features.append", "numpy.zeros", "range", "numpy.array", "numpy.append", "numpy.append", "len", "numpy.append", "numpy.append", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.local_view_features", "row.tolist.tolist", "row.tolist.tolist", "row.tolist.append", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.local_view_features", "numpy.linalg.norm", "numpy.linalg.norm", "row.tolist", "numpy.linalg.norm", "numpy.linalg.norm", "int", "enumerate", "enumerate", "numpy.zeros", "range", "len", "numpy.array", "numpy.array", "numpy.append", "len", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.isnan", "row.tolist.append", "row.tolist.append", "row.tolist.append", "numpy.isnan", "numpy.isnan", "row.tolist.append", "row.tolist.append", "row.tolist.append", "numpy.isnan", "row.tolist", "row.tolist.append", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.local_view_features", "row.tolist", "row.tolist.append", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.fully_observed", "numpy.array.append", "numpy.full", "range", "row.tolist", "row.tolist.append", "numpy.array.append", "numpy.append", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.local_view_features", "enumerate", "numpy.array", "numpy.zeros", "range", "numpy.zeros", "range", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.local_view_features", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.local_view_features", "row.tolist.append", "len", "row.tolist.append", "numpy.append", "numpy.array.append", "numpy.array", "numpy.zeros", "range", "numpy.append", "numpy.append", "numpy.sum", "numpy.append", "numpy.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.get_attacker_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.fully_observed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.fully_observed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features"], ["", "def", "update_state", "(", "self", ",", "attacker_obs", ":", "np", ".", "ndarray", "=", "None", ",", "defender_obs", ":", "np", ".", "ndarray", "=", "None", ",", "\n", "state", ":", "np", ".", "ndarray", "=", "None", ",", "attacker", ":", "bool", "=", "True", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Update approximative Markov state\n\n        :param attacker_obs: attacker obs\n        :param defender_obs: defender observation\n        :param state: current state\n        :param attacker: boolean flag whether it is attacker or not\n        :return: new state\n        \"\"\"", "\n", "if", "attacker", "and", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "            ", "a_obs_len", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", "\n", "defender_obs", "=", "attacker_obs", "[", ":", ",", "a_obs_len", ":", "a_obs_len", "+", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "]", "\n", "if", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ":", "\n", "                ", "d_bool_features", "=", "attacker_obs", "[", ":", ",", "a_obs_len", "+", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ":", "]", "\n", "", "attacker_obs", "=", "attacker_obs", "[", ":", ",", "0", ":", "a_obs_len", "]", "\n", "\n", "", "if", "not", "attacker", "and", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", ":", "\n", "            ", "attacker_obs", "=", "self", ".", "idsgame_env", ".", "state", ".", "get_attacker_observation", "(", "\n", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "network_config", ",", "\n", "local_view", "=", "False", ",", "\n", "reconnaissance", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_actions", ")", "\n", "\n", "# Zero mean", "\n", "", "if", "self", ".", "pg_agent_config", ".", "zero_mean_features", ":", "\n", "            ", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                ", "attacker_obs_1", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "attacker_obs_1", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "2", "]", "\n", "", "zero_mean_attacker_features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "attacker_obs_1", ")", ":", "\n", "                ", "mean", "=", "np", ".", "mean", "(", "row", ")", "\n", "if", "mean", "!=", "0", ":", "\n", "                    ", "t", "=", "row", "-", "mean", "\n", "", "else", ":", "\n", "                    ", "t", "=", "row", "\n", "", "if", "np", ".", "isnan", "(", "t", ")", ".", "any", "(", ")", ":", "\n", "                    ", "t", "=", "attacker_obs", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "t", "=", "t", ".", "tolist", "(", ")", "\n", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                        ", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                        ", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "2", "]", ")", "\n", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "", "zero_mean_attacker_features", ".", "append", "(", "t", ")", "\n", "\n", "", "defender_obs_1", "=", "defender_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "zero_mean_defender_features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "defender_obs_1", ")", ":", "\n", "                ", "mean", "=", "np", ".", "mean", "(", "row", ")", "\n", "if", "mean", "!=", "0", ":", "\n", "                    ", "t", "=", "row", "-", "mean", "\n", "", "else", ":", "\n", "                    ", "t", "=", "row", "\n", "", "if", "np", ".", "isnan", "(", "t", ")", ".", "any", "(", ")", ":", "\n", "                    ", "t", "=", "defender_obs", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "t", "=", "t", ".", "tolist", "(", ")", "\n", "t", ".", "append", "(", "defender_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "zero_mean_defender_features", ".", "append", "(", "t", ")", "\n", "\n", "", "attacker_obs", "=", "np", ".", "array", "(", "zero_mean_attacker_features", ")", "\n", "defender_obs", "=", "np", ".", "array", "(", "zero_mean_defender_features", ")", "\n", "\n", "# Normalize", "\n", "", "if", "self", ".", "pg_agent_config", ".", "normalize_features", ":", "\n", "            ", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                ", "attacker_obs_1", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "/", "np", ".", "linalg", ".", "norm", "(", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "attacker_obs_1", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "2", "]", "/", "np", ".", "linalg", ".", "norm", "(", "attacker_obs", "[", ":", ",", "0", ":", "-", "2", "]", ")", "\n", "", "normalized_attacker_features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "attacker_obs_1", ")", ":", "\n", "                ", "if", "np", ".", "isnan", "(", "attacker_obs_1", ")", ".", "any", "(", ")", ":", "\n", "                    ", "t", "=", "attacker_obs", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                        ", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                        ", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "2", "]", ")", "\n", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "", "normalized_attacker_features", ".", "append", "(", "t", ")", "\n", "\n", "", "if", "attacker", "and", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                ", "defender_obs_1", "=", "defender_obs", "[", ":", ",", "0", ":", "-", "1", "]", "/", "np", ".", "linalg", ".", "norm", "(", "defender_obs", "[", ":", ",", "0", ":", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "defender_obs_1", "=", "defender_obs", "/", "np", ".", "linalg", ".", "norm", "(", "defender_obs", ")", "\n", "", "normalized_defender_features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "defender_obs_1", ")", ":", "\n", "                ", "if", "np", ".", "isnan", "(", "defender_obs_1", ")", ".", "any", "(", ")", ":", "\n", "                    ", "t", "=", "defender_obs", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "if", "attacker", "and", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "t", ".", "append", "(", "defender_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                        ", "t", "=", "row", "\n", "\n", "", "", "normalized_defender_features", ".", "append", "(", "t", ")", "\n", "\n", "", "attacker_obs", "=", "np", ".", "array", "(", "normalized_attacker_features", ")", "\n", "defender_obs", "=", "np", ".", "array", "(", "normalized_defender_features", ")", "\n", "\n", "", "if", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "and", "attacker", ":", "\n", "            ", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                ", "neighbor_defense_attributes", "=", "np", ".", "zeros", "(", "(", "attacker_obs", ".", "shape", "[", "0", "]", ",", "defender_obs", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "node", "in", "range", "(", "attacker_obs", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "id", "=", "int", "(", "attacker_obs", "[", "node", "]", "[", "-", "1", "]", ")", "\n", "neighbor_defense_attributes", "[", "node", "]", "=", "defender_obs", "[", "id", "]", "\n", "", "", "else", ":", "\n", "                ", "neighbor_defense_attributes", "=", "defender_obs", "\n", "\n", "", "", "if", "self", ".", "idsgame_env", ".", "fully_observed", "(", ")", "or", "(", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", "and", "attacker", ")", ":", "\n", "            ", "if", "self", ".", "pg_agent_config", ".", "merged_ad_features", ":", "\n", "                ", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                    ", "a_pos", "=", "attacker_obs", "[", ":", ",", "-", "1", "]", "\n", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "det_values", "=", "defender_obs", "[", ":", ",", "-", "1", "]", "\n", "temp", "=", "defender_obs", "[", ":", ",", "0", ":", "-", "1", "]", "-", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                        ", "temp", "=", "defender_obs", "[", ":", ",", "0", ":", "]", "-", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "temp", ")", ":", "\n", "                        ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "t", ".", "append", "(", "a_pos", "[", "idx", "]", ")", "\n", "if", "self", ".", "idsgame_env", ".", "fully_observed", "(", ")", ":", "\n", "                            ", "t", ".", "append", "(", "det_values", "[", "idx", "]", ")", "\n", "", "features", ".", "append", "(", "t", ")", "\n", "", "", "else", ":", "\n", "                    ", "node_ids", "=", "attacker_obs", "[", ":", ",", "-", "1", "]", "\n", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "det_values", "=", "neighbor_defense_attributes", "[", ":", ",", "-", "1", "]", "\n", "", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "temp", "=", "neighbor_defense_attributes", "[", ":", ",", "0", ":", "-", "1", "]", "-", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                        ", "temp", "=", "np", ".", "full", "(", "neighbor_defense_attributes", ".", "shape", ",", "-", "1", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "neighbor_defense_attributes", ")", ")", ":", "\n", "                            ", "if", "np", ".", "sum", "(", "neighbor_defense_attributes", "[", "i", "]", ")", ">", "0", ":", "\n", "                                ", "temp", "[", "i", "]", "=", "neighbor_defense_attributes", "[", "i", "]", "-", "attacker_obs", "[", "i", ",", "0", ":", "-", "1", "]", "\n", "", "", "", "features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "temp", ")", ":", "\n", "                        ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "t", ".", "append", "(", "node_ids", "[", "idx", "]", ")", "\n", "#t.append(node_reachable[idx])", "\n", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                            ", "t", ".", "append", "(", "det_values", "[", "idx", "]", ")", "\n", "", "features", ".", "append", "(", "t", ")", "\n", "", "", "features", "=", "np", ".", "array", "(", "features", ")", "\n", "if", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ":", "\n", "                    ", "f", "=", "np", ".", "zeros", "(", "(", "features", ".", "shape", "[", "0", "]", ",", "features", ".", "shape", "[", "1", "]", "+", "d_bool_features", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "features", ".", "shape", "[", "0", "]", ")", ":", "\n", "                        ", "f", "[", "i", "]", "=", "np", ".", "append", "(", "features", "[", "i", "]", ",", "d_bool_features", "[", "i", "]", ")", "\n", "", "features", "=", "f", "\n", "", "if", "self", ".", "pg_agent_config", ".", "state_length", "==", "1", ":", "\n", "                    ", "return", "features", "\n", "", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "s", "=", "np", ".", "array", "(", "[", "features", "]", "*", "self", ".", "pg_agent_config", ".", "state_length", ")", "\n", "return", "s", "\n", "", "state", "=", "np", ".", "append", "(", "state", "[", "1", ":", "]", ",", "np", ".", "array", "(", "[", "features", "]", ")", ",", "axis", "=", "0", ")", "\n", "return", "state", "\n", "", "else", ":", "\n", "                ", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                    ", "if", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", "and", "attacker", ":", "\n", "                        ", "combined_features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "attacker_obs", ")", ":", "\n", "                            ", "combined_row", "=", "np", ".", "append", "(", "row", ",", "defender_obs", "[", "idx", "]", ")", "\n", "combined_features", ".", "append", "(", "combined_row", ")", "\n", "", "if", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ":", "\n", "                            ", "combined_features", "=", "np", ".", "array", "(", "combined_features", ")", "\n", "f", "=", "np", ".", "zeros", "(", "\n", "(", "combined_features", ".", "shape", "[", "0", "]", ",", "combined_features", ".", "shape", "[", "1", "]", "+", "d_bool_features", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "combined_features", ".", "shape", "[", "0", "]", ")", ":", "\n", "                                ", "f", "[", "i", "]", "=", "np", ".", "append", "(", "combined_features", "[", "i", "]", ",", "d_bool_features", "[", "i", "]", ")", "\n", "", "combined_features", "=", "f", "\n", "", "return", "np", ".", "array", "(", "combined_features", ")", "\n", "\n", "", "return", "np", ".", "append", "(", "attacker_obs", ",", "defender_obs", ")", "\n", "", "else", ":", "\n", "                    ", "if", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ":", "\n", "                        ", "f", "=", "np", ".", "zeros", "(", "(", "attacker_obs", ".", "shape", "[", "0", "]", ",", "\n", "attacker_obs", ".", "shape", "[", "1", "]", "+", "neighbor_defense_attributes", ".", "shape", "[", "1", "]", "+", "\n", "d_bool_features", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "f", ".", "shape", "[", "0", "]", ")", ":", "\n", "                            ", "f", "[", "i", "]", "=", "np", ".", "append", "(", "np", ".", "append", "(", "attacker_obs", "[", "i", "]", ",", "neighbor_defense_attributes", "[", "i", "]", ")", ",", "\n", "d_bool_features", "[", "i", "]", ")", "\n", "", "", "else", ":", "\n", "                        ", "f", "=", "np", ".", "zeros", "(", "(", "attacker_obs", ".", "shape", "[", "0", "]", ",", "\n", "attacker_obs", ".", "shape", "[", "1", "]", "+", "neighbor_defense_attributes", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "f", ".", "shape", "[", "0", "]", ")", ":", "\n", "                            ", "f", "[", "i", "]", "=", "np", ".", "append", "(", "attacker_obs", "[", "i", "]", ",", "neighbor_defense_attributes", "[", "i", "]", ")", "\n", "", "", "", "if", "self", ".", "pg_agent_config", ".", "state_length", "==", "1", ":", "\n", "                    ", "return", "f", "\n", "", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "s", "=", "np", ".", "array", "(", "[", "f", "]", "*", "self", ".", "pg_agent_config", ".", "state_length", ")", "\n", "return", "s", "\n", "# if not self.idsgame_env.local_view_features() or not attacker:", "\n", "#     temp = np.append(attacker_obs, defender_obs)", "\n", "# else:", "\n", "#     temp = np.append(attacker_obs, neighbor_defense_attributes)", "\n", "", "state", "=", "np", ".", "append", "(", "state", "[", "1", ":", "]", ",", "np", ".", "array", "(", "[", "f", "]", ")", ",", "axis", "=", "0", ")", "\n", "", "return", "state", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "pg_agent_config", ".", "state_length", "==", "1", ":", "\n", "                ", "if", "attacker", ":", "\n", "                    ", "return", "np", ".", "array", "(", "attacker_obs", ")", "\n", "", "else", ":", "\n", "                    ", "return", "np", ".", "array", "(", "defender_obs", ")", "\n", "", "", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                ", "if", "attacker", ":", "\n", "                    ", "return", "np", ".", "array", "(", "[", "attacker_obs", "]", "*", "self", ".", "pg_agent_config", ".", "state_length", ")", "\n", "", "else", ":", "\n", "                    ", "return", "np", ".", "array", "(", "[", "defender_obs", "]", "*", "self", ".", "pg_agent_config", ".", "state_length", ")", "\n", "", "", "if", "attacker", ":", "\n", "                ", "state", "=", "np", ".", "append", "(", "state", "[", "1", ":", "]", ",", "np", ".", "array", "(", "[", "attacker_obs", "]", ")", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "state", "=", "np", ".", "append", "(", "state", "[", "1", ":", "]", ",", "np", ".", "array", "(", "[", "defender_obs", "]", ")", ",", "axis", "=", "0", ")", "\n", "", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.grid_seq_obs": [[443, 509], ["attacker_obs.flatten", "defender_obs.flatten", "numpy.stack", "len", "numpy.zeros", "range", "len", "numpy.zeros", "range", "len", "numpy.zeros", "range", "AssertionError", "len", "numpy.zeros", "range", "AssertionError", "len", "len", "len", "len"], "methods", ["None"], ["", "", "def", "grid_seq_obs", "(", "self", ",", "attacker_obs", ",", "defender_obs", ",", "attacker_state", ",", "defender_state", ",", "attacker", "=", "True", ")", ":", "\n", "        ", "if", "attacker", "and", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "# if not self.idsgame_env.local_view_features():", "\n", "            ", "a_obs_len", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", "\n", "defender_obs", "=", "attacker_obs", "[", ":", ",", "\n", "a_obs_len", ":", "a_obs_len", "+", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "]", "\n", "if", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ":", "\n", "                ", "d_bool_features", "=", "attacker_obs", "[", ":", ",", "\n", "a_obs_len", "+", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ":", "]", "\n", "", "attacker_obs", "=", "attacker_obs", "[", ":", ",", "0", ":", "a_obs_len", "-", "1", "]", "\n", "\n", "", "a_vec", "=", "attacker_obs", ".", "flatten", "(", ")", "\n", "if", "len", "(", "attacker_state", ")", "==", "0", ":", "\n", "            ", "attacker_plane", "=", "np", ".", "zeros", "(", "(", "len", "(", "a_vec", ")", ",", "self", ".", "pg_agent_config", ".", "state_length", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "pg_agent_config", ".", "state_length", ")", ":", "\n", "                ", "attacker_plane", "[", ":", ",", "i", "]", "=", "a_vec", "\n", "", "", "elif", "len", "(", "attacker_state", ")", ">", "0", ":", "\n", "            ", "attacker_plane", "=", "attacker_state", "[", "0", "]", "\n", "# attacker_plane[:, 1:] = attacker_plane[:, 0:-1]", "\n", "# attacker_plane[:, 0] = a_vec", "\n", "n_attacker_plane", "=", "np", ".", "zeros", "(", "(", "len", "(", "a_vec", ")", ",", "self", ".", "pg_agent_config", ".", "state_length", ")", ")", "\n", "n_attacker_plane", "[", ":", ",", "0", "]", "=", "a_vec", "\n", "for", "i", "in", "range", "(", "self", ".", "pg_agent_config", ".", "state_length", "-", "1", ")", ":", "\n", "                ", "n_attacker_plane", "[", ":", ",", "i", "+", "1", "]", "=", "attacker_plane", "[", ":", ",", "i", "]", "\n", "", "attacker_plane", "=", "n_attacker_plane", "\n", "", "else", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Invalid state\"", ")", "\n", "\n", "", "d_vec", "=", "defender_obs", ".", "flatten", "(", ")", "\n", "if", "len", "(", "attacker_state", ")", "==", "0", ":", "\n", "            ", "defense_plane", "=", "np", ".", "zeros", "(", "(", "len", "(", "d_vec", ")", ",", "self", ".", "pg_agent_config", ".", "state_length", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "pg_agent_config", ".", "state_length", ")", ":", "\n", "                ", "defense_plane", "[", ":", ",", "i", "]", "=", "d_vec", "\n", "", "", "elif", "len", "(", "attacker_state", ")", ">", "0", ":", "\n", "            ", "defense_plane", "=", "attacker_state", "[", "1", "]", "\n", "# defense_plane[:, 1:] = defense_plane[:,0:-1]", "\n", "# defense_plane[:,0] = d_vec", "\n", "n_defense_plane", "=", "np", ".", "zeros", "(", "(", "len", "(", "d_vec", ")", ",", "self", ".", "pg_agent_config", ".", "state_length", ")", ")", "\n", "n_defense_plane", "[", ":", ",", "0", "]", "=", "d_vec", "\n", "for", "i", "in", "range", "(", "self", ".", "pg_agent_config", ".", "state_length", "-", "1", ")", ":", "\n", "                ", "n_defense_plane", "[", ":", ",", "i", "+", "1", "]", "=", "defense_plane", "[", ":", ",", "i", "]", "\n", "", "defense_plane", "=", "n_defense_plane", "\n", "", "else", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Invalid state\"", ")", "\n", "\n", "# rec_vec = d_bool_features.flatten()", "\n", "# if len(attacker_state) == 0:", "\n", "#     rec_plane = np.zeros((len(rec_vec), self.pg_agent_config.state_length))", "\n", "#     for i in range(self.pg_agent_config.state_length):", "\n", "#         rec_plane[:, i] = rec_vec", "\n", "# elif len(attacker_state) > 0:", "\n", "#     rec_plane = attacker_state[2]", "\n", "#     n_rec_plane = np.zeros((len(rec_vec), self.pg_agent_config.state_length))", "\n", "#     n_rec_plane[:, 0] = d_vec", "\n", "#     for i in range(self.pg_agent_config.state_length - 1):", "\n", "#         n_rec_plane[:, i + 1] = rec_plane[:, i]", "\n", "#     rec_plane = n_rec_plane", "\n", "# else:", "\n", "#     raise AssertionError(\"Invalid state\")", "\n", "\n", "# print(\"attacker_plane:{}\".format(attacker_plane.shape))", "\n", "# print(\"defender_plane:{}\".format(defense_plane.shape))", "\n", "", "feature_frames", "=", "np", ".", "stack", "(", "[", "attacker_plane", ",", "defense_plane", "]", ",", "axis", "=", "0", ")", "\n", "# print(\"feature_frames:\")", "\n", "# print(feature_frames)", "\n", "return", "feature_frames", "\n", "#raise AssertionError(\"test\")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.grid_obs": [[514, 582], ["numpy.zeros", "enumerate", "numpy.zeros", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.idsgame_config.game_config.network_config.get_adjacency_matrix_id", "range", "numpy.zeros", "range", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.fully_observed", "sklearn.preprocessing.normalize", "sklearn.preprocessing.normalize", "numpy.full", "len", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.idsgame_config.game_config.network_config.get_node_pos", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.idsgame_config.game_config.network_config.get_adjacency_matrix_id", "numpy.full", "len", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.idsgame_config.game_config.network_config.get_node_pos", "numpy.full", "sklearn.preprocessing.normalize", "sklearn.preprocessing.normalize", "numpy.stack", "numpy.stack", "int"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_adjacency_matrix_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.fully_observed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_pos", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_adjacency_matrix_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_pos"], ["", "def", "grid_obs", "(", "self", ",", "attacker_obs", ",", "defender_obs", ",", "attacker", "=", "True", ")", ":", "\n", "\n", "        ", "if", "attacker", "and", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "            ", "a_obs_len", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", "\n", "defender_obs", "=", "attacker_obs", "[", ":", ",", "a_obs_len", ":", "]", "\n", "attacker_obs", "=", "attacker_obs", "[", ":", ",", "0", ":", "a_obs_len", "]", "\n", "attacker_position", "=", "attacker_obs", "[", ":", ",", "-", "1", "]", "\n", "attacker_obs", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "elif", "self", ".", "idsgame_env", ".", "fully_observed", "(", ")", ":", "\n", "            ", "a_obs_len", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", "\n", "attacker_position", "=", "attacker_obs", "[", ":", ",", "-", "1", "]", "\n", "attacker_obs", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "defender_obs", "=", "defender_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "\n", "", "attack_plane", "=", "attacker_obs", "\n", "if", "self", ".", "pg_agent_config", ".", "normalize_features", ":", "\n", "            ", "normalized_attack_plane", "=", "preprocessing", ".", "normalize", "(", "attack_plane", ")", "\n", "\n", "", "defense_plane", "=", "defender_obs", "\n", "if", "self", ".", "pg_agent_config", ".", "normalize_features", ":", "\n", "            ", "normalized_defense_plane", "=", "preprocessing", ".", "normalize", "(", "defense_plane", ")", "\n", "\n", "", "position_plane", "=", "np", ".", "zeros", "(", "attack_plane", ".", "shape", ")", "\n", "for", "idx", ",", "present", "in", "enumerate", "(", "attacker_position", ")", ":", "\n", "            ", "position_plane", "[", "idx", "]", "=", "np", ".", "full", "(", "position_plane", ".", "shape", "[", "1", "]", ",", "present", ")", "\n", "\n", "", "reachable_plane", "=", "np", ".", "zeros", "(", "attack_plane", ".", "shape", ")", "\n", "attacker_row", ",", "attacker_col", "=", "self", ".", "idsgame_env", ".", "state", ".", "attacker_pos", "\n", "attacker_matrix_id", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "get_adjacency_matrix_id", "(", "attacker_row", ",", "attacker_col", ")", "\n", "for", "node_id", "in", "range", "(", "len", "(", "attack_plane", ")", ")", ":", "\n", "            ", "node_row", ",", "node_col", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "get_node_pos", "(", "node_id", ")", "\n", "adj_matrix_id", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "get_adjacency_matrix_id", "(", "node_row", ",", "node_col", ")", "\n", "reachable", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "adjacency_matrix", "[", "attacker_matrix_id", "]", "[", "adj_matrix_id", "]", "==", "int", "(", "1", ")", "\n", "if", "reachable", ":", "\n", "                ", "val", "=", "1", "\n", "", "else", ":", "\n", "                ", "val", "=", "0", "\n", "", "reachable_plane", "[", "node_id", "]", "=", "np", ".", "full", "(", "reachable_plane", ".", "shape", "[", "1", "]", ",", "val", ")", "\n", "\n", "\n", "", "row_difference_plane", "=", "np", ".", "zeros", "(", "attack_plane", ".", "shape", ")", "\n", "for", "node_id", "in", "range", "(", "len", "(", "attack_plane", ")", ")", ":", "\n", "            ", "node_row", ",", "node_col", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "get_node_pos", "(", "node_id", ")", "\n", "row_difference", "=", "attacker_row", "-", "node_row", "\n", "row_difference_plane", "[", "node_id", "]", "=", "np", ".", "full", "(", "row_difference_plane", ".", "shape", "[", "1", "]", ",", "row_difference", ")", "\n", "\n", "", "if", "self", ".", "pg_agent_config", ".", "normalize_features", ":", "\n", "            ", "normalized_row_difference_plance", "=", "preprocessing", ".", "normalize", "(", "row_difference_plane", ")", "\n", "\n", "", "attack_defense_difference_plane", "=", "attacker_obs", "-", "defender_obs", "\n", "if", "self", ".", "pg_agent_config", ".", "normalize_features", ":", "\n", "            ", "normalized_attack_defense_difference_plane", "=", "preprocessing", ".", "normalize", "(", "attack_defense_difference_plane", ")", "\n", "\n", "", "if", "self", ".", "pg_agent_config", ".", "normalize_features", ":", "\n", "            ", "feature_frames", "=", "np", ".", "stack", "(", "[", "normalized_attack_plane", ",", "normalized_defense_plane", ",", "position_plane", ",", "reachable_plane", ",", "\n", "normalized_row_difference_plance", ",", "\n", "normalized_attack_defense_difference_plane", "]", ",", "\n", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "feature_frames", "=", "np", ".", "stack", "(", "\n", "[", "attack_plane", ",", "defense_plane", ",", "position_plane", ",", "reachable_plane", ",", "\n", "row_difference_plane", ",", "\n", "attack_defense_difference_plane", "]", ",", "\n", "axis", "=", "0", ")", "\n", "# print(\"feature_frames:\")", "\n", "# print(feature_frames)", "\n", "# raise AssertionError(\"test\")", "\n", "", "return", "feature_frames", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.one_hot_obs": [[583, 665], ["baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.local_view_features", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.fully_observed", "numpy.zeros", "list", "range", "numpy.zeros", "range", "numpy.array", "range", "range", "int", "enumerate", "enumerate", "range", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.local_view_features", "row.tolist", "numpy.array.append", "numpy.full", "range", "row.tolist", "row.tolist.append", "numpy.array.append", "row.tolist.append", "len", "row.tolist.append", "numpy.sum", "list.index"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.fully_observed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features"], ["", "def", "one_hot_obs", "(", "self", ",", "attacker_obs", ",", "defender_obs", ",", "attacker", "=", "True", ")", ":", "\n", "        ", "attack_types", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "\n", "max_value", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "max_value", "\n", "num_nodes", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_nodes", "\n", "\n", "if", "attacker", "and", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "#if not self.idsgame_env.local_view_features():", "\n", "            ", "a_obs_len", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", "\n", "defender_obs", "=", "attacker_obs", "[", ":", ",", "a_obs_len", ":", "a_obs_len", "+", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "]", "\n", "if", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ":", "\n", "                ", "d_bool_features", "=", "attacker_obs", "[", ":", ",", "a_obs_len", "+", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ":", "]", "\n", "", "attacker_obs", "=", "attacker_obs", "[", ":", ",", "0", ":", "a_obs_len", "]", "\n", "\n", "", "if", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "and", "attacker", ":", "\n", "            ", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                ", "neighbor_defense_attributes", "=", "np", ".", "zeros", "(", "(", "attacker_obs", ".", "shape", "[", "0", "]", ",", "defender_obs", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "node", "in", "range", "(", "attacker_obs", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "id", "=", "int", "(", "attacker_obs", "[", "node", "]", "[", "-", "1", "]", ")", "\n", "neighbor_defense_attributes", "[", "node", "]", "=", "defender_obs", "[", "id", "]", "\n", "", "", "else", ":", "\n", "                ", "neighbor_defense_attributes", "=", "defender_obs", "\n", "\n", "", "", "if", "self", ".", "idsgame_env", ".", "fully_observed", "(", ")", "or", "(", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", "and", "attacker", ")", ":", "\n", "            ", "if", "self", ".", "pg_agent_config", ".", "merged_ad_features", ":", "\n", "                ", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                    ", "a_pos", "=", "attacker_obs", "[", ":", ",", "-", "1", "]", "\n", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "det_values", "=", "defender_obs", "[", ":", ",", "-", "1", "]", "\n", "temp", "=", "defender_obs", "[", ":", ",", "0", ":", "-", "1", "]", "-", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                        ", "temp", "=", "defender_obs", "[", ":", ",", "0", ":", "]", "-", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "temp", ")", ":", "\n", "                        ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "#t.append(a_pos[idx])", "\n", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                            ", "t", ".", "append", "(", "det_values", "[", "idx", "]", ")", "\n", "", "features", ".", "append", "(", "t", ")", "\n", "", "", "else", ":", "\n", "                    ", "node_ids", "=", "attacker_obs", "[", ":", ",", "-", "1", "]", "\n", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "det_values", "=", "neighbor_defense_attributes", "[", ":", ",", "-", "1", "]", "\n", "", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "temp", "=", "neighbor_defense_attributes", "[", ":", ",", "0", ":", "-", "1", "]", "-", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                        ", "temp", "=", "np", ".", "full", "(", "neighbor_defense_attributes", ".", "shape", ",", "-", "1", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "neighbor_defense_attributes", ")", ")", ":", "\n", "                            ", "if", "np", ".", "sum", "(", "neighbor_defense_attributes", "[", "i", "]", ")", ">", "0", ":", "\n", "                                ", "temp", "[", "i", "]", "=", "neighbor_defense_attributes", "[", "i", "]", "-", "attacker_obs", "[", "i", ",", "0", ":", "-", "1", "]", "\n", "", "", "", "features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "temp", ")", ":", "\n", "                        ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "t", ".", "append", "(", "node_ids", "[", "idx", "]", ")", "\n", "#t.append(node_reachable[idx])", "\n", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                            ", "t", ".", "append", "(", "det_values", "[", "idx", "]", ")", "\n", "", "features", ".", "append", "(", "t", ")", "\n", "", "", "features", "=", "np", ".", "array", "(", "features", ")", "\n", "# if self.idsgame_env.idsgame_config.reconnaissance_bool_features:", "\n", "#     f = np.zeros((features.shape[0], features.shape[1] + d_bool_features.shape[1]))", "\n", "#     for i in range(features.shape[0]):", "\n", "#         f[i] = np.append(features[i], d_bool_features[i])", "\n", "#     features = f", "\n", "", "", "if", "attacker", ":", "\n", "            ", "a_obs", "=", "np", ".", "zeros", "(", "(", "num_nodes", ",", "attack_types", "*", "(", "(", "max_value", "+", "1", ")", "*", "2", "+", "1", ")", ")", ")", "\n", "values_list", "=", "list", "(", "range", "(", "-", "max_value", ",", "max_value", "+", "1", ")", ")", "\n", "for", "n", "in", "range", "(", "num_nodes", ")", ":", "\n", "                ", "for", "t", "in", "range", "(", "attack_types", ")", ":", "\n", "                    ", "for", "v", "in", "range", "(", "-", "max_value", ",", "max_value", "+", "1", ")", ":", "\n", "                        ", "if", "features", "[", "n", "]", "[", "t", "]", "==", "v", ":", "\n", "                            ", "a_obs", "[", "n", "]", "[", "t", "*", "(", "(", "max_value", "+", "1", ")", "*", "2", ")", "+", "values_list", ".", "index", "(", "v", ")", "]", "=", "1", "\n", "", "", "", "", "a_obs", "[", ":", ",", "-", "1", "]", "=", "a_pos", "\n", "# print(\"attacker obs:{}, defender_obs:{}\".format(attacker_obs, defender_obs))", "\n", "# print(\"a_obs:{}\".format(a_obs))", "\n", "# print(\"a_obs shape:{}\".format(a_obs.shape))", "\n", "# print(\"flatten shape:{}\".format(a_obs.flatten().shape))", "\n", "# raise AssertionError(\"Test\")", "\n", "", "if", "attacker", ":", "\n", "            ", "return", "a_obs", "\n", "", "else", ":", "\n", "            ", "return", "defender_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.image_grid_obs": [[666, 759], ["set", "range", "matplotlib.colors.ListedColormap", "matplotlib.colors.ListedColormap", "matplotlib.colors.ListedColormap", "matplotlib.colors.ListedColormap", "matplotlib.figure", "matplotlib.figure", "matplotlib.pcolor", "matplotlib.pcolor", "matplotlib.axis", "matplotlib.axis", "gym_idsgame.get_img_from_fig", "numpy.rollaxis", "matplotlib.close", "matplotlib.close", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.local_view_features", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.fully_observed", "len", "numpy.zeros", "range", "numpy.array", "numpy.full", "set.add", "numpy.all", "len", "int", "enumerate", "enumerate", "numpy.full", "set.add", "sorted", "range", "baseline_env_wrapper.BaselineEnvWrapper.idsgame_env.local_view_features", "row.tolist", "numpy.array.append", "numpy.full", "range", "row.tolist", "row.tolist.append", "numpy.array.append", "len", "sorted.index", "set.add", "row.tolist.append", "len", "row.tolist.append", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.get_img_from_fig", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.fully_observed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add"], ["", "", "def", "image_grid_obs", "(", "self", ",", "attacker_obs", ",", "defender_obs", ",", "attacker", "=", "True", ")", ":", "\n", "        ", "if", "attacker", "and", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "#if not self.idsgame_env.local_view_features():", "\n", "            ", "a_obs_len", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", "\n", "defender_obs", "=", "attacker_obs", "[", ":", ",", "a_obs_len", ":", "a_obs_len", "+", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "]", "\n", "if", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ":", "\n", "                ", "d_bool_features", "=", "attacker_obs", "[", ":", ",", "a_obs_len", "+", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ":", "]", "\n", "", "attacker_obs", "=", "attacker_obs", "[", ":", ",", "0", ":", "a_obs_len", "]", "\n", "\n", "", "if", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "and", "attacker", ":", "\n", "            ", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                ", "neighbor_defense_attributes", "=", "np", ".", "zeros", "(", "(", "attacker_obs", ".", "shape", "[", "0", "]", ",", "defender_obs", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "node", "in", "range", "(", "attacker_obs", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "id", "=", "int", "(", "attacker_obs", "[", "node", "]", "[", "-", "1", "]", ")", "\n", "neighbor_defense_attributes", "[", "node", "]", "=", "defender_obs", "[", "id", "]", "\n", "", "", "else", ":", "\n", "                ", "neighbor_defense_attributes", "=", "defender_obs", "\n", "\n", "", "", "if", "self", ".", "idsgame_env", ".", "fully_observed", "(", ")", "or", "(", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", "and", "attacker", ")", ":", "\n", "            ", "if", "self", ".", "pg_agent_config", ".", "merged_ad_features", ":", "\n", "                ", "if", "not", "self", ".", "idsgame_env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                    ", "a_pos", "=", "attacker_obs", "[", ":", ",", "-", "1", "]", "\n", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "det_values", "=", "defender_obs", "[", ":", ",", "-", "1", "]", "\n", "temp", "=", "defender_obs", "[", ":", ",", "0", ":", "-", "1", "]", "-", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                        ", "temp", "=", "defender_obs", "[", ":", ",", "0", ":", "]", "-", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "temp", ")", ":", "\n", "                        ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "#t.append(a_pos[idx])", "\n", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                            ", "t", ".", "append", "(", "det_values", "[", "idx", "]", ")", "\n", "", "features", ".", "append", "(", "t", ")", "\n", "", "", "else", ":", "\n", "                    ", "node_ids", "=", "attacker_obs", "[", ":", ",", "-", "1", "]", "\n", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "det_values", "=", "neighbor_defense_attributes", "[", ":", ",", "-", "1", "]", "\n", "", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "temp", "=", "neighbor_defense_attributes", "[", ":", ",", "0", ":", "-", "1", "]", "-", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                        ", "temp", "=", "np", ".", "full", "(", "neighbor_defense_attributes", ".", "shape", ",", "-", "1", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "neighbor_defense_attributes", ")", ")", ":", "\n", "                            ", "if", "np", ".", "sum", "(", "neighbor_defense_attributes", "[", "i", "]", ")", ">", "0", ":", "\n", "                                ", "temp", "[", "i", "]", "=", "neighbor_defense_attributes", "[", "i", "]", "-", "attacker_obs", "[", "i", ",", "0", ":", "-", "1", "]", "\n", "", "", "", "features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "temp", ")", ":", "\n", "                        ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "t", ".", "append", "(", "node_ids", "[", "idx", "]", ")", "\n", "#t.append(node_reachable[idx])", "\n", "if", "not", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                            ", "t", ".", "append", "(", "det_values", "[", "idx", "]", ")", "\n", "", "features", ".", "append", "(", "t", ")", "\n", "", "", "features", "=", "np", ".", "array", "(", "features", ")", "\n", "\n", "", "", "colors", "=", "set", "(", ")", "\n", "rank_ids", "=", "[", "2", ",", "3", ",", "4", ",", "5", "]", "\n", "features", "[", "0", ",", ":", "]", "=", "[", "1", ",", "2", ",", "3", ",", "4", "]", "\n", "for", "n", "in", "range", "(", "len", "(", "a_pos", ")", ")", ":", "\n", "            ", "if", "a_pos", "[", "n", "]", "==", "1", ":", "\n", "                ", "features", "[", "n", ",", ":", "]", "=", "np", ".", "full", "(", "features", ".", "shape", "[", "1", "]", ",", "0", ")", "\n", "colors", ".", "add", "(", "0", ")", "\n", "", "elif", "np", ".", "all", "(", "features", "[", "n", "]", "==", "constants", ".", "GAME_CONFIG", ".", "INITIAL_RECONNAISSANCE_STATE", ")", ":", "\n", "                ", "features", "[", "n", ",", ":", "]", "=", "np", ".", "full", "(", "features", ".", "shape", "[", "1", "]", ",", "1", ")", "\n", "colors", ".", "add", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "values", "=", "features", "[", "n", ",", ":", "]", "\n", "sorted_values", "=", "sorted", "(", "values", ",", "key", "=", "lambda", "x", ":", "x", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "values", ")", ")", ":", "\n", "                    ", "idx", "=", "sorted_values", ".", "index", "(", "values", "[", "i", "]", ")", "\n", "values", "[", "i", "]", "=", "rank_ids", "[", "idx", "]", "\n", "colors", ".", "add", "(", "rank_ids", "[", "idx", "]", ")", "\n", "", "features", "[", "n", ",", ":", "]", "=", "values", "\n", "#print(\"features:{}\".format(features))", "\n", "", "", "cmap", "=", "matplotlib", ".", "colors", ".", "ListedColormap", "(", "[", "'white'", ",", "'red'", ",", "\"Blue\"", ",", "\"gray\"", ",", "\"yellow\"", ",", "\n", "\"green\"", ",", "\"#A4940A\"", ",", "\"#FFE600\"", "]", ",", "N", "=", "len", "(", "colors", ")", ")", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "3", ",", "3", ")", ")", "\n", "plt", ".", "pcolor", "(", "features", "[", ":", ":", "-", "1", "]", ",", "cmap", "=", "cmap", ",", "edgecolors", "=", "'k'", ",", "linewidths", "=", "3", ")", "\n", "plt", ".", "axis", "(", "\"off\"", ")", "\n", "data", "=", "util", ".", "get_img_from_fig", "(", "fig", ",", "dpi", "=", "20", ")", "\n", "data", "=", "np", ".", "rollaxis", "(", "data", ",", "2", ",", "0", ")", "\n", "plt", ".", "close", "(", ")", "\n", "#print(\"data shape:{}\".format(data.shape))", "\n", "#print(\"data shape:{}\".format(data.shape))", "\n", "#fig2 = plt.figure(figsize=(4, 4))", "\n", "#ax = plt.Axes(fig2, [0., 0., 1., 1.])", "\n", "#ax.set_axis_off()", "\n", "#fig2.add_axes(ax)", "\n", "#ax.imshow(data)", "\n", "#plt.show()", "\n", "#raise AssertionError(\"test\")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.baseline_env_wrapper.BaselineEnvWrapper.multi_channel_obs": [[760, 778], ["baseline_env_wrapper.BaselineEnvWrapper.update_state", "numpy.array", "attacker_obs.flatten", "defender_obs.flatten", "node_pos_obs.flatten", "d_bool_features.flatten", "baseline_env_wrapper.BaselineEnvWrapper.flatten"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state"], ["", "def", "multi_channel_obs", "(", "self", ",", "attacker_obs", ",", "defender_obs", ",", "attacker", "=", "True", ")", ":", "\n", "        ", "attacker_state_0", "=", "self", ".", "update_state", "(", "attacker_obs", "=", "attacker_obs", ",", "defender_obs", "=", "defender_obs", ",", "\n", "state", "=", "self", ".", "attacker_state", ",", "attacker", "=", "True", ")", "\n", "if", "attacker", "and", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "#if not self.idsgame_env.local_view_features():", "\n", "            ", "a_obs_len", "=", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", "\n", "defender_obs", "=", "attacker_obs", "[", ":", ",", "a_obs_len", ":", "a_obs_len", "+", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "]", "\n", "if", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ":", "\n", "                ", "d_bool_features", "=", "attacker_obs", "[", ":", ",", "a_obs_len", "+", "self", ".", "idsgame_env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ":", "]", "\n", "", "attacker_obs", "=", "attacker_obs", "[", ":", ",", "0", ":", "a_obs_len", "]", "\n", "node_pos_obs", "=", "attacker_obs", "[", ":", ",", "-", "1", "]", "\n", "attacker_obs", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "# print(\"attacker obs:{}\".format(attacker_obs.shape))", "\n", "# print(\"defender obs:{}\".format(defender_obs.shape))", "\n", "# print(\"reconnaissance obs:{}\".format(d_bool_features.shape))", "\n", "# print(\"node position obs:{}\".format(node_pos_obs.shape))", "\n", "# raise AssertionError(\"test\")", "\n", "", "return", "np", ".", "array", "(", "[", "attacker_obs", ".", "flatten", "(", ")", ",", "defender_obs", ".", "flatten", "(", ")", ",", "node_pos_obs", ".", "flatten", "(", ")", ",", "d_bool_features", ".", "flatten", "(", ")", ",", "attacker_state_0", ".", "flatten", "(", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BaseFeaturesExtractor.__init__": [[24, 33], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "pg_agent_config", ":", "PolicyGradientAgentConfig", ",", "observation_space", ":", "gym", ".", "Space", ",", "features_dim", ":", "int", "=", "0", ",", "\n", "node_net", ":", "bool", "=", "False", ",", "at_net", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "BaseFeaturesExtractor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "features_dim", ">", "0", "\n", "self", ".", "_observation_space", "=", "observation_space", "\n", "self", ".", "_features_dim", "=", "features_dim", "\n", "self", ".", "pg_agent_config", "=", "pg_agent_config", "\n", "self", ".", "node_net", "=", "node_net", "\n", "self", ".", "at_net", "=", "at_net", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BaseFeaturesExtractor.features_dim": [[34, 37], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "features_dim", "(", "self", ")", "->", "int", ":", "\n", "        ", "return", "self", ".", "_features_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BaseFeaturesExtractor.forward": [[38, 40], ["NotImplementedError"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "observations", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.FlattenExtractor.__init__": [[50, 56], ["common_policies.BaseFeaturesExtractor.__init__", "torch.Flatten", "torch.Flatten", "stable_baselines3.common.preprocessing.get_flattened_obs_dim"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "pg_agent_config", ":", "PolicyGradientAgentConfig", ",", "observation_space", ":", "gym", ".", "Space", ",", "\n", "node_net", ":", "bool", "=", "False", ",", "at_net", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "FlattenExtractor", ",", "self", ")", ".", "__init__", "(", "pg_agent_config", ",", "observation_space", ",", "\n", "get_flattened_obs_dim", "(", "observation_space", ")", ",", "at_net", "=", "at_net", ",", "\n", "node_net", "=", "node_net", ")", "\n", "self", ".", "flatten", "=", "nn", ".", "Flatten", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.FlattenExtractor.forward": [[57, 62], ["len", "common_policies.FlattenExtractor.flatten"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "observations", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "if", "len", "(", "observations", ".", "shape", ")", ">", "1", ":", "\n", "            ", "return", "self", ".", "flatten", "(", "observations", ")", "\n", "", "else", ":", "\n", "            ", "return", "observations", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.NatureCNN.__init__": [[73, 149], ["common_policies.BaseFeaturesExtractor.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Flatten", "torch.Flatten", "torch.Sequential", "torch.Sequential", "torch.no_grad", "torch.no_grad", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Flatten", "torch.Flatten", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.ReLU", "torch.ReLU", "torch.Flatten", "torch.Flatten", "torch.Sequential", "torch.Sequential", "common_policies.NatureCNN.cnn", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.ReLU", "torch.ReLU", "torch.Flatten", "torch.Flatten", "gym_idsgame.agents.training_agents.models.idsgame_resnet.IdsGameResNet", "torch.as_tensor().float", "torch.as_tensor().float", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Flatten", "torch.Flatten", "torch.Sequential", "torch.Sequential", "torch.as_tensor", "torch.as_tensor", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.Flatten", "torch.Flatten", "observation_space.sample"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.sample"], ["def", "__init__", "(", "self", ",", "pg_agent_config", ":", "PolicyGradientAgentConfig", ",", "observation_space", ":", "gym", ".", "spaces", ".", "Box", ",", "\n", "features_dim", ":", "int", "=", "512", ",", "node_net", ":", "bool", "=", "False", ",", "at_net", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "NatureCNN", ",", "self", ")", ".", "__init__", "(", "pg_agent_config", ",", "observation_space", ",", "pg_agent_config", ".", "features_dim", ",", "\n", "at_net", "=", "at_net", ",", "node_net", "=", "node_net", ")", "\n", "\n", "n_input_channels", "=", "observation_space", ".", "shape", "[", "0", "]", "\n", "if", "pg_agent_config", ".", "cnn_type", "==", "0", ":", "\n", "            ", "self", ".", "cnn", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "n_input_channels", ",", "out_channels", "=", "2", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "2", ",", "out_channels", "=", "2", ",", "kernel_size", "=", "2", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "2", ",", "out_channels", "=", "2", ",", "kernel_size", "=", "2", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Flatten", "(", ")", ")", "\n", "", "elif", "pg_agent_config", ".", "cnn_type", "==", "1", ":", "\n", "            ", "self", ".", "cnn", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "n_input_channels", ",", "out_channels", "=", "8", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "8", ",", "out_channels", "=", "8", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "8", ",", "out_channels", "=", "8", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Flatten", "(", ")", ")", "\n", "", "elif", "pg_agent_config", ".", "cnn_type", "==", "2", ":", "\n", "            ", "self", ".", "cnn", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "n_input_channels", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Flatten", "(", ")", ")", "\n", "", "elif", "pg_agent_config", ".", "cnn_type", "==", "3", ":", "\n", "            ", "self", ".", "cnn", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "n_input_channels", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Flatten", "(", ")", ")", "\n", "\n", "", "elif", "pg_agent_config", ".", "cnn_type", "==", "4", ":", "\n", "            ", "self", ".", "cnn", "=", "IdsGameResNet", "(", "in_channels", "=", "6", ",", "output_dim", "=", "44", ")", "\n", "", "elif", "pg_agent_config", ".", "cnn_type", "==", "5", ":", "\n", "            ", "self", ".", "cnn", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "n_input_channels", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "64", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Flatten", "(", ")", ")", "\n", "\n", "", "elif", "pg_agent_config", ".", "cnn_type", "==", "6", ":", "\n", "            ", "self", ".", "cnn", "=", "nn", ".", "Sequential", "(", "nn", ".", "Conv2d", "(", "n_input_channels", ",", "out_channels", "=", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "2", ",", "out_channels", "=", "2", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "2", ",", "out_channels", "=", "2", ",", "kernel_size", "=", "2", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Conv2d", "(", "in_channels", "=", "2", ",", "out_channels", "=", "2", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", ",", "\n", "nn", ".", "Flatten", "(", ")", ")", "\n", "\n", "", "if", "not", "self", ".", "pg_agent_config", ".", "cnn_type", "==", "4", ":", "\n", "# Compute shape by doing one forward pass", "\n", "            ", "with", "th", ".", "no_grad", "(", ")", ":", "\n", "                ", "n_flatten", "=", "self", ".", "cnn", "(", "th", ".", "as_tensor", "(", "observation_space", ".", "sample", "(", ")", "[", "None", "]", ")", ".", "float", "(", ")", ")", ".", "shape", "[", "1", "]", "\n", "\n", "", "self", ".", "linear", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "n_flatten", ",", "pg_agent_config", ".", "features_dim", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.NatureCNN.forward": [[150, 157], ["len", "observations.unsqueeze.unsqueeze.unsqueeze", "common_policies.NatureCNN.linear", "common_policies.NatureCNN.cnn", "common_policies.NatureCNN.cnn"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "observations", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "if", "len", "(", "observations", ".", "shape", ")", "==", "3", ":", "\n", "            ", "observations", "=", "observations", ".", "unsqueeze", "(", "0", ")", "\n", "", "if", "not", "self", ".", "pg_agent_config", ".", "cnn_type", "==", "4", ":", "\n", "            ", "return", "self", ".", "linear", "(", "self", ".", "cnn", "(", "observations", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "self", ".", "cnn", "(", "observations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.__init__": [[181, 215], ["torch.Module.__init__", "gym_idsgame.agents.training_agents.openai_baselines.common.utils.get_device"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.get_device"], ["def", "__init__", "(", "self", ",", "pg_agent_config", ":", "PolicyGradientAgentConfig", ",", "observation_space", ":", "gym", ".", "spaces", ".", "Space", ",", "\n", "action_space", ":", "gym", ".", "spaces", ".", "Space", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "'auto'", ",", "\n", "features_extractor_class", ":", "Type", "[", "BaseFeaturesExtractor", "]", "=", "FlattenExtractor", ",", "\n", "features_extractor_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "features_extractor", ":", "Optional", "[", "nn", ".", "Module", "]", "=", "None", ",", "\n", "normalize_images", ":", "bool", "=", "False", ",", "\n", "optimizer_class", ":", "Type", "[", "th", ".", "optim", ".", "Optimizer", "]", "=", "th", ".", "optim", ".", "Adam", ",", "\n", "optimizer_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ",", "\n", "squash_output", ":", "bool", "=", "False", ",", "\n", "node_net", ":", "bool", "=", "False", ",", "\n", "at_net", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "BasePolicy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "optimizer_kwargs", "is", "None", ":", "\n", "            ", "optimizer_kwargs", "=", "{", "}", "\n", "\n", "", "if", "features_extractor_kwargs", "is", "None", ":", "\n", "            ", "features_extractor_kwargs", "=", "{", "}", "\n", "", "self", ".", "node_net", "=", "node_net", "\n", "self", ".", "at_net", "=", "at_net", "\n", "self", ".", "pg_agent_config", "=", "pg_agent_config", "\n", "self", ".", "observation_space", "=", "observation_space", "\n", "self", ".", "action_space", "=", "action_space", "\n", "self", ".", "device", "=", "get_device", "(", "device", ",", "self", ".", "pg_agent_config", ")", "\n", "self", ".", "features_extractor", "=", "features_extractor", "\n", "self", ".", "normalize_images", "=", "normalize_images", "\n", "self", ".", "_squash_output", "=", "squash_output", "\n", "\n", "self", ".", "optimizer_class", "=", "optimizer_class", "\n", "self", ".", "optimizer_kwargs", "=", "optimizer_kwargs", "\n", "self", ".", "optimizer", "=", "None", "# type: Optional[th.optim.Optimizer]", "\n", "\n", "self", ".", "features_extractor_class", "=", "features_extractor_class", "\n", "self", ".", "features_extractor_kwargs", "=", "features_extractor_kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.extract_features": [[216, 227], ["stable_baselines3.common.preprocessing.preprocess_obs", "common_policies.BasePolicy.features_extractor"], "methods", ["None"], ["", "def", "extract_features", "(", "self", ",", "obs", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Preprocess the observation if needed and extract features.\n\n        :param obs: (th.Tensor)\n        :return: (th.Tensor)\n        \"\"\"", "\n", "assert", "self", ".", "features_extractor", "is", "not", "None", ",", "'No feature extractor was set'", "\n", "preprocessed_obs", "=", "preprocess_obs", "(", "obs", ",", "self", ".", "observation_space", ",", "normalize_images", "=", "self", ".", "normalize_images", ")", "\n", "\n", "return", "self", ".", "features_extractor", "(", "preprocessed_obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.squash_output": [[228, 232], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "squash_output", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\" (bool) Getter for squash_output.\"\"\"", "\n", "return", "self", ".", "_squash_output", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.init_weights": [[233, 241], ["isinstance", "torch.init.orthogonal_", "torch.init.orthogonal_", "module.bias.data.fill_"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "init_weights", "(", "module", ":", "nn", ".", "Module", ",", "gain", ":", "float", "=", "1", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Orthogonal initialization (used in PPO and A2C)\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Conv2d", ")", ")", ":", "\n", "            ", "nn", ".", "init", ".", "orthogonal_", "(", "module", ".", "weight", ",", "gain", "=", "gain", ")", "\n", "module", ".", "bias", ".", "data", ".", "fill_", "(", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy._dummy_schedule": [[242, 246], ["None"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_dummy_schedule", "(", "_progress", ":", "float", ")", "->", "float", ":", "\n", "        ", "\"\"\" (float) Useful for pickling policy.\"\"\"", "\n", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.forward": [[247, 249], ["NotImplementedError"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "*", "_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy._predict": [[250, 259], ["NotImplementedError"], "methods", ["None"], ["", "def", "_predict", "(", "self", ",", "observation", ":", "th", ".", "Tensor", ",", "deterministic", ":", "bool", "=", "False", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Get the action according to the policy for a given observation.\n\n        :param observation: (th.Tensor)\n        :param deterministic: (bool) Whether to use stochastic or deterministic actions\n        :return: (th.Tensor) Taken action according to the policy\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.predict": [[260, 318], ["numpy.array", "stable_baselines3.common.preprocessing.is_image_space", "common_policies.BasePolicy._is_vectorized_observation", "torch.as_tensor().to.reshape", "torch.as_tensor().to", "torch.as_tensor().to", "common_policies.BasePolicy.cpu().numpy", "torch.no_grad", "torch.no_grad", "common_policies.BasePolicy._predict", "isinstance", "common_policies.BasePolicy.unscale_action", "isinstance", "numpy.clip", "gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.vec_transpose.VecTransposeImage.transpose_image", "torch.as_tensor", "torch.as_tensor", "common_policies.BasePolicy.cpu", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy._is_vectorized_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy._predict", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.unscale_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_transpose.VecTransposeImage.transpose_image"], ["", "def", "predict", "(", "self", ",", "observation", ":", "np", ".", "ndarray", ",", "\n", "state", ":", "Optional", "[", "np", ".", "ndarray", "]", "=", "None", ",", "\n", "mask", ":", "Optional", "[", "np", ".", "ndarray", "]", "=", "None", ",", "\n", "deterministic", ":", "bool", "=", "False", ")", "->", "Tuple", "[", "np", ".", "ndarray", ",", "Optional", "[", "np", ".", "ndarray", "]", "]", ":", "\n", "        ", "\"\"\"\n        Get the policy action and state from an observation (and optional state).\n\n        :param observation: (np.ndarray) the input observation\n        :param state: (Optional[np.ndarray]) The last states (can be None, used in recurrent policies)\n        :param mask: (Optional[np.ndarray]) The last masks (can be None, used in recurrent policies)\n        :param deterministic: (bool) Whether or not to return deterministic actions.\n        :return: (Tuple[np.ndarray, Optional[np.ndarray]]) the model's action and the next state\n            (used in recurrent policies)\n        \"\"\"", "\n", "# if state is None:", "\n", "#     state = self.initial_state", "\n", "# if mask is None:", "\n", "#     mask = [False for _ in range(self.n_envs)]", "\n", "observation", "=", "np", ".", "array", "(", "observation", ")", "\n", "\n", "# Handle the different cases for images", "\n", "# as PyTorch use channel first format", "\n", "if", "is_image_space", "(", "self", ".", "observation_space", ")", ":", "\n", "            ", "if", "(", "observation", ".", "shape", "==", "self", ".", "observation_space", ".", "shape", "\n", "or", "observation", ".", "shape", "[", "1", ":", "]", "==", "self", ".", "observation_space", ".", "shape", ")", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "# Try to re-order the channels", "\n", "                ", "transpose_obs", "=", "VecTransposeImage", ".", "transpose_image", "(", "observation", ")", "\n", "if", "(", "transpose_obs", ".", "shape", "==", "self", ".", "observation_space", ".", "shape", "\n", "or", "transpose_obs", ".", "shape", "[", "1", ":", "]", "==", "self", ".", "observation_space", ".", "shape", ")", ":", "\n", "                    ", "observation", "=", "transpose_obs", "\n", "\n", "", "", "", "vectorized_env", "=", "self", ".", "_is_vectorized_observation", "(", "observation", ",", "self", ".", "observation_space", ")", "\n", "\n", "observation", "=", "observation", ".", "reshape", "(", "(", "-", "1", ",", ")", "+", "self", ".", "observation_space", ".", "shape", ")", "\n", "\n", "observation", "=", "th", ".", "as_tensor", "(", "observation", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "with", "th", ".", "no_grad", "(", ")", ":", "\n", "            ", "actions", "=", "self", ".", "_predict", "(", "observation", ",", "deterministic", "=", "deterministic", ")", "\n", "# Convert to numpy", "\n", "", "actions", "=", "actions", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Rescale to proper domain when using squashing", "\n", "if", "isinstance", "(", "self", ".", "action_space", ",", "gym", ".", "spaces", ".", "Box", ")", "and", "self", ".", "squash_output", ":", "\n", "            ", "actions", "=", "self", ".", "unscale_action", "(", "actions", ")", "\n", "\n", "", "clipped_actions", "=", "actions", "\n", "# Clip the actions to avoid out of bound error when using gaussian distribution", "\n", "if", "isinstance", "(", "self", ".", "action_space", ",", "gym", ".", "spaces", ".", "Box", ")", "and", "not", "self", ".", "squash_output", ":", "\n", "            ", "clipped_actions", "=", "np", ".", "clip", "(", "actions", ",", "self", ".", "action_space", ".", "low", ",", "self", ".", "action_space", ".", "high", ")", "\n", "\n", "", "if", "not", "vectorized_env", ":", "\n", "            ", "if", "state", "is", "not", "None", ":", "\n", "                ", "raise", "ValueError", "(", "\"Error: The environment must be vectorized when using recurrent policies.\"", ")", "\n", "", "clipped_actions", "=", "clipped_actions", "[", "0", "]", "\n", "\n", "", "return", "clipped_actions", ",", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.scale_action": [[319, 329], ["None"], "methods", ["None"], ["", "def", "scale_action", "(", "self", ",", "action", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Rescale the action from [low, high] to [-1, 1]\n        (no need for symmetric action space)\n\n        :param action: (np.ndarray) Action to scale\n        :return: (np.ndarray) Scaled action\n        \"\"\"", "\n", "low", ",", "high", "=", "self", ".", "action_space", ".", "low", ",", "self", ".", "action_space", ".", "high", "\n", "return", "2.0", "*", "(", "(", "action", "-", "low", ")", "/", "(", "high", "-", "low", ")", ")", "-", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.unscale_action": [[330, 339], ["None"], "methods", ["None"], ["", "def", "unscale_action", "(", "self", ",", "scaled_action", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Rescale the action from [-1, 1] to [low, high]\n        (no need for symmetric action space)\n\n        :param scaled_action: Action to un-scale\n        \"\"\"", "\n", "low", ",", "high", "=", "self", ".", "action_space", ".", "low", ",", "self", ".", "action_space", ".", "high", "\n", "return", "low", "+", "(", "0.5", "*", "(", "scaled_action", "+", "1.0", ")", "*", "(", "high", "-", "low", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy._is_vectorized_observation": [[340, 390], ["isinstance", "isinstance", "isinstance", "ValueError", "isinstance", "len", "ValueError", "ValueError", "len", "ValueError", "len", "len", "ValueError", "map", "len", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_is_vectorized_observation", "(", "observation", ":", "np", ".", "ndarray", ",", "observation_space", ":", "gym", ".", "spaces", ".", "Space", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        For every observation type, detects and validates the shape,\n        then returns whether or not the observation is vectorized.\n\n        :param observation: (np.ndarray) the input observation to validate\n        :param observation_space: (gym.spaces) the observation space\n        :return: (bool) whether the given observation is vectorized or not\n        \"\"\"", "\n", "if", "isinstance", "(", "observation_space", ",", "gym", ".", "spaces", ".", "Box", ")", ":", "\n", "            ", "if", "observation", ".", "shape", "==", "observation_space", ".", "shape", ":", "\n", "                ", "return", "False", "\n", "", "elif", "observation", ".", "shape", "[", "1", ":", "]", "==", "observation_space", ".", "shape", ":", "\n", "                ", "return", "True", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Error: Unexpected observation shape {observation.shape} for \"", "\n", "+", "f\"Box environment, please use {observation_space.shape} \"", "\n", "+", "\"or (n_env, {}) for the observation shape.\"", "\n", ".", "format", "(", "\", \"", ".", "join", "(", "map", "(", "str", ",", "observation_space", ".", "shape", ")", ")", ")", ")", "\n", "", "", "elif", "isinstance", "(", "observation_space", ",", "gym", ".", "spaces", ".", "Discrete", ")", ":", "\n", "            ", "if", "observation", ".", "shape", "==", "(", ")", ":", "# A numpy array of a number, has shape empty tuple '()'", "\n", "                ", "return", "False", "\n", "", "elif", "len", "(", "observation", ".", "shape", ")", "==", "1", ":", "\n", "                ", "return", "True", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Error: Unexpected observation shape {observation.shape} for \"", "\n", "+", "\"Discrete environment, please use (1,) or (n_env, 1) for the observation shape.\"", ")", "\n", "\n", "", "", "elif", "isinstance", "(", "observation_space", ",", "gym", ".", "spaces", ".", "MultiDiscrete", ")", ":", "\n", "            ", "if", "observation", ".", "shape", "==", "(", "len", "(", "observation_space", ".", "nvec", ")", ",", ")", ":", "\n", "                ", "return", "False", "\n", "", "elif", "len", "(", "observation", ".", "shape", ")", "==", "2", "and", "observation", ".", "shape", "[", "1", "]", "==", "len", "(", "observation_space", ".", "nvec", ")", ":", "\n", "                ", "return", "True", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Error: Unexpected observation shape {observation.shape} for MultiDiscrete \"", "\n", "+", "f\"environment, please use ({len(observation_space.nvec)},) or \"", "\n", "+", "f\"(n_env, {len(observation_space.nvec)}) for the observation shape.\"", ")", "\n", "", "", "elif", "isinstance", "(", "observation_space", ",", "gym", ".", "spaces", ".", "MultiBinary", ")", ":", "\n", "            ", "if", "observation", ".", "shape", "==", "(", "observation_space", ".", "n", ",", ")", ":", "\n", "                ", "return", "False", "\n", "", "elif", "len", "(", "observation", ".", "shape", ")", "==", "2", "and", "observation", ".", "shape", "[", "1", "]", "==", "observation_space", ".", "n", ":", "\n", "                ", "return", "True", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "f\"Error: Unexpected observation shape {observation.shape} for MultiBinary \"", "\n", "+", "f\"environment, please use ({observation_space.n},) or \"", "\n", "+", "f\"(n_env, {observation_space.n}) for the observation shape.\"", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Error: Cannot determine if the observation is vectorized \"", "\n", "+", "f\" with the space type {observation_space}.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy._get_data": [[391, 405], ["dict"], "methods", ["None"], ["", "", "def", "_get_data", "(", "self", ")", "->", "Dict", "[", "str", ",", "Any", "]", ":", "\n", "        ", "\"\"\"\n        Get data that need to be saved in order to re-create the policy.\n        This corresponds to the arguments of the constructor.\n\n        :return: (Dict[str, Any])\n        \"\"\"", "\n", "return", "dict", "(", "\n", "observation_space", "=", "self", ".", "observation_space", ",", "\n", "action_space", "=", "self", ".", "action_space", ",", "\n", "# Passed to the constructor by child class", "\n", "# squash_output=self.squash_output,", "\n", "# features_extractor=self.features_extractor", "\n", "normalize_images", "=", "self", ".", "normalize_images", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.save": [[407, 414], ["torch.save", "torch.save", "common_policies.BasePolicy.state_dict", "common_policies.BasePolicy._get_data"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy._get_data"], ["", "def", "save", "(", "self", ",", "path", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Save policy to a given location.\n\n        :param path: (str)\n        \"\"\"", "\n", "th", ".", "save", "(", "{", "'state_dict'", ":", "self", ".", "state_dict", "(", ")", ",", "'data'", ":", "self", ".", "_get_data", "(", ")", "}", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.load": [[415, 432], ["gym_idsgame.agents.training_agents.openai_baselines.common.utils.get_device", "torch.load", "torch.load", "cls", "cls.load_state_dict", "cls.to"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.get_device", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load"], ["", "@", "classmethod", "\n", "def", "load", "(", "cls", ",", "path", ":", "str", ",", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "'auto'", ",", "pg_agent_config", ":", "PolicyGradientAgentConfig", "=", "None", ")", "->", "'BasePolicy'", ":", "\n", "        ", "\"\"\"\n        Load policy from path.\n\n        :param path: (str)\n        :param device: ( Union[th.device, str]) Device on which the policy should be loaded.\n        :return: (BasePolicy)\n        \"\"\"", "\n", "device", "=", "get_device", "(", "device", ",", "pg_agent_config", ")", "\n", "saved_variables", "=", "th", ".", "load", "(", "path", ",", "map_location", "=", "device", ")", "\n", "# Create policy object", "\n", "model", "=", "cls", "(", "**", "saved_variables", "[", "'data'", "]", ")", "\n", "# Load weights", "\n", "model", ".", "load_state_dict", "(", "saved_variables", "[", "'state_dict'", "]", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.load_from_vector": [[433, 440], ["torch.nn.utils.vector_to_parameters", "torch.nn.utils.vector_to_parameters", "torch.FloatTensor().to", "torch.FloatTensor().to", "common_policies.BasePolicy.parameters", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["None"], ["", "def", "load_from_vector", "(", "self", ",", "vector", ":", "np", ".", "ndarray", ")", ":", "\n", "        ", "\"\"\"\n        Load parameters from a 1D vector.\n\n        :param vector: (np.ndarray)\n        \"\"\"", "\n", "th", ".", "nn", ".", "utils", ".", "vector_to_parameters", "(", "th", ".", "FloatTensor", "(", "vector", ")", ".", "to", "(", "self", ".", "device", ")", ",", "self", ".", "parameters", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.parameters_to_vector": [[441, 448], ["torch.nn.utils.parameters_to_vector().detach().cpu().numpy", "torch.nn.utils.parameters_to_vector().detach().cpu().numpy", "torch.nn.utils.parameters_to_vector().detach().cpu", "torch.nn.utils.parameters_to_vector().detach().cpu", "torch.nn.utils.parameters_to_vector().detach", "torch.nn.utils.parameters_to_vector().detach", "torch.nn.utils.parameters_to_vector", "torch.nn.utils.parameters_to_vector", "common_policies.BasePolicy.parameters"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.parameters_to_vector", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.parameters_to_vector"], ["", "def", "parameters_to_vector", "(", "self", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Convert the parameters to a 1D vector.\n\n        :return: (np.ndarray)\n        \"\"\"", "\n", "return", "th", ".", "nn", ".", "utils", ".", "parameters_to_vector", "(", "self", ".", "parameters", "(", ")", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.MlpExtractor.__init__": [[577, 720], ["torch.Module.__init__", "gym_idsgame.agents.training_agents.openai_baselines.common.utils.get_device", "enumerate", "enumerate", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "torch.Sequential().to", "range", "attack_encoder_net.append", "torch.Sequential().to", "torch.Sequential().to", "range", "defense_encoder_net.append", "torch.Sequential().to", "torch.Sequential().to", "range", "position_encoder_net.append", "torch.Sequential().to", "torch.Sequential().to", "range", "rec_encoder_net.append", "torch.Sequential().to", "torch.Sequential().to", "isinstance", "itertools.zip_longest", "torch.Sequential().to", "torch.Sequential().to", "attack_encoder_net.append", "attack_encoder_net.append", "torch.Linear", "torch.Linear", "defense_encoder_net.append", "defense_encoder_net.append", "torch.Linear", "torch.Linear", "position_encoder_net.append", "position_encoder_net.append", "torch.Linear", "torch.Linear", "rec_encoder_net.append", "rec_encoder_net.append", "torch.Linear", "torch.Linear", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "isinstance", "isinstance", "policy_net.append", "policy_net.append", "isinstance", "value_net.append", "value_net.append", "common_policies.MlpExtractor.core_lstm.to", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "activation_fn", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "activation_fn", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "activation_fn", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "activation_fn", "torch.Sequential", "torch.Sequential", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "shared_net.append", "shared_net.append", "isinstance", "isinstance", "torch.Linear", "torch.Linear", "activation_fn", "torch.Linear", "torch.Linear", "activation_fn", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "activation_fn"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.get_device"], ["def", "__init__", "(", "self", ",", "feature_dim", ":", "int", ",", "\n", "net_arch", ":", "List", "[", "Union", "[", "int", ",", "Dict", "[", "str", ",", "List", "[", "int", "]", "]", "]", "]", ",", "\n", "activation_fn", ":", "Type", "[", "nn", ".", "Module", "]", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "'auto'", ",", "\n", "pg_agent_config", ":", "PolicyGradientAgentConfig", "=", "None", ",", "\n", "at_net", ":", "bool", "=", "False", ",", "\n", "node_net", ":", "bool", "=", "False", "\n", ")", ":", "\n", "        ", "super", "(", "MlpExtractor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "pg_agent_config", "=", "pg_agent_config", "\n", "self", ".", "at_net", "=", "at_net", "\n", "self", ".", "node_net", "=", "node_net", "\n", "device", "=", "get_device", "(", "device", ",", "pg_agent_config", ")", "\n", "shared_net", ",", "policy_net", ",", "value_net", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "policy_only_layers", "=", "[", "]", "# Layer sizes of the network that only belongs to the policy network", "\n", "value_only_layers", "=", "[", "]", "# Layer sizes of the network that only belongs to the value network", "\n", "last_layer_dim_shared", "=", "feature_dim", "\n", "\n", "if", "(", "not", "self", ".", "pg_agent_config", ".", "ar_policy", "and", "self", ".", "pg_agent_config", ".", "multi_channel_obs", ")", "or", "(", "self", ".", "pg_agent_config", ".", "ar_policy", "and", "self", ".", "node_net", "and", "self", ".", "pg_agent_config", ".", "attacker_node_net_multi_channel", ")", "or", "(", "self", ".", "pg_agent_config", ".", "ar_policy", "and", "self", ".", "at_net", "and", "self", ".", "pg_agent_config", ".", "attacker_at_net_multi_channel", ")", ":", "\n", "            ", "attack_encoder_net", "=", "[", "]", "\n", "last_layer_dim_attack_encoder", "=", "self", ".", "pg_agent_config", ".", "channel_1_input_dim", "\n", "for", "i", "in", "range", "(", "self", ".", "pg_agent_config", ".", "channel_1_layers", ")", ":", "\n", "                ", "attack_encoder_net", ".", "append", "(", "nn", ".", "Linear", "(", "last_layer_dim_attack_encoder", ",", "self", ".", "pg_agent_config", ".", "channel_1_dim", ")", ")", "\n", "attack_encoder_net", ".", "append", "(", "activation_fn", "(", ")", ")", "\n", "last_layer_dim_attack_encoder", "=", "self", ".", "pg_agent_config", ".", "channel_1_dim", "\n", "", "attack_encoder_net", ".", "append", "(", "nn", ".", "Linear", "(", "last_layer_dim_attack_encoder", ",", "self", ".", "pg_agent_config", ".", "channel_1_dim", ")", ")", "\n", "self", ".", "attack_encoder", "=", "nn", ".", "Sequential", "(", "*", "attack_encoder_net", ")", ".", "to", "(", "device", ")", "\n", "\n", "defense_encoder_net", "=", "[", "]", "\n", "last_layer_dim_defense_encoder", "=", "self", ".", "pg_agent_config", ".", "channel_2_input_dim", "\n", "for", "i", "in", "range", "(", "self", ".", "pg_agent_config", ".", "channel_2_layers", ")", ":", "\n", "                ", "defense_encoder_net", ".", "append", "(", "nn", ".", "Linear", "(", "last_layer_dim_defense_encoder", ",", "self", ".", "pg_agent_config", ".", "channel_2_dim", ")", ")", "\n", "defense_encoder_net", ".", "append", "(", "activation_fn", "(", ")", ")", "\n", "last_layer_dim_defense_encoder", "=", "self", ".", "pg_agent_config", ".", "channel_2_dim", "\n", "", "defense_encoder_net", ".", "append", "(", "nn", ".", "Linear", "(", "last_layer_dim_defense_encoder", ",", "self", ".", "pg_agent_config", ".", "channel_2_dim", ")", ")", "\n", "self", ".", "defense_encoder", "=", "nn", ".", "Sequential", "(", "*", "defense_encoder_net", ")", ".", "to", "(", "device", ")", "\n", "\n", "position_encoder_net", "=", "[", "]", "\n", "last_layer_dim_position_encoder", "=", "self", ".", "pg_agent_config", ".", "channel_3_input_dim", "\n", "for", "i", "in", "range", "(", "self", ".", "pg_agent_config", ".", "channel_3_layers", ")", ":", "\n", "                ", "position_encoder_net", ".", "append", "(", "nn", ".", "Linear", "(", "last_layer_dim_position_encoder", ",", "self", ".", "pg_agent_config", ".", "channel_3_dim", ")", ")", "\n", "position_encoder_net", ".", "append", "(", "activation_fn", "(", ")", ")", "\n", "last_layer_dim_position_encoder", "=", "self", ".", "pg_agent_config", ".", "channel_3_dim", "\n", "", "position_encoder_net", ".", "append", "(", "nn", ".", "Linear", "(", "last_layer_dim_position_encoder", ",", "self", ".", "pg_agent_config", ".", "channel_3_dim", ")", ")", "\n", "self", ".", "position_encoder", "=", "nn", ".", "Sequential", "(", "*", "position_encoder_net", ")", ".", "to", "(", "device", ")", "\n", "\n", "rec_encoder_net", "=", "[", "]", "\n", "last_layer_dim_rec_encoder", "=", "self", ".", "pg_agent_config", ".", "channel_4_input_dim", "\n", "for", "i", "in", "range", "(", "self", ".", "pg_agent_config", ".", "channel_4_layers", ")", ":", "\n", "                ", "rec_encoder_net", ".", "append", "(", "\n", "nn", ".", "Linear", "(", "last_layer_dim_rec_encoder", ",", "self", ".", "pg_agent_config", ".", "channel_4_dim", ")", ")", "\n", "rec_encoder_net", ".", "append", "(", "activation_fn", "(", ")", ")", "\n", "last_layer_dim_rec_encoder", "=", "self", ".", "pg_agent_config", ".", "channel_4_dim", "\n", "", "rec_encoder_net", ".", "append", "(", "nn", ".", "Linear", "(", "last_layer_dim_rec_encoder", ",", "self", ".", "pg_agent_config", ".", "channel_4_dim", ")", ")", "\n", "self", ".", "rec_encoder", "=", "nn", ".", "Sequential", "(", "*", "rec_encoder_net", ")", ".", "to", "(", "device", ")", "\n", "\n", "if", "(", "not", "self", ".", "pg_agent_config", ".", "ar_policy", "and", "self", ".", "pg_agent_config", ".", "lstm_core", ")", "or", "(", "self", ".", "pg_agent_config", ".", "ar_policy", "and", "self", ".", "node_net", "and", "self", ".", "pg_agent_config", ".", "attacker_node_net_lstm_core", ")", "or", "(", "self", ".", "pg_agent_config", ".", "ar_policy", "and", "self", ".", "at_net", "and", "self", ".", "pg_agent_config", ".", "attacker_at_net_lstm_core", ")", ":", "\n", "                ", "self", ".", "core_lstm", "=", "th", ".", "nn", ".", "LSTM", "(", "input_size", "=", "(", "self", ".", "pg_agent_config", ".", "channel_1_dim", "+", "\n", "self", ".", "pg_agent_config", ".", "channel_2_dim", "+", "\n", "self", ".", "pg_agent_config", ".", "channel_3_dim", "+", "\n", "self", ".", "pg_agent_config", ".", "channel_4_dim", ")", ",", "\n", "hidden_size", "=", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", ",", "\n", "num_layers", "=", "self", ".", "pg_agent_config", ".", "num_lstm_layers", ")", "\n", "# initialize the hidden state.", "\n", "self", ".", "lstm_hidden", "=", "(", "th", ".", "zeros", "(", "self", ".", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "\n", "th", ".", "zeros", "(", "self", ".", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", ")", ")", "\n", "last_layer_dim_shared", "=", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", "\n", "", "else", ":", "\n", "                ", "last_layer_dim_shared", "=", "self", ".", "pg_agent_config", ".", "channel_1_dim", "+", "self", ".", "pg_agent_config", ".", "channel_2_dim", "+", "self", ".", "pg_agent_config", ".", "channel_3_dim", "+", "self", ".", "pg_agent_config", ".", "channel_4_dim", "\n", "", "", "else", ":", "\n", "            ", "if", "(", "not", "self", ".", "pg_agent_config", ".", "ar_policy", "and", "self", ".", "pg_agent_config", ".", "lstm_core", ")", "or", "(", "self", ".", "pg_agent_config", ".", "ar_policy", "and", "self", ".", "node_net", "and", "self", ".", "pg_agent_config", ".", "attacker_node_net_lstm_core", ")", "or", "(", "self", ".", "pg_agent_config", ".", "ar_policy", "and", "self", ".", "at_net", "and", "self", ".", "pg_agent_config", ".", "attacker_at_net_lstm_core", ")", ":", "\n", "                ", "self", ".", "core_lstm", "=", "th", ".", "nn", ".", "LSTM", "(", "input_size", "=", "last_layer_dim_shared", ",", "\n", "hidden_size", "=", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", ",", "\n", "num_layers", "=", "self", ".", "pg_agent_config", ".", "num_lstm_layers", ")", "\n", "# initialize the hidden state.", "\n", "self", ".", "lstm_hidden", "=", "(", "th", ".", "zeros", "(", "self", ".", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "\n", "th", ".", "zeros", "(", "self", ".", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", ")", ")", "\n", "last_layer_dim_shared", "=", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", "\n", "\n", "# Iterate through the shared layers and build the shared parts of the network", "\n", "", "", "for", "idx", ",", "layer", "in", "enumerate", "(", "net_arch", ")", ":", "\n", "            ", "if", "isinstance", "(", "layer", ",", "int", ")", ":", "# Check that this is a shared layer", "\n", "                ", "if", "not", "self", ".", "pg_agent_config", ".", "lstm_core", ":", "\n", "                    ", "layer_size", "=", "layer", "\n", "shared_net", ".", "append", "(", "nn", ".", "Linear", "(", "last_layer_dim_shared", ",", "layer_size", ")", ")", "\n", "shared_net", ".", "append", "(", "activation_fn", "(", ")", ")", "\n", "last_layer_dim_shared", "=", "layer_size", "\n", "", "", "else", ":", "\n", "                ", "assert", "isinstance", "(", "layer", ",", "dict", ")", ",", "\"Error: the net_arch list can only contain ints and dicts\"", "\n", "if", "'pi'", "in", "layer", ":", "\n", "                    ", "assert", "isinstance", "(", "layer", "[", "'pi'", "]", ",", "list", ")", ",", "\"Error: net_arch[-1]['pi'] must contain a list of integers.\"", "\n", "policy_only_layers", "=", "layer", "[", "'pi'", "]", "\n", "\n", "", "if", "'vf'", "in", "layer", ":", "\n", "                    ", "assert", "isinstance", "(", "layer", "[", "'vf'", "]", ",", "list", ")", ",", "\"Error: net_arch[-1]['vf'] must contain a list of integers.\"", "\n", "value_only_layers", "=", "layer", "[", "'vf'", "]", "\n", "", "break", "# From here on the network splits up in policy and value network", "\n", "\n", "", "", "last_layer_dim_pi", "=", "last_layer_dim_shared", "\n", "last_layer_dim_vf", "=", "last_layer_dim_shared", "\n", "\n", "# Build the non-shared part of the network", "\n", "for", "idx", ",", "(", "pi_layer_size", ",", "vf_layer_size", ")", "in", "enumerate", "(", "zip_longest", "(", "policy_only_layers", ",", "value_only_layers", ")", ")", ":", "\n", "            ", "if", "pi_layer_size", "is", "not", "None", ":", "\n", "                ", "assert", "isinstance", "(", "pi_layer_size", ",", "int", ")", ",", "\"Error: net_arch[-1]['pi'] must only contain integers.\"", "\n", "policy_net", ".", "append", "(", "nn", ".", "Linear", "(", "last_layer_dim_pi", ",", "pi_layer_size", ")", ")", "\n", "policy_net", ".", "append", "(", "activation_fn", "(", ")", ")", "\n", "last_layer_dim_pi", "=", "pi_layer_size", "\n", "\n", "", "if", "vf_layer_size", "is", "not", "None", ":", "\n", "                ", "assert", "isinstance", "(", "vf_layer_size", ",", "int", ")", ",", "\"Error: net_arch[-1]['vf'] must only contain integers.\"", "\n", "value_net", ".", "append", "(", "nn", ".", "Linear", "(", "last_layer_dim_vf", ",", "vf_layer_size", ")", ")", "\n", "value_net", ".", "append", "(", "activation_fn", "(", ")", ")", "\n", "last_layer_dim_vf", "=", "vf_layer_size", "\n", "\n", "# Save dim, used to create the distributions", "\n", "", "", "self", ".", "latent_dim_pi", "=", "last_layer_dim_pi", "\n", "self", ".", "latent_dim_vf", "=", "last_layer_dim_vf", "\n", "\n", "# Create networks", "\n", "# If the list of layers is empty, the network will just act as an Identity module", "\n", "if", "not", "self", ".", "pg_agent_config", ".", "lstm_core", "or", "(", "self", ".", "pg_agent_config", ".", "ar_policy", "and", "self", ".", "node_net", "and", "not", "self", ".", "pg_agent_config", ".", "attacker_node_net_lstm_core", ")", "or", "(", "self", ".", "pg_agent_config", ".", "ar_policy", "and", "self", ".", "at_net", "and", "not", "self", ".", "pg_agent_config", ".", "attacker_at_net_lstm_core", ")", ":", "\n", "            ", "self", ".", "shared_net", "=", "nn", ".", "Sequential", "(", "*", "shared_net", ")", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "            ", "if", "not", "self", ".", "pg_agent_config", ".", "ar_policy", "or", "(", "self", ".", "pg_agent_config", ".", "ar_policy", "and", "self", ".", "node_net", "and", "self", ".", "pg_agent_config", ".", "attacker_node_net_lstm_core", ")", "or", "(", "self", ".", "pg_agent_config", ".", "ar_policy", "and", "self", ".", "at_net", "and", "self", ".", "pg_agent_config", ".", "attacker_at_net_lstm_core", ")", ":", "\n", "                ", "self", ".", "core_lstm", "=", "self", ".", "core_lstm", ".", "to", "(", "device", ")", "\n", "", "", "self", ".", "policy_net", "=", "nn", ".", "Sequential", "(", "*", "policy_net", ")", ".", "to", "(", "device", ")", "\n", "self", ".", "value_net", "=", "nn", ".", "Sequential", "(", "*", "value_net", ")", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.MlpExtractor.forward": [[721, 776], ["common_policies.MlpExtractor.attack_encoder", "common_policies.MlpExtractor.defense_encoder", "common_policies.MlpExtractor.position_encoder", "common_policies.MlpExtractor.rec_encoder", "common_policies.MlpExtractor.shared_net", "channel_1_features.float", "channel_2_features.float", "channel_3_features.float", "channel_4_features.float", "len", "torch.cat", "torch.cat", "common_policies.MlpExtractor.policy_net", "common_policies.MlpExtractor.value_net", "common_policies.MlpExtractor.core_lstm", "range", "torch.cat", "torch.cat", "x.reshape.reshape.reshape", "common_policies.MlpExtractor.policy_net", "common_policies.MlpExtractor.value_net", "len", "torch.cat", "torch.cat", "AssertionError", "len", "torch.cat.reshape", "len", "latent_input.reshape.reshape.reshape", "common_policies.MlpExtractor.core_lstm", "outputs.append", "len", "torch.cat.reshape", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ":", "th", ".", "Tensor", ",", "lstm_state", "=", "None", ",", "masks", "=", "None", ",", "channel_1_features", "=", "None", ",", "\n", "channel_2_features", "=", "None", ",", "channel_3_features", "=", "None", ",", "channel_4_features", "=", "None", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        :return: (th.Tensor, th.Tensor) latent_policy, latent_value of the specified network.\n            If all layers are shared, then ``latent_policy == latent_value``\n        \"\"\"", "\n", "if", "(", "self", ".", "pg_agent_config", ".", "multi_channel_obs", "and", "not", "self", ".", "pg_agent_config", ".", "ar_policy", ")", "or", "(", "self", ".", "pg_agent_config", ".", "ar_policy", "and", "self", ".", "node_net", "and", "self", ".", "pg_agent_config", ".", "attacker_node_net_multi_channel", ")", ":", "\n", "            ", "channel_1_latent", "=", "self", ".", "attack_encoder", "(", "channel_1_features", ".", "float", "(", ")", ")", "\n", "channel_2_latent", "=", "self", ".", "defense_encoder", "(", "channel_2_features", ".", "float", "(", ")", ")", "\n", "channel_3_latent", "=", "self", ".", "position_encoder", "(", "channel_3_features", ".", "float", "(", ")", ")", "\n", "channel_4_latent", "=", "self", ".", "rec_encoder", "(", "channel_4_features", ".", "float", "(", ")", ")", "\n", "if", "len", "(", "channel_1_latent", ".", "shape", ")", "==", "1", ":", "\n", "                ", "features", "=", "th", ".", "cat", "(", "[", "channel_1_latent", ",", "channel_2_latent", ",", "channel_3_latent", ",", "channel_4_latent", "]", ",", "dim", "=", "0", ")", "\n", "", "elif", "len", "(", "channel_1_latent", ".", "shape", ")", "==", "2", ":", "\n", "                ", "features", "=", "th", ".", "cat", "(", "[", "channel_1_latent", ",", "channel_2_latent", ",", "channel_3_latent", ",", "channel_4_latent", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "raise", "AssertionError", "(", "\"Do not recognize the shape\"", ")", "\n", "", "", "if", "not", "self", ".", "pg_agent_config", ".", "lstm_core", "or", "(", "self", ".", "pg_agent_config", ".", "ar_policy", "and", "self", ".", "node_net", "and", "not", "self", ".", "pg_agent_config", ".", "attacker_node_net_lstm_core", ")", "or", "(", "self", ".", "pg_agent_config", ".", "ar_policy", "and", "self", ".", "at_net", "and", "not", "self", ".", "pg_agent_config", ".", "attacker_at_net_lstm_core", ")", ":", "\n", "            ", "shared_latent", "=", "self", ".", "shared_net", "(", "features", ")", "\n", "return", "self", ".", "policy_net", "(", "shared_latent", ")", ",", "self", ".", "value_net", "(", "shared_latent", ")", ",", "None", "\n", "", "else", ":", "\n", "            ", "if", "lstm_state", "is", "None", ":", "\n", "                ", "if", "len", "(", "features", ".", "shape", ")", "==", "1", ":", "\n", "                    ", "lstm_input_latent", "=", "features", ".", "reshape", "(", "1", ",", "1", ",", "features", ".", "shape", "[", "0", "]", ")", "\n", "", "elif", "len", "(", "features", ".", "shape", ")", "==", "2", ":", "\n", "                    ", "lstm_input_latent", "=", "features", ".", "reshape", "(", "1", ",", "features", ".", "shape", "[", "0", "]", ",", "features", ".", "shape", "[", "1", "]", ")", "\n", "", "lstm_latent", ",", "lstm_state", "=", "self", ".", "core_lstm", "(", "lstm_input_latent", ",", "self", ".", "lstm_hidden", ")", "\n", "self", ".", "lstm_hidden", "=", "lstm_state", "\n", "", "else", ":", "\n", "                ", "outputs", "=", "[", "]", "\n", "h_states", "=", "lstm_state", "[", "0", "]", "[", "0", "]", "\n", "c_states", "=", "lstm_state", "[", "1", "]", "[", "0", "]", "\n", "hiddden_state", "=", "(", "h_states", ",", "c_states", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "masks", ")", ")", ":", "\n", "                    ", "latent_input", "=", "features", "[", "i", "]", "\n", "# print(\"latent input shape:{}\".format(latent_input.shape))", "\n", "# print(\"features shape:{}\".format(features.shape))", "\n", "latent_input", "=", "latent_input", ".", "reshape", "(", "1", ",", "1", ",", "features", ".", "shape", "[", "1", "]", ")", "\n", "if", "masks", "[", "0", "]", "==", "1", ":", "\n", "                        ", "hiddden_state", "=", "(", "\n", "th", ".", "zeros", "(", "self", ".", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "\n", "th", ".", "zeros", "(", "self", ".", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", ")", ")", "\n", "", "lstm_latent", ",", "hidden_state", "=", "self", ".", "core_lstm", "(", "latent_input", ",", "hiddden_state", ")", "\n", "outputs", ".", "append", "(", "lstm_latent", ")", "\n", "\n", "", "x", "=", "th", ".", "cat", "(", "outputs", ",", "dim", "=", "0", ")", "\n", "x", "=", "x", ".", "reshape", "(", "(", "x", ".", "shape", "[", "0", "]", ",", "x", ".", "shape", "[", "2", "]", ")", ")", "\n", "lstm_latent", "=", "x", "\n", "\n", "", "return", "self", ".", "policy_net", "(", "lstm_latent", ")", ",", "self", ".", "value_net", "(", "lstm_latent", ")", ",", "lstm_state", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.create_mlp": [[450, 485], ["range", "len", "modules.append", "modules.append", "modules.append", "modules.append", "torch.Linear", "activation_fn", "len", "torch.Linear", "activation_fn", "torch.Linear", "torch.Tanh", "len"], "function", ["None"], ["", "", "def", "create_mlp", "(", "input_dim", ":", "int", ",", "\n", "output_dim", ":", "int", ",", "\n", "net_arch", ":", "List", "[", "int", "]", ",", "\n", "activation_fn", ":", "Type", "[", "nn", ".", "Module", "]", "=", "nn", ".", "ReLU", ",", "\n", "squash_output", ":", "bool", "=", "False", ")", "->", "List", "[", "nn", ".", "Module", "]", ":", "\n", "    ", "\"\"\"\n    Create a multi layer perceptron (MLP), which is\n    a collection of fully-connected layers each followed by an activation function.\n\n    :param input_dim: (int) Dimension of the input vector\n    :param output_dim: (int)\n    :param net_arch: (List[int]) Architecture of the neural net\n        It represents the number of units per layer.\n        The length of this list is the number of layers.\n    :param activation_fn: (Type[nn.Module]) The activation function\n        to use after each layer.\n    :param squash_output: (bool) Whether to squash the output using a Tanh\n        activation function\n    :return: (List[nn.Module])\n    \"\"\"", "\n", "if", "len", "(", "net_arch", ")", ">", "0", ":", "\n", "        ", "modules", "=", "[", "nn", ".", "Linear", "(", "input_dim", ",", "net_arch", "[", "0", "]", ")", ",", "activation_fn", "(", ")", "]", "\n", "", "else", ":", "\n", "        ", "modules", "=", "[", "]", "\n", "\n", "", "for", "idx", "in", "range", "(", "len", "(", "net_arch", ")", "-", "1", ")", ":", "\n", "        ", "modules", ".", "append", "(", "nn", ".", "Linear", "(", "net_arch", "[", "idx", "]", ",", "net_arch", "[", "idx", "+", "1", "]", ")", ")", "\n", "modules", ".", "append", "(", "activation_fn", "(", ")", ")", "\n", "\n", "", "if", "output_dim", ">", "0", ":", "\n", "        ", "last_layer_dim", "=", "net_arch", "[", "-", "1", "]", "if", "len", "(", "net_arch", ")", ">", "0", "else", "input_dim", "\n", "modules", ".", "append", "(", "nn", ".", "Linear", "(", "last_layer_dim", ",", "output_dim", ")", ")", "\n", "", "if", "squash_output", ":", "\n", "        ", "modules", ".", "append", "(", "nn", ".", "Tanh", "(", ")", ")", "\n", "", "return", "modules", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.create_sde_features_extractor": [[487, 506], ["common_policies.create_mlp", "torch.Sequential", "len", "len"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.create_mlp"], ["", "def", "create_sde_features_extractor", "(", "features_dim", ":", "int", ",", "\n", "sde_net_arch", ":", "List", "[", "int", "]", ",", "\n", "activation_fn", ":", "Type", "[", "nn", ".", "Module", "]", ")", "->", "Tuple", "[", "nn", ".", "Sequential", ",", "int", "]", ":", "\n", "    ", "\"\"\"\n    Create the neural network that will be used to extract features\n    for the gSDE exploration function.\n\n    :param features_dim: (int)\n    :param sde_net_arch: ([int])\n    :param activation_fn: (Type[nn.Module])\n    :return: (nn.Sequential, int)\n    \"\"\"", "\n", "# Special case: when using states as features (i.e. sde_net_arch is an empty list)", "\n", "# don't use any activation function", "\n", "sde_activation", "=", "activation_fn", "if", "len", "(", "sde_net_arch", ")", ">", "0", "else", "None", "\n", "latent_sde_net", "=", "create_mlp", "(", "features_dim", ",", "-", "1", ",", "sde_net_arch", ",", "activation_fn", "=", "sde_activation", ",", "squash_output", "=", "False", ")", "\n", "latent_sde_dim", "=", "sde_net_arch", "[", "-", "1", "]", "if", "len", "(", "sde_net_arch", ")", ">", "0", "else", "features_dim", "\n", "sde_features_extractor", "=", "nn", ".", "Sequential", "(", "*", "latent_sde_net", ")", "\n", "return", "sde_features_extractor", ",", "latent_sde_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.get_policy_from_name": [[511, 525], ["ValueError", "ValueError", "list", "_policy_registry[].keys"], "function", ["None"], ["def", "get_policy_from_name", "(", "base_policy_type", ":", "Type", "[", "BasePolicy", "]", ",", "name", ":", "str", ")", "->", "Type", "[", "BasePolicy", "]", ":", "\n", "    ", "\"\"\"\n    Returns the registered policy from the base type and name\n\n    :param base_policy_type: (Type[BasePolicy]) the base policy class\n    :param name: (str) the policy name\n    :return: (Type[BasePolicy]) the policy\n    \"\"\"", "\n", "if", "base_policy_type", "not", "in", "_policy_registry", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Error: the policy type {base_policy_type} is not registered!\"", ")", "\n", "", "if", "name", "not", "in", "_policy_registry", "[", "base_policy_type", "]", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Error: unknown policy type {name},\"", "\n", "f\"the only registed policy type are: {list(_policy_registry[base_policy_type].keys())}!\"", ")", "\n", "", "return", "_policy_registry", "[", "base_policy_type", "]", "[", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.register_policy": [[527, 548], ["BasePolicy.__subclasses__", "issubclass", "ValueError", "ValueError"], "function", ["None"], ["", "def", "register_policy", "(", "name", ":", "str", ",", "policy", ":", "Type", "[", "BasePolicy", "]", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Register a policy, so it can be called using its name.\n    e.g. SAC('MlpPolicy', ...) instead of SAC(MlpPolicy, ...)\n\n    :param name: (str) the policy name\n    :param policy: (Type[BasePolicy]) the policy class\n    \"\"\"", "\n", "sub_class", "=", "None", "\n", "for", "cls", "in", "BasePolicy", ".", "__subclasses__", "(", ")", ":", "\n", "        ", "if", "issubclass", "(", "policy", ",", "cls", ")", ":", "\n", "            ", "sub_class", "=", "cls", "\n", "break", "\n", "", "", "if", "sub_class", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Error: the policy {policy} is not of any known subclasses of BasePolicy!\"", ")", "\n", "\n", "", "if", "sub_class", "not", "in", "_policy_registry", ":", "\n", "        ", "_policy_registry", "[", "sub_class", "]", "=", "{", "}", "\n", "", "if", "name", "in", "_policy_registry", "[", "sub_class", "]", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Error: the name {name} is alreay registered for a different policy, will not override.\"", ")", "\n", "", "_policy_registry", "[", "sub_class", "]", "[", "name", "]", "=", "policy", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.Distribution.__init__": [[12, 14], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Distribution", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.Distribution.log_prob": [[15, 23], ["None"], "methods", ["None"], ["", "def", "log_prob", "(", "self", ",", "x", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        returns the log likelihood\n\n        :param x: (th.Tensor) the taken action\n        :return: (th.Tensor) The log likelihood of the distribution\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.Distribution.entropy": [[24, 32], ["None"], "methods", ["None"], ["", "def", "entropy", "(", "self", ")", "->", "Optional", "[", "th", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Returns Shannon's entropy of the probability\n\n        :return: (Optional[th.Tensor]) the entropy,\n            return None if no analytical form is known\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.Distribution.sample": [[33, 40], ["None"], "methods", ["None"], ["", "def", "sample", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Returns a sample from the probability distribution\n\n        :return: (th.Tensor) the stochastic action\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.Distribution.mode": [[41, 49], ["None"], "methods", ["None"], ["", "def", "mode", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Returns the most likely action (deterministic output)\n        from the probability distribution\n\n        :return: (th.Tensor) the stochastic action\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.Distribution.get_actions": [[50, 60], ["distributions.Distribution.sample", "distributions.Distribution.mode"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.mode"], ["", "def", "get_actions", "(", "self", ",", "deterministic", ":", "bool", "=", "False", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Return actions according to the probability distribution.\n\n        :param deterministic: (bool)\n        :return: (th.Tensor)\n        \"\"\"", "\n", "if", "deterministic", ":", "\n", "            ", "return", "self", ".", "mode", "(", ")", "\n", "", "return", "self", ".", "sample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.Distribution.actions_from_params": [[61, 69], ["None"], "methods", ["None"], ["", "def", "actions_from_params", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Returns samples from the probability distribution\n        given its parameters.\n\n        :return: (th.Tensor) actions\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.Distribution.log_prob_from_params": [[70, 78], ["None"], "methods", ["None"], ["", "def", "log_prob_from_params", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Returns samples and the associated log probabilities\n        from the probability distribution given its parameters.\n\n        :return: (th.Tuple[th.Tensor, th.Tensor]) actions and log prob\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.DiagGaussianDistribution.__init__": [[104, 110], ["distributions.Distribution.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "action_dim", ":", "int", ")", ":", "\n", "        ", "super", "(", "DiagGaussianDistribution", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "distribution", "=", "None", "\n", "self", ".", "action_dim", "=", "action_dim", "\n", "self", ".", "mean_actions", "=", "None", "\n", "self", ".", "log_std", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.DiagGaussianDistribution.proba_distribution_net": [[111, 126], ["torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.ones", "torch.ones"], "methods", ["None"], ["", "def", "proba_distribution_net", "(", "self", ",", "latent_dim", ":", "int", ",", "\n", "log_std_init", ":", "float", "=", "0.0", ")", "->", "Tuple", "[", "nn", ".", "Module", ",", "nn", ".", "Parameter", "]", ":", "\n", "        ", "\"\"\"\n        Create the layers and parameter that represent the distribution:\n        one output will be the mean of the Gaussian, the other parameter will be the\n        standard deviation (log std in fact to allow negative values)\n\n        :param latent_dim: (int) Dimension og the last layer of the policy (before the action layer)\n        :param log_std_init: (float) Initial value for the log standard deviation\n        :return: (nn.Linear, nn.Parameter)\n        \"\"\"", "\n", "mean_actions", "=", "nn", ".", "Linear", "(", "latent_dim", ",", "self", ".", "action_dim", ")", "\n", "# TODO: allow action dependent std", "\n", "log_std", "=", "nn", ".", "Parameter", "(", "th", ".", "ones", "(", "self", ".", "action_dim", ")", "*", "log_std_init", ",", "requires_grad", "=", "True", ")", "\n", "return", "mean_actions", ",", "log_std", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.DiagGaussianDistribution.proba_distribution": [[127, 139], ["torch.distributions.Normal", "torch.distributions.Normal", "torch.ones_like", "torch.ones_like", "log_std.exp"], "methods", ["None"], ["", "def", "proba_distribution", "(", "self", ",", "mean_actions", ":", "th", ".", "Tensor", ",", "\n", "log_std", ":", "th", ".", "Tensor", ")", "->", "'DiagGaussianDistribution'", ":", "\n", "        ", "\"\"\"\n        Create the distribution given its parameters (mean, std)\n\n        :param mean_actions: (th.Tensor)\n        :param log_std: (th.Tensor)\n        :return: (DiagGaussianDistribution)\n        \"\"\"", "\n", "action_std", "=", "th", ".", "ones_like", "(", "mean_actions", ")", "*", "log_std", ".", "exp", "(", ")", "\n", "self", ".", "distribution", "=", "Normal", "(", "mean_actions", ",", "action_std", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.DiagGaussianDistribution.mode": [[140, 142], ["None"], "methods", ["None"], ["", "def", "mode", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "distribution", ".", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.DiagGaussianDistribution.sample": [[143, 146], ["distributions.DiagGaussianDistribution.distribution.rsample"], "methods", ["None"], ["", "def", "sample", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "# Reparametrization trick to pass gradients", "\n", "        ", "return", "self", ".", "distribution", ".", "rsample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.DiagGaussianDistribution.entropy": [[147, 149], ["distributions.sum_independent_dims", "distributions.DiagGaussianDistribution.distribution.entropy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.sum_independent_dims", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.entropy"], ["", "def", "entropy", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "sum_independent_dims", "(", "self", ".", "distribution", ".", "entropy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.DiagGaussianDistribution.actions_from_params": [[150, 156], ["distributions.DiagGaussianDistribution.proba_distribution", "distributions.DiagGaussianDistribution.get_actions"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.proba_distribution", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.Distribution.get_actions"], ["", "def", "actions_from_params", "(", "self", ",", "mean_actions", ":", "th", ".", "Tensor", ",", "\n", "log_std", ":", "th", ".", "Tensor", ",", "\n", "deterministic", ":", "bool", "=", "False", ")", "->", "th", ".", "Tensor", ":", "\n", "# Update the proba distribution", "\n", "        ", "self", ".", "proba_distribution", "(", "mean_actions", ",", "log_std", ")", "\n", "return", "self", ".", "get_actions", "(", "deterministic", "=", "deterministic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.DiagGaussianDistribution.log_prob_from_params": [[157, 170], ["distributions.DiagGaussianDistribution.actions_from_params", "distributions.DiagGaussianDistribution.log_prob"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.actions_from_params", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.log_prob"], ["", "def", "log_prob_from_params", "(", "self", ",", "mean_actions", ":", "th", ".", "Tensor", ",", "\n", "log_std", ":", "th", ".", "Tensor", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Compute the log probability of taking an action\n        given the distribution parameters.\n\n        :param mean_actions: (th.Tensor)\n        :param log_std: (th.Tensor)\n        :return: (Tuple[th.Tensor, th.Tensor])\n        \"\"\"", "\n", "actions", "=", "self", ".", "actions_from_params", "(", "mean_actions", ",", "log_std", ")", "\n", "log_prob", "=", "self", ".", "log_prob", "(", "actions", ")", "\n", "return", "actions", ",", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.DiagGaussianDistribution.log_prob": [[171, 181], ["distributions.DiagGaussianDistribution.distribution.log_prob", "distributions.sum_independent_dims"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.log_prob", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.sum_independent_dims"], ["", "def", "log_prob", "(", "self", ",", "actions", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Get the log probabilities of actions according to the distribution.\n        Note that you must call ``proba_distribution()`` method before.\n\n        :param actions: (th.Tensor)\n        :return: (th.Tensor)\n        \"\"\"", "\n", "log_prob", "=", "self", ".", "distribution", ".", "log_prob", "(", "actions", ")", "\n", "return", "sum_independent_dims", "(", "log_prob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.SquashedDiagGaussianDistribution.__init__": [[192, 197], ["distributions.DiagGaussianDistribution.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "action_dim", ":", "int", ",", "epsilon", ":", "float", "=", "1e-6", ")", ":", "\n", "        ", "super", "(", "SquashedDiagGaussianDistribution", ",", "self", ")", ".", "__init__", "(", "action_dim", ")", "\n", "# Avoid NaN (prevents division by zero or log of zero)", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "gaussian_actions", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.SquashedDiagGaussianDistribution.proba_distribution": [[198, 202], ["distributions.DiagGaussianDistribution.proba_distribution"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.proba_distribution"], ["", "def", "proba_distribution", "(", "self", ",", "mean_actions", ":", "th", ".", "Tensor", ",", "\n", "log_std", ":", "th", ".", "Tensor", ")", "->", "'SquashedDiagGaussianDistribution'", ":", "\n", "        ", "super", "(", "SquashedDiagGaussianDistribution", ",", "self", ")", ".", "proba_distribution", "(", "mean_actions", ",", "log_std", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.SquashedDiagGaussianDistribution.mode": [[203, 207], ["torch.tanh", "torch.tanh"], "methods", ["None"], ["", "def", "mode", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "self", ".", "gaussian_actions", "=", "self", ".", "distribution", ".", "mean", "\n", "# Squash the output", "\n", "return", "th", ".", "tanh", "(", "self", ".", "gaussian_actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.SquashedDiagGaussianDistribution.entropy": [[208, 212], ["None"], "methods", ["None"], ["", "def", "entropy", "(", "self", ")", "->", "Optional", "[", "th", ".", "Tensor", "]", ":", "\n", "# No analytical form,", "\n", "# entropy needs to be estimated using -log_prob.mean()", "\n", "        ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.SquashedDiagGaussianDistribution.sample": [[213, 217], ["distributions.SquashedDiagGaussianDistribution.distribution.rsample", "torch.tanh", "torch.tanh"], "methods", ["None"], ["", "def", "sample", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "# Reparametrization trick to pass gradients", "\n", "        ", "self", ".", "gaussian_actions", "=", "self", ".", "distribution", ".", "rsample", "(", ")", "\n", "return", "th", ".", "tanh", "(", "self", ".", "gaussian_actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.SquashedDiagGaussianDistribution.log_prob_from_params": [[218, 223], ["distributions.SquashedDiagGaussianDistribution.actions_from_params", "distributions.SquashedDiagGaussianDistribution.log_prob"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.actions_from_params", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.log_prob"], ["", "def", "log_prob_from_params", "(", "self", ",", "mean_actions", ":", "th", ".", "Tensor", ",", "\n", "log_std", ":", "th", ".", "Tensor", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "action", "=", "self", ".", "actions_from_params", "(", "mean_actions", ",", "log_std", ")", "\n", "log_prob", "=", "self", ".", "log_prob", "(", "action", ",", "self", ".", "gaussian_actions", ")", "\n", "return", "action", ",", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.SquashedDiagGaussianDistribution.log_prob": [[224, 239], ["distributions.DiagGaussianDistribution.log_prob", "torch.sum", "torch.sum", "distributions.TanhBijector.inverse", "torch.log", "torch.log"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.log_prob", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.TanhBijector.inverse"], ["", "def", "log_prob", "(", "self", ",", "actions", ":", "th", ".", "Tensor", ",", "\n", "gaussian_actions", ":", "Optional", "[", "th", ".", "Tensor", "]", "=", "None", ")", "->", "th", ".", "Tensor", ":", "\n", "# Inverse tanh", "\n", "# Naive implementation (not stable): 0.5 * torch.log((1 + x) / (1 - x))", "\n", "# We use numpy to avoid numerical instability", "\n", "        ", "if", "gaussian_actions", "is", "None", ":", "\n", "# It will be clipped to avoid NaN when inversing tanh", "\n", "            ", "gaussian_actions", "=", "TanhBijector", ".", "inverse", "(", "actions", ")", "\n", "\n", "# Log likelihood for a Gaussian distribution", "\n", "", "log_prob", "=", "super", "(", "SquashedDiagGaussianDistribution", ",", "self", ")", ".", "log_prob", "(", "gaussian_actions", ")", "\n", "# Squash correction (from original SAC implementation)", "\n", "# this comes from the fact that tanh is bijective and differentiable", "\n", "log_prob", "-=", "th", ".", "sum", "(", "th", ".", "log", "(", "1", "-", "actions", "**", "2", "+", "self", ".", "epsilon", ")", ",", "dim", "=", "1", ")", "\n", "return", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.CategoricalDistribution.__init__": [[248, 252], ["distributions.Distribution.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "action_dim", ":", "int", ")", ":", "\n", "        ", "super", "(", "CategoricalDistribution", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "distribution", "=", "None", "\n", "self", ".", "action_dim", "=", "action_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.CategoricalDistribution.proba_distribution_net": [[253, 265], ["torch.Linear", "torch.Linear"], "methods", ["None"], ["", "def", "proba_distribution_net", "(", "self", ",", "latent_dim", ":", "int", ")", "->", "nn", ".", "Module", ":", "\n", "        ", "\"\"\"\n        Create the layer that represents the distribution:\n        it will be the logits of the Categorical distribution.\n        You can then get probabilities using a softmax.\n\n        :param latent_dim: (int) Dimension of the last layer\n            of the policy network (before the action layer)\n        :return: (nn.Linear)\n        \"\"\"", "\n", "action_logits", "=", "nn", ".", "Linear", "(", "latent_dim", ",", "self", ".", "action_dim", ")", "\n", "return", "action_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.CategoricalDistribution.proba_distribution": [[266, 269], ["torch.distributions.Categorical", "torch.distributions.Categorical"], "methods", ["None"], ["", "def", "proba_distribution", "(", "self", ",", "action_logits", ":", "th", ".", "Tensor", ")", "->", "'CategoricalDistribution'", ":", "\n", "        ", "self", ".", "distribution", "=", "Categorical", "(", "probs", "=", "action_logits", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.CategoricalDistribution.mode": [[270, 272], ["torch.argmax", "torch.argmax"], "methods", ["None"], ["", "def", "mode", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "th", ".", "argmax", "(", "self", ".", "distribution", ".", "probs", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.CategoricalDistribution.sample": [[273, 282], ["distributions.CategoricalDistribution.distribution.sample", "print", "print", "torch.tensor().type", "torch.tensor().type", "str", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type"], ["", "def", "sample", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "try", ":", "\n", "            ", "action", "=", "self", ".", "distribution", ".", "sample", "(", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "\"Nan values in distribution, consider using a lower learning rate or gradient clipping\"", ")", "\n", "print", "(", "str", "(", "e", ")", ")", "\n", "action", "=", "0", "\n", "return", "th", ".", "tensor", "(", "action", ")", ".", "type", "(", "th", ".", "LongTensor", ")", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.CategoricalDistribution.entropy": [[283, 285], ["distributions.CategoricalDistribution.distribution.entropy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.entropy"], ["", "def", "entropy", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "distribution", ".", "entropy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.CategoricalDistribution.actions_from_params": [[286, 291], ["distributions.CategoricalDistribution.proba_distribution", "distributions.CategoricalDistribution.get_actions"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.proba_distribution", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.Distribution.get_actions"], ["", "def", "actions_from_params", "(", "self", ",", "action_logits", ":", "th", ".", "Tensor", ",", "\n", "deterministic", ":", "bool", "=", "False", ")", "->", "th", ".", "Tensor", ":", "\n", "# Update the proba distribution", "\n", "        ", "self", ".", "proba_distribution", "(", "action_logits", ")", "\n", "return", "self", ".", "get_actions", "(", "deterministic", "=", "deterministic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.CategoricalDistribution.log_prob_from_params": [[292, 296], ["distributions.CategoricalDistribution.actions_from_params", "distributions.CategoricalDistribution.log_prob"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.actions_from_params", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.log_prob"], ["", "def", "log_prob_from_params", "(", "self", ",", "action_logits", ":", "th", ".", "Tensor", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "actions", "=", "self", ".", "actions_from_params", "(", "action_logits", ")", "\n", "log_prob", "=", "self", ".", "log_prob", "(", "actions", ")", "\n", "return", "actions", ",", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.CategoricalDistribution.log_prob": [[297, 299], ["distributions.CategoricalDistribution.distribution.log_prob"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.log_prob"], ["", "def", "log_prob", "(", "self", ",", "actions", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "distribution", ".", "log_prob", "(", "actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.MultiCategoricalDistribution.__init__": [[308, 312], ["distributions.Distribution.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "action_dims", ":", "List", "[", "int", "]", ")", ":", "\n", "        ", "super", "(", "MultiCategoricalDistribution", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "action_dims", "=", "action_dims", "\n", "self", ".", "distributions", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.MultiCategoricalDistribution.proba_distribution_net": [[313, 326], ["torch.Linear", "torch.Linear", "sum"], "methods", ["None"], ["", "def", "proba_distribution_net", "(", "self", ",", "latent_dim", ":", "int", ")", "->", "nn", ".", "Module", ":", "\n", "        ", "\"\"\"\n        Create the layer that represents the distribution:\n        it will be the logits (flattened) of the MultiCategorical distribution.\n        You can then get probabilities using a softmax on each sub-space.\n\n        :param latent_dim: (int) Dimension of the last layer\n            of the policy network (before the action layer)\n        :return: (nn.Linear)\n        \"\"\"", "\n", "\n", "action_logits", "=", "nn", ".", "Linear", "(", "latent_dim", ",", "sum", "(", "self", ".", "action_dims", ")", ")", "\n", "return", "action_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.MultiCategoricalDistribution.proba_distribution": [[327, 330], ["torch.distributions.Categorical", "torch.distributions.Categorical", "torch.split", "torch.split", "tuple"], "methods", ["None"], ["", "def", "proba_distribution", "(", "self", ",", "action_logits", ":", "th", ".", "Tensor", ")", "->", "'MultiCategoricalDistribution'", ":", "\n", "        ", "self", ".", "distributions", "=", "[", "Categorical", "(", "logits", "=", "split", ")", "for", "split", "in", "th", ".", "split", "(", "action_logits", ",", "tuple", "(", "self", ".", "action_dims", ")", ",", "dim", "=", "1", ")", "]", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.MultiCategoricalDistribution.mode": [[331, 333], ["torch.stack", "torch.stack", "torch.argmax", "torch.argmax"], "methods", ["None"], ["", "def", "mode", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "th", ".", "stack", "(", "[", "th", ".", "argmax", "(", "dist", ".", "probs", ",", "dim", "=", "1", ")", "for", "dist", "in", "self", ".", "distributions", "]", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.MultiCategoricalDistribution.sample": [[334, 336], ["torch.stack", "torch.stack", "dist.sample"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.sample"], ["", "def", "sample", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "th", ".", "stack", "(", "[", "dist", ".", "sample", "(", ")", "for", "dist", "in", "self", ".", "distributions", "]", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.MultiCategoricalDistribution.entropy": [[337, 339], ["torch.stack().sum", "torch.stack().sum", "torch.stack", "torch.stack", "dist.entropy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.entropy"], ["", "def", "entropy", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "th", ".", "stack", "(", "[", "dist", ".", "entropy", "(", ")", "for", "dist", "in", "self", ".", "distributions", "]", ",", "dim", "=", "1", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.MultiCategoricalDistribution.actions_from_params": [[340, 345], ["distributions.MultiCategoricalDistribution.proba_distribution", "distributions.MultiCategoricalDistribution.get_actions"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.proba_distribution", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.Distribution.get_actions"], ["", "def", "actions_from_params", "(", "self", ",", "action_logits", ":", "th", ".", "Tensor", ",", "\n", "deterministic", ":", "bool", "=", "False", ")", "->", "th", ".", "Tensor", ":", "\n", "# Update the proba distribution", "\n", "        ", "self", ".", "proba_distribution", "(", "action_logits", ")", "\n", "return", "self", ".", "get_actions", "(", "deterministic", "=", "deterministic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.MultiCategoricalDistribution.log_prob_from_params": [[346, 350], ["distributions.MultiCategoricalDistribution.actions_from_params", "distributions.MultiCategoricalDistribution.log_prob"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.actions_from_params", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.log_prob"], ["", "def", "log_prob_from_params", "(", "self", ",", "action_logits", ":", "th", ".", "Tensor", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "actions", "=", "self", ".", "actions_from_params", "(", "action_logits", ")", "\n", "log_prob", "=", "self", ".", "log_prob", "(", "actions", ")", "\n", "return", "actions", ",", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.MultiCategoricalDistribution.log_prob": [[351, 355], ["torch.stack().sum", "torch.stack().sum", "torch.stack", "torch.stack", "dist.log_prob", "zip", "torch.unbind", "torch.unbind"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.log_prob"], ["", "def", "log_prob", "(", "self", ",", "actions", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "# Extract each discrete action and compute log prob for their respective distributions", "\n", "        ", "return", "th", ".", "stack", "(", "[", "dist", ".", "log_prob", "(", "action", ")", "for", "dist", ",", "action", "in", "zip", "(", "self", ".", "distributions", ",", "\n", "th", ".", "unbind", "(", "actions", ",", "dim", "=", "1", ")", ")", "]", ",", "dim", "=", "1", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.BernoulliDistribution.__init__": [[364, 368], ["distributions.Distribution.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "action_dims", ":", "int", ")", ":", "\n", "        ", "super", "(", "BernoulliDistribution", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "distribution", "=", "None", "\n", "self", ".", "action_dims", "=", "action_dims", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.BernoulliDistribution.proba_distribution_net": [[369, 380], ["torch.Linear", "torch.Linear"], "methods", ["None"], ["", "def", "proba_distribution_net", "(", "self", ",", "latent_dim", ":", "int", ")", "->", "nn", ".", "Module", ":", "\n", "        ", "\"\"\"\n        Create the layer that represents the distribution:\n        it will be the logits of the Bernoulli distribution.\n\n        :param latent_dim: (int) Dimension of the last layer\n            of the policy network (before the action layer)\n        :return: (nn.Linear)\n        \"\"\"", "\n", "action_logits", "=", "nn", ".", "Linear", "(", "latent_dim", ",", "self", ".", "action_dims", ")", "\n", "return", "action_logits", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.BernoulliDistribution.proba_distribution": [[381, 384], ["torch.distributions.Bernoulli", "torch.distributions.Bernoulli"], "methods", ["None"], ["", "def", "proba_distribution", "(", "self", ",", "action_logits", ":", "th", ".", "Tensor", ")", "->", "'BernoulliDistribution'", ":", "\n", "        ", "self", ".", "distribution", "=", "Bernoulli", "(", "logits", "=", "action_logits", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.BernoulliDistribution.mode": [[385, 387], ["torch.round", "torch.round"], "methods", ["None"], ["", "def", "mode", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "th", ".", "round", "(", "self", ".", "distribution", ".", "probs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.BernoulliDistribution.sample": [[388, 390], ["distributions.BernoulliDistribution.distribution.sample"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.sample"], ["", "def", "sample", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "distribution", ".", "sample", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.BernoulliDistribution.entropy": [[391, 393], ["distributions.BernoulliDistribution.distribution.entropy().sum", "distributions.BernoulliDistribution.distribution.entropy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.entropy"], ["", "def", "entropy", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "distribution", ".", "entropy", "(", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.BernoulliDistribution.actions_from_params": [[394, 399], ["distributions.BernoulliDistribution.proba_distribution", "distributions.BernoulliDistribution.get_actions"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.proba_distribution", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.Distribution.get_actions"], ["", "def", "actions_from_params", "(", "self", ",", "action_logits", ":", "th", ".", "Tensor", ",", "\n", "deterministic", ":", "bool", "=", "False", ")", "->", "th", ".", "Tensor", ":", "\n", "# Update the proba distribution", "\n", "        ", "self", ".", "proba_distribution", "(", "action_logits", ")", "\n", "return", "self", ".", "get_actions", "(", "deterministic", "=", "deterministic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.BernoulliDistribution.log_prob_from_params": [[400, 404], ["distributions.BernoulliDistribution.actions_from_params", "distributions.BernoulliDistribution.log_prob"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.actions_from_params", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.log_prob"], ["", "def", "log_prob_from_params", "(", "self", ",", "action_logits", ":", "th", ".", "Tensor", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "actions", "=", "self", ".", "actions_from_params", "(", "action_logits", ")", "\n", "log_prob", "=", "self", ".", "log_prob", "(", "actions", ")", "\n", "return", "actions", ",", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.BernoulliDistribution.log_prob": [[405, 407], ["distributions.BernoulliDistribution.distribution.log_prob().sum", "distributions.BernoulliDistribution.distribution.log_prob"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.log_prob"], ["", "def", "log_prob", "(", "self", ",", "actions", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "self", ".", "distribution", ".", "log_prob", "(", "actions", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.__init__": [[431, 455], ["distributions.Distribution.__init__", "distributions.TanhBijector"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "action_dim", ":", "int", ",", "\n", "full_std", ":", "bool", "=", "True", ",", "\n", "use_expln", ":", "bool", "=", "False", ",", "\n", "squash_output", ":", "bool", "=", "False", ",", "\n", "learn_features", ":", "bool", "=", "False", ",", "\n", "epsilon", ":", "float", "=", "1e-6", ")", ":", "\n", "        ", "super", "(", "StateDependentNoiseDistribution", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "distribution", "=", "None", "\n", "self", ".", "action_dim", "=", "action_dim", "\n", "self", ".", "latent_sde_dim", "=", "None", "\n", "self", ".", "mean_actions", "=", "None", "\n", "self", ".", "log_std", "=", "None", "\n", "self", ".", "weights_dist", "=", "None", "\n", "self", ".", "exploration_mat", "=", "None", "\n", "self", ".", "exploration_matrices", "=", "None", "\n", "self", ".", "_latent_sde", "=", "None", "\n", "self", ".", "use_expln", "=", "use_expln", "\n", "self", ".", "full_std", "=", "full_std", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "learn_features", "=", "learn_features", "\n", "if", "squash_output", ":", "\n", "            ", "self", ".", "bijector", "=", "TanhBijector", "(", "epsilon", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bijector", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.get_std": [[456, 480], ["torch.exp", "torch.exp", "torch.ones().to", "torch.ones().to", "torch.exp", "torch.exp", "torch.log1p", "torch.log1p", "torch.ones", "torch.ones"], "methods", ["None"], ["", "", "def", "get_std", "(", "self", ",", "log_std", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Get the standard deviation from the learned parameter\n        (log of it by default). This ensures that the std is positive.\n\n        :param log_std: (th.Tensor)\n        :return: (th.Tensor)\n        \"\"\"", "\n", "if", "self", ".", "use_expln", ":", "\n", "# From gSDE paper, it allows to keep variance", "\n", "# above zero and prevent it from growing too fast", "\n", "            ", "below_threshold", "=", "th", ".", "exp", "(", "log_std", ")", "*", "(", "log_std", "<=", "0", ")", "\n", "# Avoid NaN: zeros values that are below zero", "\n", "safe_log_std", "=", "log_std", "*", "(", "log_std", ">", "0", ")", "+", "self", ".", "epsilon", "\n", "above_threshold", "=", "(", "th", ".", "log1p", "(", "safe_log_std", ")", "+", "1.0", ")", "*", "(", "log_std", ">", "0", ")", "\n", "std", "=", "below_threshold", "+", "above_threshold", "\n", "", "else", ":", "\n", "# Use normal exponential", "\n", "            ", "std", "=", "th", ".", "exp", "(", "log_std", ")", "\n", "\n", "", "if", "self", ".", "full_std", ":", "\n", "            ", "return", "std", "\n", "# Reduce the number of parameters:", "\n", "", "return", "th", ".", "ones", "(", "self", ".", "latent_sde_dim", ",", "self", ".", "action_dim", ")", ".", "to", "(", "log_std", ".", "device", ")", "*", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.sample_weights": [[481, 495], ["distributions.StateDependentNoiseDistribution.get_std", "torch.distributions.Normal", "torch.distributions.Normal", "distributions.StateDependentNoiseDistribution.weights_dist.rsample", "distributions.StateDependentNoiseDistribution.weights_dist.rsample", "torch.zeros_like", "torch.zeros_like"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.get_std"], ["", "def", "sample_weights", "(", "self", ",", "log_std", ":", "th", ".", "Tensor", ",", "batch_size", ":", "int", "=", "1", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Sample weights for the noise exploration matrix,\n        using a centered Gaussian distribution.\n\n        :param log_std: (th.Tensor)\n        :param batch_size: (int)\n        \"\"\"", "\n", "std", "=", "self", ".", "get_std", "(", "log_std", ")", "\n", "self", ".", "weights_dist", "=", "Normal", "(", "th", ".", "zeros_like", "(", "std", ")", ",", "std", ")", "\n", "# Reparametrization trick to pass gradients", "\n", "self", ".", "exploration_mat", "=", "self", ".", "weights_dist", ".", "rsample", "(", ")", "\n", "# Pre-compute matrices in case of parallel exploration", "\n", "self", ".", "exploration_matrices", "=", "self", ".", "weights_dist", ".", "rsample", "(", "(", "batch_size", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.proba_distribution_net": [[496, 521], ["torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "distributions.StateDependentNoiseDistribution.sample_weights", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.sample_weights"], ["", "def", "proba_distribution_net", "(", "self", ",", "latent_dim", ":", "int", ",", "log_std_init", ":", "float", "=", "-", "2.0", ",", "\n", "latent_sde_dim", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "Tuple", "[", "nn", ".", "Module", ",", "nn", ".", "Parameter", "]", ":", "\n", "        ", "\"\"\"\n        Create the layers and parameter that represent the distribution:\n        one output will be the deterministic action, the other parameter will be the\n        standard deviation of the distribution that control the weights of the noise matrix.\n\n        :param latent_dim: (int) Dimension of the last layer of the policy (before the action layer)\n        :param log_std_init: (float) Initial value for the log standard deviation\n        :param latent_sde_dim: (Optional[int]) Dimension of the last layer of the feature extractor\n            for gSDE. By default, it is shared with the policy network.\n        :return: (nn.Linear, nn.Parameter)\n        \"\"\"", "\n", "# Network for the deterministic action, it represents the mean of the distribution", "\n", "mean_actions_net", "=", "nn", ".", "Linear", "(", "latent_dim", ",", "self", ".", "action_dim", ")", "\n", "# When we learn features for the noise, the feature dimension", "\n", "# can be different between the policy and the noise network", "\n", "self", ".", "latent_sde_dim", "=", "latent_dim", "if", "latent_sde_dim", "is", "None", "else", "latent_sde_dim", "\n", "# Reduce the number of parameters if needed", "\n", "log_std", "=", "th", ".", "ones", "(", "self", ".", "latent_sde_dim", ",", "self", ".", "action_dim", ")", "if", "self", ".", "full_std", "else", "th", ".", "ones", "(", "self", ".", "latent_sde_dim", ",", "1", ")", "\n", "# Transform it to a parameter so it can be optimized", "\n", "log_std", "=", "nn", ".", "Parameter", "(", "log_std", "*", "log_std_init", ",", "requires_grad", "=", "True", ")", "\n", "# Sample an exploration matrix", "\n", "self", ".", "sample_weights", "(", "log_std", ")", "\n", "return", "mean_actions_net", ",", "log_std", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.proba_distribution": [[522, 538], ["torch.mm", "torch.mm", "torch.distributions.Normal", "torch.distributions.Normal", "latent_sde.detach", "torch.sqrt", "torch.sqrt", "distributions.StateDependentNoiseDistribution.get_std"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.get_std"], ["", "def", "proba_distribution", "(", "self", ",", "mean_actions", ":", "th", ".", "Tensor", ",", "\n", "log_std", ":", "th", ".", "Tensor", ",", "\n", "latent_sde", ":", "th", ".", "Tensor", ")", "->", "'StateDependentNoiseDistribution'", ":", "\n", "        ", "\"\"\"\n        Create the distribution given its parameters (mean, std)\n\n        :param mean_actions: (th.Tensor)\n        :param log_std: (th.Tensor)\n        :param latent_sde: (th.Tensor)\n        :return: (StateDependentNoiseDistribution)\n        \"\"\"", "\n", "# Stop gradient if we don't want to influence the features", "\n", "self", ".", "_latent_sde", "=", "latent_sde", "if", "self", ".", "learn_features", "else", "latent_sde", ".", "detach", "(", ")", "\n", "variance", "=", "th", ".", "mm", "(", "latent_sde", "**", "2", ",", "self", ".", "get_std", "(", "log_std", ")", "**", "2", ")", "\n", "self", ".", "distribution", "=", "Normal", "(", "mean_actions", ",", "th", ".", "sqrt", "(", "variance", "+", "self", ".", "epsilon", ")", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.mode": [[539, 544], ["distributions.StateDependentNoiseDistribution.bijector.forward"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward"], ["", "def", "mode", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "actions", "=", "self", ".", "distribution", ".", "mean", "\n", "if", "self", ".", "bijector", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "bijector", ".", "forward", "(", "actions", ")", "\n", "", "return", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.get_noise": [[545, 556], ["latent_sde.unsqueeze.unsqueeze.unsqueeze", "torch.bmm", "torch.bmm", "torch.bmm.squeeze", "latent_sde.unsqueeze.unsqueeze.detach", "torch.mm", "torch.mm", "len", "len", "len"], "methods", ["None"], ["", "def", "get_noise", "(", "self", ",", "latent_sde", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "latent_sde", "=", "latent_sde", "if", "self", ".", "learn_features", "else", "latent_sde", ".", "detach", "(", ")", "\n", "# Default case: only one exploration matrix", "\n", "if", "len", "(", "latent_sde", ")", "==", "1", "or", "len", "(", "latent_sde", ")", "!=", "len", "(", "self", ".", "exploration_matrices", ")", ":", "\n", "            ", "return", "th", ".", "mm", "(", "latent_sde", ",", "self", ".", "exploration_mat", ")", "\n", "# Use batch matrix multiplication for efficient computation", "\n", "# (batch_size, n_features) -> (batch_size, 1, n_features)", "\n", "", "latent_sde", "=", "latent_sde", ".", "unsqueeze", "(", "1", ")", "\n", "# (batch_size, 1, n_actions)", "\n", "noise", "=", "th", ".", "bmm", "(", "latent_sde", ",", "self", ".", "exploration_matrices", ")", "\n", "return", "noise", ".", "squeeze", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.sample": [[557, 563], ["distributions.StateDependentNoiseDistribution.get_noise", "distributions.StateDependentNoiseDistribution.bijector.forward"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.get_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward"], ["", "def", "sample", "(", "self", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "noise", "=", "self", ".", "get_noise", "(", "self", ".", "_latent_sde", ")", "\n", "actions", "=", "self", ".", "distribution", ".", "mean", "+", "noise", "\n", "if", "self", ".", "bijector", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "bijector", ".", "forward", "(", "actions", ")", "\n", "", "return", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.entropy": [[564, 570], ["distributions.sum_independent_dims", "distributions.StateDependentNoiseDistribution.distribution.entropy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.sum_independent_dims", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.entropy"], ["", "def", "entropy", "(", "self", ")", "->", "Optional", "[", "th", ".", "Tensor", "]", ":", "\n", "# No analytical form,", "\n", "# entropy needs to be estimated using -log_prob.mean()", "\n", "        ", "if", "self", ".", "bijector", "is", "not", "None", ":", "\n", "            ", "return", "None", "\n", "", "return", "sum_independent_dims", "(", "self", ".", "distribution", ".", "entropy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.actions_from_params": [[571, 578], ["distributions.StateDependentNoiseDistribution.proba_distribution", "distributions.StateDependentNoiseDistribution.get_actions"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.proba_distribution", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.Distribution.get_actions"], ["", "def", "actions_from_params", "(", "self", ",", "mean_actions", ":", "th", ".", "Tensor", ",", "\n", "log_std", ":", "th", ".", "Tensor", ",", "\n", "latent_sde", ":", "th", ".", "Tensor", ",", "\n", "deterministic", ":", "bool", "=", "False", ")", "->", "th", ".", "Tensor", ":", "\n", "# Update the proba distribution", "\n", "        ", "self", ".", "proba_distribution", "(", "mean_actions", ",", "log_std", ",", "latent_sde", ")", "\n", "return", "self", ".", "get_actions", "(", "deterministic", "=", "deterministic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.log_prob_from_params": [[579, 585], ["distributions.StateDependentNoiseDistribution.actions_from_params", "distributions.StateDependentNoiseDistribution.log_prob"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.actions_from_params", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.log_prob"], ["", "def", "log_prob_from_params", "(", "self", ",", "mean_actions", ":", "th", ".", "Tensor", ",", "\n", "log_std", ":", "th", ".", "Tensor", ",", "\n", "latent_sde", ":", "th", ".", "Tensor", ")", "->", "Tuple", "[", "th", ".", "Tensor", ",", "th", ".", "Tensor", "]", ":", "\n", "        ", "actions", "=", "self", ".", "actions_from_params", "(", "mean_actions", ",", "log_std", ",", "latent_sde", ")", "\n", "log_prob", "=", "self", ".", "log_prob", "(", "actions", ")", "\n", "return", "actions", ",", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.log_prob": [[586, 600], ["distributions.StateDependentNoiseDistribution.distribution.log_prob", "distributions.sum_independent_dims", "distributions.StateDependentNoiseDistribution.bijector.inverse", "torch.sum", "torch.sum", "distributions.StateDependentNoiseDistribution.bijector.log_prob_correction"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.log_prob", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.sum_independent_dims", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.TanhBijector.inverse", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.TanhBijector.log_prob_correction"], ["", "def", "log_prob", "(", "self", ",", "actions", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "if", "self", ".", "bijector", "is", "not", "None", ":", "\n", "            ", "gaussian_actions", "=", "self", ".", "bijector", ".", "inverse", "(", "actions", ")", "\n", "", "else", ":", "\n", "            ", "gaussian_actions", "=", "actions", "\n", "# log likelihood for a gaussian", "\n", "", "log_prob", "=", "self", ".", "distribution", ".", "log_prob", "(", "gaussian_actions", ")", "\n", "# Sum along action dim", "\n", "log_prob", "=", "sum_independent_dims", "(", "log_prob", ")", "\n", "\n", "if", "self", ".", "bijector", "is", "not", "None", ":", "\n", "# Squash correction (from original SAC implementation)", "\n", "            ", "log_prob", "-=", "th", ".", "sum", "(", "self", ".", "bijector", ".", "log_prob_correction", "(", "gaussian_actions", ")", ",", "dim", "=", "1", ")", "\n", "", "return", "log_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.TanhBijector.__init__": [[611, 614], ["object.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "epsilon", ":", "float", "=", "1e-6", ")", ":", "\n", "        ", "super", "(", "TanhBijector", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.TanhBijector.forward": [[615, 618], ["torch.tanh", "torch.tanh"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "forward", "(", "x", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "return", "th", ".", "tanh", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.TanhBijector.atanh": [[619, 628], ["x.log1p"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "atanh", "(", "x", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Inverse of Tanh\n\n        Taken from pyro: https://github.com/pyro-ppl/pyro\n        0.5 * torch.log((1 + x ) / (1 - x))\n        \"\"\"", "\n", "return", "0.5", "*", "(", "x", ".", "log1p", "(", ")", "-", "(", "-", "x", ")", ".", "log1p", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.TanhBijector.inverse": [[629, 640], ["distributions.TanhBijector.atanh", "torch.finfo", "torch.finfo", "y.clamp"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.TanhBijector.atanh"], ["", "@", "staticmethod", "\n", "def", "inverse", "(", "y", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Inverse tanh.\n\n        :param y: (th.Tensor)\n        :return: (th.Tensor)\n        \"\"\"", "\n", "eps", "=", "th", ".", "finfo", "(", "y", ".", "dtype", ")", ".", "eps", "\n", "# Clip the action to avoid NaN", "\n", "return", "TanhBijector", ".", "atanh", "(", "y", ".", "clamp", "(", "min", "=", "-", "1.", "+", "eps", ",", "max", "=", "1.", "-", "eps", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.TanhBijector.log_prob_correction": [[641, 644], ["torch.log", "torch.log", "torch.tanh", "torch.tanh"], "methods", ["None"], ["", "def", "log_prob_correction", "(", "self", ",", "x", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "# Squash correction (from original SAC implementation)", "\n", "        ", "return", "th", ".", "log", "(", "1.0", "-", "th", ".", "tanh", "(", "x", ")", "**", "2", "+", "self", ".", "epsilon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.sum_independent_dims": [[80, 94], ["len", "tensor.sum.sum", "tensor.sum.sum"], "function", ["None"], ["", "", "def", "sum_independent_dims", "(", "tensor", ":", "th", ".", "Tensor", ")", "->", "th", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    Continuous actions are usually considered to be independent,\n    so we can sum the components for the ``log_prob``\n    or the entropy.\n\n    :param tensor: (th.Tensor) shape: (n_batch, n_actions) or (n_batch,)\n    :return: (th.Tensor) shape: (n_batch,)\n    \"\"\"", "\n", "if", "len", "(", "tensor", ".", "shape", ")", ">", "1", ":", "\n", "        ", "tensor", "=", "tensor", ".", "sum", "(", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "        ", "tensor", "=", "tensor", ".", "sum", "(", ")", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.make_proba_distribution": [[646, 674], ["isinstance", "distributions.DiagGaussianDistribution", "isinstance", "len", "distributions.StateDependentNoiseDistribution", "stable_baselines3.common.preprocessing.get_action_dim", "distributions.CategoricalDistribution", "isinstance", "stable_baselines3.common.preprocessing.get_action_dim", "distributions.MultiCategoricalDistribution", "isinstance", "distributions.BernoulliDistribution", "NotImplementedError", "type"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type"], ["", "", "def", "make_proba_distribution", "(", "action_space", ":", "gym", ".", "spaces", ".", "Space", ",", "\n", "use_sde", ":", "bool", "=", "False", ",", "\n", "dist_kwargs", ":", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ")", "->", "Distribution", ":", "\n", "    ", "\"\"\"\n    Return an instance of Distribution for the correct type of action space\n\n    :param action_space: (gym.spaces.Space) the input action space\n    :param use_sde: (bool) Force the use of StateDependentNoiseDistribution\n        instead of DiagGaussianDistribution\n    :param dist_kwargs: (Optional[Dict[str, Any]]) Keyword arguments to pass to the probability distribution\n    :return: (Distribution) the appropriate Distribution object\n    \"\"\"", "\n", "if", "dist_kwargs", "is", "None", ":", "\n", "        ", "dist_kwargs", "=", "{", "}", "\n", "\n", "", "if", "isinstance", "(", "action_space", ",", "spaces", ".", "Box", ")", ":", "\n", "        ", "assert", "len", "(", "action_space", ".", "shape", ")", "==", "1", ",", "\"Error: the action space must be a vector\"", "\n", "if", "use_sde", ":", "\n", "            ", "return", "StateDependentNoiseDistribution", "(", "get_action_dim", "(", "action_space", ")", ",", "**", "dist_kwargs", ")", "\n", "", "return", "DiagGaussianDistribution", "(", "get_action_dim", "(", "action_space", ")", ",", "**", "dist_kwargs", ")", "\n", "", "elif", "isinstance", "(", "action_space", ",", "spaces", ".", "Discrete", ")", ":", "\n", "        ", "return", "CategoricalDistribution", "(", "action_space", ".", "n", ",", "**", "dist_kwargs", ")", "\n", "", "elif", "isinstance", "(", "action_space", ",", "spaces", ".", "MultiDiscrete", ")", ":", "\n", "        ", "return", "MultiCategoricalDistribution", "(", "action_space", ".", "nvec", ",", "**", "dist_kwargs", ")", "\n", "", "elif", "isinstance", "(", "action_space", ",", "spaces", ".", "MultiBinary", ")", ":", "\n", "        ", "return", "BernoulliDistribution", "(", "action_space", ".", "n", ",", "**", "dist_kwargs", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Error: probability distribution, not implemented for action space\"", "\n", "f\"of type {type(action_space)}.\"", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.__init__": [[61, 174], ["gym_idsgame.agents.training_agents.openai_baselines.common.utils.get_device", "gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.unwrap_vec_normalize", "gym_idsgame.agents.dao.experiment_result.ExperimentResult", "gym_idsgame.agents.dao.experiment_result.ExperimentResult", "print", "isinstance", "base_class.BaseRLModel._wrap_env", "gym.make", "gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.dummy_vec_env.DummyVecEnv", "ValueError", "gym.make", "gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.dummy_vec_env.DummyVecEnv", "print", "stable_baselines3.common.monitor.Monitor", "stable_baselines3.common.monitor.Monitor"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.get_device", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.__init__.unwrap_vec_normalize", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._wrap_env"], ["def", "__init__", "(", "self", ",", "\n", "policy", ":", "Type", "[", "BasePolicy", "]", ",", "\n", "env", ":", "Union", "[", "GymEnv", ",", "str", "]", ",", "\n", "policy_base", ":", "Type", "[", "BasePolicy", "]", ",", "\n", "learning_rate", ":", "Union", "[", "float", ",", "Callable", "]", ",", "\n", "policy_kwargs", ":", "Dict", "[", "str", ",", "Any", "]", "=", "None", ",", "\n", "verbose", ":", "int", "=", "0", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "'auto'", ",", "\n", "support_multi_env", ":", "bool", "=", "False", ",", "\n", "create_eval_env", ":", "bool", "=", "False", ",", "\n", "monitor_wrapper", ":", "bool", "=", "True", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "use_sde", ":", "bool", "=", "False", ",", "\n", "sde_sample_freq", ":", "int", "=", "-", "1", ",", "\n", "pg_agent_config", ":", "PolicyGradientAgentConfig", "=", "None", ")", ":", "\n", "\n", "# if isinstance(policy, str) and policy_base is not None:", "\n", "#     self.policy_class = get_policy_from_name(policy_base, policy)", "\n", "# else:", "\n", "#     self.policy_class = policy", "\n", "\n", "        ", "self", ".", "pg_agent_config", "=", "pg_agent_config", "\n", "self", ".", "device", "=", "get_device", "(", "device", ",", "pg_agent_config", ")", "\n", "if", "verbose", ">", "0", ":", "\n", "            ", "print", "(", "f\"Using {self.device} device\"", ")", "\n", "", "self", ".", "env", "=", "None", "# type: Optional[GymEnv]", "\n", "# get VecNormalize object if needed", "\n", "self", ".", "_vec_normalize_env", "=", "unwrap_vec_normalize", "(", "env", ")", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "policy_kwargs", "=", "{", "}", "if", "policy_kwargs", "is", "None", "else", "policy_kwargs", "\n", "self", ".", "attacker_observation_space", "=", "None", "# type: Optional[gym.spaces.Space]", "\n", "self", ".", "defender_observation_space", "=", "None", "# type: Optional[gym.spaces.Space]", "\n", "self", ".", "attacker_action_space", "=", "None", "# type: Optional[gym.spaces.Space]", "\n", "self", ".", "defender_action_space", "=", "None", "# type: Optional[gym.spaces.Space]", "\n", "self", ".", "n_envs", "=", "None", "\n", "self", ".", "num_timesteps", "=", "0", "\n", "self", ".", "train_result", "=", "ExperimentResult", "(", ")", "\n", "self", ".", "eval_result", "=", "ExperimentResult", "(", ")", "\n", "self", ".", "eval_env", "=", "None", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "action_noise", "=", "None", "# type: Optional[ActionNoise]", "\n", "self", ".", "start_time", "=", "None", "\n", "self", ".", "attacker_policy", "=", "None", "\n", "self", ".", "defender_policy", "=", "None", "\n", "self", ".", "attacker_node_policy", "=", "None", "\n", "self", ".", "attacker_at_policy", "=", "None", "\n", "self", ".", "defender_node_policy", "=", "None", "\n", "self", ".", "defender_at_policy", "=", "None", "\n", "self", ".", "learning_rate", "=", "learning_rate", "\n", "self", ".", "lr_schedule_a", "=", "None", "# type: Optional[Callable]", "\n", "self", ".", "lr_schedule_d", "=", "None", "# type: Optional[Callable]", "\n", "self", ".", "_last_obs_a", "=", "None", "# type: Optional[np.ndarray]", "\n", "self", ".", "_last_obs_d", "=", "None", "# type: Optional[np.ndarray]", "\n", "self", ".", "_last_obs_a_a", "=", "None", "\n", "self", ".", "_last_obs_a_d", "=", "None", "\n", "self", ".", "_last_obs_a_p", "=", "None", "\n", "self", ".", "_last_obs_a_r", "=", "None", "\n", "# When using VecNormalize:", "\n", "self", ".", "_last_original_obs", "=", "None", "# type: Optional[np.ndarray]", "\n", "self", ".", "_episode_num", "=", "0", "\n", "# Used for gSDE only", "\n", "self", ".", "use_sde", "=", "use_sde", "\n", "self", ".", "sde_sample_freq", "=", "sde_sample_freq", "\n", "# Track the training progress (from 1 to 0)", "\n", "# this is used to update the learning rate", "\n", "self", ".", "_current_progress", "=", "1", "\n", "# Buffers for logging", "\n", "self", ".", "ep_info_buffer", "=", "None", "# type: Optional[deque]", "\n", "self", ".", "ep_success_buffer", "=", "None", "# type: Optional[deque]", "\n", "# For logging", "\n", "self", ".", "_n_updates", "=", "0", "# type: int", "\n", "self", ".", "num_eval_games_total", "=", "0", "\n", "self", ".", "num_eval_hacks_total", "=", "0", "\n", "self", ".", "num_eval_games", "=", "0", "\n", "self", ".", "num_eval_hacks", "=", "0", "\n", "self", ".", "num_train_games", "=", "0", "\n", "self", ".", "num_train_hacks", "=", "0", "\n", "self", ".", "num_train_games_total", "=", "0", "\n", "self", ".", "num_train_hacks_total", "=", "0", "\n", "self", ".", "train_hack_probability", "=", "0.0", "\n", "self", ".", "train_cumulative_hack_probability", "=", "0.0", "\n", "self", ".", "eval_hack_probability", "=", "0.0", "\n", "self", ".", "eval_cumulative_hack_probability", "=", "0.0", "\n", "self", ".", "eval_attacker_cumulative_reward", "=", "0", "\n", "self", ".", "eval_defender_cumulative_reward", "=", "0", "\n", "\n", "# Create and wrap the env if needed", "\n", "if", "env", "is", "not", "None", ":", "\n", "            ", "if", "isinstance", "(", "env", ",", "str", ")", ":", "\n", "                ", "if", "create_eval_env", ":", "\n", "                    ", "eval_env", "=", "gym", ".", "make", "(", "env", ")", "\n", "if", "monitor_wrapper", ":", "\n", "                        ", "eval_env", "=", "Monitor", "(", "eval_env", ",", "filename", "=", "None", ")", "\n", "", "self", ".", "eval_env", "=", "DummyVecEnv", "(", "[", "lambda", ":", "eval_env", "]", ")", "\n", "", "if", "self", ".", "verbose", ">=", "1", ":", "\n", "                    ", "print", "(", "\"Creating environment from the given name, wrapped in a DummyVecEnv.\"", ")", "\n", "\n", "", "env", "=", "gym", ".", "make", "(", "env", ")", "\n", "if", "monitor_wrapper", ":", "\n", "                    ", "env", "=", "Monitor", "(", "env", ",", "filename", "=", "None", ")", "\n", "", "env", "=", "DummyVecEnv", "(", "[", "lambda", ":", "env", "]", ")", "\n", "\n", "", "env", "=", "self", ".", "_wrap_env", "(", "env", ")", "\n", "\n", "self", ".", "attacker_observation_space", "=", "env", ".", "attacker_observation_space", "\n", "self", ".", "defender_observation_space", "=", "env", ".", "defender_observation_space", "\n", "self", ".", "attacker_action_space", "=", "env", ".", "attacker_action_space", "\n", "self", ".", "defender_action_space", "=", "env", ".", "defender_action_space", "\n", "self", ".", "n_envs", "=", "env", ".", "num_envs", "\n", "self", ".", "env", "=", "env", "\n", "\n", "if", "not", "support_multi_env", "and", "self", ".", "n_envs", ">", "1", ":", "\n", "                ", "raise", "ValueError", "(", "\"Error: the model does not support multiple envs requires a single vectorized\"", "\n", "\" environment.\"", ")", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._wrap_env": [[176, 187], ["isinstance", "gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.dummy_vec_env.DummyVecEnv", "print"], "methods", ["None"], ["", "", "", "def", "_wrap_env", "(", "self", ",", "env", ":", "GymEnv", ")", "->", "VecEnv", ":", "\n", "        ", "if", "not", "isinstance", "(", "env", ",", "VecEnv", ")", ":", "\n", "            ", "if", "self", ".", "verbose", ">=", "1", ":", "\n", "                ", "print", "(", "\"Wrapping the env in a DummyVecEnv.\"", ")", "\n", "", "env", "=", "DummyVecEnv", "(", "[", "lambda", ":", "env", "]", ")", "\n", "\n", "# if is_image_space(env.attacker_observation_space) and not isinstance(env, VecTransposeImage):", "\n", "#     if self.verbose >= 1:", "\n", "#         print(\"Wrapping the env in a VecTransposeImage.\")", "\n", "#     env = VecTransposeImage(env)", "\n", "", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.log_metrics": [[188, 277], ["numpy.mean", "numpy.mean", "numpy.mean", "base_class.BaseRLModel.pg_agent_config.logger.info", "print", "numpy.mean", "numpy.mean", "base_class.BaseRLModel.log_tensorboard", "result.avg_episode_steps.append", "result.avg_attacker_episode_rewards.append", "result.avg_defender_episode_rewards.append", "result.epsilon_values.append", "result.hack_probability.append", "result.cumulative_hack_probabiltiy.append", "result.attacker_cumulative_reward.append", "result.defender_cumulative_reward.append", "result.avg_episode_loss_attacker.append", "result.avg_episode_loss_defender.append", "result.lr_list.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_tensorboard"], ["", "def", "log_metrics", "(", "self", ",", "iteration", ":", "int", ",", "result", ":", "ExperimentResult", ",", "attacker_episode_rewards", ":", "list", ",", "\n", "defender_episode_rewards", ":", "list", ",", "\n", "episode_steps", ":", "list", ",", "episode_avg_attacker_loss", ":", "list", "=", "None", ",", "\n", "episode_avg_defender_loss", ":", "list", "=", "None", ",", "\n", "eval", ":", "bool", "=", "False", ",", "\n", "update_stats", ":", "bool", "=", "True", ",", "lr_attacker", ":", "float", "=", "None", ",", "lr_defender", ":", "float", "=", "None", ",", "\n", "train_attacker", ":", "bool", "=", "False", ",", "\n", "train_defender", ":", "bool", "=", "False", ",", "a_pool", ":", "int", "=", "0", ",", "d_pool", ":", "int", "=", "0", ",", "\n", "total_num_episodes", ":", "int", "=", "0", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Logs average metrics for the last <self.config.log_frequency> episodes\n\n        :param iteration: the training iteration (equivalent to episode if batching is not used)\n        :param result: the result object to add the results to\n        :param attacker_episode_rewards: list of attacker episode rewards for the last <self.config.log_frequency> episodes\n        :param defender_episode_rewards: list of defender episode rewards for the last <self.config.log_frequency> episodes\n        :param episode_steps: list of episode steps for the last <self.config.log_frequency> episodes\n        :param episode_avg_attacker_loss: list of episode attacker loss for the last <self.config.log_frequency> episodes\n        :param episode_avg_defender_loss: list of episode defedner loss for the last <self.config.log_frequency> episodes\n        :param eval: boolean flag whether the metrics are logged in an evaluation context.\n        :param update_stats: boolean flag whether to update stats\n        :param lr_attacker: the learning rate of the attacker\n        :param lr_defender: the learning rate of the defender\n        :param train_attacker: boolean flag indicating whether the attacker is being trained\n        :param train_defender: boolean flag indicating whether the defender is being trained\n        :param a_pool: size of the attacker pool (if using opponent pools)\n        :param d_pool: size of the defender pool (if using opponent pools)\n        :param total_num_episodes: number of training episodes\n        :return: None\n        \"\"\"", "\n", "avg_attacker_episode_rewards", "=", "np", ".", "mean", "(", "attacker_episode_rewards", ")", "\n", "avg_defender_episode_rewards", "=", "np", ".", "mean", "(", "defender_episode_rewards", ")", "\n", "if", "lr_attacker", "is", "None", ":", "\n", "            ", "lr_attacker", "=", "0.0", "\n", "", "if", "lr_defender", "is", "None", ":", "\n", "            ", "lr_defender", "=", "0.0", "\n", "", "if", "not", "eval", "and", "episode_avg_attacker_loss", "is", "not", "None", ":", "\n", "            ", "avg_episode_attacker_loss", "=", "np", ".", "mean", "(", "episode_avg_attacker_loss", ")", "\n", "", "else", ":", "\n", "            ", "avg_episode_attacker_loss", "=", "0.0", "\n", "", "if", "not", "eval", "and", "episode_avg_defender_loss", "is", "not", "None", ":", "\n", "            ", "avg_episode_defender_loss", "=", "np", ".", "mean", "(", "episode_avg_defender_loss", ")", "\n", "", "else", ":", "\n", "            ", "avg_episode_defender_loss", "=", "0.0", "\n", "\n", "", "avg_episode_steps", "=", "np", ".", "mean", "(", "episode_steps", ")", "\n", "hack_probability", "=", "self", ".", "train_hack_probability", "if", "not", "eval", "else", "self", ".", "eval_hack_probability", "\n", "hack_probability_total", "=", "self", ".", "train_cumulative_hack_probability", "if", "not", "eval", "else", "self", ".", "eval_cumulative_hack_probability", "\n", "attacker_cumulative_reward", "=", "self", ".", "env", ".", "envs", "[", "0", "]", ".", "idsgame_env", ".", "state", ".", "attacker_cumulative_reward", "if", "not", "eval", "else", "self", ".", "eval_attacker_cumulative_reward", "\n", "defender_cumulative_reward", "=", "self", ".", "env", ".", "envs", "[", "0", "]", ".", "idsgame_env", ".", "state", ".", "defender_cumulative_reward", "if", "not", "eval", "else", "self", ".", "eval_defender_cumulative_reward", "\n", "if", "eval", ":", "\n", "            ", "log_str", "=", "\"[Eval] iter:{},avg_a_R:{:.2f},avg_d_R:{:.2f},avg_t:{:.2f},avg_h:{:.2f},acc_A_R:{:.2f},\"", "\"acc_D_R:{:.2f},lr_a:{:.4E},lr_d:{:.4E},c_h:{:.2f}\"", ".", "format", "(", "\n", "iteration", ",", "avg_attacker_episode_rewards", ",", "avg_defender_episode_rewards", ",", "avg_episode_steps", ",", "\n", "hack_probability", ",", "\n", "attacker_cumulative_reward", ",", "defender_cumulative_reward", ",", "lr_attacker", ",", "lr_defender", ",", "\n", "hack_probability_total", ")", "\n", "", "else", ":", "\n", "            ", "log_str", "=", "\"[Train] iter: {:.2f} epsilon:{:.2f},avg_a_R:{:.2f},avg_d_R:{:.2f},avg_t:{:.2f},avg_h:{:.2f},acc_A_R:{:.2f},\"", "\"acc_D_R:{:.2f},A_loss:{:.6f},D_loss:{:.6f},lr_a:{:.4E},lr_d:{:.4E},c_h:{:.2f},Tr_A:{},Tr_D:{},\"", "\"a_pool:{},d_pool:{},episode:{}\"", ".", "format", "(", "\n", "iteration", ",", "self", ".", "pg_agent_config", ".", "epsilon", ",", "avg_attacker_episode_rewards", ",", "avg_defender_episode_rewards", ",", "\n", "avg_episode_steps", ",", "hack_probability", ",", "attacker_cumulative_reward", ",", "defender_cumulative_reward", ",", "\n", "avg_episode_attacker_loss", ",", "avg_episode_defender_loss", ",", "lr_attacker", ",", "lr_defender", ",", "hack_probability_total", ",", "\n", "train_attacker", ",", "\n", "train_defender", ",", "a_pool", ",", "d_pool", ",", "total_num_episodes", ")", "\n", "", "self", ".", "pg_agent_config", ".", "logger", ".", "info", "(", "log_str", ")", "\n", "print", "(", "log_str", ")", "\n", "if", "update_stats", "and", "self", ".", "pg_agent_config", ".", "tensorboard", ":", "\n", "            ", "self", ".", "log_tensorboard", "(", "iteration", ",", "avg_attacker_episode_rewards", ",", "avg_defender_episode_rewards", ",", "\n", "avg_episode_steps", ",", "\n", "avg_episode_attacker_loss", ",", "avg_episode_defender_loss", ",", "hack_probability", ",", "\n", "attacker_cumulative_reward", ",", "defender_cumulative_reward", ",", "self", ".", "pg_agent_config", ".", "epsilon", ",", "\n", "lr_attacker", ",", "\n", "lr_defender", ",", "hack_probability_total", ",", "a_pool", ",", "d_pool", ",", "eval", "=", "eval", ")", "\n", "", "if", "update_stats", ":", "\n", "            ", "result", ".", "avg_episode_steps", ".", "append", "(", "avg_episode_steps", ")", "\n", "result", ".", "avg_attacker_episode_rewards", ".", "append", "(", "avg_attacker_episode_rewards", ")", "\n", "result", ".", "avg_defender_episode_rewards", ".", "append", "(", "avg_defender_episode_rewards", ")", "\n", "result", ".", "epsilon_values", ".", "append", "(", "self", ".", "pg_agent_config", ".", "epsilon", ")", "\n", "result", ".", "hack_probability", ".", "append", "(", "hack_probability", ")", "\n", "result", ".", "cumulative_hack_probabiltiy", ".", "append", "(", "hack_probability_total", ")", "\n", "result", ".", "attacker_cumulative_reward", ".", "append", "(", "attacker_cumulative_reward", ")", "\n", "result", ".", "defender_cumulative_reward", ".", "append", "(", "defender_cumulative_reward", ")", "\n", "result", ".", "avg_episode_loss_attacker", ".", "append", "(", "avg_episode_attacker_loss", ")", "\n", "result", ".", "avg_episode_loss_defender", ".", "append", "(", "avg_episode_defender_loss", ")", "\n", "result", ".", "lr_list", ".", "append", "(", "lr_attacker", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.log_tensorboard": [[278, 328], ["base_class.BaseRLModel.tensorboard_writer.add_scalar", "base_class.BaseRLModel.tensorboard_writer.add_scalar", "base_class.BaseRLModel.tensorboard_writer.add_scalar", "base_class.BaseRLModel.tensorboard_writer.add_scalar", "base_class.BaseRLModel.tensorboard_writer.add_scalar", "base_class.BaseRLModel.tensorboard_writer.add_scalar", "base_class.BaseRLModel.tensorboard_writer.add_scalar", "base_class.BaseRLModel.tensorboard_writer.add_scalar", "base_class.BaseRLModel.tensorboard_writer.add_scalar", "base_class.BaseRLModel.tensorboard_writer.add_scalar", "base_class.BaseRLModel.tensorboard_writer.add_scalar", "base_class.BaseRLModel.tensorboard_writer.add_scalar", "base_class.BaseRLModel.tensorboard_writer.add_scalar", "base_class.BaseRLModel.tensorboard_writer.add_scalar"], "methods", ["None"], ["", "", "def", "log_tensorboard", "(", "self", ",", "episode", ":", "int", ",", "avg_attacker_episode_rewards", ":", "float", ",", "avg_defender_episode_rewards", ":", "float", ",", "\n", "avg_episode_steps", ":", "float", ",", "episode_avg_loss_attacker", ":", "float", ",", "episode_avg_loss_defender", ":", "float", ",", "\n", "hack_probability", ":", "float", ",", "attacker_cumulative_reward", ":", "int", ",", "defender_cumulative_reward", ":", "int", ",", "\n", "epsilon", ":", "float", ",", "lr_attacker", ":", "float", ",", "lr_defender", ":", "float", ",", "cumulative_hack_probability", ":", "float", ",", "\n", "a_pool", ":", "int", ",", "d_pool", ":", "int", ",", "eval", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Log metrics to tensorboard\n\n        :param episode: the episode\n        :param avg_attacker_episode_rewards: the average attacker episode reward\n        :param avg_defender_episode_rewards: the average defender episode reward\n        :param avg_episode_steps: the average number of episode steps\n        :param episode_avg_loss_attacker: the average episode loss of the attacker\n        :param episode_avg_loss_defender: the average episode loss of the defender\n        :param hack_probability: the hack probability\n        :param attacker_cumulative_reward: the cumulative attacker reward\n        :param defender_cumulative_reward: the cumulative defender reward\n        :param epsilon: the exploration rate\n        :param lr_attacker: the learning rate of the attacker\n        :param lr_defender: the learning rate of the defender\n        :param cumulative_hack_probability: the cumulative hack probability\n        :param eval: boolean flag whether eval or not\n        :param a_pool: size of the attacker opponent pool\n        :param d_pool: size of the defender opponent pool\n        :return: None\n        \"\"\"", "\n", "train_or_eval", "=", "\"eval\"", "if", "eval", "else", "\"train\"", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'avg_episode_rewards/'", "+", "train_or_eval", "+", "\"/attacker\"", ",", "\n", "avg_attacker_episode_rewards", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'avg_episode_rewards/'", "+", "train_or_eval", "+", "\"/defender\"", ",", "\n", "avg_defender_episode_rewards", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'episode_steps/'", "+", "train_or_eval", ",", "avg_episode_steps", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'episode_avg_loss/'", "+", "train_or_eval", "+", "\"/attacker\"", ",", "episode_avg_loss_attacker", ",", "\n", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'episode_avg_loss/'", "+", "train_or_eval", "+", "\"/defender\"", ",", "episode_avg_loss_defender", ",", "\n", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'hack_probability/'", "+", "train_or_eval", ",", "hack_probability", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'cumulative_hack_probability/'", "+", "train_or_eval", ",", "cumulative_hack_probability", ",", "\n", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'cumulative_reward/attacker/'", "+", "train_or_eval", ",", "\n", "attacker_cumulative_reward", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'cumulative_reward/defender/'", "+", "train_or_eval", ",", "\n", "defender_cumulative_reward", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'epsilon'", ",", "epsilon", ",", "episode", ")", "\n", "if", "self", ".", "pg_agent_config", ".", "opponent_pool", "and", "a_pool", "is", "not", "None", "and", "d_pool", "is", "not", "None", "and", "not", "eval", ":", "\n", "            ", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'opponent_pool_size/attacker'", ",", "a_pool", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'opponent_pool_size/defender'", ",", "d_pool", ",", "episode", ")", "\n", "", "if", "not", "eval", ":", "\n", "            ", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'lr/attacker'", ",", "lr_attacker", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'lr/defender'", ",", "lr_defender", ",", "episode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._setup_model": [[329, 335], ["NotImplementedError"], "methods", ["None"], ["", "", "@", "abstractmethod", "\n", "def", "_setup_model", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Create networks, buffer and optimizers\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._get_eval_env": [[336, 350], ["base_class.BaseRLModel._wrap_env"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._wrap_env"], ["", "def", "_get_eval_env", "(", "self", ",", "eval_env", ":", "Optional", "[", "GymEnv", "]", ")", "->", "Optional", "[", "GymEnv", "]", ":", "\n", "        ", "\"\"\"\n        Return the environment that will be used for evaluation.\n\n        :param eval_env: (Optional[GymEnv]))\n        :return: (Optional[GymEnv])\n        \"\"\"", "\n", "if", "eval_env", "is", "None", ":", "\n", "            ", "eval_env", "=", "self", ".", "eval_env", "\n", "\n", "", "if", "eval_env", "is", "not", "None", ":", "\n", "            ", "eval_env", "=", "self", ".", "_wrap_env", "(", "eval_env", ")", "\n", "assert", "eval_env", ".", "num_envs", "==", "1", "\n", "", "return", "eval_env", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._setup_lr_schedule": [[351, 355], ["gym_idsgame.agents.training_agents.openai_baselines.common.utils.get_schedule_fn", "gym_idsgame.agents.training_agents.openai_baselines.common.utils.get_schedule_fn"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.get_schedule_fn", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.get_schedule_fn"], ["", "def", "_setup_lr_schedule", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"Transform to callable if needed.\"\"\"", "\n", "self", ".", "lr_schedule_a", "=", "get_schedule_fn", "(", "self", ".", "pg_agent_config", ".", "alpha_attacker", ")", "\n", "self", ".", "lr_schedule_d", "=", "get_schedule_fn", "(", "self", ".", "pg_agent_config", ".", "alpha_defender", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._update_current_progress": [[356, 364], ["float", "float"], "methods", ["None"], ["", "def", "_update_current_progress", "(", "self", ",", "num_timesteps", ":", "int", ",", "total_timesteps", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Compute current progress (from 1 to 0)\n\n        :param num_timesteps: current number of timesteps\n        :param total_timesteps:\n        \"\"\"", "\n", "self", ".", "_current_progress", "=", "1.0", "-", "float", "(", "num_timesteps", ")", "/", "float", "(", "total_timesteps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._update_learning_rate": [[365, 384], ["isinstance", "gym_idsgame.agents.training_agents.openai_baselines.common.utils.update_learning_rate", "isinstance", "gym_idsgame.agents.training_agents.openai_baselines.common.utils.update_learning_rate", "base_class.BaseRLModel.lr_schedule_a", "base_class.BaseRLModel.lr_schedule_d"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.update_learning_rate", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.update_learning_rate"], ["", "def", "_update_learning_rate", "(", "self", ",", "optimizers", ":", "Union", "[", "List", "[", "th", ".", "optim", ".", "Optimizer", "]", ",", "th", ".", "optim", ".", "Optimizer", "]", ",", "attacker", "=", "True", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Update the optimizers learning rate using the current learning rate schedule\n        and the current progress (from 1 to 0).\n\n        :param optimizers: (Union[List[th.optim.Optimizer], th.optim.Optimizer])\n            An optimizer or a list of optimizers.\n        \"\"\"", "\n", "# Log the current learning rate", "\n", "if", "attacker", ":", "\n", "            ", "if", "not", "isinstance", "(", "optimizers", ",", "list", ")", ":", "\n", "                ", "optimizers", "=", "[", "optimizers", "]", "\n", "", "for", "optimizer", "in", "optimizers", ":", "\n", "                ", "update_learning_rate", "(", "optimizer", ",", "self", ".", "lr_schedule_a", "(", "self", ".", "_current_progress", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "not", "isinstance", "(", "optimizers", ",", "list", ")", ":", "\n", "                ", "optimizers", "=", "[", "optimizers", "]", "\n", "", "for", "optimizer", "in", "optimizers", ":", "\n", "                ", "update_learning_rate", "(", "optimizer", ",", "self", ".", "lr_schedule_d", "(", "self", ".", "_current_progress", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.safe_mean": [[386, 396], ["numpy.mean", "len"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "safe_mean", "(", "arr", ":", "Union", "[", "np", ".", "ndarray", ",", "list", ",", "deque", "]", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Compute the mean of an array if there is at least one element.\n        For empty array, return NaN. It is used for logging only.\n\n        :param arr:\n        :return:\n        \"\"\"", "\n", "return", "np", ".", "nan", "if", "len", "(", "arr", ")", "==", "0", "else", "np", ".", "mean", "(", "arr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.get_env": [[397, 404], ["None"], "methods", ["None"], ["", "def", "get_env", "(", "self", ")", "->", "Optional", "[", "VecEnv", "]", ":", "\n", "        ", "\"\"\"\n        Returns the current environment (can be None if not defined).\n\n        :return: (Optional[VecEnv]) The current environment\n        \"\"\"", "\n", "return", "self", ".", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.get_vec_normalize_env": [[405, 412], ["None"], "methods", ["None"], ["", "def", "get_vec_normalize_env", "(", "self", ")", "->", "Optional", "[", "VecNormalize", "]", ":", "\n", "        ", "\"\"\"\n        Return the ``VecNormalize`` wrapper of the training env\n        if it exists.\n        :return: Optional[VecNormalize] The ``VecNormalize`` env.\n        \"\"\"", "\n", "return", "self", ".", "_vec_normalize_env", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.check_env": [[413, 443], ["ValueError", "ValueError", "ValueError", "ValueError", "stable_baselines3.common.preprocessing.is_image_space", "stable_baselines3.common.preprocessing.is_image_space", "gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.vec_transpose.VecTransposeImage.transpose_space", "gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.vec_transpose.VecTransposeImage.transpose_space"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_transpose.VecTransposeImage.transpose_space", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_transpose.VecTransposeImage.transpose_space"], ["", "@", "staticmethod", "\n", "def", "check_env", "(", "env", ":", "GymEnv", ",", "attacker_observation_space", ":", "gym", ".", "spaces", ".", "Space", ",", "attacker_action_space", ":", "gym", ".", "spaces", ".", "Space", ",", "\n", "defender_observation_space", ":", "gym", ".", "spaces", ".", "Space", ",", "defender_action_space", ":", "gym", ".", "spaces", ".", "Space", ")", ":", "\n", "        ", "\"\"\"\n        Checks the validity of the environment to load vs the one used for training.\n        Checked parameters:\n        - observation_space\n        - action_space\n\n        :param env: (GymEnv)\n        :param attacker_observation_space: (gym.spaces.Space)\n        :param attacker_action_space: (gym.spaces.Space)\n        \"\"\"", "\n", "if", "(", "attacker_observation_space", "!=", "env", ".", "attacker_observation_space", "\n", "# Special cases for images that need to be transposed", "\n", "and", "not", "(", "is_image_space", "(", "env", ".", "attacker_observation_space", ")", "\n", "and", "attacker_observation_space", "==", "VecTransposeImage", ".", "transpose_space", "(", "env", ".", "attacker_observation_space", ")", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "f'Observation spaces do not match: {attacker_observation_space} != {env.attacker_observation_space}'", ")", "\n", "", "if", "attacker_action_space", "!=", "env", ".", "attacker_action_space", ":", "\n", "            ", "raise", "ValueError", "(", "f'Action spaces do not match: {attacker_action_space} != {env.attacker_action_space}'", ")", "\n", "\n", "", "if", "(", "defender_observation_space", "!=", "env", ".", "defender_observation_space", "\n", "# Special cases for images that need to be transposed", "\n", "and", "not", "(", "is_image_space", "(", "env", ".", "defender_observation_space", ")", "\n", "and", "defender_observation_space", "==", "VecTransposeImage", ".", "transpose_space", "(", "\n", "env", ".", "defender_observation_space", ")", ")", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f'Observation spaces do not match: {defender_observation_space} != {env.defender_observation_space}'", ")", "\n", "", "if", "defender_action_space", "!=", "env", ".", "defender_action_space", ":", "\n", "            ", "raise", "ValueError", "(", "f'Action spaces do not match: {defender_action_space} != {env.defender_action_space}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.set_env": [[444, 462], ["base_class.BaseRLModel.check_env", "base_class.BaseRLModel._wrap_env"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.check_env", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._wrap_env"], ["", "", "def", "set_env", "(", "self", ",", "env", ":", "GymEnv", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Checks the validity of the environment, and if it is coherent, set it as the current environment.\n        Furthermore wrap any non vectorized env into a vectorized\n        checked parameters:\n        - observation_space\n        - action_space\n\n        :param env: The environment for learning a policy\n        \"\"\"", "\n", "self", ".", "check_env", "(", "env", ",", "self", ".", "attacker_observation_space", ",", "self", ".", "attacker_action_space", ",", "\n", "self", ".", "defender_observation_space", ",", "self", ".", "defender_action_space", ")", "\n", "# it must be coherent now", "\n", "# if it is not a VecEnv, make it a VecEnv", "\n", "env", "=", "self", ".", "_wrap_env", "(", "env", ")", "\n", "\n", "self", ".", "n_envs", "=", "env", ".", "num_envs", "\n", "self", ".", "env", "=", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.get_torch_variables": [[463, 483], ["None"], "methods", ["None"], ["", "def", "get_torch_variables", "(", "self", ",", "attacker", ":", "bool", "=", "True", ")", "->", "Tuple", "[", "List", "[", "str", "]", ",", "List", "[", "str", "]", "]", ":", "\n", "        ", "\"\"\"\n        Get the name of the torch variable that will be saved.\n        ``th.save`` and ``th.load`` will be used with the right device\n        instead of the default pickling strategy.\n\n        :return: (Tuple[List[str], List[str]])\n            name of the variables with state dicts to save, name of additional torch tensors,\n        \"\"\"", "\n", "if", "attacker", ":", "\n", "            ", "if", "not", "self", ".", "pg_agent_config", ".", "ar_policy", ":", "\n", "                ", "state_dicts", "=", "[", "\"attacker_policy\"", "]", "\n", "", "else", ":", "\n", "                ", "state_dicts", "=", "[", "\"attacker_node_policy\"", ",", "\"attacker_at_policy\"", "]", "\n", "", "", "else", ":", "\n", "            ", "if", "not", "self", ".", "pg_agent_config", ".", "ar_policy", ":", "\n", "                ", "state_dicts", "=", "[", "\"defender_policy\"", "]", "\n", "", "else", ":", "\n", "                ", "state_dicts", "=", "[", "\"defender_node_policy\"", ",", "\"defender_at_policy\"", "]", "\n", "", "", "return", "state_dicts", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.learn": [[484, 511], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "learn", "(", "self", ",", "total_timesteps", ":", "int", ",", "\n", "callback", ":", "MaybeCallback", "=", "None", ",", "\n", "log_interval", ":", "int", "=", "100", ",", "\n", "tb_log_name", ":", "str", "=", "\"run\"", ",", "\n", "eval_env", ":", "Optional", "[", "GymEnv", "]", "=", "None", ",", "\n", "eval_freq", ":", "int", "=", "-", "1", ",", "\n", "n_eval_episodes", ":", "int", "=", "5", ",", "\n", "eval_log_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "reset_num_timesteps", ":", "bool", "=", "True", ")", "->", "'BaseRLModel'", ":", "\n", "        ", "\"\"\"\n        Return a trained model.\n\n        :param total_timesteps: (int) The total number of samples to train on\n        :param callback: (function (dict, dict)) -> boolean function called at every steps with state of the algorithm.\n            It takes the local and global variables. If it returns False, training is aborted.\n        :param log_interval: (int) The number of timesteps before logging.\n        :param tb_log_name: (str) the name of the run for tensorboard log\n        :param reset_num_timesteps: (bool) whether or not to reset the current timestep number (used in logging)\n        :param eval_env: (gym.Env) Environment that will be used to evaluate the agent\n        :param eval_freq: (int) Evaluate the agent every ``eval_freq`` timesteps (this may vary a little)\n        :param n_eval_episodes: (int) Number of episode to evaluate the agent\n        :param eval_log_path: (Optional[str]) Path to a folder where the evaluations will be saved\n        :param reset_num_timesteps: (bool)\n        :return: (BaseRLModel) the trained model\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.load": [[512, 569], ["cls._load_from_file", "cls", "cls.__dict__.update", "cls.__dict__.update", "cls._setup_model", "ValueError", "NotImplementedError", "stable_baselines3.common.save_util.recursive_getattr", "stable_baselines3.common.save_util.recursive_getattr.load_state_dict", "str", "hasattr", "len", "stable_baselines3.common.save_util.recursive_setattr"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._load_from_file", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.OffPolicyRLModel._setup_model"], ["", "@", "classmethod", "\n", "def", "load", "(", "cls", ",", "load_path", ":", "str", ",", "env", ":", "Optional", "[", "GymEnv", "]", "=", "None", ",", "policy_class", "=", "None", ",", "\n", "pg_agent_config", ":", "PolicyGradientAgentConfig", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Load the model from a zip-file\n\n        :param load_path: the location of the saved data\n        :param env: the new environment to run the loaded model on\n            (can be None if you only need prediction from a trained model) has priority over any saved environment\n        :param kwargs: extra arguments to change the model when loading\n        \"\"\"", "\n", "data", ",", "params", ",", "tensors", "=", "cls", ".", "_load_from_file", "(", "load_path", ",", "pg_agent_config", "=", "pg_agent_config", ")", "\n", "\n", "if", "'policy_kwargs'", "in", "data", ":", "\n", "            ", "for", "arg_to_remove", "in", "[", "'device'", "]", ":", "\n", "                ", "if", "arg_to_remove", "in", "data", "[", "'policy_kwargs'", "]", ":", "\n", "                    ", "del", "data", "[", "'policy_kwargs'", "]", "[", "arg_to_remove", "]", "\n", "\n", "", "", "", "if", "'policy_kwargs'", "in", "kwargs", "and", "kwargs", "[", "'policy_kwargs'", "]", "!=", "data", "[", "'policy_kwargs'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "f\"The specified policy kwargs do not equal the stored policy kwargs.\"", "\n", "f\"Stored kwargs: {data['policy_kwargs']}, specified kwargs: {kwargs['policy_kwargs']}\"", ")", "\n", "\n", "# check if observation space and action space are part of the saved parameters", "\n", "# if (\"observation_space\" not in data or \"action_space\" not in data) and \"env\" not in data:", "\n", "#     raise ValueError(\"The observation_space and action_space was not given, can't verify new environments\")", "\n", "# check if given env is valid", "\n", "# if env is not None:", "\n", "#     cls.check_env(env, data[\"observation_space\"], data[\"action_space\"])", "\n", "# if no new env was given use stored env if possible", "\n", "", "if", "env", "is", "None", "and", "\"env\"", "in", "data", ":", "\n", "            ", "env", "=", "data", "[", "\"env\"", "]", "\n", "\n", "#print(\"data:{}\".format(data.keys()))", "\n", "# noinspection PyArgumentList", "\n", "", "device", "=", "\"cpu\"", "if", "not", "pg_agent_config", ".", "gpu", "else", "\"cuda:\"", "+", "str", "(", "pg_agent_config", ".", "gpu_id", ")", "\n", "model", "=", "cls", "(", "env", ",", "policy_class", ",", "device", "=", "device", ",", "_init_setup_model", "=", "False", ",", "pg_agent_config", "=", "pg_agent_config", ")", "\n", "\n", "# load parameters", "\n", "model", ".", "__dict__", ".", "update", "(", "data", ")", "\n", "model", ".", "__dict__", ".", "update", "(", "kwargs", ")", "\n", "if", "not", "hasattr", "(", "model", ",", "\"_setup_model\"", ")", "and", "len", "(", "params", ")", ">", "0", ":", "\n", "            ", "raise", "NotImplementedError", "(", "f\"{cls} has no ``_setup_model()`` method\"", ")", "\n", "", "model", ".", "device", "=", "device", "\n", "model", ".", "pg_agent_config", ".", "gpu", "=", "pg_agent_config", ".", "gpu", "\n", "model", ".", "_setup_model", "(", ")", "\n", "\n", "# put state_dicts back in place", "\n", "for", "name", "in", "params", ":", "\n", "            ", "attr", "=", "recursive_getattr", "(", "model", ",", "name", ")", "\n", "attr", ".", "load_state_dict", "(", "params", "[", "name", "]", ")", "\n", "\n", "# put tensors back in place", "\n", "", "if", "tensors", "is", "not", "None", ":", "\n", "            ", "for", "name", "in", "tensors", ":", "\n", "                ", "recursive_setattr", "(", "model", ",", "name", ",", "tensors", "[", "name", "]", ")", "\n", "\n", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._load_from_file": [[570, 642], ["isinstance", "gym_idsgame.agents.training_agents.openai_baselines.common.utils.get_device", "os.path.exists", "os.path.exists", "zipfile.ZipFile", "archive.namelist", "ValueError", "ValueError", "archive.read().decode", "stable_baselines3.common.save_util.json_to_data", "len", "archive.open", "io.BytesIO", "io.BytesIO.write", "io.BytesIO.seek", "torch.load", "archive.read", "tensor_file.read", "archive.open", "io.BytesIO", "io.BytesIO.write", "io.BytesIO.seek", "torch.load", "opt_param_file.read", "os.path.splitext", "os.path.splitext"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.get_device", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load"], ["", "@", "staticmethod", "\n", "def", "_load_from_file", "(", "load_path", ":", "str", ",", "load_data", ":", "bool", "=", "True", ",", "pg_agent_config", ":", "PolicyGradientAgentConfig", "=", "None", ")", "->", "(", "Tuple", "[", "Optional", "[", "Dict", "[", "str", ",", "Any", "]", "]", ",", "\n", "Optional", "[", "TensorDict", "]", ",", "\n", "Optional", "[", "TensorDict", "]", "]", ")", ":", "\n", "        ", "\"\"\" Load model data from a .zip archive\n\n        :param load_path: Where to load the model from\n        :param load_data: Whether we should load and return data\n            (class parameters). Mainly used by 'load_parameters' to only load model parameters (weights)\n        :return: (dict),(dict),(dict) Class parameters, model state_dicts (dict of state_dict)\n            and dict of extra tensors\n        \"\"\"", "\n", "# Check if file exists if load_path is a string", "\n", "if", "isinstance", "(", "load_path", ",", "str", ")", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "load_path", ")", ":", "\n", "                ", "if", "os", ".", "path", ".", "exists", "(", "load_path", "+", "\".zip\"", ")", ":", "\n", "                    ", "load_path", "+=", "\".zip\"", "\n", "", "else", ":", "\n", "                    ", "raise", "ValueError", "(", "f\"Error: the file {load_path} could not be found\"", ")", "\n", "\n", "# set device to cpu if cuda is not available", "\n", "", "", "", "device", "=", "get_device", "(", "None", ",", "pg_agent_config", ")", "\n", "\n", "# Open the zip archive and load data", "\n", "try", ":", "\n", "            ", "with", "zipfile", ".", "ZipFile", "(", "load_path", ",", "\"r\"", ")", "as", "archive", ":", "\n", "                ", "namelist", "=", "archive", ".", "namelist", "(", ")", "\n", "# If data or parameters is not in the", "\n", "# zip archive, assume they were stored", "\n", "# as None (_save_to_file_zip allows this).", "\n", "data", "=", "None", "\n", "tensors", "=", "None", "\n", "params", "=", "{", "}", "\n", "\n", "if", "\"data\"", "in", "namelist", "and", "load_data", ":", "\n", "# Load class parameters and convert to string", "\n", "                    ", "json_data", "=", "archive", ".", "read", "(", "\"data\"", ")", ".", "decode", "(", ")", "\n", "data", "=", "json_to_data", "(", "json_data", ")", "\n", "\n", "", "if", "\"tensors.pth\"", "in", "namelist", "and", "load_data", ":", "\n", "# Load extra tensors", "\n", "                    ", "with", "archive", ".", "open", "(", "'tensors.pth'", ",", "mode", "=", "\"r\"", ")", "as", "tensor_file", ":", "\n", "# File has to be seekable, but opt_param_file is not, so load in BytesIO first", "\n", "# fixed in python >= 3.7", "\n", "                        ", "file_content", "=", "io", ".", "BytesIO", "(", ")", "\n", "file_content", ".", "write", "(", "tensor_file", ".", "read", "(", ")", ")", "\n", "# go to start of file", "\n", "file_content", ".", "seek", "(", "0", ")", "\n", "# load the parameters with the right ``map_location``", "\n", "tensors", "=", "th", ".", "load", "(", "file_content", ",", "map_location", "=", "device", ")", "\n", "\n", "# check for all other .pth files", "\n", "", "", "other_files", "=", "[", "file_name", "for", "file_name", "in", "namelist", "if", "\n", "os", ".", "path", ".", "splitext", "(", "file_name", ")", "[", "1", "]", "==", "\".pth\"", "and", "file_name", "!=", "\"tensors.pth\"", "]", "\n", "# if there are any other files which end with .pth and aren't \"params.pth\"", "\n", "# assume that they each are optimizer parameters", "\n", "if", "len", "(", "other_files", ")", ">", "0", ":", "\n", "                    ", "for", "file_path", "in", "other_files", ":", "\n", "                        ", "with", "archive", ".", "open", "(", "file_path", ",", "mode", "=", "\"r\"", ")", "as", "opt_param_file", ":", "\n", "# File has to be seekable, but opt_param_file is not, so load in BytesIO first", "\n", "# fixed in python >= 3.7", "\n", "                            ", "file_content", "=", "io", ".", "BytesIO", "(", ")", "\n", "file_content", ".", "write", "(", "opt_param_file", ".", "read", "(", ")", ")", "\n", "# go to start of file", "\n", "file_content", ".", "seek", "(", "0", ")", "\n", "# load the parameters with the right ``map_location``", "\n", "params", "[", "os", ".", "path", ".", "splitext", "(", "file_path", ")", "[", "0", "]", "]", "=", "th", ".", "load", "(", "file_content", ",", "map_location", "=", "device", ")", "\n", "\n", "", "", "", "", "", "except", "zipfile", ".", "BadZipFile", ":", "\n", "# load_path wasn't a zip file", "\n", "            ", "raise", "ValueError", "(", "f\"Error: the file {load_path} wasn't a zip-file\"", ")", "\n", "", "return", "data", ",", "params", ",", "tensors", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.set_random_seed": [[643, 658], ["gym_idsgame.agents.training_agents.openai_baselines.common.utils.set_random_seed", "base_class.BaseRLModel.attacker_action_space.seed", "base_class.BaseRLModel.env.seed", "base_class.BaseRLModel.eval_env.seed", "torch.device"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.set_random_seed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.seed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.seed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.seed"], ["", "def", "set_random_seed", "(", "self", ",", "seed", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Set the seed of the pseudo-random generators\n        (python, numpy, pytorch, gym, action_space)\n\n        :param seed: (int)\n        \"\"\"", "\n", "if", "seed", "is", "None", ":", "\n", "            ", "return", "\n", "", "set_random_seed", "(", "seed", ",", "using_cuda", "=", "self", ".", "device", "==", "th", ".", "device", "(", "'cuda'", ")", ")", "\n", "self", ".", "attacker_action_space", ".", "seed", "(", "seed", ")", "\n", "if", "self", ".", "env", "is", "not", "None", ":", "\n", "            ", "self", ".", "env", ".", "seed", "(", "seed", ")", "\n", "", "if", "self", ".", "eval_env", "is", "not", "None", ":", "\n", "            ", "self", ".", "eval_env", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._init_callback": [[659, 689], ["isinstance", "gym_idsgame.agents.training_agents.openai_baselines.common.callbacks.CallbackList.init_callback", "gym_idsgame.agents.training_agents.openai_baselines.common.callbacks.CallbackList", "isinstance", "gym_idsgame.agents.training_agents.openai_baselines.common.callbacks.ConvertCallback", "gym_idsgame.agents.training_agents.openai_baselines.common.callbacks.EvalCallback", "gym_idsgame.agents.training_agents.openai_baselines.common.callbacks.CallbackList"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.EventCallback.init_callback"], ["", "", "def", "_init_callback", "(", "self", ",", "\n", "callback", ":", "Union", "[", "None", ",", "Callable", ",", "List", "[", "BaseCallback", "]", ",", "BaseCallback", "]", ",", "\n", "eval_env", ":", "Optional", "[", "VecEnv", "]", "=", "None", ",", "\n", "eval_freq", ":", "int", "=", "10000", ",", "\n", "n_eval_episodes", ":", "int", "=", "5", ",", "\n", "log_path", ":", "Optional", "[", "str", "]", "=", "None", ")", "->", "BaseCallback", ":", "\n", "        ", "\"\"\"\n        :param callback: (Union[callable, [BaseCallback], BaseCallback, None])\n        :return: (BaseCallback)\n        \"\"\"", "\n", "# Convert a list of callbacks into a callback", "\n", "if", "isinstance", "(", "callback", ",", "list", ")", ":", "\n", "            ", "callback", "=", "CallbackList", "(", "callback", ")", "\n", "\n", "# Convert functional callback to object", "\n", "", "if", "not", "isinstance", "(", "callback", ",", "BaseCallback", ")", ":", "\n", "            ", "callback", "=", "ConvertCallback", "(", "callback", ")", "\n", "\n", "# Create eval callback in charge of the evaluation", "\n", "", "if", "eval_env", "is", "not", "None", ":", "\n", "            ", "eval_callback", "=", "EvalCallback", "(", "eval_env", ",", "\n", "best_model_save_path", "=", "log_path", ",", "\n", "log_path", "=", "log_path", ",", "eval_freq", "=", "eval_freq", ",", "n_eval_episodes", "=", "n_eval_episodes", ",", "\n", "render", "=", "self", ".", "pg_agent_config", ".", "eval_render", ",", "\n", "deterministic", "=", "False", ",", "\n", "pg_agent_config", "=", "self", ".", "pg_agent_config", ")", "\n", "callback", "=", "CallbackList", "(", "[", "callback", ",", "eval_callback", "]", ")", "\n", "\n", "", "callback", ".", "init_callback", "(", "self", ")", "\n", "return", "callback", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._setup_learn": [[690, 760], ["time.time", "collections.deque", "collections.deque", "base_class.BaseRLModel._get_eval_env", "base_class.BaseRLModel._init_callback", "base_class.BaseRLModel.action_noise.reset", "base_class.BaseRLModel.seed", "base_class.BaseRLModel.env.reset", "base_class.BaseRLModel.env.reset", "base_class.BaseRLModel._vec_normalize_env.get_original_obs", "base_class.BaseRLModel._vec_normalize_env.get_original_obs"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._get_eval_env", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.EvalCallback._init_callback", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.seed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.get_original_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.get_original_obs"], ["", "def", "_setup_learn", "(", "self", ",", "\n", "eval_env", ":", "Optional", "[", "GymEnv", "]", ",", "\n", "callback", ":", "Union", "[", "None", ",", "Callable", ",", "List", "[", "BaseCallback", "]", ",", "BaseCallback", "]", "=", "None", ",", "\n", "eval_freq", ":", "int", "=", "10000", ",", "\n", "n_eval_episodes", ":", "int", "=", "5", ",", "\n", "log_path", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "reset_num_timesteps", ":", "bool", "=", "True", ",", "\n", ")", "->", "'BaseCallback'", ":", "\n", "        ", "\"\"\"\n        Initialize different variables needed for training.\n\n        :param eval_env: (Optional[GymEnv])\n        :param callback: (Union[None, BaseCallback, List[BaseCallback, Callable]])\n        :param eval_freq: (int)\n        :param n_eval_episodes: (int)\n        :param log_path (Optional[str]): Path to a log folder\n        :param reset_num_timesteps: (bool) Whether to reset or not the ``num_timesteps`` attribute\n        :return: (BaseCallback)\n        \"\"\"", "\n", "self", ".", "start_time", "=", "time", ".", "time", "(", ")", "\n", "self", ".", "ep_info_buffer", "=", "deque", "(", "maxlen", "=", "100", ")", "\n", "self", ".", "ep_success_buffer", "=", "deque", "(", "maxlen", "=", "100", ")", "\n", "\n", "if", "self", ".", "action_noise", "is", "not", "None", ":", "\n", "            ", "self", ".", "action_noise", ".", "reset", "(", ")", "\n", "\n", "", "if", "reset_num_timesteps", ":", "\n", "            ", "self", ".", "num_timesteps", "=", "0", "\n", "self", ".", "_episode_num", "=", "0", "\n", "\n", "# Avoid resetting the environment when calling ``.learn()`` consecutive times", "\n", "", "if", "not", "self", ".", "pg_agent_config", ".", "multi_channel_obs", ":", "\n", "            ", "if", "reset_num_timesteps", "or", "self", ".", "_last_obs_a", "is", "None", ":", "\n", "                ", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "a_obs", "=", "obs", "[", "0", "]", "\n", "d_obs", "=", "obs", "[", "1", "]", "\n", "self", ".", "_last_obs_a", "=", "a_obs", "\n", "self", ".", "_last_obs_d", "=", "d_obs", "\n", "# Retrieve unnormalized observation for saving into the buffer", "\n", "if", "self", ".", "_vec_normalize_env", "is", "not", "None", ":", "\n", "                    ", "self", ".", "_last_original_obs", "=", "self", ".", "_vec_normalize_env", ".", "get_original_obs", "(", ")", "\n", "", "", "", "else", ":", "\n", "            ", "if", "reset_num_timesteps", "or", "self", ".", "_last_obs_a_a", "is", "None", ":", "\n", "                ", "obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "a_obs", "=", "obs", "[", "0", "]", "\n", "a_obs_a", "=", "a_obs", "[", "0", "]", "\n", "a_obs_d", "=", "a_obs", "[", "1", "]", "\n", "a_obs_p", "=", "a_obs", "[", "2", "]", "\n", "a_obs_r", "=", "a_obs", "[", "3", "]", "\n", "a_obs", "=", "a_obs", "[", "4", "]", "\n", "d_obs", "=", "obs", "[", "1", "]", "\n", "self", ".", "_last_obs_a", "=", "a_obs", "\n", "self", ".", "_last_obs_a_a", "=", "a_obs_a", "\n", "self", ".", "_last_obs_a_d", "=", "a_obs_d", "\n", "self", ".", "_last_obs_a_p", "=", "a_obs_p", "\n", "self", ".", "_last_obs_a_r", "=", "a_obs_r", "\n", "self", ".", "_last_obs_d", "=", "d_obs", "\n", "# Retrieve unnormalized observation for saving into the buffer", "\n", "if", "self", ".", "_vec_normalize_env", "is", "not", "None", ":", "\n", "                    ", "self", ".", "_last_original_obs", "=", "self", ".", "_vec_normalize_env", ".", "get_original_obs", "(", ")", "\n", "\n", "", "", "", "if", "eval_env", "is", "not", "None", "and", "self", ".", "seed", "is", "not", "None", ":", "\n", "            ", "eval_env", ".", "seed", "(", "self", ".", "seed", ")", "\n", "\n", "", "eval_env", "=", "self", ".", "_get_eval_env", "(", "eval_env", ")", "\n", "\n", "# Create eval callback if needed", "\n", "callback", "=", "self", ".", "_init_callback", "(", "callback", ",", "eval_env", ",", "eval_freq", ",", "n_eval_episodes", ",", "log_path", ")", "\n", "\n", "return", "callback", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._update_info_buffer": [[761, 777], ["enumerate", "numpy.array", "info.get", "info.get", "base_class.BaseRLModel.ep_info_buffer.extend", "base_class.BaseRLModel.ep_success_buffer.append", "len"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.get", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.get", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer.extend"], ["", "def", "_update_info_buffer", "(", "self", ",", "infos", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", ",", "dones", ":", "Optional", "[", "np", ".", "ndarray", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Retrieve reward and episode length and update the buffer\n        if using Monitor wrapper.\n\n        :param infos: ([dict])\n        \"\"\"", "\n", "if", "dones", "is", "None", ":", "\n", "            ", "dones", "=", "np", ".", "array", "(", "[", "False", "]", "*", "len", "(", "infos", ")", ")", "\n", "", "for", "idx", ",", "info", "in", "enumerate", "(", "infos", ")", ":", "\n", "            ", "maybe_ep_info", "=", "info", ".", "get", "(", "'episode'", ")", "\n", "maybe_is_success", "=", "info", ".", "get", "(", "'is_success'", ")", "\n", "if", "maybe_ep_info", "is", "not", "None", ":", "\n", "                ", "self", ".", "ep_info_buffer", ".", "extend", "(", "[", "maybe_ep_info", "]", ")", "\n", "", "if", "maybe_is_success", "is", "not", "None", "and", "dones", "[", "idx", "]", ":", "\n", "                ", "self", ".", "ep_success_buffer", ".", "append", "(", "maybe_is_success", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._save_to_file_zip": [[778, 816], ["isinstance", "stable_baselines3.common.save_util.data_to_json", "os.path.splitext", "zipfile.ZipFile", "archive.writestr", "params.items", "archive.open", "torch.save", "archive.open", "torch.save"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save"], ["", "", "", "@", "staticmethod", "\n", "def", "_save_to_file_zip", "(", "save_path", ":", "str", ",", "data", ":", "Dict", "[", "str", ",", "Any", "]", "=", "None", ",", "\n", "params", ":", "Dict", "[", "str", ",", "Any", "]", "=", "None", ",", "tensors", ":", "Dict", "[", "str", ",", "Any", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Save model to a zip archive.\n\n        :param save_path: Where to store the model\n        :param data: Class parameters being stored\n        :param params: Model parameters being stored expected to contain an entry for every\n                       state_dict with its name and the state_dict\n        :param tensors: Extra tensor variables expected to contain name and value of tensors\n        \"\"\"", "\n", "\n", "# data/params can be None, so do not", "\n", "# try to serialize them blindly", "\n", "if", "data", "is", "not", "None", ":", "\n", "            ", "serialized_data", "=", "data_to_json", "(", "data", ")", "\n", "\n", "# Check postfix if save_path is a string", "\n", "", "if", "isinstance", "(", "save_path", ",", "str", ")", ":", "\n", "            ", "_", ",", "ext", "=", "os", ".", "path", ".", "splitext", "(", "save_path", ")", "\n", "if", "ext", "==", "\"\"", ":", "\n", "                ", "save_path", "+=", "\".zip\"", "\n", "\n", "# Create a zip-archive and write our objects", "\n", "# there. This works when save_path is either", "\n", "# str or a file-like", "\n", "", "", "with", "zipfile", ".", "ZipFile", "(", "save_path", ",", "\"w\"", ")", "as", "archive", ":", "\n", "# Do not try to save \"None\" elements", "\n", "            ", "if", "data", "is", "not", "None", ":", "\n", "                ", "archive", ".", "writestr", "(", "\"data\"", ",", "serialized_data", ")", "\n", "", "if", "tensors", "is", "not", "None", ":", "\n", "                ", "with", "archive", ".", "open", "(", "'tensors.pth'", ",", "mode", "=", "\"w\"", ")", "as", "tensors_file", ":", "\n", "                    ", "th", ".", "save", "(", "tensors", ",", "tensors_file", ")", "\n", "", "", "if", "params", "is", "not", "None", ":", "\n", "                ", "for", "file_name", ",", "dict_", "in", "params", ".", "items", "(", ")", ":", "\n", "                    ", "with", "archive", ".", "open", "(", "file_name", "+", "'.pth'", ",", "mode", "=", "\"w\"", ")", "as", "param_file", ":", "\n", "                        ", "th", ".", "save", "(", "dict_", ",", "param_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.excluded_save_params": [[817, 825], ["None"], "methods", ["None"], ["", "", "", "", "", "def", "excluded_save_params", "(", "self", ")", "->", "List", "[", "str", "]", ":", "\n", "        ", "\"\"\"\n        Returns the names of the parameters that should be excluded by default\n        when saving the model.\n\n        :return: ([str]) List of parameters that should be excluded from save\n        \"\"\"", "\n", "return", "[", "\"policy\"", ",", "\"device\"", ",", "\"env\"", ",", "\"eval_env\"", ",", "\"replay_buffer\"", ",", "\"rollout_buffer\"", ",", "\"_vec_normalize_env\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.save": [[826, 877], ["base_class.BaseRLModel.__dict__.copy", "base_class.BaseRLModel.get_torch_variables", "base_class.BaseRLModel._save_to_file_zip", "base_class.BaseRLModel.excluded_save_params", "base_class.BaseRLModel.extend", "base_class.BaseRLModel.append", "stable_baselines3.common.save_util.recursive_getattr", "stable_baselines3.common.save_util.recursive_getattr.state_dict", "torch_var.split", "base_class.BaseRLModel.pop", "stable_baselines3.common.save_util.recursive_getattr", "base_class.BaseRLModel.excluded_save_params"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.get_torch_variables", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._save_to_file_zip", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.excluded_save_params", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer.extend", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.excluded_save_params"], ["", "def", "save", "(", "self", ",", "path", ":", "str", ",", "exclude", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "include", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", ",", "\n", "attacker", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Save all the attributes of the object and the model parameters in a zip-file.\n\n        :param path: path to the file where the rl agent should be saved\n        :param exclude: name of parameters that should be excluded in addition to the default one\n        :param include: name of parameters that might be excluded but should be included anyway\n        \"\"\"", "\n", "# copy parameter list so we don't mutate the original dict", "\n", "data", "=", "self", ".", "__dict__", ".", "copy", "(", ")", "\n", "# use standard list of excluded parameters if none given", "\n", "if", "exclude", "is", "None", ":", "\n", "            ", "exclude", "=", "self", ".", "excluded_save_params", "(", ")", "\n", "", "else", ":", "\n", "# append standard exclude params to the given params", "\n", "            ", "exclude", ".", "extend", "(", "[", "param", "for", "param", "in", "self", ".", "excluded_save_params", "(", ")", "if", "param", "not", "in", "exclude", "]", ")", "\n", "\n", "# do not exclude params if they are specifically included", "\n", "", "if", "include", "is", "not", "None", ":", "\n", "            ", "exclude", "=", "[", "param_name", "for", "param_name", "in", "exclude", "if", "param_name", "not", "in", "include", "]", "\n", "\n", "", "state_dicts_names", ",", "tensors_names", "=", "self", ".", "get_torch_variables", "(", "attacker", "=", "attacker", ")", "\n", "# any params that are in the save vars must not be saved by data", "\n", "torch_variables", "=", "state_dicts_names", "+", "tensors_names", "\n", "for", "torch_var", "in", "torch_variables", ":", "\n", "# we need to get only the name of the top most module as we'll remove that", "\n", "            ", "var_name", "=", "torch_var", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "exclude", ".", "append", "(", "var_name", ")", "\n", "\n", "# Remove parameter entries of parameters which are to be excluded", "\n", "", "for", "param_name", "in", "exclude", ":", "\n", "            ", "if", "param_name", "in", "data", ":", "\n", "                ", "data", ".", "pop", "(", "param_name", ",", "None", ")", "\n", "\n", "# Build dict of tensor variables", "\n", "", "", "tensors", "=", "None", "\n", "if", "tensors_names", "is", "not", "None", ":", "\n", "            ", "tensors", "=", "{", "}", "\n", "for", "name", "in", "tensors_names", ":", "\n", "                ", "attr", "=", "recursive_getattr", "(", "self", ",", "name", ")", "\n", "tensors", "[", "name", "]", "=", "attr", "\n", "\n", "# Build dict of state_dicts", "\n", "", "", "params_to_save", "=", "{", "}", "\n", "for", "name", "in", "state_dicts_names", ":", "\n", "            ", "attr", "=", "recursive_getattr", "(", "self", ",", "name", ")", "\n", "# Retrieve state dict", "\n", "params_to_save", "[", "name", "]", "=", "attr", ".", "state_dict", "(", ")", "\n", "\n", "", "self", ".", "_save_to_file_zip", "(", "path", ",", "data", "=", "data", ",", "params", "=", "params_to_save", ",", "tensors", "=", "tensors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.OffPolicyRLModel.__init__": [[913, 948], ["int", "base_class.BaseRLModel.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "policy", ":", "Type", "[", "BasePolicy", "]", ",", "\n", "env", ":", "Union", "[", "GymEnv", ",", "str", "]", ",", "\n", "policy_base", ":", "Type", "[", "BasePolicy", "]", ",", "\n", "learning_rate", ":", "Union", "[", "float", ",", "Callable", "]", ",", "\n", "buffer_size", ":", "int", "=", "int", "(", "1e6", ")", ",", "\n", "learning_starts", ":", "int", "=", "100", ",", "\n", "batch_size", ":", "int", "=", "256", ",", "\n", "policy_kwargs", ":", "Dict", "[", "str", ",", "Any", "]", "=", "None", ",", "\n", "verbose", ":", "int", "=", "0", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "'auto'", ",", "\n", "support_multi_env", ":", "bool", "=", "False", ",", "\n", "create_eval_env", ":", "bool", "=", "False", ",", "\n", "monitor_wrapper", ":", "bool", "=", "True", ",", "\n", "seed", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "use_sde", ":", "bool", "=", "False", ",", "\n", "sde_sample_freq", ":", "int", "=", "-", "1", ",", "\n", "use_sde_at_warmup", ":", "bool", "=", "False", ",", "\n", "sde_support", ":", "bool", "=", "True", ")", ":", "\n", "\n", "        ", "super", "(", "OffPolicyRLModel", ",", "self", ")", ".", "__init__", "(", "policy", ",", "env", ",", "policy_base", ",", "learning_rate", ",", "\n", "policy_kwargs", ",", "verbose", ",", "\n", "device", ",", "support_multi_env", ",", "create_eval_env", ",", "monitor_wrapper", ",", "\n", "seed", ",", "use_sde", ",", "sde_sample_freq", ")", "\n", "self", ".", "buffer_size", "=", "buffer_size", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "learning_starts", "=", "learning_starts", "\n", "self", ".", "actor", "=", "None", "\n", "self", ".", "replay_buffer", "=", "None", "# type: Optional[ReplayBuffer]", "\n", "# Update policy keyword arguments", "\n", "if", "sde_support", ":", "\n", "            ", "self", ".", "policy_kwargs", "[", "'use_sde'", "]", "=", "self", ".", "use_sde", "\n", "", "self", ".", "policy_kwargs", "[", "'device'", "]", "=", "self", ".", "device", "\n", "# For gSDE only", "\n", "self", ".", "use_sde_at_warmup", "=", "use_sde_at_warmup", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.OffPolicyRLModel._setup_model": [[949, 957], ["base_class.OffPolicyRLModel._setup_lr_schedule", "base_class.OffPolicyRLModel.set_random_seed", "stable_baselines3.common.buffers.ReplayBuffer", "base_class.OffPolicyRLModel.policy_class", "base_class.OffPolicyRLModel.policy.to"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._setup_lr_schedule", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.set_random_seed"], ["", "def", "_setup_model", "(", "self", ")", ":", "\n", "        ", "self", ".", "_setup_lr_schedule", "(", ")", "\n", "self", ".", "set_random_seed", "(", "self", ".", "seed", ")", "\n", "self", ".", "replay_buffer", "=", "ReplayBuffer", "(", "self", ".", "buffer_size", ",", "self", ".", "attacker_observation_space", ",", "\n", "self", ".", "attacker_action_space", ",", "self", ".", "device", ")", "\n", "self", ".", "policy", "=", "self", ".", "policy_class", "(", "self", ".", "attacker_observation_space", ",", "self", ".", "attacker_action_space", ",", "\n", "self", ".", "lr_schedule_a", ",", "**", "self", ".", "policy_kwargs", ")", "\n", "self", ".", "policy", "=", "self", ".", "policy", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.OffPolicyRLModel.save_replay_buffer": [[958, 967], ["open", "pickle.dump", "os.path.join"], "methods", ["None"], ["", "def", "save_replay_buffer", "(", "self", ",", "path", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        Save the replay buffer as a pickle file.\n\n        :param path: (str) Path to a log folder\n        \"\"\"", "\n", "assert", "self", ".", "replay_buffer", "is", "not", "None", ",", "\"The replay buffer is not defined\"", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'replay_buffer.pkl'", ")", ",", "'wb'", ")", "as", "file_handler", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "replay_buffer", ",", "file_handler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.OffPolicyRLModel.load_replay_buffer": [[968, 976], ["isinstance", "open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load"], ["", "", "def", "load_replay_buffer", "(", "self", ",", "path", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n\n        :param path: (str) Path to the pickled replay buffer.\n        \"\"\"", "\n", "with", "open", "(", "path", ",", "'rb'", ")", "as", "file_handler", ":", "\n", "            ", "self", ".", "replay_buffer", "=", "pickle", ".", "load", "(", "file_handler", ")", "\n", "", "assert", "isinstance", "(", "self", ".", "replay_buffer", ",", "ReplayBuffer", ")", ",", "'The replay buffer must inherit from ReplayBuffer class'", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.OffPolicyRLModel.collect_rollouts": [[977, 1120], ["isinstance", "callback.on_rollout_start", "callback.on_rollout_end", "stable_baselines3.common.type_aliases.RolloutReturn", "base_class.OffPolicyRLModel.actor.reset_noise", "numpy.mean", "isinstance", "env.step", "base_class.OffPolicyRLModel._update_info_buffer", "episode_rewards.append", "total_timesteps.append", "base_class.OffPolicyRLModel.actor.reset_noise", "numpy.array", "base_class.OffPolicyRLModel.predict", "base_class.OffPolicyRLModel.policy.scale_action", "base_class.OffPolicyRLModel.policy.unscale_action", "callback.on_step", "stable_baselines3.common.type_aliases.RolloutReturn", "replay_buffer.add", "action_noise.reset", "int", "stable_baselines3.common.logger.logkv", "stable_baselines3.common.logger.logkv", "stable_baselines3.common.logger.logkv", "stable_baselines3.common.logger.logkv", "stable_baselines3.common.logger.dumpkvs", "numpy.clip", "base_class.OffPolicyRLModel._vec_normalize_env.get_original_obs", "base_class.OffPolicyRLModel._vec_normalize_env.get_original_reward", "stable_baselines3.common.logger.logkv", "stable_baselines3.common.logger.logkv", "int", "stable_baselines3.common.logger.logkv", "len", "stable_baselines3.common.logger.logkv", "base_class.OffPolicyRLModel.attacker_action_space.sample", "len", "len", "base_class.OffPolicyRLModel.safe_mean", "base_class.OffPolicyRLModel.safe_mean", "base_class.OffPolicyRLModel.actor.get_std().mean().item", "base_class.OffPolicyRLModel.safe_mean", "action_noise", "time.time", "time.time", "base_class.OffPolicyRLModel.actor.get_std().mean", "base_class.OffPolicyRLModel.actor.get_std"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.on_rollout_start", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.on_rollout_end", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel._update_info_buffer", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.ppo.ppo_policies.PPOPolicy.reset_noise", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.predict", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.scale_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.unscale_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.on_step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.get_original_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.get_original_reward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.sample", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.safe_mean", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.safe_mean", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.safe_mean", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.distributions.StateDependentNoiseDistribution.get_std"], ["", "def", "collect_rollouts", "(", "self", ",", "\n", "env", ":", "VecEnv", ",", "\n", "# Type hint as string to avoid circular import", "\n", "callback", ":", "'BaseCallback'", ",", "\n", "n_episodes", ":", "int", "=", "1", ",", "\n", "n_steps", ":", "int", "=", "-", "1", ",", "\n", "action_noise", ":", "Optional", "[", "ActionNoise", "]", "=", "None", ",", "\n", "learning_starts", ":", "int", "=", "0", ",", "\n", "replay_buffer", ":", "Optional", "[", "ReplayBuffer", "]", "=", "None", ",", "\n", "log_interval", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "RolloutReturn", ":", "\n", "        ", "\"\"\"\n        Collect rollout using the current policy (and possibly fill the replay buffer)\n\n        :param env: (VecEnv) The training environment\n        :param n_episodes: (int) Number of episodes to use to collect rollout data\n            You can also specify a ``n_steps`` instead\n        :param n_steps: (int) Number of steps to use to collect rollout data\n            You can also specify a ``n_episodes`` instead.\n        :param action_noise: (Optional[ActionNoise]) Action noise that will be used for exploration\n            Required for deterministic policy (e.g. TD3). This can also be used\n            in addition to the stochastic policy for SAC.\n        :param callback: (BaseCallback) Callback that will be called at each step\n            (and at the beginning and end of the rollout)\n        :param learning_starts: (int) Number of steps before learning for the warm-up phase.\n        :param replay_buffer: (ReplayBuffer)\n        :param log_interval: (int) Log data every ``log_interval`` episodes\n        :return: (RolloutReturn)\n        \"\"\"", "\n", "episode_rewards", ",", "total_timesteps", "=", "[", "]", ",", "[", "]", "\n", "total_steps", ",", "total_episodes", "=", "0", ",", "0", "\n", "\n", "assert", "isinstance", "(", "env", ",", "VecEnv", ")", ",", "\"You must pass a VecEnv\"", "\n", "assert", "env", ".", "num_envs", "==", "1", ",", "\"OffPolicyRLModel only support single environment\"", "\n", "\n", "if", "self", ".", "use_sde", ":", "\n", "            ", "self", ".", "actor", ".", "reset_noise", "(", ")", "\n", "\n", "", "callback", ".", "on_rollout_start", "(", ")", "\n", "continue_training", "=", "True", "\n", "\n", "while", "total_steps", "<", "n_steps", "or", "total_episodes", "<", "n_episodes", ":", "\n", "            ", "done", "=", "False", "\n", "episode_reward", ",", "episode_timesteps", "=", "0.0", ",", "0", "\n", "\n", "while", "not", "done", ":", "\n", "\n", "                ", "if", "self", ".", "use_sde", "and", "self", ".", "sde_sample_freq", ">", "0", "and", "n_steps", "%", "self", ".", "sde_sample_freq", "==", "0", ":", "\n", "# Sample a new noise matrix", "\n", "                    ", "self", ".", "actor", ".", "reset_noise", "(", ")", "\n", "\n", "# Select action randomly or according to policy", "\n", "", "if", "self", ".", "num_timesteps", "<", "learning_starts", "and", "not", "(", "self", ".", "use_sde", "and", "self", ".", "use_sde_at_warmup", ")", ":", "\n", "# Warmup phase", "\n", "                    ", "unscaled_action", "=", "np", ".", "array", "(", "[", "self", ".", "attacker_action_space", ".", "sample", "(", ")", "]", ")", "\n", "", "else", ":", "\n", "# Note: we assume that the policy uses tanh to scale the action", "\n", "# We use non-deterministic action in the case of SAC, for TD3, it does not matter", "\n", "                    ", "unscaled_action", ",", "_", "=", "self", ".", "predict", "(", "self", ".", "_last_obs", ",", "deterministic", "=", "False", ")", "\n", "\n", "# Rescale the action from [low, high] to [-1, 1]", "\n", "", "if", "isinstance", "(", "self", ".", "attacker_action_space", ",", "gym", ".", "spaces", ".", "Box", ")", ":", "\n", "                    ", "scaled_action", "=", "self", ".", "policy", ".", "scale_action", "(", "unscaled_action", ")", "\n", "\n", "# Add noise to the action (improve exploration)", "\n", "if", "action_noise", "is", "not", "None", ":", "\n", "# NOTE: in the original implementation of TD3, the noise was applied to the unscaled action", "\n", "# Update(October 2019): Not anymore", "\n", "                        ", "scaled_action", "=", "np", ".", "clip", "(", "scaled_action", "+", "action_noise", "(", ")", ",", "-", "1", ",", "1", ")", "\n", "\n", "# We store the scaled action in the buffer", "\n", "", "buffer_action", "=", "scaled_action", "\n", "action", "=", "self", ".", "policy", ".", "unscale_action", "(", "scaled_action", ")", "\n", "", "else", ":", "\n", "# Discrete case, no need to normalize or clip", "\n", "                    ", "buffer_action", "=", "unscaled_action", "\n", "action", "=", "buffer_action", "\n", "\n", "# Rescale and perform action", "\n", "", "new_obs", ",", "reward", ",", "done", ",", "infos", "=", "env", ".", "step", "(", "action", ")", "\n", "\n", "# Only stop training if return value is False, not when it is None.", "\n", "if", "callback", ".", "on_step", "(", ")", "is", "False", ":", "\n", "                    ", "return", "RolloutReturn", "(", "0.0", ",", "total_steps", ",", "total_episodes", ",", "continue_training", "=", "False", ")", "\n", "\n", "", "episode_reward", "+=", "reward", "\n", "\n", "# Retrieve reward and episode length if using Monitor wrapper", "\n", "self", ".", "_update_info_buffer", "(", "infos", ",", "done", ")", "\n", "\n", "# Store data in replay buffer", "\n", "if", "replay_buffer", "is", "not", "None", ":", "\n", "# Store only the unnormalized version", "\n", "                    ", "if", "self", ".", "_vec_normalize_env", "is", "not", "None", ":", "\n", "                        ", "new_obs_", "=", "self", ".", "_vec_normalize_env", ".", "get_original_obs", "(", ")", "\n", "reward_", "=", "self", ".", "_vec_normalize_env", ".", "get_original_reward", "(", ")", "\n", "", "else", ":", "\n", "# Avoid changing the original ones", "\n", "                        ", "self", ".", "_last_original_obs", ",", "new_obs_", ",", "reward_", "=", "self", ".", "_last_obs", ",", "new_obs", ",", "reward", "\n", "\n", "", "replay_buffer", ".", "add", "(", "self", ".", "_last_original_obs", ",", "new_obs_", ",", "buffer_action", ",", "reward_", ",", "done", ")", "\n", "\n", "", "self", ".", "_last_obs", "=", "new_obs", "\n", "# Save the unnormalized observation", "\n", "if", "self", ".", "_vec_normalize_env", "is", "not", "None", ":", "\n", "                    ", "self", ".", "_last_original_obs", "=", "new_obs_", "\n", "\n", "", "self", ".", "num_timesteps", "+=", "1", "\n", "episode_timesteps", "+=", "1", "\n", "total_steps", "+=", "1", "\n", "if", "0", "<", "n_steps", "<=", "total_steps", ":", "\n", "                    ", "break", "\n", "\n", "", "", "if", "done", ":", "\n", "                ", "total_episodes", "+=", "1", "\n", "self", ".", "_episode_num", "+=", "1", "\n", "episode_rewards", ".", "append", "(", "episode_reward", ")", "\n", "total_timesteps", ".", "append", "(", "episode_timesteps", ")", "\n", "\n", "if", "action_noise", "is", "not", "None", ":", "\n", "                    ", "action_noise", ".", "reset", "(", ")", "\n", "\n", "# Display training infos", "\n", "", "if", "self", ".", "verbose", ">=", "1", "and", "log_interval", "is", "not", "None", "and", "self", ".", "_episode_num", "%", "log_interval", "==", "0", ":", "\n", "                    ", "fps", "=", "int", "(", "self", ".", "num_timesteps", "/", "(", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", ")", ")", "\n", "logger", ".", "logkv", "(", "\"episodes\"", ",", "self", ".", "_episode_num", ")", "\n", "if", "len", "(", "self", ".", "ep_info_buffer", ")", ">", "0", "and", "len", "(", "self", ".", "ep_info_buffer", "[", "0", "]", ")", ">", "0", ":", "\n", "                        ", "logger", ".", "logkv", "(", "'ep_rew_mean'", ",", "self", ".", "safe_mean", "(", "[", "ep_info", "[", "'r'", "]", "for", "ep_info", "in", "self", ".", "ep_info_buffer", "]", ")", ")", "\n", "logger", ".", "logkv", "(", "'ep_len_mean'", ",", "self", ".", "safe_mean", "(", "[", "ep_info", "[", "'l'", "]", "for", "ep_info", "in", "self", ".", "ep_info_buffer", "]", ")", ")", "\n", "", "logger", ".", "logkv", "(", "\"fps\"", ",", "fps", ")", "\n", "logger", ".", "logkv", "(", "'time_elapsed'", ",", "int", "(", "time", ".", "time", "(", ")", "-", "self", ".", "start_time", ")", ")", "\n", "logger", ".", "logkv", "(", "\"total timesteps\"", ",", "self", ".", "num_timesteps", ")", "\n", "if", "self", ".", "use_sde", ":", "\n", "                        ", "logger", ".", "logkv", "(", "\"std\"", ",", "(", "self", ".", "actor", ".", "get_std", "(", ")", ")", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "", "if", "len", "(", "self", ".", "ep_success_buffer", ")", ">", "0", ":", "\n", "                        ", "logger", ".", "logkv", "(", "'success rate'", ",", "self", ".", "safe_mean", "(", "self", ".", "ep_success_buffer", ")", ")", "\n", "", "logger", ".", "dumpkvs", "(", ")", "\n", "\n", "", "", "", "mean_reward", "=", "np", ".", "mean", "(", "episode_rewards", ")", "if", "total_episodes", ">", "0", "else", "0.0", "\n", "\n", "callback", ".", "on_rollout_end", "(", ")", "\n", "\n", "return", "RolloutReturn", "(", "mean_reward", ",", "total_steps", ",", "total_episodes", ",", "continue_training", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.__init__": [[27, 44], ["abc.ABC.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "verbose", ":", "int", "=", "0", ")", ":", "\n", "        ", "super", "(", "BaseCallback", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# The RL model", "\n", "self", ".", "model", "=", "None", "# type: Optional[BaseRLModel]", "\n", "# An alias for self.model.get_env(), the environment used for training", "\n", "self", ".", "training_env", "=", "None", "# type: Union[gym.Env, VecEnv, None]", "\n", "# Number of time the callback was called", "\n", "self", ".", "n_calls", "=", "0", "# type: int", "\n", "# n_envs * n times env.step() was called", "\n", "self", ".", "num_timesteps", "=", "0", "# type: int", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "locals", "=", "None", "# type: Optional[Dict[str, Any]]", "\n", "self", ".", "globals", "=", "None", "# type: Optional[Dict[str, Any]]", "\n", "self", ".", "logger", "=", "None", "# type: Optional[Logger]", "\n", "# Sometimes, for event callback, it is useful", "\n", "# to have access to the parent object", "\n", "self", ".", "parent", "=", "None", "# type: Optional[BaseCallback]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.init_callback": [[46, 55], ["model.get_env", "callbacks.BaseCallback._init_callback"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.base_class.BaseRLModel.get_env", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.EvalCallback._init_callback"], ["", "def", "init_callback", "(", "self", ",", "model", ":", "'BaseRLModel'", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Initialize the callback by saving references to the\n        RL model and the training environment for convenience.\n        \"\"\"", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "training_env", "=", "model", ".", "get_env", "(", ")", "\n", "self", ".", "logger", "=", "Logger", ".", "CURRENT", "\n", "self", ".", "_init_callback", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback._init_callback": [[56, 58], ["None"], "methods", ["None"], ["", "def", "_init_callback", "(", "self", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.on_training_start": [[59, 64], ["callbacks.BaseCallback._on_training_start"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.CallbackList._on_training_start"], ["", "def", "on_training_start", "(", "self", ",", "locals_", ":", "Dict", "[", "str", ",", "Any", "]", ",", "globals_", ":", "Dict", "[", "str", ",", "Any", "]", ")", "->", "None", ":", "\n", "# Those are reference and will be updated automatically", "\n", "        ", "self", ".", "locals", "=", "locals_", "\n", "self", ".", "globals", "=", "globals_", "\n", "self", ".", "_on_training_start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback._on_training_start": [[65, 67], ["None"], "methods", ["None"], ["", "def", "_on_training_start", "(", "self", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.on_rollout_start": [[68, 70], ["callbacks.BaseCallback._on_rollout_start"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.CallbackList._on_rollout_start"], ["", "def", "on_rollout_start", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "_on_rollout_start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback._on_rollout_start": [[71, 73], ["None"], "methods", ["None"], ["", "def", "_on_rollout_start", "(", "self", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback._on_step": [[74, 80], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_on_step", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        :return: (bool) If the callback returns False, training is aborted early.\n        \"\"\"", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.on_step": [[81, 95], ["callbacks.BaseCallback._on_step"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.EveryNTimesteps._on_step"], ["", "def", "on_step", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        This method will be called by the model after each call to ``env.step()``.\n\n        For child callback (of an ``EventCallback``), this will be called\n        when the event is triggered.\n\n        :return: (bool) If the callback returns False, training is aborted early.\n        \"\"\"", "\n", "self", ".", "n_calls", "+=", "1", "\n", "# timesteps start at zero", "\n", "self", ".", "num_timesteps", "=", "self", ".", "model", ".", "num_timesteps", "+", "1", "\n", "\n", "return", "self", ".", "_on_step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.on_training_end": [[96, 98], ["callbacks.BaseCallback._on_training_end"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.CallbackList._on_training_end"], ["", "def", "on_training_end", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "_on_training_end", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback._on_training_end": [[99, 101], ["None"], "methods", ["None"], ["", "def", "_on_training_end", "(", "self", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.on_rollout_end": [[102, 104], ["callbacks.BaseCallback._on_rollout_end"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.CallbackList._on_rollout_end"], ["", "def", "on_rollout_end", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "_on_rollout_end", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback._on_rollout_end": [[105, 107], ["None"], "methods", ["None"], ["", "def", "_on_rollout_end", "(", "self", ")", "->", "None", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.EventCallback.__init__": [[117, 123], ["callbacks.BaseCallback.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "callback", ":", "Optional", "[", "BaseCallback", "]", "=", "None", ",", "verbose", ":", "int", "=", "0", ")", ":", "\n", "        ", "super", "(", "EventCallback", ",", "self", ")", ".", "__init__", "(", "verbose", "=", "verbose", ")", "\n", "self", ".", "callback", "=", "callback", "\n", "# Give access to the parent", "\n", "if", "callback", "is", "not", "None", ":", "\n", "            ", "self", ".", "callback", ".", "parent", "=", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.EventCallback.init_callback": [[124, 128], ["callbacks.BaseCallback.init_callback", "callbacks.EventCallback.callback.init_callback"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.EventCallback.init_callback", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.EventCallback.init_callback"], ["", "", "def", "init_callback", "(", "self", ",", "model", ":", "'BaseRLModel'", ")", "->", "None", ":", "\n", "        ", "super", "(", "EventCallback", ",", "self", ")", ".", "init_callback", "(", "model", ")", "\n", "if", "self", ".", "callback", "is", "not", "None", ":", "\n", "            ", "self", ".", "callback", ".", "init_callback", "(", "self", ".", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.EventCallback._on_training_start": [[129, 132], ["callbacks.EventCallback.callback.on_training_start"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.on_training_start"], ["", "", "def", "_on_training_start", "(", "self", ")", "->", "None", ":", "\n", "        ", "if", "self", ".", "callback", "is", "not", "None", ":", "\n", "            ", "self", ".", "callback", ".", "on_training_start", "(", "self", ".", "locals", ",", "self", ".", "globals", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.EventCallback._on_event": [[133, 137], ["callbacks.EventCallback.callback.on_step"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.on_step"], ["", "", "def", "_on_event", "(", "self", ")", "->", "bool", ":", "\n", "        ", "if", "self", ".", "callback", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "callback", ".", "on_step", "(", ")", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.EventCallback._on_step": [[138, 140], ["None"], "methods", ["None"], ["", "def", "_on_step", "(", "self", ")", "->", "bool", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.CallbackList.__init__": [[149, 153], ["callbacks.BaseCallback.__init__", "isinstance"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "callbacks", ":", "List", "[", "BaseCallback", "]", ")", ":", "\n", "        ", "super", "(", "CallbackList", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "isinstance", "(", "callbacks", ",", "list", ")", "\n", "self", ".", "callbacks", "=", "callbacks", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.CallbackList._init_callback": [[154, 157], ["callback.init_callback"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.EventCallback.init_callback"], ["", "def", "_init_callback", "(", "self", ")", "->", "None", ":", "\n", "        ", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "            ", "callback", ".", "init_callback", "(", "self", ".", "model", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.CallbackList._on_training_start": [[158, 161], ["callback.on_training_start"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.on_training_start"], ["", "", "def", "_on_training_start", "(", "self", ")", "->", "None", ":", "\n", "        ", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "            ", "callback", ".", "on_training_start", "(", "self", ".", "locals", ",", "self", ".", "globals", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.CallbackList._on_rollout_start": [[162, 165], ["callback.on_rollout_start"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.on_rollout_start"], ["", "", "def", "_on_rollout_start", "(", "self", ")", "->", "None", ":", "\n", "        ", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "            ", "callback", ".", "on_rollout_start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.CallbackList._on_step": [[166, 172], ["callback.on_step"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.on_step"], ["", "", "def", "_on_step", "(", "self", ")", "->", "bool", ":", "\n", "        ", "continue_training", "=", "True", "\n", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "# Return False (stop training) if at least one callback returns False", "\n", "            ", "continue_training", "=", "callback", ".", "on_step", "(", ")", "and", "continue_training", "\n", "", "return", "continue_training", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.CallbackList._on_rollout_end": [[173, 176], ["callback.on_rollout_end"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.on_rollout_end"], ["", "def", "_on_rollout_end", "(", "self", ")", "->", "None", ":", "\n", "        ", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "            ", "callback", ".", "on_rollout_end", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.CallbackList._on_training_end": [[177, 180], ["callback.on_training_end"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.BaseCallback.on_training_end"], ["", "", "def", "_on_training_end", "(", "self", ")", "->", "None", ":", "\n", "        ", "for", "callback", "in", "self", ".", "callbacks", ":", "\n", "            ", "callback", ".", "on_training_end", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.CheckpointCallback.__init__": [[190, 195], ["callbacks.BaseCallback.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "save_freq", ":", "int", ",", "save_path", ":", "str", ",", "name_prefix", "=", "'rl_model'", ",", "verbose", "=", "0", ")", ":", "\n", "        ", "super", "(", "CheckpointCallback", ",", "self", ")", ".", "__init__", "(", "verbose", ")", "\n", "self", ".", "save_freq", "=", "save_freq", "\n", "self", ".", "save_path", "=", "save_path", "\n", "self", ".", "name_prefix", "=", "name_prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.CheckpointCallback._init_callback": [[196, 200], ["os.makedirs"], "methods", ["None"], ["", "def", "_init_callback", "(", "self", ")", "->", "None", ":", "\n", "# Create folder if needed", "\n", "        ", "if", "self", ".", "save_path", "is", "not", "None", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "save_path", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.CheckpointCallback._on_step": [[201, 208], ["os.path.join", "callbacks.CheckpointCallback.model.save", "print"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save"], ["", "", "def", "_on_step", "(", "self", ")", "->", "bool", ":", "\n", "        ", "if", "self", ".", "n_calls", "%", "self", ".", "save_freq", "==", "0", ":", "\n", "            ", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "save_path", ",", "f'{self.name_prefix}_{self.num_timesteps}_steps'", ")", "\n", "self", ".", "model", ".", "save", "(", "path", ")", "\n", "if", "self", ".", "verbose", ">", "1", ":", "\n", "                ", "print", "(", "f\"Saving model checkpoint to {path}\"", ")", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.ConvertCallback.__init__": [[217, 220], ["callbacks.BaseCallback.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "callback", ",", "verbose", "=", "0", ")", ":", "\n", "        ", "super", "(", "ConvertCallback", ",", "self", ")", ".", "__init__", "(", "verbose", ")", "\n", "self", ".", "callback", "=", "callback", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.ConvertCallback._on_step": [[221, 225], ["callbacks.ConvertCallback.callback"], "methods", ["None"], ["", "def", "_on_step", "(", "self", ")", "->", "bool", ":", "\n", "        ", "if", "self", ".", "callback", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "callback", "(", "self", ".", "locals", ",", "self", ".", "globals", ")", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.EvalCallback.__init__": [[246, 281], ["callbacks.EventCallback.__init__", "isinstance", "isinstance", "gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.dummy_vec_env.DummyVecEnv", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "eval_env", ":", "Union", "[", "gym", ".", "Env", ",", "VecEnv", "]", ",", "\n", "callback_on_new_best", ":", "Optional", "[", "BaseCallback", "]", "=", "None", ",", "\n", "n_eval_episodes", ":", "int", "=", "5", ",", "\n", "eval_freq", ":", "int", "=", "10000", ",", "\n", "log_path", ":", "str", "=", "None", ",", "\n", "best_model_save_path", ":", "str", "=", "None", ",", "\n", "deterministic", ":", "bool", "=", "True", ",", "\n", "render", ":", "bool", "=", "False", ",", "\n", "verbose", ":", "int", "=", "1", ",", "\n", "pg_agent_config", ":", "PolicyGradientAgentConfig", "=", "None", ")", ":", "\n", "        ", "super", "(", "EvalCallback", ",", "self", ")", ".", "__init__", "(", "callback_on_new_best", ",", "verbose", "=", "verbose", ")", "\n", "self", ".", "n_eval_episodes", "=", "n_eval_episodes", "\n", "self", ".", "eval_freq", "=", "eval_freq", "\n", "self", ".", "best_mean_reward", "=", "-", "np", ".", "inf", "\n", "self", ".", "last_mean_reward", "=", "-", "np", ".", "inf", "\n", "self", ".", "deterministic", "=", "deterministic", "\n", "self", ".", "render", "=", "render", "\n", "self", ".", "pg_agent_config", "=", "pg_agent_config", "\n", "\n", "# Convert to VecEnv for consistency", "\n", "if", "not", "isinstance", "(", "eval_env", ",", "VecEnv", ")", ":", "\n", "            ", "eval_env", "=", "DummyVecEnv", "(", "[", "lambda", ":", "eval_env", "]", ")", "\n", "\n", "", "if", "isinstance", "(", "eval_env", ",", "VecEnv", ")", ":", "\n", "            ", "assert", "eval_env", ".", "num_envs", "==", "1", ",", "\"You must pass only one environment for evaluation\"", "\n", "\n", "", "self", ".", "eval_env", "=", "eval_env", "\n", "self", ".", "best_model_save_path", "=", "best_model_save_path", "\n", "# Logs will be written in ``evaluations.npz``", "\n", "if", "log_path", "is", "not", "None", ":", "\n", "            ", "log_path", "=", "os", ".", "path", ".", "join", "(", "log_path", ",", "'evaluations'", ")", "\n", "", "self", ".", "log_path", "=", "log_path", "\n", "self", ".", "evaluations_results", "=", "[", "]", "\n", "self", ".", "evaluations_timesteps", "=", "[", "]", "\n", "self", ".", "evaluations_length", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.EvalCallback._init_callback": [[282, 293], ["isinstance", "warnings.warn", "os.makedirs", "os.makedirs", "type", "os.path.dirname"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type"], ["", "def", "_init_callback", "(", "self", ")", ":", "\n", "# Does not work in some corner cases, where the wrapper is not the same", "\n", "        ", "if", "not", "isinstance", "(", "self", ".", "training_env", ",", "type", "(", "self", ".", "eval_env", ")", ")", ":", "\n", "            ", "warnings", ".", "warn", "(", "\"Training and eval env are not of the same type\"", "\n", "f\"{self.training_env} != {self.eval_env}\"", ")", "\n", "\n", "# Create folders if needed", "\n", "", "if", "self", ".", "best_model_save_path", "is", "not", "None", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "best_model_save_path", ",", "exist_ok", "=", "True", ")", "\n", "", "if", "self", ".", "log_path", "is", "not", "None", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "self", ".", "log_path", ")", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.EvalCallback._on_step": [[294, 319], ["gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.sync_envs_normalization", "print", "gym_idsgame.agents.training_agents.openai_baselines.common.evaluation.evaluate_policy", "callbacks.EvalCallback.evaluations_timesteps.append", "callbacks.EvalCallback.evaluations_results.append", "callbacks.EvalCallback.evaluations_length.append", "numpy.savez", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.__init__.sync_envs_normalization", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.evaluation.evaluate_policy"], ["", "", "def", "_on_step", "(", "self", ")", "->", "bool", ":", "\n", "        ", "if", "self", ".", "eval_freq", ">", "0", "and", "self", ".", "n_calls", "%", "self", ".", "eval_freq", "==", "0", ":", "\n", "# Sync training and eval env if there is VecNormalize", "\n", "            ", "sync_envs_normalization", "(", "self", ".", "training_env", ",", "self", ".", "eval_env", ")", "\n", "print", "(", "\"Starting evaluation\"", ")", "\n", "episode_rewards", ",", "episode_lengths", "=", "evaluate_policy", "(", "self", ".", "model", ",", "self", ".", "eval_env", ",", "\n", "n_eval_episodes", "=", "self", ".", "n_eval_episodes", ",", "\n", "render", "=", "self", ".", "render", ",", "\n", "deterministic", "=", "self", ".", "deterministic", ",", "\n", "return_episode_rewards", "=", "True", ",", "\n", "pg_agent_config", "=", "self", ".", "pg_agent_config", ",", "\n", "train_episode", "=", "self", ".", "model", ".", "iteration", ")", "\n", "\n", "if", "self", ".", "log_path", "is", "not", "None", ":", "\n", "                ", "self", ".", "evaluations_timesteps", ".", "append", "(", "self", ".", "num_timesteps", ")", "\n", "self", ".", "evaluations_results", ".", "append", "(", "episode_rewards", ")", "\n", "self", ".", "evaluations_length", ".", "append", "(", "episode_lengths", ")", "\n", "np", ".", "savez", "(", "self", ".", "log_path", ",", "timesteps", "=", "self", ".", "evaluations_timesteps", ",", "\n", "results", "=", "self", ".", "evaluations_results", ",", "ep_lengths", "=", "self", ".", "evaluations_length", ")", "\n", "\n", "", "mean_reward", ",", "std_reward", "=", "np", ".", "mean", "(", "episode_rewards", ")", ",", "np", ".", "std", "(", "episode_rewards", ")", "\n", "mean_ep_length", ",", "std_ep_length", "=", "np", ".", "mean", "(", "episode_lengths", ")", ",", "np", ".", "std", "(", "episode_lengths", ")", "\n", "self", ".", "last_mean_reward", "=", "mean_reward", "\n", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.StopTrainingOnRewardThreshold.__init__": [[332, 335], ["callbacks.BaseCallback.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "reward_threshold", ":", "float", ",", "verbose", ":", "int", "=", "0", ")", ":", "\n", "        ", "super", "(", "StopTrainingOnRewardThreshold", ",", "self", ")", ".", "__init__", "(", "verbose", "=", "verbose", ")", "\n", "self", ".", "reward_threshold", "=", "reward_threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.StopTrainingOnRewardThreshold._on_step": [[336, 345], ["bool", "print"], "methods", ["None"], ["", "def", "_on_step", "(", "self", ")", "->", "bool", ":", "\n", "        ", "assert", "self", ".", "parent", "is", "not", "None", ",", "(", "\"``StopTrainingOnMinimumReward`` callback must be used \"", "\n", "\"with an ``EvalCallback``\"", ")", "\n", "# Convert np.bool to bool, otherwise callback() is False won't work", "\n", "continue_training", "=", "bool", "(", "self", ".", "parent", ".", "best_mean_reward", "<", "self", ".", "reward_threshold", ")", "\n", "if", "self", ".", "verbose", ">", "0", "and", "not", "continue_training", ":", "\n", "            ", "print", "(", "f\"Stopping training because the mean reward {self.parent.best_mean_reward:.2f} \"", "\n", "f\" is above the threshold {self.reward_threshold}\"", ")", "\n", "", "return", "continue_training", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.EveryNTimesteps.__init__": [[355, 359], ["callbacks.EventCallback.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "n_steps", ":", "int", ",", "callback", ":", "BaseCallback", ")", ":", "\n", "        ", "super", "(", "EveryNTimesteps", ",", "self", ")", ".", "__init__", "(", "callback", ")", "\n", "self", ".", "n_steps", "=", "n_steps", "\n", "self", ".", "last_time_trigger", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.EveryNTimesteps._on_step": [[360, 365], ["callbacks.EveryNTimesteps._on_event"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.callbacks.EventCallback._on_event"], ["", "def", "_on_step", "(", "self", ")", "->", "bool", ":", "\n", "        ", "if", "(", "self", ".", "num_timesteps", "-", "self", ".", "last_time_trigger", ")", ">=", "self", ".", "n_steps", ":", "\n", "            ", "self", ".", "last_time_trigger", "=", "self", ".", "num_timesteps", "\n", "return", "self", ".", "_on_event", "(", ")", "\n", "", "return", "True", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.set_random_seed": [[8, 25], ["random.seed", "numpy.random.seed", "torch.manual_seed"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.seed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.seed"], ["def", "set_random_seed", "(", "seed", ":", "int", ",", "using_cuda", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Seed the different random generators\n    :param seed: (int)\n    :param using_cuda: (bool)\n    \"\"\"", "\n", "# Seed python RNG", "\n", "random", ".", "seed", "(", "seed", ")", "\n", "# Seed numpy RNG", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "# seed the RNG for all devices (both CPU and CUDA)", "\n", "th", ".", "manual_seed", "(", "seed", ")", "\n", "\n", "if", "using_cuda", ":", "\n", "# Deterministic operations for CuDNN, it may impact performances", "\n", "        ", "th", ".", "backends", ".", "cudnn", ".", "deterministic", "=", "True", "\n", "th", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.explained_variance": [[28, 45], ["numpy.var", "numpy.var"], "function", ["None"], ["", "", "def", "explained_variance", "(", "y_pred", ":", "np", ".", "ndarray", ",", "y_true", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Computes fraction of variance that ypred explains about y.\n    Returns 1 - Var[y-ypred] / Var[y]\n\n    interpretation:\n        ev=0  =>  might as well have predicted zero\n        ev=1  =>  perfect prediction\n        ev<0  =>  worse than just predicting zero\n\n    :param y_pred: (np.ndarray) the prediction\n    :param y_true: (np.ndarray) the expected value\n    :return: (float) explained variance of ypred and y\n    \"\"\"", "\n", "assert", "y_true", ".", "ndim", "==", "1", "and", "y_pred", ".", "ndim", "==", "1", "\n", "var_y", "=", "np", ".", "var", "(", "y_true", ")", "\n", "return", "np", ".", "nan", "if", "var_y", "==", "0", "else", "1", "-", "np", ".", "var", "(", "y_true", "-", "y_pred", ")", "/", "var_y", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.update_learning_rate": [[47, 57], ["None"], "function", ["None"], ["", "def", "update_learning_rate", "(", "optimizer", ":", "th", ".", "optim", ".", "Optimizer", ",", "learning_rate", ":", "float", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Update the learning rate for a given optimizer.\n    Useful when doing linear schedule.\n\n    :param optimizer: (th.optim.Optimizer)\n    :param learning_rate: (float)\n    \"\"\"", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "        ", "param_group", "[", "'lr'", "]", "=", "learning_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.get_schedule_fn": [[59, 75], ["isinstance", "utils.constant_fn", "callable", "float"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.constant_fn"], ["", "", "def", "get_schedule_fn", "(", "value_schedule", ":", "Union", "[", "Callable", ",", "float", "]", ")", "->", "Callable", ":", "\n", "    ", "\"\"\"\n    Transform (if needed) learning rate and clip range (for PPO)\n    to callable.\n\n    :param value_schedule: (callable or float)\n    :return: (function)\n    \"\"\"", "\n", "# If the passed schedule is a float", "\n", "# create a constant function", "\n", "if", "isinstance", "(", "value_schedule", ",", "(", "float", ",", "int", ")", ")", ":", "\n", "# Cast to float to avoid errors", "\n", "        ", "value_schedule", "=", "constant_fn", "(", "float", "(", "value_schedule", ")", ")", "\n", "", "else", ":", "\n", "        ", "assert", "callable", "(", "value_schedule", ")", "\n", "", "return", "value_schedule", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.constant_fn": [[77, 90], ["None"], "function", ["None"], ["", "def", "constant_fn", "(", "val", ":", "float", ")", "->", "Callable", ":", "\n", "    ", "\"\"\"\n    Create a function that returns a constant\n    It is useful for learning rate schedule (to avoid code duplication)\n\n    :param val: (float)\n    :return: (Callable)\n    \"\"\"", "\n", "\n", "def", "func", "(", "_", ")", ":", "\n", "        ", "return", "val", "\n", "\n", "", "return", "func", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.utils.get_device": [[92, 117], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.cuda.is_available", "str"], "function", ["None"], ["", "def", "get_device", "(", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "'auto'", ",", "pg_agent_config", ":", "PolicyGradientAgentConfig", "=", "None", ")", "->", "th", ".", "device", ":", "\n", "    ", "\"\"\"\n    Retrieve PyTorch device.\n    It checks that the requested device is available first.\n    For now, it supports only cpu and cuda.\n    By default, it tries to use the gpu.\n\n    :param device: (Union[str, th.device]) One for 'auto', 'cuda', 'cpu'\n    :return: (th.device)\n    \"\"\"", "\n", "if", "pg_agent_config", "is", "not", "None", ":", "\n", "        ", "device", "=", "\"cpu\"", "if", "not", "pg_agent_config", ".", "gpu", "else", "\"cuda:\"", "+", "str", "(", "pg_agent_config", ".", "gpu_id", ")", "\n", "return", "th", ".", "device", "(", "device", ")", "\n", "# Cuda by default", "\n", "", "if", "device", "==", "'auto'", ":", "\n", "        ", "device", "=", "'cuda'", "\n", "\n", "# Force conversion to th.device", "\n", "", "device", "=", "th", ".", "device", "(", "device", ")", "\n", "\n", "# Cuda not available", "\n", "if", "device", "==", "th", ".", "device", "(", "'cuda'", ")", "and", "not", "th", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "return", "th", ".", "device", "(", "'cpu'", ")", "\n", "\n", "", "return", "device", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.evaluation.evaluate_policy": [[9, 207], ["isinstance", "pg_agent_config.logger.info", "str", "range", "model.log_metrics", "numpy.mean", "numpy.std", "pg_agent_config.logger.info", "print", "env.close", "time.time", "env.reset", "pg_agent_config.logger.info", "episode_attacker_rewards.append", "episode_defender_rewards.append", "episode_steps.append", "numpy.array", "numpy.array", "numpy.array", "env.step", "env.render", "time.sleep", "model.log_metrics", "enumerate", "env.envs[].generate_gif", "float", "float", "float", "float", "env.render", "time.sleep", "torch.tensor().to", "model.predict", "callback", "model.tensorboard_writer.add_image", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "torch.Tensor().to", "model.predict", "torch.tensor().to", "model.predict", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "locals", "globals", "float", "float", "float", "float", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.tensor", "str", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.tensor", "model.predict.cpu().numpy", "model.predict.cpu().numpy", "str", "str", "model.predict.cpu", "model.predict.cpu"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_metrics", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_metrics", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.generate_gif", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.predict", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.predict", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.common_policies.BasePolicy.predict"], ["def", "evaluate_policy", "(", "model", ",", "env", ",", "n_eval_episodes", "=", "10", ",", "deterministic", "=", "True", ",", "\n", "render", "=", "False", ",", "callback", "=", "None", ",", "reward_threshold", "=", "None", ",", "\n", "return_episode_rewards", "=", "False", ",", "pg_agent_config", ":", "PolicyGradientAgentConfig", "=", "None", ",", "\n", "train_episode", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    Runs policy for ``n_eval_episodes`` episodes and returns average reward.\n    This is made to work only with one env.\n\n    :param model: (BaseRLModel) The RL agent you want to evaluate.\n    :param env: (gym.Env or VecEnv) The gym environment. In the case of a ``VecEnv``\n        this must contain only one environment.\n    :param n_eval_episodes: (int) Number of episode to evaluate the agent\n    :param deterministic: (bool) Whether to use deterministic or stochastic actions\n    :param render: (bool) Whether to render the environment or not\n    :param callback: (callable) callback function to do additional checks,\n        called after each step.\n    :param reward_threshold: (float) Minimum expected reward per episode,\n        this will raise an error if the performance is not met\n    :param return_episode_rewards: (bool) If True, a list of reward per episode\n        will be returned instead of the mean.\n    :return: (float, float) Mean reward per episode, std of reward per episode\n        returns ([float], [int]) when ``return_episode_rewards`` is True\n    \"\"\"", "\n", "if", "isinstance", "(", "env", ",", "VecEnv", ")", ":", "\n", "        ", "assert", "env", ".", "num_envs", "==", "1", ",", "\"You must pass only one environment when using this function\"", "\n", "\n", "", "pg_agent_config", ".", "logger", ".", "info", "(", "\"Starting Evaluation\"", ")", "\n", "time_str", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "\n", "model", ".", "num_eval_games", "=", "0", "\n", "model", ".", "num_eval_hacks", "=", "0", "\n", "\n", "# if len(self.eval_result.avg_episode_steps) > 0:", "\n", "#     self.config.logger.warning(\"starting eval with non-empty result object\")", "\n", "if", "pg_agent_config", ".", "eval_episodes", "<", "1", ":", "\n", "        ", "return", "\n", "", "done", "=", "False", "\n", "\n", "# Tracking metrics", "\n", "episode_attacker_rewards", "=", "[", "]", "\n", "episode_defender_rewards", "=", "[", "]", "\n", "episode_steps", "=", "[", "]", "\n", "\n", "env", ".", "envs", "[", "0", "]", ".", "enabled", "=", "True", "\n", "env", ".", "envs", "[", "0", "]", ".", "stats_recorder", ".", "closed", "=", "False", "\n", "env", ".", "envs", "[", "0", "]", ".", "episode_id", "=", "0", "\n", "\n", "for", "episode", "in", "range", "(", "n_eval_episodes", ")", ":", "\n", "        ", "obs", "=", "env", ".", "reset", "(", ")", "\n", "a_obs", "=", "obs", "[", "0", "]", "\n", "d_obs", "=", "obs", "[", "1", "]", "\n", "done", "=", "False", "\n", "episode_attacker_reward", "=", "0.0", "\n", "episode_defender_reward", "=", "0.0", "\n", "episode_length", "=", "0", "\n", "while", "not", "done", ":", "\n", "            ", "if", "pg_agent_config", ".", "eval_render", ":", "\n", "                ", "env", ".", "render", "(", ")", "\n", "time", ".", "sleep", "(", "pg_agent_config", ".", "eval_sleep", ")", "\n", "\n", "", "attacker_action", "=", "np", ".", "array", "(", "[", "0", "]", ")", "\n", "defender_action", "=", "np", ".", "array", "(", "[", "0", "]", ")", "\n", "\n", "# Get attacker and defender actions", "\n", "if", "pg_agent_config", ".", "attacker", ":", "\n", "                ", "if", "pg_agent_config", ".", "multi_channel_obs", ":", "\n", "                    ", "a_obs_a", "=", "th", ".", "Tensor", "(", "a_obs", "[", "0", "]", ")", ".", "to", "(", "device", "=", "model", ".", "device", ")", "\n", "a_obs_d", "=", "th", ".", "Tensor", "(", "a_obs", "[", "1", "]", ")", ".", "to", "(", "device", "=", "model", ".", "device", ")", "\n", "a_obs_p", "=", "th", ".", "Tensor", "(", "a_obs", "[", "2", "]", ")", ".", "to", "(", "device", "=", "model", ".", "device", ")", "\n", "a_obs_r", "=", "th", ".", "Tensor", "(", "a_obs", "[", "3", "]", ")", ".", "to", "(", "device", "=", "model", ".", "device", ")", "\n", "a_obs_0", "=", "th", ".", "Tensor", "(", "a_obs", "[", "4", "]", ")", ".", "to", "(", "device", "=", "model", ".", "device", ")", "\n", "res", "=", "model", ".", "predict", "(", "a_obs_0", ",", "deterministic", "=", "False", ",", "attacker", "=", "True", ",", "\n", "channel_1_features", "=", "a_obs_a", ",", "channel_2_features", "=", "a_obs_d", ",", "\n", "channel_3_features", "=", "a_obs_p", ",", "channel_4_features", "=", "a_obs_r", ")", "\n", "", "else", ":", "\n", "                    ", "a_obs", "=", "th", ".", "tensor", "(", "a_obs", ")", ".", "to", "(", "device", "=", "model", ".", "device", ")", "\n", "res", "=", "model", ".", "predict", "(", "a_obs", ",", "deterministic", "=", "False", ",", "attacker", "=", "True", ")", "\n", "", "if", "not", "pg_agent_config", ".", "ar_policy", ":", "\n", "                    ", "attacker_action", "=", "np", ".", "array", "(", "[", "res", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "]", ")", "\n", "", "else", ":", "\n", "                    ", "attacker_action", "=", "np", ".", "array", "(", "res", ")", "\n", "\n", "", "", "if", "pg_agent_config", ".", "defender", ":", "\n", "                ", "d_obs", "=", "th", ".", "tensor", "(", "d_obs", ")", ".", "to", "(", "device", "=", "model", ".", "device", ")", "\n", "res", "=", "model", ".", "predict", "(", "d_obs", ",", "deterministic", "=", "False", ",", "attacker", "=", "False", ")", "\n", "if", "not", "pg_agent_config", ".", "ar_policy", ":", "\n", "                    ", "defender_action", "=", "np", ".", "array", "(", "[", "res", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "]", ")", "\n", "", "else", ":", "\n", "                    ", "defender_action", "=", "np", ".", "array", "(", "res", ")", "\n", "# print(\"attacker_actions:{}\".format(attacker_action))", "\n", "# print(\"defender_actions:{}\".format(defender_action))", "\n", "# Take a step in the environment", "\n", "", "", "joint_action", "=", "np", ".", "array", "(", "[", "[", "attacker_action", ",", "defender_action", "]", "]", ")", "\n", "a_obs", ",", "d_obs", ",", "a_reward", ",", "d_reward", ",", "done", ",", "_info", "=", "env", ".", "step", "(", "joint_action", ")", "\n", "\n", "# Update state information and metrics", "\n", "episode_attacker_reward", "+=", "a_reward", "\n", "episode_defender_reward", "+=", "d_reward", "\n", "if", "callback", "is", "not", "None", ":", "\n", "                ", "callback", "(", "locals", "(", ")", ",", "globals", "(", ")", ")", "\n", "", "episode_length", "+=", "1", "\n", "# Render final frame when game completed", "\n", "", "if", "pg_agent_config", ".", "eval_render", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "time", ".", "sleep", "(", "pg_agent_config", ".", "eval_sleep", ")", "\n", "", "pg_agent_config", ".", "logger", ".", "info", "(", "\"Eval episode: {}, Game ended after {} steps\"", ".", "format", "(", "episode", ",", "episode_length", ")", ")", "\n", "\n", "# Record episode metrics", "\n", "episode_attacker_rewards", ".", "append", "(", "episode_attacker_reward", ")", "\n", "episode_defender_rewards", ".", "append", "(", "episode_defender_reward", ")", "\n", "episode_steps", ".", "append", "(", "episode_length", ")", "\n", "\n", "# Update eval stats", "\n", "model", ".", "num_eval_games", "+=", "1", "\n", "model", ".", "num_eval_games_total", "+=", "1", "\n", "\n", "if", "env", ".", "envs", "[", "0", "]", ".", "idsgame_env", ".", "state", ".", "detected", ":", "\n", "            ", "model", ".", "eval_attacker_cumulative_reward", "-=", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", "\n", "model", ".", "eval_defender_cumulative_reward", "+=", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", "\n", "", "if", "env", ".", "envs", "[", "0", "]", ".", "idsgame_env", ".", "state", ".", "hacked", ":", "\n", "            ", "model", ".", "eval_attacker_cumulative_reward", "+=", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", "\n", "model", ".", "eval_defender_cumulative_reward", "-=", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", "\n", "model", ".", "num_eval_hacks", "+=", "1", "\n", "model", ".", "num_eval_hacks_total", "+=", "1", "\n", "\n", "\n", "# Log average metrics every <self.config.eval_log_frequency> episodes", "\n", "", "if", "episode", "%", "pg_agent_config", ".", "eval_log_frequency", "==", "0", ":", "\n", "            ", "if", "model", ".", "num_eval_hacks", ">", "0", ":", "\n", "                ", "model", ".", "eval_hack_probability", "=", "float", "(", "model", ".", "num_eval_hacks", ")", "/", "float", "(", "model", ".", "num_eval_games", ")", "\n", "", "if", "model", ".", "num_eval_games_total", ">", "0", ":", "\n", "                ", "model", ".", "eval_cumulative_hack_probability", "=", "float", "(", "model", ".", "num_eval_hacks_total", ")", "/", "float", "(", "\n", "model", ".", "num_eval_games_total", ")", "\n", "", "model", ".", "log_metrics", "(", "train_episode", ",", "model", ".", "eval_result", ",", "episode_attacker_rewards", ",", "episode_defender_rewards", ",", "\n", "episode_steps", ",", "eval", "=", "True", ",", "update_stats", "=", "False", ")", "\n", "\n", "# Save gifs", "\n", "", "if", "pg_agent_config", ".", "gifs", "and", "pg_agent_config", ".", "video", ":", "\n", "# Add frames to tensorboard", "\n", "            ", "for", "idx", ",", "frame", "in", "enumerate", "(", "env", ".", "envs", "[", "0", "]", ".", "episode_frames", ")", ":", "\n", "                ", "model", ".", "tensorboard_writer", ".", "add_image", "(", "str", "(", "train_episode", ")", "+", "\"_eval_frames/\"", "+", "str", "(", "idx", ")", ",", "\n", "frame", ",", "global_step", "=", "train_episode", ",", "\n", "dataformats", "=", "\"HWC\"", ")", "\n", "\n", "# Save Gif", "\n", "", "env", ".", "envs", "[", "0", "]", ".", "generate_gif", "(", "pg_agent_config", ".", "gif_dir", "+", "\"episode_\"", "+", "str", "(", "train_episode", ")", "+", "\"_\"", "\n", "+", "time_str", "+", "\".gif\"", ",", "pg_agent_config", ".", "video_fps", ")", "\n", "\n", "# Reset LSTM state", "\n", "if", "not", "pg_agent_config", ".", "ar_policy", ":", "\n", "                ", "model", ".", "attacker_policy", ".", "mlp_extractor", ".", "lstm_hidden", "=", "(", "th", ".", "zeros", "(", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "\n", "th", ".", "zeros", "(", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "pg_agent_config", ".", "lstm_hidden_dim", ")", ")", "\n", "model", ".", "defender_policy", ".", "mlp_extractor", ".", "lstm_hidden", "=", "(", "\n", "th", ".", "zeros", "(", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "\n", "th", ".", "zeros", "(", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "pg_agent_config", ".", "lstm_hidden_dim", ")", ")", "\n", "", "else", ":", "\n", "                ", "model", ".", "attacker_node_policy", ".", "mlp_extractor", ".", "lstm_hidden", "=", "(", "th", ".", "zeros", "(", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "\n", "th", ".", "zeros", "(", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "pg_agent_config", ".", "lstm_hidden_dim", ")", ")", "\n", "model", ".", "attacker_at_policy", ".", "mlp_extractor", ".", "lstm_hidden", "=", "(", "\n", "th", ".", "zeros", "(", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "\n", "th", ".", "zeros", "(", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "pg_agent_config", ".", "lstm_hidden_dim", ")", ")", "\n", "\n", "model", ".", "defender_node_policy", ".", "mlp_extractor", ".", "lstm_hidden", "=", "(", "th", ".", "zeros", "(", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "\n", "th", ".", "zeros", "(", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "pg_agent_config", ".", "lstm_hidden_dim", ")", ")", "\n", "model", ".", "defender_at_policy", ".", "mlp_extractor", ".", "lstm_hidden", "=", "(", "\n", "th", ".", "zeros", "(", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "\n", "th", ".", "zeros", "(", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "pg_agent_config", ".", "lstm_hidden_dim", ")", ")", "\n", "\n", "\n", "# Log average eval statistics", "\n", "", "", "", "if", "model", ".", "num_eval_hacks", ">", "0", ":", "\n", "        ", "model", ".", "eval_hack_probability", "=", "float", "(", "model", ".", "num_eval_hacks", ")", "/", "float", "(", "model", ".", "num_eval_games", ")", "\n", "", "if", "model", ".", "num_eval_games_total", ">", "0", ":", "\n", "        ", "model", ".", "eval_cumulative_hack_probability", "=", "float", "(", "model", ".", "num_eval_hacks_total", ")", "/", "float", "(", "\n", "model", ".", "num_eval_games_total", ")", "\n", "", "model", ".", "log_metrics", "(", "train_episode", ",", "model", ".", "eval_result", ",", "episode_attacker_rewards", ",", "episode_defender_rewards", ",", "\n", "episode_steps", ",", "eval", "=", "True", ",", "update_stats", "=", "True", ")", "\n", "\n", "\n", "mean_reward", "=", "np", ".", "mean", "(", "episode_attacker_rewards", ")", "\n", "std_reward", "=", "np", ".", "std", "(", "episode_attacker_rewards", ")", "\n", "\n", "pg_agent_config", ".", "logger", ".", "info", "(", "\"Evaluation Complete\"", ")", "\n", "print", "(", "\"Evaluation Complete\"", ")", "\n", "env", ".", "close", "(", ")", "\n", "return", "mean_reward", ",", "std_reward", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer.__init__": [[26, 42], ["object.__init__", "stable_baselines3.common.preprocessing.get_obs_shape", "stable_baselines3.common.preprocessing.get_action_dim"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "buffer_size", ":", "int", ",", "\n", "observation_space", ":", "spaces", ".", "Space", ",", "\n", "action_space", ":", "spaces", ".", "Space", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "'cpu'", ",", "\n", "n_envs", ":", "int", "=", "1", ")", ":", "\n", "        ", "super", "(", "BaseBuffer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "buffer_size", "=", "buffer_size", "\n", "self", ".", "observation_space", "=", "observation_space", "\n", "self", ".", "action_space", "=", "action_space", "\n", "self", ".", "obs_shape", "=", "get_obs_shape", "(", "observation_space", ")", "\n", "self", ".", "action_dim", "=", "get_action_dim", "(", "action_space", ")", "\n", "self", ".", "pos", "=", "0", "\n", "self", ".", "full", "=", "False", "\n", "self", ".", "device", "=", "device", "\n", "self", ".", "n_envs", "=", "n_envs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer.swap_and_flatten": [[43, 57], ["arr.swapaxes().reshape", "len", "arr.swapaxes"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "swap_and_flatten", "(", "arr", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Swap and then flatten axes 0 (buffer_size) and 1 (n_envs)\n        to convert shape from [n_steps, n_envs, ...] (when ... is the shape of the features)\n        to [n_steps * n_envs, ...] (which maintain the order)\n\n        :param arr: (np.ndarray)\n        :return: (np.ndarray)\n        \"\"\"", "\n", "shape", "=", "arr", ".", "shape", "\n", "if", "len", "(", "shape", ")", "<", "3", ":", "\n", "            ", "shape", "=", "shape", "+", "(", "1", ",", ")", "\n", "", "return", "arr", ".", "swapaxes", "(", "0", ",", "1", ")", ".", "reshape", "(", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", ",", "*", "shape", "[", "2", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer.size": [[58, 65], ["None"], "methods", ["None"], ["", "def", "size", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        :return: (int) The current size of the buffer\n        \"\"\"", "\n", "if", "self", ".", "full", ":", "\n", "            ", "return", "self", ".", "buffer_size", "\n", "", "return", "self", ".", "pos", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer.add": [[66, 71], ["NotImplementedError"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Add elements to the buffer.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer.extend": [[72, 79], ["zip", "buffers.BaseBuffer.add"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add"], ["", "def", "extend", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Add a new batch of transitions to the buffer\n        \"\"\"", "\n", "# Do a for loop along the batch axis", "\n", "for", "data", "in", "zip", "(", "*", "args", ")", ":", "\n", "            ", "self", ".", "add", "(", "*", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer.reset": [[80, 86], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Reset the buffer.\n        \"\"\"", "\n", "self", ".", "pos", "=", "0", "\n", "self", ".", "full", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer.sample": [[87, 100], ["numpy.random.randint", "buffers.BaseBuffer._get_samples"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead._get_samples"], ["", "def", "sample", "(", "self", ",", "\n", "batch_size", ":", "int", ",", "\n", "env", ":", "Optional", "[", "VecNormalize", "]", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"\n        :param batch_size: (int) Number of element to sample\n        :param env: (Optional[VecNormalize]) associated gym VecEnv\n            to normalize the observations/rewards when sampling\n        :return: (Union[RolloutBufferSamples, ReplayBufferSamples])\n        \"\"\"", "\n", "upper_bound", "=", "self", ".", "buffer_size", "if", "self", ".", "full", "else", "self", ".", "pos", "\n", "batch_inds", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "upper_bound", ",", "size", "=", "batch_size", ")", "\n", "return", "self", ".", "_get_samples", "(", "batch_inds", ",", "env", "=", "env", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer._get_samples": [[101, 111], ["NotImplementedError"], "methods", ["None"], ["", "def", "_get_samples", "(", "self", ",", "\n", "batch_inds", ":", "np", ".", "ndarray", ",", "\n", "env", ":", "Optional", "[", "VecNormalize", "]", "=", "None", "\n", ")", ":", "\n", "        ", "\"\"\"\n        :param batch_inds: (th.Tensor)\n        :param env: (Optional[VecNormalize])\n        :return: (Union[RolloutBufferSamples, ReplayBufferSamples])\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer.to_torch": [[112, 125], ["torch.as_tensor().to", "torch.tensor().to", "torch.as_tensor", "torch.tensor"], "methods", ["None"], ["", "def", "to_torch", "(", "self", ",", "array", ":", "np", ".", "ndarray", ",", "copy", ":", "bool", "=", "True", ")", "->", "th", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Convert a numpy array to a PyTorch tensor.\n        Note: it copies the data by default\n\n        :param array: (np.ndarray)\n        :param copy: (bool) Whether to copy or not the data\n            (may be useful to avoid changing things be reference)\n        :return: (th.Tensor)\n        \"\"\"", "\n", "if", "copy", ":", "\n", "            ", "return", "th", ".", "tensor", "(", "array", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "", "return", "th", ".", "as_tensor", "(", "array", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer._normalize_obs": [[126, 132], ["env.normalize_obs().astype", "env.normalize_obs"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.normalize_obs"], ["", "@", "staticmethod", "\n", "def", "_normalize_obs", "(", "obs", ":", "np", ".", "ndarray", ",", "\n", "env", ":", "Optional", "[", "VecNormalize", "]", "=", "None", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "if", "env", "is", "not", "None", ":", "\n", "            ", "return", "env", ".", "normalize_obs", "(", "obs", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer._normalize_reward": [[133, 139], ["env.normalize_reward().astype", "env.normalize_reward"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.normalize_reward"], ["", "@", "staticmethod", "\n", "def", "_normalize_reward", "(", "reward", ":", "np", ".", "ndarray", ",", "\n", "env", ":", "Optional", "[", "VecNormalize", "]", "=", "None", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "if", "env", "is", "not", "None", ":", "\n", "            ", "return", "env", ".", "normalize_reward", "(", "reward", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "", "return", "reward", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.ReplayBuffer.__init__": [[152, 168], ["buffers.BaseBuffer.__init__", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "buffer_size", ":", "int", ",", "\n", "observation_space", ":", "spaces", ".", "Space", ",", "\n", "action_space", ":", "spaces", ".", "Space", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "'cpu'", ",", "\n", "n_envs", ":", "int", "=", "1", ")", ":", "\n", "        ", "super", "(", "ReplayBuffer", ",", "self", ")", ".", "__init__", "(", "buffer_size", ",", "observation_space", ",", "\n", "action_space", ",", "device", ",", "n_envs", "=", "n_envs", ")", "\n", "\n", "assert", "n_envs", "==", "1", ",", "\"Replay buffer only support single environment for now\"", "\n", "\n", "self", ".", "observations", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", ")", "+", "self", ".", "obs_shape", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "actions", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "action_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "next_observations", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", ")", "+", "self", ".", "obs_shape", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "rewards", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "dones", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.ReplayBuffer.add": [[169, 186], ["numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy"], ["", "def", "add", "(", "self", ",", "\n", "obs", ":", "np", ".", "ndarray", ",", "\n", "next_obs", ":", "np", ".", "ndarray", ",", "\n", "action", ":", "np", ".", "ndarray", ",", "\n", "reward", ":", "np", ".", "ndarray", ",", "\n", "done", ":", "np", ".", "ndarray", ")", "->", "None", ":", "\n", "# Copy to avoid modification by reference", "\n", "        ", "self", ".", "observations", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "obs", ")", ".", "copy", "(", ")", "\n", "self", ".", "next_observations", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "next_obs", ")", ".", "copy", "(", ")", "\n", "self", ".", "actions", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "action", ")", ".", "copy", "(", ")", "\n", "self", ".", "rewards", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "reward", ")", ".", "copy", "(", ")", "\n", "self", ".", "dones", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "done", ")", ".", "copy", "(", ")", "\n", "\n", "self", ".", "pos", "+=", "1", "\n", "if", "self", ".", "pos", "==", "self", ".", "buffer_size", ":", "\n", "            ", "self", ".", "full", "=", "True", "\n", "self", ".", "pos", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.ReplayBuffer._get_samples": [[187, 197], ["gym_idsgame.agents.training_agents.openai_baselines.common.type_aliases.ReplayBufferSamples", "buffers.ReplayBuffer._normalize_obs", "buffers.ReplayBuffer._normalize_obs", "buffers.ReplayBuffer._normalize_reward", "tuple", "map"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer._normalize_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer._normalize_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer._normalize_reward"], ["", "", "def", "_get_samples", "(", "self", ",", "\n", "batch_inds", ":", "np", ".", "ndarray", ",", "\n", "env", ":", "Optional", "[", "VecNormalize", "]", "=", "None", "\n", ")", "->", "ReplayBufferSamples", ":", "\n", "        ", "data", "=", "(", "self", ".", "_normalize_obs", "(", "self", ".", "observations", "[", "batch_inds", ",", "0", ",", ":", "]", ",", "env", ")", ",", "\n", "self", ".", "actions", "[", "batch_inds", ",", "0", ",", ":", "]", ",", "\n", "self", ".", "_normalize_obs", "(", "self", ".", "next_observations", "[", "batch_inds", ",", "0", ",", ":", "]", ",", "env", ")", ",", "\n", "self", ".", "dones", "[", "batch_inds", "]", ",", "\n", "self", ".", "_normalize_reward", "(", "self", ".", "rewards", "[", "batch_inds", "]", ",", "env", ")", ")", "\n", "return", "ReplayBufferSamples", "(", "*", "tuple", "(", "map", "(", "self", ".", "to_torch", ",", "data", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBuffer.__init__": [[213, 230], ["buffers.BaseBuffer.__init__", "buffers.RolloutBuffer.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset"], ["def", "__init__", "(", "self", ",", "\n", "buffer_size", ":", "int", ",", "\n", "observation_space", ":", "spaces", ".", "Space", ",", "\n", "action_space", ":", "spaces", ".", "Space", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "'cpu'", ",", "\n", "gae_lambda", ":", "float", "=", "1", ",", "\n", "gamma", ":", "float", "=", "0.99", ",", "\n", "n_envs", ":", "int", "=", "1", ")", ":", "\n", "\n", "        ", "super", "(", "RolloutBuffer", ",", "self", ")", ".", "__init__", "(", "buffer_size", ",", "observation_space", ",", "\n", "action_space", ",", "device", ",", "n_envs", "=", "n_envs", ")", "\n", "self", ".", "gae_lambda", "=", "gae_lambda", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "observations", ",", "self", ".", "actions", ",", "self", ".", "rewards", ",", "self", ".", "advantages", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "self", ".", "returns", ",", "self", ".", "dones", ",", "self", ".", "values", ",", "self", ".", "log_probs", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "self", ".", "generator_ready", "=", "False", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBuffer.reset": [[231, 242], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "buffers.BaseBuffer.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "observations", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", ")", "+", "self", ".", "obs_shape", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "actions", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "action_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "rewards", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "returns", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "dones", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "values", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "log_probs", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "advantages", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "generator_ready", "=", "False", "\n", "super", "(", "RolloutBuffer", ",", "self", ")", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBuffer.compute_returns_and_advantage": [[243, 275], ["last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten", "reversed", "range", "last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu().numpy", "last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu", "last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone"], "methods", ["None"], ["", "def", "compute_returns_and_advantage", "(", "self", ",", "\n", "last_value", ":", "th", ".", "Tensor", ",", "\n", "dones", ":", "np", ".", "ndarray", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Post-processing step: compute the returns (sum of discounted rewards)\n        and GAE advantage.\n        Adapted from Stable-Baselines PPO2.\n\n        Uses Generalized Advantage Estimation (https://arxiv.org/abs/1506.02438)\n        to compute the advantage. To obtain vanilla advantage (A(s) = R - V(S))\n        where R is the discounted reward with value bootstrap,\n        set ``gae_lambda=1.0`` during initialization.\n\n        :param last_value: (th.Tensor)\n        :param dones: (np.ndarray)\n\n        \"\"\"", "\n", "# convert to numpy", "\n", "last_value", "=", "last_value", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "\n", "last_gae_lam", "=", "0", "\n", "for", "step", "in", "reversed", "(", "range", "(", "self", ".", "buffer_size", ")", ")", ":", "\n", "            ", "if", "step", "==", "self", ".", "buffer_size", "-", "1", ":", "\n", "                ", "next_non_terminal", "=", "1.0", "-", "dones", "\n", "next_value", "=", "last_value", "\n", "", "else", ":", "\n", "                ", "next_non_terminal", "=", "1.0", "-", "self", ".", "dones", "[", "step", "+", "1", "]", "\n", "next_value", "=", "self", ".", "values", "[", "step", "+", "1", "]", "\n", "", "delta", "=", "self", ".", "rewards", "[", "step", "]", "+", "self", ".", "gamma", "*", "next_value", "*", "next_non_terminal", "-", "self", ".", "values", "[", "step", "]", "\n", "last_gae_lam", "=", "delta", "+", "self", ".", "gamma", "*", "self", ".", "gae_lambda", "*", "next_non_terminal", "*", "last_gae_lam", "\n", "self", ".", "advantages", "[", "step", "]", "=", "last_gae_lam", "\n", "", "self", ".", "returns", "=", "self", ".", "advantages", "+", "self", ".", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBuffer.add": [[276, 306], ["numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "value.clone().cpu().numpy().flatten", "log_prob.reshape.reshape.clone().cpu().numpy", "len", "log_prob.reshape.reshape.reshape", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "value.clone().cpu().numpy", "log_prob.reshape.reshape.clone().cpu", "value.clone().cpu", "log_prob.reshape.reshape.clone", "value.clone"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy"], ["", "def", "add", "(", "self", ",", "\n", "obs", ":", "np", ".", "ndarray", ",", "\n", "action", ":", "np", ".", "ndarray", ",", "\n", "reward", ":", "np", ".", "ndarray", ",", "\n", "done", ":", "np", ".", "ndarray", ",", "\n", "value", ":", "th", ".", "Tensor", ",", "\n", "log_prob", ":", "th", ".", "Tensor", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        :param obs: (np.ndarray) Observation\n        :param action: (np.ndarray) Action\n        :param reward: (np.ndarray)\n        :param done: (np.ndarray) End of episode signal.\n        :param value: (th.Tensor) estimated value of the current state\n            following the current policy.\n        :param log_prob: (th.Tensor) log probability of the action\n            following the current policy.\n        \"\"\"", "\n", "if", "len", "(", "log_prob", ".", "shape", ")", "==", "0", ":", "\n", "# Reshape 0-d tensor to avoid error", "\n", "            ", "log_prob", "=", "log_prob", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "", "self", ".", "observations", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "obs", ")", ".", "copy", "(", ")", "\n", "self", ".", "actions", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "action", ")", ".", "copy", "(", ")", "\n", "self", ".", "rewards", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "reward", ")", ".", "copy", "(", ")", "\n", "self", ".", "dones", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "done", ")", ".", "copy", "(", ")", "\n", "self", ".", "values", "[", "self", ".", "pos", "]", "=", "value", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "self", ".", "log_probs", "[", "self", ".", "pos", "]", "=", "log_prob", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "pos", "+=", "1", "\n", "if", "self", ".", "pos", "==", "self", ".", "buffer_size", ":", "\n", "            ", "self", ".", "full", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBuffer.get": [[307, 325], ["numpy.random.permutation", "buffers.RolloutBuffer.swap_and_flatten", "buffers.RolloutBuffer._get_samples"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer.swap_and_flatten", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead._get_samples"], ["", "", "def", "get", "(", "self", ",", "batch_size", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "Generator", "[", "RolloutBufferSamples", ",", "None", ",", "None", "]", ":", "\n", "        ", "assert", "self", ".", "full", ",", "''", "\n", "indices", "=", "np", ".", "random", ".", "permutation", "(", "self", ".", "buffer_size", "*", "self", ".", "n_envs", ")", "\n", "# Prepare the data", "\n", "if", "not", "self", ".", "generator_ready", ":", "\n", "            ", "for", "tensor", "in", "[", "'observations'", ",", "'actions'", ",", "'values'", ",", "\n", "'log_probs'", ",", "'advantages'", ",", "'returns'", "]", ":", "\n", "                ", "self", ".", "__dict__", "[", "tensor", "]", "=", "self", ".", "swap_and_flatten", "(", "self", ".", "__dict__", "[", "tensor", "]", ")", "\n", "", "self", ".", "generator_ready", "=", "True", "\n", "\n", "# Return everything, don't create minibatches", "\n", "", "if", "batch_size", "is", "None", ":", "\n", "            ", "batch_size", "=", "self", ".", "buffer_size", "*", "self", ".", "n_envs", "\n", "\n", "", "start_idx", "=", "0", "\n", "while", "start_idx", "<", "self", ".", "buffer_size", "*", "self", ".", "n_envs", ":", "\n", "            ", "yield", "self", ".", "_get_samples", "(", "indices", "[", "start_idx", ":", "start_idx", "+", "batch_size", "]", ")", "\n", "start_idx", "+=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBuffer._get_samples": [[326, 335], ["gym_idsgame.agents.training_agents.openai_baselines.common.type_aliases.RolloutBufferSamples", "buffers.RolloutBuffer.values[].flatten", "buffers.RolloutBuffer.log_probs[].flatten", "buffers.RolloutBuffer.advantages[].flatten", "buffers.RolloutBuffer.returns[].flatten", "tuple", "map"], "methods", ["None"], ["", "", "def", "_get_samples", "(", "self", ",", "batch_inds", ":", "np", ".", "ndarray", ",", "\n", "env", ":", "Optional", "[", "VecNormalize", "]", "=", "None", ")", "->", "RolloutBufferSamples", ":", "\n", "        ", "data", "=", "(", "self", ".", "observations", "[", "batch_inds", "]", ",", "\n", "self", ".", "actions", "[", "batch_inds", "]", ",", "\n", "self", ".", "values", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "log_probs", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "advantages", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "returns", "[", "batch_inds", "]", ".", "flatten", "(", ")", ")", "\n", "return", "RolloutBufferSamples", "(", "*", "tuple", "(", "map", "(", "self", ".", "to_torch", ",", "data", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferRecurrent.__init__": [[351, 370], ["buffers.BaseBuffer.__init__", "buffers.RolloutBufferRecurrent.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset"], ["def", "__init__", "(", "self", ",", "\n", "buffer_size", ":", "int", ",", "\n", "observation_space", ":", "spaces", ".", "Space", ",", "\n", "action_space", ":", "spaces", ".", "Space", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "'cpu'", ",", "\n", "gae_lambda", ":", "float", "=", "1", ",", "\n", "gamma", ":", "float", "=", "0.99", ",", "\n", "n_envs", ":", "int", "=", "1", ",", "\n", "pg_agent_config", ":", "PolicyGradientAgentConfig", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", "RolloutBufferRecurrent", ",", "self", ")", ".", "__init__", "(", "buffer_size", ",", "observation_space", ",", "\n", "action_space", ",", "device", ",", "n_envs", "=", "n_envs", ")", "\n", "self", ".", "pg_agent_config", "=", "pg_agent_config", "\n", "self", ".", "gae_lambda", "=", "gae_lambda", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "observations", ",", "self", ".", "actions", ",", "self", ".", "rewards", ",", "self", ".", "advantages", "=", "None", ",", "None", ",", "None", ",", "None", "\n", "self", ".", "returns", ",", "self", ".", "dones", ",", "self", ".", "values", ",", "self", ".", "log_probs", ",", "self", ".", "h_states", ",", "self", ".", "c_states", "=", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "self", ".", "generator_ready", "=", "False", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferRecurrent.reset": [[371, 386], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "buffers.BaseBuffer.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "observations", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", ")", "+", "self", ".", "obs_shape", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "actions", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "action_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "rewards", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "returns", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "dones", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "values", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "log_probs", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "advantages", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "h_states", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "c_states", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "generator_ready", "=", "False", "\n", "super", "(", "RolloutBufferRecurrent", ",", "self", ")", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferRecurrent.compute_returns_and_advantage": [[387, 419], ["last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten", "reversed", "range", "last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu().numpy", "last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu", "last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone"], "methods", ["None"], ["", "def", "compute_returns_and_advantage", "(", "self", ",", "\n", "last_value", ":", "th", ".", "Tensor", ",", "\n", "dones", ":", "np", ".", "ndarray", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Post-processing step: compute the returns (sum of discounted rewards)\n        and GAE advantage.\n        Adapted from Stable-Baselines PPO2.\n\n        Uses Generalized Advantage Estimation (https://arxiv.org/abs/1506.02438)\n        to compute the advantage. To obtain vanilla advantage (A(s) = R - V(S))\n        where R is the discounted reward with value bootstrap,\n        set ``gae_lambda=1.0`` during initialization.\n\n        :param last_value: (th.Tensor)\n        :param dones: (np.ndarray)\n\n        \"\"\"", "\n", "# convert to numpy", "\n", "last_value", "=", "last_value", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "\n", "last_gae_lam", "=", "0", "\n", "for", "step", "in", "reversed", "(", "range", "(", "self", ".", "buffer_size", ")", ")", ":", "\n", "            ", "if", "step", "==", "self", ".", "buffer_size", "-", "1", ":", "\n", "                ", "next_non_terminal", "=", "1.0", "-", "dones", "\n", "next_value", "=", "last_value", "\n", "", "else", ":", "\n", "                ", "next_non_terminal", "=", "1.0", "-", "self", ".", "dones", "[", "step", "+", "1", "]", "\n", "next_value", "=", "self", ".", "values", "[", "step", "+", "1", "]", "\n", "", "delta", "=", "self", ".", "rewards", "[", "step", "]", "+", "self", ".", "gamma", "*", "next_value", "*", "next_non_terminal", "-", "self", ".", "values", "[", "step", "]", "\n", "last_gae_lam", "=", "delta", "+", "self", ".", "gamma", "*", "self", ".", "gae_lambda", "*", "next_non_terminal", "*", "last_gae_lam", "\n", "self", ".", "advantages", "[", "step", "]", "=", "last_gae_lam", "\n", "", "self", ".", "returns", "=", "self", ".", "advantages", "+", "self", ".", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferRecurrent.add": [[420, 453], ["numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "value.clone().cpu().numpy().flatten", "log_prob.reshape.reshape.clone().cpu().numpy", "state[].clone().cpu().numpy", "state[].clone().cpu().numpy", "len", "log_prob.reshape.reshape.reshape", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "value.clone().cpu().numpy", "log_prob.reshape.reshape.clone().cpu", "state[].clone().cpu", "state[].clone().cpu", "value.clone().cpu", "log_prob.reshape.reshape.clone", "state[].clone", "state[].clone", "value.clone"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy"], ["", "def", "add", "(", "self", ",", "\n", "obs", ":", "np", ".", "ndarray", ",", "\n", "action", ":", "np", ".", "ndarray", ",", "\n", "reward", ":", "np", ".", "ndarray", ",", "\n", "done", ":", "np", ".", "ndarray", ",", "\n", "value", ":", "th", ".", "Tensor", ",", "\n", "log_prob", ":", "th", ".", "Tensor", ",", "\n", "state", ":", "th", ".", "Tensor", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        :param obs: (np.ndarray) Observation\n        :param action: (np.ndarray) Action\n        :param reward: (np.ndarray)\n        :param done: (np.ndarray) End of episode signal.\n        :param value: (th.Tensor) estimated value of the current state\n            following the current policy.\n        :param log_prob: (th.Tensor) log probability of the action\n            following the current policy.\n        \"\"\"", "\n", "if", "len", "(", "log_prob", ".", "shape", ")", "==", "0", ":", "\n", "# Reshape 0-d tensor to avoid error", "\n", "            ", "log_prob", "=", "log_prob", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "", "self", ".", "observations", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "obs", ")", ".", "copy", "(", ")", "\n", "self", ".", "actions", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "action", ")", ".", "copy", "(", ")", "\n", "self", ".", "rewards", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "reward", ")", ".", "copy", "(", ")", "\n", "self", ".", "dones", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "done", ")", ".", "copy", "(", ")", "\n", "self", ".", "values", "[", "self", ".", "pos", "]", "=", "value", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "self", ".", "log_probs", "[", "self", ".", "pos", "]", "=", "log_prob", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "h_states", "[", "self", ".", "pos", "]", "=", "state", "[", "0", "]", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "c_states", "[", "self", ".", "pos", "]", "=", "state", "[", "1", "]", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "pos", "+=", "1", "\n", "if", "self", ".", "pos", "==", "self", ".", "buffer_size", ":", "\n", "            ", "self", ".", "full", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferRecurrent.get": [[454, 472], ["numpy.random.permutation", "buffers.RolloutBufferRecurrent.swap_and_flatten", "buffers.RolloutBufferRecurrent._get_samples"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer.swap_and_flatten", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead._get_samples"], ["", "", "def", "get", "(", "self", ",", "batch_size", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "Generator", "[", "RolloutBufferSamplesRecurrent", ",", "None", ",", "None", "]", ":", "\n", "        ", "assert", "self", ".", "full", ",", "''", "\n", "indices", "=", "np", ".", "random", ".", "permutation", "(", "self", ".", "buffer_size", "*", "self", ".", "n_envs", ")", "\n", "# Prepare the data", "\n", "if", "not", "self", ".", "generator_ready", ":", "\n", "            ", "for", "tensor", "in", "[", "'observations'", ",", "'actions'", ",", "'values'", ",", "\n", "'log_probs'", ",", "'advantages'", ",", "'returns'", ",", "'h_states'", ",", "'c_states'", ",", "'dones'", "]", ":", "\n", "                ", "self", ".", "__dict__", "[", "tensor", "]", "=", "self", ".", "swap_and_flatten", "(", "self", ".", "__dict__", "[", "tensor", "]", ")", "\n", "", "self", ".", "generator_ready", "=", "True", "\n", "\n", "# Return everything, don't create minibatches", "\n", "", "if", "batch_size", "is", "None", ":", "\n", "            ", "batch_size", "=", "self", ".", "buffer_size", "*", "self", ".", "n_envs", "\n", "\n", "", "start_idx", "=", "0", "\n", "while", "start_idx", "<", "self", ".", "buffer_size", "*", "self", ".", "n_envs", ":", "\n", "            ", "yield", "self", ".", "_get_samples", "(", "indices", "[", "start_idx", ":", "start_idx", "+", "batch_size", "]", ")", "\n", "start_idx", "+=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferRecurrent._get_samples": [[473, 486], ["gym_idsgame.agents.training_agents.openai_baselines.common.type_aliases.RolloutBufferSamplesRecurrent", "buffers.RolloutBufferRecurrent.values[].flatten", "buffers.RolloutBufferRecurrent.log_probs[].flatten", "buffers.RolloutBufferRecurrent.advantages[].flatten", "buffers.RolloutBufferRecurrent.returns[].flatten", "tuple", "map"], "methods", ["None"], ["", "", "def", "_get_samples", "(", "self", ",", "batch_inds", ":", "np", ".", "ndarray", ",", "\n", "env", ":", "Optional", "[", "VecNormalize", "]", "=", "None", ")", "->", "RolloutBufferSamplesRecurrent", ":", "\n", "        ", "data", "=", "(", "self", ".", "observations", "[", "batch_inds", "]", ",", "\n", "self", ".", "actions", "[", "batch_inds", "]", ",", "\n", "self", ".", "values", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "log_probs", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "advantages", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "returns", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "h_states", "[", "batch_inds", "]", ",", "\n", "self", ".", "c_states", "[", "batch_inds", "]", ",", "\n", "self", ".", "dones", "[", "batch_inds", "]", "\n", ")", "\n", "return", "RolloutBufferSamplesRecurrent", "(", "*", "tuple", "(", "map", "(", "self", ".", "to_torch", ",", "data", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferRecurrentMultiHead.__init__": [[502, 522], ["buffers.BaseBuffer.__init__", "buffers.RolloutBufferRecurrentMultiHead.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset"], ["def", "__init__", "(", "self", ",", "\n", "buffer_size", ":", "int", ",", "\n", "observation_space", ":", "spaces", ".", "Space", ",", "\n", "action_space", ":", "spaces", ".", "Space", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "'cpu'", ",", "\n", "gae_lambda", ":", "float", "=", "1", ",", "\n", "gamma", ":", "float", "=", "0.99", ",", "\n", "n_envs", ":", "int", "=", "1", ",", "\n", "pg_agent_config", ":", "PolicyGradientAgentConfig", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", "RolloutBufferRecurrentMultiHead", ",", "self", ")", ".", "__init__", "(", "buffer_size", ",", "observation_space", ",", "\n", "action_space", ",", "device", ",", "n_envs", "=", "n_envs", ")", "\n", "self", ".", "pg_agent_config", "=", "pg_agent_config", "\n", "self", ".", "gae_lambda", "=", "gae_lambda", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "observations_1", ",", "self", ".", "observations_2", ",", "self", ".", "observations_3", ",", "self", ".", "observations_4", ",", "self", ".", "actions", ",", "self", ".", "rewards", ",", "self", ".", "advantages", "=", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "self", ".", "returns", ",", "self", ".", "dones", ",", "self", ".", "values", ",", "self", ".", "log_probs", ",", "self", ".", "h_states", ",", "self", ".", "c_states", "=", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "self", ".", "generator_ready", "=", "False", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferRecurrentMultiHead.reset": [[523, 541], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "buffers.BaseBuffer.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "observations_1", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "channel_1_input_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "observations_2", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "channel_2_input_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "observations_3", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "channel_3_input_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "observations_4", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "channel_4_input_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "actions", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "action_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "rewards", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "returns", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "dones", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "values", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "log_probs", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "advantages", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "h_states", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "c_states", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "generator_ready", "=", "False", "\n", "super", "(", "RolloutBufferRecurrentMultiHead", ",", "self", ")", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferRecurrentMultiHead.compute_returns_and_advantage": [[542, 574], ["last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten", "reversed", "range", "last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu().numpy", "last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu", "last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone"], "methods", ["None"], ["", "def", "compute_returns_and_advantage", "(", "self", ",", "\n", "last_value", ":", "th", ".", "Tensor", ",", "\n", "dones", ":", "np", ".", "ndarray", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Post-processing step: compute the returns (sum of discounted rewards)\n        and GAE advantage.\n        Adapted from Stable-Baselines PPO2.\n\n        Uses Generalized Advantage Estimation (https://arxiv.org/abs/1506.02438)\n        to compute the advantage. To obtain vanilla advantage (A(s) = R - V(S))\n        where R is the discounted reward with value bootstrap,\n        set ``gae_lambda=1.0`` during initialization.\n\n        :param last_value: (th.Tensor)\n        :param dones: (np.ndarray)\n\n        \"\"\"", "\n", "# convert to numpy", "\n", "last_value", "=", "last_value", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "\n", "last_gae_lam", "=", "0", "\n", "for", "step", "in", "reversed", "(", "range", "(", "self", ".", "buffer_size", ")", ")", ":", "\n", "            ", "if", "step", "==", "self", ".", "buffer_size", "-", "1", ":", "\n", "                ", "next_non_terminal", "=", "1.0", "-", "dones", "\n", "next_value", "=", "last_value", "\n", "", "else", ":", "\n", "                ", "next_non_terminal", "=", "1.0", "-", "self", ".", "dones", "[", "step", "+", "1", "]", "\n", "next_value", "=", "self", ".", "values", "[", "step", "+", "1", "]", "\n", "", "delta", "=", "self", ".", "rewards", "[", "step", "]", "+", "self", ".", "gamma", "*", "next_value", "*", "next_non_terminal", "-", "self", ".", "values", "[", "step", "]", "\n", "last_gae_lam", "=", "delta", "+", "self", ".", "gamma", "*", "self", ".", "gae_lambda", "*", "next_non_terminal", "*", "last_gae_lam", "\n", "self", ".", "advantages", "[", "step", "]", "=", "last_gae_lam", "\n", "", "self", ".", "returns", "=", "self", ".", "advantages", "+", "self", ".", "values", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferRecurrentMultiHead.add": [[575, 614], ["numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "value.clone().cpu().numpy().flatten", "log_prob.reshape.reshape.clone().cpu().numpy", "state[].clone().cpu().numpy", "state[].clone().cpu().numpy", "len", "log_prob.reshape.reshape.reshape", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "value.clone().cpu().numpy", "log_prob.reshape.reshape.clone().cpu", "state[].clone().cpu", "state[].clone().cpu", "value.clone().cpu", "log_prob.reshape.reshape.clone", "state[].clone", "state[].clone", "value.clone"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy"], ["", "def", "add", "(", "self", ",", "\n", "obs_1", ":", "np", ".", "ndarray", ",", "\n", "obs_2", ":", "np", ".", "ndarray", ",", "\n", "obs_3", ":", "np", ".", "ndarray", ",", "\n", "obs_4", ":", "np", ".", "ndarray", ",", "\n", "action", ":", "np", ".", "ndarray", ",", "\n", "reward", ":", "np", ".", "ndarray", ",", "\n", "done", ":", "np", ".", "ndarray", ",", "\n", "value", ":", "th", ".", "Tensor", ",", "\n", "log_prob", ":", "th", ".", "Tensor", ",", "\n", "state", ":", "th", ".", "Tensor", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        :param obs: (np.ndarray) Observation\n        :param action: (np.ndarray) Action\n        :param reward: (np.ndarray)\n        :param done: (np.ndarray) End of episode signal.\n        :param value: (th.Tensor) estimated value of the current state\n            following the current policy.\n        :param log_prob: (th.Tensor) log probability of the action\n            following the current policy.\n        \"\"\"", "\n", "if", "len", "(", "log_prob", ".", "shape", ")", "==", "0", ":", "\n", "# Reshape 0-d tensor to avoid error", "\n", "            ", "log_prob", "=", "log_prob", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "", "self", ".", "observations_1", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "obs_1", ")", ".", "copy", "(", ")", "\n", "self", ".", "observations_2", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "obs_2", ")", ".", "copy", "(", ")", "\n", "self", ".", "observations_3", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "obs_3", ")", ".", "copy", "(", ")", "\n", "self", ".", "observations_4", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "obs_4", ")", ".", "copy", "(", ")", "\n", "self", ".", "actions", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "action", ")", ".", "copy", "(", ")", "\n", "self", ".", "rewards", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "reward", ")", ".", "copy", "(", ")", "\n", "self", ".", "dones", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "done", ")", ".", "copy", "(", ")", "\n", "self", ".", "values", "[", "self", ".", "pos", "]", "=", "value", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "self", ".", "log_probs", "[", "self", ".", "pos", "]", "=", "log_prob", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "h_states", "[", "self", ".", "pos", "]", "=", "state", "[", "0", "]", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "c_states", "[", "self", ".", "pos", "]", "=", "state", "[", "1", "]", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "pos", "+=", "1", "\n", "if", "self", ".", "pos", "==", "self", ".", "buffer_size", ":", "\n", "            ", "self", ".", "full", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferRecurrentMultiHead.get": [[615, 634], ["numpy.random.permutation", "buffers.RolloutBufferRecurrentMultiHead.swap_and_flatten", "buffers.RolloutBufferRecurrentMultiHead._get_samples"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer.swap_and_flatten", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead._get_samples"], ["", "", "def", "get", "(", "self", ",", "batch_size", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "Generator", "[", "RolloutBufferSamplesRecurrentMultiHead", ",", "None", ",", "None", "]", ":", "\n", "        ", "assert", "self", ".", "full", ",", "''", "\n", "indices", "=", "np", ".", "random", ".", "permutation", "(", "self", ".", "buffer_size", "*", "self", ".", "n_envs", ")", "\n", "# Prepare the data", "\n", "if", "not", "self", ".", "generator_ready", ":", "\n", "            ", "for", "tensor", "in", "[", "'observations_1'", ",", "'observations_2'", ",", "'observations_3'", ",", "'observations_4'", ",", "\n", "'actions'", ",", "'values'", ",", "\n", "'log_probs'", ",", "'advantages'", ",", "'returns'", ",", "'h_states'", ",", "'c_states'", ",", "'dones'", "]", ":", "\n", "                ", "self", ".", "__dict__", "[", "tensor", "]", "=", "self", ".", "swap_and_flatten", "(", "self", ".", "__dict__", "[", "tensor", "]", ")", "\n", "", "self", ".", "generator_ready", "=", "True", "\n", "\n", "# Return everything, don't create minibatches", "\n", "", "if", "batch_size", "is", "None", ":", "\n", "            ", "batch_size", "=", "self", ".", "buffer_size", "*", "self", ".", "n_envs", "\n", "\n", "", "start_idx", "=", "0", "\n", "while", "start_idx", "<", "self", ".", "buffer_size", "*", "self", ".", "n_envs", ":", "\n", "            ", "yield", "self", ".", "_get_samples", "(", "indices", "[", "start_idx", ":", "start_idx", "+", "batch_size", "]", ")", "\n", "start_idx", "+=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferRecurrentMultiHead._get_samples": [[635, 651], ["gym_idsgame.agents.training_agents.openai_baselines.common.type_aliases.RolloutBufferSamplesRecurrentMultiHead", "buffers.RolloutBufferRecurrentMultiHead.values[].flatten", "buffers.RolloutBufferRecurrentMultiHead.log_probs[].flatten", "buffers.RolloutBufferRecurrentMultiHead.advantages[].flatten", "buffers.RolloutBufferRecurrentMultiHead.returns[].flatten", "tuple", "map"], "methods", ["None"], ["", "", "def", "_get_samples", "(", "self", ",", "batch_inds", ":", "np", ".", "ndarray", ",", "\n", "env", ":", "Optional", "[", "VecNormalize", "]", "=", "None", ")", "->", "RolloutBufferSamplesRecurrentMultiHead", ":", "\n", "        ", "data", "=", "(", "self", ".", "observations_1", "[", "batch_inds", "]", ",", "\n", "self", ".", "observations_2", "[", "batch_inds", "]", ",", "\n", "self", ".", "observations_3", "[", "batch_inds", "]", ",", "\n", "self", ".", "observations_4", "[", "batch_inds", "]", ",", "\n", "self", ".", "actions", "[", "batch_inds", "]", ",", "\n", "self", ".", "values", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "log_probs", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "advantages", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "returns", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "h_states", "[", "batch_inds", "]", ",", "\n", "self", ".", "c_states", "[", "batch_inds", "]", ",", "\n", "self", ".", "dones", "[", "batch_inds", "]", "\n", ")", "\n", "return", "RolloutBufferSamplesRecurrentMultiHead", "(", "*", "tuple", "(", "map", "(", "self", ".", "to_torch", ",", "data", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferAR.__init__": [[667, 689], ["buffers.BaseBuffer.__init__", "buffers.RolloutBufferAR.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset"], ["def", "__init__", "(", "self", ",", "\n", "buffer_size", ":", "int", ",", "\n", "observation_space", ":", "spaces", ".", "Space", ",", "\n", "action_space", ":", "spaces", ".", "Space", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "'cpu'", ",", "\n", "gae_lambda", ":", "float", "=", "1", ",", "\n", "gamma", ":", "float", "=", "0.99", ",", "\n", "n_envs", ":", "int", "=", "1", ",", "\n", "pg_agent_config", ":", "PolicyGradientAgentConfig", "=", "None", ",", "\n", "attacker", ":", "bool", "=", "False", ")", ":", "\n", "\n", "        ", "super", "(", "RolloutBufferAR", ",", "self", ")", ".", "__init__", "(", "buffer_size", ",", "observation_space", ",", "\n", "action_space", ",", "device", ",", "n_envs", "=", "n_envs", ")", "\n", "self", ".", "pg_agent_config", "=", "pg_agent_config", "\n", "self", ".", "attacker", "=", "attacker", "\n", "self", ".", "gae_lambda", "=", "gae_lambda", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "node_observations", ",", "self", ".", "at_observations", ",", "self", ".", "node_actions", ",", "self", ".", "at_actions", ",", "self", ".", "rewards", ",", "self", ".", "node_advantages", ",", "self", ".", "at_advantages", "=", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "self", ".", "node_returns", ",", "self", ".", "at_returns", ",", "self", ".", "dones", ",", "self", ".", "node_values", ",", "self", ".", "at_values", ",", "self", ".", "node_log_probs", ",", "self", ".", "at_log_probs", "=", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "self", ".", "generator_ready", "=", "False", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferAR.reset": [[690, 711], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "buffers.BaseBuffer.reset", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "if", "self", ".", "attacker", ":", "\n", "            ", "self", ".", "node_observations", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "attacker_node_net_input_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_observations", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "attacker_at_net_input_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "node_observations", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "defender_node_net_input_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_observations", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "defender_at_net_input_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "self", ".", "node_actions", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "action_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_actions", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "action_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "rewards", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "node_returns", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_returns", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "dones", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "node_values", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_values", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "node_log_probs", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_log_probs", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "node_advantages", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_advantages", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "generator_ready", "=", "False", "\n", "super", "(", "RolloutBufferAR", ",", "self", ")", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferAR.compute_returns_and_advantage": [[712, 757], ["last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten", "reversed", "reversed", "last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu().numpy", "range", "range", "last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu", "last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone"], "methods", ["None"], ["", "def", "compute_returns_and_advantage", "(", "self", ",", "\n", "last_value", ":", "th", ".", "Tensor", ",", "\n", "dones", ":", "np", ".", "ndarray", ",", "node", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Post-processing step: compute the returns (sum of discounted rewards)\n        and GAE advantage.\n        Adapted from Stable-Baselines PPO2.\n\n        Uses Generalized Advantage Estimation (https://arxiv.org/abs/1506.02438)\n        to compute the advantage. To obtain vanilla advantage (A(s) = R - V(S))\n        where R is the discounted reward with value bootstrap,\n        set ``gae_lambda=1.0`` during initialization.\n\n        :param last_value: (th.Tensor)\n        :param dones: (np.ndarray)\n\n        \"\"\"", "\n", "# convert to numpy", "\n", "last_value", "=", "last_value", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "\n", "last_gae_lam", "=", "0", "\n", "if", "node", ":", "\n", "            ", "for", "step", "in", "reversed", "(", "range", "(", "self", ".", "buffer_size", ")", ")", ":", "\n", "                ", "if", "step", "==", "self", ".", "buffer_size", "-", "1", ":", "\n", "                    ", "next_non_terminal", "=", "1.0", "-", "dones", "\n", "next_value", "=", "last_value", "\n", "", "else", ":", "\n", "                    ", "next_non_terminal", "=", "1.0", "-", "self", ".", "dones", "[", "step", "+", "1", "]", "\n", "next_value", "=", "self", ".", "node_values", "[", "step", "+", "1", "]", "\n", "", "delta", "=", "self", ".", "rewards", "[", "step", "]", "+", "self", ".", "gamma", "*", "next_value", "*", "next_non_terminal", "-", "self", ".", "node_values", "[", "step", "]", "\n", "last_gae_lam", "=", "delta", "+", "self", ".", "gamma", "*", "self", ".", "gae_lambda", "*", "next_non_terminal", "*", "last_gae_lam", "\n", "self", ".", "node_advantages", "[", "step", "]", "=", "last_gae_lam", "\n", "", "self", ".", "node_returns", "=", "self", ".", "node_advantages", "+", "self", ".", "node_values", "\n", "", "else", ":", "\n", "            ", "for", "step", "in", "reversed", "(", "range", "(", "self", ".", "buffer_size", ")", ")", ":", "\n", "                ", "if", "step", "==", "self", ".", "buffer_size", "-", "1", ":", "\n", "                    ", "next_non_terminal", "=", "1.0", "-", "dones", "\n", "next_value", "=", "last_value", "\n", "", "else", ":", "\n", "                    ", "next_non_terminal", "=", "1.0", "-", "self", ".", "dones", "[", "step", "+", "1", "]", "\n", "next_value", "=", "self", ".", "at_values", "[", "step", "+", "1", "]", "\n", "", "delta", "=", "self", ".", "rewards", "[", "step", "]", "+", "self", ".", "gamma", "*", "next_value", "*", "next_non_terminal", "-", "self", ".", "at_values", "[", "step", "]", "\n", "last_gae_lam", "=", "delta", "+", "self", ".", "gamma", "*", "self", ".", "gae_lambda", "*", "next_non_terminal", "*", "last_gae_lam", "\n", "self", ".", "at_advantages", "[", "step", "]", "=", "last_gae_lam", "\n", "", "self", ".", "at_returns", "=", "self", ".", "at_advantages", "+", "self", ".", "at_values", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferAR.add": [[758, 797], ["numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "node_value.clone().cpu().numpy().flatten", "at_value.clone().cpu().numpy().flatten", "node_log_prob.reshape.reshape.clone().cpu().numpy", "at_log_prob.clone().cpu().numpy", "len", "node_log_prob.reshape.reshape.reshape", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "node_value.clone().cpu().numpy", "at_value.clone().cpu().numpy", "node_log_prob.reshape.reshape.clone().cpu", "at_log_prob.clone().cpu", "node_value.clone().cpu", "at_value.clone().cpu", "node_log_prob.reshape.reshape.clone", "at_log_prob.clone", "node_value.clone", "at_value.clone"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy"], ["", "", "def", "add", "(", "self", ",", "\n", "node_obs", ":", "np", ".", "ndarray", ",", "\n", "at_obs", ":", "np", ".", "ndarray", ",", "\n", "node_action", ":", "np", ".", "ndarray", ",", "\n", "reward", ":", "np", ".", "ndarray", ",", "\n", "done", ":", "np", ".", "ndarray", ",", "\n", "node_value", ":", "th", ".", "Tensor", ",", "\n", "node_log_prob", ":", "th", ".", "Tensor", ",", "\n", "at_action", ":", "np", ".", "ndarray", ",", "\n", "at_log_prob", ":", "th", ".", "Tensor", ",", "\n", "at_value", ":", "th", ".", "Tensor", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        :param node_obs: (np.ndarray) Observation\n        :param node_action: (np.ndarray) Action\n        :param reward: (np.ndarray)\n        :param done: (np.ndarray) End of episode signal.\n        :param node_value: (th.Tensor) estimated value of the current state\n            following the current policy.\n        :param node_log_prob: (th.Tensor) log probability of the action\n            following the current policy.\n        \"\"\"", "\n", "if", "len", "(", "node_log_prob", ".", "shape", ")", "==", "0", ":", "\n", "# Reshape 0-d tensor to avoid error", "\n", "            ", "node_log_prob", "=", "node_log_prob", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "", "self", ".", "node_observations", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "node_obs", ")", ".", "copy", "(", ")", "\n", "self", ".", "at_observations", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "at_obs", ")", ".", "copy", "(", ")", "\n", "self", ".", "node_actions", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "node_action", ")", ".", "copy", "(", ")", "\n", "self", ".", "at_actions", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "at_action", ")", ".", "copy", "(", ")", "\n", "self", ".", "rewards", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "reward", ")", ".", "copy", "(", ")", "\n", "self", ".", "dones", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "done", ")", ".", "copy", "(", ")", "\n", "self", ".", "node_values", "[", "self", ".", "pos", "]", "=", "node_value", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "self", ".", "at_values", "[", "self", ".", "pos", "]", "=", "at_value", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "self", ".", "node_log_probs", "[", "self", ".", "pos", "]", "=", "node_log_prob", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "at_log_probs", "[", "self", ".", "pos", "]", "=", "at_log_prob", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "pos", "+=", "1", "\n", "if", "self", ".", "pos", "==", "self", ".", "buffer_size", ":", "\n", "            ", "self", ".", "full", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferAR.get": [[798, 817], ["numpy.random.permutation", "buffers.RolloutBufferAR.swap_and_flatten", "buffers.RolloutBufferAR._get_samples"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer.swap_and_flatten", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead._get_samples"], ["", "", "def", "get", "(", "self", ",", "batch_size", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "Generator", "[", "RolloutBufferSamplesAR", ",", "None", ",", "None", "]", ":", "\n", "        ", "assert", "self", ".", "full", ",", "''", "\n", "indices", "=", "np", ".", "random", ".", "permutation", "(", "self", ".", "buffer_size", "*", "self", ".", "n_envs", ")", "\n", "# Prepare the data", "\n", "if", "not", "self", ".", "generator_ready", ":", "\n", "            ", "for", "tensor", "in", "[", "'node_observations'", ",", "'node_actions'", ",", "'node_values'", ",", "\n", "'node_log_probs'", ",", "'node_advantages'", ",", "'node_returns'", ",", "'at_actions'", ",", "'at_log_probs'", ",", "'at_observations'", ",", "\n", "'at_values'", ",", "'at_returns'", ",", "'at_advantages'", "]", ":", "\n", "                ", "self", ".", "__dict__", "[", "tensor", "]", "=", "self", ".", "swap_and_flatten", "(", "self", ".", "__dict__", "[", "tensor", "]", ")", "\n", "", "self", ".", "generator_ready", "=", "True", "\n", "\n", "# Return everything, don't create minibatches", "\n", "", "if", "batch_size", "is", "None", ":", "\n", "            ", "batch_size", "=", "self", ".", "buffer_size", "*", "self", ".", "n_envs", "\n", "\n", "", "start_idx", "=", "0", "\n", "while", "start_idx", "<", "self", ".", "buffer_size", "*", "self", ".", "n_envs", ":", "\n", "            ", "yield", "self", ".", "_get_samples", "(", "indices", "[", "start_idx", ":", "start_idx", "+", "batch_size", "]", ")", "\n", "start_idx", "+=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferAR._get_samples": [[818, 834], ["gym_idsgame.agents.training_agents.openai_baselines.common.type_aliases.RolloutBufferSamplesAR", "buffers.RolloutBufferAR.node_values[].flatten", "buffers.RolloutBufferAR.node_log_probs[].flatten", "buffers.RolloutBufferAR.node_advantages[].flatten", "buffers.RolloutBufferAR.node_returns[].flatten", "buffers.RolloutBufferAR.at_log_probs[].flatten", "buffers.RolloutBufferAR.at_values[].flatten", "buffers.RolloutBufferAR.at_returns[].flatten", "buffers.RolloutBufferAR.at_advantages[].flatten", "tuple", "map"], "methods", ["None"], ["", "", "def", "_get_samples", "(", "self", ",", "batch_inds", ":", "np", ".", "ndarray", ",", "\n", "env", ":", "Optional", "[", "VecNormalize", "]", "=", "None", ")", "->", "RolloutBufferSamplesAR", ":", "\n", "        ", "data", "=", "(", "self", ".", "node_observations", "[", "batch_inds", "]", ",", "\n", "self", ".", "node_actions", "[", "batch_inds", "]", ",", "\n", "self", ".", "node_values", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "node_log_probs", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "node_advantages", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "node_returns", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "at_actions", "[", "batch_inds", "]", ",", "\n", "self", ".", "at_log_probs", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "at_observations", "[", "batch_inds", "]", ",", "\n", "self", ".", "at_values", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "at_returns", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "at_advantages", "[", "batch_inds", "]", ".", "flatten", "(", ")", "\n", ")", "\n", "return", "RolloutBufferSamplesAR", "(", "*", "tuple", "(", "map", "(", "self", ".", "to_torch", ",", "data", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrent.__init__": [[850, 874], ["buffers.BaseBuffer.__init__", "buffers.RolloutBufferARRecurrent.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset"], ["def", "__init__", "(", "self", ",", "\n", "buffer_size", ":", "int", ",", "\n", "observation_space", ":", "spaces", ".", "Space", ",", "\n", "action_space", ":", "spaces", ".", "Space", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "'cpu'", ",", "\n", "gae_lambda", ":", "float", "=", "1", ",", "\n", "gamma", ":", "float", "=", "0.99", ",", "\n", "n_envs", ":", "int", "=", "1", ",", "\n", "pg_agent_config", ":", "PolicyGradientAgentConfig", "=", "None", ",", "\n", "attacker", ":", "bool", "=", "False", ")", ":", "\n", "\n", "        ", "super", "(", "RolloutBufferARRecurrent", ",", "self", ")", ".", "__init__", "(", "buffer_size", ",", "observation_space", ",", "\n", "action_space", ",", "device", ",", "n_envs", "=", "n_envs", ")", "\n", "self", ".", "pg_agent_config", "=", "pg_agent_config", "\n", "self", ".", "attacker", "=", "attacker", "\n", "self", ".", "gae_lambda", "=", "gae_lambda", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "node_observations", ",", "self", ".", "at_observations", ",", "self", ".", "node_actions", ",", "self", ".", "at_actions", ",", "self", ".", "rewards", ",", "self", ".", "node_advantages", ",", "self", ".", "at_advantages", "=", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "self", ".", "node_returns", ",", "self", ".", "at_returns", ",", "self", ".", "dones", ",", "self", ".", "node_values", ",", "self", ".", "at_values", ",", "self", ".", "node_log_probs", ",", "self", ".", "at_log_probs", ",", "self", ".", "node_h_states", ",", "self", ".", "node_c_states", ",", "self", ".", "at_h_states", ",", "self", ".", "at_c_states", "=", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "self", ".", "generator_ready", "=", "False", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrent.reset": [[875, 908], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "buffers.BaseBuffer.reset", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "if", "self", ".", "attacker", ":", "\n", "            ", "self", ".", "node_observations", "=", "np", ".", "zeros", "(", "\n", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "attacker_node_net_input_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_observations", "=", "np", ".", "zeros", "(", "\n", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "attacker_at_net_input_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "node_observations", "=", "np", ".", "zeros", "(", "\n", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "defender_node_net_input_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_observations", "=", "np", ".", "zeros", "(", "\n", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "defender_at_net_input_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "self", ".", "node_actions", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "action_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_actions", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "action_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "rewards", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "node_returns", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_returns", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "dones", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "node_values", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_values", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "node_log_probs", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_log_probs", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "node_advantages", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_advantages", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "generator_ready", "=", "False", "\n", "self", ".", "node_h_states", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "node_c_states", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_h_states", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_c_states", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "super", "(", "RolloutBufferARRecurrent", ",", "self", ")", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrent.compute_returns_and_advantage": [[909, 954], ["last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten", "reversed", "reversed", "last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu().numpy", "range", "range", "last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu", "last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone"], "methods", ["None"], ["", "def", "compute_returns_and_advantage", "(", "self", ",", "\n", "last_value", ":", "th", ".", "Tensor", ",", "\n", "dones", ":", "np", ".", "ndarray", ",", "node", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Post-processing step: compute the returns (sum of discounted rewards)\n        and GAE advantage.\n        Adapted from Stable-Baselines PPO2.\n\n        Uses Generalized Advantage Estimation (https://arxiv.org/abs/1506.02438)\n        to compute the advantage. To obtain vanilla advantage (A(s) = R - V(S))\n        where R is the discounted reward with value bootstrap,\n        set ``gae_lambda=1.0`` during initialization.\n\n        :param last_value: (th.Tensor)\n        :param dones: (np.ndarray)\n\n        \"\"\"", "\n", "# convert to numpy", "\n", "last_value", "=", "last_value", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "\n", "last_gae_lam", "=", "0", "\n", "if", "node", ":", "\n", "            ", "for", "step", "in", "reversed", "(", "range", "(", "self", ".", "buffer_size", ")", ")", ":", "\n", "                ", "if", "step", "==", "self", ".", "buffer_size", "-", "1", ":", "\n", "                    ", "next_non_terminal", "=", "1.0", "-", "dones", "\n", "next_value", "=", "last_value", "\n", "", "else", ":", "\n", "                    ", "next_non_terminal", "=", "1.0", "-", "self", ".", "dones", "[", "step", "+", "1", "]", "\n", "next_value", "=", "self", ".", "node_values", "[", "step", "+", "1", "]", "\n", "", "delta", "=", "self", ".", "rewards", "[", "step", "]", "+", "self", ".", "gamma", "*", "next_value", "*", "next_non_terminal", "-", "self", ".", "node_values", "[", "step", "]", "\n", "last_gae_lam", "=", "delta", "+", "self", ".", "gamma", "*", "self", ".", "gae_lambda", "*", "next_non_terminal", "*", "last_gae_lam", "\n", "self", ".", "node_advantages", "[", "step", "]", "=", "last_gae_lam", "\n", "", "self", ".", "node_returns", "=", "self", ".", "node_advantages", "+", "self", ".", "node_values", "\n", "", "else", ":", "\n", "            ", "for", "step", "in", "reversed", "(", "range", "(", "self", ".", "buffer_size", ")", ")", ":", "\n", "                ", "if", "step", "==", "self", ".", "buffer_size", "-", "1", ":", "\n", "                    ", "next_non_terminal", "=", "1.0", "-", "dones", "\n", "next_value", "=", "last_value", "\n", "", "else", ":", "\n", "                    ", "next_non_terminal", "=", "1.0", "-", "self", ".", "dones", "[", "step", "+", "1", "]", "\n", "next_value", "=", "self", ".", "at_values", "[", "step", "+", "1", "]", "\n", "", "delta", "=", "self", ".", "rewards", "[", "step", "]", "+", "self", ".", "gamma", "*", "next_value", "*", "next_non_terminal", "-", "self", ".", "at_values", "[", "step", "]", "\n", "last_gae_lam", "=", "delta", "+", "self", ".", "gamma", "*", "self", ".", "gae_lambda", "*", "next_non_terminal", "*", "last_gae_lam", "\n", "self", ".", "at_advantages", "[", "step", "]", "=", "last_gae_lam", "\n", "", "self", ".", "at_returns", "=", "self", ".", "at_advantages", "+", "self", ".", "at_values", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrent.add": [[955, 1001], ["numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "node_value.clone().cpu().numpy().flatten", "at_value.clone().cpu().numpy().flatten", "node_log_prob.reshape.reshape.clone().cpu().numpy", "at_log_prob.clone().cpu().numpy", "len", "node_log_prob.reshape.reshape.reshape", "node_state[].clone().cpu().numpy", "node_state[].clone().cpu().numpy", "at_state[].clone().cpu().numpy", "at_state[].clone().cpu().numpy", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "node_value.clone().cpu().numpy", "at_value.clone().cpu().numpy", "node_log_prob.reshape.reshape.clone().cpu", "at_log_prob.clone().cpu", "node_state[].clone().cpu", "node_state[].clone().cpu", "at_state[].clone().cpu", "at_state[].clone().cpu", "node_value.clone().cpu", "at_value.clone().cpu", "node_log_prob.reshape.reshape.clone", "at_log_prob.clone", "node_state[].clone", "node_state[].clone", "at_state[].clone", "at_state[].clone", "node_value.clone", "at_value.clone"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy"], ["", "", "def", "add", "(", "self", ",", "\n", "node_obs", ":", "np", ".", "ndarray", ",", "\n", "at_obs", ":", "np", ".", "ndarray", ",", "\n", "node_action", ":", "np", ".", "ndarray", ",", "\n", "reward", ":", "np", ".", "ndarray", ",", "\n", "done", ":", "np", ".", "ndarray", ",", "\n", "node_value", ":", "th", ".", "Tensor", ",", "\n", "node_log_prob", ":", "th", ".", "Tensor", ",", "\n", "at_action", ":", "np", ".", "ndarray", ",", "\n", "at_log_prob", ":", "th", ".", "Tensor", ",", "\n", "at_value", ":", "th", ".", "Tensor", ",", "\n", "node_state", ":", "th", ".", "Tensor", ",", "\n", "at_state", ":", "th", ".", "Tensor", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        :param node_obs: (np.ndarray) Observation\n        :param node_action: (np.ndarray) Action\n        :param reward: (np.ndarray)\n        :param done: (np.ndarray) End of episode signal.\n        :param node_value: (th.Tensor) estimated value of the current state\n            following the current policy.\n        :param node_log_prob: (th.Tensor) log probability of the action\n            following the current policy.\n        \"\"\"", "\n", "if", "len", "(", "node_log_prob", ".", "shape", ")", "==", "0", ":", "\n", "# Reshape 0-d tensor to avoid error", "\n", "            ", "node_log_prob", "=", "node_log_prob", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "", "self", ".", "node_observations", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "node_obs", ")", ".", "copy", "(", ")", "\n", "self", ".", "at_observations", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "at_obs", ")", ".", "copy", "(", ")", "\n", "self", ".", "node_actions", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "node_action", ")", ".", "copy", "(", ")", "\n", "self", ".", "at_actions", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "at_action", ")", ".", "copy", "(", ")", "\n", "self", ".", "rewards", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "reward", ")", ".", "copy", "(", ")", "\n", "self", ".", "dones", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "done", ")", ".", "copy", "(", ")", "\n", "self", ".", "node_values", "[", "self", ".", "pos", "]", "=", "node_value", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "self", ".", "at_values", "[", "self", ".", "pos", "]", "=", "at_value", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "self", ".", "node_log_probs", "[", "self", ".", "pos", "]", "=", "node_log_prob", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "at_log_probs", "[", "self", ".", "pos", "]", "=", "at_log_prob", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "node_state", "is", "not", "None", ":", "\n", "            ", "self", ".", "node_h_states", "[", "self", ".", "pos", "]", "=", "node_state", "[", "0", "]", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "node_c_states", "[", "self", ".", "pos", "]", "=", "node_state", "[", "1", "]", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "if", "at_state", "is", "not", "None", ":", "\n", "            ", "self", ".", "at_h_states", "[", "self", ".", "pos", "]", "=", "at_state", "[", "0", "]", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "at_c_states", "[", "self", ".", "pos", "]", "=", "at_state", "[", "1", "]", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "self", ".", "pos", "+=", "1", "\n", "if", "self", ".", "pos", "==", "self", ".", "buffer_size", ":", "\n", "            ", "self", ".", "full", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrent.get": [[1002, 1022], ["numpy.random.permutation", "buffers.RolloutBufferARRecurrent.swap_and_flatten", "buffers.RolloutBufferARRecurrent._get_samples"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer.swap_and_flatten", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead._get_samples"], ["", "", "def", "get", "(", "self", ",", "batch_size", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "Generator", "[", "RolloutBufferSamplesARRecurrent", ",", "None", ",", "None", "]", ":", "\n", "        ", "assert", "self", ".", "full", ",", "''", "\n", "indices", "=", "np", ".", "random", ".", "permutation", "(", "self", ".", "buffer_size", "*", "self", ".", "n_envs", ")", "\n", "# Prepare the data", "\n", "if", "not", "self", ".", "generator_ready", ":", "\n", "            ", "for", "tensor", "in", "[", "'node_observations'", ",", "'node_actions'", ",", "'node_values'", ",", "\n", "'node_log_probs'", ",", "'node_advantages'", ",", "'node_returns'", ",", "'at_actions'", ",", "'at_log_probs'", ",", "'at_observations'", ",", "\n", "'at_values'", ",", "'at_returns'", ",", "'at_advantages'", ",", "'node_h_states'", ",", "'node_c_states'", ",", "'dones'", ",", "\n", "'at_h_states'", ",", "'at_c_states'", "]", ":", "\n", "                ", "self", ".", "__dict__", "[", "tensor", "]", "=", "self", ".", "swap_and_flatten", "(", "self", ".", "__dict__", "[", "tensor", "]", ")", "\n", "", "self", ".", "generator_ready", "=", "True", "\n", "\n", "# Return everything, don't create minibatches", "\n", "", "if", "batch_size", "is", "None", ":", "\n", "            ", "batch_size", "=", "self", ".", "buffer_size", "*", "self", ".", "n_envs", "\n", "\n", "", "start_idx", "=", "0", "\n", "while", "start_idx", "<", "self", ".", "buffer_size", "*", "self", ".", "n_envs", ":", "\n", "            ", "yield", "self", ".", "_get_samples", "(", "indices", "[", "start_idx", ":", "start_idx", "+", "batch_size", "]", ")", "\n", "start_idx", "+=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrent._get_samples": [[1023, 1044], ["gym_idsgame.agents.training_agents.openai_baselines.common.type_aliases.RolloutBufferSamplesARRecurrent", "buffers.RolloutBufferARRecurrent.node_values[].flatten", "buffers.RolloutBufferARRecurrent.node_log_probs[].flatten", "buffers.RolloutBufferARRecurrent.node_advantages[].flatten", "buffers.RolloutBufferARRecurrent.node_returns[].flatten", "buffers.RolloutBufferARRecurrent.at_log_probs[].flatten", "buffers.RolloutBufferARRecurrent.at_values[].flatten", "buffers.RolloutBufferARRecurrent.at_returns[].flatten", "buffers.RolloutBufferARRecurrent.at_advantages[].flatten", "tuple", "map"], "methods", ["None"], ["", "", "def", "_get_samples", "(", "self", ",", "batch_inds", ":", "np", ".", "ndarray", ",", "\n", "env", ":", "Optional", "[", "VecNormalize", "]", "=", "None", ")", "->", "RolloutBufferSamplesARRecurrent", ":", "\n", "        ", "data", "=", "(", "self", ".", "node_observations", "[", "batch_inds", "]", ",", "\n", "self", ".", "node_actions", "[", "batch_inds", "]", ",", "\n", "self", ".", "node_values", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "node_log_probs", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "node_advantages", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "node_returns", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "at_actions", "[", "batch_inds", "]", ",", "\n", "self", ".", "at_log_probs", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "at_observations", "[", "batch_inds", "]", ",", "\n", "self", ".", "at_values", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "at_returns", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "at_advantages", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "node_h_states", "[", "batch_inds", "]", ",", "\n", "self", ".", "node_c_states", "[", "batch_inds", "]", ",", "\n", "self", ".", "dones", "[", "batch_inds", "]", ",", "\n", "self", ".", "at_h_states", "[", "batch_inds", "]", ",", "\n", "self", ".", "at_c_states", "[", "batch_inds", "]", "\n", ")", "\n", "return", "RolloutBufferSamplesARRecurrent", "(", "*", "tuple", "(", "map", "(", "self", ".", "to_torch", ",", "data", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.__init__": [[1060, 1083], ["buffers.BaseBuffer.__init__", "buffers.RolloutBufferARRecurrentMultiHead.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset"], ["def", "__init__", "(", "self", ",", "\n", "buffer_size", ":", "int", ",", "\n", "observation_space", ":", "spaces", ".", "Space", ",", "\n", "action_space", ":", "spaces", ".", "Space", ",", "\n", "device", ":", "Union", "[", "th", ".", "device", ",", "str", "]", "=", "'cpu'", ",", "\n", "gae_lambda", ":", "float", "=", "1", ",", "\n", "gamma", ":", "float", "=", "0.99", ",", "\n", "n_envs", ":", "int", "=", "1", ",", "\n", "pg_agent_config", ":", "PolicyGradientAgentConfig", "=", "None", ",", ")", ":", "\n", "\n", "        ", "super", "(", "RolloutBufferARRecurrentMultiHead", ",", "self", ")", ".", "__init__", "(", "buffer_size", ",", "observation_space", ",", "\n", "action_space", ",", "device", ",", "n_envs", "=", "n_envs", ")", "\n", "self", ".", "pg_agent_config", "=", "pg_agent_config", "\n", "self", ".", "gae_lambda", "=", "gae_lambda", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "node_observations_1", ",", "self", ".", "node_observations_2", ",", "self", ".", "node_observations_3", ",", "self", ".", "node_observations_4", ",", "self", ".", "at_observations", ",", "self", ".", "node_actions", ",", "self", ".", "at_actions", ",", "self", ".", "rewards", ",", "self", ".", "node_advantages", ",", "self", ".", "at_advantages", "=", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "self", ".", "node_returns", ",", "self", ".", "at_returns", ",", "self", ".", "dones", ",", "self", ".", "node_values", ",", "self", ".", "at_values", ",", "self", ".", "node_log_probs", ",", "self", ".", "at_log_probs", ",", "self", ".", "node_h_states", ",", "self", ".", "node_c_states", ",", "self", ".", "at_h_states", ",", "self", ".", "at_c_states", "=", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", ",", "None", "\n", "self", ".", "generator_ready", "=", "False", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.reset": [[1084, 1112], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "buffers.BaseBuffer.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "node_observations_1", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "channel_1_input_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "node_observations_2", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "channel_2_input_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "node_observations_3", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "channel_3_input_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "node_observations_4", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "channel_4_input_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_observations", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "attacker_at_net_input_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "node_actions", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "action_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_actions", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "action_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "rewards", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "node_returns", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_returns", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "dones", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "node_values", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_values", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "node_log_probs", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_log_probs", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "node_advantages", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_advantages", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "generator_ready", "=", "False", "\n", "self", ".", "node_h_states", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "node_c_states", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_h_states", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "at_c_states", "=", "np", ".", "zeros", "(", "(", "self", ".", "buffer_size", ",", "self", ".", "n_envs", ",", "self", ".", "pg_agent_config", ".", "num_lstm_layers", ",", "1", ",", "\n", "self", ".", "pg_agent_config", ".", "lstm_hidden_dim", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "super", "(", "RolloutBufferARRecurrentMultiHead", ",", "self", ")", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.compute_returns_and_advantage": [[1113, 1158], ["last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten", "reversed", "reversed", "last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu().numpy", "range", "range", "last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone().cpu", "last_value.clone().cpu().numpy().flatten.clone().cpu().numpy().flatten.clone"], "methods", ["None"], ["", "def", "compute_returns_and_advantage", "(", "self", ",", "\n", "last_value", ":", "th", ".", "Tensor", ",", "\n", "dones", ":", "np", ".", "ndarray", ",", "node", ":", "bool", "=", "True", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Post-processing step: compute the returns (sum of discounted rewards)\n        and GAE advantage.\n        Adapted from Stable-Baselines PPO2.\n\n        Uses Generalized Advantage Estimation (https://arxiv.org/abs/1506.02438)\n        to compute the advantage. To obtain vanilla advantage (A(s) = R - V(S))\n        where R is the discounted reward with value bootstrap,\n        set ``gae_lambda=1.0`` during initialization.\n\n        :param last_value: (th.Tensor)\n        :param dones: (np.ndarray)\n\n        \"\"\"", "\n", "# convert to numpy", "\n", "last_value", "=", "last_value", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "\n", "last_gae_lam", "=", "0", "\n", "if", "node", ":", "\n", "            ", "for", "step", "in", "reversed", "(", "range", "(", "self", ".", "buffer_size", ")", ")", ":", "\n", "                ", "if", "step", "==", "self", ".", "buffer_size", "-", "1", ":", "\n", "                    ", "next_non_terminal", "=", "1.0", "-", "dones", "\n", "next_value", "=", "last_value", "\n", "", "else", ":", "\n", "                    ", "next_non_terminal", "=", "1.0", "-", "self", ".", "dones", "[", "step", "+", "1", "]", "\n", "next_value", "=", "self", ".", "node_values", "[", "step", "+", "1", "]", "\n", "", "delta", "=", "self", ".", "rewards", "[", "step", "]", "+", "self", ".", "gamma", "*", "next_value", "*", "next_non_terminal", "-", "self", ".", "node_values", "[", "step", "]", "\n", "last_gae_lam", "=", "delta", "+", "self", ".", "gamma", "*", "self", ".", "gae_lambda", "*", "next_non_terminal", "*", "last_gae_lam", "\n", "self", ".", "node_advantages", "[", "step", "]", "=", "last_gae_lam", "\n", "", "self", ".", "node_returns", "=", "self", ".", "node_advantages", "+", "self", ".", "node_values", "\n", "", "else", ":", "\n", "            ", "for", "step", "in", "reversed", "(", "range", "(", "self", ".", "buffer_size", ")", ")", ":", "\n", "                ", "if", "step", "==", "self", ".", "buffer_size", "-", "1", ":", "\n", "                    ", "next_non_terminal", "=", "1.0", "-", "dones", "\n", "next_value", "=", "last_value", "\n", "", "else", ":", "\n", "                    ", "next_non_terminal", "=", "1.0", "-", "self", ".", "dones", "[", "step", "+", "1", "]", "\n", "next_value", "=", "self", ".", "at_values", "[", "step", "+", "1", "]", "\n", "", "delta", "=", "self", ".", "rewards", "[", "step", "]", "+", "self", ".", "gamma", "*", "next_value", "*", "next_non_terminal", "-", "self", ".", "at_values", "[", "step", "]", "\n", "last_gae_lam", "=", "delta", "+", "self", ".", "gamma", "*", "self", ".", "gae_lambda", "*", "next_non_terminal", "*", "last_gae_lam", "\n", "self", ".", "at_advantages", "[", "step", "]", "=", "last_gae_lam", "\n", "", "self", ".", "at_returns", "=", "self", ".", "at_advantages", "+", "self", ".", "at_values", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.add": [[1159, 1211], ["numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "numpy.array().copy", "node_value.clone().cpu().numpy().flatten", "at_value.clone().cpu().numpy().flatten", "node_log_prob.reshape.reshape.clone().cpu().numpy", "at_log_prob.clone().cpu().numpy", "len", "node_log_prob.reshape.reshape.reshape", "node_state[].clone().cpu().numpy", "node_state[].clone().cpu().numpy", "at_state[].clone().cpu().numpy", "at_state[].clone().cpu().numpy", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "node_value.clone().cpu().numpy", "at_value.clone().cpu().numpy", "node_log_prob.reshape.reshape.clone().cpu", "at_log_prob.clone().cpu", "node_state[].clone().cpu", "node_state[].clone().cpu", "at_state[].clone().cpu", "at_state[].clone().cpu", "node_value.clone().cpu", "at_value.clone().cpu", "node_log_prob.reshape.reshape.clone", "at_log_prob.clone", "node_state[].clone", "node_state[].clone", "at_state[].clone", "at_state[].clone", "node_value.clone", "at_value.clone"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy"], ["", "", "def", "add", "(", "self", ",", "\n", "node_obs_1", ":", "np", ".", "ndarray", ",", "\n", "node_obs_2", ":", "np", ".", "ndarray", ",", "\n", "node_obs_3", ":", "np", ".", "ndarray", ",", "\n", "node_obs_4", ":", "np", ".", "ndarray", ",", "\n", "at_obs", ":", "np", ".", "ndarray", ",", "\n", "node_action", ":", "np", ".", "ndarray", ",", "\n", "reward", ":", "np", ".", "ndarray", ",", "\n", "done", ":", "np", ".", "ndarray", ",", "\n", "node_value", ":", "th", ".", "Tensor", ",", "\n", "node_log_prob", ":", "th", ".", "Tensor", ",", "\n", "at_action", ":", "np", ".", "ndarray", ",", "\n", "at_log_prob", ":", "th", ".", "Tensor", ",", "\n", "at_value", ":", "th", ".", "Tensor", ",", "\n", "node_state", ":", "th", ".", "Tensor", ",", "\n", "at_state", ":", "th", ".", "Tensor", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        :param node_obs_1: (np.ndarray) Observation\n        :param node_action: (np.ndarray) Action\n        :param reward: (np.ndarray)\n        :param done: (np.ndarray) End of episode signal.\n        :param node_value: (th.Tensor) estimated value of the current state\n            following the current policy.\n        :param node_log_prob: (th.Tensor) log probability of the action\n            following the current policy.\n        \"\"\"", "\n", "if", "len", "(", "node_log_prob", ".", "shape", ")", "==", "0", ":", "\n", "# Reshape 0-d tensor to avoid error", "\n", "            ", "node_log_prob", "=", "node_log_prob", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n", "", "self", ".", "node_observations_1", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "node_obs_1", ")", ".", "copy", "(", ")", "\n", "self", ".", "node_observations_2", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "node_obs_2", ")", ".", "copy", "(", ")", "\n", "self", ".", "node_observations_3", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "node_obs_3", ")", ".", "copy", "(", ")", "\n", "self", ".", "node_observations_4", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "node_obs_4", ")", ".", "copy", "(", ")", "\n", "self", ".", "at_observations", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "at_obs", ")", ".", "copy", "(", ")", "\n", "self", ".", "node_actions", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "node_action", ")", ".", "copy", "(", ")", "\n", "self", ".", "at_actions", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "at_action", ")", ".", "copy", "(", ")", "\n", "self", ".", "rewards", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "reward", ")", ".", "copy", "(", ")", "\n", "self", ".", "dones", "[", "self", ".", "pos", "]", "=", "np", ".", "array", "(", "done", ")", ".", "copy", "(", ")", "\n", "self", ".", "node_values", "[", "self", ".", "pos", "]", "=", "node_value", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "self", ".", "at_values", "[", "self", ".", "pos", "]", "=", "at_value", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "\n", "self", ".", "node_log_probs", "[", "self", ".", "pos", "]", "=", "node_log_prob", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "at_log_probs", "[", "self", ".", "pos", "]", "=", "at_log_prob", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "node_state", "is", "not", "None", ":", "\n", "            ", "self", ".", "node_h_states", "[", "self", ".", "pos", "]", "=", "node_state", "[", "0", "]", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "node_c_states", "[", "self", ".", "pos", "]", "=", "node_state", "[", "1", "]", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "if", "at_state", "is", "not", "None", ":", "\n", "            ", "self", ".", "at_h_states", "[", "self", ".", "pos", "]", "=", "at_state", "[", "0", "]", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "self", ".", "at_c_states", "[", "self", ".", "pos", "]", "=", "at_state", "[", "1", "]", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "self", ".", "pos", "+=", "1", "\n", "if", "self", ".", "pos", "==", "self", ".", "buffer_size", ":", "\n", "            ", "self", ".", "full", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead.get": [[1212, 1233], ["numpy.random.permutation", "buffers.RolloutBufferARRecurrentMultiHead.swap_and_flatten", "buffers.RolloutBufferARRecurrentMultiHead._get_samples"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.BaseBuffer.swap_and_flatten", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead._get_samples"], ["", "", "def", "get", "(", "self", ",", "batch_size", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "Generator", "[", "RolloutBufferSamplesARRecurrentMultiHead", ",", "None", ",", "None", "]", ":", "\n", "        ", "assert", "self", ".", "full", ",", "''", "\n", "indices", "=", "np", ".", "random", ".", "permutation", "(", "self", ".", "buffer_size", "*", "self", ".", "n_envs", ")", "\n", "# Prepare the data", "\n", "if", "not", "self", ".", "generator_ready", ":", "\n", "            ", "for", "tensor", "in", "[", "'node_observations_1'", ",", "'node_observations_2'", ",", "'node_observations_3'", ",", "'node_observations_4'", ",", "\n", "'node_actions'", ",", "'node_values'", ",", "\n", "'node_log_probs'", ",", "'node_advantages'", ",", "'node_returns'", ",", "'at_actions'", ",", "'at_log_probs'", ",", "'at_observations'", ",", "\n", "'at_values'", ",", "'at_returns'", ",", "'at_advantages'", ",", "'node_h_states'", ",", "'node_c_states'", ",", "'dones'", ",", "\n", "'at_h_states'", ",", "'at_c_states'", "]", ":", "\n", "                ", "self", ".", "__dict__", "[", "tensor", "]", "=", "self", ".", "swap_and_flatten", "(", "self", ".", "__dict__", "[", "tensor", "]", ")", "\n", "", "self", ".", "generator_ready", "=", "True", "\n", "\n", "# Return everything, don't create minibatches", "\n", "", "if", "batch_size", "is", "None", ":", "\n", "            ", "batch_size", "=", "self", ".", "buffer_size", "*", "self", ".", "n_envs", "\n", "\n", "", "start_idx", "=", "0", "\n", "while", "start_idx", "<", "self", ".", "buffer_size", "*", "self", ".", "n_envs", ":", "\n", "            ", "yield", "self", ".", "_get_samples", "(", "indices", "[", "start_idx", ":", "start_idx", "+", "batch_size", "]", ")", "\n", "start_idx", "+=", "batch_size", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.buffers.RolloutBufferARRecurrentMultiHead._get_samples": [[1234, 1258], ["gym_idsgame.agents.training_agents.openai_baselines.common.type_aliases.RolloutBufferSamplesARRecurrentMultiHead", "buffers.RolloutBufferARRecurrentMultiHead.node_values[].flatten", "buffers.RolloutBufferARRecurrentMultiHead.node_log_probs[].flatten", "buffers.RolloutBufferARRecurrentMultiHead.node_advantages[].flatten", "buffers.RolloutBufferARRecurrentMultiHead.node_returns[].flatten", "buffers.RolloutBufferARRecurrentMultiHead.at_log_probs[].flatten", "buffers.RolloutBufferARRecurrentMultiHead.at_values[].flatten", "buffers.RolloutBufferARRecurrentMultiHead.at_returns[].flatten", "buffers.RolloutBufferARRecurrentMultiHead.at_advantages[].flatten", "tuple", "map"], "methods", ["None"], ["", "", "def", "_get_samples", "(", "self", ",", "batch_inds", ":", "np", ".", "ndarray", ",", "\n", "env", ":", "Optional", "[", "VecNormalize", "]", "=", "None", ")", "->", "RolloutBufferSamplesARRecurrentMultiHead", ":", "\n", "        ", "data", "=", "(", "self", ".", "node_observations_1", "[", "batch_inds", "]", ",", "\n", "self", ".", "node_observations_2", "[", "batch_inds", "]", ",", "\n", "self", ".", "node_observations_3", "[", "batch_inds", "]", ",", "\n", "self", ".", "node_observations_4", "[", "batch_inds", "]", ",", "\n", "self", ".", "node_actions", "[", "batch_inds", "]", ",", "\n", "self", ".", "node_values", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "node_log_probs", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "node_advantages", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "node_returns", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "at_actions", "[", "batch_inds", "]", ",", "\n", "self", ".", "at_log_probs", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "at_observations", "[", "batch_inds", "]", ",", "\n", "self", ".", "at_values", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "at_returns", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "at_advantages", "[", "batch_inds", "]", ".", "flatten", "(", ")", ",", "\n", "self", ".", "node_h_states", "[", "batch_inds", "]", ",", "\n", "self", ".", "node_c_states", "[", "batch_inds", "]", ",", "\n", "self", ".", "dones", "[", "batch_inds", "]", ",", "\n", "self", ".", "at_h_states", "[", "batch_inds", "]", ",", "\n", "self", ".", "at_c_states", "[", "batch_inds", "]", "\n", ")", "\n", "return", "RolloutBufferSamplesARRecurrentMultiHead", "(", "*", "tuple", "(", "map", "(", "self", ".", "to_torch", ",", "data", ")", ")", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.opponent_pool_config.OpponentPoolConfig.__init__": [[5, 27], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "pool_maxsize", ":", "int", "=", "10000", ",", "pool_increment_period", ":", "int", "=", "1000", ",", "\n", "head_to_head_period", ":", "int", "=", "1000", ",", "quality_scores", ":", "bool", "=", "False", ",", "quality_score_eta", ":", "float", "=", "0.01", ",", "\n", "pool_prob", ":", "float", "=", "0.20", ",", "initial_quality", ":", "int", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Initialize the DTO\n\n        :param pool_maxsize: maximum size of the opponent pool, when max size is reached FIFO replacement will happen\n        :param pool_increment_period: number of episodes of training before the policy is added to the pool\n        :param head_to_head_period: the period of head-to-head between two policies before a new opponent is sampled\n        :param quality_scores: boolean flag whether to track quality scores of opponents in the pool\n        :param quality_score_eta: the learning rate for updating quality scores in the opponent pool\n        :param pool_prob: probability of selecting opponent from pool (probability of playing against current\n                          best parameters is then 1-pool_prob)\n        :param initial_quality: the initial quality when using quality scores for sampling from the pool\n        \"\"\"", "\n", "self", ".", "pool_maxsize", "=", "pool_maxsize", "\n", "self", ".", "pool_increment_period", "=", "pool_increment_period", "\n", "self", ".", "head_to_head_period", "=", "head_to_head_period", "\n", "self", ".", "quality_scores", "=", "quality_scores", "\n", "self", ".", "quality_score_eta", "=", "quality_score_eta", "\n", "self", ".", "pool_prob", "=", "pool_prob", "\n", "self", ".", "initial_quality", "=", "initial_quality", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.opponent_pool_config.OpponentPoolConfig.to_str": [[28, 36], ["None"], "methods", ["None"], ["", "def", "to_str", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        :return: a string with information about all of the parameters\n        \"\"\"", "\n", "return", "\"Opponent Pool Hyperparameters: pool_maxsize:{0},pool_increment_period:{1},h2h_period:{2},\"", "\"quality_scores:{3},quality_score_eta:{4},pool_prob:{5},initial_quality:{6}\"", ".", "format", "(", "\n", "self", ".", "pool_maxsize", ",", "self", ".", "pool_increment_period", ",", "self", ".", "head_to_head_period", ",", "self", ".", "quality_scores", ",", "\n", "self", ".", "quality_score_eta", ",", "self", ".", "pool_prob", ",", "self", ".", "initial_quality", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.common.opponent_pool_config.OpponentPoolConfig.to_csv": [[37, 54], ["open", "csv.writer", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "str", "str", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "def", "to_csv", "(", "self", ",", "file_path", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Write parameters to csv file\n\n        :param file_path: path to the file\n        :return: None\n        \"\"\"", "\n", "with", "open", "(", "file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"parameter\"", ",", "\"value\"", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"pool_maxsize\"", ",", "str", "(", "self", ".", "pool_maxsize", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"pool_increment_period\"", ",", "str", "(", "self", ".", "pool_increment_period", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"head_to_head_period\"", ",", "str", "(", "self", ".", "head_to_head_period", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"quality_scores\"", ",", "str", "(", "self", ".", "quality_scores", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"quality_score_eta\"", ",", "str", "(", "self", ".", "quality_score_eta", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"pool_prob\"", ",", "str", "(", "self", ".", "pool_prob", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"initial_quality\"", ",", "str", "(", "self", ".", "initial_quality", ")", "]", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_check_nan.VecCheckNan.__init__": [[19, 27], ["gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.base_vec_env.VecEnvWrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "venv", ",", "raise_exception", "=", "False", ",", "warn_once", "=", "True", ",", "check_inf", "=", "True", ")", ":", "\n", "        ", "VecEnvWrapper", ".", "__init__", "(", "self", ",", "venv", ")", "\n", "self", ".", "raise_exception", "=", "raise_exception", "\n", "self", ".", "warn_once", "=", "warn_once", "\n", "self", ".", "check_inf", "=", "check_inf", "\n", "self", ".", "_actions", "=", "None", "\n", "self", ".", "_observations", "=", "None", "\n", "self", ".", "_user_warned", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_check_nan.VecCheckNan.step_async": [[28, 33], ["vec_check_nan.VecCheckNan._check_val", "vec_check_nan.VecCheckNan.venv.step_async"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_check_nan.VecCheckNan._check_val", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.step_async"], ["", "def", "step_async", "(", "self", ",", "actions", ")", ":", "\n", "        ", "self", ".", "_check_val", "(", "async_step", "=", "True", ",", "actions", "=", "actions", ")", "\n", "\n", "self", ".", "_actions", "=", "actions", "\n", "self", ".", "venv", ".", "step_async", "(", "actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_check_nan.VecCheckNan.step_wait": [[34, 41], ["vec_check_nan.VecCheckNan.venv.step_wait", "vec_check_nan.VecCheckNan._check_val"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.step_wait", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_check_nan.VecCheckNan._check_val"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "observations", ",", "rewards", ",", "news", ",", "infos", "=", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "\n", "self", ".", "_check_val", "(", "async_step", "=", "False", ",", "observations", "=", "observations", ",", "rewards", "=", "rewards", ",", "news", "=", "news", ")", "\n", "\n", "self", ".", "_observations", "=", "observations", "\n", "return", "observations", ",", "rewards", ",", "news", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_check_nan.VecCheckNan.reset": [[42, 50], ["vec_check_nan.VecCheckNan.venv.reset", "vec_check_nan.VecCheckNan._check_val"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_check_nan.VecCheckNan._check_val"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "observations", "=", "self", ".", "venv", ".", "reset", "(", ")", "\n", "self", ".", "_actions", "=", "None", "\n", "\n", "self", ".", "_check_val", "(", "async_step", "=", "False", ",", "observations", "=", "observations", ")", "\n", "\n", "self", ".", "_observations", "=", "observations", "\n", "return", "observations", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_check_nan.VecCheckNan._check_val": [[51, 87], ["kwargs.items", "numpy.any", "enumerate", "numpy.isnan", "numpy.any", "found.append", "found.append", "ValueError", "warnings.warn", "numpy.isinf", "len"], "methods", ["None"], ["", "def", "_check_val", "(", "self", ",", "*", ",", "async_step", ",", "**", "kwargs", ")", ":", "\n", "# if warn and warn once and have warned once: then stop checking", "\n", "        ", "if", "not", "self", ".", "raise_exception", "and", "self", ".", "warn_once", "and", "self", ".", "_user_warned", ":", "\n", "            ", "return", "\n", "\n", "", "found", "=", "[", "]", "\n", "for", "name", ",", "val", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "has_nan", "=", "np", ".", "any", "(", "np", ".", "isnan", "(", "val", ")", ")", "\n", "has_inf", "=", "self", ".", "check_inf", "and", "np", ".", "any", "(", "np", ".", "isinf", "(", "val", ")", ")", "\n", "if", "has_inf", ":", "\n", "                ", "found", ".", "append", "(", "(", "name", ",", "\"inf\"", ")", ")", "\n", "", "if", "has_nan", ":", "\n", "                ", "found", ".", "append", "(", "(", "name", ",", "\"nan\"", ")", ")", "\n", "\n", "", "", "if", "found", ":", "\n", "            ", "self", ".", "_user_warned", "=", "True", "\n", "msg", "=", "\"\"", "\n", "for", "i", ",", "(", "name", ",", "type_val", ")", "in", "enumerate", "(", "found", ")", ":", "\n", "                ", "msg", "+=", "\"found {} in {}\"", ".", "format", "(", "type_val", ",", "name", ")", "\n", "if", "i", "!=", "len", "(", "found", ")", "-", "1", ":", "\n", "                    ", "msg", "+=", "\", \"", "\n", "\n", "", "", "msg", "+=", "\".\\r\\nOriginated from the \"", "\n", "\n", "if", "not", "async_step", ":", "\n", "                ", "if", "self", ".", "_actions", "is", "None", ":", "\n", "                    ", "msg", "+=", "\"environment observation (at reset)\"", "\n", "", "else", ":", "\n", "                    ", "msg", "+=", "\"environment, Last given value was: \\r\\n\\taction={}\"", ".", "format", "(", "self", ".", "_actions", ")", "\n", "", "", "else", ":", "\n", "                ", "msg", "+=", "\"RL model, Last given value was: \\r\\n\\tobservations={}\"", ".", "format", "(", "self", ".", "_observations", ")", "\n", "\n", "", "if", "self", ".", "raise_exception", ":", "\n", "                ", "raise", "ValueError", "(", "msg", ")", "\n", "", "else", ":", "\n", "                ", "warnings", ".", "warn", "(", "msg", ",", "UserWarning", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_frame_stack.VecFrameStack.__init__": [[18, 27], ["numpy.repeat", "numpy.repeat", "numpy.zeros", "gym.spaces.Box", "gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.base_vec_env.VecEnvWrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "venv", ":", "VecEnv", ",", "n_stack", ":", "int", ")", ":", "\n", "        ", "self", ".", "venv", "=", "venv", "\n", "self", ".", "n_stack", "=", "n_stack", "\n", "wrapped_obs_space", "=", "venv", ".", "attacker_observation_space", "\n", "low", "=", "np", ".", "repeat", "(", "wrapped_obs_space", ".", "low", ",", "self", ".", "n_stack", ",", "axis", "=", "-", "1", ")", "\n", "high", "=", "np", ".", "repeat", "(", "wrapped_obs_space", ".", "high", ",", "self", ".", "n_stack", ",", "axis", "=", "-", "1", ")", "\n", "self", ".", "stackedobs", "=", "np", ".", "zeros", "(", "(", "venv", ".", "num_envs", ",", ")", "+", "low", ".", "shape", ",", "low", ".", "dtype", ")", "\n", "observation_space", "=", "spaces", ".", "Box", "(", "low", "=", "low", ",", "high", "=", "high", ",", "dtype", "=", "venv", ".", "attacker_observation_space", ".", "dtype", ")", "\n", "VecEnvWrapper", ".", "__init__", "(", "self", ",", "venv", ",", "attacker_observation_space", "=", "observation_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_frame_stack.VecFrameStack.step_wait": [[28, 45], ["vec_frame_stack.VecFrameStack.venv.step_wait", "numpy.roll", "enumerate", "numpy.concatenate", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.step_wait"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "observations", ",", "rewards", ",", "dones", ",", "infos", "=", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "last_ax_size", "=", "observations", ".", "shape", "[", "-", "1", "]", "\n", "self", ".", "stackedobs", "=", "np", ".", "roll", "(", "self", ".", "stackedobs", ",", "shift", "=", "-", "last_ax_size", ",", "axis", "=", "-", "1", ")", "\n", "for", "i", ",", "done", "in", "enumerate", "(", "dones", ")", ":", "\n", "            ", "if", "done", ":", "\n", "                ", "if", "'terminal_observation'", "in", "infos", "[", "i", "]", ":", "\n", "                    ", "old_terminal", "=", "infos", "[", "i", "]", "[", "'terminal_observation'", "]", "\n", "new_terminal", "=", "np", ".", "concatenate", "(", "\n", "(", "self", ".", "stackedobs", "[", "i", ",", "...", ",", ":", "-", "last_ax_size", "]", ",", "old_terminal", ")", ",", "axis", "=", "-", "1", ")", "\n", "infos", "[", "i", "]", "[", "'terminal_observation'", "]", "=", "new_terminal", "\n", "", "else", ":", "\n", "                    ", "warnings", ".", "warn", "(", "\n", "\"VecFrameStack wrapping a VecEnv without terminal_observation info\"", ")", "\n", "", "self", ".", "stackedobs", "[", "i", "]", "=", "0", "\n", "", "", "self", ".", "stackedobs", "[", "...", ",", "-", "observations", ".", "shape", "[", "-", "1", "]", ":", "]", "=", "observations", "\n", "return", "self", ".", "stackedobs", ",", "rewards", ",", "dones", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_frame_stack.VecFrameStack.reset": [[46, 54], ["vec_frame_stack.VecFrameStack.venv.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Reset all environments\n        \"\"\"", "\n", "obs", "=", "self", ".", "venv", ".", "reset", "(", ")", "\n", "self", ".", "stackedobs", "[", "...", "]", "=", "0", "\n", "self", ".", "stackedobs", "[", "...", ",", "-", "obs", ".", "shape", "[", "-", "1", "]", ":", "]", "=", "obs", "\n", "return", "self", ".", "stackedobs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_frame_stack.VecFrameStack.close": [[55, 57], ["vec_frame_stack.VecFrameStack.venv.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "venv", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.subproc_vec_env.SubprocVecEnv.__init__": [[70, 96], ["len", "multiprocessing.get_context", "zip", "zip", "subproc_vec_env.SubprocVecEnv.remotes[].send", "subproc_vec_env.SubprocVecEnv.remotes[].recv", "gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.base_vec_env.VecEnv.__init__", "multiprocessing.get_context.Process", "multiprocessing.get_context.Process.start", "subproc_vec_env.SubprocVecEnv.processes.append", "work_remote.close", "len", "multiprocessing.get_all_start_methods", "gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.base_vec_env.CloudpickleWrapper", "multiprocessing.get_context.Pipe", "range"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.start", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["def", "__init__", "(", "self", ",", "env_fns", ",", "start_method", "=", "None", ")", ":", "\n", "        ", "self", ".", "waiting", "=", "False", "\n", "self", ".", "closed", "=", "False", "\n", "n_envs", "=", "len", "(", "env_fns", ")", "\n", "\n", "if", "start_method", "is", "None", ":", "\n", "# Fork is not a thread safe method (see issue #217)", "\n", "# but is more user friendly (does not require to wrap the code in", "\n", "# a `if __name__ == \"__main__\":`)", "\n", "            ", "forkserver_available", "=", "'forkserver'", "in", "multiprocessing", ".", "get_all_start_methods", "(", ")", "\n", "start_method", "=", "'forkserver'", "if", "forkserver_available", "else", "'spawn'", "\n", "", "ctx", "=", "multiprocessing", ".", "get_context", "(", "start_method", ")", "\n", "\n", "self", ".", "remotes", ",", "self", ".", "work_remotes", "=", "zip", "(", "*", "[", "ctx", ".", "Pipe", "(", ")", "for", "_", "in", "range", "(", "n_envs", ")", "]", ")", "\n", "self", ".", "processes", "=", "[", "]", "\n", "for", "work_remote", ",", "remote", ",", "env_fn", "in", "zip", "(", "self", ".", "work_remotes", ",", "self", ".", "remotes", ",", "env_fns", ")", ":", "\n", "            ", "args", "=", "(", "work_remote", ",", "remote", ",", "CloudpickleWrapper", "(", "env_fn", ")", ")", "\n", "# daemon=True: if the main process crashes, we should not cause things to hang", "\n", "process", "=", "ctx", ".", "Process", "(", "target", "=", "_worker", ",", "args", "=", "args", ",", "daemon", "=", "True", ")", "# pytype:disable=attribute-error", "\n", "process", ".", "start", "(", ")", "\n", "self", ".", "processes", ".", "append", "(", "process", ")", "\n", "work_remote", ".", "close", "(", ")", "\n", "\n", "", "self", ".", "remotes", "[", "0", "]", ".", "send", "(", "(", "'get_spaces'", ",", "None", ")", ")", "\n", "observation_space", ",", "action_space", "=", "self", ".", "remotes", "[", "0", "]", ".", "recv", "(", ")", "\n", "VecEnv", ".", "__init__", "(", "self", ",", "len", "(", "env_fns", ")", ",", "observation_space", ",", "action_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.subproc_vec_env.SubprocVecEnv.step_async": [[97, 101], ["zip", "remote.send"], "methods", ["None"], ["", "def", "step_async", "(", "self", ",", "actions", ")", ":", "\n", "        ", "for", "remote", ",", "action", "in", "zip", "(", "self", ".", "remotes", ",", "actions", ")", ":", "\n", "            ", "remote", ".", "send", "(", "(", "'step'", ",", "action", ")", ")", "\n", "", "self", ".", "waiting", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.subproc_vec_env.SubprocVecEnv.step_wait": [[102, 107], ["zip", "remote.recv", "subproc_vec_env._flatten_obs", "numpy.stack", "numpy.stack"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.subproc_vec_env._flatten_obs"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "results", "=", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "self", ".", "remotes", "]", "\n", "self", ".", "waiting", "=", "False", "\n", "obs", ",", "rews", ",", "dones", ",", "infos", "=", "zip", "(", "*", "results", ")", "\n", "return", "_flatten_obs", "(", "obs", ",", "self", ".", "attacker_observation_space", ")", ",", "np", ".", "stack", "(", "rews", ")", ",", "np", ".", "stack", "(", "dones", ")", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.subproc_vec_env.SubprocVecEnv.seed": [[108, 112], ["enumerate", "remote.send", "remote.recv"], "methods", ["None"], ["", "def", "seed", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "        ", "for", "idx", ",", "remote", "in", "enumerate", "(", "self", ".", "remotes", ")", ":", "\n", "            ", "remote", ".", "send", "(", "(", "'seed'", ",", "seed", "+", "idx", ")", ")", "\n", "", "return", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "self", ".", "remotes", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.subproc_vec_env.SubprocVecEnv.reset": [[113, 118], ["subproc_vec_env._flatten_obs", "remote.send", "remote.recv"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.subproc_vec_env._flatten_obs"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "'reset'", ",", "None", ")", ")", "\n", "", "obs", "=", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "self", ".", "remotes", "]", "\n", "return", "_flatten_obs", "(", "obs", ",", "self", ".", "attacker_observation_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.subproc_vec_env.SubprocVecEnv.close": [[119, 130], ["remote.send", "process.join", "remote.recv"], "methods", ["None"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "closed", ":", "\n", "            ", "return", "\n", "", "if", "self", ".", "waiting", ":", "\n", "            ", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "                ", "remote", ".", "recv", "(", ")", "\n", "", "", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "'close'", ",", "None", ")", ")", "\n", "", "for", "process", "in", "self", ".", "processes", ":", "\n", "            ", "process", ".", "join", "(", ")", "\n", "", "self", ".", "closed", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.subproc_vec_env.SubprocVecEnv.get_images": [[131, 138], ["pipe.send", "pipe.recv"], "methods", ["None"], ["", "def", "get_images", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "Sequence", "[", "np", ".", "ndarray", "]", ":", "\n", "        ", "for", "pipe", "in", "self", ".", "remotes", ":", "\n", "# gather images from subprocesses", "\n", "# `mode` will be taken into account later", "\n", "            ", "pipe", ".", "send", "(", "(", "'render'", ",", "(", "args", ",", "{", "'mode'", ":", "'rgb_array'", ",", "**", "kwargs", "}", ")", ")", ")", "\n", "", "imgs", "=", "[", "pipe", ".", "recv", "(", ")", "for", "pipe", "in", "self", ".", "remotes", "]", "\n", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.subproc_vec_env.SubprocVecEnv.get_attr": [[139, 145], ["subproc_vec_env.SubprocVecEnv._get_target_remotes", "remote.send", "remote.recv"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.subproc_vec_env.SubprocVecEnv._get_target_remotes"], ["", "def", "get_attr", "(", "self", ",", "attr_name", ",", "indices", "=", "None", ")", ":", "\n", "        ", "\"\"\"Return attribute from vectorized environment (see base class).\"\"\"", "\n", "target_remotes", "=", "self", ".", "_get_target_remotes", "(", "indices", ")", "\n", "for", "remote", "in", "target_remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "'get_attr'", ",", "attr_name", ")", ")", "\n", "", "return", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "target_remotes", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.subproc_vec_env.SubprocVecEnv.set_attr": [[146, 153], ["subproc_vec_env.SubprocVecEnv._get_target_remotes", "remote.send", "remote.recv"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.subproc_vec_env.SubprocVecEnv._get_target_remotes"], ["", "def", "set_attr", "(", "self", ",", "attr_name", ",", "value", ",", "indices", "=", "None", ")", ":", "\n", "        ", "\"\"\"Set attribute inside vectorized environments (see base class).\"\"\"", "\n", "target_remotes", "=", "self", ".", "_get_target_remotes", "(", "indices", ")", "\n", "for", "remote", "in", "target_remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "'set_attr'", ",", "(", "attr_name", ",", "value", ")", ")", ")", "\n", "", "for", "remote", "in", "target_remotes", ":", "\n", "            ", "remote", ".", "recv", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.subproc_vec_env.SubprocVecEnv.env_method": [[154, 160], ["subproc_vec_env.SubprocVecEnv._get_target_remotes", "remote.send", "remote.recv"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.subproc_vec_env.SubprocVecEnv._get_target_remotes"], ["", "", "def", "env_method", "(", "self", ",", "method_name", ",", "*", "method_args", ",", "indices", "=", "None", ",", "**", "method_kwargs", ")", ":", "\n", "        ", "\"\"\"Call instance methods of vectorized environments.\"\"\"", "\n", "target_remotes", "=", "self", ".", "_get_target_remotes", "(", "indices", ")", "\n", "for", "remote", "in", "target_remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "'env_method'", ",", "(", "method_name", ",", "method_args", ",", "method_kwargs", ")", ")", ")", "\n", "", "return", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "target_remotes", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.subproc_vec_env.SubprocVecEnv._get_target_remotes": [[161, 171], ["subproc_vec_env.SubprocVecEnv._get_indices"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnv._get_indices"], ["", "def", "_get_target_remotes", "(", "self", ",", "indices", ")", ":", "\n", "        ", "\"\"\"\n        Get the connection object needed to communicate with the wanted\n        envs that are in subprocesses.\n\n        :param indices: (None,int,Iterable) refers to indices of envs.\n        :return: ([multiprocessing.Connection]) Connection object to communicate between processes.\n        \"\"\"", "\n", "indices", "=", "self", ".", "_get_indices", "(", "indices", ")", "\n", "return", "[", "self", ".", "remotes", "[", "i", "]", "for", "i", "in", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.subproc_vec_env._worker": [[10, 44], ["parent_remote.close", "env_fn_wrapper.var", "remote.recv", "env_fn_wrapper.var.step", "remote.send", "env_fn_wrapper.var.reset", "env_fn_wrapper.var.reset", "remote.send", "remote.send", "env_fn_wrapper.var.render", "remote.close", "remote.send", "getattr", "remote.send", "getattr.", "remote.send", "getattr", "remote.send", "setattr"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["def", "_worker", "(", "remote", ",", "parent_remote", ",", "env_fn_wrapper", ")", ":", "\n", "    ", "parent_remote", ".", "close", "(", ")", "\n", "env", "=", "env_fn_wrapper", ".", "var", "(", ")", "\n", "while", "True", ":", "\n", "        ", "try", ":", "\n", "            ", "cmd", ",", "data", "=", "remote", ".", "recv", "(", ")", "\n", "if", "cmd", "==", "'step'", ":", "\n", "                ", "observation", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "data", ")", "\n", "if", "done", ":", "\n", "# save final observation where user can get it, then reset", "\n", "                    ", "info", "[", "'terminal_observation'", "]", "=", "observation", "\n", "observation", "=", "env", ".", "reset", "(", ")", "\n", "", "remote", ".", "send", "(", "(", "observation", ",", "reward", ",", "done", ",", "info", ")", ")", "\n", "", "elif", "cmd", "==", "'reset'", ":", "\n", "                ", "observation", "=", "env", ".", "reset", "(", ")", "\n", "remote", ".", "send", "(", "observation", ")", "\n", "", "elif", "cmd", "==", "'render'", ":", "\n", "                ", "remote", ".", "send", "(", "env", ".", "render", "(", "*", "data", "[", "0", "]", ",", "**", "data", "[", "1", "]", ")", ")", "\n", "", "elif", "cmd", "==", "'close'", ":", "\n", "                ", "remote", ".", "close", "(", ")", "\n", "break", "\n", "", "elif", "cmd", "==", "'get_spaces'", ":", "\n", "                ", "remote", ".", "send", "(", "(", "env", ".", "observation_space", ",", "env", ".", "action_space", ")", ")", "\n", "", "elif", "cmd", "==", "'env_method'", ":", "\n", "                ", "method", "=", "getattr", "(", "env", ",", "data", "[", "0", "]", ")", "\n", "remote", ".", "send", "(", "method", "(", "*", "data", "[", "1", "]", ",", "**", "data", "[", "2", "]", ")", ")", "\n", "", "elif", "cmd", "==", "'get_attr'", ":", "\n", "                ", "remote", ".", "send", "(", "getattr", "(", "env", ",", "data", ")", ")", "\n", "", "elif", "cmd", "==", "'set_attr'", ":", "\n", "                ", "remote", ".", "send", "(", "setattr", "(", "env", ",", "data", "[", "0", "]", ",", "data", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "", "", "except", "EOFError", ":", "\n", "            ", "break", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.subproc_vec_env._flatten_obs": [[173, 197], ["isinstance", "isinstance", "len", "isinstance", "isinstance", "collections.OrderedDict", "isinstance", "isinstance", "len", "tuple", "numpy.stack", "numpy.stack", "space.spaces.keys", "numpy.stack", "range"], "function", ["None"], ["", "", "def", "_flatten_obs", "(", "obs", ",", "space", ")", ":", "\n", "    ", "\"\"\"\n    Flatten observations, depending on the observation space.\n\n    :param obs: (list<X> or tuple<X> where X is dict<ndarray>, tuple<ndarray> or ndarray) observations.\n                A list or tuple of observations, one per environment.\n                Each environment observation may be a NumPy array, or a dict or tuple of NumPy arrays.\n    :return (OrderedDict<ndarray>, tuple<ndarray> or ndarray) flattened observations.\n            A flattened NumPy array or an OrderedDict or tuple of flattened numpy arrays.\n            Each NumPy array has the environment index as its first axis.\n    \"\"\"", "\n", "assert", "isinstance", "(", "obs", ",", "(", "list", ",", "tuple", ")", ")", ",", "\"expected list or tuple of observations per environment\"", "\n", "assert", "len", "(", "obs", ")", ">", "0", ",", "\"need observations from at least one environment\"", "\n", "\n", "if", "isinstance", "(", "space", ",", "gym", ".", "spaces", ".", "Dict", ")", ":", "\n", "        ", "assert", "isinstance", "(", "space", ".", "spaces", ",", "OrderedDict", ")", ",", "\"Dict space must have ordered subspaces\"", "\n", "assert", "isinstance", "(", "obs", "[", "0", "]", ",", "dict", ")", ",", "\"non-dict observation for environment with Dict observation space\"", "\n", "return", "OrderedDict", "(", "[", "(", "k", ",", "np", ".", "stack", "(", "[", "o", "[", "k", "]", "for", "o", "in", "obs", "]", ")", ")", "for", "k", "in", "space", ".", "spaces", ".", "keys", "(", ")", "]", ")", "\n", "", "elif", "isinstance", "(", "space", ",", "gym", ".", "spaces", ".", "Tuple", ")", ":", "\n", "        ", "assert", "isinstance", "(", "obs", "[", "0", "]", ",", "tuple", ")", ",", "\"non-tuple observation for environment with Tuple observation space\"", "\n", "obs_len", "=", "len", "(", "space", ".", "spaces", ")", "\n", "return", "tuple", "(", "(", "np", ".", "stack", "(", "[", "o", "[", "i", "]", "for", "o", "in", "obs", "]", ")", "for", "i", "in", "range", "(", "obs_len", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "np", ".", "stack", "(", "obs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.dummy_vec_env.DummyVecEnv.__init__": [[22, 45], ["gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.base_vec_env.VecEnv.__init__", "gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.util.obs_space_info", "gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.util.obs_space_info", "collections.OrderedDict", "collections.OrderedDict", "numpy.zeros", "numpy.zeros", "numpy.zeros", "fn", "len", "range", "numpy.zeros", "numpy.zeros", "tuple", "tuple"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.util.obs_space_info", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.util.obs_space_info"], ["def", "__init__", "(", "self", ",", "env_fns", ")", ":", "\n", "        ", "self", ".", "envs", "=", "[", "fn", "(", ")", "for", "fn", "in", "env_fns", "]", "\n", "env", "=", "self", ".", "envs", "[", "0", "]", "\n", "VecEnv", ".", "__init__", "(", "self", ",", "len", "(", "env_fns", ")", ",", "env", ".", "attacker_observation_space", ",", "env", ".", "attacker_action_space", ",", "\n", "env", ".", "defender_observation_space", ",", "env", ".", "defender_action_space", ")", "\n", "attacker_obs_space", "=", "env", ".", "attacker_observation_space", "\n", "self", ".", "attacker_keys", ",", "attacker_shapes", ",", "attacker_dtypes", "=", "obs_space_info", "(", "attacker_obs_space", ")", "\n", "defender_obs_space", "=", "env", ".", "defender_observation_space", "\n", "self", ".", "defender_keys", ",", "defender_shapes", ",", "defender_dtypes", "=", "obs_space_info", "(", "defender_obs_space", ")", "\n", "\n", "\n", "self", ".", "buf_a_obs", "=", "OrderedDict", "(", "[", "\n", "(", "k", ",", "np", ".", "zeros", "(", "(", "self", ".", "num_envs", ",", ")", "+", "tuple", "(", "attacker_shapes", "[", "k", "]", ")", ",", "dtype", "=", "attacker_dtypes", "[", "k", "]", ")", ")", "\n", "for", "k", "in", "self", ".", "attacker_keys", "]", ")", "\n", "self", ".", "buf_d_obs", "=", "OrderedDict", "(", "[", "\n", "(", "k", ",", "np", ".", "zeros", "(", "(", "self", ".", "num_envs", ",", ")", "+", "tuple", "(", "defender_shapes", "[", "k", "]", ")", ",", "dtype", "=", "defender_dtypes", "[", "k", "]", ")", ")", "\n", "for", "k", "in", "self", ".", "defender_keys", "]", ")", "\n", "self", ".", "buf_dones", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_envs", ",", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "self", ".", "buf_a_rews", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_envs", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "buf_d_rews", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_envs", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "buf_infos", "=", "[", "{", "}", "for", "_", "in", "range", "(", "self", ".", "num_envs", ")", "]", "\n", "self", ".", "actions", "=", "None", "\n", "self", ".", "metadata", "=", "env", ".", "metadata", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.dummy_vec_env.DummyVecEnv.step_async": [[46, 48], ["None"], "methods", ["None"], ["", "def", "step_async", "(", "self", ",", "actions", ")", ":", "\n", "        ", "self", ".", "actions", "=", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.dummy_vec_env.DummyVecEnv.step_wait": [[49, 66], ["range", "dummy_vec_env.DummyVecEnv.envs[].step", "dummy_vec_env.DummyVecEnv._save_obs", "numpy.copy", "numpy.copy", "numpy.copy", "numpy.copy", "numpy.copy", "copy.deepcopy", "dummy_vec_env.DummyVecEnv.envs[].reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.dummy_vec_env.DummyVecEnv._save_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset"], ["", "def", "step_wait", "(", "self", ",", "update_stats", ":", "bool", "=", "False", ")", ":", "\n", "        ", "for", "env_idx", "in", "range", "(", "self", ".", "num_envs", ")", ":", "\n", "            ", "obs", ",", "rew", ",", "self", ".", "buf_dones", "[", "env_idx", "]", ",", "self", ".", "buf_infos", "[", "env_idx", "]", "=", "self", ".", "envs", "[", "env_idx", "]", ".", "step", "(", "self", ".", "actions", "[", "env_idx", "]", ")", "\n", "self", ".", "buf_a_rews", "[", "env_idx", "]", "=", "rew", "[", "0", "]", "\n", "self", ".", "buf_d_rews", "[", "env_idx", "]", "=", "rew", "[", "1", "]", "\n", "if", "self", ".", "buf_dones", "[", "env_idx", "]", ":", "\n", "# save final observation where user can get it, then reset", "\n", "                ", "self", ".", "buf_infos", "[", "env_idx", "]", "[", "'terminal_observation'", "]", "=", "obs", "\n", "r_obs", "=", "self", ".", "envs", "[", "env_idx", "]", ".", "reset", "(", "update_stats", "=", "update_stats", ")", "\n", "if", "r_obs", "is", "not", "None", ":", "\n", "                    ", "obs", "=", "r_obs", "\n", "", "", "a_obs", "=", "obs", "[", "0", "]", "\n", "d_obs", "=", "obs", "[", "1", "]", "\n", "self", ".", "_save_obs", "(", "env_idx", ",", "a_obs", ",", "d_obs", ")", "\n", "", "return", "(", "np", ".", "copy", "(", "a_obs", ")", ",", "np", ".", "copy", "(", "d_obs", ")", ",", "np", ".", "copy", "(", "self", ".", "buf_a_rews", ")", ",", "np", ".", "copy", "(", "self", ".", "buf_d_rews", ")", ",", "np", ".", "copy", "(", "self", ".", "buf_dones", ")", ",", "\n", "deepcopy", "(", "self", ".", "buf_infos", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.dummy_vec_env.DummyVecEnv.seed": [[67, 72], ["list", "enumerate", "list.append", "env.seed"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.seed"], ["", "def", "seed", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "        ", "seeds", "=", "list", "(", ")", "\n", "for", "idx", ",", "env", "in", "enumerate", "(", "self", ".", "envs", ")", ":", "\n", "            ", "seeds", ".", "append", "(", "env", ".", "seed", "(", "seed", "+", "idx", ")", ")", "\n", "", "return", "seeds", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.dummy_vec_env.DummyVecEnv.reset": [[73, 78], ["range", "numpy.copy", "dummy_vec_env.DummyVecEnv.envs[].reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset"], ["", "def", "reset", "(", "self", ",", "update_stats", ":", "bool", "=", "False", ")", ":", "\n", "        ", "for", "env_idx", "in", "range", "(", "self", ".", "num_envs", ")", ":", "\n", "            ", "obs", "=", "self", ".", "envs", "[", "env_idx", "]", ".", "reset", "(", "update_stats", "=", "update_stats", ")", "\n", "# self._save_obs(env_idx, a_obs, d_obs)", "\n", "", "return", "np", ".", "copy", "(", "obs", ")", "\n", "#return self._obs_from_buf()", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.dummy_vec_env.DummyVecEnv.close": [[80, 83], ["env.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "for", "env", "in", "self", ".", "envs", ":", "\n", "            ", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.dummy_vec_env.DummyVecEnv.get_images": [[84, 86], ["env.render"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render"], ["", "", "def", "get_images", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "Sequence", "[", "np", ".", "ndarray", "]", ":", "\n", "        ", "return", "[", "env", ".", "render", "(", "*", "args", ",", "mode", "=", "'rgb_array'", ",", "**", "kwargs", ")", "for", "env", "in", "self", ".", "envs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.dummy_vec_env.DummyVecEnv.render": [[87, 103], ["dummy_vec_env.DummyVecEnv.envs[].render", "super().render"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render"], ["", "def", "render", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Gym environment rendering. If there are multiple environments then\n        they are tiled together in one image via ``BaseVecEnv.render()``.\n        Otherwise (if ``self.num_envs == 1``), we pass the render call directly to the\n        underlying environment.\n\n        Therefore, some arguments such as ``mode`` will have values that are valid\n        only when ``num_envs == 1``.\n\n        :param mode: The rendering type.\n        \"\"\"", "\n", "if", "self", ".", "num_envs", "==", "1", ":", "\n", "            ", "return", "self", ".", "envs", "[", "0", "]", ".", "render", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "return", "super", "(", ")", ".", "render", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.dummy_vec_env.DummyVecEnv._save_obs": [[104, 106], ["None"], "methods", ["None"], ["", "", "def", "_save_obs", "(", "self", ",", "env_idx", ",", "a_obs", ",", "d_obs", ")", ":", "\n", "        ", "pass", "\n", "# for key in self.attacker_keys:", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.dummy_vec_env.DummyVecEnv._obs_from_buf": [[119, 121], ["gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.util.dict_to_obs", "gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.util.copy_obs_dict"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.util.dict_to_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.util.copy_obs_dict"], ["", "def", "_obs_from_buf", "(", "self", ")", ":", "\n", "        ", "return", "dict_to_obs", "(", "self", ".", "attacker_observation_space", ",", "copy_obs_dict", "(", "self", ".", "buf_a_obs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.dummy_vec_env.DummyVecEnv.get_attr": [[122, 126], ["dummy_vec_env.DummyVecEnv._get_target_envs", "getattr"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.dummy_vec_env.DummyVecEnv._get_target_envs"], ["", "def", "get_attr", "(", "self", ",", "attr_name", ",", "indices", "=", "None", ")", ":", "\n", "        ", "\"\"\"Return attribute from vectorized environment (see base class).\"\"\"", "\n", "target_envs", "=", "self", ".", "_get_target_envs", "(", "indices", ")", "\n", "return", "[", "getattr", "(", "env_i", ",", "attr_name", ")", "for", "env_i", "in", "target_envs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.dummy_vec_env.DummyVecEnv.set_attr": [[127, 132], ["dummy_vec_env.DummyVecEnv._get_target_envs", "setattr"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.dummy_vec_env.DummyVecEnv._get_target_envs"], ["", "def", "set_attr", "(", "self", ",", "attr_name", ",", "value", ",", "indices", "=", "None", ")", ":", "\n", "        ", "\"\"\"Set attribute inside vectorized environments (see base class).\"\"\"", "\n", "target_envs", "=", "self", ".", "_get_target_envs", "(", "indices", ")", "\n", "for", "env_i", "in", "target_envs", ":", "\n", "            ", "setattr", "(", "env_i", ",", "attr_name", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.dummy_vec_env.DummyVecEnv.env_method": [[133, 137], ["dummy_vec_env.DummyVecEnv._get_target_envs", "getattr"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.dummy_vec_env.DummyVecEnv._get_target_envs"], ["", "", "def", "env_method", "(", "self", ",", "method_name", ",", "*", "method_args", ",", "indices", "=", "None", ",", "**", "method_kwargs", ")", ":", "\n", "        ", "\"\"\"Call instance methods of vectorized environments.\"\"\"", "\n", "target_envs", "=", "self", ".", "_get_target_envs", "(", "indices", ")", "\n", "return", "[", "getattr", "(", "env_i", ",", "method_name", ")", "(", "*", "method_args", ",", "**", "method_kwargs", ")", "for", "env_i", "in", "target_envs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.dummy_vec_env.DummyVecEnv._get_target_envs": [[138, 141], ["dummy_vec_env.DummyVecEnv._get_indices"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnv._get_indices"], ["", "def", "_get_target_envs", "(", "self", ",", "indices", ")", ":", "\n", "        ", "indices", "=", "self", ".", "_get_indices", "(", "indices", ")", "\n", "return", "[", "self", ".", "envs", "[", "i", "]", "for", "i", "in", "indices", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.AlreadySteppingError.__init__": [[44, 47], ["Exception.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "msg", "=", "'already running an async step'", "\n", "Exception", ".", "__init__", "(", "self", ",", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.NotSteppingError.__init__": [[55, 58], ["Exception.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "msg", "=", "'not running an async step'", "\n", "Exception", ".", "__init__", "(", "self", ",", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnv.__init__": [[72, 79], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_envs", ",", "attacker_observation_space", ",", "attacker_action_space", ",", "\n", "defender_observation_space", ",", "defender_action_space", ")", ":", "\n", "        ", "self", ".", "num_envs", "=", "num_envs", "\n", "self", ".", "attacker_observation_space", "=", "attacker_observation_space", "\n", "self", ".", "attacker_action_space", "=", "attacker_action_space", "\n", "self", ".", "defender_observation_space", "=", "defender_observation_space", "\n", "self", ".", "defender_action_space", "=", "defender_action_space", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnv.reset": [[80, 93], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Reset all the environments and return an array of\n        observations, or a tuple of observation arrays.\n\n        If step_async is still doing work, that work will\n        be cancelled and step_wait() should not be called\n        until step_async() is invoked again.\n\n        :return: ([int] or [float]) observation\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnv.step_async": [[94, 105], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "step_async", "(", "self", ",", "actions", ")", ":", "\n", "        ", "\"\"\"\n        Tell all the environments to start taking a step\n        with the given actions.\n        Call step_wait() to get the results of the step.\n\n        You should not call this if a step_async run is\n        already pending.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnv.step_wait": [[106, 114], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Wait for the step taken with step_async().\n\n        :return: ([int] or [float], [float], [bool], dict) observation, reward, done, information\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnv.close": [[115, 121], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "close", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Clean up the environment's resources.\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnv.get_attr": [[122, 132], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "get_attr", "(", "self", ",", "attr_name", ",", "indices", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Return attribute from vectorized environment.\n\n        :param attr_name: (str) The name of the attribute whose value to return\n        :param indices: (list,int) Indices of envs to get attribute from\n        :return: (list) List of values of 'attr_name' in all environments\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnv.set_attr": [[133, 144], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "set_attr", "(", "self", ",", "attr_name", ",", "value", ",", "indices", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Set attribute inside vectorized environments.\n\n        :param attr_name: (str) The name of attribute to assign new value\n        :param value: (obj) Value to assign to `attr_name`\n        :param indices: (list,int) Indices of envs to assign value\n        :return: (NoneType)\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnv.env_method": [[145, 157], ["NotImplementedError"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "env_method", "(", "self", ",", "method_name", ",", "*", "method_args", ",", "indices", "=", "None", ",", "**", "method_kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Call instance methods of vectorized environments.\n\n        :param method_name: (str) The name of the environment method to invoke.\n        :param indices: (list,int) Indices of envs whose method to call\n        :param method_args: (tuple) Any positional arguments to provide in the call\n        :param method_kwargs: (dict) Any keyword arguments to provide in the call\n        :return: (list) List of items returned by the environment's method call\n        \"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnv.step": [[158, 167], ["base_vec_env.VecEnv.step_async", "base_vec_env.VecEnv.step_wait"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.step_async", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.step_wait"], ["", "def", "step", "(", "self", ",", "actions", ",", "update_stats", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Step the environments with the given action\n\n        :param actions: ([int] or [float]) the action\n        :return: ([int] or [float], [float], [bool], dict) observation, reward, done, information\n        \"\"\"", "\n", "self", ".", "step_async", "(", "actions", ")", "\n", "return", "self", ".", "step_wait", "(", "update_stats", "=", "update_stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnv.get_images": [[168, 173], ["None"], "methods", ["None"], ["", "def", "get_images", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "Sequence", "[", "np", ".", "ndarray", "]", ":", "\n", "        ", "\"\"\"\n        Return RGB images from each environment\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnv.render": [[174, 196], ["base_vec_env.tile_images", "base_vec_env.VecEnv.get_images", "cv2.imshow", "cv2.waitKey", "stable_baselines3.common.logger.warn"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.tile_images", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.get_images"], ["", "def", "render", "(", "self", ",", "*", "args", ",", "mode", ":", "str", "=", "'human'", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Gym environment rendering\n\n        :param mode: the rendering type\n        \"\"\"", "\n", "try", ":", "\n", "            ", "imgs", "=", "self", ".", "get_images", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "NotImplementedError", ":", "\n", "            ", "logger", ".", "warn", "(", "'Render not defined for {}'", ".", "format", "(", "self", ")", ")", "\n", "return", "\n", "\n", "# Create a big image by tiling images from subprocesses", "\n", "", "bigimg", "=", "tile_images", "(", "imgs", ")", "\n", "if", "mode", "==", "'human'", ":", "\n", "            ", "import", "cv2", "# pytype:disable=import-error", "\n", "cv2", ".", "imshow", "(", "'vecenv'", ",", "bigimg", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ")", "\n", "cv2", ".", "waitKey", "(", "1", ")", "\n", "", "elif", "mode", "==", "'rgb_array'", ":", "\n", "            ", "return", "bigimg", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnv.seed": [[197, 208], ["None"], "methods", ["None"], ["", "", "@", "abstractmethod", "\n", "def", "seed", "(", "self", ",", "seed", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "List", "[", "Union", "[", "None", ",", "int", "]", "]", ":", "\n", "        ", "\"\"\"\n        Sets the random seeds for all environments, based on a given seed.\n        Each individual environment will still get its own seed, by incrementing the given seed.\n\n        :param seed: (Optional[int]) The random seed. May be None for completely random seeding.\n        :return: (List[Union[None, int]]) Returns a list containing the seeds for each individual env.\n            Note that all list elements may be None, if the env does not return anything when being seeded.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnv.unwrapped": [[209, 215], ["isinstance"], "methods", ["None"], ["", "@", "property", "\n", "def", "unwrapped", "(", "self", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "VecEnvWrapper", ")", ":", "\n", "            ", "return", "self", ".", "venv", ".", "unwrapped", "\n", "", "else", ":", "\n", "            ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnv.getattr_depth_check": [[216, 227], ["hasattr", "type", "type"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type"], ["", "", "def", "getattr_depth_check", "(", "self", ",", "name", ",", "already_found", ")", ":", "\n", "        ", "\"\"\"Check if an attribute reference is being hidden in a recursive call to __getattr__\n\n        :param name: (str) name of attribute to check for\n        :param already_found: (bool) whether this attribute has already been found in a wrapper\n        :return: (str or None) name of module whose attribute is being shadowed, if any.\n        \"\"\"", "\n", "if", "hasattr", "(", "self", ",", "name", ")", "and", "already_found", ":", "\n", "            ", "return", "f\"{type(self).__module__}.{type(self).__name__}\"", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnv._get_indices": [[228, 240], ["range", "isinstance"], "methods", ["None"], ["", "", "def", "_get_indices", "(", "self", ",", "indices", ")", ":", "\n", "        ", "\"\"\"\n        Convert a flexibly-typed reference to environment indices to an implied list of indices.\n\n        :param indices: (None,int,Iterable) refers to indices of envs.\n        :return: (list) the implied list of indices.\n        \"\"\"", "\n", "if", "indices", "is", "None", ":", "\n", "            ", "indices", "=", "range", "(", "self", ".", "num_envs", ")", "\n", "", "elif", "isinstance", "(", "indices", ",", "int", ")", ":", "\n", "            ", "indices", "=", "[", "indices", "]", "\n", "", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.__init__": [[251, 256], ["base_vec_env.VecEnv.__init__", "dict", "inspect.getmembers"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "venv", ",", "attacker_observation_space", "=", "None", ",", "attacker_action_space", "=", "None", ")", ":", "\n", "        ", "self", ".", "venv", "=", "venv", "\n", "VecEnv", ".", "__init__", "(", "self", ",", "num_envs", "=", "venv", ".", "num_envs", ",", "attacker_observation_space", "=", "attacker_observation_space", "or", "venv", ".", "observation_space", ",", "\n", "attacker_action_space", "=", "attacker_action_space", "or", "venv", ".", "action_space", ")", "\n", "self", ".", "class_attributes", "=", "dict", "(", "inspect", ".", "getmembers", "(", "self", ".", "__class__", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.step_async": [[257, 259], ["base_vec_env.VecEnvWrapper.venv.step_async"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.step_async"], ["", "def", "step_async", "(", "self", ",", "actions", ")", ":", "\n", "        ", "self", ".", "venv", ".", "step_async", "(", "actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.reset": [[260, 263], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "reset", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.step_wait": [[264, 267], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.seed": [[268, 270], ["base_vec_env.VecEnvWrapper.venv.seed"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.seed"], ["", "def", "seed", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.close": [[271, 273], ["base_vec_env.VecEnvWrapper.venv.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.render": [[274, 276], ["base_vec_env.VecEnvWrapper.venv.render"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render"], ["", "def", "render", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "render", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.get_images": [[277, 279], ["base_vec_env.VecEnvWrapper.venv.get_images"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.get_images"], ["", "def", "get_images", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "get_images", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.get_attr": [[280, 282], ["base_vec_env.VecEnvWrapper.venv.get_attr"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.get_attr"], ["", "def", "get_attr", "(", "self", ",", "attr_name", ",", "indices", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "get_attr", "(", "attr_name", ",", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.set_attr": [[283, 285], ["base_vec_env.VecEnvWrapper.venv.set_attr"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.set_attr"], ["", "def", "set_attr", "(", "self", ",", "attr_name", ",", "value", ",", "indices", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "set_attr", "(", "attr_name", ",", "value", ",", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.env_method": [[286, 288], ["base_vec_env.VecEnvWrapper.venv.env_method"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.env_method"], ["", "def", "env_method", "(", "self", ",", "method_name", ",", "*", "method_args", ",", "indices", "=", "None", ",", "**", "method_kwargs", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "env_method", "(", "method_name", ",", "*", "method_args", ",", "indices", "=", "indices", ",", "**", "method_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.__getattr__": [[289, 302], ["base_vec_env.VecEnvWrapper.getattr_depth_check", "base_vec_env.VecEnvWrapper.getattr_recursive", "AttributeError", "type", "type"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.getattr_depth_check", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.getattr_recursive", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type"], ["", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"Find attribute from wrapped venv(s) if this wrapper does not have it.\n        Useful for accessing attributes from venvs which are wrapped with multiple wrappers\n        which have unique attributes of interest.\n        \"\"\"", "\n", "blocked_class", "=", "self", ".", "getattr_depth_check", "(", "name", ",", "already_found", "=", "False", ")", "\n", "if", "blocked_class", "is", "not", "None", ":", "\n", "            ", "own_class", "=", "f\"{type(self).__module__}.{type(self).__name__}\"", "\n", "error_str", "=", "(", "f\"Error: Recursive attribute lookup for {name} from {own_class} is \"", "\n", "\"ambiguous and hides attribute from {blocked_class}\"", ")", "\n", "raise", "AttributeError", "(", "error_str", ")", "\n", "\n", "", "return", "self", ".", "getattr_recursive", "(", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper._get_all_attributes": [[303, 311], ["base_vec_env.VecEnvWrapper.__dict__.copy", "base_vec_env.VecEnvWrapper.update"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update"], ["", "def", "_get_all_attributes", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get all (inherited) instance and class attributes\n\n        :return: (dict<str, object>) all_attributes\n        \"\"\"", "\n", "all_attributes", "=", "self", ".", "__dict__", ".", "copy", "(", ")", "\n", "all_attributes", ".", "update", "(", "self", ".", "class_attributes", ")", "\n", "return", "all_attributes", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.getattr_recursive": [[312, 329], ["base_vec_env.VecEnvWrapper._get_all_attributes", "getattr", "hasattr", "base_vec_env.VecEnvWrapper.venv.getattr_recursive", "getattr"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper._get_all_attributes", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.getattr_recursive"], ["", "def", "getattr_recursive", "(", "self", ",", "name", ")", ":", "\n", "        ", "\"\"\"Recursively check wrappers to find attribute.\n\n        :param name (str) name of attribute to look for\n        :return: (object) attribute\n        \"\"\"", "\n", "all_attributes", "=", "self", ".", "_get_all_attributes", "(", ")", "\n", "if", "name", "in", "all_attributes", ":", "# attribute is present in this wrapper", "\n", "            ", "attr", "=", "getattr", "(", "self", ",", "name", ")", "\n", "", "elif", "hasattr", "(", "self", ".", "venv", ",", "'getattr_recursive'", ")", ":", "\n", "# Attribute not present, child is wrapper. Call getattr_recursive rather than getattr", "\n", "# to avoid a duplicate call to getattr_depth_check.", "\n", "            ", "attr", "=", "self", ".", "venv", ".", "getattr_recursive", "(", "name", ")", "\n", "", "else", ":", "# attribute not present, child is an unwrapped VecEnv", "\n", "            ", "attr", "=", "getattr", "(", "self", ".", "venv", ",", "name", ")", "\n", "\n", "", "return", "attr", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.getattr_depth_check": [[330, 347], ["base_vec_env.VecEnvWrapper._get_all_attributes", "base_vec_env.VecEnvWrapper.venv.getattr_depth_check", "base_vec_env.VecEnvWrapper.venv.getattr_depth_check", "type", "type"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper._get_all_attributes", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.getattr_depth_check", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.getattr_depth_check", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type"], ["", "def", "getattr_depth_check", "(", "self", ",", "name", ",", "already_found", ")", ":", "\n", "        ", "\"\"\"See base class.\n\n        :return: (str or None) name of module whose attribute is being shadowed, if any.\n        \"\"\"", "\n", "all_attributes", "=", "self", ".", "_get_all_attributes", "(", ")", "\n", "if", "name", "in", "all_attributes", "and", "already_found", ":", "\n", "# this venv's attribute is being hidden because of a higher venv.", "\n", "            ", "shadowed_wrapper_class", "=", "f\"{type(self).__module__}.{type(self).__name__}\"", "\n", "", "elif", "name", "in", "all_attributes", "and", "not", "already_found", ":", "\n", "# we have found the first reference to the attribute. Now check for duplicates.", "\n", "            ", "shadowed_wrapper_class", "=", "self", ".", "venv", ".", "getattr_depth_check", "(", "name", ",", "True", ")", "\n", "", "else", ":", "\n", "# this wrapper does not have the attribute. Keep searching.", "\n", "            ", "shadowed_wrapper_class", "=", "self", ".", "venv", ".", "getattr_depth_check", "(", "name", ",", "already_found", ")", "\n", "\n", "", "return", "shadowed_wrapper_class", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.CloudpickleWrapper.__init__": [[350, 357], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "var", ")", ":", "\n", "        ", "\"\"\"\n        Uses cloudpickle to serialize contents (otherwise multiprocessing tries to use pickle)\n\n        :param var: (Any) the variable you wish to wrap for pickling with cloudpickle\n        \"\"\"", "\n", "self", ".", "var", "=", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.CloudpickleWrapper.__getstate__": [[358, 360], ["cloudpickle.dumps"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "return", "cloudpickle", ".", "dumps", "(", "self", ".", "var", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.CloudpickleWrapper.__setstate__": [[361, 363], ["pickle.loads"], "methods", ["None"], ["", "def", "__setstate__", "(", "self", ",", "obs", ")", ":", "\n", "        ", "self", ".", "var", "=", "pickle", ".", "loads", "(", "obs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.tile_images": [[12, 36], ["numpy.asarray", "int", "int", "numpy.array", "np.array.reshape", "out_image.reshape.transpose", "out_image.reshape.reshape", "numpy.ceil", "numpy.ceil", "numpy.sqrt", "list", "float", "range"], "function", ["None"], ["def", "tile_images", "(", "img_nhwc", ":", "Sequence", "[", "np", ".", "ndarray", "]", ")", "->", "np", ".", "ndarray", ":", "# pragma: no cover", "\n", "    ", "\"\"\"\n    Tile N images into one big PxQ image\n    (P,Q) are chosen to be as close as possible, and if N\n    is square, then P=Q.\n\n    :param img_nhwc: (Sequence[np.ndarray]) list or array of images, ndim=4 once turned into array. img nhwc\n        n = batch index, h = height, w = width, c = channel\n    :return: (np.ndarray) img_HWc, ndim=3\n    \"\"\"", "\n", "img_nhwc", "=", "np", ".", "asarray", "(", "img_nhwc", ")", "\n", "n_images", ",", "height", ",", "width", ",", "n_channels", "=", "img_nhwc", ".", "shape", "\n", "# new_height was named H before", "\n", "new_height", "=", "int", "(", "np", ".", "ceil", "(", "np", ".", "sqrt", "(", "n_images", ")", ")", ")", "\n", "# new_width was named W before", "\n", "new_width", "=", "int", "(", "np", ".", "ceil", "(", "float", "(", "n_images", ")", "/", "new_height", ")", ")", "\n", "img_nhwc", "=", "np", ".", "array", "(", "list", "(", "img_nhwc", ")", "+", "[", "img_nhwc", "[", "0", "]", "*", "0", "for", "_", "in", "range", "(", "n_images", ",", "new_height", "*", "new_width", ")", "]", ")", "\n", "# img_HWhwc", "\n", "out_image", "=", "img_nhwc", ".", "reshape", "(", "(", "new_height", ",", "new_width", ",", "height", ",", "width", ",", "n_channels", ")", ")", "\n", "# img_HhWwc", "\n", "out_image", "=", "out_image", ".", "transpose", "(", "0", ",", "2", ",", "1", ",", "3", ",", "4", ")", "\n", "# img_Hh_Ww_c", "\n", "out_image", "=", "out_image", ".", "reshape", "(", "(", "new_height", "*", "height", ",", "new_width", "*", "width", ",", "n_channels", ")", ")", "\n", "return", "out_image", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_transpose.VecTransposeImage.__init__": [[21, 26], ["stable_baselines3.common.preprocessing.is_image_space", "vec_transpose.VecTransposeImage.transpose_space", "gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.base_vec_env.VecEnvWrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_transpose.VecTransposeImage.transpose_space", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "venv", ":", "VecEnv", ")", ":", "\n", "        ", "assert", "is_image_space", "(", "venv", ".", "attacker_observation_space", ")", ",", "'The observation space must be an image'", "\n", "\n", "observation_space", "=", "self", ".", "transpose_space", "(", "venv", ".", "attacker_observation_space", ")", "\n", "super", "(", "VecTransposeImage", ",", "self", ")", ".", "__init__", "(", "venv", ",", "attacker_observation_space", "=", "observation_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_transpose.VecTransposeImage.transpose_space": [[27, 39], ["stable_baselines3.common.preprocessing.is_image_space", "gym.spaces.Box"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "transpose_space", "(", "observation_space", ":", "spaces", ".", "Box", ")", "->", "spaces", ".", "Box", ":", "\n", "        ", "\"\"\"\n        Transpose an observation space (re-order channels).\n\n        :param observation_space: (spaces.Box)\n        :return: (spaces.Box)\n        \"\"\"", "\n", "assert", "is_image_space", "(", "observation_space", ")", ",", "'The observation space must be an image'", "\n", "width", ",", "height", ",", "channels", "=", "observation_space", ".", "shape", "\n", "new_shape", "=", "(", "channels", ",", "width", ",", "height", ")", "\n", "return", "spaces", ".", "Box", "(", "low", "=", "0", ",", "high", "=", "255", ",", "shape", "=", "new_shape", ",", "dtype", "=", "observation_space", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_transpose.VecTransposeImage.transpose_image": [[40, 51], ["numpy.transpose", "len", "numpy.transpose"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "transpose_image", "(", "image", ":", "np", ".", "ndarray", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Transpose an image or batch of images (re-order channels).\n\n        :param image: (np.ndarray)\n        :return: (np.ndarray)\n        \"\"\"", "\n", "if", "len", "(", "image", ".", "shape", ")", "==", "3", ":", "\n", "            ", "return", "np", ".", "transpose", "(", "image", ",", "(", "2", ",", "0", ",", "1", ")", ")", "\n", "", "return", "np", ".", "transpose", "(", "image", ",", "(", "0", ",", "3", ",", "1", ",", "2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_transpose.VecTransposeImage.step_wait": [[52, 55], ["vec_transpose.VecTransposeImage.venv.step_wait", "vec_transpose.VecTransposeImage.transpose_image"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.step_wait", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_transpose.VecTransposeImage.transpose_image"], ["", "def", "step_wait", "(", "self", ")", "->", "'GymStepReturn'", ":", "\n", "        ", "observations", ",", "rewards", ",", "dones", ",", "infos", "=", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "return", "self", ".", "transpose_image", "(", "observations", ")", ",", "rewards", ",", "dones", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_transpose.VecTransposeImage.reset": [[56, 61], ["vec_transpose.VecTransposeImage.transpose_image", "vec_transpose.VecTransposeImage.venv.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_transpose.VecTransposeImage.transpose_image", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset"], ["", "def", "reset", "(", "self", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Reset all environments\n        \"\"\"", "\n", "return", "self", ".", "transpose_image", "(", "self", ".", "venv", ".", "reset", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_transpose.VecTransposeImage.close": [[62, 64], ["vec_transpose.VecTransposeImage.venv.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "self", ".", "venv", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_video_recorder.VecVideoRecorder.__init__": [[27, 61], ["gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.base_vec_env.VecEnvWrapper.__init__", "os.path.abspath", "os.makedirs", "isinstance", "isinstance", "isinstance", "isinstance", "temp_env.get_attr"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.get_attr"], ["def", "__init__", "(", "self", ",", "venv", ",", "video_folder", ",", "record_video_trigger", ",", "\n", "video_length", "=", "200", ",", "name_prefix", "=", "'rl-video'", ")", ":", "\n", "\n", "        ", "VecEnvWrapper", ".", "__init__", "(", "self", ",", "venv", ")", "\n", "\n", "self", ".", "env", "=", "venv", "\n", "# Temp variable to retrieve metadata", "\n", "temp_env", "=", "venv", "\n", "\n", "# Unwrap to retrieve metadata dict", "\n", "# that will be used by gym recorder", "\n", "while", "isinstance", "(", "temp_env", ",", "VecNormalize", ")", "or", "isinstance", "(", "temp_env", ",", "VecFrameStack", ")", ":", "\n", "            ", "temp_env", "=", "temp_env", ".", "venv", "\n", "\n", "", "if", "isinstance", "(", "temp_env", ",", "DummyVecEnv", ")", "or", "isinstance", "(", "temp_env", ",", "SubprocVecEnv", ")", ":", "\n", "            ", "metadata", "=", "temp_env", ".", "get_attr", "(", "'metadata'", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "metadata", "=", "temp_env", ".", "metadata", "\n", "\n", "", "self", ".", "env", ".", "metadata", "=", "metadata", "\n", "\n", "self", ".", "record_video_trigger", "=", "record_video_trigger", "\n", "self", ".", "video_recorder", "=", "None", "\n", "\n", "self", ".", "video_folder", "=", "os", ".", "path", ".", "abspath", "(", "video_folder", ")", "\n", "# Create output folder if needed", "\n", "os", ".", "makedirs", "(", "self", ".", "video_folder", ",", "exist_ok", "=", "True", ")", "\n", "\n", "self", ".", "name_prefix", "=", "name_prefix", "\n", "self", ".", "step_id", "=", "0", "\n", "self", ".", "video_length", "=", "video_length", "\n", "\n", "self", ".", "recording", "=", "False", "\n", "self", ".", "recorded_frames", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_video_recorder.VecVideoRecorder.reset": [[62, 66], ["vec_video_recorder.VecVideoRecorder.venv.reset", "vec_video_recorder.VecVideoRecorder.start_video_recorder"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_video_recorder.VecVideoRecorder.start_video_recorder"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs", "=", "self", ".", "venv", ".", "reset", "(", ")", "\n", "self", ".", "start_video_recorder", "(", ")", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_video_recorder.VecVideoRecorder.start_video_recorder": [[67, 80], ["vec_video_recorder.VecVideoRecorder.close_video_recorder", "os.path.join", "gym.wrappers.monitoring.video_recorder.VideoRecorder", "vec_video_recorder.VecVideoRecorder.video_recorder.capture_frame"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_video_recorder.VecVideoRecorder.close_video_recorder", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.capture_frame"], ["", "def", "start_video_recorder", "(", "self", ")", ":", "\n", "        ", "self", ".", "close_video_recorder", "(", ")", "\n", "\n", "video_name", "=", "f'{self.name_prefix}-step-{self.step_id}-to-step-{self.step_id + self.video_length}'", "\n", "base_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "video_folder", ",", "video_name", ")", "\n", "self", ".", "video_recorder", "=", "video_recorder", ".", "VideoRecorder", "(", "env", "=", "self", ".", "env", ",", "\n", "base_path", "=", "base_path", ",", "\n", "metadata", "=", "{", "'step_id'", ":", "self", ".", "step_id", "}", "\n", ")", "\n", "\n", "self", ".", "video_recorder", ".", "capture_frame", "(", ")", "\n", "self", ".", "recorded_frames", "=", "1", "\n", "self", ".", "recording", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_video_recorder.VecVideoRecorder._video_enabled": [[81, 83], ["vec_video_recorder.VecVideoRecorder.record_video_trigger"], "methods", ["None"], ["", "def", "_video_enabled", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "record_video_trigger", "(", "self", ".", "step_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_video_recorder.VecVideoRecorder.step_wait": [[84, 98], ["vec_video_recorder.VecVideoRecorder.venv.step_wait", "vec_video_recorder.VecVideoRecorder.video_recorder.capture_frame", "vec_video_recorder.VecVideoRecorder._video_enabled", "stable_baselines3.common.logger.info", "vec_video_recorder.VecVideoRecorder.close_video_recorder", "vec_video_recorder.VecVideoRecorder.start_video_recorder"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.step_wait", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.capture_frame", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._video_enabled", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_video_recorder.VecVideoRecorder.close_video_recorder", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_video_recorder.VecVideoRecorder.start_video_recorder"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "obs", ",", "rews", ",", "dones", ",", "infos", "=", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "\n", "self", ".", "step_id", "+=", "1", "\n", "if", "self", ".", "recording", ":", "\n", "            ", "self", ".", "video_recorder", ".", "capture_frame", "(", ")", "\n", "self", ".", "recorded_frames", "+=", "1", "\n", "if", "self", ".", "recorded_frames", ">", "self", ".", "video_length", ":", "\n", "                ", "logger", ".", "info", "(", "\"Saving video to \"", ",", "self", ".", "video_recorder", ".", "path", ")", "\n", "self", ".", "close_video_recorder", "(", ")", "\n", "", "", "elif", "self", ".", "_video_enabled", "(", ")", ":", "\n", "            ", "self", ".", "start_video_recorder", "(", ")", "\n", "\n", "", "return", "obs", ",", "rews", ",", "dones", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_video_recorder.VecVideoRecorder.close_video_recorder": [[99, 104], ["vec_video_recorder.VecVideoRecorder.video_recorder.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "close_video_recorder", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "recording", ":", "\n", "            ", "self", ".", "video_recorder", ".", "close", "(", ")", "\n", "", "self", ".", "recording", "=", "False", "\n", "self", ".", "recorded_frames", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_video_recorder.VecVideoRecorder.close": [[105, 108], ["gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.base_vec_env.VecEnvWrapper.close", "vec_video_recorder.VecVideoRecorder.close_video_recorder"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_video_recorder.VecVideoRecorder.close_video_recorder"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "VecEnvWrapper", ".", "close", "(", "self", ")", "\n", "self", ".", "close_video_recorder", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_video_recorder.VecVideoRecorder.__del__": [[109, 111], ["vec_video_recorder.VecVideoRecorder.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.__init__": [[24, 40], ["gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.base_vec_env.VecEnvWrapper.__init__", "stable_baselines3.common.running_mean_std.RunningMeanStd", "stable_baselines3.common.running_mean_std.RunningMeanStd", "numpy.zeros", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "venv", ",", "training", "=", "True", ",", "norm_obs", "=", "True", ",", "norm_reward", "=", "True", ",", "\n", "clip_obs", "=", "10.", ",", "clip_reward", "=", "10.", ",", "gamma", "=", "0.99", ",", "epsilon", "=", "1e-8", ")", ":", "\n", "        ", "VecEnvWrapper", ".", "__init__", "(", "self", ",", "venv", ")", "\n", "self", ".", "obs_rms", "=", "RunningMeanStd", "(", "shape", "=", "self", ".", "attacker_observation_space", ".", "shape", ")", "\n", "self", ".", "ret_rms", "=", "RunningMeanStd", "(", "shape", "=", "(", ")", ")", "\n", "self", ".", "clip_obs", "=", "clip_obs", "\n", "self", ".", "clip_reward", "=", "clip_reward", "\n", "# Returns: discounted rewards", "\n", "self", ".", "ret", "=", "np", ".", "zeros", "(", "self", ".", "num_envs", ")", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "training", "=", "training", "\n", "self", ".", "norm_obs", "=", "norm_obs", "\n", "self", ".", "norm_reward", "=", "norm_reward", "\n", "self", ".", "old_obs", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "self", ".", "old_reward", "=", "np", ".", "array", "(", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.__getstate__": [[41, 53], ["vec_normalize.VecNormalize.__dict__.copy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Gets state for pickling.\n\n        Excludes self.venv, as in general VecEnv's may not be pickleable.\"\"\"", "\n", "state", "=", "self", ".", "__dict__", ".", "copy", "(", ")", "\n", "# these attributes are not pickleable", "\n", "del", "state", "[", "'venv'", "]", "\n", "del", "state", "[", "'class_attributes'", "]", "\n", "# these attributes depend on the above and so we would prefer not to pickle", "\n", "del", "state", "[", "'ret'", "]", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.__setstate__": [[54, 64], ["vec_normalize.VecNormalize.__dict__.update"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "\"\"\"\n        Restores pickled state.\n\n        User must call set_venv() after unpickling before using.\n\n        :param state: (dict)\"\"\"", "\n", "self", ".", "__dict__", ".", "update", "(", "state", ")", "\n", "assert", "'venv'", "not", "in", "state", "\n", "self", ".", "venv", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.set_venv": [[65, 79], ["gym_idsgame.agents.training_agents.openai_baselines.common.vec_env.base_vec_env.VecEnvWrapper.__init__", "numpy.zeros", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["", "def", "set_venv", "(", "self", ",", "venv", ")", ":", "\n", "        ", "\"\"\"\n        Sets the vector environment to wrap to venv.\n\n        Also sets attributes derived from this such as `num_env`.\n\n        :param venv: (VecEnv)\n        \"\"\"", "\n", "if", "self", ".", "venv", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Trying to set venv of already initialized VecNormalize wrapper.\"", ")", "\n", "", "VecEnvWrapper", ".", "__init__", "(", "self", ",", "venv", ")", "\n", "if", "self", ".", "obs_rms", ".", "mean", ".", "shape", "!=", "self", ".", "attacker_observation_space", ".", "shape", ":", "\n", "            ", "raise", "ValueError", "(", "\"venv is incompatible with current statistics.\"", ")", "\n", "", "self", ".", "ret", "=", "np", ".", "zeros", "(", "self", ".", "num_envs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.step_wait": [[80, 101], ["vec_normalize.VecNormalize.venv.step_wait", "vec_normalize.VecNormalize.normalize_obs", "vec_normalize.VecNormalize.normalize_reward", "vec_normalize.VecNormalize.obs_rms.update", "vec_normalize.VecNormalize._update_reward"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.step_wait", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.normalize_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.normalize_reward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize._update_reward"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Apply sequence of actions to sequence of environments\n        actions -> (observations, rewards, news)\n\n        where 'news' is a boolean vector indicating whether each element is new.\n        \"\"\"", "\n", "obs", ",", "rews", ",", "news", ",", "infos", "=", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "self", ".", "old_obs", "=", "obs", "\n", "self", ".", "old_reward", "=", "rews", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "self", ".", "obs_rms", ".", "update", "(", "obs", ")", "\n", "", "obs", "=", "self", ".", "normalize_obs", "(", "obs", ")", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "self", ".", "_update_reward", "(", "rews", ")", "\n", "", "rews", "=", "self", ".", "normalize_reward", "(", "rews", ")", "\n", "\n", "self", ".", "ret", "[", "news", "]", "=", "0", "\n", "return", "obs", ",", "rews", ",", "news", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize._update_reward": [[102, 106], ["vec_normalize.VecNormalize.ret_rms.update"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update"], ["", "def", "_update_reward", "(", "self", ",", "reward", ")", ":", "\n", "        ", "\"\"\"Update reward normalization statistics.\"\"\"", "\n", "self", ".", "ret", "=", "self", ".", "ret", "*", "self", ".", "gamma", "+", "reward", "\n", "self", ".", "ret_rms", ".", "update", "(", "self", ".", "ret", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.normalize_obs": [[107, 117], ["numpy.clip", "numpy.sqrt"], "methods", ["None"], ["", "def", "normalize_obs", "(", "self", ",", "obs", ")", ":", "\n", "        ", "\"\"\"\n        Normalize observations using this VecNormalize's observations statistics.\n        Calling this method does not update statistics.\n        \"\"\"", "\n", "if", "self", ".", "norm_obs", ":", "\n", "            ", "obs", "=", "np", ".", "clip", "(", "(", "obs", "-", "self", ".", "obs_rms", ".", "mean", ")", "/", "np", ".", "sqrt", "(", "self", ".", "obs_rms", ".", "var", "+", "self", ".", "epsilon", ")", ",", "\n", "-", "self", ".", "clip_obs", ",", "\n", "self", ".", "clip_obs", ")", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.normalize_reward": [[118, 127], ["numpy.clip", "numpy.sqrt"], "methods", ["None"], ["", "def", "normalize_reward", "(", "self", ",", "reward", ")", ":", "\n", "        ", "\"\"\"\n        Normalize rewards using this VecNormalize's rewards statistics.\n        Calling this method does not update statistics.\n        \"\"\"", "\n", "if", "self", ".", "norm_reward", ":", "\n", "            ", "reward", "=", "np", ".", "clip", "(", "reward", "/", "np", ".", "sqrt", "(", "self", ".", "ret_rms", ".", "var", "+", "self", ".", "epsilon", ")", ",", "\n", "-", "self", ".", "clip_reward", ",", "self", ".", "clip_reward", ")", "\n", "", "return", "reward", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.unnormalize_obs": [[128, 132], ["numpy.sqrt"], "methods", ["None"], ["", "def", "unnormalize_obs", "(", "self", ",", "obs", ")", ":", "\n", "        ", "if", "self", ".", "norm_obs", ":", "\n", "            ", "return", "(", "obs", "*", "np", ".", "sqrt", "(", "self", ".", "obs_rms", ".", "var", "+", "self", ".", "epsilon", ")", ")", "+", "self", ".", "obs_rms", ".", "mean", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.unnormalize_reward": [[133, 137], ["numpy.sqrt"], "methods", ["None"], ["", "def", "unnormalize_reward", "(", "self", ",", "reward", ")", ":", "\n", "        ", "if", "self", ".", "norm_reward", ":", "\n", "            ", "return", "reward", "*", "np", ".", "sqrt", "(", "self", ".", "ret_rms", ".", "var", "+", "self", ".", "epsilon", ")", "\n", "", "return", "reward", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.get_original_obs": [[138, 144], ["vec_normalize.VecNormalize.old_obs.copy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy"], ["", "def", "get_original_obs", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns an unnormalized version of the observations from the most recent\n        step or reset.\n        \"\"\"", "\n", "return", "self", ".", "old_obs", ".", "copy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.get_original_reward": [[145, 150], ["vec_normalize.VecNormalize.old_reward.copy"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy"], ["", "def", "get_original_reward", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns an unnormalized version of the rewards from the most recent step.\n        \"\"\"", "\n", "return", "self", ".", "old_reward", ".", "copy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.reset": [[151, 161], ["vec_normalize.VecNormalize.venv.reset", "numpy.zeros", "vec_normalize.VecNormalize.normalize_obs", "vec_normalize.VecNormalize._update_reward"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.normalize_obs", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize._update_reward"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Reset all environments\n        \"\"\"", "\n", "obs", "=", "self", ".", "venv", ".", "reset", "(", ")", "\n", "self", ".", "old_obs", "=", "obs", "\n", "self", ".", "ret", "=", "np", ".", "zeros", "(", "self", ".", "num_envs", ")", "\n", "if", "self", ".", "training", ":", "\n", "            ", "self", ".", "_update_reward", "(", "self", ".", "ret", ")", "\n", "", "return", "self", ".", "normalize_obs", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load": [[162, 175], ["pickle.load.set_venv", "open", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.set_venv", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load"], ["", "@", "staticmethod", "\n", "def", "load", "(", "load_path", ",", "venv", ")", ":", "\n", "        ", "\"\"\"\n        Loads a saved VecNormalize object.\n\n        :param load_path: the path to load from.\n        :param venv: the VecEnv to wrap.\n        :return: (VecNormalize)\n        \"\"\"", "\n", "with", "open", "(", "load_path", ",", "\"rb\"", ")", "as", "file_handler", ":", "\n", "            ", "vec_normalize", "=", "pickle", ".", "load", "(", "file_handler", ")", "\n", "", "vec_normalize", ".", "set_venv", "(", "venv", ")", "\n", "return", "vec_normalize", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save": [[176, 179], ["open", "pickle.dump"], "methods", ["None"], ["", "def", "save", "(", "self", ",", "save_path", ")", ":", "\n", "        ", "with", "open", "(", "save_path", ",", "\"wb\"", ")", "as", "file_handler", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ",", "file_handler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save_running_average": [[180, 187], ["zip", "open", "pickle.dump"], "methods", ["None"], ["", "", "def", "save_running_average", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"\n        :param path: (str) path to log dir\n        \"\"\"", "\n", "for", "rms", ",", "name", "in", "zip", "(", "[", "self", ".", "obs_rms", ",", "self", ".", "ret_rms", "]", ",", "[", "'obs_rms'", ",", "'ret_rms'", "]", ")", ":", "\n", "            ", "with", "open", "(", "f\"{path}/{name}.pkl\"", ",", "'wb'", ")", "as", "file_handler", ":", "\n", "                ", "pickle", ".", "dump", "(", "rms", ",", "file_handler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load_running_average": [[188, 195], ["open", "setattr", "pickle.load"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load"], ["", "", "", "def", "load_running_average", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"\n        :param path: (str) path to log dir\n        \"\"\"", "\n", "for", "name", "in", "[", "'obs_rms'", ",", "'ret_rms'", "]", ":", "\n", "            ", "with", "open", "(", "f\"{path}/{name}.pkl\"", ",", "'rb'", ")", "as", "file_handler", ":", "\n", "                ", "setattr", "(", "self", ",", "name", ",", "pickle", ".", "load", "(", "file_handler", ")", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.__init__.unwrap_vec_normalize": [[16, 27], ["isinstance", "isinstance"], "function", ["None"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.__init__.sync_envs_normalization": [[30, 44], ["isinstance", "isinstance", "copy.deepcopy", "copy.deepcopy"], "function", ["None"], []], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.util.copy_obs_dict": [[11, 20], ["isinstance", "collections.OrderedDict", "type", "numpy.copy", "obs.items"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy"], ["from", "gym_idsgame", ".", "config", ".", "client_config", "import", "ClientConfig", "\n", "\n", "def", "create_artefact_dirs", "(", "output_dir", ":", "str", ",", "random_seed", ":", "int", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Creates artefact directories if they do not already exist\n\n    :param output_dir: the base directory\n    :param random_seed: the random seed of the experiment\n    :return: None\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.util.dict_to_obs": [[22, 42], ["isinstance", "isinstance", "tuple", "len", "len", "set", "obs_dict.keys", "range", "len"], "function", ["None"], ["        ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/results/logs/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/results/plots/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "\"/results/data/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/results/data/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "\"/results/hyperparameters/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/results/hyperparameters/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "\"/results/gifs/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/results/gifs/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "\"/results/tensorboard/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", "+", "\"/results/tensorboard/\"", "+", "str", "(", "random_seed", ")", "+", "\"/\"", ")", "\n", "\n", "\n", "", "", "def", "setup_logger", "(", "name", ":", "str", ",", "logdir", ":", "str", ",", "time_str", "=", "None", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.util.obs_space_info": [[44, 74], ["isinstance", "subspaces.items", "isinstance", "isinstance", "keys.append", "hasattr", "enumerate", "type"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type"], ["# create formatter", "\n", "formatter", "=", "logging", ".", "Formatter", "(", "'%(asctime)s,%(message)s'", ")", "\n", "# log to console", "\n", "ch", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "ch", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "ch", ".", "setFormatter", "(", "formatter", ")", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "name", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "# log to file", "\n", "if", "time_str", "is", "None", ":", "\n", "        ", "time_str", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "", "fh", "=", "logging", ".", "FileHandler", "(", "logdir", "+", "\"/\"", "+", "time_str", "+", "\"_\"", "+", "name", "+", "\".log\"", ",", "mode", "=", "\"w\"", ")", "\n", "fh", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "fh", ".", "setFormatter", "(", "formatter", ")", "\n", "\n", "# add the handlers to the logger", "\n", "logger", ".", "addHandler", "(", "fh", ")", "\n", "#logger.addHandler(ch)", "\n", "return", "logger", "\n", "\n", "", "def", "write_config_file", "(", "config", ":", "ClientConfig", ",", "path", ":", "str", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Writes a config object to a config file\n\n    :param config: the config to write\n    :param path: the path to write the file\n    :return: None\n    \"\"\"", "\n", "json_str", "=", "json", ".", "dumps", "(", "json", ".", "loads", "(", "jsonpickle", ".", "encode", "(", "config", ")", ")", ",", "indent", "=", "4", ",", "sort_keys", "=", "True", ")", "\n", "with", "io", ".", "open", "(", "path", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.q_learning.q_agent.QAgent.__init__": [[19, 49], ["gym_idsgame.agents.dao.experiment_result.ExperimentResult", "gym_idsgame.agents.dao.experiment_result.ExperimentResult", "tqdm.tqdm", "random.seed", "numpy.random.seed", "torch.manual_seed", "logging.getLogger"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.seed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.seed"], ["def", "__init__", "(", "self", ",", "env", ":", "IdsGameEnv", ",", "config", ":", "QAgentConfig", ")", ":", "\n", "        ", "\"\"\"\n        Initialize environment and hyperparameters\n\n        :param config: the configuration\n        \"\"\"", "\n", "self", ".", "env", "=", "env", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "train_result", "=", "ExperimentResult", "(", ")", "\n", "self", ".", "eval_result", "=", "ExperimentResult", "(", ")", "\n", "self", ".", "num_eval_games_total", "=", "0", "\n", "self", ".", "num_eval_hacks_total", "=", "0", "\n", "self", ".", "num_eval_games", "=", "0", "\n", "self", ".", "num_eval_hacks", "=", "0", "\n", "self", ".", "num_train_games", "=", "0", "\n", "self", ".", "num_train_hacks", "=", "0", "\n", "self", ".", "num_train_games_total", "=", "0", "\n", "self", ".", "num_train_hacks_total", "=", "0", "\n", "self", ".", "train_hack_probability", "=", "0.0", "\n", "self", ".", "train_cumulative_hack_probability", "=", "0.0", "\n", "self", ".", "eval_hack_probability", "=", "0.0", "\n", "self", ".", "eval_cumulative_hack_probability", "=", "0.0", "\n", "self", ".", "eval_attacker_cumulative_reward", "=", "0", "\n", "self", ".", "eval_defender_cumulative_reward", "=", "0", "\n", "self", ".", "outer_train", "=", "tqdm", ".", "tqdm", "(", "total", "=", "self", ".", "config", ".", "num_episodes", ",", "desc", "=", "'Train Episode'", ",", "position", "=", "0", ")", "\n", "if", "self", ".", "config", ".", "logger", "is", "None", ":", "\n", "            ", "self", ".", "config", ".", "logger", "=", "logging", ".", "getLogger", "(", "'QAgent'", ")", "\n", "", "random", ".", "seed", "(", "self", ".", "config", ".", "random_seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "self", ".", "config", ".", "random_seed", ")", "\n", "torch", ".", "manual_seed", "(", "self", ".", "config", ".", "random_seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.q_learning.q_agent.QAgent.log_metrics": [[50, 127], ["numpy.mean", "numpy.mean", "numpy.mean", "q_agent.QAgent.config.logger.info", "numpy.mean", "numpy.mean", "hasattr", "q_agent.QAgent.buffer.size", "q_agent.QAgent.outer_eval.set_description_str", "q_agent.QAgent.outer_train.set_description_str", "q_agent.QAgent.log_tensorboard", "result.avg_episode_steps.append", "result.avg_attacker_episode_rewards.append", "result.avg_defender_episode_rewards.append", "result.epsilon_values.append", "result.hack_probability.append", "result.cumulative_hack_probabiltiy.append", "result.attacker_cumulative_reward.append", "result.defender_cumulative_reward.append", "result.avg_episode_loss_attacker.append", "result.avg_episode_loss_defender.append", "result.lr_list.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.size", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_tensorboard"], ["", "def", "log_metrics", "(", "self", ",", "episode", ":", "int", ",", "result", ":", "ExperimentResult", ",", "attacker_episode_rewards", ":", "list", ",", "\n", "defender_episode_rewards", ":", "list", ",", "\n", "episode_steps", ":", "list", ",", "episode_avg_attacker_loss", ":", "list", "=", "None", ",", "\n", "episode_avg_defender_loss", ":", "list", "=", "None", ",", "\n", "eval", ":", "bool", "=", "False", ",", "\n", "update_stats", ":", "bool", "=", "True", ",", "lr", ":", "float", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Logs average metrics for the last <self.config.log_frequency> episodes\n\n        :param episode: the episode\n        :param result: the result object to add the results to\n        :param attacker_episode_rewards: list of attacker episode rewards for the last <self.config.log_frequency> episodes\n        :param defender_episode_rewards: list of defender episode rewards for the last <self.config.log_frequency> episodes\n        :param episode_steps: list of episode steps for the last <self.config.log_frequency> episodes\n        :param episode_avg_attacker_loss: list of episode attacker loss for the last <self.config.log_frequency> episodes\n        :param episode_avg_defender_loss: list of episode defedner loss for the last <self.config.log_frequency> episodes\n        :param eval: boolean flag whether the metrics are logged in an evaluation context.\n        :param update_stats: boolean flag whether to update stats\n        :param lr: the learning rate\n        :return: None\n        \"\"\"", "\n", "avg_attacker_episode_rewards", "=", "np", ".", "mean", "(", "attacker_episode_rewards", ")", "\n", "avg_defender_episode_rewards", "=", "np", ".", "mean", "(", "defender_episode_rewards", ")", "\n", "if", "lr", "is", "None", ":", "\n", "            ", "lr", "=", "0.0", "\n", "", "if", "not", "eval", "and", "episode_avg_attacker_loss", "is", "not", "None", ":", "\n", "            ", "avg_episode_attacker_loss", "=", "np", ".", "mean", "(", "episode_avg_attacker_loss", ")", "\n", "", "else", ":", "\n", "            ", "avg_episode_attacker_loss", "=", "0.0", "\n", "", "if", "not", "eval", "and", "episode_avg_defender_loss", "is", "not", "None", ":", "\n", "            ", "avg_episode_defender_loss", "=", "np", ".", "mean", "(", "episode_avg_defender_loss", ")", "\n", "", "else", ":", "\n", "            ", "avg_episode_defender_loss", "=", "0.0", "\n", "\n", "", "if", "hasattr", "(", "self", ",", "\"buffer\"", ")", "and", "self", ".", "buffer", "is", "not", "None", ":", "\n", "            ", "replay_memory_size", "=", "self", ".", "buffer", ".", "size", "(", ")", "\n", "", "else", ":", "\n", "            ", "replay_memory_size", "=", "-", "1", "\n", "", "avg_episode_steps", "=", "np", ".", "mean", "(", "episode_steps", ")", "\n", "hack_probability", "=", "self", ".", "train_hack_probability", "if", "not", "eval", "else", "self", ".", "eval_hack_probability", "\n", "hack_probability_total", "=", "self", ".", "train_cumulative_hack_probability", "if", "not", "eval", "else", "self", ".", "eval_cumulative_hack_probability", "\n", "attacker_cumulative_reward", "=", "self", ".", "env", ".", "state", ".", "attacker_cumulative_reward", "if", "not", "eval", "else", "self", ".", "eval_attacker_cumulative_reward", "\n", "defender_cumulative_reward", "=", "self", ".", "env", ".", "state", ".", "defender_cumulative_reward", "if", "not", "eval", "else", "self", ".", "eval_defender_cumulative_reward", "\n", "if", "eval", ":", "\n", "            ", "log_str", "=", "\"[Eval] episode:{},avg_a_R:{:.2f},avg_d_R:{:.2f},avg_t:{:.2f},avg_h:{:.2f},acc_A_R:{:.2f},\"", "\"acc_D_R:{:.2f},replay_s:{},lr:{:.2E},c_h:{:.2f}\"", ".", "format", "(", "\n", "episode", ",", "avg_attacker_episode_rewards", ",", "avg_defender_episode_rewards", ",", "avg_episode_steps", ",", "hack_probability", ",", "\n", "attacker_cumulative_reward", ",", "defender_cumulative_reward", ",", "replay_memory_size", ",", "lr", ",", "\n", "hack_probability_total", ")", "\n", "self", ".", "outer_eval", ".", "set_description_str", "(", "log_str", ")", "\n", "", "else", ":", "\n", "            ", "log_str", "=", "\"[Train] episode: {:.2f} epsilon:{:.2f},avg_a_R:{:.2f},avg_d_R:{:.2f},avg_t:{:.2f},avg_h:{:.2f},acc_A_R:{:.2f},\"", "\"acc_D_R:{:.2f},A_loss:{:.6f},D_loss:{:.6f},replay_s:{},lr:{:.2E},c_h:{:.2f}\"", ".", "format", "(", "\n", "episode", ",", "self", ".", "config", ".", "epsilon", ",", "avg_attacker_episode_rewards", ",", "avg_defender_episode_rewards", ",", "\n", "avg_episode_steps", ",", "hack_probability", ",", "attacker_cumulative_reward", ",", "defender_cumulative_reward", ",", "\n", "avg_episode_attacker_loss", ",", "avg_episode_defender_loss", ",", "replay_memory_size", ",", "lr", ",", "hack_probability_total", ")", "\n", "self", ".", "outer_train", ".", "set_description_str", "(", "log_str", ")", "\n", "", "self", ".", "config", ".", "logger", ".", "info", "(", "log_str", ")", "\n", "if", "update_stats", "and", "self", ".", "config", ".", "dqn_config", "is", "not", "None", "and", "self", ".", "config", ".", "dqn_config", ".", "tensorboard", ":", "\n", "            ", "self", ".", "log_tensorboard", "(", "episode", ",", "avg_attacker_episode_rewards", ",", "avg_defender_episode_rewards", ",", "avg_episode_steps", ",", "\n", "avg_episode_attacker_loss", ",", "avg_episode_defender_loss", ",", "hack_probability", ",", "\n", "attacker_cumulative_reward", ",", "defender_cumulative_reward", ",", "self", ".", "config", ".", "epsilon", ",", "lr", ",", "\n", "hack_probability_total", ",", "eval", "=", "eval", ")", "\n", "", "if", "update_stats", ":", "\n", "            ", "result", ".", "avg_episode_steps", ".", "append", "(", "avg_episode_steps", ")", "\n", "result", ".", "avg_attacker_episode_rewards", ".", "append", "(", "avg_attacker_episode_rewards", ")", "\n", "result", ".", "avg_defender_episode_rewards", ".", "append", "(", "avg_defender_episode_rewards", ")", "\n", "result", ".", "epsilon_values", ".", "append", "(", "self", ".", "config", ".", "epsilon", ")", "\n", "result", ".", "hack_probability", ".", "append", "(", "hack_probability", ")", "\n", "result", ".", "cumulative_hack_probabiltiy", ".", "append", "(", "hack_probability_total", ")", "\n", "result", ".", "attacker_cumulative_reward", ".", "append", "(", "attacker_cumulative_reward", ")", "\n", "result", ".", "defender_cumulative_reward", ".", "append", "(", "defender_cumulative_reward", ")", "\n", "result", ".", "avg_episode_loss_attacker", ".", "append", "(", "avg_episode_attacker_loss", ")", "\n", "result", ".", "avg_episode_loss_defender", ".", "append", "(", "avg_episode_defender_loss", ")", "\n", "result", ".", "lr_list", ".", "append", "(", "lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.q_learning.q_agent.QAgent.log_tensorboard": [[128, 170], ["q_agent.QAgent.tensorboard_writer.add_scalar", "q_agent.QAgent.tensorboard_writer.add_scalar", "q_agent.QAgent.tensorboard_writer.add_scalar", "q_agent.QAgent.tensorboard_writer.add_scalar", "q_agent.QAgent.tensorboard_writer.add_scalar", "q_agent.QAgent.tensorboard_writer.add_scalar", "q_agent.QAgent.tensorboard_writer.add_scalar", "q_agent.QAgent.tensorboard_writer.add_scalar", "q_agent.QAgent.tensorboard_writer.add_scalar", "q_agent.QAgent.tensorboard_writer.add_scalar", "q_agent.QAgent.tensorboard_writer.add_scalar"], "methods", ["None"], ["", "", "def", "log_tensorboard", "(", "self", ",", "episode", ":", "int", ",", "avg_attacker_episode_rewards", ":", "float", ",", "avg_defender_episode_rewards", ":", "float", ",", "\n", "avg_episode_steps", ":", "float", ",", "episode_avg_loss_attacker", ":", "float", ",", "episode_avg_loss_defender", ":", "float", ",", "\n", "hack_probability", ":", "float", ",", "attacker_cumulative_reward", ":", "int", ",", "defender_cumulative_reward", ":", "int", ",", "\n", "epsilon", ":", "float", ",", "lr", ":", "float", ",", "cumulative_hack_probability", ":", "float", ",", "eval", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Log metrics to tensorboard\n\n        :param episode: the episode\n        :param avg_attacker_episode_rewards: the average attacker episode reward\n        :param avg_defender_episode_rewards: the average defender episode reward\n        :param avg_episode_steps: the average number of episode steps\n        :param episode_avg_loss_attacker: the average episode loss of the attacker\n        :param episode_avg_loss_defender: the average episode loss of the defender\n        :param hack_probability: the hack probability\n        :param attacker_cumulative_reward: the cumulative attacker reward\n        :param defender_cumulative_reward: the cumulative defender reward\n        :param epsilon: the exploration rate\n        :param lr: the learning rate\n        :param cumulative_hack_probability: the cumulative hack probability\n        :param eval: boolean flag whether eval or not\n        :return: None\n        \"\"\"", "\n", "train_or_eval", "=", "\"eval\"", "if", "eval", "else", "\"train\"", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'avg_episode_rewards/'", "+", "train_or_eval", "+", "\"/attacker\"", ",", "\n", "avg_attacker_episode_rewards", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'avg_episode_rewards/'", "+", "train_or_eval", "+", "\"/defender\"", ",", "\n", "avg_defender_episode_rewards", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'episode_steps/'", "+", "train_or_eval", ",", "avg_episode_steps", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'episode_avg_loss/'", "+", "train_or_eval", "+", "\"/attacker\"", ",", "episode_avg_loss_attacker", ",", "\n", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'episode_avg_loss/'", "+", "train_or_eval", "+", "\"/defender\"", ",", "episode_avg_loss_defender", ",", "\n", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'hack_probability/'", "+", "train_or_eval", ",", "hack_probability", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'cumulative_hack_probability/'", "+", "train_or_eval", ",", "cumulative_hack_probability", ",", "\n", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'cumulative_reward/attacker/'", "+", "train_or_eval", ",", "\n", "attacker_cumulative_reward", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'cumulative_reward/defender/'", "+", "train_or_eval", ",", "\n", "defender_cumulative_reward", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'epsilon'", ",", "epsilon", ",", "episode", ")", "\n", "if", "not", "eval", ":", "\n", "            ", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'lr'", ",", "lr", ",", "episode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.q_learning.q_agent.QAgent.anneal_epsilon": [[171, 179], ["None"], "methods", ["None"], ["", "", "def", "anneal_epsilon", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Anneals the exploration rate slightly until it reaches the minimum value\n\n        :return: None\n        \"\"\"", "\n", "if", "self", ".", "config", ".", "epsilon", ">", "self", ".", "config", ".", "min_epsilon", ":", "\n", "            ", "self", ".", "config", ".", "epsilon", "=", "self", ".", "config", ".", "epsilon", "*", "self", ".", "config", ".", "epsilon_decay", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.q_learning.q_agent.QAgent.get_action": [[180, 183], ["None"], "methods", ["None"], ["", "", "@", "abstractmethod", "\n", "def", "get_action", "(", "self", ",", "s", ",", "eval", "=", "False", ",", "attacker", "=", "True", ")", "->", "int", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.q_learning.q_agent.QAgent.train": [[184, 187], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "train", "(", "self", ")", "->", "ExperimentResult", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.q_learning.q_agent.QAgent.eval": [[188, 191], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "eval", "(", "self", ",", "log", "=", "True", ")", "->", "ExperimentResult", ":", "\n", "        ", "pass", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.q_learning.q_agent_config.QAgentConfig.__init__": [[12, 88], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "gamma", ":", "float", "=", "0.8", ",", "alpha", ":", "float", "=", "0.1", ",", "epsilon", ":", "float", "=", "0.9", ",", "render", ":", "bool", "=", "False", ",", "\n", "eval_sleep", ":", "float", "=", "0.35", ",", "\n", "epsilon_decay", ":", "float", "=", "0.999", ",", "min_epsilon", ":", "float", "=", "0.1", ",", "eval_episodes", ":", "int", "=", "1", ",", "\n", "train_log_frequency", ":", "int", "=", "100", ",", "\n", "eval_log_frequency", ":", "int", "=", "1", ",", "video", ":", "bool", "=", "False", ",", "video_fps", ":", "int", "=", "5", ",", "video_dir", ":", "bool", "=", "None", ",", "\n", "num_episodes", ":", "int", "=", "5000", ",", "\n", "eval_render", ":", "bool", "=", "False", ",", "gifs", ":", "bool", "=", "False", ",", "gif_dir", ":", "str", "=", "None", ",", "eval_frequency", ":", "int", "=", "1000", ",", "\n", "video_frequency", ":", "int", "=", "101", ",", "attacker", ":", "bool", "=", "True", ",", "defender", ":", "bool", "=", "False", ",", "\n", "save_dir", ":", "str", "=", "None", ",", "attacker_load_path", ":", "str", "=", "None", ",", "defender_load_path", ":", "str", "=", "None", ",", "\n", "dqn_config", ":", "DQNConfig", "=", "None", ",", "\n", "checkpoint_freq", ":", "int", "=", "100000", ",", "random_seed", ":", "int", "=", "0", ",", "eval_epsilon", ":", "float", "=", "0.0", ",", "\n", "tab_full_state_space", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Initialize environment and hyperparameters\n\n        :param gamma: the discount factor\n        :param alpha: the learning rate\n        :param epsilon: the exploration rate\n        :param render: whether to render the environment *during training*\n        :param eval_sleep: amount of sleep between time-steps during evaluation and rendering\n        :param epsilon_decay: rate of decay of epsilon\n        :param min_epsilon: minimum epsilon rate\n        :param eval_episodes: number of evaluation episodes\n        :param train_log_frequency: number of episodes between logs during train\n        :param eval_log_frequency: number of episodes between logs during eval\n        :param video: boolean flag whether to record video of the evaluation.\n        :param video_dir: path where to save videos (will overwrite)\n        :param gif_dir: path where to save gifs (will overwrite)\n        :param num_episodes: number of training epochs\n        :param eval_render: whether to render the game during evaluation or not\n                            (perhaps set to False if video is recorded instead)\n        :param gifs: boolean flag whether to save gifs during evaluation or not\n        :param eval_frequency: the frequency (episodes) when running evaluation\n        :param video_frequency: the frequency (eval episodes) to record video and gif\n        :param attacker: True if the QAgent is an attacker\n        :param attacker: True if the QAgent is a defender\n        :param save_dir: dir to save Q-table\n        :param attacker_load_path: path to load a saved Q-table of the attacker\n        :param defender_load_path: path to load a saved Q-table of the defender\n        :param dqn_config: configuration for DQN\n        :param checkpoint_freq: frequency of checkpointing the model (episodes)\n        :param random_seed: the random seed for reproducibility\n        :param eval_epsilon: evaluation epsilon for implementing a \"soft policy\" rather than a \"greedy policy\"\n        :param tab_full_state_space: a boolean flag indicating whether the tabular q learning approach use full\n                                     state space or not\n        \"\"\"", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "render", "=", "render", "\n", "self", ".", "eval_sleep", "=", "eval_sleep", "\n", "self", ".", "epsilon_decay", "=", "epsilon_decay", "\n", "self", ".", "min_epsilon", "=", "min_epsilon", "\n", "self", ".", "eval_episodes", "=", "eval_episodes", "\n", "self", ".", "train_log_frequency", "=", "train_log_frequency", "\n", "self", ".", "eval_log_frequency", "=", "eval_log_frequency", "\n", "self", ".", "video", "=", "video", "\n", "self", ".", "video_fps", "=", "video_fps", "\n", "self", ".", "video_dir", "=", "video_dir", "\n", "self", ".", "num_episodes", "=", "num_episodes", "\n", "self", ".", "eval_render", "=", "eval_render", "\n", "self", ".", "gifs", "=", "gifs", "\n", "self", ".", "gif_dir", "=", "gif_dir", "\n", "self", ".", "eval_frequency", "=", "eval_frequency", "\n", "self", ".", "logger", "=", "None", "\n", "self", ".", "video_frequency", "=", "video_frequency", "\n", "self", ".", "attacker", "=", "attacker", "\n", "self", ".", "defender", "=", "defender", "\n", "self", ".", "save_dir", "=", "save_dir", "\n", "self", ".", "attacker_load_path", "=", "attacker_load_path", "\n", "self", ".", "defender_load_path", "=", "defender_load_path", "\n", "self", ".", "dqn_config", "=", "dqn_config", "\n", "self", ".", "checkpoint_freq", "=", "checkpoint_freq", "\n", "self", ".", "random_seed", "=", "random_seed", "\n", "self", ".", "eval_epsilon", "=", "eval_epsilon", "\n", "self", ".", "tab_full_state_space", "=", "tab_full_state_space", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.q_learning.q_agent_config.QAgentConfig.to_str": [[89, 104], ["None"], "methods", ["None"], ["", "def", "to_str", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        :return: a string with information about all of the parameters\n        \"\"\"", "\n", "return", "\"Hyperparameters: gamma:{0},alpha:{1},epsilon:{2},render:{3},eval_sleep:{4},\"", "\"epsilon_decay:{5},min_epsilon:{6},eval_episodes:{7},train_log_frequency:{8},\"", "\"eval_log_frequency:{9},video:{10},video_fps:{11},\"", "\"video_dir:{12},num_episodes:{13},eval_render:{14},gifs:{15},\"", "\"gifdir:{16},eval_frequency:{17},video_frequency:{18},attacker{19},defender:{20},\"", "\"checkpoint_freq:{21},random_seed:{22},eval_epsilon:{23},tab_full_state_space:{24}\"", ".", "format", "(", "\n", "self", ".", "gamma", ",", "self", ".", "alpha", ",", "self", ".", "epsilon", ",", "self", ".", "render", ",", "self", ".", "eval_sleep", ",", "self", ".", "epsilon_decay", ",", "\n", "self", ".", "min_epsilon", ",", "self", ".", "eval_episodes", ",", "self", ".", "train_log_frequency", ",", "self", ".", "eval_log_frequency", ",", "self", ".", "video", ",", "\n", "self", ".", "video_fps", ",", "self", ".", "video_dir", ",", "self", ".", "num_episodes", ",", "self", ".", "eval_render", ",", "self", ".", "gifs", ",", "self", ".", "gif_dir", ",", "\n", "self", ".", "eval_frequency", ",", "self", ".", "video_frequency", ",", "self", ".", "attacker", ",", "self", ".", "defender", ",", "self", ".", "checkpoint_freq", ",", "\n", "self", ".", "random_seed", ",", "self", ".", "eval_epsilon", ",", "self", ".", "tab_full_state_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.q_learning.q_agent_config.QAgentConfig.to_csv": [[105, 157], ["open", "csv.writer", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "def", "to_csv", "(", "self", ",", "file_path", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Write parameters to csv file\n\n        :param file_path: path to the file\n        :return: None\n        \"\"\"", "\n", "with", "open", "(", "file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"parameter\"", ",", "\"value\"", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"gamma\"", ",", "str", "(", "self", ".", "gamma", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"alpha\"", ",", "str", "(", "self", ".", "alpha", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"epsilon\"", ",", "str", "(", "self", ".", "epsilon", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"render\"", ",", "str", "(", "self", ".", "render", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eval_sleep\"", ",", "str", "(", "self", ".", "eval_sleep", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"epsilon_decay\"", ",", "str", "(", "self", ".", "epsilon_decay", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"min_epsilon\"", ",", "str", "(", "self", ".", "min_epsilon", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eval_episodes\"", ",", "str", "(", "self", ".", "eval_episodes", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"train_log_frequency\"", ",", "str", "(", "self", ".", "train_log_frequency", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eval_log_frequency\"", ",", "str", "(", "self", ".", "eval_log_frequency", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"video\"", ",", "str", "(", "self", ".", "video", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"video_fps\"", ",", "str", "(", "self", ".", "video_fps", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"video_dir\"", ",", "str", "(", "self", ".", "video_dir", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"num_episodes\"", ",", "str", "(", "self", ".", "num_episodes", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eval_render\"", ",", "str", "(", "self", ".", "eval_render", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"gifs\"", ",", "str", "(", "self", ".", "gifs", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"gifdir\"", ",", "str", "(", "self", ".", "gif_dir", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eval_frequency\"", ",", "str", "(", "self", ".", "eval_frequency", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"video_frequency\"", ",", "str", "(", "self", ".", "video_frequency", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"attacker\"", ",", "str", "(", "self", ".", "attacker", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"defender\"", ",", "str", "(", "self", ".", "defender", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"checkpoint_freq\"", ",", "str", "(", "self", ".", "checkpoint_freq", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"random_seed\"", ",", "str", "(", "self", ".", "random_seed", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eval_epsilon\"", ",", "str", "(", "self", ".", "eval_epsilon", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"tab_full_state_space\"", ",", "str", "(", "self", ".", "tab_full_state_space", ")", "]", ")", "\n", "if", "self", ".", "dqn_config", "is", "not", "None", ":", "\n", "                ", "writer", ".", "writerow", "(", "[", "\"input_dim\"", ",", "str", "(", "self", ".", "dqn_config", ".", "input_dim", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"output_dim\"", ",", "str", "(", "self", ".", "dqn_config", ".", "attacker_output_dim", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hidden_dim\"", ",", "str", "(", "self", ".", "dqn_config", ".", "hidden_dim", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"replay_memory_size\"", ",", "str", "(", "self", ".", "dqn_config", ".", "replay_memory_size", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"replay_start_size\"", ",", "str", "(", "self", ".", "dqn_config", ".", "replay_start_size", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"batch_size\"", ",", "str", "(", "self", ".", "dqn_config", ".", "batch_size", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"target_network_update_freq\"", ",", "str", "(", "self", ".", "dqn_config", ".", "target_network_update_freq", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"gpu\"", ",", "str", "(", "self", ".", "dqn_config", ".", "gpu", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"tensorboard\"", ",", "str", "(", "self", ".", "dqn_config", ".", "tensorboard", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"tensorboard_dir\"", ",", "str", "(", "self", ".", "dqn_config", ".", "tensorboard_dir", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"loss_fn\"", ",", "str", "(", "self", ".", "dqn_config", ".", "loss_fn", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"optimizer\"", ",", "str", "(", "self", ".", "dqn_config", ".", "optimizer", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"num_hidden_layers\"", ",", "str", "(", "self", ".", "dqn_config", ".", "num_hidden_layers", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"lr_exp_decay\"", ",", "str", "(", "self", ".", "dqn_config", ".", "lr_exp_decay", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"lr_decay_rate\"", ",", "str", "(", "self", ".", "dqn_config", ".", "lr_decay_rate", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hidden_activation\"", ",", "str", "(", "self", ".", "dqn_config", ".", "hidden_activation", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.q_learning.q_agent_config.QAgentConfig.hparams_dict": [[158, 192], ["None"], "methods", ["None"], ["", "", "", "def", "hparams_dict", "(", "self", ")", ":", "\n", "        ", "hparams", "=", "{", "}", "\n", "hparams", "[", "\"gamma\"", "]", "=", "self", ".", "gamma", "\n", "hparams", "[", "\"alpha\"", "]", "=", "self", ".", "alpha", "\n", "hparams", "[", "\"epsilon\"", "]", "=", "self", ".", "epsilon", "\n", "hparams", "[", "\"epsilon_decay\"", "]", "=", "self", ".", "epsilon_decay", "\n", "hparams", "[", "\"min_epsilon\"", "]", "=", "self", ".", "min_epsilon", "\n", "hparams", "[", "\"eval_episodes\"", "]", "=", "self", ".", "eval_episodes", "\n", "hparams", "[", "\"train_log_frequency\"", "]", "=", "self", ".", "train_log_frequency", "\n", "hparams", "[", "\"eval_log_frequency\"", "]", "=", "self", ".", "eval_log_frequency", "\n", "hparams", "[", "\"num_episodes\"", "]", "=", "self", ".", "num_episodes", "\n", "hparams", "[", "\"eval_frequency\"", "]", "=", "self", ".", "eval_frequency", "\n", "hparams", "[", "\"attacker\"", "]", "=", "self", ".", "attacker", "\n", "hparams", "[", "\"defender\"", "]", "=", "self", ".", "defender", "\n", "hparams", "[", "\"checkpoint_freq\"", "]", "=", "self", ".", "checkpoint_freq", "\n", "hparams", "[", "\"random_seed\"", "]", "=", "self", ".", "random_seed", "\n", "hparams", "[", "\"eval_epsilon\"", "]", "=", "self", ".", "eval_epsilon", "\n", "hparams", "[", "\"tab_full_state_space\"", "]", "=", "self", ".", "tab_full_state_space", "\n", "if", "self", ".", "dqn_config", "is", "not", "None", ":", "\n", "            ", "hparams", "[", "\"input_dim\"", "]", "=", "self", ".", "dqn_config", ".", "input_dim", "\n", "hparams", "[", "\"output_dim\"", "]", "=", "self", ".", "dqn_config", ".", "attacker_output_dim", "\n", "hparams", "[", "\"hidden_dim\"", "]", "=", "self", ".", "dqn_config", ".", "hidden_dim", "\n", "hparams", "[", "\"replay_memory_size\"", "]", "=", "self", ".", "dqn_config", ".", "replay_memory_size", "\n", "hparams", "[", "\"replay_start_size\"", "]", "=", "self", ".", "dqn_config", ".", "replay_start_size", "\n", "hparams", "[", "\"batch_size\"", "]", "=", "self", ".", "dqn_config", ".", "batch_size", "\n", "hparams", "[", "\"num_hidden_layers\"", "]", "=", "self", ".", "dqn_config", ".", "num_hidden_layers", "\n", "hparams", "[", "\"target_network_update_freq\"", "]", "=", "self", ".", "dqn_config", ".", "target_network_update_freq", "\n", "hparams", "[", "\"gpu\"", "]", "=", "self", ".", "dqn_config", ".", "gpu", "\n", "hparams", "[", "\"loss_fn\"", "]", "=", "self", ".", "dqn_config", ".", "loss_fn", "\n", "hparams", "[", "\"optimizer\"", "]", "=", "self", ".", "dqn_config", ".", "optimizer", "\n", "hparams", "[", "\"lr_exp_decay\"", "]", "=", "self", ".", "dqn_config", ".", "lr_exp_decay", "\n", "hparams", "[", "\"lr_decay_rate\"", "]", "=", "self", ".", "dqn_config", ".", "lr_decay_rate", "\n", "hparams", "[", "\"hidden_activation\"", "]", "=", "self", ".", "dqn_config", ".", "hidden_activation", "\n", "", "return", "hparams", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.__init__": [[12, 18], ["collections.deque", "ValueError"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "buffer_size", ":", "int", ")", ":", "\n", "        ", "if", "buffer_size", "<", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"The replay buffer size cannot be negative\"", ")", "\n", "", "self", ".", "BUFFER_SIZE", "=", "buffer_size", "\n", "self", ".", "count", "=", "0", "\n", "self", ".", "buffer", "=", "deque", "(", ")", "# efficient datastructure for pops and appends", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.add_tuple": [[19, 44], ["attacker_state_1.flatten", "defender_state_1.flatten", "attacker_state_2.flatten", "defender_state_2.flatten", "replay_buffer.ReplayBuffer.buffer.append", "replay_buffer.ReplayBuffer.buffer.popleft", "replay_buffer.ReplayBuffer.buffer.append"], "methods", ["None"], ["", "def", "add_tuple", "(", "self", ",", "state1", ":", "np", ".", "ndarray", ",", "action", ":", "int", ",", "reward", ":", "float", ",", "done", ":", "bool", ",", "state2", ":", "np", ".", "ndarray", ")", ":", "\n", "        ", "\"\"\"\n        Adds a tuple of experience to the replay buffer\n\n        :param state1: the starting state of the experience (4 84x84 images)\n        :param action: the action taken in state1 (int)\n        :param reward: the reward received with taking action in state1 and transitioning to state2 (float scalar)\n        :param done: a boolean flag that indicates whether state2 is a terminal state and the episode is over\n        :param state2: the state transitioned to when taking action in state1 (4 84x84 images)\n        :return: None\n        \"\"\"", "\n", "# # Clip all positive rewards at 1 and all negative rewards at -1, leaving 0 rewards unchanged", "\n", "# reward = np.clip(reward, -1, 1)", "\n", "attacker_state_1", ",", "defender_state_1", "=", "state1", "\n", "attacker_state_2", ",", "defender_state_2", "=", "state2", "\n", "attacker_reward", ",", "defender_reward", "=", "reward", "\n", "attacker_action", ",", "defender_action", "=", "action", "\n", "exp_tuple", "=", "(", "attacker_state_1", ".", "flatten", "(", ")", ",", "defender_state_1", ".", "flatten", "(", ")", ",", "attacker_action", ",", "defender_action", ",", "\n", "attacker_reward", ",", "defender_reward", ",", "done", ",", "attacker_state_2", ".", "flatten", "(", ")", ",", "defender_state_2", ".", "flatten", "(", ")", ")", "\n", "if", "self", ".", "count", "<", "self", ".", "BUFFER_SIZE", ":", "\n", "            ", "self", ".", "buffer", ".", "append", "(", "exp_tuple", ")", "\n", "self", ".", "count", "+=", "1", "\n", "", "else", ":", "\n", "            ", "self", ".", "buffer", ".", "popleft", "(", ")", "\n", "self", ".", "buffer", ".", "append", "(", "exp_tuple", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.size": [[45, 50], ["None"], "methods", ["None"], ["", "", "def", "size", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        :return: the size of the buffer\n        \"\"\"", "\n", "return", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.sample": [[51, 72], ["random.sample", "list", "ValueError", "map", "list", "zip"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.sample"], ["", "def", "sample", "(", "self", ",", "batch_size", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Samples a random batch from the replay  buffer\n\n        :param batch_size: the size of the batch\n        :return: Five arrays: s_batch, a_batch, r_batch, d_batch, s2_batch\n        \"\"\"", "\n", "if", "batch_size", "<", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot sample a batch of size less than 1\"", ")", "\n", "\n", "", "sample_size", "=", "self", ".", "count", "if", "self", ".", "count", "<", "batch_size", "else", "batch_size", "\n", "# Gives a list of [(state1, action, reward, done, state2)]", "\n", "batch", "=", "random", ".", "sample", "(", "self", ".", "buffer", ",", "sample_size", ")", "\n", "\n", "# 1. Unzips the list of tuples [(state1, action, reward, done, state2)] into 5 independent tuples", "\n", "# 2. Converts each tuple into numpy arrays", "\n", "s_attacker_batch", ",", "s_defender_batch", ",", "a_attacker_batch", ",", "a_defender_batch", ",", "r_attacker_batch", ",", "r_defender_batch", ",", "d_batch", ",", "s2_attacker_batch", ",", "s2_defender_batch", "=", "list", "(", "map", "(", "np", ".", "array", ",", "list", "(", "zip", "(", "*", "batch", ")", ")", ")", ")", "\n", "\n", "return", "s_attacker_batch", ",", "s_defender_batch", ",", "a_attacker_batch", ",", "a_defender_batch", ",", "r_attacker_batch", ",", "r_defender_batch", ",", "d_batch", ",", "s2_attacker_batch", ",", "s2_defender_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.clear": [[73, 81], ["replay_buffer.ReplayBuffer.buffer.clear"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.clear"], ["", "def", "clear", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Clears/resets the buffer\n\n        :return: None\n        \"\"\"", "\n", "self", ".", "buffer", ".", "clear", "(", ")", "\n", "self", ".", "count", "=", "0", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.lstm_w_softmax.LSTMwithSoftmax.__init__": [[14, 62], ["super().__init__", "torch.nn.ModuleList", "lstm_w_softmax.LSTMwithSoftmax.layers.append", "range", "lstm_w_softmax.LSTMwithSoftmax.layers.append", "lstm_w_softmax.LSTMwithSoftmax.layers.append", "torch.nn.LSTM", "lstm_w_softmax.LSTMwithSoftmax.layers.append", "torch.nn.Linear", "torch.nn.Softmax", "lstm_w_softmax.LSTMwithSoftmax.layers.append", "lstm_w_softmax.LSTMwithSoftmax.layers.append", "lstm_w_softmax.LSTMwithSoftmax.get_hidden_activation", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.get_hidden_activation"], ["def", "__init__", "(", "self", ",", "input_dim", ":", "int", ",", "output_dim", ":", "int", ",", "hidden_dim", ":", "int", ",", "num_lstm_layers", ":", "int", "=", "2", ",", "\n", "num_hidden_linear_layers", ":", "int", "=", "2", ",", "\n", "hidden_activation", ":", "str", "=", "\"ReLU\"", ",", "seq_length", ":", "int", "=", "4", ")", ":", "\n", "        ", "\"\"\"\n        Builds the model\n\n        :param input_dim: the input dimension\n        :param output_dim: the output dimension\n        :param hidden_dim: the hidden dimension\n        :param num_lstm_layers: the number of hidden layers\n        :param num_hidden_linear_layers: the number of linear layers\n        :param hidden_activation: hidden activation type\n        :param seq_length: length of the sequence\n        \"\"\"", "\n", "super", "(", "LSTMwithSoftmax", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "num_hidden_layers", "=", "num_lstm_layers", "\n", "self", ".", "num_lstm_layers", "=", "num_lstm_layers", "\n", "self", ".", "num_hidden_linear_layers", "=", "num_hidden_linear_layers", "\n", "self", ".", "num_layers", "=", "self", ".", "num_lstm_layers", "+", "self", ".", "num_hidden_linear_layers", "+", "1", "\n", "self", ".", "hidden_activation", "=", "hidden_activation", "\n", "\n", "# Define layers of FNN", "\n", "self", ".", "layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "# Input layer", "\n", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "LSTM", "(", "input_size", "=", "input_dim", ",", "hidden_size", "=", "hidden_dim", ",", "\n", "num_layers", "=", "num_lstm_layers", ",", "\n", "batch_first", "=", "True", ")", ")", "\n", "\n", "# self.layers.append(torch.nn.Linear(input_dim, hidden_dim))", "\n", "# self.layers.append(self.get_hidden_activation())", "\n", "\n", "# Hidden Layers", "\n", "for", "i", "in", "range", "(", "self", ".", "num_hidden_linear_layers", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "#self.layers.append(torch.nn.Linear(hidden_dim, hidden_dim))", "\n", "                ", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "hidden_dim", "*", "seq_length", ",", "hidden_dim", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", ")", "\n", "", "self", ".", "layers", ".", "append", "(", "self", ".", "get_hidden_activation", "(", ")", ")", "\n", "\n", "# Output layer", "\n", "", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "hidden_dim", ",", "self", ".", "output_dim", ")", ")", "\n", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Softmax", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.lstm_w_softmax.LSTMwithSoftmax.get_hidden_activation": [[63, 85], ["torch.nn.ReLU", "torch.nn.LeakyReLU", "torch.nn.LogSigmoid", "torch.nn.PReLU", "torch.nn.Sigmoid", "torch.nn.Softplus", "torch.nn.Tanh", "ValueError"], "methods", ["None"], ["", "def", "get_hidden_activation", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Interprets the hidden activation\n\n        :return: the hidden activation function\n        \"\"\"", "\n", "if", "self", ".", "hidden_activation", "==", "\"ReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"LeakyReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "LeakyReLU", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"LogSigmoid\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "LogSigmoid", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"PReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "PReLU", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"Sigmoid\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"Softplus\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Softplus", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"Tanh\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Tanh", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Activation type: {} not recognized\"", ".", "format", "(", "self", ".", "hidden_activation", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.lstm_w_softmax.LSTMwithSoftmax.forward": [[86, 101], ["torch.reshape", "range", "len"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Forward propagation\n\n        :param x: input tensor\n        :return: Output prediction\n        \"\"\"", "\n", "y", "=", "x", "\n", "hidden_vec", ",", "last_hidden", "=", "self", ".", "layers", "[", "0", "]", "(", "y", ")", "\n", "y", "=", "hidden_vec", "\n", "# flatten", "\n", "y", "=", "torch", ".", "reshape", "(", "y", ",", "(", "y", ".", "shape", "[", "0", "]", ",", "y", ".", "shape", "[", "1", "]", "*", "y", ".", "shape", "[", "2", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "self", ".", "layers", ")", ")", ":", "\n", "            ", "y", "=", "self", ".", "layers", "[", "i", "]", "(", "y", ")", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.lstm_w_softmax.test": [[103, 140], ["lstm_w_softmax.LSTMwithSoftmax", "torch.randn", "torch.empty().random_", "torch.nn.CrossEntropyLoss", "torch.optim.SGD", "range", "LSTMwithSoftmax.parameters", "LSTMwithSoftmax.", "print", "torch.nn.CrossEntropyLoss.", "torch.optim.SGD.zero_grad", "criterion.backward", "torch.optim.SGD.step", "torch.empty", "torch.empty().random_.squeeze", "print", "criterion.item"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step"], ["", "", "def", "test", "(", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    A basic test-case to verify that the model can fit some randomly generated data\n\n    :return: None\n    \"\"\"", "\n", "# Constants", "\n", "batch_size", "=", "64", "\n", "input_dim", "=", "44", "\n", "output_dim", "=", "44", "\n", "hidden_dim", "=", "64", "\n", "\n", "# Create model", "\n", "model", "=", "LSTMwithSoftmax", "(", "input_dim", ",", "output_dim", ",", "hidden_dim", ",", "num_lstm_layers", "=", "2", ")", "\n", "\n", "# Create random Tensors to hold inputs and outputs", "\n", "x", "=", "torch", ".", "randn", "(", "batch_size", ",", "4", ",", "input_dim", ")", "\n", "y", "=", "torch", ".", "empty", "(", "batch_size", ",", "dtype", "=", "torch", ".", "long", ")", ".", "random_", "(", "output_dim", ")", "\n", "\n", "# Construct our loss function and an Optimizer. The call to model.parameters()", "\n", "# in the SGD constructor will contain the learnable parameters of the layers in the model", "\n", "criterion", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'sum'", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "1e-4", ")", "\n", "for", "t", "in", "range", "(", "20000", ")", ":", "\n", "# Forward pass: Compute predicted y by passing x to the model", "\n", "        ", "y_pred", "=", "model", "(", "x", ")", "\n", "\n", "# Compute and print loss", "\n", "print", "(", "\"y_pred shape:{}\"", ".", "format", "(", "y_pred", ".", "shape", ")", ")", "\n", "loss", "=", "criterion", "(", "y_pred", ",", "y", ".", "squeeze", "(", ")", ")", "\n", "if", "t", "%", "100", "==", "99", ":", "\n", "            ", "print", "(", "\"step: {}, loss:{}\"", ".", "format", "(", "t", ",", "loss", ".", "item", "(", ")", ")", ")", "\n", "\n", "# Zero gradients, perform a backward pass, and update the weights.", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.idsgame_resnet.IdsGameResNet.__init__": [[10, 20], ["super().__init__", "torchvision.resnet18", "torch.nn.Conv2d"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", "=", "1", ",", "output_dim", "=", "44", ")", ":", "\n", "        ", "super", "(", "IdsGameResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "# bring resnet", "\n", "self", ".", "model", "=", "models", ".", "resnet18", "(", "pretrained", "=", "False", ",", "num_classes", "=", "output_dim", ",", "norm_layer", "=", "torch", ".", "nn", ".", "InstanceNorm2d", ")", "\n", "\n", "# original definition of the first layer on the resnet class", "\n", "# self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)", "\n", "\n", "self", ".", "model", ".", "conv1", "=", "torch", ".", "nn", ".", "Conv2d", "(", "in_channels", ",", "out_channels", "=", "64", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.idsgame_resnet.IdsGameResNet.forward": [[21, 23], ["idsgame_resnet.IdsGameResNet.model"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "model", "(", "x", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_linear.FNNwithLinear.__init__": [[12, 47], ["super().__init__", "torch.nn.ModuleList", "fnn_w_linear.FNNwithLinear.layers.append", "fnn_w_linear.FNNwithLinear.layers.append", "range", "fnn_w_linear.FNNwithLinear.layers.append", "torch.nn.Linear", "fnn_w_linear.FNNwithLinear.get_hidden_activation", "fnn_w_linear.FNNwithLinear.layers.append", "fnn_w_linear.FNNwithLinear.layers.append", "torch.nn.Linear", "torch.nn.Linear", "fnn_w_linear.FNNwithLinear.get_hidden_activation"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.get_hidden_activation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.get_hidden_activation"], ["def", "__init__", "(", "self", ",", "input_dim", ":", "int", ",", "output_dim", ":", "int", ",", "hidden_dim", ":", "int", ",", "num_hidden_layers", ":", "int", "=", "2", ",", "\n", "hidden_activation", ":", "str", "=", "\"ReLU\"", ")", ":", "\n", "        ", "\"\"\"\n        Bulilds the model\n\n        :param input_dim: the input dimension\n        :param output_dim: the output dimension\n        :param hidden_dim: the hidden dimension\n        :param num_hidden_layers: the number of hidden layers\n        :param hidden_activation: hidden activation type\n        \"\"\"", "\n", "super", "(", "FNNwithLinear", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "self", ".", "num_layers", "=", "num_hidden_layers", "+", "2", "\n", "self", ".", "hidden_activation", "=", "hidden_activation", "\n", "\n", "\n", "# Define layers of FNN", "\n", "self", ".", "layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "# Input layer", "\n", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "input_dim", ",", "hidden_dim", ")", ")", "\n", "self", ".", "layers", ".", "append", "(", "self", ".", "get_hidden_activation", "(", ")", ")", "\n", "\n", "# Hidden Layers", "\n", "for", "i", "in", "range", "(", "self", ".", "num_hidden_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", ")", "\n", "self", ".", "layers", ".", "append", "(", "self", ".", "get_hidden_activation", "(", ")", ")", "\n", "\n", "# Output layer", "\n", "", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "hidden_dim", ",", "self", ".", "output_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_linear.FNNwithLinear.get_hidden_activation": [[48, 70], ["torch.nn.ReLU", "torch.nn.LeakyReLU", "torch.nn.LogSigmoid", "torch.nn.PReLU", "torch.nn.Sigmoid", "torch.nn.Softplus", "torch.nn.Tanh", "ValueError"], "methods", ["None"], ["", "def", "get_hidden_activation", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Interprets the hidden activation\n\n        :return: the hidden activation function\n        \"\"\"", "\n", "if", "self", ".", "hidden_activation", "==", "\"ReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"LeakyReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "LeakyReLU", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"LogSigmoid\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "LogSigmoid", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"PReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "PReLU", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"Sigmoid\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"Softplus\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Softplus", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"Tanh\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Tanh", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Activation type: {} not recognized\"", ".", "format", "(", "self", ".", "hidden_activation", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_linear.FNNwithLinear.forward": [[71, 82], ["range", "len"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Forward propagation\n\n        :param x: input tensor\n        :return: Output prediction\n        \"\"\"", "\n", "y", "=", "x", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "layers", ")", ")", ":", "\n", "            ", "y", "=", "self", ".", "layers", "[", "i", "]", "(", "y", ")", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_linear.test": [[84, 120], ["fnn_w_linear.FNNwithLinear", "torch.randn", "torch.randn", "torch.nn.MSELoss", "torch.optim.SGD", "range", "FNNwithLinear.parameters", "FNNwithLinear.", "torch.nn.MSELoss.", "torch.optim.SGD.zero_grad", "criterion.backward", "torch.optim.SGD.step", "print", "criterion.item"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step"], ["", "", "def", "test", "(", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    A basic test-case to verify that the model can fit some randomly generated data\n\n    :return: None\n    \"\"\"", "\n", "# Constants", "\n", "input_dim", "=", "44", "\n", "output_dim", "=", "44", "\n", "hidden_dim", "=", "64", "\n", "batch_size", "=", "64", "\n", "\n", "# Create model", "\n", "model", "=", "FNNwithLinear", "(", "input_dim", ",", "output_dim", ",", "hidden_dim", ",", "num_hidden_layers", "=", "2", ")", "\n", "\n", "# Create random Tensors to hold inputs and outputs", "\n", "x", "=", "torch", ".", "randn", "(", "batch_size", ",", "input_dim", ")", "\n", "y", "=", "torch", ".", "randn", "(", "batch_size", ",", "output_dim", ")", "\n", "\n", "# Construct our loss function and an Optimizer. The call to model.parameters()", "\n", "# in the SGD constructor will contain the learnable parameters of the layers in the model", "\n", "criterion", "=", "torch", ".", "nn", ".", "MSELoss", "(", "reduction", "=", "'sum'", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "1e-4", ")", "\n", "for", "t", "in", "range", "(", "20000", ")", ":", "\n", "# Forward pass: Compute predicted y by passing x to the model", "\n", "        ", "y_pred", "=", "model", "(", "x", ")", "\n", "\n", "# Compute and print loss", "\n", "loss", "=", "criterion", "(", "y_pred", ",", "y", ")", "\n", "if", "t", "%", "100", "==", "99", ":", "\n", "            ", "print", "(", "\"step: {}, loss:{}\"", ".", "format", "(", "t", ",", "loss", ".", "item", "(", ")", ")", ")", "\n", "\n", "# Zero gradients, perform a backward pass, and update the weights.", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_actor_critic.FFNActorCritic.__init__": [[12, 49], ["super().__init__", "torch.nn.ModuleList", "fnn_actor_critic.FFNActorCritic.layers.append", "fnn_actor_critic.FFNActorCritic.layers.append", "range", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "fnn_actor_critic.FFNActorCritic.get_hidden_activation", "fnn_actor_critic.FFNActorCritic.layers.append", "fnn_actor_critic.FFNActorCritic.layers.append", "torch.nn.Linear", "fnn_actor_critic.FFNActorCritic.get_hidden_activation"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.get_hidden_activation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.get_hidden_activation"], ["def", "__init__", "(", "self", ",", "input_dim", ":", "int", ",", "output_dim", ":", "int", ",", "hidden_dim", ":", "int", ",", "num_hidden_layers", ":", "int", "=", "2", ",", "\n", "hidden_activation", ":", "str", "=", "\"ReLU\"", ")", ":", "\n", "        ", "\"\"\"\n        Bulilds the model\n\n        :param input_dim: the input dimension\n        :param output_dim: the output dimension\n        :param hidden_dim: the hidden dimension\n        :param num_hidden_layers: the number of hidden layers\n        :param hidden_activation: hidden activation type\n        \"\"\"", "\n", "super", "(", "FFNActorCritic", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "self", ".", "num_layers", "=", "num_hidden_layers", "+", "2", "\n", "self", ".", "hidden_activation", "=", "hidden_activation", "\n", "\n", "# Define layers of FNN", "\n", "self", ".", "layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "# Input layer", "\n", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "input_dim", ",", "hidden_dim", ")", ")", "\n", "self", ".", "layers", ".", "append", "(", "self", ".", "get_hidden_activation", "(", ")", ")", "\n", "\n", "# Hidden Layers", "\n", "for", "i", "in", "range", "(", "self", ".", "num_hidden_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", ")", "\n", "self", ".", "layers", ".", "append", "(", "self", ".", "get_hidden_activation", "(", ")", ")", "\n", "\n", "# Actor's head (one output per action)", "\n", "", "self", ".", "actor_head", "=", "torch", ".", "nn", ".", "Linear", "(", "hidden_dim", ",", "self", ".", "output_dim", ")", "\n", "\n", "# Critic's head (single output to predict the value of the state", "\n", "self", ".", "critic_head", "=", "torch", ".", "nn", ".", "Linear", "(", "hidden_dim", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_actor_critic.FFNActorCritic.get_hidden_activation": [[50, 72], ["torch.nn.ReLU", "torch.nn.LeakyReLU", "torch.nn.LogSigmoid", "torch.nn.PReLU", "torch.nn.Sigmoid", "torch.nn.Softplus", "torch.nn.Tanh", "ValueError"], "methods", ["None"], ["", "def", "get_hidden_activation", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Interprets the hidden activation\n\n        :return: the hidden activation function\n        \"\"\"", "\n", "if", "self", ".", "hidden_activation", "==", "\"ReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"LeakyReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "LeakyReLU", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"LogSigmoid\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "LogSigmoid", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"PReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "PReLU", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"Sigmoid\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"Softplus\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Softplus", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"Tanh\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Tanh", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Activation type: {} not recognized\"", ".", "format", "(", "self", ".", "hidden_activation", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_actor_critic.FFNActorCritic.forward": [[73, 92], ["range", "torch.nn.functional.softmax", "fnn_actor_critic.FFNActorCritic.critic_head", "len", "fnn_actor_critic.FFNActorCritic.actor_head"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Forward propagation\n\n        :param x: input tensor\n        :return: Output prediction\n        \"\"\"", "\n", "y", "=", "x", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "layers", ")", ")", ":", "\n", "            ", "y", "=", "self", ".", "layers", "[", "i", "]", "(", "y", ")", "\n", "\n", "# actor: choses action to take from state s_t", "\n", "# by returning probability of each action", "\n", "", "action_prob", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "self", ".", "actor_head", "(", "y", ")", ")", "\n", "\n", "# critic: evaluates being in the state s_t", "\n", "state_values", "=", "self", ".", "critic_head", "(", "y", ")", "\n", "\n", "return", "action_prob", ",", "state_values", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_actor_critic.test": [[94, 133], ["fnn_actor_critic.FFNActorCritic", "torch.randn", "torch.empty().random_", "torch.randn", "torch.nn.CrossEntropyLoss", "torch.nn.MSELoss", "torch.optim.SGD", "range", "FFNActorCritic.parameters", "FFNActorCritic.", "torch.nn.CrossEntropyLoss.", "torch.nn.MSELoss.", "torch.optim.SGD.zero_grad", "criterion_a.backward", "torch.optim.SGD.step", "torch.empty", "torch.empty().random_.squeeze", "torch.randn.squeeze", "print", "criterion_a.item", "criterion_v.item"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step"], ["", "", "def", "test", "(", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    A basic test-case to verify that the model can fit some randomly generated data\n\n    :return: None\n    \"\"\"", "\n", "# Constants", "\n", "input_dim", "=", "44", "\n", "output_dim", "=", "44", "\n", "hidden_dim", "=", "64", "\n", "batch_size", "=", "64", "\n", "\n", "# Create model", "\n", "model", "=", "FFNActorCritic", "(", "input_dim", ",", "output_dim", ",", "hidden_dim", ",", "num_hidden_layers", "=", "2", ")", "\n", "\n", "# Create random Tensors to hold inputs and outputs", "\n", "x", "=", "torch", ".", "randn", "(", "batch_size", ",", "input_dim", ")", "\n", "y_1", "=", "torch", ".", "empty", "(", "batch_size", ",", "dtype", "=", "torch", ".", "long", ")", ".", "random_", "(", "output_dim", ")", "\n", "y_2", "=", "torch", ".", "randn", "(", "batch_size", ",", "1", ")", "\n", "\n", "# Construct our loss function and an Optimizer. The call to model.parameters()", "\n", "# in the SGD constructor will contain the learnable parameters of the layers in the model", "\n", "criterion_a", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'sum'", ")", "\n", "criterion_v", "=", "torch", ".", "nn", ".", "MSELoss", "(", "reduction", "=", "'sum'", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "1e-4", ")", "\n", "for", "t", "in", "range", "(", "20000", ")", ":", "\n", "# Forward pass: Compute predicted y_1 by passing x to the model", "\n", "        ", "y_pred_a", ",", "y_pred_v", "=", "model", "(", "x", ")", "\n", "\n", "# Compute and print loss", "\n", "loss_1", "=", "criterion_a", "(", "y_pred_a", ",", "y_1", ".", "squeeze", "(", ")", ")", "\n", "loss_2", "=", "criterion_v", "(", "y_pred_v", ",", "y_2", ".", "squeeze", "(", ")", ")", "\n", "if", "t", "%", "100", "==", "99", ":", "\n", "            ", "print", "(", "\"step: {}, loss_a:{}, loss_v:{}\"", ".", "format", "(", "t", ",", "loss_1", ".", "item", "(", ")", ",", "loss_2", ".", "item", "(", ")", ")", ")", "\n", "\n", "# Zero gradients, perform a backward pass, and update the weights.", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss_1", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.cnn_w_softmax.CNNwithSoftmax.__init__": [[16, 100], ["super().__init__", "torch.nn.ModuleList", "range", "cnn_w_softmax.CNNwithSoftmax.layers.append", "cnn_w_softmax.CNNwithSoftmax.layers.append", "cnn_w_softmax.CNNwithSoftmax.layers.append", "cnn_w_softmax.CNNwithSoftmax.layers.append", "cnn_w_softmax.CNNwithSoftmax.layers.append", "torch.nn.Linear", "torch.nn.Softmax", "torch.nn.Conv2d", "cnn_w_softmax.CNNwithSoftmax.layers.append", "torch.nn.MaxPool2d", "cnn_w_softmax.CNNwithSoftmax.layers.append", "cnn_w_softmax.CNNwithSoftmax.layers.append", "torch.nn.Conv2d", "cnn_w_softmax.CNNwithSoftmax.layers.append", "torch.nn.Conv1d", "torch.nn.Conv2d", "cnn_w_softmax.CNNwithSoftmax.layers.append", "torch.nn.MaxPool2d", "torch.nn.Conv1d", "torch.nn.Conv1d"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ":", "int", ",", "output_dim", ":", "int", ",", "hidden_dim", ":", "int", ",", "num_hidden_layers", ":", "int", "=", "2", ",", "\n", "hidden_activation", ":", "str", "=", "\"ReLU\"", ",", "conv_kernels", ":", "List", "[", "int", "]", "=", "None", ",", "conv_strides", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "conv_out_channels", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "pool_kernels", ":", "List", "[", "int", "]", "=", "None", ",", "pool_strides", ":", "List", "[", "int", "]", "=", "None", ",", "pool", ":", "List", "[", "bool", "]", "=", "None", ",", "\n", "flat_dim", ":", "int", "=", "256", ",", "conv_2d", ":", "bool", "=", "True", ",", "conv_1d", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Builds the model\n\n        :param input_dim: the input dimension\n        :param output_dim: the output dimension\n        :param hidden_dim: the hidden dimension\n        :param num_hidden_layers: the number of hidden layers\n        :param hidden_activation: hidden activation type\n        :param conv_kernels: size of the conv kernels\n        :param conv_strides: size of the conv strides\n        :param conv_out_channels: size of the output channels for conv layers\n        :param pool_kernels: size of the pool kernels\n        :param pool_strides: size of the pool strides\n        :param pool: boolean vector whether to add a pooling layer after each conv layer\n        :param flat_dim: dimension of the flatten layer at the end\n        :param conv_1d: boolean flag, whether to use 1D convs\n        :param conv_2d: boolean flag, whether to use 2D convs\n        \"\"\"", "\n", "super", "(", "CNNwithSoftmax", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "self", ".", "num_layers", "=", "num_hidden_layers", "+", "2", "\n", "self", ".", "hidden_activation", "=", "hidden_activation", "\n", "self", ".", "conv_kernels", "=", "conv_kernels", "\n", "self", ".", "conv_strides", "=", "conv_strides", "\n", "self", ".", "pool_kernels", "=", "pool_kernels", "\n", "self", ".", "pool_strides", "=", "pool_strides", "\n", "self", ".", "conv_out_channels", "=", "conv_out_channels", "\n", "self", ".", "pool", "=", "pool", "\n", "self", ".", "flat_dim", "=", "flat_dim", "\n", "self", ".", "conv_1d", "=", "conv_1d", "\n", "self", ".", "conv_2d", "=", "conv_2d", "\n", "\n", "# Define layers of CNN", "\n", "self", ".", "layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "# Input layer", "\n", "if", "self", ".", "conv_2d", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Conv2d", "(", "in_channels", "=", "input_dim", "[", "0", "]", ",", "out_channels", "=", "3", ",", "\n", "kernel_size", "=", "2", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ")", ")", "\n", "# self.layers.append(torch.nn.Conv2d(in_channels=input_dim[0], out_channels=self.conv_out_channels[0],", "\n", "#                                    kernel_size=self.conv_kernels[0], stride=self.conv_strides[0], padding=0))", "\n", "", "elif", "self", ".", "conv_1d", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Conv1d", "(", "in_channels", "=", "input_dim", "[", "0", "]", ",", "out_channels", "=", "self", ".", "conv_out_channels", "[", "0", "]", ",", "\n", "kernel_size", "=", "self", ".", "conv_kernels", "[", "0", "]", ",", "stride", "=", "self", ".", "conv_strides", "[", "0", "]", ",", "\n", "padding", "=", "0", ")", ")", "\n", "", "if", "pool", "[", "0", "]", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "self", ".", "pool_kernels", "[", "0", "]", ",", "stride", "=", "self", ".", "pool_strides", "[", "0", "]", ",", "padding", "=", "0", ")", ")", "\n", "\n", "# Hidden Layers", "\n", "", "for", "i", "in", "range", "(", "self", ".", "num_hidden_layers", ")", ":", "\n", "            ", "if", "self", ".", "conv_2d", ":", "\n", "                ", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Conv2d", "(", "in_channels", "=", "self", ".", "conv_out_channels", "[", "i", "-", "1", "]", ",", "out_channels", "=", "self", ".", "conv_out_channels", "[", "i", "+", "1", "]", ",", "\n", "kernel_size", "=", "self", ".", "conv_kernels", "[", "i", "+", "1", "]", ",", "stride", "=", "self", ".", "conv_strides", "[", "i", "+", "1", "]", ",", "\n", "padding", "=", "0", ")", ")", "\n", "", "elif", "self", ".", "conv_1d", ":", "\n", "                ", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Conv1d", "(", "in_channels", "=", "self", ".", "conv_out_channels", "[", "i", "-", "1", "]", ",", "\n", "out_channels", "=", "self", ".", "conv_out_channels", "[", "i", "+", "1", "]", ",", "\n", "kernel_size", "=", "self", ".", "conv_kernels", "[", "i", "+", "1", "]", ",", "\n", "stride", "=", "self", ".", "conv_strides", "[", "i", "+", "1", "]", ",", "\n", "padding", "=", "0", ")", ")", "\n", "", "if", "pool", "[", "i", "+", "1", "]", ":", "\n", "                ", "self", ".", "layers", ".", "append", "(", "\n", "torch", ".", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "self", ".", "pool_kernels", "[", "i", "+", "1", "]", ",", "stride", "=", "self", ".", "pool_strides", "[", "i", "+", "1", "]", ",", "padding", "=", "0", ")", ")", "\n", "", "", "if", "self", ".", "conv_2d", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "\n", "torch", ".", "nn", ".", "Conv2d", "(", "in_channels", "=", "self", ".", "conv_out_channels", "[", "-", "2", "]", ",", "out_channels", "=", "self", ".", "conv_out_channels", "[", "-", "1", "]", ",", "\n", "kernel_size", "=", "self", ".", "conv_kernels", "[", "-", "1", "]", ",", "stride", "=", "self", ".", "conv_strides", "[", "-", "1", "]", ",", "padding", "=", "0", ")", ")", "\n", "", "elif", "self", ".", "conv_1d", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "\n", "torch", ".", "nn", ".", "Conv1d", "(", "in_channels", "=", "self", ".", "conv_out_channels", "[", "-", "2", "]", ",", "out_channels", "=", "self", ".", "conv_out_channels", "[", "-", "1", "]", ",", "\n", "kernel_size", "=", "self", ".", "conv_kernels", "[", "-", "1", "]", ",", "stride", "=", "self", ".", "conv_strides", "[", "-", "1", "]", ",", "padding", "=", "0", ")", ")", "\n", "# Output layer", "\n", "", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "flat_dim", ",", "self", ".", "output_dim", ")", ")", "\n", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Softmax", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.cnn_w_softmax.CNNwithSoftmax.get_hidden_activation": [[101, 123], ["torch.nn.ReLU", "torch.nn.LeakyReLU", "torch.nn.LogSigmoid", "torch.nn.PReLU", "torch.nn.Sigmoid", "torch.nn.Softplus", "torch.nn.Tanh", "ValueError"], "methods", ["None"], ["", "def", "get_hidden_activation", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Interprets the hidden activation\n\n        :return: the hidden activation function\n        \"\"\"", "\n", "if", "self", ".", "hidden_activation", "==", "\"ReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"LeakyReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "LeakyReLU", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"LogSigmoid\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "LogSigmoid", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"PReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "PReLU", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"Sigmoid\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"Softplus\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Softplus", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"Tanh\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Tanh", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Activation type: {} not recognized\"", ".", "format", "(", "self", ".", "hidden_activation", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.cnn_w_softmax.CNNwithSoftmax.forward": [[124, 214], ["torch.nn.Sequential", "cnn_w_softmax.CNNwithSoftmax.cnn", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Flatten"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Forward propagation\n\n        :param x: input tensor\n        :return: Output prediction\n        \"\"\"", "\n", "y", "=", "x", "\n", "# print(\"y shape:{}\".format(y.shape))", "\n", "# y = torch.nn.Conv2d(3, out_channels=12, kernel_size=2, stride=1, padding=0)(y)", "\n", "# print(\"y shape:{}\".format(y.shape))", "\n", "# y = torch.nn.ReLU()(y)", "\n", "# y = torch.nn.Conv2d(in_channels=12, out_channels=12, kernel_size=2, stride=1, padding=0)(y)", "\n", "# print(\"y shape:{}\".format(y.shape))", "\n", "# y = torch.nn.ReLU()(y)", "\n", "# y = torch.nn.Conv2d(in_channels=12, out_channels=12, kernel_size=1, stride=1, padding=0)(y)", "\n", "# y = torch.nn.ReLU()(y)", "\n", "# print(\"y shape:{}\".format(y.shape))", "\n", "# y = torch.nn.Flatten()(y)", "\n", "# print(\"y shape:{}\".format(y.shape))", "\n", "# y = torch.nn.Linear(36, 44)(y)", "\n", "# print(\"y shape:{}\".format(y.shape))", "\n", "# y = torch.nn.Softmax()(y)", "\n", "\n", "# self.cnn = torch.nn.Sequential(torch.nn.Conv2d(6, out_channels=64, kernel_size=1, stride=1, padding=0),", "\n", "#                          torch.nn.ReLU(),", "\n", "#                          torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1, stride=1, padding=0),", "\n", "#                          torch.nn.ReLU(),", "\n", "#                          torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1, stride=1, padding=0),", "\n", "#                          torch.nn.ReLU(),", "\n", "#                          torch.nn.Flatten(),", "\n", "#                          torch.nn.Linear(768, 44),", "\n", "#                          torch.nn.Softmax())", "\n", "\n", "# self.cnn = torch.nn.Sequential(torch.nn.Conv2d(6, out_channels=64, kernel_size=1, stride=1, padding=0),", "\n", "#                                torch.nn.MaxPool2d(kernel_size=2, stride=1,padding=0),", "\n", "#                                torch.nn.ReLU(),", "\n", "#                                torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1, stride=1,", "\n", "#                                                padding=0),", "\n", "#                                torch.nn.MaxPool2d(kernel_size=1, stride=1, padding=0),", "\n", "#                                torch.nn.ReLU(),", "\n", "#                                torch.nn.Conv2d(in_channels=64, out_channels=64, kernel_size=1, stride=1,", "\n", "#                                                padding=0),", "\n", "#                                torch.nn.MaxPool2d(kernel_size=1, stride=1, padding=0),", "\n", "#                                torch.nn.ReLU(),", "\n", "#                                torch.nn.Flatten(),", "\n", "#                                torch.nn.Linear(768, 44),", "\n", "#                                torch.nn.Softmax())", "\n", "#resnet18 = models.resnet18(pretrained=False, num_classes=44)", "\n", "# my_resnet = IdsGameResNet(in_channels=6)", "\n", "# self.cnn = my_resnet", "\n", "# self.cnn = torch.nn.Sequential(torch.nn.Conv2d(3, out_channels=2, kernel_size=1, stride=1, padding=0),", "\n", "#                          torch.nn.ReLU(),", "\n", "#                          torch.nn.Conv2d(in_channels=2, out_channels=2, kernel_size=2, stride=1, padding=0),", "\n", "#                          torch.nn.ReLU(),", "\n", "#                          torch.nn.Conv2d(in_channels=2, out_channels=2, kernel_size=2, stride=1, padding=0),", "\n", "#                          torch.nn.ReLU(),", "\n", "#                          torch.nn.Flatten(),", "\n", "#                          torch.nn.Linear(6, 44),", "\n", "#                          torch.nn.Softmax())", "\n", "# self.cnn = torch.nn.Sequential(torch.nn.Conv2d(3, out_channels=2, kernel_size=3, stride=1, padding=0),", "\n", "#                          torch.nn.ReLU(),", "\n", "#                          torch.nn.Conv2d(in_channels=2, out_channels=2, kernel_size=3, stride=1, padding=0),", "\n", "#                          torch.nn.ReLU(),", "\n", "#                          torch.nn.Conv2d(in_channels=2, out_channels=2, kernel_size=2, stride=1, padding=0),", "\n", "#                          torch.nn.ReLU(),", "\n", "#                          torch.nn.Conv2d(in_channels=2, out_channels=2, kernel_size=1, stride=1,padding=0),", "\n", "#                          torch.nn.ReLU(),", "\n", "#                          torch.nn.Flatten(),", "\n", "#                          torch.nn.Linear(18, 10),", "\n", "#                          torch.nn.Softmax())", "\n", "\n", "self", ".", "cnn", "=", "torch", ".", "nn", ".", "Sequential", "(", "torch", ".", "nn", ".", "Conv2d", "(", "3", ",", "out_channels", "=", "2", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", ")", ",", "\n", "torch", ".", "nn", ".", "Conv2d", "(", "in_channels", "=", "2", ",", "out_channels", "=", "2", ",", "kernel_size", "=", "2", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", ")", ",", "\n", "torch", ".", "nn", ".", "Conv2d", "(", "in_channels", "=", "2", ",", "out_channels", "=", "2", ",", "kernel_size", "=", "2", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "torch", ".", "nn", ".", "ReLU", "(", ")", ",", "\n", "torch", ".", "nn", ".", "Flatten", "(", ")", ")", "\n", "y", "=", "self", ".", "cnn", "(", "y", ")", "\n", "#print(\"y shape:{}\".format(y.shape))", "\n", "# for i in range(len(self.layers)):", "\n", "#     print(\"layer i:{}\".format(i))", "\n", "#     print(\"input shape:{}\".format(y.shape))", "\n", "#     # Flatten", "\n", "#     if i == len(self.layers)-1:", "\n", "#         y = self.layers[i](y.view(y.size(0), -1))", "\n", "#     else:", "\n", "#         y = self.layers[i](y)", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.cnn_w_softmax.test": [[216, 257], ["cnn_w_softmax.CNNwithSoftmax", "torch.randn", "torch.empty().random_", "torch.nn.CrossEntropyLoss", "torch.optim.SGD", "range", "CNNwithSoftmax.parameters", "CNNwithSoftmax.", "torch.nn.CrossEntropyLoss.", "torch.optim.SGD.zero_grad", "criterion.backward", "torch.optim.SGD.step", "torch.empty", "print", "criterion.item"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step"], ["", "", "def", "test", "(", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    A basic test-case to verify that the model can fit some randomly generated data\n\n    :return: None\n    \"\"\"", "\n", "# Constants", "\n", "input_dim", "=", "(", "3", ",", "60", ",", "60", ")", "\n", "output_dim", "=", "10", "\n", "hidden_dim", "=", "64", "\n", "batch_size", "=", "1", "\n", "\n", "# Create model", "\n", "model", "=", "CNNwithSoftmax", "(", "input_dim", ",", "output_dim", ",", "hidden_dim", ",", "num_hidden_layers", "=", "2", ",", "conv_kernels", "=", "[", "2", ",", "1", ",", "1", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "conv_strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", ",", "1", ",", "1", "]", ",", "conv_out_channels", "=", "[", "2", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", "]", ",", "pool_kernels", "=", "[", "2", ",", "2", ",", "2", ",", "2", ",", "2", "]", ",", "\n", "pool_strides", "=", "[", "None", ",", "None", ",", "None", ",", "None", ",", "None", "]", ",", "pool", "=", "[", "False", ",", "False", ",", "False", ",", "False", ",", "False", ",", "False", "]", ",", "\n", "flat_dim", "=", "3", ",", "conv_1d", "=", "False", ",", "conv_2d", "=", "True", ")", "\n", "\n", "# Create random Tensors to hold inputs and outputs", "\n", "x", "=", "torch", ".", "randn", "(", "batch_size", ",", "input_dim", "[", "0", "]", ",", "input_dim", "[", "1", "]", ",", "input_dim", "[", "2", "]", ")", "\n", "#x = torch.randn(batch_size, input_dim[0], input_dim[1])", "\n", "y", "=", "torch", ".", "empty", "(", "batch_size", ",", "dtype", "=", "torch", ".", "long", ")", ".", "random_", "(", "output_dim", ")", "\n", "\n", "# Construct our loss function and an Optimizer. The call to model.parameters()", "\n", "# in the SGD constructor will contain the learnable parameters of the layers in the model", "\n", "criterion", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'sum'", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "1e-4", ")", "\n", "for", "t", "in", "range", "(", "20000", ")", ":", "\n", "# Forward pass: Compute predicted y by passing x to the model", "\n", "        ", "y_pred", "=", "model", "(", "x", ")", "\n", "\n", "# Compute and print loss", "\n", "#print(\"y shape:{}, y_pred shape:{}\".format(y.shape, y_pred.shape))", "\n", "loss", "=", "criterion", "(", "y_pred", ",", "y", ")", "\n", "if", "t", "%", "100", "==", "99", ":", "\n", "            ", "print", "(", "\"step: {}, loss:{}\"", ".", "format", "(", "t", ",", "loss", ".", "item", "(", ")", ")", ")", "\n", "\n", "# Zero gradients, perform a backward pass, and update the weights.", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.__init__": [[14, 49], ["super().__init__", "torch.nn.ModuleList", "fnn_w_softmax.FNNwithSoftmax.layers.append", "fnn_w_softmax.FNNwithSoftmax.layers.append", "range", "fnn_w_softmax.FNNwithSoftmax.layers.append", "fnn_w_softmax.FNNwithSoftmax.layers.append", "torch.nn.Linear", "fnn_w_softmax.FNNwithSoftmax.get_hidden_activation", "fnn_w_softmax.FNNwithSoftmax.layers.append", "fnn_w_softmax.FNNwithSoftmax.layers.append", "torch.nn.Linear", "torch.nn.Softmax", "torch.nn.Linear", "fnn_w_softmax.FNNwithSoftmax.get_hidden_activation"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.get_hidden_activation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.get_hidden_activation"], ["def", "__init__", "(", "self", ",", "input_dim", ":", "int", ",", "output_dim", ":", "int", ",", "hidden_dim", ":", "int", ",", "num_hidden_layers", ":", "int", "=", "2", ",", "\n", "hidden_activation", ":", "str", "=", "\"ReLU\"", ")", ":", "\n", "        ", "\"\"\"\n        Builds the model\n\n        :param input_dim: the input dimension\n        :param output_dim: the output dimension\n        :param hidden_dim: the hidden dimension\n        :param num_hidden_layers: the number of hidden layers\n        :param hidden_activation: hidden activation type\n        \"\"\"", "\n", "super", "(", "FNNwithSoftmax", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "self", ".", "num_layers", "=", "num_hidden_layers", "+", "2", "\n", "self", ".", "hidden_activation", "=", "hidden_activation", "\n", "\n", "# Define layers of FNN", "\n", "self", ".", "layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "\n", "# Input layer", "\n", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "input_dim", ",", "hidden_dim", ")", ")", "\n", "self", ".", "layers", ".", "append", "(", "self", ".", "get_hidden_activation", "(", ")", ")", "\n", "\n", "# Hidden Layers", "\n", "for", "i", "in", "range", "(", "self", ".", "num_hidden_layers", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", ")", "\n", "self", ".", "layers", ".", "append", "(", "self", ".", "get_hidden_activation", "(", ")", ")", "\n", "\n", "# Output layer", "\n", "", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Linear", "(", "hidden_dim", ",", "self", ".", "output_dim", ")", ")", "\n", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Softmax", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.get_hidden_activation": [[50, 72], ["torch.nn.ReLU", "torch.nn.LeakyReLU", "torch.nn.LogSigmoid", "torch.nn.PReLU", "torch.nn.Sigmoid", "torch.nn.Softplus", "torch.nn.Tanh", "ValueError"], "methods", ["None"], ["", "def", "get_hidden_activation", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Interprets the hidden activation\n\n        :return: the hidden activation function\n        \"\"\"", "\n", "if", "self", ".", "hidden_activation", "==", "\"ReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "ReLU", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"LeakyReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "LeakyReLU", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"LogSigmoid\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "LogSigmoid", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"PReLU\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "PReLU", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"Sigmoid\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"Softplus\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Softplus", "(", ")", "\n", "", "elif", "self", ".", "hidden_activation", "==", "\"Tanh\"", ":", "\n", "            ", "return", "torch", ".", "nn", ".", "Tanh", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Activation type: {} not recognized\"", ".", "format", "(", "self", ".", "hidden_activation", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.FNNwithSoftmax.forward": [[73, 84], ["range", "len"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\"\n        Forward propagation\n\n        :param x: input tensor\n        :return: Output prediction\n        \"\"\"", "\n", "y", "=", "x", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "layers", ")", ")", ":", "\n", "            ", "y", "=", "self", ".", "layers", "[", "i", "]", "(", "y", ")", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.models.fnn_w_softmax.test": [[86, 122], ["fnn_w_softmax.FNNwithSoftmax", "torch.randn", "torch.empty().random_", "torch.nn.CrossEntropyLoss", "torch.optim.SGD", "range", "FNNwithSoftmax.parameters", "FNNwithSoftmax.", "torch.nn.CrossEntropyLoss.", "torch.optim.SGD.zero_grad", "criterion.backward", "torch.optim.SGD.step", "torch.empty", "torch.empty().random_.squeeze", "print", "criterion.item"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step"], ["", "", "def", "test", "(", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    A basic test-case to verify that the model can fit some randomly generated data\n\n    :return: None\n    \"\"\"", "\n", "# Constants", "\n", "input_dim", "=", "44", "\n", "output_dim", "=", "44", "\n", "hidden_dim", "=", "64", "\n", "batch_size", "=", "64", "\n", "\n", "# Create model", "\n", "model", "=", "FNNwithSoftmax", "(", "input_dim", ",", "output_dim", ",", "hidden_dim", ",", "num_hidden_layers", "=", "2", ")", "\n", "\n", "# Create random Tensors to hold inputs and outputs", "\n", "x", "=", "torch", ".", "randn", "(", "batch_size", ",", "input_dim", ")", "\n", "y", "=", "torch", ".", "empty", "(", "batch_size", ",", "dtype", "=", "torch", ".", "long", ")", ".", "random_", "(", "output_dim", ")", "\n", "\n", "# Construct our loss function and an Optimizer. The call to model.parameters()", "\n", "# in the SGD constructor will contain the learnable parameters of the layers in the model", "\n", "criterion", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'sum'", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "1e-4", ")", "\n", "for", "t", "in", "range", "(", "20000", ")", ":", "\n", "# Forward pass: Compute predicted y by passing x to the model", "\n", "        ", "y_pred", "=", "model", "(", "x", ")", "\n", "\n", "# Compute and print loss", "\n", "loss", "=", "criterion", "(", "y_pred", ",", "y", ".", "squeeze", "(", ")", ")", "\n", "if", "t", "%", "100", "==", "99", ":", "\n", "            ", "print", "(", "\"step: {}, loss:{}\"", ".", "format", "(", "t", ",", "loss", ".", "item", "(", ")", ")", ")", "\n", "\n", "# Zero gradients, perform a backward pass, and update the weights.", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.__init__": [[19, 49], ["gym_idsgame.agents.dao.experiment_result.ExperimentResult", "gym_idsgame.agents.dao.experiment_result.ExperimentResult", "tqdm.tqdm", "random.seed", "numpy.random.seed", "torch.manual_seed", "logging.getLogger"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.seed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.base_vec_env.VecEnvWrapper.seed"], ["def", "__init__", "(", "self", ",", "env", ":", "IdsGameEnv", ",", "config", ":", "PolicyGradientAgentConfig", ")", ":", "\n", "        ", "\"\"\"\n        Initialize environment and hyperparameters\n\n        :param config: the configuration\n        \"\"\"", "\n", "self", ".", "env", "=", "env", "\n", "self", ".", "config", "=", "config", "\n", "self", ".", "train_result", "=", "ExperimentResult", "(", ")", "\n", "self", ".", "eval_result", "=", "ExperimentResult", "(", ")", "\n", "self", ".", "num_eval_games_total", "=", "0", "\n", "self", ".", "num_eval_hacks_total", "=", "0", "\n", "self", ".", "num_eval_games", "=", "0", "\n", "self", ".", "num_eval_hacks", "=", "0", "\n", "self", ".", "num_train_games", "=", "0", "\n", "self", ".", "num_train_hacks", "=", "0", "\n", "self", ".", "num_train_games_total", "=", "0", "\n", "self", ".", "num_train_hacks_total", "=", "0", "\n", "self", ".", "train_hack_probability", "=", "0.0", "\n", "self", ".", "train_cumulative_hack_probability", "=", "0.0", "\n", "self", ".", "eval_hack_probability", "=", "0.0", "\n", "self", ".", "eval_cumulative_hack_probability", "=", "0.0", "\n", "self", ".", "eval_attacker_cumulative_reward", "=", "0", "\n", "self", ".", "eval_defender_cumulative_reward", "=", "0", "\n", "self", ".", "outer_train", "=", "tqdm", ".", "tqdm", "(", "total", "=", "self", ".", "config", ".", "num_episodes", ",", "desc", "=", "'Train Episode'", ",", "position", "=", "0", ")", "\n", "if", "self", ".", "config", ".", "logger", "is", "None", ":", "\n", "            ", "self", ".", "config", ".", "logger", "=", "logging", ".", "getLogger", "(", "'PolicyGradient Agent'", ")", "\n", "", "random", ".", "seed", "(", "self", ".", "config", ".", "random_seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "self", ".", "config", ".", "random_seed", ")", "\n", "torch", ".", "manual_seed", "(", "self", ".", "config", ".", "random_seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_action_dist": [[50, 58], ["pg_agent.PolicyGradientAgent.config.logger.info", "list", "map", "dist.data.cpu().numpy().tolist", "str", "dist.data.cpu().numpy", "dist.data.cpu"], "methods", ["None"], ["", "def", "log_action_dist", "(", "self", ",", "dist", ",", "attacker", "=", "True", ")", ":", "\n", "        ", "suffix", "=", "\"[Attacker]\"", "\n", "if", "not", "attacker", ":", "\n", "            ", "suffix", "=", "\"[Defender]\"", "\n", "", "log_str", "=", "suffix", "+", "\" Initial State Action Dist: [\"", "\n", "dist_str", "=", "\",\"", ".", "join", "(", "list", "(", "map", "(", "lambda", "x", ":", "str", "(", "x", ")", ",", "dist", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", ")", ")", "\n", "log_str", "=", "log_str", "+", "dist_str", "+", "\"]\"", "\n", "self", ".", "config", ".", "logger", ".", "info", "(", "log_str", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_metrics": [[59, 145], ["numpy.mean", "numpy.mean", "numpy.mean", "pg_agent.PolicyGradientAgent.config.logger.info", "numpy.mean", "numpy.mean", "pg_agent.PolicyGradientAgent.outer_eval.set_description_str", "pg_agent.PolicyGradientAgent.outer_train.set_description_str", "pg_agent.PolicyGradientAgent.log_tensorboard", "result.avg_episode_steps.append", "result.avg_attacker_episode_rewards.append", "result.avg_defender_episode_rewards.append", "result.epsilon_values.append", "result.hack_probability.append", "result.cumulative_hack_probabiltiy.append", "result.attacker_cumulative_reward.append", "result.defender_cumulative_reward.append", "result.avg_episode_loss_attacker.append", "result.avg_episode_loss_defender.append", "result.lr_list.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_tensorboard"], ["", "def", "log_metrics", "(", "self", ",", "iteration", ":", "int", ",", "result", ":", "ExperimentResult", ",", "attacker_episode_rewards", ":", "list", ",", "\n", "defender_episode_rewards", ":", "list", ",", "\n", "episode_steps", ":", "list", ",", "episode_avg_attacker_loss", ":", "list", "=", "None", ",", "\n", "episode_avg_defender_loss", ":", "list", "=", "None", ",", "\n", "eval", ":", "bool", "=", "False", ",", "\n", "update_stats", ":", "bool", "=", "True", ",", "lr_attacker", ":", "float", "=", "None", ",", "lr_defender", ":", "float", "=", "None", ",", "\n", "train_attacker", ":", "bool", "=", "False", ",", "\n", "train_defender", ":", "bool", "=", "False", ",", "a_pool", ":", "int", "=", "0", ",", "d_pool", ":", "int", "=", "0", ",", "total_num_episodes", ":", "int", "=", "0", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Logs average metrics for the last <self.config.log_frequency> episodes\n\n        :param iteration: the training iteration (equivalent to episode if batching is not used)\n        :param result: the result object to add the results to\n        :param attacker_episode_rewards: list of attacker episode rewards for the last <self.config.log_frequency> episodes\n        :param defender_episode_rewards: list of defender episode rewards for the last <self.config.log_frequency> episodes\n        :param episode_steps: list of episode steps for the last <self.config.log_frequency> episodes\n        :param episode_avg_attacker_loss: list of episode attacker loss for the last <self.config.log_frequency> episodes\n        :param episode_avg_defender_loss: list of episode defedner loss for the last <self.config.log_frequency> episodes\n        :param eval: boolean flag whether the metrics are logged in an evaluation context.\n        :param update_stats: boolean flag whether to update stats\n        :param lr_attacker: the learning rate of the attacker\n        :param lr_defender: the learning rate of the defender\n        :param train_attacker: boolean flag indicating whether the attacker is being trained\n        :param train_defender: boolean flag indicating whether the defender is being trained\n        :param a_pool: size of the attacker pool (if using opponent pools)\n        :param d_pool: size of the defender pool (if using opponent pools)\n        :param total_num_episodes: number of training episodes\n        :return: None\n        \"\"\"", "\n", "avg_attacker_episode_rewards", "=", "np", ".", "mean", "(", "attacker_episode_rewards", ")", "\n", "avg_defender_episode_rewards", "=", "np", ".", "mean", "(", "defender_episode_rewards", ")", "\n", "if", "lr_attacker", "is", "None", ":", "\n", "            ", "lr_attacker", "=", "0.0", "\n", "", "if", "lr_defender", "is", "None", ":", "\n", "            ", "lr_defender", "=", "0.0", "\n", "", "if", "not", "eval", "and", "episode_avg_attacker_loss", "is", "not", "None", ":", "\n", "            ", "avg_episode_attacker_loss", "=", "np", ".", "mean", "(", "episode_avg_attacker_loss", ")", "\n", "", "else", ":", "\n", "            ", "avg_episode_attacker_loss", "=", "0.0", "\n", "", "if", "not", "eval", "and", "episode_avg_defender_loss", "is", "not", "None", ":", "\n", "            ", "avg_episode_defender_loss", "=", "np", ".", "mean", "(", "episode_avg_defender_loss", ")", "\n", "", "else", ":", "\n", "            ", "avg_episode_defender_loss", "=", "0.0", "\n", "\n", "", "avg_episode_steps", "=", "np", ".", "mean", "(", "episode_steps", ")", "\n", "hack_probability", "=", "self", ".", "train_hack_probability", "if", "not", "eval", "else", "self", ".", "eval_hack_probability", "\n", "hack_probability_total", "=", "self", ".", "train_cumulative_hack_probability", "if", "not", "eval", "else", "self", ".", "eval_cumulative_hack_probability", "\n", "attacker_cumulative_reward", "=", "self", ".", "env", ".", "state", ".", "attacker_cumulative_reward", "if", "not", "eval", "else", "self", ".", "eval_attacker_cumulative_reward", "\n", "defender_cumulative_reward", "=", "self", ".", "env", ".", "state", ".", "defender_cumulative_reward", "if", "not", "eval", "else", "self", ".", "eval_defender_cumulative_reward", "\n", "if", "eval", ":", "\n", "            ", "log_str", "=", "\"[Eval] iter:{},avg_a_R:{:.2f},avg_d_R:{:.2f},avg_t:{:.2f},avg_h:{:.2f},acc_A_R:{:.2f},\"", "\"acc_D_R:{:.2f},lr_a:{:.2E},lr_d:{:.2E},c_h:{:.2f}\"", ".", "format", "(", "\n", "iteration", ",", "avg_attacker_episode_rewards", ",", "avg_defender_episode_rewards", ",", "avg_episode_steps", ",", "hack_probability", ",", "\n", "attacker_cumulative_reward", ",", "defender_cumulative_reward", ",", "lr_attacker", ",", "lr_defender", ",", "\n", "hack_probability_total", ")", "\n", "self", ".", "outer_eval", ".", "set_description_str", "(", "log_str", ")", "\n", "", "else", ":", "\n", "            ", "log_str", "=", "\"[Train] iter: {:.2f} epsilon:{:.2f},avg_a_R:{:.2f},avg_d_R:{:.2f},avg_t:{:.2f},avg_h:{:.2f},acc_A_R:{:.2f},\"", "\"acc_D_R:{:.2f},A_loss:{:.6f},D_loss:{:.6f},lr_a:{:.2E},lr_d:{:.2E},c_h:{:.2f},Tr_A:{},Tr_D:{},\"", "\"a_pool:{},d_pool:{},episode:{}\"", ".", "format", "(", "\n", "iteration", ",", "self", ".", "config", ".", "epsilon", ",", "avg_attacker_episode_rewards", ",", "avg_defender_episode_rewards", ",", "\n", "avg_episode_steps", ",", "hack_probability", ",", "attacker_cumulative_reward", ",", "defender_cumulative_reward", ",", "\n", "avg_episode_attacker_loss", ",", "avg_episode_defender_loss", ",", "lr_attacker", ",", "lr_defender", ",", "hack_probability_total", ",", "\n", "train_attacker", ",", "\n", "train_defender", ",", "a_pool", ",", "d_pool", ",", "total_num_episodes", ")", "\n", "self", ".", "outer_train", ".", "set_description_str", "(", "log_str", ")", "\n", "", "self", ".", "config", ".", "logger", ".", "info", "(", "log_str", ")", "\n", "if", "update_stats", "and", "self", ".", "config", ".", "tensorboard", ":", "\n", "            ", "self", ".", "log_tensorboard", "(", "iteration", ",", "avg_attacker_episode_rewards", ",", "avg_defender_episode_rewards", ",", "avg_episode_steps", ",", "\n", "avg_episode_attacker_loss", ",", "avg_episode_defender_loss", ",", "hack_probability", ",", "\n", "attacker_cumulative_reward", ",", "defender_cumulative_reward", ",", "self", ".", "config", ".", "epsilon", ",", "lr_attacker", ",", "\n", "lr_defender", ",", "hack_probability_total", ",", "a_pool", ",", "d_pool", ",", "eval", "=", "eval", ")", "\n", "", "if", "update_stats", ":", "\n", "            ", "result", ".", "avg_episode_steps", ".", "append", "(", "avg_episode_steps", ")", "\n", "result", ".", "avg_attacker_episode_rewards", ".", "append", "(", "avg_attacker_episode_rewards", ")", "\n", "result", ".", "avg_defender_episode_rewards", ".", "append", "(", "avg_defender_episode_rewards", ")", "\n", "result", ".", "epsilon_values", ".", "append", "(", "self", ".", "config", ".", "epsilon", ")", "\n", "result", ".", "hack_probability", ".", "append", "(", "hack_probability", ")", "\n", "result", ".", "cumulative_hack_probabiltiy", ".", "append", "(", "hack_probability_total", ")", "\n", "result", ".", "attacker_cumulative_reward", ".", "append", "(", "attacker_cumulative_reward", ")", "\n", "result", ".", "defender_cumulative_reward", ".", "append", "(", "defender_cumulative_reward", ")", "\n", "result", ".", "avg_episode_loss_attacker", ".", "append", "(", "avg_episode_attacker_loss", ")", "\n", "result", ".", "avg_episode_loss_defender", ".", "append", "(", "avg_episode_defender_loss", ")", "\n", "result", ".", "lr_list", ".", "append", "(", "lr_attacker", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.log_tensorboard": [[146, 195], ["pg_agent.PolicyGradientAgent.tensorboard_writer.add_scalar", "pg_agent.PolicyGradientAgent.tensorboard_writer.add_scalar", "pg_agent.PolicyGradientAgent.tensorboard_writer.add_scalar", "pg_agent.PolicyGradientAgent.tensorboard_writer.add_scalar", "pg_agent.PolicyGradientAgent.tensorboard_writer.add_scalar", "pg_agent.PolicyGradientAgent.tensorboard_writer.add_scalar", "pg_agent.PolicyGradientAgent.tensorboard_writer.add_scalar", "pg_agent.PolicyGradientAgent.tensorboard_writer.add_scalar", "pg_agent.PolicyGradientAgent.tensorboard_writer.add_scalar", "pg_agent.PolicyGradientAgent.tensorboard_writer.add_scalar", "pg_agent.PolicyGradientAgent.tensorboard_writer.add_scalar", "pg_agent.PolicyGradientAgent.tensorboard_writer.add_scalar", "pg_agent.PolicyGradientAgent.tensorboard_writer.add_scalar", "pg_agent.PolicyGradientAgent.tensorboard_writer.add_scalar"], "methods", ["None"], ["", "", "def", "log_tensorboard", "(", "self", ",", "episode", ":", "int", ",", "avg_attacker_episode_rewards", ":", "float", ",", "avg_defender_episode_rewards", ":", "float", ",", "\n", "avg_episode_steps", ":", "float", ",", "episode_avg_loss_attacker", ":", "float", ",", "episode_avg_loss_defender", ":", "float", ",", "\n", "hack_probability", ":", "float", ",", "attacker_cumulative_reward", ":", "int", ",", "defender_cumulative_reward", ":", "int", ",", "\n", "epsilon", ":", "float", ",", "lr_attacker", ":", "float", ",", "lr_defender", ":", "float", ",", "cumulative_hack_probability", ":", "float", ",", "\n", "a_pool", ":", "int", ",", "d_pool", ":", "int", ",", "eval", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Log metrics to tensorboard\n\n        :param episode: the episode\n        :param avg_attacker_episode_rewards: the average attacker episode reward\n        :param avg_defender_episode_rewards: the average defender episode reward\n        :param avg_episode_steps: the average number of episode steps\n        :param episode_avg_loss_attacker: the average episode loss of the attacker\n        :param episode_avg_loss_defender: the average episode loss of the defender\n        :param hack_probability: the hack probability\n        :param attacker_cumulative_reward: the cumulative attacker reward\n        :param defender_cumulative_reward: the cumulative defender reward\n        :param epsilon: the exploration rate\n        :param lr_attacker: the learning rate of the attacker\n        :param lr_defender: the learning rate of the defender\n        :param cumulative_hack_probability: the cumulative hack probability\n        :param eval: boolean flag whether eval or not\n        :param a_pool: size of the attacker opponent pool\n        :param d_pool: size of the defender opponent pool\n        :return: None\n        \"\"\"", "\n", "train_or_eval", "=", "\"eval\"", "if", "eval", "else", "\"train\"", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'avg_episode_rewards/'", "+", "train_or_eval", "+", "\"/attacker\"", ",", "\n", "avg_attacker_episode_rewards", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'avg_episode_rewards/'", "+", "train_or_eval", "+", "\"/defender\"", ",", "\n", "avg_defender_episode_rewards", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'episode_steps/'", "+", "train_or_eval", ",", "avg_episode_steps", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'episode_avg_loss/'", "+", "train_or_eval", "+", "\"/attacker\"", ",", "episode_avg_loss_attacker", ",", "\n", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'episode_avg_loss/'", "+", "train_or_eval", "+", "\"/defender\"", ",", "episode_avg_loss_defender", ",", "\n", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'hack_probability/'", "+", "train_or_eval", ",", "hack_probability", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'cumulative_hack_probability/'", "+", "train_or_eval", ",", "cumulative_hack_probability", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'cumulative_reward/attacker/'", "+", "train_or_eval", ",", "\n", "attacker_cumulative_reward", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'cumulative_reward/defender/'", "+", "train_or_eval", ",", "\n", "defender_cumulative_reward", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'epsilon'", ",", "epsilon", ",", "episode", ")", "\n", "if", "self", ".", "config", ".", "opponent_pool", "and", "a_pool", "is", "not", "None", "and", "d_pool", "is", "not", "None", "and", "not", "eval", ":", "\n", "            ", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'opponent_pool_size/attacker'", ",", "a_pool", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'opponent_pool_size/defender'", ",", "d_pool", ",", "episode", ")", "\n", "", "if", "not", "eval", ":", "\n", "            ", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'lr/attacker'", ",", "lr_attacker", ",", "episode", ")", "\n", "self", ".", "tensorboard_writer", ".", "add_scalar", "(", "'lr/defender'", ",", "lr_defender", ",", "episode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.anneal_epsilon": [[196, 204], ["None"], "methods", ["None"], ["", "", "def", "anneal_epsilon", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Anneals the exploration rate slightly until it reaches the minimum value\n\n        :return: None\n        \"\"\"", "\n", "if", "self", ".", "config", ".", "epsilon", ">", "self", ".", "config", ".", "min_epsilon", ":", "\n", "            ", "self", ".", "config", ".", "epsilon", "=", "self", ".", "config", ".", "epsilon", "*", "self", ".", "config", ".", "epsilon_decay", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.update_state": [[205, 427], ["pg_agent.PolicyGradientAgent.env.local_view_features", "pg_agent.PolicyGradientAgent.env.state.get_attacker_observation", "enumerate", "enumerate", "numpy.array", "numpy.array", "enumerate", "enumerate", "numpy.array", "numpy.array", "pg_agent.PolicyGradientAgent.env.local_view_features", "pg_agent.PolicyGradientAgent.env.fully_observed", "numpy.mean", "numpy.isnan().any", "zero_mean_attacker_features.append", "numpy.mean", "numpy.isnan().any", "zero_mean_defender_features.append", "numpy.isnan().any", "normalized_attacker_features.append", "numpy.isnan().any", "normalized_defender_features.append", "numpy.zeros", "range", "numpy.array", "numpy.append", "numpy.append", "len", "numpy.append", "numpy.append", "pg_agent.PolicyGradientAgent.env.local_view_features", "row.tolist.tolist", "row.tolist.tolist", "row.tolist.append", "pg_agent.PolicyGradientAgent.env.local_view_features", "numpy.linalg.norm", "numpy.linalg.norm", "row.tolist", "numpy.linalg.norm", "numpy.linalg.norm", "int", "enumerate", "enumerate", "numpy.zeros", "range", "len", "numpy.array", "numpy.array", "numpy.append", "len", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.isnan", "row.tolist.append", "row.tolist.append", "row.tolist.append", "numpy.isnan", "numpy.isnan", "row.tolist.append", "row.tolist.append", "row.tolist.append", "numpy.isnan", "row.tolist", "row.tolist.append", "pg_agent.PolicyGradientAgent.env.local_view_features", "row.tolist", "row.tolist.append", "pg_agent.PolicyGradientAgent.env.fully_observed", "numpy.array.append", "numpy.full", "range", "row.tolist", "row.tolist.append", "numpy.array.append", "numpy.append", "pg_agent.PolicyGradientAgent.env.local_view_features", "enumerate", "numpy.array", "numpy.zeros", "range", "numpy.zeros", "range", "pg_agent.PolicyGradientAgent.env.local_view_features", "pg_agent.PolicyGradientAgent.env.local_view_features", "row.tolist.append", "len", "row.tolist.append", "numpy.append", "numpy.array.append", "numpy.array", "numpy.zeros", "range", "numpy.append", "numpy.append", "numpy.sum", "numpy.append", "numpy.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.get_attacker_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.fully_observed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.fully_observed", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features"], ["", "", "def", "update_state", "(", "self", ",", "attacker_obs", ":", "np", ".", "ndarray", "=", "None", ",", "defender_obs", ":", "np", ".", "ndarray", "=", "None", ",", "\n", "state", ":", "np", ".", "ndarray", "=", "None", ",", "attacker", ":", "bool", "=", "True", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Update approximative Markov state\n\n        :param attacker_obs: attacker obs\n        :param defender_obs: defender observation\n        :param state: current state\n        :param attacker: boolean flag whether it is attacker or not\n        :return: new state\n        \"\"\"", "\n", "if", "attacker", "and", "self", ".", "env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "            ", "a_obs_len", "=", "self", ".", "env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", "\n", "defender_obs", "=", "attacker_obs", "[", ":", ",", "\n", "a_obs_len", ":", "a_obs_len", "+", "self", ".", "env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "]", "\n", "if", "self", ".", "env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ":", "\n", "                ", "d_bool_features", "=", "attacker_obs", "[", ":", ",", "\n", "a_obs_len", "+", "self", ".", "env", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ":", "]", "\n", "", "attacker_obs", "=", "attacker_obs", "[", ":", ",", "0", ":", "a_obs_len", "]", "\n", "\n", "", "if", "not", "attacker", "and", "self", ".", "env", ".", "local_view_features", "(", ")", ":", "\n", "            ", "attacker_obs", "=", "self", ".", "env", ".", "state", ".", "get_attacker_observation", "(", "\n", "self", ".", "env", ".", "idsgame_config", ".", "game_config", ".", "network_config", ",", "\n", "local_view", "=", "False", ",", "\n", "reconnaissance", "=", "self", ".", "env", ".", "idsgame_config", ".", "reconnaissance_actions", ")", "\n", "\n", "# Zero mean", "\n", "", "if", "self", ".", "config", ".", "zero_mean_features", ":", "\n", "            ", "if", "not", "self", ".", "env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                ", "attacker_obs_1", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "attacker_obs_1", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "2", "]", "\n", "", "zero_mean_attacker_features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "attacker_obs_1", ")", ":", "\n", "                ", "mean", "=", "np", ".", "mean", "(", "row", ")", "\n", "if", "mean", "!=", "0", ":", "\n", "                    ", "t", "=", "row", "-", "mean", "\n", "", "else", ":", "\n", "                    ", "t", "=", "row", "\n", "", "if", "np", ".", "isnan", "(", "t", ")", ".", "any", "(", ")", ":", "\n", "                    ", "t", "=", "attacker_obs", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "t", "=", "t", ".", "tolist", "(", ")", "\n", "if", "not", "self", ".", "env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                        ", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                        ", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "2", "]", ")", "\n", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "", "zero_mean_attacker_features", ".", "append", "(", "t", ")", "\n", "\n", "", "defender_obs_1", "=", "defender_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "zero_mean_defender_features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "defender_obs_1", ")", ":", "\n", "                ", "mean", "=", "np", ".", "mean", "(", "row", ")", "\n", "if", "mean", "!=", "0", ":", "\n", "                    ", "t", "=", "row", "-", "mean", "\n", "", "else", ":", "\n", "                    ", "t", "=", "row", "\n", "", "if", "np", ".", "isnan", "(", "t", ")", ".", "any", "(", ")", ":", "\n", "                    ", "t", "=", "defender_obs", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "t", "=", "t", ".", "tolist", "(", ")", "\n", "t", ".", "append", "(", "defender_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "zero_mean_defender_features", ".", "append", "(", "t", ")", "\n", "\n", "", "attacker_obs", "=", "np", ".", "array", "(", "zero_mean_attacker_features", ")", "\n", "defender_obs", "=", "np", ".", "array", "(", "zero_mean_defender_features", ")", "\n", "\n", "# Normalize", "\n", "", "if", "self", ".", "config", ".", "normalize_features", ":", "\n", "            ", "if", "not", "self", ".", "env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                ", "attacker_obs_1", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "/", "np", ".", "linalg", ".", "norm", "(", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "attacker_obs_1", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "2", "]", "/", "np", ".", "linalg", ".", "norm", "(", "attacker_obs", "[", ":", ",", "0", ":", "-", "2", "]", ")", "\n", "", "normalized_attacker_features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "attacker_obs_1", ")", ":", "\n", "                ", "if", "np", ".", "isnan", "(", "attacker_obs_1", ")", ".", "any", "(", ")", ":", "\n", "                    ", "t", "=", "attacker_obs", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "if", "not", "self", ".", "env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                        ", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                        ", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "2", "]", ")", "\n", "t", ".", "append", "(", "attacker_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "", "normalized_attacker_features", ".", "append", "(", "t", ")", "\n", "\n", "", "if", "attacker", "and", "self", ".", "env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                ", "defender_obs_1", "=", "defender_obs", "[", ":", ",", "0", ":", "-", "1", "]", "/", "np", ".", "linalg", ".", "norm", "(", "defender_obs", "[", ":", ",", "0", ":", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "defender_obs_1", "=", "defender_obs", "/", "np", ".", "linalg", ".", "norm", "(", "defender_obs", ")", "\n", "", "normalized_defender_features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "defender_obs_1", ")", ":", "\n", "                ", "if", "np", ".", "isnan", "(", "defender_obs_1", ")", ".", "any", "(", ")", ":", "\n", "                    ", "t", "=", "defender_obs", "[", "idx", "]", "\n", "", "else", ":", "\n", "                    ", "if", "attacker", "and", "self", ".", "env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "t", ".", "append", "(", "defender_obs", "[", "idx", "]", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "                        ", "t", "=", "row", "\n", "\n", "", "", "normalized_defender_features", ".", "append", "(", "t", ")", "\n", "\n", "", "attacker_obs", "=", "np", ".", "array", "(", "normalized_attacker_features", ")", "\n", "defender_obs", "=", "np", ".", "array", "(", "normalized_defender_features", ")", "\n", "\n", "", "if", "self", ".", "env", ".", "local_view_features", "(", ")", "and", "attacker", ":", "\n", "            ", "if", "not", "self", ".", "env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                ", "neighbor_defense_attributes", "=", "np", ".", "zeros", "(", "(", "attacker_obs", ".", "shape", "[", "0", "]", ",", "defender_obs", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "node", "in", "range", "(", "attacker_obs", ".", "shape", "[", "0", "]", ")", ":", "\n", "                    ", "id", "=", "int", "(", "attacker_obs", "[", "node", "]", "[", "-", "1", "]", ")", "\n", "neighbor_defense_attributes", "[", "node", "]", "=", "defender_obs", "[", "id", "]", "\n", "", "", "else", ":", "\n", "                ", "neighbor_defense_attributes", "=", "defender_obs", "\n", "\n", "", "", "if", "self", ".", "env", ".", "fully_observed", "(", ")", "or", "(", "self", ".", "env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", "and", "attacker", ")", ":", "\n", "            ", "if", "self", ".", "config", ".", "merged_ad_features", ":", "\n", "                ", "if", "not", "self", ".", "env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                    ", "a_pos", "=", "attacker_obs", "[", ":", ",", "-", "1", "]", "\n", "if", "not", "self", ".", "env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "det_values", "=", "defender_obs", "[", ":", ",", "-", "1", "]", "\n", "temp", "=", "defender_obs", "[", ":", ",", "0", ":", "-", "1", "]", "-", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                        ", "temp", "=", "defender_obs", "[", ":", ",", "0", ":", "]", "-", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "temp", ")", ":", "\n", "                        ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "t", ".", "append", "(", "a_pos", "[", "idx", "]", ")", "\n", "if", "self", ".", "env", ".", "fully_observed", "(", ")", ":", "\n", "                            ", "t", ".", "append", "(", "det_values", "[", "idx", "]", ")", "\n", "", "features", ".", "append", "(", "t", ")", "\n", "", "", "else", ":", "\n", "                    ", "node_ids", "=", "attacker_obs", "[", ":", ",", "-", "1", "]", "\n", "if", "not", "self", ".", "env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "det_values", "=", "neighbor_defense_attributes", "[", ":", ",", "-", "1", "]", "\n", "", "if", "not", "self", ".", "env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "temp", "=", "neighbor_defense_attributes", "[", ":", ",", "0", ":", "-", "1", "]", "-", "attacker_obs", "[", ":", ",", "0", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                        ", "temp", "=", "np", ".", "full", "(", "neighbor_defense_attributes", ".", "shape", ",", "-", "1", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "neighbor_defense_attributes", ")", ")", ":", "\n", "                            ", "if", "np", ".", "sum", "(", "neighbor_defense_attributes", "[", "i", "]", ")", ">", "0", ":", "\n", "                                ", "temp", "[", "i", "]", "=", "neighbor_defense_attributes", "[", "i", "]", "-", "attacker_obs", "[", "i", ",", "0", ":", "-", "1", "]", "\n", "", "", "", "features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "temp", ")", ":", "\n", "                        ", "t", "=", "row", ".", "tolist", "(", ")", "\n", "t", ".", "append", "(", "node_ids", "[", "idx", "]", ")", "\n", "# t.append(node_reachable[idx])", "\n", "if", "not", "self", ".", "env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ":", "\n", "                            ", "t", ".", "append", "(", "det_values", "[", "idx", "]", ")", "\n", "", "features", ".", "append", "(", "t", ")", "\n", "", "", "features", "=", "np", ".", "array", "(", "features", ")", "\n", "if", "self", ".", "env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ":", "\n", "                    ", "f", "=", "np", ".", "zeros", "(", "(", "features", ".", "shape", "[", "0", "]", ",", "features", ".", "shape", "[", "1", "]", "+", "d_bool_features", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "features", ".", "shape", "[", "0", "]", ")", ":", "\n", "                        ", "f", "[", "i", "]", "=", "np", ".", "append", "(", "features", "[", "i", "]", ",", "d_bool_features", "[", "i", "]", ")", "\n", "", "features", "=", "f", "\n", "", "if", "self", ".", "config", ".", "state_length", "==", "1", ":", "\n", "                    ", "return", "features", "\n", "", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "s", "=", "np", ".", "array", "(", "[", "features", "]", "*", "self", ".", "config", ".", "state_length", ")", "\n", "return", "s", "\n", "", "state", "=", "np", ".", "append", "(", "state", "[", "1", ":", "]", ",", "np", ".", "array", "(", "[", "features", "]", ")", ",", "axis", "=", "0", ")", "\n", "return", "state", "\n", "", "else", ":", "\n", "                ", "if", "not", "self", ".", "env", ".", "local_view_features", "(", ")", "or", "not", "attacker", ":", "\n", "                    ", "if", "self", ".", "env", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", "and", "attacker", ":", "\n", "                        ", "combined_features", "=", "[", "]", "\n", "for", "idx", ",", "row", "in", "enumerate", "(", "attacker_obs", ")", ":", "\n", "                            ", "combined_row", "=", "np", ".", "append", "(", "row", ",", "defender_obs", "[", "idx", "]", ")", "\n", "combined_features", ".", "append", "(", "combined_row", ")", "\n", "", "if", "self", ".", "env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ":", "\n", "                            ", "combined_features", "=", "np", ".", "array", "(", "combined_features", ")", "\n", "f", "=", "np", ".", "zeros", "(", "\n", "(", "combined_features", ".", "shape", "[", "0", "]", ",", "combined_features", ".", "shape", "[", "1", "]", "+", "d_bool_features", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "combined_features", ".", "shape", "[", "0", "]", ")", ":", "\n", "                                ", "f", "[", "i", "]", "=", "np", ".", "append", "(", "combined_features", "[", "i", "]", ",", "d_bool_features", "[", "i", "]", ")", "\n", "", "combined_features", "=", "f", "\n", "", "return", "np", ".", "array", "(", "combined_features", ")", "\n", "\n", "", "return", "np", ".", "append", "(", "attacker_obs", ",", "defender_obs", ")", "\n", "", "else", ":", "\n", "                    ", "if", "self", ".", "env", ".", "idsgame_config", ".", "reconnaissance_bool_features", ":", "\n", "                        ", "f", "=", "np", ".", "zeros", "(", "(", "attacker_obs", ".", "shape", "[", "0", "]", ",", "\n", "attacker_obs", ".", "shape", "[", "1", "]", "+", "neighbor_defense_attributes", ".", "shape", "[", "1", "]", "+", "\n", "d_bool_features", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "f", ".", "shape", "[", "0", "]", ")", ":", "\n", "                            ", "f", "[", "i", "]", "=", "np", ".", "append", "(", "np", ".", "append", "(", "attacker_obs", "[", "i", "]", ",", "neighbor_defense_attributes", "[", "i", "]", ")", ",", "\n", "d_bool_features", "[", "i", "]", ")", "\n", "", "", "else", ":", "\n", "                        ", "f", "=", "np", ".", "zeros", "(", "(", "attacker_obs", ".", "shape", "[", "0", "]", ",", "\n", "attacker_obs", ".", "shape", "[", "1", "]", "+", "neighbor_defense_attributes", ".", "shape", "[", "1", "]", ")", ")", "\n", "for", "i", "in", "range", "(", "f", ".", "shape", "[", "0", "]", ")", ":", "\n", "                            ", "f", "[", "i", "]", "=", "np", ".", "append", "(", "attacker_obs", "[", "i", "]", ",", "neighbor_defense_attributes", "[", "i", "]", ")", "\n", "", "", "", "if", "self", ".", "config", ".", "state_length", "==", "1", ":", "\n", "                    ", "return", "f", "\n", "", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                    ", "s", "=", "np", ".", "array", "(", "[", "f", "]", "*", "self", ".", "config", ".", "state_length", ")", "\n", "return", "s", "\n", "# if not self.env.local_view_features() or not attacker:", "\n", "#     temp = np.append(attacker_obs, defender_obs)", "\n", "# else:", "\n", "#     temp = np.append(attacker_obs, neighbor_defense_attributes)", "\n", "", "state", "=", "np", ".", "append", "(", "state", "[", "1", ":", "]", ",", "np", ".", "array", "(", "[", "f", "]", ")", ",", "axis", "=", "0", ")", "\n", "", "return", "state", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "config", ".", "state_length", "==", "1", ":", "\n", "                ", "if", "attacker", ":", "\n", "                    ", "return", "np", ".", "array", "(", "attacker_obs", ")", "\n", "", "else", ":", "\n", "                    ", "return", "np", ".", "array", "(", "defender_obs", ")", "\n", "", "", "if", "len", "(", "state", ")", "==", "0", ":", "\n", "                ", "if", "attacker", ":", "\n", "                    ", "return", "np", ".", "array", "(", "[", "attacker_obs", "]", "*", "self", ".", "config", ".", "state_length", ")", "\n", "", "else", ":", "\n", "                    ", "return", "np", ".", "array", "(", "[", "defender_obs", "]", "*", "self", ".", "config", ".", "state_length", ")", "\n", "", "", "if", "attacker", ":", "\n", "                ", "state", "=", "np", ".", "append", "(", "state", "[", "1", ":", "]", ",", "np", ".", "array", "(", "[", "attacker_obs", "]", ")", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "state", "=", "np", ".", "append", "(", "state", "[", "1", ":", "]", ",", "np", ".", "array", "(", "[", "defender_obs", "]", ")", ",", "axis", "=", "0", ")", "\n", "", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_legal_attacker_actions": [[429, 448], ["range", "len", "pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global", "pg_agent.PolicyGradientAgent.env.is_attack_legal", "int", "range", "range", "legal_actions_2.append", "illegal_actions.append", "legal_actions.append", "illegal_actions.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal"], ["", "", "def", "get_legal_attacker_actions", "(", "self", ",", "attacker_obs", ")", ":", "\n", "        ", "legal_actions", "=", "[", "]", "\n", "illegal_actions", "=", "[", "]", "\n", "num_attack_types", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "2", "]", ".", "shape", "[", "1", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "attacker_obs", ")", ")", ":", "\n", "            ", "if", "int", "(", "attacker_obs", "[", "i", "]", "[", "-", "1", "]", ")", "==", "1", ":", "\n", "                ", "for", "ac", "in", "range", "(", "num_attack_types", ")", ":", "\n", "                    ", "legal_actions", ".", "append", "(", "i", "*", "num_attack_types", "+", "ac", ")", "\n", "", "", "else", ":", "\n", "                ", "for", "ac", "in", "range", "(", "num_attack_types", ")", ":", "\n", "                    ", "illegal_actions", ".", "append", "(", "i", "*", "num_attack_types", "+", "ac", ")", "\n", "", "", "", "legal_actions_2", "=", "[", "]", "\n", "for", "action", "in", "legal_actions", ":", "\n", "            ", "global_action", "=", "PolicyGradientAgent", ".", "convert_local_attacker_action_to_global", "(", "action", ",", "attacker_obs", ")", "\n", "if", "self", ".", "env", ".", "is_attack_legal", "(", "global_action", ")", ":", "\n", "                ", "legal_actions_2", ".", "append", "(", "action", ")", "\n", "", "else", ":", "\n", "                ", "illegal_actions", ".", "append", "(", "action", ")", "\n", "", "", "return", "legal_actions_2", ",", "illegal_actions", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.convert_local_attacker_action_to_global": [[449, 457], ["int"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "convert_local_attacker_action_to_global", "(", "action_id", ",", "attacker_obs", ")", ":", "\n", "        ", "num_attack_types", "=", "attacker_obs", "[", ":", ",", "0", ":", "-", "2", "]", ".", "shape", "[", "1", "]", "\n", "neighbor", "=", "action_id", "//", "num_attack_types", "\n", "attack_type", "=", "action_id", "%", "num_attack_types", "\n", "target_id", "=", "int", "(", "attacker_obs", "[", "neighbor", "]", "[", "-", "2", "]", ")", "\n", "attacker_action", "=", "target_id", "*", "num_attack_types", "+", "attack_type", "\n", "return", "attacker_action", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.get_action": [[458, 461], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "get_action", "(", "self", ",", "s", ",", "eval", "=", "False", ",", "attacker", "=", "True", ")", "->", "int", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.train": [[462, 465], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "train", "(", "self", ")", "->", "ExperimentResult", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent.PolicyGradientAgent.eval": [[466, 469], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "eval", "(", "self", ",", "log", "=", "True", ")", "->", "ExperimentResult", ":", "\n", "        ", "pass", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.__init__": [[12, 255], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "gamma", ":", "float", "=", "0.8", ",", "alpha_attacker", ":", "float", "=", "0.1", ",", "alpha_defender", ":", "float", "=", "0.1", ",", "\n", "epsilon", ":", "float", "=", "0.9", ",", "render", ":", "bool", "=", "False", ",", "\n", "eval_sleep", ":", "float", "=", "0.35", ",", "\n", "epsilon_decay", ":", "float", "=", "0.999", ",", "min_epsilon", ":", "float", "=", "0.1", ",", "eval_episodes", ":", "int", "=", "1", ",", "\n", "train_log_frequency", ":", "int", "=", "100", ",", "\n", "eval_log_frequency", ":", "int", "=", "1", ",", "video", ":", "bool", "=", "False", ",", "video_fps", ":", "int", "=", "5", ",", "video_dir", ":", "bool", "=", "None", ",", "\n", "num_episodes", ":", "int", "=", "5000", ",", "\n", "eval_render", ":", "bool", "=", "False", ",", "gifs", ":", "bool", "=", "False", ",", "gif_dir", ":", "str", "=", "None", ",", "eval_frequency", ":", "int", "=", "1000", ",", "\n", "video_frequency", ":", "int", "=", "101", ",", "attacker", ":", "bool", "=", "True", ",", "defender", ":", "bool", "=", "False", ",", "\n", "save_dir", ":", "str", "=", "None", ",", "attacker_load_path", ":", "str", "=", "None", ",", "defender_load_path", ":", "str", "=", "None", ",", "\n", "checkpoint_freq", ":", "int", "=", "100000", ",", "random_seed", ":", "int", "=", "0", ",", "eval_epsilon", ":", "float", "=", "0.0", ",", "\n", "input_dim_attacker", ":", "int", "=", "30", ",", "output_dim_attacker", ":", "int", "=", "30", ",", "output_dim_defender", ":", "int", "=", "33", ",", "\n", "input_dim_defender", ":", "int", "=", "30", ",", "\n", "hidden_dim", ":", "int", "=", "64", ",", "\n", "batch_size", ":", "int", "=", "64", ",", "num_hidden_layers", "=", "2", ",", "\n", "gpu", ":", "bool", "=", "False", ",", "tensorboard", ":", "bool", "=", "False", ",", "tensorboard_dir", ":", "str", "=", "\"\"", ",", "\n", "optimizer", ":", "str", "=", "\"Adam\"", ",", "lr_exp_decay", ":", "bool", "=", "False", ",", "\n", "lr_decay_rate", ":", "float", "=", "0.96", ",", "hidden_activation", ":", "str", "=", "\"ReLU\"", ",", "clip_gradient", "=", "False", ",", "\n", "max_gradient_norm", "=", "40", ",", "critic_loss_fn", ":", "str", "=", "\"MSE\"", ",", "state_length", "=", "1", ",", "\n", "alternating_optimization", ":", "bool", "=", "False", ",", "alternating_period", ":", "int", "=", "15000", ",", "\n", "opponent_pool", ":", "bool", "=", "False", ",", "opponent_pool_config", ":", "OpponentPoolConfig", "=", "None", ",", "\n", "normalize_features", ":", "bool", "=", "False", ",", "gpu_id", ":", "int", "=", "0", ",", "merged_ad_features", ":", "bool", "=", "False", ",", "\n", "optimization_iterations", ":", "int", "=", "28", ",", "eps_clip", ":", "float", "=", "0.2", ",", "zero_mean_features", ":", "bool", "=", "False", ",", "\n", "lstm_network", ":", "bool", "=", "False", ",", "lstm_seq_length", ":", "int", "=", "4", ",", "num_lstm_layers", ":", "int", "=", "4", ",", "\n", "gae_lambda", ":", "float", "=", "0.95", ",", "cnn_feature_extractor", ":", "bool", "=", "False", ",", "features_dim", ":", "int", "=", "44", ",", "\n", "flatten_feature_planes", ":", "bool", "=", "False", ",", "cnn_type", ":", "int", "=", "0", ",", "ent_coef", ":", "float", "=", "0.0", ",", "\n", "vf_coef", ":", "float", "=", "0.5", ",", "render_attacker_view", ":", "bool", "=", "False", ",", "lr_progress_decay", ":", "bool", "=", "False", ",", "\n", "lr_progress_power_decay", ":", "int", "=", "1", ",", "use_sde", ":", "bool", "=", "False", ",", "sde_sample_freq", ":", "int", "=", "4", ",", "\n", "seq_cnn", ":", "bool", "=", "False", ",", "baselines_in_pool", ":", "bool", "=", "False", ",", "one_hot_obs", ":", "bool", "=", "False", ",", "\n", "grid_image_obs", ":", "bool", "=", "False", ",", "force_exploration", ":", "bool", "=", "False", ",", "force_exp_p", ":", "float", "=", "0.05", ",", "\n", "lstm_core", ":", "bool", "=", "False", ",", "lstm_hidden_dim", ":", "int", "=", "64", ",", "pi_hidden_layers", ":", "int", "=", "2", ",", "\n", "pi_hidden_dim", ":", "int", "=", "64", ",", "vf_hidden_layers", ":", "int", "=", "2", ",", "vf_hidden_dim", ":", "int", "=", "64", ",", "\n", "multi_channel_obs", ":", "bool", "=", "False", ",", "\n", "channel_1_layers", ":", "int", "=", "2", ",", "channel_1_dim", ":", "int", "=", "64", ",", "channel_1_input_dim", ":", "int", "=", "4", ",", "\n", "channel_2_layers", ":", "int", "=", "2", ",", "channel_2_dim", ":", "int", "=", "64", ",", "channel_2_input_dim", ":", "int", "=", "4", ",", "\n", "channel_3_layers", ":", "int", "=", "2", ",", "channel_3_dim", ":", "int", "=", "64", ",", "channel_3_input_dim", ":", "int", "=", "4", ",", "\n", "channel_4_layers", ":", "int", "=", "2", ",", "channel_4_dim", ":", "int", "=", "64", ",", "channel_4_input_dim", ":", "int", "=", "4", ",", "\n", "mini_batch_size", ":", "int", "=", "64", ",", "ar_policy", ":", "bool", "=", "False", ",", "attacker_node_input_dim", ":", "int", "=", "64", ",", "\n", "attacker_at_net_input_dim", ":", "int", "=", "64", ",", "attacker_node_net_output_dim", "=", "4", ",", "attacker_at_net_output_dim", "=", "4", ",", "\n", "attacker_node_net_multi_channel", ":", "bool", "=", "False", ",", "attacker_at_net_multi_channel", ":", "bool", "=", "False", ",", "\n", "attacker_node_net_lstm_core", ":", "bool", "=", "False", ",", "attacker_at_net_lstm_core", ":", "bool", "=", "False", ",", "\n", "defender_node_input_dim", ":", "int", "=", "64", ",", "\n", "defender_at_net_input_dim", ":", "int", "=", "64", ",", "defender_node_net_output_dim", "=", "4", ",", "defender_at_net_output_dim", "=", "4", ",", "\n", "defender_node_net_multi_channel", ":", "bool", "=", "False", ",", "defender_at_net_multi_channel", ":", "bool", "=", "False", ",", "\n", "defender_node_net_lstm_core", ":", "bool", "=", "False", ",", "defender_at_net_lstm_core", ":", "bool", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"\n        Initialize environment and hyperparameters\n\n        :param gamma: the discount factor\n        :param alpha_attacker: the learning rate of the attacker\n        :param alpha_defender: the learning rate of the defender\n        :param epsilon: the exploration rate\n        :param render: whether to render the environment *during training*\n        :param eval_sleep: amount of sleep between time-steps during evaluation and rendering\n        :param epsilon_decay: rate of decay of epsilon\n        :param min_epsilon: minimum epsilon rate\n        :param eval_episodes: number of evaluation episodes\n        :param train_log_frequency: number of episodes between logs during train\n        :param eval_log_frequency: number of episodes between logs during eval\n        :param video: boolean flag whether to record video of the evaluation.\n        :param video_dir: path where to save videos (will overwrite)\n        :param gif_dir: path where to save gifs (will overwrite)\n        :param num_episodes: number of training epochs\n        :param eval_render: whether to render the game during evaluation or not\n                            (perhaps set to False if video is recorded instead)\n        :param gifs: boolean flag whether to save gifs during evaluation or not\n        :param eval_frequency: the frequency (episodes) when running evaluation\n        :param video_frequency: the frequency (eval episodes) to record video and gif\n        :param attacker: True if the QAgent is an attacker\n        :param attacker: True if the QAgent is a defender\n        :param save_dir: dir to save Q-table\n        :param attacker_load_path: path to load a saved Q-table of the attacker\n        :param defender_load_path: path to load a saved Q-table of the defender\n        :param checkpoint_freq: frequency of checkpointing the model (episodes)\n        :param random_seed: the random seed for reproducibility\n        :param eval_epsilon: evaluation epsilon for implementing a \"soft policy\" rather than a \"greedy policy\"\n        :param input_dim_attacker: input dimension of the policy network for the attacker\n        :param input_dim_defender: input dimension of the policy network for the defender\n        :param output_dim_attacker: output dimensions of the policy network of the attacker\n        :param output_dim_defender: output dimensions of the policy network of the defender\n        :param hidden_dim: hidden dimension of the policy network\n        :param num_hidden_layers: number of hidden layers\n        :param batch_size: the batch size during training\n        :param gpu: boolean flag whether using GPU or not\n        :param tensorboard: boolean flag whether using tensorboard logging or not\n        :param tensorboard_dir: tensorboard logdir\n        :param optimizer: optimizer\n        :param lr_exp_decay: whether to use exponential decay of learning rate or not\n        :param lr_decay_rate: decay rate of lr\n        :param hidden_activation: the activation function for hidden units\n        :param clip_gradient: boolean flag whether to clip gradient or not\n        :param max_gradient_norm: max norm of gradient before clipping it\n        :param critic_loss_fn: loss function for the critic\n        :param state_length: length of observations to use for approximative Markov state\n        :param alternating_optimization: boolean flag whether using alteranting optimization or not\n        :param alternating_period: period for alternating between training attacker and defender\n        :param opponent_pool: boolean flag whether using opponent pool or not\n        :param opponent_pool_config: DTO with config when training against opponent pool\n        :param normalize_features: boolean flag that indicates whether features should be normalized or not\n        :param gpu_id: id of the GPU to use\n        :param merged_ad_features: a boolean flag indicating whether features in fully observed environments\n                                   should pre preprocessed by subtracting defense values with attack values\n        :param optimization_iterations: number of optimization iterations, this correspond to \"K\" in PPO\n        :param eps_clip: clip parameter for PPO\n        :param zero_mean_features: boolean flag whether to zero mean the features\n        :param lstm_network: boolean flag whether to use the LSTM network\n        :param lstm_seq_length: sequence length for LSTM\n        :param num_lstm_layers: number of LSTM layers (for stacked LSTM)\n        :param gae_lambda: gae_lambda parameter of PPO\n        :param cnn_feature_extractor: boolean flag, if true, use CNN instead of MLP or LSTM\n        :param features_dim: number of features in final layer of CNN before softmax\n        :param flatten_feature_planes: boolean flag whether to use a flat input of all feature planes used for CNN\n        :param cnn_type: type of CNN\n        :param ent_coef: entropy coefficient for PPO\n        :param vf_coef: value coefficient for PPO\n        :param render_attacker_view: if True, show attacker view when rendering rather than spectator view\n        :param lr_progress_decay: boolean flag whether learning rate is decayed with respect to progress\n        :param lr_progress_power_decay: the power that the progress is raised before lr decay\n        :param use_sde: boolean flag whether to use state-dependent exploration\n        :param sde_sample_freq: frequency of sampling in state-dependent exploration\n        :param seq_cnn: boolean flag whether to use sequence-like frame input\n        :param baselines_in_pool: boolean flag whether to include baseline policies in opponent pool\n        :param one_hot_obs: if true, use one hot encoded features\n        :param grid_image_obs: if true, use grid image obs\n        :param force_exploration: boolean flag whether to force exploration actions during training\n        :param force_exp_p: probability of forceful exploration actions during training\n        \"\"\"", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "alpha_attacker", "=", "alpha_attacker", "\n", "self", ".", "alpha_defender", "=", "alpha_defender", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "render", "=", "render", "\n", "self", ".", "eval_sleep", "=", "eval_sleep", "\n", "self", ".", "epsilon_decay", "=", "epsilon_decay", "\n", "self", ".", "min_epsilon", "=", "min_epsilon", "\n", "self", ".", "eval_episodes", "=", "eval_episodes", "\n", "self", ".", "train_log_frequency", "=", "train_log_frequency", "\n", "self", ".", "eval_log_frequency", "=", "eval_log_frequency", "\n", "self", ".", "video", "=", "video", "\n", "self", ".", "video_fps", "=", "video_fps", "\n", "self", ".", "video_dir", "=", "video_dir", "\n", "self", ".", "num_episodes", "=", "num_episodes", "\n", "self", ".", "eval_render", "=", "eval_render", "\n", "self", ".", "gifs", "=", "gifs", "\n", "self", ".", "gif_dir", "=", "gif_dir", "\n", "self", ".", "eval_frequency", "=", "eval_frequency", "\n", "self", ".", "logger", "=", "None", "\n", "self", ".", "video_frequency", "=", "video_frequency", "\n", "self", ".", "attacker", "=", "attacker", "\n", "self", ".", "defender", "=", "defender", "\n", "self", ".", "save_dir", "=", "save_dir", "\n", "self", ".", "attacker_load_path", "=", "attacker_load_path", "\n", "self", ".", "defender_load_path", "=", "defender_load_path", "\n", "self", ".", "checkpoint_freq", "=", "checkpoint_freq", "\n", "self", ".", "random_seed", "=", "random_seed", "\n", "self", ".", "eval_epsilon", "=", "eval_epsilon", "\n", "self", ".", "input_dim_attacker", "=", "input_dim_attacker", "\n", "self", ".", "input_dim_defender", "=", "input_dim_defender", "\n", "self", ".", "output_dim_attacker", "=", "output_dim_attacker", "\n", "self", ".", "output_dim_defender", "=", "output_dim_defender", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "\n", "self", ".", "gpu", "=", "gpu", "\n", "self", ".", "tensorboard", "=", "tensorboard", "\n", "self", ".", "tensorboard_dir", "=", "tensorboard_dir", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "lr_exp_decay", "=", "lr_exp_decay", "\n", "self", ".", "lr_decay_rate", "=", "lr_decay_rate", "\n", "self", ".", "hidden_activation", "=", "hidden_activation", "\n", "self", ".", "clip_gradient", "=", "clip_gradient", "\n", "self", ".", "max_gradient_norm", "=", "max_gradient_norm", "\n", "self", ".", "critic_loss_fn", "=", "critic_loss_fn", "\n", "self", ".", "state_length", "=", "state_length", "\n", "self", ".", "alternating_optimization", "=", "alternating_optimization", "\n", "self", ".", "alternating_period", "=", "alternating_period", "\n", "self", ".", "opponent_pool", "=", "opponent_pool", "\n", "self", ".", "opponent_pool_config", "=", "opponent_pool_config", "\n", "self", ".", "normalize_features", "=", "normalize_features", "\n", "self", ".", "gpu_id", "=", "gpu_id", "\n", "self", ".", "merged_ad_features", "=", "merged_ad_features", "\n", "self", ".", "optimization_iterations", "=", "optimization_iterations", "\n", "self", ".", "eps_clip", "=", "eps_clip", "\n", "self", ".", "zero_mean_features", "=", "zero_mean_features", "\n", "self", ".", "lstm_network", "=", "lstm_network", "\n", "self", ".", "lstm_seq_length", "=", "lstm_seq_length", "\n", "self", ".", "num_lstm_layers", "=", "num_lstm_layers", "\n", "self", ".", "gae_lambda", "=", "gae_lambda", "\n", "self", ".", "cnn_feature_extractor", "=", "cnn_feature_extractor", "\n", "self", ".", "features_dim", "=", "features_dim", "\n", "self", ".", "flatten_feature_planes", "=", "flatten_feature_planes", "\n", "self", ".", "cnn_type", "=", "cnn_type", "\n", "self", ".", "ent_coef", "=", "ent_coef", "\n", "self", ".", "vf_coef", "=", "vf_coef", "\n", "self", ".", "render_attacker_view", "=", "render_attacker_view", "\n", "self", ".", "lr_progress_decay", "=", "lr_progress_decay", "\n", "self", ".", "lr_progress_power_decay", "=", "lr_progress_power_decay", "\n", "self", ".", "use_sde", "=", "use_sde", "\n", "self", ".", "sde_sample_freq", "=", "sde_sample_freq", "\n", "self", ".", "seq_cnn", "=", "seq_cnn", "\n", "self", ".", "baselines_in_pool", "=", "baselines_in_pool", "\n", "self", ".", "one_hot_obs", "=", "one_hot_obs", "\n", "self", ".", "grid_image_obs", "=", "grid_image_obs", "\n", "self", ".", "force_exploration", "=", "force_exploration", "\n", "self", ".", "force_exp_p", "=", "force_exp_p", "\n", "self", ".", "lstm_core", "=", "lstm_core", "\n", "self", ".", "lstm_hidden_dim", "=", "lstm_hidden_dim", "\n", "self", ".", "pi_hidden_layers", "=", "pi_hidden_layers", "\n", "self", ".", "pi_hidden_dim", "=", "pi_hidden_dim", "\n", "self", ".", "vf_hidden_layers", "=", "vf_hidden_layers", "\n", "self", ".", "vf_hidden_dim", "=", "vf_hidden_dim", "\n", "self", ".", "multi_channel_obs", "=", "multi_channel_obs", "\n", "self", ".", "channel_1_layers", "=", "channel_1_layers", "\n", "self", ".", "channel_1_dim", "=", "channel_1_dim", "\n", "self", ".", "channel_1_input_dim", "=", "channel_1_input_dim", "\n", "self", ".", "channel_2_layers", "=", "channel_2_layers", "\n", "self", ".", "channel_2_dim", "=", "channel_2_dim", "\n", "self", ".", "channel_2_input_dim", "=", "channel_2_input_dim", "\n", "self", ".", "channel_3_layers", "=", "channel_3_layers", "\n", "self", ".", "channel_3_dim", "=", "channel_3_dim", "\n", "self", ".", "channel_3_input_dim", "=", "channel_3_input_dim", "\n", "self", ".", "channel_4_layers", "=", "channel_4_layers", "\n", "self", ".", "channel_4_dim", "=", "channel_4_dim", "\n", "self", ".", "channel_4_input_dim", "=", "channel_4_input_dim", "\n", "self", ".", "mini_batch_size", "=", "mini_batch_size", "\n", "self", ".", "ar_policy", "=", "ar_policy", "\n", "self", ".", "attacker_at_net_input_dim", "=", "attacker_at_net_input_dim", "\n", "self", ".", "attacker_node_net_input_dim", "=", "attacker_node_input_dim", "\n", "self", ".", "attacker_node_net_output_dim", "=", "attacker_node_net_output_dim", "\n", "self", ".", "attacker_at_net_output_dim", "=", "attacker_at_net_output_dim", "\n", "self", ".", "attacker_node_net_multi_channel", "=", "attacker_node_net_multi_channel", "\n", "self", ".", "attacker_at_net_multi_channel", "=", "attacker_at_net_multi_channel", "\n", "self", ".", "attacker_node_net_lstm_core", "=", "attacker_node_net_lstm_core", "\n", "self", ".", "attacker_at_net_lstm_core", "=", "attacker_at_net_lstm_core", "\n", "self", ".", "defender_at_net_input_dim", "=", "defender_at_net_input_dim", "\n", "self", ".", "defender_node_net_input_dim", "=", "defender_node_input_dim", "\n", "self", ".", "defender_node_net_output_dim", "=", "defender_node_net_output_dim", "\n", "self", ".", "defender_at_net_output_dim", "=", "defender_at_net_output_dim", "\n", "self", ".", "defender_node_net_multi_channel", "=", "defender_node_net_multi_channel", "\n", "self", ".", "defender_at_net_multi_channel", "=", "defender_at_net_multi_channel", "\n", "self", ".", "defender_node_net_lstm_core", "=", "defender_node_net_lstm_core", "\n", "self", ".", "defender_at_net_lstm_core", "=", "defender_at_net_lstm_core", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_str": [[257, 289], ["None"], "methods", ["None"], ["", "def", "to_str", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        :return: a string with information about all of the parameters\n        \"\"\"", "\n", "return", "\"Hyperparameters: gamma:{0},alpha_attacker:{1},epsilon:{2},render:{3},eval_sleep:{4},\"", "\"epsilon_decay:{5},min_epsilon:{6},eval_episodes:{7},train_log_frequency:{8},\"", "\"eval_log_frequency:{9},video:{10},video_fps:{11},\"", "\"video_dir:{12},num_episodes:{13},eval_render:{14},gifs:{15},\"", "\"gifdir:{16},eval_frequency:{17},video_frequency:{18},attacker{19},defender:{20},\"", "\"checkpoint_freq:{21},random_seed:{22},eval_epsilon:{23},clip_gradient:{24},max_gradient_norm:{25},\"", "\"output_dim_defender:{26},critic_loss_fn:{27},state_length:{28},alternating_optimization:{29},\"", "\"alternating_period:{30},normalize_features:{31},alpha_defender:{32},gpu_id:{33},\"", "\"merged_ad_features:{34},optimization_iterations{35},eps_clip:{36},zero_mean_features:{37},\"", "\"input_dim_defender:{38},input_dim_attacker:{39},lstm_network:{40},num_hidden_layers:{41},\"", "\"lstm_seq_length:{41},num_lstm_layers:{42},gae_lambda:{43},cnn_feature_exatractor:{44},\"", "\"features_dim:{45},flatten_feature_planes:{46},cnn_type:{47},ent_coef:{48},vf_coef:{49},\"", "\"lr_progress_decay:{50},lr_progress_power_decay:{51},use_sde:{52},sde_sample_freq:{53},\"", "\"baselines_in_pool:{54},one_hot_obs:{55},grid_img_obs:{56},force_exploration{57},force_exp_p:{58},\"", "\"\"", ".", "format", "(", "\n", "self", ".", "gamma", ",", "self", ".", "alpha_attacker", ",", "self", ".", "epsilon", ",", "self", ".", "render", ",", "self", ".", "eval_sleep", ",", "self", ".", "epsilon_decay", ",", "\n", "self", ".", "min_epsilon", ",", "self", ".", "eval_episodes", ",", "self", ".", "train_log_frequency", ",", "self", ".", "eval_log_frequency", ",", "self", ".", "video", ",", "\n", "self", ".", "video_fps", ",", "self", ".", "video_dir", ",", "self", ".", "num_episodes", ",", "self", ".", "eval_render", ",", "self", ".", "gifs", ",", "self", ".", "gif_dir", ",", "\n", "self", ".", "eval_frequency", ",", "self", ".", "video_frequency", ",", "self", ".", "attacker", ",", "self", ".", "defender", ",", "self", ".", "checkpoint_freq", ",", "\n", "self", ".", "random_seed", ",", "self", ".", "eval_epsilon", ",", "self", ".", "clip_gradient", ",", "self", ".", "max_gradient_norm", ",", "self", ".", "output_dim_defender", ",", "\n", "self", ".", "critic_loss_fn", ",", "self", ".", "state_length", ",", "self", ".", "alternating_optimization", ",", "self", ".", "alternating_period", ",", "\n", "self", ".", "normalize_features", ",", "self", ".", "alpha_defender", ",", "self", ".", "gpu_id", ",", "self", ".", "merged_ad_features", ",", "\n", "self", ".", "optimization_iterations", ",", "self", ".", "eps_clip", ",", "self", ".", "zero_mean_features", ",", "self", ".", "input_dim_defender", ",", "\n", "self", ".", "input_dim_attacker", ",", "self", ".", "lstm_network", ",", "self", ".", "num_hidden_layers", ",", "self", ".", "lstm_seq_length", ",", "\n", "self", ".", "num_lstm_layers", ",", "self", ".", "gae_lambda", ",", "self", ".", "cnn_feature_extractor", ",", "self", ".", "features_dim", ",", "\n", "self", ".", "flatten_feature_planes", ",", "self", ".", "ent_coef", ",", "self", ".", "vf_coef", ",", "self", ".", "lr_progress_decay", ",", "\n", "self", ".", "lr_progress_power_decay", ",", "self", ".", "use_sde", ",", "self", ".", "sde_sample_freq", ",", "self", ".", "baselines_in_pool", ",", "self", ".", "one_hot_obs", ",", "\n", "self", ".", "grid_image_obs", ",", "self", ".", "force_exploration", ",", "self", ".", "force_exp_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.to_csv": [[290, 379], ["open", "csv.writer", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str", "str"], "methods", ["None"], ["", "def", "to_csv", "(", "self", ",", "file_path", ":", "str", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Write parameters to csv file\n\n        :param file_path: path to the file\n        :return: None\n        \"\"\"", "\n", "with", "open", "(", "file_path", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"parameter\"", ",", "\"value\"", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"gamma\"", ",", "str", "(", "self", ".", "gamma", ")", "]", ")", "\n", "# if type(self.alpha_attacker) == float:", "\n", "#     writer.writerow([\"alpha_attacker\", str(self.alpha_attacker)])", "\n", "writer", ".", "writerow", "(", "[", "\"epsilon\"", ",", "str", "(", "self", ".", "epsilon", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"render\"", ",", "str", "(", "self", ".", "render", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eval_sleep\"", ",", "str", "(", "self", ".", "eval_sleep", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"epsilon_decay\"", ",", "str", "(", "self", ".", "epsilon_decay", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"min_epsilon\"", ",", "str", "(", "self", ".", "min_epsilon", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eval_episodes\"", ",", "str", "(", "self", ".", "eval_episodes", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"train_log_frequency\"", ",", "str", "(", "self", ".", "train_log_frequency", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eval_log_frequency\"", ",", "str", "(", "self", ".", "eval_log_frequency", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"video\"", ",", "str", "(", "self", ".", "video", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"video_fps\"", ",", "str", "(", "self", ".", "video_fps", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"video_dir\"", ",", "str", "(", "self", ".", "video_dir", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"num_episodes\"", ",", "str", "(", "self", ".", "num_episodes", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eval_render\"", ",", "str", "(", "self", ".", "eval_render", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"gifs\"", ",", "str", "(", "self", ".", "gifs", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"gifdir\"", ",", "str", "(", "self", ".", "gif_dir", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eval_frequency\"", ",", "str", "(", "self", ".", "eval_frequency", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"video_frequency\"", ",", "str", "(", "self", ".", "video_frequency", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"attacker\"", ",", "str", "(", "self", ".", "attacker", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"defender\"", ",", "str", "(", "self", ".", "defender", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"checkpoint_freq\"", ",", "str", "(", "self", ".", "checkpoint_freq", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"random_seed\"", ",", "str", "(", "self", ".", "random_seed", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eval_epsilon\"", ",", "str", "(", "self", ".", "eval_epsilon", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"input_dim_attacker\"", ",", "str", "(", "self", ".", "input_dim_attacker", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"output_dim_attacker\"", ",", "str", "(", "self", ".", "output_dim_attacker", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hidden_dim\"", ",", "str", "(", "self", ".", "hidden_dim", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"batch_size\"", ",", "str", "(", "self", ".", "batch_size", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"gpu\"", ",", "str", "(", "self", ".", "gpu", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"tensorboard\"", ",", "str", "(", "self", ".", "tensorboard", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"tensorboard_dir\"", ",", "str", "(", "self", ".", "tensorboard_dir", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"optimizer\"", ",", "str", "(", "self", ".", "optimizer", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"num_hidden_layers\"", ",", "str", "(", "self", ".", "num_hidden_layers", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"lr_exp_decay\"", ",", "str", "(", "self", ".", "lr_exp_decay", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"lr_decay_rate\"", ",", "str", "(", "self", ".", "lr_decay_rate", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"hidden_activation\"", ",", "str", "(", "self", ".", "hidden_activation", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"clip_gradient\"", ",", "str", "(", "self", ".", "clip_gradient", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"max_gradient_norm\"", ",", "str", "(", "self", ".", "max_gradient_norm", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"output_dim_defender\"", ",", "str", "(", "self", ".", "output_dim_defender", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"critic_loss_fn\"", ",", "str", "(", "self", ".", "critic_loss_fn", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"state_length\"", ",", "str", "(", "self", ".", "state_length", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"alternating_optimization\"", ",", "str", "(", "self", ".", "alternating_optimization", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"alternating_period\"", ",", "str", "(", "self", ".", "alternating_period", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"normalize_features\"", ",", "str", "(", "self", ".", "normalize_features", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"alpha_defender\"", ",", "str", "(", "self", ".", "normalize_features", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"gpu_id\"", ",", "str", "(", "self", ".", "gpu_id", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"merged_ad_features\"", ",", "str", "(", "self", ".", "merged_ad_features", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"optimization_iterations\"", ",", "str", "(", "self", ".", "optimization_iterations", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"eps_clip\"", ",", "str", "(", "self", ".", "eps_clip", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"zero_mean_features\"", ",", "str", "(", "self", ".", "zero_mean_features", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"input_dim_defender\"", ",", "str", "(", "self", ".", "input_dim_defender", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"lstm_network\"", ",", "str", "(", "self", ".", "lstm_network", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"lstm_seq_length\"", ",", "str", "(", "self", ".", "lstm_seq_length", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"num_lstm_layers\"", ",", "str", "(", "self", ".", "num_lstm_layers", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"gae_lambda\"", ",", "str", "(", "self", ".", "gae_lambda", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"cnn_feature_extractor\"", ",", "str", "(", "self", ".", "cnn_feature_extractor", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"features_dim\"", ",", "str", "(", "self", ".", "features_dim", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"flatten_feature_planes\"", ",", "str", "(", "self", ".", "flatten_feature_planes", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"cnn_type\"", ",", "str", "(", "self", ".", "cnn_type", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"ent_coef\"", ",", "str", "(", "self", ".", "ent_coef", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"vf_coef\"", ",", "str", "(", "self", ".", "vf_coef", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"lr_progress_decay\"", ",", "str", "(", "self", ".", "lr_progress_decay", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"lr_progress_power_decay\"", ",", "str", "(", "self", ".", "lr_progress_power_decay", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"use_sde\"", ",", "str", "(", "self", ".", "use_sde", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"sde_sample_freq\"", ",", "str", "(", "self", ".", "sde_sample_freq", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"baselines_in_pool\"", ",", "str", "(", "self", ".", "baselines_in_pool", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"one_hot_obs\"", ",", "str", "(", "self", ".", "one_hot_obs", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"grid_image_obs\"", ",", "str", "(", "self", ".", "grid_image_obs", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"force_exploration\"", ",", "str", "(", "self", ".", "force_exploration", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"force_exp_p\"", ",", "str", "(", "self", ".", "force_exp_p", ")", "]", ")", "\n", "if", "self", ".", "opponent_pool", "and", "self", ".", "opponent_pool_config", "is", "not", "None", ":", "\n", "                ", "writer", ".", "writerow", "(", "[", "\"pool_maxsize\"", ",", "str", "(", "self", ".", "opponent_pool_config", ".", "pool_maxsize", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"pool_increment_period\"", ",", "str", "(", "self", ".", "opponent_pool_config", ".", "pool_increment_period", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"head_to_head_period\"", ",", "str", "(", "self", ".", "opponent_pool_config", ".", "head_to_head_period", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"quality_scores\"", ",", "str", "(", "self", ".", "opponent_pool_config", ".", "quality_scores", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"quality_score_eta\"", ",", "str", "(", "self", ".", "opponent_pool_config", ".", "quality_score_eta", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"pool_prob\"", ",", "str", "(", "self", ".", "opponent_pool_config", ".", "pool_prob", ")", "]", ")", "\n", "writer", ".", "writerow", "(", "[", "\"initial_quality\"", ",", "str", "(", "self", ".", "opponent_pool_config", ".", "initial_quality", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.policy_gradient.pg_agent_config.PolicyGradientAgentConfig.hparams_dict": [[382, 458], ["type", "sum", "type", "sum", "list", "list"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type"], ["", "", "", "def", "hparams_dict", "(", "self", ")", ":", "\n", "        ", "hparams", "=", "{", "}", "\n", "hparams", "[", "\"gamma\"", "]", "=", "self", ".", "gamma", "\n", "hparams", "[", "\"alpha_attacker\"", "]", "=", "self", ".", "alpha_attacker", "\n", "hparams", "[", "\"epsilon\"", "]", "=", "self", ".", "epsilon", "\n", "hparams", "[", "\"epsilon_decay\"", "]", "=", "self", ".", "epsilon_decay", "\n", "hparams", "[", "\"min_epsilon\"", "]", "=", "self", ".", "min_epsilon", "\n", "hparams", "[", "\"eval_episodes\"", "]", "=", "self", ".", "eval_episodes", "\n", "hparams", "[", "\"train_log_frequency\"", "]", "=", "self", ".", "train_log_frequency", "\n", "hparams", "[", "\"eval_log_frequency\"", "]", "=", "self", ".", "eval_log_frequency", "\n", "hparams", "[", "\"num_episodes\"", "]", "=", "self", ".", "num_episodes", "\n", "hparams", "[", "\"eval_frequency\"", "]", "=", "self", ".", "eval_frequency", "\n", "hparams", "[", "\"attacker\"", "]", "=", "self", ".", "attacker", "\n", "hparams", "[", "\"defender\"", "]", "=", "self", ".", "defender", "\n", "hparams", "[", "\"checkpoint_freq\"", "]", "=", "self", ".", "checkpoint_freq", "\n", "hparams", "[", "\"random_seed\"", "]", "=", "self", ".", "random_seed", "\n", "hparams", "[", "\"eval_epsilon\"", "]", "=", "self", ".", "eval_epsilon", "\n", "if", "type", "(", "self", ".", "input_dim_attacker", ")", "==", "tuple", ":", "\n", "            ", "hparams", "[", "\"input_dim_attacker\"", "]", "=", "sum", "(", "list", "(", "self", ".", "input_dim_attacker", ")", ")", "\n", "", "else", ":", "\n", "            ", "hparams", "[", "\"input_dim_attacker\"", "]", "=", "self", ".", "input_dim_attacker", "\n", "", "hparams", "[", "\"output_dim_attacker\"", "]", "=", "self", ".", "output_dim_attacker", "\n", "hparams", "[", "\"hidden_dim\"", "]", "=", "self", ".", "hidden_dim", "\n", "hparams", "[", "\"batch_size\"", "]", "=", "self", ".", "batch_size", "\n", "hparams", "[", "\"num_hidden_layers\"", "]", "=", "self", ".", "num_hidden_layers", "\n", "hparams", "[", "\"gpu\"", "]", "=", "self", ".", "gpu", "\n", "hparams", "[", "\"optimizer\"", "]", "=", "self", ".", "optimizer", "\n", "hparams", "[", "\"lr_exp_decay\"", "]", "=", "self", ".", "lr_exp_decay", "\n", "hparams", "[", "\"lr_decay_rate\"", "]", "=", "self", ".", "lr_decay_rate", "\n", "hparams", "[", "\"hidden_activation\"", "]", "=", "self", ".", "hidden_activation", "\n", "hparams", "[", "\"clip_gradient\"", "]", "=", "self", ".", "clip_gradient", "\n", "hparams", "[", "\"max_gradient_norm\"", "]", "=", "self", ".", "max_gradient_norm", "\n", "hparams", "[", "\"output_dim_defender\"", "]", "=", "self", ".", "output_dim_defender", "\n", "hparams", "[", "\"critic_loss_fn\"", "]", "=", "self", ".", "critic_loss_fn", "\n", "hparams", "[", "\"state_length\"", "]", "=", "self", ".", "state_length", "\n", "hparams", "[", "\"alternating_optimization\"", "]", "=", "self", ".", "alternating_optimization", "\n", "hparams", "[", "\"alternating_period\"", "]", "=", "self", ".", "alternating_period", "\n", "hparams", "[", "\"normalize_features\"", "]", "=", "self", ".", "normalize_features", "\n", "hparams", "[", "\"alpha_defender\"", "]", "=", "self", ".", "alpha_defender", "\n", "hparams", "[", "\"gpu_id\"", "]", "=", "self", ".", "gpu_id", "\n", "hparams", "[", "\"merged_ad_features\"", "]", "=", "self", ".", "merged_ad_features", "\n", "hparams", "[", "\"optimization_iterations\"", "]", "=", "self", ".", "optimization_iterations", "\n", "hparams", "[", "\"eps_clip\"", "]", "=", "self", ".", "eps_clip", "\n", "hparams", "[", "\"zero_mean_features\"", "]", "=", "self", ".", "zero_mean_features", "\n", "if", "type", "(", "self", ".", "input_dim_defender", ")", "==", "tuple", ":", "\n", "            ", "hparams", "[", "\"input_dim_defender\"", "]", "=", "sum", "(", "list", "(", "self", ".", "input_dim_defender", ")", ")", "\n", "", "else", ":", "\n", "            ", "hparams", "[", "\"input_dim_defender\"", "]", "=", "self", ".", "input_dim_defender", "\n", "", "hparams", "[", "\"lstm_network\"", "]", "=", "self", ".", "lstm_network", "\n", "hparams", "[", "\"lstm_seq_length\"", "]", "=", "self", ".", "lstm_seq_length", "\n", "hparams", "[", "\"num_lstm_layers\"", "]", "=", "self", ".", "num_lstm_layers", "\n", "hparams", "[", "\"gae_lambda\"", "]", "=", "self", ".", "gae_lambda", "\n", "hparams", "[", "\"cnn_feature_extractor\"", "]", "=", "self", ".", "cnn_feature_extractor", "\n", "hparams", "[", "\"features_dim\"", "]", "=", "self", ".", "features_dim", "\n", "hparams", "[", "\"flatten_feature_planes\"", "]", "=", "self", ".", "flatten_feature_planes", "\n", "hparams", "[", "\"cnn_type\"", "]", "=", "self", ".", "cnn_type", "\n", "hparams", "[", "\"ent_coef\"", "]", "=", "self", ".", "ent_coef", "\n", "hparams", "[", "\"vf_coef\"", "]", "=", "self", ".", "vf_coef", "\n", "hparams", "[", "\"lr_progress_decay\"", "]", "=", "self", ".", "lr_progress_decay", "\n", "hparams", "[", "\"lr_progress_power_decay\"", "]", "=", "self", ".", "lr_progress_power_decay", "\n", "hparams", "[", "\"use_sde\"", "]", "=", "self", ".", "use_sde", "\n", "hparams", "[", "\"sde_sample_freq\"", "]", "=", "self", ".", "sde_sample_freq", "\n", "hparams", "[", "\"baselines_in_pool\"", "]", "=", "self", ".", "baselines_in_pool", "\n", "hparams", "[", "\"one_hot_obs\"", "]", "=", "self", ".", "one_hot_obs", "\n", "hparams", "[", "\"grid_img_obs\"", "]", "=", "self", ".", "grid_image_obs", "\n", "hparams", "[", "\"force_exploration\"", "]", "=", "self", ".", "force_exploration", "\n", "hparams", "[", "\"force_exp_p\"", "]", "=", "self", ".", "force_exp_p", "\n", "if", "self", ".", "opponent_pool", "and", "self", ".", "opponent_pool_config", "is", "not", "None", ":", "\n", "            ", "hparams", "[", "\"pool_maxsize\"", "]", "=", "self", ".", "opponent_pool_config", ".", "pool_maxsize", "\n", "hparams", "[", "\"pool_increment_period\"", "]", "=", "self", ".", "opponent_pool_config", ".", "pool_increment_period", "\n", "hparams", "[", "\"head_to_head_period\"", "]", "=", "self", ".", "opponent_pool_config", ".", "head_to_head_period", "\n", "hparams", "[", "\"quality_scores\"", "]", "=", "self", ".", "opponent_pool_config", ".", "quality_scores", "\n", "hparams", "[", "\"quality_score_eta\"", "]", "=", "self", ".", "opponent_pool_config", ".", "quality_score_eta", "\n", "hparams", "[", "\"pool_prob\"", "]", "=", "self", ".", "opponent_pool_config", ".", "pool_prob", "\n", "hparams", "[", "\"initial_quality\"", "]", "=", "self", ".", "opponent_pool_config", ".", "initial_quality", "\n", "", "return", "hparams", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.manual_agents.manual_defense_agent.ManualDefenseAgent.__init__": [[13, 25], ["gym_idsgame.agents.agent.Agent.__init__", "manual_defense_agent.ManualDefenseAgent.idsgame_config.render_config.manual_default", "gym_idsgame.envs.rendering.viewer.Viewer", "gym_idsgame.envs.rendering.viewer.Viewer.manual_start_defender"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.render_config.RenderConfig.manual_default", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.manual_start_defender"], ["def", "__init__", "(", "self", ",", "idsgame_config", ")", ":", "\n", "        ", "\"\"\"\n        Sets up the GUI with the manual defender\n\n        :param idsgame_config: the configuration\n        \"\"\"", "\n", "super", "(", "ManualDefenseAgent", ",", "self", ")", ".", "__init__", "(", "idsgame_config", ".", "game_config", ")", "\n", "self", ".", "idsgame_config", "=", "idsgame_config", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "attacker_view", "=", "True", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "manual_default", "(", ")", "\n", "viewer", "=", "Viewer", "(", "self", ".", "idsgame_config", ")", "\n", "viewer", ".", "manual_start_defender", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.manual_agents.manual_attack_agent.ManualAttackAgent.__init__": [[13, 24], ["gym_idsgame.agents.agent.Agent.__init__", "manual_attack_agent.ManualAttackAgent.idsgame_config.render_config.manual_default", "gym_idsgame.envs.rendering.viewer.Viewer", "gym_idsgame.envs.rendering.viewer.Viewer.manual_start_attacker"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.render_config.RenderConfig.manual_default", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.manual_start_attacker"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", ")", ":", "\n", "        ", "\"\"\"\n        Sets up the GUI with the manual attacker\n\n        :param idsgame_config: the configuration\n        \"\"\"", "\n", "super", "(", "ManualAttackAgent", ",", "self", ")", ".", "__init__", "(", "idsgame_config", ".", "game_config", ")", "\n", "self", ".", "idsgame_config", "=", "idsgame_config", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "manual_default", "(", ")", "\n", "viewer", "=", "Viewer", "(", "self", ".", "idsgame_config", ")", "\n", "viewer", ".", "manual_start_attacker", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.config.hp_tuning_config.HpTuningConfig.__init__": [[7, 14], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "param_1", ":", "str", ",", "param_2", ":", "str", ",", "alpha", ":", "list", "=", "None", ",", "epsilon_decay", ":", "list", "=", "None", ",", "\n", "num_hidden_layers", ":", "list", "=", "None", ")", ":", "\n", "        ", "self", ".", "param_1", "=", "param_1", "\n", "self", ".", "param_2", "=", "param_2", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "epsilon_decay", "=", "epsilon_decay", "\n", "self", ".", "num_hidden_layers", "=", "num_hidden_layers", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.config.client_config.ClientConfig.__init__": [[15, 63], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "env_name", ":", "str", ",", "attacker_type", ":", "int", "=", "0", ",", "\n", "defender_type", ":", "int", "=", "1", ",", "mode", ":", "int", "=", "0", ",", "q_agent_config", ":", "QAgentConfig", "=", "None", ",", "\n", "pg_agent_config", ":", "PolicyGradientAgentConfig", "=", "None", ",", "\n", "output_dir", ":", "str", "=", "None", ",", "simulation_config", ":", "SimulationConfig", "=", "None", ",", "title", "=", "None", ",", "\n", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ",", "run_many", ":", "bool", "=", "False", ",", "\n", "random_seeds", ":", "list", "=", "None", ",", "random_seed", "=", "0", ",", "hp_tuning_config", ":", "HpTuningConfig", "=", "None", ",", "\n", "hp_tuning", ":", "bool", "=", "False", ",", "bot_attacker", "=", "False", ",", "bot_defender", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Class constructor, initializes the DTO\n\n        :param env_name: name of the environment for the experiment\n        :param attacker_type: type of attacker\n        :param defender_type: type of defender\n        :param mode: type of experiment\n        :param q_agent_config: configuration in case QAgent is used for one of the agents\n        :param simulation_config: configuration for running a simulation (no training)\n        :param output_dir: directory to save outputs (results)\n        :param title: title in the GUI\n        :param idsgame_config: idsgame configuration\n        :param initial_state_path: path to initial state\n        :param run_many: if this is true, it will try to run many experiments in a row, using different random seeds\n        :param random_seeds: list of random seeds when running several experiments in a row\n        :param random_seed: specific random seed\n        :param hp_tuning_config: hyperparameter tuning config\n        :param hp_tuning: boolean flag, if true runs hyperparameter tuning, otherwise run regular experiment\n        :param pg_agent_config: policy gradient agent config\n        :param bot_attacker: boolean flag whether the attacker should be an external bot agent\n        :param bot_defender: boolean flag whether the defender should be an external bot agent\n        \"\"\"", "\n", "self", ".", "env_name", "=", "env_name", "\n", "self", ".", "attacker_type", "=", "attacker_type", "\n", "self", ".", "defender_type", "=", "defender_type", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "q_agent_config", "=", "q_agent_config", "\n", "self", ".", "logger", "=", "None", "\n", "self", ".", "output_dir", "=", "output_dir", "\n", "self", ".", "simulation_config", "=", "simulation_config", "\n", "self", ".", "title", "=", "title", "\n", "self", ".", "idsgame_config", "=", "idsgame_config", "\n", "self", ".", "initial_state_path", "=", "initial_state_path", "\n", "self", ".", "run_many", "=", "run_many", "\n", "self", ".", "random_seeds", "=", "random_seeds", "\n", "self", ".", "random_seed", "=", "random_seed", "\n", "self", ".", "hp_tuning_config", "=", "hp_tuning_config", "\n", "self", ".", "hp_tuning", "=", "hp_tuning", "\n", "self", ".", "pg_agent_config", "=", "pg_agent_config", "\n", "self", ".", "bot_attacker", "=", "bot_attacker", "\n", "self", ".", "bot_defender", "=", "bot_defender", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.__init__": [[30, 93], ["idsgame_env.IdsGameEnv.validate_config", "idsgame_env.IdsGameEnv.idsgame_config.game_config.initial_state.copy", "idsgame_env.IdsGameEnv.idsgame_config.game_config.get_attacker_observation_space", "idsgame_env.IdsGameEnv.idsgame_config.game_config.get_action_space", "idsgame_env.IdsGameEnv.idsgame_config.game_config.get_action_space", "int", "idsgame_env.IdsGameEnv.past_positions.append", "idsgame_env.IdsGameEnv.save_initial_state", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "float", "float", "math.pow", "int", "math.pow"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.validate_config", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.get_attacker_observation_space", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.get_action_space", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.get_action_space", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initializes the environment\n\n        Observation:\n            Type: Box(num_nodes*num_attack_types)\n        Actions:\n            Type: Discrete(num_nodes*num_action_types)\n        Reward:\n            Reward is 0 for all steps except the final step which is either +100 (win) or -100 (loss)\n        Starting State:\n            Start node, all attack values are 0\n        Episode Termination:\n            When attacker reaches DATA node or when attacker is detected\n\n        :param idsgame_config: configuration of the environment\n        :param save_dir: directory to save outputs, e.g. initial state\n        :param initial_state_path: path to the initial state (if none, use default)\n        \"\"\"", "\n", "import", "gym_idsgame", ".", "envs", ".", "util", ".", "idsgame_util", "as", "util", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "idsgame_config", "=", "IdsGameConfig", "(", "initial_state_path", "=", "initial_state_path", ")", "\n", "", "self", ".", "save_dir", "=", "save_dir", "\n", "self", ".", "validate_config", "(", "idsgame_config", ")", "\n", "self", ".", "idsgame_config", ":", "IdsGameConfig", "=", "idsgame_config", "\n", "self", ".", "state", ":", "GameState", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "initial_state", ".", "copy", "(", ")", "\n", "self", ".", "observation_space", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "get_attacker_observation_space", "(", ")", "\n", "self", ".", "attacker_action_space", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "get_action_space", "(", "defender", "=", "False", ")", "\n", "self", ".", "defender_action_space", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "get_action_space", "(", "defender", "=", "True", ")", "\n", "self", ".", "viewer", "=", "None", "\n", "self", ".", "steps_beyond_done", "=", "None", "\n", "self", ".", "metadata", "=", "{", "\n", "'render.modes'", ":", "[", "'human'", ",", "'rgb_array'", "]", ",", "\n", "'video.frames_per_second'", ":", "50", "# Video rendering speed", "\n", "}", "\n", "self", ".", "reward_range", "=", "(", "float", "(", "constants", ".", "GAME_CONFIG", ".", "NEGATIVE_REWARD", ")", ",", "float", "(", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", ")", ")", "\n", "self", ".", "num_states", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_nodes", "\n", "self", ".", "num_states_full", "=", "int", "(", "math", ".", "pow", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "max_value", "+", "1", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "num_nodes", "*", "\n", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", ")", ")", ")", "\n", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "fully_observed", ":", "\n", "            ", "self", ".", "num_states_full", "=", "int", "(", "math", ".", "pow", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "max_value", "+", "1", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "num_nodes", "*", "\n", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", ")", "*", "2", ")", ")", "\n", "", "self", ".", "num_attack_actions", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_actions", "\n", "self", ".", "num_defense_actions", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_defense_actions", "\n", "self", ".", "past_moves", "=", "[", "]", "\n", "self", ".", "past_positions", "=", "[", "]", "\n", "self", ".", "past_positions", ".", "append", "(", "self", ".", "state", ".", "attacker_pos", ")", "\n", "self", ".", "past_reconnaissance_activities", "=", "[", "]", "\n", "self", ".", "save_initial_state", "(", ")", "\n", "self", ".", "furthest_hack", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "num_rows", "-", "1", "\n", "self", ".", "a_cumulative_reward", "=", "0", "\n", "self", ".", "d_cumulative_reward", "=", "0", "\n", "self", ".", "game_trajectories", "=", "[", "]", "\n", "self", ".", "game_trajectory", "=", "[", "]", "\n", "self", ".", "attack_detections", "=", "[", "]", "\n", "self", ".", "total_attacks", "=", "[", "]", "\n", "self", ".", "defenses", "=", "[", "]", "\n", "self", ".", "attacks", "=", "[", "]", "\n", "self", ".", "hacked_nodes", "=", "[", "]", "\n", "self", ".", "num_failed_attacks", "=", "0", "\n", "self", ".", "failed_attacks", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.step": [[95, 226], ["trajectory.append", "idsgame_env.IdsGameEnv.get_defender_action", "trajectory.append", "idsgame_env.IdsGameEnv.state.defend", "idsgame_env.IdsGameEnv.state.add_defense_event", "idsgame_env.IdsGameEnv.get_observation", "trajectory.append", "trajectory.append", "trajectory.append", "idsgame_env.IdsGameEnv.get_attacker_action", "trajectory.append", "idsgame_env.IdsGameEnv.defenses.append", "util.is_attack_legal", "idsgame_env.IdsGameEnv.past_moves.append", "idsgame_env.IdsGameEnv.state.add_attack_event", "idsgame_env.IdsGameEnv.attacks.append", "idsgame_env.IdsGameEnv.viewer.gameframe.set_state", "idsgame_env.IdsGameEnv.game_trajectories.append", "idsgame_env.IdsGameEnv.get_observation", "idsgame_env.IdsGameEnv.state.attack", "idsgame_env.IdsGameEnv.state.reconnaissance", "idsgame_env.IdsGameEnv.past_reconnaissance_activities.append", "idsgame_env.IdsGameEnv.state.simulate_attack", "idsgame_env.IdsGameEnv.total_attacks.append", "idsgame_env.IdsGameEnv.past_positions.append", "idsgame_env.IdsGameEnv.state.simulate_detection", "gym.logger.warn", "idsgame_env.IdsGameEnv.past_positions.append", "idsgame_env.IdsGameEnv.hacked_nodes.append", "idsgame_env.IdsGameEnv.get_detect_reward", "idsgame_env.IdsGameEnv.attack_detections.append", "idsgame_env.IdsGameEnv.get_hack_reward", "idsgame_env.IdsGameEnv.get_successful_attack_reward"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.AttackDefenseEnv.get_defender_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.defend", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.add_defense_event", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.AttackDefenseEnv.get_attacker_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.add_attack_event", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.set_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.attack", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.reconnaissance", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.simulate_attack", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.simulate_detection", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_detect_reward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_hack_reward", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_successful_attack_reward"], ["", "def", "step", "(", "self", ",", "action", ":", "int", ")", "->", "Union", "[", "np", ".", "ndarray", ",", "int", ",", "bool", ",", "dict", "]", ":", "\n", "        ", "\"\"\"\n        Takes a step in the environment using the given action.\n\n        When end of episode is reached, the caller is responsible for calling `reset()`\n        to reset this environment's state.\n\n        :param action: the action to take in the environment\n        :return:\n            observation (object): agent's observation of the current environment\n            reward (float) : amount of reward returned after previous action\n            done (bool): whether the episode has ended, in which case further step() calls will return undefined results\n            info (dict): contains auxiliary diagnostic information (helpful for debugging, and sometimes learning)\n        \"\"\"", "\n", "import", "gym_idsgame", ".", "envs", ".", "util", ".", "idsgame_util", "as", "util", "\n", "# Initialization", "\n", "trajectory", "=", "[", "]", "\n", "trajectory", ".", "append", "(", "self", ".", "state", ")", "\n", "reward", "=", "(", "0", ",", "0", ")", "\n", "info", "=", "{", "}", "\n", "info", "[", "\"moved\"", "]", "=", "False", "\n", "self", ".", "state", ".", "attack_events", "=", "[", "]", "\n", "self", ".", "state", ".", "defense_events", "=", "[", "]", "\n", "\n", "if", "self", ".", "state", ".", "game_step", ">", "constants", ".", "GAME_CONFIG", ".", "MAX_GAME_STEPS", ":", "\n", "            ", "return", "self", ".", "get_observation", "(", ")", ",", "(", "100", "*", "constants", ".", "GAME_CONFIG", ".", "NEGATIVE_REWARD", ",", "\n", "100", "*", "constants", ".", "GAME_CONFIG", ".", "NEGATIVE_REWARD", ")", ",", "True", ",", "info", "\n", "\n", "", "attack_action", ",", "defense_action", "=", "action", "\n", "\n", "# 1. Interpret attacker action", "\n", "attacker_pos", "=", "self", ".", "state", ".", "attacker_pos", "\n", "if", "attack_action", "!=", "-", "1", ":", "\n", "            ", "target_node_id", ",", "target_pos", ",", "attack_type", ",", "reconnaissance", "=", "self", ".", "get_attacker_action", "(", "action", ")", "\n", "trajectory", ".", "append", "(", "[", "target_node_id", ",", "target_pos", ",", "attack_type", ",", "reconnaissance", "]", ")", "\n", "\n", "# 2. Interpret defense action", "\n", "", "defense_node_id", ",", "defense_pos", ",", "defense_type", ",", "=", "self", ".", "get_defender_action", "(", "action", ")", "\n", "trajectory", ".", "append", "(", "[", "defense_node_id", ",", "defense_pos", ",", "defense_type", "]", ")", "\n", "\n", "# 3. Defend", "\n", "detect", "=", "defense_type", "==", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "\n", "defense_successful", "=", "self", ".", "state", ".", "defend", "(", "defense_node_id", ",", "defense_type", ",", "self", ".", "idsgame_config", ".", "game_config", ".", "max_value", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ",", "detect", "=", "detect", ")", "\n", "if", "defense_successful", ":", "\n", "            ", "self", ".", "defenses", ".", "append", "(", "(", "defense_node_id", ",", "defense_type", ",", "detect", ",", "self", ".", "state", ".", "game_step", ")", ")", "\n", "", "self", ".", "state", ".", "add_defense_event", "(", "defense_pos", ",", "defense_type", ")", "\n", "\n", "if", "attack_action", "!=", "-", "1", "and", "util", ".", "is_attack_legal", "(", "target_pos", ",", "attacker_pos", ",", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ",", "\n", "past_positions", "=", "self", ".", "past_positions", ")", ":", "\n", "            ", "self", ".", "past_moves", ".", "append", "(", "target_node_id", ")", "\n", "if", "not", "reconnaissance", ":", "\n", "# 4. Attack", "\n", "                ", "self", ".", "state", ".", "attack", "(", "target_node_id", ",", "attack_type", ",", "self", ".", "idsgame_config", ".", "game_config", ".", "max_value", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ",", "\n", "reconnaissance_enabled", "=", "self", ".", "idsgame_config", ".", "reconnaissance_actions", ")", "\n", "", "else", ":", "\n", "                ", "rec_reward", "=", "self", ".", "state", ".", "reconnaissance", "(", "target_node_id", ",", "attack_type", ",", "reconnaissance_reward", "=", "self", ".", "idsgame_config", ".", "reconnaissance_reward", ")", "\n", "self", ".", "past_reconnaissance_activities", ".", "append", "(", "(", "target_node_id", ",", "attack_type", ")", ")", "\n", "reward", "=", "(", "rec_reward", ",", "0", ")", "\n", "\n", "", "self", ".", "state", ".", "add_attack_event", "(", "target_pos", ",", "attack_type", ",", "self", ".", "state", ".", "attacker_pos", ",", "reconnaissance", ")", "\n", "self", ".", "attacks", ".", "append", "(", "(", "target_node_id", ",", "attack_type", ",", "self", ".", "state", ".", "game_step", ",", "reconnaissance", ")", ")", "\n", "\n", "attack_successful", "=", "False", "\n", "if", "not", "reconnaissance", ":", "\n", "# 5. Simulate attack outcome", "\n", "                ", "attack_successful", "=", "self", ".", "state", ".", "simulate_attack", "(", "target_node_id", ",", "attack_type", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ")", "\n", "", "if", "self", ".", "idsgame_config", ".", "save_attack_stats", ":", "\n", "                ", "self", ".", "total_attacks", ".", "append", "(", "[", "target_node_id", ",", "attack_successful", ",", "reconnaissance", "]", ")", "\n", "\n", "# 6. Update state based on attack outcome", "\n", "", "if", "attack_successful", ":", "\n", "                ", "if", "not", "reconnaissance", ":", "\n", "                    ", "info", "[", "\"moved\"", "]", "=", "True", "\n", "self", ".", "past_positions", ".", "append", "(", "target_pos", ")", "\n", "self", ".", "state", ".", "attacker_pos", "=", "target_pos", "\n", "self", ".", "hacked_nodes", ".", "append", "(", "target_node_id", ")", "\n", "if", "target_pos", "==", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "data_pos", ":", "\n", "                        ", "self", ".", "state", ".", "done", "=", "True", "\n", "self", ".", "state", ".", "hacked", "=", "True", "\n", "reward", "=", "self", ".", "get_hack_reward", "(", "attack_type", ",", "target_node_id", ")", "\n", "", "else", ":", "\n", "                        ", "reward", "=", "self", ".", "get_successful_attack_reward", "(", "attack_type", ",", "target_node_id", ")", "\n", "", "", "self", ".", "num_failed_attacks", "=", "0", "\n", "", "else", ":", "\n", "                ", "self", ".", "num_failed_attacks", "+=", "1", "\n", "if", "(", "target_node_id", ",", "attack_type", ")", "in", "self", ".", "failed_attacks", ":", "\n", "                    ", "self", ".", "failed_attacks", "[", "(", "target_node_id", ",", "attack_type", ")", "]", "=", "self", ".", "failed_attacks", "[", "(", "target_node_id", ",", "attack_type", ")", "]", "+", "1", "\n", "", "else", ":", "\n", "                    ", "self", ".", "failed_attacks", "[", "(", "target_node_id", ",", "attack_type", ")", "]", "=", "1", "\n", "", "self", ".", "past_positions", ".", "append", "(", "self", ".", "state", ".", "attacker_pos", ")", "\n", "detected", "=", "self", ".", "state", ".", "simulate_detection", "(", "target_node_id", ",", "reconnaissance", "=", "reconnaissance", ",", "\n", "reconnaissance_detection_factor", "=", "self", ".", "idsgame_config", ".", "reconnaissance_detection_factor", ")", "\n", "if", "detected", ":", "\n", "                    ", "self", ".", "state", ".", "done", "=", "True", "\n", "self", ".", "state", ".", "detected", "=", "True", "\n", "reward", "=", "self", ".", "get_detect_reward", "(", "target_node_id", ",", "attack_type", ",", "self", ".", "state", ".", "defense_det", "[", "target_node_id", "]", ",", "reconnaissance", ")", "\n", "# else:", "\n", "#     if not reconnaissance:", "\n", "#         reward = self.get_blocked_attack_reward(target_node_id, attack_type)", "\n", "", "if", "self", ".", "idsgame_config", ".", "save_attack_stats", ":", "\n", "                    ", "self", ".", "attack_detections", ".", "append", "(", "[", "target_node_id", ",", "detected", ",", "self", ".", "state", ".", "defense_det", "[", "target_node_id", "]", "]", ")", "\n", "", "", "", "else", ":", "\n", "#print(\"illegal action:{}\".format(attack_action))", "\n", "            ", "reward", "=", "-", "1", "*", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", ",", "0", "\n", "# self.state.done = True", "\n", "# self.state.detected = True", "\n", "\n", "", "if", "self", ".", "state", ".", "done", ":", "\n", "            ", "if", "self", ".", "steps_beyond_done", "is", "None", ":", "\n", "                ", "self", ".", "steps_beyond_done", "=", "0", "\n", "", "else", ":", "\n", "                ", "gym", ".", "logger", ".", "warn", "(", "\n", "\"You are calling 'step()' even though this environment has already returned done = True. \"", "\n", "\"You should always call 'reset()' once you receive 'done = True' -- \"", "\n", "\"any further steps are undefined behavior.\"", ")", "\n", "self", ".", "steps_beyond_done", "+=", "1", "\n", "", "", "self", ".", "state", ".", "game_step", "+=", "1", "\n", "observation", "=", "self", ".", "get_observation", "(", ")", "\n", "if", "self", ".", "viewer", "is", "not", "None", ":", "\n", "            ", "self", ".", "viewer", ".", "gameframe", ".", "set_state", "(", "self", ".", "state", ")", "\n", "", "self", ".", "a_cumulative_reward", "+=", "reward", "[", "0", "]", "\n", "self", ".", "d_cumulative_reward", "+=", "reward", "[", "1", "]", "\n", "trajectory", ".", "append", "(", "reward", "[", "0", "]", ")", "\n", "trajectory", ".", "append", "(", "reward", "[", "1", "]", ")", "\n", "trajectory", ".", "append", "(", "self", ".", "state", ")", "\n", "if", "self", ".", "idsgame_config", ".", "save_trajectories", ":", "\n", "            ", "self", ".", "game_trajectories", ".", "append", "(", "trajectory", ")", "\n", "", "return", "observation", ",", "reward", ",", "self", ".", "state", ".", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.reset": [[227, 266], ["idsgame_env.IdsGameEnv.state.new_game", "idsgame_env.IdsGameEnv.get_observation", "idsgame_env.IdsGameEnv.past_positions.append", "idsgame_env.IdsGameEnv.state.randomize_attacker_position", "idsgame_env.IdsGameEnv.viewer.gameframe.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.new_game", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.randomize_attacker_position", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset"], ["", "def", "reset", "(", "self", ",", "update_stats", "=", "False", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Resets the environment and returns the initial state\n\n        :param update_stats: whether the game count should be incremented or not\n        :return: the initial state\n        \"\"\"", "\n", "self", ".", "past_moves", "=", "[", "]", "\n", "self", ".", "past_positions", "=", "[", "]", "\n", "self", ".", "past_reconnaissance_activities", "=", "[", "]", "\n", "self", ".", "failed_attacks", "=", "{", "}", "\n", "self", ".", "furthest_hack", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "num_rows", "-", "1", "\n", "self", ".", "steps_beyond_done", "=", "None", "\n", "self", ".", "state", ".", "new_game", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "initial_state", ",", "self", ".", "a_cumulative_reward", ",", "\n", "self", ".", "d_cumulative_reward", ",", "update_stats", "=", "update_stats", ",", "\n", "randomize_state", "=", "self", ".", "idsgame_config", ".", "randomize_env", ",", "\n", "network_config", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ",", "\n", "num_attack_types", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ",", "\n", "defense_val", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "defense_val", ",", "\n", "attack_val", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "attack_val", ",", "\n", "det_val", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "det_val", ",", "\n", "vulnerability_val", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "vulnerabilitiy_val", ",", "\n", "num_vulnerabilities_per_layer", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_vulnerabilities_per_layer", ",", "\n", "num_vulnerabilities_per_node", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_vulnerabilities_per_node", ",", "\n", "randomize_visibility", "=", "self", ".", "idsgame_config", ".", "randomize_visibility", ",", "\n", "visibility_p", "=", "self", ".", "idsgame_config", ".", "visibility_p", ")", "\n", "self", ".", "a_cumulative_reward", "=", "0", "\n", "self", ".", "d_cumulative_reward", "=", "0", "\n", "if", "self", ".", "idsgame_config", ".", "randomize_starting_position", ":", "\n", "            ", "self", ".", "state", ".", "randomize_attacker_position", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ")", "\n", "", "if", "self", ".", "viewer", "is", "not", "None", ":", "\n", "            ", "self", ".", "viewer", ".", "gameframe", ".", "reset", "(", ")", "\n", "", "observation", "=", "self", ".", "get_observation", "(", ")", "\n", "self", ".", "past_positions", ".", "append", "(", "self", ".", "state", ".", "attacker_pos", ")", "\n", "self", ".", "defenses", "=", "[", "]", "\n", "self", ".", "attacks", "=", "[", "]", "\n", "self", ".", "hacked_nodes", "=", "[", "]", "\n", "self", ".", "num_failed_attacks", "=", "0", "\n", "return", "observation", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.restart": [[267, 276], ["idsgame_env.IdsGameEnv.reset", "idsgame_env.IdsGameEnv.state.restart"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.restart"], ["", "def", "restart", "(", "self", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Restarts the game, and all the history\n\n        :return: the observation from the first state\n        \"\"\"", "\n", "obs", "=", "self", ".", "reset", "(", ")", "\n", "self", ".", "state", ".", "restart", "(", ")", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.render": [[277, 301], ["idsgame_env.IdsGameEnv.viewer.render", "NotImplemented", "idsgame_env.IdsGameEnv.__setup_viewer", "idsgame_env.IdsGameEnv.viewer.gameframe.set_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.__setup_viewer", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.set_state"], ["", "def", "render", "(", "self", ",", "mode", ":", "str", "=", "'human'", ")", ":", "\n", "        ", "\"\"\"\n        Renders the environment\n\n        Supported rendering modes:\n\n        - human: render to the current display or terminal and\n          return nothing. Usually for human consumption.\n        - rgb_array: Return an numpy.ndarray with shape (x, y, 3),\n          representing RGB values for an x-by-y pixel image, suitable\n          for turning into a video.\n\n        :param mode: the rendering mode\n        :return: True (if human mode) otherwise an rgb array\n        \"\"\"", "\n", "if", "mode", "not", "in", "self", ".", "metadata", "[", "\"render.modes\"", "]", ":", "\n", "            ", "raise", "NotImplemented", "(", "\"mode: {} is not supported\"", ".", "format", "(", "mode", ")", ")", "\n", "", "if", "self", ".", "viewer", "is", "None", ":", "\n", "            ", "self", ".", "__setup_viewer", "(", ")", "\n", "self", ".", "viewer", ".", "gameframe", ".", "set_state", "(", "self", ".", "state", ")", "\n", "", "arr", "=", "self", ".", "viewer", ".", "render", "(", "return_rgb_array", "=", "mode", "==", "'rgb_array'", ")", "\n", "self", ".", "state", ".", "attack_events", "=", "[", "]", "\n", "self", ".", "state", ".", "defense_events", "=", "[", "]", "\n", "return", "arr", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.close": [[302, 312], ["idsgame_env.IdsGameEnv.viewer.close", "idsgame_env.IdsGameEnv.idsgame_config.render_config.new_window"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.render_config.RenderConfig.new_window"], ["", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Closes the viewer (cleanup)\n\n        :return: None\n        \"\"\"", "\n", "if", "self", ".", "viewer", ":", "\n", "            ", "self", ".", "viewer", ".", "close", "(", ")", "\n", "self", ".", "viewer", "=", "None", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "new_window", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_attacker_node_from_observation": [[313, 322], ["idsgame_env.IdsGameEnv.state.get_attacker_node_from_observation"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_attacker_node_from_observation"], ["", "", "def", "get_attacker_node_from_observation", "(", "self", ",", "observation", ":", "np", ".", "ndarray", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Extracts which node the attacker is currently at from the observation representation\n\n        :param observation: the observation representation emitted from the environment\n        :return: the id of the node that the attacker is in\n        \"\"\"", "\n", "return", "self", ".", "state", ".", "get_attacker_node_from_observation", "(", "\n", "observation", ",", "reconnaissance", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.hack_probability": [[323, 331], ["float", "float"], "methods", ["None"], ["", "def", "hack_probability", "(", "self", ")", "->", "float", ":", "\n", "        ", "\"\"\"\n        :return: the cumulative hack-probabiltiy according to the game history\n        \"\"\"", "\n", "hack_probability", "=", "0.0", "\n", "if", "self", ".", "state", ".", "num_hacks", ">", "0", ":", "\n", "            ", "hack_probability", "=", "float", "(", "self", ".", "state", ".", "num_hacks", ")", "/", "float", "(", "self", ".", "state", ".", "num_games", ")", "\n", "", "return", "hack_probability", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal": [[332, 343], ["util.is_attack_id_legal"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_attack_id_legal"], ["", "def", "is_attack_legal", "(", "self", ",", "attack_action", ":", "int", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Check if a given attack is legal or not.\n\n        :param attack_action: the attack to verify\n        :return: True if legal otherwise False\n        \"\"\"", "\n", "import", "gym_idsgame", ".", "envs", ".", "util", ".", "idsgame_util", "as", "util", "\n", "return", "util", ".", "is_attack_id_legal", "(", "attack_action", ",", "self", ".", "idsgame_config", ".", "game_config", ",", "self", ".", "state", ".", "attacker_pos", ",", "\n", "self", ".", "state", ",", "self", ".", "past_positions", ",", "\n", "past_reconnaissance_activities", "=", "self", ".", "past_reconnaissance_activities", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_defense_legal": [[344, 353], ["util.is_defense_id_legal"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.is_defense_id_legal"], ["", "def", "is_defense_legal", "(", "self", ",", "defense_action", ":", "int", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Check if a given defense is legal or not.\n\n        :param defense_action: the defense action to verify\n        :return: True if legal otherwise False\n        \"\"\"", "\n", "import", "gym_idsgame", ".", "envs", ".", "util", ".", "idsgame_util", "as", "util", "\n", "return", "util", ".", "is_defense_id_legal", "(", "defense_action", ",", "self", ".", "idsgame_config", ".", "game_config", ",", "self", ".", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_initial_state": [[354, 362], ["os.path.exists", "gym_idsgame.envs.dao.game_state.GameState.save"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.save"], ["", "def", "save_initial_state", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Saves initial state to disk in binary npy format\n\n        :return: None\n        \"\"\"", "\n", "if", "self", ".", "save_dir", "is", "not", "None", "and", "os", ".", "path", ".", "exists", "(", "self", ".", "save_dir", ")", ":", "\n", "            ", "GameState", ".", "save", "(", "self", ".", "save_dir", ",", "self", ".", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_trajectories": [[363, 380], ["str", "open", "pickle.dump", "time.time"], "methods", ["None"], ["", "", "def", "save_trajectories", "(", "self", ",", "checkpoint", "=", "True", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Saves the current list of game trajectories to disk\n\n        :param checkpoint: boolean flag that indicates whether this is a checkpoint save or final save\n        :return: None\n        \"\"\"", "\n", "suffix", "=", "\".pkl\"", "\n", "if", "checkpoint", ":", "\n", "            ", "suffix", "=", "\"_checkpoint.pkl\"", "\n", "", "if", "self", ".", "idsgame_config", ".", "save_trajectories", ":", "\n", "            ", "path", "=", "self", ".", "save_dir", "\n", "time_str", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "filehandler", "=", "open", "(", "path", "+", "\"/trajectories_\"", "+", "time_str", "+", "suffix", ",", "'wb'", ")", "\n", "pickle", ".", "dump", "(", "self", ".", "game_trajectories", ",", "filehandler", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "game_trajectories", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.save_attack_data": [[381, 406], ["str", "time.time", "open", "csv.writer", "csv.writer.writerow", "open", "csv.writer", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow"], "methods", ["None"], ["", "", "def", "save_attack_data", "(", "self", ",", "checkpoint", "=", "True", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Saves the attack statistics to disk\n\n        :param checkpoint: boolean flag that indicates whether this is a checkpoint save or final save\n        :return: None\n        \"\"\"", "\n", "suffix", "=", "\".csv\"", "\n", "if", "checkpoint", ":", "\n", "            ", "suffix", "=", "\"_checkpoint.csv\"", "\n", "", "if", "self", ".", "idsgame_config", ".", "save_attack_stats", ":", "\n", "            ", "time_str", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "with", "open", "(", "self", ".", "save_dir", "+", "\"/attack_detections_stats_\"", "+", "time_str", "+", "suffix", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"target_node\"", ",", "\"detected\"", ",", "\"detection_val\"", "]", ")", "\n", "for", "row", "in", "self", ".", "attack_detections", ":", "\n", "                    ", "writer", ".", "writerow", "(", "row", ")", "\n", "", "", "with", "open", "(", "self", ".", "save_dir", "+", "\"/attack_stats_\"", "+", "time_str", "+", "suffix", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "writer", ".", "writerow", "(", "[", "\"target_node\"", ",", "\"attack_outcome\"", "]", ")", "\n", "for", "row", "in", "self", ".", "total_attacks", ":", "\n", "                    ", "writer", ".", "writerow", "(", "row", ")", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "attack_detections", "=", "[", "]", "\n", "self", ".", "total_attacks", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_hack_reward": [[407, 455], ["util.defense_score", "util.defense_score", "idsgame_env.IdsGameEnv.idsgame_config.game_config.network_config.get_row_ids", "idsgame_env.IdsGameEnv.state.min_attack_type", "max", "len", "math.pow"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.defense_score", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.defense_score", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_row_ids", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.min_attack_type"], ["", "", "def", "get_hack_reward", "(", "self", ",", "attack_type", ":", "int", ",", "node_id", ":", "int", ")", "->", "Union", "[", "int", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Returns the attacker and defender reward in the case when the hacker manages to reach the target node\n\n        :return: (attacker_reward, defender_reward)\n        \"\"\"", "\n", "import", "gym_idsgame", ".", "envs", ".", "util", ".", "idsgame_util", "as", "util", "\n", "if", "not", "self", ".", "idsgame_config", ".", "game_config", ".", "dense_rewards", "and", "not", "self", ".", "idsgame_config", ".", "game_config", ".", "dense_rewards_v2", "and", "not", "self", ".", "idsgame_config", ".", "game_config", ".", "dense_rewards_v3", ":", "\n", "            ", "return", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", ",", "-", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", "\n", "", "elif", "self", ".", "idsgame_config", ".", "game_config", ".", "dense_rewards_v3", ":", "\n", "            ", "missed_defense", "=", "0", "\n", "for", "defense", "in", "self", ".", "defenses", ":", "\n", "                ", "match", "=", "False", "\n", "for", "attack", "in", "self", ".", "attacks", ":", "\n", "# if attack[0] == defense[0] and defense[2]:", "\n", "#     match = True", "\n", "                    ", "if", "not", "defense", "[", "2", "]", "and", "attack", "[", "0", "]", "==", "defense", "[", "0", "]", "and", "defense", "[", "1", "]", "==", "attack", "[", "1", "]", ":", "\n", "                        ", "match", "=", "True", "\n", "", "", "if", "not", "match", ":", "\n", "                    ", "missed_defense", "+=", "1", "\n", "", "", "defense_score", "=", "util", ".", "defense_score", "(", "self", ".", "state", ",", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ")", "\n", "reference_defense_score", "=", "util", ".", "defense_score", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "initial_state", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ")", "\n", "max_defense_score", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "max_value", "*", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "num_rows", "\n", "\n", "attack_row", ",", "attack_col", "=", "self", ".", "state", ".", "attacker_pos", "\n", "row_ids", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "get_row_ids", "(", "attack_row", ")", "\n", "min_ats", "=", "self", ".", "state", ".", "min_attack_type", "(", "node_id", ",", "row_ids", ")", "\n", "if", "node_id", "in", "self", ".", "state", ".", "reconnaissance_actions", "and", "attack_type", "in", "min_ats", ":", "\n", "                ", "num_good_attacks", "=", "1", "\n", "if", "(", "node_id", ",", "attack_type", ")", "in", "self", ".", "failed_attacks", ":", "\n", "                    ", "num_good_attacks", "=", "self", ".", "failed_attacks", "[", "(", "node_id", ",", "attack_type", ")", "]", "+", "1", "\n", "", "num_bad_attacks", "=", "0", "\n", "for", "k", "in", "self", ".", "failed_attacks", ":", "\n", "                    ", "n_id", ",", "at", "=", "k", "\n", "if", "not", "n_id", "==", "node_id", ":", "\n", "                        ", "num_bad_attacks", "=", "num_bad_attacks", "+", "1", "\n", "", "", "reward", "=", "max", "(", "num_good_attacks", "-", "math", ".", "pow", "(", "num_bad_attacks", ",", "2", ")", ",", "0", ")", "\n", "\n", "return", "reward", ",", "-", "(", "(", "max_defense_score", "-", "reference_defense_score", ")", "-", "(", "defense_score", "-", "reference_defense_score", ")", ")", "\n", "\n", "", "return", "-", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", ",", "-", "(", "(", "max_defense_score", "-", "reference_defense_score", ")", "-", "(", "defense_score", "-", "reference_defense_score", ")", ")", "\n", "", "else", ":", "\n", "            ", "bonus", "=", "1", "if", "self", ".", "num_failed_attacks", "==", "0", "else", "1", "/", "self", ".", "num_failed_attacks", "\n", "return", "bonus", "+", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", ",", "-", "len", "(", "self", ".", "hacked_nodes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_detect_reward": [[456, 523], ["idsgame_env.IdsGameEnv.idsgame_config.game_config.network_config.get_row_ids", "idsgame_env.IdsGameEnv.state.min_attack_type", "util.defense_score", "util.defense_score"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_row_ids", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.min_attack_type", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.defense_score", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.defense_score"], ["", "", "def", "get_detect_reward", "(", "self", ",", "target_node_id", ":", "int", ",", "attack_type", ":", "int", ",", "detection_value", ",", "reconnaissance", ":", "bool", ")", "->", "Union", "[", "int", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Returns the attacker and defender reward in the case when the attacker was detected.\n\n        :return: (attacker_reward, defender_reward)\n        \"\"\"", "\n", "import", "gym_idsgame", ".", "envs", ".", "util", ".", "idsgame_util", "as", "util", "\n", "if", "not", "self", ".", "idsgame_config", ".", "game_config", ".", "dense_rewards", "and", "not", "self", ".", "idsgame_config", ".", "game_config", ".", "dense_rewards_v2", "and", "not", "self", ".", "idsgame_config", ".", "game_config", ".", "dense_rewards_v3", ":", "\n", "            ", "return", "-", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", ",", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", "\n", "", "elif", "self", ".", "idsgame_config", ".", "game_config", ".", "dense_rewards", "and", "self", ".", "idsgame_config", ".", "game_config", ".", "dense_rewards_v2", ":", "\n", "            ", "return", "-", "100", "*", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", ",", "100", "*", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", "\n", "", "elif", "self", ".", "idsgame_config", ".", "game_config", ".", "dense_rewards_v3", ":", "\n", "            ", "missed_defense", "=", "0", "\n", "for", "defense", "in", "self", ".", "defenses", ":", "\n", "                ", "match", "=", "False", "\n", "for", "attack", "in", "self", ".", "attacks", ":", "\n", "# if attack[0] == defense[0] and defense[2]:", "\n", "#     match = True", "\n", "                    ", "if", "not", "defense", "[", "2", "]", "and", "attack", "[", "0", "]", "==", "defense", "[", "0", "]", "and", "defense", "[", "1", "]", "==", "attack", "[", "1", "]", ":", "\n", "                        ", "match", "=", "True", "\n", "", "", "if", "not", "match", ":", "\n", "                    ", "missed_defense", "+=", "1", "\n", "\n", "", "", "attack_row", ",", "attack_col", "=", "self", ".", "state", ".", "attacker_pos", "\n", "row_ids", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "get_row_ids", "(", "attack_row", ")", "\n", "min_ats", "=", "self", ".", "state", ".", "min_attack_type", "(", "target_node_id", ",", "row_ids", ")", "\n", "\n", "added_defense", "=", "0", "\n", "for", "defense", "in", "self", ".", "defenses", ":", "\n", "# if defense[2] and defense[0] == target_node_id:", "\n", "#     added_defense += 1", "\n", "                ", "if", "not", "defense", "[", "2", "]", "and", "defense", "[", "1", "]", "==", "attack_type", "and", "defense", "[", "0", "]", "==", "target_node_id", ":", "\n", "                    ", "added_defense", "+=", "1", "\n", "\n", "", "", "defense_score", "=", "util", ".", "defense_score", "(", "self", ".", "state", ",", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ",", "self", ".", "idsgame_config", ".", "game_config", ")", "\n", "reference_defense_score", "=", "util", ".", "defense_score", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "initial_state", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ")", "\n", "if", "not", "reconnaissance", "and", "target_node_id", "in", "self", ".", "state", ".", "reconnaissance_actions", "and", "attack_type", "in", "min_ats", ":", "\n", "                ", "return", "0", ",", "(", "defense_score", "-", "reference_defense_score", ")", "\n", "", "else", ":", "\n", "                ", "return", "-", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", ",", "(", "defense_score", "-", "reference_defense_score", ")", "\n", "", "", "else", ":", "\n", "            ", "added_detection", "=", "0", "\n", "for", "defense", "in", "self", ".", "defenses", ":", "\n", "                ", "if", "defense", "[", "2", "]", "and", "defense", "[", "0", "]", "==", "target_node_id", ":", "\n", "                    ", "added_detection", "+=", "1", "\n", "", "", "detection_ratio", "=", "added_detection", "/", "(", "(", "detection_value", "+", "1", ")", ")", "\n", "blocked_attacks", "=", "0", "\n", "for", "defense", "in", "self", ".", "defenses", ":", "\n", "                ", "blocked", "=", "False", "\n", "for", "attack", "in", "self", ".", "attacks", ":", "\n", "                    ", "if", "defense", "[", "0", "]", "==", "attack", "[", "0", "]", "and", "defense", "[", "1", "]", "==", "attack", "[", "1", "]", "and", "defense", "[", "3", "]", "<", "attack", "[", "2", "]", ":", "\n", "                        ", "blocked", "=", "True", "\n", "", "", "if", "blocked", ":", "\n", "                    ", "blocked_attacks", "+=", "1", "\n", "", "", "norm_factor", "=", "self", ".", "state", ".", "game_step", "if", "self", ".", "state", ".", "game_step", ">", "0", "else", "1", "\n", "defender_reward", "=", "(", "blocked_attacks", ")", "/", "norm_factor", "\n", "#return 0*constants.GAME_CONFIG.POSITIVE_REWARD, added_detection", "\n", "#return -1 * constants.GAME_CONFIG.POSITIVE_REWARD, added_detection", "\n", "#return -constants.GAME_CONFIG.POSITIVE_REWARD, defender_reward", "\n", "# min_at = self.state.min_attack_type(target_node_id)", "\n", "# if target_node_id in self.state.reconnaissance_actions and min_at == attack_type:", "\n", "#     #print(\"min_at3\")", "\n", "#     return 0, constants.GAME_CONFIG.POSITIVE_REWARD", "\n", "return", "-", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", ",", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", "\n", "#else:", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_successful_attack_reward": [[527, 577], ["idsgame_env.IdsGameEnv.idsgame_config.game_config.network_config.get_row_ids", "idsgame_env.IdsGameEnv.state.min_attack_type", "max", "math.pow", "idsgame_env.IdsGameEnv.idsgame_config.game_config.network_config.get_node_id"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_row_ids", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.min_attack_type", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_id"], ["", "", "def", "get_successful_attack_reward", "(", "self", ",", "attack_type", ":", "int", ",", "node_id", ":", "int", ")", "->", "Union", "[", "int", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Returns the reward for the attacker and defender after a successful attack on some server in\n        the network\n\n        :return:(attacker_reward, defender_reward)\n        \"\"\"", "\n", "if", "not", "self", ".", "idsgame_config", ".", "game_config", ".", "dense_rewards", "and", "not", "self", ".", "idsgame_config", ".", "game_config", ".", "dense_rewards_v2", "and", "not", "self", ".", "idsgame_config", ".", "game_config", ".", "dense_rewards_v3", ":", "\n", "            ", "return", "0", ",", "0", "\n", "", "elif", "self", ".", "idsgame_config", ".", "game_config", ".", "dense_rewards", "and", "self", ".", "idsgame_config", ".", "game_config", ".", "dense_rewards_v2", ":", "\n", "            ", "attack_row", ",", "attack_col", "=", "self", ".", "state", ".", "attacker_pos", "\n", "if", "attack_row", "<", "self", ".", "furthest_hack", ":", "\n", "                ", "self", ".", "furthest_hack", "=", "attack_row", "\n", "return", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", ",", "-", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", "\n", "", "elif", "attack_row", ">", "self", ".", "furthest_hack", ":", "\n", "                ", "return", "-", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", ",", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", "\n", "", "return", "0", ",", "0", "\n", "", "elif", "self", ".", "idsgame_config", ".", "game_config", ".", "dense_rewards_v3", ":", "\n", "            ", "attack_row", ",", "attack_col", "=", "self", ".", "state", ".", "attacker_pos", "\n", "row_ids", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "get_row_ids", "(", "attack_row", ")", "\n", "min_ats", "=", "self", ".", "state", ".", "min_attack_type", "(", "node_id", ",", "row_ids", ")", "\n", "if", "node_id", "in", "self", ".", "state", ".", "reconnaissance_actions", "and", "attack_type", "in", "min_ats", ":", "\n", "                ", "num_good_attacks", "=", "1", "\n", "if", "(", "node_id", ",", "attack_type", ")", "in", "self", ".", "failed_attacks", ":", "\n", "                    ", "num_good_attacks", "=", "self", ".", "failed_attacks", "[", "(", "node_id", ",", "attack_type", ")", "]", "+", "1", "\n", "", "num_bad_attacks", "=", "0", "\n", "for", "k", "in", "self", ".", "failed_attacks", ":", "\n", "                    ", "n_id", ",", "at", "=", "k", "\n", "if", "not", "n_id", "==", "node_id", ":", "\n", "                        ", "num_bad_attacks", "=", "num_bad_attacks", "+", "1", "\n", "", "", "reward", "=", "max", "(", "num_good_attacks", "-", "math", ".", "pow", "(", "num_bad_attacks", ",", "2", ")", ",", "0", ")", "\n", "return", "reward", ",", "0", "\n", "", "return", "-", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", ",", "0", "\n", "", "else", ":", "\n", "            ", "attack_row", ",", "attack_col", "=", "self", ".", "state", ".", "attacker_pos", "\n", "bonus", "=", "1", "if", "self", ".", "num_failed_attacks", "==", "0", "else", "1", "/", "self", ".", "num_failed_attacks", "\n", "if", "attack_row", "<", "self", ".", "furthest_hack", ":", "\n", "                ", "self", ".", "furthest_hack", "=", "attack_row", "\n", "extra_reward", "=", "0", "\n", "if", "self", ".", "idsgame_config", ".", "extra_reconnaissance_reward", ":", "\n", "                    ", "for", "rec_act", "in", "self", ".", "past_reconnaissance_activities", ":", "\n", "                        ", "node_id", ",", "rec_type", "=", "rec_act", "\n", "server_id", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "get_node_id", "(", "self", ".", "state", ".", "attacker_pos", ")", "\n", "if", "node_id", "==", "server_id", ":", "\n", "                            ", "extra_reward", "=", "1", "\n", "", "", "", "return", "bonus", "+", "extra_reward", "+", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", ",", "0", "\n", "", "elif", "attack_row", ">", "self", ".", "furthest_hack", ":", "\n", "                ", "return", "-", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", ",", "0", "\n", "", "return", "0", ",", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.validate_config": [[578, 591], ["AssertionError", "AssertionError", "AssertionError"], "methods", ["None"], ["", "", "def", "validate_config", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Validates the configuration for the environment\n\n        :param idsgame_config: the config to validate\n        :return: None\n        \"\"\"", "\n", "if", "idsgame_config", ".", "game_config", ".", "num_layers", "<", "0", ":", "\n", "            ", "raise", "AssertionError", "(", "\"The number of layers cannot be less than 0\"", ")", "\n", "", "if", "idsgame_config", ".", "game_config", ".", "num_attack_types", "<", "1", ":", "\n", "            ", "raise", "AssertionError", "(", "\"The number of attack types cannot be less than 1\"", ")", "\n", "", "if", "idsgame_config", ".", "game_config", ".", "max_value", "<", "1", ":", "\n", "            ", "raise", "AssertionError", "(", "\"The max attack/defense value cannot be less than 1\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_blocked_attack_reward": [[592, 617], ["upd_defenses.append"], "methods", ["None"], ["", "", "def", "get_blocked_attack_reward", "(", "self", ",", "target_node_id", ":", "int", ",", "attack_type", ":", "int", ")", "->", "Union", "[", "int", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Returns the reward for the attacker and defender after a blocked attack on some server in\n        the network\n\n        :return:(attacker_reward, defender_reward)\n        \"\"\"", "\n", "if", "not", "self", ".", "idsgame_config", ".", "game_config", ".", "dense_rewards", "and", "not", "self", ".", "idsgame_config", ".", "game_config", ".", "dense_rewards_v2", ":", "\n", "            ", "return", "0", ",", "0", "\n", "", "elif", "self", ".", "idsgame_config", ".", "game_config", ".", "dense_rewards", "and", "not", "self", ".", "idsgame_config", ".", "game_config", ".", "dense_rewards_v2", ":", "\n", "            ", "return", "0", ",", "0", "\n", "", "else", ":", "\n", "            ", "upd_defenses", "=", "[", "]", "\n", "match", "=", "False", "\n", "for", "defense", "in", "self", ".", "defenses", ":", "\n", "                ", "if", "(", "(", "defense", "[", "0", "]", "==", "target_node_id", "and", "defense", "[", "1", "]", "==", "attack_type", ")", ")", "and", "not", "match", ":", "\n", "                   ", "match", "=", "True", "\n", "", "else", ":", "\n", "                    ", "upd_defenses", ".", "append", "(", "defense", ")", "\n", "", "", "self", ".", "defenses", "=", "upd_defenses", "\n", "if", "match", ":", "\n", "                ", "return", "0", ",", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", "\n", "", "upd_defenses", "=", "[", "]", "\n", "return", "0", ",", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_observation": [[618, 630], ["idsgame_env.IdsGameEnv.state.get_attacker_observation", "idsgame_env.IdsGameEnv.state.get_defender_observation"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.get_attacker_observation", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.get_defender_observation"], ["", "", "def", "get_observation", "(", "self", ")", "->", "Union", "[", "np", ".", "ndarray", ",", "np", ".", "ndarray", "]", ":", "\n", "        ", "\"\"\"\n        Returns an observation of the state\n\n        :return: (attacker_obs, defender_obs)\n        \"\"\"", "\n", "attacker_obs", "=", "self", ".", "state", ".", "get_attacker_observation", "(", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ",", "local_view", "=", "self", ".", "idsgame_config", ".", "local_view_observations", ",", "\n", "reconnaissance", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "reconnaissance_actions", ",", "\n", "reconnaissance_bool_features", "=", "self", ".", "idsgame_config", ".", "reconnaissance_bool_features", ")", "\n", "defender_obs", "=", "self", ".", "state", ".", "get_defender_observation", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ")", "\n", "return", "attacker_obs", ",", "defender_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.fully_observed": [[631, 638], ["None"], "methods", ["None"], ["", "def", "fully_observed", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Boolean function to check whether the environment is configured to be fully observed or not\n\n        :return: True if the environment is fully observed, otherwise false\n        \"\"\"", "\n", "return", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "fully_observed", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.local_view_features": [[639, 646], ["None"], "methods", ["None"], ["", "def", "local_view_features", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Boolean function to check whether the environment uses local view observations of the attacker\n\n        :return: True if the environment uses local view observations\n        \"\"\"", "\n", "return", "self", ".", "idsgame_config", ".", "local_view_observations", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_reconnaissance": [[647, 651], ["util.interpret_attack_action"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.interpret_attack_action"], ["", "def", "is_reconnaissance", "(", "self", ",", "action", ")", ":", "\n", "        ", "import", "gym_idsgame", ".", "envs", ".", "util", ".", "idsgame_util", "as", "util", "\n", "server_id", ",", "server_pos", ",", "attack_type", ",", "reconnaissance", "=", "util", ".", "interpret_attack_action", "(", "action", ",", "self", ".", "idsgame_config", ".", "game_config", ")", "\n", "return", "reconnaissance", "\n", "# if server_id not in self.state.reconnaissance_actions:", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_attacker_action": [[658, 661], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "get_attacker_action", "(", "self", ",", "action", ")", "->", "Union", "[", "int", ",", "Union", "[", "int", ",", "int", "]", ",", "int", "]", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.get_defender_action": [[662, 665], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "get_defender_action", "(", "self", ",", "action", ")", "->", "Union", "[", "Union", "[", "int", ",", "int", "]", ",", "int", ",", "int", "]", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.__setup_viewer": [[668, 679], ["os.path.dirname", "os.path.join", "Viewer", "idsgame_env.IdsGameEnv.viewer.agent_start"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.agent_start"], ["", "def", "__setup_viewer", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Setup for the viewer to use for rendering\n        :return: None\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "envs", ".", "rendering", ".", "viewer", "import", "Viewer", "\n", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "resource_path", "=", "os", ".", "path", ".", "join", "(", "script_dir", ",", "'./rendering/'", ",", "constants", ".", "RENDERING", ".", "RESOURCES_DIR", ")", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "resources_dir", "=", "resource_path", "\n", "self", ".", "viewer", "=", "Viewer", "(", "idsgame_config", "=", "self", ".", "idsgame_config", ")", "\n", "self", ".", "viewer", ".", "agent_start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv._build_state_to_idx_map": [[680, 698], ["list", "enumerate", "itertools.product", "int", "int", "list", "len", "math.pow", "range"], "methods", ["None"], ["", "def", "_build_state_to_idx_map", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Builds a map that maps states to index (useful when constructing Q-tables for example)\n\n        :return: the lookup map\n        \"\"\"", "\n", "n_state_elems", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_nodes", "*", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", ")", "\n", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "fully_observed", ":", "\n", "            ", "n_state_elems", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_nodes", "*", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", ")", "*", "2", "\n", "", "states", "=", "list", "(", "\n", "itertools", ".", "product", "(", "list", "(", "range", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "max_value", "+", "1", ")", ")", ",", "repeat", "=", "n_state_elems", ")", ")", "\n", "assert", "int", "(", "len", "(", "states", ")", ")", "==", "int", "(", "math", ".", "pow", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "max_value", "+", "1", ",", "n_state_elems", ")", ")", "\n", "state_to_idx", "=", "{", "}", "\n", "for", "idx", ",", "s", "in", "enumerate", "(", "states", ")", ":", "\n", "            ", "state_to_idx", "[", "s", "]", "=", "idx", "\n", "", "return", "state_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.AttackerEnv.__init__": [[708, 722], ["idsgame_env.IdsGameEnv.__init__", "idsgame_env.AttackerEnv.idsgame_config.game_config.get_attacker_observation_space", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.get_attacker_observation_space"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot instantiate env without configuration\"", ")", "\n", "", "if", "idsgame_config", ".", "defender_agent", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot instantiate attacker-env without a defender agent\"", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ",", "initial_state_path", "=", "initial_state_path", ")", "\n", "self", ".", "observation_space", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "get_attacker_observation_space", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.AttackerEnv.get_attacker_action": [[723, 727], ["util.interpret_attack_action"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.interpret_attack_action"], ["", "def", "get_attacker_action", "(", "self", ",", "action", ")", "->", "Union", "[", "int", ",", "Union", "[", "int", ",", "int", "]", ",", "int", "]", ":", "\n", "        ", "import", "gym_idsgame", ".", "envs", ".", "util", ".", "idsgame_util", "as", "util", "\n", "attacker_action", ",", "_", "=", "action", "\n", "return", "util", ".", "interpret_attack_action", "(", "attacker_action", ",", "self", ".", "idsgame_config", ".", "game_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.AttackerEnv.get_defender_action": [[728, 734], ["idsgame_env.AttackerEnv.idsgame_config.defender_agent.action", "util.interpret_defense_action"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.random_defense_bot_agent.RandomDefenseBotAgent.action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.interpret_defense_action"], ["", "def", "get_defender_action", "(", "self", ",", "action", ")", "->", "Union", "[", "Union", "[", "int", ",", "int", "]", ",", "int", ",", "int", "]", ":", "\n", "        ", "import", "gym_idsgame", ".", "envs", ".", "util", ".", "idsgame_util", "as", "util", "\n", "defend_id", "=", "self", ".", "idsgame_config", ".", "defender_agent", ".", "action", "(", "self", ".", "state", ")", "\n", "defend_node_id", ",", "defend_node_pos", ",", "defend_type", "=", "util", ".", "interpret_defense_action", "(", "\n", "defend_id", ",", "self", ".", "idsgame_config", ".", "game_config", ")", "\n", "return", "defend_node_id", ",", "defend_node_pos", ",", "defend_type", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.DefenderEnv.__init__": [[743, 757], ["idsgame_env.IdsGameEnv.__init__", "idsgame_env.DefenderEnv.idsgame_config.game_config.get_defender_observation_space", "ValueError", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.get_defender_observation_space"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot instantiate env without configuration\"", ")", "\n", "", "if", "idsgame_config", ".", "attacker_agent", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot instantiate defender-env without an attacker agent\"", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ",", "initial_state_path", "=", "initial_state_path", ")", "\n", "self", ".", "observation_space", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "get_defender_observation_space", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.DefenderEnv.get_defender_action": [[758, 762], ["util.interpret_defense_action"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.interpret_defense_action"], ["", "def", "get_defender_action", "(", "self", ",", "action", ")", "->", "Union", "[", "int", ",", "Union", "[", "int", ",", "int", "]", ",", "int", "]", ":", "\n", "        ", "import", "gym_idsgame", ".", "envs", ".", "util", ".", "idsgame_util", "as", "util", "\n", "_", ",", "defender_action", "=", "action", "\n", "return", "util", ".", "interpret_defense_action", "(", "defender_action", ",", "self", ".", "idsgame_config", ".", "game_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.DefenderEnv.get_attacker_action": [[763, 768], ["idsgame_env.DefenderEnv.idsgame_config.attacker_agent.action", "util.interpret_attack_action"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.random_defense_bot_agent.RandomDefenseBotAgent.action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.interpret_attack_action"], ["", "def", "get_attacker_action", "(", "self", ",", "action", ")", "->", "Union", "[", "Union", "[", "int", ",", "int", "]", ",", "int", ",", "int", ",", "bool", "]", ":", "\n", "        ", "import", "gym_idsgame", ".", "envs", ".", "util", ".", "idsgame_util", "as", "util", "\n", "attack_id", "=", "self", ".", "idsgame_config", ".", "attacker_agent", ".", "action", "(", "self", ".", "state", ")", "\n", "attack_node_id", ",", "attack_node_pos", ",", "attack_type", ",", "reconnaissance", "=", "util", ".", "interpret_attack_action", "(", "attack_id", ",", "self", ".", "idsgame_config", ".", "game_config", ")", "\n", "return", "attack_node_id", ",", "attack_node_pos", ",", "attack_type", ",", "reconnaissance", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.AttackDefenseEnv.__init__": [[776, 787], ["idsgame_env.IdsGameEnv.__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot instantiate env without configuration\"", ")", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ",", "initial_state_path", "=", "initial_state_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.AttackDefenseEnv.get_defender_action": [[788, 792], ["util.interpret_defense_action"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.interpret_defense_action"], ["", "def", "get_defender_action", "(", "self", ",", "action", ":", "Union", "[", "int", ",", "int", "]", ")", "->", "Union", "[", "int", ",", "Union", "[", "int", ",", "int", "]", ",", "int", "]", ":", "\n", "        ", "_", ",", "defender_action", "=", "action", "\n", "import", "gym_idsgame", ".", "envs", ".", "util", ".", "idsgame_util", "as", "util", "\n", "return", "util", ".", "interpret_defense_action", "(", "defender_action", ",", "self", ".", "idsgame_config", ".", "game_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.AttackDefenseEnv.get_attacker_action": [[793, 797], ["util.interpret_attack_action"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.interpret_attack_action"], ["", "def", "get_attacker_action", "(", "self", ",", "action", ":", "Union", "[", "int", ",", "int", "]", ")", "->", "Union", "[", "Union", "[", "int", ",", "int", "]", ",", "int", ",", "int", "]", ":", "\n", "        ", "attacker_action", ",", "_", "=", "action", "\n", "import", "gym_idsgame", ".", "envs", ".", "util", ".", "idsgame_util", "as", "util", "\n", "return", "util", ".", "interpret_attack_action", "(", "attacker_action", ",", "self", ".", "idsgame_config", ".", "game_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV0Env.__init__": [[814, 833], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v0\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV0Env.__init__": [[847, 866], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v0\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV0Env.__init__": [[880, 899], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v0\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV0Env.__init__": [[913, 932], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v0\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV0Env.__init__": [[946, 963], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v0\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV1Env.__init__": [[980, 999], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "4", ",", "det_val", "=", "3", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v1\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV1Env.__init__": [[1013, 1032], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "4", ",", "det_val", "=", "3", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v1\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV1Env.__init__": [[1046, 1065], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "4", ",", "det_val", "=", "3", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v1\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV1Env.__init__": [[1079, 1098], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "4", ",", "det_val", "=", "3", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v1\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV1Env.__init__": [[1112, 1129], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "4", ",", "det_val", "=", "3", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v1\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV2Env.__init__": [[1145, 1164], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "2", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v2\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV2Env.__init__": [[1178, 1197], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "2", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v2\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV2Env.__init__": [[1211, 1230], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "2", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v2\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV2Env.__init__": [[1244, 1263], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "2", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v2\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV2Env.__init__": [[1277, 1294], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "2", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v2\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV3Env.__init__": [[1310, 1329], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "2", ",", "num_servers_per_layer", "=", "3", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "3", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v3\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV3Env.__init__": [[1343, 1362], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "2", ",", "num_servers_per_layer", "=", "3", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "3", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v3\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV3Env.__init__": [[1376, 1395], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "2", ",", "num_servers_per_layer", "=", "3", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "3", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v3\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV3Env.__init__": [[1409, 1428], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "2", ",", "num_servers_per_layer", "=", "3", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "3", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v3\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV3Env.__init__": [[1442, 1459], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "2", ",", "num_servers_per_layer", "=", "3", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "3", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v3\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV4Env.__init__": [[1475, 1494], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "4", ",", "num_servers_per_layer", "=", "5", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "5", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v4\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV4Env.__init__": [[1508, 1527], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "4", ",", "num_servers_per_layer", "=", "5", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "5", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v4\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV4Env.__init__": [[1541, 1560], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "4", ",", "num_servers_per_layer", "=", "5", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "5", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v4\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV4Env.__init__": [[1574, 1593], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "4", ",", "num_servers_per_layer", "=", "5", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "5", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v4\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV4Env.__init__": [[1607, 1624], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "4", ",", "num_servers_per_layer", "=", "5", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "5", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v4\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV5Env.__init__": [[1639, 1660], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.network_config.NetworkConfig", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "4", ",", "num_servers_per_layer", "=", "5", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "2", ")", "\n", "game_config", ".", "network_config", "=", "NetworkConfig", "(", "game_config", ".", "num_rows", ",", "game_config", ".", "num_cols", ",", "\n", "connected_layers", "=", "True", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v5\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV5Env.__init__": [[1675, 1696], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.network_config.NetworkConfig", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "4", ",", "num_servers_per_layer", "=", "5", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "2", ")", "\n", "game_config", ".", "network_config", "=", "NetworkConfig", "(", "game_config", ".", "num_rows", ",", "game_config", ".", "num_cols", ",", "\n", "connected_layers", "=", "True", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v5\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV5Env.__init__": [[1710, 1731], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.network_config.NetworkConfig", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "4", ",", "num_servers_per_layer", "=", "5", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "2", ")", "\n", "game_config", ".", "network_config", "=", "NetworkConfig", "(", "game_config", ".", "num_rows", ",", "game_config", ".", "num_cols", ",", "\n", "connected_layers", "=", "True", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v5\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV5Env.__init__": [[1746, 1767], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.network_config.NetworkConfig", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "4", ",", "num_servers_per_layer", "=", "5", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "2", ")", "\n", "game_config", ".", "network_config", "=", "NetworkConfig", "(", "game_config", ".", "num_rows", ",", "game_config", ".", "num_cols", ",", "\n", "connected_layers", "=", "True", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v5\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV5Env.__init__": [[1781, 1800], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.network_config.NetworkConfig", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "4", ",", "num_servers_per_layer", "=", "5", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "2", ")", "\n", "game_config", ".", "network_config", "=", "NetworkConfig", "(", "game_config", ".", "num_rows", ",", "game_config", ".", "num_cols", ",", "\n", "connected_layers", "=", "True", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v5\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV6Env.__init__": [[1815, 1837], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.network_config.NetworkConfig", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "4", ",", "num_servers_per_layer", "=", "5", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "2", ")", "\n", "game_config", ".", "network_config", "=", "NetworkConfig", "(", "game_config", ".", "num_rows", ",", "game_config", ".", "num_cols", ",", "\n", "connected_layers", "=", "True", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v6\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV6Env.__init__": [[1852, 1874], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.network_config.NetworkConfig", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "4", ",", "num_servers_per_layer", "=", "5", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "2", ")", "\n", "game_config", ".", "network_config", "=", "NetworkConfig", "(", "game_config", ".", "num_rows", ",", "game_config", ".", "num_cols", ",", "\n", "connected_layers", "=", "True", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v6\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV6Env.__init__": [[1888, 1910], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.network_config.NetworkConfig", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "4", ",", "num_servers_per_layer", "=", "5", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "2", ")", "\n", "game_config", ".", "network_config", "=", "NetworkConfig", "(", "game_config", ".", "num_rows", ",", "game_config", ".", "num_cols", ",", "\n", "connected_layers", "=", "True", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v6\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV6Env.__init__": [[1925, 1947], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.network_config.NetworkConfig", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "4", ",", "num_servers_per_layer", "=", "5", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "2", ")", "\n", "game_config", ".", "network_config", "=", "NetworkConfig", "(", "game_config", ".", "num_rows", ",", "game_config", ".", "num_cols", ",", "\n", "connected_layers", "=", "True", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v6\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV6Env.__init__": [[1961, 1981], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.network_config.NetworkConfig", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "4", ",", "num_servers_per_layer", "=", "5", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "2", ")", "\n", "game_config", ".", "network_config", "=", "NetworkConfig", "(", "game_config", ".", "num_rows", ",", "game_config", ".", "num_cols", ",", "\n", "connected_layers", "=", "True", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v6\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV7Env.__init__": [[1997, 2017], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "2", ",", "num_servers_per_layer", "=", "3", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "3", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v7\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV7Env.__init__": [[2031, 2051], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "2", ",", "num_servers_per_layer", "=", "3", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "3", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v7\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV7Env.__init__": [[2065, 2085], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "2", ",", "num_servers_per_layer", "=", "3", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "3", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v7\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV7Env.__init__": [[2099, 2119], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "2", ",", "num_servers_per_layer", "=", "3", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "3", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v7\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV7Env.__init__": [[2133, 2151], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "2", ",", "num_servers_per_layer", "=", "3", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "3", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v7\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV8Env.__init__": [[2167, 2187], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v8\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV8Env.__init__": [[2201, 2221], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v8\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV8Env.__init__": [[2235, 2255], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v8\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV8Env.__init__": [[2269, 2289], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v8\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV8Env.__init__": [[2303, 2321], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v8\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV9Env.__init__": [[2337, 2357], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "2", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v9\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV9Env.__init__": [[2371, 2391], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "2", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v9\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV9Env.__init__": [[2405, 2425], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "2", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v9\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV9Env.__init__": [[2439, 2459], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "2", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v9\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV9Env.__init__": [[2473, 2491], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "2", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v9\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV10Env.__init__": [[2507, 2528], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v10\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV10Env.__init__": [[2542, 2563], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v10\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV10Env.__init__": [[2577, 2598], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v10\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV10Env.__init__": [[2612, 2633], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v10\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV10Env.__init__": [[2647, 2666], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "9", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "2", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v10\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV11Env.__init__": [[2681, 2702], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "0", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "2", ",", "max_value", "=", "2", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "0", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "0", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "0", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v11\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV11Env.__init__": [[2716, 2737], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "0", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "2", ",", "max_value", "=", "2", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "0", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "0", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "0", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v11\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV11Env.__init__": [[2751, 2772], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "0", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "2", ",", "max_value", "=", "2", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "0", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "0", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "0", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v11\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV11Env.__init__": [[2786, 2807], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "0", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "2", ",", "max_value", "=", "2", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "0", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "0", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "0", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v11\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV11Env.__init__": [[2821, 2840], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "0", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "2", ",", "max_value", "=", "2", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "0", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "0", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "0", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v11\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV12Env.__init__": [[2856, 2878], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "0", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "2", ",", "max_value", "=", "2", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "1", ",", "attack_val", "=", "1", ",", "num_vulnerabilities_per_node", "=", "0", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "0", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v12\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV12Env.__init__": [[2893, 2915], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "0", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "2", ",", "max_value", "=", "2", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "1", ",", "attack_val", "=", "1", ",", "num_vulnerabilities_per_node", "=", "0", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "0", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v12\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV12Env.__init__": [[2930, 2952], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "0", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "2", ",", "max_value", "=", "2", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "1", ",", "attack_val", "=", "1", ",", "num_vulnerabilities_per_node", "=", "0", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "0", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v12\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV12Env.__init__": [[2967, 2989], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "0", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "2", ",", "max_value", "=", "2", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "1", ",", "attack_val", "=", "1", ",", "num_vulnerabilities_per_node", "=", "0", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "0", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v12\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV12Env.__init__": [[3004, 3024], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "0", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "2", ",", "max_value", "=", "2", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "1", ",", "attack_val", "=", "1", ",", "num_vulnerabilities_per_node", "=", "0", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "0", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v12\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV13Env.__init__": [[3040, 3061], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "0", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "2", ",", "max_value", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "0", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "0", ",", "det_val", "=", "10", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "0", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v13\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV13Env.__init__": [[3075, 3096], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "0", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "2", ",", "max_value", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "0", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "0", ",", "det_val", "=", "10", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "0", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v13\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV13Env.__init__": [[3110, 3131], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "0", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "2", ",", "max_value", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "0", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "0", ",", "det_val", "=", "10", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "0", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v13\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV13Env.__init__": [[3145, 3166], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "0", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "2", ",", "max_value", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "0", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "0", ",", "det_val", "=", "10", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "0", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v13\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV13Env.__init__": [[3180, 3199], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "0", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "2", ",", "max_value", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "0", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "0", ",", "det_val", "=", "10", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "0", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v13\"", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV14Env.__init__": [[3216, 3241], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "4", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "3", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "game_config", ".", "network_config", ".", "relative_neighbor_positions", "=", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", "]", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v14\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "True", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV14Env.__init__": [[3256, 3281], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "4", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "3", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "game_config", ".", "network_config", ".", "relative_neighbor_positions", "=", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", "]", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v14\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "True", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV14Env.__init__": [[3296, 3321], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "4", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "3", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "game_config", ".", "network_config", ".", "relative_neighbor_positions", "=", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", "]", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v14\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "True", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV14Env.__init__": [[3336, 3361], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "4", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "3", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "game_config", ".", "network_config", ".", "relative_neighbor_positions", "=", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", "]", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v14\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "True", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV14Env.__init__": [[3376, 3399], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "4", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "3", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "game_config", ".", "network_config", ".", "relative_neighbor_positions", "=", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", "]", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v14\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "True", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV15Env.__init__": [[3417, 3442], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "10", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "2", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "game_config", ".", "network_config", ".", "relative_neighbor_positions", "=", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", "]", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v15\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "True", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV15Env.__init__": [[3457, 3482], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "10", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "2", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "game_config", ".", "network_config", ".", "relative_neighbor_positions", "=", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", "]", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v15\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "True", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV15Env.__init__": [[3497, 3522], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "10", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "2", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "game_config", ".", "network_config", ".", "relative_neighbor_positions", "=", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", "]", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v15\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "True", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV15Env.__init__": [[3537, 3562], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "10", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "2", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "game_config", ".", "network_config", ".", "relative_neighbor_positions", "=", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", "]", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v15\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "True", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV15Env.__init__": [[3577, 3600], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "10", ",", "max_value", "=", "10", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "2", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "2", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "game_config", ".", "network_config", ".", "relative_neighbor_positions", "=", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", "]", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v15\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "True", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV16Env.__init__": [[3617, 3643], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "4", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "3", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards_v2", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "game_config", ".", "network_config", ".", "relative_neighbor_positions", "=", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", "]", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v16\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV16Env.__init__": [[3658, 3684], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "4", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "3", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards_v2", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "game_config", ".", "network_config", ".", "relative_neighbor_positions", "=", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", "]", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v16\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV16Env.__init__": [[3699, 3725], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "4", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "3", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards_v2", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "game_config", ".", "network_config", ".", "relative_neighbor_positions", "=", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", "]", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v16\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV16Env.__init__": [[3740, 3766], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "4", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "1", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "4", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards_v2", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "game_config", ".", "network_config", ".", "relative_neighbor_positions", "=", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", "]", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v16\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV16Env.__init__": [[3781, 3805], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "4", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "3", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards_v2", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "True", "\n", "game_config", ".", "network_config", ".", "relative_neighbor_positions", "=", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", "]", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v16\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV17Env.__init__": [[3822, 3847], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "4", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "3", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards_v2", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v17\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV17Env.__init__": [[3862, 3887], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "4", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "3", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards_v2", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v17\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV17Env.__init__": [[3902, 3927], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "4", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "3", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards_v2", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v17\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV17Env.__init__": [[3942, 3967], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "4", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "1", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "4", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards_v2", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v17\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV17Env.__init__": [[3982, 4005], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "4", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "3", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "4", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "0", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards_v2", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v17\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV18Env.__init__": [[4021, 4052], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "len", "gym_idsgame.envs.dao.game_config.GameConfig.set_attack_actions", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_attack_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "7", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "7", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "7", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "1", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards_v2", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "game_config", ".", "reconnaissance_actions", "=", "True", "\n", "game_config", ".", "network_config", ".", "relative_neighbor_positions", "=", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", "]", "\n", "game_config", ".", "network_config", ".", "max_neighbors", "=", "len", "(", "game_config", ".", "network_config", ".", "relative_neighbor_positions", ")", "\n", "game_config", ".", "set_attack_actions", "(", "local_view", "=", "True", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v18\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_bool_features", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_actions", "=", "True", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV18Env.__init__": [[4067, 4099], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "len", "gym_idsgame.envs.dao.game_config.GameConfig.set_attack_actions", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_attack_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "7", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "7", ",", "min_random_det_val", "=", "1", ",", "\n", "max_random_v_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "7", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "1", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards_v2", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "game_config", ".", "reconnaissance_actions", "=", "True", "\n", "game_config", ".", "network_config", ".", "relative_neighbor_positions", "=", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", "]", "\n", "game_config", ".", "network_config", ".", "max_neighbors", "=", "len", "(", "game_config", ".", "network_config", ".", "relative_neighbor_positions", ")", "\n", "game_config", ".", "set_attack_actions", "(", "local_view", "=", "True", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v18\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_bool_features", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_actions", "=", "True", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV18Env.__init__": [[4114, 4145], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "len", "gym_idsgame.envs.dao.game_config.GameConfig.set_attack_actions", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_attack_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "7", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "7", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "7", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "1", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards_v2", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "game_config", ".", "reconnaissance_actions", "=", "True", "\n", "game_config", ".", "network_config", ".", "relative_neighbor_positions", "=", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", "]", "\n", "game_config", ".", "network_config", ".", "max_neighbors", "=", "len", "(", "game_config", ".", "network_config", ".", "relative_neighbor_positions", ")", "\n", "game_config", ".", "set_attack_actions", "(", "local_view", "=", "True", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v18\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_bool_features", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_actions", "=", "True", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV18Env.__init__": [[4160, 4191], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "len", "gym_idsgame.envs.dao.game_config.GameConfig.set_attack_actions", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_attack_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "7", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "7", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "7", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "1", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards_v2", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "game_config", ".", "reconnaissance_actions", "=", "True", "\n", "game_config", ".", "network_config", ".", "relative_neighbor_positions", "=", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", "]", "\n", "game_config", ".", "network_config", ".", "max_neighbors", "=", "len", "(", "game_config", ".", "network_config", ".", "relative_neighbor_positions", ")", "\n", "game_config", ".", "set_attack_actions", "(", "local_view", "=", "True", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v18\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_bool_features", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_actions", "=", "True", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV18Env.__init__": [[4206, 4235], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "len", "gym_idsgame.envs.dao.game_config.GameConfig.set_attack_actions", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_attack_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "1", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "7", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "7", ",", "min_random_det_val", "=", "1", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "7", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "1", ",", "num_vulnerabilities_per_layer", "=", "1", ")", "\n", "game_config", ".", "dense_rewards_v2", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "game_config", ".", "reconnaissance_actions", "=", "True", "\n", "game_config", ".", "network_config", ".", "relative_neighbor_positions", "=", "[", "(", "-", "1", ",", "0", ")", ",", "(", "1", ",", "0", ")", "]", "\n", "game_config", ".", "network_config", ".", "max_neighbors", "=", "len", "(", "game_config", ".", "network_config", ".", "relative_neighbor_positions", ")", "\n", "game_config", ".", "set_attack_actions", "(", "local_view", "=", "True", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v18\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_bool_features", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_actions", "=", "True", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV19Env.__init__": [[4252, 4286], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.game_config.GameConfig.set_attack_actions", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_attack_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "9", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "7", ",", "min_random_det_val", "=", "1", ",", "\n", "reconnaissance_actions", "=", "True", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "9", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "1", ",", "num_vulnerabilities_per_layer", "=", "1", ",", "\n", "randomize_visibility", "=", "True", ",", "visibility_p", "=", "0.0", ")", "\n", "game_config", ".", "dense_rewards_v3", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "game_config", ".", "reconnaissance_actions", "=", "True", "\n", "game_config", ".", "set_attack_actions", "(", "local_view", "=", "False", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v19\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "idsgame_config", ".", "reconnaissance_bool_features", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_actions", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_reward", "=", "False", "\n", "idsgame_config", ".", "randomize_visibility", "=", "False", "\n", "idsgame_config", ".", "visibility_p", "=", "0.0", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV19Env.__init__": [[4301, 4334], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "9", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "7", ",", "min_random_det_val", "=", "1", ",", "\n", "reconnaissance_actions", "=", "True", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "9", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "1", ",", "num_vulnerabilities_per_layer", "=", "1", ",", "\n", "randomize_visibility", "=", "True", ",", "visibility_p", "=", "0.0", ")", "\n", "game_config", ".", "dense_rewards_v3", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "game_config", ".", "reconnaissance_actions", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v19\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "idsgame_config", ".", "reconnaissance_bool_features", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_actions", "=", "True", "\n", "idsgame_config", ".", "randomize_visibility", "=", "False", "\n", "idsgame_config", ".", "visibility_p", "=", "0.0", "\n", "idsgame_config", ".", "reconnaissance_detection_factor", "=", "1", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV19Env.__init__": [[4349, 4383], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.game_config.GameConfig.set_attack_actions", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_attack_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "9", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "7", ",", "min_random_det_val", "=", "1", ",", "\n", "reconnaissance_actions", "=", "True", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "9", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "1", ",", "num_vulnerabilities_per_layer", "=", "1", ",", "\n", "randomize_visibility", "=", "True", ",", "visibility_p", "=", "0.0", ")", "\n", "game_config", ".", "dense_rewards_v3", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "game_config", ".", "reconnaissance_actions", "=", "True", "\n", "game_config", ".", "set_attack_actions", "(", "local_view", "=", "False", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v19\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "idsgame_config", ".", "reconnaissance_bool_features", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_actions", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_reward", "=", "False", "\n", "idsgame_config", ".", "randomize_visibility", "=", "False", "\n", "idsgame_config", ".", "visibility_p", "=", "0.0", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV19Env.__init__": [[4398, 4432], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.game_config.GameConfig.set_attack_actions", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_attack_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "9", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "7", ",", "min_random_det_val", "=", "1", ",", "\n", "reconnaissance_actions", "=", "True", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "9", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "1", ",", "num_vulnerabilities_per_layer", "=", "1", ",", "\n", "randomize_visibility", "=", "True", ",", "visibility_p", "=", "0.0", ")", "\n", "game_config", ".", "dense_rewards_v3", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "game_config", ".", "reconnaissance_actions", "=", "True", "\n", "game_config", ".", "set_attack_actions", "(", "local_view", "=", "False", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v19\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_bool_features", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "idsgame_config", ".", "reconnaissance_actions", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_reward", "=", "False", "\n", "idsgame_config", ".", "randomize_visibility", "=", "False", "\n", "idsgame_config", ".", "visibility_p", "=", "0.0", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV19Env.__init__": [[4447, 4479], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.game_config.GameConfig.set_attack_actions", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_attack_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "9", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "7", ",", "min_random_det_val", "=", "1", ",", "\n", "reconnaissance_actions", "=", "True", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "9", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "1", ",", "num_vulnerabilities_per_layer", "=", "1", ",", "\n", "randomize_visibility", "=", "True", ",", "visibility_p", "=", "0.0", ")", "\n", "game_config", ".", "dense_rewards_v3", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "game_config", ".", "reconnaissance_actions", "=", "True", "\n", "game_config", ".", "set_attack_actions", "(", "local_view", "=", "False", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v19\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_bool_features", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "idsgame_config", ".", "reconnaissance_actions", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_reward", "=", "False", "\n", "idsgame_config", ".", "randomize_visibility", "=", "False", "\n", "idsgame_config", ".", "visibility_p", "=", "0.0", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV20Env.__init__": [[4496, 4530], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.game_config.GameConfig.set_attack_actions", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_attack_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "9", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "3", ",", "min_random_det_val", "=", "1", ",", "\n", "reconnaissance_actions", "=", "True", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "9", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "1", ",", "num_vulnerabilities_per_layer", "=", "2", ",", "\n", "randomize_visibility", "=", "False", ",", "visibility_p", "=", "0.0", ")", "\n", "game_config", ".", "dense_rewards_v3", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "game_config", ".", "reconnaissance_actions", "=", "True", "\n", "game_config", ".", "set_attack_actions", "(", "local_view", "=", "False", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v20\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "idsgame_config", ".", "reconnaissance_bool_features", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_actions", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_reward", "=", "False", "\n", "idsgame_config", ".", "randomize_visibility", "=", "False", "\n", "idsgame_config", ".", "visibility_p", "=", "0.0", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV20Env.__init__": [[4545, 4578], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "9", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "3", ",", "min_random_det_val", "=", "1", ",", "\n", "reconnaissance_actions", "=", "True", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "9", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "1", ",", "num_vulnerabilities_per_layer", "=", "2", ",", "\n", "randomize_visibility", "=", "False", ",", "visibility_p", "=", "0.0", ")", "\n", "game_config", ".", "dense_rewards_v3", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "game_config", ".", "reconnaissance_actions", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v20\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "idsgame_config", ".", "reconnaissance_bool_features", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_actions", "=", "True", "\n", "idsgame_config", ".", "randomize_visibility", "=", "False", "\n", "idsgame_config", ".", "visibility_p", "=", "0.0", "\n", "idsgame_config", ".", "reconnaissance_detection_factor", "=", "1", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV20Env.__init__": [[4593, 4627], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.game_config.GameConfig.set_attack_actions", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_attack_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "9", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "3", ",", "min_random_det_val", "=", "1", ",", "\n", "reconnaissance_actions", "=", "True", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "9", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "1", ",", "num_vulnerabilities_per_layer", "=", "2", ",", "\n", "randomize_visibility", "=", "False", ",", "visibility_p", "=", "0.0", ")", "\n", "game_config", ".", "dense_rewards_v3", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "game_config", ".", "reconnaissance_actions", "=", "True", "\n", "game_config", ".", "set_attack_actions", "(", "local_view", "=", "False", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v20\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "idsgame_config", ".", "reconnaissance_bool_features", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_actions", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_reward", "=", "False", "\n", "idsgame_config", ".", "randomize_visibility", "=", "False", "\n", "idsgame_config", ".", "visibility_p", "=", "0.0", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV20Env.__init__": [[4642, 4676], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.game_config.GameConfig.set_attack_actions", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_attack_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "9", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "3", ",", "min_random_det_val", "=", "1", ",", "\n", "reconnaissance_actions", "=", "True", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "9", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "1", ",", "num_vulnerabilities_per_layer", "=", "2", ",", "\n", "randomize_visibility", "=", "False", ",", "visibility_p", "=", "0.0", ")", "\n", "game_config", ".", "dense_rewards_v3", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "game_config", ".", "reconnaissance_actions", "=", "True", "\n", "game_config", ".", "set_attack_actions", "(", "local_view", "=", "False", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v20\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_bool_features", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "idsgame_config", ".", "reconnaissance_actions", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_reward", "=", "False", "\n", "idsgame_config", ".", "randomize_visibility", "=", "False", "\n", "idsgame_config", ".", "visibility_p", "=", "0.0", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV20Env.__init__": [[4691, 4723], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.game_config.GameConfig.set_attack_actions", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_attack_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "9", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "3", ",", "min_random_det_val", "=", "1", ",", "\n", "reconnaissance_actions", "=", "True", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "9", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "1", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "1", ",", "num_vulnerabilities_per_layer", "=", "2", ",", "\n", "randomize_visibility", "=", "False", ",", "visibility_p", "=", "0.0", ")", "\n", "game_config", ".", "dense_rewards_v3", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "game_config", ".", "reconnaissance_actions", "=", "True", "\n", "game_config", ".", "set_attack_actions", "(", "local_view", "=", "False", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v19\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_bool_features", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "idsgame_config", ".", "reconnaissance_actions", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_reward", "=", "False", "\n", "idsgame_config", ".", "randomize_visibility", "=", "False", "\n", "idsgame_config", ".", "visibility_p", "=", "0.0", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomDefenseV21Env.__init__": [[4740, 4774], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.game_config.GameConfig.set_attack_actions", "RandomDefenseBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_attack_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_defense_bot_agent", "import", "RandomDefenseBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "9", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "1", ",", "min_random_det_val", "=", "1", ",", "\n", "reconnaissance_actions", "=", "True", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "1", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "0", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "1", ",", "num_vulnerabilities_per_layer", "=", "2", ",", "\n", "randomize_visibility", "=", "False", ",", "visibility_p", "=", "0.0", ")", "\n", "game_config", ".", "dense_rewards_v3", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "game_config", ".", "reconnaissance_actions", "=", "True", "\n", "game_config", ".", "set_attack_actions", "(", "local_view", "=", "False", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "RandomDefenseBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_defense-v21\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "idsgame_config", ".", "reconnaissance_bool_features", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_actions", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_reward", "=", "False", "\n", "idsgame_config", ".", "randomize_visibility", "=", "False", "\n", "idsgame_config", ".", "visibility_p", "=", "0.0", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMinimalDefenseV21Env.__init__": [[4789, 4822], ["idsgame_env.AttackerEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "DefendMinimalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "defend_minimal_value_bot_agent", "import", "DefendMinimalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "9", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "1", ",", "min_random_det_val", "=", "1", ",", "\n", "reconnaissance_actions", "=", "True", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "1", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "0", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "1", ",", "num_vulnerabilities_per_layer", "=", "2", ",", "\n", "randomize_visibility", "=", "False", ",", "visibility_p", "=", "0.0", ")", "\n", "game_config", ".", "dense_rewards_v3", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "game_config", ".", "reconnaissance_actions", "=", "True", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "defender_agent", "=", "DefendMinimalValueBotAgent", "(", "game_config", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "defender_agent", "=", "defender_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-minimal_defense-v21\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "idsgame_config", ".", "reconnaissance_bool_features", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_actions", "=", "True", "\n", "idsgame_config", ".", "randomize_visibility", "=", "False", "\n", "idsgame_config", ".", "visibility_p", "=", "0.0", "\n", "idsgame_config", ".", "reconnaissance_detection_factor", "=", "1", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameRandomAttackV21Env.__init__": [[4837, 4871], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.game_config.GameConfig.set_attack_actions", "RandomAttackBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_attack_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "random_attack_bot_agent", "import", "RandomAttackBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "9", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "1", ",", "min_random_det_val", "=", "1", ",", "\n", "reconnaissance_actions", "=", "True", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "1", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "0", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "1", ",", "num_vulnerabilities_per_layer", "=", "2", ",", "\n", "randomize_visibility", "=", "False", ",", "visibility_p", "=", "0.0", ")", "\n", "game_config", ".", "dense_rewards_v3", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "game_config", ".", "reconnaissance_actions", "=", "True", "\n", "game_config", ".", "set_attack_actions", "(", "local_view", "=", "False", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "RandomAttackBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-random_attack-v21\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "idsgame_config", ".", "reconnaissance_bool_features", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_actions", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_reward", "=", "False", "\n", "idsgame_config", ".", "randomize_visibility", "=", "False", "\n", "idsgame_config", ".", "visibility_p", "=", "0.0", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameMaximalAttackV21Env.__init__": [[4886, 4920], ["idsgame_env.DefenderEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.game_config.GameConfig.set_attack_actions", "AttackMaximalValueBotAgent", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_attack_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "from", "gym_idsgame", ".", "agents", ".", "bot_agents", ".", "attack_maximal_value_bot_agent", "import", "AttackMaximalValueBotAgent", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "9", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "1", ",", "min_random_det_val", "=", "1", ",", "\n", "reconnaissance_actions", "=", "True", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "1", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "0", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "1", ",", "num_vulnerabilities_per_layer", "=", "2", ",", "\n", "randomize_visibility", "=", "False", ",", "visibility_p", "=", "0.0", ")", "\n", "game_config", ".", "dense_rewards_v3", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "game_config", ".", "reconnaissance_actions", "=", "True", "\n", "game_config", ".", "set_attack_actions", "(", "local_view", "=", "False", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "attacker_agent", "=", "AttackMaximalValueBotAgent", "(", "game_config", ",", "self", ")", "\n", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ",", "attacker_agent", "=", "attacker_agent", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-maximal_attack-v21\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_bool_features", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "idsgame_config", ".", "reconnaissance_actions", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_reward", "=", "False", "\n", "idsgame_config", ".", "randomize_visibility", "=", "False", "\n", "idsgame_config", ".", "visibility_p", "=", "0.0", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameV21Env.__init__": [[4935, 4967], ["idsgame_env.AttackDefenseEnv.__init__", "gym_idsgame.envs.dao.game_config.GameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_initial_state", "gym_idsgame.envs.dao.game_config.GameConfig.set_attack_actions", "gym_idsgame.envs.dao.idsgame_config.IdsGameConfig", "gym_idsgame.envs.dao.game_config.GameConfig.set_load_initial_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_initial_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_attack_actions", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_config.GameConfig.set_load_initial_state"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", "=", "None", ",", "save_dir", ":", "str", "=", "None", ",", "initial_state_path", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Initialization of the environment\n\n        :param save_dir: directory to save outputs of the env\n        :param initial_state_path: path to the initial state (if none, use default)\n        :param idsgame_config: configuration of the environment (if not specified a default config is used)\n        \"\"\"", "\n", "if", "idsgame_config", "is", "None", ":", "\n", "            ", "game_config", "=", "GameConfig", "(", "num_layers", "=", "1", ",", "num_servers_per_layer", "=", "2", ",", "num_attack_types", "=", "4", ",", "max_value", "=", "9", ",", "\n", "min_random_a_val", "=", "0", ",", "min_random_d_val", "=", "1", ",", "min_random_det_val", "=", "1", ",", "\n", "reconnaissance_actions", "=", "True", ")", "\n", "game_config", ".", "set_initial_state", "(", "defense_val", "=", "1", ",", "attack_val", "=", "0", ",", "num_vulnerabilities_per_node", "=", "0", ",", "det_val", "=", "1", ",", "\n", "vulnerability_val", "=", "1", ",", "num_vulnerabilities_per_layer", "=", "2", ",", "\n", "randomize_visibility", "=", "False", ",", "visibility_p", "=", "0.0", ")", "\n", "game_config", ".", "dense_rewards_v3", "=", "True", "\n", "game_config", ".", "network_config", ".", "fully_observed", "=", "False", "\n", "game_config", ".", "reconnaissance_actions", "=", "True", "\n", "game_config", ".", "set_attack_actions", "(", "local_view", "=", "False", ")", "\n", "if", "initial_state_path", "is", "not", "None", ":", "\n", "                ", "game_config", ".", "set_load_initial_state", "(", "initial_state_path", ")", "\n", "", "idsgame_config", "=", "IdsGameConfig", "(", "game_config", "=", "game_config", ")", "\n", "idsgame_config", ".", "render_config", ".", "caption", "=", "\"idsgame-v21\"", "\n", "idsgame_config", ".", "randomize_env", "=", "True", "\n", "idsgame_config", ".", "randomize_starting_position", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_bool_features", "=", "True", "\n", "idsgame_config", ".", "local_view_observations", "=", "False", "\n", "idsgame_config", ".", "reconnaissance_actions", "=", "True", "\n", "idsgame_config", ".", "reconnaissance_reward", "=", "False", "\n", "idsgame_config", ".", "randomize_visibility", "=", "False", "\n", "idsgame_config", ".", "visibility_p", "=", "0.0", "\n", "", "super", "(", ")", ".", "__init__", "(", "idsgame_config", "=", "idsgame_config", ",", "save_dir", "=", "save_dir", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.__init__": [[33, 40], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", ")", ":", "\n", "        ", "\"\"\"\n\n        :param idsgame_config: configuratin for the IdsGameEnv\n        \"\"\"", "\n", "self", ".", "idsgame_config", "=", "idsgame_config", "\n", "self", ".", "isopen", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.manual_start_attacker": [[41, 53], ["gym_idsgame.envs.rendering.frames.game_frame.GameFrame", "pyglet.clock.schedule_interval", "pyglet.app.run"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run"], ["", "def", "manual_start_attacker", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Starts the IDS-game app in a manual mode where the attacker is controlled with keyboard and mouse\n\n        :return: None\n        \"\"\"", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_attacker", "=", "True", "\n", "self", ".", "gameframe", "=", "GameFrame", "(", "idsgame_config", "=", "self", ".", "idsgame_config", ")", "\n", "self", ".", "gameframe", ".", "on_close", "=", "self", ".", "window_closed_by_user", "\n", "self", ".", "isopen", "=", "True", "\n", "pyglet", ".", "clock", ".", "schedule_interval", "(", "self", ".", "gameframe", ".", "update", ",", "1", "/", "60.", ")", "\n", "pyglet", ".", "app", ".", "run", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.manual_start_defender": [[54, 66], ["gym_idsgame.envs.rendering.frames.game_frame.GameFrame", "pyglet.clock.schedule_interval", "pyglet.app.run"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.gym_idsgame.runnner.Runner.run"], ["", "def", "manual_start_defender", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Starts the IDS-game app in a manual mode where the defender is controlled with keyboard and mouse\n\n        :return: None\n        \"\"\"", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_defender", "=", "True", "\n", "self", ".", "gameframe", "=", "GameFrame", "(", "idsgame_config", "=", "self", ".", "idsgame_config", ")", "\n", "self", ".", "gameframe", ".", "on_close", "=", "self", ".", "window_closed_by_user", "\n", "self", ".", "isopen", "=", "True", "\n", "pyglet", ".", "clock", ".", "schedule_interval", "(", "self", ".", "gameframe", ".", "update", ",", "1", "/", "60.", ")", "\n", "pyglet", ".", "app", ".", "run", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.agent_start": [[67, 77], ["gym_idsgame.envs.rendering.frames.game_frame.GameFrame"], "methods", ["None"], ["", "def", "agent_start", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Creates the IDS-game frame in agent-mode, where actions are taken programmatically rather than through\n        moving mouse and keyboard.\n        \"\"\"", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_attacker", "=", "False", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_defender", "=", "False", "\n", "self", ".", "gameframe", "=", "GameFrame", "(", "idsgame_config", "=", "self", ".", "idsgame_config", ")", "\n", "self", ".", "gameframe", ".", "on_close", "=", "self", ".", "window_closed_by_user", "\n", "self", ".", "isopen", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.window_closed_by_user": [[78, 88], ["viewer.Viewer.gameframe.close", "print", "sys.exit"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "window_closed_by_user", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Callback when the frame is closed by the user\n\n        :return: None\n        \"\"\"", "\n", "self", ".", "isopen", "=", "False", "\n", "self", ".", "gameframe", ".", "close", "(", ")", "\n", "print", "(", "\"Window closed, exiting\"", ")", "\n", "sys", ".", "exit", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.close": [[89, 96], ["viewer.Viewer.gameframe.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "close", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Closes the frame\n\n        :return: None\n        \"\"\"", "\n", "self", ".", "gameframe", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render_frame": [[97, 116], ["viewer.Viewer.gameframe.clear", "viewer.Viewer.gameframe.switch_to", "viewer.Viewer.gameframe.dispatch_events", "viewer.Viewer.gameframe.on_draw", "viewer.Viewer.gameframe.flip", "viewer.Viewer.extract_rgb_array"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.clear", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.on_draw", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.extract_rgb_array"], ["", "def", "render_frame", "(", "self", ",", "return_rgb_array", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Renders a frame manually.\n\n        Using pyglet together with openAI gym means that we have to integrate OpenGL's event-loop\n        with the event-loop of the RL agent and the gym framework. That's why we render things manually and dispatch\n        events manually rather than just calling pyglet.app.run().\n\n        :param return_rgb_array: if this is true it returns the RGB array for the rendered frame (for recording)\n        :return: RGB array or bool\n        \"\"\"", "\n", "self", ".", "gameframe", ".", "clear", "(", ")", "# Clears the frame", "\n", "self", ".", "gameframe", ".", "switch_to", "(", ")", "# Make this window the current OpenGL rendering context", "\n", "self", ".", "gameframe", ".", "dispatch_events", "(", ")", "# Poll the OS for events and call related handlers for updating the frame", "\n", "self", ".", "gameframe", ".", "on_draw", "(", ")", "# Draw the frame", "\n", "if", "return_rgb_array", ":", "\n", "            ", "arr", "=", "self", ".", "extract_rgb_array", "(", ")", "\n", "", "self", ".", "gameframe", ".", "flip", "(", ")", "# Swaps the OpenGL front and back buffers Updates the visible display with the back buffer", "\n", "return", "arr", "if", "return_rgb_array", "else", "self", ".", "isopen", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render": [[118, 140], ["viewer.Viewer.gameframe.unschedule_events", "viewer.Viewer.render_frame", "frames.append", "range", "viewer.Viewer.gameframe.reset_events", "numpy.array", "viewer.Viewer.gameframe.simulate_events", "viewer.Viewer.render_frame", "frames.append", "time.sleep", "len", "len"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.unschedule_events", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render_frame", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset_events", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.simulate_events", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render_frame"], ["", "def", "render", "(", "self", ",", "return_rgb_array", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Renders a state of the IDS game. A single state might include many frames. For example if an attack or defense\n        move was made, this will cause several frames to visualize the attack/defense.\n\n        :param return_rgb_array: boolean whether to return rgb array or not\n\n        :return: RGB array or bool\n        \"\"\"", "\n", "self", ".", "gameframe", ".", "unschedule_events", "(", ")", "\n", "frames", "=", "[", "]", "\n", "arr", "=", "self", ".", "render_frame", "(", "return_rgb_array", ")", "\n", "frames", ".", "append", "(", "arr", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "gameframe", ".", "idsgame_config", ".", "render_config", ".", "num_blinks", ")", ":", "\n", "            ", "if", "len", "(", "self", ".", "gameframe", ".", "game_state", ".", "defense_events", ")", ">", "0", "or", "len", "(", "self", ".", "gameframe", ".", "game_state", ".", "attack_events", ")", ">", "0", ":", "\n", "                ", "self", ".", "gameframe", ".", "simulate_events", "(", "i", ")", "\n", "arr", "=", "self", ".", "render_frame", "(", "return_rgb_array", "=", "return_rgb_array", ")", "\n", "frames", ".", "append", "(", "arr", ")", "\n", "time", ".", "sleep", "(", "self", ".", "gameframe", ".", "idsgame_config", ".", "render_config", ".", "blink_interval", ")", "\n", "", "", "self", ".", "gameframe", ".", "reset_events", "(", ")", "\n", "\n", "return", "np", ".", "array", "(", "frames", ")", "if", "return_rgb_array", "else", "self", ".", "isopen", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.extract_rgb_array": [[141, 159], ["pyglet.image.get_buffer_manager().get_color_buffer", "pyglet.image.get_buffer_manager().get_color_buffer.get_image_data", "numpy.fromstring", "arr.reshape.reshape.reshape", "pyglet.image.get_buffer_manager().get_color_buffer.get_image_data.get_data", "pyglet.image.get_buffer_manager"], "methods", ["None"], ["", "def", "extract_rgb_array", "(", "self", ")", "->", "np", ".", "ndarray", ":", "\n", "        ", "\"\"\"\n        Extract RGB array from pyglet, this can then be used to record video of the rendering through gym's API\n\n        :return: RGB Array [height, width, 3]\n        \"\"\"", "\n", "buffer", "=", "pyglet", ".", "image", ".", "get_buffer_manager", "(", ")", ".", "get_color_buffer", "(", ")", "\n", "image_data", "=", "buffer", ".", "get_image_data", "(", ")", "\n", "arr", "=", "np", ".", "fromstring", "(", "image_data", ".", "get_data", "(", ")", ",", "dtype", "=", "np", ".", "uint8", ",", "sep", "=", "''", ")", "\n", "# In https://github.com/openai/gym-http-api/issues/2, we", "\n", "# discovered that someone using Xmonad on Arch was having", "\n", "# a window of size 598 x 398, though a 600 x 400 window", "\n", "# was requested. (Guess Xmonad was preserving a pixel for", "\n", "# the boundary.) So we use the buffer height/width rather", "\n", "# than the requested one.", "\n", "arr", "=", "arr", ".", "reshape", "(", "buffer", ".", "height", ",", "buffer", ".", "width", ",", "4", ")", "\n", "arr", "=", "arr", "[", ":", ":", "-", "1", ",", ":", ",", "0", ":", "3", "]", "\n", "return", "arr", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.__init__": [[20, 30], ["network.Network.__create_node", "range", "range"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.__create_node"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", ")", ":", "\n", "        ", "\"\"\"\n        Class constructor, initializes the network\n\n        :param idsgame_config: config for the IdsGameEnv\n        \"\"\"", "\n", "self", ".", "idsgame_config", "=", "idsgame_config", "\n", "self", ".", "grid", "=", "[", "[", "self", ".", "__create_node", "(", "i", ",", "j", ")", "for", "j", "in", "range", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_cols", ")", "]", "for", "i", "in", "\n", "range", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_rows", ")", "]", "\n", "self", ".", "horizontal_links", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.create_links": [[31, 101], ["network.Network.__root_edge", "network.Network.__leaf_edge", "[].get_link_coords", "network.Network.__create_horizontal_links", "[].get_link_coords", "network.Network.__create_horizontal_links", "network.Network.horizontal_links.append", "network.Network.horizontal_links.append", "range", "range", "range", "range", "[].add_out_edge", "range", "range", "range", "[].add_out_edge", "[].add_in_edge", "network.Network.__create_horizontal_links", "network.Network.horizontal_links.append", "range", "range", "range", "[].add_in_edge", "[].add_out_edge", "[].add_in_edge", "[].add_out_edge", "int", "network.Network.idsgame_config.game_config.network_config.get_coords_of_adjacency_matrix_id", "network.Network.idsgame_config.game_config.network_config.get_coords_of_adjacency_matrix_id", "[].add_horizontal_edge", "[].add_horizontal_edge", "network.Network.__create_link"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.__root_edge", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.__leaf_edge", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.get_link_coords", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.__create_horizontal_links", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.get_link_coords", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.__create_horizontal_links", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.add_out_edge", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.add_out_edge", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.add_in_edge", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.__create_horizontal_links", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.add_in_edge", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.add_out_edge", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.add_in_edge", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.add_out_edge", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_coords_of_adjacency_matrix_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_coords_of_adjacency_matrix_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.add_horizontal_edge", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.add_horizontal_edge", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.__create_link"], ["", "def", "create_links", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Creates links between the nodes in the network according to the game configuration\n        :return: None\n        \"\"\"", "\n", "\n", "# Create Root Link", "\n", "root_row", ",", "root_col", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "start_pos", "\n", "root_edge", "=", "self", ".", "__root_edge", "(", "self", ".", "grid", "[", "root_row", "]", "[", "root_col", "]", ")", "\n", "\n", "# Create Leaf Link", "\n", "leaf_edge", "=", "self", ".", "__leaf_edge", "(", "self", ".", "grid", "[", "0", "]", "[", "root_col", "]", ")", "\n", "\n", "# Create horizontal links (shared links)", "\n", "_", ",", "root_y", ",", "_", ",", "_", "=", "self", ".", "grid", "[", "root_row", "]", "[", "root_col", "]", ".", "get_link_coords", "(", "lower", "=", "True", ",", "upper", "=", "False", ")", "\n", "top_layer_links", "=", "self", ".", "__create_horizontal_links", "(", "root_y", ",", "self", ".", "idsgame_config", ".", "game_config", ".", "num_rows", "-", "2", ")", "\n", "_", ",", "data_y", ",", "_", ",", "_", "=", "self", ".", "grid", "[", "0", "]", "[", "root_col", "]", ".", "get_link_coords", "(", "lower", "=", "False", ",", "upper", "=", "True", ")", "\n", "bottom_layer_links", "=", "self", ".", "__create_horizontal_links", "(", "data_y", ",", "1", ")", "\n", "self", ".", "horizontal_links", ".", "append", "(", "bottom_layer_links", ")", "\n", "\n", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "connected_layers", ":", "\n", "            ", "for", "row", "in", "range", "(", "1", ",", "self", ".", "idsgame_config", ".", "game_config", ".", "num_rows", "-", "1", ")", ":", "\n", "                ", "y", "=", "self", ".", "grid", "[", "row", "]", "[", "0", "]", ".", "y", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "8.5", "\n", "links", "=", "self", ".", "__create_horizontal_links", "(", "y", ",", "row", ")", "\n", "self", ".", "horizontal_links", ".", "append", "(", "links", ")", "\n", "\n", "", "", "self", ".", "horizontal_links", ".", "append", "(", "top_layer_links", ")", "\n", "\n", "# Add horizontal links to each node (for dynamic visualization later on)", "\n", "for", "col", "in", "range", "(", "0", ",", "self", ".", "idsgame_config", ".", "game_config", ".", "num_cols", ")", ":", "\n", "            ", "if", "col", "<", "root_col", ":", "\n", "                ", "for", "i", "in", "range", "(", "col", ",", "root_col", ")", ":", "\n", "                    ", "self", ".", "grid", "[", "self", ".", "idsgame_config", ".", "game_config", ".", "num_rows", "-", "2", "]", "[", "col", "]", ".", "add_in_edge", "(", "top_layer_links", "[", "i", "]", ")", "\n", "self", ".", "grid", "[", "1", "]", "[", "col", "]", ".", "add_out_edge", "(", "bottom_layer_links", "[", "i", "]", ")", "\n", "", "", "if", "col", ">", "root_col", ":", "\n", "                ", "for", "i", "in", "range", "(", "root_col", ",", "col", ")", ":", "\n", "                    ", "self", ".", "grid", "[", "self", ".", "idsgame_config", ".", "game_config", ".", "num_rows", "-", "2", "]", "[", "col", "]", ".", "add_in_edge", "(", "top_layer_links", "[", "i", "]", ")", "\n", "self", ".", "grid", "[", "1", "]", "[", "col", "]", ".", "add_out_edge", "(", "bottom_layer_links", "[", "i", "]", ")", "\n", "\n", "", "", "", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "connected_layers", ":", "\n", "            ", "for", "row", "in", "range", "(", "1", ",", "self", ".", "idsgame_config", ".", "game_config", ".", "num_rows", "-", "1", ")", ":", "\n", "                ", "for", "col", "in", "range", "(", "0", ",", "self", ".", "idsgame_config", ".", "game_config", ".", "num_cols", ")", ":", "\n", "                    ", "if", "col", ">", "0", ":", "\n", "                        ", "self", ".", "grid", "[", "row", "]", "[", "col", "]", ".", "add_horizontal_edge", "(", "self", ".", "horizontal_links", "[", "row", "]", "[", "col", "-", "1", "]", ")", "\n", "", "if", "col", "<", "self", ".", "idsgame_config", ".", "game_config", ".", "num_cols", "-", "1", ":", "\n", "                        ", "self", ".", "grid", "[", "row", "]", "[", "col", "]", ".", "add_horizontal_edge", "(", "self", ".", "horizontal_links", "[", "row", "]", "[", "col", "]", ")", "\n", "\n", "# Create Leaf Link and Vertical Links between servers", "\n", "", "", "", "", "for", "i", "in", "range", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "adjacency_matrix", ".", "shape", "[", "0", "]", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "i", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "                ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "adjacency_matrix", "[", "i", "]", "[", "j", "]", "==", "int", "(", "1", ")", ":", "\n", "                    ", "row_1", ",", "col_1", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "get_coords_of_adjacency_matrix_id", "(", "i", ")", "\n", "n1", "=", "self", ".", "grid", "[", "row_1", "]", "[", "col_1", "]", "\n", "row_2", ",", "col_2", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "get_coords_of_adjacency_matrix_id", "(", "j", ")", "\n", "n2", "=", "self", ".", "grid", "[", "row_2", "]", "[", "col_2", "]", "\n", "if", "row_2", "!=", "row_1", ":", "\n", "                        ", "self", ".", "__create_link", "(", "n1", ",", "n2", ")", "\n", "\n", "# add leaf edge to servers on last layer", "\n", "", "", "", "", "for", "j", "in", "range", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_servers_per_layer", ")", ":", "\n", "            ", "row", "=", "1", "\n", "col", "=", "j", "\n", "self", ".", "grid", "[", "row", "]", "[", "col", "]", ".", "add_out_edge", "(", "leaf_edge", ")", "\n", "\n", "# add root edge to servers on first layer", "\n", "", "for", "j", "in", "range", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_servers_per_layer", ")", ":", "\n", "            ", "row", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_rows", "-", "2", "\n", "col", "=", "j", "\n", "self", ".", "grid", "[", "row", "]", "[", "col", "]", ".", "add_in_edge", "(", "root_edge", ")", "\n", "", "self", ".", "grid", "[", "root_row", "]", "[", "root_col", "]", ".", "add_out_edge", "(", "root_edge", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.__create_horizontal_links": [[103, 121], ["range", "range", "[].get_link_coords", "y_coords.append", "x_coords.append", "len", "gym_idsgame.envs.rendering.util.render_util.batch_line", "horizontal_edges.append", "len"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.get_link_coords", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_line"], ["", "def", "__create_horizontal_links", "(", "self", ",", "y_coord", ":", "float", ",", "row", ":", "int", ")", "->", "list", ":", "\n", "# create horizontal links of first layer that must be shared", "\n", "        ", "y_coords", "=", "[", "]", "\n", "x_coords", "=", "[", "]", "\n", "horizontal_edges", "=", "[", "]", "\n", "for", "col", "in", "range", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_servers_per_layer", ")", ":", "\n", "            ", "x1", ",", "y1", ",", "_", ",", "_", "=", "self", ".", "grid", "[", "row", "]", "[", "col", "]", ".", "get_link_coords", "(", "lower", "=", "True", ",", "upper", "=", "False", ")", "\n", "y_coords", ".", "append", "(", "y_coord", ")", "\n", "x_coords", ".", "append", "(", "x1", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "0", ",", "len", "(", "x_coords", ")", "-", "1", ")", ":", "\n", "            ", "if", "i", "<", "len", "(", "x_coords", ")", "-", "1", ":", "\n", "                ", "horizontal_edge", "=", "batch_line", "(", "x_coords", "[", "i", "]", ",", "y_coords", "[", "i", "]", ",", "x_coords", "[", "i", "+", "1", "]", ",", "y_coords", "[", "i", "+", "1", "]", ",", "\n", "constants", ".", "RENDERING", ".", "BLACK", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "background", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "line_width", ")", "\n", "horizontal_edges", ".", "append", "(", "horizontal_edge", ")", "\n", "", "", "return", "horizontal_edges", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.set_node_states": [[123, 136], ["range", "range", "node.set_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.set_state"], ["", "def", "set_node_states", "(", "self", ",", "game_state", ":", "GameState", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Updates the node states\n\n        :param game_state: the render state to update the nodes with\n        :return: None\n        \"\"\"", "\n", "for", "i", "in", "range", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_rows", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_cols", ")", ":", "\n", "                ", "node", "=", "self", ".", "grid", "[", "i", "]", "[", "j", "]", "\n", "if", "node", ".", "node_type", "!=", "NodeType", ".", "EMPTY", ":", "\n", "                    ", "node", ".", "set_state", "(", "game_state", ".", "attack_values", "[", "node", ".", "id", "]", ",", "game_state", ".", "defense_values", "[", "node", ".", "id", "]", ",", "\n", "game_state", ".", "defense_det", "[", "node", ".", "id", "]", ",", "game_state", ".", "reconnaissance_state", "[", "node", ".", "id", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.__create_node": [[137, 155], ["network.Network.idsgame_config.game_config.network_config.get_node_id", "gym_idsgame.envs.rendering.network.nodes.data_node.DataNode", "gym_idsgame.envs.rendering.network.nodes.start_node.StartNode", "gym_idsgame.envs.rendering.network.nodes.server_node.ServerNode", "gym_idsgame.envs.rendering.network.nodes.empty_node.EmptyNode"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_id"], ["", "", "", "", "def", "__create_node", "(", "self", ",", "row", ":", "int", ",", "col", ":", "int", ")", "->", "Node", ":", "\n", "        ", "\"\"\"\n        Creates a node in the network. Based on the network config it creates either a DATA node, a START node,\n        a SERVER node, or an EMPTY node.\n\n        :param row: row in the grid\n        :param col: column in the grid\n        :return: the created node\n        \"\"\"", "\n", "node_id", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "get_node_id", "(", "(", "row", ",", "col", ")", ")", "\n", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "graph_layout", "[", "row", "]", "[", "col", "]", "==", "NodeType", ".", "DATA", ".", "value", ":", "\n", "            ", "return", "DataNode", "(", "self", ".", "idsgame_config", ",", "row", ",", "col", ",", "node_id", ")", "# Data node", "\n", "", "elif", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "graph_layout", "[", "row", "]", "[", "col", "]", "==", "NodeType", ".", "START", ".", "value", ":", "\n", "            ", "return", "StartNode", "(", "self", ".", "idsgame_config", ",", "row", ",", "col", ",", "node_id", ")", "# Start node", "\n", "", "elif", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "graph_layout", "[", "row", "]", "[", "col", "]", "==", "NodeType", ".", "SERVER", ".", "value", ":", "\n", "            ", "return", "ServerNode", "(", "self", ".", "idsgame_config", ",", "row", ",", "col", ",", "node_id", ")", "# Server node", "\n", "", "else", ":", "\n", "            ", "return", "EmptyNode", "(", "self", ".", "idsgame_config", ",", "row", ",", "col", ",", "node_id", ")", "# Empty node", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.__create_link": [[156, 178], ["network.Network.__connect_start_and_server_nodes", "n1.add_out_edge", "n2.add_in_edge", "network.Network.__connect_server_and_server_nodes", "n1.add_out_edge", "n2.add_in_edge", "network.Network.__connect_server_and_data_nodes", "n1.add_out_edge", "n2.add_in_edge", "AssertionError"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.__connect_start_and_server_nodes", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.add_out_edge", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.add_in_edge", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.__connect_server_and_server_nodes", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.add_out_edge", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.add_in_edge", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.__connect_server_and_data_nodes", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.add_out_edge", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.add_in_edge"], ["", "", "def", "__create_link", "(", "self", ",", "n1", ":", "Node", ",", "n2", ":", "Node", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Creates a link in the network between two nodes\n\n        :param n1: node1\n        :param n2: node2\n        :return: None\n        \"\"\"", "\n", "if", "n1", ".", "node_type", "==", "NodeType", ".", "START", ":", "\n", "            ", "edge", "=", "self", ".", "__connect_start_and_server_nodes", "(", "n1", ",", "n2", ")", "\n", "n1", ".", "add_out_edge", "(", "edge", ")", "\n", "n2", ".", "add_in_edge", "(", "edge", ")", "\n", "", "elif", "n1", ".", "node_type", "==", "NodeType", ".", "SERVER", "and", "n2", ".", "node_type", "==", "NodeType", ".", "SERVER", ":", "\n", "            ", "edge", "=", "self", ".", "__connect_server_and_server_nodes", "(", "n1", ",", "n2", ")", "\n", "n1", ".", "add_out_edge", "(", "edge", ")", "\n", "n2", ".", "add_in_edge", "(", "edge", ")", "\n", "", "elif", "n1", ".", "node_type", "==", "NodeType", ".", "SERVER", "and", "n2", ".", "node_type", "==", "NodeType", ".", "DATA", ":", "\n", "            ", "edge", "=", "self", ".", "__connect_server_and_data_nodes", "(", "n1", ",", "n2", ")", "\n", "n1", ".", "add_out_edge", "(", "edge", ")", "\n", "n2", ".", "add_in_edge", "(", "edge", ")", "\n", "", "else", ":", "\n", "            ", "raise", "AssertionError", "(", "\"Linktype not recognized\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.get": [[179, 188], ["None"], "methods", ["None"], ["", "", "def", "get", "(", "self", ",", "pos", ":", "Union", "[", "int", ",", "int", "]", ")", "->", "Node", ":", "\n", "        ", "\"\"\"\n        Gets a node at a given position in the network\n\n        :param pos: the position to get the node from\n        :return: the node\n        \"\"\"", "\n", "row", ",", "col", "=", "pos", "\n", "return", "self", ".", "grid", "[", "row", "]", "[", "col", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.__root_edge": [[189, 203], ["n1.get_link_coords", "gym_idsgame.envs.rendering.util.render_util.batch_line"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.get_link_coords", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_line"], ["", "def", "__root_edge", "(", "self", ",", "n1", ":", "Node", ")", ":", "\n", "        ", "\"\"\"\n        Creates the \"root edge\", the edge between the START node and all immediate child nodes.\n        This edge is created in a special method because it should be blinking when visualizing all attacks on\n        the servers in the layer below the start node\n\n        :param n1: node1\n        :return: the created edge (openGL vertex list)\n        \"\"\"", "\n", "x1", ",", "y1", ",", "col1", ",", "row1", "=", "n1", ".", "get_link_coords", "(", "lower", "=", "True", ",", "upper", "=", "False", ")", "\n", "return", "batch_line", "(", "x1", ",", "y1", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "6", ",", "\n", "x1", ",", "y1", "-", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "6", ",", "\n", "constants", ".", "RENDERING", ".", "BLACK", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "background", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "line_width", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.__leaf_edge": [[204, 220], ["n1.get_link_coords", "gym_idsgame.envs.rendering.util.render_util.batch_line"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.get_link_coords", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_line"], ["", "def", "__leaf_edge", "(", "self", ",", "n1", ":", "Node", ")", ":", "\n", "        ", "\"\"\"\n        Creates the \"leaf edge\", the edge between the DATA node and the nodes on the layer above\n        This edge is created in a special method because it should be blinking when visualizing all attacks on\n        the data node\n\n        :param n1: node1\n        :return: the created edge (openGL vertex list)\n        \"\"\"", "\n", "leaf_edge", "=", "None", "\n", "x2", ",", "y2", ",", "col2", ",", "row2", "=", "n1", ".", "get_link_coords", "(", "upper", "=", "True", ",", "lower", "=", "False", ")", "\n", "leaf_edge", "=", "batch_line", "(", "x2", ",", "y2", ",", "x2", ",", "y2", "-", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "3", ",", "\n", "constants", ".", "RENDERING", ".", "BLACK", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "background", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "line_width", ")", "\n", "return", "leaf_edge", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.__connect_start_and_server_nodes": [[221, 234], ["n1.get_link_coords", "n2.get_link_coords", "gym_idsgame.envs.rendering.util.render_util.batch_line"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.get_link_coords", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.get_link_coords", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_line"], ["", "def", "__connect_start_and_server_nodes", "(", "self", ",", "n1", ":", "Node", ",", "n2", ":", "Node", ")", ":", "\n", "        ", "\"\"\"\n        Creates a vertical link between the start node and server nodes on the layer below\n\n        :param n1: node1\n        :param n2: node2\n        :return: a list of the created links\n        \"\"\"", "\n", "x1", ",", "y1", ",", "col1", ",", "row1", "=", "n1", ".", "get_link_coords", "(", "lower", "=", "True", ",", "upper", "=", "False", ")", "\n", "x2", ",", "y2", ",", "col2", ",", "row2", "=", "n2", ".", "get_link_coords", "(", "upper", "=", "True", ",", "lower", "=", "False", ")", "\n", "e1", "=", "batch_line", "(", "x2", ",", "y1", ",", "x2", ",", "y2", ",", "constants", ".", "RENDERING", ".", "BLACK", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "background", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "line_width", ")", "\n", "return", "e1", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.__connect_server_and_server_nodes": [[235, 247], ["n1.get_link_coords", "n2.get_link_coords", "gym_idsgame.envs.rendering.util.render_util.batch_line"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.get_link_coords", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.get_link_coords", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_line"], ["", "def", "__connect_server_and_server_nodes", "(", "self", ",", "n1", ":", "Node", ",", "n2", ":", "Node", ")", ":", "\n", "        ", "\"\"\"\n        Creates a vertical link between two server nodes\n        :param n1: node1\n        :param n2: node2\n        :return: the created link\n        \"\"\"", "\n", "_", ",", "y1", ",", "_", ",", "_", "=", "n1", ".", "get_link_coords", "(", "lower", "=", "True", ",", "upper", "=", "False", ")", "\n", "x2", ",", "y2", ",", "col2", ",", "row2", "=", "n2", ".", "get_link_coords", "(", "upper", "=", "True", ",", "lower", "=", "False", ")", "\n", "e1", "=", "batch_line", "(", "x2", ",", "y1", ",", "x2", ",", "y2", ",", "constants", ".", "RENDERING", ".", "BLACK", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "background", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "line_width", ")", "\n", "return", "e1", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.__connect_server_and_data_nodes": [[248, 261], ["n1.get_link_coords", "n2.get_link_coords", "gym_idsgame.envs.rendering.util.render_util.batch_line"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.get_link_coords", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.get_link_coords", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_line"], ["", "def", "__connect_server_and_data_nodes", "(", "self", ",", "n1", ":", "Node", ",", "n2", ":", "Node", ")", ":", "\n", "        ", "\"\"\"\n        Creates a vertical link between a server node and the data node\n\n        :param n1: node1\n        :param n2: node2\n        :return: the created link\n        \"\"\"", "\n", "x1", ",", "y1", ",", "col1", ",", "row1", "=", "n1", ".", "get_link_coords", "(", "upper", "=", "False", ",", "lower", "=", "True", ")", "\n", "x2", ",", "y2", ",", "col2", ",", "row2", "=", "n2", ".", "get_link_coords", "(", "upper", "=", "True", ",", "lower", "=", "False", ")", "\n", "e1", "=", "batch_line", "(", "x1", ",", "y1", ",", "x1", ",", "y2", ",", "constants", ".", "RENDERING", ".", "BLACK", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "background", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "line_width", ")", "\n", "return", "e1", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.server_node.ServerNode.__init__": [[16, 33], ["pyglet.resource.image", "gym_idsgame.envs.rendering.network.nodes.resource_node.ResourceNode.__init__", "server_node.ServerNode.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", ",", "row", ":", "int", ",", "col", ":", "int", ",", "id", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Initializes the node\n\n        :param idsgame_config: configuration for the IdsGameEnv\n        :param row: the row in the grid\n        :param col: the column in the grid\n        :param id: the id of the node\n        \"\"\"", "\n", "avatar", "=", "pyglet", ".", "resource", ".", "image", "(", "idsgame_config", ".", "render_config", ".", "server_filename", ")", "\n", "super", "(", "ServerNode", ",", "self", ")", ".", "__init__", "(", "avatar", ",", "idsgame_config", ",", "\n", "idsgame_config", ".", "render_config", ".", "background", ")", "\n", "self", ".", "col", "=", "col", "\n", "self", ".", "row", "=", "row", "\n", "self", ".", "_id", "=", "id", "\n", "self", ".", "scale", "=", "idsgame_config", ".", "render_config", ".", "server_scale", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.server_node.ServerNode.node_type": [[34, 40], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "node_type", "(", "self", ")", "->", "NodeType", ":", "\n", "        ", "\"\"\"\n        :return: the type of the node (SERVER)\n        \"\"\"", "\n", "return", "NodeType", ".", "SERVER", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.server_node.ServerNode.id": [[41, 47], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "id", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        :return: the id of the node\n        \"\"\"", "\n", "return", "self", ".", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.server_node.ServerNode.init_labels": [[48, 66], ["server_node.ServerNode.create_labels", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.create_labels"], ["", "def", "init_labels", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Initializes the labels of the node\n\n        :return: None\n        \"\"\"", "\n", "attack_label_x", "=", "self", ".", "x", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "14", "\n", "attack_label_y", "=", "self", ".", "row", "*", "int", "(", "(", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", ")", "/", "1.5", ")", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "4", "\n", "defense_label_x", "=", "self", ".", "x", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "14", "\n", "defense_label_y", "=", "self", ".", "row", "*", "int", "(", "(", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", ")", "/", "1.5", ")", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "7", "\n", "det_label_x", "=", "self", ".", "x", "-", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "12", "\n", "det_label_y", "=", "self", ".", "row", "*", "int", "(", "(", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", ")", "/", "1.5", ")", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "3", "\n", "self", ".", "create_labels", "(", "attack_label_x", "=", "attack_label_x", ",", "attack_label_y", "=", "attack_label_y", ",", "\n", "defense_label_x", "=", "defense_label_x", ",", "defense_label_y", "=", "defense_label_y", ",", "\n", "det_label_x", "=", "det_label_x", ",", "det_label_y", "=", "det_label_y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.server_node.ServerNode.visualize_attack": [[67, 83], ["range", "pyglet.clock.schedule_once", "pyglet.clock.schedule_once"], "methods", ["None"], ["", "def", "visualize_attack", "(", "self", ",", "attack_type", ":", "int", ",", "attacker_pos", ":", "Union", "[", "int", ",", "int", "]", ",", "edges_list", ":", "list", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Simulates an attack against the node.\n\n        :param attack_type: the type of the attack\n        :param attacker_pos: the current position of the attacker\n        :param edges_list: edges list for visualization (blinking)\n        :return: None\n        \"\"\"", "\n", "for", "i", "in", "range", "(", "0", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "num_blinks", ")", ":", "\n", "            ", "if", "i", "%", "2", "==", "0", ":", "\n", "                ", "clock", ".", "schedule_once", "(", "self", ".", "blink_red_attack", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "blink_interval", "*", "i", ",", "\n", "attacker_pos", ")", "\n", "", "else", ":", "\n", "                ", "clock", ".", "schedule_once", "(", "self", ".", "blink_black_attack", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "blink_interval", "*", "i", ",", "\n", "attacker_pos", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.server_node.ServerNode.blink_red_attack": [[84, 116], ["list", "list", "len", "len"], "methods", ["None"], ["", "", "", "def", "blink_red_attack", "(", "self", ",", "dt", ",", "attacker_pos", ":", "Union", "[", "int", ",", "int", "]", ",", "edges_list", ":", "list", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Makes the node and its links blink red to visualize an attack\n\n        :param dt: the time since the last scheduled blink\n        :param attacker_pos: the attackers position\n        :param edges_list: list of edges to blink\n        :return: None\n        \"\"\"", "\n", "color", "=", "constants", ".", "RENDERING", ".", "RED", "\n", "color_list", "=", "list", "(", "color", ")", "+", "list", "(", "color", ")", "\n", "attacker_row", ",", "attacker_col", "=", "attacker_pos", "\n", "if", "attacker_row", ">", "self", ".", "row", ":", "\n", "            ", "for", "edge", "in", "self", ".", "incoming_edges", ":", "\n", "                ", "edge", ".", "colors", "=", "color_list", "\n", "", "", "elif", "attacker_row", "<", "self", ".", "row", ":", "\n", "            ", "for", "edge", "in", "self", ".", "outgoing_edges", ":", "\n", "                ", "edge", ".", "colors", "=", "color_list", "\n", "", "", "else", ":", "\n", "#assert len(self.horizontal_edges) > 0", "\n", "            ", "if", "len", "(", "self", ".", "horizontal_edges", ")", ">", "0", ":", "\n", "                ", "if", "attacker_col", "<", "self", ".", "col", ":", "\n", "                    ", "self", ".", "horizontal_edges", "[", "0", "]", ".", "colors", "=", "color_list", "\n", "", "else", ":", "\n", "                    ", "if", "len", "(", "self", ".", "horizontal_edges", ")", ">", "1", ":", "\n", "                        ", "self", ".", "horizontal_edges", "[", "1", "]", ".", "colors", "=", "color_list", "\n", "", "else", ":", "\n", "                        ", "self", ".", "horizontal_edges", "[", "0", "]", ".", "colors", "=", "color_list", "\n", "\n", "", "", "", "", "lbl_color", "=", "constants", ".", "RENDERING", ".", "RED_ALPHA", "\n", "self", ".", "attack_label", ".", "color", "=", "lbl_color", "\n", "self", ".", "color", "=", "constants", ".", "RENDERING", ".", "RED", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.server_node.ServerNode.blink_black_attack": [[118, 149], ["list", "list", "len", "len"], "methods", ["None"], ["", "def", "blink_black_attack", "(", "self", ",", "dt", ",", "attacker_pos", ":", "Union", "[", "int", ",", "int", "]", ",", "edges_list", ":", "list", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Makes the node and its links blink black to visualize an attack\n\n        :param dt: the time since the last scheduled blink\n        :param attacker_pos: the attackers position\n        :param edges_list: list of edges to blink\n        :return: None\n        \"\"\"", "\n", "color", "=", "constants", ".", "RENDERING", ".", "BLACK", "\n", "color_list", "=", "list", "(", "color", ")", "+", "list", "(", "color", ")", "\n", "attacker_row", ",", "attacker_col", "=", "attacker_pos", "\n", "if", "attacker_row", ">", "self", ".", "row", ":", "\n", "            ", "for", "edge", "in", "self", ".", "incoming_edges", ":", "\n", "                ", "edge", ".", "colors", "=", "color_list", "\n", "", "", "elif", "attacker_row", "<", "self", ".", "row", ":", "\n", "            ", "for", "edge", "in", "self", ".", "outgoing_edges", ":", "\n", "                ", "edge", ".", "colors", "=", "color_list", "\n", "", "", "else", ":", "\n", "#assert len(self.horizontal_edges) > 0", "\n", "            ", "if", "len", "(", "self", ".", "horizontal_edges", ")", ">", "0", ":", "\n", "                ", "if", "attacker_col", "<", "self", ".", "col", ":", "\n", "                    ", "self", ".", "horizontal_edges", "[", "0", "]", ".", "colors", "=", "color_list", "\n", "", "else", ":", "\n", "                    ", "if", "len", "(", "self", ".", "horizontal_edges", ")", ">", "1", ":", "\n", "                        ", "self", ".", "horizontal_edges", "[", "1", "]", ".", "colors", "=", "color_list", "\n", "", "else", ":", "\n", "                        ", "self", ".", "horizontal_edges", "[", "0", "]", ".", "colors", "=", "color_list", "\n", "", "", "", "", "lbl_color", "=", "constants", ".", "RENDERING", ".", "BLACK_ALPHA", "\n", "self", ".", "attack_label", ".", "color", "=", "lbl_color", "\n", "self", ".", "color", "=", "constants", ".", "RENDERING", ".", "WHITE", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.server_node.ServerNode.center_avatar": [[150, 169], ["int"], "methods", ["None"], ["", "def", "center_avatar", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Utiltiy function for centering the avatar inside a cell\n\n        :return: The centered coordinates in the grid\n        \"\"\"", "\n", "if", "self", ".", "col", "<", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "num_cols", "//", "2", ")", ":", "\n", "            ", "self", ".", "x", "=", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "-", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "num_cols", "//", "2", "-", "(", "self", ".", "col", ")", ")", "*", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "\n", "", "elif", "self", ".", "col", ">", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "num_cols", "//", "2", ")", ":", "\n", "            ", "self", ".", "x", "=", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "+", "(", "self", ".", "col", "-", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "num_cols", "//", "2", ")", ")", "*", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "\n", "", "else", ":", "\n", "            ", "self", ".", "x", "=", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "\n", "\n", "", "self", ".", "y", "=", "int", "(", "(", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "1.5", ")", ")", "*", "self", ".", "row", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "3.5", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.server_node.ServerNode.get_link_coords": [[170, 187], ["None"], "methods", ["None"], ["", "def", "get_link_coords", "(", "self", ",", "upper", ":", "bool", "=", "True", ",", "lower", ":", "bool", "=", "False", ")", "->", "Union", "[", "float", ",", "float", ",", "int", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Gets the coordinates of link endpoints of the node\n\n        :param upper: if True, returns the upper endpoint\n        :param lower: if False, returns the lower endpoint\n        :return: (x-coordinate, y-coordinate, grid-column, grid-row)\n        \"\"\"", "\n", "if", "upper", ":", "\n", "            ", "x", "=", "self", ".", "x", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "14", "\n", "y", "=", "(", "self", ".", "row", "+", "1", ")", "*", "(", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "1.5", ")", "-", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "6", "\n", "", "elif", "lower", ":", "\n", "            ", "x", "=", "self", ".", "x", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "14", "\n", "y", "=", "(", "self", ".", "row", "+", "1", ")", "*", "(", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "1.5", ")", "-", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "1.75", "\n", "", "return", "x", ",", "y", ",", "self", ".", "col", ",", "self", ".", "row", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.node.Node.node_type": [[12, 16], ["None"], "methods", ["None"], ["@", "property", "\n", "@", "abstractmethod", "\n", "def", "node_type", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.node.Node.id": [[17, 21], ["None"], "methods", ["None"], ["", "@", "property", "\n", "@", "abstractmethod", "\n", "def", "id", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.node.Node.pos": [[22, 25], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "pos", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "row", ",", "self", ".", "col", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.node.Node.manual_blink_defense": [[26, 29], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "manual_blink_defense", "(", "self", ",", "i", ",", "detect", ":", "bool", "=", "False", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.node.Node.manual_blink_attack": [[30, 33], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "manual_blink_attack", "(", "self", ",", "i", ",", "attacker_pos", ":", "Union", "[", "int", ",", "int", "]", ",", "edges", "=", "None", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.node.Node.manual_reconnaissance": [[34, 37], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "manual_reconnaissance", "(", "self", ",", "i", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.node.Node.set_state": [[38, 41], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "set_state", "(", "self", ",", "attack_values", ",", "defense_values", ",", "det_value", ",", "reconnaissance_states", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.node.Node.unschedule": [[42, 45], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "unschedule", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.node.Node.visualize_defense": [[46, 49], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "visualize_defense", "(", "self", ",", "defense_type", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.node.Node.reset": [[50, 53], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "reset", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.node.Node.add_in_edge": [[54, 57], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "add_in_edge", "(", "self", ",", "edge", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.node.Node.add_horizontal_edge": [[58, 61], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "add_horizontal_edge", "(", "self", ",", "edge", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.node.Node.add_out_edge": [[62, 65], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "add_out_edge", "(", "self", ",", "edge", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.node.Node.get_link_coords": [[66, 69], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "get_link_coords", "(", "self", ",", "upper", "=", "True", ",", "lower", "=", "False", ")", ":", "\n", "        ", "pass", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.start_node.StartNode.__init__": [[15, 45], ["gym_idsgame.envs.rendering.network.nodes.node.Node.__init__", "start_node.StartNode.__draw", "int"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.start_node.StartNode.__draw"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", ",", "row", ":", "int", ",", "col", ":", "int", ",", "id", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Initializes the node\n\n        :param idsgame_config: configuratin for the IdsGameEnv\n        :param row: the row in the grid network\n        :param col: the column in the grid network\n        :param id: the id of the node\n        \"\"\"", "\n", "super", "(", "StartNode", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "idsgame_config", "=", "idsgame_config", "\n", "self", ".", "row", "=", "row", "\n", "self", ".", "col", "=", "col", "\n", "self", ".", "_id", "=", "id", "\n", "if", "self", ".", "col", "<", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "num_cols", "//", "2", ")", ":", "\n", "            ", "self", ".", "x", "=", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "-", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "num_cols", "//", "2", "-", "(", "self", ".", "col", ")", ")", "*", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "14", "\n", "", "elif", "self", ".", "col", ">", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "num_cols", "//", "2", ")", ":", "\n", "            ", "self", ".", "x", "=", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "+", "(", "self", ".", "col", "-", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "num_cols", "//", "2", ")", ")", "*", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "14", "\n", "", "else", ":", "\n", "            ", "self", ".", "x", "=", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "14", "\n", "", "self", ".", "y", "=", "self", ".", "row", "*", "int", "(", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "1.5", ")", "+", "(", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "1.5", ")", "/", "2", "\n", "self", ".", "radius", "=", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "7", "\n", "self", ".", "outgoing_edges", "=", "[", "]", "\n", "self", ".", "incoming_edges", "=", "[", "]", "\n", "self", ".", "__draw", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.start_node.StartNode.node_type": [[46, 52], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "node_type", "(", "self", ")", "->", "NodeType", ":", "\n", "        ", "\"\"\"\n        :return: the node type (START)\n        \"\"\"", "\n", "return", "NodeType", ".", "START", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.start_node.StartNode.id": [[53, 59], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "id", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        :return: the id of the node\n        \"\"\"", "\n", "return", "self", ".", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.start_node.StartNode.__draw": [[60, 68], ["gym_idsgame.envs.rendering.util.render_util.create_circle"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.create_circle"], ["", "def", "__draw", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Draws the node (a black circle)\n        :return: None\n        \"\"\"", "\n", "create_circle", "(", "self", ".", "x", ",", "self", ".", "y", ",", "self", ".", "radius", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "first_foreground", ",", "\n", "constants", ".", "RENDERING", ".", "BLACK", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.start_node.StartNode.get_link_coords": [[69, 83], ["None"], "methods", ["None"], ["", "def", "get_link_coords", "(", "self", ",", "upper", ":", "bool", "=", "True", ",", "lower", ":", "bool", "=", "False", ")", "->", "Union", "[", "float", ",", "float", ",", "int", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Gets the coordinates of link endpoints of the node\n\n        :param upper: if True, returns the upper endpoint\n        :param lower: if False, returns the lower endpoint\n        :return: (x-coordinate, y-coordinate, grid-column, grid-row)\n        \"\"\"", "\n", "# x = self.col * self.idsgame_config.render_config.rect_size + \\", "\n", "#     self.idsgame_config.render_config.rect_size / 2", "\n", "x", "=", "self", ".", "x", "\n", "y", "=", "(", "self", ".", "row", "+", "1", ")", "*", "(", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "1.5", ")", "-", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "1.75", "\n", "return", "x", ",", "y", ",", "self", ".", "col", ",", "self", ".", "row", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.start_node.StartNode.manual_blink_defense": [[87, 89], ["None"], "methods", ["None"], ["", "def", "manual_blink_defense", "(", "self", ",", "i", ",", "detect", ":", "bool", "=", "False", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.start_node.StartNode.manual_blink_attack": [[90, 92], ["None"], "methods", ["None"], ["", "def", "manual_blink_attack", "(", "self", ",", "i", ",", "attacker_pos", ":", "Union", "[", "int", ",", "int", "]", ",", "edges", "=", "None", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.start_node.StartNode.manual_reconnaissance": [[93, 95], ["None"], "methods", ["None"], ["", "def", "manual_reconnaissance", "(", "self", ",", "i", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.start_node.StartNode.set_state": [[96, 98], ["None"], "methods", ["None"], ["", "def", "set_state", "(", "self", ",", "attack_values", ",", "defense_values", ",", "det_value", ",", "reconnaissance_states", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.start_node.StartNode.visualize_defense": [[99, 101], ["None"], "methods", ["None"], ["", "def", "visualize_defense", "(", "self", ",", "defense_type", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.start_node.StartNode.reset": [[102, 104], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.start_node.StartNode.add_out_edge": [[105, 113], ["start_node.StartNode.outgoing_edges.append"], "methods", ["None"], ["", "def", "add_out_edge", "(", "self", ",", "edge", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Add an edge to the list of outgoing edges of the node\n\n        :param edge: edge to add\n        :return: None\n        \"\"\"", "\n", "self", ".", "outgoing_edges", ".", "append", "(", "edge", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.start_node.StartNode.add_in_edge": [[114, 122], ["start_node.StartNode.incoming_edges.append"], "methods", ["None"], ["", "def", "add_in_edge", "(", "self", ",", "edge", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Add an edge to the list of ingoing edges of the node\n\n        :param edge: edge to add\n        :return: None\n        \"\"\"", "\n", "self", ".", "incoming_edges", ".", "append", "(", "edge", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.start_node.StartNode.add_horizontal_edge": [[123, 125], ["None"], "methods", ["None"], ["", "def", "add_horizontal_edge", "(", "self", ",", "edge", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.start_node.StartNode.unschedule": [[126, 128], ["None"], "methods", ["None"], ["", "def", "unschedule", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.data_node.DataNode.__init__": [[16, 32], ["pyglet.resource.image", "gym_idsgame.envs.rendering.network.nodes.resource_node.ResourceNode.__init__", "data_node.DataNode.reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", ",", "row", ":", "int", ",", "col", ":", "int", ",", "id", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Constructor, Initializes the node\n\n        :param idsgame_config: config for IdsGameEnv\n        :param row: the row in the grid of the node\n        :param col: the column in the grid of the node\n        :param id: the id of the node\n        \"\"\"", "\n", "avatar", "=", "pyglet", ".", "resource", ".", "image", "(", "idsgame_config", ".", "render_config", ".", "data_filename", ")", "\n", "super", "(", "DataNode", ",", "self", ")", ".", "__init__", "(", "avatar", ",", "idsgame_config", ",", "idsgame_config", ".", "render_config", ".", "background", ")", "\n", "self", ".", "col", "=", "col", "\n", "self", ".", "row", "=", "row", "\n", "self", ".", "_id", "=", "id", "\n", "self", ".", "scale", "=", "idsgame_config", ".", "render_config", ".", "data_scale", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.data_node.DataNode.node_type": [[33, 39], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "node_type", "(", "self", ")", "->", "NodeType", ":", "\n", "        ", "\"\"\"\n        The node type\n        \"\"\"", "\n", "return", "NodeType", ".", "DATA", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.data_node.DataNode.id": [[40, 46], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "id", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        :return: the id of the node\n        \"\"\"", "\n", "return", "self", ".", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.data_node.DataNode.init_labels": [[47, 65], ["data_node.DataNode.create_labels", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.create_labels"], ["", "def", "init_labels", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Initializes labels of the node\n\n        :return: None\n        \"\"\"", "\n", "attack_label_x", "=", "self", ".", "x", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "14", "\n", "attack_label_y", "=", "self", ".", "row", "*", "int", "(", "(", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", ")", "/", "1.5", ")", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "4", "\n", "defense_label_x", "=", "self", ".", "x", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "14", "\n", "defense_label_y", "=", "self", ".", "row", "*", "int", "(", "(", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", ")", "/", "1.5", ")", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "7", "\n", "det_label_x", "=", "self", ".", "x", "-", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "12", "\n", "det_label_y", "=", "self", ".", "row", "*", "int", "(", "(", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", ")", "/", "1.5", ")", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "3", "\n", "self", ".", "create_labels", "(", "attack_label_x", "=", "attack_label_x", ",", "attack_label_y", "=", "attack_label_y", ",", "\n", "defense_label_x", "=", "defense_label_x", ",", "defense_label_y", "=", "defense_label_y", ",", "\n", "det_label_x", "=", "det_label_x", ",", "det_label_y", "=", "det_label_y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.data_node.DataNode.visualize_attack": [[66, 82], ["range", "pyglet.clock.schedule_once", "pyglet.clock.schedule_once"], "methods", ["None"], ["", "def", "visualize_attack", "(", "self", ",", "attack_type", ":", "int", ",", "attacker_pos", ":", "Union", "[", "int", ",", "int", "]", ",", "edges_list", ":", "list", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Simulates an attack against the node.\n\n        :param attack_type: the type of the attack\n        :param attacker_pos: the current position of the attacker\n        :param edges_list: edges list for visualization (blinking)\n        :return: None\n        \"\"\"", "\n", "for", "i", "in", "range", "(", "0", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "num_blinks", ")", ":", "\n", "            ", "if", "i", "%", "2", "==", "0", ":", "\n", "                ", "clock", ".", "schedule_once", "(", "self", ".", "blink_red_attack", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "blink_interval", "*", "i", ",", "attacker_pos", ",", "edges_list", ")", "\n", "", "else", ":", "\n", "                ", "clock", ".", "schedule_once", "(", "self", ".", "blink_black_attack", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "blink_interval", "*", "i", ",", "attacker_pos", ",", "edges_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.data_node.DataNode.blink_red_attack": [[83, 99], ["list", "list"], "methods", ["None"], ["", "", "", "def", "blink_red_attack", "(", "self", ",", "dt", ",", "attacker_pos", ":", "Union", "[", "int", ",", "int", "]", ",", "edges_list", ":", "list", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Makes the node and its links blink red to visualize an attack\n\n        :param dt: the time since the last scheduled blink\n        :param attacker_pos: the attackers position\n        :param edges_list: list of edges to blink\n        :return: None\n        \"\"\"", "\n", "color", "=", "constants", ".", "RENDERING", ".", "RED", "\n", "color_list", "=", "list", "(", "color", ")", "+", "list", "(", "color", ")", "\n", "for", "edge", "in", "edges_list", ":", "\n", "            ", "edge", ".", "colors", "=", "color_list", "\n", "", "lbl_color", "=", "constants", ".", "RENDERING", ".", "RED_ALPHA", "\n", "self", ".", "attack_label", ".", "color", "=", "lbl_color", "\n", "self", ".", "color", "=", "constants", ".", "RENDERING", ".", "RED", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.data_node.DataNode.blink_black_attack": [[100, 116], ["list", "list"], "methods", ["None"], ["", "def", "blink_black_attack", "(", "self", ",", "dt", ",", "attacker_pos", ":", "Union", "[", "int", ",", "int", "]", ",", "edges_list", ":", "list", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Makes the node and its links blink black to visualize an attack\n\n        :param dt: the time since the last scheduled blink\n        :param attacker_pos: the attackers position\n        :param edges_list: list of edges to blink\n        :return: None\n        \"\"\"", "\n", "color", "=", "constants", ".", "RENDERING", ".", "BLACK", "\n", "color_list", "=", "list", "(", "color", ")", "+", "list", "(", "color", ")", "\n", "for", "edge", "in", "edges_list", ":", "\n", "            ", "edge", ".", "colors", "=", "color_list", "\n", "", "lbl_color", "=", "constants", ".", "RENDERING", ".", "BLACK_ALPHA", "\n", "self", ".", "attack_label", ".", "color", "=", "lbl_color", "\n", "self", ".", "color", "=", "constants", ".", "RENDERING", ".", "WHITE", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.data_node.DataNode.center_avatar": [[117, 136], ["int"], "methods", ["None"], ["", "def", "center_avatar", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Utility function for centering the avatar inside a cell\n\n        :return: None\n        \"\"\"", "\n", "if", "self", ".", "col", "<", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "num_cols", "//", "2", ")", ":", "\n", "            ", "self", ".", "x", "=", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "-", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "num_cols", "//", "2", "-", "(", "self", ".", "col", ")", ")", "*", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "-", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "25", "\n", "", "elif", "self", ".", "col", ">", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "num_cols", "//", "2", ")", ":", "\n", "            ", "self", ".", "x", "=", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "+", "(", "self", ".", "col", "-", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "num_cols", "//", "2", ")", ")", "*", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "-", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "25", "\n", "", "else", ":", "\n", "            ", "self", ".", "x", "=", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "-", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "25", "\n", "\n", "", "self", ".", "y", "=", "int", "(", "(", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "1.5", ")", ")", "*", "self", ".", "row", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "3.5", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.data_node.DataNode.get_link_coords": [[137, 149], ["None"], "methods", ["None"], ["", "def", "get_link_coords", "(", "self", ",", "upper", ":", "bool", "=", "True", ",", "lower", ":", "bool", "=", "False", ")", "->", "Union", "[", "float", ",", "float", ",", "int", ",", "int", "]", ":", "\n", "        ", "\"\"\"\n        Gets the coordinates of link endpoints of the node\n\n        :param upper: if True, returns the upper endpoint\n        :param lower: if False, returns the lower endpoint\n        :return: (x-coordinate, y-coordinate, grid-column, grid-row)\n        \"\"\"", "\n", "assert", "not", "(", "upper", "and", "lower", ")", "\n", "x", "=", "self", ".", "x", "+", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "9", "\n", "y", "=", "(", "self", ".", "row", "+", "1", ")", "*", "(", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", "/", "1.5", ")", "\n", "return", "x", ",", "y", ",", "self", ".", "col", ",", "self", ".", "row", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.__init__": [[14, 28], ["gym_idsgame.envs.rendering.network.nodes.node.Node.__init__"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", ",", "row", ":", "int", ",", "col", ":", "int", ",", "id", ":", "int", ")", ":", "\n", "        ", "\"\"\"\n        Class constructor, initializes the node\n\n        :param idsgame_config: configuration for the IdsGameEnv\n        :param row: the row in the grid\n        :param col: the column in the grid\n        :param id: the id of the node\n        \"\"\"", "\n", "super", "(", "EmptyNode", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "idsgame_config", "=", "idsgame_config", "\n", "self", ".", "row", "=", "row", "\n", "self", ".", "col", "=", "col", "\n", "self", ".", "_id", "=", "id", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.node_type": [[29, 35], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "node_type", "(", "self", ")", "->", "NodeType", ":", "\n", "        ", "\"\"\"\n        :return: the node type\n        \"\"\"", "\n", "return", "NodeType", ".", "EMPTY", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.id": [[36, 42], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "id", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        :return: the id of the node\n        \"\"\"", "\n", "return", "self", ".", "_id", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.manual_blink_defense": [[46, 48], ["None"], "methods", ["None"], ["", "def", "manual_blink_defense", "(", "self", ",", "i", ",", "detect", ":", "bool", "=", "False", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.manual_blink_attack": [[49, 51], ["None"], "methods", ["None"], ["", "def", "manual_blink_attack", "(", "self", ",", "i", ",", "attacker_pos", ":", "Union", "[", "int", ",", "int", "]", ",", "edges", "=", "None", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.manual_reconnaissance": [[52, 54], ["None"], "methods", ["None"], ["", "def", "manual_reconnaissance", "(", "self", ",", "i", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.set_state": [[55, 57], ["None"], "methods", ["None"], ["", "def", "set_state", "(", "self", ",", "attack_values", ",", "defense_values", ",", "det_value", ",", "reconnaissance_states", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.visualize_defense": [[58, 60], ["None"], "methods", ["None"], ["", "def", "visualize_defense", "(", "self", ",", "detect", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.reset": [[61, 63], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.add_in_edge": [[64, 66], ["None"], "methods", ["None"], ["", "def", "add_in_edge", "(", "self", ",", "edge", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.add_out_edge": [[67, 69], ["None"], "methods", ["None"], ["", "def", "add_out_edge", "(", "self", ",", "edge", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.add_horizontal_edge": [[70, 72], ["None"], "methods", ["None"], ["", "def", "add_horizontal_edge", "(", "self", ",", "edge", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.get_link_coords": [[73, 75], ["None"], "methods", ["None"], ["", "def", "get_link_coords", "(", "self", ",", "upper", "=", "True", ",", "lower", "=", "False", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.get_coords": [[76, 78], ["None"], "methods", ["None"], ["", "def", "get_coords", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.get_node": [[79, 81], ["None"], "methods", ["None"], ["", "def", "get_node", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.empty_node.EmptyNode.unschedule": [[82, 84], ["None"], "methods", ["None"], ["", "def", "unschedule", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.__init__": [[21, 40], ["super().__init__", "pyglet.resource.image", "pyglet.sprite.Sprite", "resource_node.ResourceNode.initialize_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.initialize_state"], ["def", "__init__", "(", "self", ",", "avatar", ",", "idsgame_config", ":", "IdsGameConfig", ",", "group", ")", ":", "\n", "        ", "\"\"\"\n        Class constructor, initializes the resource node\n\n        :param avatar: the avatar of the node\n        :param idsgame_config: configuration for the IdsGameEnv\n        :param group: the group to render the resource in (background or foreground)\n        \"\"\"", "\n", "self", ".", "idsgame_config", "=", "idsgame_config", "\n", "super", "(", "ResourceNode", ",", "self", ")", ".", "__init__", "(", "avatar", ",", "batch", "=", "idsgame_config", ".", "render_config", ".", "batch", ",", "group", "=", "group", ")", "\n", "self", ".", "outgoing_edges", "=", "[", "]", "\n", "self", ".", "incoming_edges", "=", "[", "]", "\n", "self", ".", "horizontal_edges", "=", "[", "]", "\n", "self", ".", "glass_avatar", "=", "pyglet", ".", "resource", ".", "image", "(", "self", ".", "idsgame_config", ".", "render_config", ".", "glass_filename", ")", "\n", "self", ".", "glass", "=", "pyglet", ".", "sprite", ".", "Sprite", "(", "self", ".", "glass_avatar", ",", "x", "=", "self", ".", "x", ",", "y", "=", "self", ".", "y", ",", "batch", "=", "idsgame_config", ".", "render_config", ".", "batch", ",", "\n", "group", "=", "idsgame_config", ".", "render_config", ".", "second_foreground", ")", "\n", "self", ".", "glass", ".", "scale", "=", "self", ".", "idsgame_config", ".", "render_config", ".", "cage_scale", "\n", "self", ".", "glass", ".", "visible", "=", "False", "\n", "self", ".", "initialize_state", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.visualize_defense": [[41, 55], ["range", "pyglet.clock.schedule_once", "pyglet.clock.schedule_once"], "methods", ["None"], ["", "def", "visualize_defense", "(", "self", ",", "detect", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Simulates defense of the node\n\n        :param detect: whether it is a detection defense or not\n        :return: None\n        \"\"\"", "\n", "for", "i", "in", "range", "(", "0", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "num_blinks", ")", ":", "\n", "            ", "if", "i", "%", "2", "==", "0", ":", "\n", "                ", "clock", ".", "schedule_once", "(", "self", ".", "blink_green_defense", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "blink_interval", "*", "i", ",", "\n", "detect", "=", "detect", ")", "\n", "", "else", ":", "\n", "                ", "clock", ".", "schedule_once", "(", "self", ".", "blink_black_defense", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "blink_interval", "*", "i", ",", "\n", "detect", "=", "detect", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.set_labels": [[56, 65], ["None"], "methods", ["None"], ["", "", "", "def", "set_labels", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Updates the labels of the node\n\n        :return: None\n        \"\"\"", "\n", "self", ".", "attack_label", ".", "text", "=", "self", ".", "attack_text", "\n", "self", ".", "defense_label", ".", "text", "=", "self", ".", "defense_text", "\n", "self", ".", "det_label", ".", "text", "=", "self", ".", "det_text", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.attack_text": [[66, 77], ["len", "map", "str"], "methods", ["None"], ["", "@", "property", "\n", "def", "attack_text", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        :return: the attack text of the node\n        \"\"\"", "\n", "if", "self", ".", "idsgame_config", ".", "render_config", ".", "attacker_view", "or", "(", "not", "self", ".", "idsgame_config", ".", "render_config", ".", "attacker_view", "and", "not", "self", ".", "idsgame_config", ".", "render_config", ".", "defender_view", ")", ":", "\n", "            ", "return", "\"A=\"", "+", "\",\"", ".", "join", "(", "map", "(", "lambda", "x", ":", "str", "(", "x", ")", ",", "self", ".", "attack_values", ")", ")", "\n", "", "else", ":", "\n", "            ", "dummy_values", "=", "[", "\"x\"", "]", "*", "len", "(", "self", ".", "attack_values", ")", "\n", "return", "\"A=\"", "+", "\",\"", ".", "join", "(", "dummy_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.defense_text": [[78, 95], ["len", "enumerate", "map", "str", "str"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "defense_text", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        :return: the defense text of the node\n        \"\"\"", "\n", "if", "self", ".", "idsgame_config", ".", "render_config", ".", "defender_view", "or", "(", "not", "self", ".", "idsgame_config", ".", "render_config", ".", "attacker_view", "and", "\n", "not", "self", ".", "idsgame_config", ".", "render_config", ".", "defender_view", ")", ":", "\n", "            ", "return", "\"D=\"", "+", "\",\"", ".", "join", "(", "map", "(", "lambda", "x", ":", "str", "(", "x", ")", ",", "self", ".", "defense_values", ")", ")", "\n", "", "else", ":", "\n", "            ", "dummy_values", "=", "[", "\"x\"", "]", "*", "len", "(", "self", ".", "defense_values", ")", "\n", "if", "self", ".", "idsgame_config", ".", "reconnaissance_actions", ":", "\n", "                ", "constants", ".", "GAME_CONFIG", ".", "INITIAL_RECONNAISSANCE_STATE", "\n", "for", "idx", ",", "rec", "in", "enumerate", "(", "self", ".", "reconnaissance_state", ")", ":", "\n", "                    ", "if", "rec", "!=", "constants", ".", "GAME_CONFIG", ".", "INITIAL_RECONNAISSANCE_STATE", ":", "\n", "                        ", "dummy_values", "[", "idx", "]", "=", "str", "(", "rec", ")", "\n", "", "", "", "return", "\"D=\"", "+", "\",\"", ".", "join", "(", "dummy_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.det_text": [[96, 107], ["str"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "det_text", "(", "self", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        :return: the detection text of the node\n        \"\"\"", "\n", "if", "self", ".", "idsgame_config", ".", "render_config", ".", "defender_view", "or", "(", "not", "self", ".", "idsgame_config", ".", "render_config", ".", "attacker_view", "and", "\n", "not", "self", ".", "idsgame_config", ".", "render_config", ".", "defender_view", ")", ":", "\n", "            ", "return", "\"Det=\"", "+", "str", "(", "self", ".", "det", ")", "\n", "", "else", ":", "\n", "            ", "return", "\"Det=x\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.initialize_state": [[108, 117], ["None"], "methods", ["None"], ["", "", "def", "initialize_state", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        initializes the state of the node\n        :return: None\n        \"\"\"", "\n", "self", ".", "attack_values", "=", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "self", ".", "defense_values", "=", "[", "2", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", "]", "\n", "self", ".", "reconnaissance_state", "=", "[", "constants", ".", "GAME_CONFIG", ".", "INITIAL_RECONNAISSANCE_STATE", "]", "*", "10", "\n", "self", ".", "det", "=", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.blink_green_defense": [[118, 132], ["None"], "methods", ["None"], ["", "def", "blink_green_defense", "(", "self", ",", "dt", ",", "detect", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Visualizes a defense action by blinking green\n\n        :param dt: the time since the last blink\n        :param detect: whether it is a detection type of defense or not\n        :return: None\n        \"\"\"", "\n", "color", "=", "constants", ".", "RENDERING", ".", "GREEN_ALPHA", "\n", "if", "detect", ":", "\n", "            ", "self", ".", "det_label", ".", "color", "=", "color", "\n", "", "else", ":", "\n", "            ", "self", ".", "defense_label", ".", "color", "=", "color", "\n", "", "self", ".", "color", "=", "constants", ".", "RENDERING", ".", "GREEN", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.blink_black_defense": [[133, 147], ["None"], "methods", ["None"], ["", "def", "blink_black_defense", "(", "self", ",", "dt", ",", "detect", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Visualizes a defense action by blinking black\n\n        :param dt: time since the last blink\n        :param detect: whether it is a detection type of defense or not\n        :return: None\n        \"\"\"", "\n", "color", "=", "constants", ".", "RENDERING", ".", "BLACK_ALPHA", "\n", "if", "detect", ":", "\n", "            ", "self", ".", "det_label", ".", "color", "=", "color", "\n", "", "else", ":", "\n", "            ", "self", ".", "defense_label", ".", "color", "=", "color", "\n", "", "self", ".", "color", "=", "constants", ".", "RENDERING", ".", "WHITE", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.unschedule": [[148, 155], ["pyglet.clock.unschedule", "pyglet.clock.unschedule"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.unschedule", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.unschedule"], ["", "def", "unschedule", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Unschedules all event of this node (e.g blink events)\n        :return:\n        \"\"\"", "\n", "clock", ".", "unschedule", "(", "self", ".", "blink_green_defense", ")", "\n", "clock", ".", "unschedule", "(", "self", ".", "blink_red_attack", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.set_state": [[156, 171], ["resource_node.ResourceNode.set_labels"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.set_labels"], ["", "def", "set_state", "(", "self", ",", "attack_values", ",", "defense_values", ",", "det_value", ",", "reconnaissance_state", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Sets the state of the node\n\n        :param attack_values: attack values\n        :param defense_values: defense values\n        :param det_value: detection probabilities\n        :param reconnaissance_state: reconnaissance_state values\n        :return: None\n        \"\"\"", "\n", "self", ".", "attack_values", "=", "attack_values", "\n", "self", ".", "defense_values", "=", "defense_values", "\n", "self", ".", "det", "=", "det_value", "\n", "self", ".", "reconnaissance_state", "=", "reconnaissance_state", "\n", "self", ".", "set_labels", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.manual_blink_defense": [[172, 185], ["resource_node.ResourceNode.blink_green_defense", "resource_node.ResourceNode.blink_black_defense"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.blink_green_defense", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.blink_black_defense"], ["", "def", "manual_blink_defense", "(", "self", ",", "i", ":", "int", ",", "detect", ":", "bool", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Manual defense blink, when not using the clock to schedule blinks but rather ticking the clock manually.\n        Used when the agent plays the game and not a human.\n\n        :param i: the blink number\n        :param detect: whether it is a detection defense or not\n        :return: None\n        \"\"\"", "\n", "if", "i", "%", "2", "==", "0", ":", "\n", "            ", "self", ".", "blink_green_defense", "(", "0", ",", "detect", "=", "detect", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "blink_black_defense", "(", "0", ",", "detect", "=", "detect", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.manual_blink_attack": [[186, 200], ["resource_node.ResourceNode.blink_red_attack", "resource_node.ResourceNode.blink_black_attack"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.blink_red_attack", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.blink_black_attack"], ["", "", "def", "manual_blink_attack", "(", "self", ",", "i", ":", "int", ",", "attacker_pos", ":", "Union", "[", "int", ",", "int", "]", ",", "edges", ":", "list", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Manual attack blink, when not using the clock to schedule blinks but rather ticking the clock manually.\n        Used when the agent plays the game and not a human.\n\n        :param i: the blink number\n        :param attacker_pos: the attackers position\n        :param edges: list of edges for visualizatio\n        :return: None\n       \"\"\"", "\n", "if", "i", "%", "2", "==", "0", ":", "\n", "            ", "self", ".", "blink_red_attack", "(", "0", ",", "attacker_pos", ",", "edges_list", "=", "edges", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "blink_black_attack", "(", "0", ",", "attacker_pos", ",", "edges_list", "=", "edges", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.create_labels": [[201, 229], ["gym_idsgame.envs.rendering.util.render_util.batch_label", "gym_idsgame.envs.rendering.util.render_util.batch_label", "gym_idsgame.envs.rendering.util.render_util.batch_label"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_label", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_label", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_label"], ["", "", "def", "create_labels", "(", "self", ",", "attack_label_x", ":", "int", ",", "attack_label_y", ":", "int", ",", "defense_label_x", ":", "int", ",", "defense_label_y", ":", "int", ",", "\n", "det_label_x", ":", "int", ",", "det_label_y", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Creates the labels of the node\n\n        :param attack_label_x: the x coordinate of the attack label\n        :param attack_label_y: the y coordinate of the attack label\n        :param defense_label_x: the x coordinate of the defense label\n        :param defense_label_y: the y coordinate of the defense label\n        :param det_label_x: the x coordinate of the detection label\n        :param det_label_y: the y coordinate of the detection label\n        :return: None\n        \"\"\"", "\n", "self", ".", "attack_label", "=", "batch_label", "(", "self", ".", "attack_text", ",", "attack_label_x", ",", "attack_label_y", ",", "\n", "constants", ".", "RENDERING", ".", "NODE_STATE_FONT_SIZE", ",", "constants", ".", "RENDERING", ".", "BLACK_ALPHA", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "background", ",", "multiline", "=", "False", ",", "\n", "width", "=", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", ")", "\n", "self", ".", "defense_label", "=", "batch_label", "(", "self", ".", "defense_text", ",", "defense_label_x", ",", "defense_label_y", ",", "\n", "constants", ".", "RENDERING", ".", "NODE_STATE_FONT_SIZE", ",", "constants", ".", "RENDERING", ".", "BLACK_ALPHA", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "background", ",", "multiline", "=", "False", ",", "\n", "width", "=", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", ")", "\n", "self", ".", "det_label", "=", "batch_label", "(", "self", ".", "det_text", ",", "det_label_x", ",", "det_label_y", ",", "\n", "constants", ".", "RENDERING", ".", "NODE_STATE_FONT_SIZE", ",", "constants", ".", "RENDERING", ".", "BLACK_ALPHA", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "background", ",", "multiline", "=", "False", ",", "\n", "width", "=", "self", ".", "idsgame_config", ".", "render_config", ".", "rect_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.add_out_edge": [[230, 238], ["resource_node.ResourceNode.outgoing_edges.append"], "methods", ["None"], ["", "def", "add_out_edge", "(", "self", ",", "edge", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Add an edge to the list of outgoing edges of the node\n\n        :param edge: edge to add\n        :return: None\n        \"\"\"", "\n", "self", ".", "outgoing_edges", ".", "append", "(", "edge", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.add_in_edge": [[239, 247], ["resource_node.ResourceNode.incoming_edges.append"], "methods", ["None"], ["", "def", "add_in_edge", "(", "self", ",", "edge", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Add an edge to the list of ingoing edges of the node\n\n        :param edge: edge to add\n        :return: None\n        \"\"\"", "\n", "self", ".", "incoming_edges", ".", "append", "(", "edge", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.add_horizontal_edge": [[248, 256], ["resource_node.ResourceNode.horizontal_edges.append"], "methods", ["None"], ["", "def", "add_horizontal_edge", "(", "self", ",", "edge", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Add an edge to the list of horizontal edges of the node\n\n        :param edge: edge to add\n        :return: None\n        \"\"\"", "\n", "self", ".", "horizontal_edges", ".", "append", "(", "edge", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.reset": [[257, 265], ["resource_node.ResourceNode.center_avatar", "resource_node.ResourceNode.initialize_state", "resource_node.ResourceNode.init_labels"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.center_avatar", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.initialize_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.data_node.DataNode.init_labels"], ["", "def", "reset", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the node, centers the image, resets the state and the labels.\n        :return: None\n        \"\"\"", "\n", "self", ".", "center_avatar", "(", ")", "\n", "self", ".", "initialize_state", "(", ")", "\n", "self", ".", "init_labels", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.toggle_attacker_view": [[266, 269], ["None"], "methods", ["None"], ["", "def", "toggle_attacker_view", "(", "self", ")", ":", "\n", "        ", "self", ".", "idsgame_config", ".", "render_config", ".", "attacker_view", "=", "True", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "defender_view", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.toggle_defender_view": [[270, 273], ["None"], "methods", ["None"], ["", "def", "toggle_defender_view", "(", "self", ")", ":", "\n", "        ", "self", ".", "idsgame_config", ".", "render_config", ".", "attacker_view", "=", "False", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "defender_view", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.toggle_full_view": [[274, 277], ["None"], "methods", ["None"], ["", "def", "toggle_full_view", "(", "self", ")", ":", "\n", "        ", "self", ".", "idsgame_config", ".", "render_config", ".", "attacker_view", "=", "True", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "defender_view", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.visualize_reconnaissance": [[278, 284], ["range", "pyglet.clock.schedule_once", "pyglet.clock.schedule_once"], "methods", ["None"], ["", "def", "visualize_reconnaissance", "(", "self", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "0", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "num_blinks", ")", ":", "\n", "            ", "if", "i", "%", "2", "==", "0", ":", "\n", "                ", "clock", ".", "schedule_once", "(", "self", ".", "show_glass", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "blink_interval", "*", "i", ")", "\n", "", "else", ":", "\n", "                ", "clock", ".", "schedule_once", "(", "self", ".", "hide_glass", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "blink_interval", "*", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.manual_reconnaissance": [[285, 297], ["resource_node.ResourceNode.show_glass", "resource_node.ResourceNode.hide_glass"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.show_glass", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.hide_glass"], ["", "", "", "def", "manual_reconnaissance", "(", "self", ",", "i", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Manual attack blink, when not using the clock to schedule blinks but rather ticking the clock manually.\n        Used when the agent plays the game and not a human.\n\n        :param i: the blink number\n        :return: None\n       \"\"\"", "\n", "if", "i", "%", "2", "==", "0", ":", "\n", "            ", "self", ".", "show_glass", "(", "0", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "hide_glass", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.show_glass": [[298, 302], ["None"], "methods", ["None"], ["", "", "def", "show_glass", "(", "self", ",", "dt", ")", ":", "\n", "        ", "self", ".", "glass", ".", "x", "=", "self", ".", "x", "+", "20", "\n", "self", ".", "glass", ".", "y", "=", "self", ".", "y", "\n", "self", ".", "glass", ".", "visible", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.hide_glass": [[303, 305], ["None"], "methods", ["None"], ["", "def", "hide_glass", "(", "self", ",", "dt", ")", ":", "\n", "        ", "self", ".", "glass", ".", "visible", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.center_avatar": [[307, 310], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "center_avatar", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.visualize_attack": [[311, 314], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "visualize_attack", "(", "self", ",", "attack_type", ",", "attacker_pos", ",", "edges_list", "=", "None", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.blink_red_attack": [[315, 318], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "blink_red_attack", "(", "self", ",", "dt", ",", "edges_list", "=", "None", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.blink_black_attack": [[319, 322], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "blink_black_attack", "(", "self", ",", "dt", ",", "edges_list", "=", "None", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.__init__": [[10, 33], ["os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "directory", ",", "file_prefix", ",", "autoreset", "=", "False", ",", "env_id", "=", "None", ")", ":", "\n", "        ", "self", ".", "autoreset", "=", "autoreset", "\n", "self", ".", "env_id", "=", "env_id", "\n", "\n", "self", ".", "initial_reset_timestamp", "=", "None", "\n", "self", ".", "directory", "=", "directory", "\n", "self", ".", "file_prefix", "=", "file_prefix", "\n", "self", ".", "episode_lengths", "=", "[", "]", "\n", "self", ".", "episode_rewards_1", "=", "[", "]", "\n", "self", ".", "episode_rewards_2", "=", "[", "]", "\n", "self", ".", "episode_types", "=", "[", "]", "# experimental addition", "\n", "self", ".", "_type", "=", "'t'", "\n", "self", ".", "timestamps", "=", "[", "]", "\n", "self", ".", "steps", "=", "None", "\n", "self", ".", "total_steps", "=", "0", "\n", "self", ".", "rewards_1", "=", "None", "\n", "self", ".", "rewards_2", "=", "None", "\n", "\n", "self", ".", "done", "=", "None", "\n", "self", ".", "closed", "=", "False", "\n", "\n", "filename", "=", "'{}.stats.json'", ".", "format", "(", "self", ".", "file_prefix", ")", "\n", "self", ".", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "directory", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type": [[38, 43], ["gym.error.Error"], "methods", ["None"], ["", "@", "type", ".", "setter", "\n", "def", "type", "(", "self", ",", "type", ")", ":", "\n", "        ", "if", "type", "not", "in", "[", "'t'", ",", "'e'", "]", ":", "\n", "            ", "raise", "error", ".", "Error", "(", "'Invalid episode type {}: must be t for training or e for evaluation'", ",", "type", ")", "\n", "", "self", ".", "_type", "=", "type", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.before_step": [[44, 51], ["gym.error.ResetNeeded", "gym.error.ResetNeeded"], "methods", ["None"], ["", "def", "before_step", "(", "self", ",", "action", ")", ":", "\n", "        ", "assert", "not", "self", ".", "closed", "\n", "\n", "if", "self", ".", "done", ":", "\n", "            ", "raise", "error", ".", "ResetNeeded", "(", "\"Trying to step environment which is currently done. While the monitor is active for {}, you cannot step beyond the end of an episode. Call 'env.reset()' to start the next episode.\"", ".", "format", "(", "self", ".", "env_id", ")", ")", "\n", "", "elif", "self", ".", "steps", "is", "None", ":", "\n", "            ", "raise", "error", ".", "ResetNeeded", "(", "\"Trying to step an environment before reset. While the monitor is active for {}, you must call 'env.reset()' before taking an initial step.\"", ".", "format", "(", "self", ".", "env_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.after_step": [[52, 75], ["idsgame_stats_recorder.StatsRecorder.type"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type"], ["", "", "def", "after_step", "(", "self", ",", "observation", ",", "reward", ",", "done", ",", "info", ")", ":", "\n", "        ", "self", ".", "steps", "+=", "1", "\n", "self", ".", "total_steps", "+=", "1", "\n", "if", "type", "(", "reward", ")", "==", "tuple", ":", "\n", "            ", "reward_1", ",", "reward_2", "=", "reward", "\n", "self", ".", "rewards_1", "+=", "reward_1", "\n", "self", ".", "rewards_2", "+=", "reward_2", "\n", "", "elif", "type", "(", "reward", ")", "==", "list", ":", "\n", "            ", "reward_1", "=", "reward", "[", "0", "]", "\n", "reward_2", "=", "reward", "[", "1", "]", "\n", "self", ".", "rewards_1", "+=", "reward_1", "\n", "self", ".", "rewards_2", "+=", "reward_2", "\n", "", "else", ":", "\n", "            ", "self", ".", "rewards_1", "+=", "reward", "\n", "", "self", ".", "done", "=", "done", "\n", "\n", "if", "done", ":", "\n", "            ", "self", ".", "save_complete", "(", ")", "\n", "\n", "", "if", "done", ":", "\n", "            ", "if", "self", ".", "autoreset", ":", "\n", "                ", "self", ".", "before_reset", "(", ")", "\n", "self", ".", "after_reset", "(", "observation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.before_reset": [[76, 85], ["gym.error.Error", "time.time"], "methods", ["None"], ["", "", "", "def", "before_reset", "(", "self", ")", ":", "\n", "        ", "assert", "not", "self", ".", "closed", "\n", "\n", "if", "self", ".", "done", "is", "not", "None", "and", "not", "self", ".", "done", "and", "self", ".", "steps", ">", "0", ":", "\n", "            ", "raise", "error", ".", "Error", "(", "\"Tried to reset environment which is not done. While the monitor is active for {}, you cannot call reset() unless the episode is over.\"", ".", "format", "(", "self", ".", "env_id", ")", ")", "\n", "\n", "", "self", ".", "done", "=", "False", "\n", "if", "self", ".", "initial_reset_timestamp", "is", "None", ":", "\n", "            ", "self", ".", "initial_reset_timestamp", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.after_reset": [[86, 94], ["idsgame_stats_recorder.StatsRecorder.episode_types.append"], "methods", ["None"], ["", "", "def", "after_reset", "(", "self", ",", "observation", ")", ":", "\n", "        ", "self", ".", "steps", "=", "0", "\n", "self", ".", "rewards_1", "=", "0", "\n", "self", ".", "rewards_2", "=", "0", "\n", "# We write the type at the beginning of the episode. If a user", "\n", "# changes the type, it's more natural for it to apply next", "\n", "# time the user calls reset().", "\n", "self", ".", "episode_types", ".", "append", "(", "self", ".", "_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.save_complete": [[95, 101], ["idsgame_stats_recorder.StatsRecorder.episode_lengths.append", "idsgame_stats_recorder.StatsRecorder.episode_rewards_1.append", "idsgame_stats_recorder.StatsRecorder.episode_rewards_2.append", "idsgame_stats_recorder.StatsRecorder.timestamps.append", "float", "float", "time.time"], "methods", ["None"], ["", "def", "save_complete", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "steps", "is", "not", "None", ":", "\n", "            ", "self", ".", "episode_lengths", ".", "append", "(", "self", ".", "steps", ")", "\n", "self", ".", "episode_rewards_1", ".", "append", "(", "float", "(", "self", ".", "rewards_1", ")", ")", "\n", "self", ".", "episode_rewards_2", ".", "append", "(", "float", "(", "self", ".", "rewards_2", ")", ")", "\n", "self", ".", "timestamps", ".", "append", "(", "time", ".", "time", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.close": [[102, 105], ["idsgame_stats_recorder.StatsRecorder.flush"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.flush"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "flush", "(", ")", "\n", "self", ".", "closed", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.flush": [[106, 119], ["gym.utils.atomic_write.atomic_write", "json.dump"], "methods", ["None"], ["", "def", "flush", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "closed", ":", "\n", "            ", "return", "\n", "\n", "", "with", "atomic_write", ".", "atomic_write", "(", "self", ".", "path", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "{", "\n", "'initial_reset_timestamp'", ":", "self", ".", "initial_reset_timestamp", ",", "\n", "'timestamps'", ":", "self", ".", "timestamps", ",", "\n", "'episode_lengths'", ":", "self", ".", "episode_lengths", ",", "\n", "'episode_rewards'", ":", "self", ".", "episode_rewards_1", ",", "\n", "'episode_rewards_2'", ":", "self", ".", "episode_rewards_2", ",", "\n", "'episode_types'", ":", "self", ".", "episode_types", ",", "\n", "}", ",", "f", ",", "default", "=", "json_encode_np", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.__init__": [[15, 33], ["gym.Wrapper.__init__", "env.metadata.get", "idsgame_monitor.IdsGameMonitor._start"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.get", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._start"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "directory", ",", "video_callable", "=", "None", ",", "force", "=", "False", ",", "resume", "=", "False", ",", "\n", "write_upon_reset", "=", "False", ",", "uid", "=", "None", ",", "mode", "=", "None", ",", "video_frequency", "=", "1", ",", "openai_baseline", "=", "False", ")", ":", "\n", "        ", "super", "(", "IdsGameMonitor", ",", "self", ")", ".", "__init__", "(", "env", ")", "\n", "\n", "self", ".", "videos", "=", "[", "]", "\n", "\n", "self", ".", "stats_recorder", "=", "None", "\n", "self", ".", "video_recorder", "=", "None", "\n", "self", ".", "enabled", "=", "False", "\n", "self", ".", "episode_id", "=", "0", "\n", "self", ".", "_monitor_id", "=", "None", "\n", "self", ".", "openai_baseline_reset", "=", "True", "\n", "self", ".", "env_semantics_autoreset", "=", "env", ".", "metadata", ".", "get", "(", "'semantics.autoreset'", ")", "\n", "self", ".", "_start", "(", "directory", ",", "video_callable", ",", "force", ",", "resume", ",", "\n", "write_upon_reset", ",", "uid", ",", "mode", ")", "\n", "self", ".", "episode_frames", "=", "[", "]", "\n", "self", ".", "video_frequency", "=", "video_frequency", "\n", "self", ".", "openai_baseline", "=", "openai_baseline", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step": [[34, 42], ["idsgame_monitor.IdsGameMonitor._before_step", "idsgame_monitor.IdsGameMonitor.env.step", "idsgame_monitor.IdsGameMonitor._after_step"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._before_step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._after_step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "self", ".", "_before_step", "(", "action", ")", "\n", "# if self.episode_id % self.video_frequency == 0:", "\n", "#     self._before_step(action)", "\n", "observation", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "# if self.episode_id % self.video_frequency == 0:", "\n", "done", "=", "self", ".", "_after_step", "(", "observation", ",", "reward", ",", "done", ",", "info", ")", "\n", "return", "observation", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.reset": [[43, 51], ["idsgame_monitor.IdsGameMonitor._before_reset", "idsgame_monitor.IdsGameMonitor.env.reset", "idsgame_monitor.IdsGameMonitor._after_reset", "len"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._before_reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._after_reset"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "(", "self", ".", "openai_baseline", "and", "len", "(", "self", ".", "episode_frames", ")", ">", "0", ")", "or", "(", "self", ".", "openai_baseline", "and", "not", "self", ".", "openai_baseline_reset", ")", ":", "\n", "            ", "return", "\n", "", "self", ".", "_before_reset", "(", ")", "\n", "observation", "=", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "self", ".", "_after_reset", "(", "observation", ")", "\n", "self", ".", "openai_baseline_reset", "=", "False", "\n", "return", "observation", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.set_monitor_mode": [[52, 55], ["gym.logger.info", "idsgame_monitor.IdsGameMonitor._set_mode"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._set_mode"], ["", "def", "set_monitor_mode", "(", "self", ",", "mode", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Setting the monitor mode is deprecated and will be removed soon\"", ")", "\n", "self", ".", "_set_mode", "(", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._start": [[57, 117], ["monitor_closer.register", "os.path.abspath", "gym_idsgame.envs.rendering.video.idsgame_stats_recorder.StatsRecorder", "gym.logger.warn", "os.path.exists", "gym.logger.info", "idsgame_monitor.clear_monitor_files", "os.path.exists", "os.mkdir", "idsgame_monitor.IdsGameMonitor._set_mode", "os.makedirs", "os.makedirs", "idsgame_monitor.detect_training_manifests", "os.getpid", "callable", "gym.error.Error", "len", "gym.error.Error", "type"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.clear_monitor_files", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._set_mode", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.detect_training_manifests", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type"], ["", "def", "_start", "(", "self", ",", "directory", ",", "video_callable", "=", "None", ",", "force", "=", "False", ",", "resume", "=", "False", ",", "\n", "write_upon_reset", "=", "False", ",", "uid", "=", "None", ",", "mode", "=", "None", ")", ":", "\n", "        ", "\"\"\"Start monitoring.\n\n        Args:\n            directory (str): A per-training run directory where to record stats.\n            video_callable (Optional[function, False]): function that takes in the index of the episode and outputs a boolean, indicating whether we should record a video on this episode. The default (for video_callable is None) is to take perfect cubes, capped at 1000. False disables video recording.\n            force (bool): Clear out existing training data from this directory (by deleting every file prefixed with \"openaigym.\").\n            resume (bool): Retain the training data already in this directory, which will be merged with our new data\n            write_upon_reset (bool): Write the manifest file on each reset. (This is currently a JSON file, so writing it is somewhat expensive.)\n            uid (Optional[str]): A unique id used as part of the suffix for the file. By default, uses os.getpid().\n            mode (['evaluation', 'training']): Whether this is an evaluation or training episode.\n        \"\"\"", "\n", "if", "self", ".", "env", ".", "spec", "is", "None", ":", "\n", "            ", "logger", ".", "warn", "(", "\"Trying to monitor an environment which has no 'spec' set. This usually means you did not create it via 'gym.make', and is recommended only for advanced users.\"", ")", "\n", "env_id", "=", "'(unknown)'", "\n", "", "else", ":", "\n", "            ", "env_id", "=", "self", ".", "env", ".", "spec", ".", "id", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "\n", "            ", "logger", ".", "info", "(", "'Creating monitor directory %s'", ",", "directory", ")", "\n", "if", "six", ".", "PY3", ":", "\n", "                ", "os", ".", "makedirs", "(", "directory", ",", "exist_ok", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "os", ".", "makedirs", "(", "directory", ")", "\n", "\n", "", "", "if", "video_callable", "is", "None", ":", "\n", "            ", "video_callable", "=", "self", ".", "periodic_video_schedule", "\n", "", "elif", "video_callable", "==", "False", ":", "\n", "            ", "video_callable", "=", "disable_videos", "\n", "", "elif", "not", "callable", "(", "video_callable", ")", ":", "\n", "            ", "raise", "error", ".", "Error", "(", "'You must provide a function, None, or False for video_callable, not {}: {}'", ".", "format", "(", "type", "(", "video_callable", ")", ",", "video_callable", ")", ")", "\n", "", "self", ".", "video_callable", "=", "video_callable", "\n", "\n", "# Check on whether we need to clear anything", "\n", "if", "force", ":", "\n", "            ", "clear_monitor_files", "(", "directory", ")", "\n", "", "elif", "not", "resume", ":", "\n", "            ", "training_manifests", "=", "detect_training_manifests", "(", "directory", ")", "\n", "if", "len", "(", "training_manifests", ")", ">", "0", ":", "\n", "                ", "raise", "error", ".", "Error", "(", "'''Trying to write to monitor directory {} with existing monitor files: {}.\n\n You should use a unique directory for each training run, or use 'force=True' to automatically clear previous monitor files.'''", ".", "format", "(", "directory", ",", "', '", ".", "join", "(", "training_manifests", "[", ":", "5", "]", ")", ")", ")", "\n", "\n", "", "", "self", ".", "_monitor_id", "=", "monitor_closer", ".", "register", "(", "self", ")", "\n", "\n", "self", ".", "enabled", "=", "True", "\n", "self", ".", "directory", "=", "os", ".", "path", ".", "abspath", "(", "directory", ")", "\n", "# We use the 'openai-gym' prefix to determine if a file is", "\n", "# ours", "\n", "self", ".", "file_prefix", "=", "FILE_PREFIX", "\n", "self", ".", "file_infix", "=", "'{}.{}'", ".", "format", "(", "self", ".", "_monitor_id", ",", "uid", "if", "uid", "else", "os", ".", "getpid", "(", ")", ")", "\n", "\n", "self", ".", "stats_recorder", "=", "idsgame_stats_recorder", ".", "StatsRecorder", "(", "directory", ",", "'{}.episode_batch.{}'", ".", "format", "(", "self", ".", "file_prefix", ",", "self", ".", "file_infix", ")", ",", "autoreset", "=", "self", ".", "env_semantics_autoreset", ",", "env_id", "=", "env_id", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "os", ".", "mkdir", "(", "directory", ")", "\n", "self", ".", "write_upon_reset", "=", "write_upon_reset", "\n", "\n", "if", "mode", "is", "not", "None", ":", "\n", "            ", "self", ".", "_set_mode", "(", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._flush": [[118, 140], ["idsgame_monitor.IdsGameMonitor.stats_recorder.flush", "os.path.join", "gym.logger.debug", "gym.utils.atomic_write.atomic_write", "json.dump", "os.path.basename", "idsgame_monitor.IdsGameMonitor._env_info", "os.path.basename", "os.path.basename"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.flush", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._env_info"], ["", "", "def", "_flush", "(", "self", ",", "force", "=", "False", ")", ":", "\n", "        ", "\"\"\"Flush all relevant monitor information to disk.\"\"\"", "\n", "if", "not", "self", ".", "write_upon_reset", "and", "not", "force", ":", "\n", "            ", "return", "\n", "\n", "", "self", ".", "stats_recorder", ".", "flush", "(", ")", "\n", "\n", "# Give it a very distiguished name, since we need to pick it", "\n", "# up from the filesystem later.", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "directory", ",", "'{}.manifest.{}.manifest.json'", ".", "format", "(", "self", ".", "file_prefix", ",", "self", ".", "file_infix", ")", ")", "\n", "logger", ".", "debug", "(", "'Writing training manifest file to %s'", ",", "path", ")", "\n", "with", "atomic_write", ".", "atomic_write", "(", "path", ")", "as", "f", ":", "\n", "# We need to write relative paths here since people may", "\n", "# move the training_dir around. It would be cleaner to", "\n", "# already have the basenames rather than basename'ing", "\n", "# manually, but this works for now.", "\n", "            ", "json", ".", "dump", "(", "{", "\n", "'stats'", ":", "os", ".", "path", ".", "basename", "(", "self", ".", "stats_recorder", ".", "path", ")", ",", "\n", "'videos'", ":", "[", "(", "os", ".", "path", ".", "basename", "(", "v", ")", ",", "os", ".", "path", ".", "basename", "(", "m", ")", ")", "\n", "for", "v", ",", "m", "in", "self", ".", "videos", "]", ",", "\n", "'env_info'", ":", "self", ".", "_env_info", "(", ")", ",", "\n", "}", ",", "f", ",", "default", "=", "json_encode_np", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.close": [[141, 157], ["super().close", "idsgame_monitor.IdsGameMonitor.stats_recorder.close", "idsgame_monitor.IdsGameMonitor._flush", "monitor_closer.unregister", "gym.logger.info", "idsgame_monitor.IdsGameMonitor._close_video_recorder"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._flush", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._close_video_recorder"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "\"\"\"Flush all monitor data to disk and close any open rending windows.\"\"\"", "\n", "super", "(", "IdsGameMonitor", ",", "self", ")", ".", "close", "(", ")", "\n", "\n", "if", "not", "self", ".", "enabled", ":", "\n", "            ", "return", "\n", "", "self", ".", "stats_recorder", ".", "close", "(", ")", "\n", "if", "self", ".", "video_recorder", "is", "not", "None", ":", "\n", "            ", "self", ".", "_close_video_recorder", "(", ")", "\n", "", "self", ".", "_flush", "(", "force", "=", "True", ")", "\n", "\n", "# Stop tracking this for autoclose", "\n", "monitor_closer", ".", "unregister", "(", "self", ".", "_monitor_id", ")", "\n", "self", ".", "enabled", "=", "False", "\n", "\n", "logger", ".", "info", "(", "'''Finished writing results. You can upload them to the scoreboard via gym.upload(%r)'''", ",", "self", ".", "directory", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._set_mode": [[158, 166], ["gym.error.Error"], "methods", ["None"], ["", "def", "_set_mode", "(", "self", ",", "mode", ")", ":", "\n", "        ", "if", "mode", "==", "'evaluation'", ":", "\n", "            ", "type", "=", "'e'", "\n", "", "elif", "mode", "==", "'training'", ":", "\n", "            ", "type", "=", "'t'", "\n", "", "else", ":", "\n", "            ", "raise", "error", ".", "Error", "(", "'Invalid mode {}: must be \"training\" or \"evaluation\"'", ",", "mode", ")", "\n", "", "self", ".", "stats_recorder", ".", "type", "=", "type", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._before_step": [[167, 170], ["idsgame_monitor.IdsGameMonitor.stats_recorder.before_step"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.before_step"], ["", "def", "_before_step", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "not", "self", ".", "enabled", ":", "return", "\n", "self", ".", "stats_recorder", ".", "before_step", "(", "action", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._after_step": [[171, 188], ["idsgame_monitor.IdsGameMonitor.stats_recorder.after_step", "idsgame_monitor.IdsGameMonitor.video_recorder.capture_frame", "idsgame_monitor.IdsGameMonitor.reset_video_recorder", "idsgame_monitor.IdsGameMonitor._flush", "idsgame_monitor.IdsGameMonitor.episode_frames.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.after_step", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.capture_frame", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.reset_video_recorder", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._flush"], ["", "def", "_after_step", "(", "self", ",", "observation", ",", "reward", ",", "done", ",", "info", ")", ":", "\n", "        ", "if", "not", "self", ".", "enabled", ":", "return", "done", "\n", "\n", "if", "done", "and", "self", ".", "env_semantics_autoreset", ":", "\n", "# For envs with BlockingReset wrapping VNCEnv, this observation will be the first one of the new episode", "\n", "            ", "self", ".", "reset_video_recorder", "(", ")", "\n", "self", ".", "episode_id", "+=", "1", "\n", "self", ".", "_flush", "(", ")", "\n", "\n", "# Record stats", "\n", "", "self", ".", "stats_recorder", ".", "after_step", "(", "observation", ",", "reward", ",", "done", ",", "info", ")", "\n", "# Record video", "\n", "frames", "=", "self", ".", "video_recorder", ".", "capture_frame", "(", ")", "\n", "if", "frames", "is", "not", "None", ":", "\n", "            ", "for", "frame", "in", "frames", ":", "\n", "                ", "self", ".", "episode_frames", ".", "append", "(", "frame", ")", "\n", "", "", "return", "done", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.generate_gif": [[189, 196], ["imageio.mimsave", "len"], "methods", ["None"], ["", "def", "generate_gif", "(", "self", ",", "path", ",", "fps", "=", "55", ")", ":", "\n", "        ", "if", "(", "self", ".", "episode_frames", "is", "not", "None", "and", "len", "(", "self", ".", "episode_frames", ")", ">", "0", "\n", "and", "(", "self", ".", "episode_id", "-", "1", ")", "%", "(", "self", ".", "video_frequency", ")", "==", "0", ")", ":", "\n", "            ", "imageio", ".", "mimsave", "(", "path", ",", "self", ".", "episode_frames", ",", "fps", "=", "fps", ")", "\n", "", "if", "self", ".", "openai_baseline", ":", "\n", "            ", "self", ".", "episode_frames", "=", "[", "]", "\n", "self", ".", "openai_baseline_reset", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._before_reset": [[197, 200], ["idsgame_monitor.IdsGameMonitor.stats_recorder.before_reset"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.before_reset"], ["", "", "def", "_before_reset", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "enabled", ":", "return", "\n", "self", ".", "stats_recorder", ".", "before_reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._after_reset": [[201, 214], ["idsgame_monitor.IdsGameMonitor.stats_recorder.after_reset", "idsgame_monitor.IdsGameMonitor.reset_video_recorder", "idsgame_monitor.IdsGameMonitor._flush"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.after_reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.reset_video_recorder", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._flush"], ["", "def", "_after_reset", "(", "self", ",", "observation", ")", ":", "\n", "        ", "if", "not", "self", ".", "enabled", ":", "return", "\n", "\n", "# Reset the stat count", "\n", "self", ".", "stats_recorder", ".", "after_reset", "(", "observation", ")", "\n", "\n", "self", ".", "reset_video_recorder", "(", ")", "\n", "self", ".", "episode_frames", "=", "[", "]", "\n", "\n", "# Bump *after* all reset activity has finished", "\n", "self", ".", "episode_id", "+=", "1", "\n", "\n", "self", ".", "_flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.reset_video_recorder": [[215, 233], ["gym_idsgame.envs.rendering.video.idsgame_video_recorder.IdsGameVideoRecorder", "idsgame_monitor.IdsGameMonitor.video_recorder.capture_frame", "idsgame_monitor.IdsGameMonitor._close_video_recorder", "os.path.join", "idsgame_monitor.IdsGameMonitor._video_enabled", "idsgame_monitor.IdsGameMonitor.episode_frames.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.capture_frame", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._close_video_recorder", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._video_enabled"], ["", "def", "reset_video_recorder", "(", "self", ")", ":", "\n", "# Close any existing video recorder", "\n", "        ", "if", "self", ".", "video_recorder", ":", "\n", "            ", "self", ".", "_close_video_recorder", "(", ")", "\n", "\n", "# Start recording the next video.", "\n", "#", "\n", "# TODO: calculate a more correct 'episode_id' upon merge", "\n", "", "self", ".", "video_recorder", "=", "idsgame_video_recorder", ".", "IdsGameVideoRecorder", "(", "\n", "env", "=", "self", ".", "env", ",", "\n", "base_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "directory", ",", "'{}.video.{}.video{:06}'", ".", "format", "(", "self", ".", "file_prefix", ",", "self", ".", "file_infix", ",", "self", ".", "episode_id", ")", ")", ",", "\n", "metadata", "=", "{", "'episode_id'", ":", "self", ".", "episode_id", "}", ",", "\n", "enabled", "=", "self", ".", "_video_enabled", "(", ")", ",", "\n", ")", "\n", "frames", "=", "self", ".", "video_recorder", ".", "capture_frame", "(", ")", "\n", "if", "frames", "is", "not", "None", ":", "\n", "            ", "for", "frame", "in", "frames", ":", "\n", "                ", "self", ".", "episode_frames", ".", "append", "(", "frame", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._close_video_recorder": [[234, 238], ["idsgame_monitor.IdsGameMonitor.video_recorder.close", "idsgame_monitor.IdsGameMonitor.videos.append"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "", "", "def", "_close_video_recorder", "(", "self", ")", ":", "\n", "        ", "self", ".", "video_recorder", ".", "close", "(", ")", "\n", "if", "self", ".", "video_recorder", ".", "functional", ":", "\n", "            ", "self", ".", "videos", ".", "append", "(", "(", "self", ".", "video_recorder", ".", "path", ",", "self", ".", "video_recorder", ".", "metadata_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._video_enabled": [[239, 241], ["idsgame_monitor.IdsGameMonitor.video_callable"], "methods", ["None"], ["", "", "def", "_video_enabled", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "video_callable", "(", "self", ".", "episode_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor._env_info": [[242, 249], ["None"], "methods", ["None"], ["", "def", "_env_info", "(", "self", ")", ":", "\n", "        ", "env_info", "=", "{", "\n", "'gym_version'", ":", "version", ".", "VERSION", ",", "\n", "}", "\n", "if", "self", ".", "env", ".", "spec", ":", "\n", "            ", "env_info", "[", "'env_id'", "]", "=", "self", ".", "env", ".", "spec", ".", "id", "\n", "", "return", "env_info", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.__del__": [[250, 253], ["idsgame_monitor.IdsGameMonitor.close"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "# Make sure we've closed up shop when garbage collecting", "\n", "        ", "self", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.get_total_steps": [[254, 256], ["None"], "methods", ["None"], ["", "def", "get_total_steps", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "stats_recorder", ".", "total_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.get_episode_rewards": [[257, 259], ["None"], "methods", ["None"], ["", "def", "get_episode_rewards", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "stats_recorder", ".", "episode_rewards", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.get_episode_lengths": [[260, 262], ["None"], "methods", ["None"], ["", "def", "get_episode_lengths", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "stats_recorder", ".", "episode_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.IdsGameMonitor.periodic_video_schedule": [[263, 268], ["None"], "methods", ["None"], ["", "def", "periodic_video_schedule", "(", "self", ",", "episode_id", ")", ":", "\n", "        ", "if", "episode_id", "%", "self", ".", "video_frequency", "==", "0", ":", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.detect_training_manifests": [[269, 273], ["os.listdir", "os.path.join", "f.startswith"], "function", ["None"], ["", "", "", "def", "detect_training_manifests", "(", "training_dir", ",", "files", "=", "None", ")", ":", "\n", "    ", "if", "files", "is", "None", ":", "\n", "        ", "files", "=", "os", ".", "listdir", "(", "training_dir", ")", "\n", "", "return", "[", "os", ".", "path", ".", "join", "(", "training_dir", ",", "f", ")", "for", "f", "in", "files", "if", "f", ".", "startswith", "(", "MANIFEST_PREFIX", "+", "'.'", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.detect_monitor_files": [[274, 276], ["os.path.join", "os.listdir", "f.startswith"], "function", ["None"], ["", "def", "detect_monitor_files", "(", "training_dir", ")", ":", "\n", "    ", "return", "[", "os", ".", "path", ".", "join", "(", "training_dir", ",", "f", ")", "for", "f", "in", "os", ".", "listdir", "(", "training_dir", ")", "if", "f", ".", "startswith", "(", "FILE_PREFIX", "+", "'.'", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.clear_monitor_files": [[277, 285], ["idsgame_monitor.detect_monitor_files", "gym.logger.info", "len", "len", "os.unlink"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.detect_monitor_files"], ["", "def", "clear_monitor_files", "(", "training_dir", ")", ":", "\n", "    ", "files", "=", "detect_monitor_files", "(", "training_dir", ")", "\n", "if", "len", "(", "files", ")", "==", "0", ":", "\n", "        ", "return", "\n", "\n", "", "logger", ".", "info", "(", "'Clearing %d monitor files from previous run (because force=True was provided)'", ",", "len", "(", "files", ")", ")", "\n", "for", "file", "in", "files", ":", "\n", "        ", "os", ".", "unlink", "(", "file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.capped_cubic_video_schedule": [[286, 291], ["int", "round"], "function", ["None"], ["", "", "def", "capped_cubic_video_schedule", "(", "episode_id", ")", ":", "\n", "    ", "if", "episode_id", "<", "1000", ":", "\n", "        ", "return", "int", "(", "round", "(", "episode_id", "**", "(", "1.", "/", "3", ")", ")", ")", "**", "3", "==", "episode_id", "\n", "", "else", ":", "\n", "        ", "return", "episode_id", "%", "1000", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.disable_videos": [[292, 294], ["None"], "function", ["None"], ["", "", "def", "disable_videos", "(", "episode_id", ")", ":", "\n", "    ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor._open_monitors": [[299, 301], ["list", "monitor_closer.closeables.values"], "function", ["None"], ["def", "_open_monitors", "(", ")", ":", "\n", "    ", "return", "list", "(", "monitor_closer", ".", "closeables", ".", "values", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.load_env_info_from_manifests": [[302, 311], ["idsgame_monitor.collapse_env_infos", "open", "json.load", "env_infos.append"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.collapse_env_infos", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load"], ["", "def", "load_env_info_from_manifests", "(", "manifests", ",", "training_dir", ")", ":", "\n", "    ", "env_infos", "=", "[", "]", "\n", "for", "manifest", "in", "manifests", ":", "\n", "        ", "with", "open", "(", "manifest", ")", "as", "f", ":", "\n", "            ", "contents", "=", "json", ".", "load", "(", "f", ")", "\n", "env_infos", ".", "append", "(", "contents", "[", "'env_info'", "]", ")", "\n", "\n", "", "", "env_info", "=", "collapse_env_infos", "(", "env_infos", ",", "training_dir", ")", "\n", "return", "env_info", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.load_results": [[312, 352], ["idsgame_monitor.detect_training_manifests", "gym.logger.debug", "idsgame_monitor.collapse_env_infos", "idsgame_monitor.merge_stats_files", "os.path.exists", "gym.logger.error", "gym.logger.error", "open", "json.load", "stats_files.append", "env_infos.append", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.detect_training_manifests", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.collapse_env_infos", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.merge_stats_files", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load"], ["", "def", "load_results", "(", "training_dir", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "training_dir", ")", ":", "\n", "        ", "logger", ".", "error", "(", "'Training directory %s not found'", ",", "training_dir", ")", "\n", "return", "\n", "\n", "", "manifests", "=", "detect_training_manifests", "(", "training_dir", ")", "\n", "if", "not", "manifests", ":", "\n", "        ", "logger", ".", "error", "(", "'No manifests found in training directory %s'", ",", "training_dir", ")", "\n", "return", "\n", "\n", "", "logger", ".", "debug", "(", "'Uploading data from manifest %s'", ",", "', '", ".", "join", "(", "manifests", ")", ")", "\n", "\n", "# Load up stats + video files", "\n", "stats_files", "=", "[", "]", "\n", "videos", "=", "[", "]", "\n", "env_infos", "=", "[", "]", "\n", "\n", "for", "manifest", "in", "manifests", ":", "\n", "        ", "with", "open", "(", "manifest", ")", "as", "f", ":", "\n", "            ", "contents", "=", "json", ".", "load", "(", "f", ")", "\n", "# Make these paths absolute again", "\n", "stats_files", ".", "append", "(", "os", ".", "path", ".", "join", "(", "training_dir", ",", "contents", "[", "'stats'", "]", ")", ")", "\n", "videos", "+=", "[", "(", "os", ".", "path", ".", "join", "(", "training_dir", ",", "v", ")", ",", "os", ".", "path", ".", "join", "(", "training_dir", ",", "m", ")", ")", "\n", "for", "v", ",", "m", "in", "contents", "[", "'videos'", "]", "]", "\n", "env_infos", ".", "append", "(", "contents", "[", "'env_info'", "]", ")", "\n", "\n", "", "", "env_info", "=", "collapse_env_infos", "(", "env_infos", ",", "training_dir", ")", "\n", "data_sources", ",", "initial_reset_timestamps", ",", "timestamps", ",", "episode_lengths", ",", "episode_rewards", ",", "episode_types", ",", "initial_reset_timestamp", "=", "merge_stats_files", "(", "stats_files", ")", "\n", "\n", "return", "{", "\n", "'manifests'", ":", "manifests", ",", "\n", "'env_info'", ":", "env_info", ",", "\n", "'data_sources'", ":", "data_sources", ",", "\n", "'timestamps'", ":", "timestamps", ",", "\n", "'episode_lengths'", ":", "episode_lengths", ",", "\n", "'episode_rewards'", ":", "episode_rewards", ",", "\n", "'episode_types'", ":", "episode_types", ",", "\n", "'initial_reset_timestamps'", ":", "initial_reset_timestamps", ",", "\n", "'initial_reset_timestamp'", ":", "initial_reset_timestamp", ",", "\n", "'videos'", ":", "videos", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.merge_stats_files": [[354, 392], ["enumerate", "numpy.argsort", "[].tolist", "[].tolist", "[].tolist", "[].tolist", "[].tolist", "len", "min", "open", "json.load", "json.load.get", "initial_reset_timestamps.append", "len", "len", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.vec_env.vec_normalize.VecNormalize.load", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.get"], ["", "def", "merge_stats_files", "(", "stats_files", ")", ":", "\n", "    ", "timestamps", "=", "[", "]", "\n", "episode_lengths", "=", "[", "]", "\n", "episode_rewards", "=", "[", "]", "\n", "episode_types", "=", "[", "]", "\n", "initial_reset_timestamps", "=", "[", "]", "\n", "data_sources", "=", "[", "]", "\n", "\n", "for", "i", ",", "path", "in", "enumerate", "(", "stats_files", ")", ":", "\n", "        ", "with", "open", "(", "path", ")", "as", "f", ":", "\n", "            ", "content", "=", "json", ".", "load", "(", "f", ")", "\n", "if", "len", "(", "content", "[", "'timestamps'", "]", ")", "==", "0", ":", "continue", "# so empty file doesn't mess up results, due to null initial_reset_timestamp", "\n", "data_sources", "+=", "[", "i", "]", "*", "len", "(", "content", "[", "'timestamps'", "]", ")", "\n", "timestamps", "+=", "content", "[", "'timestamps'", "]", "\n", "episode_lengths", "+=", "content", "[", "'episode_lengths'", "]", "\n", "episode_rewards", "+=", "content", "[", "'episode_rewards'", "]", "\n", "# Recent addition", "\n", "episode_types", "+=", "content", ".", "get", "(", "'episode_types'", ",", "[", "]", ")", "\n", "# Keep track of where each episode came from.", "\n", "initial_reset_timestamps", ".", "append", "(", "content", "[", "'initial_reset_timestamp'", "]", ")", "\n", "\n", "", "", "idxs", "=", "np", ".", "argsort", "(", "timestamps", ")", "\n", "timestamps", "=", "np", ".", "array", "(", "timestamps", ")", "[", "idxs", "]", ".", "tolist", "(", ")", "\n", "episode_lengths", "=", "np", ".", "array", "(", "episode_lengths", ")", "[", "idxs", "]", ".", "tolist", "(", ")", "\n", "episode_rewards", "=", "np", ".", "array", "(", "episode_rewards", ")", "[", "idxs", "]", ".", "tolist", "(", ")", "\n", "data_sources", "=", "np", ".", "array", "(", "data_sources", ")", "[", "idxs", "]", ".", "tolist", "(", ")", "\n", "\n", "if", "episode_types", ":", "\n", "        ", "episode_types", "=", "np", ".", "array", "(", "episode_types", ")", "[", "idxs", "]", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "        ", "episode_types", "=", "None", "\n", "\n", "", "if", "len", "(", "initial_reset_timestamps", ")", ">", "0", ":", "\n", "        ", "initial_reset_timestamp", "=", "min", "(", "initial_reset_timestamps", ")", "\n", "", "else", ":", "\n", "        ", "initial_reset_timestamp", "=", "0", "\n", "\n", "", "return", "data_sources", ",", "initial_reset_timestamps", ",", "timestamps", ",", "episode_lengths", ",", "episode_rewards", ",", "episode_types", ",", "initial_reset_timestamp", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_monitor.collapse_env_infos": [[394, 406], ["len", "gym.error.Error", "gym.error.Error"], "function", ["None"], ["", "def", "collapse_env_infos", "(", "env_infos", ",", "training_dir", ")", ":", "\n", "    ", "assert", "len", "(", "env_infos", ")", ">", "0", "\n", "\n", "first", "=", "env_infos", "[", "0", "]", "\n", "for", "other", "in", "env_infos", "[", "1", ":", "]", ":", "\n", "        ", "if", "first", "!=", "other", ":", "\n", "            ", "raise", "error", ".", "Error", "(", "'Found two unequal env_infos: {} and {}. This usually indicates that your training directory {} has commingled results from multiple runs.'", ".", "format", "(", "first", ",", "other", ",", "training_dir", ")", ")", "\n", "\n", "", "", "for", "key", "in", "[", "'env_id'", ",", "'gym_version'", "]", ":", "\n", "        ", "if", "key", "not", "in", "first", ":", "\n", "            ", "raise", "error", ".", "Error", "(", "\"env_info {} from training directory {} is missing expected key {}. This is unexpected and likely indicates a bug in gym.\"", ".", "format", "(", "first", ",", "training_dir", ",", "key", ")", ")", "\n", "", "", "return", "first", "\n", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.IdsGameVideoRecorder.__init__": [[32, 90], ["env.metadata.get", "env.metadata.get", "os.path.splitext", "os.path.splitext", "os.path.splitext", "os.path.splitext", "idsgame_video_recorder.touch", "env.metadata.get", "idsgame_video_recorder.IdsGameVideoRecorder.write_metadata", "gym.logger.info", "gym.error.Error", "gym.error.Error", "gym.logger.info", "tempfile.NamedTemporaryFile"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.get", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.get", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.touch", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.get", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.IdsGameVideoRecorder.write_metadata"], ["def", "__init__", "(", "self", ",", "env", ",", "path", "=", "None", ",", "metadata", "=", "None", ",", "enabled", "=", "True", ",", "base_path", "=", "None", ")", ":", "\n", "        ", "modes", "=", "env", ".", "metadata", ".", "get", "(", "'render.modes'", ",", "[", "]", ")", "\n", "self", ".", "_async", "=", "env", ".", "metadata", ".", "get", "(", "'semantics.async'", ")", "\n", "self", ".", "enabled", "=", "enabled", "\n", "\n", "# Don't bother setting anything else if not enabled", "\n", "if", "not", "self", ".", "enabled", ":", "\n", "            ", "return", "\n", "\n", "", "self", ".", "ansi_mode", "=", "False", "\n", "if", "'rgb_array'", "not", "in", "modes", ":", "\n", "            ", "if", "'ansi'", "in", "modes", ":", "\n", "                ", "self", ".", "ansi_mode", "=", "True", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "'Disabling video recorder because {} neither supports video mode \"rgb_array\" nor \"ansi\".'", ".", "format", "(", "env", ")", ")", "\n", "# Whoops, turns out we shouldn't be enabled after all", "\n", "self", ".", "enabled", "=", "False", "\n", "return", "\n", "\n", "", "", "if", "path", "is", "not", "None", "and", "base_path", "is", "not", "None", ":", "\n", "            ", "raise", "error", ".", "Error", "(", "\"You can pass at most one of `path` or `base_path`.\"", ")", "\n", "\n", "", "self", ".", "last_frame", "=", "None", "\n", "self", ".", "env", "=", "env", "\n", "\n", "required_ext", "=", "'.json'", "if", "self", ".", "ansi_mode", "else", "'.mp4'", "\n", "if", "path", "is", "None", ":", "\n", "            ", "if", "base_path", "is", "not", "None", ":", "\n", "# Base path given, append ext", "\n", "                ", "path", "=", "base_path", "+", "required_ext", "\n", "", "else", ":", "\n", "# Otherwise, just generate a unique filename", "\n", "                ", "with", "tempfile", ".", "NamedTemporaryFile", "(", "suffix", "=", "required_ext", ",", "delete", "=", "False", ")", "as", "f", ":", "\n", "                    ", "path", "=", "f", ".", "name", "\n", "", "", "", "self", ".", "path", "=", "path", "\n", "\n", "path_base", ",", "actual_ext", "=", "os", ".", "path", ".", "splitext", "(", "self", ".", "path", ")", "\n", "\n", "if", "actual_ext", "!=", "required_ext", ":", "\n", "            ", "hint", "=", "\" HINT: The environment is text-only, therefore we're recording its text output in a structured JSON format.\"", "if", "self", ".", "ansi_mode", "else", "''", "\n", "raise", "error", ".", "Error", "(", "\"Invalid path given: {} -- must have file extension {}.{}\"", ".", "format", "(", "self", ".", "path", ",", "required_ext", ",", "hint", ")", ")", "\n", "# Touch the file in any case, so we know it's present. (This", "\n", "# corrects for platform platform differences. Using ffmpeg on", "\n", "# OS X, the file is precreated, but not on Linux.", "\n", "", "touch", "(", "path", ")", "\n", "\n", "self", ".", "frames_per_sec", "=", "env", ".", "metadata", ".", "get", "(", "'video.frames_per_second'", ",", "30", ")", "\n", "self", ".", "encoder", "=", "None", "# lazily start the process", "\n", "self", ".", "broken", "=", "False", "\n", "\n", "# Dump metadata", "\n", "self", ".", "metadata", "=", "metadata", "or", "{", "}", "\n", "self", ".", "metadata", "[", "'content_type'", "]", "=", "'video/vnd.openai.ansivid'", "if", "self", ".", "ansi_mode", "else", "'video/mp4'", "\n", "self", ".", "metadata_path", "=", "'{}.meta.json'", ".", "format", "(", "path_base", ")", "\n", "self", ".", "write_metadata", "(", ")", "\n", "\n", "logger", ".", "info", "(", "'Starting new video recorder writing to %s'", ",", "self", ".", "path", ")", "\n", "self", ".", "empty", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.IdsGameVideoRecorder.functional": [[91, 94], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "functional", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "enabled", "and", "not", "self", ".", "broken", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.IdsGameVideoRecorder.capture_frame": [[95, 121], ["gym.logger.debug", "idsgame_video_recorder.IdsGameVideoRecorder.env.render", "isinstance", "numpy.array", "gym.logger.warn", "idsgame_video_recorder.IdsGameVideoRecorder._encode_ansi_frame", "idsgame_video_recorder.IdsGameVideoRecorder._encode_image_frame"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.rendering.viewer.Viewer.render", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.IdsGameVideoRecorder._encode_ansi_frame", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.IdsGameVideoRecorder._encode_image_frame"], ["", "def", "capture_frame", "(", "self", ")", ":", "\n", "        ", "\"\"\"Render the given `env` and add the resulting frame to the video.\"\"\"", "\n", "if", "not", "self", ".", "functional", ":", "return", "\n", "logger", ".", "debug", "(", "'Capturing video frame: path=%s'", ",", "self", ".", "path", ")", "\n", "\n", "render_mode", "=", "'ansi'", "if", "self", ".", "ansi_mode", "else", "'rgb_array'", "\n", "frames", "=", "self", ".", "env", ".", "render", "(", "mode", "=", "render_mode", ")", "\n", "if", "isinstance", "(", "frames", ",", "np", ".", "ndarray", ")", ":", "\n", "            ", "for", "frame", "in", "frames", ":", "# multiple frames", "\n", "                ", "if", "frame", "is", "None", ":", "\n", "                    ", "if", "self", ".", "_async", ":", "\n", "                        ", "return", "\n", "", "else", ":", "\n", "# Indicates a bug in the environment: don't want to raise", "\n", "# an error here.", "\n", "                        ", "logger", ".", "warn", "(", "'Env returned None on render(). Disabling further rendering for video recorder by marking as disabled: path=%s metadata_path=%s'", ",", "self", ".", "path", ",", "self", ".", "metadata_path", ")", "\n", "self", ".", "broken", "=", "True", "\n", "", "", "else", ":", "\n", "                    ", "self", ".", "last_frame", "=", "frame", "\n", "if", "self", ".", "ansi_mode", ":", "\n", "                        ", "self", ".", "_encode_ansi_frame", "(", "frame", ")", "\n", "", "else", ":", "\n", "                        ", "self", ".", "_encode_image_frame", "(", "frame", ")", "\n", "", "", "", "return", "frames", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "array", "(", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.IdsGameVideoRecorder.close": [[122, 152], ["idsgame_video_recorder.IdsGameVideoRecorder.write_metadata", "gym.logger.debug", "idsgame_video_recorder.IdsGameVideoRecorder.encoder.close", "os.remove", "os.remove", "os.remove", "os.remove", "gym.logger.info", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "os.remove", "os.remove", "os.remove", "os.remove"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.IdsGameVideoRecorder.write_metadata", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "\"\"\"Make sure to manually close, or else you'll leak the encoder process\"\"\"", "\n", "if", "not", "self", ".", "enabled", ":", "\n", "            ", "return", "\n", "\n", "", "if", "self", ".", "encoder", ":", "\n", "            ", "logger", ".", "debug", "(", "'Closing video encoder: path=%s'", ",", "self", ".", "path", ")", "\n", "self", ".", "encoder", ".", "close", "(", ")", "\n", "self", ".", "encoder", "=", "None", "\n", "", "else", ":", "\n", "# No frames captured. Set metadata, and remove the empty output file.", "\n", "            ", "os", ".", "remove", "(", "self", ".", "path", ")", "\n", "\n", "if", "self", ".", "metadata", "is", "None", ":", "\n", "                ", "self", ".", "metadata", "=", "{", "}", "\n", "", "self", ".", "metadata", "[", "'empty'", "]", "=", "True", "\n", "\n", "# If broken, get rid of the output file, otherwise we'd leak it.", "\n", "", "if", "self", ".", "broken", ":", "\n", "            ", "logger", ".", "info", "(", "'Cleaning up paths for broken video recorder: path=%s metadata_path=%s'", ",", "self", ".", "path", ",", "self", ".", "metadata_path", ")", "\n", "\n", "# Might have crashed before even starting the output file, don't try to remove in that case.", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "path", ")", ":", "\n", "                ", "os", ".", "remove", "(", "self", ".", "path", ")", "\n", "\n", "", "if", "self", ".", "metadata", "is", "None", ":", "\n", "                ", "self", ".", "metadata", "=", "{", "}", "\n", "", "self", ".", "metadata", "[", "'broken'", "]", "=", "True", "\n", "\n", "", "self", ".", "write_metadata", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.IdsGameVideoRecorder.write_metadata": [[153, 156], ["open", "json.dump"], "methods", ["None"], ["", "def", "write_metadata", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "self", ".", "metadata_path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "self", ".", "metadata", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.IdsGameVideoRecorder._encode_ansi_frame": [[157, 163], ["idsgame_video_recorder.IdsGameVideoRecorder.encoder.capture_frame", "idsgame_video_recorder.TextEncoder"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.capture_frame"], ["", "", "def", "_encode_ansi_frame", "(", "self", ",", "frame", ")", ":", "\n", "        ", "if", "not", "self", ".", "encoder", ":", "\n", "            ", "self", ".", "encoder", "=", "TextEncoder", "(", "self", ".", "path", ",", "self", ".", "frames_per_sec", ")", "\n", "self", ".", "metadata", "[", "'encoder_version'", "]", "=", "self", ".", "encoder", ".", "version_info", "\n", "", "self", ".", "encoder", ".", "capture_frame", "(", "frame", ")", "\n", "self", ".", "empty", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.IdsGameVideoRecorder._encode_image_frame": [[164, 176], ["idsgame_video_recorder.ImageEncoder", "idsgame_video_recorder.IdsGameVideoRecorder.encoder.capture_frame", "gym.logger.warn"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.capture_frame"], ["", "def", "_encode_image_frame", "(", "self", ",", "frame", ")", ":", "\n", "        ", "if", "not", "self", ".", "encoder", ":", "\n", "            ", "self", ".", "encoder", "=", "ImageEncoder", "(", "self", ".", "path", ",", "frame", ".", "shape", ",", "self", ".", "frames_per_sec", ")", "\n", "self", ".", "metadata", "[", "'encoder_version'", "]", "=", "self", ".", "encoder", ".", "version_info", "\n", "\n", "", "try", ":", "\n", "            ", "self", ".", "encoder", ".", "capture_frame", "(", "frame", ")", "\n", "", "except", "error", ".", "InvalidFrame", "as", "e", ":", "\n", "            ", "logger", ".", "warn", "(", "'Tried to pass invalid video frame, marking as broken: %s'", ",", "e", ")", "\n", "self", ".", "broken", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "empty", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.TextEncoder.__init__": [[182, 186], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "output_path", ",", "frames_per_sec", ")", ":", "\n", "        ", "self", ".", "output_path", "=", "output_path", "\n", "self", ".", "frames_per_sec", "=", "frames_per_sec", "\n", "self", ".", "frames", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.TextEncoder.capture_frame": [[187, 206], ["isinstance", "frame.getvalue.encode", "idsgame_video_recorder.TextEncoder.frames.append", "isinstance", "six.b", "gym.error.InvalidFrame", "six.b", "gym.error.InvalidFrame", "frame.getvalue", "gym.error.InvalidFrame", "type"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type"], ["", "def", "capture_frame", "(", "self", ",", "frame", ")", ":", "\n", "        ", "from", "six", "import", "string_types", "\n", "string", "=", "None", "\n", "if", "isinstance", "(", "frame", ",", "string_types", ")", ":", "\n", "            ", "string", "=", "frame", "\n", "", "elif", "isinstance", "(", "frame", ",", "StringIO", ")", ":", "\n", "            ", "string", "=", "frame", ".", "getvalue", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "error", ".", "InvalidFrame", "(", "'Wrong type {} for {}: text frame must be a string or StringIO'", ".", "format", "(", "type", "(", "frame", ")", ",", "frame", ")", ")", "\n", "\n", "", "frame_bytes", "=", "string", ".", "encode", "(", "'utf-8'", ")", "\n", "\n", "if", "frame_bytes", "[", "-", "1", ":", "]", "!=", "six", ".", "b", "(", "'\\n'", ")", ":", "\n", "            ", "raise", "error", ".", "InvalidFrame", "(", "'Frame must end with a newline: \"\"\"{}\"\"\"'", ".", "format", "(", "string", ")", ")", "\n", "\n", "", "if", "six", ".", "b", "(", "'\\r'", ")", "in", "frame_bytes", ":", "\n", "            ", "raise", "error", ".", "InvalidFrame", "(", "'Frame contains carriage returns (only newlines are allowed: \"\"\"{}\"\"\"'", ".", "format", "(", "string", ")", ")", "\n", "\n", "", "self", ".", "frames", ".", "append", "(", "frame_bytes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.TextEncoder.close": [[207, 236], ["six.b", "max", "max", "open", "json.dump", "len", "frame.count", "max", "six.b", "frame.replace", "len", "six.b", "six.b", "frame.split", "six.b"], "methods", ["None"], ["", "def", "close", "(", "self", ")", ":", "\n", "#frame_duration = float(1) / self.frames_per_sec", "\n", "        ", "frame_duration", "=", ".5", "\n", "\n", "# Turn frames into events: clear screen beforehand", "\n", "# https://rosettacode.org/wiki/Terminal_control/Clear_the_screen#Python", "\n", "# https://rosettacode.org/wiki/Terminal_control/Cursor_positioning#Python", "\n", "clear_code", "=", "six", ".", "b", "(", "\"%c[2J\\033[1;1H\"", "%", "(", "27", ")", ")", "\n", "# Decode the bytes as UTF-8 since JSON may only contain UTF-8", "\n", "events", "=", "[", "(", "frame_duration", ",", "(", "clear_code", "+", "frame", ".", "replace", "(", "six", ".", "b", "(", "'\\n'", ")", ",", "six", ".", "b", "(", "'\\r\\n'", ")", ")", ")", ".", "decode", "(", "'utf-8'", ")", ")", "for", "frame", "in", "self", ".", "frames", "]", "\n", "\n", "# Calculate frame size from the largest frames.", "\n", "# Add some padding since we'll get cut off otherwise.", "\n", "height", "=", "max", "(", "[", "frame", ".", "count", "(", "six", ".", "b", "(", "'\\n'", ")", ")", "for", "frame", "in", "self", ".", "frames", "]", ")", "+", "1", "\n", "width", "=", "max", "(", "[", "max", "(", "[", "len", "(", "line", ")", "for", "line", "in", "frame", ".", "split", "(", "six", ".", "b", "(", "'\\n'", ")", ")", "]", ")", "for", "frame", "in", "self", ".", "frames", "]", ")", "+", "2", "\n", "\n", "data", "=", "{", "\n", "\"version\"", ":", "1", ",", "\n", "\"width\"", ":", "width", ",", "\n", "\"height\"", ":", "height", ",", "\n", "\"duration\"", ":", "len", "(", "self", ".", "frames", ")", "*", "frame_duration", ",", "\n", "\"command\"", ":", "\"-\"", ",", "\n", "\"title\"", ":", "\"gym VideoRecorder episode\"", ",", "\n", "\"env\"", ":", "{", "}", ",", "# could add some env metadata here", "\n", "\"stdout\"", ":", "events", ",", "\n", "}", "\n", "\n", "with", "open", "(", "self", ".", "output_path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "data", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.TextEncoder.version_info": [[237, 240], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "version_info", "(", "self", ")", ":", "\n", "        ", "return", "{", "'backend'", ":", "'TextEncoder'", ",", "'version'", ":", "1", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.__init__": [[242, 262], ["idsgame_video_recorder.ImageEncoder.start", "gym.error.InvalidFrame", "distutils.spawn.find_executable", "distutils.spawn.find_executable", "distutils.spawn.find_executable", "distutils.spawn.find_executable", "distutils.spawn.find_executable", "distutils.spawn.find_executable", "distutils.spawn.find_executable", "distutils.spawn.find_executable", "gym.error.DependencyNotInstalled"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.start"], ["    ", "def", "__init__", "(", "self", ",", "output_path", ",", "frame_shape", ",", "frames_per_sec", ")", ":", "\n", "        ", "self", ".", "proc", "=", "None", "\n", "self", ".", "output_path", "=", "output_path", "\n", "# Frame shape should be lines-first, so w and h are swapped", "\n", "h", ",", "w", ",", "pixfmt", "=", "frame_shape", "\n", "if", "pixfmt", "!=", "3", "and", "pixfmt", "!=", "4", ":", "\n", "            ", "raise", "error", ".", "InvalidFrame", "(", "\"Your frame has shape {}, but we require (w,h,3) or (w,h,4), i.e., RGB values for a w-by-h image, with an optional alpha channel.\"", ".", "format", "(", "frame_shape", ")", ")", "\n", "", "self", ".", "wh", "=", "(", "w", ",", "h", ")", "\n", "self", ".", "includes_alpha", "=", "(", "pixfmt", "==", "4", ")", "\n", "self", ".", "frame_shape", "=", "frame_shape", "\n", "self", ".", "frames_per_sec", "=", "frames_per_sec", "\n", "\n", "if", "distutils", ".", "spawn", ".", "find_executable", "(", "'avconv'", ")", "is", "not", "None", ":", "\n", "            ", "self", ".", "backend", "=", "'avconv'", "\n", "", "elif", "distutils", ".", "spawn", ".", "find_executable", "(", "'ffmpeg'", ")", "is", "not", "None", ":", "\n", "            ", "self", ".", "backend", "=", "'ffmpeg'", "\n", "", "else", ":", "\n", "            ", "raise", "error", ".", "DependencyNotInstalled", "(", "\"\"\"Found neither the ffmpeg nor avconv executables. On OS X, you can install ffmpeg via `brew install ffmpeg`. On most Ubuntu variants, `sudo apt-get install ffmpeg` should do it. On Ubuntu 14.04, however, you'll need to install avconv with `sudo apt-get install libav-tools`.\"\"\"", ")", "\n", "\n", "", "self", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.version_info": [[263, 270], ["str", "subprocess.check_output"], "methods", ["None"], ["", "@", "property", "\n", "def", "version_info", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "'backend'", ":", "self", ".", "backend", ",", "\n", "'version'", ":", "str", "(", "subprocess", ".", "check_output", "(", "[", "self", ".", "backend", ",", "'-version'", "]", ",", "\n", "stderr", "=", "subprocess", ".", "STDOUT", ")", ")", ",", "\n", "'cmdline'", ":", "self", ".", "cmdline", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.start": [[272, 297], ["gym.logger.debug", "hasattr", "subprocess.Popen", "subprocess.Popen"], "methods", ["None"], ["", "def", "start", "(", "self", ")", ":", "\n", "        ", "self", ".", "cmdline", "=", "(", "self", ".", "backend", ",", "\n", "'-nostats'", ",", "\n", "'-loglevel'", ",", "'error'", ",", "# suppress warnings", "\n", "'-y'", ",", "\n", "'-r'", ",", "'%d'", "%", "self", ".", "frames_per_sec", ",", "\n", "\n", "# input", "\n", "'-f'", ",", "'rawvideo'", ",", "\n", "'-s:v'", ",", "'{}x{}'", ".", "format", "(", "*", "self", ".", "wh", ")", ",", "\n", "'-pix_fmt'", ",", "(", "'rgb32'", "if", "self", ".", "includes_alpha", "else", "'rgb24'", ")", ",", "\n", "'-i'", ",", "'-'", ",", "# this used to be /dev/stdin, which is not Windows-friendly", "\n", "\n", "# output", "\n", "'-vf'", ",", "'scale=trunc(iw/2)*2:trunc(ih/2)*2'", ",", "\n", "'-vcodec'", ",", "'libx264'", ",", "\n", "'-pix_fmt'", ",", "'yuv420p'", ",", "\n", "self", ".", "output_path", "\n", ")", "\n", "\n", "logger", ".", "debug", "(", "'Starting ffmpeg with \"%s\"'", ",", "' '", ".", "join", "(", "self", ".", "cmdline", ")", ")", "\n", "if", "hasattr", "(", "os", ",", "'setsid'", ")", ":", "#setsid not present on Windows", "\n", "            ", "self", ".", "proc", "=", "subprocess", ".", "Popen", "(", "self", ".", "cmdline", ",", "stdin", "=", "subprocess", ".", "PIPE", ",", "preexec_fn", "=", "os", ".", "setsid", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "proc", "=", "subprocess", ".", "Popen", "(", "self", ".", "cmdline", ",", "stdin", "=", "subprocess", ".", "PIPE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.capture_frame": [[298, 310], ["isinstance", "gym.error.InvalidFrame", "gym.error.InvalidFrame", "gym.error.InvalidFrame", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "distutils.version.LooseVersion", "idsgame_video_recorder.ImageEncoder.proc.stdin.write", "idsgame_video_recorder.ImageEncoder.proc.stdin.write", "frame.tobytes", "frame.tostring", "type"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_stats_recorder.StatsRecorder.type"], ["", "", "def", "capture_frame", "(", "self", ",", "frame", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "frame", ",", "(", "np", ".", "ndarray", ",", "np", ".", "generic", ")", ")", ":", "\n", "            ", "raise", "error", ".", "InvalidFrame", "(", "'Wrong type {} for {} (must be np.ndarray or np.generic)'", ".", "format", "(", "type", "(", "frame", ")", ",", "frame", ")", ")", "\n", "", "if", "frame", ".", "shape", "!=", "self", ".", "frame_shape", ":", "\n", "            ", "raise", "error", ".", "InvalidFrame", "(", "\"Your frame has shape {}, but the VideoRecorder is configured for shape {}.\"", ".", "format", "(", "frame", ".", "shape", ",", "self", ".", "frame_shape", ")", ")", "\n", "", "if", "frame", ".", "dtype", "!=", "np", ".", "uint8", ":", "\n", "            ", "raise", "error", ".", "InvalidFrame", "(", "\"Your frame has data type {}, but we require uint8 (i.e. RGB values from 0-255).\"", ".", "format", "(", "frame", ".", "dtype", ")", ")", "\n", "\n", "", "if", "distutils", ".", "version", ".", "LooseVersion", "(", "np", ".", "__version__", ")", ">=", "distutils", ".", "version", ".", "LooseVersion", "(", "'1.9.0'", ")", ":", "\n", "            ", "self", ".", "proc", ".", "stdin", ".", "write", "(", "frame", ".", "tobytes", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "proc", ".", "stdin", ".", "write", "(", "frame", ".", "tostring", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close": [[311, 316], ["idsgame_video_recorder.ImageEncoder.proc.stdin.close", "idsgame_video_recorder.ImageEncoder.proc.wait", "gym.logger.error"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["", "", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "proc", ".", "stdin", ".", "close", "(", ")", "\n", "ret", "=", "self", ".", "proc", ".", "wait", "(", ")", "\n", "if", "ret", "!=", "0", ":", "\n", "            ", "logger", ".", "error", "(", "\"VideoRecorder encoder exited with status {}\"", ".", "format", "(", "ret", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.touch": [[12, 14], ["open().close", "open"], "function", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.video.idsgame_video_recorder.ImageEncoder.close"], ["def", "touch", "(", "path", ")", ":", "\n", "    ", "open", "(", "path", ",", "'a'", ")", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.__init__": [[27, 55], ["super().__init__", "game_frame.GameFrame.setup_resources_path", "game_frame.GameFrame.create_batch", "game_frame.GameFrame.set_state", "game_frame.GameFrame.switch_to", "game_frame.GameFrame.toggle_attacker_view", "game_frame.GameFrame.toggle_defender_view", "game_frame.GameFrame.toggle_full_view"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.setup_resources_path", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.create_batch", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.set_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.toggle_attacker_view", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.toggle_defender_view", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.toggle_full_view"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", ")", ":", "\n", "        ", "\"\"\"\n        Constructor, initializes the frame\n\n        :param idsgame_config: Config for the IdsGameEnv\n        \"\"\"", "\n", "self", ".", "idsgame_config", "=", "idsgame_config", "\n", "# call constructor of parent class", "\n", "super", "(", "GameFrame", ",", "self", ")", ".", "__init__", "(", "height", "=", "idsgame_config", ".", "render_config", ".", "height", ",", "\n", "width", "=", "idsgame_config", ".", "render_config", ".", "width", ",", "\n", "caption", "=", "idsgame_config", ".", "render_config", ".", "caption", ")", "\n", "self", ".", "resource_network", "=", "None", "\n", "self", ".", "attacker_sprite", "=", "None", "\n", "self", ".", "defender_agent", "=", "None", "\n", "self", ".", "attacker_agent", "=", "None", "\n", "self", ".", "game_state", ":", "GameState", "=", "None", "\n", "self", ".", "setup_resources_path", "(", ")", "\n", "self", ".", "create_batch", "(", ")", "\n", "self", ".", "set_state", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "initial_state", ")", "\n", "self", ".", "switch_to", "(", ")", "\n", "self", ".", "attacker_view", "=", "self", ".", "idsgame_config", ".", "render_config", ".", "attacker_view", "\n", "self", ".", "defender_view", "=", "self", ".", "idsgame_config", ".", "render_config", ".", "defender_view", "\n", "if", "self", ".", "attacker_view", "and", "not", "self", ".", "defender_view", ":", "\n", "            ", "self", ".", "toggle_attacker_view", "(", ")", "\n", "", "elif", "not", "self", ".", "attacker_view", "and", "self", ".", "defender_view", ":", "\n", "            ", "self", ".", "toggle_defender_view", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "toggle_full_view", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.create_batch": [[56, 87], ["gym_idsgame.envs.rendering.util.render_util.batch_rect_fill", "gym_idsgame.envs.rendering.network.network.Network", "game_frame.GameFrame.resource_network.create_links", "gym_idsgame.envs.rendering.agents.attacker.Attacker", "gym_idsgame.envs.rendering.frames.panels.game_panel.GamePanel"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_rect_fill", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.create_links"], ["", "", "def", "create_batch", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Creates a batch of elements to render. By grouping elements in a batch we can utilize OpenGL batch rendering\n        and reduce the cpu <\u2013> gpu data transfers and the number of draw-calls.\n\n        :return: None\n        \"\"\"", "\n", "\n", "# Sets the background color", "\n", "batch_rect_fill", "(", "0", ",", "0", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "width", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "height", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "bg_color", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "background", ")", "\n", "\n", "# Resource Network", "\n", "self", ".", "resource_network", "=", "Network", "(", "self", ".", "idsgame_config", ")", "\n", "\n", "# Resource Network Links", "\n", "self", ".", "resource_network", ".", "create_links", "(", ")", "\n", "\n", "# Attacker Sprite", "\n", "attacker_row", ",", "attacker_col", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "start_pos", "\n", "self", ".", "attacker_sprite", "=", "Attacker", "(", "self", ".", "idsgame_config", ",", "attacker_col", ",", "attacker_row", ")", "\n", "\n", "# Defender Agent", "\n", "self", ".", "defender_agent", "=", "self", ".", "idsgame_config", ".", "defender_agent", "\n", "\n", "# Attacker Agent", "\n", "self", ".", "attacker_agent", "=", "self", ".", "idsgame_config", ".", "attacker_agent", "\n", "\n", "# Game Panel", "\n", "self", ".", "game_panel", "=", "GamePanel", "(", "self", ".", "idsgame_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.setup_resources_path": [[88, 101], ["os.path.exists", "pyglet.resource.reindex", "os.path.dirname", "os.path.join"], "methods", ["None"], ["", "def", "setup_resources_path", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Setup path to resources (e.g. images)\n\n        :return: None\n        \"\"\"", "\n", "if", "os", ".", "path", ".", "exists", "(", "self", ".", "idsgame_config", ".", "render_config", ".", "resources_dir", ")", ":", "\n", "            ", "pyglet", ".", "resource", ".", "path", "=", "[", "self", ".", "idsgame_config", ".", "render_config", ".", "resources_dir", "]", "\n", "", "else", ":", "\n", "            ", "script_dir", "=", "os", ".", "path", ".", "dirname", "(", "__file__", ")", "\n", "resource_path", "=", "os", ".", "path", ".", "join", "(", "script_dir", ",", "'./'", ",", "constants", ".", "RENDERING", ".", "RESOURCES_DIR", ")", "\n", "pyglet", ".", "resource", ".", "path", "=", "[", "resource_path", "]", "\n", "", "pyglet", ".", "resource", ".", "reindex", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.on_draw": [[102, 117], ["game_frame.GameFrame.clear", "game_frame.GameFrame.idsgame_config.render_config.batch.draw", "game_frame.GameFrame.switch_to"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.experience_replay.replay_buffer.ReplayBuffer.clear"], ["", "def", "on_draw", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Event handler for on_draw event. OpenGL does not remember what was rendered on the previous frame so\n        we redraw each frame every time. This method is typically called many times per second.\n\n        Draws the GridWorld Frame\n\n        :return: None\n        \"\"\"", "\n", "# Clear the window", "\n", "self", ".", "clear", "(", ")", "\n", "# Draw batch with the frame contents", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ".", "draw", "(", ")", "\n", "# Make this window the current OpenGL rendering context", "\n", "self", ".", "switch_to", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.on_mouse_press": [[118, 277], ["game_frame.GameFrame.unschedule_events", "range", "range", "game_frame.GameFrame.game_state.defend", "game_frame.GameFrame.attacker_agent.action", "gym_idsgame.interpret_attack_action", "gym_idsgame.is_attack_legal", "[].visualize_defense", "gym_idsgame.is_attack_legal", "[].visualize_attack", "game_frame.GameFrame.game_state.attack", "game_frame.GameFrame.game_state.reconnaissance", "[].visualize_attack", "game_frame.GameFrame.game_state.simulate_attack", "[].visualize_reconnaissance", "game_frame.GameFrame.game_state.simulate_detection", "gym_idsgame.is_attack_legal", "game_frame.GameFrame.defender_agent.action", "gym_idsgame.interpret_defense_action", "game_frame.GameFrame.idsgame_config.game_config.network_config.get_node_id", "game_frame.GameFrame.game_state.defend", "[].visualize_defense", "game_frame.GameFrame.resource_network.get", "game_frame.GameFrame.game_state.attack", "game_frame.GameFrame.game_state.reconnaissance", "node.visualize_attack", "game_frame.GameFrame.game_state.simulate_attack", "node.visualize_reconnaissance", "game_frame.GameFrame.game_state.simulate_detection", "game_frame.GameFrame.resource_network.get"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.unschedule_events", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.defend", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.random_defense_bot_agent.RandomDefenseBotAgent.action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.interpret_attack_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.visualize_defense", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.visualize_attack", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.attack", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.reconnaissance", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.visualize_attack", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.simulate_attack", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.visualize_reconnaissance", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.simulate_detection", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.envs.idsgame_env.IdsGameEnv.is_attack_legal", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.bot_agents.random_defense_bot_agent.RandomDefenseBotAgent.action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.idsgame_util.interpret_defense_action", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.network_config.NetworkConfig.get_node_id", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.defend", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.visualize_defense", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.get", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.attack", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.reconnaissance", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.visualize_attack", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.simulate_attack", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.visualize_reconnaissance", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.simulate_detection", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.get"], ["", "def", "on_mouse_press", "(", "self", ",", "x", ":", "int", ",", "y", ":", "int", ",", "button", ",", "modifiers", ")", "->", "None", ":", "\n", "# Dont do anything if agent is playing", "\n", "        ", "if", "not", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_attacker", "and", "not", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_defender", ":", "\n", "            ", "return", "\n", "# Dont do anything if game is over", "\n", "", "if", "self", ".", "game_state", ".", "done", ":", "\n", "            ", "return", "\n", "\n", "# Unschedule events from previous press, if any", "\n", "", "self", ".", "unschedule_events", "(", ")", "\n", "# 1. Find the node in the network that was pressed", "\n", "for", "i", "in", "range", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_rows", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_cols", ")", ":", "\n", "                ", "node", "=", "self", ".", "resource_network", ".", "grid", "[", "i", "]", "[", "j", "]", "\n", "if", "node", ".", "node_type", "!=", "NodeType", ".", "EMPTY", ":", "\n", "\n", "                    ", "if", "node", ".", "node_type", "==", "NodeType", ".", "START", ":", "\n", "                        ", "if", "node", ".", "x", "-", "node", ".", "radius", "<", "x", "<", "(", "node", ".", "x", "+", "node", ".", "radius", ")", "and", "node", ".", "y", "-", "node", ".", "radius", "<", "y", "<", "(", "node", ".", "y", "+", "node", ".", "radius", ")", ":", "\n", "# 1.5 Special case: if it is the start node, let the attacker move there without making", "\n", "# any attack or risk to be detected", "\n", "                            ", "if", "node", ".", "node_type", "==", "NodeType", ".", "START", "and", "util", ".", "is_attack_legal", "(", "\n", "node", ".", "pos", ",", "self", ".", "attacker_sprite", ".", "pos", ",", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ")", ":", "\n", "                                ", "attack_row", ",", "attack_col", "=", "self", ".", "game_state", ".", "attacker_pos", "\n", "self", ".", "resource_network", ".", "grid", "[", "attack_row", "]", "[", "attack_col", "]", ".", "visualize_attack", "(", "\n", "self", ".", "game_state", ".", "attack_defense_type", ",", "node", ".", "pos", ",", "[", "]", ")", "\n", "self", ".", "game_state", ".", "attacker_pos", "=", "node", ".", "pos", "\n", "self", ".", "game_state", ".", "game_step", "+=", "1", "\n", "return", "\n", "\n", "", "", "", "if", "node", ".", "x", "<", "x", "<", "(", "node", ".", "x", "+", "node", ".", "width", ")", "and", "node", ".", "y", "<", "y", "<", "(", "node", ".", "y", "+", "node", ".", "height", ")", ":", "\n", "\n", "# Manual Defender", "\n", "                        ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_defender", ":", "\n", "\n", "                            ", "detect", "=", "modifiers", "&", "pyglet", ".", "window", ".", "key", ".", "MOD_SHIFT", "\n", "\n", "# 2. Update defense state", "\n", "self", ".", "game_state", ".", "defend", "(", "node", ".", "id", ",", "self", ".", "game_state", ".", "attack_defense_type", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "max_value", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ",", "detect", "=", "detect", ")", "\n", "\n", "# 3. Update attack state", "\n", "attack_id", "=", "self", ".", "attacker_agent", ".", "action", "(", "self", ".", "game_state", ")", "\n", "attack_node_id", ",", "attack_node_pos", ",", "attack_type", ",", "reconnaissance", "=", "util", ".", "interpret_attack_action", "(", "\n", "attack_id", ",", "self", ".", "idsgame_config", ".", "game_config", ")", "\n", "attack_row", ",", "attack_col", "=", "attack_node_pos", "\n", "legal", "=", "util", ".", "is_attack_legal", "(", "attack_node_pos", ",", "self", ".", "attacker_sprite", ".", "pos", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ")", "\n", "\n", "if", "not", "reconnaissance", ":", "\n", "                                ", "self", ".", "game_state", ".", "attack", "(", "attack_node_id", ",", "attack_type", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "max_value", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ",", "\n", "reconnaissance_enabled", "=", "self", ".", "idsgame_config", ".", "reconnaissance_actions", ")", "\n", "", "else", ":", "\n", "                                ", "self", ".", "game_state", ".", "reconnaissance", "(", "attack_node_id", ",", "attack_type", ",", "reconnaissance_reward", "=", "self", ".", "idsgame_config", ".", "reconnaissance_reward", ")", "\n", "\n", "# 4. Visualize defense", "\n", "", "self", ".", "resource_network", ".", "grid", "[", "node", ".", "row", "]", "[", "node", ".", "col", "]", ".", "visualize_defense", "(", "detect", "=", "detect", ")", "\n", "\n", "attack_successful", "=", "False", "\n", "\n", "if", "not", "reconnaissance", ":", "\n", "# 6. Visualize attack", "\n", "                                ", "edges", "=", "[", "]", "\n", "if", "self", ".", "resource_network", ".", "grid", "[", "attack_row", "]", "[", "attack_col", "]", ".", "node_type", "==", "NodeType", ".", "DATA", ":", "\n", "                                    ", "edges", "=", "self", ".", "resource_network", ".", "get", "(", "self", ".", "attacker_sprite", ".", "pos", ")", ".", "outgoing_edges", "\n", "\n", "", "self", ".", "resource_network", ".", "grid", "[", "attack_row", "]", "[", "attack_col", "]", ".", "visualize_attack", "(", "\n", "attack_type", ",", "self", ".", "game_state", ".", "attacker_pos", ",", "edges", ")", "\n", "\n", "# 7. Simulate attack outcome", "\n", "attack_successful", "=", "self", ".", "game_state", ".", "simulate_attack", "(", "\n", "attack_node_id", ",", "attack_type", ",", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ")", "\n", "", "else", ":", "\n", "# 6. Visualize reconnaissance", "\n", "                                ", "self", ".", "resource_network", ".", "grid", "[", "attack_row", "]", "[", "attack_col", "]", ".", "visualize_reconnaissance", "(", ")", "\n", "\n", "# 8. Update game state based on the outcome of the attack", "\n", "", "self", ".", "game_state", ".", "game_step", "+=", "1", "\n", "if", "attack_successful", ":", "\n", "                                ", "self", ".", "game_state", ".", "attacker_pos", "=", "(", "attack_row", ",", "attack_col", ")", "\n", "if", "self", ".", "resource_network", ".", "grid", "[", "attack_row", "]", "[", "attack_col", "]", ".", "node_type", "==", "NodeType", ".", "DATA", ":", "\n", "                                    ", "self", ".", "game_state", ".", "done", "=", "True", "\n", "self", ".", "game_state", ".", "hacked", "=", "True", "\n", "", "", "else", ":", "\n", "                                ", "detected", "=", "self", ".", "game_state", ".", "simulate_detection", "(", "\n", "self", ".", "resource_network", ".", "grid", "[", "attack_row", "]", "[", "attack_col", "]", ".", "id", ",", "reconnaissance", "=", "reconnaissance", ",", "\n", "reconnaissance_detection_factor", "=", "self", ".", "idsgame_config", ".", "reconnaissance_detection_factor", ")", "\n", "if", "detected", ":", "\n", "                                    ", "self", ".", "game_state", ".", "done", "=", "True", "\n", "self", ".", "game_state", ".", "detected", "=", "True", "\n", "\n", "# Manual Attacker", "\n", "", "", "", "elif", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_attacker", ":", "\n", "# 2. Check that the selected node can be attacked (there is a link to it from the current", "\n", "# position of the attacker)", "\n", "                            ", "if", "util", ".", "is_attack_legal", "(", "node", ".", "pos", ",", "self", ".", "attacker_sprite", ".", "pos", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ")", ":", "\n", "# 3. Update defense state", "\n", "                                ", "defend_id", "=", "self", ".", "defender_agent", ".", "action", "(", "self", ".", "game_state", ")", "\n", "defend_node_id", ",", "defend_node_pos", ",", "defend_type", "=", "util", ".", "interpret_defense_action", "(", "\n", "defend_id", ",", "self", ".", "idsgame_config", ".", "game_config", ")", "\n", "defense_row", ",", "defense_col", "=", "defend_node_pos", "\n", "detect", "=", "defend_type", "==", "self", ".", "idsgame_config", ".", "game_config", ".", "max_value", "+", "1", "\n", "\n", "defend_node_id", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ".", "get_node_id", "(", "\n", "(", "defense_row", ",", "defense_col", ")", ")", "\n", "self", ".", "game_state", ".", "defend", "(", "defend_node_id", ",", "defend_type", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "max_value", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ",", "detect", "=", "detect", ")", "\n", "\n", "# 4. Update attack state", "\n", "reconnaissance", "=", "self", ".", "game_state", ".", "attack_defense_type", ">=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "\n", "if", "not", "reconnaissance", ":", "\n", "                                    ", "self", ".", "game_state", ".", "attack", "(", "node", ".", "id", ",", "self", ".", "game_state", ".", "attack_defense_type", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "max_value", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ",", "\n", "reconnaissance_enabled", "=", "self", ".", "idsgame_config", ".", "reconnaissance_actions", ")", "\n", "", "else", ":", "\n", "                                    ", "attack_type", "=", "self", ".", "game_state", ".", "attack_defense_type", "-", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "\n", "self", ".", "game_state", ".", "reconnaissance", "(", "node", ".", "id", ",", "attack_type", ",", "reconnaissance_reward", "=", "self", ".", "idsgame_config", ".", "reconnaissance_reward", ")", "\n", "\n", "# 5. Visualize defense", "\n", "", "self", ".", "resource_network", ".", "grid", "[", "defense_row", "]", "[", "defense_col", "]", ".", "visualize_defense", "(", "detect", ")", "\n", "\n", "attack_successful", "=", "False", "\n", "\n", "if", "not", "reconnaissance", ":", "\n", "# 6. Visualize attack", "\n", "                                    ", "edges", "=", "[", "]", "\n", "if", "node", ".", "node_type", "==", "NodeType", ".", "DATA", ":", "\n", "                                        ", "edges", "=", "self", ".", "resource_network", ".", "get", "(", "self", ".", "attacker_sprite", ".", "pos", ")", ".", "outgoing_edges", "\n", "", "node", ".", "visualize_attack", "(", "self", ".", "game_state", ".", "attack_defense_type", ",", "self", ".", "game_state", ".", "attacker_pos", ",", "\n", "edges", ")", "\n", "\n", "# 7. Simulate attack outcome", "\n", "attack_successful", "=", "self", ".", "game_state", ".", "simulate_attack", "(", "\n", "node", ".", "id", ",", "self", ".", "game_state", ".", "attack_defense_type", ",", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ")", "\n", "", "else", ":", "\n", "# 6. Visualize reconnaissance activity", "\n", "                                    ", "node", ".", "visualize_reconnaissance", "(", ")", "\n", "\n", "# 8. Update game state based on the outcome of the attack", "\n", "", "self", ".", "game_state", ".", "game_step", "+=", "1", "\n", "if", "attack_successful", ":", "\n", "                                    ", "self", ".", "game_state", ".", "attacker_pos", "=", "node", ".", "pos", "\n", "if", "node", ".", "node_type", "==", "NodeType", ".", "DATA", ":", "\n", "                                        ", "self", ".", "game_state", ".", "done", "=", "True", "\n", "self", ".", "game_state", ".", "hacked", "=", "True", "\n", "", "", "else", ":", "\n", "                                    ", "detected", "=", "self", ".", "game_state", ".", "simulate_detection", "(", "node", ".", "id", ",", "reconnaissance", "=", "reconnaissance", ",", "\n", "reconnaissance_detection_factor", "=", "self", ".", "idsgame_config", ".", "reconnaissance_detection_factor", ")", "\n", "if", "detected", ":", "\n", "                                        ", "self", ".", "game_state", ".", "done", "=", "True", "\n", "self", ".", "game_state", ".", "detected", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.on_key_press": [[278, 396], ["game_frame.GameFrame.reset", "game_frame.GameFrame.toggle_attacker_view", "game_frame.GameFrame.toggle_defender_view", "game_frame.GameFrame.toggle_full_view"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.toggle_attacker_view", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.toggle_defender_view", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.toggle_full_view"], ["", "", "", "", "", "", "", "", "", "def", "on_key_press", "(", "self", ",", "symbol", ",", "modifiers", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Event handler for on_key_press event.\n        The user can move the agent with key presses.\n\n        :param symbol: the symbol of the keypress\n        :param modifiers: _\n        :return: None\n        \"\"\"", "\n", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_attacker", "or", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_defender", ":", "\n", "            ", "if", "symbol", "==", "pyglet", ".", "window", ".", "key", ".", "_1", ":", "\n", "                ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_attacker", ":", "\n", "                    ", "cond", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ">", "1", "\n", "if", "self", ".", "idsgame_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "cond", "=", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", ")", ">", "1", "\n", "", "if", "cond", ":", "\n", "                        ", "self", ".", "game_state", ".", "attack_defense_type", "=", "1", "\n", "", "", "elif", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_defender", ":", "\n", "                    ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ">", "1", ":", "\n", "                        ", "self", ".", "game_state", ".", "attack_defense_type", "=", "1", "\n", "", "", "", "elif", "symbol", "==", "pyglet", ".", "window", ".", "key", ".", "_2", ":", "\n", "                ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_attacker", ":", "\n", "                    ", "cond", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ">", "2", "\n", "if", "self", ".", "idsgame_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "cond", "=", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", ")", ">", "2", "\n", "", "if", "cond", ":", "\n", "                        ", "self", ".", "game_state", ".", "attack_defense_type", "=", "2", "\n", "", "", "elif", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_defender", ":", "\n", "                    ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ">", "2", ":", "\n", "                        ", "self", ".", "game_state", ".", "attack_defense_type", "=", "2", "\n", "", "", "", "elif", "symbol", "==", "pyglet", ".", "window", ".", "key", ".", "_3", ":", "\n", "                ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_attacker", ":", "\n", "                    ", "cond", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ">", "3", "\n", "if", "self", ".", "idsgame_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "cond", "=", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", ")", ">", "3", "\n", "", "if", "cond", ":", "\n", "                        ", "self", ".", "game_state", ".", "attack_defense_type", "=", "3", "\n", "", "", "elif", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_defender", ":", "\n", "                    ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ">", "3", ":", "\n", "                        ", "self", ".", "game_state", ".", "attack_defense_type", "=", "3", "\n", "", "", "", "elif", "symbol", "==", "pyglet", ".", "window", ".", "key", ".", "_4", ":", "\n", "                ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_attacker", ":", "\n", "                    ", "cond", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "//", "self", ".", "idsgame_config", ".", "game_config", ".", "num_nodes", ">", "4", "\n", "if", "self", ".", "idsgame_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "cond", "=", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", ")", ">", "4", "\n", "", "if", "cond", ":", "\n", "                        ", "self", ".", "game_state", ".", "attack_defense_type", "=", "4", "\n", "", "", "elif", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_defender", ":", "\n", "                    ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ">", "4", ":", "\n", "                        ", "self", ".", "game_state", ".", "attack_defense_type", "=", "4", "\n", "", "", "", "elif", "symbol", "==", "pyglet", ".", "window", ".", "key", ".", "_5", ":", "\n", "                ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_attacker", ":", "\n", "                    ", "cond", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ">", "5", "\n", "if", "self", ".", "idsgame_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "cond", "=", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", ")", ">", "5", "\n", "", "if", "cond", ":", "\n", "                        ", "self", ".", "game_state", ".", "attack_defense_type", "=", "5", "\n", "", "", "elif", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_defender", ":", "\n", "                    ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ">", "5", ":", "\n", "                        ", "self", ".", "game_state", ".", "attack_defense_type", "=", "5", "\n", "", "", "", "elif", "symbol", "==", "pyglet", ".", "window", ".", "key", ".", "_6", ":", "\n", "                ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_attacker", ":", "\n", "                    ", "cond", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ">", "6", "\n", "if", "self", ".", "idsgame_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "cond", "=", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", ")", ">", "6", "\n", "", "if", "cond", ":", "\n", "                        ", "self", ".", "game_state", ".", "attack_defense_type", "=", "6", "\n", "", "", "elif", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_defender", ":", "\n", "                    ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ">", "6", ":", "\n", "                        ", "self", ".", "game_state", ".", "attack_defense_type", "=", "6", "\n", "", "", "", "elif", "symbol", "==", "pyglet", ".", "window", ".", "key", ".", "_7", ":", "\n", "                ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_attacker", ":", "\n", "                    ", "cond", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ">", "7", "\n", "if", "self", ".", "idsgame_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "cond", "=", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", ")", ">", "7", "\n", "", "if", "cond", ":", "\n", "                        ", "self", ".", "game_state", ".", "attack_defense_type", "=", "7", "\n", "", "", "elif", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_defender", ":", "\n", "                    ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ">", "7", ":", "\n", "                        ", "self", ".", "game_state", ".", "attack_defense_type", "=", "7", "\n", "", "", "", "elif", "symbol", "==", "pyglet", ".", "window", ".", "key", ".", "_8", ":", "\n", "                ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_attacker", ":", "\n", "                    ", "cond", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ">", "8", "\n", "if", "self", ".", "idsgame_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "cond", "=", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", ")", ">", "8", "\n", "", "if", "cond", ":", "\n", "                        ", "self", ".", "game_state", ".", "attack_defense_type", "=", "8", "\n", "", "", "elif", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_defender", ":", "\n", "                    ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ">", "8", ":", "\n", "                        ", "self", ".", "game_state", ".", "attack_defense_type", "=", "8", "\n", "", "", "", "elif", "symbol", "==", "pyglet", ".", "window", ".", "key", ".", "_9", ":", "\n", "                ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_attacker", ":", "\n", "                    ", "cond", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ">", "9", "\n", "if", "self", ".", "idsgame_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "cond", "=", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", ")", ">", "9", "\n", "", "if", "cond", ":", "\n", "                        ", "self", ".", "game_state", ".", "attack_defense_type", "=", "9", "\n", "", "", "elif", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_defender", ":", "\n", "                    ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ">", "9", ":", "\n", "                        ", "self", ".", "game_state", ".", "attack_defense_type", "=", "9", "\n", "", "", "", "elif", "symbol", "==", "pyglet", ".", "window", ".", "key", ".", "_0", ":", "\n", "                ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_attacker", ":", "\n", "                    ", "cond", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ">", "0", "\n", "if", "self", ".", "idsgame_config", ".", "reconnaissance_actions", ":", "\n", "                        ", "cond", "=", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "+", "1", ")", ">", "0", "\n", "", "if", "cond", ":", "\n", "                        ", "self", ".", "game_state", ".", "attack_defense_type", "=", "0", "\n", "", "", "elif", "self", ".", "idsgame_config", ".", "game_config", ".", "manual_defender", ":", "\n", "                    ", "if", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ">", "0", ":", "\n", "                        ", "self", ".", "game_state", ".", "attack_defense_type", "=", "0", "\n", "", "", "", "elif", "symbol", "==", "pyglet", ".", "window", ".", "key", ".", "SPACE", ":", "\n", "                ", "self", ".", "reset", "(", "update_stats", "=", "True", ")", "\n", "", "elif", "symbol", "==", "pyglet", ".", "window", ".", "key", ".", "A", ":", "\n", "                ", "self", ".", "toggle_attacker_view", "(", ")", "\n", "", "elif", "symbol", "==", "pyglet", ".", "window", ".", "key", ".", "D", ":", "\n", "                ", "self", ".", "toggle_defender_view", "(", ")", "\n", "", "elif", "symbol", "==", "pyglet", ".", "window", ".", "key", ".", "F", ":", "\n", "                ", "self", ".", "toggle_full_view", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.toggle_attacker_view": [[397, 411], ["range", "game_frame.GameFrame.attacker_sprite.show", "range", "node.toggle_attacker_view"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.agents.attacker.Attacker.show", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.toggle_attacker_view"], ["", "", "", "def", "toggle_attacker_view", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Toggle attacker's view, hide defender details (partially observed)\n\n        :return: None\n        \"\"\"", "\n", "self", ".", "attacker_view", "=", "True", "\n", "self", ".", "defender_view", "=", "False", "\n", "for", "i", "in", "range", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_rows", "-", "1", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_cols", ")", ":", "\n", "                ", "node", "=", "self", ".", "resource_network", ".", "grid", "[", "i", "]", "[", "j", "]", "\n", "if", "node", "is", "not", "None", "and", "node", ".", "node_type", "!=", "NodeType", ".", "EMPTY", ":", "\n", "                    ", "node", ".", "toggle_attacker_view", "(", ")", "\n", "", "", "", "self", ".", "attacker_sprite", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.toggle_defender_view": [[412, 426], ["range", "game_frame.GameFrame.attacker_sprite.hide", "range", "node.toggle_defender_view"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.agents.attacker.Attacker.hide", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.toggle_defender_view"], ["", "def", "toggle_defender_view", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Toggle defender's view, hide attacker details (partially observed)\n\n        :return: None\n        \"\"\"", "\n", "self", ".", "attacker_view", "=", "False", "\n", "self", ".", "defender_view", "=", "True", "\n", "for", "i", "in", "range", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_rows", "-", "1", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_cols", ")", ":", "\n", "                ", "node", "=", "self", ".", "resource_network", ".", "grid", "[", "i", "]", "[", "j", "]", "\n", "if", "node", "is", "not", "None", "and", "node", ".", "node_type", "!=", "NodeType", ".", "EMPTY", ":", "\n", "                    ", "node", ".", "toggle_defender_view", "(", ")", "\n", "", "", "", "self", ".", "attacker_sprite", ".", "hide", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.toggle_full_view": [[427, 441], ["range", "game_frame.GameFrame.attacker_sprite.show", "range", "node.toggle_full_view"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.agents.attacker.Attacker.show", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.toggle_full_view"], ["", "def", "toggle_full_view", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Toggle fully observed view\n\n        :return: None\n        \"\"\"", "\n", "self", ".", "attacker_view", "=", "True", "\n", "self", ".", "defender_view", "=", "True", "\n", "for", "i", "in", "range", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_rows", "-", "1", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_cols", ")", ":", "\n", "                ", "node", "=", "self", ".", "resource_network", ".", "grid", "[", "i", "]", "[", "j", "]", "\n", "if", "node", "is", "not", "None", "and", "node", ".", "node_type", "!=", "NodeType", ".", "EMPTY", ":", "\n", "                    ", "node", ".", "toggle_full_view", "(", ")", "\n", "", "", "", "self", ".", "attacker_sprite", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.update": [[443, 451], ["game_frame.GameFrame.set_state"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.set_state"], ["", "def", "update", "(", "self", ",", "dt", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Event handler for the update-event (timer-based typically), used to update the state of the grid.\n\n        :param dt: the number of seconds since the function was last called\n        :return: None\n        \"\"\"", "\n", "self", ".", "set_state", "(", "self", ".", "game_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.set_state": [[453, 468], ["game_state.copy", "game_frame.GameFrame.game_panel.update_state_text", "game_frame.GameFrame.attacker_sprite.move_to_pos", "game_frame.GameFrame.resource_network.set_node_states", "game_frame.GameFrame.attacker_sprite.detected", "game_frame.GameFrame.attacker_sprite.undetect"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.copy", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.update_state_text", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.agents.attacker.Attacker.move_to_pos", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.set_node_states", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.agents.attacker.Attacker.detected", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.agents.attacker.Attacker.undetect"], ["", "def", "set_state", "(", "self", ",", "game_state", ":", "GameState", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Updates the current state\n\n        :param state: the new state\n        :return: None\n        \"\"\"", "\n", "self", ".", "game_state", "=", "game_state", ".", "copy", "(", ")", "\n", "self", ".", "game_panel", ".", "update_state_text", "(", "self", ".", "game_state", ")", "\n", "self", ".", "attacker_sprite", ".", "move_to_pos", "(", "self", ".", "game_state", ".", "attacker_pos", ")", "\n", "if", "game_state", ".", "detected", ":", "\n", "            ", "self", ".", "attacker_sprite", ".", "detected", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "attacker_sprite", ".", "undetect", "(", ")", "\n", "", "self", ".", "resource_network", ".", "set_node_states", "(", "self", ".", "game_state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.simulate_events": [[469, 478], ["game_frame.GameFrame.simulate_defense_events", "game_frame.GameFrame.simulate_attack_events"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.simulate_defense_events", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.simulate_attack_events"], ["", "def", "simulate_events", "(", "self", ",", "i", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Simulates attack/defense events manually. Method used when rendering in agent-mode\n\n        :param i: the index of the event visualization\n        :return:  None\n        \"\"\"", "\n", "self", ".", "simulate_defense_events", "(", "self", ".", "game_state", ".", "defense_events", ",", "i", ")", "\n", "self", ".", "simulate_attack_events", "(", "self", ".", "game_state", ".", "attack_events", ",", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset_events": [[479, 487], ["None"], "methods", ["None"], ["", "def", "reset_events", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the events for agent-mode rendering\n\n        :return: None\n        \"\"\"", "\n", "self", ".", "game_state", ".", "attack_events", "=", "[", "]", "\n", "self", ".", "game_state", ".", "defense_events", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.simulate_attack_events": [[488, 512], ["[].manual_blink_attack", "[].manual_reconnaissance", "[].manual_blink_attack", "game_frame.GameFrame.resource_network.get"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.manual_blink_attack", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.manual_reconnaissance", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.manual_blink_attack", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.network.network.Network.get"], ["", "def", "simulate_attack_events", "(", "self", ",", "attack_events", ":", "List", "[", "AttackDefenseEvent", "]", ",", "i", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Simulate attack events manually for rendering in agent-mode\n\n        :param attack_events: the list of attack events to simulate\n        :param i: the index of the event visualization\n        :return: None\n        \"\"\"", "\n", "for", "attack", "in", "attack_events", ":", "\n", "            ", "self", ".", "attack_type", "=", "attack", ".", "attack_defense_type", "\n", "target_node", ":", "Node", "=", "self", ".", "resource_network", ".", "grid", "[", "attack", ".", "target_row", "]", "[", "attack", ".", "target_col", "]", "\n", "attack_row", ",", "attack_col", "=", "attack", ".", "attacker_pos", "\n", "edges", "=", "[", "]", "\n", "if", "not", "attack", ".", "reconnaissance", ":", "\n", "                ", "if", "target_node", ".", "node_type", "==", "NodeType", ".", "DATA", ":", "\n", "                    ", "edges", "=", "self", ".", "resource_network", ".", "get", "(", "attack", ".", "attacker_pos", ")", ".", "outgoing_edges", "\n", "", "if", "target_node", ".", "node_type", "==", "NodeType", ".", "START", ":", "\n", "                    ", "self", ".", "resource_network", ".", "grid", "[", "attack_row", "]", "[", "attack_col", "]", ".", "manual_blink_attack", "(", "\n", "i", ",", "target_node", ".", "pos", ",", "edges", ")", "\n", "return", "\n", "", "self", ".", "resource_network", ".", "grid", "[", "attack", ".", "target_row", "]", "[", "attack", ".", "target_col", "]", ".", "manual_blink_attack", "(", "\n", "i", ",", "attack", ".", "attacker_pos", ",", "edges", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "resource_network", ".", "grid", "[", "attack", ".", "target_row", "]", "[", "attack", ".", "target_col", "]", ".", "manual_reconnaissance", "(", "i", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.simulate_defense_events": [[513, 524], ["[].manual_blink_defense"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.manual_blink_defense"], ["", "", "", "def", "simulate_defense_events", "(", "self", ",", "defense_events", ":", "List", "[", "AttackDefenseEvent", "]", ",", "i", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Simulate defense events manually for rendering in agent-mode\n\n        :param defense_events: the list of defense events to simulate\n        :param i: the index of the event visualization\n        :return: None\n        \"\"\"", "\n", "for", "defense", "in", "defense_events", ":", "\n", "            ", "detect", "=", "defense", ".", "attack_defense_type", "==", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", "\n", "self", ".", "resource_network", ".", "grid", "[", "defense", ".", "target_row", "]", "[", "defense", ".", "target_col", "]", ".", "manual_blink_defense", "(", "i", ",", "detect", "=", "detect", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.unschedule_events": [[525, 537], ["range", "range", "node.unschedule"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.nodes.resource_node.ResourceNode.unschedule"], ["", "", "def", "unschedule_events", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Utility method for unscheduling events. When the user triggers an action before the last action completed,\n        this method will be called to avoid getting spam-visualizations in the UI.\n\n        :return: None\n        \"\"\"", "\n", "for", "i", "in", "range", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_rows", "-", "1", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "num_cols", ")", ":", "\n", "                ", "node", "=", "self", ".", "resource_network", ".", "grid", "[", "i", "]", "[", "j", "]", "\n", "if", "node", "is", "not", "None", ":", "\n", "                    ", "node", ".", "unschedule", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset": [[538, 568], ["game_frame.GameFrame.game_state.new_game", "game_frame.GameFrame.set_state", "game_frame.GameFrame.reset_events", "game_frame.GameFrame.unschedule_events", "game_frame.GameFrame.switch_to", "game_frame.GameFrame.game_state.randomize_attacker_position"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.new_game", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.set_state", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.reset_events", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.frames.game_frame.GameFrame.unschedule_events", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.dao.game_state.GameState.randomize_attacker_position"], ["", "", "", "", "def", "reset", "(", "self", ",", "update_stats", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Resets the agent state without closing the screen\n\n        :param update_stats: boolean flag whether to update the game statistics\n        :return: None\n        \"\"\"", "\n", "self", ".", "game_state", ".", "new_game", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "initial_state", ",", "\n", "a_reward", "=", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", ",", "\n", "d_reward", "=", "constants", ".", "GAME_CONFIG", ".", "POSITIVE_REWARD", ",", "\n", "update_stats", "=", "update_stats", ",", "\n", "randomize_state", "=", "self", ".", "idsgame_config", ".", "randomize_env", ",", "\n", "network_config", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ",", "\n", "num_attack_types", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_attack_types", ",", "\n", "defense_val", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "defense_val", ",", "\n", "attack_val", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "attack_val", ",", "\n", "det_val", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "det_val", ",", "\n", "vulnerability_val", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "vulnerabilitiy_val", ",", "\n", "num_vulnerabilities_per_layer", "=", "\n", "self", ".", "idsgame_config", ".", "game_config", ".", "num_vulnerabilities_per_layer", ",", "\n", "num_vulnerabilities_per_node", "=", "self", ".", "idsgame_config", ".", "game_config", ".", "num_vulnerabilities_per_node", ",", "\n", "randomize_visibility", "=", "self", ".", "idsgame_config", ".", "randomize_visibility", ",", "\n", "visibility_p", "=", "self", ".", "idsgame_config", ".", "visibility_p", "\n", ")", "\n", "if", "self", ".", "idsgame_config", ".", "randomize_starting_position", ":", "\n", "            ", "self", ".", "game_state", ".", "randomize_attacker_position", "(", "self", ".", "idsgame_config", ".", "game_config", ".", "network_config", ")", "\n", "", "self", ".", "set_state", "(", "self", ".", "game_state", ")", "\n", "self", ".", "reset_events", "(", ")", "\n", "self", ".", "unschedule_events", "(", ")", "\n", "self", ".", "switch_to", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.__init__": [[14, 28], ["game_panel.GamePanel.set_labels"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.set_labels"], ["def", "__init__", "(", "self", ",", "idsgame_config", ":", "IdsGameConfig", ")", ":", "\n", "        ", "\"\"\"\n        Constructor, initializes the panel\n\n        :param idsgame_config: IdsGameEnv config\n        \"\"\"", "\n", "self", ".", "idsgame_config", "=", "idsgame_config", "\n", "self", ".", "attack_type_label", "=", "None", "\n", "self", ".", "a_reward_label", "=", "None", "\n", "self", ".", "d_reward_label", "=", "None", "\n", "self", ".", "step_label", "=", "None", "\n", "self", ".", "num_games_label", "=", "None", "\n", "self", ".", "hack_probability", "=", "None", "\n", "self", ".", "set_labels", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.set_labels": [[29, 115], ["gym_idsgame.envs.rendering.util.render_util.batch_label", "gym_idsgame.envs.rendering.util.render_util.batch_label", "gym_idsgame.envs.rendering.util.render_util.batch_label", "gym_idsgame.envs.rendering.util.render_util.batch_label", "gym_idsgame.envs.rendering.util.render_util.batch_label", "gym_idsgame.envs.rendering.util.render_util.batch_label", "gym_idsgame.envs.rendering.util.render_util.batch_label", "gym_idsgame.envs.rendering.util.render_util.batch_label", "gym_idsgame.envs.rendering.util.render_util.batch_label", "gym_idsgame.envs.rendering.util.render_util.batch_label", "gym_idsgame.envs.rendering.util.render_util.batch_label", "gym_idsgame.envs.rendering.util.render_util.batch_label", "gym_idsgame.envs.rendering.util.render_util.batch_label"], "methods", ["home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_label", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_label", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_label", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_label", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_label", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_label", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_label", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_label", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_label", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_label", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_label", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_label", "home.repos.pwc.inspect_result.Limmen_gym-idsgame.util.render_util.batch_label"], ["", "def", "set_labels", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Creates the labels of the panel (should only be called once)\n\n        :return: None\n        \"\"\"", "\n", "batch_label", "(", "self", ".", "idsgame_config", ".", "render_config", ".", "title", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "height", "-", "constants", ".", "RENDERING", ".", "PANEL_TOP_MARGIN", ",", "\n", "constants", ".", "RENDERING", ".", "PANEL_FONT_SIZE", ",", "constants", ".", "RENDERING", ".", "BLACK_ALPHA", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "second_foreground", ",", "bold", "=", "True", ")", "\n", "batch_label", "(", "\"Attack Reward: \"", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "\n", "-", "4.1", "*", "constants", ".", "RENDERING", ".", "PANEL_LEFT_MARGIN", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "height", "-", "constants", ".", "RENDERING", ".", "PANEL_TOP_MARGIN", "*", "2", ",", "\n", "constants", ".", "RENDERING", ".", "PANEL_FONT_SIZE", ",", "constants", ".", "RENDERING", ".", "BLACK_ALPHA", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "second_foreground", ")", "\n", "batch_label", "(", "\"Time-step: \"", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "\n", "-", "4.1", "*", "constants", ".", "RENDERING", ".", "PANEL_LEFT_MARGIN", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "height", "-", "constants", ".", "RENDERING", ".", "PANEL_TOP_MARGIN", "*", "3", ",", "\n", "constants", ".", "RENDERING", ".", "PANEL_FONT_SIZE", ",", "constants", ".", "RENDERING", ".", "BLACK_ALPHA", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "second_foreground", ")", "\n", "batch_label", "(", "\"A/D Type: \"", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "-", "\n", "0.8", "*", "constants", ".", "RENDERING", ".", "PANEL_LEFT_MARGIN", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "height", "-", "constants", ".", "RENDERING", ".", "PANEL_TOP_MARGIN", "*", "3", ",", "\n", "constants", ".", "RENDERING", ".", "PANEL_FONT_SIZE", ",", "constants", ".", "RENDERING", ".", "BLACK_ALPHA", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "second_foreground", ")", "\n", "batch_label", "(", "\"Defense Reward: \"", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "-", "\n", "0.8", "*", "constants", ".", "RENDERING", ".", "PANEL_LEFT_MARGIN", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "height", "-", "constants", ".", "RENDERING", ".", "PANEL_TOP_MARGIN", "*", "2", ",", "\n", "constants", ".", "RENDERING", ".", "PANEL_FONT_SIZE", ",", "constants", ".", "RENDERING", ".", "BLACK_ALPHA", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "second_foreground", ")", "\n", "batch_label", "(", "\"Num Games: \"", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "\n", "+", "constants", ".", "RENDERING", ".", "PANEL_LEFT_MARGIN", "*", "2.4", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "height", "-", "constants", ".", "RENDERING", ".", "PANEL_TOP_MARGIN", "*", "2", ",", "\n", "constants", ".", "RENDERING", ".", "PANEL_FONT_SIZE", ",", "constants", ".", "RENDERING", ".", "BLACK_ALPHA", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "second_foreground", ")", "\n", "batch_label", "(", "\"P(breached): \"", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "\n", "+", "constants", ".", "RENDERING", ".", "PANEL_LEFT_MARGIN", "*", "2.4", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "height", "-", "constants", ".", "RENDERING", ".", "PANEL_TOP_MARGIN", "*", "3", ",", "\n", "constants", ".", "RENDERING", ".", "PANEL_FONT_SIZE", ",", "constants", ".", "RENDERING", ".", "BLACK_ALPHA", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "second_foreground", ")", "\n", "self", ".", "attack_type_label", "=", "batch_label", "(", "\"0\"", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "+", "\n", "0.9", "*", "constants", ".", "RENDERING", ".", "PANEL_LEFT_MARGIN", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "height", "\n", "-", "constants", ".", "RENDERING", ".", "PANEL_TOP_MARGIN", "*", "3", ",", "\n", "constants", ".", "RENDERING", ".", "PANEL_FONT_SIZE", ",", "constants", ".", "RENDERING", ".", "BLACK_ALPHA", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "second_foreground", ")", "\n", "self", ".", "a_reward_label", "=", "batch_label", "(", "\"0\"", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "\n", "-", "2.5", "*", "constants", ".", "RENDERING", ".", "PANEL_LEFT_MARGIN", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "height", "-", "\n", "constants", ".", "RENDERING", ".", "PANEL_TOP_MARGIN", "*", "2", ",", "\n", "constants", ".", "RENDERING", ".", "PANEL_FONT_SIZE", ",", "constants", ".", "RENDERING", ".", "BLACK_ALPHA", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "second_foreground", ")", "\n", "self", ".", "d_reward_label", "=", "batch_label", "(", "\"0\"", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "+", "\n", "0.9", "*", "constants", ".", "RENDERING", ".", "PANEL_LEFT_MARGIN", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "height", "-", "\n", "constants", ".", "RENDERING", ".", "PANEL_TOP_MARGIN", "*", "2", ",", "\n", "constants", ".", "RENDERING", ".", "PANEL_FONT_SIZE", ",", "constants", ".", "RENDERING", ".", "BLACK_ALPHA", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "second_foreground", ")", "\n", "self", ".", "step_label", "=", "batch_label", "(", "\"0\"", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "\n", "-", "2.5", "*", "constants", ".", "RENDERING", ".", "PANEL_LEFT_MARGIN", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "height", "-", "\n", "constants", ".", "RENDERING", ".", "PANEL_TOP_MARGIN", "*", "3", ",", "\n", "constants", ".", "RENDERING", ".", "PANEL_FONT_SIZE", ",", "constants", ".", "RENDERING", ".", "BLACK_ALPHA", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "second_foreground", ")", "\n", "self", ".", "num_games_label", "=", "batch_label", "(", "\"0\"", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "+", "\n", "3.8", "*", "constants", ".", "RENDERING", ".", "PANEL_LEFT_MARGIN", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "height", "-", "\n", "constants", ".", "RENDERING", ".", "PANEL_TOP_MARGIN", "*", "2", ",", "\n", "constants", ".", "RENDERING", ".", "PANEL_FONT_SIZE", ",", "constants", ".", "RENDERING", ".", "BLACK_ALPHA", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "second_foreground", ")", "\n", "self", ".", "hack_probability", "=", "batch_label", "(", "\"0.0\"", ",", "self", ".", "idsgame_config", ".", "render_config", ".", "width", "//", "2", "+", "\n", "3.8", "*", "constants", ".", "RENDERING", ".", "PANEL_LEFT_MARGIN", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "height", "-", "\n", "constants", ".", "RENDERING", ".", "PANEL_TOP_MARGIN", "*", "3", ",", "\n", "constants", ".", "RENDERING", ".", "PANEL_FONT_SIZE", ",", "constants", ".", "RENDERING", ".", "BLACK_ALPHA", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "batch", ",", "\n", "self", ".", "idsgame_config", ".", "render_config", ".", "second_foreground", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Limmen_gym-idsgame.panels.game_panel.GamePanel.update_state_text": [[116, 132], ["str", "str", "str", "str", "str", "float", "float"], "methods", ["None"], ["", "def", "update_state_text", "(", "self", ",", "game_state", ":", "GameState", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Updates the text of the labels on the panel\n\n        :param game_state: the state to reflect in the labels\n        :return: None\n        \"\"\"", "\n", "self", ".", "attack_type_label", ".", "text", "=", "str", "(", "game_state", ".", "attack_defense_type", ")", "\n", "self", ".", "a_reward_label", ".", "text", "=", "str", "(", "game_state", ".", "attacker_cumulative_reward", ")", "\n", "self", ".", "d_reward_label", ".", "text", "=", "str", "(", "game_state", ".", "defender_cumulative_reward", ")", "\n", "self", ".", "step_label", ".", "text", "=", "str", "(", "game_state", ".", "game_step", ")", "\n", "self", ".", "num_games_label", ".", "text", "=", "str", "(", "game_state", ".", "num_games", ")", "\n", "hack_probability", "=", "0.0", "\n", "if", "game_state", ".", "num_hacks", ">", "0", ":", "\n", "            ", "hack_probability", "=", "float", "(", "game_state", ".", "num_hacks", ")", "/", "float", "(", "game_state", ".", "num_games", ")", "\n", "", "self", ".", "hack_probability", ".", "text", "=", "\"{0:.2f}\"", ".", "format", "(", "hack_probability", ")", "\n", "", "", ""]]}