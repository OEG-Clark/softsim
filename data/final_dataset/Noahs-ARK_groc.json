{"home.repos.pwc.inspect_result.Noahs-ARK_groc.None.adaptive_io.AdaptiveEmbedding.__init__": [[18, 43], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "torch.nn.ParameterList", "range", "min", "max", "len", "len", "adaptive_io.AdaptiveEmbedding.emb_layers.append", "adaptive_io.AdaptiveEmbedding.emb_projs.append", "torch.nn.Embedding", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.locked_dropout.LockedDropout.__init__"], ["def", "__init__", "(", "self", ",", "n_tokens", ",", "d_embed", ",", "d_proj", ",", "cutoffs", ",", "div_val", "=", "4", ")", ":", "\n", "        ", "super", "(", "AdaptiveEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_tokens", "=", "n_tokens", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "self", ".", "d_proj", "=", "d_proj", "\n", "\n", "assert", "0", "<", "min", "(", "cutoffs", ")", "<=", "max", "(", "cutoffs", ")", "<", "n_tokens", "\n", "self", ".", "cutoffs", "=", "cutoffs", "+", "[", "n_tokens", "]", "\n", "self", ".", "cutoff_ends", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "self", ".", "div_val", "=", "div_val", "\n", "assert", "self", ".", "div_val", ">", "1", "\n", "assert", "len", "(", "self", ".", "cutoffs", ")", ">", "1", "\n", "\n", "self", ".", "emb_scale", "=", "d_proj", "**", "0.5", "\n", "\n", "self", ".", "emb_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "emb_projs", "=", "nn", ".", "ParameterList", "(", ")", "\n", "\n", "# embedding layers / projections", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "            ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "d_emb_i", "=", "d_embed", "//", "(", "div_val", "**", "i", ")", "\n", "self", ".", "emb_layers", ".", "append", "(", "nn", ".", "Embedding", "(", "r_idx", "-", "l_idx", ",", "d_emb_i", ")", ")", "\n", "self", ".", "emb_projs", ".", "append", "(", "nn", ".", "Linear", "(", "d_emb_i", ",", "d_proj", ")", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.adaptive_io.AdaptiveEmbedding.forward": [[44, 74], ["indices.contiguous().view", "torch.zeros", "range", "torch.zeros.view", "torch.zeros.view.mul_", "len", "mask_i.nonzero().squeeze", "torch.nn.functional.linear", "torch.zeros.index_copy_", "indices.contiguous", "indices.contiguous().view.size", "mask_i.nonzero().squeeze.numel", "indices.contiguous().view.index_select", "torch.zeros.type_as", "indices.size", "mask_i.nonzero"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "indices", ")", ":", "\n", "        ", "param", "=", "self", ".", "emb_layers", "[", "0", "]", ".", "weight", ".", "data", "\n", "idx_flat", "=", "indices", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "emb_flat", "=", "torch", ".", "zeros", "(", "[", "idx_flat", ".", "size", "(", "0", ")", ",", "self", ".", "d_proj", "]", ",", "dtype", "=", "param", ".", "dtype", ",", "device", "=", "param", ".", "device", ")", "\n", "\n", "# for each cluster", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "# find elements in that cluster", "\n", "            ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "mask_i", "=", "(", "idx_flat", ">=", "l_idx", ")", "&", "(", "idx_flat", "<", "r_idx", ")", "\n", "\n", "# if there are no elements, continue", "\n", "indices_i", "=", "mask_i", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "if", "indices_i", ".", "numel", "(", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "# add embeddings from this cluster", "\n", "", "idx_i", "=", "idx_flat", ".", "index_select", "(", "0", ",", "indices_i", ")", "-", "l_idx", "\n", "emb_i", "=", "self", ".", "emb_layers", "[", "i", "]", "(", "idx_i", ")", "\n", "emb_i", "=", "F", ".", "linear", "(", "emb_i", ",", "self", ".", "emb_projs", "[", "i", "]", ")", "\n", "emb_flat", "=", "emb_flat", ".", "type_as", "(", "emb_i", ")", "if", "emb_flat", ".", "dtype", "!=", "emb_i", ".", "dtype", "else", "emb_flat", "# small hack for AMP-O1", "\n", "emb_flat", ".", "index_copy_", "(", "0", ",", "indices_i", ",", "emb_i", ")", "\n", "\n", "# reshape embeddings", "\n", "", "embed", "=", "emb_flat", ".", "view", "(", "*", "indices", ".", "size", "(", ")", ",", "self", ".", "d_proj", ")", "\n", "\n", "# rescale embeddings", "\n", "embed", ".", "mul_", "(", "self", ".", "emb_scale", ")", "\n", "\n", "return", "embed", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.adaptive_io.ProjectedAdaptiveLogSoftmax.__init__": [[79, 109], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.ModuleList", "torch.nn.ParameterList", "range", "min", "max", "len", "len", "len", "adaptive_io.ProjectedAdaptiveLogSoftmax.out_projs.append", "adaptive_io.ProjectedAdaptiveLogSoftmax.out_layers.append", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.locked_dropout.LockedDropout.__init__"], ["def", "__init__", "(", "self", ",", "n_tokens", ",", "d_embed", ",", "d_proj", ",", "cutoffs", ",", "div_val", "=", "4", ")", ":", "\n", "        ", "super", "(", "ProjectedAdaptiveLogSoftmax", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "n_tokens", "=", "n_tokens", "\n", "self", ".", "d_embed", "=", "d_embed", "\n", "self", ".", "d_proj", "=", "d_proj", "\n", "\n", "assert", "0", "<", "min", "(", "cutoffs", ")", "<=", "max", "(", "cutoffs", ")", "<", "n_tokens", "\n", "self", ".", "cutoffs", "=", "cutoffs", "+", "[", "n_tokens", "]", "\n", "self", ".", "cutoff_ends", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "self", ".", "div_val", "=", "div_val", "\n", "assert", "self", ".", "div_val", ">", "1", "\n", "assert", "len", "(", "self", ".", "cutoffs", ")", ">", "1", "\n", "\n", "self", ".", "shortlist_size", "=", "self", ".", "cutoffs", "[", "0", "]", "\n", "self", ".", "n_clusters", "=", "len", "(", "self", ".", "cutoffs", ")", "-", "1", "\n", "self", ".", "head_size", "=", "self", ".", "shortlist_size", "+", "self", ".", "n_clusters", "\n", "\n", "# clusters parameters", "\n", "self", ".", "cluster_proj", "=", "nn", ".", "Linear", "(", "self", ".", "d_embed", ",", "self", ".", "n_clusters", ")", "\n", "\n", "self", ".", "out_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "out_projs", "=", "nn", ".", "ParameterList", "(", ")", "\n", "\n", "# output layers / projections", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "            ", "l_idx", ",", "r_idx", "=", "self", ".", "cutoff_ends", "[", "i", "]", ",", "self", ".", "cutoff_ends", "[", "i", "+", "1", "]", "\n", "d_emb_i", "=", "d_embed", "//", "(", "div_val", "**", "i", ")", "\n", "self", ".", "out_projs", ".", "append", "(", "nn", ".", "Linear", "(", "d_emb_i", ",", "d_proj", ")", ".", "weight", ")", "\n", "self", ".", "out_layers", ".", "append", "(", "nn", ".", "Linear", "(", "d_emb_i", ",", "r_idx", "-", "l_idx", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.adaptive_io.ProjectedAdaptiveLogSoftmax._compute_logit": [[110, 114], ["torch.nn.functional.linear", "torch.nn.functional.linear", "proj.t().contiguous", "proj.t"], "methods", ["None"], ["", "", "def", "_compute_logit", "(", "self", ",", "hidden", ",", "weight", ",", "bias", ",", "proj", ")", ":", "\n", "        ", "proj_hid", "=", "F", ".", "linear", "(", "hidden", ",", "proj", ".", "t", "(", ")", ".", "contiguous", "(", ")", ")", "# TODO: .contiguous() not necessary?", "\n", "logit", "=", "F", ".", "linear", "(", "proj_hid", ",", "weight", ",", "bias", "=", "bias", ")", "\n", "return", "logit", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.adaptive_io.ProjectedAdaptiveLogSoftmax.forward": [[115, 182], ["hidden.view.view.view", "target.view.view.view", "range", "adaptive_io.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.nn.functional.log_softmax", "torch.zeros_like", "range", "torch.zeros_like.view", "len", "weights.append", "biases.append", "adaptive_io.ProjectedAdaptiveLogSoftmax.float", "mask_i.nonzero().squeeze", "torch.nn.functional.log_softmax.index_select", "torch.zeros_like.index_copy_", "head_logprob.index_select.gather().squeeze.size", "torch.cat", "torch.cat", "len", "mask_i.nonzero().squeeze.numel", "target.view.view.index_select", "F.log_softmax.index_select.gather().squeeze", "hidden.view.view.index_select", "adaptive_io.ProjectedAdaptiveLogSoftmax._compute_logit", "torch.nn.functional.log_softmax", "mask_i.nonzero", "adaptive_io.ProjectedAdaptiveLogSoftmax.float", "torch.nn.functional.log_softmax.gather().squeeze", "F.log_softmax.index_select.gather", "torch.nn.functional.log_softmax.gather"], "methods", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.adaptive_io.ProjectedAdaptiveLogSoftmax._compute_logit", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.adaptive_io.ProjectedAdaptiveLogSoftmax._compute_logit"], ["", "def", "forward", "(", "self", ",", "hidden", ",", "target", ")", ":", "\n", "        ", "\"\"\"\n        Input:\n            - `hidden` FloatTensor(shape + (d_proj,))\n            - `target` LongTensor(shape)\n        Output:\n            - `nll` FloatTensor(shape)\n        \"\"\"", "\n", "assert", "hidden", ".", "shape", "[", "-", "1", "]", "==", "self", ".", "d_proj", "\n", "assert", "hidden", ".", "shape", "[", ":", "-", "1", "]", "==", "target", ".", "shape", "\n", "shape", "=", "target", ".", "shape", "\n", "hidden", "=", "hidden", ".", "view", "(", "-", "1", ",", "self", ".", "d_proj", ")", "\n", "target", "=", "target", ".", "view", "(", "-", "1", ")", "\n", "\n", "# construct weights and biases", "\n", "weights", ",", "biases", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "cutoffs", ")", ")", ":", "\n", "            ", "weight_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "weight", "\n", "bias_i", "=", "self", ".", "out_layers", "[", "i", "]", ".", "bias", "\n", "if", "i", "==", "0", ":", "\n", "                ", "weight_i", "=", "torch", ".", "cat", "(", "[", "weight_i", ",", "self", ".", "cluster_proj", ".", "weight", "]", ",", "dim", "=", "0", ")", "\n", "bias_i", "=", "torch", ".", "cat", "(", "[", "bias_i", ",", "self", ".", "cluster_proj", ".", "bias", "]", ",", "dim", "=", "0", ")", "\n", "", "weights", ".", "append", "(", "weight_i", ")", "\n", "biases", ".", "append", "(", "bias_i", ")", "\n", "\n", "# head / cluster assignments", "\n", "", "head_logit", "=", "self", ".", "_compute_logit", "(", "hidden", ",", "weights", "[", "0", "]", ",", "biases", "[", "0", "]", ",", "self", ".", "out_projs", "[", "0", "]", ")", "\n", "head_logprob", "=", "F", ".", "log_softmax", "(", "head_logit", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "\n", "# final log-probabilities", "\n", "nll", "=", "torch", ".", "zeros_like", "(", "target", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "hidden", ".", "device", ")", "\n", "\n", "offset", "=", "0", "\n", "cutoff_values", "=", "[", "0", "]", "+", "self", ".", "cutoffs", "\n", "\n", "# for each cluster", "\n", "for", "i", "in", "range", "(", "len", "(", "cutoff_values", ")", "-", "1", ")", ":", "\n", "\n", "# select the target tokens in that cluster", "\n", "            ", "l_idx", ",", "r_idx", "=", "cutoff_values", "[", "i", "]", ",", "cutoff_values", "[", "i", "+", "1", "]", "\n", "mask_i", "=", "(", "target", ">=", "l_idx", ")", "&", "(", "target", "<", "r_idx", ")", "\n", "indices_i", "=", "mask_i", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "\n", "# if there are not any, there is nothing to do", "\n", "if", "indices_i", ".", "numel", "(", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "# index in current cluster", "\n", "", "target_i", "=", "target", ".", "index_select", "(", "0", ",", "indices_i", ")", "-", "l_idx", "\n", "head_logprob_i", "=", "head_logprob", ".", "index_select", "(", "0", ",", "indices_i", ")", "\n", "\n", "if", "i", "==", "0", ":", "\n", "# for targets in the head cluster, there is just the head score", "\n", "                ", "logprob_i", "=", "head_logprob_i", ".", "gather", "(", "1", ",", "target_i", "[", ":", ",", "None", "]", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "# otherwise, we sum the cluster assignment (head) and target scores", "\n", "                ", "hidden_i", "=", "hidden", ".", "index_select", "(", "0", ",", "indices_i", ")", "\n", "tail_logit_i", "=", "self", ".", "_compute_logit", "(", "hidden_i", ",", "weights", "[", "i", "]", ",", "biases", "[", "i", "]", ",", "self", ".", "out_projs", "[", "i", "]", ")", "\n", "tail_logprob_i", "=", "F", ".", "log_softmax", "(", "tail_logit_i", ".", "float", "(", ")", ",", "dim", "=", "1", ")", "\n", "logprob_i", "=", "head_logprob_i", "[", ":", ",", "-", "i", "]", "+", "tail_logprob_i", ".", "gather", "(", "1", ",", "target_i", "[", ":", ",", "None", "]", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "# populate output", "\n", "", "nll", ".", "index_copy_", "(", "0", ",", "indices_i", ",", "-", "logprob_i", ")", "\n", "\n", "offset", "+=", "logprob_i", ".", "size", "(", "0", ")", "\n", "\n", "", "return", "nll", ".", "view", "(", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.adaptive_io.compute_dummy_loss": [[184, 194], ["sum", "sum", "sum", "sum", "sum"], "function", ["None"], ["", "", "def", "compute_dummy_loss", "(", "in_emb", ",", "out_emb", ")", ":", "\n", "# hack to fix adaptive ou/in with distributed code", "\n", "    ", "dummy_loss", "=", "0", "*", "(", "\n", "sum", "(", "x", ".", "weight", "[", "0", ",", "0", "]", "for", "x", "in", "in_emb", ".", "emb_layers", ")", "+", "\n", "sum", "(", "x", "[", "0", ",", "0", "]", "for", "x", "in", "in_emb", ".", "emb_projs", ")", "+", "\n", "sum", "(", "x", "[", "0", ",", "0", "]", "for", "x", "in", "out_emb", ".", "out_projs", ")", "+", "\n", "sum", "(", "x", ".", "weight", "[", "0", ",", "0", "]", "for", "x", "in", "out_emb", ".", "out_layers", ")", "+", "\n", "sum", "(", "x", ".", "bias", "[", "0", "]", "for", "x", "in", "out_emb", ".", "out_layers", ")", "\n", ")", "\n", "return", "dummy_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.adaptive_io.build_adaptive_io": [[196, 211], ["adaptive_io.AdaptiveEmbedding", "adaptive_io.ProjectedAdaptiveLogSoftmax", "range", "len"], "function", ["None"], ["", "def", "build_adaptive_io", "(", "vocab_size", ",", "hidden_size", ",", "adapt_io_cutoffs", ",", "\n", "adapt_io_divval", ",", "adapt_io_tied", ",", "**", "kargs", ")", ":", "\n", "    ", "in_emb", "=", "AdaptiveEmbedding", "(", "\n", "vocab_size", ",", "hidden_size", ",", "hidden_size", ",", "\n", "cutoffs", "=", "adapt_io_cutoffs", ",", "\n", "div_val", "=", "adapt_io_divval", ")", "\n", "out_emb", "=", "ProjectedAdaptiveLogSoftmax", "(", "\n", "vocab_size", ",", "hidden_size", ",", "hidden_size", ",", "\n", "cutoffs", "=", "adapt_io_cutoffs", ",", "\n", "div_val", "=", "adapt_io_divval", ")", "\n", "if", "adapt_io_tied", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "adapt_io_cutoffs", ")", "+", "1", ")", ":", "\n", "            ", "out_emb", ".", "out_layers", "[", "i", "]", ".", "weight", "=", "in_emb", ".", "emb_layers", "[", "i", "]", ".", "weight", "\n", "out_emb", ".", "out_projs", "[", "i", "]", "=", "in_emb", ".", "emb_projs", "[", "i", "]", "\n", "", "", "return", "in_emb", ",", "out_emb", "\n", "", ""]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.main.logging": [[197, 205], ["print", "open", "f_log.write", "os.path.join", "str", "model"], "function", ["None"], ["", "def", "logging", "(", "s", ",", "print_", "=", "True", ",", "log_", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n       Function to print logs to be used by different files.\n    \"\"\"", "\n", "print", "(", "s", ")", "\n", "if", "log_", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "save_dir", ",", "'log.txt'", ")", ",", "'a+'", ")", "as", "f_log", ":", "\n", "            ", "f_log", ".", "write", "(", "str", "(", "s", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.main.model_save": [[223, 225], ["utils.save_checkpoint"], "function", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.utils.save_checkpoint"], ["", "", "def", "model_save", "(", "model", ",", "criterion", ",", "optimizer", ",", "save", ")", ":", "\n", "    ", "save_checkpoint", "(", "model", ",", "criterion", ",", "optimizer", ",", "save", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.main.model_load": [[226, 241], ["open", "torch.load", "torch.load", "open", "torch.load", "torch.load", "open", "torch.load", "torch.load", "hasattr", "torch.load.coverage_filter", "hasattr", "torch.load.coverage_filter", "len", "torch.load.rel_arr.to", "len", "torch.load.def_arr.to"], "function", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.coverage_filter", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.coverage_filter"], ["", "def", "model_load", "(", "fn", ")", ":", "\n", "    ", "global", "model", ",", "criterion", ",", "optimizer", "\n", "with", "open", "(", "fn", "+", "'/model.pt'", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "model", "=", "torch", ".", "load", "(", "f", ",", "map_location", "=", "\"cuda:%d\"", "%", "args", ".", "cuda_device", ")", "\n", "model", ".", "H", ".", "coverage", "=", "args", ".", "coverage", "\n", "model", ".", "H", ".", "char_update_ratio", "=", "args", ".", "char_update_ratio", "\n", "if", "hasattr", "(", "model", ",", "\"rel_arr\"", ")", "and", "model", ".", "rel_arr", "is", "not", "None", "and", "len", "(", "model", ".", "rel_arr", ")", ">", "0", ":", "\n", "            ", "model", ".", "rel_arr", "=", "model", ".", "coverage_filter", "(", "model", ".", "rel_arr", ".", "to", "(", "args", ".", "cuda_device", ")", ")", "\n", "", "if", "hasattr", "(", "model", ",", "\"def_arr\"", ")", "and", "model", ".", "def_arr", "is", "not", "None", "and", "len", "(", "model", ".", "def_arr", ")", ">", "0", ":", "\n", "            ", "model", ".", "def_arr", "=", "model", ".", "coverage_filter", "(", "model", ".", "def_arr", ".", "to", "(", "args", ".", "cuda_device", ")", ")", "\n", "", "", "with", "open", "(", "fn", "+", "'/criterion.pt'", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "criterion", "=", "torch", ".", "load", "(", "f", ")", "\n", "", "with", "open", "(", "fn", "+", "'/optimizer.pt'", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "optimizer", "=", "torch", ".", "load", "(", "f", ")", "\n", "", "return", "model", ",", "criterion", ",", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.main.corpus_load": [[242, 253], ["print", "os.path.exists", "hashlib.md5().hexdigest", "main.logging", "torch.load", "torch.load", "main.logging", "data.Corpus", "torch.save", "torch.save", "hashlib.md5", "corpus_path.strip().encode", "corpus_path.strip"], "function", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.logging", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.logging"], ["", "def", "corpus_load", "(", "corpus_path", ",", "use_unk", "=", "False", ")", ":", "\n", "    ", "fn", "=", "'corpus.{}.data'", ".", "format", "(", "hashlib", ".", "md5", "(", "corpus_path", ".", "strip", "(", "'/'", ")", ".", "encode", "(", ")", ")", ".", "hexdigest", "(", ")", ")", "\n", "print", "(", "fn", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "fn", ")", ":", "\n", "        ", "logging", "(", "'Loading cached dataset from {}...'", ".", "format", "(", "corpus_path", ")", ")", "\n", "corpus", "=", "torch", ".", "load", "(", "fn", ")", "\n", "", "else", ":", "\n", "        ", "logging", "(", "'Producing dataset from {} ...'", ".", "format", "(", "corpus_path", ")", ")", "\n", "corpus", "=", "data", ".", "Corpus", "(", "args", ".", "data", ",", "use_unk", "=", "use_unk", ")", "\n", "torch", ".", "save", "(", "corpus", ",", "fn", ")", "\n", "", "return", "corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.main.evaluate": [[307, 320], ["model.eval", "torch.Tensor", "torch.Tensor", "len", "model.init_hidden", "range", "utils.get_batch", "model", "utils.repackage_hidden", "torch.Tensor.item", "len", "data_source.size", "torch.mm", "torch.mm", "len", "weight.t", "criterion"], "function", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.utils.get_batch", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.utils.repackage_hidden"], ["", "def", "evaluate", "(", "data_source", ",", "batch_size", "=", "10", ")", ":", "\n", "# Turn on evaluation mode which disables dropout.", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "total_loss", "=", "torch", ".", "Tensor", "(", "[", "0", "]", ")", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model", ".", "init_hidden", "(", "batch_size", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "data_source", ".", "size", "(", "0", ")", "-", "1", ",", "args", ".", "bptt", ")", ":", "\n", "        ", "data", ",", "targets", "=", "get_batch", "(", "data_source", ",", "i", ",", "args", ",", "evaluation", "=", "True", ")", "\n", "output", ",", "weight", ",", "bias", ",", "hidden", "=", "model", "(", "data", ",", "hidden", ")", "\n", "logits", "=", "torch", ".", "mm", "(", "output", ",", "weight", ".", "t", "(", ")", ")", "+", "bias", "\n", "total_loss", "+=", "len", "(", "data", ")", "*", "criterion", "(", "logits", ",", "targets", ")", ".", "data", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "", "return", "total_loss", ".", "item", "(", ")", "/", "len", "(", "data_source", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.main.train": [[322, 377], ["time.time", "len", "model.init_hidden", "max", "model.train", "utils.get_batch", "utils.repackage_hidden", "optimizer.zero_grad", "model", "criterion", "loss.backward", "optimizer.step", "int", "torch.mm", "torch.mm", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "main.logging", "time.time", "train_data.size", "numpy.random.random", "numpy.random.normal", "weight.t", "sum", "sum", "total_loss.item", "time.time", "math.exp", "len", "math.log", "dropped_rnn_h.pow().mean", "dropped_rnn_h.pow"], "function", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.main.train", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.utils.get_batch", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.utils.repackage_hidden", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.logging"], ["", "def", "train", "(", ")", ":", "\n", "# Turn on training mode which enables dropout.", "\n", "    ", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "ntokens", "=", "len", "(", "corpus", ".", "dictionary", ")", "\n", "hidden", "=", "model", ".", "init_hidden", "(", "args", ".", "batch_size", ")", "\n", "batch", ",", "i", "=", "0", ",", "0", "\n", "while", "i", "<", "train_data", ".", "size", "(", "0", ")", "-", "1", "-", "1", ":", "\n", "        ", "bptt", "=", "args", ".", "bptt", "if", "np", ".", "random", ".", "random", "(", ")", "<", "0.95", "else", "args", ".", "bptt", "/", "2.", "\n", "# Prevent excessively small or negative sequence lengths", "\n", "seq_len", "=", "max", "(", "5", ",", "int", "(", "np", ".", "random", ".", "normal", "(", "bptt", ",", "5", ")", ")", ")", "\n", "# There's a very small chance that it could select a very long sequence length resulting in OOM", "\n", "# seq_len = min(seq_len, args.bptt + 10)", "\n", "\n", "lr2", "=", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "*", "seq_len", "/", "args", ".", "bptt", "\n", "model", ".", "train", "(", ")", "\n", "data", ",", "targets", "=", "get_batch", "(", "train_data", ",", "i", ",", "args", ",", "seq_len", "=", "seq_len", ")", "\n", "\n", "# Starting each batch, we detach the hidden state from how it was previously produced.", "\n", "# If we didn't, the model would try backpropagating all the way to start of the dataset.", "\n", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "output", ",", "weight", ",", "bias", ",", "hidden", ",", "rnn_hs", ",", "dropped_rnn_hs", "=", "model", "(", "data", ",", "hidden", ",", "return_h", "=", "True", ")", "\n", "\n", "\n", "logits", "=", "torch", ".", "mm", "(", "output", ",", "weight", ".", "t", "(", ")", ")", "+", "bias", "\n", "raw_loss", "=", "criterion", "(", "logits", ",", "targets", ")", "\n", "\n", "loss", "=", "raw_loss", "\n", "# Activation Regularization", "\n", "if", "args", ".", "alpha", ":", "loss", "=", "loss", "+", "sum", "(", "args", ".", "alpha", "*", "dropped_rnn_h", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "dropped_rnn_h", "in", "dropped_rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "# Temporal Activation Regularization (slowness)", "\n", "if", "args", ".", "beta", ":", "loss", "=", "loss", "+", "sum", "(", "args", ".", "beta", "*", "(", "rnn_h", "[", "1", ":", "]", "-", "rnn_h", "[", ":", "-", "1", "]", ")", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "for", "rnn_h", "in", "rnn_hs", "[", "-", "1", ":", "]", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# `clip_grad_norm` helps prevent the exploding gradient problem in RNNs / LSTMs.", "\n", "if", "args", ".", "clip", ":", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "params", ",", "args", ".", "clip", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "total_loss", "+=", "raw_loss", ".", "data", "\n", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", "=", "lr2", "\n", "if", "batch", "%", "args", ".", "log_interval", "==", "0", "and", "batch", ">", "0", ":", "\n", "            ", "cur_loss", "=", "total_loss", ".", "item", "(", ")", "/", "args", ".", "log_interval", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "logging", "(", "'| epoch {:3d} | {:5d}/{:5d} batches | lr {:05.5e} | ms/batch {:5.2f} | '", "\n", "'loss {:5.2f} | ppl {:8.2f} | bpc {:8.3f}'", ".", "format", "(", "\n", "epoch", ",", "batch", ",", "len", "(", "train_data", ")", "//", "args", ".", "bptt", ",", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "\n", "elapsed", "*", "1000", "/", "args", ".", "log_interval", ",", "cur_loss", ",", "math", ".", "exp", "(", "cur_loss", ")", ",", "cur_loss", "/", "math", ".", "log", "(", "2", ")", ")", ")", "\n", "total_loss", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "###", "\n", "", "batch", "+=", "1", "\n", "i", "+=", "seq_len", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.logging": [[83, 88], ["print", "open", "f_log.write", "os.path.join", "str"], "function", ["None"], ["", "", "def", "logging", "(", "s", ",", "print_", "=", "True", ",", "log_", "=", "True", ")", ":", "\n", "    ", "print", "(", "s", ",", "file", "=", "sys", ".", "stderr", ")", "\n", "if", "log_", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "'eval_log.txt'", ")", ",", "'a+'", ")", "as", "f_log", ":", "\n", "            ", "f_log", ".", "write", "(", "str", "(", "s", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.log_interpolate": [[89, 111], ["d1.size", "torch.cat", "torch.cat", "torch.logsumexp", "torch.logsumexp", "d1.view", "numpy.log", "d2.view", "numpy.log"], "function", ["None"], ["", "", "", "def", "log_interpolate", "(", "d1", ",", "d2", ",", "weight", "=", "0.5", ")", ":", "\n", "    ", "\"\"\"\n    Interpolates the two distributions in log space. Uses torch.logsumexp\n    just in case, even though we're only adding pairs of probabilities,\n    because some of the probabilities in question can be quite small to\n    begin with!\n\n    Inputs:\n      d1: Tensor, requires_grad=True, size=(batch_size, vocab_size)\n      d2: Tensor, size=(batch_size, vocab_size)\n      weight: int. the interpolation weight (relative weight of d1 and d2)\n        makes the resulting distribution sum to 1 and not 2 :)\n\n    Returns:\n      A Tensor of size (batch_size, vocab_size) representing the interpolation of\n      d2 with each of the distributions for the batch instances in d1\n    \"\"\"", "\n", "batch_size", ",", "vocab_size", "=", "d1", ".", "size", "(", ")", "\n", "lse_tensor", "=", "torch", ".", "cat", "(", "(", "d1", ".", "view", "(", "batch_size", ",", "vocab_size", ",", "1", ")", "+", "np", ".", "log", "(", "weight", ")", ",", "\n", "d2", ".", "view", "(", "batch_size", ",", "vocab_size", ",", "1", ")", "+", "np", ".", "log", "(", "1", "-", "weight", ")", ")", "\n", ",", "2", ")", "\n", "return", "torch", ".", "logsumexp", "(", "lse_tensor", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.model_load": [[113, 121], ["open", "torch.load", "torch.load", "open", "torch.load", "torch.load", "open", "torch.load", "torch.load"], "function", ["None"], ["", "def", "model_load", "(", "fn", ",", "device", "=", "0", ")", ":", "\n", "    ", "with", "open", "(", "fn", "+", "'/model.pt'", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "model", "=", "torch", ".", "load", "(", "f", ",", "map_location", "=", "f'cuda:{device}'", ")", "\n", "", "with", "open", "(", "fn", "+", "'/criterion.pt'", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "criterion", "=", "torch", ".", "load", "(", "f", ",", "map_location", "=", "f'cuda:{device}'", ")", "\n", "", "with", "open", "(", "fn", "+", "'/optimizer.pt'", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "optimizer", "=", "torch", ".", "load", "(", "f", ",", "map_location", "=", "f'cuda:{device}'", ")", "\n", "", "return", "model", ",", "criterion", ",", "optimizer", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.corpus_load": [[122, 136], ["print", "os.path.exists", "evaluate.logging", "torch.load", "torch.load", "evaluate.logging", "data.Corpus", "torch.save", "torch.save", "hashlib.md5().hexdigest", "hashlib.md5().hexdigest", "hashlib.md5", "hashlib.md5", "corpus_path.strip().encode", "corpus_path.strip", "corpus_path.strip"], "function", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.logging", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.logging"], ["", "def", "corpus_load", "(", "corpus_path", ",", "test", ",", "use_unk", "=", "False", ")", ":", "\n", "    ", "if", "test", ":", "\n", "        ", "fn", "=", "'corpus.{}.data'", ".", "format", "(", "hashlib", ".", "md5", "(", "(", "corpus_path", ".", "strip", "(", "'/'", ")", "+", "\"-test\"", ")", ".", "encode", "(", ")", ")", ".", "hexdigest", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "fn", "=", "'corpus.{}.data'", ".", "format", "(", "hashlib", ".", "md5", "(", "corpus_path", ".", "strip", "(", "'/'", ")", ".", "encode", "(", ")", ")", ".", "hexdigest", "(", ")", ")", "\n", "", "print", "(", "fn", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "fn", ")", ":", "\n", "        ", "logging", "(", "'Loading cached dataset from {}...'", ".", "format", "(", "corpus_path", ")", ")", "\n", "corpus", "=", "torch", ".", "load", "(", "fn", ")", "\n", "", "else", ":", "\n", "        ", "logging", "(", "'Producing dataset from {} ...'", ".", "format", "(", "corpus_path", ")", ")", "\n", "corpus", "=", "data", ".", "Corpus", "(", "args", ".", "test_data", ",", "use_unk", "=", "use_unk", ")", "\n", "torch", ".", "save", "(", "corpus", ",", "fn", ")", "\n", "", "return", "corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.evaluate": [[137, 271], ["model.eval", "data_source.size", "len", "torch.arange().long", "torch.arange().long", "torch.zeros().cuda", "torch.zeros().cuda", "collections.deque", "model.init_hidden", "isinstance", "range", "os.path.isfile", "evaluate.logging", "evaluate.logging", "evaluate.logging", "evaluate.logging", "torch.LogSoftmax", "torch.NLLLoss", "model.get_new", "utils.get_batch", "model", "isinstance", "utils.repackage_hidden", "print", "total_loss.item", "torch.arange", "torch.arange", "torch.zeros", "torch.zeros", "os.path.join", "open", "pickle.load", "torch.load", "torch.load", "torch.load", "torch.load", "range", "len", "print", "torch.mm", "torch.mm", "len", "collections.deque.popleft", "collections.deque.append", "evaluate.logging", "evaluate.logging", "evaluate.logging", "torch.zeros().cuda", "torch.zeros().cuda", "os.path.join", "os.path.join", "os.path.join", "evaluate.logging", "torch.load", "torch.load", "torch.zeros", "torch.zeros", "torch.load.size", "collections.deque.append", "weight.t", "lexp.log.exp", "logits.exp.log", "len", "collections.deque.append", "math.exp", "open", "pickle.dump", "torch.save", "torch.save", "evaluate.logging", "torch.save", "torch.save", "os.path.join", "[].size", "[].size", "criterion", "nn.LogSoftmax.", "evaluate.log_interpolate", "ValueError", "math.exp", "os.path.join", "os.path.join", "evaluate.logging", "torch.save", "torch.save", "torch.cat", "torch.cat", "os.path.join", "torch.zeros", "torch.zeros", "torch.load.size", "uniform_dist.repeat", "nn.LogSoftmax.", "evaluate.log_interpolate", "nn.NLLLoss.", "os.path.join", "torch.cat.size", "log_interpolate.size", "torch.cat", "torch.cat", "output.view", "torch.cat", "torch.cat", "torch.bmm().view", "torch.bmm().view", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like.scatter_add_", "torch.cat.size", "c[].view", "nn.LogSoftmax.", "nn.LogSoftmax.", "evaluate.log_interpolate", "c[].view", "c[].view", "torch.bmm", "torch.bmm", "torch.cat.t", "torch.zeros_like.log", "lexp.log.exp"], "function", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.logging", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.logging", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.logging", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.logging", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.get_new", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.utils.get_batch", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.utils.repackage_hidden", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.logging", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.logging", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.logging", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.logging", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.logging", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.log_interpolate", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.logging", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.log_interpolate", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.log_interpolate"], ["", "def", "evaluate", "(", "model", ",", "criterion", ",", "data_source", ",", "batch_size", "=", "10", ")", ":", "\n", "# Turn on evaluation mode which disables dropout.", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "\n", "n", "=", "data_source", ".", "size", "(", "0", ")", "\n", "cache_N", "=", "args", ".", "cache_size", "\n", "output_dim", "=", "model", ".", "H", ".", "emsize", "\n", "V", "=", "len", "(", "model", ".", "dict", ".", "word2idx", ")", "\n", "batch_row_idx", "=", "torch", ".", "arange", "(", "batch_size", ")", ".", "long", "(", ")", "\n", "uniform_prob", "=", "1", "/", "V", "\n", "uniform_dist", "=", "(", "torch", ".", "zeros", "(", "(", "1", ",", "V", ")", ")", ".", "cuda", "(", ")", "+", "uniform_prob", ")", ".", "log", "(", ")", "\n", "unigram_counts", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "V", ")", ")", ".", "cuda", "(", ")", "\n", "cache", "=", "deque", "(", "maxlen", "=", "cache_N", ")", "\n", "\n", "hidden", "=", "model", ".", "init_hidden", "(", "batch_size", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "'recover-state.pkl'", ")", ")", ":", "\n", "        ", "start_iter", "=", "0", "\n", "total_loss", "=", "0", "\n", "", "else", ":", "\n", "        ", "logging", "(", "\"Restoring from recover-state.pkl...\"", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "'recover-state.pkl'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "start_iter", ",", "total_loss", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "logging", "(", "\"Restoring from recover-cache-targets.pt...\"", ")", "\n", "if", "args", ".", "adapt_method", "in", "[", "\"interpolate_neural\"", ",", "\"interpolate_unigram\"", "]", ":", "\n", "            ", "hidden", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "'recover-hidden.pt'", ")", ")", "\n", "cache_targets", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "'recover-cache-targets.pt'", ")", ")", "\n", "if", "args", ".", "adapt_method", "==", "\"interpolate_neural\"", ":", "\n", "                ", "logging", "(", "\"Restoring from recover-cache.pt...\"", ")", "\n", "cache_vectors", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "'recover-cache.pt'", ")", ")", "\n", "", "else", ":", "\n", "                ", "cache_vectors", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "2", ",", "cache_targets", ".", "size", "(", "0", ")", ")", ")", "\n", "", "for", "ci", "in", "range", "(", "cache_targets", ".", "size", "(", "0", ")", ")", ":", "\n", "                ", "cache", ".", "append", "(", "(", "cache_targets", "[", "ci", "]", ",", "cache_vectors", "[", ":", ",", ":", ",", "ci", "]", ")", ")", "\n", "unigram_counts", "[", "batch_row_idx", ",", "cache_targets", "[", "ci", "]", "]", "+=", "1", "\n", "", "", "if", "len", "(", "cache", ")", ">", "0", ":", "\n", "            ", "print", "(", "\"{} {}\"", ".", "format", "(", "cache", "[", "0", "]", "[", "0", "]", ".", "size", "(", ")", ",", "cache", "[", "0", "]", "[", "1", "]", ".", "size", "(", ")", ")", ")", "\n", "", "logging", "(", "\"Restore complete.\"", ")", "\n", "\n", "", "if", "args", ".", "bptt", ">", "1", "and", "args", ".", "adapt_method", "in", "interpolate_methods", ":", "\n", "        ", "logging", "(", "\"Warning: cache will not work with bptt > 1\"", ")", "\n", "", "if", "isinstance", "(", "criterion", ",", "nn", ".", "CrossEntropyLoss", ")", ":", "\n", "        ", "softmax", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "1", ")", "\n", "loss_function", "=", "nn", ".", "NLLLoss", "(", ")", "\n", "\n", "", "if", "args", ".", "downweight_oov", ">", "0.0", "and", "args", ".", "downweight_oov", "<", "1.0", ":", "\n", "        ", "dw_inds", "=", "model", ".", "get_new", "(", ")", "\n", "", "uniform_dist_shaped", "=", "None", "\n", "for", "i", "in", "range", "(", "start_iter", ",", "n", "-", "1", ",", "args", ".", "bptt", ")", ":", "\n", "        ", "data", ",", "targets", "=", "get_batch", "(", "data_source", ",", "i", ",", "args", ",", "evaluation", "=", "True", ")", "\n", "output", ",", "weight", ",", "bias", ",", "hidden", "=", "model", "(", "data", ",", "hidden", ",", "eval_mode", "=", "True", ")", "\n", "\n", "if", "isinstance", "(", "criterion", ",", "nn", ".", "CrossEntropyLoss", ")", ":", "\n", "            ", "logits", "=", "torch", ".", "mm", "(", "output", ",", "weight", ".", "t", "(", ")", ")", "\n", "if", "args", ".", "downweight_oov", ">", "0.0", "and", "args", ".", "downweight_oov", "<", "1.0", ":", "\n", "                ", "lexp", "=", "logits", ".", "exp", "(", ")", "\n", "lexp", "[", ":", ",", "dw_inds", "]", "*=", "args", ".", "downweight_oov", "\n", "logits", "=", "lexp", ".", "log", "(", ")", "\n", "", "logits", "+=", "bias", "\n", "if", "args", ".", "adapt_method", "==", "\"change_vocab\"", ":", "\n", "                ", "loss", "=", "criterion", "(", "logits", ",", "targets", ")", ".", "data", "\n", "", "elif", "args", ".", "adapt_method", "in", "interpolate_methods", ":", "\n", "# first do uniform interpolation by adding a constant to logits", "\n", "                ", "model_dist", "=", "softmax", "(", "logits", ")", "\n", "if", "uniform_dist_shaped", "is", "None", ":", "\n", "                    ", "uniform_dist_shaped", "=", "uniform_dist", ".", "repeat", "(", "model_dist", ".", "size", "(", "0", ")", ",", "1", ")", "\n", "", "model_dist", "=", "log_interpolate", "(", "model_dist", ",", "\n", "uniform_dist_shaped", ",", "\n", "weight", "=", "args", ".", "lamu", ")", "\n", "if", "args", ".", "adapt_method", "==", "\"interpolate_unigram\"", ":", "\n", "                    ", "unigram_dist", "=", "softmax", "(", "unigram_counts", ")", "\n", "model_dist", "=", "log_interpolate", "(", "model_dist", ",", "unigram_dist", ",", "\n", "weight", "=", "args", ".", "lam", ")", "\n", "", "elif", "args", ".", "adapt_method", "==", "\"interpolate_neural\"", "and", "i", "!=", "0", ":", "\n", "                    ", "cache_inds", "=", "torch", ".", "cat", "(", "[", "c", "[", "0", "]", ".", "view", "(", "1", ",", "-", "1", ")", "for", "c", "in", "cache", "]", ",", "dim", "=", "0", ")", "\n", "\n", "# b * n * m (n = 1, m = dim)", "\n", "batched_output", "=", "output", ".", "view", "(", "batch_size", ",", "1", ",", "-", "1", ")", "\n", "# b * m * p (m = dim, p = number of elements in cache)", "\n", "batched_cache_weight", "=", "torch", ".", "cat", "(", "[", "c", "[", "1", "]", ".", "view", "(", "batch_size", ",", "-", "1", ",", "1", ")", "for", "c", "in", "cache", "]", ",", "\n", "dim", "=", "2", ")", "\n", "# b * n * p (n = 1, p = number of elements in cache. squeeze out n to get", "\n", "# b distributions over the cache (batch_size * cache_size)", "\n", "cache_scores", "=", "torch", ".", "bmm", "(", "batched_output", ",", "batched_cache_weight", ")", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "if", "args", ".", "global_norm", ":", "\n", "                        ", "cache_scores", "=", "(", "cache_scores", "*", "args", ".", "theta", "+", "args", ".", "alpha", ")", ".", "exp", "(", ")", "\n", "", "else", ":", "\n", "                        ", "cache_scores", "=", "(", "cache_scores", "*", "args", ".", "theta", ")", ".", "exp", "(", ")", "\n", "", "cache_vocab_scores", "=", "torch", ".", "zeros_like", "(", "logits", ")", "\n", "cache_vocab_scores", ".", "scatter_add_", "(", "dim", "=", "1", ",", "\n", "index", "=", "cache_inds", ".", "t", "(", ")", ",", "\n", "src", "=", "cache_scores", ")", "\n", "if", "args", ".", "global_norm", ":", "\n", "                        ", "model_dist", "=", "softmax", "(", "(", "logits", ".", "exp", "(", ")", "+", "cache_vocab_scores", ")", ".", "log", "(", ")", ")", "\n", "", "else", ":", "\n", "                        ", "neural_cache_dist", "=", "softmax", "(", "cache_vocab_scores", ".", "log", "(", ")", ")", "\n", "model_dist", "=", "log_interpolate", "(", "model_dist", ",", "neural_cache_dist", ",", "\n", "weight", "=", "args", ".", "lam", ")", "\n", "\n", "", "", "loss", "=", "loss_function", "(", "model_dist", ",", "targets", ")", ".", "data", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Unknown adaptation method: {}\"", ".", "format", "(", "args", ".", "adapt_method", ")", ")", "\n", "", "total_loss", "+=", "len", "(", "data", ")", "*", "loss", "\n", "", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "\n", "# update cache", "\n", "if", "len", "(", "cache", ")", "==", "cache", ".", "maxlen", ":", "\n", "            ", "old_targets", ",", "_", "=", "cache", ".", "popleft", "(", ")", "\n", "unigram_counts", "[", "batch_row_idx", ",", "old_targets", "]", "-=", "1", "\n", "", "if", "args", ".", "adapt_method", "==", "\"interpolate_unigram\"", ":", "\n", "            ", "cache", ".", "append", "(", "(", "targets", ",", "None", ")", ")", "\n", "", "elif", "args", ".", "adapt_method", "==", "\"interpolate_neural\"", ":", "\n", "            ", "cache", ".", "append", "(", "(", "targets", ",", "output", ")", ")", "\n", "", "unigram_counts", "[", "batch_row_idx", ",", "targets", "]", "+=", "1", "\n", "\n", "print", "(", "\"\\r{}/{} - ppl: {:3.2f}\"", ".", "format", "(", "i", ",", "n", ",", "math", ".", "exp", "(", "total_loss", "/", "n", ")", ")", ")", "\n", "\n", "if", "i", "%", "100", "==", "0", "and", "i", ">", "0", ":", "\n", "            ", "logging", "(", "\"{}/{} - ppl: {:3.2f}\"", ".", "format", "(", "i", ",", "n", ",", "math", ".", "exp", "(", "total_loss", "/", "n", ")", ")", ")", "\n", "", "if", "i", "%", "5000", "==", "0", "and", "i", ">", "0", ":", "\n", "            ", "logging", "(", "\"Saving to recover-state.pkl...\"", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "'recover-state.pkl'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "                ", "pickle", ".", "dump", "(", "(", "i", ",", "total_loss", ")", ",", "f", ")", "\n", "", "if", "args", ".", "adapt_method", "in", "[", "\"interpolate_neural\"", ",", "\"interpolate_unigram\"", "]", ":", "\n", "                ", "torch", ".", "save", "(", "hidden", ",", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "'recover-hidden.pt'", ")", ")", "\n", "if", "args", ".", "adapt_method", "==", "\"interpolate_neural\"", ":", "\n", "                    ", "logging", "(", "\"Saving to recover-cache.pt... ({})\"", ".", "format", "(", "batched_cache_weight", ".", "size", "(", ")", ")", ")", "\n", "torch", ".", "save", "(", "batched_cache_weight", ",", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "'recover-cache.pt'", ")", ")", "\n", "", "else", ":", "\n", "                    ", "cache_inds", "=", "torch", ".", "cat", "(", "[", "c", "[", "0", "]", ".", "view", "(", "1", ",", "-", "1", ")", "for", "c", "in", "cache", "]", ",", "dim", "=", "0", ")", "\n", "", "logging", "(", "\"Saving to recover-cache-targets.pt... ({})\"", ".", "format", "(", "cache_inds", ".", "size", "(", ")", ")", ")", "\n", "torch", ".", "save", "(", "cache_inds", ",", "os", ".", "path", ".", "join", "(", "args", ".", "save", ",", "'recover-cache-targets.pt'", ")", ")", "\n", "", "logging", "(", "\"Save complete.\"", ")", "\n", "\n", "", "", "return", "total_loss", ".", "item", "(", ")", "/", "n", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.data.Dictionary.__init__": [[25, 30], ["collections.Counter"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "word2idx", "=", "{", "}", "\n", "self", ".", "idx2word", "=", "[", "]", "\n", "self", ".", "counter", "=", "Counter", "(", ")", "\n", "self", ".", "total", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.data.Dictionary.add_word": [[31, 39], ["data.Dictionary.idx2word.append", "len"], "methods", ["None"], ["", "def", "add_word", "(", "self", ",", "word", ")", ":", "\n", "        ", "if", "word", "not", "in", "self", ".", "word2idx", ":", "\n", "            ", "self", ".", "idx2word", ".", "append", "(", "word", ")", "\n", "self", ".", "word2idx", "[", "word", "]", "=", "len", "(", "self", ".", "idx2word", ")", "-", "1", "\n", "", "token_id", "=", "self", ".", "word2idx", "[", "word", "]", "\n", "self", ".", "counter", "[", "token_id", "]", "+=", "1", "\n", "self", ".", "total", "+=", "1", "\n", "return", "self", ".", "word2idx", "[", "word", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.data.Dictionary.__len__": [[40, 42], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "idx2word", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.data.Dictionary.set_unk": [[43, 46], ["data.Dictionary.add_word"], "methods", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.data.Dictionary.add_word"], ["", "def", "set_unk", "(", "self", ")", ":", "\n", "        ", "self", ".", "unk", "=", "\"<UNK>\"", "\n", "self", ".", "unk_id", "=", "self", ".", "add_word", "(", "self", ".", "unk", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.data.Corpus.__init__": [[49, 65], ["data.Dictionary", "print", "data.Corpus.store_words", "data.Corpus.store_words", "data.Corpus.store_words", "print", "data.Corpus.order_by_freq", "print", "data.Corpus.tokenize", "data.Corpus.tokenize", "data.Corpus.tokenize", "os.path.join", "os.path.join", "os.path.join", "print", "data.Corpus.dictionary.set_unk", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.data.Corpus.store_words", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.data.Corpus.store_words", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.data.Corpus.store_words", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.data.Corpus.order_by_freq", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.data.Corpus.tokenize", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.data.Corpus.tokenize", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.data.Corpus.tokenize", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.data.Dictionary.set_unk"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "use_unk", "=", "False", ")", ":", "\n", "        ", "self", ".", "use_unk", "=", "use_unk", "\n", "self", ".", "dictionary", "=", "Dictionary", "(", ")", "\n", "print", "(", "\"Indexing words...\"", ")", "\n", "self", ".", "train", "=", "self", ".", "store_words", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ")", "\n", "self", ".", "valid", "=", "self", ".", "store_words", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ")", "\n", "self", ".", "test", "=", "self", ".", "store_words", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ")", "\n", "print", "(", "\"Sorting vocab by frequency...\"", ")", "\n", "self", ".", "order_by_freq", "(", ")", "\n", "if", "self", ".", "use_unk", ":", "\n", "            ", "print", "(", "\"Adding UNK token...\"", ")", "\n", "self", ".", "dictionary", ".", "set_unk", "(", ")", "\n", "", "print", "(", "\"Tokenizing text...\"", ")", "\n", "self", ".", "train", "=", "self", ".", "tokenize", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'train.txt'", ")", ")", "\n", "self", ".", "valid", "=", "self", ".", "tokenize", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'valid.txt'", ")", ")", "\n", "self", ".", "test", "=", "self", ".", "tokenize", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'test.txt'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.data.Corpus.store_words": [[66, 77], ["os.path.exists", "open", "len", "line.split", "data.Corpus.dictionary.add_word"], "methods", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.data.Dictionary.add_word"], ["", "def", "store_words", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"Stores words from a text file.\"\"\"", "\n", "assert", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "# Add words to the dictionary", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "tokens", "=", "0", "\n", "for", "line", "in", "f", ":", "\n", "                ", "words", "=", "line", ".", "split", "(", ")", "+", "[", "'<eos>'", "]", "\n", "tokens", "+=", "len", "(", "words", ")", "\n", "for", "word", "in", "words", ":", "\n", "                    ", "self", ".", "dictionary", ".", "add_word", "(", "word", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.data.Corpus.order_by_freq": [[78, 92], ["enumerate", "data.Corpus.dictionary.word2idx.keys", "sorted"], "methods", ["None"], ["", "", "", "", "def", "order_by_freq", "(", "self", ")", ":", "\n", "        ", "\"\"\"Ordering vocab by frequency.\"\"\"", "\n", "dd", "=", "self", ".", "dictionary", ".", "counter", "\n", "ord_ids", "=", "sorted", "(", "dd", ",", "key", "=", "dd", ".", "get", ")", "[", ":", ":", "-", "1", "]", "\n", "ord_hash", ",", "new_counter", "=", "{", "}", ",", "{", "}", "\n", "for", "j", ",", "cur_id", "in", "enumerate", "(", "ord_ids", ")", ":", "\n", "            ", "ord_hash", "[", "cur_id", "]", "=", "j", "\n", "", "for", "word", "in", "self", ".", "dictionary", ".", "word2idx", ".", "keys", "(", ")", ":", "\n", "            ", "cur_id", "=", "self", ".", "dictionary", ".", "word2idx", "[", "word", "]", "\n", "self", ".", "dictionary", ".", "word2idx", "[", "word", "]", "=", "ord_hash", "[", "cur_id", "]", "\n", "self", ".", "dictionary", ".", "idx2word", "[", "ord_hash", "[", "cur_id", "]", "]", "=", "word", "\n", "replaced_count", "=", "dd", "[", "cur_id", "]", "\n", "new_counter", "[", "cur_id", "]", "=", "dd", "[", "ord_ids", "[", "cur_id", "]", "]", "\n", "", "self", ".", "dictionary", ".", "counter", "=", "new_counter", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.data.Corpus.tokenize": [[94, 119], ["os.path.exists", "print", "open", "open", "torch.LongTensor", "len", "line.split", "line.split", "ValueError"], "methods", ["None"], ["", "def", "tokenize", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"Tokenizes a text file.\"\"\"", "\n", "assert", "os", ".", "path", ".", "exists", "(", "path", ")", "\n", "# Add words to the dictionary", "\n", "print", "(", "\"starting tokenization\"", ")", "\n", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "tokens", "=", "0", "\n", "for", "line", "in", "f", ":", "\n", "                ", "words", "=", "line", ".", "split", "(", ")", "+", "[", "'<eos>'", "]", "\n", "tokens", "+=", "len", "(", "words", ")", "\n", "# Tokenize file content", "\n", "", "", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "ids", "=", "torch", ".", "LongTensor", "(", "tokens", ")", "\n", "token", "=", "0", "\n", "for", "line", "in", "f", ":", "\n", "                ", "words", "=", "line", ".", "split", "(", ")", "+", "[", "'<eos>'", "]", "\n", "for", "word", "in", "words", ":", "\n", "                    ", "if", "word", "in", "self", ".", "dictionary", ".", "word2idx", ":", "\n", "                        ", "ids", "[", "token", "]", "=", "self", ".", "dictionary", ".", "word2idx", "[", "word", "]", "\n", "", "elif", "self", ".", "dictionary", ".", "unk", "is", "not", "None", ":", "\n", "                        ", "ids", "[", "token", "]", "=", "self", ".", "dictionary", ".", "unk_id", "\n", "", "else", ":", "\n", "                        ", "raise", "ValueError", "(", "f\"Unknown word: {word}\"", ")", "\n", "", "token", "+=", "1", "\n", "", "", "", "return", "ids", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.__init__": [[30, 41], ["torch.Module.__init__", "locked_dropout.LockedDropout", "model.RNNModel.define_embedding", "model.RNNModel.define_rnn", "model.RNNModel.define_joint", "model.RNNModel.define_bias", "model.RNNModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.locked_dropout.LockedDropout.__init__", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.define_embedding", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.define_rnn", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.define_joint", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.define_bias", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.init_weights"], ["def", "__init__", "(", "self", ",", "H", ",", "char_arr", "=", "None", ",", "rel_arr", "=", "None", ",", "def_arr", "=", "None", ",", "dict", "=", "None", ")", ":", "\n", "        ", "super", "(", "RNNModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "H", "=", "H", "\n", "self", ".", "dict", "=", "dict", "\n", "self", ".", "use_dropout", "=", "True", "\n", "self", ".", "_lockdrop", "=", "LockedDropout", "(", ")", "\n", "self", ".", "define_embedding", "(", "H", ",", "char_arr", ",", "rel_arr", ",", "def_arr", ")", "\n", "self", ".", "define_rnn", "(", "H", ")", "\n", "self", ".", "define_joint", "(", "H", ")", "\n", "self", ".", "define_bias", "(", "H", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.define_joint": [[42, 51], ["torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "range", "eval", "model.RNNModel._output_network.append", "torch.Linear", "torch.Linear", "torch.Linear", "H.joint_emb_activation.lower"], "methods", ["None"], ["", "def", "define_joint", "(", "self", ",", "H", ")", ":", "\n", "        ", "\"\"\"\n            Define the joint embedding for the deep residual method.\n        \"\"\"", "\n", "if", "H", ".", "joint_emb", "is", "not", "None", ":", "\n", "            ", "self", ".", "_output_network", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "i", "in", "range", "(", "H", ".", "joint_emb_depth", ")", ":", "\n", "                ", "self", ".", "_output_network", ".", "append", "(", "nn", ".", "Linear", "(", "H", ".", "joint_emb", ",", "H", ".", "joint_emb", ",", "bias", "=", "True", ")", ")", "\n", "", "self", ".", "_output_act", "=", "eval", "(", "\"torch.nn.functional.%s\"", "%", "H", ".", "joint_emb_activation", ".", "lower", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.define_embedding": [[52, 110], ["torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.Embedding().cuda", "torch.Embedding().cuda", "torch.Embedding().cuda", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "model.RNNModel._char_network.append", "model.RNNModel._char_network.append", "model.RNNModel._char_network.append", "model.RNNModel._char_network.append", "model.RNNModel._char_network.append", "model.RNNModel._char_network.append", "eval", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Conv1d().cuda", "torch.Conv1d().cuda", "torch.Conv1d().cuda", "torch.Conv1d().cuda", "torch.Conv1d().cuda", "torch.Conv1d().cuda", "torch.Conv1d().cuda", "torch.Conv1d().cuda", "torch.Conv1d().cuda", "torch.Conv1d().cuda", "torch.Conv1d().cuda", "torch.Conv1d().cuda", "torch.Conv1d().cuda", "torch.Conv1d().cuda", "torch.Conv1d().cuda", "torch.Conv1d().cuda", "torch.Conv1d().cuda", "torch.Conv1d().cuda", "allennlp.modules.highway.Highway", "model.RNNModel.coverage_filter", "model.RNNModel.coverage_filter", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "torch.zeros().cuda", "allennlp.modules.highway.Highway", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.coverage_filter", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.coverage_filter"], ["", "", "def", "define_embedding", "(", "self", ",", "H", ",", "char_arr", ",", "rel_arr", ",", "def_arr", ")", ":", "\n", "        ", "\"\"\"\n            Define the embedding for different methods.\n        \"\"\"", "\n", "if", "H", ".", "joint_emb", "is", "not", "None", ":", "\n", "            ", "self", ".", "_jdrop", "=", "nn", ".", "Dropout", "(", "H", ".", "joint_dropout", "if", "self", ".", "use_dropout", "else", "0", ")", "\n", "\n", "", "if", "H", ".", "char_emb", "or", "H", ".", "cnnsoftmax", ":", "\n", "            ", "self", ".", "char_arr", "=", "torch", ".", "LongTensor", "(", "char_arr", ")", ".", "cuda", "(", ")", "\n", "self", ".", "rel_arr", ",", "self", ".", "def_arr", "=", "None", ",", "None", "\n", "self", ".", "_char_emb", "=", "nn", ".", "Embedding", "(", "262", ",", "H", ".", "char_emsize", ")", ".", "cuda", "(", ")", "\n", "self", ".", "_char_network", "=", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "_char_network", ".", "append", "(", "nn", ".", "Conv1d", "(", "H", ".", "char_emsize", ",", "32", ",", "1", ",", "stride", "=", "(", "1", ",", ")", ")", ".", "cuda", "(", ")", ")", "\n", "self", ".", "_char_network", ".", "append", "(", "nn", ".", "Conv1d", "(", "H", ".", "char_emsize", ",", "32", ",", "2", ",", "stride", "=", "(", "1", ",", ")", ")", ".", "cuda", "(", ")", ")", "\n", "self", ".", "_char_network", ".", "append", "(", "nn", ".", "Conv1d", "(", "H", ".", "char_emsize", ",", "64", ",", "3", ",", "stride", "=", "(", "2", ",", ")", ")", ".", "cuda", "(", ")", ")", "\n", "self", ".", "_char_network", ".", "append", "(", "nn", ".", "Conv1d", "(", "H", ".", "char_emsize", ",", "128", ",", "4", ",", "stride", "=", "(", "3", ",", ")", ")", ".", "cuda", "(", ")", ")", "\n", "self", ".", "_char_network", ".", "append", "(", "nn", ".", "Conv1d", "(", "H", ".", "char_emsize", ",", "256", ",", "5", ",", "stride", "=", "(", "4", ",", ")", ")", ".", "cuda", "(", ")", ")", "\n", "self", ".", "_char_network", ".", "append", "(", "nn", ".", "Conv1d", "(", "H", ".", "char_emsize", ",", "512", ",", "6", ",", "stride", "=", "(", "5", ",", ")", ")", ".", "cuda", "(", ")", ")", "\n", "self", ".", "_conv_activation", "=", "eval", "(", "\"torch.nn.functional.%s\"", "%", "H", ".", "char_activation", ")", "\n", "if", "not", "H", ".", "char_nohighways", ":", "\n", "                ", "self", ".", "_char_highways", "=", "Highway", "(", "1024", ",", "H", ".", "hdepth", ",", "activation", "=", "self", ".", "_conv_activation", ")", "\n", "", "self", ".", "_char_linear", "=", "nn", ".", "Linear", "(", "1024", ",", "H", ".", "emsize", ",", "bias", "=", "False", ")", "\n", "nforms", "=", "1", "\n", "\n", "if", "rel_arr", ":", "\n", "                ", "self", ".", "rel_arr", "=", "self", ".", "coverage_filter", "(", "torch", ".", "LongTensor", "(", "rel_arr", ")", ".", "cuda", "(", ")", ")", "\n", "nforms", "+=", "1", "\n", "", "if", "def_arr", ":", "\n", "                ", "self", ".", "def_arr", "=", "self", ".", "coverage_filter", "(", "torch", ".", "LongTensor", "(", "def_arr", ")", ".", "cuda", "(", ")", ")", "\n", "nforms", "+=", "1", "\n", "\n", "", "self", ".", "rel_exist", "=", "self", ".", "rel_arr", "is", "not", "None", "\n", "self", ".", "def_exist", "=", "self", ".", "def_arr", "is", "not", "None", "\n", "self", ".", "nforms", "=", "H", ".", "nforms", "=", "nforms", "\n", "if", "H", ".", "defenc", "==", "\"lstm\"", ":", "\n", "                ", "if", "def_arr", ":", "\n", "                    ", "defsize", "=", "self", ".", "def_arr", ".", "shape", "[", "1", "]", "\n", "def_h", "=", "torch", ".", "zeros", "(", "H", ".", "hdepth", ",", "defsize", ",", "H", ".", "emsize", ")", ".", "cuda", "(", ")", "\n", "self", ".", "def_hid", "=", "(", "def_h", ",", "def_h", ")", "\n", "", "if", "rel_arr", ":", "\n", "                    ", "relsize", "=", "self", ".", "rel_arr", ".", "shape", "[", "1", "]", "\n", "rel_h", "=", "torch", ".", "zeros", "(", "H", ".", "hdepth", ",", "relsize", ",", "H", ".", "emsize", ")", ".", "cuda", "(", ")", "\n", "self", ".", "rel_hid", "=", "(", "rel_h", ",", "rel_h", ")", "\n", "", "self", ".", "_definition_network", "=", "torch", ".", "nn", ".", "LSTM", "(", "H", ".", "emsize", ",", "H", ".", "emsize", ",", "num_layers", "=", "H", ".", "hdepth", ")", "\n", "", "elif", "H", ".", "defenc", "==", "\"highway\"", ":", "\n", "                ", "self", ".", "_definition_network", "=", "Highway", "(", "H", ".", "emsize", ",", "H", ".", "hdepth", ",", "activation", "=", "self", ".", "_conv_activation", ")", "\n", "\n", "", "if", "H", ".", "combine", "==", "\"concat\"", ":", "\n", "                ", "self", ".", "_comb_lin", "=", "nn", ".", "Linear", "(", "H", ".", "emsize", "*", "H", ".", "nforms", ",", "H", ".", "emsize", ",", "bias", "=", "True", ")", "\n", "\n", "", "if", "H", ".", "cnnsoftmax", "or", "H", ".", "char_emb", ":", "\n", "                ", "if", "H", ".", "cnnsoftmax", ":", "\n", "                    ", "self", ".", "_lookup", "=", "nn", ".", "Embedding", "(", "H", ".", "ntoken", ",", "H", ".", "emsize", ")", "\n", "", "if", "H", ".", "cnncorr", ":", "\n", "                    ", "self", ".", "_cnnsoftmax_correction", "=", "nn", ".", "Linear", "(", "H", ".", "cnncorr", ",", "H", ".", "ntoken", ",", "bias", "=", "False", ")", "\n", "self", ".", "_cnnsoftmax_M", "=", "nn", ".", "Linear", "(", "H", ".", "cnncorr", ",", "H", ".", "emsize", ",", "bias", "=", "False", ")", "\n", "", "", "", "else", ":", "\n", "            ", "self", ".", "_lookup", "=", "nn", ".", "Embedding", "(", "H", ".", "ntoken", ",", "H", ".", "emsize", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.coverage_filter": [[112, 123], ["torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "len", "len"], "methods", ["None"], ["", "", "def", "coverage_filter", "(", "self", ",", "arr", ")", ":", "\n", "        ", "\"\"\"\n            Function to control the vocabulary coverage of the external knowledge\n            base for relational and definitional forms.\n        \"\"\"", "\n", "if", "self", ".", "H", ".", "coverage", "<", "1", ":", "\n", "            ", "ex_ids", "=", "(", "arr", "-", "self", ".", "H", ".", "ntoken", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "nonzero", "(", ")", ".", "squeeze", "(", ")", "\n", "mask", "=", "(", "torch", ".", "rand", "(", "len", "(", "ex_ids", ")", ")", ">=", "self", ".", "H", ".", "coverage", ")", ".", "cuda", "(", ")", ".", "long", "(", ")", "\n", "ids", "=", "(", "mask", "*", "torch", ".", "arange", "(", "len", "(", "ex_ids", ")", ")", ".", "cuda", "(", ")", ")", ".", "nonzero", "(", ")", "\n", "arr", "[", "ex_ids", "[", "ids", "]", "]", "=", "self", ".", "H", ".", "ntoken", "\n", "", "return", "arr", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.change_embedding_vocab": [[125, 213], ["len", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "hasattr", "hasattr", "hasattr", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "hasattr", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "model.RNNModel._bias.weight.data.fill_", "model.RNNModel._lookup.cuda", "model.RNNModel._decoder.cuda", "new_words.append", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "hasattr", "hasattr", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.Linear", "torch.Linear", "torch.Linear", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.Linear", "torch.Linear", "torch.Linear", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.nn.init.uniform_", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.nn.init.zeros_", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad"], "methods", ["None"], ["", "def", "change_embedding_vocab", "(", "self", ",", "char_arr", ",", "rel_arr", ",", "def_arr", ",", "new_dict", ",", "\n", "set_zero", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        if set_zero=True, the new embedding params should be all 0s (so the only\n        probability new words get is from uniform interpolation). otherwise, they\n        should be randomly initialized for fine-tuning.\n        \"\"\"", "\n", "self", ".", "H", ".", "ntoken", "=", "len", "(", "new_dict", ".", "word2idx", ")", "\n", "self", ".", "old_dict", "=", "self", ".", "dict", "\n", "self", ".", "dict", "=", "new_dict", "\n", "\n", "new_words", "=", "[", "]", "\n", "for", "w", "in", "self", ".", "dict", ".", "word2idx", ":", "\n", "            ", "if", "w", "not", "in", "self", ".", "old_dict", ".", "word2idx", ":", "\n", "                ", "new_words", ".", "append", "(", "self", ".", "dict", ".", "word2idx", "[", "w", "]", ")", "\n", "", "", "self", ".", "new_words", "=", "torch", ".", "LongTensor", "(", "new_words", ")", "\n", "\n", "if", "hasattr", "(", "self", ",", "\"_lookup\"", ")", ":", "\n", "            ", "new_lookup", "=", "nn", ".", "Embedding", "(", "self", ".", "H", ".", "ntoken", ",", "self", ".", "H", ".", "emsize", ")", "\n", "if", "set_zero", ":", "\n", "                ", "torch", ".", "nn", ".", "init", ".", "zeros_", "(", "new_lookup", ".", "weight", ")", "\n", "", "else", ":", "\n", "                ", "init", "=", "self", ".", "H", ".", "init", "\n", "torch", ".", "nn", ".", "init", ".", "uniform_", "(", "new_lookup", ".", "weight", ",", "-", "init", ",", "init", ")", "\n", "# copy old embeddings", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "for", "word", "in", "self", ".", "old_dict", ".", "word2idx", ":", "\n", "                    ", "old_idx", "=", "self", ".", "old_dict", ".", "word2idx", "[", "word", "]", "\n", "if", "word", "in", "self", ".", "dict", ".", "word2idx", ":", "\n", "                        ", "new_idx", "=", "self", ".", "dict", ".", "word2idx", "[", "word", "]", "\n", "new_lookup", ".", "weight", "[", "new_idx", "]", "=", "self", ".", "_lookup", ".", "weight", "[", "old_idx", "]", "\n", "\n", "", "", "", "", "if", "(", "hasattr", "(", "self", ".", "H", ",", "\"char_emb\"", ")", "and", "self", ".", "H", ".", "char_emb", ")", "or", "(", "hasattr", "(", "self", ".", "H", ",", "\"cnnsoftmax\"", ")", "and", "self", ".", "H", ".", "cnnsoftmax", ")", ":", "\n", "            ", "self", ".", "char_arr", "=", "torch", ".", "LongTensor", "(", "char_arr", ")", ".", "cuda", "(", ")", "\n", "if", "self", ".", "rel_exist", ":", "\n", "                ", "self", ".", "rel_arr", "=", "torch", ".", "LongTensor", "(", "rel_arr", ")", ".", "cuda", "(", ")", "\n", "", "if", "self", ".", "def_exist", ":", "\n", "                ", "self", ".", "def_arr", "=", "torch", ".", "LongTensor", "(", "def_arr", ")", ".", "cuda", "(", ")", "\n", "", "if", "self", ".", "H", ".", "cnnsoftmax", ":", "\n", "                ", "self", ".", "_lookup", "=", "new_lookup", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "_lookup", "=", "new_lookup", "\n", "\n", "", "if", "not", "self", ".", "H", ".", "char_emb", ":", "\n", "            ", "if", "self", ".", "H", ".", "tied", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "new_decoder", "=", "nn", ".", "Linear", "(", "self", ".", "H", ".", "emsize", ",", "self", ".", "H", ".", "ntoken", ")", "\n", "new_decoder", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "self", ".", "_lookup", ".", "weight", ".", "data", ")", "\n", "if", "set_zero", ":", "\n", "                        ", "torch", ".", "nn", ".", "init", ".", "zeros_", "(", "new_decoder", ".", "bias", ")", "\n", "new_decoder", ".", "bias", "-=", "np", ".", "inf", "# give OOVs 0 probability", "\n", "", "for", "word", "in", "self", ".", "old_dict", ".", "word2idx", ":", "\n", "                        ", "old_idx", "=", "self", ".", "old_dict", ".", "word2idx", "[", "word", "]", "\n", "if", "word", "in", "self", ".", "dict", ".", "word2idx", ":", "\n", "                            ", "new_idx", "=", "self", ".", "dict", ".", "word2idx", "[", "word", "]", "\n", "new_decoder", ".", "bias", "[", "new_idx", "]", "=", "self", ".", "_decoder", ".", "bias", "[", "old_idx", "]", "\n", "", "", "", "self", ".", "_decoder", "=", "new_decoder", "\n", "", "else", ":", "\n", "                ", "new_decoder", "=", "nn", ".", "Linear", "(", "self", ".", "H", ".", "emsize", ",", "self", ".", "H", ".", "ntoken", ")", "\n", "if", "set_zero", ":", "\n", "                    ", "torch", ".", "nn", ".", "init", ".", "zeros_", "(", "new_decoder", ".", "weight", ")", "\n", "torch", ".", "nn", ".", "init", ".", "zeros_", "(", "new_decoder", ".", "bias", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                        ", "new_decoder", ".", "bias", "-=", "np", ".", "inf", "# give OOVs 0 probability", "\n", "", "", "else", ":", "\n", "                    ", "init", "=", "self", ".", "H", ".", "init", "\n", "torch", ".", "nn", ".", "init", ".", "uniform_", "(", "new_decoder", ".", "weight", ",", "-", "init", ",", "init", ")", "\n", "torch", ".", "nn", ".", "init", ".", "uniform_", "(", "new_decoder", ".", "bias", ",", "-", "init", ",", "init", ")", "\n", "# copy old embeddings", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "for", "word", "in", "self", ".", "old_dict", ".", "word2idx", ":", "\n", "                        ", "old_idx", "=", "self", ".", "old_dict", ".", "word2idx", "[", "word", "]", "\n", "if", "word", "in", "self", ".", "dict", ".", "word2idx", ":", "\n", "                            ", "new_idx", "=", "self", ".", "dict", ".", "word2idx", "[", "word", "]", "\n", "new_decoder", ".", "weight", "[", "new_idx", "]", "=", "self", ".", "_decoder", ".", "weight", "[", "old_idx", "]", "\n", "new_decoder", ".", "bias", "[", "new_idx", "]", "=", "self", ".", "_decoder", ".", "bias", "[", "old_idx", "]", "\n", "", "", "", "self", ".", "_decoder", "=", "new_decoder", "\n", "\n", "", "", "if", "hasattr", "(", "self", ",", "\"_bias\"", ")", "and", "not", "self", ".", "H", ".", "predict_bias", ":", "\n", "            ", "self", ".", "_bias", "=", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "H", ".", "ntoken", ",", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "_bias", ".", "weight", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n", "", "if", "hasattr", "(", "self", ",", "\"_lookup\"", ")", ":", "\n", "            ", "self", ".", "_lookup", ".", "cuda", "(", ")", "\n", "\n", "", "if", "hasattr", "(", "self", ",", "\"_decoder\"", ")", ":", "\n", "            ", "self", ".", "_decoder", ".", "cuda", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.get_new": [[214, 220], ["None"], "methods", ["None"], ["", "", "def", "get_new", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return indices for words which were not in the model's vocabulary prior\n        to the most recent call to change_embedding_vocab\n        \"\"\"", "\n", "return", "self", ".", "new_words", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.get_uncovered": [[221, 229], ["torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["None"], ["", "def", "get_uncovered", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return indices for words which do not have rel/def coverage\n        \"\"\"", "\n", "if", "self", ".", "H", ".", "char_emb", ":", "\n", "            ", "return", "(", "self", ".", "rel_arr", "-", "self", ".", "H", ".", "ntoken", ")", ".", "sum", "(", "dim", "=", "1", ")", ".", "nonzero", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "torch", ".", "LongTensor", "(", "[", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.get_new_uncovered": [[230, 234], ["model.RNNModel.get_uncovered", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.get_uncovered"], ["", "", "def", "get_new_uncovered", "(", "self", ")", ":", "\n", "        ", "uncovered", "=", "self", ".", "get_uncovered", "(", ")", "\n", "new_uncovered", "=", "[", "w", "for", "w", "in", "new_words", "if", "w", "in", "uncovered", "]", "\n", "return", "torch", ".", "LongTensor", "(", "new_uncovered", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.define_rnn": [[235, 244], ["torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "torch.nn.LSTM", "range"], "methods", ["None"], ["", "def", "define_rnn", "(", "self", ",", "H", ")", ":", "\n", "        ", "\"\"\"\n            Define the prefix encoder rnn.\n        \"\"\"", "\n", "assert", "H", ".", "rnn_type", "in", "[", "'LSTM'", "]", ",", "'RNN type is not supported'", "\n", "if", "H", ".", "rnn_type", "==", "'LSTM'", ":", "\n", "            ", "self", ".", "_prefix_network", "=", "[", "torch", ".", "nn", ".", "LSTM", "(", "H", ".", "emsize", "if", "l", "==", "0", "else", "H", ".", "nhid", ",", "H", ".", "nhid", "if", "l", "!=", "H", ".", "nlayers", "-", "1", "else", "(", "H", ".", "emsize", ")", ",", "1", ",", "dropout", "=", "0", ")", "for", "l", "in", "range", "(", "H", ".", "nlayers", ")", "]", "\n", "\n", "", "self", ".", "_prefix_network", "=", "torch", ".", "nn", ".", "ModuleList", "(", "self", ".", "_prefix_network", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.define_bias": [[246, 266], ["torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.Dropout", "torch.Dropout", "torch.Dropout", "eval", "adaptive_io.AdaptiveEmbedding", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "eval"], "methods", ["None"], ["", "def", "define_bias", "(", "self", ",", "H", ")", ":", "\n", "        ", "\"\"\"\n            Define bias for different methods.\n        \"\"\"", "\n", "if", "H", ".", "predict_bias", ":", "\n", "            ", "self", ".", "_bias", "=", "torch", ".", "nn", ".", "Linear", "(", "H", ".", "emsize", ",", "H", ".", "bias_out", ",", "bias", "=", "True", ")", "\n", "self", ".", "_bias_drop", "=", "nn", ".", "Dropout", "(", "H", ".", "bias_drop", "if", "self", ".", "use_dropout", "else", "0", ")", "\n", "self", ".", "_bias_activation", "=", "eval", "(", "\"torch.nn.functional.%s\"", "%", "H", ".", "bias_activation", ")", "\n", "", "else", ":", "\n", "            ", "if", "H", ".", "adaptiveoutputs", "or", "H", ".", "adaptiveoutputs_tied", ":", "\n", "                ", "self", ".", "_decoder", "=", "AdaptiveEmbedding", "(", "H", ".", "ntoken", ",", "H", ".", "emsize", ",", "H", ".", "emsize", ",", "cutoffs", "=", "eval", "(", "H", ".", "adaptivecutoffs", ")", ")", "\n", "if", "H", ".", "adaptiveoutputs_tied", ":", "\n", "                    ", "self", ".", "_lookup", "=", "self", ".", "_decoder", "\n", "", "self", ".", "_bias", "=", "torch", ".", "nn", ".", "Linear", "(", "H", ".", "ntoken", ",", "1", ",", "bias", "=", "False", ")", "\n", "", "elif", "H", ".", "char_emb", "or", "H", ".", "joint_emb", "is", "not", "None", "or", "H", ".", "cnnsoftmax", ":", "\n", "                ", "self", ".", "_bias", "=", "torch", ".", "nn", ".", "Linear", "(", "H", ".", "ntoken", ",", "1", ",", "bias", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "_decoder", "=", "nn", ".", "Linear", "(", "H", ".", "emsize", ",", "H", ".", "ntoken", ")", "\n", "if", "H", ".", "tied", ":", "\n", "                    ", "self", ".", "_decoder", ".", "weight", "=", "self", ".", "_lookup", ".", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.change_vocab": [[267, 284], ["len", "print", "torch.Embedding().cuda", "torch.Embedding().cuda", "torch.Embedding().cuda", "torch.Linear().cuda", "torch.Linear().cuda", "torch.Linear().cuda", "torch.Embedding().cuda.weight.data.uniform_", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["None"], ["", "", "", "", "def", "change_vocab", "(", "self", ",", "newdict", ")", ":", "\n", "        ", "\"\"\"\n            Create new embeddings or use existing ones for the words\n            in the new vocabulary.\n        \"\"\"", "\n", "H", "=", "self", ".", "H", "\n", "init", "=", "self", ".", "H", ".", "init", "\n", "new_ntoken", "=", "len", "(", "newdict", ".", "idx2word", ")", "\n", "print", "(", "\"Changing the vocab...\"", ")", "\n", "if", "H", ".", "tied", ":", "\n", "            ", "new_encoder", "=", "nn", ".", "Embedding", "(", "new_ntoken", ",", "H", ".", "emsize", ")", ".", "cuda", "(", ")", "\n", "new_decoder", "=", "nn", ".", "Linear", "(", "H", ".", "emsize", ",", "new_ntoken", ")", ".", "cuda", "(", ")", "\n", "new_encoder", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "init", ",", "init", ")", "\n", "new_decoder", ".", "weight", "=", "new_encoder", ".", "weight", "\n", "self", ".", "_lookup", "=", "new_encoder", "\n", "self", ".", "_decoder", "=", "new_decoder", "\n", "", "self", ".", "dict", "=", "dict", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.init_weights": [[285, 317], ["hasattr", "hasattr", "model.RNNModel._lookup.weight.data.uniform_", "enumerate", "hasattr", "model.RNNModel._char_linear.weight.data.uniform_", "enumerate", "model.RNNModel._char_network[].weight.data.uniform_", "enumerate", "model.RNNModel._definition_network._layers[].weight.data.uniform_", "hasattr", "model.RNNModel._decoder.bias.data.fill_", "range", "hasattr", "model.RNNModel._bias.weight.data.uniform_", "model.RNNModel._char_highways._layers[].weight.data.uniform_", "[].weight.data.uniform_", "model.RNNModel._bias.weight.data.fill_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n            Initialize weights by randomly from the same range.\n        \"\"\"", "\n", "init", "=", "self", ".", "H", ".", "init", "\n", "if", "not", "self", ".", "H", ".", "char_emb", "and", "not", "self", ".", "H", ".", "adaptiveoutputs", "and", "not", "self", ".", "H", ".", "adaptiveoutputs_tied", ":", "\n", "            ", "self", ".", "_lookup", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "init", ",", "init", ")", "\n", "\n", "", "if", "self", ".", "H", ".", "char_emb", ":", "\n", "            ", "for", "i", ",", "conv", "in", "enumerate", "(", "self", ".", "_char_network", ")", ":", "\n", "                ", "self", ".", "_char_network", "[", "i", "]", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "init", ",", "init", ")", "\n", "", "if", "hasattr", "(", "self", ",", "\"_char_highways\"", ")", ":", "\n", "                ", "for", "j", ",", "layer", "in", "enumerate", "(", "self", ".", "_char_highways", ".", "_layers", ")", ":", "\n", "                    ", "self", ".", "_char_highways", ".", "_layers", "[", "j", "]", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "init", ",", "init", ")", "\n", "", "", "self", ".", "_char_linear", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "init", ",", "init", ")", "\n", "\n", "", "if", "self", ".", "H", ".", "defenc", "==", "\"highway\"", ":", "\n", "            ", "for", "j", ",", "layer", "in", "enumerate", "(", "self", ".", "_definition_network", ".", "_layers", ")", ":", "\n", "                ", "self", ".", "_definition_network", ".", "_layers", "[", "j", "]", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "init", ",", "init", ")", "\n", "\n", "", "", "if", "hasattr", "(", "self", ",", "'decoder'", ")", ":", "\n", "            ", "if", "hasattr", "(", "self", ".", "_decoder", ",", "'bias'", ")", "and", "self", ".", "_decoder", ".", "bias", "is", "not", "None", ":", "\n", "                ", "self", ".", "_decoder", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "if", "self", ".", "H", ".", "joint_emb", ":", "\n", "                ", "for", "i", "in", "range", "(", "self", ".", "H", ".", "joint_emb_depth", ")", ":", "\n", "                    ", "self", ".", "_output_network", "[", "i", "]", "[", "0", "]", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "init", ",", "init", ")", "\n", "", "", "", "if", "hasattr", "(", "self", ",", "'bias'", ")", ":", "\n", "            ", "if", "not", "self", ".", "H", ".", "predict_bias", ":", "\n", "                ", "if", "hasattr", "(", "self", ",", "'bias'", ")", ":", "\n", "                    ", "self", ".", "_bias", ".", "weight", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "_bias", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "init", ",", "init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.init_hidden": [[318, 327], ["next", "model.RNNModel.parameters", "weight.new().zero_", "weight.new().zero_", "range", "weight.new", "weight.new"], "methods", ["None"], ["", "", "", "def", "init_hidden", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "\"\"\"\n            Initializes the hidden state and cell state of the prefix network.\n        \"\"\"", "\n", "weight", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "data", "\n", "if", "self", ".", "H", ".", "rnn_type", "==", "'LSTM'", ":", "\n", "            ", "return", "[", "(", "weight", ".", "new", "(", "1", ",", "bsz", ",", "self", ".", "H", ".", "nhid", "if", "l", "!=", "self", ".", "H", ".", "nlayers", "-", "1", "else", "(", "self", ".", "H", ".", "emsize", ")", ")", ".", "zero_", "(", ")", ",", "\n", "weight", ".", "new", "(", "1", ",", "bsz", ",", "self", ".", "H", ".", "nhid", "if", "l", "!=", "self", ".", "H", ".", "nlayers", "-", "1", "else", "(", "self", ".", "H", ".", "emsize", ")", ")", ".", "zero_", "(", ")", ")", "\n", "for", "l", "in", "range", "(", "self", ".", "H", ".", "nlayers", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.estimate_bias": [[328, 334], ["model.RNNModel._bias_drop", "model.RNNModel._bias_activation().min", "model.RNNModel._bias_activation", "model.RNNModel._bias"], "methods", ["None"], ["", "", "def", "estimate_bias", "(", "self", ",", "weight", ")", ":", "\n", "       ", "\"\"\"\n           Estimates the vocabulary bias based on the current weight.\n       \"\"\"", "\n", "weight", "=", "self", ".", "_bias_drop", "(", "weight", ")", "\n", "return", "self", ".", "_bias_activation", "(", "(", "self", ".", "_bias", "(", "weight", ")", ")", ")", ".", "min", "(", "dim", "=", "1", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.char_enc": [[335, 358], ["model.RNNModel._char_emb", "char_emb.view.view.view", "hasattr", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "model.RNNModel._char_linear", "conv().max", "model.RNNModel._conv_activation", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "model.RNNModel._char_highways", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "conv"], "methods", ["None"], ["", "def", "char_enc", "(", "self", ",", "char_arr", ",", "cache", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            Character-level encoder that extracts surface features for each word represented by its characters.\n        \"\"\"", "\n", "char_emb", "=", "self", ".", "_char_emb", "(", "char_arr", ")", "\n", "sh", "=", "char_emb", ".", "shape", "\n", "char_emb", "=", "char_emb", ".", "view", "(", "sh", "[", "1", "]", ",", "sh", "[", "3", "]", ",", "sh", "[", "2", "]", ")", "\n", "token_embedding", "=", "cache", "\n", "for", "conv", "in", "self", ".", "_char_network", ":", "\n", "            ", "out", "=", "conv", "(", "char_emb", ")", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "convolved", "=", "self", ".", "_conv_activation", "(", "out", "[", "0", "]", ")", "\n", "if", "token_embedding", "is", "not", "None", ":", "\n", "                ", "token_embedding", "=", "torch", ".", "cat", "(", "[", "token_embedding", ",", "convolved", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "token_embedding", "=", "convolved", "\n", "", "del", "(", "convolved", ")", "\n", "del", "(", "out", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "if", "hasattr", "(", "self", ",", "\"_char_highways\"", ")", ":", "\n", "            ", "token_embedding", "=", "self", ".", "_char_highways", "(", "token_embedding", ")", "\n", "", "del", "(", "char_emb", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "return", "self", ".", "_char_linear", "(", "token_embedding", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.get_weight": [[359, 380], ["range", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "round", "model.RNNModel.char_enc", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.char_enc"], ["", "def", "get_weight", "(", "self", ",", "char_arr", ")", ":", "\n", "        ", "\"\"\"\n            Function which encodes and returns the given vocabulary items in a memory efficient way.\n        \"\"\"", "\n", "div", "=", "self", ".", "H", ".", "div", "\n", "maxbs", "=", "round", "(", "char_arr", ".", "shape", "[", "1", "]", "/", "div", ")", "+", "1", "\n", "char_emb", ",", "result", "=", "None", ",", "None", "\n", "for", "i", "in", "range", "(", "maxbs", ")", ":", "\n", "            ", "cur_arr", "=", "char_arr", "[", ":", ",", "(", "i", "*", "div", ")", ":", "(", "i", "+", "1", ")", "*", "div", ",", ":", "]", "\n", "if", "cur_arr", ".", "shape", "[", "1", "]", "==", "0", ":", "\n", "                ", "break", "\n", "", "cur_emb", "=", "self", ".", "char_enc", "(", "cur_arr", ",", "cache", "=", "None", ")", "\n", "diff", "=", "cur_emb", ".", "shape", "[", "0", "]", "\n", "if", "result", "is", "not", "None", ":", "\n", "                ", "result", "=", "torch", ".", "cat", "(", "[", "result", ",", "cur_emb", "]", ")", "\n", "", "else", ":", "\n", "                ", "result", "=", "cur_emb", "\n", "", "del", "(", "cur_emb", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.batch_combined_enc": [[381, 403], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "model.RNNModel.combined_enc", "char_emb.detach.detach.detach", "numpy.arange", "numpy.random.rand", "hasattr"], "methods", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.combined_enc"], ["", "def", "batch_combined_enc", "(", "self", ",", "l", "=", "None", ",", "r", "=", "None", ",", "new", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            Compute the compositional representations for the selected vocabulary items in a batch-like mode. For efficiency the updates are made in a sparse way with probability p that is controlled by\n            the char_update_ratio argument.\n        \"\"\"", "\n", "# Get the indexes correspond to the left and right offsets", "\n", "num", "=", "r", "-", "l", "\n", "full", "=", "r", "==", "self", ".", "H", ".", "ntoken", "and", "l", "==", "0", "\n", "if", "full", ":", "\n", "            ", "num", "+=", "1", "# add empty token", "\n", "\n", "", "vocab_idxs", "=", "torch", ".", "tensor", "(", "np", ".", "arange", "(", "num", ")", ")", "+", "l", "\n", "# Get the combined representations for those indexes", "\n", "fixed", "=", "np", ".", "random", ".", "rand", "(", ")", ">", "self", ".", "H", ".", "char_update_ratio", "and", "not", "new", "\n", "\n", "if", "not", "fixed", "or", "not", "hasattr", "(", "self", ",", "\"combined_cached\"", ")", ":", "\n", "            ", "self", ".", "combined_cached", "=", "self", ".", "combined_enc", "(", "vocab_idxs", ",", "full", "=", "full", ",", "fixed", "=", "fixed", ",", "l", "=", "l", ",", "r", "=", "r", ")", "\n", "", "char_emb", "=", "self", ".", "combined_cached", "\n", "\n", "if", "fixed", ":", "\n", "            ", "char_emb", "=", "char_emb", ".", "detach", "(", ")", "\n", "", "return", "char_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.combined_enc": [[404, 423], ["model.RNNModel.batch_combined_forms", "len", "model.RNNModel.char_enc", "model.RNNModel.get_weight", "input.view", "input.view"], "methods", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.batch_combined_forms", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.char_enc", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.get_weight"], ["", "def", "combined_enc", "(", "self", ",", "input", ",", "full", "=", "False", ",", "fixed", "=", "None", ",", "l", "=", "0", ",", "r", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n            Get the combined representation for a given input. The input here\n            can be the training batch tensor or a 1d array with indexes pointing\n            to the vocabulary elements.\n        \"\"\"", "\n", "batch_input", "=", "len", "(", "input", ".", "shape", ")", ">", "1", "\n", "if", "batch_input", ":", "\n", "# Encode the training batch tensor.", "\n", "            ", "char_emb", "=", "self", ".", "char_enc", "(", "self", ".", "char_arr", "[", ":", ",", "input", ".", "view", "(", "-", "1", ")", "]", ")", "\n", "", "else", ":", "\n", "# Encode the elements in the vocabulary.", "\n", "            ", "char_emb", "=", "self", ".", "get_weight", "(", "self", ".", "char_arr", "[", ":", ",", "input", ".", "view", "(", "-", "1", ")", "]", ")", "\n", "char_emb", "[", "-", "1", "]", "=", "0", "#empty pad", "\n", "", "result", "=", "self", ".", "batch_combined_forms", "(", "char_emb", ",", "input", ",", "batch_input", "=", "batch_input", ",", "full", "=", "full", ",", "fixed", "=", "fixed", ",", "r", "=", "r", ")", "\n", "if", "full", "and", "not", "batch_input", ":", "\n", "            ", "return", "result", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.batch_combined_forms": [[424, 481], ["range", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "round", "model.RNNModel.combine", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "model.RNNModel.embed_features", "model.RNNModel.fpass", "model.RNNModel.embed_features", "model.RNNModel.fpass", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "input.view", "input.view"], "methods", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.combine", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.embed_features", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.fpass", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.embed_features", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.fpass"], ["", "", "def", "batch_combined_forms", "(", "self", ",", "char_emb", ",", "input", ",", "batch_input", "=", "None", ",", "full", "=", "None", ",", "fixed", "=", "None", ",", "r", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            Compute the compositional input embedding of words by taking\n            into account surface, relational, and definitional features.\n        \"\"\"", "\n", "if", "not", "self", ".", "rel_exist", "and", "not", "self", ".", "def_exist", ":", "\n", "            ", "result", "=", "char_emb", "\n", "", "else", ":", "\n", "            ", "div", "=", "self", ".", "H", ".", "div", "\n", "maxbs", "=", "round", "(", "char_emb", ".", "shape", "[", "0", "]", "/", "div", ")", "+", "1", "\n", "result", "=", "None", "\n", "for", "i", "in", "range", "(", "maxbs", ")", ":", "\n", "                ", "if", "batch_input", ":", "\n", "                    ", "cur_emb", "=", "char_emb", "\n", "", "else", ":", "\n", "                    ", "cur_emb", "=", "char_emb", "[", "i", "*", "div", ":", "(", "i", "+", "1", ")", "*", "div", ",", ":", "]", "\n", "", "rel_emb", ",", "def_emb", "=", "None", ",", "None", "\n", "cur_rel_emb", ",", "cur_def_emb", "=", "None", ",", "None", "\n", "if", "cur_emb", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "                    ", "break", "\n", "# Compute relational embedding", "\n", "", "if", "self", ".", "rel_exist", ":", "\n", "                    ", "if", "batch_input", ":", "\n", "                        ", "word_ids", "=", "self", ".", "rel_arr", "[", "input", ".", "view", "(", "-", "1", ")", "]", "\n", "", "else", ":", "\n", "                        ", "word_ids", "=", "self", ".", "rel_arr", "[", "input", "[", "i", "*", "div", ":", "(", "i", "+", "1", ")", "*", "div", "]", "]", "\n", "", "rel_emb", "=", "self", ".", "embed_features", "(", "word_ids", ",", "char_emb", ",", "full", "=", "full", ",", "fixed", "=", "fixed", ",", "r", "=", "r", ")", "\n", "cur_rel_emb", "=", "self", ".", "fpass", "(", "rel_emb", ",", "\"rel\"", ")", "\n", "if", "full", "and", "not", "batch_input", ":", "\n", "                        ", "cur_rel_emb", "[", "-", "1", "]", "=", "0", "\n", "\n", "# Compute definitional embedding", "\n", "", "", "if", "self", ".", "def_exist", ":", "\n", "                    ", "if", "batch_input", ":", "\n", "                        ", "word_ids", "=", "self", ".", "def_arr", "[", "input", ".", "view", "(", "-", "1", ")", "]", "\n", "", "else", ":", "\n", "                        ", "word_ids", "=", "self", ".", "def_arr", "[", "input", "[", "i", "*", "div", ":", "(", "i", "+", "1", ")", "*", "div", "]", "]", "\n", "", "def_emb", "=", "self", ".", "embed_features", "(", "word_ids", ",", "char_emb", ",", "full", "=", "full", ",", "fixed", "=", "fixed", ",", "r", "=", "r", ")", "\n", "cur_def_emb", "=", "self", ".", "fpass", "(", "def_emb", ",", "\"def\"", ")", "\n", "if", "full", "and", "not", "batch_input", ":", "\n", "                        ", "cur_def_emb", "[", "-", "1", "]", "=", "0", "\n", "\n", "# Compute combined embedding", "\n", "", "", "cur_res", "=", "self", ".", "combine", "(", "cur_emb", ",", "rel_emb", "=", "cur_rel_emb", ",", "def_emb", "=", "cur_def_emb", ")", "\n", "\n", "if", "result", "is", "not", "None", ":", "\n", "                    ", "result", "=", "torch", ".", "cat", "(", "[", "result", ",", "cur_res", "]", ")", "\n", "", "else", ":", "\n", "                    ", "result", "=", "cur_res", "\n", "\n", "", "del", "(", "word_ids", ",", "cur_res", ",", "cur_emb", ",", "def_emb", ")", "\n", "del", "(", "rel_emb", ",", "cur_def_emb", ",", "cur_rel_emb", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "if", "batch_input", ":", "\n", "                    ", "break", "\n", "", "", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.embed_features": [[482, 495], ["model.RNNModel.char_enc", "emb.view.view.view", "word_ids.view"], "methods", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.char_enc"], ["", "def", "embed_features", "(", "self", ",", "word_ids", ",", "char_emb", ",", "full", "=", "False", ",", "fixed", "=", "False", ",", "r", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n            Get an embedding for relational or definitional features.\n        \"\"\"", "\n", "if", "full", ":", "\n", "# Use the recently encoded vocabulary items to represent relations.", "\n", "            ", "emb", "=", "char_emb", "[", "word_ids", "]", "\n", "", "else", ":", "\n", "# Encode the vocabulary items needed for the relational features.", "\n", "            ", "sh", "=", "word_ids", ".", "shape", "\n", "emb", "=", "self", ".", "char_enc", "(", "self", ".", "char_arr", "[", ":", ",", "word_ids", ".", "view", "(", "-", "1", ")", "]", ")", "\n", "emb", "=", "emb", ".", "view", "(", "sh", "[", "0", "]", ",", "sh", "[", "1", "]", ",", "emb", ".", "shape", "[", "-", "1", "]", ")", "\n", "", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.combine": [[497, 530], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.RNNModel._comb_lin", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.RNNModel._comb_lin", "torch.cat.view", "torch.cat.view", "torch.cat.view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.RNNModel._comb_lin", "torch.cat.view", "torch.cat.view", "torch.cat.view"], "methods", ["None"], ["", "def", "combine", "(", "self", ",", "cur_emb", ",", "rel_emb", "=", "None", ",", "def_emb", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            Function to combine surface, relational and definitional features.\n        \"\"\"", "\n", "\n", "if", "self", ".", "rel_exist", "and", "self", ".", "def_exist", ":", "\n", "            ", "if", "self", ".", "H", ".", "combine", "==", "\"concat\"", ":", "\n", "                ", "combined", "=", "torch", ".", "cat", "(", "(", "cur_emb", ",", "rel_emb", ",", "def_emb", ")", ",", "1", ")", "\n", "result", "=", "self", ".", "_comb_lin", "(", "combined", ".", "view", "(", "-", "1", ",", "self", ".", "H", ".", "emsize", "*", "self", ".", "nforms", ")", ")", "\n", "", "elif", "self", ".", "H", ".", "combine", "==", "\"add\"", ":", "\n", "                ", "result", "=", "cur_emb", "+", "rel_emb", "+", "def_emb", "\n", "", "elif", "self", ".", "H", ".", "combine", "==", "\"multiply\"", ":", "\n", "                ", "result", "=", "cur_emb", "*", "rel_emb", "*", "def_emb", "\n", "", "", "elif", "self", ".", "def_exist", ":", "\n", "            ", "if", "self", ".", "H", ".", "combine", "==", "\"concat\"", ":", "\n", "                ", "combined", "=", "torch", ".", "cat", "(", "(", "cur_emb", ",", "def_emb", ")", ",", "1", ")", "\n", "result", "=", "self", ".", "_comb_lin", "(", "combined", ".", "view", "(", "-", "1", ",", "self", ".", "H", ".", "emsize", "*", "self", ".", "nforms", ")", ")", "\n", "", "elif", "self", ".", "H", ".", "combine", "==", "\"add\"", ":", "\n", "                ", "result", "=", "cur_emb", "+", "def_emb", "\n", "", "elif", "self", ".", "H", ".", "combine", "==", "\"multiply\"", ":", "\n", "                ", "result", "=", "cur_emb", "*", "def_emb", "\n", "", "", "elif", "self", ".", "rel_exist", ":", "\n", "            ", "if", "self", ".", "H", ".", "combine", "==", "\"concat\"", ":", "\n", "                ", "combined", "=", "torch", ".", "cat", "(", "(", "cur_emb", ",", "rel_emb", ")", ",", "1", ")", "\n", "result", "=", "self", ".", "_comb_lin", "(", "combined", ".", "view", "(", "-", "1", ",", "self", ".", "H", ".", "emsize", "*", "self", ".", "nforms", ")", ")", "\n", "", "elif", "self", ".", "H", ".", "combine", "==", "\"add\"", ":", "\n", "                ", "result", "=", "cur_emb", "+", "rel_emb", "\n", "", "elif", "self", ".", "H", ".", "combine", "==", "\"multiply\"", ":", "\n", "                ", "result", "=", "cur_emb", "*", "rel_emb", "\n", "", "", "else", ":", "\n", "            ", "result", "=", "cur_emb", "\n", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.fpass": [[531, 542], ["model.RNNModel.mean", "eval", "model.RNNModel._definition_network", "model.RNNModel._definition_network"], "methods", ["None"], ["", "def", "fpass", "(", "self", ",", "y", ",", "type", ")", ":", "\n", "        ", "\"\"\"\n            Encoding function for the relational and definitional features.\n            Currently implemented with a highway net.\n        \"\"\"", "\n", "if", "self", ".", "H", ".", "defenc", "==", "\"lstm\"", ":", "\n", "            ", "h", "=", "eval", "(", "\"self.%s_hid\"", "%", "type", ")", "\n", "y", ",", "h", "=", "self", ".", "_definition_network", "(", "y", ",", "h", ")", "\n", "", "elif", "self", ".", "H", ".", "defenc", "==", "\"highway\"", ":", "\n", "            ", "y", "=", "self", ".", "_definition_network", "(", "y", ")", "\n", "", "return", "y", ".", "mean", "(", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.batch_apply_output_network": [[543, 562], ["range", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "round", "model.RNNModel.apply_output_network", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.apply_output_network"], ["", "def", "batch_apply_output_network", "(", "self", ",", "weight", ",", "l", "=", "None", ",", "r", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            Memory efficient way to use apply_output_network() function onss large vocabularies.\n        \"\"\"", "\n", "div", "=", "self", ".", "H", ".", "div", "\n", "maxbs", "=", "round", "(", "weight", ".", "shape", "[", "0", "]", "/", "div", ")", "+", "1", "\n", "result", "=", "None", "\n", "for", "i", "in", "range", "(", "maxbs", ")", ":", "\n", "            ", "cur_res", "=", "self", ".", "apply_output_network", "(", "weight", "[", "i", "*", "div", ":", "(", "i", "+", "1", ")", "*", "div", ",", ":", "]", ")", "\n", "if", "cur_res", ".", "shape", "[", "0", "]", "==", "0", ":", "\n", "                ", "break", "\n", "", "if", "result", "is", "not", "None", ":", "\n", "               ", "result", "=", "torch", ".", "cat", "(", "[", "result", ",", "cur_res", "]", ")", "\n", "", "else", ":", "\n", "               ", "result", "=", "cur_res", "\n", "", "del", "(", "cur_res", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.apply_output_network": [[563, 584], ["range", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "model.RNNModel._lockdrop().view", "model.RNNModel._output_act", "model.RNNModel._jdrop", "model.RNNModel._lockdrop", "prev_encoder_out.view"], "methods", ["None"], ["", "def", "apply_output_network", "(", "self", ",", "weight", ")", ":", "\n", "        ", "\"\"\"\n            Make a forward pass of the given input embeddings stored in <weight> through a deep residual network to get the output embedding.\n        \"\"\"", "\n", "sh", "=", "weight", ".", "shape", "\n", "prev_encoder_out", "=", "weight", "\n", "for", "i", "in", "range", "(", "self", ".", "H", ".", "joint_emb_depth", ")", ":", "\n", "            ", "if", "self", ".", "H", ".", "joint_locked_dropout", ":", "\n", "                ", "cur_weight", "=", "self", ".", "_lockdrop", "(", "prev_encoder_out", ".", "view", "(", "sh", "[", "0", "]", ",", "1", ",", "sh", "[", "1", "]", ")", ",", "self", ".", "H", ".", "joint_dropout", "if", "self", ".", "use_dropout", "else", "0", ")", ".", "view", "(", "sh", "[", "0", "]", ",", "sh", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "                ", "cur_weight", "=", "self", ".", "_jdrop", "(", "prev_encoder_out", ")", "if", "self", ".", "use_dropout", "else", "prev_encoder_out", "\n", "", "if", "self", ".", "H", ".", "bilinear", ":", "\n", "                ", "cur_weight_proj", "=", "self", ".", "_output_network", "[", "i", "]", "(", "cur_weight", ")", "\n", "", "else", ":", "\n", "                ", "cur_weight_proj", "=", "self", ".", "_output_act", "(", "self", ".", "_output_network", "[", "i", "]", "(", "cur_weight", ")", ")", "\n", "cur_weight_proj", "=", "cur_weight_proj", "+", "weight", "\n", "", "prev_encoder_out", "=", "cur_weight_proj", "\n", "del", "(", "cur_weight_proj", ")", "\n", "del", "(", "cur_weight", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "", "return", "prev_encoder_out", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.rnn_pass": [[585, 601], ["enumerate", "rnn", "new_hidden.append", "raw_outputs.append", "model.RNNModel._lockdrop", "outputs.append"], "methods", ["None"], ["", "def", "rnn_pass", "(", "self", ",", "raw_output", ",", "hidden", ")", ":", "\n", "        ", "\"\"\"\n            Make a forward pass of the given input stored in <emb> through\n            the recurrent network. <hidden> is the state of the reccurrent\n            network from the previous timestep.\n        \"\"\"", "\n", "new_hidden", ",", "raw_outputs", ",", "outputs", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "l", ",", "rnn", "in", "enumerate", "(", "self", ".", "_prefix_network", ")", ":", "\n", "            ", "current_input", "=", "raw_output", "\n", "raw_output", ",", "new_h", "=", "rnn", "(", "raw_output", ",", "hidden", "[", "l", "]", ")", "\n", "new_hidden", ".", "append", "(", "new_h", ")", "\n", "raw_outputs", ".", "append", "(", "raw_output", ")", "\n", "if", "l", "!=", "self", ".", "H", ".", "nlayers", "-", "1", ":", "\n", "                ", "raw_output", "=", "self", ".", "_lockdrop", "(", "raw_output", ",", "self", ".", "H", ".", "dropouth", "if", "self", ".", "use_dropout", "else", "0", ")", "\n", "outputs", ".", "append", "(", "raw_output", ")", "\n", "", "", "return", "raw_output", ",", "raw_outputs", ",", "outputs", ",", "new_hidden", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.output_dropout": [[602, 607], ["model.RNNModel._lockdrop().view", "model.RNNModel._lockdrop", "model.RNNModel.view"], "methods", ["None"], ["", "def", "output_dropout", "(", "self", ",", "weight", ")", ":", "\n", "        ", "if", "self", ".", "H", ".", "output_dropout", ">", "0", "and", "weight", "is", "not", "None", ":", "\n", "            ", "sh", "=", "weight", ".", "shape", "\n", "weight", "=", "self", ".", "_lockdrop", "(", "weight", ".", "view", "(", "sh", "[", "0", "]", ",", "1", ",", "sh", "[", "1", "]", ")", ",", "self", ".", "H", ".", "output_dropout", "if", "self", ".", "use_dropout", "else", "0", ")", ".", "view", "(", "sh", "[", "0", "]", ",", "sh", "[", "1", "]", ")", "\n", "", "return", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.output_embedding": [[608, 638], ["model.RNNModel.output_dropout", "model.RNNModel.output_dropout", "model.RNNModel.batch_combined_enc", "model.RNNModel.batch_apply_output_network", "model.RNNModel._decoder", "model.RNNModel._cnnsoftmax_M", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "torch.arange().cuda", "model.RNNModel.batch_combined_enc", "model.RNNModel._cnnsoftmax_M", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "model.RNNModel.squeeze"], "methods", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.output_dropout", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.output_dropout", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.batch_combined_enc", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.batch_apply_output_network", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.batch_combined_enc"], ["", "def", "output_embedding", "(", "self", ",", "l_idx", ",", "h_idx", ",", "weight", "=", "None", ",", "adapt_call", "=", "False", ",", "new", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            Return the output embedding for the full vocabulary or for\n            a subset of it when there is a call from adaptive softmax.\n        \"\"\"", "\n", "if", "adapt_call", ":", "\n", "            ", "if", "self", ".", "H", ".", "char_emb", "or", "self", ".", "H", ".", "cnnsoftmax", ":", "\n", "                ", "weight", "=", "self", ".", "batch_combined_enc", "(", "l", "=", "l_idx", ",", "r", "=", "h_idx", ",", "new", "=", "new", ")", "\n", "if", "self", ".", "H", ".", "cnncorr", ":", "\n", "                    ", "corr", "=", "self", ".", "_cnnsoftmax_M", "(", "self", ".", "_cnnsoftmax_correction", ".", "weight", ")", "\n", "weight", "=", "weight", "+", "corr", "[", "l_idx", ":", "h_idx", "]", "\n", "", "", "else", ":", "\n", "                ", "weight", "=", "weight", "[", "l_idx", ":", "h_idx", "]", "\n", "", "weight", "=", "self", ".", "output_dropout", "(", "weight", ")", "\n", "if", "self", ".", "H", ".", "joint_emb", ":", "\n", "                ", "weight", "=", "self", ".", "batch_apply_output_network", "(", "weight", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "self", ".", "H", ".", "adaptiveoutputs", "or", "self", ".", "H", ".", "adaptiveoutputs_tied", ":", "\n", "                ", "weight", "=", "self", ".", "_decoder", "(", "torch", ".", "arange", "(", "self", ".", "H", ".", "ntoken", ")", ".", "cuda", "(", ")", ")", "\n", "", "elif", "(", "self", ".", "H", ".", "char_emb", "or", "self", ".", "H", ".", "cnnsoftmax", ")", ":", "\n", "                ", "weight", "=", "self", ".", "batch_combined_enc", "(", "l", "=", "0", ",", "r", "=", "self", ".", "H", ".", "ntoken", ")", "\n", "if", "self", ".", "H", ".", "cnncorr", ":", "\n", "                    ", "corr", "=", "self", ".", "_cnnsoftmax_M", "(", "self", ".", "_cnnsoftmax_correction", ".", "weight", ")", "\n", "weight", "=", "weight", "+", "corr", ".", "squeeze", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "weight", "=", "self", ".", "_lookup", ".", "weight", "if", "self", ".", "H", ".", "tied", "or", "self", ".", "H", ".", "joint_emb", "is", "not", "None", "else", "self", ".", "_decoder", ".", "weight", "\n", "\n", "", "weight", "=", "self", ".", "output_dropout", "(", "weight", ")", "\n", "\n", "", "return", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.embed_inputs": [[639, 654], ["model.RNNModel._lockdrop", "model.RNNModel._lookup().view", "weight[].view", "model.RNNModel._lookup().view", "model.RNNModel._lookup", "model.RNNModel._lookup", "input.view"], "methods", ["None"], ["", "def", "embed_inputs", "(", "self", ",", "input", ",", "weight", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n            Embed inputs using the given output embedding or based on the\n            corresponding input embedding of each method.\n        \"\"\"", "\n", "emb", "=", "None", "\n", "if", "emb", "is", "None", ":", "\n", "            ", "if", "self", ".", "H", ".", "adaptiveoutputs", "or", "self", ".", "H", ".", "cnnsoftmax", ":", "\n", "                ", "emb", "=", "self", ".", "_lookup", "(", "input", ")", ".", "view", "(", "input", ".", "shape", "[", "0", "]", ",", "input", ".", "shape", "[", "1", "]", ",", "self", ".", "H", ".", "emsize", ")", "\n", "", "elif", "self", ".", "H", ".", "adaptiveoutputs_tied", "or", "self", ".", "H", ".", "char_emb", ":", "\n", "                ", "emb", "=", "weight", "[", "input", ".", "view", "(", "-", "1", ")", "]", ".", "view", "(", "input", ".", "shape", "[", "0", "]", ",", "input", ".", "shape", "[", "1", "]", ",", "self", ".", "H", ".", "emsize", ")", "\n", "", "else", ":", "\n", "                ", "emb", "=", "self", ".", "_lookup", "(", "input", ")", ".", "view", "(", "input", ".", "shape", "[", "0", "]", ",", "input", ".", "shape", "[", "1", "]", ",", "self", ".", "H", ".", "emsize", ")", "\n", "", "", "emb", "=", "self", ".", "_lockdrop", "(", "emb", ",", "self", ".", "H", ".", "dropouti", "if", "self", ".", "use_dropout", "else", "0", ")", "\n", "return", "emb", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.output_bias": [[655, 669], ["model.RNNModel.view", "model.RNNModel.estimate_bias", "hasattr", "hasattr"], "methods", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.estimate_bias"], ["", "def", "output_bias", "(", "self", ",", "weight", ")", ":", "\n", "        ", "\"\"\"\n            Return the output bias for the full vocabulary.\n        \"\"\"", "\n", "if", "self", ".", "H", ".", "predict_bias", ":", "\n", "            ", "bias", "=", "self", ".", "estimate_bias", "(", "weight", ")", "\n", "", "else", ":", "\n", "            ", "if", "hasattr", "(", "self", ",", "'_bias'", ")", ":", "\n", "                ", "bias", "=", "self", ".", "_bias", ".", "weight", "\n", "", "elif", "self", ".", "H", ".", "tied", "or", "self", ".", "H", ".", "fullsoftmax", ":", "\n", "                ", "bias", "=", "self", ".", "_decoder", ".", "bias", "\n", "", "elif", "hasattr", "(", "self", ",", "'decoder'", ")", ":", "\n", "                ", "bias", "=", "self", ".", "_decoder", ".", "weight", "\n", "", "", "return", "bias", ".", "view", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.forward": [[670, 704], ["model.RNNModel.embed_inputs", "model.RNNModel.rnn_pass", "model.RNNModel._lockdrop", "model.RNNModel.view", "outputs.append", "model.RNNModel.output_bias", "model.RNNModel.output_embedding", "model.RNNModel.size", "model.RNNModel.batch_apply_output_network", "hasattr", "model.RNNModel.output_embedding", "model.RNNModel.size", "model.RNNModel.size"], "methods", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.embed_inputs", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.rnn_pass", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.output_bias", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.output_embedding", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.batch_apply_output_network", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.output_embedding"], ["", "def", "forward", "(", "self", ",", "input", ",", "hidden", ",", "return_h", "=", "False", ",", "eval_mode", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n            This function makes a forward pass of the input tensor and returns the components for computing the logits as well as optionally the hidden states of the rnn.\n        \"\"\"", "\n", "# Load output embedding", "\n", "if", "eval_mode", ":", "\n", "            ", "if", "not", "hasattr", "(", "self", ",", "\"cached_weight\"", ")", ":", "\n", "                ", "weight", "=", "self", ".", "output_embedding", "(", "0", ",", "self", ".", "H", ".", "ntoken", ")", "\n", "self", ".", "cached_weight", "=", "weight", "\n", "", "else", ":", "\n", "                ", "weight", "=", "self", ".", "cached_weight", "\n", "", "", "else", ":", "\n", "            ", "weight", "=", "self", ".", "output_embedding", "(", "0", ",", "self", ".", "H", ".", "ntoken", ")", "\n", "\n", "# Embed input tensor", "\n", "", "emb", "=", "self", ".", "embed_inputs", "(", "input", ",", "weight", "=", "weight", ")", "\n", "\n", "# Encode the prefixes of the input tensor", "\n", "raw_output", ",", "raw_outputs", ",", "outputs", ",", "hidden", "=", "self", ".", "rnn_pass", "(", "emb", ",", "hidden", ")", "\n", "output", "=", "self", ".", "_lockdrop", "(", "raw_output", ",", "self", ".", "H", ".", "dropout", "if", "self", ".", "use_dropout", "else", "0", ")", "\n", "result", "=", "output", ".", "view", "(", "output", ".", "size", "(", "0", ")", "*", "output", ".", "size", "(", "1", ")", ",", "output", ".", "size", "(", "2", ")", ")", "\n", "outputs", ".", "append", "(", "output", ")", "\n", "\n", "# Apply output transformation", "\n", "if", "self", ".", "H", ".", "joint_emb", "is", "not", "None", ":", "\n", "            ", "weight", "=", "self", ".", "batch_apply_output_network", "(", "weight", ")", "\n", "\n", "# Load bias", "\n", "", "bias", "=", "self", ".", "output_bias", "(", "weight", "=", "weight", ")", "\n", "\n", "if", "return_h", ":", "\n", "            ", "return", "result", ",", "weight", ",", "bias", ",", "hidden", ",", "raw_outputs", ",", "outputs", "\n", "", "else", ":", "\n", "            ", "return", "result", ",", "weight", ",", "bias", ",", "hidden", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.locked_dropout.LockedDropout.__init__": [[21, 23], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.locked_dropout.LockedDropout.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.locked_dropout.LockedDropout.forward": [[24, 31], ["x.data.new().bernoulli_", "mask.expand_as.expand_as.expand_as", "torch.autograd.Variable", "torch.autograd.Variable", "x.data.new", "x.size", "x.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "dropout", "=", "0.5", ")", ":", "\n", "        ", "if", "not", "self", ".", "training", "or", "not", "dropout", ":", "\n", "            ", "return", "x", "\n", "", "m", "=", "x", ".", "data", ".", "new", "(", "1", ",", "x", ".", "size", "(", "1", ")", ",", "x", ".", "size", "(", "2", ")", ")", ".", "bernoulli_", "(", "1", "-", "dropout", ")", "\n", "mask", "=", "Variable", "(", "m", ",", "requires_grad", "=", "False", ")", "/", "(", "1", "-", "dropout", ")", "\n", "mask", "=", "mask", ".", "expand_as", "(", "x", ")", "\n", "return", "mask", "*", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.utils.repackage_hidden": [[21, 28], ["isinstance", "h.detach", "tuple", "utils.repackage_hidden"], "function", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.utils.repackage_hidden"], ["def", "repackage_hidden", "(", "h", ")", ":", "\n", "    ", "\"\"\"Wraps hidden states in new Tensors,\n    to detach them from their history.\"\"\"", "\n", "if", "isinstance", "(", "h", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "return", "h", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "tuple", "(", "repackage_hidden", "(", "v", ")", "for", "v", "in", "h", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.utils.batchify": [[30, 41], ["data.cuda.narrow", "data.cuda.view().t().contiguous", "data.cuda.size", "data.cuda.cuda", "data.cuda.view().t", "data.cuda.view"], "function", ["None"], ["", "", "def", "batchify", "(", "data", ",", "bsz", ",", "args", ")", ":", "\n", "# Work out how cleanly we can divide the dataset into bsz parts.", "\n", "    ", "nbatch", "=", "data", ".", "size", "(", "0", ")", "//", "bsz", "\n", "# Trim off any extra elements that wouldn't cleanly fit (remainders).", "\n", "data", "=", "data", ".", "narrow", "(", "0", ",", "0", ",", "nbatch", "*", "bsz", ")", "\n", "# Evenly divide the data across the bsz batches.", "\n", "data", "=", "data", ".", "view", "(", "bsz", ",", "-", "1", ")", ".", "t", "(", ")", ".", "contiguous", "(", ")", "\n", "\n", "if", "args", ".", "cuda", ":", "\n", "        ", "data", "=", "data", ".", "cuda", "(", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.utils.get_batch": [[43, 48], ["min", "source[].view", "len"], "function", ["None"], ["", "def", "get_batch", "(", "source", ",", "i", ",", "args", ",", "seq_len", "=", "None", ",", "evaluation", "=", "False", ")", ":", "\n", "    ", "seq_len", "=", "min", "(", "seq_len", "if", "seq_len", "else", "args", ".", "bptt", ",", "len", "(", "source", ")", "-", "1", "-", "i", ")", "\n", "data", "=", "source", "[", "i", ":", "i", "+", "seq_len", "]", "\n", "target", "=", "source", "[", "i", "+", "1", ":", "i", "+", "1", "+", "seq_len", "]", ".", "view", "(", "-", "1", ")", "\n", "return", "data", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.utils.create_exp_dir": [[50, 60], ["print", "os.path.exists", "os.mkdir", "os.mkdir", "os.path.join", "os.path.join", "shutil.copyfile", "os.path.basename"], "function", ["None"], ["", "def", "create_exp_dir", "(", "path", ",", "scripts_to_save", "=", "None", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "path", ")", "\n", "\n", "", "print", "(", "'Experiment dir : {}'", ".", "format", "(", "path", ")", ")", "\n", "if", "scripts_to_save", "is", "not", "None", ":", "\n", "        ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "path", ",", "'scripts'", ")", ")", "\n", "for", "script", "in", "scripts_to_save", ":", "\n", "            ", "dst_file", "=", "os", ".", "path", ".", "join", "(", "path", ",", "'scripts'", ",", "os", ".", "path", ".", "basename", "(", "script", ")", ")", "\n", "shutil", ".", "copyfile", "(", "script", ",", "dst_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.utils.save_checkpoint": [[61, 70], ["torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["", "", "", "def", "save_checkpoint", "(", "model", ",", "criterion", ",", "optimizer", ",", "path", ",", "finetune", "=", "False", ")", ":", "\n", "    ", "if", "finetune", ":", "\n", "        ", "torch", ".", "save", "(", "model", ",", "os", ".", "path", ".", "join", "(", "path", ",", "'finetune_model.pt'", ")", ")", "\n", "torch", ".", "save", "(", "criterion", ",", "os", ".", "path", ".", "join", "(", "path", ",", "'finetune_criterion.pt'", ")", ")", "\n", "torch", ".", "save", "(", "optimizer", ",", "os", ".", "path", ".", "join", "(", "path", ",", "'finetune_optimizer.pt'", ")", ")", "\n", "", "else", ":", "\n", "        ", "torch", ".", "save", "(", "model", ",", "os", ".", "path", ".", "join", "(", "path", ",", "'model.pt'", ")", ")", "\n", "torch", ".", "save", "(", "criterion", ",", "os", ".", "path", ".", "join", "(", "path", ",", "'criterion.pt'", ")", ")", "\n", "torch", ".", "save", "(", "optimizer", ",", "os", ".", "path", ".", "join", "(", "path", ",", "'optimizer.pt'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.utils.consecutive_groups": [[71, 73], ["numpy.split", "numpy.where", "numpy.diff"], "function", ["None"], ["", "", "def", "consecutive_groups", "(", "data", ",", "stepsize", "=", "1", ")", ":", "\n", "    ", "return", "np", ".", "split", "(", "data", ",", "np", ".", "where", "(", "np", ".", "diff", "(", "data", ")", "!=", "stepsize", ")", "[", "0", "]", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.utils.load_criterion": [[75, 82], ["logging", "torch.nn.CrossEntropyLoss"], "function", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.evaluate.logging"], ["", "def", "load_criterion", "(", "args", ",", "ntokens", ",", "logging", ")", ":", "\n", "    ", "\"\"\"\n\tFunction to load different criteria depending on the vocabulary splits and size.\n    \"\"\"", "\n", "logging", "(", "\"Using no splits; vocab size {}\"", ".", "format", "(", "ntokens", ")", ")", "\n", "criterion", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "return", "criterion", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.utils.store_word_ce": [[85, 113], ["model.eval", "model.init_hidden", "range", "pickle.dump", "utils.get_batch", "model", "enumerate", "utils.repackage_hidden", "open", "data_source.size", "torch.mm", "weight.t", "criterion", "vocab[].append", "target.tolist", "target_loss.tolist", "target_loss.tolist"], "function", ["home.repos.pwc.inspect_result.Noahs-ARK_groc.None.model.RNNModel.init_hidden", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.utils.get_batch", "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.utils.repackage_hidden"], ["", "def", "store_word_ce", "(", "args", ",", "data_source", ",", "model", ",", "corpus", ",", "criterion", ",", "fname", "=", "'out'", ")", ":", "\n", "    ", "\"\"\"\n       Store the cross-entropy loss per word in the vocabulary.\n    \"\"\"", "\n", "# Turn on evaluation mode which disables dropout.", "\n", "model", ".", "eval", "(", ")", "\n", "batch_size", "=", "data_source", ".", "shape", "[", "1", "]", "\n", "hidden", "=", "model", ".", "init_hidden", "(", "batch_size", ")", "\n", "\n", "# Initialize vocabulary structure to store the crossentropy losses.", "\n", "vocab", ",", "words", "=", "{", "}", ",", "corpus", ".", "dictionary", ".", "idx2word", "\n", "\n", "# Add the loss per word in the vocabulary structure for each different context.", "\n", "for", "i", "in", "range", "(", "0", ",", "data_source", ".", "size", "(", "0", ")", "-", "1", ",", "args", ".", "bptt", ")", ":", "\n", "        ", "data", ",", "targets", "=", "get_batch", "(", "data_source", ",", "i", ",", "args", ",", "evaluation", "=", "True", ")", "\n", "output", ",", "weight", ",", "bias", ",", "hidden", "=", "model", "(", "data", ",", "hidden", ")", "\n", "pred_targets", "=", "torch", ".", "mm", "(", "output", ",", "weight", ".", "t", "(", ")", ")", "+", "bias", "\n", "for", "j", ",", "target", "in", "enumerate", "(", "targets", ")", ":", "\n", "            ", "target_loss", "=", "criterion", "(", "pred_targets", "[", "j", ":", "j", "+", "1", "]", ",", "targets", "[", "j", ":", "j", "+", "1", "]", ")", ".", "data", "\n", "word", "=", "words", "[", "target", ".", "tolist", "(", ")", "]", "\n", "if", "word", "in", "vocab", ":", "\n", "                ", "vocab", "[", "word", "]", ".", "append", "(", "target_loss", ".", "tolist", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "vocab", "[", "word", "]", "=", "[", "target_loss", ".", "tolist", "(", ")", "]", "\n", "", "", "hidden", "=", "repackage_hidden", "(", "hidden", ")", "\n", "\n", "# Store the vocabulary to the disk.", "\n", "", "pickle", ".", "dump", "(", "vocab", ",", "open", "(", "fname", "+", "'.pkl'", ",", "'wb'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Noahs-ARK_groc.None.utils.get_external_knowledge": [[115, 178], ["all_words.append", "hasattr", "hasattr", "batch_to_ids", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "wordnet.synsets", "[].tolist", "[].tolist", "relations.append", "definitions.append", "print", "len", "int", "int", "int", "int", "int", "int", "len", "range", "len", "range", "l.name", "len", "rel_lens.append", "len", "def_lens.append", "len", "numpy.mean", "numpy.max", "numpy.min", "len", "numpy.mean", "numpy.max", "numpy.min", "s.lemmas", "numpy.unique", "synset[].definition().split", "len", "len", "numpy.pad", "numpy.pad", "len", "len", "len", "l.name", "synset[].definition", "len", "len", "len", "len"], "function", ["None"], ["", "def", "get_external_knowledge", "(", "args", ",", "corpus", ")", ":", "\n", "    ", "\"\"\"\n        Function to extract surface, relational, and definitional\n        features from an external knowledge base.\n    \"\"\"", "\n", "char_arr", ",", "char_vocab", "=", "None", ",", "None", "\n", "rel_arr", ",", "def_arr", "=", "None", ",", "None", "\n", "if", "(", "hasattr", "(", "args", ",", "\"char_emb\"", ")", "and", "args", ".", "char_emb", ")", "or", "(", "hasattr", "(", "args", ",", "\"cnnsoftmax\"", ")", "and", "args", ".", "cnnsoftmax", ")", ":", "\n", "# extract sufrface forms", "\n", "        ", "from", "allennlp", ".", "modules", ".", "elmo", "import", "batch_to_ids", "\n", "all_words", "=", "corpus", ".", "dictionary", ".", "idx2word", "\n", "all_words", ".", "append", "(", "''", ")", "# empty pad token", "\n", "char_arr", ",", "char_vocab", "=", "batch_to_ids", "(", "[", "all_words", "]", ")", ",", "None", "\n", "char_arr", "=", "char_arr", "[", ":", ",", ":", ",", ":", "args", ".", "max_charlen", "]", "\n", "max_dlen", "=", "args", ".", "max_deflen", "\n", "max_rlen", "=", "args", ".", "max_rellen", "\n", "# extract relational and definitional forms", "\n", "if", "args", ".", "rel_emb", "or", "args", ".", "def_emb", ":", "\n", "            ", "from", "nltk", ".", "corpus", "import", "wordnet", "\n", "definitions", ",", "relations", "=", "[", "]", ",", "[", "]", "\n", "rel_lens", ",", "def_lens", "=", "[", "]", ",", "[", "]", "\n", "count", ",", "rels", ",", "defs", "=", "0", ",", "0", ",", "0", "\n", "print", "(", "\"Loading external info...\"", ")", "\n", "for", "word", "in", "all_words", ":", "\n", "                ", "synset", "=", "wordnet", ".", "synsets", "(", "word", ")", "\n", "cur_def", "=", "[", "len", "(", "all_words", ")", "-", "1", "for", "i", "in", "range", "(", "max_dlen", ")", "]", "\n", "cur_rel", "=", "[", "len", "(", "all_words", ")", "-", "1", "for", "i", "in", "range", "(", "max_rlen", ")", "]", "\n", "if", "len", "(", "synset", ")", ">", "0", ":", "\n", "                    ", "synonyms", "=", "[", "l", ".", "name", "(", ")", "for", "s", "in", "synset", "for", "l", "in", "s", ".", "lemmas", "(", ")", "if", "l", ".", "name", "(", ")", "in", "corpus", ".", "dictionary", ".", "word2idx", "]", "\n", "synonyms", "=", "[", "corpus", ".", "dictionary", ".", "word2idx", "[", "w", "]", "for", "w", "in", "np", ".", "unique", "(", "synonyms", ")", "]", "\n", "top_def", "=", "[", "corpus", ".", "dictionary", ".", "word2idx", "[", "w", "]", "for", "w", "in", "synset", "[", "0", "]", ".", "definition", "(", ")", ".", "split", "(", ")", "if", "w", "in", "corpus", ".", "dictionary", ".", "word2idx", "]", "\n", "cur_rel", "=", "synonyms", "\n", "cur_def", "=", "top_def", "\n", "if", "len", "(", "synonyms", ")", ">", "0", ":", "\n", "                        ", "rels", "+=", "1", "\n", "rel_lens", ".", "append", "(", "len", "(", "synonyms", ")", ")", "\n", "", "if", "len", "(", "top_def", ")", ">", "0", ":", "\n", "                        ", "defs", "+=", "1", "\n", "def_lens", ".", "append", "(", "len", "(", "top_def", ")", ")", "\n", "", "", "cur_rel_padded", "=", "np", ".", "pad", "(", "cur_rel", ",", "(", "0", ",", "(", "500", "-", "len", "(", "cur_rel", ")", ")", ")", ",", "constant_values", "=", "len", "(", "all_words", ")", "-", "1", ")", "[", ":", "max_rlen", "]", ".", "tolist", "(", ")", "\n", "cur_def_padded", "=", "np", ".", "pad", "(", "cur_def", ",", "(", "0", ",", "(", "500", "-", "len", "(", "cur_def", ")", ")", ")", ",", "constant_values", "=", "len", "(", "all_words", ")", "-", "1", ")", "[", ":", "max_dlen", "]", ".", "tolist", "(", ")", "\n", "relations", ".", "append", "(", "cur_rel_padded", ")", "\n", "definitions", ".", "append", "(", "cur_def_padded", ")", "\n", "print", "(", "\"(%d/%d)\"", "%", "(", "count", ",", "len", "(", "all_words", ")", ")", ",", "end", "=", "\"\\r\"", ")", "\n", "count", "+=", "1", "\n", "", "print", "(", "\"====== External knowledge ======\"", ")", "\n", "print", "(", "\"[*] Relations (%d/%d)\"", "%", "(", "rels", ",", "len", "(", "relations", ")", ")", ")", "\n", "print", "(", "\" nonzero: %.2f%s\"", "%", "(", "(", "rels", "*", "100", "/", "len", "(", "relations", ")", ")", ",", "'%'", ")", ")", "\n", "print", "(", "\" avg: %d\"", "%", "int", "(", "np", ".", "mean", "(", "rel_lens", ")", ")", ")", "\n", "print", "(", "\" max: %d\"", "%", "int", "(", "np", ".", "max", "(", "rel_lens", ")", ")", ")", "\n", "print", "(", "\" min: %d\"", "%", "int", "(", "np", ".", "min", "(", "rel_lens", ")", ")", ")", "\n", "print", "(", "\"[*] Definitions (%d/%d)\"", "%", "(", "defs", ",", "len", "(", "definitions", ")", ")", ")", "\n", "print", "(", "\" nonzero: %.2f%s\"", "%", "(", "(", "defs", "*", "100", "/", "len", "(", "definitions", ")", ")", ",", "'%'", ")", ")", "\n", "print", "(", "\" avg: %d\"", "%", "int", "(", "np", ".", "mean", "(", "def_lens", ")", ")", ")", "\n", "print", "(", "\" max: %d\"", "%", "int", "(", "np", ".", "max", "(", "def_lens", ")", ")", ")", "\n", "print", "(", "\" min: %d\"", "%", "int", "(", "np", ".", "min", "(", "def_lens", ")", ")", ")", "\n", "print", "(", "\"==================================\"", ")", "\n", "if", "args", ".", "rel_emb", ":", "\n", "                ", "rel_arr", "=", "relations", "\n", "", "if", "args", ".", "def_emb", ":", "\n", "                ", "def_arr", "=", "definitions", "\n", "", "", "", "return", "char_arr", ",", "rel_arr", ",", "def_arr", "\n", "", ""]]}