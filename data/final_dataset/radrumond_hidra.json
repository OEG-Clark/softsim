{"home.repos.pwc.inspect_result.radrumond_hidra.None.train.train": [[6, 109], ["tensorflow.Session", "tf.Session.run", "data_sampler.sample_Task", "m.loadWeights", "print", "time.time", "range", "m.saveWeights", "tensorflow.global_variables_initializer", "data_sampler.sample_Task", "next", "tf.Session.run", "losses.append", "lossesB.append", "buffer.append", "numpy.argmax", "numpy.argmax", "range", "temp_yp.append", "temp_ypn.append", "str", "len", "tf.Session.run", "tf.Session.run", "numpy.reshape", "numpy.reshape", "aux.append", "numpy.mean", "print", "time.time", "print", "m.saveWeights", "int", "numpy.unique", "numpy.where", "numpy.mean", "range", "numpy.argmax", "next", "tf.Session.run", "lossestest.append", "lossesBtest.append", "buffertest.append", "temp_yptest.append", "tf.Session.run", "len", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.unique", "numpy.mean", "numpy.mean", "float", "time.time", "numpy.argmax", "numpy.argmax", "numpy.argmax"], "function", ["home.repos.pwc.inspect_result.radrumond_hidra.data_gen.omni_gen.OmniChar_Gen.sample_Task", "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.loadWeights", "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.saveWeights", "home.repos.pwc.inspect_result.radrumond_hidra.data_gen.omni_gen.OmniChar_Gen.sample_Task", "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.saveWeights"], ["def", "train", "(", "m", ",", "mt", ",", "# m is the model foir training, mt is the model for testing", "\n", "data_sampler", ",", "# Creates the data generator for training and testing", "\n", "min_classes", ",", "# minimum amount of classes", "\n", "max_classes", ",", "# maximum    ||  ||   ||", "\n", "train_shots", ",", "# number of samples per class (train)", "\n", "test_shots", ",", "# number of samples per class (test)", "\n", "meta_batch", ",", "# Number of tasks", "\n", "meta_iters", ",", "# Number of iterations", "\n", "test_iters", ",", "# Iterations in Test", "\n", "train_step", ",", "\n", "name", ")", ":", "# Experiment name for experiments", "\n", "\n", "    ", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "# bnorms = [v for v in tf.global_variables() if \"bn\" in v.name]", "\n", "#---------Performance Tracking lists---------------------------------------", "\n", "losses", "=", "[", "]", "\n", "temp_yp", "=", "[", "]", "\n", "temp_ypn", "=", "[", "]", "\n", "nls", "=", "[", "]", "\n", "aps", "=", "[", "]", "\n", "buffer", "=", "[", "]", "\n", "lossesB", "=", "[", "]", "\n", "#--------------------------------------------------------------------------", "\n", "\n", "#---------Load train and test data-sets------------------------------------", "\n", "train_gen", "=", "data_sampler", ".", "sample_Task", "(", "meta_batch", ",", "min_classes", ",", "max_classes", "+", "1", ",", "train_shots", ",", "test_shots", ",", "\"train\"", ")", "\n", "if", "mt", "is", "not", "None", ":", "\n", "        ", "test_gen", "=", "data_sampler", ".", "sample_Task", "(", "meta_batch", ",", "min_classes", ",", "max_classes", "+", "1", ",", "train_shots", ",", "test_shots", ",", "\"test\"", ")", "\n", "", "m", ".", "loadWeights", "(", "sess", ",", "name", ",", "step", "=", "str", "(", "int", "(", "train_step", ")", ")", ",", "model_name", "=", "name", "+", "\".ckpt\"", ")", "\n", "#--------------------------------------------------------------------------", "\n", "\n", "#TRAIN LOOP", "\n", "print", "(", "\"Starting meta training:\"", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "for", "i", "in", "range", "(", "meta_iters", ")", ":", "\n", "\n", "        ", "xb1", ",", "yb1", ",", "xb2", ",", "yb2", "=", "next", "(", "train_gen", ")", "\n", "num_l", "=", "[", "len", "(", "np", ".", "unique", "(", "np", ".", "argmax", "(", "yb1", ",", "axis", "=", "-", "1", ")", ")", ")", "]", "\n", "\n", "if", "m", ".", "maml_n", "==", "2", ":", "# in case it uses hydra master node, it should re-assign the output nodes from the master", "\n", "            ", "sess", ".", "run", "(", "m", ".", "init_assign", ",", "feed_dict", "=", "{", "m", ".", "label_n", ":", "[", "5", "]", "}", ")", "\n", "", "l", ",", "_", ",", "vals", ",", "ps", "=", "sess", ".", "run", "(", "[", "m", ".", "train_loss", ",", "m", ".", "meta_op", ",", "m", ".", "val_losses", ",", "m", ".", "val_predictions", "]", ",", "feed_dict", "=", "{", "m", ".", "train_xb", ":", "xb1", ",", "\n", "m", ".", "train_yb", ":", "yb1", ",", "\n", "m", ".", "val_xb", ":", "xb2", ",", "\n", "m", ".", "val_yb", ":", "yb2", ",", "\n", "m", ".", "label_n", ":", "num_l", "}", ")", "\n", "if", "m", ".", "maml_n", "==", "2", ":", "# in case it uses hydra master node, it should update the master", "\n", "            ", "sess", ".", "run", "(", "m", ".", "final_assign", ",", "feed_dict", "=", "{", "m", ".", "label_n", ":", "num_l", "}", ")", "\n", "\n", "", "losses", ".", "append", "(", "vals", ")", "\n", "lossesB", ".", "append", "(", "vals", ")", "\n", "buffer", ".", "append", "(", "l", ")", "\n", "\n", "#Calculate accuaracies", "\n", "aux", "=", "[", "]", "\n", "tmp_pred", "=", "np", ".", "argmax", "(", "np", ".", "reshape", "(", "ps", "[", "-", "1", "]", ",", "[", "-", "1", ",", "num_l", "[", "0", "]", "]", ")", ",", "axis", "=", "-", "1", ")", "\n", "tmp_true", "=", "np", ".", "argmax", "(", "np", ".", "reshape", "(", "yb2", ",", "[", "-", "1", ",", "num_l", "[", "0", "]", "]", ")", ",", "axis", "=", "-", "1", ")", "\n", "for", "ccci", "in", "range", "(", "num_l", "[", "0", "]", ")", ":", "\n", "            ", "tmp_idx", "=", "np", ".", "where", "(", "tmp_true", "==", "ccci", ")", "[", "0", "]", "\n", "#print(tmp_idx)", "\n", "aux", ".", "append", "(", "np", ".", "mean", "(", "tmp_pred", "[", "tmp_idx", "]", "==", "tmp_true", "[", "tmp_idx", "]", ")", ")", "\n", "", "temp_yp", ".", "append", "(", "np", ".", "mean", "(", "tmp_pred", "==", "tmp_true", ")", ")", "\n", "temp_ypn", ".", "append", "(", "aux", ")", "\n", "\n", "#EVALUATE and PRINT", "\n", "if", "i", "%", "100", "==", "0", ":", "\n", "            ", "testString", "=", "\"\"", "\n", "#If we give a test model, it will test using the weights from train", "\n", "if", "mt", "is", "not", "None", "and", "i", "%", "1000", "==", "0", ":", "\n", "                ", "lossestest", "=", "[", "]", "\n", "buffertest", "=", "[", "]", "\n", "lossesBtest", "=", "[", "]", "\n", "temp_yptest", "=", "[", "]", "\n", "for", "z", "in", "range", "(", "100", ")", ":", "\n", "                    ", "if", "m", ".", "maml_n", "==", "2", ":", "\n", "                        ", "sess", ".", "run", "(", "mt", ".", "init_assign", ",", "feed_dict", "=", "{", "mt", ".", "label_n", ":", "[", "5", "]", "}", ")", "\n", "", "xb1", ",", "yb1", ",", "xb2", ",", "yb2", "=", "next", "(", "test_gen", ")", "\n", "num_l", "=", "[", "len", "(", "np", ".", "unique", "(", "np", ".", "argmax", "(", "yb1", ",", "axis", "=", "-", "1", ")", ")", ")", "]", "\n", "l", ",", "vals", ",", "ps", "=", "sess", ".", "run", "(", "[", "mt", ".", "test_train_loss", ",", "mt", ".", "test_val_losses", ",", "mt", ".", "val_predictions", "]", ",", "feed_dict", "=", "{", "mt", ".", "train_xb", ":", "xb1", ",", "\n", "mt", ".", "train_yb", ":", "yb1", ",", "\n", "mt", ".", "val_xb", ":", "xb2", ",", "\n", "mt", ".", "val_yb", ":", "yb2", ",", "\n", "mt", ".", "label_n", ":", "num_l", "}", ")", "\n", "lossestest", ".", "append", "(", "vals", ")", "\n", "lossesBtest", ".", "append", "(", "vals", ")", "\n", "buffertest", ".", "append", "(", "l", ")", "\n", "temp_yptest", ".", "append", "(", "np", ".", "mean", "(", "np", ".", "argmax", "(", "ps", "[", "-", "1", "]", ",", "axis", "=", "-", "1", ")", "==", "np", ".", "argmax", "(", "yb2", ",", "axis", "=", "-", "1", ")", ")", ")", "\n", "\n", "", "testString", "=", "f\"\\n        TEST: TLoss {np.mean(buffertest):.3f} VLoss {np.mean(lossesBtest,axis=0)[-1]:.3f}, ACCURACY {np.mean(temp_yptest):.4f}\"", "\n", "", "print", "(", "f\"Epoch {i}: TLoss {np.mean(buffer):.4f}, VLoss {np.mean(lossesB,axis=0)[-1]:.4f},\"", ",", "\n", "f\"Accuracy {np.mean(temp_yp):.4}\"", ",", "f\", Per label acc: {[float('%.4f' % elem) for elem in aux]}\"", ",", "f\"Finished in {time.time()-start}s\"", ",", "testString", ")", "\n", "\n", "buffer", "=", "[", "]", "\n", "lossesB", "=", "[", "]", "\n", "temp_yp", "=", "[", "]", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "# f\"\\n TRUE: {yb2}\\n PRED: {ps}\")", "\n", "", "if", "i", "%", "5000", "==", "0", ":", "\n", "            ", "print", "(", "\"Saving...\"", ")", "\n", "m", ".", "saveWeights", "(", "sess", ",", "name", ",", "i", ",", "model_name", "=", "name", "+", "\".ckpt\"", ")", "\n", "\n", "", "", "m", ".", "saveWeights", "(", "sess", ",", "name", ",", "i", ",", "model_name", "=", "name", "+", "\".ckpt\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.radrumond_hidra.None.test.test": [[5, 55], ["tensorflow.Session", "tf.Session.run", "data_sampler.sample_Task", "print", "m.loadWeights", "range", "print", "tensorflow.global_variables_initializer", "next", "tf.Session.run", "losses.append", "lossesB.append", "buffer.append", "numpy.argmax", "range", "temp_yp.append", "str", "len", "tf.Session.run", "len", "all_accs.append", "print", "print", "int", "numpy.unique", "numpy.mean", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std", "numpy.argmax", "numpy.argmax", "numpy.mean", "numpy.mean", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.radrumond_hidra.data_gen.omni_gen.OmniChar_Gen.sample_Task", "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.loadWeights"], ["def", "test", "(", "m", ",", "data_sampler", ",", "\n", "eval_step", ",", "\n", "min_classes", ",", "\n", "max_classes", ",", "\n", "train_shots", ",", "\n", "test_shots", ",", "\n", "meta_batch", ",", "\n", "meta_iters", ",", "\n", "name", ")", ":", "\n", "\n", "    ", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "losses", "=", "[", "]", "\n", "\n", "temp_yp", "=", "[", "]", "\n", "aps", "=", "[", "]", "\n", "buffer", "=", "[", "]", "\n", "lossesB", "=", "[", "]", "\n", "\n", "train_gen", "=", "data_sampler", ".", "sample_Task", "(", "meta_batch", ",", "min_classes", ",", "max_classes", "+", "1", ",", "train_shots", ",", "test_shots", ",", "\"test\"", ")", "\n", "print", "(", "\"TEST MODE\"", ")", "\n", "m", ".", "loadWeights", "(", "sess", ",", "name", ",", "step", "=", "str", "(", "int", "(", "eval_step", ")", ")", ",", "model_name", "=", "name", "+", "\".ckpt\"", ")", "\n", "for", "i", "in", "range", "(", "meta_iters", ")", ":", "\n", "        ", "xb1", ",", "yb1", ",", "xb2", ",", "yb2", "=", "next", "(", "train_gen", ")", "\n", "num_l", "=", "[", "len", "(", "np", ".", "unique", "(", "np", ".", "argmax", "(", "yb1", ",", "axis", "=", "-", "1", ")", ")", ")", "]", "\n", "\n", "if", "m", ".", "maml_n", "==", "2", ":", "\n", "            ", "sess", ".", "run", "(", "m", ".", "init_assign", ",", "feed_dict", "=", "{", "m", ".", "label_n", ":", "[", "5", "]", "}", ")", "\n", "", "l", ",", "vals", ",", "ps", "=", "sess", ".", "run", "(", "[", "m", ".", "test_train_loss", ",", "m", ".", "test_val_losses", ",", "m", ".", "val_predictions", "]", ",", "feed_dict", "=", "{", "m", ".", "train_xb", ":", "xb1", ",", "\n", "m", ".", "train_yb", ":", "yb1", ",", "\n", "m", ".", "val_xb", ":", "xb2", ",", "\n", "m", ".", "val_yb", ":", "yb2", ",", "\n", "m", ".", "label_n", ":", "num_l", "}", ")", "\n", "\n", "losses", ".", "append", "(", "vals", ")", "\n", "lossesB", ".", "append", "(", "vals", ")", "\n", "buffer", ".", "append", "(", "l", ")", "\n", "\n", "true_vals", "=", "np", ".", "argmax", "(", "yb2", ",", "axis", "=", "-", "1", ")", "\n", "all_accs", "=", "[", "]", "\n", "for", "pred_epoch", "in", "range", "(", "len", "(", "ps", ")", ")", ":", "\n", "        \t", "all_accs", ".", "append", "(", "np", ".", "mean", "(", "np", ".", "argmax", "(", "ps", "[", "pred_epoch", "]", ",", "axis", "=", "-", "1", ")", "==", "true_vals", ")", ")", "\n", "", "temp_yp", ".", "append", "(", "all_accs", ")", "\n", "\n", "\n", "# if i%1==0:", "\n", "if", "i", "%", "50", "==", "0", ":", "\n", "            ", "print", "(", "f\"({i}/{meta_iters})\"", ")", "\n", "print", "(", "f\"Final: TLoss {np.mean(buffer)}, VLoss {np.mean(lossesB,axis=0)}\"", ",", "f\"Accuracy {np.mean(temp_yp,axis=0)}\"", ")", "\n", "", "", "print", "(", "f\"Final: TLoss {np.mean(buffer)}-{np.std(buffer)}, VLoss {np.mean(lossesB,axis=0)}-{np.std(lossesB,axis=0)}\"", ",", "f\"Accuracy {np.mean(temp_yp,axis=0)}-{np.std(temp_yp,axis=0)}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.None.args.boolean_string": [[13, 17], ["ValueError"], "function", ["None"], ["def", "boolean_string", "(", "s", ")", ":", "\n", "    ", "if", "s", "not", "in", "{", "'False'", ",", "'True'", "}", ":", "\n", "        ", "raise", "ValueError", "(", "'Not a valid boolean string'", ")", "\n", "", "return", "s", "==", "'True'", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.None.args.argument_parser": [[18, 63], ["int", "argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "vars", "time.time", "argparse.ArgumentParser.parse_args", "print", "os.system", "open", "print", "json.dump", "open", "json.load", "str"], "function", ["None"], ["", "def", "argument_parser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Get an argument parser for a training script.\n    \"\"\"", "\n", "file_time", "=", "int", "(", "time", ".", "time", "(", ")", ")", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", ".", "add_argument", "(", "'--arch'", ",", "help", "=", "'name architecture'", ",", "default", "=", "\"fcn\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "help", "=", "'random seed'", ",", "default", "=", "0", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--name'", ",", "help", "=", "'name add-on'", ",", "type", "=", "str", ",", "default", "=", "'Model_config-'", "+", "str", "(", "file_time", ")", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "help", "=", "'data set to evaluate on'", ",", "type", "=", "str", ",", "default", "=", "'Omniglot'", ")", "\n", "parser", ".", "add_argument", "(", "'--data_path'", ",", "help", "=", "'path to data folder'", ",", "type", "=", "str", ",", "default", "=", "'/home/'", ")", "\n", "parser", ".", "add_argument", "(", "'--config'", ",", "help", "=", "'json config file'", ",", "type", "=", "str", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint'", ",", "help", "=", "'checkpoint directory'", ",", "default", "=", "'model_checkpoint'", ")", "\n", "parser", ".", "add_argument", "(", "'--test'", ",", "help", "=", "'Testing or Not'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--testintrain'", ",", "help", "=", "'Testing during train or Not'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--min_classes'", ",", "help", "=", "'minimum number of classes for n-way'", ",", "default", "=", "2", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--max_classes'", ",", "help", "=", "'maximum (excluded) number of classes for n-way'", ",", "default", "=", "2", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--ttrain_shots'", ",", "help", "=", "'number of examples per class in meta train'", ",", "default", "=", "5", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--ttest_shots'", ",", "help", "=", "'number of examples per class in meta test'", ",", "default", "=", "15", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--etrain_shots'", ",", "help", "=", "'number of examples per class in meta train'", ",", "default", "=", "5", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--etest_shots'", ",", "help", "=", "'number of examples per class in meta test'", ",", "default", "=", "15", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--train_inner_K'", ",", "help", "=", "'number of inner gradient steps during meta training'", ",", "default", "=", "5", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--test_inner_K'", ",", "help", "=", "'number of inner gradient steps during meta testing'", ",", "default", "=", "5", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--learning_rate'", ",", "help", "=", "'Adam step size for inner training'", ",", "default", "=", "0.4", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--meta_step'", ",", "help", "=", "'meta-training step size'", ",", "default", "=", "0.01", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--meta_batch'", ",", "help", "=", "'meta-training batch size'", ",", "default", "=", "1", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--meta_iters'", ",", "help", "=", "'meta-training iterations'", ",", "default", "=", "70001", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--eval_iters'", ",", "help", "=", "'meta-training iterations'", ",", "default", "=", "2000", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--step'", ",", "help", "=", "'Checkpoint step to load'", ",", "default", "=", "59999", ",", "type", "=", "float", ")", "\n", "# python main_emb.py --meta_step 0.005 --meta_batch 8 --learning_rate 0.3 --test --checkpoint Model_config-1568818723", "\n", "\n", "args", "=", "vars", "(", "parser", ".", "parse_args", "(", ")", ")", "\n", "#os.system(\"mkdir -p \" + args['checkpoint'])", "\n", "if", "args", "[", "'config'", "]", "is", "None", ":", "\n", "        ", "args", "[", "'config'", "]", "=", "f\"{args['checkpoint']}/{args['name']}/{args['name']}.json\"", "\n", "print", "(", "args", "[", "'config'", "]", ")", "\n", "# os.system(\"mkdir -p \" + f\"{args['checkpoint']}\")", "\n", "os", ".", "system", "(", "\"mkdir -p \"", "+", "f\"{args['checkpoint']}/{args['name']}\"", ")", "\n", "with", "open", "(", "args", "[", "'config'", "]", ",", "'w'", ")", "as", "write_file", ":", "\n", "            ", "print", "(", "\"Json Dumping...\"", ")", "\n", "json", ".", "dump", "(", "args", ",", "write_file", ")", "\n", "", "", "else", ":", "\n", "        ", "with", "open", "(", "args", "[", "'config'", "]", ",", "'r'", ")", "as", "open_file", ":", "\n", "            ", "args", "=", "json", ".", "load", "(", "open_file", ")", "\n", "", "", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.None.args.train_kwargs": [[64, 79], ["None"], "function", ["None"], ["", "def", "train_kwargs", "(", "parsed_args", ")", ":", "\n", "    ", "\"\"\"\n    Build kwargs for the train() function from the parsed\n    command-line arguments.\n    \"\"\"", "\n", "return", "{", "\n", "'min_classes'", ":", "parsed_args", ".", "min_classes", ",", "\n", "'max_classes'", ":", "parsed_args", ".", "max_classes", ",", "\n", "'train_shots'", ":", "parsed_args", ".", "ttrain_shots", ",", "\n", "'test_shots'", ":", "parsed_args", ".", "ttest_shots", ",", "\n", "'meta_batch'", ":", "parsed_args", ".", "meta_batch", ",", "\n", "'meta_iters'", ":", "parsed_args", ".", "meta_iters", ",", "\n", "'test_iters'", ":", "parsed_args", ".", "eval_iters", ",", "\n", "'train_step'", ":", "parsed_args", ".", "step", ",", "\n", "'name'", ":", "parsed_args", ".", "name", ",", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.None.args.test_kwargs": [[82, 96], ["None"], "function", ["None"], ["", "def", "test_kwargs", "(", "parsed_args", ")", ":", "\n", "    ", "\"\"\"\n    Build kwargs for the train() function from the parsed\n    command-line arguments.\n    \"\"\"", "\n", "return", "{", "\n", "'eval_step'", ":", "parsed_args", ".", "step", ",", "\n", "'min_classes'", ":", "parsed_args", ".", "min_classes", ",", "\n", "'max_classes'", ":", "parsed_args", ".", "max_classes", ",", "\n", "'train_shots'", ":", "parsed_args", ".", "etrain_shots", ",", "\n", "'test_shots'", ":", "parsed_args", ".", "etest_shots", ",", "\n", "'meta_batch'", ":", "parsed_args", ".", "meta_batch", ",", "\n", "'meta_iters'", ":", "parsed_args", ".", "eval_iters", ",", "\n", "'name'", ":", "parsed_args", ".", "name", ",", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.data_gen.omni_gen.MiniImgNet_Gen.__init__": [[10, 22], ["os.listdir", "os.listdir", "os.listdir"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", "=", "\"/tmp/data/miniimagenet\"", ",", "data_path", "=", "None", ")", ":", "\n", "\n", "        ", "if", "data_path", "is", "None", ":", "\n", "            ", "self", ".", "path", "=", "path", "\n", "self", ".", "train_paths", "=", "[", "\"train/\"", "+", "x", "for", "x", "in", "os", ".", "listdir", "(", "path", "+", "\"/train\"", ")", "]", "\n", "self", ".", "test_paths", "=", "[", "\"test/\"", "+", "x", "for", "x", "in", "os", ".", "listdir", "(", "path", "+", "\"/test\"", ")", "]", "\n", "self", ".", "val_paths", "=", "[", "\"val/\"", "+", "x", "for", "x", "in", "os", ".", "listdir", "(", "path", "+", "\"/val\"", ")", "]", "\n", "\n", "", "self", ".", "data_path", "=", "data_path", "\n", "self", ".", "meta_train", "=", "None", "\n", "self", ".", "meta_test", "=", "None", "\n", "self", ".", "meta_val", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.data_gen.omni_gen.MiniImgNet_Gen.sample_Task": [[24, 118], ["print", "print", "ValueError", "numpy.random.randint", "range", "enumerate", "numpy.random.choice", "enumerate", "numpy.array", "numpy.array", "numpy.reshape", "numpy.reshape", "meta_train_x.append", "meta_train_y.append", "meta_test_x.append", "meta_test_y.append", "meta_data.append", "enumerate", "ValueError", "range", "numpy.random.choice", "numpy.reshape.append", "numpy.reshape.append", "train_y.append", "test_y.append", "numpy.eye", "numpy.eye", "omni_gen.unison_shuffled_copies", "omni_gen.unison_shuffled_copies", "numpy.array", "meta_data.append", "enumerate", "numpy.array", "len", "len", "len", "numpy.reshape().astype", "len", "numpy.reshape().astype", "omni_gen.loadImgDir", "numpy.array", "meta_data.append", "numpy.ones", "numpy.ones", "omni_gen.loadImgDir", "numpy.array", "numpy.reshape", "numpy.reshape", "omni_gen.loadImgDir", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.radrumond_hidra.data_gen.omni_gen.unison_shuffled_copies", "home.repos.pwc.inspect_result.radrumond_hidra.data_gen.omni_gen.unison_shuffled_copies", "home.repos.pwc.inspect_result.radrumond_hidra.data_gen.omni_gen.loadImgDir", "home.repos.pwc.inspect_result.radrumond_hidra.data_gen.omni_gen.loadImgDir", "home.repos.pwc.inspect_result.radrumond_hidra.data_gen.omni_gen.loadImgDir"], ["", "def", "sample_Task", "(", "self", ",", "mb_size", ",", "min_class", ",", "max_class", ",", "train_size", ",", "test_size", ",", "training", "=", "\"train\"", ",", "shuffle", "=", "True", ")", ":", "\n", "\n", "        ", "print", "(", "'Loading MiniImagenet data...'", ")", "\n", "if", "training", "==", "\"train\"", ":", "\n", "            ", "if", "self", ".", "meta_train", "is", "None", ":", "\n", "                ", "meta_data", "=", "[", "]", "\n", "for", "idx", ",", "im_class", "in", "enumerate", "(", "self", ".", "train_paths", ")", ":", "\n", "                    ", "meta_data", ".", "append", "(", "np", ".", "array", "(", "loadImgDir", "(", "self", ".", "path", "+", "\"/\"", "+", "im_class", ",", "[", "84", ",", "84", "]", ",", "rgb", "=", "True", ")", ")", ")", "\n", "", "self", ".", "meta_train", "=", "meta_data", "\n", "", "else", ":", "\n", "                ", "meta_data", "=", "self", ".", "meta_train", "\n", "\n", "\n", "", "", "elif", "training", "==", "\"val\"", ":", "\n", "            ", "if", "self", ".", "meta_val", "is", "None", ":", "\n", "                ", "meta_data", "=", "[", "]", "\n", "for", "idx", ",", "im_class", "in", "enumerate", "(", "self", ".", "val_paths", ")", ":", "\n", "#                 print(idx)", "\n", "                    ", "meta_data", ".", "append", "(", "np", ".", "array", "(", "loadImgDir", "(", "self", ".", "path", "+", "\"/\"", "+", "im_class", ",", "[", "84", ",", "84", "]", ",", "rgb", "=", "True", ")", ")", ")", "\n", "", "self", ".", "meta_val", "=", "meta_data", "\n", "", "else", ":", "\n", "                ", "meta_data", "=", "self", ".", "meta_val", "\n", "\n", "\n", "", "", "elif", "training", "==", "\"test\"", ":", "\n", "            ", "if", "self", ".", "meta_test", "is", "None", ":", "\n", "                ", "meta_data", "=", "[", "]", "\n", "for", "idx", ",", "im_class", "in", "enumerate", "(", "self", ".", "test_paths", ")", ":", "\n", "#                 print(idx)", "\n", "                    ", "meta_data", ".", "append", "(", "np", ".", "array", "(", "loadImgDir", "(", "self", ".", "path", "+", "\"/\"", "+", "im_class", ",", "[", "84", ",", "84", "]", ",", "rgb", "=", "True", ")", ")", ")", "\n", "", "self", ".", "meta_test", "=", "meta_data", "\n", "", "else", ":", "\n", "                ", "meta_data", "=", "self", ".", "meta_test", "\n", "\n", "", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Training needs to be train, val or test\"", ")", "\n", "", "print", "(", "f'Finished loading MiniImagenet data: {np.array(meta_data).shape}'", ")", "\n", "\n", "if", "min_class", "<", "2", ":", "\n", "            ", "raise", "ValueError", "(", "\"Minimum number of classes must be >=2\"", ")", "\n", "\n", "\n", "\n", "", "while", "True", ":", "\n", "\n", "            ", "meta_train_x", "=", "[", "]", "\n", "meta_train_y", "=", "[", "]", "\n", "meta_test_x", "=", "[", "]", "\n", "meta_test_y", "=", "[", "]", "\n", "\n", "# sample fixed number classes for a meta batch", "\n", "nr_classes", "=", "np", ".", "random", ".", "randint", "(", "min_class", ",", "max_class", ")", "\n", "\n", "\n", "for", "mb", "in", "range", "(", "mb_size", ")", ":", "\n", "\n", "# select which classes in the meta batch", "\n", "                ", "classes", "=", "np", ".", "random", ".", "choice", "(", "range", "(", "len", "(", "meta_data", ")", ")", ",", "nr_classes", ",", "replace", "=", "False", ")", "\n", "train_x", "=", "[", "]", "\n", "train_y", "=", "[", "]", "\n", "test_x", "=", "[", "]", "\n", "test_y", "=", "[", "]", "\n", "\n", "for", "label_nr", ",", "cl", "in", "enumerate", "(", "classes", ")", ":", "\n", "\n", "                    ", "images", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "meta_data", "[", "cl", "]", ")", ",", "train_size", "+", "test_size", ",", "False", ")", "\n", "train_imgs", "=", "images", "[", ":", "train_size", "]", "\n", "test_imgs", "=", "images", "[", "train_size", ":", "]", "\n", "\n", "train_x", ".", "append", "(", "meta_data", "[", "cl", "]", "[", "train_imgs", "]", ")", "\n", "test_x", ".", "append", "(", "meta_data", "[", "cl", "]", "[", "test_imgs", "]", ")", "\n", "\n", "train_y", ".", "append", "(", "np", ".", "ones", "(", "train_size", ")", "*", "label_nr", ")", "\n", "test_y", ".", "append", "(", "np", ".", "ones", "(", "test_size", ")", "*", "label_nr", ")", "\n", "\n", "\n", "", "train_x", "=", "np", ".", "array", "(", "train_x", ")", "\n", "train_y", "=", "np", ".", "eye", "(", "len", "(", "classes", ")", ")", "[", "np", ".", "reshape", "(", "np", ".", "array", "(", "train_y", ")", ",", "-", "1", ")", ".", "astype", "(", "int", ")", "]", "\n", "test_x", "=", "np", ".", "array", "(", "test_x", ")", "\n", "test_y", "=", "np", ".", "eye", "(", "len", "(", "classes", ")", ")", "[", "np", ".", "reshape", "(", "np", ".", "array", "(", "test_y", ")", ",", "-", "1", ")", ".", "astype", "(", "int", ")", "]", "\n", "\n", "train_x", "=", "np", ".", "reshape", "(", "train_x", ",", "[", "-", "1", ",", "84", ",", "84", ",", "3", "]", ")", "\n", "test_x", "=", "np", ".", "reshape", "(", "test_x", ",", "[", "-", "1", ",", "84", ",", "84", ",", "3", "]", ")", "\n", "\n", "if", "shuffle", ":", "\n", "                    ", "train_x", ",", "train_y", "=", "unison_shuffled_copies", "(", "train_x", ",", "train_y", ")", "\n", "test_x", ",", "test_y", "=", "unison_shuffled_copies", "(", "test_x", ",", "test_y", ")", "\n", "\n", "", "meta_train_x", ".", "append", "(", "train_x", ")", "\n", "meta_train_y", ".", "append", "(", "train_y", ")", "\n", "meta_test_x", ".", "append", "(", "test_x", ")", "\n", "meta_test_y", ".", "append", "(", "test_y", ")", "\n", "# print('YIEEEEEEELDING')", "\n", "", "yield", "meta_train_x", ",", "meta_train_y", ",", "meta_test_x", ",", "meta_test_y", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.data_gen.omni_gen.OmniChar_Gen.__init__": [[124, 161], ["print", "enumerate", "numpy.concatenate", "print", "len", "range", "os.listdir", "omni_gen.OmniChar_Gen.meta_data.append", "list", "numpy.random.shuffle", "print", "list", "os.listdir", "len", "print", "os.listdir", "data.append", "range", "os.listdir", "os.listdir", "c.append", "len", "set", "set", "omni_gen.readImg", "list", "len", "range", "len"], "methods", ["home.repos.pwc.inspect_result.radrumond_hidra.data_gen.omni_gen.readImg"], ["    ", "def", "__init__", "(", "self", ",", "path", "=", "\"/tmp/data/omniglot\"", ",", "data_path", "=", "None", ",", "test_idx", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "path", "=", "path", "\n", "self", ".", "tasks", "=", "[", "\"/images_background/\"", "+", "x", "for", "x", "in", "os", ".", "listdir", "(", "path", "+", "\"/images_background\"", ")", "]", "+", "[", "\"/images_evaluation/\"", "+", "x", "for", "x", "in", "os", ".", "listdir", "(", "path", "+", "\"/images_evaluation\"", ")", "]", "\n", "\n", "\n", "self", ".", "lens", "=", "{", "}", "\n", "for", "task", "in", "self", ".", "tasks", ":", "\n", "            ", "self", ".", "lens", "[", "task", "]", "=", "len", "(", "os", ".", "listdir", "(", "self", ".", "path", "+", "task", ")", ")", "\n", "\n", "", "self", ".", "meta_data", "=", "[", "]", "\n", "print", "(", "\"Loading Omniglot data\"", ")", "\n", "for", "idx", ",", "task", "in", "enumerate", "(", "range", "(", "len", "(", "self", ".", "tasks", ")", ")", ")", ":", "\n", "            ", "if", "idx", "%", "10", "==", "0", ":", "\n", "                ", "print", "(", "f\"Loading tasks {idx}/{len(self.tasks)}\"", ")", "\n", "", "data", "=", "[", "]", "\n", "for", "char", "in", "os", ".", "listdir", "(", "self", ".", "path", "+", "self", ".", "tasks", "[", "task", "]", ")", ":", "\n", "                ", "c", "=", "[", "]", "\n", "\n", "for", "img", "in", "os", ".", "listdir", "(", "self", ".", "path", "+", "self", ".", "tasks", "[", "task", "]", "+", "\"/\"", "+", "char", ")", ":", "\n", "                    ", "c", ".", "append", "(", "readImg", "(", "self", ".", "path", "+", "self", ".", "tasks", "[", "task", "]", "+", "\"/\"", "+", "char", "+", "\"/\"", "+", "img", ")", ")", "\n", "\n", "", "data", ".", "append", "(", "c", ")", "\n", "\n", "", "self", ".", "meta_data", ".", "append", "(", "data", ")", "\n", "", "self", ".", "meta_data", "=", "np", ".", "concatenate", "(", "self", ".", "meta_data", ")", "\n", "\n", "print", "(", "\"Finished loading data\"", ")", "\n", "if", "test_idx", "==", "None", ":", "\n", "            ", "self", ".", "train_idx", "=", "list", "(", "range", "(", "len", "(", "self", ".", "meta_data", ")", ")", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "self", ".", "train_idx", ")", "\n", "self", ".", "test_idx", "=", "self", ".", "train_idx", "[", "1200", ":", "]", "\n", "self", ".", "train_idx", "=", "self", ".", "train_idx", "[", ":", "1200", "]", "\n", "print", "(", "\"Test_idx:\"", ",", "self", ".", "test_idx", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "test_idx", "=", "test_idx", "\n", "self", ".", "train_idx", "=", "list", "(", "set", "(", "list", "(", "range", "(", "len", "(", "self", ".", "meta_data", ")", ")", ")", ")", "-", "set", "(", "self", ".", "test_idx", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.data_gen.omni_gen.OmniChar_Gen.sample_Task": [[163, 227], ["ValueError", "idx.copy", "numpy.random.shuffle", "numpy.random.randint", "range", "ValueError", "numpy.random.choice", "enumerate", "numpy.array", "numpy.array", "numpy.reshape", "numpy.reshape", "meta_train_x.append", "meta_train_y.append", "meta_test_x.append", "meta_test_y.append", "numpy.random.choice", "numpy.reshape.append", "numpy.reshape.append", "train_y.append", "test_y.append", "numpy.eye", "numpy.eye", "omni_gen.unison_shuffled_copies", "omni_gen.unison_shuffled_copies", "range", "len", "numpy.reshape().astype", "len", "numpy.reshape().astype", "numpy.ones", "numpy.ones", "numpy.reshape", "numpy.reshape", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.radrumond_hidra.data_gen.omni_gen.unison_shuffled_copies", "home.repos.pwc.inspect_result.radrumond_hidra.data_gen.omni_gen.unison_shuffled_copies"], ["", "", "def", "sample_Task", "(", "self", ",", "mb_size", ",", "min_class", ",", "max_class", ",", "train_size", ",", "test_size", ",", "training", "=", "\"train\"", ",", "shuffle", "=", "True", ")", ":", "\n", "\n", "        ", "if", "training", "==", "\"train\"", ":", "\n", "            ", "idx", "=", "self", ".", "train_idx", "\n", "", "elif", "training", "==", "\"test\"", ":", "\n", "            ", "idx", "=", "self", ".", "test_idx", "\n", "", "else", ":", "\n", "        \t", "raise", "ValueError", "(", "\"Omniglot only supports train and test for training param\"", ")", "\n", "\n", "", "if", "min_class", "<", "2", ":", "\n", "            ", "raise", "ValueError", "(", "\"Minimum number of classes must be >=2\"", ")", "\n", "## We can remove this later and make it dynamic", "\n", "\n", "", "while", "True", ":", "\n", "\n", "            ", "image_idx", "=", "idx", ".", "copy", "(", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "image_idx", ")", "\n", "\n", "meta_train_x", "=", "[", "]", "\n", "meta_train_y", "=", "[", "]", "\n", "meta_test_x", "=", "[", "]", "\n", "meta_test_y", "=", "[", "]", "\n", "\n", "# Roll number of classes in the mb", "\n", "nr_classes", "=", "np", ".", "random", ".", "randint", "(", "min_class", ",", "max_class", ")", "\n", "\n", "for", "task", "in", "range", "(", "mb_size", ")", ":", "\n", "\n", "                ", "train_x", "=", "[", "]", "\n", "train_y", "=", "[", "]", "\n", "test_x", "=", "[", "]", "\n", "test_y", "=", "[", "]", "\n", "# Sample the characters for the task", "\n", "chars", "=", "np", ".", "random", ".", "choice", "(", "image_idx", ",", "nr_classes", ",", "False", ")", "\n", "\n", "# Sample the shots for each character", "\n", "for", "label_nr", ",", "char", "in", "enumerate", "(", "chars", ")", ":", "\n", "                    ", "images", "=", "np", ".", "random", ".", "choice", "(", "range", "(", "20", ")", ",", "train_size", "+", "test_size", ",", "False", ")", "\n", "train_imgs", "=", "images", "[", ":", "train_size", "]", "\n", "test_imgs", "=", "images", "[", "train_size", ":", "]", "\n", "\n", "train_x", ".", "append", "(", "self", ".", "meta_data", "[", "char", "]", "[", "train_imgs", "]", ")", "\n", "test_x", ".", "append", "(", "self", ".", "meta_data", "[", "char", "]", "[", "test_imgs", "]", ")", "\n", "\n", "train_y", ".", "append", "(", "np", ".", "ones", "(", "train_size", ")", "*", "label_nr", ")", "\n", "test_y", ".", "append", "(", "np", ".", "ones", "(", "test_size", ")", "*", "label_nr", ")", "\n", "\n", "", "train_x", "=", "np", ".", "array", "(", "train_x", ")", "\n", "train_y", "=", "np", ".", "eye", "(", "len", "(", "chars", ")", ")", "[", "np", ".", "reshape", "(", "np", ".", "array", "(", "train_y", ")", ",", "-", "1", ")", ".", "astype", "(", "int", ")", "]", "\n", "test_x", "=", "np", ".", "array", "(", "test_x", ")", "\n", "test_y", "=", "np", ".", "eye", "(", "len", "(", "chars", ")", ")", "[", "np", ".", "reshape", "(", "np", ".", "array", "(", "test_y", ")", ",", "-", "1", ")", ".", "astype", "(", "int", ")", "]", "\n", "\n", "train_x", "=", "np", ".", "reshape", "(", "train_x", ",", "[", "-", "1", ",", "28", ",", "28", ",", "1", "]", ")", "\n", "test_x", "=", "np", ".", "reshape", "(", "test_x", ",", "[", "-", "1", ",", "28", ",", "28", ",", "1", "]", ")", "\n", "if", "shuffle", ":", "\n", "                    ", "train_x", ",", "train_y", "=", "unison_shuffled_copies", "(", "train_x", ",", "train_y", ")", "\n", "test_x", ",", "test_y", "=", "unison_shuffled_copies", "(", "test_x", ",", "test_y", ")", "\n", "\n", "", "meta_train_x", ".", "append", "(", "train_x", ")", "\n", "meta_train_y", ".", "append", "(", "train_y", ")", "\n", "meta_test_x", ".", "append", "(", "test_x", ")", "\n", "meta_test_y", ".", "append", "(", "test_y", ")", "\n", "\n", "", "yield", "meta_train_x", ",", "meta_train_y", ",", "meta_test_x", ",", "meta_test_y", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.data_gen.omni_gen.getOrder": [[228, 240], ["numpy.random.randint", "int", "min"], "function", ["None"], ["", "", "", "def", "getOrder", "(", "minClass", ",", "maxClass", ",", "mb_size", ",", "number_chars", "=", "1200", ")", ":", "\n", "# gives a list integers between minClass and maxClass that sum up to 1200, ", "\n", "    ", "lens", "=", "[", "]", "\n", "sums", "=", "0", "\n", "while", "sums", "<=", "number_chars", "-", "minClass", "*", "mb_size", ":", "\n", "        ", "maxV", "=", "int", "(", "(", "number_chars", "-", "sums", ")", "/", "mb_size", ")", "+", "1", "\n", "\n", "n", "=", "np", ".", "random", ".", "randint", "(", "minClass", ",", "min", "(", "maxV", ",", "maxClass", ")", ")", "\n", "\n", "lens", "+=", "[", "n", "]", "*", "mb_size", "\n", "sums", "=", "sums", "+", "(", "n", "*", "mb_size", ")", "\n", "", "return", "lens", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.data_gen.omni_gen.readImg": [[241, 260], ["cv2.imread", "cv2.resize().astype", "numpy.max", "cv2.resize", "len", "numpy.reshape", "print", "print", "print"], "function", ["None"], ["", "def", "readImg", "(", "path", ",", "size", "=", "[", "28", ",", "28", "]", ",", "rgb", "=", "False", ")", ":", "\n", "\n", "    ", "img", "=", "cv2", ".", "imread", "(", "path", ")", "\n", "img", "=", "cv2", ".", "resize", "(", "img", ",", "(", "size", "[", "0", "]", ",", "size", "[", "1", "]", ")", ")", ".", "astype", "(", "float", ")", "\n", "if", "np", ".", "max", "(", "img", ")", ">", "1.0", ":", "\n", "        ", "img", "/=", "255.", "\n", "\n", "", "if", "not", "rgb", ":", "\n", "        ", "return", "img", "[", ":", ",", ":", ",", ":", "1", "]", "\n", "", "else", ":", "\n", "\n", "        ", "if", "len", "(", "img", ".", "shape", ")", "==", "3", ":", "\n", "            ", "if", "img", ".", "shape", "[", "-", "1", "]", "!=", "3", ":", "\n", "                ", "print", "(", "'ASFASFASFAS'", ")", "\n", "print", "(", "img", ".", "shape", ")", "\n", "print", "(", "path", ")", "\n", "", "return", "img", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "reshape", "(", "[", "img", ",", "img", ",", "img", "]", ",", "[", "size", "[", "0", "]", ",", "size", "[", "1", "]", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.data_gen.omni_gen.unison_shuffled_copies": [[262, 266], ["numpy.random.permutation", "len", "len", "len"], "function", ["None"], ["", "", "", "def", "unison_shuffled_copies", "(", "a", ",", "b", ")", ":", "\n", "    ", "assert", "len", "(", "a", ")", "==", "len", "(", "b", ")", "\n", "p", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "a", ")", ")", "\n", "return", "a", "[", "p", "]", ",", "b", "[", "p", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.data_gen.omni_gen.loadImgDir": [[268, 276], ["os.listdir", "imgs.append", "omni_gen.readImg"], "function", ["home.repos.pwc.inspect_result.radrumond_hidra.data_gen.omni_gen.readImg"], ["", "def", "loadImgDir", "(", "path", ",", "size", ",", "rgb", ")", ":", "\n", "\n", "    ", "imgs", "=", "[", "]", "\n", "\n", "for", "img", "in", "os", ".", "listdir", "(", "path", ")", ":", "\n", "\n", "        ", "imgs", ".", "append", "(", "readImg", "(", "path", "+", "\"/\"", "+", "img", ",", "size", ",", "rgb", ")", ")", "\n", "", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml2.MAML.__init__": [[9, 21], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "train_lr", ",", "meta_lr", ",", "image_shape", ",", "isMIN", ",", "label_size", "=", "2", ")", ":", "\n", "        ", "self", ".", "train_lr", "=", "train_lr", "\n", "self", ".", "meta_lr", "=", "meta_lr", "\n", "self", ".", "image_shape", "=", "image_shape", "\n", "self", ".", "isMIN", "=", "isMIN", "\n", "self", ".", "saver", "=", "None", "\n", "self", ".", "label_size", "=", "label_size", "\n", "self", ".", "finals", "=", "64", "\n", "self", ".", "maml_n", "=", "2", "\n", "if", "isMIN", ":", "\n", "            ", "self", ".", "finals", "=", "800", "\n", "", "self", ".", "max_labels", "=", "label_size", "\n", "", "def", "build", "(", "self", ",", "K", ",", "meta_batchsz", ",", "mode", "=", "'train'", ")", ":", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml2.MAML.build": [[21, 112], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "maml2.MAML.dense_weights", "range", "tensorflow.map_fn", "maml2.MAML.init_assign.append", "maml2.MAML.init_assign.append", "maml2.MAML.forward", "tensorflow.losses.softmax_cross_entropy", "tensorflow.gradients", "dict", "dict", "maml2.MAML.forward", "tensorflow.losses.softmax_cross_entropy", "val_preds.append", "val_losses.append", "range", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer.compute_gradients", "tensorflow.train.AdamOptimizer.apply_gradients", "tensorflow.assign", "tensorflow.assign", "list", "zip", "zip", "tensorflow.losses.softmax_cross_entropy", "tensorflow.gradients", "dict", "dict", "maml2.MAML.forward", "tensorflow.losses.softmax_cross_entropy", "val_preds.append", "val_losses.append", "tensorflow.reduce_sum", "tensorflow.clip_by_norm", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.assign_add", "tensorflow.assign_add", "tensorflow.reduce_sum", "tensorflow.trainable_variables", "maml2.MAML.weights.values", "maml2.MAML.weights.keys", "maml2.MAML.weights.keys", "maml2.MAML.weights.keys", "maml2.MAML.forward", "list", "zip", "zip", "tensorflow.reduce_sum", "range", "maml2.MAML.build.ClipIfNotNone"], "methods", ["home.repos.pwc.inspect_result.radrumond_hidra.archs.hydra.Model.dense_weights", "home.repos.pwc.inspect_result.radrumond_hidra.archs.hydra.Model.forward", "home.repos.pwc.inspect_result.radrumond_hidra.archs.hydra.Model.forward", "home.repos.pwc.inspect_result.radrumond_hidra.archs.hydra.Model.forward", "home.repos.pwc.inspect_result.radrumond_hidra.archs.hydra.Model.forward"], ["", "def", "build", "(", "self", ",", "K", ",", "meta_batchsz", ",", "mode", "=", "'train'", ")", ":", "\n", "\n", "# Meta batch of tasks ", "\n", "        ", "self", ".", "train_xb", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "None", ",", "None", ",", "None", ",", "self", ".", "image_shape", "[", "-", "1", "]", "]", ")", "\n", "self", ".", "train_yb", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "None", ",", "None", "]", ")", "\n", "self", ".", "val_xb", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "None", ",", "None", ",", "None", ",", "self", ".", "image_shape", "[", "-", "1", "]", "]", ")", "\n", "self", ".", "val_yb", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "None", ",", "None", "]", ")", "\n", "self", ".", "label_n", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "None", ",", "name", "=", "\"num_labs\"", ")", "\n", "#Initialize weights", "\n", "self", ".", "weights", ",", "self", ".", "cells", "=", "self", ".", "dense_weights", "(", ")", "\n", "training", "=", "True", "if", "mode", "is", "'train'", "else", "False", "\n", "self", ".", "init_assign", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "max_labels", ")", ":", "\n", "            ", "self", ".", "init_assign", ".", "append", "(", "tf", ".", "assign", "(", "self", ".", "weights", "[", "'d_1w'", "+", "str", "(", "i", ")", "]", ",", "self", ".", "cells", "[", "'d_1'", "]", ")", ")", "\n", "self", ".", "init_assign", ".", "append", "(", "tf", ".", "assign", "(", "self", ".", "weights", "[", "'b_1w'", "+", "str", "(", "i", ")", "]", ",", "self", ".", "cells", "[", "'b_1'", "]", ")", ")", "\n", "\n", "# Handle one task update", "\n", "", "def", "meta_task", "(", "inputs", ")", ":", "\n", "\n", "            ", "train_x", ",", "train_y", ",", "val_x", ",", "val_y", "=", "inputs", "\n", "val_preds", ",", "val_losses", "=", "[", "]", ",", "[", "]", "\n", "\n", "train_pred", "=", "self", ".", "forward", "(", "train_x", ",", "self", ".", "weights", ",", "training", ")", "\n", "train_loss", "=", "tf", ".", "losses", ".", "softmax_cross_entropy", "(", "train_y", ",", "train_pred", ")", "\n", "\n", "grads", "=", "tf", ".", "gradients", "(", "train_loss", ",", "list", "(", "self", ".", "weights", ".", "values", "(", ")", ")", ")", "\n", "gvs", "=", "dict", "(", "zip", "(", "self", ".", "weights", ".", "keys", "(", ")", ",", "grads", ")", ")", "\n", "\n", "a", "=", "[", "self", ".", "weights", "[", "key", "]", "-", "self", ".", "train_lr", "*", "gvs", "[", "key", "]", "for", "key", "in", "self", ".", "weights", ".", "keys", "(", ")", "]", "\n", "#             for key in self.weights.keys():", "\n", "#                 print(key, gvs[key])", "\n", "fast_weights", "=", "dict", "(", "zip", "(", "self", ".", "weights", ".", "keys", "(", ")", ",", "a", ")", ")", "\n", "\n", "# Validation after each update", "\n", "val_pred", "=", "self", ".", "forward", "(", "val_x", ",", "fast_weights", ",", "training", ")", "\n", "val_loss", "=", "tf", ".", "losses", ".", "softmax_cross_entropy", "(", "val_y", ",", "val_pred", ")", "\n", "# record T0 pred and loss for meta-test", "\n", "val_preds", ".", "append", "(", "val_pred", ")", "\n", "val_losses", ".", "append", "(", "val_loss", ")", "\n", "\n", "# continue to build T1-TK steps graph", "\n", "for", "_", "in", "range", "(", "1", ",", "K", ")", ":", "\n", "\n", "# Update weights on train data of task t", "\n", "                ", "loss", "=", "tf", ".", "losses", ".", "softmax_cross_entropy", "(", "train_y", ",", "self", ".", "forward", "(", "train_x", ",", "fast_weights", ",", "training", ")", ")", "\n", "grads", "=", "tf", ".", "gradients", "(", "loss", ",", "list", "(", "fast_weights", ".", "values", "(", ")", ")", ")", "\n", "gvs", "=", "dict", "(", "zip", "(", "fast_weights", ".", "keys", "(", ")", ",", "grads", ")", ")", "\n", "fast_weights", "=", "dict", "(", "zip", "(", "fast_weights", ".", "keys", "(", ")", ",", "[", "fast_weights", "[", "key", "]", "-", "self", ".", "train_lr", "*", "gvs", "[", "key", "]", "for", "key", "in", "fast_weights", ".", "keys", "(", ")", "]", ")", ")", "\n", "\n", "# Evaluate validation data of task t", "\n", "val_pred", "=", "self", ".", "forward", "(", "val_x", ",", "fast_weights", ",", "training", ")", "\n", "val_loss", "=", "tf", ".", "losses", ".", "softmax_cross_entropy", "(", "val_y", ",", "val_pred", ")", "\n", "val_preds", ".", "append", "(", "val_pred", ")", "\n", "val_losses", ".", "append", "(", "val_loss", ")", "\n", "\n", "", "result", "=", "[", "train_pred", ",", "train_loss", ",", "val_preds", ",", "val_losses", "]", "\n", "\n", "return", "result", "\n", "\n", "", "out_dtype", "=", "[", "tf", ".", "float32", ",", "tf", ".", "float32", ",", "[", "tf", ".", "float32", "]", "*", "K", ",", "[", "tf", ".", "float32", "]", "*", "K", "]", "\n", "result", "=", "tf", ".", "map_fn", "(", "meta_task", ",", "elems", "=", "(", "self", ".", "train_xb", ",", "self", ".", "train_yb", ",", "self", ".", "val_xb", ",", "self", ".", "val_yb", ")", ",", "\n", "dtype", "=", "out_dtype", ",", "parallel_iterations", "=", "meta_batchsz", ",", "name", "=", "'map_fn'", ")", "\n", "train_pred_tasks", ",", "train_loss_tasks", ",", "val_preds_tasks", ",", "val_losses_tasks", "=", "result", "\n", "\n", "if", "mode", "is", "'train'", ":", "\n", "            ", "self", ".", "train_loss", "=", "train_loss", "=", "tf", ".", "reduce_sum", "(", "train_loss_tasks", ")", "/", "meta_batchsz", "\n", "self", ".", "val_losses", "=", "val_losses", "=", "[", "tf", ".", "reduce_sum", "(", "val_losses_tasks", "[", "j", "]", ")", "/", "meta_batchsz", "for", "j", "in", "range", "(", "K", ")", "]", "\n", "self", ".", "val_predictions", "=", "val_preds_tasks", "\n", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "meta_lr", ",", "name", "=", "'meta_optim'", ")", "\n", "# varLista = [vv for k,vv in self.weights.items()] + [v for v in tf.global_variables() if \"bn\" in v.name]", "\n", "gvs", "=", "optimizer", ".", "compute_gradients", "(", "self", ".", "val_losses", "[", "-", "1", "]", ")", "\n", "# print(gvs)", "\n", "def", "ClipIfNotNone", "(", "grad", ")", ":", "\n", "                ", "if", "grad", "is", "None", ":", "\n", "                    ", "return", "grad", "\n", "", "return", "tf", ".", "clip_by_norm", "(", "grad", ",", "10", ")", "\n", "", "gvs", "=", "[", "(", "ClipIfNotNone", "(", "grad", ")", ",", "var", ")", "for", "grad", ",", "var", "in", "gvs", "]", "\n", "self", ".", "meta_op", "=", "optimizer", ".", "apply_gradients", "(", "gvs", ")", "\n", "dSums", "=", "tf", ".", "reduce_sum", "(", "[", "self", ".", "weights", "[", "\"d_1w\"", "+", "str", "(", "i", ")", "]", "-", "self", ".", "cells", "[", "\"d_1\"", "]", "for", "i", "in", "range", "(", "self", ".", "max_labels", ")", "]", ",", "0", ")", "/", "tf", ".", "cast", "(", "self", ".", "label_n", "[", "0", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "bSums", "=", "tf", ".", "reduce_sum", "(", "[", "self", ".", "weights", "[", "\"b_1w\"", "+", "str", "(", "i", ")", "]", "-", "self", ".", "cells", "[", "\"b_1\"", "]", "for", "i", "in", "range", "(", "self", ".", "max_labels", ")", "]", ",", "0", ")", "/", "tf", ".", "cast", "(", "self", ".", "label_n", "[", "0", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "thishere", "=", "dSums", "\n", "self", ".", "final_assign", "=", "[", "tf", ".", "assign_add", "(", "self", ".", "cells", "[", "\"d_1\"", "]", ",", "dSums", ")", ",", "tf", ".", "assign_add", "(", "self", ".", "cells", "[", "\"b_1\"", "]", ",", "bSums", ")", "]", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "test_train_loss", "=", "train_loss", "=", "tf", ".", "reduce_sum", "(", "train_loss_tasks", ")", "/", "meta_batchsz", "\n", "self", ".", "test_val_losses", "=", "val_losses", "=", "[", "tf", ".", "reduce_sum", "(", "val_losses_tasks", "[", "j", "]", ")", "/", "meta_batchsz", "for", "j", "in", "range", "(", "K", ")", "]", "\n", "self", ".", "val_predictions", "=", "val_preds_tasks", "\n", "\n", "\n", "", "self", ".", "saving_weights", "=", "[", "w", "for", "w", "in", "tf", ".", "trainable_variables", "(", ")", "if", "\"d_\"", "not", "in", "w", ".", "name", "or", "\"MASTER\"", "in", "w", ".", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml2.MAML.conv_layer": [[113, 118], ["tensorflow.variable_scope", "tensorflow.nn.conv2d", "tensorflow.nn.bias_add"], "methods", ["None"], ["", "def", "conv_layer", "(", "self", ",", "x", ",", "W", ",", "b", ",", "name", ",", "strides", "=", "1", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "x", "=", "tf", ".", "nn", ".", "conv2d", "(", "x", ",", "W", ",", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "'SAME'", ")", "\n", "x", "=", "tf", ".", "nn", ".", "bias_add", "(", "x", ",", "b", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml2.MAML.fc_layer": [[119, 124], ["tensorflow.variable_scope", "tensorflow.matmul", "tensorflow.nn.bias_add"], "methods", ["None"], ["", "def", "fc_layer", "(", "self", ",", "x", ",", "name", ",", "weights", "=", "None", ",", "biases", "=", "None", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "fc", "=", "tf", ".", "matmul", "(", "x", ",", "weights", ")", "\n", "fc", "=", "tf", ".", "nn", ".", "bias_add", "(", "fc", ",", "biases", ")", "\n", "return", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml2.MAML.loadWeights": [[125, 137], ["os.path.isfile", "tensorflow.train.Saver", "str", "saver.restore", "print", "print"], "methods", ["None"], ["", "", "def", "loadWeights", "(", "self", ",", "sess", ",", "name", ",", "step", "=", "0", ",", "modeldir", "=", "'./model_checkpoint/'", ",", "model_name", "=", "'model.ckpt'", ")", ":", "\n", "        ", "if", "self", ".", "saver", "==", "None", ":", "\n", "            ", "z", "=", "self", ".", "saving_weights", "\n", "#print(\"KEYS:\", z.keys())", "\n", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "z", ",", "max_to_keep", "=", "12", ")", "\n", "", "saver", "=", "self", ".", "saver", "\n", "checkpoint_path", "=", "modeldir", "+", "f\"{name}/\"", "+", "model_name", "+", "\"-\"", "+", "str", "(", "step", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "checkpoint_path", "+", "\".marker\"", ")", ":", "\n", "            ", "saver", ".", "restore", "(", "sess", ",", "checkpoint_path", ")", "\n", "print", "(", "'The checkpoint has been loaded.'", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "checkpoint_path", "+", "\".marker not found. Starting from scratch.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml2.MAML.saveWeights": [[138, 149], ["saver.save", "print", "open().close", "tensorflow.train.Saver", "os.path.exists", "os.makedirs", "open", "str"], "methods", ["None"], ["", "", "def", "saveWeights", "(", "self", ",", "sess", ",", "name", ",", "step", "=", "0", ",", "modeldir", "=", "'./model_checkpoint/'", ",", "model_name", "=", "'model.ckpt'", ")", ":", "\n", "        ", "if", "self", ".", "saver", "==", "None", ":", "\n", "            ", "z", "=", "self", ".", "saving_weights", "\n", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "z", ",", "max_to_keep", "=", "12", ")", "\n", "", "saver", "=", "self", ".", "saver", "\n", "checkpoint_path", "=", "modeldir", "+", "f\"{name}/\"", "+", "model_name", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "modeldir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "modeldir", ")", "\n", "", "saver", ".", "save", "(", "sess", ",", "checkpoint_path", ",", "global_step", "=", "step", ")", "\n", "print", "(", "'The checkpoint has been created.'", ")", "\n", "open", "(", "checkpoint_path", "+", "\"-\"", "+", "str", "(", "step", ")", "+", "\".marker\"", ",", "'a'", ")", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml2.MAML.dense_weights": [[151, 153], ["None"], "methods", ["None"], ["", "def", "dense_weights", "(", "self", ")", ":", "\n", "        ", "return", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "weights", ",", "training", ")", ":", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml2.MAML.forward": [[153, 155], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "weights", ",", "training", ")", ":", "\n", "        ", "return", "\n", "", "", ""]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.fcn.Model.__init__": [[9, 11], ["archs.maml.MAML.__init__"], "methods", ["home.repos.pwc.inspect_result.radrumond_hidra.archs.hydra.Model.__init__"], ["    ", "def", "__init__", "(", "self", ",", "train_lr", ",", "meta_lr", ",", "image_shape", ",", "isMIN", ",", "label_size", "=", "2", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "train_lr", ",", "meta_lr", ",", "image_shape", ",", "isMIN", ",", "label_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.fcn.Model.dense_weights": [[12, 59], ["tensorflow.contrib.layers.xavier_initializer", "print", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "print"], "methods", ["None"], ["", "def", "dense_weights", "(", "self", ")", ":", "\n", "        ", "weights", "=", "{", "}", "\n", "cells", "=", "{", "}", "\n", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", "\n", "print", "(", "\"Creating/loading Weights\"", ")", "\n", "divider", "=", "1", "\n", "inic", "=", "1", "\n", "filters", "=", "64", "\n", "finals", "=", "64", "\n", "if", "self", ".", "isMIN", ":", "\n", "            ", "divider", "=", "2", "\n", "inic", "=", "3", "\n", "finals", "=", "800", "\n", "filters", "=", "32", "\n", "", "with", "tf", ".", "variable_scope", "(", "'MAML'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "weights", "[", "'c_1'", "]", "=", "tf", ".", "get_variable", "(", "'c_1'", ",", "shape", "=", "(", "3", ",", "3", ",", "inic", ",", "filters", ")", ",", "initializer", "=", "initializer", ")", "\n", "weights", "[", "'c_2'", "]", "=", "tf", ".", "get_variable", "(", "'c_2'", ",", "shape", "=", "(", "3", ",", "3", ",", "filters", ",", "filters", ")", ",", "initializer", "=", "initializer", ")", "\n", "weights", "[", "'c_3'", "]", "=", "tf", ".", "get_variable", "(", "'c_3'", ",", "shape", "=", "(", "3", ",", "3", ",", "filters", ",", "filters", ")", ",", "initializer", "=", "initializer", ")", "\n", "weights", "[", "'c_4'", "]", "=", "tf", ".", "get_variable", "(", "'c_4'", ",", "shape", "=", "(", "3", ",", "3", ",", "filters", ",", "filters", ")", ",", "initializer", "=", "initializer", ")", "\n", "weights", "[", "'cb_1'", "]", "=", "tf", ".", "get_variable", "(", "'cb_1'", ",", "shape", "=", "(", "filters", ")", ",", "initializer", "=", "tf", ".", "initializers", ".", "constant", ")", "\n", "weights", "[", "'cb_2'", "]", "=", "tf", ".", "get_variable", "(", "'cb_2'", ",", "shape", "=", "(", "filters", ")", ",", "initializer", "=", "tf", ".", "initializers", ".", "constant", ")", "\n", "weights", "[", "'cb_3'", "]", "=", "tf", ".", "get_variable", "(", "'cb_3'", ",", "shape", "=", "(", "filters", ")", ",", "initializer", "=", "tf", ".", "initializers", ".", "constant", ")", "\n", "weights", "[", "'cb_4'", "]", "=", "tf", ".", "get_variable", "(", "'cb_4'", ",", "shape", "=", "(", "filters", ")", ",", "initializer", "=", "tf", ".", "initializers", ".", "constant", ")", "\n", "weights", "[", "'d_1'", "]", "=", "tf", ".", "get_variable", "(", "'d_1w'", ",", "[", "finals", ",", "self", ".", "label_size", "]", ",", "initializer", "=", "initializer", ")", "\n", "weights", "[", "'b_1'", "]", "=", "tf", ".", "get_variable", "(", "'d_1b'", ",", "[", "self", ".", "label_size", "]", ",", "initializer", "=", "tf", ".", "initializers", ".", "constant", ")", "\n", "\n", "\"\"\"weights['mean']     = tf.get_variable('mean',    [64],   initializer=tf.zeros_initializer())\n            weights['variance'] = tf.get_variable('variance',[64],   initializer=tf.ones_initializer() )\n            weights['offset']   = tf.get_variable('offset',  [64],   initializer=tf.zeros_initializer())\n            weights['scale']    = tf.get_variable('scale',   [64],   initializer=tf.ones_initializer() )\n            \n            weights['mean1']     = tf.get_variable('mean',    [64],   initializer=tf.zeros_initializer())\n            weights['variance1'] = tf.get_variable('variance',[64],   initializer=tf.ones_initializer() )\n            weights['offset1']   = tf.get_variable('offset',  [64],   initializer=tf.zeros_initializer())\n            weights['scale1']    = tf.get_variable('scale',   [64],   initializer=tf.ones_initializer() )\n            \n            weights['mean2']     = tf.get_variable('mean',    [64],   initializer=tf.zeros_initializer())\n            weights['variance2'] = tf.get_variable('variance',[64],   initializer=tf.ones_initializer() )\n            weights['offset2']   = tf.get_variable('offset',  [64],   initializer=tf.zeros_initializer())\n            weights['scale2']    = tf.get_variable('scale',   [64],   initializer=tf.ones_initializer() )\n            \n            weights['mean3']     = tf.get_variable('mean',    [64],   initializer=tf.zeros_initializer())\n            weights['variance3'] = tf.get_variable('variance',[64],   initializer=tf.ones_initializer() )\n            weights['offset3']   = tf.get_variable('offset',  [64],   initializer=tf.zeros_initializer())\n            weights['scale3']    = tf.get_variable('scale',   [64],   initializer=tf.ones_initializer() )\"\"\"", "\n", "print", "(", "\"Done Creating/loading Weights\"", ")", "\n", "", "return", "weights", ",", "cells", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.fcn.Model.forward": [[60, 88], ["fcn.Model.conv_layer", "tensorflow.layers.batch_normalization", "tensorflow.nn.relu", "fcn.Model.conv_layer", "tensorflow.layers.batch_normalization", "tensorflow.nn.relu", "fcn.Model.conv_layer", "tensorflow.layers.batch_normalization", "tensorflow.nn.relu", "fcn.Model.conv_layer", "tensorflow.layers.batch_normalization", "tensorflow.nn.relu", "fcn.Model.fc_layer", "tensorflow.layers.MaxPooling2D", "tensorflow.layers.MaxPooling2D", "tensorflow.layers.MaxPooling2D", "tensorflow.layers.MaxPooling2D", "tensorflow.layers.Flatten"], "methods", ["home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.conv_layer", "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.conv_layer", "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.conv_layer", "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.conv_layer", "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.fc_layer"], ["", "def", "forward", "(", "self", ",", "x", ",", "weights", ",", "training", ")", ":", "\n", "        ", "conv1", "=", "self", ".", "conv_layer", "(", "x", ",", "weights", "[", "\"c_1\"", "]", ",", "weights", "[", "\"cb_1\"", "]", ",", "\"conv1\"", ")", "\n", "conv1", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "conv1", ",", "name", "=", "\"bn1\"", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "\n", "conv1", "=", "tf", ".", "nn", ".", "relu", "(", "conv1", ")", "\n", "conv1", "=", "tf", ".", "layers", ".", "MaxPooling2D", "(", "2", ",", "2", ")", "(", "conv1", ")", "\n", "\n", "conv2", "=", "self", ".", "conv_layer", "(", "conv1", ",", "weights", "[", "\"c_2\"", "]", ",", "weights", "[", "\"cb_2\"", "]", ",", "\"conv2\"", ")", "\n", "conv2", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "conv2", ",", "name", "=", "\"bn2\"", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "\n", "conv2", "=", "tf", ".", "nn", ".", "relu", "(", "conv2", ")", "\n", "conv2", "=", "tf", ".", "layers", ".", "MaxPooling2D", "(", "2", ",", "2", ")", "(", "conv2", ")", "\n", "\n", "conv3", "=", "self", ".", "conv_layer", "(", "conv2", ",", "weights", "[", "\"c_3\"", "]", ",", "weights", "[", "\"cb_3\"", "]", ",", "\"conv3\"", ")", "\n", "conv3", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "conv3", ",", "name", "=", "\"bn3\"", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "\n", "conv3", "=", "tf", ".", "nn", ".", "relu", "(", "conv3", ")", "\n", "conv3", "=", "tf", ".", "layers", ".", "MaxPooling2D", "(", "2", ",", "2", ")", "(", "conv3", ")", "\n", "\n", "conv4", "=", "self", ".", "conv_layer", "(", "conv3", ",", "weights", "[", "\"c_4\"", "]", ",", "weights", "[", "\"cb_4\"", "]", ",", "\"conv4\"", ")", "\n", "conv4", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "conv4", ",", "name", "=", "\"bn4\"", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "\n", "conv4", "=", "tf", ".", "nn", ".", "relu", "(", "conv4", ")", "\n", "conv4", "=", "tf", ".", "layers", ".", "MaxPooling2D", "(", "2", ",", "2", ")", "(", "conv4", ")", "\n", "# print(conv4)", "\n", "#         bn = tf.squeeze(conv4,axis=(1,2))", "\n", "bn", "=", "tf", ".", "layers", ".", "Flatten", "(", ")", "(", "conv4", ")", "\n", "# tf.reshape(bn, [3244,234])", "\n", "\n", "fc1", "=", "self", ".", "fc_layer", "(", "bn", ",", "\"dense1\"", ",", "weights", "[", "\"d_1\"", "]", ",", "weights", "[", "\"b_1\"", "]", ")", "\n", "#         bn = tf.reshape(bn,[-1,])", "\n", "return", "fc1", "", "", "", ""]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.__init__": [[9, 20], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "train_lr", ",", "meta_lr", ",", "image_shape", ",", "isMIN", ",", "label_size", "=", "2", ")", ":", "\n", "        ", "self", ".", "train_lr", "=", "train_lr", "\n", "self", ".", "meta_lr", "=", "meta_lr", "\n", "self", ".", "image_shape", "=", "image_shape", "\n", "self", ".", "isMIN", "=", "isMIN", "\n", "self", ".", "saver", "=", "None", "\n", "self", ".", "label_size", "=", "label_size", "\n", "self", ".", "finals", "=", "64", "\n", "self", ".", "maml_n", "=", "1", "\n", "if", "isMIN", ":", "\n", "            ", "self", ".", "finals", "=", "800", "\n", "", "", "def", "build", "(", "self", ",", "K", ",", "meta_batchsz", ",", "mode", "=", "'train'", ")", ":", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.build": [[20, 95], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "maml.MAML.dense_weights", "tensorflow.map_fn", "tensorflow.trainable_variables", "maml.MAML.forward", "tensorflow.losses.softmax_cross_entropy", "tensorflow.gradients", "dict", "dict", "maml.MAML.forward", "tensorflow.losses.softmax_cross_entropy", "val_preds.append", "val_losses.append", "range", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer.compute_gradients", "tensorflow.train.AdamOptimizer.apply_gradients", "list", "zip", "zip", "tensorflow.losses.softmax_cross_entropy", "tensorflow.gradients", "dict", "dict", "maml.MAML.forward", "tensorflow.losses.softmax_cross_entropy", "val_preds.append", "val_losses.append", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "maml.MAML.weights.values", "maml.MAML.weights.keys", "maml.MAML.weights.keys", "maml.MAML.weights.keys", "maml.MAML.forward", "list", "zip", "zip", "tensorflow.reduce_sum", "range", "tensorflow.clip_by_norm", "tensorflow.reduce_sum", "range", "dict.values", "dict.keys", "dict.keys", "dict.keys"], "methods", ["home.repos.pwc.inspect_result.radrumond_hidra.archs.hydra.Model.dense_weights", "home.repos.pwc.inspect_result.radrumond_hidra.archs.hydra.Model.forward", "home.repos.pwc.inspect_result.radrumond_hidra.archs.hydra.Model.forward", "home.repos.pwc.inspect_result.radrumond_hidra.archs.hydra.Model.forward", "home.repos.pwc.inspect_result.radrumond_hidra.archs.hydra.Model.forward"], ["", "", "def", "build", "(", "self", ",", "K", ",", "meta_batchsz", ",", "mode", "=", "'train'", ")", ":", "\n", "\n", "# Meta batch of tasks ", "\n", "        ", "self", ".", "train_xb", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "None", ",", "None", ",", "None", ",", "self", ".", "image_shape", "[", "-", "1", "]", "]", ")", "\n", "self", ".", "train_yb", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "None", ",", "None", "]", ")", "\n", "self", ".", "val_xb", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "None", ",", "None", ",", "None", ",", "self", ".", "image_shape", "[", "-", "1", "]", "]", ")", "\n", "self", ".", "val_yb", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "None", ",", "None", "]", ")", "\n", "self", ".", "label_n", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "1", ",", "name", "=", "\"num_labs\"", ")", "\n", "#Initialize weights", "\n", "self", ".", "weights", ",", "self", ".", "cells", "=", "self", ".", "dense_weights", "(", ")", "\n", "training", "=", "True", "if", "mode", "is", "'train'", "else", "False", "\n", "\n", "# Handle one task update", "\n", "def", "meta_task", "(", "inputs", ")", ":", "\n", "            ", "train_x", ",", "train_y", ",", "val_x", ",", "val_y", "=", "inputs", "\n", "val_preds", ",", "val_losses", "=", "[", "]", ",", "[", "]", "\n", "\n", "train_pred", "=", "self", ".", "forward", "(", "train_x", ",", "self", ".", "weights", ",", "training", ")", "\n", "train_loss", "=", "tf", ".", "losses", ".", "softmax_cross_entropy", "(", "train_y", ",", "train_pred", ")", "\n", "\n", "grads", "=", "tf", ".", "gradients", "(", "train_loss", ",", "list", "(", "self", ".", "weights", ".", "values", "(", ")", ")", ")", "\n", "gvs", "=", "dict", "(", "zip", "(", "self", ".", "weights", ".", "keys", "(", ")", ",", "grads", ")", ")", "\n", "\n", "a", "=", "[", "self", ".", "weights", "[", "key", "]", "-", "self", ".", "train_lr", "*", "gvs", "[", "key", "]", "for", "key", "in", "self", ".", "weights", ".", "keys", "(", ")", "]", "\n", "#             for key in self.weights.keys():", "\n", "#                 print(key, gvs[key])", "\n", "fast_weights", "=", "dict", "(", "zip", "(", "self", ".", "weights", ".", "keys", "(", ")", ",", "a", ")", ")", "\n", "\n", "# Validation after each update", "\n", "val_pred", "=", "self", ".", "forward", "(", "val_x", ",", "fast_weights", ",", "training", ")", "\n", "val_loss", "=", "tf", ".", "losses", ".", "softmax_cross_entropy", "(", "val_y", ",", "val_pred", ")", "\n", "# record T0 pred and loss for meta-test", "\n", "val_preds", ".", "append", "(", "val_pred", ")", "\n", "val_losses", ".", "append", "(", "val_loss", ")", "\n", "\n", "# continue to build T1-TK steps graph", "\n", "for", "_", "in", "range", "(", "1", ",", "K", ")", ":", "\n", "\n", "# Update weights on train data of task t", "\n", "                ", "loss", "=", "tf", ".", "losses", ".", "softmax_cross_entropy", "(", "train_y", ",", "self", ".", "forward", "(", "train_x", ",", "fast_weights", ",", "training", ")", ")", "\n", "grads", "=", "tf", ".", "gradients", "(", "loss", ",", "list", "(", "fast_weights", ".", "values", "(", ")", ")", ")", "\n", "gvs", "=", "dict", "(", "zip", "(", "fast_weights", ".", "keys", "(", ")", ",", "grads", ")", ")", "\n", "fast_weights", "=", "dict", "(", "zip", "(", "fast_weights", ".", "keys", "(", ")", ",", "[", "fast_weights", "[", "key", "]", "-", "self", ".", "train_lr", "*", "gvs", "[", "key", "]", "for", "key", "in", "fast_weights", ".", "keys", "(", ")", "]", ")", ")", "\n", "\n", "# Evaluate validation data of task t", "\n", "val_pred", "=", "self", ".", "forward", "(", "val_x", ",", "fast_weights", ",", "training", ")", "\n", "val_loss", "=", "tf", ".", "losses", ".", "softmax_cross_entropy", "(", "val_y", ",", "val_pred", ")", "\n", "val_preds", ".", "append", "(", "val_pred", ")", "\n", "val_losses", ".", "append", "(", "val_loss", ")", "\n", "\n", "", "result", "=", "[", "train_pred", ",", "train_loss", ",", "val_preds", ",", "val_losses", "]", "\n", "\n", "return", "result", "\n", "\n", "", "out_dtype", "=", "[", "tf", ".", "float32", ",", "tf", ".", "float32", ",", "[", "tf", ".", "float32", "]", "*", "K", ",", "[", "tf", ".", "float32", "]", "*", "K", "]", "\n", "result", "=", "tf", ".", "map_fn", "(", "meta_task", ",", "elems", "=", "(", "self", ".", "train_xb", ",", "self", ".", "train_yb", ",", "self", ".", "val_xb", ",", "self", ".", "val_yb", ")", ",", "\n", "dtype", "=", "out_dtype", ",", "parallel_iterations", "=", "meta_batchsz", ",", "name", "=", "'map_fn'", ")", "\n", "train_pred_tasks", ",", "train_loss_tasks", ",", "val_preds_tasks", ",", "val_losses_tasks", "=", "result", "\n", "\n", "if", "mode", "is", "'train'", ":", "\n", "            ", "self", ".", "train_loss", "=", "train_loss", "=", "tf", ".", "reduce_sum", "(", "train_loss_tasks", ")", "/", "meta_batchsz", "\n", "self", ".", "val_losses", "=", "val_losses", "=", "[", "tf", ".", "reduce_sum", "(", "val_losses_tasks", "[", "j", "]", ")", "/", "meta_batchsz", "for", "j", "in", "range", "(", "K", ")", "]", "\n", "self", ".", "val_predictions", "=", "val_preds_tasks", "\n", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "meta_lr", ",", "name", "=", "'meta_optim'", ")", "\n", "gvs", "=", "optimizer", ".", "compute_gradients", "(", "self", ".", "val_losses", "[", "-", "1", "]", ")", "\n", "gvs", "=", "[", "(", "tf", ".", "clip_by_norm", "(", "grad", ",", "10", ")", ",", "var", ")", "for", "grad", ",", "var", "in", "gvs", "]", "\n", "self", ".", "meta_op", "=", "optimizer", ".", "apply_gradients", "(", "gvs", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "test_train_loss", "=", "train_loss", "=", "tf", ".", "reduce_sum", "(", "train_loss_tasks", ")", "/", "meta_batchsz", "\n", "self", ".", "test_val_losses", "=", "val_losses", "=", "[", "tf", ".", "reduce_sum", "(", "val_losses_tasks", "[", "j", "]", ")", "/", "meta_batchsz", "for", "j", "in", "range", "(", "K", ")", "]", "\n", "self", ".", "val_predictions", "=", "val_preds_tasks", "\n", "\n", "", "self", ".", "saving_weights", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "", "def", "conv_layer", "(", "self", ",", "x", ",", "W", ",", "b", ",", "name", ",", "strides", "=", "1", ")", ":", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.conv_layer": [[95, 100], ["tensorflow.variable_scope", "tensorflow.nn.conv2d", "tensorflow.nn.bias_add"], "methods", ["None"], ["", "def", "conv_layer", "(", "self", ",", "x", ",", "W", ",", "b", ",", "name", ",", "strides", "=", "1", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "x", "=", "tf", ".", "nn", ".", "conv2d", "(", "x", ",", "W", ",", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "'SAME'", ")", "\n", "x", "=", "tf", ".", "nn", ".", "bias_add", "(", "x", ",", "b", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.fc_layer": [[101, 106], ["tensorflow.variable_scope", "tensorflow.matmul", "tensorflow.nn.bias_add"], "methods", ["None"], ["", "def", "fc_layer", "(", "self", ",", "x", ",", "name", ",", "weights", "=", "None", ",", "biases", "=", "None", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "                ", "fc", "=", "tf", ".", "matmul", "(", "x", ",", "weights", ")", "\n", "fc", "=", "tf", ".", "nn", ".", "bias_add", "(", "fc", ",", "biases", ")", "\n", "return", "fc", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.loadWeights": [[107, 119], ["os.path.isfile", "tensorflow.train.Saver", "saver.restore", "print", "print"], "methods", ["None"], ["", "", "def", "loadWeights", "(", "self", ",", "sess", ",", "name", ",", "step", "=", "0", ",", "modeldir", "=", "'./model_checkpoint/'", ",", "model_name", "=", "'model.ckpt'", ")", ":", "\n", "        ", "if", "self", ".", "saver", "==", "None", ":", "\n", "            ", "z", "=", "self", ".", "saving_weights", "\n", "#print(\"KEYS:\", z.keys())", "\n", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "z", ",", "max_to_keep", "=", "12", ")", "\n", "", "saver", "=", "self", ".", "saver", "\n", "checkpoint_path", "=", "modeldir", "+", "f\"{name}/\"", "+", "model_name", "+", "\"-\"", "+", "step", "\n", "if", "os", ".", "path", ".", "isfile", "(", "checkpoint_path", "+", "\".marker\"", ")", ":", "\n", "            ", "saver", ".", "restore", "(", "sess", ",", "checkpoint_path", ")", "\n", "print", "(", "'The checkpoint has been loaded.'", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "checkpoint_path", "+", "\".marker not found. Starting from scratch.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.saveWeights": [[120, 131], ["saver.save", "print", "open().close", "tensorflow.train.Saver", "os.path.exists", "os.makedirs", "open", "str", "int"], "methods", ["None"], ["", "", "def", "saveWeights", "(", "self", ",", "sess", ",", "name", ",", "step", "=", "0", ",", "modeldir", "=", "'./model_checkpoint/'", ",", "model_name", "=", "'model.ckpt'", ")", ":", "\n", "        ", "if", "self", ".", "saver", "==", "None", ":", "\n", "            ", "z", "=", "self", ".", "saving_weights", "\n", "self", ".", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "z", ",", "max_to_keep", "=", "12", ")", "\n", "", "saver", "=", "self", ".", "saver", "\n", "checkpoint_path", "=", "modeldir", "+", "f\"{name}/\"", "+", "model_name", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "modeldir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "modeldir", ")", "\n", "", "saver", ".", "save", "(", "sess", ",", "checkpoint_path", ",", "global_step", "=", "step", ")", "\n", "print", "(", "'The checkpoint has been created.'", ")", "\n", "open", "(", "checkpoint_path", "+", "\"-\"", "+", "str", "(", "int", "(", "step", ")", ")", "+", "\".marker\"", ",", "'a'", ")", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.dense_weights": [[133, 135], ["None"], "methods", ["None"], ["", "def", "dense_weights", "(", "self", ")", ":", "\n", "        ", "return", "\n", "", "def", "forward", "(", "self", ",", "x", ",", "weights", ",", "training", ")", ":", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.forward": [[135, 137], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "weights", ",", "training", ")", ":", "\n", "        ", "return", "", "", "", ""]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.hydra.Model.__init__": [[22, 27], ["archs.maml2.MAML.__init__"], "methods", ["home.repos.pwc.inspect_result.radrumond_hidra.archs.hydra.Model.__init__"], ["    ", "def", "__init__", "(", "self", ",", "train_lr", ",", "meta_lr", ",", "image_shape", ",", "isMIN", ",", "label_size", "=", "2", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "train_lr", ",", "meta_lr", ",", "image_shape", ",", "isMIN", ",", "label_size", ")", "\n", "self", ".", "finals", "=", "64", "\n", "if", "isMIN", ":", "\n", "            ", "self", ".", "finals", "=", "800", "\n", "", "", "def", "getBin", "(", "self", ",", "l", "=", "10", ")", ":", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.hydra.Model.getBin": [[27, 41], ["range", "list", "numbers.append", "num.append", "int"], "methods", ["None"], ["", "", "def", "getBin", "(", "self", ",", "l", "=", "10", ")", ":", "\n", "        ", "x_", "=", "2", "\n", "n", "=", "1", "\n", "while", "x_", "<", "l", ":", "\n", "            ", "x_", "=", "x_", "*", "2", "\n", "n", "+=", "1", "\n", "\n", "", "numbers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "l", ")", ":", "\n", "            ", "num", "=", "[", "]", "\n", "for", "j", "in", "list", "(", "'{0:0b}'", ".", "format", "(", "i", "+", "1", ")", ".", "zfill", "(", "n", ")", ")", ":", "\n", "                ", "num", ".", "append", "(", "int", "(", "j", ")", ")", "\n", "", "numbers", ".", "append", "(", "num", ")", "\n", "", "return", "numbers", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.hydra.Model.dense_weights": [[42, 74], ["tensorflow.contrib.layers.xavier_initializer", "print", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "range", "tensorflow.get_variable", "tensorflow.get_variable", "str", "str", "str", "str"], "methods", ["None"], ["", "def", "dense_weights", "(", "self", ")", ":", "\n", "        ", "weights", "=", "{", "}", "\n", "cells", "=", "{", "}", "\n", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", "\n", "divider", "=", "1", "\n", "inic", "=", "1", "\n", "filters", "=", "64", "\n", "self", ".", "finals", "=", "64", "\n", "if", "self", ".", "isMIN", ":", "\n", "            ", "print", "(", "\"\\n\\n\\n\\n\\n\\n\\n\\n\\nIS MIN\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\"", ")", "\n", "divider", "=", "2", "\n", "inic", "=", "3", "\n", "self", ".", "finals", "=", "800", "\n", "filters", "=", "32", "\n", "", "with", "tf", ".", "variable_scope", "(", "'MASTER'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "cells", "[", "'d_1'", "]", "=", "tf", ".", "get_variable", "(", "'MASTER_d_1w'", ",", "[", "self", ".", "finals", ",", "1", "]", ",", "initializer", "=", "initializer", ")", "\n", "cells", "[", "'b_1'", "]", "=", "tf", ".", "get_variable", "(", "'MASTER_d_1b'", ",", "[", "1", "]", ",", "initializer", "=", "tf", ".", "initializers", ".", "constant", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'MAML'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "weights", "[", "'c_1'", "]", "=", "tf", ".", "get_variable", "(", "'c_1'", ",", "shape", "=", "(", "3", ",", "3", ",", "inic", ",", "filters", ")", ",", "initializer", "=", "initializer", ")", "\n", "weights", "[", "'c_2'", "]", "=", "tf", ".", "get_variable", "(", "'c_2'", ",", "shape", "=", "(", "3", ",", "3", ",", "filters", ",", "filters", ")", ",", "initializer", "=", "initializer", ")", "\n", "weights", "[", "'c_3'", "]", "=", "tf", ".", "get_variable", "(", "'c_3'", ",", "shape", "=", "(", "3", ",", "3", ",", "filters", ",", "filters", ")", ",", "initializer", "=", "initializer", ")", "\n", "weights", "[", "'c_4'", "]", "=", "tf", ".", "get_variable", "(", "'c_4'", ",", "shape", "=", "(", "3", ",", "3", ",", "filters", ",", "filters", ")", ",", "initializer", "=", "initializer", ")", "\n", "weights", "[", "'cb_1'", "]", "=", "tf", ".", "get_variable", "(", "'cb_1'", ",", "shape", "=", "(", "filters", ")", ",", "initializer", "=", "tf", ".", "initializers", ".", "constant", ")", "\n", "weights", "[", "'cb_2'", "]", "=", "tf", ".", "get_variable", "(", "'cb_2'", ",", "shape", "=", "(", "filters", ")", ",", "initializer", "=", "tf", ".", "initializers", ".", "constant", ")", "\n", "weights", "[", "'cb_3'", "]", "=", "tf", ".", "get_variable", "(", "'cb_3'", ",", "shape", "=", "(", "filters", ")", ",", "initializer", "=", "tf", ".", "initializers", ".", "constant", ")", "\n", "weights", "[", "'cb_4'", "]", "=", "tf", ".", "get_variable", "(", "'cb_4'", ",", "shape", "=", "(", "filters", ")", ",", "initializer", "=", "tf", ".", "initializers", ".", "constant", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "max_labels", ")", ":", "\n", "                ", "weights", "[", "'d_1w'", "+", "str", "(", "i", ")", "]", "=", "tf", ".", "get_variable", "(", "'d_1w'", "+", "str", "(", "i", ")", ",", "[", "self", ".", "finals", ",", "1", "]", ",", "initializer", "=", "initializer", ")", "\n", "weights", "[", "'b_1w'", "+", "str", "(", "i", ")", "]", "=", "tf", ".", "get_variable", "(", "'d_1b'", "+", "str", "(", "i", ")", ",", "[", "1", "]", ",", "initializer", "=", "tf", ".", "initializers", ".", "constant", ")", "\n", "\n", "\n", "", "", "return", "weights", ",", "cells", "\n", "\n"]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.hydra.Model.forward": [[75, 103], ["hydra.Model.conv_layer", "tensorflow.layers.batch_normalization", "tensorflow.nn.relu", "hydra.Model.conv_layer", "tensorflow.layers.batch_normalization", "tensorflow.nn.relu", "hydra.Model.conv_layer", "tensorflow.layers.batch_normalization", "tensorflow.nn.relu", "hydra.Model.conv_layer", "tensorflow.layers.batch_normalization", "tensorflow.nn.relu", "tensorflow.layers.MaxPooling2D", "tensorflow.layers.MaxPooling2D", "tensorflow.layers.MaxPooling2D", "tensorflow.layers.MaxPooling2D", "tensorflow.layers.Flatten", "hydra.Model.fc_layer", "tensorflow.concat", "range", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.conv_layer", "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.conv_layer", "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.conv_layer", "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.conv_layer", "home.repos.pwc.inspect_result.radrumond_hidra.archs.maml.MAML.fc_layer"], ["", "def", "forward", "(", "self", ",", "x", ",", "weights", ",", "training", ")", ":", "\n", "# with tf.variable_scope('MAML', reuse= tf.AUTO_REUSE):", "\n", "        ", "conv1", "=", "self", ".", "conv_layer", "(", "x", ",", "weights", "[", "\"c_1\"", "]", ",", "weights", "[", "\"cb_1\"", "]", ",", "\"conv1\"", ")", "\n", "conv1", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "conv1", ",", "name", "=", "\"bn1\"", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "\n", "conv1", "=", "tf", ".", "nn", ".", "relu", "(", "conv1", ")", "\n", "conv1", "=", "tf", ".", "layers", ".", "MaxPooling2D", "(", "2", ",", "2", ")", "(", "conv1", ")", "\n", "\n", "conv2", "=", "self", ".", "conv_layer", "(", "conv1", ",", "weights", "[", "\"c_2\"", "]", ",", "weights", "[", "\"cb_2\"", "]", ",", "\"conv2\"", ")", "\n", "conv2", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "conv2", ",", "name", "=", "\"bn2\"", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "\n", "conv2", "=", "tf", ".", "nn", ".", "relu", "(", "conv2", ")", "\n", "conv2", "=", "tf", ".", "layers", ".", "MaxPooling2D", "(", "2", ",", "2", ")", "(", "conv2", ")", "\n", "\n", "conv3", "=", "self", ".", "conv_layer", "(", "conv2", ",", "weights", "[", "\"c_3\"", "]", ",", "weights", "[", "\"cb_3\"", "]", ",", "\"conv3\"", ")", "\n", "conv3", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "conv3", ",", "name", "=", "\"bn3\"", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "\n", "conv3", "=", "tf", ".", "nn", ".", "relu", "(", "conv3", ")", "\n", "conv3", "=", "tf", ".", "layers", ".", "MaxPooling2D", "(", "2", ",", "2", ")", "(", "conv3", ")", "\n", "\n", "conv4", "=", "self", ".", "conv_layer", "(", "conv3", ",", "weights", "[", "\"c_4\"", "]", ",", "weights", "[", "\"cb_4\"", "]", ",", "\"conv4\"", ")", "\n", "conv4", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "conv4", ",", "name", "=", "\"bn4\"", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", "\n", "conv4", "=", "tf", ".", "nn", ".", "relu", "(", "conv4", ")", "\n", "conv4", "=", "tf", ".", "layers", ".", "MaxPooling2D", "(", "2", ",", "2", ")", "(", "conv4", ")", "\n", "\n", "bn", "=", "tf", ".", "layers", ".", "Flatten", "(", ")", "(", "conv4", ")", "\n", "\n", "agg", "=", "[", "self", ".", "fc_layer", "(", "bn", ",", "\"dense\"", "+", "str", "(", "i", ")", ",", "weights", "[", "\"d_1w\"", "+", "str", "(", "i", ")", "]", ",", "weights", "[", "\"b_1w\"", "+", "str", "(", "i", ")", "]", ")", "for", "i", "in", "range", "(", "self", ".", "max_labels", ")", "]", "\n", "fc1", "=", "tf", ".", "concat", "(", "agg", ",", "axis", "=", "-", "1", ")", "[", ":", ",", ":", "self", ".", "label_n", "[", "0", "]", "]", "\n", "\n", "return", "fc1", "", "", "", ""]], "home.repos.pwc.inspect_result.radrumond_hidra.archs.hydra.getBin": [[7, 21], ["range", "list", "numbers.append", "num.append", "int"], "function", ["None"], ["def", "getBin", "(", "l", "=", "10", ")", ":", "\n", "    ", "x_", "=", "2", "\n", "n", "=", "1", "\n", "while", "x_", "<", "l", ":", "\n", "        ", "x_", "=", "x_", "*", "2", "\n", "n", "+=", "1", "\n", "\n", "", "numbers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "l", ")", ":", "\n", "        ", "num", "=", "[", "]", "\n", "for", "j", "in", "list", "(", "'{0:0b}'", ".", "format", "(", "i", "+", "1", ")", ".", "zfill", "(", "n", ")", ")", ":", "\n", "            ", "num", ".", "append", "(", "int", "(", "j", ")", ")", "\n", "", "numbers", ".", "append", "(", "num", ")", "\n", "", "return", "numbers", "\n", "", "class", "Model", "(", "MAML", ")", ":", "\n"]]}