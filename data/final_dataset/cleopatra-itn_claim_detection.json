{"home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_2.evaluate.parse_args": [[16, 33], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.lib.format_checker.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--scores'", ",", "'-s'", ",", "required", "=", "True", ",", "\n", "help", "=", "'File with predicted scores from your model.\\\n                        Format: qid Q0 docid rank score tag'", ")", "\n", "parser", ".", "add_argument", "(", "'--gold-labels'", ",", "'-g'", ",", "required", "=", "True", ",", "\n", "help", "=", "'File with gold labels. Format: qid 0 docid relevance'", ")", "\n", "parser", ".", "add_argument", "(", "'--metrics'", ",", "'-m'", ",", "choices", "=", "METRICS", ",", "action", "=", "'append'", ",", "\n", "help", "=", "'Metrics for evaluation. \\\n                        This parameter can be added multiple times with different metrics.'", ")", "\n", "parser", ".", "add_argument", "(", "'--depths'", ",", "'-d'", ",", "choices", "=", "METRICS_DEPTH", ",", "action", "=", "'append'", ",", "type", "=", "int", ",", "\n", "help", "=", "'Depth of evaluation. Example: Recall@K, Precision@K.\\\n                        This parameter can be added multiple times.'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "'-o'", ",", "\n", "help", "=", "'Output file with metrics.\\\n                        If not specified, prints output in stdout.'", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_2.evaluate.extract_metrics": [[34, 46], ["pandas.DataFrame", "eval", "scores.append.append", "eval."], "function", ["None"], ["", "def", "extract_metrics", "(", "results", ",", "metrics", ",", "depths", ")", ":", "\n", "    ", "metrics", ",", "depths", "=", "metrics", "or", "METRICS", ",", "depths", "or", "METRICS_DEPTH", "\n", "scores", "=", "pd", ".", "DataFrame", "(", "[", "]", ",", "columns", "=", "SCORES_COLUMNS", ")", "\n", "for", "metric", "in", "metrics", ":", "\n", "        ", "for", "depth", "in", "depths", ":", "\n", "            ", "score", "=", "{", "}", "\n", "metric_fn", "=", "eval", "(", "f'results.get_{metric}'", ")", "\n", "score", "[", "'metric'", "]", "=", "metric", "\n", "score", "[", "'@depth'", "]", "=", "depth", "\n", "score", "[", "'score'", "]", "=", "'{:,.3f}'", ".", "format", "(", "metric_fn", "(", "depth", "=", "depth", ")", ")", "\n", "scores", "=", "scores", ".", "append", "(", "score", ",", "ignore_index", "=", "True", ")", "\n", "", "", "return", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_2.evaluate.main": [[47, 64], ["format_checker.run_checks", "trectools.TrecQrel", "trectools.TrecRun", "trectools.TrecEval", "evaluate.extract_metrics", "extract_metrics.loc[].astype", "extract_metrics.loc[].replace", "str", "extract_metrics.to_csv", "logger.logger.info", "print", "extract_metrics.to_string"], "function", ["home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.lib.format_checker.run_checks", "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_2.evaluate.extract_metrics"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "format_check_passed", "=", "run_checks", "(", "args", ".", "scores", ")", "\n", "if", "not", "format_check_passed", ":", "\n", "        ", "return", "\n", "", "gold_labels", "=", "TrecQrel", "(", "args", ".", "gold_labels", ")", "\n", "prediction", "=", "TrecRun", "(", "args", ".", "scores", ")", "\n", "\n", "results", "=", "TrecEval", "(", "prediction", ",", "gold_labels", ")", "\n", "metrics", "=", "extract_metrics", "(", "results", ",", "args", ".", "metrics", ",", "args", ".", "depths", ")", "\n", "\n", "metrics", ".", "loc", "[", ":", ",", "'@depth'", "]", "=", "metrics", ".", "loc", "[", ":", ",", "'@depth'", "]", ".", "astype", "(", "str", ")", "\n", "metrics", ".", "loc", "[", ":", ",", "'@depth'", "]", "=", "metrics", ".", "loc", "[", ":", ",", "'@depth'", "]", ".", "replace", "(", "str", "(", "MAX_DEPTH", ")", ",", "'all'", ")", "\n", "if", "args", ".", "output", ":", "\n", "        ", "metrics", ".", "to_csv", "(", "args", ".", "output", ",", "sep", "=", "'\\t'", ",", "index", "=", "False", ")", "\n", "logger", ".", "info", "(", "f'Saved results to file: {args.output}'", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "metrics", ".", "to_string", "(", "index", "=", "False", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_2.bertsent_triplets.query_claim_dict": [[37, 47], ["range", "len", "pairs[].split", "dct[].append", "int", "int"], "function", ["None"], ["def", "query_claim_dict", "(", "pairs", ")", ":", "\n", "    ", "dct", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "pairs", ")", ")", ":", "\n", "        ", "q_id", ",", "_", ",", "cl_ind", ",", "_", "=", "pairs", "[", "i", "]", ".", "split", "(", ")", "\n", "if", "q_id", "not", "in", "dct", ":", "\n", "            ", "dct", "[", "q_id", "]", "=", "[", "int", "(", "cl_ind", ")", "]", "\n", "", "else", ":", "\n", "            ", "dct", "[", "q_id", "]", ".", "append", "(", "int", "(", "cl_ind", ")", ")", "\n", "\n", "", "", "return", "dct", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_2.bertsent_triplets.id_to_index_dict": [[49, 57], ["None"], "function", ["None"], ["", "def", "id_to_index_dict", "(", "ids", ")", ":", "\n", "    ", "temp_dict", "=", "{", "}", "\n", "cnt", "=", "0", "\n", "for", "idx", "in", "ids", ":", "\n", "        ", "temp_dict", "[", "idx", "]", "=", "cnt", "\n", "cnt", "+=", "1", "\n", "\n", "", "return", "temp_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_2.bertsent_triplets.get_triples": [[58, 89], ["range", "len", "raw_pairs[].split", "q_txt_dict[].strip", "claim_txt_dict[].strip", "title_txt_dict[].strip", "claim_txt_dict[].strip", "title_txt_dict[].strip", "numpy.argsort", "numpy.argsort", "triples.append", "triples.append", "triples.append", "len", "len", "str", "str"], "function", ["None"], ["", "def", "get_triples", "(", "id_to_indx", ",", "raw_pairs", ",", "q_txt_dict", ",", "q_claim_dict", ",", "claim_txt_dict", ",", "title_txt_dict", ",", "cos_sim", ",", "phase", ")", ":", "\n", "\n", "    ", "triples", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "raw_pairs", ")", ")", ":", "\n", "        ", "q_id", ",", "_", ",", "cl_ind", ",", "_", "=", "raw_pairs", "[", "i", "]", ".", "split", "(", ")", "\n", "query", "=", "q_txt_dict", "[", "q_id", "]", ".", "strip", "(", ")", "\n", "claim", "=", "claim_txt_dict", "[", "cl_ind", "]", ".", "strip", "(", ")", "\n", "title", "=", "title_txt_dict", "[", "cl_ind", "]", ".", "strip", "(", ")", "\n", "\n", "true_ids", "=", "q_claim_dict", "[", "q_id", "]", "\n", "\n", "sims", "=", "cos_sim", "[", "id_to_indx", "[", "q_id", "]", ",", ":", "]", "*", "-", "1", "\n", "sims", "[", "true_ids", "]", "+=", "-", "100", "\n", "\n", "if", "phase", "==", "'train'", ":", "\n", "            ", "top_sort_inds", "=", "np", ".", "argsort", "(", "sims", ")", "[", "len", "(", "true_ids", ")", ":", "args", ".", "negs", "]", "\n", "", "else", ":", "\n", "            ", "top_sort_inds", "=", "np", ".", "argsort", "(", "sims", ")", "[", "len", "(", "true_ids", ")", ":", "3", "]", "\n", "\n", "", "for", "c", "in", "top_sort_inds", ":", "\n", "            ", "claim_neg", "=", "claim_txt_dict", "[", "str", "(", "c", ")", "]", ".", "strip", "(", ")", "\n", "title_neg", "=", "title_txt_dict", "[", "str", "(", "c", ")", "]", ".", "strip", "(", ")", "\n", "if", "phase", "==", "'train'", ":", "\n", "                ", "triples", ".", "append", "(", "[", "query", ",", "claim", ",", "claim_neg", "]", ")", "\n", "triples", ".", "append", "(", "[", "query", ",", "title", ",", "title_neg", "]", ")", "\n", "# triples.append([query, title+\" \"+claim, title_neg+\" \"+claim_neg])", "\n", "", "else", ":", "\n", "                ", "triples", ".", "append", "(", "[", "query", ",", "claim", ",", "claim_neg", "]", ")", "\n", "# triples.append([query, title+\" \"+claim, title_neg+\" \"+claim_neg])", "\n", "\n", "", "", "", "return", "triples", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_2.bertsent_triplets.get_proc_text": [[91, 105], ["re.search"], "function", ["None"], ["", "def", "get_proc_text", "(", "data", ",", "text_type", ")", ":", "\n", "    ", "txt_dict", "=", "{", "}", "\n", "for", "idx", "in", "data", ":", "\n", "        ", "text", "=", "data", "[", "idx", "]", "[", "text_type", "]", "\n", "\n", "text", "=", "[", "word", "for", "word", "in", "text", "if", "not", "re", ".", "search", "(", "r'<(/?)[a-z]+>'", ",", "word", ")", "]", "\n", "\n", "proc_text", "=", "\"\"", "\n", "for", "word", "in", "text", ":", "\n", "            ", "proc_text", "+=", "word", "if", "word", "in", "[", "','", ",", "'.'", "]", "else", "\" \"", "+", "word", "\n", "\n", "", "txt_dict", "[", "idx", "]", "=", "proc_text", "\n", "\n", "", "return", "txt_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_2.helper_funcs.get_text_processor": [[6, 34], ["ekphrasis.classes.preprocessor.TextPreProcessor", "ekphrasis.classes.tokenizer.SocialTokenizer"], "function", ["None"], ["def", "get_text_processor", "(", "word_stats", "=", "'twitter'", ")", ":", "\n", "    ", "return", "TextPreProcessor", "(", "\n", "# terms that will be normalized", "\n", "normalize", "=", "[", "'url'", ",", "'email'", ",", "'phone'", ",", "'user'", "]", ",", "\n", "# terms that will be annotated", "\n", "annotate", "=", "{", "\"hashtag\"", ",", "\"allcaps\"", ",", "\"elongated\"", ",", "\"repeated\"", ",", "\n", "'emphasis'", ",", "'censored'", "}", ",", "\n", "fix_html", "=", "True", ",", "# fix HTML tokens", "\n", "\n", "# corpus from which the word statistics are going to be used", "\n", "# for word segmentation", "\n", "segmenter", "=", "word_stats", ",", "\n", "\n", "# corpus from which the word statistics are going to be used", "\n", "# for spell correction", "\n", "corrector", "=", "word_stats", ",", "\n", "\n", "unpack_hashtags", "=", "True", ",", "# perform word segmentation on hashtags", "\n", "unpack_contractions", "=", "True", ",", "# Unpack contractions (can't -> can not)", "\n", "spell_correct_elong", "=", "False", ",", "# spell correction for elongated words", "\n", "\n", "# select a tokenizer. You can use SocialTokenizer, or pass your own", "\n", "# the tokenizer, should take as input a string and return a list of tokens", "\n", "tokenizer", "=", "SocialTokenizer", "(", "lowercase", "=", "True", ")", ".", "tokenize", ",", "\n", "\n", "# list of dictionaries, for replacing tokens extracted from the text,", "\n", "# with other expressions. You can pass more than one dictionaries.", "\n", "dicts", "=", "[", "emoticons", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_2.bertsent_pairwise.query_claim_dict": [[34, 41], ["range", "len", "pairs[].split", "dct[].append", "int", "int"], "function", ["None"], ["def", "query_claim_dict", "(", "pairs", ")", ":", "\n", "    ", "dct", "=", "{", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "pairs", ")", ")", ":", "\n", "        ", "q_id", ",", "_", ",", "cl_ind", ",", "_", "=", "pairs", "[", "i", "]", ".", "split", "(", ")", "\n", "dct", "[", "q_id", "]", "=", "[", "int", "(", "cl_ind", ")", "]", "if", "q_id", "not", "in", "dct", "else", "dct", "[", "q_id", "]", ".", "append", "(", "int", "(", "cl_ind", ")", ")", "\n", "\n", "", "return", "dct", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_2.bertsent_pairwise.get_pospair_feats": [[43, 61], ["range", "len", "raw_pairs[].split", "pairs.append", "pairs.append", "query.strip", "query.strip", "claim.strip", "claim.strip", "title.strip", "title.strip"], "function", ["None"], ["", "def", "get_pospair_feats", "(", "raw_pairs", ",", "q_txt_dict", ",", "claim_txt_dict", ",", "title_txt_dict", ",", "phase", ")", ":", "\n", "\n", "    ", "pairs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "raw_pairs", ")", ")", ":", "\n", "        ", "q_id", ",", "_", ",", "cl_ind", ",", "_", "=", "raw_pairs", "[", "i", "]", ".", "split", "(", ")", "\n", "query", "=", "q_txt_dict", "[", "q_id", "]", "\n", "claim", "=", "claim_txt_dict", "[", "cl_ind", "]", "\n", "title", "=", "title_txt_dict", "[", "cl_ind", "]", "\n", "if", "phase", "==", "'train'", ":", "\n", "# pairs.append([query.strip(), claim.strip()])", "\n", "# pairs.append([query.strip(), title.strip()])", "\n", "# pairs.append([claim.strip(), title.strip()])", "\n", "            ", "pairs", ".", "append", "(", "[", "query", ".", "strip", "(", ")", ",", "title", ".", "strip", "(", ")", "+", "\" \"", "+", "claim", ".", "strip", "(", ")", "]", ")", "\n", "", "else", ":", "\n", "# pairs.append([query.strip(), claim.strip()])", "\n", "            ", "pairs", ".", "append", "(", "[", "query", ".", "strip", "(", ")", ",", "title", ".", "strip", "(", ")", "+", "\" \"", "+", "claim", ".", "strip", "(", ")", "]", ")", "\n", "\n", "", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_2.bertsent_pairwise.get_negpair_feats": [[64, 93], ["random.sample", "numpy.argsort", "list", "pairs.append", "pairs.append", "pairs.append", "str", "str", "query.strip", "claim.strip", "query.strip", "title.strip", "query.strip", "claim.strip"], "function", ["None"], ["", "def", "get_negpair_feats", "(", "ids", ",", "q_claim_dict", ",", "tr_txt_dict", ",", "claim_txt_dict", ",", "title_txt_dict", ",", "cos_sim", ",", "n_sample", ",", "phase", ")", ":", "\n", "\n", "    ", "pairs", "=", "[", "]", "\n", "cnt", "=", "0", "\n", "for", "idx", "in", "ids", ":", "\n", "        ", "query", "=", "tr_txt_dict", "[", "idx", "]", "\n", "true_ids", "=", "q_claim_dict", "[", "idx", "]", "\n", "\n", "sims", "=", "cos_sim", "[", "cnt", ",", ":", "]", "*", "-", "1", "\n", "sims", "[", "true_ids", "]", "+=", "-", "100", "\n", "\n", "top_sort_inds", "=", "np", ".", "argsort", "(", "sims", ")", "[", "1", ":", "6", "]", "\n", "\n", "ch", "=", "random", ".", "sample", "(", "list", "(", "top_sort_inds", ")", ",", "n_sample", ")", "\n", "\n", "for", "c", "in", "ch", ":", "\n", "            ", "claim", "=", "claim_txt_dict", "[", "str", "(", "c", ")", "]", "\n", "title", "=", "title_txt_dict", "[", "str", "(", "c", ")", "]", "\n", "if", "phase", "==", "'train'", ":", "\n", "                ", "pairs", ".", "append", "(", "[", "query", ".", "strip", "(", ")", ",", "claim", ".", "strip", "(", ")", "]", ")", "\n", "pairs", ".", "append", "(", "[", "query", ".", "strip", "(", ")", ",", "title", ".", "strip", "(", ")", "]", ")", "\n", "# pairs.append([query.strip(), title.strip()+\" \"+claim.strip()])", "\n", "", "else", ":", "\n", "                ", "pairs", ".", "append", "(", "[", "query", ".", "strip", "(", ")", ",", "claim", ".", "strip", "(", ")", "]", ")", "\n", "# pairs.append([query.strip(), title.strip()+\" \"+claim.strip()])", "\n", "\n", "", "", "cnt", "+=", "1", "\n", "\n", "", "return", "pairs", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_2.bertsent_pairwise.get_proc_text": [[95, 109], ["re.search"], "function", ["None"], ["", "def", "get_proc_text", "(", "data", ",", "text_type", ")", ":", "\n", "    ", "txt_dict", "=", "{", "}", "\n", "for", "idx", "in", "data", ":", "\n", "        ", "text", "=", "data", "[", "idx", "]", "[", "text_type", "]", "\n", "\n", "text", "=", "[", "word", "for", "word", "in", "text", "if", "not", "re", ".", "search", "(", "r'<(/?)[a-z]+>'", ",", "word", ")", "]", "\n", "\n", "proc_text", "=", "\"\"", "\n", "for", "word", "in", "text", ":", "\n", "            ", "proc_text", "+=", "word", "if", "word", "in", "[", "','", ",", "'.'", "]", "else", "\" \"", "+", "word", "\n", "\n", "", "txt_dict", "[", "idx", "]", "=", "proc_text", "\n", "\n", "", "return", "txt_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.lib.format_checker.check_format": [[19, 37], ["open", "enumerate", "line_str.split", "pair_ids.get", "check", "COLUMNS.index", "COLUMNS.index"], "function", ["None"], ["def", "check_format", "(", "preditions_file_path", ")", ":", "\n", "    ", "with", "open", "(", "preditions_file_path", ")", "as", "tsvfile", ":", "\n", "        ", "pair_ids", "=", "{", "}", "\n", "for", "line_no", ",", "line_str", "in", "enumerate", "(", "tsvfile", ",", "start", "=", "1", ")", ":", "\n", "            ", "line", "=", "line_str", ".", "split", "(", "'\\t'", ")", "\n", "for", "check", "in", "LINE_CHECKS", ":", "\n", "                ", "error", "=", "check", "(", "line", ")", "\n", "if", "error", "is", "not", "None", ":", "\n", "                    ", "return", "f'{error} on line {line_no} in file: {preditions_file_path}'", "\n", "\n", "", "", "tweet_id", ",", "vclaim_id", "=", "line", "[", "COLUMNS", ".", "index", "(", "'qid'", ")", "]", ",", "line", "[", "COLUMNS", ".", "index", "(", "'docno'", ")", "]", "\n", "duplication", "=", "pair_ids", ".", "get", "(", "(", "tweet_id", ",", "vclaim_id", ")", ",", "False", ")", "\n", "if", "duplication", ":", "\n", "                ", "return", "f'Duplication of pair(tweet_id={tweet_id}, vclaim_id={vclaim_id}) '", "f'on lines {duplication} and {line_no} in file: {preditions_file_path}'", "\n", "", "else", ":", "\n", "                ", "pair_ids", "[", "(", "tweet_id", ",", "vclaim_id", ")", "]", "=", "line_no", "\n", "", "", "", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.lib.format_checker.run_checks": [[38, 47], ["format_checker.check_format", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.format_checker.main.check_format"], ["", "def", "run_checks", "(", "prediction_file", ")", ":", "\n", "    ", "error", "=", "check_format", "(", "prediction_file", ")", "\n", "if", "error", ":", "\n", "        ", "print", "(", "f\"Format check: {bcolors.FAIL}Failed{bcolors.ENDC}\"", ")", "\n", "print", "(", "f\"Cause: {bcolors.BOLD}{error}{bcolors.ENDC}\"", ")", "\n", "return", "False", "\n", "", "else", ":", "\n", "        ", "print", "(", "f\"Format check: {bcolors.OKGREEN}Passed{bcolors.ENDC}\"", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.lib.format_checker.parse_args": [[48, 54], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.lib.format_checker.parse_args"], ["", "", "def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--model-prediction'", ",", "'-m'", ",", "required", "=", "True", ",", "\n", "help", "=", "'Path to the file containing the model predictions,\\\n                              which are supposed to be checked'", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.lib.logger.Logger": [[9, 30], ["logging.Formatter", "colorlog.ColoredFormatter", "logging.getLogger", "logging.getLogger.setLevel", "logging.FileHandler", "logging.StreamHandler", "logging.StreamHandler.setFormatter", "logging.FileHandler.setFormatter", "logging.getLogger.addHandler", "logging.getLogger.addHandler"], "function", ["None"], ["def", "Logger", "(", ")", ":", "\n", "    ", "file_frmt", "=", "logging", ".", "Formatter", "(", "\n", "'[%(asctime)s ][%(levelname)-8s][%(message)s ]'", ")", "\n", "stream_frmt", "=", "ColoredFormatter", "(", "\n", "'[%(asctime)s ][%(log_color)s%(levelname)-8s%(reset)s][%(log_color)s%(message)s%(reset)s ]'", ")", "\n", "\n", "logger", "=", "logging", ".", "getLogger", "(", "'Threshold'", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "\n", "# file handler", "\n", "fh", "=", "logging", ".", "FileHandler", "(", "'RandomThreshold.log'", ")", "\n", "\n", "# stream handler", "\n", "ch", "=", "logging", ".", "StreamHandler", "(", ")", "\n", "\n", "ch", ".", "setFormatter", "(", "stream_frmt", ")", "\n", "fh", ".", "setFormatter", "(", "file_frmt", ")", "\n", "\n", "logger", ".", "addHandler", "(", "ch", ")", "\n", "logger", ".", "addHandler", "(", "fh", ")", "\n", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.ensemble_bert.get_tweet_data": [[35, 46], ["pandas.DataFrame", "twit_id.append", "twit_y.append", "numpy.array().astype", "numpy.array"], "function", ["None"], ["def", "get_tweet_data", "(", "tweet_list", ")", ":", "\n", "    ", "twit_y", ",", "twit_id", "=", "[", "]", ",", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "twit_id", ".", "append", "(", "id", ")", "\n", "twit_y", ".", "append", "(", "tweet_list", "[", "id", "]", "[", "'worthy'", "]", ")", "\n", "\n", "", "tweetDF", "=", "pd", ".", "DataFrame", "(", ")", "\n", "tweetDF", "[", "'label'", "]", "=", "twit_y", "\n", "tweetDF", "[", "'tweet_id'", "]", "=", "twit_id", "\n", "\n", "return", "np", ".", "array", "(", "twit_y", ")", ".", "astype", "(", "np", ".", "int", ")", ",", "tweetDF", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.ensemble_bert.get_pos_feat": [[48, 64], ["numpy.array", "numpy.zeros", "pos_feat.append", "len", "sum", "wd.split", "sum"], "function", ["None"], ["", "def", "get_pos_feat", "(", "tweet_list", ",", "pos_type", ")", ":", "\n", "    ", "pos_feat", "=", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "temp", "=", "np", ".", "zeros", "(", "len", "(", "pos_tags", ")", ")", "\n", "proc_twit", "=", "tweet_list", "[", "id", "]", "[", "pos_type", "]", "\n", "for", "wd", "in", "proc_twit", ":", "\n", "            ", "pos", "=", "wd", ".", "split", "(", "'_'", ")", "[", "1", "]", "\n", "if", "pos", "in", "pos_tags", ":", "\n", "                ", "temp", "[", "pos_tags", "[", "pos", "]", "]", "+=", "1", "\n", "\n", "", "", "if", "sum", "(", "temp", ")", ">", "0", ":", "\n", "            ", "temp", "=", "temp", "/", "sum", "(", "temp", ")", "\n", "\n", "", "pos_feat", ".", "append", "(", "temp", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "pos_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.ensemble_bert.get_dep_relations": [[67, 83], ["set", "nlp", "set.add"], "function", ["None"], ["", "def", "get_dep_relations", "(", "train_data", ",", "w2v_type", ")", ":", "\n", "    ", "pos_tags", "=", "[", "'ADJ'", ",", "'ADV'", ",", "'NOUN'", ",", "'PROPN'", ",", "'VERB'", ",", "'NUM'", "]", "\n", "dep_dict", "=", "set", "(", ")", "\n", "for", "id", "in", "train_data", ":", "\n", "        ", "words", "=", "train_data", "[", "id", "]", "[", "w2v_type", "]", "\n", "sent", "=", "\" \"", ".", "join", "(", "words", ")", "\n", "\n", "doc", "=", "nlp", "(", "sent", ")", "\n", "\n", "for", "token", "in", "doc", ":", "\n", "            ", "if", "token", ".", "pos_", "in", "pos_tags", "and", "token", ".", "head", ".", "pos_", "in", "pos_tags", ":", "\n", "# rel = token.pos_+'-'+token.dep_+'-'+token.head.pos_", "\n", "                ", "rel", "=", "token", ".", "pos_", "+", "'-'", "+", "token", ".", "dep_", "\n", "dep_dict", ".", "add", "(", "rel", ")", "\n", "\n", "", "", "", "return", "dep_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.ensemble_bert.get_dep_feats": [[85, 107], ["numpy.array", "numpy.zeros", "nlp", "feats.append", "len", "sum", "sum"], "function", ["None"], ["", "def", "get_dep_feats", "(", "tweet_list", ",", "w2v_type", ")", ":", "\n", "    ", "feats", "=", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "temp", "=", "np", ".", "zeros", "(", "len", "(", "dep_map", ")", ")", "\n", "words", "=", "tweet_list", "[", "id", "]", "[", "w2v_type", "]", "\n", "sent", "=", "\" \"", ".", "join", "(", "words", ")", "\n", "\n", "doc", "=", "nlp", "(", "sent", ")", "\n", "\n", "for", "token", "in", "doc", ":", "\n", "# rel = token.pos_+'-'+token.dep_+'-'+token.head.pos_", "\n", "            ", "rel", "=", "token", ".", "pos_", "+", "'-'", "+", "token", ".", "dep_", "\n", "if", "rel", "in", "dep_map", ":", "\n", "                ", "temp", "[", "dep_map", "[", "rel", "]", "]", "+=", "1", "\n", "\n", "\n", "", "", "if", "sum", "(", "temp", ")", ">", "0", ":", "\n", "            ", "temp", "=", "temp", "/", "sum", "(", "temp", ")", "\n", "\n", "", "feats", ".", "append", "(", "temp", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_w2v_pos.get_best_svm_model": [[40, 88], ["numpy.logspace", "numpy.logspace", "numpy.logspace", "sklearn.decomposition.PCA().fit", "decomposition.PCA().fit.transform", "decomposition.PCA().fit.transform", "sklearn.decomposition.PCA", "sklearn.svm.SVC", "svm.SVC.fit", "svm.SVC.predict", "sklearn.metrics.accuracy_score", "svm.SVC.decision_function", "scorer.main.evaluate", "open", "valDF.iterrows", "results_file.write", "round", "round", "round", "round"], "function", ["home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main.evaluate"], ["def", "get_best_svm_model", "(", "feature_vector_train", ",", "label", ",", "feature_vector_valid", ")", ":", "\n", "    ", "param_grid", "=", "[", "{", "'kernel'", ":", "'linear'", ",", "'C'", ":", "np", ".", "logspace", "(", "-", "3", ",", "3", ",", "20", ")", ",", "'gamma'", ":", "[", "1", "]", "}", ",", "\n", "{", "'kernel'", ":", "'rbf'", ",", "'C'", ":", "np", ".", "logspace", "(", "-", "3", ",", "3", ",", "20", ")", ",", "\n", "'gamma'", ":", "np", ".", "logspace", "(", "-", "3", ",", "3", ",", "20", ")", "}", "]", "\n", "\n", "pca_list", "=", "[", "1.0", ",", "0.99", ",", "0.98", ",", "0.97", ",", "0.96", ",", "0.95", "]", "\n", "best_acc", "=", "0.0", "\n", "best_model", "=", "0", "\n", "best_prec", "=", "0.0", "\n", "best_pca_nk", "=", "0", "\n", "temp_xtrain", "=", "feature_vector_train", "\n", "temp_xval", "=", "feature_vector_valid", "\n", "for", "pca_nk", "in", "pca_list", ":", "\n", "        ", "if", "pca_nk", "!=", "1.0", ":", "\n", "            ", "pca", "=", "decomposition", ".", "PCA", "(", "n_components", "=", "pca_nk", ")", ".", "fit", "(", "temp_xtrain", ")", "\n", "feature_vector_train", "=", "pca", ".", "transform", "(", "temp_xtrain", ")", "\n", "feature_vector_valid", "=", "pca", ".", "transform", "(", "temp_xval", ")", "\n", "", "for", "params", "in", "param_grid", ":", "\n", "            ", "for", "C", "in", "params", "[", "'C'", "]", ":", "\n", "                ", "for", "gamma", "in", "params", "[", "'gamma'", "]", ":", "\n", "# Model with different parameters", "\n", "                    ", "model", "=", "svm", ".", "SVC", "(", "C", "=", "C", ",", "gamma", "=", "gamma", ",", "kernel", "=", "params", "[", "'kernel'", "]", ",", "random_state", "=", "42", ",", "class_weight", "=", "'balanced'", ")", "\n", "\n", "# fit the training dataset on the classifier", "\n", "model", ".", "fit", "(", "feature_vector_train", ",", "label", ")", "\n", "\n", "# predict the labels on validation dataset", "\n", "predictions", "=", "model", ".", "predict", "(", "feature_vector_valid", ")", "\n", "\n", "acc", "=", "metrics", ".", "accuracy_score", "(", "predictions", ",", "val_y", ")", "\n", "\n", "predicted_distance", "=", "model", ".", "decision_function", "(", "feature_vector_valid", ")", "\n", "results_fpath", "=", "my_loc", "+", "'/results/temp5_%d.tsv'", "%", "(", "args", ".", "out_file", ")", "\n", "with", "open", "(", "results_fpath", ",", "\"w\"", ")", "as", "results_file", ":", "\n", "                        ", "for", "i", ",", "line", "in", "valDF", ".", "iterrows", "(", ")", ":", "\n", "                            ", "dist", "=", "predicted_distance", "[", "i", "]", "\n", "results_file", ".", "write", "(", "\"{}\\t{}\\t{}\\t{}\\n\"", ".", "format", "(", "'covid-19'", ",", "line", "[", "'tweet_id'", "]", ",", "\n", "dist", ",", "\"w2v_pos\"", ")", ")", "\n", "\n", "", "", "_", ",", "_", ",", "avg_precision", ",", "_", ",", "_", "=", "evaluate", "(", "'data/dev.tsv'", ",", "results_fpath", ")", "\n", "\n", "if", "round", "(", "avg_precision", ",", "4", ")", ">=", "round", "(", "best_prec", ",", "4", ")", "and", "round", "(", "acc", ",", "2", ")", ">=", "round", "(", "best_acc", ",", "2", ")", ":", "\n", "                        ", "best_prec", "=", "avg_precision", "\n", "best_acc", "=", "acc", "\n", "best_model", "=", "model", "\n", "best_pca_nk", "=", "pca_nk", "\n", "\n", "", "", "", "", "", "return", "best_acc", ",", "best_pca_nk", ",", "best_model", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_w2v_pos.get_spacy_doc_vectors": [[90, 102], ["numpy.array", "nlp", "vec_feat.append", "vec_feat.append", "numpy.zeros"], "function", ["None"], ["", "def", "get_spacy_doc_vectors", "(", "input_feats", ",", "nlp", ")", ":", "\n", "    ", "vec_feat", "=", "[", "]", "\n", "for", "tweet", "in", "input_feats", ":", "\n", "        ", "proc_tweet", "=", "nlp", "(", "tweet", ")", "\n", "if", "not", "proc_tweet", ".", "has_vector", "or", "proc_tweet", ".", "vector_norm", "==", "0", ":", "\n", "            ", "vec_feat", ".", "append", "(", "np", ".", "zeros", "(", "300", ")", ")", "\n", "", "else", ":", "\n", "            ", "tweet_vector", "=", "proc_tweet", ".", "vector", "\n", "tweet_vector", "=", "tweet_vector", "/", "proc_tweet", ".", "vector_norm", "\n", "vec_feat", ".", "append", "(", "tweet_vector", ")", "\n", "\n", "", "", "return", "np", ".", "array", "(", "vec_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_w2v_pos.get_gensim_doc_vectors": [[103, 121], ["numpy.array", "tweet.split", "vec_feat.append", "numpy.zeros", "numpy.array().mean", "np.array().mean.append", "numpy.linalg.norm", "model.wv.get_vector", "numpy.array"], "function", ["None"], ["", "def", "get_gensim_doc_vectors", "(", "input_feats", ",", "model", ",", "size", ")", ":", "\n", "    ", "vec_feat", "=", "[", "]", "\n", "for", "tweet", "in", "input_feats", ":", "\n", "        ", "words", "=", "tweet", ".", "split", "(", ")", "\n", "temp", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "            ", "if", "word", "in", "model", ".", "wv", ".", "vocab", ":", "\n", "                ", "temp", ".", "append", "(", "model", ".", "wv", ".", "get_vector", "(", "word", ")", ")", "\n", "\n", "", "", "if", "not", "temp", ":", "\n", "            ", "temp", "=", "np", ".", "zeros", "(", "size", ")", "\n", "", "else", ":", "\n", "            ", "temp", "=", "np", ".", "array", "(", "temp", ")", ".", "mean", "(", "axis", "=", "0", ")", "\n", "temp", "=", "temp", "/", "np", ".", "linalg", ".", "norm", "(", "temp", ",", "2", ")", "\n", "\n", "", "vec_feat", ".", "append", "(", "temp", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "vec_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_w2v_pos.get_tweet_data": [[123, 136], ["pandas.DataFrame", "twit_id.append", "twit_y.append", "twit_x.append", "numpy.array"], "function", ["None"], ["", "def", "get_tweet_data", "(", "tweet_list", ",", "w2v_type", ")", ":", "\n", "    ", "twit_x", ",", "twit_y", ",", "twit_id", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "twit_id", ".", "append", "(", "id", ")", "\n", "twit_y", ".", "append", "(", "tweet_list", "[", "id", "]", "[", "'worthy'", "]", ")", "\n", "twit_x", ".", "append", "(", "\" \"", ".", "join", "(", "tweet_list", "[", "id", "]", "[", "w2v_type", "]", ")", ")", "\n", "\n", "", "tweetDF", "=", "pd", ".", "DataFrame", "(", ")", "\n", "tweetDF", "[", "'text'", "]", "=", "twit_x", "\n", "tweetDF", "[", "'label'", "]", "=", "twit_y", "\n", "tweetDF", "[", "'tweet_id'", "]", "=", "twit_id", "\n", "\n", "return", "twit_x", ",", "np", ".", "array", "(", "twit_y", ")", ",", "tweetDF", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_w2v_pos.get_pos_feat": [[138, 154], ["numpy.array", "numpy.zeros", "pos_feat.append", "len", "sum", "wd.split", "sum"], "function", ["None"], ["", "def", "get_pos_feat", "(", "tweet_list", ",", "pos_type", ")", ":", "\n", "    ", "pos_feat", "=", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "temp", "=", "np", ".", "zeros", "(", "len", "(", "pos_tags", ")", ")", "\n", "proc_twit", "=", "tweet_list", "[", "id", "]", "[", "pos_type", "]", "\n", "for", "wd", "in", "proc_twit", ":", "\n", "            ", "pos", "=", "wd", ".", "split", "(", "'_'", ")", "[", "1", "]", "\n", "if", "pos", "in", "pos_tags", ":", "\n", "                ", "temp", "[", "pos_tags", "[", "pos", "]", "]", "+=", "1", "\n", "\n", "", "", "if", "sum", "(", "temp", ")", ">", "0", ":", "\n", "            ", "temp", "=", "temp", "/", "sum", "(", "temp", ")", "\n", "\n", "", "pos_feat", ".", "append", "(", "temp", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "pos_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_bert.get_best_svm_model": [[38, 87], ["print", "numpy.logspace", "numpy.logspace", "sklearn.decomposition.PCA().fit", "decomposition.PCA().fit.transform", "decomposition.PCA().fit.transform", "sklearn.decomposition.PCA", "SVC", "SVC.fit", "SVC.score", "SVC.decision_function", "scorer.main.evaluate", "open", "valDF.iterrows", "results_file.write", "round", "round", "round", "round"], "function", ["home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main.evaluate"], ["def", "get_best_svm_model", "(", "feature_vector_train", ",", "label", ",", "feature_vector_valid", ",", "fname", ",", "emb_type", ")", ":", "\n", "# param_grid = [{'kernel':'linear', 'C': np.logspace(-2, 2, 10), 'gamma': [1]}, ", "\n", "#               {'kernel':'rbf', 'C': np.logspace(-2, 2, 10), ", "\n", "#               'gamma': np.logspace(-2, 2, 10)}]", "\n", "    ", "param_grid", "=", "[", "{", "'kernel'", ":", "'rbf'", ",", "'C'", ":", "np", ".", "logspace", "(", "-", "3", ",", "3", ",", "30", ")", ",", "\n", "'gamma'", ":", "np", ".", "logspace", "(", "-", "3", ",", "3", ",", "30", ")", "}", "]", "\n", "\n", "pca_list", "=", "[", "1.0", ",", "0.99", ",", "0.98", ",", "0.97", ",", "0.96", ",", "0.95", "]", "\n", "best_acc", "=", "0.0", "\n", "best_model", "=", "0", "\n", "best_prec", "=", "0.0", "\n", "best_pca_nk", "=", "0", "\n", "temp_xtrain", "=", "feature_vector_train", "\n", "temp_xval", "=", "feature_vector_valid", "\n", "for", "pca_nk", "in", "pca_list", ":", "\n", "        ", "print", "(", "pca_nk", ")", "\n", "if", "pca_nk", "!=", "1.0", ":", "\n", "            ", "pca", "=", "decomposition", ".", "PCA", "(", "n_components", "=", "pca_nk", ")", ".", "fit", "(", "temp_xtrain", ")", "\n", "feature_vector_train", "=", "pca", ".", "transform", "(", "temp_xtrain", ")", "\n", "feature_vector_valid", "=", "pca", ".", "transform", "(", "temp_xval", ")", "\n", "", "for", "params", "in", "param_grid", ":", "\n", "            ", "for", "C", "in", "params", "[", "'C'", "]", ":", "\n", "                ", "for", "gamma", "in", "params", "[", "'gamma'", "]", ":", "\n", "# Model with different parameters", "\n", "                    ", "model", "=", "SVC", "(", "C", "=", "C", ",", "gamma", "=", "gamma", ",", "kernel", "=", "params", "[", "'kernel'", "]", ",", "random_state", "=", "42", ",", "class_weight", "=", "'balanced'", ",", "gpu_id", "=", "args", ".", "gpu_id", ")", "\n", "\n", "# fit the training dataset on the classifier", "\n", "model", ".", "fit", "(", "feature_vector_train", ",", "label", ")", "\n", "\n", "# predict the acc on validation dataset", "\n", "acc", "=", "model", ".", "score", "(", "feature_vector_valid", ",", "val_y", ")", "\n", "\n", "predicted_distance", "=", "model", ".", "decision_function", "(", "feature_vector_valid", ")", "\n", "results_fpath", "=", "my_loc", "+", "'/results/bert_word_%s_%s_svm_norm%d.tsv'", "%", "(", "fname", ",", "emb_type", ",", "args", ".", "normalize", ")", "\n", "with", "open", "(", "results_fpath", ",", "\"w\"", ")", "as", "results_file", ":", "\n", "                        ", "for", "i", ",", "line", "in", "valDF", ".", "iterrows", "(", ")", ":", "\n", "                            ", "dist", "=", "predicted_distance", "[", "i", "]", "[", "0", "]", "\n", "results_file", ".", "write", "(", "\"{}\\t{}\\t{}\\t{}\\n\"", ".", "format", "(", "'covid-19'", ",", "line", "[", "'tweet_id'", "]", ",", "\n", "dist", ",", "\"bert_wd\"", ")", ")", "\n", "\n", "", "", "_", ",", "_", ",", "avg_precision", ",", "_", ",", "_", "=", "evaluate", "(", "'data/dev.tsv'", ",", "results_fpath", ")", "\n", "\n", "if", "round", "(", "avg_precision", ",", "4", ")", ">=", "round", "(", "best_prec", ",", "4", ")", "and", "round", "(", "acc", ",", "2", ")", ">=", "round", "(", "best_acc", ",", "2", ")", ":", "\n", "                        ", "best_prec", "=", "avg_precision", "\n", "best_acc", "=", "acc", "\n", "best_model", "=", "model", "\n", "best_pca_nk", "=", "pca_nk", "\n", "\n", "", "", "", "", "", "return", "best_acc", ",", "best_pca_nk", ",", "best_model", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_bert.get_tweet_data": [[90, 101], ["pandas.DataFrame", "twit_id.append", "twit_y.append", "numpy.array().astype", "numpy.array"], "function", ["None"], ["", "def", "get_tweet_data", "(", "tweet_list", ")", ":", "\n", "    ", "twit_y", ",", "twit_id", "=", "[", "]", ",", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "twit_id", ".", "append", "(", "id", ")", "\n", "twit_y", ".", "append", "(", "tweet_list", "[", "id", "]", "[", "'worthy'", "]", ")", "\n", "\n", "", "tweetDF", "=", "pd", ".", "DataFrame", "(", ")", "\n", "tweetDF", "[", "'label'", "]", "=", "twit_y", "\n", "tweetDF", "[", "'tweet_id'", "]", "=", "twit_id", "\n", "\n", "return", "np", ".", "array", "(", "twit_y", ")", ".", "astype", "(", "np", ".", "int", ")", ",", "tweetDF", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_w2v_neposdep.get_best_svm_model": [[42, 90], ["numpy.logspace", "numpy.logspace", "numpy.logspace", "sklearn.decomposition.PCA().fit", "decomposition.PCA().fit.transform", "decomposition.PCA().fit.transform", "sklearn.decomposition.PCA", "sklearn.svm.SVC", "svm.SVC.fit", "svm.SVC.predict", "sklearn.metrics.accuracy_score", "svm.SVC.decision_function", "scorer.main.evaluate", "open", "valDF.iterrows", "results_file.write", "round", "round", "round", "round"], "function", ["home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main.evaluate"], ["def", "get_best_svm_model", "(", "feature_vector_train", ",", "label", ",", "feature_vector_valid", ")", ":", "\n", "    ", "param_grid", "=", "[", "{", "'kernel'", ":", "'linear'", ",", "'C'", ":", "np", ".", "logspace", "(", "-", "3", ",", "3", ",", "20", ")", ",", "'gamma'", ":", "[", "1", "]", "}", ",", "\n", "{", "'kernel'", ":", "'rbf'", ",", "'C'", ":", "np", ".", "logspace", "(", "-", "3", ",", "3", ",", "20", ")", ",", "\n", "'gamma'", ":", "np", ".", "logspace", "(", "-", "3", ",", "3", ",", "20", ")", "}", "]", "\n", "\n", "pca_list", "=", "[", "1.0", ",", "0.99", ",", "0.98", ",", "0.97", ",", "0.96", ",", "0.95", "]", "\n", "best_acc", "=", "0.0", "\n", "best_model", "=", "0", "\n", "best_prec", "=", "0.0", "\n", "best_pca_nk", "=", "0", "\n", "temp_xtrain", "=", "feature_vector_train", "\n", "temp_xval", "=", "feature_vector_valid", "\n", "for", "pca_nk", "in", "pca_list", ":", "\n", "        ", "if", "pca_nk", "!=", "1.0", ":", "\n", "            ", "pca", "=", "decomposition", ".", "PCA", "(", "n_components", "=", "pca_nk", ")", ".", "fit", "(", "temp_xtrain", ")", "\n", "feature_vector_train", "=", "pca", ".", "transform", "(", "temp_xtrain", ")", "\n", "feature_vector_valid", "=", "pca", ".", "transform", "(", "temp_xval", ")", "\n", "", "for", "params", "in", "param_grid", ":", "\n", "            ", "for", "C", "in", "params", "[", "'C'", "]", ":", "\n", "                ", "for", "gamma", "in", "params", "[", "'gamma'", "]", ":", "\n", "# Model with different parameters", "\n", "                    ", "model", "=", "svm", ".", "SVC", "(", "C", "=", "C", ",", "gamma", "=", "gamma", ",", "kernel", "=", "params", "[", "'kernel'", "]", ",", "random_state", "=", "42", ",", "class_weight", "=", "'balanced'", ")", "\n", "\n", "# fit the training dataset on the classifier", "\n", "model", ".", "fit", "(", "feature_vector_train", ",", "label", ")", "\n", "\n", "# predict the labels on validation dataset", "\n", "predictions", "=", "model", ".", "predict", "(", "feature_vector_valid", ")", "\n", "\n", "acc", "=", "metrics", ".", "accuracy_score", "(", "predictions", ",", "val_y", ")", "\n", "\n", "predicted_distance", "=", "model", ".", "decision_function", "(", "feature_vector_valid", ")", "\n", "results_fpath", "=", "my_loc", "+", "'/results/temp9_%d.tsv'", "%", "(", "args", ".", "out_file", ")", "\n", "with", "open", "(", "results_fpath", ",", "\"w\"", ")", "as", "results_file", ":", "\n", "                        ", "for", "i", ",", "line", "in", "valDF", ".", "iterrows", "(", ")", ":", "\n", "                            ", "dist", "=", "predicted_distance", "[", "i", "]", "\n", "results_file", ".", "write", "(", "\"{}\\t{}\\t{}\\t{}\\n\"", ".", "format", "(", "'covid-19'", ",", "line", "[", "'tweet_id'", "]", ",", "\n", "dist", ",", "\"w2v_all\"", ")", ")", "\n", "\n", "", "", "_", ",", "_", ",", "avg_precision", ",", "_", ",", "_", "=", "evaluate", "(", "'data/dev.tsv'", ",", "results_fpath", ")", "\n", "\n", "if", "round", "(", "avg_precision", ",", "4", ")", ">=", "round", "(", "best_prec", ",", "4", ")", "and", "round", "(", "acc", ",", "2", ")", ">=", "round", "(", "best_acc", ",", "2", ")", ":", "\n", "                        ", "best_prec", "=", "avg_precision", "\n", "best_acc", "=", "acc", "\n", "best_model", "=", "model", "\n", "best_pca_nk", "=", "pca_nk", "\n", "\n", "", "", "", "", "", "return", "best_acc", ",", "best_pca_nk", ",", "best_model", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_w2v_neposdep.get_spacy_doc_vectors": [[92, 104], ["numpy.array", "nlp", "vec_feat.append", "vec_feat.append", "numpy.zeros"], "function", ["None"], ["", "def", "get_spacy_doc_vectors", "(", "input_feats", ",", "nlp", ")", ":", "\n", "    ", "vec_feat", "=", "[", "]", "\n", "for", "tweet", "in", "input_feats", ":", "\n", "        ", "proc_tweet", "=", "nlp", "(", "tweet", ")", "\n", "if", "not", "proc_tweet", ".", "has_vector", "or", "proc_tweet", ".", "vector_norm", "==", "0", ":", "\n", "            ", "vec_feat", ".", "append", "(", "np", ".", "zeros", "(", "300", ")", ")", "\n", "", "else", ":", "\n", "            ", "tweet_vector", "=", "proc_tweet", ".", "vector", "\n", "tweet_vector", "=", "tweet_vector", "/", "proc_tweet", ".", "vector_norm", "\n", "vec_feat", ".", "append", "(", "tweet_vector", ")", "\n", "\n", "", "", "return", "np", ".", "array", "(", "vec_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_w2v_neposdep.get_gensim_doc_vectors": [[105, 123], ["numpy.array", "tweet.split", "vec_feat.append", "numpy.zeros", "numpy.array().mean", "np.array().mean.append", "numpy.linalg.norm", "model.wv.get_vector", "numpy.array"], "function", ["None"], ["", "def", "get_gensim_doc_vectors", "(", "input_feats", ",", "model", ",", "size", ")", ":", "\n", "    ", "vec_feat", "=", "[", "]", "\n", "for", "tweet", "in", "input_feats", ":", "\n", "        ", "words", "=", "tweet", ".", "split", "(", ")", "\n", "temp", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "            ", "if", "word", "in", "model", ".", "wv", ".", "vocab", ":", "\n", "                ", "temp", ".", "append", "(", "model", ".", "wv", ".", "get_vector", "(", "word", ")", ")", "\n", "\n", "", "", "if", "not", "temp", ":", "\n", "            ", "temp", "=", "np", ".", "zeros", "(", "size", ")", "\n", "", "else", ":", "\n", "            ", "temp", "=", "np", ".", "array", "(", "temp", ")", ".", "mean", "(", "axis", "=", "0", ")", "\n", "temp", "=", "temp", "/", "np", ".", "linalg", ".", "norm", "(", "temp", ",", "2", ")", "\n", "\n", "", "vec_feat", ".", "append", "(", "temp", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "vec_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_w2v_neposdep.get_tweet_data": [[125, 138], ["pandas.DataFrame", "twit_id.append", "twit_y.append", "twit_x.append", "numpy.array"], "function", ["None"], ["", "def", "get_tweet_data", "(", "tweet_list", ",", "w2v_type", ")", ":", "\n", "    ", "twit_x", ",", "twit_y", ",", "twit_id", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "twit_id", ".", "append", "(", "id", ")", "\n", "twit_y", ".", "append", "(", "tweet_list", "[", "id", "]", "[", "'worthy'", "]", ")", "\n", "twit_x", ".", "append", "(", "\" \"", ".", "join", "(", "tweet_list", "[", "id", "]", "[", "w2v_type", "]", ")", ")", "\n", "\n", "", "tweetDF", "=", "pd", ".", "DataFrame", "(", ")", "\n", "tweetDF", "[", "'text'", "]", "=", "twit_x", "\n", "tweetDF", "[", "'label'", "]", "=", "twit_y", "\n", "tweetDF", "[", "'tweet_id'", "]", "=", "twit_id", "\n", "\n", "return", "twit_x", ",", "np", ".", "array", "(", "twit_y", ")", ",", "tweetDF", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_w2v_neposdep.get_ne_feat": [[140, 156], ["numpy.array", "numpy.zeros", "nes_feat.append", "len"], "function", ["None"], ["", "def", "get_ne_feat", "(", "tweet_list", ",", "ner_type", ")", ":", "\n", "    ", "nes_feat", "=", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "temp", "=", "np", ".", "zeros", "(", "len", "(", "ne_tags", ")", ")", "\n", "proc_twit", "=", "tweet_list", "[", "id", "]", "[", "ner_type", "]", "\n", "for", "wd", "in", "proc_twit", ":", "\n", "            ", "ne_tag", "=", "wd", "[", "'label'", "]", "\n", "if", "ne_tag", "in", "ne_tags", ":", "\n", "                ", "temp", "[", "ne_tags", "[", "ne_tag", "]", "]", "+=", "1", "\n", "\n", "# if sum(temp) > 0:", "\n", "#     temp = temp/sum(temp)", "\n", "\n", "", "", "nes_feat", ".", "append", "(", "temp", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "nes_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_w2v_neposdep.get_pos_feat": [[158, 174], ["numpy.array", "numpy.zeros", "pos_feat.append", "len", "sum", "wd.split", "sum"], "function", ["None"], ["", "def", "get_pos_feat", "(", "tweet_list", ",", "pos_type", ")", ":", "\n", "    ", "pos_feat", "=", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "temp", "=", "np", ".", "zeros", "(", "len", "(", "pos_tags", ")", ")", "\n", "proc_twit", "=", "tweet_list", "[", "id", "]", "[", "pos_type", "]", "\n", "for", "wd", "in", "proc_twit", ":", "\n", "            ", "pos", "=", "wd", ".", "split", "(", "'_'", ")", "[", "1", "]", "\n", "if", "pos", "in", "pos_tags", ":", "\n", "                ", "temp", "[", "pos_tags", "[", "pos", "]", "]", "+=", "1", "\n", "\n", "", "", "if", "sum", "(", "temp", ")", ">", "0", ":", "\n", "            ", "temp", "=", "temp", "/", "sum", "(", "temp", ")", "\n", "\n", "", "pos_feat", ".", "append", "(", "temp", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "pos_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_w2v_neposdep.get_dep_relations": [[176, 191], ["set", "nlp", "set.add"], "function", ["None"], ["", "def", "get_dep_relations", "(", "w2v_type", ")", ":", "\n", "    ", "pos_tags", "=", "[", "'ADJ'", ",", "'ADV'", ",", "'NOUN'", ",", "'PROPN'", ",", "'VERB'", ",", "'NUM'", "]", "\n", "dep_dict", "=", "set", "(", ")", "\n", "for", "id", "in", "train_data", ":", "\n", "        ", "words", "=", "train_data", "[", "id", "]", "[", "w2v_type", "]", "\n", "sent", "=", "\" \"", ".", "join", "(", "words", ")", "\n", "\n", "doc", "=", "nlp", "(", "sent", ")", "\n", "\n", "for", "token", "in", "doc", ":", "\n", "            ", "if", "token", ".", "pos_", "in", "pos_tags", "and", "token", ".", "head", ".", "pos_", "in", "pos_tags", ":", "\n", "                ", "rel", "=", "token", ".", "pos_", "+", "'-'", "+", "token", ".", "dep_", "+", "'-'", "+", "token", ".", "head", ".", "pos_", "\n", "dep_dict", ".", "add", "(", "rel", ")", "\n", "\n", "", "", "", "return", "dep_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_w2v_neposdep.get_dep_feats": [[193, 214], ["numpy.array", "numpy.zeros", "nlp", "feats.append", "len", "sum", "sum"], "function", ["None"], ["", "def", "get_dep_feats", "(", "tweet_list", ",", "w2v_type", ")", ":", "\n", "    ", "feats", "=", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "temp", "=", "np", ".", "zeros", "(", "len", "(", "dep_map", ")", ")", "\n", "words", "=", "tweet_list", "[", "id", "]", "[", "w2v_type", "]", "\n", "sent", "=", "\" \"", ".", "join", "(", "words", ")", "\n", "\n", "doc", "=", "nlp", "(", "sent", ")", "\n", "\n", "for", "token", "in", "doc", ":", "\n", "            ", "rel", "=", "token", ".", "pos_", "+", "'-'", "+", "token", ".", "dep_", "+", "'-'", "+", "token", ".", "head", ".", "pos_", "\n", "\n", "if", "rel", "in", "dep_map", ":", "\n", "                ", "temp", "[", "dep_map", "[", "rel", "]", "]", "+=", "1", "\n", "\n", "", "", "if", "sum", "(", "temp", ")", ">", "0", ":", "\n", "            ", "temp", "=", "temp", "/", "sum", "(", "temp", ")", "\n", "\n", "", "feats", ".", "append", "(", "temp", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.ensemble_w2v_posdep.get_spacy_doc_vectors": [[36, 48], ["numpy.array", "nlp", "vec_feat.append", "vec_feat.append", "numpy.zeros"], "function", ["None"], ["def", "get_spacy_doc_vectors", "(", "input_feats", ",", "nlp", ")", ":", "\n", "    ", "vec_feat", "=", "[", "]", "\n", "for", "tweet", "in", "input_feats", ":", "\n", "        ", "proc_tweet", "=", "nlp", "(", "tweet", ")", "\n", "if", "not", "proc_tweet", ".", "has_vector", "or", "proc_tweet", ".", "vector_norm", "==", "0", ":", "\n", "            ", "vec_feat", ".", "append", "(", "np", ".", "zeros", "(", "300", ")", ")", "\n", "", "else", ":", "\n", "            ", "tweet_vector", "=", "proc_tweet", ".", "vector", "\n", "tweet_vector", "=", "tweet_vector", "/", "proc_tweet", ".", "vector_norm", "\n", "vec_feat", ".", "append", "(", "tweet_vector", ")", "\n", "\n", "", "", "return", "np", ".", "array", "(", "vec_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.ensemble_w2v_posdep.get_gensim_doc_vectors": [[50, 68], ["numpy.array", "tweet.split", "vec_feat.append", "numpy.zeros", "numpy.array().mean", "np.array().mean.append", "numpy.linalg.norm", "model.wv.get_vector", "numpy.array"], "function", ["None"], ["", "def", "get_gensim_doc_vectors", "(", "input_feats", ",", "model", ",", "size", ")", ":", "\n", "    ", "vec_feat", "=", "[", "]", "\n", "for", "tweet", "in", "input_feats", ":", "\n", "        ", "words", "=", "tweet", ".", "split", "(", ")", "\n", "temp", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "            ", "if", "word", "in", "model", ".", "wv", ".", "vocab", ":", "\n", "                ", "temp", ".", "append", "(", "model", ".", "wv", ".", "get_vector", "(", "word", ")", ")", "\n", "\n", "", "", "if", "not", "temp", ":", "\n", "            ", "temp", "=", "np", ".", "zeros", "(", "size", ")", "\n", "", "else", ":", "\n", "            ", "temp", "=", "np", ".", "array", "(", "temp", ")", ".", "mean", "(", "axis", "=", "0", ")", "\n", "temp", "=", "temp", "/", "np", ".", "linalg", ".", "norm", "(", "temp", ",", "2", ")", "\n", "\n", "", "vec_feat", ".", "append", "(", "temp", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "vec_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.ensemble_w2v_posdep.get_tweet_data": [[70, 83], ["pandas.DataFrame", "twit_id.append", "twit_y.append", "twit_x.append", "numpy.array().astype", "numpy.array"], "function", ["None"], ["", "def", "get_tweet_data", "(", "tweet_list", ",", "w2v_type", ")", ":", "\n", "    ", "twit_x", ",", "twit_y", ",", "twit_id", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "twit_id", ".", "append", "(", "id", ")", "\n", "twit_y", ".", "append", "(", "tweet_list", "[", "id", "]", "[", "'worthy'", "]", ")", "\n", "twit_x", ".", "append", "(", "\" \"", ".", "join", "(", "tweet_list", "[", "id", "]", "[", "w2v_type", "]", ")", ")", "\n", "\n", "", "tweetDF", "=", "pd", ".", "DataFrame", "(", ")", "\n", "tweetDF", "[", "'text'", "]", "=", "twit_x", "\n", "tweetDF", "[", "'label'", "]", "=", "twit_y", "\n", "tweetDF", "[", "'tweet_id'", "]", "=", "twit_id", "\n", "\n", "return", "twit_x", ",", "np", ".", "array", "(", "twit_y", ")", ".", "astype", "(", "np", ".", "int", ")", ",", "tweetDF", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.ensemble_w2v_posdep.get_pos_feat": [[85, 101], ["numpy.array", "numpy.zeros", "pos_feat.append", "len", "sum", "wd.split", "sum"], "function", ["None"], ["", "def", "get_pos_feat", "(", "tweet_list", ",", "pos_type", ")", ":", "\n", "    ", "pos_feat", "=", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "temp", "=", "np", ".", "zeros", "(", "len", "(", "pos_tags", ")", ")", "\n", "proc_twit", "=", "tweet_list", "[", "id", "]", "[", "pos_type", "]", "\n", "for", "wd", "in", "proc_twit", ":", "\n", "            ", "pos", "=", "wd", ".", "split", "(", "'_'", ")", "[", "1", "]", "\n", "if", "pos", "in", "pos_tags", ":", "\n", "                ", "temp", "[", "pos_tags", "[", "pos", "]", "]", "+=", "1", "\n", "\n", "", "", "if", "sum", "(", "temp", ")", ">", "0", ":", "\n", "            ", "temp", "=", "temp", "/", "sum", "(", "temp", ")", "\n", "\n", "", "pos_feat", ".", "append", "(", "temp", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "pos_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.ensemble_w2v_posdep.get_dep_relations": [[103, 119], ["set", "nlp", "set.add"], "function", ["None"], ["", "def", "get_dep_relations", "(", "w2v_type", ")", ":", "\n", "    ", "pos_tags", "=", "[", "'ADJ'", ",", "'ADV'", ",", "'NOUN'", ",", "'PROPN'", ",", "'VERB'", ",", "'NUM'", "]", "\n", "dep_dict", "=", "set", "(", ")", "\n", "for", "id", "in", "train_data", ":", "\n", "        ", "words", "=", "train_data", "[", "id", "]", "[", "w2v_type", "]", "\n", "sent", "=", "\" \"", ".", "join", "(", "words", ")", "\n", "\n", "doc", "=", "nlp", "(", "sent", ")", "\n", "\n", "for", "token", "in", "doc", ":", "\n", "            ", "if", "token", ".", "pos_", "in", "pos_tags", "and", "token", ".", "head", ".", "pos_", "in", "pos_tags", ":", "\n", "# rel = token.pos_+'-'+token.dep_+'-'+token.head.pos_", "\n", "                ", "rel", "=", "token", ".", "pos_", "+", "'-'", "+", "token", ".", "dep_", "\n", "dep_dict", ".", "add", "(", "rel", ")", "\n", "\n", "", "", "", "return", "dep_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.ensemble_w2v_posdep.get_dep_feats": [[121, 143], ["numpy.array", "numpy.zeros", "nlp", "feats.append", "len", "sum", "sum"], "function", ["None"], ["", "def", "get_dep_feats", "(", "tweet_list", ",", "w2v_type", ")", ":", "\n", "    ", "feats", "=", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "temp", "=", "np", ".", "zeros", "(", "len", "(", "dep_map", ")", ")", "\n", "words", "=", "tweet_list", "[", "id", "]", "[", "w2v_type", "]", "\n", "sent", "=", "\" \"", ".", "join", "(", "words", ")", "\n", "\n", "doc", "=", "nlp", "(", "sent", ")", "\n", "\n", "for", "token", "in", "doc", ":", "\n", "# rel = token.pos_+'-'+token.dep_+'-'+token.head.pos_", "\n", "            ", "rel", "=", "token", ".", "pos_", "+", "'-'", "+", "token", ".", "dep_", "\n", "if", "rel", "in", "dep_map", ":", "\n", "                ", "temp", "[", "dep_map", "[", "rel", "]", "]", "+=", "1", "\n", "\n", "\n", "", "", "if", "sum", "(", "temp", ")", ">", "0", ":", "\n", "            ", "temp", "=", "temp", "/", "sum", "(", "temp", ")", "\n", "\n", "", "feats", ".", "append", "(", "temp", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_w2v_posdep.get_best_svm_model": [[42, 91], ["print", "numpy.logspace", "numpy.logspace", "sklearn.decomposition.PCA().fit", "decomposition.PCA().fit.transform", "decomposition.PCA().fit.transform", "sklearn.decomposition.PCA", "SVC", "SVC.fit", "SVC.score", "SVC.decision_function", "scorer.main.evaluate", "open", "valDF.iterrows", "results_file.write", "round", "round", "round", "round"], "function", ["home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main.evaluate"], ["def", "get_best_svm_model", "(", "feature_vector_train", ",", "label", ",", "feature_vector_valid", ",", "wordmod", ")", ":", "\n", "# param_grid = [{'kernel':'linear', 'C': np.logspace(-2, 2, 10), 'gamma': [1]}, ", "\n", "#               {'kernel':'rbf', 'C': np.logspace(-2, 2, 10), ", "\n", "#               'gamma': np.logspace(-2, 2, 10)}]", "\n", "    ", "param_grid", "=", "[", "{", "'kernel'", ":", "'rbf'", ",", "'C'", ":", "np", ".", "logspace", "(", "-", "3", ",", "3", ",", "30", ")", ",", "\n", "'gamma'", ":", "np", ".", "logspace", "(", "-", "3", ",", "3", ",", "30", ")", "}", "]", "\n", "\n", "pca_list", "=", "[", "1.0", ",", "0.99", ",", "0.98", ",", "0.97", ",", "0.96", ",", "0.95", "]", "\n", "best_acc", "=", "0.0", "\n", "best_model", "=", "0", "\n", "best_prec", "=", "0.0", "\n", "best_pca_nk", "=", "0", "\n", "temp_xtrain", "=", "feature_vector_train", "\n", "temp_xval", "=", "feature_vector_valid", "\n", "for", "pca_nk", "in", "pca_list", ":", "\n", "        ", "print", "(", "pca_nk", ")", "\n", "if", "pca_nk", "!=", "1.0", ":", "\n", "            ", "pca", "=", "decomposition", ".", "PCA", "(", "n_components", "=", "pca_nk", ")", ".", "fit", "(", "temp_xtrain", ")", "\n", "feature_vector_train", "=", "pca", ".", "transform", "(", "temp_xtrain", ")", "\n", "feature_vector_valid", "=", "pca", ".", "transform", "(", "temp_xval", ")", "\n", "", "for", "params", "in", "param_grid", ":", "\n", "            ", "for", "C", "in", "params", "[", "'C'", "]", ":", "\n", "                ", "for", "gamma", "in", "params", "[", "'gamma'", "]", ":", "\n", "# Model with different parameters", "\n", "                    ", "model", "=", "SVC", "(", "C", "=", "C", ",", "gamma", "=", "gamma", ",", "kernel", "=", "params", "[", "'kernel'", "]", ",", "random_state", "=", "42", ",", "class_weight", "=", "'balanced'", ",", "gpu_id", "=", "args", ".", "gpu_id", ")", "\n", "\n", "# fit the training dataset on the classifier", "\n", "model", ".", "fit", "(", "feature_vector_train", ",", "label", ")", "\n", "\n", "# predict the acc on validation dataset", "\n", "acc", "=", "model", ".", "score", "(", "feature_vector_valid", ",", "val_y", ")", "\n", "\n", "predicted_distance", "=", "model", ".", "decision_function", "(", "feature_vector_valid", ")", "\n", "results_fpath", "=", "my_loc", "+", "'/results/task1_%s_posdep_svm_dev_%d_%d.tsv'", "%", "(", "wordmod", ",", "args", ".", "tag_type", ",", "args", ".", "norm_type", ")", "\n", "with", "open", "(", "results_fpath", ",", "\"w\"", ")", "as", "results_file", ":", "\n", "                        ", "for", "i", ",", "line", "in", "valDF", ".", "iterrows", "(", ")", ":", "\n", "                            ", "dist", "=", "predicted_distance", "[", "i", "]", "[", "0", "]", "\n", "results_file", ".", "write", "(", "\"{}\\t{}\\t{}\\t{}\\n\"", ".", "format", "(", "'covid-19'", ",", "line", "[", "'tweet_id'", "]", ",", "\n", "dist", ",", "\"w2v_posdep\"", ")", ")", "\n", "\n", "", "", "_", ",", "_", ",", "avg_precision", ",", "_", ",", "_", "=", "evaluate", "(", "'data/dev.tsv'", ",", "results_fpath", ")", "\n", "\n", "if", "round", "(", "avg_precision", ",", "4", ")", ">=", "round", "(", "best_prec", ",", "4", ")", "and", "round", "(", "acc", ",", "2", ")", ">=", "round", "(", "best_acc", ",", "2", ")", ":", "\n", "                        ", "best_prec", "=", "avg_precision", "\n", "best_acc", "=", "acc", "\n", "best_model", "=", "model", "\n", "best_pca_nk", "=", "pca_nk", "\n", "\n", "", "", "", "", "", "return", "best_acc", ",", "best_pca_nk", ",", "best_model", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_w2v_posdep.get_spacy_doc_vectors": [[93, 105], ["numpy.array", "nlp", "vec_feat.append", "vec_feat.append", "numpy.zeros"], "function", ["None"], ["", "def", "get_spacy_doc_vectors", "(", "input_feats", ",", "nlp", ")", ":", "\n", "    ", "vec_feat", "=", "[", "]", "\n", "for", "tweet", "in", "input_feats", ":", "\n", "        ", "proc_tweet", "=", "nlp", "(", "tweet", ")", "\n", "if", "not", "proc_tweet", ".", "has_vector", "or", "proc_tweet", ".", "vector_norm", "==", "0", ":", "\n", "            ", "vec_feat", ".", "append", "(", "np", ".", "zeros", "(", "300", ")", ")", "\n", "", "else", ":", "\n", "            ", "tweet_vector", "=", "proc_tweet", ".", "vector", "\n", "tweet_vector", "=", "tweet_vector", "/", "proc_tweet", ".", "vector_norm", "\n", "vec_feat", ".", "append", "(", "tweet_vector", ")", "\n", "\n", "", "", "return", "np", ".", "array", "(", "vec_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_w2v_posdep.get_gensim_doc_vectors": [[107, 125], ["numpy.array", "tweet.split", "vec_feat.append", "numpy.zeros", "numpy.array().mean", "np.array().mean.append", "numpy.linalg.norm", "model.wv.get_vector", "numpy.array"], "function", ["None"], ["", "def", "get_gensim_doc_vectors", "(", "input_feats", ",", "model", ",", "size", ")", ":", "\n", "    ", "vec_feat", "=", "[", "]", "\n", "for", "tweet", "in", "input_feats", ":", "\n", "        ", "words", "=", "tweet", ".", "split", "(", ")", "\n", "temp", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "            ", "if", "word", "in", "model", ".", "wv", ".", "vocab", ":", "\n", "                ", "temp", ".", "append", "(", "model", ".", "wv", ".", "get_vector", "(", "word", ")", ")", "\n", "\n", "", "", "if", "not", "temp", ":", "\n", "            ", "temp", "=", "np", ".", "zeros", "(", "size", ")", "\n", "", "else", ":", "\n", "            ", "temp", "=", "np", ".", "array", "(", "temp", ")", ".", "mean", "(", "axis", "=", "0", ")", "\n", "temp", "=", "temp", "/", "np", ".", "linalg", ".", "norm", "(", "temp", ",", "2", ")", "\n", "\n", "", "vec_feat", ".", "append", "(", "temp", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "vec_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_w2v_posdep.get_tweet_data": [[127, 140], ["pandas.DataFrame", "twit_id.append", "twit_y.append", "twit_x.append", "numpy.array().astype", "numpy.array"], "function", ["None"], ["", "def", "get_tweet_data", "(", "tweet_list", ",", "w2v_type", ")", ":", "\n", "    ", "twit_x", ",", "twit_y", ",", "twit_id", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "twit_id", ".", "append", "(", "id", ")", "\n", "twit_y", ".", "append", "(", "tweet_list", "[", "id", "]", "[", "'worthy'", "]", ")", "\n", "twit_x", ".", "append", "(", "\" \"", ".", "join", "(", "tweet_list", "[", "id", "]", "[", "w2v_type", "]", ")", ")", "\n", "\n", "", "tweetDF", "=", "pd", ".", "DataFrame", "(", ")", "\n", "tweetDF", "[", "'text'", "]", "=", "twit_x", "\n", "tweetDF", "[", "'label'", "]", "=", "twit_y", "\n", "tweetDF", "[", "'tweet_id'", "]", "=", "twit_id", "\n", "\n", "return", "twit_x", ",", "np", ".", "array", "(", "twit_y", ")", ".", "astype", "(", "np", ".", "int", ")", ",", "tweetDF", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_w2v_posdep.get_pos_feat": [[142, 158], ["numpy.array", "numpy.zeros", "pos_feat.append", "len", "sum", "wd.split", "sum"], "function", ["None"], ["", "def", "get_pos_feat", "(", "tweet_list", ",", "pos_type", ")", ":", "\n", "    ", "pos_feat", "=", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "temp", "=", "np", ".", "zeros", "(", "len", "(", "pos_tags", ")", ")", "\n", "proc_twit", "=", "tweet_list", "[", "id", "]", "[", "pos_type", "]", "\n", "for", "wd", "in", "proc_twit", ":", "\n", "            ", "pos", "=", "wd", ".", "split", "(", "'_'", ")", "[", "1", "]", "\n", "if", "pos", "in", "pos_tags", ":", "\n", "                ", "temp", "[", "pos_tags", "[", "pos", "]", "]", "+=", "1", "\n", "\n", "", "", "if", "sum", "(", "temp", ")", ">", "0", ":", "\n", "            ", "temp", "=", "temp", "/", "sum", "(", "temp", ")", "\n", "\n", "", "pos_feat", ".", "append", "(", "temp", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "pos_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_w2v_posdep.get_dep_relations": [[160, 176], ["set", "nlp", "set.add"], "function", ["None"], ["", "def", "get_dep_relations", "(", "w2v_type", ")", ":", "\n", "    ", "pos_tags", "=", "[", "'ADJ'", ",", "'ADV'", ",", "'NOUN'", ",", "'PROPN'", ",", "'VERB'", ",", "'NUM'", "]", "\n", "dep_dict", "=", "set", "(", ")", "\n", "for", "id", "in", "train_data", ":", "\n", "        ", "words", "=", "train_data", "[", "id", "]", "[", "w2v_type", "]", "\n", "sent", "=", "\" \"", ".", "join", "(", "words", ")", "\n", "\n", "doc", "=", "nlp", "(", "sent", ")", "\n", "\n", "for", "token", "in", "doc", ":", "\n", "            ", "if", "token", ".", "pos_", "in", "pos_tags", "and", "token", ".", "head", ".", "pos_", "in", "pos_tags", ":", "\n", "# rel = token.pos_+'-'+token.dep_+'-'+token.head.pos_", "\n", "                ", "rel", "=", "token", ".", "pos_", "+", "'-'", "+", "token", ".", "dep_", "\n", "dep_dict", ".", "add", "(", "rel", ")", "\n", "\n", "", "", "", "return", "dep_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_w2v_posdep.get_dep_feats": [[178, 200], ["numpy.array", "numpy.zeros", "nlp", "feats.append", "len", "sum", "sum"], "function", ["None"], ["", "def", "get_dep_feats", "(", "tweet_list", ",", "w2v_type", ")", ":", "\n", "    ", "feats", "=", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "temp", "=", "np", ".", "zeros", "(", "len", "(", "dep_map", ")", ")", "\n", "words", "=", "tweet_list", "[", "id", "]", "[", "w2v_type", "]", "\n", "sent", "=", "\" \"", ".", "join", "(", "words", ")", "\n", "\n", "doc", "=", "nlp", "(", "sent", ")", "\n", "\n", "for", "token", "in", "doc", ":", "\n", "# rel = token.pos_+'-'+token.dep_+'-'+token.head.pos_", "\n", "            ", "rel", "=", "token", ".", "pos_", "+", "'-'", "+", "token", ".", "dep_", "\n", "if", "rel", "in", "dep_map", ":", "\n", "                ", "temp", "[", "dep_map", "[", "rel", "]", "]", "+=", "1", "\n", "\n", "\n", "", "", "if", "sum", "(", "temp", ")", ">", "0", ":", "\n", "            ", "temp", "=", "temp", "/", "sum", "(", "temp", ")", "\n", "\n", "", "feats", ".", "append", "(", "temp", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.helper_funcs.get_text_processor": [[21, 49], ["ekphrasis.classes.preprocessor.TextPreProcessor", "ekphrasis.classes.tokenizer.SocialTokenizer"], "function", ["None"], ["corrector", "=", "word_stats", ",", "\n", "\n", "unpack_hashtags", "=", "True", ",", "# perform word segmentation on hashtags", "\n", "unpack_contractions", "=", "True", ",", "# Unpack contractions (can't -> can not)", "\n", "spell_correct_elong", "=", "False", ",", "# spell correction for elongated words", "\n", "\n", "# select a tokenizer. You can use SocialTokenizer, or pass your own", "\n", "# the tokenizer, should take as input a string and return a list of tokens", "\n", "tokenizer", "=", "SocialTokenizer", "(", "lowercase", "=", "True", ")", ".", "tokenize", ",", "\n", "\n", "# list of dictionaries, for replacing tokens extracted from the text,", "\n", "# with other expressions. You can pass more than one dictionaries.", "\n", "dicts", "=", "[", "emoticons", "]", "\n", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.helper_funcs.avg_wordembs_wostop": [[55, 66], ["range", "numpy.array", "numpy.mean", "len", "numpy.any", "numpy.zeros().astype", "np.array.append", "numpy.zeros"], "function", ["None"], []], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.helper_funcs.get_word_sent_embedding": [[68, 146], ["tokenizer.tokenize", "tokenizer.convert_tokens_to_ids", "torch.tensor().to", "torch.tensor().to", "torch.stack", "torch.squeeze", "token_embeddings.permute.permute", "numpy.mean", "helper_funcs.avg_wordembs_wostop", "numpy.mean", "helper_funcs.avg_wordembs_wostop", "torch.mean().cpu().numpy", "helper_funcs.avg_wordembs_wostop", "torch.mean().cpu().numpy", "helper_funcs.avg_wordembs_wostop", "len", "torch.no_grad", "model", "torch.cat", "token_vecs_cat.append", "len", "torch.sum", "token_vecs_sum.append", "len", "token_vecs.cpu().numpy", "len", "token_vecs.cpu().numpy", "len", "torch.tensor", "torch.tensor", "torch.cat.cpu().numpy", "torch.sum.cpu().numpy", "torch.mean().cpu", "torch.mean().cpu", "token_vecs.cpu", "token_vecs.cpu", "torch.cat.cpu", "torch.sum.cpu", "torch.mean", "torch.mean"], "function", ["home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.helper_funcs.avg_wordembs_wostop", "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.helper_funcs.avg_wordembs_wostop", "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.helper_funcs.avg_wordembs_wostop", "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.helper_funcs.avg_wordembs_wostop"], []], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_bert_wordpos.get_best_svm_model": [[38, 88], ["print", "numpy.logspace", "numpy.logspace", "sklearn.decomposition.PCA().fit", "decomposition.PCA().fit.transform", "decomposition.PCA().fit.transform", "sklearn.decomposition.PCA", "SVC", "SVC.fit", "SVC.score", "SVC.decision_function", "scorer.main.evaluate", "open", "valDF.iterrows", "results_file.write", "round", "round", "round", "round"], "function", ["home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main.evaluate"], ["def", "get_best_svm_model", "(", "feature_vector_train", ",", "label", ",", "feature_vector_valid", ",", "fname", ",", "emb_type", ")", ":", "\n", "# param_grid = [{'kernel':'linear', 'C': np.logspace(-2, 2, 10), 'gamma': [1]}, ", "\n", "#               {'kernel':'rbf', 'C': np.logspace(-2, 2, 10), ", "\n", "#               'gamma': np.logspace(-2, 2, 10)}]", "\n", "    ", "param_grid", "=", "[", "{", "'kernel'", ":", "'rbf'", ",", "'C'", ":", "np", ".", "logspace", "(", "-", "3", ",", "3", ",", "30", ")", ",", "\n", "'gamma'", ":", "np", ".", "logspace", "(", "-", "3", ",", "3", ",", "30", ")", "}", "]", "\n", "\n", "pca_list", "=", "[", "1.0", ",", "0.99", ",", "0.98", ",", "0.97", ",", "0.96", ",", "0.95", "]", "\n", "best_acc", "=", "0.0", "\n", "best_model", "=", "0", "\n", "best_prec", "=", "0.0", "\n", "best_pca_nk", "=", "0", "\n", "temp_xtrain", "=", "feature_vector_train", "\n", "temp_xval", "=", "feature_vector_valid", "\n", "for", "pca_nk", "in", "pca_list", ":", "\n", "        ", "print", "(", "pca_nk", ")", "\n", "if", "pca_nk", "!=", "1.0", ":", "\n", "            ", "pca", "=", "decomposition", ".", "PCA", "(", "n_components", "=", "pca_nk", ")", ".", "fit", "(", "temp_xtrain", ")", "\n", "feature_vector_train", "=", "pca", ".", "transform", "(", "temp_xtrain", ")", "\n", "feature_vector_valid", "=", "pca", ".", "transform", "(", "temp_xval", ")", "\n", "\n", "", "for", "params", "in", "param_grid", ":", "\n", "            ", "for", "C", "in", "params", "[", "'C'", "]", ":", "\n", "                ", "for", "gamma", "in", "params", "[", "'gamma'", "]", ":", "\n", "# Model with different parameters", "\n", "                    ", "model", "=", "SVC", "(", "C", "=", "C", ",", "gamma", "=", "gamma", ",", "kernel", "=", "params", "[", "'kernel'", "]", ",", "random_state", "=", "42", ",", "class_weight", "=", "'balanced'", ",", "gpu_id", "=", "args", ".", "gpu_id", ")", "\n", "\n", "# fit the training dataset on the classifier", "\n", "model", ".", "fit", "(", "feature_vector_train", ",", "label", ")", "\n", "\n", "# predict the acc on validation dataset", "\n", "acc", "=", "model", ".", "score", "(", "feature_vector_valid", ",", "val_y", ")", "\n", "\n", "predicted_distance", "=", "model", ".", "decision_function", "(", "feature_vector_valid", ")", "\n", "results_fpath", "=", "my_loc", "+", "'/results/bert_word_pos_%s_%s_svm_norm%d.tsv'", "%", "(", "fname", ",", "emb_type", ",", "args", ".", "normalize", ")", "\n", "with", "open", "(", "results_fpath", ",", "\"w\"", ")", "as", "results_file", ":", "\n", "                        ", "for", "i", ",", "line", "in", "valDF", ".", "iterrows", "(", ")", ":", "\n", "                            ", "dist", "=", "predicted_distance", "[", "i", "]", "[", "0", "]", "\n", "results_file", ".", "write", "(", "\"{}\\t{}\\t{}\\t{}\\n\"", ".", "format", "(", "'covid-19'", ",", "line", "[", "'tweet_id'", "]", ",", "\n", "dist", ",", "\"bert_wd_pos\"", ")", ")", "\n", "\n", "", "", "_", ",", "_", ",", "avg_precision", ",", "_", ",", "_", "=", "evaluate", "(", "'data/dev.tsv'", ",", "results_fpath", ")", "\n", "\n", "if", "round", "(", "avg_precision", ",", "4", ")", ">=", "round", "(", "best_prec", ",", "4", ")", "and", "round", "(", "acc", ",", "2", ")", ">=", "round", "(", "best_acc", ",", "2", ")", ":", "\n", "                        ", "best_prec", "=", "avg_precision", "\n", "best_acc", "=", "acc", "\n", "best_model", "=", "model", "\n", "best_pca_nk", "=", "pca_nk", "\n", "\n", "", "", "", "", "", "return", "best_acc", ",", "best_pca_nk", ",", "best_model", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_bert_wordpos.get_tweet_data": [[91, 102], ["pandas.DataFrame", "twit_id.append", "twit_y.append", "numpy.array().astype", "numpy.array"], "function", ["None"], ["", "def", "get_tweet_data", "(", "tweet_list", ")", ":", "\n", "    ", "twit_y", ",", "twit_id", "=", "[", "]", ",", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "twit_id", ".", "append", "(", "id", ")", "\n", "twit_y", ".", "append", "(", "tweet_list", "[", "id", "]", "[", "'worthy'", "]", ")", "\n", "\n", "", "tweetDF", "=", "pd", ".", "DataFrame", "(", ")", "\n", "tweetDF", "[", "'label'", "]", "=", "twit_y", "\n", "tweetDF", "[", "'tweet_id'", "]", "=", "twit_id", "\n", "\n", "return", "np", ".", "array", "(", "twit_y", ")", ".", "astype", "(", "np", ".", "int", ")", ",", "tweetDF", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_bert_wordpos.get_pos_feat": [[104, 120], ["numpy.array", "numpy.zeros", "pos_feat.append", "len", "sum", "wd.split", "sum"], "function", ["None"], ["", "def", "get_pos_feat", "(", "tweet_list", ",", "pos_type", ")", ":", "\n", "    ", "pos_feat", "=", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "temp", "=", "np", ".", "zeros", "(", "len", "(", "pos_tags", ")", ")", "\n", "proc_twit", "=", "tweet_list", "[", "id", "]", "[", "pos_type", "]", "\n", "for", "wd", "in", "proc_twit", ":", "\n", "            ", "pos", "=", "wd", ".", "split", "(", "'_'", ")", "[", "1", "]", "\n", "if", "pos", "in", "pos_tags", ":", "\n", "                ", "temp", "[", "pos_tags", "[", "pos", "]", "]", "+=", "1", "\n", "\n", "", "", "if", "sum", "(", "temp", ")", ">", "0", ":", "\n", "            ", "temp", "=", "temp", "/", "sum", "(", "temp", ")", "\n", "\n", "", "pos_feat", ".", "append", "(", "temp", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "pos_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_bert_posdep.get_best_svm_model": [[38, 88], ["print", "numpy.logspace", "numpy.logspace", "sklearn.decomposition.PCA().fit", "decomposition.PCA().fit.transform", "decomposition.PCA().fit.transform", "sklearn.decomposition.PCA", "SVC", "SVC.fit", "SVC.score", "SVC.decision_function", "scorer.main.evaluate", "open", "valDF.iterrows", "results_file.write", "round", "round", "round", "round"], "function", ["home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main.evaluate"], ["def", "get_best_svm_model", "(", "feature_vector_train", ",", "label", ",", "feature_vector_valid", ",", "fname", ",", "emb_type", ")", ":", "\n", "# param_grid = [{'kernel':'linear', 'C': np.logspace(-2, 2, 10), 'gamma': [1]}, ", "\n", "#               {'kernel':'rbf', 'C': np.logspace(-2, 2, 10), ", "\n", "#               'gamma': np.logspace(-2, 2, 10)}]", "\n", "    ", "param_grid", "=", "[", "{", "'kernel'", ":", "'rbf'", ",", "'C'", ":", "np", ".", "logspace", "(", "-", "3", ",", "3", ",", "30", ")", ",", "\n", "'gamma'", ":", "np", ".", "logspace", "(", "-", "3", ",", "3", ",", "30", ")", "}", "]", "\n", "\n", "pca_list", "=", "[", "1.0", ",", "0.99", ",", "0.98", ",", "0.97", ",", "0.96", ",", "0.95", "]", "\n", "best_acc", "=", "0.0", "\n", "best_model", "=", "0", "\n", "best_prec", "=", "0.0", "\n", "best_pca_nk", "=", "0", "\n", "temp_xtrain", "=", "feature_vector_train", "\n", "temp_xval", "=", "feature_vector_valid", "\n", "for", "pca_nk", "in", "pca_list", ":", "\n", "        ", "print", "(", "pca_nk", ")", "\n", "if", "pca_nk", "!=", "1.0", ":", "\n", "            ", "pca", "=", "decomposition", ".", "PCA", "(", "n_components", "=", "pca_nk", ")", ".", "fit", "(", "temp_xtrain", ")", "\n", "feature_vector_train", "=", "pca", ".", "transform", "(", "temp_xtrain", ")", "\n", "feature_vector_valid", "=", "pca", ".", "transform", "(", "temp_xval", ")", "\n", "\n", "", "for", "params", "in", "param_grid", ":", "\n", "            ", "for", "C", "in", "params", "[", "'C'", "]", ":", "\n", "                ", "for", "gamma", "in", "params", "[", "'gamma'", "]", ":", "\n", "# Model with different parameters", "\n", "                    ", "model", "=", "SVC", "(", "C", "=", "C", ",", "gamma", "=", "gamma", ",", "kernel", "=", "params", "[", "'kernel'", "]", ",", "random_state", "=", "42", ",", "class_weight", "=", "'balanced'", ",", "gpu_id", "=", "args", ".", "gpu_id", ")", "\n", "\n", "# fit the training dataset on the classifier", "\n", "model", ".", "fit", "(", "feature_vector_train", ",", "label", ")", "\n", "\n", "# predict the acc on validation dataset", "\n", "acc", "=", "model", ".", "score", "(", "feature_vector_valid", ",", "val_y", ")", "\n", "\n", "predicted_distance", "=", "model", ".", "decision_function", "(", "feature_vector_valid", ")", "\n", "results_fpath", "=", "my_loc", "+", "'/results/bert_word_posdep_%s_%s_svm_norm%d.tsv'", "%", "(", "fname", ",", "emb_type", ",", "args", ".", "normalize", ")", "\n", "with", "open", "(", "results_fpath", ",", "\"w\"", ")", "as", "results_file", ":", "\n", "                        ", "for", "i", ",", "line", "in", "valDF", ".", "iterrows", "(", ")", ":", "\n", "                            ", "dist", "=", "predicted_distance", "[", "i", "]", "[", "0", "]", "\n", "results_file", ".", "write", "(", "\"{}\\t{}\\t{}\\t{}\\n\"", ".", "format", "(", "'covid-19'", ",", "line", "[", "'tweet_id'", "]", ",", "\n", "dist", ",", "\"bert_wd_posdep\"", ")", ")", "\n", "\n", "", "", "_", ",", "_", ",", "avg_precision", ",", "_", ",", "_", "=", "evaluate", "(", "'data/dev.tsv'", ",", "results_fpath", ")", "\n", "\n", "if", "round", "(", "avg_precision", ",", "4", ")", ">=", "round", "(", "best_prec", ",", "4", ")", "and", "round", "(", "acc", ",", "2", ")", ">=", "round", "(", "best_acc", ",", "2", ")", ":", "\n", "                        ", "best_prec", "=", "avg_precision", "\n", "best_acc", "=", "acc", "\n", "best_model", "=", "model", "\n", "best_pca_nk", "=", "pca_nk", "\n", "\n", "", "", "", "", "", "return", "best_acc", ",", "best_pca_nk", ",", "best_model", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_bert_posdep.get_tweet_data": [[91, 102], ["pandas.DataFrame", "twit_id.append", "twit_y.append", "numpy.array().astype", "numpy.array"], "function", ["None"], ["", "def", "get_tweet_data", "(", "tweet_list", ")", ":", "\n", "    ", "twit_y", ",", "twit_id", "=", "[", "]", ",", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "twit_id", ".", "append", "(", "id", ")", "\n", "twit_y", ".", "append", "(", "tweet_list", "[", "id", "]", "[", "'worthy'", "]", ")", "\n", "\n", "", "tweetDF", "=", "pd", ".", "DataFrame", "(", ")", "\n", "tweetDF", "[", "'label'", "]", "=", "twit_y", "\n", "tweetDF", "[", "'tweet_id'", "]", "=", "twit_id", "\n", "\n", "return", "np", ".", "array", "(", "twit_y", ")", ".", "astype", "(", "np", ".", "int", ")", ",", "tweetDF", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_bert_posdep.get_pos_feat": [[104, 120], ["numpy.array", "numpy.zeros", "pos_feat.append", "len", "sum", "wd.split", "sum"], "function", ["None"], ["", "def", "get_pos_feat", "(", "tweet_list", ",", "pos_type", ")", ":", "\n", "    ", "pos_feat", "=", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "temp", "=", "np", ".", "zeros", "(", "len", "(", "pos_tags", ")", ")", "\n", "proc_twit", "=", "tweet_list", "[", "id", "]", "[", "pos_type", "]", "\n", "for", "wd", "in", "proc_twit", ":", "\n", "            ", "pos", "=", "wd", ".", "split", "(", "'_'", ")", "[", "1", "]", "\n", "if", "pos", "in", "pos_tags", ":", "\n", "                ", "temp", "[", "pos_tags", "[", "pos", "]", "]", "+=", "1", "\n", "\n", "", "", "if", "sum", "(", "temp", ")", ">", "0", ":", "\n", "            ", "temp", "=", "temp", "/", "sum", "(", "temp", ")", "\n", "\n", "", "pos_feat", ".", "append", "(", "temp", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "pos_feat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_bert_posdep.get_dep_relations": [[123, 139], ["set", "nlp", "set.add"], "function", ["None"], ["", "def", "get_dep_relations", "(", "train_data", ",", "w2v_type", ")", ":", "\n", "    ", "pos_tags", "=", "[", "'ADJ'", ",", "'ADV'", ",", "'NOUN'", ",", "'PROPN'", ",", "'VERB'", ",", "'NUM'", "]", "\n", "dep_dict", "=", "set", "(", ")", "\n", "for", "id", "in", "train_data", ":", "\n", "        ", "words", "=", "train_data", "[", "id", "]", "[", "w2v_type", "]", "\n", "sent", "=", "\" \"", ".", "join", "(", "words", ")", "\n", "\n", "doc", "=", "nlp", "(", "sent", ")", "\n", "\n", "for", "token", "in", "doc", ":", "\n", "            ", "if", "token", ".", "pos_", "in", "pos_tags", "and", "token", ".", "head", ".", "pos_", "in", "pos_tags", ":", "\n", "# rel = token.pos_+'-'+token.dep_+'-'+token.head.pos_", "\n", "                ", "rel", "=", "token", ".", "pos_", "+", "'-'", "+", "token", ".", "dep_", "\n", "dep_dict", ".", "add", "(", "rel", ")", "\n", "\n", "", "", "", "return", "dep_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.task_1.svm_bert_posdep.get_dep_feats": [[141, 163], ["numpy.array", "numpy.zeros", "nlp", "feats.append", "len", "sum", "sum"], "function", ["None"], ["", "def", "get_dep_feats", "(", "tweet_list", ",", "w2v_type", ")", ":", "\n", "    ", "feats", "=", "[", "]", "\n", "for", "id", "in", "tweet_list", ":", "\n", "        ", "temp", "=", "np", ".", "zeros", "(", "len", "(", "dep_map", ")", ")", "\n", "words", "=", "tweet_list", "[", "id", "]", "[", "w2v_type", "]", "\n", "sent", "=", "\" \"", ".", "join", "(", "words", ")", "\n", "\n", "doc", "=", "nlp", "(", "sent", ")", "\n", "\n", "for", "token", "in", "doc", ":", "\n", "# rel = token.pos_+'-'+token.dep_+'-'+token.head.pos_", "\n", "            ", "rel", "=", "token", ".", "pos_", "+", "'-'", "+", "token", ".", "dep_", "\n", "if", "rel", "in", "dep_map", ":", "\n", "                ", "temp", "[", "dep_map", "[", "rel", "]", "]", "+=", "1", "\n", "\n", "\n", "", "", "if", "sum", "(", "temp", ")", ">", "0", ":", "\n", "            ", "temp", "=", "temp", "/", "sum", "(", "temp", ")", "\n", "\n", "", "feats", ".", "append", "(", "temp", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "feats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.format_checker.main.check_format": [[21, 35], ["open", "out.read().strip", "enumerate", "out.read().strip.split", "line.strip().split", "int", "float", "out.read", "_LINE_PATTERN_A.match", "logging.error", "float.strip", "line.strip"], "function", ["None"], ["def", "check_format", "(", "file_path", ")", ":", "\n", "    ", "with", "open", "(", "file_path", ",", "encoding", "=", "'UTF-8'", ")", "as", "out", ":", "\n", "        ", "file_content", "=", "out", ".", "read", "(", ")", ".", "strip", "(", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "file_content", ".", "split", "(", "'\\n'", ")", ")", ":", "\n", "            ", "topic_id", ",", "tweet_id", ",", "score", ",", "run_id", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "\n", "if", "not", "_LINE_PATTERN_A", ".", "match", "(", "\"%s\\t%s\"", "%", "(", "tweet_id", ",", "score", ")", ")", ":", "\n", "# 1. Check line format.", "\n", "                ", "logging", ".", "error", "(", "\"Wrong line format: {}\"", ".", "format", "(", "line", ")", ")", "\n", "return", "False", "\n", "", "tweet_id", "=", "int", "(", "tweet_id", ")", "\n", "score", "=", "float", "(", "score", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main._read_gold_and_pred": [[18, 57], ["open", "open", "len", "logging.error", "ValueError", "line_res.strip().split", "int", "line.split", "int", "float", "line_score.append", "set().difference", "int.strip", "float.strip", "logging.error", "quit", "line_res.strip", "int", "set"], "function", ["None"], ["logging", ".", "basicConfig", "(", "format", "=", "'%(levelname)s : %(message)s'", ",", "level", "=", "logging", ".", "INFO", ")", "\n", "\n", "\n", "def", "check_format", "(", "file_path", ")", ":", "\n", "    ", "with", "open", "(", "file_path", ",", "encoding", "=", "'UTF-8'", ")", "as", "out", ":", "\n", "        ", "file_content", "=", "out", ".", "read", "(", ")", ".", "strip", "(", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "file_content", ".", "split", "(", "'\\n'", ")", ")", ":", "\n", "            ", "topic_id", ",", "tweet_id", ",", "score", ",", "run_id", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", "\n", "\n", "if", "not", "_LINE_PATTERN_A", ".", "match", "(", "\"%s\\t%s\"", "%", "(", "tweet_id", ",", "score", ")", ")", ":", "\n", "# 1. Check line format.", "\n", "                ", "logging", ".", "error", "(", "\"Wrong line format: {}\"", ".", "format", "(", "line", ")", ")", "\n", "return", "False", "\n", "", "tweet_id", "=", "int", "(", "tweet_id", ")", "\n", "score", "=", "float", "(", "score", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "return", "True", "\n", "\n", "\n", "", "if", "__name__", "==", "\"__main__\"", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--pred_file_path\"", ",", "\"-p\"", ",", "required", "=", "True", ",", "help", "=", "\"The absolute path to the file you want to check.\"", ",", "type", "=", "str", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "logging", ".", "info", "(", "\"Task 5: Checking file: {}\"", ".", "format", "(", "args", ".", "pred_file_path", ")", ")", "\n", "check_format", "(", "args", ".", "pred_file_path", ")", "", "", ""]], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main._compute_average_precision": [[59, 76], ["sum", "enumerate", "precisions.append", "sum", "gold_labels.items"], "function", ["None"], []], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main._compute_reciprocal_rank": [[78, 86], ["enumerate"], "function", ["None"], []], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main._compute_precisions": [[88, 102], ["min", "enumerate", "range", "range", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main.evaluate": [[104, 126], ["main._read_gold_and_pred", "main._compute_precisions", "main._compute_average_precision", "main._compute_reciprocal_rank", "len", "len", "sorted", "len", "len", "gold_labels.items"], "function", ["home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main._read_gold_and_pred", "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main._compute_precisions", "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main._compute_average_precision", "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main._compute_reciprocal_rank"], []], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main.get_threshold_line_format": [[128, 133], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main.print_thresholded_metric": [[134, 143], ["main.get_threshold_line_format", "logging.info", "logging.info", "logging.info", "get_threshold_line_format.format"], "function", ["home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main.get_threshold_line_format"], []], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main.print_single_metric": [[144, 148], ["logging.info", "logging.info"], "function", ["None"], []], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main.print_metrics_info": [[149, 159], ["logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info", "logging.info"], "function", ["None"], []], "home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.scorer.main.validate_files": [[161, 180], ["len", "len", "logging.error", "len", "len", "logging.error", "set", "format_checker.main.check_format", "logging.error", "len", "len"], "function", ["home.repos.pwc.inspect_result.cleopatra-itn_claim_detection.format_checker.main.check_format"], []]}