{"home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.load_data.LoadDataset.__init__": [[16, 20], ["print", "print"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_name", ")", ":", "\n", "        ", "self", ".", "data_name", "=", "data_name", "\n", "print", "(", "\"Current dataset: kdd20_s1, kdd20_s2, cora, citeseer, amazoncobuy, coauthor, reddit.\"", ")", "\n", "print", "(", "\"Selecting {0} Dataset ...\"", ".", "format", "(", "self", ".", "data_name", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.load_data.LoadDataset.load_data": [[22, 55], ["print", "print", "load_data.LoadDataset.load_kdd20", "load_data.LoadDataset.load_kdd20", "dgl.data.CoraGraphDataset", "dgl.data.CoraGraphDataset", "dgl.data.CoraGraphDataset", "dgl.data.CoraGraphDataset", "dgl.data.CiteseerGraphDataset", "dgl.data.CiteseerGraphDataset", "dgl.data.CiteseerGraphDataset", "dgl.data.CiteseerGraphDataset", "dgl.data.PubmedGraphDataset", "dgl.data.PubmedGraphDataset", "dgl.data.PubmedGraphDataset", "dgl.data.PubmedGraphDataset", "dgl.data.AmazonCoBuyComputerDataset", "dgl.data.AmazonCoBuyComputerDataset", "dgl.data.AmazonCoBuyComputerDataset", "dgl.data.AmazonCoBuyComputerDataset", "dgl.data.CoauthorCSDataset", "dgl.data.CoauthorCSDataset", "dgl.data.CoauthorCSDataset", "dgl.data.CoauthorCSDataset", "dgl.data.RedditDataset", "dgl.data.RedditDataset", "dgl.data.RedditDataset", "dgl.data.RedditDataset", "utils.preprocess_dgl_adj"], "methods", ["home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.load_data.LoadDataset.load_kdd20", "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.load_data.LoadDataset.load_kdd20", "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.preprocess_dgl_adj"], ["", "def", "load_data", "(", "self", ")", ":", "\n", "# Load dataset based on given data_name.", "\n", "        ", "if", "self", ".", "data_name", "==", "'kdd20_s1'", ":", "\n", "            ", "return", "self", ".", "load_kdd20", "(", "1", ")", "\n", "", "if", "self", ".", "data_name", "==", "'kdd20_s2'", ":", "\n", "            ", "return", "self", ".", "load_kdd20", "(", "2", ")", "\n", "", "if", "self", ".", "data_name", "==", "\"cora\"", ":", "# cora_v2", "\n", "            ", "dataset", "=", "dgl", ".", "data", ".", "CoraGraphDataset", "(", ")", "\n", "", "if", "self", ".", "data_name", "==", "\"citeseer\"", ":", "# citeseer", "\n", "            ", "dataset", "=", "dgl", ".", "data", ".", "CiteseerGraphDataset", "(", ")", "\n", "", "if", "self", ".", "data_name", "==", "\"pubmed\"", ":", "# pubmed", "\n", "            ", "dataset", "=", "dgl", ".", "data", ".", "PubmedGraphDataset", "(", ")", "\n", "", "if", "self", ".", "data_name", "==", "\"amazoncobuy\"", ":", "# amazon_co_buy_photo", "\n", "            ", "dataset", "=", "dgl", ".", "data", ".", "AmazonCoBuyComputerDataset", "(", ")", "# AmazonCoBuyPhotoDataset", "\n", "", "if", "self", ".", "data_name", "==", "\"coauthor\"", ":", "# coauthor_cs", "\n", "            ", "dataset", "=", "dgl", ".", "data", ".", "CoauthorCSDataset", "(", ")", "\n", "", "if", "self", ".", "data_name", "==", "\"reddit\"", ":", "# reddit", "\n", "            ", "dataset", "=", "dgl", ".", "data", ".", "RedditDataset", "(", ")", "\n", "\n", "# Load graph, feature matrix, and label", "\n", "", "graph", "=", "dataset", "[", "0", "]", "\n", "feat", "=", "graph", ".", "ndata", "[", "'feat'", "]", "# float32", "\n", "label", "=", "graph", ".", "ndata", "[", "'label'", "]", "# int64", "\n", "\n", "# Preprocessing the adjacency matrix (dgl graph) and update the graph", "\n", "if", "self", ".", "data_name", "==", "\"amazoncobuy\"", "or", "self", ".", "data_name", "==", "\"coauthor\"", ":", "\n", "            ", "graph", "=", "preprocess_dgl_adj", "(", "graph", ")", "\n", "graph", ".", "ndata", "[", "'feat'", "]", "=", "feat", "\n", "graph", ".", "ndata", "[", "'label'", "]", "=", "label", "\n", "\n", "", "print", "(", "\"Data is stored in: /Users/[user_name]/.dgl\"", ")", "\n", "print", "(", "\"{0} Dataset Loaded!\"", ".", "format", "(", "self", ".", "data_name", ")", ")", "\n", "return", "graph", ",", "feat", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.load_data.LoadDataset.load_kdd20": [[57, 90], ["print", "dgl.from_scipy", "dgl.from_scipy", "dgl.from_scipy", "dgl.from_scipy", "torch.FloatTensor", "torch.LongTensor", "print", "print", "utils.read_pickle", "utils.read_pickle", "utils.read_pickle", "len", "preprocessing.LabelEncoder", "preprocessing.LabelEncoder.fit_transform", "utils.read_pickle", "numpy.load", "numpy.load", "numpy.load.max", "set"], "methods", ["home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.read_pickle", "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.read_pickle", "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.read_pickle", "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.read_pickle"], ["", "def", "load_kdd20", "(", "self", ",", "stage", "=", "1", ")", ":", "\n", "# Load KDD Cup 2020 Dataset", "\n", "# Read the pickle file", "\n", "        ", "if", "stage", "==", "1", ":", "\n", "            ", "A", "=", "read_pickle", "(", "'../data/kdd20_s1/experimental_adj.pkl'", ")", "# (scipy.sparse.csr_matrix)", "\n", "X", "=", "read_pickle", "(", "'../data/kdd20_s1/experimental_features.pkl'", ")", "# (array)", "\n", "Y", "=", "read_pickle", "(", "'../data/kdd20_s1/experimental_train.pkl'", ")", "# (array)", "\n", "", "elif", "stage", "==", "2", ":", "\n", "            ", "A", "=", "read_pickle", "(", "'../data/kdd20_s2/adj_matrix_formal_stage.pkl'", ")", "# (scipy.sparse.csr_matrix)", "\n", "X", "=", "np", ".", "load", "(", "'../data/kdd20_s2/feature_formal_stage.npy'", ")", "# (array)", "\n", "Y", "=", "np", ".", "load", "(", "'../data/kdd20_s2/train_labels_formal_stage.npy'", ")", "# (array)", "\n", "", "else", ":", "\n", "            ", "return", "\"Please select stage 1 or 2.\"", "\n", "", "if", "Y", ".", "max", "(", ")", "+", "1", "!=", "len", "(", "set", "(", "Y", ")", ")", ":", "\n", "# Execute Label Transform", "\n", "            ", "from", "sklearn", "import", "preprocessing", "\n", "le", "=", "preprocessing", ".", "LabelEncoder", "(", ")", "\n", "Y", "=", "le", ".", "fit_transform", "(", "Y", ")", "\n", "", "print", "(", "\"The shape of A, X, Y: \"", ",", "A", ".", "shape", ",", "X", ".", "shape", ",", "Y", ".", "shape", ")", "\n", "# Remove the nodes which has no labels. # new", "\n", "A", "=", "A", "[", ":", "Y", ".", "shape", "[", "0", "]", ",", ":", "Y", ".", "shape", "[", "0", "]", "]", "\n", "X", "=", "X", "[", ":", "Y", ".", "shape", "[", "0", "]", "]", "\n", "# Convert to the desirable format", "\n", "graph", "=", "dgl", ".", "from_scipy", "(", "A", ")", "# dgl graph", "\n", "feat", "=", "torch", ".", "FloatTensor", "(", "X", ")", "# feature matrix", "\n", "label", "=", "torch", ".", "LongTensor", "(", "Y", ")", "# label", "\n", "graph", ".", "ndata", "[", "'feat'", "]", "=", "feat", "# update the graph", "\n", "graph", ".", "ndata", "[", "'label'", "]", "=", "label", "\n", "# label_fake = torch.zeros(A.shape[0] - Y.shape[0], dtype = int)", "\n", "# label = torch.cat([label_real, label_fake])", "\n", "print", "(", "\"Data is stored in: ../data/kdd20_s{0}/\"", ".", "format", "(", "stage", ")", ")", "\n", "print", "(", "\"KDD Cup 2020 Dataset Loaded!\"", ")", "\n", "return", "graph", ",", "feat", ",", "label", "\n", "", "", ""]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.models_GCN.GCN.__init__": [[15, 61], ["super().__init__", "torch.nn.ModuleList", "models_GCN.GCN.layers.append", "range", "models_GCN.GCN.layers.append", "models_GCN.GCN.layers.append", "dgl.nn.pytorch.GraphConv", "dgl.nn.pytorch.GraphConv", "dgl.nn.pytorch.GraphConv", "models_GCN.GCN.layers.append", "models_GCN.GCN.layers.append", "torch.nn.Dropout", "dgl.nn.pytorch.SGConv", "dgl.nn.pytorch.SGConv", "dgl.nn.pytorch.SGConv", "torch.nn.Dropout", "dgl.nn.pytorch.SAGEConv", "dgl.nn.pytorch.SAGEConv", "dgl.nn.pytorch.SAGEConv", "dgl.nn.pytorch.TAGConv", "dgl.nn.pytorch.TAGConv", "dgl.nn.pytorch.TAGConv", "dgl.nn.pytorch.GINConv", "dgl.nn.pytorch.GINConv", "dgl.nn.pytorch.GINConv", "print", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.models_LT.LabelTransition.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "g", ",", "\n", "in_feats", ",", "\n", "n_hidden", ",", "\n", "n_classes", ",", "\n", "n_layers", ",", "\n", "activation", ",", "\n", "dropout", ",", "\n", "model_name", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "GCN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "g", "=", "g", "# graph DGLGraph", "\n", "self", ".", "layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", ")", "\n", "self", ".", "aggregator_type", "=", "kwargs", "[", "\"aggregator_type\"", "]", "\n", "# Select the model layer", "\n", "if", "model_name", "==", "\"GCN\"", ":", "\n", "            ", "model_in", "=", "GraphConv", "(", "in_feats", ",", "n_hidden", ",", "activation", "=", "activation", ",", "allow_zero_in_degree", "=", "True", ")", "\n", "model_h", "=", "GraphConv", "(", "n_hidden", ",", "n_hidden", ",", "activation", "=", "activation", ",", "allow_zero_in_degree", "=", "True", ")", "\n", "model_out", "=", "GraphConv", "(", "n_hidden", ",", "n_classes", ",", "allow_zero_in_degree", "=", "True", ")", "\n", "", "elif", "model_name", "==", "\"SGC\"", ":", "# k for the size of filter", "\n", "            ", "model_in", "=", "SGConv", "(", "in_feats", ",", "n_hidden", ",", "k", "=", "2", ",", "allow_zero_in_degree", "=", "True", ")", "\n", "model_h", "=", "SGConv", "(", "n_hidden", ",", "n_hidden", ",", "k", "=", "2", ",", "allow_zero_in_degree", "=", "True", ")", "\n", "model_out", "=", "SGConv", "(", "n_hidden", ",", "n_classes", ",", "k", "=", "2", ",", "allow_zero_in_degree", "=", "True", ")", "\n", "", "elif", "model_name", "==", "\"GraphSAGE\"", ":", "# Aggregator type: mean, gcn, pool, lstm.", "\n", "            ", "model_in", "=", "SAGEConv", "(", "in_feats", ",", "n_hidden", ",", "self", ".", "aggregator_type", ",", "activation", "=", "activation", ")", "\n", "model_h", "=", "SAGEConv", "(", "n_hidden", ",", "n_hidden", ",", "self", ".", "aggregator_type", ",", "activation", "=", "activation", ")", "\n", "model_out", "=", "SAGEConv", "(", "n_hidden", ",", "n_classes", ",", "self", ".", "aggregator_type", ")", "\n", "", "elif", "model_name", "==", "\"TAGCN\"", ":", "# k for the size of filter", "\n", "            ", "model_in", "=", "TAGConv", "(", "in_feats", ",", "n_hidden", ",", "k", "=", "2", ",", "activation", "=", "activation", ")", "\n", "model_h", "=", "TAGConv", "(", "n_hidden", ",", "n_hidden", ",", "k", "=", "2", ",", "activation", "=", "activation", ")", "\n", "model_out", "=", "TAGConv", "(", "n_hidden", ",", "n_classes", ",", "k", "=", "2", ")", "\n", "", "elif", "model_name", "==", "\"GIN\"", ":", "# Aggregator type: sum, max or mean.", "\n", "            ", "model_in", "=", "GINConv", "(", "torch", ".", "nn", ".", "Linear", "(", "in_feats", ",", "n_hidden", ")", ",", "self", ".", "aggregator_type", ",", "init_eps", "=", "0", ")", "\n", "model_h", "=", "GINConv", "(", "torch", ".", "nn", ".", "Linear", "(", "n_hidden", ",", "n_hidden", ")", ",", "self", ".", "aggregator_type", ",", "init_eps", "=", "0", ")", "\n", "model_out", "=", "GINConv", "(", "torch", ".", "nn", ".", "Linear", "(", "n_hidden", ",", "n_classes", ")", ",", "self", ".", "aggregator_type", ",", "init_eps", "=", "0", ")", "\n", "# if model_name == \"xxx\": # Add model layer here if necessary", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"model_name is incorrect!\"", ")", "\n", "return", "0", "\n", "# Build the model", "\n", "", "self", ".", "layers", ".", "append", "(", "model_in", ")", "# input layer", "\n", "for", "_", "in", "range", "(", "n_layers", "-", "1", ")", ":", "\n", "            ", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ")", "\n", "self", ".", "layers", ".", "append", "(", "model_h", ")", "# hidden layers", "\n", "", "self", ".", "layers", ".", "append", "(", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", ")", "\n", "self", ".", "layers", ".", "append", "(", "model_out", ")", "# output layer", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.models_GCN.GCN.forward": [[63, 71], ["enumerate", "type", "layer", "layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "feat", ")", ":", "\n", "        ", "h", "=", "feat", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "if", "type", "(", "layer", ")", "==", "torch", ".", "nn", ".", "modules", ".", "dropout", ".", "Dropout", ":", "\n", "                ", "h", "=", "layer", "(", "h", ")", "\n", "", "else", ":", "\n", "                ", "h", "=", "layer", "(", "self", ".", "g", ",", "h", ")", "\n", "", "", "return", "h", "\n", "", "", ""]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.pretrain.train": [[26, 106], ["torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.utils.tensorboard.SummaryWriter", "range", "torch.utils.tensorboard.SummaryWriter.close", "utils.load_checkpoint", "model.train", "model", "torch.nn.CrossEntropyLoss.", "optimizer.zero_grad", "loss_fn.backward", "optimizer.step", "os.path.exists", "print", "torch.utils.tensorboard.SummaryWriter.add_scalar", "torch.utils.tensorboard.SummaryWriter.add_scalar", "torch.utils.tensorboard.SummaryWriter.add_scalar", "torch.utils.tensorboard.SummaryWriter.add_scalar", "torch.utils.tensorboard.SummaryWriter.flush", "print", "time.time", "dur.append", "torch.no_grad", "torch.no_grad", "utils.compute_accuracy", "torch.nn.CrossEntropyLoss.", "utils.compute_accuracy", "torch.nn.CrossEntropyLoss.", "os.remove", "utils.save_checkpoint", "loss_fn.item", "loss_fn.item", "datetime.datetime.now().strftime", "numpy.mean", "loss_fn.item", "loss_fn.item", "time.time", "datetime.datetime.now", "model.state_dict", "optimizer.state_dict"], "function", ["home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.load_checkpoint", "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.pretrain.train", "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.compute_accuracy", "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.compute_accuracy", "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.save_checkpoint"], ["def", "train", "(", "model", ",", "optimizer", ",", "dirs", ",", "feat", ",", "label", ",", "train_mask", ",", "val_mask", ",", "n_epochs", ")", ":", "\n", "    ", "\"\"\"\n    @topic: Fitting the GCNs\n    @input: feature matrix, label, train/val masks, and #epochs.\n    @return: train and save the model parameters.\n    \"\"\"", "\n", "loss_fn", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "# Define the loss function", "\n", "\n", "# Load checkpoint", "\n", "try", ":", "\n", "        ", "model", ",", "optimizer", ",", "start_epoch", ",", "best_acc", "=", "load_checkpoint", "(", "dirs", "+", "'model_best.pth.tar'", ",", "model", ",", "optimizer", ")", "\n", "", "except", ":", "\n", "        ", "print", "(", "\"Model parameter is not found.\"", ")", "\n", "start_epoch", "=", "1", "\n", "", "if", "n_epochs", "<=", "start_epoch", ":", "\n", "        ", "n_epochs", "+=", "start_epoch", "\n", "\n", "", "writer", "=", "SummaryWriter", "(", "log_dir", "=", "dirs", ",", "\n", "comment", "=", "\"_time%s\"", "%", "(", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y-%m-%d %H:%M:%S\"", ")", ")", ",", "purge_step", "=", "start_epoch", ")", "\n", "\n", "dur", "=", "[", "]", "\n", "best_acc", "=", "0", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "n_epochs", ")", ":", "\n", "        ", "model", ".", "train", "(", ")", "\n", "\n", "if", "epoch", ">=", "3", ":", "\n", "            ", "t0", "=", "time", ".", "time", "(", ")", "\n", "\n", "# forward", "\n", "", "logits", "=", "model", "(", "feat", ")", "\n", "loss", "=", "loss_fn", "(", "logits", "[", "train_mask", "]", ",", "label", "[", "train_mask", "]", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "epoch", ">=", "3", ":", "\n", "            ", "dur", ".", "append", "(", "time", ".", "time", "(", ")", "-", "t0", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "acc_train", "=", "compute_accuracy", "(", "logits", ",", "label", ",", "train_mask", ")", "\n", "loss_train", "=", "loss_fn", "(", "logits", "[", "train_mask", "]", ",", "label", "[", "train_mask", "]", ")", "\n", "acc_val", "=", "compute_accuracy", "(", "logits", ",", "label", ",", "val_mask", ")", "\n", "loss_val", "=", "loss_fn", "(", "logits", "[", "val_mask", "]", ",", "label", "[", "val_mask", "]", ")", "\n", "\n", "# Define the file name", "\n", "", "FileName", "=", "\"Epoch{0}.pth.tar\"", ".", "format", "(", "epoch", ")", "\n", "# Delete previous existing parameter file", "\n", "if", "os", ".", "path", ".", "exists", "(", "dirs", "+", "\"Epoch{0}.pth.tar\"", ".", "format", "(", "epoch", "-", "1", ")", ")", ":", "\n", "            ", "os", ".", "remove", "(", "dirs", "+", "\"Epoch{0}.pth.tar\"", ".", "format", "(", "epoch", "-", "1", ")", ")", "\n", "", "if", "acc_val", ">", "best_acc", ":", "\n", "            ", "best_acc", "=", "acc_val", "\n", "is_best", "=", "True", "\n", "# Save checkpoint", "\n", "save_checkpoint", "(", "\n", "state", "=", "{", "\n", "'epoch'", ":", "epoch", "+", "1", ",", "\n", "'state_dict'", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "'best_acc'", ":", "best_acc", ",", "\n", "'optimizer'", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", ",", "is_best", "=", "is_best", ",", "directory", "=", "dirs", ",", "filename", "=", "FileName", "\n", ")", "\n", "\n", "# Output the result", "\n", "#if epoch % n_epochs//10 == 0:", "\n", "", "print", "(", "\"Epoch {:05d} | Time(s) {:.4f} | Train Loss {:.4f} | Val Loss {:.4f} \"", "\n", "\"| Train Accuracy {:.4f} | Val Accuracy {:.4f} \"", ".", "format", "(", "epoch", ",", "np", ".", "mean", "(", "dur", ")", ",", "loss_train", ".", "item", "(", ")", ",", "loss_val", ".", "item", "(", ")", ",", "acc_train", ",", "acc_val", ")", ")", "\n", "\n", "# Update SummaryWriter", "\n", "writer", ".", "add_scalar", "(", "'Loss/train'", ",", "loss_train", ".", "item", "(", ")", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'Loss/cross'", ",", "loss_val", ".", "item", "(", ")", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'Accuracy/train'", ",", "acc_train", ",", "epoch", ")", "\n", "writer", ".", "add_scalar", "(", "'Accuracy/cross'", ",", "acc_val", ",", "epoch", ")", "\n", "writer", ".", "flush", "(", ")", "\n", "\n", "", "writer", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.pretrain.evaluation": [[109, 126], ["model.eval", "utils.load_checkpoint", "model", "utils.compute_accuracy", "print", "graph.number_of_nodes", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.load_checkpoint", "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.compute_accuracy"], ["", "def", "evaluation", "(", "model", ",", "optimizer", ",", "path", ",", "graph", ",", "feat", ",", "label", ",", "test_mask", ")", ":", "# for dgl 0.5.x", "\n", "    ", "\"\"\"\n    @topic: Evaluation on the given model\n    @input: graph, feature matrix, label and its mask.\n    @return: print out the test acc.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "if", "not", "graph", ".", "number_of_nodes", "(", ")", "==", "len", "(", "feat", ")", "==", "len", "(", "label", ")", "==", "len", "(", "test_mask", ")", ":", "\n", "            ", "return", "\"The length of adj/feat/label/test_mask is not equal!\"", "\n", "", "model", ".", "eval", "(", ")", "\n", "model", ",", "optimizer", ",", "start_epoch", ",", "best_acc", "=", "load_checkpoint", "(", "path", ",", "model", ",", "optimizer", ")", "\n", "model", ".", "g", "=", "graph", "# update the graph", "\n", "logits", "=", "model", "(", "feat", ")", "\n", "acc", "=", "compute_accuracy", "(", "logits", ",", "label", ",", "test_mask", ")", "\n", "print", "(", "\"Best Testing Accuracy: {:.2%}\"", ".", "format", "(", "acc", ")", ")", "\n", "", "except", ":", "\n", "        ", "return", "\"Model parameter is not found.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.pretrain.prediction": [[129, 147], ["model.eval", "utils.load_checkpoint", "model", "torch.nn.functional.softmax", "torch.nn.functional.softmax", "graph.number_of_nodes", "len", "torch.max", "torch.max"], "function", ["home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.load_checkpoint"], ["", "", "def", "prediction", "(", "model", ",", "optimizer", ",", "path", ",", "graph", ",", "feat", ")", ":", "\n", "    ", "\"\"\"\n    @topic: Generate predicted label with well-trained GCN model\n    @input: graph, feature matrix.\n    @return: predicted label (1D Tensor), probabilistic matrix (2D Tensor).\n    \"\"\"", "\n", "try", ":", "\n", "        ", "if", "graph", ".", "number_of_nodes", "(", ")", "!=", "len", "(", "feat", ")", ":", "\n", "            ", "return", "\"The length of adj/feat is not equal!\"", "\n", "", "model", ".", "eval", "(", ")", "\n", "model", ",", "optimizer", ",", "_", ",", "_", "=", "load_checkpoint", "(", "path", ",", "model", ",", "optimizer", ")", "\n", "model", ".", "g", "=", "graph", "# update the graph (dgl 0.5.x)", "\n", "Y_pred_2d", "=", "model", "(", "feat", ")", "# predicted label (2d)", "\n", "Y_pred_2d_softmax", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "Y_pred_2d", ",", "dim", "=", "1", ")", "# Normalize each row to sum=1", "\n", "Y_pred", "=", "torch", ".", "max", "(", "Y_pred_2d_softmax", ",", "dim", "=", "1", ")", "[", "1", "]", "# predicted label (1d)", "\n", "return", "Y_pred", ",", "Y_pred_2d_softmax", "\n", "", "except", ":", "\n", "        ", "return", "\"Model parameter is not found.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.perturbation.select_target_nodes": [[21, 44], ["torch.zeros", "torch.zeros", "int", "int", "torch.unique", "torch.unique", "numpy.random.seed", "numpy.random.choice", "len", "range", "len", "abs", "len", "range", "len"], "function", ["None"], ["def", "select_target_nodes", "(", "label", ",", "test_mask", ",", "sample_rate", "=", "0.1", ",", "atk_class", "=", "-", "1", ")", ":", "\n", "    ", "\"\"\"\n    @topic: Select target nodes for targeted/non-targeted perturbations.\n    @input:\n        label (int tensor): ground-truth label;\n        test_mask (bool tensor): the mask for testing set;\n        sample_rate (float): the ratio of sampling in the testing set;\n        atk_class (int): the attacked target class.\n    @return:\n        target_nodes_list (array): the list of target nodes;\n        target_mask (bool tensor): the mask for target nodes.\n    \"\"\"", "\n", "target_mask", "=", "torch", ".", "zeros", "(", "[", "len", "(", "label", ")", "]", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "test_id_list", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "test_mask", ")", ")", "if", "test_mask", "[", "i", "]", "==", "True", "]", "\n", "target_size", "=", "int", "(", "len", "(", "label", "[", "test_mask", "]", ")", "*", "sample_rate", ")", "# Decide the size of target nodes", "\n", "if", "int", "(", "atk_class", ")", "in", "torch", ".", "unique", "(", "label", ")", ":", "# Select \"atk_class\" nodes from test graph", "\n", "        ", "target_idx", "=", "[", "l", "for", "l", "in", "range", "(", "len", "(", "label", ")", ")", "if", "label", "[", "l", "]", "==", "atk_class", "and", "l", "in", "test_id_list", "]", "\n", "target_nodes_list", "=", "[", "i", "for", "i", "in", "target_idx", "[", ":", "target_size", "]", "]", "\n", "", "else", ":", "# Random select \"target_size\" nodes if \"atk_class\" doesn't belong to any existing classes", "\n", "        ", "np", ".", "random", ".", "seed", "(", "abs", "(", "atk_class", ")", ")", "# Fix the random seed for reproduction.", "\n", "target_nodes_list", "=", "np", ".", "random", ".", "choice", "(", "test_id_list", ",", "target_size", ",", "replace", "=", "False", ")", "\n", "", "target_mask", "[", "target_nodes_list", "]", "=", "True", "# Generate the target mask", "\n", "return", "target_nodes_list", ",", "target_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.perturbation.perturb_adj": [[46, 55], ["numpy.random.seed", "numpy.random.choice", "numpy.zeros", "range", "scipy.csr_matrix"], "function", ["None"], ["", "def", "perturb_adj", "(", "rows", ",", "cols", ",", "target_nodes_list", ",", "num_connect", ",", "seed", "=", "0", ")", ":", "\n", "    ", "\"\"\"Generate perturbator adjacency matrix\"\"\"", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "col_idx", "=", "np", ".", "random", ".", "choice", "(", "target_nodes_list", ",", "(", "rows", ",", "num_connect", ")", ",", "replace", "=", "False", ")", "\n", "pert_adj", "=", "np", ".", "zeros", "(", "(", "rows", ",", "cols", ")", ",", "dtype", "=", "np", ".", "int8", ")", "\n", "for", "r", "in", "range", "(", "rows", ")", ":", "\n", "        ", "pert_adj", "[", "r", ",", "col_idx", "[", "r", "]", "]", "=", "1", "\n", "", "return", "ss", ".", "csr_matrix", "(", "pert_adj", ")", "# returns as a scipy sparse matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.perturbation.perturb_feat": [[57, 62], ["numpy.zeros"], "function", ["None"], ["", "def", "perturb_feat", "(", "rows", ",", "cols", ",", "feat_val", "=", "1.", ")", ":", "\n", "    ", "\"\"\"Generate perturbator feature matrix\"\"\"", "\n", "pert_feat", "=", "np", ".", "zeros", "(", "(", "rows", ",", "cols", ")", ",", "dtype", "=", "float", ")", "\n", "pert_feat", "[", ":", "]", "=", "feat_val", "# Assign feat values", "\n", "return", "pert_feat", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.perturbation.format_check": [[64, 82], ["print", "pert_adj.getnnz().max", "pert_adj.getnnz"], "function", ["None"], ["", "def", "format_check", "(", "pert_adj", ",", "len_graph", ",", "num_connect", ")", ":", "\n", "    ", "\"\"\"Check the format of perturbator adj\"\"\"", "\n", "# input: pert_adj: perturbator adj matrix (scipy sparse matrix);", "\n", "# for each new node k_i, the number of its link should be smaller or equal to the threshold.", "\n", "if", "pert_adj", ".", "getnnz", "(", "axis", "=", "1", ")", ".", "max", "(", ")", "<=", "num_connect", ":", "# Should be True", "\n", "        ", "check1", "=", "True", "\n", "", "else", ":", "\n", "        ", "check1", "=", "False", "\n", "# the edges pattern between new nodes must be symmetric", "\n", "", "if", "(", "pert_adj", "[", ":", ",", "len_graph", ":", "]", ".", "T", "!=", "pert_adj", "[", ":", ",", "len_graph", ":", "]", ")", ".", "sum", "(", ")", "==", "0", ":", "\n", "        ", "check2", "=", "True", "\n", "", "else", ":", "\n", "        ", "check2", "=", "False", "\n", "", "print", "(", "\"The result of 2 checks: \"", ",", "check1", ",", "check2", ")", "\n", "if", "check1", "and", "check2", ":", "\n", "        ", "return", "\"Check Passed!\"", "\n", "", "else", ":", "\n", "        ", "return", "\"Check Failed!\"", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.models_LT.LabelTransition.__init__": [[19, 21], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "ALPHA", "=", "1.0", ")", ":", "\n", "        ", "self", ".", "ALPHA", "=", "ALPHA", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.models_LT.LabelTransition.get_labels_dict": [[23, 36], ["dict", "dict", "numpy.array", "range", "len", "range", "len"], "methods", ["None"], ["", "def", "get_labels_dict", "(", "self", ",", "Y_pred", ",", "Y_noisy", ")", ":", "\n", "        ", "\"\"\"\n        @topic: Convert labels as dict\n        @input: Y_pred/Y_noisy(1D-array).\n        @return: infer_dict/noisy_dict(dict).\n        \"\"\"", "\n", "infer_dict", "=", "dict", "(", ")", "# keys: idx; values: Y_pred.", "\n", "noisy_dict", "=", "dict", "(", ")", "# keys: idx; values: Y_noisy. ", "\n", "idx", "=", "np", ".", "array", "(", "[", "i", "for", "i", "in", "range", "(", "len", "(", "Y_noisy", ")", ")", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "idx", ")", ")", ":", "\n", "            ", "infer_dict", "[", "idx", "[", "i", "]", "]", "=", "Y_pred", "[", "i", "]", "\n", "noisy_dict", "[", "idx", "[", "i", "]", "]", "=", "Y_noisy", "[", "i", "]", "\n", "", "return", "infer_dict", ",", "noisy_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.models_LT.LabelTransition.generate_counting_matrix": [[38, 50], ["numpy.zeros", "range", "len"], "methods", ["None"], ["", "def", "generate_counting_matrix", "(", "self", ",", "Y_pred", ",", "Y_noisy", ",", "NUM_CLASSES", ")", ":", "\n", "        ", "\"\"\"\n        @topic: Generate counting matrix and testing labels\n        @input: Y_pred/Y_noisy (1D-array); NUM_CLASSES (int).\n        @return: C (2D-array).\n        \"\"\"", "\n", "C_matrix", "=", "np", ".", "zeros", "(", "(", "NUM_CLASSES", ",", "NUM_CLASSES", ")", ",", "dtype", "=", "int", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "Y_noisy", ")", ")", ":", "\n", "            ", "r", "=", "Y_pred", "[", "i", "]", "\n", "c", "=", "Y_noisy", "[", "i", "]", "\n", "C_matrix", "[", "r", "]", "[", "c", "]", "+=", "1", "\n", "", "return", "C_matrix", "# (NUM_CLASSES, NUM_CLASSES)", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.models_LT.LabelTransition.approx_Gibbs_sampling": [[52, 65], ["torch.index_select", "torch.sum", "torch.max", "torch.transpose"], "methods", ["None"], ["", "def", "approx_Gibbs_sampling", "(", "self", ",", "Y_pred_sm", ",", "Y_noisy", ",", "TM", ")", ":", "\n", "        ", "\"\"\"\n        @topic: Approximate Gibbs Sampling\n        @input:\n            Y_pred_sm (2D Tensor: NUM_SAMPLES x NUM_CLASSES);\n            Y_noisy (1D Tensor: NUM_SAMPLES x 1);\n            TM (2D Tensor: NUM_CLASSES x NUM_CLASSES).\n        @return: Y_infer (1D Tensor: NUM_SAMPLES x 1).\n        \"\"\"", "\n", "unnorm_probs", "=", "Y_pred_sm", "*", "torch", ".", "index_select", "(", "torch", ".", "transpose", "(", "TM", ",", "0", ",", "1", ")", ",", "0", ",", "Y_noisy", ")", "\n", "probs", "=", "unnorm_probs", "/", "torch", ".", "sum", "(", "unnorm_probs", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "Y_infer", "=", "torch", ".", "max", "(", "probs", ",", "dim", "=", "1", ")", "[", "1", "]", "\n", "return", "Y_infer", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.models_LT.LabelTransition.infer_label": [[67, 140], ["numpy.array", "models_LT.LabelTransition.get_labels_dict", "models_LT.LabelTransition.generate_counting_matrix", "torch.FloatTensor", "torch.LongTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.utils.tensorboard.SummaryWriter", "range", "numpy.array", "utils.tensor2array", "utils.dump_pickle", "torch.utils.tensorboard.SummaryWriter.close", "int", "Y_pred_sm.cuda.cuda.cuda", "Y_noisy.cuda.cuda.cuda", "C.cuda.cuda.cuda", "TM_warmup.cuda.cuda.cuda", "int", "enumerate", "torch.utils.tensorboard.SummaryWriter.add_scalar", "os.path.join", "print", "models_LT.LabelTransition.approx_Gibbs_sampling", "models_LT.LabelTransition.approx_Gibbs_sampling", "models_LT.LabelTransition.cuda", "int", "numpy.array", "sklearn.metrics.accuracy_score", "range", "torch.sum", "TM_i.cuda", "z_dict.values", "len", "z_dict.values"], "methods", ["home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.models_LT.LabelTransition.get_labels_dict", "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.models_LT.LabelTransition.generate_counting_matrix", "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.tensor2array", "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.dump_pickle", "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.models_LT.LabelTransition.approx_Gibbs_sampling", "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.models_LT.LabelTransition.approx_Gibbs_sampling"], ["", "def", "infer_label", "(", "self", ",", "Y_pred", ",", "Y_pred_sm", ",", "Y_noisy", ",", "Y_gt", ",", "TM_warmup", ",", "GPU", ",", "NUM_EPOCHS", "=", "100", ",", "WARMUP_STEP", "=", "20", ")", ":", "\n", "        ", "\"\"\"\n        @topic: Infer the labels with noisy labels\n        @input:\n            Y_pred/Y_noisy/Y_gt: predicted/noisy/groundtruth labels (1D array: NUM_SAMPLES x 1);\n            Y_pred_sm: categorical distribution (2D array: NUM_SAMPLES x NUM_CLASSES);\n            TM_warmup: warming-up transition matrix (2D array: NUM_CLASSES x NUM_CLASSES);\n            GPU: the ID of GPU device;\n            NUM_EPOCHS: the number of training epochs (int);\n            WARMUP_STEP: using TM_warmup if step < WARMUP_STEP (int);\n        @return:\n            Y_infer: new inferred label (1D array: NUM_SAMPLES x 1);\n            C: counting matrix (2D array: NUM_CLASSES x NUM_CLASSES).\n        \"\"\"", "\n", "# Get index of label", "\n", "idx", "=", "np", ".", "array", "(", "[", "i", "for", "i", "in", "range", "(", "len", "(", "Y_noisy", ")", ")", "]", ")", "\n", "# Get Y_pred/Y_noisy dict", "\n", "z_dict", ",", "y_dict", "=", "self", ".", "get_labels_dict", "(", "Y_pred", ",", "Y_noisy", ")", "\n", "# Generate counting matrix", "\n", "C", "=", "self", ".", "generate_counting_matrix", "(", "Y_pred", ",", "Y_noisy", ",", "int", "(", "Y_pred_sm", ".", "shape", "[", "1", "]", ")", ")", "\n", "# Convert to pytorch tensor", "\n", "Y_pred_sm", "=", "torch", ".", "FloatTensor", "(", "Y_pred_sm", ")", "\n", "Y_noisy", "=", "torch", ".", "LongTensor", "(", "Y_noisy", ")", "\n", "C", "=", "torch", ".", "FloatTensor", "(", "C", ")", "\n", "TM_warmup", "=", "torch", ".", "FloatTensor", "(", "TM_warmup", ")", "\n", "# Setup the GPU", "\n", "if", "GPU", ">=", "0", ":", "\n", "            ", "Y_pred_sm", "=", "Y_pred_sm", ".", "cuda", "(", ")", "\n", "Y_noisy", "=", "Y_noisy", ".", "cuda", "(", ")", "\n", "C", "=", "C", ".", "cuda", "(", ")", "\n", "TM_warmup", "=", "TM_warmup", ".", "cuda", "(", ")", "\n", "# Setup the interval", "\n", "", "if", "WARMUP_STEP", ">=", "1000", ":", "\n", "            ", "interval", "=", "int", "(", "WARMUP_STEP", "//", "100", ")", "\n", "", "else", ":", "\n", "            ", "interval", "=", "10", "\n", "# Record the data if necessary", "\n", "", "writer", "=", "SummaryWriter", "(", "log_dir", "=", "os", ".", "path", ".", "join", "(", "\"runs\"", ",", "'Logs_LT'", ")", ")", "\n", "\n", "for", "step", "in", "range", "(", "NUM_EPOCHS", ")", ":", "\n", "# Update transition matrix TM for every n steps", "\n", "            ", "if", "step", "%", "interval", "==", "0", ":", "\n", "                ", "TM_i", "=", "(", "C", "+", "self", ".", "ALPHA", ")", "/", "torch", ".", "sum", "(", "C", "+", "self", ".", "ALPHA", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "TM_i", "=", "TM_i", ".", "cuda", "(", ")", "if", "GPU", ">=", "0", "else", "TM_i", "\n", "print", "(", "\".\"", ",", "end", "=", "' '", ")", "\n", "# Infer Z by Gibbs sampling based on corresponding TM", "\n", "", "if", "step", "<", "WARMUP_STEP", ":", "\n", "                ", "Y_infer", "=", "self", ".", "approx_Gibbs_sampling", "(", "Y_pred_sm", ",", "Y_noisy", ",", "TM_warmup", ")", "\n", "", "else", ":", "\n", "                ", "Y_infer", "=", "self", ".", "approx_Gibbs_sampling", "(", "Y_pred_sm", ",", "Y_noisy", ",", "TM_i", ")", "\n", "", "Y_infer", "=", "Y_infer", ".", "cuda", "(", ")", "if", "GPU", ">=", "0", "else", "Y_infer", "\n", "# Update the counting matrix C", "\n", "for", "num_i", ",", "idx_i", "in", "enumerate", "(", "idx", ")", ":", "\n", "                ", "C", "[", "z_dict", "[", "idx_i", "]", "]", "[", "y_dict", "[", "idx_i", "]", "]", "-=", "1", "\n", "assert", "C", "[", "z_dict", "[", "idx_i", "]", "]", "[", "y_dict", "[", "idx_i", "]", "]", ">=", "0", "\n", "z_dict", "[", "idx_i", "]", "=", "int", "(", "Y_infer", "[", "num_i", "]", ")", "\n", "C", "[", "z_dict", "[", "idx_i", "]", "]", "[", "y_dict", "[", "idx_i", "]", "]", "+=", "1", "\n", "\n", "# Compute accuracy for every n steps", "\n", "# Tensorboard --logdir=./runs/Logs_LT --port 8999", "\n", "", "if", "step", "%", "interval", "==", "0", ":", "\n", "                ", "Y_infer_i", "=", "np", ".", "array", "(", "[", "v", "for", "v", "in", "z_dict", ".", "values", "(", ")", "]", ")", "\n", "acc_i", "=", "accuracy_score", "(", "Y_gt", ",", "Y_infer_i", ")", "\n", "", "writer", ".", "add_scalar", "(", "'Accuracy_Y_infer'", ",", "acc_i", ",", "step", ")", "\n", "\n", "# Get new infer label z", "\n", "", "Y_inferred", "=", "np", ".", "array", "(", "[", "v", "for", "v", "in", "z_dict", ".", "values", "(", ")", "]", ")", "\n", "# Store the parameters", "\n", "C", "=", "tensor2array", "(", "C", ",", "GPU", ")", "# array", "\n", "dump_pickle", "(", "'../data/noisy_label/Y_C.pkl'", ",", "[", "Y_inferred", ",", "C", "]", ")", "\n", "writer", ".", "close", "(", ")", "\n", "return", "Y_inferred", ",", "C", "\n", "", "", ""]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.read_pickle": [[17, 21], ["open", "pickle.load"], "function", ["None"], ["def", "read_pickle", "(", "file_name", ")", ":", "\n", "    ", "\"\"\"Load the dataset\"\"\"", "\n", "with", "open", "(", "file_name", ",", "'rb'", ")", "as", "file", ":", "\n", "        ", "return", "pickle", ".", "load", "(", "file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.dump_pickle": [[22, 26], ["open", "pickle.dump"], "function", ["None"], ["", "", "def", "dump_pickle", "(", "file_name", ",", "data", ")", ":", "\n", "    ", "\"\"\"Export the dataset\"\"\"", "\n", "with", "open", "(", "file_name", ",", "'wb'", ")", "as", "file", ":", "\n", "        ", "pickle", ".", "dump", "(", "data", ",", "file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.preprocess_dgl_adj": [[27, 41], ["graph.adjacency_matrix", "scipy.csr_matrix", "numpy.power().flatten", "scipy.diags", "ss.csr_matrix.dot().T.dot", "dgl.from_scipy", "ss.csr_matrix.sum", "numpy.eye", "ss.csr_matrix.toarray", "numpy.power", "numpy.isinf", "ss.csr_matrix.dot"], "function", ["None"], ["", "", "def", "preprocess_dgl_adj", "(", "graph", ")", ":", "\n", "    ", "\"\"\"\n    @topic: Normalize adjacency matrix (dgl graph) for GCNs.\n    @input: graph (dgl graph); @return: graph_normalized (dgl graph).\n    \"\"\"", "\n", "adj_csr", "=", "graph", ".", "adjacency_matrix", "(", "scipy_fmt", "=", "\"csr\"", ")", "# convert dgl graph to csr matrix", "\n", "adj_csr", "=", "ss", ".", "csr_matrix", "(", "np", ".", "eye", "(", "adj_csr", ".", "shape", "[", "0", "]", ")", "+", "adj_csr", ".", "toarray", "(", ")", ")", "# add self-connection for each node", "\n", "rowsum", "=", "adj_csr", ".", "sum", "(", "1", ")", ".", "A1", "# sum up along the columns", "\n", "d_inv_sqrt", "=", "np", ".", "power", "(", "rowsum", ",", "-", "0.5", ")", ".", "flatten", "(", ")", "\n", "d_inv_sqrt", "[", "np", ".", "isinf", "(", "d_inv_sqrt", ")", "]", "=", "0.", "# Eliminate the inf number", "\n", "d_mat_inv_sqrt", "=", "ss", ".", "diags", "(", "d_inv_sqrt", ")", "# compute the inverse squared degree matrix", "\n", "adj_normalized", "=", "adj_csr", ".", "dot", "(", "d_mat_inv_sqrt", ")", ".", "T", ".", "dot", "(", "d_mat_inv_sqrt", ")", "# note that both matrix should be sparse matrix.", "\n", "graph_normalized", "=", "dgl", ".", "from_scipy", "(", "adj_normalized", ")", "\n", "return", "graph_normalized", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.split_masks": [[42, 61], ["torch.manual_seed", "list", "torch.zeros", "utils.split_masks.create_mask"], "function", ["None"], ["", "def", "split_masks", "(", "Y", ",", "cut_rate", "=", "0.2", ")", ":", "\n", "    ", "\"\"\"Split the train/val/test masks\"\"\"", "\n", "# input: Y: real label; cut_rate: the cur ratio of test mask.", "\n", "\n", "def", "create_mask", "(", "shape", ")", ":", "\n", "# Create a zero tensor for mask", "\n", "        ", "return", "torch", ".", "zeros", "(", "[", "shape", "]", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "\n", "# Create masks", "\n", "", "tensor_shape", "=", "Y", ".", "shape", "[", "0", "]", "\n", "train_mask", ",", "val_mask", ",", "test_mask", "=", "create_mask", "(", "tensor_shape", ")", ",", "create_mask", "(", "tensor_shape", ")", ",", "create_mask", "(", "tensor_shape", ")", "\n", "# Generate a random idx", "\n", "torch", ".", "manual_seed", "(", "12", ")", "\n", "idx", "=", "list", "(", "torch", ".", "utils", ".", "data", ".", "RandomSampler", "(", "range", "(", "0", ",", "Y", ".", "shape", "[", "0", "]", ")", ")", ")", "\n", "# Split the mask", "\n", "train_mask", "[", "idx", "[", ":", "int", "(", "len", "(", "idx", ")", "*", "(", "1", "-", "cut_rate", "*", "2", ")", ")", "]", "]", "=", "True", "# First (1-cut_rate*2) for train", "\n", "val_mask", "[", "idx", "[", "int", "(", "len", "(", "idx", ")", "*", "(", "1", "-", "cut_rate", "*", "2", ")", ")", ":", "int", "(", "len", "(", "idx", ")", "*", "(", "1", "-", "cut_rate", ")", ")", "]", "]", "=", "True", "# Second part for val", "\n", "test_mask", "[", "idx", "[", "int", "(", "len", "(", "idx", ")", "*", "(", "1", "-", "cut_rate", ")", ")", ":", "int", "(", "len", "(", "idx", ")", "*", "1", ")", "]", "]", "=", "True", "# Rest for test", "\n", "return", "train_mask", ",", "val_mask", ",", "test_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.generate_random_noise_label": [[62, 74], ["numpy.random.seed", "numpy.random.randint", "numpy.random.choice", "numpy.array", "min", "len", "int", "max", "len", "len"], "function", ["None"], ["", "def", "generate_random_noise_label", "(", "label", ",", "noisy_ratio", "=", "0.3", ",", "seed", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    @topic: Randomly generate noise label with given noisy_ratio.\n    @input: lable(1D-array), noise_ratio(float), seed(int).\n    @return: noisy label (1D-array).\n    \"\"\"", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "label_", "=", "np", ".", "random", ".", "randint", "(", "min", "(", "label", ")", ",", "high", "=", "max", "(", "label", ")", ",", "size", "=", "len", "(", "label", ")", ")", "\n", "mask_idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "label", ")", ",", "int", "(", "noisy_ratio", "*", "len", "(", "label", ")", ")", ",", "replace", "=", "False", ")", "\n", "label", "=", "np", ".", "array", "(", "label", ")", "\n", "label", "[", "mask_idx", "]", "=", "label_", "[", "mask_idx", "]", "\n", "return", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.gen_init_trans_matrix": [[75, 91], ["numpy.zeros", "range", "numpy.sum", "len"], "function", ["None"], ["", "def", "gen_init_trans_matrix", "(", "Y_pred_sm", ",", "Y_noisy", ",", "NUM_CLASSES", ")", ":", "\n", "    ", "\"\"\"\n    @topic: Generate initial transition matrix\n    @input:\n        Y_pred_sm (2D-array: NUM_SAMPLES x NUM_CLASSES);\n        Y_noisy (1D-array: NUM_SAMPLES x 1);\n        NUM_CLASSES (int).\n    @return: TM_init (2D-array: NUM_CLASSES x NUM_CLASSES).\n    \"\"\"", "\n", "unnorm_TM", "=", "np", ".", "zeros", "(", "(", "NUM_CLASSES", ",", "NUM_CLASSES", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "Y_noisy", ")", ")", ":", "\n", "        ", "label", "=", "Y_noisy", "[", "i", "]", "\n", "unnorm_TM", "[", ":", ",", "label", "]", "+=", "Y_pred_sm", "[", "i", "]", "\n", "", "unnorm_TM_sum", "=", "np", ".", "sum", "(", "unnorm_TM", ",", "axis", "=", "1", ")", "\n", "TM_init", "=", "unnorm_TM", "/", "unnorm_TM_sum", "[", ":", ",", "None", "]", "\n", "return", "TM_init", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.MinMaxScaler": [[92, 100], ["data.max", "data.min"], "function", ["None"], ["", "def", "MinMaxScaler", "(", "data", ",", "low", ",", "high", ")", ":", "\n", "    ", "\"\"\"Rescale 2D matrix into given range\"\"\"", "\n", "# input: data (2d matrix), low/high (Scalar).", "\n", "# output: scaled data (2d matrix).", "\n", "data_max", ",", "data_min", "=", "data", ".", "max", "(", "axis", "=", "0", ")", ",", "data", ".", "min", "(", "axis", "=", "0", ")", "\n", "data_std", "=", "(", "data", "-", "data_min", ")", "/", "(", "data_max", "-", "data_min", "+", "0.00001", ")", "\n", "data_scaled", "=", "data_std", "*", "(", "high", "-", "low", ")", "+", "low", "\n", "return", "data_scaled", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.compute_accuracy": [[101, 108], ["torch.max", "torch.sum", "len", "torch.sum.item"], "function", ["None"], ["", "def", "compute_accuracy", "(", "logits", ",", "labels", ",", "mask", ")", ":", "\n", "    ", "\"\"\"Compute the accuracy\"\"\"", "\n", "logits", "=", "logits", "[", "mask", "]", "\n", "labels", "=", "labels", "[", "mask", "]", "\n", "_", ",", "indices", "=", "torch", ".", "max", "(", "logits", ",", "dim", "=", "1", ")", "\n", "correct", "=", "torch", ".", "sum", "(", "indices", "==", "labels", ")", "\n", "return", "correct", ".", "item", "(", ")", "*", "1.0", "/", "len", "(", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.save_checkpoint": [[109, 118], ["torch.save", "os.path.exists", "os.makedirs", "shutil.copyfile"], "function", ["None"], ["", "def", "save_checkpoint", "(", "state", ",", "is_best", ",", "directory", ",", "filename", "=", "'checkpoint.pth.tar'", ")", ":", "\n", "    ", "\"\"\"Saves checkpoint\"\"\"", "\n", "import", "shutil", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "directory", ")", "\n", "", "filename", "=", "directory", "+", "filename", "\n", "torch", ".", "save", "(", "state", ",", "filename", ")", "\n", "if", "is_best", ":", "\n", "        ", "shutil", ".", "copyfile", "(", "filename", ",", "directory", "+", "'model_best.pth.tar'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.load_checkpoint": [[119, 126], ["torch.load", "model.load_state_dict", "optimizer.load_state_dict"], "function", ["None"], ["", "", "def", "load_checkpoint", "(", "checkpoint_fpath", ",", "model", ",", "optimizer", ")", ":", "\n", "    ", "\"\"\"Loads checkpoint\"\"\"", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_fpath", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state_dict'", "]", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "'optimizer'", "]", ")", "\n", "best_acc", "=", "checkpoint", "[", "'best_acc'", "]", "\n", "return", "model", ",", "optimizer", ",", "checkpoint", "[", "'epoch'", "]", ",", "best_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.count_parameters": [[127, 130], ["sum", "p.numel", "model.parameters"], "function", ["None"], ["", "def", "count_parameters", "(", "model", ")", ":", "\n", "    ", "\"\"\"Count the number of trianable parameters\"\"\"", "\n", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.tensor2array": [[131, 134], ["tensor.numpy", "tensor.cpu().numpy", "tensor.cpu"], "function", ["None"], ["", "def", "tensor2array", "(", "tensor", ",", "gpu", ")", ":", "\n", "    ", "\"\"\"Convert tensor to numpy array (Input must be Tensor)!\"\"\"", "\n", "return", "tensor", ".", "numpy", "(", ")", "if", "gpu", "<", "0", "else", "tensor", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.concate_adj": [[135, 146], ["scipy.vstack", "scipy.hstack"], "function", ["None"], ["", "def", "concate_adj", "(", "adj_old", ",", "adj_new", ")", ":", "\n", "    ", "\"\"\"Concate the perturbator adj matrix into original adj matrix\"\"\"", "\n", "# input: adj_old/adj_new are scipy sparse matrix.", "\n", "# outtput: scipy sparse matrix.", "\n", "if", "adj_old", ".", "shape", "[", "1", "]", "!=", "adj_new", "[", ":", ",", "0", ":", "adj_old", ".", "shape", "[", "1", "]", "]", ".", "shape", "[", "1", "]", ":", "\n", "        ", "return", "\"Columns are not matched!\"", "\n", "", "adj_vstack", "=", "ss", ".", "vstack", "(", "[", "adj_old", ",", "adj_new", "[", ":", ",", "0", ":", "adj_old", ".", "shape", "[", "1", "]", "]", "]", ")", "\n", "if", "adj_vstack", ".", "shape", "[", "0", "]", "!=", "adj_new", ".", "T", ".", "shape", "[", "0", "]", ":", "\n", "        ", "return", "\"Rows are not matched!\"", "\n", "", "att_hstack", "=", "ss", ".", "hstack", "(", "[", "adj_vstack", ",", "adj_new", ".", "T", "]", ")", "\n", "return", "att_hstack", "\n", "\n"]], "home.repos.pwc.inspect_result.junzhuang-code_graphlt.graphLT.utils.concate_feat": [[147, 154], ["numpy.vstack"], "function", ["None"], ["", "def", "concate_feat", "(", "feat_old", ",", "feat_new", ")", ":", "\n", "    ", "\"\"\"Concate the feature matrix\"\"\"", "\n", "# input: feat_old/feat_new are numpy array.", "\n", "# outtput: numpy array.", "\n", "if", "feat_old", ".", "shape", "[", "1", "]", "!=", "feat_new", ".", "shape", "[", "1", "]", ":", "\n", "        ", "return", "\"Columns are not matched!\"", "\n", "", "return", "np", ".", "vstack", "(", "(", "feat_old", ",", "feat_new", ")", ")", "\n", "", ""]]}