{"home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.lse.LSE.__init__": [[8, 15], ["torch.Module.__init__", "torch.device", "torch.device", "torch.device", "torch.device", "max", "numpy.finfo"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.__init__"], ["\t", "def", "__init__", "(", "self", ",", "*", ",", "mc_sample_num", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "super", "(", "LSE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "device", "=", "device", "or", "'cpu'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "self", ".", "mc_sample_num", "=", "mc_sample_num", "\n", "self", ".", "mc_sample_num_eval", "=", "max", "(", "1.0", ",", "mc_sample_num", ")", "\n", "self", ".", "eps", "=", "np", ".", "finfo", "(", "float", ")", ".", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.lse.LSE.cuda": [[16, 21], ["torch.device", "torch.device", "torch.device", "torch.device", "super().cuda"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["", "def", "cuda", "(", "self", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "device", "=", "device", "or", "'cuda'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "assert", "self", ".", "device", ".", "type", "==", "'cuda'", "\n", "super", "(", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.lse.LSE.cpu": [[22, 25], ["torch.device", "torch.device", "torch.device", "torch.device", "super().cuda"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["", "def", "cpu", "(", "self", ")", ":", "\n", "\t\t", "self", ".", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "super", "(", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.lse.LSE.forward": [[26, 51], ["lse.LSE.ls_gnhp", "type", "lse.LSE.ls_ghp", "type", "lse.LSE.ls_gpp", "Exception", "type", "type"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.lse.LSE.ls_gnhp", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.lse.LSE.ls_ghp", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.lse.LSE.ls_gpp"], ["", "def", "forward", "(", "self", ",", "model", ",", "\n", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ",", "eval_tag", "=", "False", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tmodel : GNHP or GPP or GHP ... \n\t\tchoose the right LS function based on model type \n\t\tleast-square training objective \n\t\tsum_k ( integral(lambda_k(t)^2) - 2 sum lambda_k(t) )\n\t\t\"\"\"", "\n", "if", "type", "(", "model", ")", ".", "__name__", "==", "'GNHP'", ":", "\n", "\t\t\t", "return", "self", ".", "ls_gnhp", "(", "\n", "model", ",", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ",", "\n", "eval_tag", "=", "False", "\n", ")", "\n", "", "elif", "type", "(", "model", ")", ".", "__name__", "==", "'GHP'", ":", "\n", "\t\t\t", "return", "self", ".", "ls_ghp", "(", "\n", "model", ",", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ",", "\n", "eval_tag", "=", "False", "\n", ")", "\n", "", "elif", "type", "(", "model", ")", ".", "__name__", "==", "'GPP'", ":", "\n", "\t\t\t", "return", "self", ".", "ls_gpp", "(", "\n", "model", ",", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ",", "\n", "eval_tag", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "\t\t\t", "raise", "Exception", "(", "f\"Unknown model type : {type(model).__name__}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.lse.LSE.ls_gnhp": [[52, 102], ["model.get_target", "model.get_cells_gates_states", "model.get_intensities_given_types", "model.get_mc_samples", "model.get_intensities_all_fine_types", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "float", "target_tensor.unsqueeze", "model.get_intensities_given_types.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "float", "model.get_inten_num", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "token_num_tensor.float"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_target", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.get_cells_gates_states", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_intensities_given_types", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.hp.GHP.get_mc_samples", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_intensities_all_fine_types", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_inten_num"], ["", "", "def", "ls_gnhp", "(", "self", ",", "model", ",", "\n", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ",", "eval_tag", "=", "False", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tvery similar to mle_gnhp in MLE \n\t\t\"\"\"", "\n", "target_tensor", ",", "mask_tensor", "=", "model", ".", "get_target", "(", "event_tensor", ")", "\n", "# B x T+1 , starting from 1st actual event ", "\n", "all_c_p_actual", ",", "all_cb_p_actual", ",", "all_d_p_actual", ",", "all_o_p_actual", ",", "_", ",", "_", "=", "model", ".", "get_cells_gates_states", "(", "event_tensor", ",", "dtime_tensor", ")", "\n", "# B x T+1 x D ", "\n", "inten_p_actual", "=", "model", ".", "get_intensities_given_types", "(", "\n", "all_c_p_actual", ",", "all_cb_p_actual", ",", "all_d_p_actual", ",", "all_o_p_actual", ",", "\n", "target_tensor", ".", "unsqueeze", "(", "-", "1", ")", ",", "dtime_tensor", "[", ":", ",", "1", ":", "]", "\n", ")", "# B x (T + 1) x 1", "\n", "\"\"\"\n\t\tNOTE : we sometimes use very small mc sample to train for speed-up\n\t\tbut we need >= 1 for stable eval\n\t\t\"\"\"", "\n", "mc_sample_num", "=", "self", ".", "mc_sample_num_eval", "if", "eval_tag", "else", "self", ".", "mc_sample_num", "\n", "mc_sample_num_tensor", "=", "(", "token_num_tensor", ".", "float", "(", ")", "*", "mc_sample_num", ")", ".", "long", "(", ")", "\n", "all_c_p_noise", ",", "all_cb_p_noise", ",", "all_d_p_noise", ",", "all_o_p_noise", ",", "all_dtime_noise", ",", "all_mask_noise", "=", "model", ".", "get_mc_samples", "(", "\n", "all_c_p_actual", ",", "all_cb_p_actual", ",", "\n", "all_d_p_actual", ",", "all_o_p_actual", ",", "\n", "dtime_tensor", "[", ":", ",", "1", ":", "]", ",", "mc_sample_num_tensor", ",", "\n", "duration_tensor", ",", "mask_tensor", "\n", ")", "\n", "inten_p_actual", "=", "inten_p_actual", ".", "sum", "(", "-", "1", ")", "*", "mask_tensor", "\n", "# B x (T + 1)", "\n", "\n", "# B x T' (x D)", "\n", "inten_p_noise", "=", "model", ".", "get_intensities_all_fine_types", "(", "\n", "all_c_p_noise", ",", "all_cb_p_noise", ",", "all_d_p_noise", ",", "all_o_p_noise", ",", "\n", "all_dtime_noise", "\n", ")", "\n", "# B x T' x K", "\n", "quad_inten_p_noise", "=", "inten_p_noise", "**", "2", "\n", "# B x T' x K ", "\n", "integral", "=", "torch", ".", "sum", "(", "quad_inten_p_noise", ",", "dim", "=", "-", "1", ")", "*", "all_mask_noise", "\n", "# B x T' ", "\n", "actual_counts", "=", "torch", ".", "sum", "(", "all_mask_noise", ",", "dim", "=", "-", "1", ")", "# B ", "\n", "integral", "=", "torch", ".", "sum", "(", "integral", ",", "dim", "=", "-", "1", ")", "/", "actual_counts", "\n", "integral", "=", "duration_tensor", "*", "integral", "# B ", "\n", "\n", "minus_square", "=", "2", "*", "torch", ".", "sum", "(", "inten_p_actual", ")", "-", "torch", ".", "sum", "(", "integral", ")", "\n", "\n", "inten_num", "=", "float", "(", "torch", ".", "sum", "(", "mask_tensor", ")", ")", "\n", "inten_num", "+=", "float", "(", "torch", ".", "sum", "(", "all_mask_noise", ")", ")", "*", "model", ".", "get_inten_num", "(", ")", "\n", "\n", "return", "minus_square", ",", "inten_num", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.lse.LSE.ls_ghp": [[103, 106], ["None"], "methods", ["None"], ["", "def", "ls_ghp", "(", "self", ",", "model", ",", "\n", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ",", "eval_tag", "=", "False", ")", ":", "\n", "\t\t", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.lse.LSE.ls_gpp": [[107, 110], ["None"], "methods", ["None"], ["", "def", "ls_gpp", "(", "self", ",", "model", ",", "\n", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ",", "eval_tag", "=", "False", ")", ":", "\n", "\t\t", "raise", "NotImplementedError", "", "", "", ""]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.predict.Predict.__init__": [[8, 15], ["torch.Module.__init__", "torch.device", "torch.device", "torch.device", "torch.device", "numpy.finfo"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.__init__"], ["\t", "def", "__init__", "(", "self", ",", "*", ",", "over_rate", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "super", "(", "Predict", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "device", "=", "device", "or", "'cpu'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "self", ".", "over_rate", "=", "over_rate", "\n", "self", ".", "eps", "=", "np", ".", "finfo", "(", "float", ")", ".", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.predict.Predict.cuda": [[16, 21], ["torch.device", "torch.device", "torch.device", "torch.device", "super().cuda"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["", "def", "cuda", "(", "self", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "device", "=", "device", "or", "'cuda'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "assert", "self", ".", "device", ".", "type", "==", "'cuda'", "\n", "super", "(", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.predict.Predict.cpu": [[22, 25], ["torch.device", "torch.device", "torch.device", "torch.device", "super().cuda"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["", "def", "cpu", "(", "self", ")", ":", "\n", "\t\t", "self", ".", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "super", "(", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.predict.Predict.forward": [[26, 45], ["predict.Predict.predict_gnhp", "type", "predict.Predict.predict_ghp", "type", "predict.Predict.predict_gpp", "Exception", "type", "type"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.predict.Predict.predict_gnhp", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.predict.Predict.predict_ghp", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.predict.Predict.predict_gpp"], ["", "def", "forward", "(", "self", ",", "model", ",", "\n", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tmodel : GNHP or GPP or GHP ... \n\t\t\"\"\"", "\n", "if", "type", "(", "model", ")", ".", "__name__", "==", "'GNHP'", ":", "\n", "\t\t\t", "return", "self", ".", "predict_gnhp", "(", "\n", "model", ",", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", "\n", ")", "\n", "", "elif", "type", "(", "model", ")", ".", "__name__", "==", "'GHP'", ":", "\n", "\t\t\t", "return", "self", ".", "predict_ghp", "(", "\n", "model", ",", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", "\n", ")", "\n", "", "elif", "type", "(", "model", ")", ".", "__name__", "==", "'GPP'", ":", "\n", "\t\t\t", "return", "self", ".", "predict_gpp", "(", "\n", "model", ",", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", "\n", ")", "\n", "", "else", ":", "\n", "\t\t\t", "raise", "Exception", "(", "f\"Unknown model type : {type(model).__name__}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.predict.Predict.predict_gnhp": [[46, 61], ["model.get_target", "model.get_cells_gates_states", "model.get_next_events_given_states", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.abs().float", "torch.abs().float", "torch.abs().float", "torch.abs().float", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_target", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.get_cells_gates_states", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.get_next_events_given_states"], ["", "", "def", "predict_gnhp", "(", "self", ",", "model", ",", "\n", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ")", ":", "\n", "\t\t", "target_tensor", ",", "mask_tensor", "=", "model", ".", "get_target", "(", "event_tensor", ")", "\n", "all_c_p_actual", ",", "all_cb_p_actual", ",", "all_d_p_actual", ",", "all_o_p_actual", ",", "_", ",", "_", "=", "model", ".", "get_cells_gates_states", "(", "event_tensor", ",", "dtime_tensor", ")", "\n", "all_dtime_predict", ",", "all_type_predict", "=", "model", ".", "get_next_events_given_states", "(", "\n", "all_c_p_actual", ",", "all_cb_p_actual", ",", "all_d_p_actual", ",", "all_o_p_actual", ",", "\n", "dtime_tensor", "[", ":", ",", "1", ":", "]", ",", "self", ".", "over_rate", "\n", ")", "\n", "se", "=", "(", "all_dtime_predict", "-", "dtime_tensor", "[", ":", ",", "1", ":", "]", ")", "**", "2", "\n", "se", "=", "torch", ".", "sum", "(", "se", "*", "mask_tensor", ")", "\n", "en", "=", "torch", ".", "abs", "(", "all_type_predict", "-", "target_tensor", ")", ".", "float", "(", ")", "*", "mask_tensor", "\n", "en", "=", "torch", ".", "sum", "(", "en", ">", "0.5", ")", "\n", "return", "se", ",", "en", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.predict.Predict.predict_gpp": [[62, 65], ["None"], "methods", ["None"], ["", "def", "predict_gpp", "(", "self", ",", "model", ",", "\n", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ")", ":", "\n", "\t\t", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.predict.Predict.predict_ghp": [[66, 69], ["None"], "methods", ["None"], ["", "def", "predict_ghp", "(", "self", ",", "model", ",", "\n", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ")", ":", "\n", "\t\t", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.mle.MLE.__init__": [[8, 15], ["torch.Module.__init__", "torch.device", "torch.device", "torch.device", "torch.device", "max", "numpy.finfo"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.__init__"], ["\t", "def", "__init__", "(", "self", ",", "*", ",", "mc_sample_num", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "super", "(", "MLE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "device", "=", "device", "or", "'cpu'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "self", ".", "mc_sample_num", "=", "mc_sample_num", "\n", "self", ".", "mc_sample_num_eval", "=", "max", "(", "1.0", ",", "mc_sample_num", ")", "\n", "self", ".", "eps", "=", "np", ".", "finfo", "(", "float", ")", ".", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.mle.MLE.cuda": [[16, 21], ["torch.device", "torch.device", "torch.device", "torch.device", "super().cuda"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["", "def", "cuda", "(", "self", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "device", "=", "device", "or", "'cuda'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "assert", "self", ".", "device", ".", "type", "==", "'cuda'", "\n", "super", "(", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.mle.MLE.cpu": [[22, 25], ["torch.device", "torch.device", "torch.device", "torch.device", "super().cuda"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["", "def", "cpu", "(", "self", ")", ":", "\n", "\t\t", "self", ".", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "super", "(", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.mle.MLE.forward": [[26, 49], ["mle.MLE.mle_gnhp", "type", "mle.MLE.mle_ghp", "type", "mle.MLE.mle_gpp", "Exception", "type", "type"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.mle.MLE.mle_gnhp", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.mle.MLE.mle_ghp", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.mle.MLE.mle_gpp"], ["", "def", "forward", "(", "self", ",", "model", ",", "\n", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ",", "eval_tag", "=", "False", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tmodel : GNHP or GPP or GHP ... \n\t\tchoose the right MLE function based on model type\n\t\t\"\"\"", "\n", "if", "type", "(", "model", ")", ".", "__name__", "==", "'GNHP'", ":", "\n", "\t\t\t", "return", "self", ".", "mle_gnhp", "(", "\n", "model", ",", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ",", "\n", "eval_tag", "=", "False", "\n", ")", "\n", "", "elif", "type", "(", "model", ")", ".", "__name__", "==", "'GHP'", ":", "\n", "\t\t\t", "return", "self", ".", "mle_ghp", "(", "\n", "model", ",", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ",", "\n", "eval_tag", "=", "False", "\n", ")", "\n", "", "elif", "type", "(", "model", ")", ".", "__name__", "==", "'GPP'", ":", "\n", "\t\t\t", "return", "self", ".", "mle_gpp", "(", "\n", "model", ",", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ",", "\n", "eval_tag", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "\t\t\t", "raise", "Exception", "(", "f\"Unknown model type : {type(model).__name__}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.mle.MLE.mle_gnhp": [[51, 105], ["model.get_target", "model.get_cells_gates_states", "model.get_intensities_given_types", "model.get_mc_samples", "model.get_intensities_all_fine_types", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "float", "target_tensor.unsqueeze", "torch.log", "torch.log", "torch.log", "torch.log", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "float", "model.get_inten_num", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "token_num_tensor.float", "model.get_intensities_given_types.sum"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_target", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.get_cells_gates_states", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_intensities_given_types", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.hp.GHP.get_mc_samples", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_intensities_all_fine_types", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_inten_num"], ["", "", "def", "mle_gnhp", "(", "self", ",", "model", ",", "\n", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ",", "eval_tag", "=", "False", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tinput\n\t\t\tmodel [object of GNHP] : p_theta or simply p \n\t\t\tevent_tensor [B x T+2] : a batch of event types with length T+2\n\t\t\tdtime_tensor [B x T+2] : a batch of dtimes with length T+2\n\t\t\ttoken_num_tensor [B] : # of tokens per seq \n\t\t\tduration_tensor [B] : duration per seq\n\t\t\"\"\"", "\n", "target_tensor", ",", "mask_tensor", "=", "model", ".", "get_target", "(", "event_tensor", ")", "\n", "# B x T+1 , starting from 1st actual event ", "\n", "all_c_p_actual", ",", "all_cb_p_actual", ",", "all_d_p_actual", ",", "all_o_p_actual", ",", "_", ",", "_", "=", "model", ".", "get_cells_gates_states", "(", "event_tensor", ",", "dtime_tensor", ")", "\n", "# B x T+1 x D ", "\n", "inten_p_actual", "=", "model", ".", "get_intensities_given_types", "(", "\n", "all_c_p_actual", ",", "all_cb_p_actual", ",", "all_d_p_actual", ",", "all_o_p_actual", ",", "\n", "target_tensor", ".", "unsqueeze", "(", "-", "1", ")", ",", "dtime_tensor", "[", ":", ",", "1", ":", "]", "\n", ")", "# B x (T + 1) x 1", "\n", "\"\"\"\n\t\tNOTE : we sometimes use very small mc sample to train for speed-up\n\t\tbut we need >= 1 for stable eval\n\t\t\"\"\"", "\n", "mc_sample_num", "=", "self", ".", "mc_sample_num_eval", "if", "eval_tag", "else", "self", ".", "mc_sample_num", "\n", "mc_sample_num_tensor", "=", "(", "token_num_tensor", ".", "float", "(", ")", "*", "mc_sample_num", ")", ".", "long", "(", ")", "\n", "all_c_p_noise", ",", "all_cb_p_noise", ",", "all_d_p_noise", ",", "all_o_p_noise", ",", "all_dtime_noise", ",", "all_mask_noise", "=", "model", ".", "get_mc_samples", "(", "\n", "all_c_p_actual", ",", "all_cb_p_actual", ",", "\n", "all_d_p_actual", ",", "all_o_p_actual", ",", "\n", "dtime_tensor", "[", ":", ",", "1", ":", "]", ",", "mc_sample_num_tensor", ",", "\n", "duration_tensor", ",", "mask_tensor", "\n", ")", "\n", "# B x T' (x D)", "\n", "inten_p_noise", "=", "model", ".", "get_intensities_all_fine_types", "(", "\n", "all_c_p_noise", ",", "all_cb_p_noise", ",", "all_d_p_noise", ",", "all_o_p_noise", ",", "\n", "all_dtime_noise", "\n", ")", "\n", "# B x T' x K", "\n", "log_inten", "=", "torch", ".", "log", "(", "inten_p_actual", ".", "sum", "(", "-", "1", ")", "+", "self", ".", "eps", ")", "*", "mask_tensor", "\n", "# B x (T + 1)", "\n", "integral", "=", "torch", ".", "sum", "(", "inten_p_noise", ",", "dim", "=", "-", "1", ")", "*", "all_mask_noise", "\n", "# B x T'", "\n", "actual_counts", "=", "torch", ".", "sum", "(", "all_mask_noise", ",", "dim", "=", "-", "1", ")", "# B ", "\n", "integral", "=", "torch", ".", "sum", "(", "integral", ",", "dim", "=", "-", "1", ")", "/", "actual_counts", "\n", "integral", "=", "duration_tensor", "*", "integral", "# B", "\n", "log_likelihood", "=", "torch", ".", "sum", "(", "log_inten", ")", "-", "torch", ".", "sum", "(", "integral", ")", "\n", "\"\"\"\n\t\tcount # of intensities that we computed for this log-likelihood\n\t\t\"\"\"", "\n", "inten_num", "=", "float", "(", "torch", ".", "sum", "(", "mask_tensor", ")", ")", "\n", "# one intensity per actual event ", "\n", "inten_num", "+=", "float", "(", "torch", ".", "sum", "(", "all_mask_noise", ")", ")", "*", "model", ".", "get_inten_num", "(", ")", "\n", "# total # of intensities per noise sample", "\n", "return", "log_likelihood", ",", "inten_num", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.mle.MLE.mle_ghp": [[107, 159], ["model.get_target", "model.get_states", "model.get_mc_samples", "model.get_intensities", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "model.get_intensities", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "float", "torch.log", "torch.log", "torch.log", "torch.log", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "float", "model.get_inten_num", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "token_num_tensor.float", "target_tensor.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_target", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.hp.GHP.get_states", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.hp.GHP.get_mc_samples", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.hp.GHP.get_intensities", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.hp.GHP.get_intensities", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_inten_num"], ["", "def", "mle_ghp", "(", "self", ",", "model", ",", "\n", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ",", "eval_tag", "=", "False", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tinput\n\t\t\tmodel [object of GNHP] : p_theta or simply p \n\t\t\tevent_tensor [B x T+2] : a batch of event types with length T+2\n\t\t\tdtime_tensor [B x T+2] : a batch of dtimes with length T+2\n\t\t\ttoken_num_tensor [B] : # of tokens per seq \n\t\t\tduration_tensor [B] : duration per seq\n\t\t\"\"\"", "\n", "target_tensor", ",", "mask_tensor", "=", "model", ".", "get_target", "(", "event_tensor", ")", "\n", "# B x T+1", "\n", "past_event", ",", "past_time", "=", "model", ".", "get_states", "(", "event_tensor", ",", "dtime_tensor", ")", "\n", "# B x T", "\n", "\"\"\"\n\t\tNOTE : we sometimes use very small mc sample to train for speed-up\n\t\tbut we need >= 1 for stable eval\n\t\t\"\"\"", "\n", "mc_sample_num", "=", "self", ".", "mc_sample_num_eval", "if", "eval_tag", "else", "self", ".", "mc_sample_num", "\n", "mc_sample_num_tensor", "=", "(", "token_num_tensor", ".", "float", "(", ")", "*", "mc_sample_num", ")", ".", "long", "(", ")", "\n", "\n", "all_time_noise", ",", "all_mask_noise", "=", "model", ".", "get_mc_samples", "(", "\n", "dtime_tensor", "[", ":", ",", "1", ":", "]", ",", "mc_sample_num_tensor", ",", "duration_tensor", ",", "mask_tensor", "\n", ")", "\n", "# B x T' ", "\n", "inten_p_actual", "=", "model", ".", "get_intensities", "(", "\n", "past_event", ",", "past_time", ",", "torch", ".", "cumsum", "(", "dtime_tensor", ",", "dim", "=", "-", "1", ")", "[", ":", ",", "1", ":", "]", "\n", ")", "\n", "inten_p_actual", "=", "torch", ".", "gather", "(", "\n", "inten_p_actual", ",", "# B x T+1 x K ", "\n", "-", "1", ",", "target_tensor", ".", "unsqueeze", "(", "-", "1", ")", "# B x T+1 x 1", "\n", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "# B x T+1", "\n", "inten_p_noise", "=", "model", ".", "get_intensities", "(", "\n", "past_event", ",", "past_time", ",", "all_time_noise", "\n", ")", "\n", "# B x T' x K ", "\n", "log_inten", "=", "torch", ".", "log", "(", "inten_p_actual", "+", "self", ".", "eps", ")", "*", "mask_tensor", "\n", "# B x T+1", "\n", "integral", "=", "torch", ".", "sum", "(", "inten_p_noise", ",", "dim", "=", "-", "1", ")", "*", "all_mask_noise", "\n", "# B x T' ", "\n", "actual_counts", "=", "torch", ".", "sum", "(", "all_mask_noise", ",", "dim", "=", "-", "1", ")", "# B ", "\n", "integral", "=", "torch", ".", "sum", "(", "integral", ",", "dim", "=", "-", "1", ")", "/", "actual_counts", "\n", "integral", "=", "duration_tensor", "*", "integral", "# B ", "\n", "log_likelihood", "=", "torch", ".", "sum", "(", "log_inten", ")", "-", "torch", ".", "sum", "(", "integral", ")", "\n", "\"\"\"\n\t\tcount # of intensities that we computed for this log-likelihood\n\t\t\"\"\"", "\n", "inten_num", "=", "float", "(", "torch", ".", "sum", "(", "mask_tensor", ")", ")", "\n", "inten_num", "+=", "float", "(", "torch", ".", "sum", "(", "all_mask_noise", ")", ")", "*", "model", ".", "get_inten_num", "(", ")", "\n", "\n", "return", "log_likelihood", ",", "inten_num", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.mle.MLE.mle_gpp": [[162, 196], ["model.get_target", "model.get_intensities_given_types", "model.get_intensities_all_fine_types", "float", "target_tensor.unsqueeze", "torch.log", "torch.log", "torch.log", "torch.log", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "model.get_intensities_given_types.sum"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_target", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_intensities_given_types", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_intensities_all_fine_types"], ["", "def", "mle_gpp", "(", "self", ",", "model", ",", "\n", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ",", "eval_tag", "=", "False", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tinput\n\t\t\tmodel [object of GPP] : p_theta or simply p \n\t\t\tevent_tensor [B x T+2] : a batch of event types with length T+2\n\t\t\tdtime_tensor [B x T+2] : a batch of dtimes with length T+2\n\t\t\ttoken_num_tensor [B] : # of tokens per seq \n\t\t\tduration_tensor [B] : duration per seq\n\t\t\"\"\"", "\n", "target_tensor", ",", "mask_tensor", "=", "model", ".", "get_target", "(", "event_tensor", ")", "\n", "# B x T+1 , starting from 1st actual event ", "\n", "inten_p_actual", "=", "model", ".", "get_intensities_given_types", "(", "\n", "target_tensor", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "\n", "# B x (T+1) x 1", "\n", "inten_p_noise", "=", "model", ".", "get_intensities_all_fine_types", "(", ")", "\n", "# K", "\n", "log_inten", "=", "torch", ".", "log", "(", "inten_p_actual", ".", "sum", "(", "-", "1", ")", "+", "self", ".", "eps", ")", "*", "mask_tensor", "\n", "# B x (T + 1)", "\n", "integral", "=", "torch", ".", "sum", "(", "inten_p_noise", ")", "*", "duration_tensor", "# B", "\n", "log_likelihood", "=", "torch", ".", "sum", "(", "log_inten", ")", "-", "torch", ".", "sum", "(", "integral", ")", "\n", "\"\"\"\n\t\tcount # of intensities that we computed for this log-likelihood\n\t\tfor GPP (generalized Poisson process), intensities are stationary \n\t\tso we only need to make K computation\n\t\tthe cost stays the same when we have more sequences \n\t\tbecause intensities are history-independent\n\t\tactually, # of intensities evaluated means nothing in this model\n\t\targuably, it should be 0 because we only care \n\t\t# of ``neural'' intensity evaluations\n\t\t\"\"\"", "\n", "inten_num", "=", "float", "(", "model", ".", "event_num", ")", "\n", "return", "log_likelihood", ",", "inten_num", "", "", "", ""]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.nce.NCE.__init__": [[9, 32], ["torch.Module.__init__", "torch.device", "torch.device", "torch.device", "torch.device", "numpy.finfo"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.__init__"], ["\t", "def", "__init__", "(", "self", ",", "*", ",", "\n", "noise_process_num", ",", "noise_type_num", ",", "over_rate", ",", "redraw_prob", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "super", "(", "NCE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\"\"\"\n\t\t:param noise_process_num: M1, # of noise processes in parallel \n\t\t:param noise_type_num: M2, # of noise types per time t\n\t\t:param over_rate: over-sampling rate for noise times\n\t\t\"\"\"", "\n", "device", "=", "device", "or", "'cpu'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "self", ".", "noise_process_num", "=", "noise_process_num", "\n", "self", ".", "noise_type_num", "=", "noise_type_num", "\n", "self", ".", "over_rate", "=", "over_rate", "\n", "self", ".", "redraw_prob", "=", "redraw_prob", "\n", "self", ".", "eps", "=", "np", ".", "finfo", "(", "float", ")", ".", "eps", "\n", "assert", "noise_process_num", ">=", "1", ",", "f\"invalid noise process # : {noise_process_num} \"", "\n", "assert", "noise_type_num", ">=", "1", ",", "f\"invalid noise type # : {noise_type_num}\"", "\n", "assert", "over_rate", ">=", "1.0", ",", "f\"invalid over rate : {over_rate} \"", "\n", "\n", "\"\"\"\n\t\treparametric normalizer for binary-classification NCE (Guo et al 2018)\n\t\t\"\"\"", "\n", "self", ".", "normalizer", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.nce.NCE.cuda": [[34, 39], ["torch.device", "torch.device", "torch.device", "torch.device", "super().cuda"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["", "def", "cuda", "(", "self", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "device", "=", "device", "or", "'cuda'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "assert", "self", ".", "device", ".", "type", "==", "'cuda'", "\n", "super", "(", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.nce.NCE.cpu": [[40, 43], ["torch.device", "torch.device", "torch.device", "torch.device", "super().cuda"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["", "def", "cpu", "(", "self", ")", ":", "\n", "\t\t", "self", ".", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "super", "(", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.nce.NCE.forward": [[45, 202], ["model.get_target", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.get_cells_gates_states", "model.get_interpolated_cells", "model.get_intensities_given_types", "model.get_intensities_given_types", "nce.NCE.count_inten_num", "random.uniform", "nce.NCE.compute_obj_frac", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "noise.get_noise_samples", "Exception", "target_tensor.unsqueeze", "nce.NCE.compute_obj_async", "type", "nce.NCE.compute_obj_sync", "nce.NCE.normalizer().squeeze", "nce.NCE.normalizer().squeeze", "nce.NCE.compute_obj_binary", "Exception", "torch.Sequential", "torch.Sequential", "nce.NCE.normalizer.to", "torch.Linear", "torch.Linear", "torch.Softplus", "torch.Softplus", "nce.NCE.normalizer", "nce.NCE.normalizer"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_target", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.get_cells_gates_states", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.get_interpolated_cells", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_intensities_given_types", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_intensities_given_types", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.nce.NCE.count_inten_num", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.nce.NCE.compute_obj_frac", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_noise_samples", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.nce.NCE.compute_obj_async", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.nce.NCE.compute_obj_sync", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.nce.NCE.compute_obj_binary"], ["", "def", "forward", "(", "self", ",", "method", ",", "model", ",", "noise", ",", "\n", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ",", "\n", "noise_tensor_pack", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tinput : \n\t\t\tmethod [str] : which NCE method to use -- frac or async or sync?\n\t\t\tmodel [object of GNHP] : p_theta or simply p \n\t\t\tnoise [object of GNHP/GPP] : p_N or simply q (q is a convention for proposal dist)\n\t\t\tevent_tensor [B x T+2] : a batch of event types with length T+2\n\t\t\tdtime_tensor [B x T+2] : a batch of dtimes with length T+2\n\t\t\ttoken_num_tensor [B] : # of tokens per seq \n\t\t\tduration_tensor [B] : duration per seq\n\t\t\tnoise_tensor_pack : list of tensors related to noise samples\n\t\t\"\"\"", "\n", "\"\"\"\n\t\tNOTE : for now, we only use NCE to train GNHP, not GPP\n\t\tGPP can only be used as a noise distribution \n\t\t\"\"\"", "\n", "\"\"\"\n\t\tget cells, gates & states for actual events from model\n\t\t\"\"\"", "\n", "target_tensor", ",", "mask_tensor", "=", "model", ".", "get_target", "(", "event_tensor", ")", "\n", "# B x T+1 , starting from 1st actual event ", "\n", "\n", "have_noise", "=", "noise_tensor_pack", "is", "not", "None", "\n", "prob_small", "=", "self", ".", "redraw_prob", "<=", "1e-6", "\n", "random_draw", "=", "random", ".", "uniform", "(", "0.0", ",", "1.0", ")", "<=", "self", ".", "redraw_prob", "\n", "\n", "if", "not", "have_noise", "or", "(", "not", "prob_small", "and", "random_draw", ")", ":", "\n", "\t\t\t", "\"\"\"\n\t\t\tno noise samples yet or roll a dice and decide to draw\n\t\t\t\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t\t", "\"\"\"\n\t\t\t\tget noise times and types and their q intensities \n\t\t\t\t\"\"\"", "\n", "\"\"\"\n\t\t\t\t_time : _noise == at noise times, _actual == at actual times\n\t\t\t\t_time_type : _actual_noise == at actual times, of noise types\n\t\t\t\t\"\"\"", "\n", "all_type_actual_noise", ",", "all_type_noise_noise", ",", "all_dtime_noise", ",", "all_mask_noise", ",", "inten_q_actual_both", ",", "inten_q_noise_noise", ",", "all_accept_prob_noise", ",", "all_S_noise", ",", "all_inten_num_noise", "=", "noise", ".", "get_noise_samples", "(", "\n", "method", ",", "\n", "event_tensor", ",", "dtime_tensor", ",", "target_tensor", ",", "mask_tensor", ",", "duration_tensor", ",", "\n", "self", ".", "noise_process_num", ",", "self", ".", "noise_type_num", ",", "self", ".", "over_rate", "\n", ")", "\n", "# _noise : B x T' ", "\n", "# _actual : B x (T+1)", "\n", "# _actual_noise : B x (T+1) x noise_type_num", "\n", "# _noise_noise : B x T' x noise_type_num", "\n", "# S : <T' ", "\n", "count_noise", "=", "1.0", "\n", "new_noise_pack", "=", "all_type_actual_noise", ",", "all_type_noise_noise", ",", "all_dtime_noise", ",", "all_mask_noise", ",", "inten_q_actual_both", ",", "inten_q_noise_noise", ",", "all_accept_prob_noise", ",", "all_S_noise", ",", "all_inten_num_noise", "\n", "", "", "elif", "have_noise", "and", "(", "prob_small", "or", "not", "random_draw", ")", ":", "\n", "\t\t\t", "\"\"\"\n\t\t\tuse pre-saved noise pack\n\t\t\t\"\"\"", "\n", "all_type_actual_noise", ",", "all_type_noise_noise", ",", "all_dtime_noise", ",", "all_mask_noise", ",", "inten_q_actual_both", ",", "inten_q_noise_noise", ",", "all_accept_prob_noise", ",", "all_S_noise", ",", "all_inten_num_noise", "=", "noise_tensor_pack", "\n", "\n", "count_noise", "=", "0.0", "\n", "new_noise_pack", "=", "None", "# don't update it", "\n", "", "else", ":", "\n", "\t\t\t", "raise", "Exception", "(", "f\"Unknown case : do you want to sample at all or not?!\"", ")", "\n", "\n", "", "\"\"\"\n\t\tgiven all of K (fine) intensities of noise dist q \n\t\tat both noise and actual times \n\t\tfind the intensities of actual and noise event types \n\t\t_both : of both actual and noise event types \n\t\t\"\"\"", "\n", "all_type_actual_both", "=", "torch", ".", "cat", "(", "\n", "[", "target_tensor", ".", "unsqueeze", "(", "-", "1", ")", ",", "all_type_actual_noise", "]", ",", "dim", "=", "-", "1", "\n", ")", "# B x (T + 1) x (1 + noise_type_num) # 0-th == actual", "\n", "\"\"\"\n\t\tcompute cells and gates for model p\n\t\t\"\"\"", "\n", "all_c_p_actual", ",", "all_cb_p_actual", ",", "all_d_p_actual", ",", "all_o_p_actual", ",", "_", ",", "_", "=", "model", ".", "get_cells_gates_states", "(", "event_tensor", ",", "dtime_tensor", ")", "\n", "# B x T+1 x D ", "\n", "\"\"\"\n\t\tinterpolate cells and gates at noise times\n\t\t\"\"\"", "\n", "all_c_p_noise", ",", "all_cb_p_noise", ",", "all_d_p_noise", ",", "all_o_p_noise", "=", "model", ".", "get_interpolated_cells", "(", "\n", "all_c_p_actual", ",", "all_cb_p_actual", ",", "all_d_p_actual", ",", "all_o_p_actual", ",", "\n", "all_S_noise", "\n", ")", "# B x T' x D ", "\n", "\"\"\"\n\t\tcompute intensities of model distribution p \n\t\t\"\"\"", "\n", "inten_p_actual_both", "=", "model", ".", "get_intensities_given_types", "(", "\n", "all_c_p_actual", ",", "all_cb_p_actual", ",", "all_d_p_actual", ",", "all_o_p_actual", ",", "\n", "all_type_actual_both", ",", "dtime_tensor", "[", ":", ",", "1", ":", "]", "\n", ")", "# B x (T + 1) x (1 + noise_type_num)", "\n", "inten_p_noise_noise", "=", "model", ".", "get_intensities_given_types", "(", "\n", "all_c_p_noise", ",", "all_cb_p_noise", ",", "all_d_p_noise", ",", "all_o_p_noise", ",", "\n", "all_type_noise_noise", ",", "all_dtime_noise", "\n", ")", "# B x T' x noise_type_num ", "\n", "if", "method", "==", "'nce_frac'", ":", "\n", "\t\t\t", "nce_obj", "=", "self", ".", "compute_obj_frac", "(", "\n", "inten_p_actual_both", ",", "inten_p_noise_noise", ",", "\n", "inten_q_actual_both", ",", "inten_q_noise_noise", ",", "\n", "mask_tensor", ",", "all_mask_noise", ",", "all_accept_prob_noise", "\n", ")", "\n", "", "elif", "method", "==", "'nce_async'", ":", "\n", "\t\t\t", "nce_obj", "=", "self", ".", "compute_obj_async", "(", "\n", "inten_p_actual_both", ",", "inten_p_noise_noise", ",", "\n", "inten_q_actual_both", ",", "inten_q_noise_noise", ",", "\n", "mask_tensor", ",", "all_mask_noise", "\n", ")", "\n", "", "elif", "method", "==", "'nce_sync'", ":", "\n", "\t\t\t", "nce_obj", "=", "self", ".", "compute_obj_sync", "(", "\n", "inten_p_actual_both", ",", "inten_p_noise_noise", ",", "\n", "inten_q_actual_both", ",", "inten_q_noise_noise", ",", "\n", "mask_tensor", ",", "all_mask_noise", "\n", ")", "\n", "", "elif", "method", "==", "'nce_binary'", ":", "\n", "\n", "\t\t\t", "if", "not", "self", ".", "normalizer", ":", "\n", "\t\t\t\t", "self", ".", "normalizer", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "model", ".", "hidden_dim", ",", "1", ")", ",", "nn", ".", "Softplus", "(", ")", "\n", ")", "\n", "self", ".", "normalizer", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "", "norm_actual", "=", "self", ".", "normalizer", "(", "all_c_p_actual", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "# B x (T + 1)", "\n", "norm_noise", "=", "self", ".", "normalizer", "(", "all_c_p_noise", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "# B x T'", "\n", "\n", "nce_obj", "=", "self", ".", "compute_obj_binary", "(", "\n", "inten_p_actual_both", ",", "inten_p_noise_noise", ",", "\n", "norm_actual", ",", "norm_noise", ",", "\n", "mask_tensor", ",", "all_mask_noise", "\n", ")", "\n", "\n", "", "else", ":", "\n", "\t\t\t", "raise", "Exception", "(", "f\"Unknown NCE method : {method}\"", ")", "\n", "", "\"\"\"\n\t\tcount # of intensities that we computed for this objective\n\t\t\"\"\"", "\n", "inten_num", "=", "self", ".", "count_inten_num", "(", "\n", "type", "(", "noise", ")", ".", "__name__", ",", "\n", "mask_tensor", ",", "all_mask_noise", ",", "all_inten_num_noise", ",", "count_noise", "\n", ")", "\n", "return", "nce_obj", ",", "inten_num", ",", "new_noise_pack", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.nce.NCE.count_inten_num": [[203, 228], ["float", "float", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "Exception", "float", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "count_inten_num", "(", "self", ",", "noise_name", ",", "\n", "mask_tensor", ",", "all_mask_noise", ",", "all_inten_num_noise", ",", "count_noise", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tcount # of intensities that we computed for this objective\n\t\t\"\"\"", "\n", "inten_num", "=", "float", "(", "torch", ".", "sum", "(", "mask_tensor", ")", ")", "\n", "# intensity under model p per actual event ", "\n", "inten_num", "+=", "float", "(", "torch", ".", "sum", "(", "all_mask_noise", ")", ")", "\n", "# intensity under model p per noise event ", "\n", "if", "noise_name", "==", "'GNHP'", ":", "\n", "\t\t\t", "inten_num", "+=", "float", "(", "torch", ".", "sum", "(", "mask_tensor", ")", ")", "*", "1.0", "*", "count_noise", "\n", "# intensity under noise dist q per actual event ", "\n", "inten_num", "+=", "all_inten_num_noise", "*", "1.0", "*", "count_noise", "\n", "# all_inten_num_noise : # of intensities computed in order to get noise samples", "\n", "# including, e.g., # of intensities computed in thinning algorithm", "\n", "# this number already considers intensity under noise dist q per noise event ", "\n", "# so we shouldn't double-count it", "\n", "", "elif", "noise_name", "==", "'GPP'", ":", "\n", "\t\t\t", "inten_num", "+=", "0.0", "\n", "# it is super cheap to compute intensities in GPP ", "\n", "# we only count intensities that are expensive to compute ", "\n", "# e.g., neural intensities ", "\n", "", "else", ":", "\n", "\t\t\t", "raise", "Exception", "(", "f\"Unknown noise name : {noise_name}\"", ")", "\n", "", "return", "inten_num", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.nce.NCE.compute_obj_frac": [[230, 261], ["torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "inten_p_noise_noise.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "inten_q_noise_noise.sum"], "methods", ["None"], ["", "def", "compute_obj_frac", "(", "self", ",", "\n", "inten_p_actual_both", ",", "inten_p_noise_noise", ",", "\n", "inten_q_actual_both", ",", "inten_q_noise_noise", ",", "\n", "mask_tensor", ",", "all_mask_noise", ",", "all_accept_prob_noise", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tfractional version of NCE (fractional version of async) : \n\t\t\"\"\"", "\n", "assert", "self", ".", "noise_type_num", "==", "1", ",", "\"more than 1 noise type for frac (i.e. frac of async)?!\"", "\n", "\"\"\"\n\t\tlargely copy _async : may need to revise or merge\n\t\t\"\"\"", "\n", "nume_actual", "=", "inten_p_actual_both", "[", ":", ",", ":", ",", "0", "]", "\n", "deno_actual", "=", "inten_p_actual_both", "[", ":", ",", ":", ",", "0", "]", "+", "inten_q_actual_both", "[", ":", ",", ":", ",", "0", "]", "*", "(", "self", ".", "noise_process_num", "*", "1.0", ")", "\n", "log_posterior_actual", "=", "torch", ".", "log", "(", "nume_actual", "+", "self", ".", "eps", ")", "-", "torch", ".", "log", "(", "deno_actual", "+", "self", ".", "eps", ")", "\n", "log_posterior_actual", "=", "log_posterior_actual", "*", "mask_tensor", "\n", "# B x (T + 1)", "\n", "deno_noise", "=", "inten_p_noise_noise", ".", "sum", "(", "-", "1", ")", "+", "inten_q_noise_noise", ".", "sum", "(", "-", "1", ")", "*", "(", "self", ".", "noise_process_num", "*", "1.0", ")", "\n", "log_posterior_noise", "=", "-", "torch", ".", "log", "(", "deno_noise", "+", "self", ".", "eps", ")", "\n", "\"\"\"\n\t\tNOTE : USE ACCEPT PROB that fall in [0, 1]\n\t\tsuch that each proposed noise time is counted with some probability\n\t\tthis increases sample efficiency\n\t\t\"\"\"", "\n", "log_posterior_noise", "=", "log_posterior_noise", "*", "all_mask_noise", "*", "all_accept_prob_noise", "\n", "# B x T' ", "\n", "nce_obj", "=", "torch", ".", "sum", "(", "log_posterior_actual", ")", "+", "torch", ".", "sum", "(", "log_posterior_noise", ")", "\n", "return", "nce_obj", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.nce.NCE.compute_obj_async": [[263, 288], ["torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "inten_p_noise_noise.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "inten_q_noise_noise.sum"], "methods", ["None"], ["", "def", "compute_obj_async", "(", "self", ",", "\n", "inten_p_actual_both", ",", "inten_p_noise_noise", ",", "\n", "inten_q_actual_both", ",", "inten_q_noise_noise", ",", "\n", "mask_tensor", ",", "all_mask_noise", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tasync version of NCE : only one not-NULL noise types per time\n\t\t\"\"\"", "\n", "assert", "self", ".", "noise_type_num", "==", "1", ",", "\"more than 1 noise type for async?!\"", "\n", "\"\"\"\n\t\tcompute NCE objective \n\t\t\"\"\"", "\n", "nume_actual", "=", "inten_p_actual_both", "[", ":", ",", ":", ",", "0", "]", "\n", "deno_actual", "=", "inten_p_actual_both", "[", ":", ",", ":", ",", "0", "]", "+", "inten_q_actual_both", "[", ":", ",", ":", ",", "0", "]", "*", "(", "self", ".", "noise_process_num", "*", "1.0", ")", "\n", "log_posterior_actual", "=", "torch", ".", "log", "(", "nume_actual", "+", "self", ".", "eps", ")", "-", "torch", ".", "log", "(", "deno_actual", "+", "self", ".", "eps", ")", "\n", "log_posterior_actual", "=", "log_posterior_actual", "*", "mask_tensor", "\n", "# B x (T + 1)", "\n", "deno_noise", "=", "inten_p_noise_noise", ".", "sum", "(", "-", "1", ")", "+", "inten_q_noise_noise", ".", "sum", "(", "-", "1", ")", "*", "(", "self", ".", "noise_process_num", "*", "1.0", ")", "\n", "log_posterior_noise", "=", "-", "torch", ".", "log", "(", "deno_noise", "+", "self", ".", "eps", ")", "\n", "log_posterior_noise", "=", "log_posterior_noise", "*", "all_mask_noise", "\n", "# B x T' ", "\n", "nce_obj", "=", "torch", ".", "sum", "(", "log_posterior_actual", ")", "+", "torch", ".", "sum", "(", "log_posterior_noise", ")", "\n", "return", "nce_obj", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.nce.NCE.compute_obj_binary": [[290, 321], ["torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "inten_p_noise_noise.sum"], "methods", ["None"], ["", "def", "compute_obj_binary", "(", "self", ",", "\n", "inten_p_actual_both", ",", "inten_p_noise_noise", ",", "\n", "norm_actual", ",", "norm_noise", ",", "\n", "mask_tensor", ",", "all_mask_noise", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tbinary-classification NCE : real next event or noise next event?\n\t\t\"\"\"", "\n", "\"\"\"\n\t\tneural normalizer or constant 1? \n\t\tGuo et al used both\n\t\tI tried both but constant = 1.0 makes better\n\t\tif one wants to use the neural normalizer\n\t\tjust simply comment out the 2 lines below\n\t\t\"\"\"", "\n", "norm_actual", "=", "1.0", "# comment out to use neural", "\n", "norm_noise", "=", "1.0", "# comment out to use neural", "\n", "\n", "nume_actual", "=", "inten_p_actual_both", "[", ":", ",", ":", ",", "0", "]", "*", "norm_actual", "\n", "deno_actual", "=", "inten_p_actual_both", "[", ":", ",", ":", ",", "0", "]", "*", "norm_actual", "+", "1.0", "\n", "# reparametrization trick proposed by Mnih & Teh 2012", "\n", "# used by Guo et al 2018", "\n", "log_posterior_actual", "=", "torch", ".", "log", "(", "nume_actual", "+", "self", ".", "eps", ")", "-", "torch", ".", "log", "(", "deno_actual", "+", "self", ".", "eps", ")", "\n", "log_posterior_actual", "=", "log_posterior_actual", "*", "mask_tensor", "\n", "# B x (T + 1)", "\n", "deno_noise", "=", "inten_p_noise_noise", ".", "sum", "(", "-", "1", ")", "*", "norm_noise", "+", "1.0", "\n", "log_posterior_noise", "=", "-", "torch", ".", "log", "(", "deno_noise", "+", "self", ".", "eps", ")", "\n", "log_posterior_noise", "=", "log_posterior_noise", "*", "all_mask_noise", "\n", "# B x T' ", "\n", "nce_obj", "=", "torch", ".", "sum", "(", "log_posterior_actual", ")", "+", "torch", ".", "sum", "(", "log_posterior_noise", ")", "\n", "return", "nce_obj", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.objectives.nce.NCE.compute_obj_sync": [[327, 356], ["ratio_actual_both.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "ratio_noise_noise.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["def", "compute_obj_sync", "(", "self", ",", "\n", "inten_p_actual_both", ",", "inten_p_noise_noise", ",", "\n", "inten_q_actual_both", ",", "inten_q_noise_noise", ",", "\n", "mask_tensor", ",", "all_mask_noise", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tsync version of NCE : multiple not-NULL noise types per time\n\t\t\"\"\"", "\n", "assert", "self", ".", "noise_process_num", "==", "1", ",", "\"more then 1 process for sync?!\"", "\n", "\"\"\"\n\t\tcompute NCE objective \n\t\t\"\"\"", "\n", "ratio_actual_both", "=", "inten_p_actual_both", "/", "(", "inten_q_actual_both", "+", "self", ".", "eps", ")", "\n", "# B x (T + 1) x (1 + noise_type_num)", "\n", "ratio_noise_noise", "=", "inten_p_noise_noise", "/", "(", "inten_q_noise_noise", "+", "self", ".", "eps", ")", "\n", "# B x T' x noise_type_num", "\n", "nume_actual", "=", "ratio_actual_both", "[", ":", ",", ":", ",", "0", "]", "\n", "deno_actual", "=", "ratio_actual_both", ".", "sum", "(", "-", "1", ")", "\n", "log_posterior_actual", "=", "torch", ".", "log", "(", "nume_actual", "+", "self", ".", "eps", ")", "-", "torch", ".", "log", "(", "deno_actual", "+", "self", ".", "eps", ")", "\n", "log_posterior_actual", "=", "log_posterior_actual", "*", "mask_tensor", "\n", "# B x (T + 1)", "\n", "deno_noise", "=", "ratio_noise_noise", ".", "sum", "(", "-", "1", ")", "+", "1.0", "\n", "log_posterior_noise", "=", "-", "torch", ".", "log", "(", "deno_noise", "+", "self", ".", "eps", ")", "\n", "log_posterior_noise", "=", "log_posterior_noise", "*", "all_mask_noise", "\n", "# B x T'", "\n", "nce_obj", "=", "torch", ".", "sum", "(", "log_posterior_actual", ")", "+", "torch", ".", "sum", "(", "log_posterior_noise", ")", "\n", "return", "nce_obj", "", "", "", ""]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.org_log.main": [[22, 46], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "vars", "os.path.abspath", "os.path.join", "ncempp.io.log.LogBatchReader", "ncempp.io.log.LogBatchReader.write_csv"], "function", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.write_csv"], ["def", "main", "(", ")", ":", "\n", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'organize logs'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "'-ds'", ",", "'--Dataset'", ",", "required", "=", "True", ",", "type", "=", "str", ",", "help", "=", "'e.g. smallnhp, meme, etc'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-cn'", ",", "'--CSVName'", ",", "required", "=", "True", ",", "type", "=", "str", ",", "\n", "help", "=", "'prefix name of meta and log csv'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-rp'", ",", "'--RootPath'", ",", "type", "=", "str", ",", "default", "=", "'../../'", ",", "\n", "help", "=", "'root path of project'", "\n", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "dict_args", "=", "vars", "(", "args", ")", "\n", "\n", "root_path", "=", "os", ".", "path", ".", "abspath", "(", "args", ".", "RootPath", ")", "\n", "args", ".", "PathLog", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "f\"logs/{dict_args['Dataset']}\"", ")", "\n", "\n", "org", "=", "LogBatchReader", "(", "args", ".", "PathLog", ",", "args", ".", "CSVName", ")", "\n", "org", ".", "write_csv", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.train.train": [[13, 138], ["ncempp.run.manager.Manager", "print", "ncempp.run.manager.Manager.prepare_training", "print", "ncempp.run.manager.Manager.load_data", "print", "ncempp.run.manager.Manager.process_data", "print", "list", "list", "list", "ncempp.run.manager.Manager.get_batchupdate_num", "range", "ncempp.run.manager.Manager.print_or_buffer", "ncempp.run.manager.Manager.checkpoint", "ncempp.run.manager.Manager.flush_buffer", "range", "time.time", "ncempp.run.manager.Manager.train_batch", "time.time", "list.append", "list.append", "print", "time.time", "ncempp.run.manager.Manager.eval_mle_epoch", "time.time", "list.append", "ncempp.run.manager.Manager.print_or_buffer", "ncempp.run.manager.Manager.checkpoint", "sum", "ncempp.run.manager.Manager.print_or_buffer", "ncempp.run.manager.Manager.checkpoint", "sum", "ncempp.run.manager.Manager.print_or_buffer", "ncempp.run.manager.Manager.checkpoint", "ncempp.run.manager.Manager.print_or_buffer", "ncempp.run.manager.Manager.checkpoint", "ncempp.run.manager.Manager.print_or_buffer", "ncempp.run.manager.Manager.checkpoint", "ncempp.run.manager.Manager.save_model"], "function", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.prepare_training", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.load_data", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.process_data", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.get_batchupdate_num", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.print_or_buffer", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogWriter.checkpoint", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.flush_buffer", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.train_batch", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.eval_mle_epoch", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.print_or_buffer", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogWriter.checkpoint", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.print_or_buffer", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogWriter.checkpoint", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.print_or_buffer", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogWriter.checkpoint", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.print_or_buffer", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogWriter.checkpoint", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.print_or_buffer", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogWriter.checkpoint", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.save_model"], ["def", "train", "(", "args", ")", ":", "\n", "# track memory", "\n", "#process = psutil.Process(os.getpid())", "\n", "#print(f'memory starts at : {process.memory_info().rss/1000000:.3f} MB')", "\n", "\t", "\"\"\"\n\ttrain model with chosen method\n\t\"\"\"", "\n", "manager", "=", "Manager", "(", "args", "=", "args", ")", "\n", "print", "(", "'prepare model and training method'", ")", "\n", "manager", ".", "prepare_training", "(", ")", "\n", "#print(f'memory afterwards : {process.memory_info().rss/1000000:.3f} MB')", "\n", "print", "(", "'load train and dev data'", ")", "\n", "manager", ".", "load_data", "(", "[", "'train'", ",", "'dev'", "]", ")", "\n", "#print(f'memory afterwards : {process.memory_info().rss/1000000:.3f} MB')", "\n", "print", "(", "'process data (into tensors) '", ")", "\n", "manager", ".", "process_data", "(", ")", "\n", "#print(f'memory afterwards : {process.memory_info().rss/1000000:.3f} MB')", "\n", "\n", "print", "(", "'start training ...'", ")", "\n", "\n", "best_obj", "=", "-", "1e6", "\n", "best_epoch", "=", "-", "1", "\n", "best_batch", "=", "-", "1", "\n", "\n", "report_gap", "=", "args", "[", "'TrackPeriod'", "]", "//", "args", "[", "'SizeBatchUpdate'", "]", "\n", "report_gap", "=", "1", "if", "report_gap", "==", "0", "else", "report_gap", "\n", "\n", "train_times", "=", "list", "(", ")", "\n", "dev_times", "=", "list", "(", ")", "\n", "inten_nums", "=", "list", "(", ")", "\n", "\n", "num_reports", "=", "0", "\n", "max_epochs", "=", "args", "[", "'MaxEpoch'", "]", "\n", "train_batch_num", "=", "manager", ".", "get_batchupdate_num", "(", "'train'", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "max_epochs", ")", ":", "\n", "\n", "\t\t", "for", "i_batch", "in", "range", "(", "train_batch_num", ")", ":", "\n", "# i_batch for updating params", "\n", "\n", "\t\t\t", "iteration", "=", "epoch", "*", "train_batch_num", "+", "i_batch", "\n", "\n", "\"\"\"\n\t\t\tTrain and optimize\n\t\t\t\"\"\"", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "obj", ",", "num", ",", "inten_num", "=", "manager", ".", "train_batch", "(", "i_batch", ")", "\n", "toc", "=", "time", ".", "time", "(", ")", "\n", "train_times", ".", "append", "(", "toc", "-", "tic", ")", "\n", "inten_nums", ".", "append", "(", "inten_num", ")", "\n", "\n", "#message = f\"iteration {iteration} loglik (per token) is {(obj/num):.4f}\"", "\n", "#manager.checkpoint(message) # too many checkpoint messages", "\n", "#message = f\"training on {i_batch}-th batch of {epoch}-th epoch\"", "\n", "#print(message)", "\n", "#print(f'memory afterwards : {process.memory_info().rss/1000000:.3f} MB')", "\n", "\"\"\"\n\t\t\tEval on dev data\n\t\t\t\"\"\"", "\n", "if", "iteration", "%", "report_gap", "==", "report_gap", "-", "1", ":", "\n", "\t\t\t\t", "\"\"\"\n\t\t\t\told way : (iteration // report_gap > num_reports)\n\t\t\t\tthis can be buggy \n\t\t\t\te.g., if batch_size = 1 and track_period = 1\n\t\t\t\tthen report_gap = 1 and we should eval after every batch\n\t\t\t\thowever, at beginning, iter = 0 and num_reports = 0\n\t\t\t\tthen iter // report_gap = 0 not > 0 = num_reports\n\t\t\t\tso it doesn't eval after the first batch!!!\n\t\t\t\tnew way is exact and doesn't have this issue\n\t\t\t\te.g., when iter = 0 and report_gap = 1\n\t\t\t\titer % report_gap = 0 == 0 = report_gap - 1\n\t\t\t\t\"\"\"", "\n", "print", "(", "f\"validating after {i_batch}-th update batch of {epoch}-th epoch\"", ")", "\n", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "obj", ",", "num", "=", "manager", ".", "eval_mle_epoch", "(", "'dev'", ")", "\n", "avg_obj", "=", "obj", "/", "num", "\n", "toc", "=", "time", ".", "time", "(", ")", "\n", "dev_times", ".", "append", "(", "toc", "-", "tic", ")", "\n", "#print(f\"after validating one epoch\")", "\n", "#print(f'memory afterwards : {process.memory_info().rss/1000000:.3f} MB')", "\n", "\n", "message", "=", "f\"eval: {iteration} iteration, {i_batch}-th batch of {epoch}-th epoch, loglik (per token) is {avg_obj:.4f}\"", "\n", "manager", ".", "print_or_buffer", "(", "message", ")", "\n", "manager", ".", "checkpoint", "(", "message", ")", "\n", "\"\"\"\n\t\t\t\ttrack total time for training on {report_gap} batches\n\t\t\t\t\"\"\"", "\n", "total_train_time", "=", "sum", "(", "train_times", "[", "-", "report_gap", ":", "]", ")", "\n", "message", "=", "f'{total_train_time:.4f} seconds for training since last validation'", "\n", "manager", ".", "print_or_buffer", "(", "message", ")", "\n", "manager", ".", "checkpoint", "(", "message", ")", "\n", "# for train time", "\n", "total_inten_num", "=", "sum", "(", "inten_nums", "[", "-", "report_gap", ":", "]", ")", "\n", "message", "=", "f'# of intensities computed = {total_inten_num:.0f} since last validation'", "\n", "manager", ".", "print_or_buffer", "(", "message", ")", "\n", "manager", ".", "checkpoint", "(", "message", ")", "\n", "# for # of intensities computed", "\n", "message", "=", "f'{dev_times[-1]:.4f} seconds for eval'", "# useful to track :-) ", "\n", "manager", ".", "print_or_buffer", "(", "message", ")", "\n", "manager", ".", "checkpoint", "(", "message", ")", "\n", "# for dev time", "\n", "if", "avg_obj", ">", "best_obj", ":", "\n", "\t\t\t\t\t", "best_obj", "=", "avg_obj", "\n", "updated", "=", "True", "\n", "best_batch", "=", "i_batch", "\n", "best_epoch", "=", "epoch", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "updated", "=", "False", "\n", "", "message", "=", "f\"Current best loglik is {best_obj:.4f} (updated at {best_batch}-th batch of {best_epoch}-th epoch)\"", "\n", "if", "updated", ":", "\n", "\t\t\t\t\t", "message", "+=", "\", best updated at this iteration\"", "\n", "manager", ".", "save_model", "(", ")", "\n", "#print(message)", "\n", "", "manager", ".", "print_or_buffer", "(", "message", ")", "\n", "manager", ".", "checkpoint", "(", "message", ")", "\n", "num_reports", "+=", "1", "\n", "\n", "", "", "", "message", "=", "f'training finished'", "\n", "# important indicator for if training finished", "\n", "# on a server like MARCC, ", "\n", "# sometimes training terminated but not finished", "\n", "manager", ".", "print_or_buffer", "(", "message", ")", "\n", "manager", ".", "checkpoint", "(", "message", ")", "\n", "manager", ".", "flush_buffer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.train.get_args": [[140, 250], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "vars"], "function", ["None"], ["", "def", "get_args", "(", ")", ":", "\n", "\t", "\"\"\"\n\tRetrieves arguments from command line\n\t\"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Training model ...'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-ds'", ",", "'--Dataset'", ",", "required", "=", "True", ",", "type", "=", "str", ",", "\n", "help", "=", "'e.g. smallnhp'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-md'", ",", "'--Model'", ",", "default", "=", "'gnhp'", ",", "type", "=", "str", ",", "\n", "choices", "=", "[", "'gnhp'", ",", "'gpp'", ",", "'ghp'", "]", ",", "\n", "help", "=", "'model to train : gnhp (default) or gpp or ghp?'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-c'", ",", "'--Config'", ",", "required", "=", "True", ",", "type", "=", "str", ",", "\n", "help", "=", "'name of config file used by model, e.g., onetoone'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-d'", ",", "'--DimLSTM'", ",", "default", "=", "8", ",", "type", "=", "int", ",", "\n", "help", "=", "'dimension of LSTM'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-sbc'", ",", "'--SizeBatchCompute'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'size of mini-batch (# seqs) to compute loss'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-sbu'", ",", "'--SizeBatchUpdate'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'size of mini-batch (# seqs) to update params---ideal : N x sbc'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-tp'", ",", "'--TrackPeriod'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "'# of sequences for each checkpoint'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-tr'", ",", "'--TrainRatio'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "'ratio of training data to use for this run'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-dr'", ",", "'--DevRatio'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "'ratio of dev data to use for this run'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-me'", ",", "'--MaxEpoch'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "'max # of epochs of training'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-tm'", ",", "'--TrainMethod'", ",", "required", "=", "True", ",", "type", "=", "str", ",", "\n", "choices", "=", "[", "\n", "'mle'", ",", "# MLE method", "\n", "'lse'", ",", "# least-square estimation", "\n", "'nce_frac'", ",", "'nce_async'", ",", "#'nce_sync', # ranking-based NCE", "\n", "'nce_binary'", "# classification-based NCE", "\n", "]", ",", "\n", "help", "=", "'training method : mle or nce? for nce, frac or async method? (frac and async are in paper)'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-mc'", ",", "'--MCSample'", ",", "default", "=", "1", ",", "type", "=", "float", ",", "\n", "help", "=", "'# of Monte-Carlo samples per actual event in MLE'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-nf'", ",", "'--NoiseFolder'", ",", "type", "=", "str", ",", "\n", "help", "=", "'folder name of saved noise model and log containing useful info like config file name'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-rdp'", ",", "'--ReDrawProb'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "\n", "help", "=", "'default 0.0 : probability to redraw noise samples for each real sequence'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-np'", ",", "'--NoiseProcess'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'# of noise processes in parallel to sample noise times'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-nt'", ",", "'--NoiseType'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'# of noise event types for each noise process'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-nm'", ",", "'--NoiseMode'", ",", "type", "=", "str", ",", "\n", "default", "=", "'multinomial'", ",", "choices", "=", "[", "'multinomial'", ",", "'uniform'", "]", ",", "\n", "help", "=", "'way to sample noise event types (from q) : '", "+", "'multinomial--use computed intensities; uniform--uniformly (for speed-up)'", "\n", "# why not use action='store_true'? current way makes MARCC script simple", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-or'", ",", "'--OverRate'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "'over sampling rate in thinning algorithm (currently dummy)'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-lr'", ",", "'--LearnRate'", ",", "default", "=", "1e-3", ",", "type", "=", "float", ",", "\n", "help", "=", "'(starting) learning rate of the training algorithm'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-sd'", ",", "'--Seed'", ",", "default", "=", "12345", ",", "type", "=", "int", ",", "\n", "help", "=", "'random seed. e.g. 12345'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-gpu'", ",", "'--UseGPU'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "choices", "=", "[", "0", ",", "1", "]", ",", "\n", "help", "=", "'use GPU or not : 0--not, 1--use'", "\n", "# why not use action='store_true'? current way makes MARCC script simple", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-rp'", ",", "'--RootPath'", ",", "type", "=", "str", ",", "default", "=", "'../../'", ",", "\n", "help", "=", "'root path of project'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-wb'", ",", "'--WriteBuffer'", ",", "type", "=", "str", ",", "default", "=", "'print'", ",", "choices", "=", "[", "'buffer'", ",", "'print'", "]", ",", "\n", "help", "=", "'print method: buffer or print?'", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "vars", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.train.aug_args_with_log": [[251, 279], ["os.getpid", "datetime.datetime.now().isoformat", "os.path.abspath", "os.path.join", "train.get_foldername", "os.path.join", "os.path.join", "os.makedirs", "os.path.join", "os.path.join", "datetime.datetime.now"], "function", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.gen_seq.get_foldername"], ["", "def", "aug_args_with_log", "(", "dict_args", ")", ":", "\n", "\t", "\"\"\"\n\tcreate the path to folder for saving logs, models, and plots\n\t\"\"\"", "\n", "id_process", "=", "os", ".", "getpid", "(", ")", "\n", "time_current", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "isoformat", "(", ")", "\n", "\n", "root_path", "=", "os", ".", "path", ".", "abspath", "(", "dict_args", "[", "'RootPath'", "]", ")", "\n", "dict_args", "[", "'PathData'", "]", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "f\"data/{dict_args['Dataset']}\"", ")", "\n", "dict_args", "[", "'Version'", "]", "=", "torch", ".", "__version__", "\n", "dict_args", "[", "'ID'", "]", "=", "id_process", "\n", "dict_args", "[", "'TIME'", "]", "=", "time_current", "\n", "\n", "folder_name", "=", "get_foldername", "(", "dict_args", ",", "id_process", ")", "\n", "#print(folder_name)", "\n", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "'logs'", ",", "dict_args", "[", "'Dataset'", "]", ")", "\n", "path_log", "=", "os", ".", "path", ".", "join", "(", "path", ",", "folder_name", ")", "\n", "os", ".", "makedirs", "(", "path_log", ")", "\n", "\n", "file_log", "=", "os", ".", "path", ".", "join", "(", "path_log", ",", "'log.txt'", ")", "\n", "file_model", "=", "os", ".", "path", ".", "join", "(", "path_log", ",", "'saved_model.pkl'", ")", "\n", "# some sys may think a file with no extension is an executable : bad", "\n", "\n", "dict_args", "[", "'PathLog'", "]", "=", "file_log", "\n", "dict_args", "[", "'PathModel'", "]", "=", "file_model", "\n", "dict_args", "[", "'PathSave'", "]", "=", "path", "\n", "dict_args", "[", "'PathRun'", "]", "=", "path_log", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.train.get_foldername": [[280, 308], ["list", "list.append"], "function", ["None"], ["", "def", "get_foldername", "(", "dict_args", ",", "id_process", ")", ":", "\n", "\t", "\"\"\"\n\tcreate folder name for current run\n\t\"\"\"", "\n", "# format: [arg name, name used in path]", "\n", "args_used_in_name", "=", "[", "\n", "[", "'TrainMethod'", ",", "'meth'", "]", ",", "\n", "[", "'Model'", ",", "'md'", "]", ",", "\n", "[", "'Config'", ",", "'conf'", "]", ",", "\n", "[", "'MCSample'", ",", "'mc'", "]", ",", "\n", "[", "'ReDrawProb'", ",", "'rdp'", "]", ",", "\n", "[", "'NoiseProcess'", ",", "'np'", "]", ",", "\n", "[", "'NoiseType'", ",", "'nt'", "]", ",", "\n", "[", "'DimLSTM'", ",", "'dim'", "]", ",", "\n", "[", "'UseGPU'", ",", "'gpu'", "]", ",", "\n", "[", "'SizeBatchCompute'", ",", "'batchcomp'", "]", ",", "\n", "[", "'SizeBatchUpdate'", ",", "'batchupd'", "]", ",", "\n", "[", "'TrainRatio'", ",", "'tr'", "]", ",", "\n", "[", "'NoiseMode'", ",", "'nm'", "]", ",", "\n", "[", "'Seed'", ",", "'seed'", "]", ",", "\n", "#['LearnRate', 'lr'],", "\n", "]", "\n", "folder_name", "=", "list", "(", ")", "\n", "for", "arg_name", ",", "rename", "in", "args_used_in_name", ":", "\n", "\t\t", "folder_name", ".", "append", "(", "'{}-{}'", ".", "format", "(", "rename", ",", "dict_args", "[", "arg_name", "]", ")", ")", "\n", "", "folder_name", "=", "'_'", ".", "join", "(", "folder_name", ")", "\n", "folder_name", "=", "f'{folder_name}_{id_process}'", "\n", "return", "folder_name", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.train.main": [[309, 316], ["train.get_args", "train.aug_args_with_log", "train.train"], "function", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.get_args", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.gen_seq.aug_args_with_log", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.train.train"], ["", "def", "main", "(", ")", ":", "\n", "\n", "\t", "dict_args", "=", "get_args", "(", ")", "\n", "aug_args_with_log", "(", "dict_args", ")", "\n", "if", "''", "in", "dict_args", ":", "\n", "\t\t", "del", "dict_args", "[", "''", "]", "\n", "", "train", "(", "dict_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.test.test": [[13, 73], ["ncempp.run.tester.Tester", "print", "ncempp.run.tester.Tester.load_data", "print", "ncempp.run.tester.Tester.process_data", "print", "list", "print", "time.time", "ncempp.run.tester.Tester.eval_mle_epoch", "time.time", "list.append", "ncempp.run.tester.Tester.print_or_buffer", "ncempp.run.tester.Tester.print_or_buffer", "print", "time.time", "ncempp.run.tester.Tester.eval_predict_epoch", "time.time", "list.append", "ncempp.run.tester.Tester.print_or_buffer", "ncempp.run.tester.Tester.print_or_buffer", "ncempp.run.tester.Tester.print_or_buffer", "ncempp.run.tester.Tester.flush_buffer", "numpy.sqrt"], "function", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.load_data", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.process_data", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.eval_mle_epoch", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.print_or_buffer", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.print_or_buffer", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.tester.Tester.eval_predict_epoch", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.print_or_buffer", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.print_or_buffer", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.print_or_buffer", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.flush_buffer"], ["def", "test", "(", "args", ")", ":", "\n", "# track memory", "\n", "#process = psutil.Process(os.getpid())", "\n", "#print(f'memory starts at : {process.memory_info().rss/1000000:.3f} MB')", "\n", "\t", "\"\"\"\n\ttrain model with chosen method\n\t\"\"\"", "\n", "manager", "=", "Tester", "(", "args", "=", "args", ")", "\n", "#print('prepare model and testing method')", "\n", "#manager.prepare_testing()", "\n", "#print(f'memory afterwards : {process.memory_info().rss/1000000:.3f} MB')", "\n", "print", "(", "f\"load {args['Split']} data\"", ")", "\n", "manager", ".", "load_data", "(", "[", "args", "[", "'Split'", "]", "]", ")", "\n", "#print(f'memory afterwards : {process.memory_info().rss/1000000:.3f} MB')", "\n", "print", "(", "'process data (into tensors) '", ")", "\n", "manager", ".", "process_data", "(", ")", "\n", "#print(f'memory afterwards : {process.memory_info().rss/1000000:.3f} MB')", "\n", "\n", "print", "(", "'start testing ...'", ")", "\n", "\n", "dev_times", "=", "list", "(", ")", "\n", "\n", "print", "(", "f\"\\ntesting on log-likelihood\"", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "obj", ",", "num", "=", "manager", ".", "eval_mle_epoch", "(", "args", "[", "'Split'", "]", ")", "\n", "avg_obj", "=", "obj", "/", "num", "\n", "toc", "=", "time", ".", "time", "(", ")", "\n", "dev_times", ".", "append", "(", "toc", "-", "tic", ")", "\n", "#print(f\"after validating one epoch\")", "\n", "#print(f'memory afterwards : {process.memory_info().rss/1000000:.3f} MB')", "\n", "\n", "message", "=", "f\"eval: loglik (per token) is {avg_obj:.4f}\"", "\n", "manager", ".", "print_or_buffer", "(", "message", ")", "\n", "message", "=", "f'{dev_times[-1]:.4f} seconds for eval'", "# useful to track :-) ", "\n", "manager", ".", "print_or_buffer", "(", "message", ")", "\n", "# for dev time", "\n", "\n", "print", "(", "f\"\\ntesting on prediction accuracy\"", ")", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "se", ",", "en", ",", "num", "=", "manager", ".", "eval_predict_epoch", "(", "args", "[", "'Split'", "]", ")", "\n", "mse", "=", "se", "/", "num", "\n", "er", "=", "en", "/", "num", "\n", "toc", "=", "time", ".", "time", "(", ")", "\n", "dev_times", ".", "append", "(", "toc", "-", "tic", ")", "\n", "#print(f\"after validating one epoch\")", "\n", "#print(f'memory afterwards : {process.memory_info().rss/1000000:.3f} MB')", "\n", "\n", "message", "=", "f\"eval: mse (per token) is {mse:.4f}\"", "\n", "message", "+=", "f\"\\neval: rmse (per token) is {numpy.sqrt(mse):.4f}\"", "\n", "message", "+=", "f\"\\neval: error rate (per token) is {100*er:.2f} %\"", "\n", "manager", ".", "print_or_buffer", "(", "message", ")", "\n", "message", "=", "f'{dev_times[-1]:.4f} seconds for eval'", "# useful to track :-) ", "\n", "manager", ".", "print_or_buffer", "(", "message", ")", "\n", "\n", "message", "=", "f'\\ntesting finished'", "\n", "# important indicator for if training finished", "\n", "# on a server like MARCC, ", "\n", "# sometimes training terminated but not finished", "\n", "manager", ".", "print_or_buffer", "(", "message", ")", "\n", "manager", ".", "flush_buffer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.test.get_args": [[75, 131], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "vars"], "function", ["None"], ["", "def", "get_args", "(", ")", ":", "\n", "\t", "\"\"\"\n\tRetrieves arguments from command line\n\t\"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Training model ...'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-ds'", ",", "'--Dataset'", ",", "required", "=", "True", ",", "type", "=", "str", ",", "\n", "help", "=", "'e.g. smallnhp'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-mf'", ",", "'--ModelFolder'", ",", "type", "=", "str", ",", "\n", "help", "=", "'folder name of saved model and log containing useful info like config file name'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-sp'", ",", "'--Split'", ",", "type", "=", "str", ",", "\n", "help", "=", "'data split used to eval'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-sbc'", ",", "'--SizeBatchCompute'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'size of mini-batch (# seqs) to compute loss'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-sbu'", ",", "'--SizeBatchUpdate'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "'size of mini-batch (# seqs) to update params---ideal : N x sbc'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-r'", ",", "'--Ratio'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "'ratio of dev/test data to use for this run'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-mc'", ",", "'--MCSample'", ",", "default", "=", "1", ",", "type", "=", "float", ",", "\n", "help", "=", "'# of Monte-Carlo samples per actual event in MLE'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-or'", ",", "'--OverRate'", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "'over sampling rate in thinning algorithm (currently dummy)'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-sd'", ",", "'--Seed'", ",", "default", "=", "12345", ",", "type", "=", "int", ",", "\n", "help", "=", "'random seed. e.g. 12345'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-gpu'", ",", "'--UseGPU'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "choices", "=", "[", "0", ",", "1", "]", ",", "\n", "help", "=", "'use GPU or not : 0--not, 1--use'", "\n", "# why not use action='store_true'? current way makes MARCC script simple", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-rp'", ",", "'--RootPath'", ",", "type", "=", "str", ",", "default", "=", "'../../'", ",", "\n", "help", "=", "'root path of project'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-wb'", ",", "'--WriteBuffer'", ",", "type", "=", "str", ",", "default", "=", "'print'", ",", "choices", "=", "[", "'buffer'", ",", "'print'", "]", ",", "\n", "help", "=", "'print method: buffer or print?'", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "vars", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.test.aug_args_with_log": [[132, 151], ["os.getpid", "datetime.datetime.now().isoformat", "os.path.abspath", "os.path.join", "os.path.join", "[].upper", "datetime.datetime.now"], "function", ["None"], ["", "def", "aug_args_with_log", "(", "dict_args", ")", ":", "\n", "\t", "\"\"\"\n\tcreate the path to folder for saving logs, models, and plots\n\t\"\"\"", "\n", "id_process", "=", "os", ".", "getpid", "(", ")", "\n", "time_current", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "isoformat", "(", ")", "\n", "\n", "root_path", "=", "os", ".", "path", ".", "abspath", "(", "dict_args", "[", "'RootPath'", "]", ")", "\n", "dict_args", "[", "'PathData'", "]", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "f\"data/{dict_args['Dataset']}\"", ")", "\n", "dict_args", "[", "'Version'", "]", "=", "torch", ".", "__version__", "\n", "dict_args", "[", "'ID'", "]", "=", "id_process", "\n", "dict_args", "[", "'TIME'", "]", "=", "time_current", "\n", "\n", "capsplit", "=", "dict_args", "[", "'Split'", "]", "[", "0", "]", ".", "upper", "(", ")", "+", "dict_args", "[", "'Split'", "]", "[", "1", ":", "]", "\n", "dict_args", "[", "f\"{capsplit}Ratio\"", "]", "=", "dict_args", "[", "'Ratio'", "]", "\n", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "'logs'", ",", "dict_args", "[", "'Dataset'", "]", ")", "\n", "\n", "dict_args", "[", "'PathSave'", "]", "=", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.test.main": [[152, 159], ["test.get_args", "test.aug_args_with_log", "test.test"], "function", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.get_args", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.gen_seq.aug_args_with_log", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.test.test"], ["", "def", "main", "(", ")", ":", "\n", "\n", "\t", "dict_args", "=", "get_args", "(", ")", "\n", "aug_args_with_log", "(", "dict_args", ")", "\n", "if", "''", "in", "dict_args", ":", "\n", "\t\t", "del", "dict_args", "[", "''", "]", "\n", "", "test", "(", "dict_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.draw_lc.draw_lc": [[13, 19], ["ncempp.eval.draw.Drawer", "ncempp.eval.draw.Drawer.draw_lc"], "function", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.draw_lc"], ["def", "draw_lc", "(", "args", ")", ":", "\n", "\t", "\"\"\"\n\tdraw learning curves given restored results \n\t\"\"\"", "\n", "drawer", "=", "Drawer", "(", "args", "=", "args", ")", "\n", "drawer", ".", "draw_lc", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.draw_lc.get_args": [[20, 98], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "vars"], "function", ["None"], ["", "def", "get_args", "(", ")", ":", "\n", "\t", "\"\"\"\n\tRetrieves arguments from command line\n\t\"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'draw figures ...'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-ds'", ",", "'--Dataset'", ",", "required", "=", "True", ",", "type", "=", "str", ",", "help", "=", "'e.g. smallnhp'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-cn'", ",", "'--CSVName'", ",", "required", "=", "True", ",", "type", "=", "str", ",", "\n", "help", "=", "'prefix name of meta and log csv'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-yl'", ",", "'--YLow'", ",", "type", "=", "float", ",", "default", "=", "-", "numpy", ".", "inf", ",", "\n", "help", "=", "'y value on graph can not be lowr than this given value'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-ih'", ",", "'--IntenHigh'", ",", "type", "=", "float", ",", "default", "=", "numpy", ".", "inf", ",", "\n", "help", "=", "'# inten on graph can not be higher than this given value'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-th'", ",", "'--TimeHigh'", ",", "type", "=", "float", ",", "default", "=", "numpy", ".", "inf", ",", "\n", "help", "=", "'wall-clock time on graph can not be higher than this given value'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-ct'", ",", "'--ContinualTrain'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "choices", "=", "[", "0", ",", "1", "]", ",", "\n", "help", "=", "'0==False(default);1==True : draw continual training strategy?'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-hm'", ",", "'--HybridMultiplier'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "'M of the MLE run that we want to use for continual hybrid training'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-wp'", ",", "'--WaitPeriod'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "'# of tracked validations before we see it as converged'", "\n", ")", "\n", "#parser.add_argument(", "\n", "#\t'-ann', '--Annotate', type=str, default='2', ", "\n", "#\thelp=\"where to annotate? 1/ann of the curve..., can be 3,2,3,...\"", "\n", "#)", "\n", "parser", ".", "add_argument", "(", "\n", "'-ub'", ",", "'--UseBatch'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "choices", "=", "[", "0", ",", "1", "]", ",", "\n", "help", "=", "\"1==True(default);0==False : show batchsize in curve annotation?\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-prefix'", ",", "'--Prefix'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "\n", "help", "=", "'prefix of the figure pdf name'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-inter'", ",", "'--Inter'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "\"# of points to interpolate for smoothing\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-loc'", ",", "'--Location'", ",", "type", "=", "int", ",", "default", "=", "3", ",", "\n", "help", "=", "\"loc of legends\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-tes'", ",", "'--TextSize'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "\"font size of text\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-tis'", ",", "'--TickSize'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "\"font size of tick\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-les'", ",", "'--LegendSize'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "\"font size of legend\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-las'", ",", "'--LabelSize'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "\n", "help", "=", "\"font size of label\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-rp'", ",", "'--RootPath'", ",", "type", "=", "str", ",", "default", "=", "'../../'", ",", "\n", "help", "=", "'root path of project'", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "vars", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.draw_lc.aug_args_with_log": [[99, 108], ["os.path.abspath", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "aug_args_with_log", "(", "dict_args", ")", ":", "\n", "\t", "\"\"\"\n\tcompose path to folder of logs\n\t\"\"\"", "\n", "root_path", "=", "os", ".", "path", ".", "abspath", "(", "dict_args", "[", "'RootPath'", "]", ")", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "'logs'", ",", "dict_args", "[", "'Dataset'", "]", ")", "\n", "dict_args", "[", "'PathSave'", "]", "=", "path", "\n", "dict_args", "[", "'PathMetaCSV'", "]", "=", "os", ".", "path", ".", "join", "(", "path", ",", "f\"{dict_args['CSVName']}_meta.csv\"", ")", "\n", "dict_args", "[", "'PathLogCSV'", "]", "=", "os", ".", "path", ".", "join", "(", "path", ",", "f\"{dict_args['CSVName']}_log.csv\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.draw_lc.main": [[109, 116], ["draw_lc.get_args", "draw_lc.aug_args_with_log", "draw_lc.draw_lc"], "function", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.get_args", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.gen_seq.aug_args_with_log", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.draw_lc"], ["", "def", "main", "(", ")", ":", "\n", "\n", "\t", "dict_args", "=", "get_args", "(", ")", "\n", "aug_args_with_log", "(", "dict_args", ")", "\n", "if", "''", "in", "dict_args", ":", "\n", "\t\t", "del", "dict_args", "[", "''", "]", "\n", "", "draw_lc", "(", "dict_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.gen_seq.gen": [[13, 69], ["ncempp.run.manager.Manager", "print", "ncempp.run.manager.Manager.prepare_gen", "print", "ncempp.run.manager.Manager.save_model", "ncempp.run.manager.Manager.print_or_buffer", "ncempp.run.manager.Manager.checkpoint", "ncempp.run.manager.Manager.flush_buffer", "ncempp.run.manager.Manager.print_or_buffer", "ncempp.run.manager.Manager.checkpoint", "range", "ncempp.run.manager.Manager.print_or_buffer", "ncempp.run.manager.Manager.checkpoint", "ncempp.run.manager.Manager.print_or_buffer", "ncempp.run.manager.Manager.checkpoint", "os.path.join", "ncempp.run.manager.Manager.gen_seq", "seqs.append", "open", "pickle.dump", "ncempp.run.manager.Manager.print_or_buffer", "ncempp.run.manager.Manager.checkpoint", "s.lower"], "function", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.prepare_gen", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.save_model", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.print_or_buffer", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogWriter.checkpoint", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.flush_buffer", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.print_or_buffer", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogWriter.checkpoint", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.print_or_buffer", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogWriter.checkpoint", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.print_or_buffer", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogWriter.checkpoint", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.gen_seq", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.print_or_buffer", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogWriter.checkpoint"], ["def", "gen", "(", "args", ")", ":", "\n", "\t", "\"\"\"\n\tgen data from randomly init model\n\t\"\"\"", "\n", "manager", "=", "Manager", "(", "args", "=", "args", ")", "\n", "print", "(", "'prepare model and training method'", ")", "\n", "manager", ".", "prepare_gen", "(", ")", "\n", "\n", "print", "(", "'start generating ...'", ")", "\n", "\n", "report_gap", "=", "args", "[", "'TrackPeriod'", "]", "\n", "report_gap", "=", "1", "if", "report_gap", "==", "0", "else", "report_gap", "\n", "\n", "for", "s", "in", "[", "'Train'", ",", "'Dev'", ",", "'Test'", ",", "'Future'", "]", ":", "\n", "\n", "\t\t", "arg_name", "=", "f'Num{s}'", "\n", "num_seqs", "=", "args", "[", "arg_name", "]", "\n", "\n", "message", "=", "f\"generating {num_seqs} seqs for {s}\"", "\n", "manager", ".", "print_or_buffer", "(", "message", ")", "\n", "manager", ".", "checkpoint", "(", "message", ")", "\n", "\n", "seqs", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "num_seqs", ")", ":", "\n", "\n", "\t\t\t", "\"\"\"\n\t\t\tgenerating seqs\n\t\t\t\"\"\"", "\n", "seq", "=", "manager", ".", "gen_seq", "(", ")", "\n", "seqs", ".", "append", "(", "seq", ")", "\n", "\n", "if", "i", "%", "report_gap", "==", "report_gap", "-", "1", ":", "\n", "\n", "\t\t\t\t", "message", "=", "f'finish {i+1} sequences'", "\n", "manager", ".", "print_or_buffer", "(", "message", ")", "\n", "manager", ".", "checkpoint", "(", "message", ")", "\n", "\n", "", "", "message", "=", "f\"finish generating for {s}\"", "\n", "manager", ".", "print_or_buffer", "(", "message", ")", "\n", "manager", ".", "checkpoint", "(", "message", ")", "\n", "\n", "message", "=", "f\"one sample sequence is {seqs[0]}\"", "\n", "manager", ".", "print_or_buffer", "(", "message", ")", "\n", "manager", ".", "checkpoint", "(", "message", ")", "\n", "\n", "path_data", "=", "os", ".", "path", ".", "join", "(", "args", "[", "'PathData'", "]", ",", "f'{s.lower()}.pkl'", ")", "\n", "with", "open", "(", "path_data", ",", "'wb'", ")", "as", "f", ":", "\n", "\t\t\t", "pickle", ".", "dump", "(", "seqs", ",", "f", ")", "\n", "\n", "", "", "manager", ".", "save_model", "(", ")", "\n", "\n", "message", "=", "f\"generating finished\"", "\n", "manager", ".", "print_or_buffer", "(", "message", ")", "\n", "manager", ".", "checkpoint", "(", "message", ")", "\n", "manager", ".", "flush_buffer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.gen_seq.get_args": [[71, 140], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "vars"], "function", ["None"], ["", "def", "get_args", "(", ")", ":", "\n", "\t", "\"\"\"\n\tRetrieves arguments from command line\n\t\"\"\"", "\n", "\"\"\"\n\tNOTE : some args will be saved in log file \n\tso that the data-generating model can be read and used as noise model\n\t\"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'generating data ...'", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-ds'", ",", "'--Dataset'", ",", "required", "=", "True", ",", "type", "=", "str", ",", "\n", "help", "=", "'e.g. gnhp10k (10k means 10,000), name of the dataset we generate'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-d'", ",", "'--DimLSTM'", ",", "default", "=", "8", ",", "type", "=", "int", ",", "\n", "help", "=", "'dimension of LSTM of the data-generating model'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-c'", ",", "'--Config'", ",", "required", "=", "True", ",", "type", "=", "str", ",", "\n", "help", "=", "'name of config file used by model, e.g., onetoone'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-ntoken'", ",", "'--NumToken'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "\"# of tokens in each sequence\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-ntrain'", ",", "'--NumTrain'", ",", "default", "=", "10000", ",", "type", "=", "int", ",", "\n", "help", "=", "\"# of training seqs\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-ndev'", ",", "'--NumDev'", ",", "default", "=", "1000", ",", "type", "=", "int", ",", "\n", "help", "=", "\"# of dev seqs\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-ntest'", ",", "'--NumTest'", ",", "default", "=", "1000", ",", "type", "=", "int", ",", "\n", "help", "=", "\"# of test seqs\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-nfuture'", ",", "'--NumFuture'", ",", "default", "=", "1000", ",", "type", "=", "int", ",", "\n", "help", "=", "\"# of seqs for future use\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-tp'", ",", "'--TrackPeriod'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "\n", "help", "=", "'# of sequences for each checkpoint'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-nm'", ",", "'--NoiseMode'", ",", "type", "=", "str", ",", "\n", "default", "=", "'multinomial'", ",", "choices", "=", "[", "'multinomial'", "]", ",", "\n", "help", "=", "'way to sample event types, must be multinomial for exact sampling '", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-sd'", ",", "'--Seed'", ",", "default", "=", "12345", ",", "type", "=", "int", ",", "\n", "help", "=", "'random seed. e.g. 12345'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-gpu'", ",", "'--UseGPU'", ",", "default", "=", "0", ",", "type", "=", "int", ",", "choices", "=", "[", "0", ",", "1", "]", ",", "\n", "help", "=", "'use GPU or not : 0--not, 1--use'", "\n", "# why not use action='store_true'? current way makes MARCC script simple", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-rp'", ",", "'--RootPath'", ",", "type", "=", "str", ",", "default", "=", "'../../'", ",", "\n", "help", "=", "'root path of project'", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "'-wb'", ",", "'--WriteBuffer'", ",", "type", "=", "str", ",", "default", "=", "'print'", ",", "choices", "=", "[", "'buffer'", ",", "'print'", "]", ",", "\n", "help", "=", "'print method: buffer or print?'", "\n", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "vars", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.gen_seq.aug_args_with_log": [[141, 169], ["os.getpid", "datetime.datetime.now().isoformat", "os.path.abspath", "os.path.join", "gen_seq.get_foldername", "os.path.join", "os.path.join", "os.makedirs", "os.path.join", "os.path.join", "datetime.datetime.now"], "function", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.gen_seq.get_foldername"], ["", "def", "aug_args_with_log", "(", "dict_args", ")", ":", "\n", "\t", "\"\"\"\n\tcreate the path to folder for saving logs, models, and plots\n\t\"\"\"", "\n", "id_process", "=", "os", ".", "getpid", "(", ")", "\n", "time_current", "=", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "isoformat", "(", ")", "\n", "\n", "root_path", "=", "os", ".", "path", ".", "abspath", "(", "dict_args", "[", "'RootPath'", "]", ")", "\n", "dict_args", "[", "'PathData'", "]", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "f\"data/{dict_args['Dataset']}\"", ")", "\n", "dict_args", "[", "'Version'", "]", "=", "torch", ".", "__version__", "\n", "dict_args", "[", "'ID'", "]", "=", "id_process", "\n", "dict_args", "[", "'TIME'", "]", "=", "time_current", "\n", "\n", "folder_name", "=", "get_foldername", "(", "dict_args", ",", "id_process", ")", "\n", "#print(folder_name)", "\n", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "'logs'", ",", "dict_args", "[", "'Dataset'", "]", ")", "\n", "path_log", "=", "os", ".", "path", ".", "join", "(", "path", ",", "folder_name", ")", "\n", "os", ".", "makedirs", "(", "path_log", ")", "\n", "\n", "file_log", "=", "os", ".", "path", ".", "join", "(", "path_log", ",", "'log.txt'", ")", "\n", "file_model", "=", "os", ".", "path", ".", "join", "(", "path_log", ",", "'saved_model.pkl'", ")", "\n", "# some sys may think a file with no extension is an executable : bad", "\n", "\n", "dict_args", "[", "'PathLog'", "]", "=", "file_log", "\n", "dict_args", "[", "'PathModel'", "]", "=", "file_model", "\n", "dict_args", "[", "'PathSave'", "]", "=", "path", "\n", "dict_args", "[", "'PathRun'", "]", "=", "path_log", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.gen_seq.get_foldername": [[170, 187], ["list", "list.append"], "function", ["None"], ["", "def", "get_foldername", "(", "dict_args", ",", "id_process", ")", ":", "\n", "\t", "\"\"\"\n\tcreate folder name for current run\n\t\"\"\"", "\n", "# format: [arg name, name used in path]", "\n", "args_used_in_name", "=", "[", "\n", "[", "'Config'", ",", "'conf'", "]", ",", "\n", "[", "'DimLSTM'", ",", "'dim'", "]", ",", "\n", "[", "'UseGPU'", ",", "'gpu'", "]", ",", "\n", "[", "'Seed'", ",", "'seed'", "]", ",", "\n", "]", "\n", "folder_name", "=", "list", "(", ")", "\n", "for", "arg_name", ",", "rename", "in", "args_used_in_name", ":", "\n", "\t\t", "folder_name", ".", "append", "(", "'{}-{}'", ".", "format", "(", "rename", ",", "dict_args", "[", "arg_name", "]", ")", ")", "\n", "", "folder_name", "=", "'_'", ".", "join", "(", "folder_name", ")", "\n", "folder_name", "=", "f'{folder_name}_datagen_{id_process}'", "\n", "return", "folder_name", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.gen_seq.main": [[188, 195], ["gen_seq.get_args", "gen_seq.aug_args_with_log", "gen_seq.gen"], "function", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.get_args", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.gen_seq.aug_args_with_log", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.gen_seq.gen"], ["", "def", "main", "(", ")", ":", "\n", "\n", "\t", "dict_args", "=", "get_args", "(", ")", "\n", "aug_args_with_log", "(", "dict_args", ")", "\n", "if", "''", "in", "dict_args", ":", "\n", "\t\t", "del", "dict_args", "[", "''", "]", "\n", "", "gen", "(", "dict_args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.tester.Tester.__init__": [[24, 98], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "os.path.join", "tester.Tester.load_log", "os.path.join", "tester.Tester.load_config", "os.path.join", "tester.Tester.load_model", "ncempp.io.data.DataProcessor", "ncempp.objectives.mle.MLE", "ncempp.objectives.predict.Predict", "ncempp.models.nhp.GNHP", "tester.Tester.model.cuda", "ncempp.models.pp.GPP", "ncempp.models.hp.GHP", "Exception"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.load_log", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.load_config", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.load_model", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["\t", "def", "__init__", "(", "self", ",", "*", ",", "args", ")", ":", "\n", "\t\t", "self", ".", "args", "=", "args", "\n", "\"\"\"\n\t\tset random numbers \n\t\t\"\"\"", "\n", "random", ".", "seed", "(", "args", "[", "'Seed'", "]", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", "[", "'Seed'", "]", ")", "\n", "torch", ".", "manual_seed", "(", "args", "[", "'Seed'", "]", ")", "\n", "\n", "\"\"\"\n\t\tcreate model p \n\t\t\"\"\"", "\n", "log_path", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "args", "[", "'PathSave'", "]", ",", "f\"{self.args['ModelFolder']}/log.txt\"", ")", "\n", "saved_args", "=", "self", ".", "load_log", "(", "log_path", ")", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "args", "[", "'PathData'", "]", ",", "f\"{saved_args['Config']}.config\"", ")", "\n", "coarse_num", ",", "event_num", ",", "fine_to_coarse", "=", "self", ".", "load_config", "(", "config_path", ")", "\n", "device", "=", "'cuda'", "if", "args", "[", "'UseGPU'", "]", "else", "'cpu'", "\n", "\n", "if", "saved_args", "[", "'Model'", "]", "==", "'gnhp'", ":", "\n", "\t\t\t", "self", ".", "model", "=", "GNHP", "(", "\n", "coarse_num", "=", "coarse_num", ",", "\n", "event_num", "=", "event_num", ",", "\n", "fine_to_coarse", "=", "fine_to_coarse", ",", "\n", "hidden_dim", "=", "saved_args", "[", "'DimLSTM'", "]", ",", "\n", "device", "=", "device", "\n", ")", "\n", "", "elif", "saved_args", "[", "'Model'", "]", "==", "'gpp'", ":", "\n", "\t\t\t", "self", ".", "model", "=", "GPP", "(", "\n", "coarse_num", "=", "coarse_num", ",", "\n", "event_num", "=", "event_num", ",", "\n", "fine_to_coarse", "=", "fine_to_coarse", ",", "\n", "device", "=", "device", "\n", ")", "\n", "", "elif", "saved_args", "[", "'Model'", "]", "==", "'ghp'", ":", "\n", "\t\t\t", "assert", "False", ",", "f\"Hawkes can't be used as testing model yet...\"", "\n", "self", ".", "model", "=", "GHP", "(", "\n", "coarse_num", "=", "coarse_num", ",", "\n", "event_num", "=", "event_num", ",", "\n", "fine_to_coarse", "=", "fine_to_coarse", ",", "\n", "device", "=", "device", "\n", ")", "\n", "", "else", ":", "\n", "\t\t\t", "raise", "Exception", "(", "f\"Unknown model : {args['Model']}\"", ")", "\n", "\n", "", "model_path", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "args", "[", "'PathSave'", "]", ",", "f\"{self.args['ModelFolder']}/saved_model\"", "\n", ")", "\n", "if", "'.pkl'", "in", "saved_args", "[", "'PathModel'", "]", ":", "\n", "\t\t\t", "model_path", "+=", "'.pkl'", "\n", "", "self", ".", "load_model", "(", "self", ".", "model", ",", "model_path", ")", "\n", "if", "args", "[", "'UseGPU'", "]", ":", "\n", "\t\t\t", "self", ".", "model", ".", "cuda", "(", ")", "\n", "\n", "", "self", ".", "proc", "=", "DataProcessor", "(", "\n", "idx_BOS", "=", "self", ".", "model", ".", "idx_BOS", ",", "\n", "idx_EOS", "=", "self", ".", "model", ".", "idx_EOS", ",", "\n", "idx_PAD", "=", "self", ".", "model", ".", "idx_PAD", ",", "\n", "device", "=", "'cuda'", "if", "args", "[", "'UseGPU'", "]", "else", "'cpu'", "\n", ")", "\n", "\n", "self", ".", "mle", "=", "MLE", "(", "\n", "mc_sample_num", "=", "self", ".", "args", "[", "'MCSample'", "]", ",", "\n", "device", "=", "'cuda'", "if", "self", ".", "args", "[", "'UseGPU'", "]", "else", "'cpu'", "\n", ")", "\n", "self", ".", "predict", "=", "Predict", "(", "\n", "over_rate", "=", "self", ".", "args", "[", "'OverRate'", "]", ",", "\n", "device", "=", "'cuda'", "if", "self", ".", "args", "[", "'UseGPU'", "]", "else", "'cpu'", "\n", ")", "\n", "\n", "self", ".", "device", "=", "'cuda'", "if", "args", "[", "'UseGPU'", "]", "else", "'cpu'", "\n", "self", ".", "write_buffer", "=", "[", "]", "\n", "self", ".", "use_buffer", "=", "True", "if", "args", "[", "'WriteBuffer'", "]", "==", "'buffer'", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.tester.Tester.compute_predict_error": [[99, 106], ["tester.Tester.predict", "float", "float", "float", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "compute_predict_error", "(", "self", ",", "split", ",", "i_batch_comp", ")", ":", "\n", "\t\t", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", "=", "self", ".", "data_tensor", "[", "split", "]", "[", "i_batch_comp", "]", "\n", "se", ",", "en", "=", "self", ".", "predict", "(", "\n", "self", ".", "model", ",", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", "\n", ")", "\n", "return", "float", "(", "se", ")", ",", "float", "(", "en", ")", ",", "float", "(", "torch", ".", "sum", "(", "token_num_tensor", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.tester.Tester.eval_predict_batch": [[107, 112], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tester.Tester.compute_predict_error"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.tester.Tester.compute_predict_error"], ["", "def", "eval_predict_batch", "(", "self", ",", "split", ",", "i_batch_comp", ")", ":", "\n", "\t\t", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t", "se", ",", "en", ",", "token_num", "=", "self", ".", "compute_predict_error", "(", "split", ",", "i_batch_comp", ")", "\n", "", "return", "se", ",", "en", ",", "token_num", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.tester.Tester.eval_predict_epoch": [[113, 124], ["range", "len", "tester.Tester.eval_predict_batch", "float", "float", "float"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.tester.Tester.eval_predict_batch"], ["", "def", "eval_predict_epoch", "(", "self", ",", "split", ")", ":", "\n", "\t\t", "total_se", "=", "0.0", "\n", "total_en", "=", "0.0", "\n", "total_num", "=", "0.0", "\n", "for", "i_batch_comp", "in", "range", "(", "len", "(", "self", ".", "data_tensor", "[", "split", "]", ")", ")", ":", "\n", "\t\t\t", "se_batch", ",", "en_batch", ",", "token_num_batch", "=", "self", ".", "eval_predict_batch", "(", "split", ",", "i_batch_comp", ")", "\n", "total_se", "+=", "float", "(", "se_batch", ")", "\n", "total_en", "+=", "float", "(", "en_batch", ")", "\n", "total_num", "+=", "float", "(", "token_num_batch", ")", "\n", "", "return", "total_se", ",", "total_en", ",", "total_num", "", "", "", ""]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.__init__": [[25, 76], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "os.path.join", "manager.Manager.load_config", "ncempp.io.data.DataProcessor", "ncempp.models.nhp.GNHP", "manager.Manager.model.cuda", "ncempp.models.pp.GPP", "ncempp.models.hp.GHP", "Exception"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.load_config", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["\t", "def", "__init__", "(", "self", ",", "*", ",", "args", ")", ":", "\n", "\t\t", "self", ".", "args", "=", "args", "\n", "\"\"\"\n\t\tset random numbers \n\t\t\"\"\"", "\n", "random", ".", "seed", "(", "args", "[", "'Seed'", "]", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", "[", "'Seed'", "]", ")", "\n", "torch", ".", "manual_seed", "(", "args", "[", "'Seed'", "]", ")", "\n", "\"\"\"\n\t\tcreate model p \n\t\t\"\"\"", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "args", "[", "'PathData'", "]", ",", "f\"{args['Config']}.config\"", ")", "\n", "coarse_num", ",", "event_num", ",", "fine_to_coarse", "=", "self", ".", "load_config", "(", "config_path", ")", "\n", "\n", "if", "args", "[", "'Model'", "]", "==", "'gnhp'", ":", "\n", "\t\t\t", "self", ".", "model", "=", "GNHP", "(", "\n", "coarse_num", "=", "coarse_num", ",", "\n", "event_num", "=", "event_num", ",", "\n", "fine_to_coarse", "=", "fine_to_coarse", ",", "\n", "hidden_dim", "=", "args", "[", "'DimLSTM'", "]", ",", "\n", "device", "=", "'cuda'", "if", "args", "[", "'UseGPU'", "]", "else", "'cpu'", "\n", ")", "\n", "", "elif", "args", "[", "'Model'", "]", "==", "'gpp'", ":", "\n", "\t\t\t", "self", ".", "model", "=", "GPP", "(", "\n", "coarse_num", "=", "coarse_num", ",", "\n", "event_num", "=", "event_num", ",", "\n", "fine_to_coarse", "=", "fine_to_coarse", ",", "\n", "device", "=", "'cuda'", "if", "args", "[", "'UseGPU'", "]", "else", "'cpu'", "\n", ")", "\n", "", "elif", "args", "[", "'Model'", "]", "==", "'ghp'", ":", "\n", "\t\t\t", "self", ".", "model", "=", "GHP", "(", "\n", "coarse_num", "=", "coarse_num", ",", "\n", "event_num", "=", "event_num", ",", "\n", "fine_to_coarse", "=", "fine_to_coarse", ",", "\n", "device", "=", "'cuda'", "if", "args", "[", "'UseGPU'", "]", "else", "'cpu'", "\n", ")", "\n", "", "else", ":", "\n", "\t\t\t", "raise", "Exception", "(", "f\"Unknown model : {args['Model']}\"", ")", "\n", "\n", "", "self", ".", "proc", "=", "DataProcessor", "(", "\n", "idx_BOS", "=", "self", ".", "model", ".", "idx_BOS", ",", "\n", "idx_EOS", "=", "self", ".", "model", ".", "idx_EOS", ",", "\n", "idx_PAD", "=", "self", ".", "model", ".", "idx_PAD", ",", "\n", "device", "=", "'cuda'", "if", "args", "[", "'UseGPU'", "]", "else", "'cpu'", "\n", ")", "\n", "if", "args", "[", "'UseGPU'", "]", ":", "\n", "\t\t\t", "self", ".", "model", ".", "cuda", "(", ")", "\n", "\n", "", "self", ".", "device", "=", "'cuda'", "if", "args", "[", "'UseGPU'", "]", "else", "'cpu'", "\n", "self", ".", "write_buffer", "=", "[", "]", "\n", "self", ".", "use_buffer", "=", "True", "if", "args", "[", "'WriteBuffer'", "]", "==", "'buffer'", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.prepare_training": [[77, 156], ["ncempp.io.log.LogWriter", "torch.optim.Adam", "torch.optim.Adam", "manager.Manager.optimizer.zero_grad", "ncempp.objectives.mle.MLE", "manager.Manager.model.parameters", "ncempp.objectives.lse.LSE", "os.path.join", "manager.Manager.load_log", "os.path.join", "manager.Manager.load_config", "os.path.join", "manager.Manager.load_model", "ncempp.objectives.nce.NCE", "Exception", "ncempp.models.nhp.GNHP", "manager.Manager.noise.cuda", "ncempp.models.pp.GPP", "Exception", "Exception"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.load_log", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.load_config", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.load_model", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["", "def", "prepare_training", "(", "self", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tprepare training-related stuff\n\t\t\"\"\"", "\n", "self", ".", "log_writer", "=", "LogWriter", "(", "self", ".", "args", "[", "'PathLog'", "]", ",", "self", ".", "args", ")", "\n", "self", ".", "optimizer", "=", "optim", ".", "Adam", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "args", "[", "'LearnRate'", "]", "\n", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\"\"\"\n\t\tcreate training obj\n\t\t\"\"\"", "\n", "self", ".", "mle", "=", "MLE", "(", "\n", "mc_sample_num", "=", "self", ".", "args", "[", "'MCSample'", "]", ",", "\n", "device", "=", "'cuda'", "if", "self", ".", "args", "[", "'UseGPU'", "]", "else", "'cpu'", "\n", ")", "\n", "if", "self", ".", "args", "[", "'TrainMethod'", "]", "==", "'mle'", ":", "\n", "\t\t\t", "self", ".", "noise", "=", "None", "\n", "self", ".", "nce", "=", "None", "\n", "", "elif", "self", ".", "args", "[", "'TrainMethod'", "]", "==", "'lse'", ":", "\n", "\t\t\t", "self", ".", "lse", "=", "LSE", "(", "\n", "mc_sample_num", "=", "self", ".", "args", "[", "'MCSample'", "]", ",", "\n", "device", "=", "'cuda'", "if", "self", ".", "args", "[", "'UseGPU'", "]", "else", "'cpu'", "\n", ")", "\n", "self", ".", "noise", "=", "None", "\n", "self", ".", "nce", "=", "None", "\n", "", "elif", "'nce'", "in", "self", ".", "args", "[", "'TrainMethod'", "]", ":", "# nce_frac or _async or _sync", "\n", "\t\t\t", "log_path", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "args", "[", "'PathSave'", "]", ",", "f\"{self.args['NoiseFolder']}/log.txt\"", ")", "\n", "noise_args", "=", "self", ".", "load_log", "(", "log_path", ")", "\n", "config_path", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "args", "[", "'PathData'", "]", ",", "f\"{noise_args['Config']}.config\"", ")", "\n", "coarse_num", ",", "event_num", ",", "fine_to_coarse", "=", "self", ".", "load_config", "(", "config_path", ")", "\n", "\n", "if", "'Model'", "not", "in", "noise_args", "or", "noise_args", "[", "'Model'", "]", "==", "'gnhp'", ":", "\n", "\t\t\t\t", "self", ".", "noise", "=", "GNHP", "(", "\n", "coarse_num", "=", "coarse_num", ",", "\n", "event_num", "=", "event_num", ",", "\n", "fine_to_coarse", "=", "fine_to_coarse", ",", "\n", "hidden_dim", "=", "noise_args", "[", "'DimLSTM'", "]", ",", "\n", "noise_mode", "=", "self", ".", "args", "[", "'NoiseMode'", "]", ",", "\n", "device", "=", "'cuda'", "if", "self", ".", "args", "[", "'UseGPU'", "]", "else", "'cpu'", "\n", ")", "\n", "", "elif", "noise_args", "[", "'Model'", "]", "==", "'gpp'", ":", "\n", "\t\t\t\t", "self", ".", "noise", "=", "GPP", "(", "\n", "coarse_num", "=", "coarse_num", ",", "\n", "event_num", "=", "event_num", ",", "\n", "fine_to_coarse", "=", "fine_to_coarse", ",", "\n", "noise_mode", "=", "self", ".", "args", "[", "'NoiseMode'", "]", ",", "\n", "device", "=", "'cuda'", "if", "self", ".", "args", "[", "'UseGPU'", "]", "else", "'cpu'", "\n", ")", "\n", "", "elif", "noise_args", "[", "'Model'", "]", "==", "'ghp'", ":", "\n", "\t\t\t\t", "raise", "Exception", "(", "f\"Hawkes can't be used as proposal yet!\"", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "raise", "Exception", "(", "f\"Unknown model : {noise_args['Model']}\"", ")", "\n", "\n", "", "\"\"\"\n\t\t\tNOTE : model may be trained and saved on another machine\n\t\t\tso its abs path may be not compitable\n\t\t\tbut its rel path must be compitable \n\t\t\tso we make the hybrid/combined abs path here\n\t\t\t\"\"\"", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "\n", "self", ".", "args", "[", "'PathSave'", "]", ",", "f\"{self.args['NoiseFolder']}/saved_model\"", "\n", ")", "\n", "if", "'.pkl'", "in", "noise_args", "[", "'PathModel'", "]", ":", "\n", "\t\t\t\t", "model_path", "+=", "'.pkl'", "\n", "", "self", ".", "load_model", "(", "self", ".", "noise", ",", "model_path", ")", "\n", "self", ".", "nce", "=", "NCE", "(", "\n", "noise_process_num", "=", "self", ".", "args", "[", "'NoiseProcess'", "]", ",", "\n", "noise_type_num", "=", "self", ".", "args", "[", "'NoiseType'", "]", ",", "\n", "over_rate", "=", "self", ".", "args", "[", "'OverRate'", "]", ",", "\n", "redraw_prob", "=", "self", ".", "args", "[", "'ReDrawProb'", "]", ",", "\n", "device", "=", "'cuda'", "if", "self", ".", "args", "[", "'UseGPU'", "]", "else", "'cpu'", "\n", ")", "\n", "if", "self", ".", "args", "[", "'UseGPU'", "]", ":", "\n", "\t\t\t\t", "self", ".", "noise", ".", "cuda", "(", ")", "\n", "", "", "else", ":", "\n", "\t\t\t", "raise", "Exception", "(", "f\"Unknow method : {self.args['TrainMethod']}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.load_config": [[157, 169], ["dict", "open", "f.read().split", "f.read().split.pop", "l.split", "int", "max", "max", "dict.keys", "dict.values", "f.read", "int"], "methods", ["None"], ["", "", "def", "load_config", "(", "self", ",", "config_path", ")", ":", "\n", "\t\t", "with", "open", "(", "config_path", ",", "'r'", ")", "as", "f", ":", "\n", "\t\t\t", "lines", "=", "f", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "", "if", "lines", "[", "-", "1", "]", "==", "''", ":", "\n", "\t\t\t", "lines", ".", "pop", "(", "-", "1", ")", "\n", "", "rst", "=", "dict", "(", ")", "\n", "for", "l", "in", "lines", ":", "\n", "\t\t\t", "k", ",", "v", "=", "l", ".", "split", "(", "' '", ")", "\n", "rst", "[", "int", "(", "k", ")", "]", "=", "int", "(", "v", ")", "\n", "", "K", "=", "max", "(", "rst", ".", "keys", "(", ")", ")", "+", "1", "\n", "C", "=", "max", "(", "rst", ".", "values", "(", ")", ")", "+", "1", "\n", "return", "C", ",", "K", ",", "rst", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.load_log": [[170, 174], ["ncempp.io.log.LogReader", "ncempp.io.log.LogReader.get_args"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.get_args"], ["", "def", "load_log", "(", "self", ",", "log_path", ")", ":", "\n", "\t\t", "log_reader", "=", "LogReader", "(", "log_path", ")", "\n", "saved_args", "=", "log_reader", ".", "get_args", "(", ")", "\n", "return", "saved_args", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.load_data": [[175, 201], ["dict", "len", "int", "len", "int", "open", "pickle.load", "os.path.join"], "methods", ["None"], ["", "def", "load_data", "(", "self", ",", "splits", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tload data for each split, e.g., train, dev, ...\n\t\t\"\"\"", "\n", "self", ".", "data", "=", "dict", "(", ")", "\n", "for", "s", "in", "splits", ":", "\n", "\t\t\t", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "args", "[", "'PathData'", "]", ",", "f'{s}.pkl'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "\t\t\t\t", "self", ".", "data", "[", "s", "]", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "", "\"\"\"\n\t\tfor training and dev data, need to adjust # of sequences\n\t\t(usually for quick debugging and learning curves)\n\t\tNOTE : this may trigger bug in test stage\n\t\tbut we don't need to test, right? we only compare learning curves!!!???\n\t\t\"\"\"", "\n", "if", "'train'", "in", "splits", "and", "'TrainRatio'", "in", "self", ".", "args", ":", "\n", "\t\t\t", "total_num", "=", "len", "(", "self", ".", "data", "[", "'train'", "]", ")", "\n", "cur_num", "=", "int", "(", "total_num", "*", "self", ".", "args", "[", "'TrainRatio'", "]", ")", "\n", "cur_num", "=", "1", "if", "cur_num", "<", "1", "else", "cur_num", "\n", "assert", "cur_num", ">=", "1", "and", "cur_num", "<=", "total_num", ",", "f\"# of seqs wrong : {cur_num}\"", "\n", "self", ".", "data", "[", "'train'", "]", "=", "self", ".", "data", "[", "'train'", "]", "[", ":", "cur_num", "]", "\n", "", "if", "'dev'", "in", "splits", "and", "'DevRatio'", "in", "self", ".", "args", ":", "\n", "\t\t\t", "total_num", "=", "len", "(", "self", ".", "data", "[", "'dev'", "]", ")", "\n", "cur_num", "=", "int", "(", "total_num", "*", "self", ".", "args", "[", "'DevRatio'", "]", ")", "\n", "cur_num", "=", "1", "if", "cur_num", "<", "1", "else", "cur_num", "\n", "assert", "cur_num", ">=", "1", "and", "cur_num", "<=", "total_num", ",", "f\"# of seqs wrong : {cur_num}\"", "\n", "self", ".", "data", "[", "'dev'", "]", "=", "self", ".", "data", "[", "'dev'", "]", "[", ":", "cur_num", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.load_model": [[202, 211], ["model.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.device", "torch.device", "torch.device", "torch.device"], "methods", ["None"], ["", "", "def", "load_model", "(", "self", ",", "model", ",", "path_saved_state", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tload saved_state and assign it to model\n\t\tmodel can be either p or noise dist q \n\t\t\"\"\"", "\n", "model", ".", "load_state_dict", "(", "\n", "torch", ".", "load", "(", "\n", "path_saved_state", ",", "\n", "map_location", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.save_model": [[214, 216], ["torch.save", "torch.save", "torch.save", "torch.save", "manager.Manager.model.state_dict"], "methods", ["None"], ["", "def", "save_model", "(", "self", ")", ":", "\n", "\t\t", "torch", ".", "save", "(", "self", ".", "model", ".", "state_dict", "(", ")", ",", "self", ".", "args", "[", "'PathModel'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.process_data": [[217, 264], ["dict", "dict", "dict", "manager.Manager.proc.process_batch", "dict", "len", "list", "range", "len", "[].append", "list"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.data.DataProcessor.process_batch"], ["", "def", "process_data", "(", "self", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tNOTE : \n\t\tanother way is to only process data into tensors when needed\n\t\tit will save memory, esp for large datasets\n\t\tbut it will be slower, cuz of re-processing\n\t\tbut for the datasets we have used \n\t\twe don't need to do this because they are not that large \n\t\tactually, for a dataset with # seqs == 200K and avg. len == 10\n\t\tthe memory cost is only < 100 MB --- very minor \n\t\tso we don't need to worry about it now \n\t\thowever, in the future, if we indeed work with super-large data \n\t\twe may have to make this change\n\t\t\"\"\"", "\n", "\"\"\"\n\t\tNOTE : \n\t\tdata tensors organized in BatchCompute\n\t\tdata tensors for noise samples (init as None)\n\t\t\"\"\"", "\n", "self", ".", "data_tensor", "=", "dict", "(", ")", "\n", "self", ".", "noise_tensor_pack", "=", "dict", "(", ")", "\n", "for", "s", "in", "self", ".", "data", ":", "\n", "\t\t\t", "self", ".", "data_tensor", "[", "s", "]", ",", "self", ".", "noise_tensor_pack", "[", "s", "]", "=", "self", ".", "proc", ".", "process_batch", "(", "\n", "self", ".", "data", "[", "s", "]", ",", "self", ".", "args", "[", "'SizeBatchCompute'", "]", ")", "\n", "", "\"\"\"\n\t\tNOTE : \n\t\ttrack list of batch compute for each batch update\n\t\t\"\"\"", "\n", "self", ".", "upd_to_comp", "=", "dict", "(", ")", "\n", "for", "s", "in", "self", ".", "data", ":", "\n", "\t\t\t", "self", ".", "upd_to_comp", "[", "s", "]", "=", "dict", "(", ")", "\n", "i_upd", ",", "i_comp", "=", "0", ",", "0", "\n", "num_seqs", "=", "len", "(", "self", ".", "data", "[", "s", "]", ")", "\n", "self", ".", "upd_to_comp", "[", "s", "]", "[", "i_upd", "]", "=", "list", "(", ")", "\n", "for", "i_seq", "in", "range", "(", "num_seqs", ")", ":", "\n", "\t\t\t\t", "batch_comp_end", "=", "i_seq", "%", "self", ".", "args", "[", "'SizeBatchCompute'", "]", "==", "self", ".", "args", "[", "'SizeBatchCompute'", "]", "-", "1", "\n", "data_end", "=", "i_seq", "==", "num_seqs", "-", "1", "\n", "if", "batch_comp_end", "or", "data_end", ":", "\n", "\t\t\t\t\t", "self", ".", "upd_to_comp", "[", "s", "]", "[", "i_upd", "]", ".", "append", "(", "i_comp", ")", "\n", "i_comp", "+=", "1", "\n", "", "batch_upd_end", "=", "i_seq", "%", "self", ".", "args", "[", "'SizeBatchUpdate'", "]", "==", "self", ".", "args", "[", "'SizeBatchUpdate'", "]", "-", "1", "\n", "if", "batch_upd_end", "and", "not", "data_end", ":", "\n", "\t\t\t\t\t", "i_upd", "+=", "1", "\n", "self", ".", "upd_to_comp", "[", "s", "]", "[", "i_upd", "]", "=", "list", "(", ")", "\n", "", "", "", "assert", "i_comp", "==", "len", "(", "self", ".", "data_tensor", "[", "s", "]", ")", ",", "\"# of compute batches NOT match???!!!\"", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.compute_mle": [[265, 287], ["manager.Manager.mle", "float", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "compute_mle", "(", "self", ",", "split", ",", "i_batch_comp", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tcompute mle on i_batch-th batch of data of split \n\t\tinput \n\t\t\tsplit : train, dev, or test \n\t\t\ti_batch_comp : i-th batch for computing\n\t\t\"\"\"", "\n", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", "=", "self", ".", "data_tensor", "[", "split", "]", "[", "i_batch_comp", "]", "\n", "\"\"\"\n\t\tinten_num : # of intensities computed for this batch of data\n\t\t\"\"\"", "\n", "if", "'train'", "in", "split", ":", "\n", "\t\t\t", "eval_tag", "=", "False", "\n", "", "else", ":", "\n", "\t\t\t", "eval_tag", "=", "True", "\n", "\n", "", "log_likelihood", ",", "inten_num", "=", "self", ".", "mle", "(", "\n", "self", ".", "model", ",", "\n", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ",", "\n", "eval_tag", ")", "\n", "return", "log_likelihood", ",", "float", "(", "torch", ".", "sum", "(", "token_num_tensor", ")", ")", ",", "inten_num", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.compute_lse": [[288, 305], ["manager.Manager.lse", "float", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["None"], ["", "def", "compute_lse", "(", "self", ",", "split", ",", "i_batch_comp", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tcompute ls on i_batch-th batch of data of split \n\t\t\"\"\"", "\n", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", "=", "self", ".", "data_tensor", "[", "split", "]", "[", "i_batch_comp", "]", "\n", "if", "'train'", "in", "split", ":", "\n", "\t\t\t", "eval_tag", "=", "False", "\n", "", "else", ":", "\n", "\t\t\t", "eval_tag", "=", "True", "\n", "\n", "", "minus_square", ",", "inten_num", "=", "self", ".", "lse", "(", "\n", "self", ".", "model", ",", "\n", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ",", "\n", "eval_tag", ")", "\n", "\n", "return", "minus_square", ",", "float", "(", "torch", ".", "sum", "(", "token_num_tensor", ")", ")", ",", "inten_num", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.compute_nce": [[306, 327], ["manager.Manager.get_nosie_pack", "manager.Manager.nce", "manager.Manager.save_noise_pack", "float", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.get_nosie_pack", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.save_noise_pack"], ["", "def", "compute_nce", "(", "self", ",", "split", ",", "i_batch_comp", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tcompute nce on i_batch-th batch of data of split \n\t\tinput \n\t\t\tsplit : train, dev, or test \n\t\t\ti_batch_comp : i-th batch for computing\n\t\t\"\"\"", "\n", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", "=", "self", ".", "data_tensor", "[", "split", "]", "[", "i_batch_comp", "]", "\n", "noise_tensor_pack", "=", "self", ".", "get_nosie_pack", "(", "split", ",", "i_batch_comp", ")", "\n", "\"\"\"\n\t\tinten_num : # of intensities computed for this batch of data\n\t\t\"\"\"", "\n", "nce_obj", ",", "inten_num", ",", "new_noise_pack", "=", "self", ".", "nce", "(", "\n", "self", ".", "args", "[", "'TrainMethod'", "]", ",", "# nce_frac or _async or _sync", "\n", "self", ".", "model", ",", "self", ".", "noise", ",", "\n", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", ",", "\n", "noise_tensor_pack", "\n", ")", "\n", "self", ".", "save_noise_pack", "(", "split", ",", "i_batch_comp", ",", "new_noise_pack", ")", "\n", "return", "nce_obj", ",", "float", "(", "torch", ".", "sum", "(", "token_num_tensor", ")", ")", ",", "inten_num", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.get_nosie_pack": [[328, 335], ["range", "rst[].to"], "methods", ["None"], ["", "def", "get_nosie_pack", "(", "self", ",", "split", ",", "i_batch_comp", ")", ":", "\n", "\t\t", "rst", "=", "self", ".", "noise_tensor_pack", "[", "split", "]", "[", "i_batch_comp", "]", "\n", "if", "rst", "is", "not", "None", "and", "self", ".", "device", "==", "'cuda'", ":", "\n", "# move it from CPU to GPU ", "\n", "\t\t\t", "for", "i", "in", "range", "(", "6", ")", ":", "\n", "\t\t\t\t", "rst", "[", "i", "]", ".", "to", "(", "'cuda'", ")", "\n", "", "", "return", "rst", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.save_noise_pack": [[336, 344], ["range", "[].to"], "methods", ["None"], ["", "def", "save_noise_pack", "(", "self", ",", "split", ",", "i_batch_comp", ",", "new_noise_pack", ")", ":", "\n", "\t\t", "if", "new_noise_pack", "is", "not", "None", ":", "\n", "\t\t\t", "self", ".", "noise_tensor_pack", "[", "split", "]", "[", "i_batch_comp", "]", "=", "new_noise_pack", "\n", "", "if", "self", ".", "device", "==", "'cuda'", ":", "\n", "# new pack comes from GPU, move it to CPU ", "\n", "# or old pack moved to GPU already, move it back", "\n", "\t\t\t", "for", "i", "in", "range", "(", "6", ")", ":", "\n", "\t\t\t\t", "self", ".", "noise_tensor_pack", "[", "split", "]", "[", "i_batch_comp", "]", "[", "i", "]", ".", "to", "(", "'cpu'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.train_batch": [[345, 373], ["manager.Manager.optimizer.zero_grad", "manager.Manager.optimizer.step", "float", "manager.Manager.compute_mle", "manager.Manager.compute_lse", "manager.Manager.compute_nce", "Exception"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.compute_mle", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.compute_lse", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.compute_nce"], ["", "", "", "def", "train_batch", "(", "self", ",", "i_batch", ")", ":", "\n", "# i_batch : for updating", "\n", "#print(f\"i batch = {i_batch}\")", "\n", "\t\t", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "# clear grads", "\n", "token_num", ",", "inten_num", "=", "0.0", ",", "0.0", "\n", "batch_indices", "=", "self", ".", "upd_to_comp", "[", "'train'", "]", "[", "i_batch", "]", "\n", "for", "i_batch_comp", "in", "batch_indices", ":", "\n", "# iterate each batch-compute responsible for this update", "\n", "\t\t\t", "if", "self", ".", "args", "[", "'TrainMethod'", "]", "==", "'mle'", ":", "\n", "\t\t\t\t", "to_maximize", ",", "token_num_i", ",", "inten_num_i", "=", "self", ".", "compute_mle", "(", "'train'", ",", "i_batch_comp", ")", "\n", "", "elif", "self", ".", "args", "[", "'TrainMethod'", "]", "==", "'lse'", ":", "\n", "\t\t\t\t", "to_maximize", ",", "token_num_i", ",", "inten_num_i", "=", "self", ".", "compute_lse", "(", "'train'", ",", "i_batch_comp", ")", "\n", "", "elif", "'nce'", "in", "self", ".", "args", "[", "'TrainMethod'", "]", ":", "# nce_frac or _async or _sync", "\n", "\t\t\t\t", "to_maximize", ",", "token_num_i", ",", "inten_num_i", "=", "self", ".", "compute_nce", "(", "'train'", ",", "i_batch_comp", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "raise", "Exception", "(", "f\"Unknow method : {self.args['TrainMethod']}\"", ")", "\n", "", "(", "-", "to_maximize", ")", ".", "backward", "(", ")", "\n", "token_num", "+=", "token_num_i", "\n", "inten_num", "+=", "inten_num_i", "\n", "", "\"\"\"\n\t\tNOTE : when we do backward() many times and then step()\n\t\tdoes it take sum or average??? sum!\n\t\t\"\"\"", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "return", "float", "(", "to_maximize", ")", ",", "token_num", ",", "inten_num", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.eval_mle_batch": [[374, 379], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "manager.Manager.compute_mle"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.compute_mle"], ["", "def", "eval_mle_batch", "(", "self", ",", "split", ",", "i_batch_comp", ")", ":", "\n", "\t\t", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t", "log_likelihood", ",", "token_num", ",", "inten_num", "=", "self", ".", "compute_mle", "(", "split", ",", "i_batch_comp", ")", "\n", "", "return", "log_likelihood", ",", "token_num", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.eval_lse_batch": [[380, 385], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "manager.Manager.compute_lse"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.compute_lse"], ["", "def", "eval_lse_batch", "(", "self", ",", "split", ",", "i_batch_comp", ")", ":", "\n", "\t\t", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t", "minus_square", ",", "token_num", ",", "inten_num", "=", "self", ".", "compute_lse", "(", "split", ",", "i_batch_comp", ")", "\n", "", "return", "minus_square", ",", "token_num", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.eval_nce_batch": [[386, 390], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "manager.Manager.compute_nce"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.compute_nce"], ["", "def", "eval_nce_batch", "(", "self", ",", "split", ",", "i_batch_comp", ")", ":", "\n", "\t\t", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t", "nce_obj", ",", "token_num", ",", "inten_num", "=", "self", ".", "compute_nce", "(", "split", ",", "i_batch_comp", ")", "\n", "", "return", "nce_obj", ",", "token_num", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.eval_mle_epoch": [[391, 404], ["range", "len", "manager.Manager.eval_mle_batch", "float"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.eval_mle_batch"], ["", "def", "eval_mle_epoch", "(", "self", ",", "split", ")", ":", "\n", "#print(f\"eval MLE for one epoch\")", "\n", "#process = psutil.Process(os.getpid())", "\n", "\t\t", "total_log_likelihood", "=", "0.0", "\n", "total_num", "=", "0.0", "\n", "for", "i_batch_comp", "in", "range", "(", "len", "(", "self", ".", "data_tensor", "[", "split", "]", ")", ")", ":", "\n", "#print(f\"eval {i_batch_comp}-th compute batch\")", "\n", "\t\t\t", "log_likelihood_batch", ",", "token_num_batch", "=", "self", ".", "eval_mle_batch", "(", "split", ",", "i_batch_comp", ")", "\n", "total_log_likelihood", "+=", "float", "(", "log_likelihood_batch", ")", "\n", "total_num", "+=", "token_num_batch", "\n", "#print(f'memory afterwards : {process.memory_info().rss/1000000:.3f} MB')", "\n", "", "return", "total_log_likelihood", ",", "total_num", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.prepare_gen": [[405, 410], ["ncempp.io.log.LogWriter"], "methods", ["None"], ["", "def", "prepare_gen", "(", "self", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tprepare data-generating stuff\n\t\t\"\"\"", "\n", "self", ".", "log_writer", "=", "LogWriter", "(", "self", ".", "args", "[", "'PathLog'", "]", ",", "self", ".", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.gen_seq": [[411, 427], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "manager.Manager.model.draw_seq", "rst.append"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.draw_seq"], ["", "def", "gen_seq", "(", "self", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tdraw an i.i.d. sample sequence from model p\n\t\t\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\t\t\t", "seq", "=", "self", ".", "model", ".", "draw_seq", "(", "self", ".", "args", "[", "'NumToken'", "]", ")", "\n", "", "last_time", "=", "0.0", "\n", "rst", "=", "[", "]", "\n", "for", "dt", ",", "k", "in", "seq", ":", "\n", "\t\t\t", "token", "=", "{", "\n", "'name'", ":", "k", ",", "'time'", ":", "last_time", "+", "dt", ",", "\n", "'time_since_last_event'", ":", "dt", "\n", "}", "\n", "last_time", "=", "token", "[", "'time'", "]", "\n", "rst", ".", "append", "(", "token", ")", "\n", "", "return", "rst", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.get_batchcompute_num": [[429, 432], ["len"], "methods", ["None"], ["", "def", "get_batchcompute_num", "(", "self", ",", "split", ")", ":", "\n", "# return # of batches for computing loss ", "\n", "\t\t", "return", "len", "(", "self", ".", "data_tensor", "[", "split", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.get_batchupdate_num": [[433, 436], ["len"], "methods", ["None"], ["", "def", "get_batchupdate_num", "(", "self", ",", "split", ")", ":", "\n", "# return # of batches for updating params", "\n", "\t\t", "return", "len", "(", "self", ".", "upd_to_comp", "[", "split", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.get_seq_num": [[437, 439], ["len"], "methods", ["None"], ["", "def", "get_seq_num", "(", "self", ",", "split", ")", ":", "\n", "\t\t", "return", "len", "(", "self", ".", "data", "[", "split", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.checkpoint": [[440, 442], ["manager.Manager.log_writer.checkpoint"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogWriter.checkpoint"], ["", "def", "checkpoint", "(", "self", ",", "to_write", ")", ":", "\n", "\t\t", "self", ".", "log_writer", ".", "checkpoint", "(", "to_write", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.print_or_buffer": [[443, 448], ["manager.Manager.write_buffer.append", "print"], "methods", ["None"], ["", "def", "print_or_buffer", "(", "self", ",", "message", ")", ":", "\n", "\t\t", "if", "self", ".", "use_buffer", ":", "\n", "\t\t\t", "self", ".", "write_buffer", ".", "append", "(", "message", ")", "\n", "", "else", ":", "\n", "\t\t\t", "print", "(", "message", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.run.manager.Manager.flush_buffer": [[449, 453], ["print"], "methods", ["None"], ["", "", "def", "flush_buffer", "(", "self", ")", ":", "\n", "\t\t", "for", "message", "in", "self", ".", "write_buffer", ":", "\n", "\t\t\t", "print", "(", "message", ")", "\n", "", "self", ".", "write_buffer", "=", "[", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.__init__": [[15, 50], ["open", "f.read().split", "l.split", "float", "os.path.join", "f.read().split.pop", "f.read"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "*", ",", "args", ")", ":", "\n", "\t\t", "self", ".", "args", "=", "args", "\n", "self", ".", "figure_tags", "=", "[", "'inten'", ",", "'time'", "]", "\n", "self", ".", "figure_labels", "=", "{", "\n", "'inten'", ":", "[", "'# of intensities computed'", ",", "'log-likelihood'", "]", ",", "\n", "'time'", ":", "[", "'wall-clock time'", ",", "'log-likelihood'", "]", ",", "\n", "}", "\n", "self", ".", "index", "=", "{", "\n", "'inten'", ":", "2", ",", "'time'", ":", "1", ",", "'ll'", ":", "3", "# ll : loglikelihood", "\n", "}", "\n", "self", ".", "color", "=", "{", "\n", "'mle'", ":", "'red'", ",", "\n", "'lse'", ":", "'orange'", ",", "\n", "'nce_frac'", ":", "'blue'", ",", "'nce_async'", ":", "'blue'", ",", "'nce_sync'", ":", "'blue'", ",", "\n", "'nce_binary'", ":", "'green'", ",", "\n", "'hybrid'", ":", "'blueviolet'", ",", "\n", "'high'", ":", "'red'", ",", "\n", "}", "\n", "self", ".", "range", "=", "{", "\n", "'y_low'", ":", "args", "[", "'YLow'", "]", ",", "\n", "'inten_high'", ":", "args", "[", "'IntenHigh'", "]", ",", "\n", "'time_high'", ":", "args", "[", "'TimeHigh'", "]", "\n", "}", "\n", "\"\"\"\n\t\tcollect annotation positions\n\t\t\"\"\"", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "args", "[", "'PathSave'", "]", ",", "'anns.txt'", ")", ",", "'r'", ")", "as", "f", ":", "\n", "\t\t\t", "anns", "=", "f", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "if", "anns", "[", "-", "1", "]", "==", "''", ":", "\n", "\t\t\t\t", "anns", ".", "pop", "(", "-", "1", ")", "\n", "", "", "self", ".", "ann", "=", "{", "}", "\n", "for", "l", "in", "anns", ":", "\n", "\t\t\t", "method_m_b", ",", "ann_frac", "=", "l", ".", "split", "(", "' '", ")", "\n", "ann_frac", "=", "float", "(", "ann_frac", ")", "\n", "self", ".", "ann", "[", "method_m_b", "]", "=", "ann_frac", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.draw_lc": [[51, 129], ["list", "list.pop", "list.pop.index", "list.pop.index", "list.pop.index", "list.pop.index", "list.pop.index", "list.pop.index", "list.pop.index", "list", "list.pop", "list", "list", "open", "csv.reader", "open", "csv.reader", "list.append", "enumerate", "run.append", "draw.Drawer.draw_one_figure", "list.append", "list.append", "list", "int", "list.append", "vals[].append", "list.pop.index"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.draw_one_figure"], ["", "", "def", "draw_lc", "(", "self", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tget all results\n\t\t\"\"\"", "\n", "all_runs", "=", "list", "(", ")", "\n", "\"\"\"\n\t\tread meta data\n\t\t\"\"\"", "\n", "with", "open", "(", "self", ".", "args", "[", "'PathMetaCSV'", "]", ")", "as", "csvfile", ":", "\n", "\t\t\t", "readCSV", "=", "csv", ".", "reader", "(", "csvfile", ",", "delimiter", "=", "','", ")", "\n", "for", "row", "in", "readCSV", ":", "\n", "\t\t\t\t", "all_runs", ".", "append", "(", "row", ")", "\n", "", "", "\"\"\"\n\t\tread header \n\t\t\"\"\"", "\n", "header", "=", "all_runs", ".", "pop", "(", "0", ")", "\n", "method_i", "=", "header", ".", "index", "(", "'TrainMethod'", ")", "\n", "mc_i", "=", "header", ".", "index", "(", "'MCSample'", ")", "\n", "batch_i", "=", "header", ".", "index", "(", "'SizeBatchUpdate'", ")", "\n", "np_i", "=", "header", ".", "index", "(", "'NoiseProcess'", ")", "\n", "nt_i", "=", "header", ".", "index", "(", "'NoiseType'", ")", "\n", "logidx_i", "=", "header", ".", "index", "(", "'_index'", ")", "\n", "keep_i", "=", "header", ".", "index", "(", "'_keep'", ")", "\n", "vals_i", "=", "-", "1", "\n", "\"\"\"\n\t\tread log data\n\t\t\"\"\"", "\n", "log_rows", "=", "list", "(", ")", "\n", "with", "open", "(", "self", ".", "args", "[", "'PathLogCSV'", "]", ")", "as", "csvfile", ":", "\n", "\t\t\t", "readCSV", "=", "csv", ".", "reader", "(", "csvfile", ",", "delimiter", "=", "','", ")", "\n", "for", "row", "in", "readCSV", ":", "\n", "\t\t\t\t", "log_rows", ".", "append", "(", "row", ")", "\n", "", "", "indices", "=", "log_rows", ".", "pop", "(", "0", ")", "# a list ", "\n", "vals", "=", "list", "(", ")", "\n", "for", "idx", "in", "indices", ":", "\n", "\t\t\t", "vals", ".", "append", "(", "list", "(", ")", ")", "\n", "", "for", "row", "in", "log_rows", ":", "\n", "\t\t\t", "for", "i", ",", "v", "in", "enumerate", "(", "row", ")", ":", "\n", "\t\t\t\t", "if", "v", "!=", "''", ":", "\n", "\t\t\t\t\t", "assert", "'|'", "in", "v", ",", "\"not a track?\"", "\n", "vals", "[", "i", "]", ".", "append", "(", "v", ")", "\n", "", "", "", "\"\"\"\n\t\tmatch logs with runs\n\t\t\"\"\"", "\n", "for", "run", "in", "all_runs", ":", "\n", "\t\t\t", "logidx", "=", "run", "[", "logidx_i", "]", "\n", "run", ".", "append", "(", "vals", "[", "indices", ".", "index", "(", "logidx", ")", "]", ")", "\n", "# that's why its index is -1", "\n", "", "\"\"\"\n\t\tprune runs with keep=0\n\t\t\"\"\"", "\n", "draw_runs", "=", "list", "(", ")", "\n", "for", "run", "in", "all_runs", ":", "\n", "\t\t\t", "if", "int", "(", "run", "[", "keep_i", "]", ")", "==", "1", ":", "\n", "\t\t\t\t", "draw_runs", ".", "append", "(", "run", ")", "\n", "", "", "\"\"\"\n\t\tdraw curves\n\t\t\"\"\"", "\n", "for", "figure_tag", "in", "self", ".", "figure_tags", ":", "\n", "\t\t\t", "\"\"\"\n\t\t\tfor each tag (i.e., inten, time, etc...) : \n\t\t\t# inten : vs. # of intensities computed \n\t\t\t# time : vs. wall-clock time \n\t\t\tfind x_i and y_i : index of x and y in 'Values'\n\t\t\t\"\"\"", "\n", "x_i", "=", "self", ".", "index", "[", "figure_tag", "]", "\n", "y_i", "=", "self", ".", "index", "[", "'ll'", "]", "\n", "xlabel", "=", "self", ".", "figure_labels", "[", "figure_tag", "]", "[", "0", "]", "\n", "ylabel", "=", "self", ".", "figure_labels", "[", "figure_tag", "]", "[", "1", "]", "\n", "x_high", "=", "self", ".", "range", "[", "f'{figure_tag}_high'", "]", "\n", "y_low", "=", "self", ".", "range", "[", "'y_low'", "]", "\n", "fig_name", "=", "f\"lc_tag={figure_tag}_csv={self.args['CSVName']}_xhigh={x_high:.0f}_ylow={y_low:.0f}.pdf\"", "\n", "if", "self", ".", "args", "[", "'Prefix'", "]", "!=", "''", ":", "\n", "\t\t\t\t", "fig_name", "=", "self", ".", "args", "[", "'Prefix'", "]", "+", "'_'", "+", "fig_name", "\n", "", "self", ".", "draw_one_figure", "(", "\n", "draw_runs", ",", "method_i", ",", "mc_i", ",", "batch_i", ",", "\n", "np_i", ",", "nt_i", ",", "vals_i", ",", "x_i", ",", "y_i", ",", "\n", "x_high", ",", "y_low", ",", "xlabel", ",", "ylabel", ",", "fig_name", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.draw_one_figure": [[131, 451], ["dict", "dict", "dict.items", "matplotlib.subplots", "set", "dict", "dict.items", "matplotlib.xlim", "matplotlib.hlines", "matplotlib.ylim", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.legend", "matplotlib.tight_layout", "matplotlib.savefig", "draw.Drawer.get_prefix", "draw.Drawer.get_annotate", "numpy.cumsum", "range", "numpy.array", "[].append", "[].append", "numpy.mean", "numpy.mean", "numpy.min", "numpy.max", "numpy.linspace", "scipy.interpolate.interp1d", "scipy.interpolate.interp1d.", "scipy.interpolate.interp1d", "scipy.interpolate.interp1d.", "scipy.interpolate.interp1d", "scipy.interpolate.interp1d.", "range", "matplotlib.plot", "matplotlib.fill_between", "set.add", "matplotlib.ylim", "legobj.set_linewidth", "legobj.set_alpha", "os.path.join", "list", "list", "v.split.split.split", "numpy.mean.append", "numpy.mean.append", "draw.Drawer.array", "draw.Drawer.array", "draw.Drawer.array", "draw.Drawer.array", "numpy.mean.min", "numpy.mean.max", "list", "list", "list", "list", "len", "numpy.max", "numpy.linspace", "numpy.linspace", "numpy.linspace", "numpy.linspace", "matplotlib.plot", "matplotlib.fill_between", "list", "list", "int", "list", "list", "len", "draw.Drawer.find_where_to_annotate", "matplotlib.text", "numpy.mean", "numpy.mean", "method_m_annotate.split", "draw.Drawer.get_mi", "float", "float", "len", "len", "numpy.mean.append", "numpy.mean.append", "numpy.min.append", "numpy.max.append", "abs", "len", "max", "max", "max", "max", "max", "max", "len", "len", "abs", "len", "numpy.linspace", "numpy.linspace", "len", "max", "max", "len", "matplotlib.plot", "matplotlib.fill_between", "set.add", "float", "float", "len", "numpy.abs"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.get_prefix", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.get_annotate", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.array", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.array", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.array", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.array", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.array", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.find_where_to_annotate", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.get_mi"], ["", "", "def", "draw_one_figure", "(", "self", ",", "\n", "all_runs", ",", "method_i", ",", "mc_i", ",", "batch_i", ",", "\n", "np_i", ",", "nt_i", ",", "vals_i", ",", "x_i", ",", "y_i", ",", "\n", "x_high", ",", "y_low", ",", "xlabel", ",", "ylabel", ",", "fig_name", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tNOTE : same hyperparam may have different runs with different random seed \n\t\t\"\"\"", "\n", "curve_with_band", "=", "dict", "(", ")", "\n", "\n", "for", "run", "in", "all_runs", ":", "\n", "\t\t\t", "\"\"\"\n\t\t\tfor this curve (i.e. this run of training method)\n\t\t\tfind its color and label based on training method\n\t\t\t\"\"\"", "\n", "#print(run)", "\n", "method", "=", "run", "[", "method_i", "]", "\n", "color", "=", "self", ".", "color", "[", "method", "]", "\n", "label", "=", "self", ".", "get_prefix", "(", "method", ")", "\n", "m", "=", "run", "[", "self", ".", "get_mi", "(", "method", ",", "[", "mc_i", ",", "np_i", ",", "nt_i", "]", ")", "]", "\n", "batch", "=", "run", "[", "batch_i", "]", "\n", "annotate", "=", "self", ".", "get_annotate", "(", "method", ",", "m", ",", "batch", ")", "\n", "vals", "=", "run", "[", "vals_i", "]", "\n", "# get curve", "\n", "x", ",", "y", "=", "list", "(", ")", ",", "list", "(", ")", "\n", "for", "v", "in", "vals", ":", "\n", "\t\t\t\t", "v", "=", "v", ".", "split", "(", "'|'", ")", "\n", "x", ".", "append", "(", "float", "(", "v", "[", "x_i", "]", ")", ")", "\n", "y", ".", "append", "(", "float", "(", "v", "[", "y_i", "]", ")", ")", "\n", "", "x", "=", "numpy", ".", "cumsum", "(", "x", ")", "\n", "\"\"\"\n\t\t\tsmooth y : \n\t\t\trigid and wavy y doesn't make sense---why? \n\t\t\ty is dev-performance---if we find it drop, we'll just use prev saved model \n\t\t\tso actual performance of entire model never goes down\n\t\t\t\"\"\"", "\n", "for", "i", "in", "range", "(", "len", "(", "y", ")", "-", "1", ")", ":", "\n", "\t\t\t\t", "if", "y", "[", "i", "+", "1", "]", "<", "y", "[", "i", "]", ":", "\n", "\t\t\t\t\t", "y", "[", "i", "+", "1", "]", "=", "y", "[", "i", "]", "\n", "", "", "y", "=", "numpy", ".", "array", "(", "y", ")", "\n", "\"\"\"\n\t\t\tsave curves to draw\n\t\t\t\"\"\"", "\n", "if", "f'{method}_{m}_{batch}'", "not", "in", "curve_with_band", ":", "\n", "\t\t\t\t", "curve_with_band", "[", "f'{method}_{m}_{batch}'", "]", "=", "{", "\n", "'method'", ":", "method", ",", "'m'", ":", "m", ",", "'batch'", ":", "batch", ",", "\n", "'color'", ":", "color", ",", "'label'", ":", "label", ",", "\n", "'annotate'", ":", "annotate", ",", "\n", "'x_all'", ":", "[", "]", ",", "'y_all'", ":", "[", "]", "\n", "}", "\n", "\n", "", "curve_with_band", "[", "f'{method}_{m}_{batch}'", "]", "[", "'x_all'", "]", ".", "append", "(", "x", ")", "\n", "curve_with_band", "[", "f'{method}_{m}_{batch}'", "]", "[", "'y_all'", "]", ".", "append", "(", "y", ")", "\n", "\n", "", "\"\"\"\n\t\tNOTE : aggregate random runs for each hyper-param\n\t\t\"\"\"", "\n", "inter_num", "=", "self", ".", "args", "[", "'Inter'", "]", "# for interpolation, may be a hyper-param", "\n", "smooth_kind", "=", "'linear'", "\n", "highest", "=", "dict", "(", ")", "# track highest value achieved by each method", "\n", "x_cat", ",", "y_cat", ",", "y_min_cat", ",", "y_max_cat", "=", "None", ",", "None", ",", "None", ",", "None", "# to save the extrapolated MLE curve", "\n", "\n", "for", "method_m_b", ",", "info", "in", "curve_with_band", ".", "items", "(", ")", ":", "\n", "\n", "\t\t\t", "x", "=", "numpy", ".", "mean", "(", "self", ".", "array", "(", "info", "[", "'x_all'", "]", ")", ",", "axis", "=", "0", ")", "\n", "y", "=", "numpy", ".", "mean", "(", "self", ".", "array", "(", "info", "[", "'y_all'", "]", ")", ",", "axis", "=", "0", ")", "\n", "y_min", "=", "numpy", ".", "min", "(", "self", ".", "array", "(", "info", "[", "'y_all'", "]", ")", ",", "axis", "=", "0", ")", "\n", "y_max", "=", "numpy", ".", "max", "(", "self", ".", "array", "(", "info", "[", "'y_all'", "]", ")", ",", "axis", "=", "0", ")", "\n", "\n", "\"\"\"\n\t\t\tfurther smooth : use poly\n\t\t\tfirst make a smoother function using current x and y\n\t\t\t\"\"\"", "\n", "\"\"\"\n\t\t\tmake new x\n\t\t\t\"\"\"", "\n", "x_new", "=", "numpy", ".", "linspace", "(", "x", ".", "min", "(", ")", ",", "x", ".", "max", "(", ")", ",", "inter_num", "*", "len", "(", "x", ")", ")", "\n", "smooth", "=", "interpolate", ".", "interp1d", "(", "x", ",", "y", ",", "kind", "=", "smooth_kind", ")", "\n", "#spl = make_interp_spline(x, y, k=3)  # type: BSpline", "\n", "#y_smooth = spl(x_new)", "\n", "y_new", "=", "smooth", "(", "x_new", ")", "\n", "smooth", "=", "interpolate", ".", "interp1d", "(", "x", ",", "y_min", ",", "kind", "=", "smooth_kind", ")", "\n", "#spl = make_interp_spline(x, y, k=3)  # type: BSpline", "\n", "#y_smooth = spl(x_new)", "\n", "y_min_new", "=", "smooth", "(", "x_new", ")", "\n", "smooth", "=", "interpolate", ".", "interp1d", "(", "x", ",", "y_max", ",", "kind", "=", "smooth_kind", ")", "\n", "#spl = make_interp_spline(x, y, k=3)  # type: BSpline", "\n", "#y_smooth = spl(x_new)", "\n", "y_max_new", "=", "smooth", "(", "x_new", ")", "\n", "\n", "\"\"\"\n\t\t\tonly draw values within range\n\t\t\t\"\"\"", "\n", "x", ",", "y", ",", "y_min", ",", "y_max", "=", "list", "(", ")", ",", "list", "(", ")", ",", "list", "(", ")", ",", "list", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "x_new", ")", ")", ":", "\n", "\t\t\t\t", "if", "x_new", "[", "i", "]", "<=", "x_high", "and", "y_new", "[", "i", "]", ">=", "y_low", "-", "0.1", "*", "numpy", ".", "abs", "(", "y_low", ")", ":", "\n", "\t\t\t\t\t", "\"\"\"\n\t\t\t\t\tNOTE : we over-draw to make band look better\n\t\t\t\t\tin the end, we will crop out the over-drawn curve\n\t\t\t\t\t\"\"\"", "\n", "x", ".", "append", "(", "x_new", "[", "i", "]", ")", "\n", "y", ".", "append", "(", "y_new", "[", "i", "]", ")", "\n", "y_min", ".", "append", "(", "y_min_new", "[", "i", "]", ")", "\n", "y_max", ".", "append", "(", "y_max_new", "[", "i", "]", ")", "\n", "\n", "", "", "info", "[", "'x'", "]", "=", "x", "\n", "info", "[", "'y'", "]", ",", "info", "[", "'y_min'", "]", ",", "info", "[", "'y_max'", "]", "=", "y", ",", "y_min", ",", "y_max", "\n", "\n", "info", "[", "'x_entire'", "]", "=", "x_new", "\n", "info", "[", "'y_entire'", "]", ",", "info", "[", "'y_min_entire'", "]", ",", "info", "[", "'y_max_entire'", "]", "=", "y_new", ",", "y_min_new", ",", "y_max_new", "\n", "\n", "\"\"\"\n\t\t\ttrack highest (mean) y for this method \n\t\t\t\"\"\"", "\n", "method", "=", "info", "[", "'method'", "]", "\n", "if", "method_m_b", "not", "in", "highest", ":", "\n", "\t\t\t\t", "highest", "[", "method_m_b", "]", "=", "[", "]", "\n", "", "highest", "[", "method_m_b", "]", "+=", "[", "numpy", ".", "max", "(", "y_new", ")", "]", "\n", "\"\"\"\n\t\t\ttrack a MLE curve for concatenation\n\t\t\ttrack the entire curve \n\t\t\teven though some parts may not be shown on its own curve in this window\n\t\t\tthose parts may be shown on the corresponding NCE curves!!!\n\t\t\t\"\"\"", "\n", "if", "info", "[", "'method'", "]", "==", "'mle'", "and", "abs", "(", "float", "(", "info", "[", "'m'", "]", ")", "-", "float", "(", "self", ".", "args", "[", "'HybridMultiplier'", "]", ")", ")", "<", "1e-3", ":", "\n", "\t\t\t\t", "x_cat", ",", "y_cat", ",", "y_min_cat", ",", "y_max_cat", "=", "info", "[", "'x_entire'", "]", ",", "info", "[", "'y_entire'", "]", ",", "info", "[", "'y_min_entire'", "]", ",", "info", "[", "'y_max_entire'", "]", "\n", "\n", "", "", "\"\"\"\n\t\tNOTE : okay, we have all the curves to draw, now we draw them\n\t\t\"\"\"", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "used", "=", "set", "(", ")", "# track used labels", "\n", "drawn", "=", "dict", "(", ")", "# track drawn part of each curve... useful for concat MLE to NCE", "\n", "alpha", "=", "0.2", "\n", "linewidth", "=", "0.5", "\n", "linewidth2", "=", "1.0", "\n", "\n", "for", "method_m_b", ",", "info", "in", "curve_with_band", ".", "items", "(", ")", ":", "\n", "\n", "\t\t\t", "method", "=", "info", "[", "'method'", "]", "\n", "m", "=", "info", "[", "'m'", "]", "\n", "batch", "=", "info", "[", "'batch'", "]", "\n", "color", "=", "info", "[", "'color'", "]", "\n", "label", "=", "info", "[", "'label'", "]", "\n", "annotate", "=", "info", "[", "'annotate'", "]", "\n", "\"\"\"\n\t\t\tplot \n\t\t\t\"\"\"", "\n", "x", ",", "y", ",", "y_min", ",", "y_max", "=", "info", "[", "'x'", "]", ",", "info", "[", "'y'", "]", ",", "info", "[", "'y_min'", "]", ",", "info", "[", "'y_max'", "]", "\n", "#print(f\"\\n\\n check len\")", "\n", "#for xlist in info['x']: ", "\n", "#\tprint(f\"len = {len(xlist)}\")", "\n", "plt", ".", "plot", "(", "\n", "x", ",", "y", ",", "ls", "=", "'-'", ",", "lw", "=", "linewidth", ",", "\n", "color", "=", "color", ",", "label", "=", "label", "if", "label", "not", "in", "used", "else", "''", ")", "\n", "plt", ".", "fill_between", "(", "\n", "x", ",", "y_min", ",", "y_max", ",", "color", "=", "color", ",", "alpha", "=", "alpha", ")", "\n", "used", ".", "add", "(", "label", ")", "# track used labels", "\n", "\n", "extrapolated", "=", "False", "\n", "if", "len", "(", "x", ")", ">", "0", "and", "x", "[", "-", "1", "]", "<", "x_high", ":", "\n", "\t\t\t\t", "extrapolated", "=", "True", "\n", "\"\"\"\n\t\t\t\textrapolate to the end\n\t\t\t\t\"\"\"", "\n", "x_extra", "=", "numpy", ".", "linspace", "(", "x", "[", "-", "1", "]", ",", "x_high", ",", "inter_num", ")", "\n", "y_extra", "=", "numpy", ".", "linspace", "(", "max", "(", "y", ")", ",", "max", "(", "y", ")", ",", "inter_num", ")", "\n", "y_min_extra", "=", "numpy", ".", "linspace", "(", "max", "(", "y_min", ")", ",", "max", "(", "y_min", ")", ",", "inter_num", ")", "\n", "y_max_extra", "=", "numpy", ".", "linspace", "(", "max", "(", "y_max", ")", ",", "max", "(", "y_max", ")", ",", "inter_num", ")", "\n", "plt", ".", "plot", "(", "x_extra", ",", "y_extra", ",", "ls", "=", "'-'", ",", "lw", "=", "linewidth", ",", "color", "=", "color", ")", "\n", "plt", ".", "fill_between", "(", "x_extra", ",", "y_min_extra", ",", "y_max_extra", ",", "color", "=", "color", ",", "alpha", "=", "alpha", ")", "\n", "", "\"\"\"\n\t\t\tconcat MLE : choose where curve stops increasing ... \n\t\t\tif it keeps increasing within this window, then choose boundary\n\t\t\ta good place to concat MLE curve is where NCE started converging\n\t\t\t\"\"\"", "\n", "i", "=", "0", "\n", "i_cat", "=", "None", "\n", "while", "i_cat", "is", "None", "and", "i", "<", "len", "(", "x", ")", ":", "\n", "\t\t\t\t", "i_giveup", "=", "i", "+", "self", ".", "args", "[", "'WaitPeriod'", "]", "*", "inter_num", "\n", "if", "i_giveup", ">=", "len", "(", "x", ")", ":", "\n", "\t\t\t\t\t", "i_giveup", "=", "len", "(", "x", ")", "-", "1", "\n", "", "if", "abs", "(", "y", "[", "i", "]", "-", "y", "[", "i_giveup", "]", ")", "<", "1e-6", ":", "\n", "\t\t\t\t\t", "i_cat", "=", "i", "\n", "", "i", "+=", "1", "\n", "", "if", "i_cat", "is", "None", ":", "\n", "\t\t\t\t", "i_cat", "=", "len", "(", "x", ")", "-", "1", "\n", "", "\"\"\"\n\t\t\tannotate : manually define how to place annotations\n\t\t\t\"\"\"", "\n", "x_ann", ",", "y_ann", "=", "list", "(", "x", ")", ",", "list", "(", "y", ")", "\n", "if", "extrapolated", ":", "\n", "\t\t\t\t", "inter_ann", "=", "int", "(", "len", "(", "x", ")", "*", "(", "x_high", "-", "x", "[", "-", "1", "]", ")", "/", "(", "x", "[", "-", "1", "]", "-", "x", "[", "0", "]", ")", ")", "\n", "x_ann", "+=", "list", "(", "numpy", ".", "linspace", "(", "x", "[", "-", "1", "]", ",", "x_high", ",", "inter_ann", ")", ")", "\n", "y_ann", "+=", "list", "(", "numpy", ".", "linspace", "(", "max", "(", "y", ")", ",", "max", "(", "y", ")", ",", "inter_ann", ")", ")", "\n", "", "if", "len", "(", "x", ")", ">", "0", ":", "\n", "\t\t\t\t", "x_idx", ",", "y_idx", "=", "self", ".", "find_where_to_annotate", "(", "x_ann", ",", "y_ann", ",", "method_m_b", ")", "\n", "plt", ".", "text", "(", "\n", "x_ann", "[", "x_idx", "]", ",", "y_ann", "[", "y_idx", "]", ",", "annotate", ",", "color", "=", "'black'", ",", "\n", "fontsize", "=", "self", ".", "args", "[", "'TextSize'", "]", ",", "\n", "horizontalalignment", "=", "'center'", ",", "\n", "verticalalignment", "=", "'center'", "\n", ")", "\n", "# OLD way: annotate where we concate MLE curve", "\n", "#plt.text(x[i_cat], y[i_cat], annotate, color='black')", "\n", "", "\"\"\"\n\t\t\ttrack drawn part of this curve\n\t\t\t\"\"\"", "\n", "drawn", "[", "f'{method}||{m}||{annotate}'", "]", "=", "{", "\n", "'xy'", ":", "[", "x", ",", "y", ",", "y_min", ",", "y_max", "]", ",", "\n", "'converge'", ":", "i_cat", "\n", "}", "\n", "\n", "", "\"\"\"\n\t\ttrack the highest value \n\t\tto check if we need to concat NCE curves\n\t\t\"\"\"", "\n", "highest_method", "=", "None", "\n", "highest_y", "=", "-", "numpy", ".", "inf", "\n", "for", "method_m_b", "in", "highest", ":", "\n", "\t\t\t", "if", "numpy", ".", "mean", "(", "highest", "[", "method_m_b", "]", ")", ">", "highest_y", ":", "\n", "\t\t\t\t", "highest_y", "=", "numpy", ".", "mean", "(", "highest", "[", "method_m_b", "]", ")", "\n", "highest_method", "=", "method", "\n", "", "", "\"\"\"\n\t\tconcat NCE curves with MLE curves : to show the hybrid training strategies \n\t\t\"\"\"", "\n", "if", "highest_method", "==", "'mle'", "and", "self", ".", "args", "[", "'ContinualTrain'", "]", ":", "\n", "\t\t\t", "label", "=", "'NCE->MLE'", "\n", "\"\"\"\n\t\t\twhen NCE hasn't improved yet for several rounds of evaluation\n\t\t\t\"\"\"", "\n", "assert", "x_cat", "is", "not", "None", "and", "y_cat", "is", "not", "None", ",", "f\"no MLE with rho={self.args['HybridMultiplier']}?!\"", "\n", "for", "method_m_annotate", "in", "drawn", ":", "\n", "\t\t\t\t", "method", ",", "m", ",", "annotate", "=", "method_m_annotate", ".", "split", "(", "'||'", ")", "\n", "x", ",", "y", ",", "y_min", ",", "y_max", "=", "drawn", "[", "method_m_annotate", "]", "[", "'xy'", "]", "\n", "if", "'nce'", "in", "method", "and", "len", "(", "x", ")", ">", "0", ":", "\n", "\t\t\t\t\t", "\"\"\"\n\t\t\t\t\tfor this curve, we find its steady point\n\t\t\t\t\tif no steady point (i.e., keep increasing), then its right most point\n\t\t\t\t\tif this point is at right boundary -> ignore it \n\t\t\t\t\tif not, concat MLE curve to it\n\t\t\t\t\t\"\"\"", "\n", "\"\"\"\n\t\t\t\t\tthen what's a steady point? \n\t\t\t\t\tit is where training stops improving \n\t\t\t\t\tprecisely, not improving fast enough, \n\t\t\t\t\tit may be wavy, but not worth to wait longer cuz it is too slow...\n\t\t\t\t\ttechnically, it is the first point where \n\t\t\t\t\twaiting for the wait period doesn't really help!\n\t\t\t\t\t\"\"\"", "\n", "i_cat", "=", "drawn", "[", "method_m_annotate", "]", "[", "'converge'", "]", "\n", "y_converge", "=", "y", "[", "i_cat", "]", "\n", "if", "x", "[", "i_cat", "]", "<", "x_high", ":", "\n", "\t\t\t\t\t\t", "\"\"\"\n\t\t\t\t\t\tstill within show range \n\t\t\t\t\t\tfind the concat part of MLE\n\t\t\t\t\t\t1. find y in MLE that matches y_max \n\t\t\t\t\t\t2. find its index i \n\t\t\t\t\t\t3. adjust x values to shift segment\n\t\t\t\t\t\t\"\"\"", "\n", "y_keep", "=", "y_cat", ">=", "y_converge", "\n", "y_seg", "=", "y_cat", "[", "y_keep", "]", "\n", "y_min_seg", "=", "y_min_cat", "[", "y_keep", "]", "\n", "y_max_seq", "=", "y_max_cat", "[", "y_keep", "]", "\n", "x_seg", "=", "x_cat", "[", "y_keep", "]", "\n", "x_seg", "-=", "x_seg", "[", "0", "]", "\n", "x_seg", "+=", "x", "[", "i_cat", "]", "\n", "x_keep", "=", "x_seg", "<=", "x_high", "\n", "x_seg", "=", "x_seg", "[", "x_keep", "]", "\n", "y_seg", "=", "y_seg", "[", "x_keep", "]", "\n", "y_min_seg", "=", "y_min_seg", "[", "x_keep", "]", "\n", "y_max_seq", "=", "y_max_seq", "[", "x_keep", "]", "\n", "\n", "plt", ".", "plot", "(", "\n", "x_seg", ",", "y_seg", ",", "ls", "=", "'-'", ",", "lw", "=", "linewidth", ",", "\n", "color", "=", "self", ".", "color", "[", "'hybrid'", "]", ",", "alpha", "=", "1.0", ",", "\n", "label", "=", "label", "if", "label", "not", "in", "used", "else", "''", "\n", ")", "\n", "plt", ".", "fill_between", "(", "\n", "x_seg", ",", "y_min_seg", ",", "y_max_seq", ",", "\n", "color", "=", "self", ".", "color", "[", "'hybrid'", "]", ",", "alpha", "=", "alpha", "\n", ")", "\n", "used", ".", "add", "(", "label", ")", "# track used labels", "\n", "", "", "", "", "\"\"\"\n\t\tplot the highest value : dashed line - - - \n\t\tcolor indicates achieved by which method \n\t\tthis has to be done in the end s.t. x_min and x_max are final\n\t\t\"\"\"", "\n", "#highest_color = self.color[highest_method]", "\n", "highest_color", "=", "self", ".", "color", "[", "'high'", "]", "\n", "x_min", ",", "x_max", "=", "plt", ".", "xlim", "(", ")", "\n", "plt", ".", "hlines", "(", "\n", "highest_y", ",", "x_min", ",", "x_max", ",", "\n", "colors", "=", "highest_color", ",", "linestyles", "=", "'dashed'", ",", "linewidth", "=", "linewidth2", ")", "\n", "\"\"\"\n\t\tlabel and legend\n\t\t\"\"\"", "\n", "\"\"\"\n\t\tcrop out-of-view curves\n\t\t\"\"\"", "\n", "bottom", ",", "_", "=", "plt", ".", "ylim", "(", ")", "\n", "if", "bottom", "<", "y_low", ":", "\n", "\t\t\t", "plt", ".", "ylim", "(", "bottom", "=", "y_low", ")", "\n", "", "plt", ".", "xlabel", "(", "xlabel", ",", "fontsize", "=", "self", ".", "args", "[", "'LabelSize'", "]", ")", "\n", "plt", ".", "ylabel", "(", "ylabel", ",", "fontsize", "=", "self", ".", "args", "[", "'LabelSize'", "]", ")", "\n", "plt", ".", "xticks", "(", "fontsize", "=", "self", ".", "args", "[", "'TickSize'", "]", ")", "\n", "plt", ".", "yticks", "(", "fontsize", "=", "self", ".", "args", "[", "'TickSize'", "]", ",", "rotation", "=", "0", ")", "\n", "leg", "=", "plt", ".", "legend", "(", "\n", "loc", "=", "self", ".", "args", "[", "'Location'", "]", ",", "\n", "prop", "=", "{", "'size'", ":", "self", ".", "args", "[", "'LegendSize'", "]", "}", "\n", ")", "# or 'best'?", "\n", "for", "legobj", "in", "leg", ".", "legendHandles", ":", "\n", "\t\t\t", "legobj", ".", "set_linewidth", "(", "4.0", ")", "\n", "legobj", ".", "set_alpha", "(", "0.5", ")", "\n", "", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "args", "[", "'PathSave'", "]", ",", "fig_name", ")", ",", "\n", "format", "=", "'pdf'", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.get_prefix": [[453, 464], ["Exception"], "methods", ["None"], ["", "def", "get_prefix", "(", "self", ",", "method", ")", ":", "\n", "\t\t", "if", "method", "==", "'mle'", ":", "\n", "\t\t\t", "return", "'MLE'", "\n", "", "elif", "method", "==", "'lse'", ":", "\n", "\t\t\t", "return", "'LSE'", "\n", "", "elif", "method", "==", "'nce_binary'", ":", "\n", "\t\t\t", "return", "'b-NCE'", "\n", "", "elif", "'nce'", "in", "method", ":", "\n", "\t\t\t", "return", "'NCE'", "\n", "", "else", ":", "\n", "\t\t\t", "raise", "Exception", "(", "f'Unknown method : {method}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.get_mi": [[465, 477], ["Exception"], "methods", ["None"], ["", "", "def", "get_mi", "(", "self", ",", "method", ",", "x", ")", ":", "\n", "# items in x : in order of : mc_i, np_i, nt_i", "\n", "\t\t", "if", "method", "==", "'mle'", ":", "\n", "\t\t\t", "return", "x", "[", "0", "]", "\n", "", "elif", "method", "==", "'lse'", ":", "\n", "\t\t\t", "return", "x", "[", "0", "]", "\n", "", "elif", "method", "==", "'nce_frac'", "or", "method", "==", "'nce_async'", "or", "method", "==", "'nce_binary'", ":", "\n", "\t\t\t", "return", "x", "[", "1", "]", "\n", "", "elif", "method", "==", "'nce_sync'", ":", "\n", "\t\t\t", "return", "x", "[", "2", "]", "\n", "", "else", ":", "\n", "\t\t\t", "raise", "Exception", "(", "f'Unknown method : {method}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.get_annotate": [[478, 491], ["Exception"], "methods", ["None"], ["", "", "def", "get_annotate", "(", "self", ",", "method", ",", "m", ",", "batch", ")", ":", "\n", "\t\t", "rst", "=", "''", "\n", "if", "method", "==", "'mle'", ":", "\n", "\t\t\t", "rst", "+=", "f'\\u03C1={m}'", "\n", "", "elif", "method", "==", "'lse'", ":", "\n", "\t\t\t", "rst", "+=", "f'\\u03C1={m}'", "\n", "", "elif", "method", "==", "'nce_frac'", "or", "method", "==", "'nce_async'", "or", "method", "==", "'nce_sync'", "or", "method", "==", "'nce_binary'", ":", "\n", "\t\t\t", "rst", "+=", "f'M={m}'", "\n", "", "else", ":", "\n", "\t\t\t", "raise", "Exception", "(", "f'Unknown method : {method}'", ")", "\n", "", "if", "self", ".", "args", "[", "'UseBatch'", "]", ":", "\n", "\t\t\t", "rst", "+=", "f'\\nB={batch}'", "\n", "", "return", "rst", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.find_where_to_annotate": [[492, 497], ["int", "len", "len", "len"], "methods", ["None"], ["", "def", "find_where_to_annotate", "(", "self", ",", "x", ",", "y", ",", "method_m_b", ")", ":", "\n", "\t\t", "idx", "=", "int", "(", "len", "(", "x", ")", "/", "self", ".", "ann", "[", "method_m_b", "]", ")", "\n", "if", "idx", ">=", "len", "(", "x", ")", ":", "\n", "\t\t\t", "idx", "=", "len", "(", "x", ")", "-", "1", "\n", "", "return", "idx", ",", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.array": [[498, 514], ["enumerate", "numpy.array", "len", "len", "len", "numpy.zeros", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.eval.draw.Drawer.array"], ["", "def", "array", "(", "self", ",", "x", ")", ":", "\n", "# make array with a list of vectors with diff lens", "\n", "\t\t", "maxlen", "=", "-", "1", "\n", "maxy", "=", "None", "\n", "for", "y", "in", "x", ":", "\n", "\t\t\t", "if", "len", "(", "y", ")", ">", "maxlen", ":", "\n", "\t\t\t\t", "maxlen", "=", "len", "(", "y", ")", "\n", "maxy", "=", "y", "\n", "", "", "for", "i", ",", "y", "in", "enumerate", "(", "x", ")", ":", "\n", "\t\t\t", "if", "len", "(", "y", ")", "<", "maxlen", ":", "\n", "\t\t\t\t", "newy", "=", "numpy", ".", "zeros", "(", "maxlen", ")", "\n", "newy", "[", ":", "len", "(", "y", ")", "]", "=", "y", "[", ":", "]", "\n", "dy", "=", "y", "[", "-", "1", "]", "-", "maxy", "[", "len", "(", "y", ")", "-", "1", "]", "\n", "newy", "[", "len", "(", "y", ")", ":", "]", "=", "maxy", "[", "len", "(", "y", ")", ":", "]", "+", "dy", "\n", "x", "[", "i", "]", "=", "newy", "\n", "", "", "return", "numpy", ".", "array", "(", "x", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.cont_time_cell.CTLSTMCell.__init__": [[8, 16], ["torch.Module.__init__", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_dim", ",", "device", "=", "None", ")", ":", "\n", "        ", "super", "(", "CTLSTMCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "device", "=", "device", "or", "'cpu'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "hidden_dim", "*", "2", ",", "hidden_dim", "*", "7", ",", "bias", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.cont_time_cell.CTLSTMCell.forward": [[18, 43], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "cont_time_cell.CTLSTMCell.linear", "cont_time_cell.CTLSTMCell.chunk", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.softplus", "torch.softplus", "torch.softplus", "rnn_input.dim"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "rnn_input", ",", "hidden_t_i_minus", ",", "cell_t_i_minus", ",", "cell_bar_im1", ")", ":", "\n", "\n", "        ", "dim_of_hidden", "=", "rnn_input", ".", "dim", "(", ")", "-", "1", "\n", "\n", "input_i", "=", "torch", ".", "cat", "(", "(", "rnn_input", ",", "hidden_t_i_minus", ")", ",", "dim", "=", "dim_of_hidden", ")", "\n", "output_i", "=", "self", ".", "linear", "(", "input_i", ")", "\n", "\n", "gate_input", ",", "gate_forget", ",", "gate_output", ",", "gate_pre_c", ",", "gate_input_bar", ",", "gate_forget_bar", ",", "gate_decay", "=", "output_i", ".", "chunk", "(", "\n", "7", ",", "dim_of_hidden", ")", "\n", "\n", "gate_input", "=", "torch", ".", "sigmoid", "(", "gate_input", ")", "\n", "gate_forget", "=", "torch", ".", "sigmoid", "(", "gate_forget", ")", "\n", "gate_output", "=", "torch", ".", "sigmoid", "(", "gate_output", ")", "\n", "gate_pre_c", "=", "torch", ".", "tanh", "(", "gate_pre_c", ")", "\n", "gate_input_bar", "=", "torch", ".", "sigmoid", "(", "gate_input_bar", ")", "\n", "gate_forget_bar", "=", "torch", ".", "sigmoid", "(", "gate_forget_bar", ")", "\n", "gate_decay", "=", "F", ".", "softplus", "(", "gate_decay", ",", "1.0", ")", "# decay scale is always 1.0", "\n", "\n", "cell_i", "=", "gate_forget", "*", "cell_t_i_minus", "+", "gate_input", "*", "gate_pre_c", "\n", "cell_bar_i", "=", "gate_forget_bar", "*", "cell_bar_im1", "+", "gate_input_bar", "*", "gate_pre_c", "\n", "\n", "return", "cell_i", ",", "cell_bar_i", ",", "gate_decay", ",", "gate_output", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.cont_time_cell.CTLSTMCell.decay": [[44, 58], ["dtime.unsqueeze().expand_as.unsqueeze().expand_as.dim", "cell_i.dim", "dtime.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze().expand_as", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "dtime.unsqueeze().expand_as.unsqueeze().expand_as.unsqueeze", "cell_i.dim"], "methods", ["None"], ["", "def", "decay", "(", "self", ",", "cell_i", ",", "cell_bar_i", ",", "gate_decay", ",", "gate_output", ",", "dtime", ")", ":", "\n", "# no need to consider extra_dim_particle here", "\n", "# cuz this function is applicable to any # of dims", "\n", "        ", "if", "dtime", ".", "dim", "(", ")", "<", "cell_i", ".", "dim", "(", ")", ":", "\n", "# e.g. ", "\n", "# cell_i : B x T x D ", "\n", "# dtime : B x T ", "\n", "            ", "dtime", "=", "dtime", ".", "unsqueeze", "(", "cell_i", ".", "dim", "(", ")", "-", "1", ")", ".", "expand_as", "(", "cell_i", ")", "\n", "\n", "", "cell_t_ip1_minus", "=", "cell_bar_i", "+", "(", "cell_i", "-", "cell_bar_i", ")", "*", "torch", ".", "exp", "(", "\n", "-", "gate_decay", "*", "dtime", ")", "\n", "hidden_t_ip1_minus", "=", "gate_output", "*", "torch", ".", "tanh", "(", "cell_t_ip1_minus", ")", "\n", "\n", "return", "cell_t_ip1_minus", ",", "hidden_t_ip1_minus", "", "", "", ""]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.__init__": [[21, 69], ["torch.Module.__init__", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.Embedding", "torch.Embedding", "torch.Embedding", "ncempp.models.cont_time_cell.CTLSTMCell", "ncempp.models.layers.LinearEmbedding", "ncempp.models.layers.CF", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "numpy.finfo", "numpy.finfo"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.__init__"], ["def", "__init__", "(", "self", ",", "*", ",", "\n", "coarse_num", ",", "event_num", ",", "fine_to_coarse", ",", "\n", "hidden_dim", "=", "8", ",", "beta", "=", "1.0", ",", "noise_mode", "=", "'multinomial'", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "super", "(", "GNHP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\"\"\"\n\t\tinput \n\t\t\tcoarse_num : # of coarse event types \n\t\t\tevent_num : # of fine event types  \n\t\t\tfine_to_coarse : dictionary k -> c\n\t\t\tnoise_mode : how to sample noise types when used as noise dist q\n\t\t\"\"\"", "\n", "\n", "device", "=", "device", "or", "'cpu'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "self", ".", "eps", "=", "np", ".", "finfo", "(", "float", ")", ".", "eps", "\n", "self", ".", "max", "=", "np", ".", "finfo", "(", "float", ")", ".", "max", "\n", "self", ".", "noise_mode", "=", "noise_mode", "\n", "\n", "self", ".", "coarse_num", "=", "coarse_num", "# # of coarse event types ", "\n", "self", ".", "event_num", "=", "event_num", "# # of fine event types ", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "beta", "=", "beta", "\n", "\n", "self", ".", "idx_BOS", "=", "self", ".", "event_num", "\n", "self", ".", "idx_EOS", "=", "self", ".", "event_num", "+", "1", "\n", "self", ".", "idx_PAD", "=", "self", ".", "event_num", "+", "2", "\n", "\n", "self", ".", "in_emb", "=", "nn", ".", "Embedding", "(", "\n", "self", ".", "event_num", "+", "3", ",", "self", ".", "hidden_dim", ")", "\n", "self", ".", "rnn_cell", "=", "CTLSTMCell", "(", "\n", "self", ".", "hidden_dim", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "out_emb", "=", "LinearEmbedding", "(", "\n", "num_embeddings", "=", "self", ".", "coarse_num", ",", "\n", "embedding_dim", "=", "self", ".", "hidden_dim", ",", "\n", "device", "=", "self", ".", "device", "\n", ")", "\n", "self", ".", "coarse_to_fine", "=", "CF", "(", "\n", "coarse_num", "=", "coarse_num", ",", "event_num", "=", "event_num", ",", "\n", "fine_to_coarse", "=", "fine_to_coarse", ",", "\n", "device", "=", "self", ".", "device", "\n", ")", "\n", "\n", "self", ".", "init_h", "=", "torch", ".", "zeros", "(", "\n", "size", "=", "[", "hidden_dim", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "init_c", "=", "torch", ".", "zeros", "(", "\n", "size", "=", "[", "hidden_dim", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "init_cb", "=", "torch", ".", "zeros", "(", "\n", "size", "=", "[", "hidden_dim", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.cuda": [[71, 76], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "super().cuda"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["", "def", "cuda", "(", "self", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "device", "=", "device", "or", "'cuda:0'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "assert", "self", ".", "device", ".", "type", "==", "'cuda'", "\n", "super", "(", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.cpu": [[77, 80], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "super().cuda"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["", "def", "cpu", "(", "self", ")", ":", "\n", "\t\t", "self", ".", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "super", "(", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.get_inten_num": [[81, 86], ["None"], "methods", ["None"], ["", "def", "get_inten_num", "(", "self", ")", ":", "\n", "\t\t", "\"\"\"\n\t\treturn # of intensities to be computed in this model\n\t\t\"\"\"", "\n", "return", "self", ".", "coarse_num", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.get_cells_gates_states": [[87, 147], ["event_tensor.size", "nhp.GNHP.init_c.unsqueeze().expand", "nhp.GNHP.init_cb.unsqueeze().expand", "nhp.GNHP.init_h.unsqueeze().expand", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "nhp.GNHP.in_emb", "nhp.GNHP.rnn_cell", "nhp.GNHP.rnn_cell.decay", "nhp.GNHP.rnn_cell.decay", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "nhp.GNHP.init_c.unsqueeze", "nhp.GNHP.init_cb.unsqueeze", "nhp.GNHP.init_h.unsqueeze", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "dtime_i.size"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.cont_time_cell.CTLSTMCell.decay", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.cont_time_cell.CTLSTMCell.decay"], ["", "def", "get_cells_gates_states", "(", "self", ",", "event_tensor", ",", "dtime_tensor", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tinput \n\t\t\tevent_tensor [B x T+2] : tensor of event types \n\t\t\tdtime_tensor [B x T+2] : tensor of dtimes\n\t\treturn\n\t\t\tcells, gates, and states [B x T+1]\n\t\t\"\"\"", "\n", "batch_size", ",", "T_plus_2", "=", "event_tensor", ".", "size", "(", ")", "\n", "cell_t_i_minus", "=", "self", ".", "init_c", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "\n", "batch_size", ",", "self", ".", "hidden_dim", ")", "\n", "cell_bar_im1", "=", "self", ".", "init_cb", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "\n", "batch_size", ",", "self", ".", "hidden_dim", ")", "\n", "hidden_t_i_minus", "=", "self", ".", "init_h", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "\n", "batch_size", ",", "self", ".", "hidden_dim", ")", "\n", "\n", "all_cell", ",", "all_cell_bar", "=", "[", "]", ",", "[", "]", "\n", "all_gate_output", ",", "all_gate_decay", "=", "[", "]", ",", "[", "]", "\n", "all_hidden", "=", "[", "]", "\n", "all_hidden_after_update", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "T_plus_2", "-", "1", ")", ":", "\n", "# only T+1 events update LSTM ", "\n", "# BOS, k1t1, ..., kItI", "\n", "\t\t\t", "emb_i", "=", "self", ".", "in_emb", "(", "event_tensor", "[", ":", ",", "i", "]", ")", "\n", "dtime_i", "=", "dtime_tensor", "[", ":", ",", "i", "+", "1", "]", "# need to carefully check here", "\n", "\n", "cell_i", ",", "cell_bar_i", ",", "gate_decay_i", ",", "gate_output_i", "=", "self", ".", "rnn_cell", "(", "\n", "emb_i", ",", "hidden_t_i_minus", ",", "cell_t_i_minus", ",", "cell_bar_im1", "\n", ")", "\n", "_", ",", "hidden_t_i_plus", "=", "self", ".", "rnn_cell", ".", "decay", "(", "\n", "cell_i", ",", "cell_bar_i", ",", "gate_decay_i", ",", "gate_output_i", ",", "\n", "torch", ".", "zeros", "(", "dtime_i", ".", "size", "(", ")", ",", "device", "=", "self", ".", "device", ")", "\n", ")", "\n", "cell_t_ip1_minus", ",", "hidden_t_ip1_minus", "=", "self", ".", "rnn_cell", ".", "decay", "(", "\n", "cell_i", ",", "cell_bar_i", ",", "gate_decay_i", ",", "gate_output_i", ",", "\n", "dtime_i", "\n", ")", "\n", "all_cell", ".", "append", "(", "cell_i", ")", "\n", "all_cell_bar", ".", "append", "(", "cell_bar_i", ")", "\n", "all_gate_decay", ".", "append", "(", "gate_decay_i", ")", "\n", "all_gate_output", ".", "append", "(", "gate_output_i", ")", "\n", "all_hidden", ".", "append", "(", "hidden_t_ip1_minus", ")", "\n", "all_hidden_after_update", ".", "append", "(", "hidden_t_i_plus", ")", "\n", "cell_t_i_minus", "=", "cell_t_ip1_minus", "\n", "cell_bar_im1", "=", "cell_bar_i", "\n", "hidden_t_i_minus", "=", "hidden_t_ip1_minus", "\n", "\n", "# these tensors shape : batch_size, T+1, hidden_dim", "\n", "# cells and gates right after BOS, 1st event, ..., I-th event", "\n", "# hidden right before 1st event, ..., I-th event, End event (PAD)", "\n", "", "all_cell", "=", "torch", ".", "stack", "(", "all_cell", ",", "dim", "=", "1", ")", "\n", "all_cell_bar", "=", "torch", ".", "stack", "(", "all_cell_bar", ",", "dim", "=", "1", ")", "\n", "all_gate_decay", "=", "torch", ".", "stack", "(", "all_gate_decay", ",", "dim", "=", "1", ")", "\n", "all_gate_output", "=", "torch", ".", "stack", "(", "all_gate_output", ",", "dim", "=", "1", ")", "\n", "all_hidden", "=", "torch", ".", "stack", "(", "all_hidden", ",", "dim", "=", "1", ")", "\n", "all_hidden_after_update", "=", "torch", ".", "stack", "(", "all_hidden_after_update", ",", "dim", "=", "1", ")", "\n", "#assert all_gate_decay.data.cpu().numpy().all() >= 0.0, \"Decay > 0\"", "\n", "return", "all_cell", ",", "all_cell_bar", ",", "all_gate_decay", ",", "all_gate_output", ",", "all_hidden", ",", "all_hidden_after_update", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.get_target": [[148, 159], ["event_tensor.size", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "event_tensor[].clone().detach", "event_tensor[].clone"], "methods", ["None"], ["", "def", "get_target", "(", "self", ",", "event_tensor", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tmake target variables and masks \n\t\ti.e., set >= event_num to 0, also mask them out \n\t\t\"\"\"", "\n", "batch_size", ",", "T_plus_2", "=", "event_tensor", ".", "size", "(", ")", "\n", "mask", "=", "torch", ".", "ones", "(", "(", "batch_size", ",", "T_plus_2", "-", "1", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "target_data", "=", "event_tensor", "[", ":", ",", "1", ":", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "mask", "[", "target_data", ">=", "self", ".", "event_num", "]", "=", "0.0", "\n", "target_data", "[", "target_data", ">=", "self", ".", "event_num", "]", "=", "0", "# PAD to be 0", "\n", "return", "target_data", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.get_intensities_given_types": [[160, 189], ["nhp.GNHP.coarse_to_fine.get_coarse_for_given_fine", "nhp.GNHP.out_emb.get_embeddings_given_types", "nhp.GNHP.rnn_cell.decay", "torch.softplus", "torch.softplus", "torch.softplus", "nhp.GNHP.coarse_to_fine.get_fine_probs_given_types", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "all_h_t.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_coarse_for_given_fine", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.LinearEmbedding.get_embeddings_given_types", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.cont_time_cell.CTLSTMCell.decay", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_fine_probs_given_types"], ["", "def", "get_intensities_given_types", "(", "self", ",", "\n", "all_cell", ",", "all_cell_bar", ",", "all_gate_decay", ",", "all_gate_output", ",", "\n", "event_tensor", ",", "dtime_tensor", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tget intensities given types \n\t\te.g., for MLE, compute intensities for the sum term in log-likelihood\n\t\te.g., for NCE, compute intensities for times drawn from p or q \n\t\tnote that these cells, gates, event types and dtimes \n\t\tmay be either at the oberservation times when actual events happened \n\t\tor at the sampled times \n\t\te.g., for MLE, they are sampled times for Monte-Carlo approx \n\t\te.g., for NCE, they are sampled times from noise dist q \n\t\t\"\"\"", "\n", "coarse_types", "=", "self", ".", "coarse_to_fine", ".", "get_coarse_for_given_fine", "(", "event_tensor", ")", "\n", "# batch_size x T+1 x N (N can be 1)", "\n", "coarse_embs", "=", "self", ".", "out_emb", ".", "get_embeddings_given_types", "(", "coarse_types", ")", "\n", "# batch_size x T+1 x N x D", "\n", "_", ",", "all_h_t", "=", "self", ".", "rnn_cell", ".", "decay", "(", "\n", "all_cell", ",", "all_cell_bar", ",", "all_gate_decay", ",", "all_gate_output", ",", "dtime_tensor", ")", "\n", "# batch_size x T+1 x D", "\n", "coarse_intensities", "=", "F", ".", "softplus", "(", "\n", "torch", ".", "sum", "(", "\n", "coarse_embs", "*", "all_h_t", ".", "unsqueeze", "(", "-", "2", ")", ",", "dim", "=", "-", "1", "\n", ")", ",", "beta", "=", "self", ".", "beta", "\n", ")", "# batch_size x T+1 x N (N can be 1)", "\n", "fine_intensities", "=", "self", ".", "coarse_to_fine", ".", "get_fine_probs_given_types", "(", "\n", "coarse_intensities", ",", "coarse_types", ",", "event_tensor", ")", "\n", "# batch_size x T+1 x N (N can be 1)", "\n", "return", "fine_intensities", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.get_intensities_all_coarse_types": [[190, 209], ["nhp.GNHP.out_emb.get_embeddings_all_types", "nhp.GNHP.rnn_cell.decay", "torch.softplus", "torch.softplus", "torch.softplus", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "nhp.GNHP.t"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.LinearEmbedding.get_embeddings_all_types", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.cont_time_cell.CTLSTMCell.decay"], ["", "def", "get_intensities_all_coarse_types", "(", "self", ",", "\n", "all_cell", ",", "all_cell_bar", ",", "all_gate_decay", ",", "all_gate_output", ",", "\n", "dtime_tensor", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tget intensities for all coarse types \n\t\te.g., compute total intensity in thinning algorithm\n\t\ttotal_coarse_intensity == total_fine_intensity\n\t\tNOTE : although comments use 3D as example \n\t\tthe coce is actually robust to any # of dimensions\n\t\t\"\"\"", "\n", "coarse_embs", "=", "self", ".", "out_emb", ".", "get_embeddings_all_types", "(", ")", "\n", "# C x D ", "\n", "_", ",", "all_h_t", "=", "self", ".", "rnn_cell", ".", "decay", "(", "\n", "all_cell", ",", "all_cell_bar", ",", "all_gate_decay", ",", "all_gate_output", ",", "dtime_tensor", ")", "\n", "# batch_size x T+1 x D ", "\n", "coarse_intensities", "=", "F", ".", "softplus", "(", "\n", "torch", ".", "matmul", "(", "all_h_t", ",", "coarse_embs", ".", "t", "(", ")", ")", ",", "beta", "=", "self", ".", "beta", ")", "\n", "# batch_size x T+1 x C ", "\n", "return", "coarse_intensities", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.get_intensities_all_fine_types": [[210, 226], ["nhp.GNHP.get_intensities_all_coarse_types", "nhp.GNHP.coarse_to_fine.get_fine_probs_all_types"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_intensities_all_coarse_types", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_fine_probs_all_types"], ["", "def", "get_intensities_all_fine_types", "(", "self", ",", "\n", "all_cell", ",", "all_cell_bar", ",", "all_gate_decay", ",", "all_gate_output", ",", "\n", "dtime_tensor", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tget intensities for all types \n\t\te.g., compute all intensities for integral term in log-likelihood\n\t\tnote that these cells, gates, and dtimes \n\t\tmay be either at the oberservation times when actual events happened \n\t\tor at the sampled times \n\t\te.g., for MLE, they are sampled times for Monte-Carlo approx \n\t\te.g., for NCE, they are sampled times from noise dist q \n\t\t\"\"\"", "\n", "coarse_intensities", "=", "self", ".", "get_intensities_all_coarse_types", "(", "\n", "all_cell", ",", "all_cell_bar", ",", "all_gate_decay", ",", "all_gate_output", ",", "dtime_tensor", ")", "\n", "# return : batch_size x T+1 x K", "\n", "return", "self", ".", "coarse_to_fine", ".", "get_fine_probs_all_types", "(", "coarse_intensities", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.get_mc_samples": [[227, 310], ["all_cell.size", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.ones.uniform_", "torch.ones.uniform_", "torch.ones.uniform_", "duration_tensor.unsqueeze", "fallin[].float", "mask_tensor[].unsqueeze", "sampled_dt.size", "all_cell[].unsqueeze().expand", "all_cell_bar[].unsqueeze().expand", "all_gate_decay[].unsqueeze().expand", "all_gate_output[].unsqueeze().expand", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "fallin.sum", "torch.zeros.unsqueeze", "torch.zeros.unsqueeze", "torch.zeros.unsqueeze", "torch.zeros.unsqueeze", "torch.zeros.unsqueeze", "torch.zeros.unsqueeze", "curr_time.unsqueeze", "all_cell[].unsqueeze", "all_cell_bar[].unsqueeze", "all_gate_decay[].unsqueeze", "all_gate_output[].unsqueeze"], "methods", ["None"], ["", "def", "get_mc_samples", "(", "self", ",", "\n", "all_cell", ",", "all_cell_bar", ",", "all_gate_decay", ",", "all_gate_output", ",", "dtime_tensor", ",", "\n", "mc_sample_num_tensor", ",", "duration_tensor", ",", "mask_tensor", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tfor MLE, sample time points for each interval \n\t\tfor Monte-Carlo approximation of the integral in log-likelihood\n\t\t\"\"\"", "\n", "\"\"\"\n\t\tinput \n\t\t\tmc_sample_num_tensor [B] : # of MC samples per sequence \n\t\t\tduration_tensor [B] : duration per sequence \n\t\t\tmask_tensor [B x T+1] : 1.0/0.0 mask of each token of each sequence\n\t\t\"\"\"", "\n", "all_c_inter", ",", "all_cb_inter", "=", "[", "]", ",", "[", "]", "\n", "all_d_inter", ",", "all_o_inter", "=", "[", "]", ",", "[", "]", "\n", "all_dtime_inter", "=", "[", "]", "\n", "all_mask_inter", "=", "[", "]", "\n", "\n", "batch_size", ",", "T_plus_1", ",", "hidden_dim", "=", "all_cell", ".", "size", "(", ")", "\n", "\"\"\"\n\t\tdraw MC time samles \n\t\tTODO : use randomized rounding when rho * I is not integer !!!\n\t\t\"\"\"", "\n", "mc_max", "=", "torch", ".", "max", "(", "mc_sample_num_tensor", ")", "\n", "mc_max", "=", "mc_max", "if", "mc_max", ">", "1", "else", "1", "\n", "u", "=", "torch", ".", "ones", "(", "size", "=", "[", "batch_size", ",", "mc_max", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "u", ",", "_", "=", "torch", ".", "sort", "(", "u", ".", "uniform_", "(", "0.0", ",", "1.0", ")", ")", "# batch_size x mc_max ", "\n", "sampled_time", "=", "u", "*", "duration_tensor", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "last_time", "=", "torch", ".", "zeros", "(", "size", "=", "[", "batch_size", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "for", "i", "in", "range", "(", "T_plus_1", ")", ":", "\n", "\t\t\t", "\"\"\"\n\t\t\tstarting from the 1st (non-BOS) event \n\t\t\tfind mc samples in this interval\n\t\t\t\"\"\"", "\n", "dtime_i", "=", "dtime_tensor", "[", ":", ",", "i", "]", "# batch_size ", "\n", "curr_time", "=", "last_time", "+", "dtime_i", "\n", "fallin", "=", "(", "sampled_time", ">", "last_time", ".", "unsqueeze", "(", "-", "1", ")", ")", "&", "(", "sampled_time", "<=", "curr_time", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "# 0/1 unit 8 : batch_size x mc_max", "\n", "\"\"\"\n\t\t\tfind the min rectangle covering all 1 \n\t\t\t\"\"\"", "\n", "fallin_idx", "=", "fallin", ".", "sum", "(", "0", ")", ">", "0.5", "\n", "\n", "mask_inter", "=", "fallin", "[", ":", ",", "fallin_idx", "]", ".", "float", "(", ")", "\n", "mask_inter", "*=", "mask_tensor", "[", ":", ",", "i", "]", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "chosen_time", "=", "sampled_time", "[", ":", ",", "fallin_idx", "]", "\n", "sampled_dt", "=", "chosen_time", "-", "last_time", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\"\"\"\n\t\t\tchosen time may < past time : they are chosen cuz that col is chosen \n\t\t\tand they will eventually be masked out in the end \n\t\t\t\"\"\"", "\n", "sampled_dt", "[", "sampled_dt", "<", "0.0", "]", "=", "0.0", "\n", "# batch_size x S (S may be 0)", "\n", "_", ",", "S", "=", "sampled_dt", ".", "size", "(", ")", "\n", "\n", "c_inter", "=", "all_cell", "[", ":", ",", "i", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "S", ",", "hidden_dim", ")", "\n", "cb_inter", "=", "all_cell_bar", "[", ":", ",", "i", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "S", ",", "hidden_dim", ")", "\n", "d_inter", "=", "all_gate_decay", "[", ":", ",", "i", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "S", ",", "hidden_dim", ")", "\n", "o_inter", "=", "all_gate_output", "[", ":", ",", "i", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "S", ",", "hidden_dim", ")", "\n", "\n", "last_time", "=", "curr_time", "\n", "\n", "all_c_inter", ".", "append", "(", "c_inter", ")", "\n", "all_cb_inter", ".", "append", "(", "cb_inter", ")", "\n", "all_d_inter", ".", "append", "(", "d_inter", ")", "\n", "all_o_inter", ".", "append", "(", "o_inter", ")", "\n", "\n", "all_dtime_inter", ".", "append", "(", "sampled_dt", ")", "\n", "all_mask_inter", ".", "append", "(", "mask_inter", ")", "\n", "\n", "", "all_c_inter", "=", "torch", ".", "cat", "(", "all_c_inter", ",", "dim", "=", "1", ")", "\n", "all_cb_inter", "=", "torch", ".", "cat", "(", "all_cb_inter", ",", "dim", "=", "1", ")", "\n", "all_d_inter", "=", "torch", ".", "cat", "(", "all_d_inter", ",", "dim", "=", "1", ")", "\n", "all_o_inter", "=", "torch", ".", "cat", "(", "all_o_inter", ",", "dim", "=", "1", ")", "\n", "all_dtime_inter", "=", "torch", ".", "cat", "(", "all_dtime_inter", ",", "dim", "=", "1", ")", "\n", "all_mask_inter", "=", "torch", ".", "cat", "(", "all_mask_inter", ",", "dim", "=", "1", ")", "\n", "\n", "return", "all_c_inter", ",", "all_cb_inter", ",", "all_d_inter", ",", "all_o_inter", ",", "all_dtime_inter", ",", "all_mask_inter", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.get_interpolated_cells": [[312, 340], ["all_cell.size", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "all_cell[].unsqueeze().expand", "all_cell_bar[].unsqueeze().expand", "all_gate_decay[].unsqueeze().expand", "all_gate_output[].unsqueeze().expand", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "all_cell[].unsqueeze", "all_cell_bar[].unsqueeze", "all_gate_decay[].unsqueeze", "all_gate_output[].unsqueeze"], "methods", ["None"], ["", "def", "get_interpolated_cells", "(", "self", ",", "\n", "all_cell", ",", "all_cell_bar", ",", "all_gate_decay", ",", "all_gate_output", ",", "all_S_inter", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tgiven a tensor of cells & gates \n\t\tinterpolate the cells & gates between them \n\t\t# of interpolated points is in S\n\t\t\"\"\"", "\n", "all_c_inter", ",", "all_cb_inter", "=", "[", "]", ",", "[", "]", "\n", "all_d_inter", ",", "all_o_inter", "=", "[", "]", ",", "[", "]", "\n", "batch_size", ",", "T_plus_1", ",", "D", "=", "all_cell", ".", "size", "(", ")", "\n", "for", "i", "in", "range", "(", "T_plus_1", ")", ":", "\n", "\t\t\t", "c_inter", "=", "all_cell", "[", ":", ",", "i", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "\n", "batch_size", ",", "all_S_inter", "[", "i", "]", ",", "D", ")", "\n", "cb_inter", "=", "all_cell_bar", "[", ":", ",", "i", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "\n", "batch_size", ",", "all_S_inter", "[", "i", "]", ",", "D", ")", "\n", "d_inter", "=", "all_gate_decay", "[", ":", ",", "i", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "\n", "batch_size", ",", "all_S_inter", "[", "i", "]", ",", "D", ")", "\n", "o_inter", "=", "all_gate_output", "[", ":", ",", "i", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "\n", "batch_size", ",", "all_S_inter", "[", "i", "]", ",", "D", ")", "\n", "all_c_inter", ".", "append", "(", "c_inter", ")", "\n", "all_cb_inter", ".", "append", "(", "cb_inter", ")", "\n", "all_d_inter", ".", "append", "(", "d_inter", ")", "\n", "all_o_inter", ".", "append", "(", "o_inter", ")", "\n", "", "all_c_inter", "=", "torch", ".", "cat", "(", "all_c_inter", ",", "dim", "=", "1", ")", "\n", "all_cb_inter", "=", "torch", ".", "cat", "(", "all_cb_inter", ",", "dim", "=", "1", ")", "\n", "all_d_inter", "=", "torch", ".", "cat", "(", "all_d_inter", ",", "dim", "=", "1", ")", "\n", "all_o_inter", "=", "torch", ".", "cat", "(", "all_o_inter", ",", "dim", "=", "1", ")", "\n", "return", "all_c_inter", ",", "all_cb_inter", ",", "all_d_inter", ",", "all_o_inter", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.get_noise_samples": [[342, 355], ["nhp.GNHP.get_cells_gates_states", "nhp.GNHP.get_noise_samples_given_states"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.get_cells_gates_states", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_noise_samples_given_states"], ["", "def", "get_noise_samples", "(", "self", ",", "method", ",", "\n", "event_tensor", ",", "dtime_tensor", ",", "target_tensor", ",", "mask_tensor", ",", "duration_tensor", ",", "\n", "noise_process_num", ",", "noise_type_num", ",", "over", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tdraw noise samples from q and evaluate these samples\n\t\t\"\"\"", "\n", "all_c_q_actual", ",", "all_cb_q_actual", ",", "all_d_q_actual", ",", "all_o_q_actual", ",", "_", ",", "_", "=", "self", ".", "get_cells_gates_states", "(", "event_tensor", ",", "dtime_tensor", ")", "\n", "# B x T+1 x D ", "\n", "return", "self", ".", "get_noise_samples_given_states", "(", "\n", "method", ",", "all_c_q_actual", ",", "all_cb_q_actual", ",", "all_d_q_actual", ",", "all_o_q_actual", ",", "\n", "target_tensor", ",", "mask_tensor", ",", "dtime_tensor", "[", ":", ",", "1", ":", "]", ",", "duration_tensor", ",", "\n", "noise_process_num", ",", "noise_type_num", ",", "over", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.get_noise_samples_given_states": [[358, 442], ["all_cell.size", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "nhp.GNHP.draw_noise_samples_per_interval", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "all_S.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "float", "mask_tensor[].unsqueeze", "mask_tensor[].unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.draw_noise_samples_per_interval"], ["", "def", "get_noise_samples_given_states", "(", "self", ",", "nce_method", ",", "\n", "all_cell", ",", "all_cell_bar", ",", "all_gate_decay", ",", "all_gate_output", ",", "\n", "target_tensor", ",", "mask_tensor", ",", "\n", "dtime_tensor", ",", "duration_tensor", ",", "\n", "noise_process_num", ",", "noise_type_num", ",", "over", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tfor NCE method, sample noise times and event types \n\t\twhen object of this class is used as a noise distribution q \n\t\t\"\"\"", "\n", "\"\"\"\n\t\tinput \n\t\t\tnce_method : nce_frac or nce_async or nce_sync\n\t\t\tnoise_process_num [0] : # noise processes in parallel \n\t\t\tnoise_type_num [0] : # noise types per noise and actual time\n\t\t\tduration_tensor [B] : duration of each sequence\n\t\t\tmask_tensor [B x T+1] : 1.0/0.0 mask of each token of each seq\n\t\t\"\"\"", "\n", "\"\"\"\n\t\t_time : _noise == at noise times \n\t\t_time_type : _actual_noise == at actual times, of noise types \n\t\t_both : at both times (or of both actual and noise types, subj. to context)\n\t\t\"\"\"", "\n", "all_type_actual_noise", "=", "[", "]", "\n", "all_type_noise_noise", "=", "[", "]", "\n", "all_dtime_noise", "=", "[", "]", "\n", "all_mask_noise", "=", "[", "]", "\n", "inten_q_actual_both", "=", "[", "]", "# these intensities no need to compute again outside", "\n", "inten_q_noise_noise", "=", "[", "]", "\n", "all_accept_prob_noise", "=", "[", "]", "\n", "all_S", "=", "[", "]", "\n", "all_inten_num_noise", "=", "0", "\n", "# count # of intensities computed in this sampling algorithm", "\n", "\n", "_", ",", "T_plus_1", ",", "_", "=", "all_cell", ".", "size", "(", ")", "\n", "for", "i", "in", "range", "(", "T_plus_1", ")", ":", "\n", "\t\t\t", "\"\"\"\n\t\t\tdraw noise times and noise types \n\t\t\t\"\"\"", "\n", "type_both_noise", ",", "dtime_noise", ",", "mask_noise", ",", "fine_inten_actual_both", ",", "fine_inten_noise_noise", ",", "accept_prob_noise", ",", "S", ",", "inten_num_noise", "=", "self", ".", "draw_noise_samples_per_interval", "(", "\n", "nce_method", ",", "\n", "all_cell", "[", ":", ",", "i", ",", ":", "]", ",", "all_cell_bar", "[", ":", ",", "i", ",", ":", "]", ",", "\n", "all_gate_decay", "[", ":", ",", "i", ",", ":", "]", ",", "all_gate_output", "[", ":", ",", "i", ",", ":", "]", ",", "\n", "target_tensor", "[", ":", ",", "i", "]", ",", "dtime_tensor", "[", ":", ",", "i", "]", ",", "\n", "noise_process_num", ",", "noise_type_num", ",", "over", "\n", ")", "\n", "\"\"\"\n\t\t\ttype_both_noise : B x (S + 1) x noise_type_num # -1 th is actual time\n\t\t\tdtime_noise, mask_noise, accept_prob : B x S\n\t\t\tfine_inten_both : B x (S + 1) x K\n\t\t\t\"\"\"", "\n", "all_type_noise_noise", ".", "append", "(", "type_both_noise", "[", ":", ",", ":", "-", "1", ",", ":", "]", ")", "\n", "all_type_actual_noise", ".", "append", "(", "type_both_noise", "[", ":", ",", "-", "1", ",", ":", "]", ")", "\n", "all_dtime_noise", ".", "append", "(", "dtime_noise", ")", "\n", "inten_q_actual_both", ".", "append", "(", "fine_inten_actual_both", ")", "\n", "inten_q_noise_noise", ".", "append", "(", "fine_inten_noise_noise", ")", "\n", "all_accept_prob_noise", ".", "append", "(", "accept_prob_noise", ")", "\n", "all_S", ".", "append", "(", "S", ")", "\n", "\"\"\"\n\t\t\tmask_noise all set to 0.0 if this token is masked out \n\t\t\t\"\"\"", "\n", "mask_noise", "=", "mask_noise", "*", "mask_tensor", "[", ":", ",", "i", "]", ".", "unsqueeze", "(", "1", ")", "\n", "all_mask_noise", ".", "append", "(", "mask_noise", ")", "\n", "\"\"\"\n\t\t\tproperly mask out fake # of inten and sum them\n\t\t\t\"\"\"", "\n", "inten_num_noise", "=", "inten_num_noise", "*", "mask_tensor", "[", ":", ",", "i", "]", ".", "unsqueeze", "(", "1", ")", "\n", "inten_num_noise", "=", "float", "(", "torch", ".", "sum", "(", "inten_num_noise", ")", ")", "\n", "all_inten_num_noise", "+=", "inten_num_noise", "\n", "\n", "", "all_type_actual_noise", "=", "torch", ".", "stack", "(", "all_type_actual_noise", ",", "dim", "=", "1", ")", "\n", "all_type_noise_noise", "=", "torch", ".", "cat", "(", "all_type_noise_noise", ",", "dim", "=", "1", ")", "\n", "all_dtime_noise", "=", "torch", ".", "cat", "(", "all_dtime_noise", ",", "dim", "=", "1", ")", "\n", "all_mask_noise", "=", "torch", ".", "cat", "(", "all_mask_noise", ",", "dim", "=", "1", ")", "\n", "inten_q_actual_both", "=", "torch", ".", "stack", "(", "inten_q_actual_both", ",", "dim", "=", "1", ")", "\n", "inten_q_noise_noise", "=", "torch", ".", "cat", "(", "inten_q_noise_noise", ",", "dim", "=", "1", ")", "\n", "all_accept_prob_noise", "=", "torch", ".", "cat", "(", "all_accept_prob_noise", ",", "dim", "=", "1", ")", "\n", "\n", "return", "all_type_actual_noise", ",", "all_type_noise_noise", ",", "all_dtime_noise", ",", "all_mask_noise", ",", "inten_q_actual_both", ",", "inten_q_noise_noise", ",", "all_accept_prob_noise", ",", "all_S", ",", "all_inten_num_noise", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.draw_noise_samples_per_interval": [[444, 619], ["int", "c.size", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty.exponential_", "torch.empty.exponential_", "torch.empty.exponential_", "sampled_dt.cumsum.cumsum.cumsum", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "c.unsqueeze().expand", "cb.unsqueeze().expand", "d.unsqueeze().expand", "o.unsqueeze().expand", "nhp.GNHP.get_intensities_all_coarse_types", "torch.cat.sum", "torch.cat.sum", "torch.cat.sum", "nhp.GNHP.thinning", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "nhp.GNHP.coarse_to_fine.get_fine_probs_all_types", "ncempp.models.utils.sample_noise_types", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "dtime.unsqueeze", "to_collect.float", "dtime.unsqueeze", "c.unsqueeze", "cb.unsqueeze", "d.unsqueeze", "o.unsqueeze", "coarse_inten_both[].unsqueeze", "target.unsqueeze", "Exception"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_intensities_all_coarse_types", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.thinning", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_fine_probs_all_types", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.utils.sample_noise_types"], ["", "def", "draw_noise_samples_per_interval", "(", "self", ",", "nce_method", ",", "\n", "c", ",", "cb", ",", "d", ",", "o", ",", "target", ",", "dtime", ",", "M1", ",", "M2", ",", "over", ",", "type_mask", "=", "None", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tinput \n\t\t\tnce_method [str] : nce_frac or nce_async or nce_sync\n\t\t\tc [B x D] : c_i in NHP\n\t\t\tcb [B x D] : \\bar{c}_i in NHP\n\t\t\td [B x D] : d_i in NHP, how fast c(t) goes from c_i to \\bar{c}_i\n\t\t\to [B x D] :  o_i in NHP\n\t\t\ttarget [B] : actual event type \n\t\t\tdtime [B] : actual time intervals between last and next actual event \n\t\t\tM1 [0] : # of noise processes in parallel \n\t\t\tM2 [0] : # of noise TYPEs per atual/noise time\n\t\t\tover [0] : over-sampling rate\n\t\t\ttype_mask [B x K] : 1.0/0.0 mask for possible/valid event types of this interval\n\t\t\"\"\"", "\n", "\"\"\"\n\t\tNOTE : why type_mask? \n\t\tfor some complex model p, the valid event types may change over time \n\t\tthen we only want to propose the possible types \n\t\tso we use the type_mask to maks out the impossible ones \n\t\twhy we only use it here but NOT in get_noise_samples? \n\t\tbecause for such complex model p, \n\t\twe would draw noise samples on-the-fly of training\n\t\tmeaing that get_noise_samples won't be called in that case \n\t\tso we leave it out of get_noise_samples \n\t\twhich also makes code run faster\n\t\t\"\"\"", "\n", "if", "nce_method", "==", "'nce_frac'", ":", "\n", "\t\t\t", "\"\"\"\n\t\t\tfractional thinning algorithm : all noise times are used and reweighted by prob\n\t\t\t\"\"\"", "\n", "fractional", "=", "True", "\n", "", "elif", "nce_method", "==", "'nce_sync'", "or", "nce_method", "==", "'nce_async'", ":", "\n", "\t\t\t", "\"\"\"\n\t\t\tthinning algorithm : noise times might be rejected \n\t\t\t\"\"\"", "\n", "fractional", "=", "False", "\n", "", "elif", "nce_method", "==", "'nce_binary'", ":", "\n", "\t\t\t", "\"\"\"\n\t\t\tbinary-classification-NCE: noise times might be rejected\n\t\t\t\"\"\"", "\n", "fractional", "=", "False", "\n", "", "else", ":", "\n", "\t\t\t", "raise", "Exception", "(", "f\"Unknown NCE method : {nce_method}\"", ")", "\n", "", "\"\"\"\n\t\tNOTE : try best to speed it up---AS FAST AS IT CAN BE\n\t\t\"\"\"", "\n", "\"\"\"\n\t\tchoose (over-)sampling rate for thinning algorithm\n\t\twhy we construct (upper bound) sample rate this way ? \n\t\twell, in principle, we should find an upper bound intensity\n\t\tso that thinning algorithm is exact \n\t\thowever, for a misspecified model, this may often be bad: \n\t\te.g., if it is too high, we got too many noise times which is expensive \n\t\tfortunately, this sampling is used for training, not testing! \n\t\tthat being said, we can leverage the training data!!!\n\t\twith constructed 'sample_rate', \n\t\tthere will be 'over' # of tokens in expectation!!!\n\t\twhen sample_rate is actually an upper bound, algorithm is exact \n\t\twhen it is not, all proposed times are accepted\n\t\tthis acts as a correction to a mis-specified noise model\n\t\tsuch that we can always get some noise times :-)\n\t\t\"\"\"", "\n", "\"\"\"\n\t\tNOTE : if we ever run into super-long run-time or out-of-memory\n\t\tcheck if any / ends up in large # to slow things down!!!\n\t\te.g., / 0.0 will end up a very large number \n\t\tif this number is used as a dimension size, then we got HUGE overhead\n\t\tit may also have other bad effect \n\t\te.g., dtime too small, sample rate too high \n\t\tfor given sample_num_per_seq, it doesn't cover the interval enough, etc \n\t\tso we need to carefully revisit this part...\n\t\t\"\"\"", "\n", "sample_rate", "=", "over", "*", "1.0", "/", "(", "dtime", "+", "self", ".", "eps", ")", "\n", "\"\"\"\n\t\tcompute # of noise samples per interval per seq \n\t\t\"\"\"", "\n", "\"\"\"\n\t\tthinning algorithm to sample # of events (1 or 0)\n\t\tat any time t given the (actual) history up to time t \n\t\tequivalent to having M noise processes in parallel \n\t\twe set only one process with rate = rate x M \n\t\tequivalent to union of samples drawn from M processes, but less overhead\n\t\t\"\"\"", "\n", "sample_num_per_seq", "=", "int", "(", "over", "*", "M1", "+", "self", ".", "eps", ")", "\n", "sample_num_per_seq", "=", "1", "if", "sample_num_per_seq", "<", "1", "else", "sample_num_per_seq", "\n", "sample_num_max", "=", "sample_num_per_seq", "\n", "batch_size", ",", "D", "=", "c", ".", "size", "(", ")", "\n", "\"\"\"\n\t\tprepare tensors to host samples\n\t\t\"\"\"", "\n", "Exp_numbers", "=", "torch", ".", "empty", "(", "\n", "size", "=", "[", "batch_size", ",", "sample_num_max", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "Unif_numbers", "=", "torch", ".", "empty", "(", "\n", "size", "=", "[", "batch_size", ",", "sample_num_max", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "\"\"\"\n\t\trejection sampling for # of noise events at each t \n\t\t\"\"\"", "\n", "Exp_numbers", ".", "exponential_", "(", "1.0", ")", "\n", "sampled_dt", "=", "Exp_numbers", "/", "(", "sample_rate", "*", "M1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "sampled_dt", "=", "sampled_dt", ".", "cumsum", "(", "dim", "=", "-", "1", ")", "# batch_size x sample_num_max", "\n", "\"\"\"\n\t\tsample noise types for noise times + actual time \n\t\t\"\"\"", "\n", "sampled_and_actual_dt", "=", "torch", ".", "cat", "(", "[", "sampled_dt", ",", "dtime", ".", "unsqueeze", "(", "-", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "# batch_size x (sample_num_max + 1)", "\n", "\"\"\"\n\t\tcompute intensities at noise AND actual time points \n\t\t\"\"\"", "\n", "c_both", "=", "c", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "sample_num_max", "+", "1", ",", "D", ")", "\n", "cb_both", "=", "cb", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "sample_num_max", "+", "1", ",", "D", ")", "\n", "d_both", "=", "d", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "sample_num_max", "+", "1", ",", "D", ")", "\n", "o_both", "=", "o", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "sample_num_max", "+", "1", ",", "D", ")", "\n", "# batch_size x (sample_num_max + 1) x D", "\n", "coarse_inten_both", "=", "self", ".", "get_intensities_all_coarse_types", "(", "\n", "c_both", ",", "cb_both", ",", "d_both", ",", "o_both", ",", "sampled_and_actual_dt", "\n", ")", "# batch_size x (sample_num_max + 1) x coarse_num", "\n", "total_coarse_inten_both", "=", "coarse_inten_both", ".", "sum", "(", "-", "1", ")", "\n", "# batch_size x (sample_num_max + 1)", "\n", "\"\"\"\n\t\tonly collect time points that not exceed dtime\n\t\t\"\"\"", "\n", "to_collect", "=", "sampled_dt", "<", "dtime", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\"\"\"\n\t\tcount # of intensities to be computed for sampling noise times and types\n\t\tthis MUST be done before to_collect is used and pruned (cuz of rejection)\n\t\tBUT we shouldn't sum them here : some of them need to be properly masked out\n\t\t\"\"\"", "\n", "inten_num_noise", "=", "to_collect", ".", "float", "(", ")", "*", "self", ".", "coarse_num", "\n", "# batch_size x sample_num_max", "\n", "# total # of intensities per proposed noise sample (for thinning)", "\n", "\"\"\"\n\t\tthinning algorithm to get noise times and intensities at noise times\n\t\t\"\"\"", "\n", "dtime_noise", ",", "mask_noise", ",", "accept_prob_noise", ",", "coarse_inten_noise", ",", "S", "=", "self", ".", "thinning", "(", "\n", "Unif_numbers", ",", "sample_rate", ",", "total_coarse_inten_both", "[", ":", ",", ":", "-", "1", "]", ",", "\n", "sampled_dt", ",", "to_collect", ",", "coarse_inten_both", "[", ":", ",", ":", "-", "1", ",", ":", "]", ",", "\n", "batch_size", ",", "sample_num_max", ",", "fractional", "\n", ")", "\n", "\"\"\"\n\t\tsample event types at noise times and actual time \n\t\t\"\"\"", "\n", "coarse_inten_both", "=", "torch", ".", "cat", "(", "\n", "[", "coarse_inten_noise", ",", "coarse_inten_both", "[", ":", ",", "-", "1", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "1", "\n", ")", "# batch_size x (S + 1) x C # discard useless (sample_num_max - S) samples", "\n", "fine_inten_both", "=", "self", ".", "coarse_to_fine", ".", "get_fine_probs_all_types", "(", "\n", "coarse_inten_both", ")", "\n", "# batch_size x (S + 1) x K ", "\n", "\n", "if", "type_mask", "is", "not", "None", ":", "\n", "\t\t\t", "fine_inten_both", "=", "fine_inten_both", "*", "type_mask", "\n", "\n", "", "type_both_noise", "=", "sample_noise_types", "(", "\n", "fine_inten_both", ",", "batch_size", ",", "S", "+", "1", ",", "M2", ",", "\n", "self", ".", "event_num", ",", "self", ".", "noise_mode", ",", "self", ".", "device", ")", "\n", "# batch_size x (S + 1) x M2", "\n", "\"\"\"\n\t\tgather intensities at actual and noise times \n\t\tof actual and noise types \n\t\t\"\"\"", "\n", "type_actual_both", "=", "torch", ".", "cat", "(", "\n", "[", "target", ".", "unsqueeze", "(", "-", "1", ")", ",", "type_both_noise", "[", ":", ",", "-", "1", ",", ":", "]", "]", ",", "dim", "=", "-", "1", "\n", ")", "# batch_size x (1 + M2)", "\n", "fine_inten_actual_both", "=", "torch", ".", "gather", "(", "\n", "fine_inten_both", "[", ":", ",", "-", "1", ",", ":", "]", ",", "# batch_size x K ", "\n", "1", ",", "type_actual_both", "\n", ")", "# batch_size x (1 + M2)", "\n", "fine_inten_noise_noise", "=", "torch", ".", "gather", "(", "\n", "fine_inten_both", "[", ":", ",", ":", "-", "1", ",", ":", "]", ",", "# batch_size x S x K", "\n", "2", ",", "type_both_noise", "[", ":", ",", ":", "-", "1", ",", ":", "]", "\n", ")", "# batch_size x S x M2", "\n", "return", "type_both_noise", ",", "dtime_noise", ",", "mask_noise", ",", "fine_inten_actual_both", ",", "fine_inten_noise_noise", ",", "accept_prob_noise", ",", "S", ",", "inten_num_noise", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.thinning": [[621, 690], ["Unif_numbers.uniform_", "to_collect.float", "to_collect.sum", "keep_col.expand.expand.expand", "sampled_dt[].view", "to_collect[].view().float", "accept_prob[].view", "sampled_dt[].view.size", "coarse_inten_noise[].view", "sample_rate.unsqueeze", "keep_col.expand.expand.sum", "to_collect[].view"], "methods", ["None"], ["", "def", "thinning", "(", "self", ",", "\n", "Unif_numbers", ",", "sample_rate", ",", "total_coarse_inten_noise", ",", "\n", "sampled_dt", ",", "to_collect", ",", "coarse_inten_noise", ",", "batch_size", ",", "sample_num_max", ",", "fractional", ")", ":", "\n", "\t\t", "\"\"\"\n\t\trejection sampling (only for proposed noise times)\n\t\tinput \n\t\t\tfractional [boolean] : \n\t\t\t\ttrue : keep all proposed noise times and their accept probs \n\t\t\t\tfalse : only keep the (stochastically-)accepted noise times \n\t\t\"\"\"", "\n", "accept_prob", "=", "total_coarse_inten_noise", "/", "(", "sample_rate", ".", "unsqueeze", "(", "-", "1", ")", "+", "self", ".", "eps", ")", "\n", "accept_prob", "[", "accept_prob", ">", "1.0", "]", "=", "1.0", "# scale prob back to (0, 1)", "\n", "Unif_numbers", ".", "uniform_", "(", "0.0", ",", "1.0", ")", "\n", "if", "fractional", ":", "\n", "\t\t\t", "\"\"\"\n\t\t\tNOTE : we may adaptively change threshold in the future\n\t\t\t\"\"\"", "\n", "threshold", "=", "0.01", "\n", "\"\"\"\n\t\t\twhen accept prob >= threshold, we keep it \n\t\t\twhen accept prob < threshold, we stochastically accept it \n\t\t\t\"\"\"", "\n", "id1", "=", "accept_prob", "<", "threshold", "# accep prob too small", "\n", "id2", "=", "Unif_numbers", "<", "accept_prob", "# accept some noise times", "\n", "to_collect", "[", "id1", "*", "(", "~", "id2", ")", "]", "=", "0", "\n", "\"\"\"\n\t\t\tadjust accept prob to 1 for id2 \n\t\t\tbecause accept prob will be used to scale log posterior \n\t\t\tand samples indexed by id2 are not fractional\n\t\t\t\"\"\"", "\n", "accept_prob", "[", "id1", "*", "id2", "]", "=", "1.0", "\n", "\"\"\"\n\t\t\tin fractional thinning, quite most will be collected\n\t\t\tso there won't be many zeros to discard \n\t\t\tso we don't find those zeros and save time\n\t\t\t\"\"\"", "\n", "dtime_noise", "=", "sampled_dt", "\n", "mask_noise", "=", "to_collect", ".", "float", "(", ")", "\n", "accept_prob_noise", "=", "accept_prob", "\n", "S", "=", "sample_num_max", "\n", "#coarse_inten_noise = coarse_inten_noise", "\n", "", "else", ":", "\n", "\t\t\t", "to_collect", "[", "Unif_numbers", ">", "accept_prob", "]", "=", "0", "\n", "\"\"\"\n\t\t\tfor efficiency (when these noise samples are actually used), \n\t\t\tfor each column, we check if all rows are 0\n\t\t\tif yes, we discard this column (all seqs in a batch)\n\t\t\tif no, we keep this column (all seqs in a batch)\n\t\t\t\"\"\"", "\n", "cnt_each_col", "=", "to_collect", ".", "sum", "(", "dim", "=", "0", ",", "keepdim", "=", "True", ")", "\n", "keep_col", "=", "cnt_each_col", ">", "0", "\n", "if", "keep_col", ".", "sum", "(", ")", "<", "1", ":", "\n", "# nothing to collect, we force an accepted time", "\n", "# this is why over=1 may be good enough : ", "\n", "# when we don't accept, we force one!!!", "\n", "# this acts as a correction to a mis-specified model", "\n", "\t\t\t\t", "keep_col", "[", ":", ",", "0", "]", "=", "1", "\n", "", "keep_col", "=", "keep_col", ".", "expand", "(", "batch_size", ",", "sample_num_max", ")", "\n", "\"\"\"\n\t\t\tcollect sample times, coarse intensities and construct mask \n\t\t\t\"\"\"", "\n", "dtime_noise", "=", "sampled_dt", "[", "keep_col", "]", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "mask_noise", "=", "to_collect", "[", "keep_col", "]", ".", "view", "(", "batch_size", ",", "-", "1", ")", ".", "float", "(", ")", "\n", "accept_prob_noise", "=", "accept_prob", "[", "keep_col", "]", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "# batch_size x S", "\n", "_", ",", "S", "=", "dtime_noise", ".", "size", "(", ")", "\n", "coarse_inten_noise", "=", "coarse_inten_noise", "[", "keep_col", ",", ":", "]", ".", "view", "(", "\n", "batch_size", ",", "S", ",", "self", ".", "coarse_num", ")", "\n", "", "return", "dtime_noise", ",", "mask_noise", ",", "accept_prob_noise", ",", "coarse_inten_noise", ",", "S", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.get_next_events_given_states": [[696, 725], ["all_cell.size", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "nhp.GNHP.mbr_time_type"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.mbr_time_type"], ["def", "get_next_events_given_states", "(", "self", ",", "\n", "all_cell", ",", "all_cell_bar", ",", "all_gate_decay", ",", "all_gate_output", ",", "\n", "dtime_tensor", ",", "over", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tpredict next event by aggregating many draws\n\t\t\"\"\"", "\n", "\n", "_", ",", "T_plus_1", ",", "_", "=", "all_cell", ".", "size", "(", ")", "\n", "\n", "all_dtime_predict", "=", "[", "]", "\n", "all_type_predict", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "T_plus_1", ")", ":", "\n", "\t\t\t", "\"\"\"\n\t\t\tdraw times and types (given times)\n\t\t\t\"\"\"", "\n", "dtime_predict", ",", "type_predict", "=", "self", ".", "mbr_time_type", "(", "\n", "all_cell", "[", ":", ",", "i", ",", ":", "]", ",", "all_cell_bar", "[", ":", ",", "i", ",", ":", "]", ",", "\n", "all_gate_decay", "[", ":", ",", "i", ",", ":", "]", ",", "all_gate_output", "[", ":", ",", "i", ",", ":", "]", ",", "\n", "dtime_tensor", "[", ":", ",", "i", "]", ",", "over", "\n", ")", "\n", "all_dtime_predict", "+=", "[", "dtime_predict", "]", "\n", "all_type_predict", "+=", "[", "type_predict", "]", "\n", "\n", "", "all_dtime_predict", "=", "torch", ".", "stack", "(", "all_dtime_predict", ",", "dim", "=", "1", ")", "\n", "all_type_predict", "=", "torch", ".", "stack", "(", "all_type_predict", ",", "dim", "=", "1", ")", "\n", "\n", "return", "all_dtime_predict", ",", "all_type_predict", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.mbr_time_type": [[727, 783], ["c.size", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty.exponential_", "torch.empty.exponential_", "torch.empty.exponential_", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "c.unsqueeze().expand", "cb.unsqueeze().expand", "d.unsqueeze().expand", "o.unsqueeze().expand", "nhp.GNHP.get_intensities_all_coarse_types", "nhp.GNHP.sum", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "sample_rate.unsqueeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "nhp.GNHP.coarse_to_fine.get_fine_probs_all_types", "dtime.unsqueeze", "c.unsqueeze", "cb.unsqueeze", "d.unsqueeze", "o.unsqueeze", "sample_rate.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_intensities_all_coarse_types", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_fine_probs_all_types"], ["", "def", "mbr_time_type", "(", "self", ",", "c", ",", "cb", ",", "d", ",", "o", ",", "dtime", ",", "over", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tnumerical approximation to MBR time and type by importance sampling\n\t\tsimilar to draw_noise_samples_per_interval\n\t\tnot couple code to avoid mess up\n\t\t\"\"\"", "\n", "sample_rate", "=", "over", "*", "1.0", "/", "(", "dtime", "+", "self", ".", "eps", ")", "# B ", "\n", "batch_size", ",", "D", "=", "c", ".", "size", "(", ")", "\n", "m", "=", "10", "# may make it hyper-param", "\n", "\"\"\"\n\t\tsample from q\n\t\t\"\"\"", "\n", "Exp_numbers", "=", "torch", ".", "empty", "(", "\n", "size", "=", "[", "batch_size", ",", "m", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", "\n", ")", "\n", "Exp_numbers", ".", "exponential_", "(", "1.0", ")", "\n", "sampled_dt", "=", "Exp_numbers", "/", "(", "sample_rate", "+", "self", ".", "eps", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "# B x M ", "\n", "\"\"\"\n\t\tcompute q\n\t\t\"\"\"", "\n", "q_prob", "=", "sample_rate", ".", "unsqueeze", "(", "-", "1", ")", "*", "torch", ".", "exp", "(", "\n", "-", "sample_rate", ".", "unsqueeze", "(", "-", "1", ")", "*", "sampled_dt", ")", "\n", "# B x M ", "\n", "\"\"\"\n\t\tcompute p\n\t\t\"\"\"", "\n", "sampled_and_actual_dt", "=", "torch", ".", "cat", "(", "[", "sampled_dt", ",", "dtime", ".", "unsqueeze", "(", "-", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "c_both", "=", "c", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "m", "+", "1", ",", "D", ")", "\n", "cb_both", "=", "cb", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "m", "+", "1", ",", "D", ")", "\n", "d_both", "=", "d", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "m", "+", "1", ",", "D", ")", "\n", "o_both", "=", "o", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "m", "+", "1", ",", "D", ")", "\n", "# batch_size x (m + 1) x D", "\n", "coarse_inten_both", "=", "self", ".", "get_intensities_all_coarse_types", "(", "\n", "c_both", ",", "cb_both", ",", "d_both", ",", "o_both", ",", "sampled_and_actual_dt", "\n", ")", "\n", "total_coarse_inten_both", "=", "coarse_inten_both", ".", "sum", "(", "-", "1", ")", "\n", "# batch_size x (m + 1)", "\n", "total_coarse_inten_sample", "=", "total_coarse_inten_both", "[", ":", ",", ":", "-", "1", "]", "\n", "avg_total_inten", "=", "torch", ".", "mean", "(", "total_coarse_inten_sample", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "p_prob", "=", "total_coarse_inten_sample", "*", "torch", ".", "exp", "(", "\n", "-", "avg_total_inten", "*", "sampled_dt", ")", "\n", "\"\"\"\n\t\tcompute weights and predcited time\n\t\t\"\"\"", "\n", "weights", "=", "p_prob", "/", "q_prob", "+", "self", ".", "eps", "\n", "weights", "/=", "torch", ".", "sum", "(", "weights", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "time_predict", "=", "torch", ".", "sum", "(", "sampled_dt", "*", "weights", ",", "dim", "=", "-", "1", ")", "\n", "\"\"\"\n\t\tcompute predicted type\n\t\t\"\"\"", "\n", "fine_inten_actual", "=", "self", ".", "coarse_to_fine", ".", "get_fine_probs_all_types", "(", "\n", "coarse_inten_both", ")", "[", ":", ",", "-", "1", ",", ":", "]", "# B x K ", "\n", "type_predict", "=", "torch", ".", "argmax", "(", "fine_inten_actual", ",", "dim", "=", "-", "1", ")", "# B ", "\n", "\n", "return", "time_predict", ",", "type_predict", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.draw_seq": [[790, 806], ["nhp.GNHP.init_c.unsqueeze().clone", "nhp.GNHP.clone", "nhp.GNHP.clone", "nhp.GNHP.clone().fill_", "range", "nhp.GNHP.update", "nhp.GNHP.draw_next", "rst.append", "nhp.GNHP.init_c.unsqueeze", "nhp.GNHP.clone"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.update", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.draw_next"], ["def", "draw_seq", "(", "self", ",", "num", ")", ":", "\n", "\t\t", "rst", "=", "[", "]", "\n", "# use BOS to init", "\n", "k", "=", "self", ".", "idx_BOS", "\n", "dt", "=", "0.0", "\n", "c", "=", "self", ".", "init_c", ".", "unsqueeze", "(", "0", ")", ".", "clone", "(", ")", "# 1 x D", "\n", "cb", "=", "c", ".", "clone", "(", ")", "# 1 x D", "\n", "d", "=", "c", ".", "clone", "(", ")", "\n", "o", "=", "c", ".", "clone", "(", ")", ".", "fill_", "(", "1.0", ")", "\n", "for", "i", "in", "range", "(", "num", ")", ":", "\n", "# update using last event", "\n", "\t\t\t", "c", ",", "cb", ",", "d", ",", "o", "=", "self", ".", "update", "(", "k", ",", "dt", ",", "c", ",", "cb", ",", "d", ",", "o", ")", "\n", "# then draw the next event", "\n", "dt", ",", "k", "=", "self", ".", "draw_next", "(", "c", ",", "cb", ",", "d", ",", "o", ")", "\n", "rst", ".", "append", "(", "(", "dt", ",", "k", ")", ")", "\n", "", "return", "rst", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.update": [[807, 822], ["torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "torch.zeros().fill_", "nhp.GNHP.in_emb", "nhp.GNHP.rnn_cell.decay", "nhp.GNHP.rnn_cell", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.cont_time_cell.CTLSTMCell.decay"], ["", "def", "update", "(", "self", ",", "k", ",", "dt", ",", "c", ",", "cb", ",", "d", ",", "o", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tk : event type (idx) (maybe BOS)\n\t\tdt : event dtime since last event (or init)\n\t\tc, cb, d, o : gates after LAST update (or init)\n\t\t\"\"\"", "\n", "event_tensor", "=", "torch", ".", "zeros", "(", "\n", "size", "=", "[", "1", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", ".", "fill_", "(", "k", ")", "\n", "dtime_i", "=", "torch", ".", "zeros", "(", "\n", "size", "=", "[", "1", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", ".", "fill_", "(", "dt", ")", "\n", "emb_i", "=", "self", ".", "in_emb", "(", "event_tensor", ")", "# 1 x D", "\n", "\n", "c_t_minus", ",", "h_t_minus", "=", "self", ".", "rnn_cell", ".", "decay", "(", "c", ",", "cb", ",", "d", ",", "o", ",", "dtime_i", ")", "\n", "c", ",", "cb", ",", "d", ",", "o", "=", "self", ".", "rnn_cell", "(", "emb_i", ",", "h_t_minus", ",", "c_t_minus", ",", "cb", ")", "\n", "return", "c", ",", "cb", ",", "d", ",", "o", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.nhp.GNHP.draw_next": [[823, 903], ["nhp.GNHP.get_intensities_all_coarse_types", "nhp.GNHP.sum", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty.exponential_", "torch.empty.exponential_", "torch.empty.exponential_", "sampled_dt.cumsum.cumsum.cumsum", "c.size", "c.unsqueeze().expand", "cb.unsqueeze().expand", "d.unsqueeze().expand", "o.unsqueeze().expand", "nhp.GNHP.get_intensities_all_coarse_types", "nhp.GNHP.sum", "torch.empty.uniform_", "torch.empty.uniform_", "torch.empty.uniform_", "accept_dt.min", "int", "float", "accept_coarse_inten.unsqueeze().unsqueeze", "nhp.GNHP.coarse_to_fine.get_fine_probs_all_types", "ncempp.models.utils.sample_noise_types", "int", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "accept_idx.size", "int.sum", "float.sum", "int.sum", "c.unsqueeze", "cb.unsqueeze", "d.unsqueeze", "o.unsqueeze", "accept_coarse_inten.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_intensities_all_coarse_types", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_intensities_all_coarse_types", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_fine_probs_all_types", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.utils.sample_noise_types"], ["", "def", "draw_next", "(", "self", ",", "c", ",", "cb", ",", "d", ",", "o", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tdraw next event dtime and type using thinning algorithm\n\t\tNOTE : different from the thinning method in this calss \n\t\tthat thinning : draw noise samples given h(t)\n\t\tthis thinning : draw next event given h(t_i)\n\t\tthere is similar code \n\t\tbut we decide to separate them to not mess up each other\n\t\t\"\"\"", "\n", "over", "=", "10.0", "\n", "N", "=", "500", "\n", "\"\"\"\n\t\tfind upper bound (a conservative estimate)\n\t\t\"\"\"", "\n", "coarse_inten", "=", "self", ".", "get_intensities_all_coarse_types", "(", "\n", "c", ",", "cb", ",", "d", ",", "o", ",", "\n", "torch", ".", "zeros", "(", "size", "=", "[", "1", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", ")", "# 1 x C", "\n", "total_coarse_inten", "=", "coarse_inten", ".", "sum", "(", ")", "# 0", "\n", "sample_rate", "=", "total_coarse_inten", "*", "over", "# 0", "\n", "\"\"\"\n\t\trejection sampling for next event dtime and type\n\t\t\"\"\"", "\n", "Exp_numbers", "=", "torch", ".", "empty", "(", "\n", "size", "=", "[", "1", ",", "N", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "Unif_numbers", "=", "torch", ".", "empty", "(", "\n", "size", "=", "[", "1", ",", "N", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "Exp_numbers", ".", "exponential_", "(", "1.0", ")", "\n", "sampled_dt", "=", "Exp_numbers", "/", "sample_rate", "\n", "sampled_dt", "=", "sampled_dt", ".", "cumsum", "(", "dim", "=", "-", "1", ")", "# 1 x N", "\n", "\"\"\"\n\t\tcompute intensities at sampled times\n\t\t\"\"\"", "\n", "D", "=", "c", ".", "size", "(", "-", "1", ")", "# hidden dimension", "\n", "c_exp", "=", "c", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "1", ",", "N", ",", "D", ")", "\n", "cb_exp", "=", "cb", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "1", ",", "N", ",", "D", ")", "\n", "d_exp", "=", "d", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "1", ",", "N", ",", "D", ")", "\n", "o_exp", "=", "o", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "1", ",", "N", ",", "D", ")", "\n", "coarse_inten", "=", "self", ".", "get_intensities_all_coarse_types", "(", "\n", "c_exp", ",", "cb_exp", ",", "d_exp", ",", "o_exp", ",", "sampled_dt", "\n", ")", "# 1 x N x C", "\n", "total_coarse_inten", "=", "coarse_inten", ".", "sum", "(", "-", "1", ")", "# 1 x N ", "\n", "accept_prob", "=", "total_coarse_inten", "/", "(", "sample_rate", "+", "self", ".", "eps", ")", "\n", "# 1 x N", "\n", "Unif_numbers", ".", "uniform_", "(", "0.0", ",", "1.0", ")", "\n", "\"\"\"\n\t\trandomly accept\n\t\t\"\"\"", "\n", "accept_idx", "=", "Unif_numbers", "<=", "accept_prob", "# accept : 1 x ?", "\n", "accept_dt", "=", "sampled_dt", "[", "accept_idx", "]", "# ?", "\n", "#print()", "\n", "#print(accept_dt.size())", "\n", "accept_coarse_inten", "=", "coarse_inten", "[", "accept_idx", ",", ":", "]", "# ? x C", "\n", "#print(accept_coarse_inten.size())", "\n", "assert", "accept_idx", ".", "size", "(", "-", "1", ")", ">", "0", ",", "\"no accept?\"", "\n", "dt", ",", "min_i", "=", "accept_dt", ".", "min", "(", "dim", "=", "-", "1", ")", "# 1 ", "\n", "min_i", "=", "int", "(", "min_i", ".", "sum", "(", ")", ")", "\n", "dt", "=", "float", "(", "dt", ".", "sum", "(", ")", ")", "\n", "accept_coarse_inten", "=", "accept_coarse_inten", "[", "min_i", ",", ":", "]", "# C", "\n", "\"\"\"\n\t\tsample event type\n\t\t\"\"\"", "\n", "\"\"\"\n\t\tNOTE : most robust # of dimension is 3\n\t\tcuz that is for which coarse_to_fine is optimized\n\t\t\"\"\"", "\n", "accept_coarse_inten_exp", "=", "accept_coarse_inten", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "fine_inten", "=", "self", ".", "coarse_to_fine", ".", "get_fine_probs_all_types", "(", "\n", "accept_coarse_inten_exp", ")", "# 1 x 1 x K", "\n", "#fine_inten = fine_inten.unsqueeze(0) # 1 x 1 x K", "\n", "\"\"\"\n\t\tcontinue \n\t\t\"\"\"", "\n", "sampled_k", "=", "sample_noise_types", "(", "\n", "fine_inten", ",", "1", ",", "1", ",", "1", ",", "\n", "self", ".", "event_num", ",", "self", ".", "noise_mode", ",", "self", ".", "device", "\n", ")", "# 1 x 1 x 1 ", "\n", "\n", "sampled_k", "=", "int", "(", "sampled_k", ".", "sum", "(", ")", ")", "\n", "return", "dt", ",", "sampled_k", "", "", "", ""]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.hp.GHP.__init__": [[20, 74], ["torch.Module.__init__", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "ncempp.models.layers.CF", "numpy.finfo", "numpy.finfo", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.__init__"], ["def", "__init__", "(", "self", ",", "*", ",", "\n", "coarse_num", ",", "event_num", ",", "fine_to_coarse", ",", "\n", "beta", "=", "1.0", ",", "noise_mode", "=", "'multinomial'", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "super", "(", "GHP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\"\"\"\n\t\tinput \n\t\t\tcoarse_num : # of coarse event types \n\t\t\tevent_num : # of fine event types  \n\t\t\tfine_to_coarse : dictionary k -> c\n\t\t\tnoise_mode : how to sample noise types when used as noise dist q\n\t\t\"\"\"", "\n", "\n", "device", "=", "device", "or", "'cpu'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "self", ".", "eps", "=", "np", ".", "finfo", "(", "float", ")", ".", "eps", "\n", "self", ".", "max", "=", "np", ".", "finfo", "(", "float", ")", ".", "max", "\n", "self", ".", "noise_mode", "=", "noise_mode", "\n", "\n", "self", ".", "coarse_num", "=", "coarse_num", "# # of coarse event types ", "\n", "self", ".", "event_num", "=", "event_num", "# # of fine event types ", "\n", "self", ".", "beta", "=", "beta", "\n", "\n", "self", ".", "idx_BOS", "=", "self", ".", "event_num", "\n", "self", ".", "idx_EOS", "=", "self", ".", "event_num", "+", "1", "\n", "self", ".", "idx_PAD", "=", "self", ".", "event_num", "+", "2", "\n", "\n", "self", ".", "mu", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "\n", "[", "self", ".", "coarse_num", "]", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", "\n", ")", "\n", ")", "\n", "\n", "\"\"\"\n\t\talpha + delta : [k, k'] -- effect of k to k'\n\t\t\"\"\"", "\n", "self", ".", "alpha", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "\n", "[", "self", ".", "coarse_num", ",", "self", ".", "coarse_num", "]", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", "\n", ")", "\n", ")", "\n", "\n", "self", ".", "delta", "=", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros", "(", "\n", "[", "self", ".", "coarse_num", ",", "self", ".", "coarse_num", "]", ",", "\n", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", "\n", ")", "\n", ")", "\n", "\n", "self", ".", "coarse_to_fine", "=", "CF", "(", "\n", "coarse_num", "=", "coarse_num", ",", "event_num", "=", "event_num", ",", "\n", "fine_to_coarse", "=", "fine_to_coarse", ",", "\n", "device", "=", "self", ".", "device", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.hp.GHP.cuda": [[76, 81], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "super().cuda"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["", "def", "cuda", "(", "self", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "device", "=", "device", "or", "'cuda:0'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "assert", "self", ".", "device", ".", "type", "==", "'cuda'", "\n", "super", "(", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.hp.GHP.cpu": [[82, 85], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "super().cuda"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["", "def", "cpu", "(", "self", ")", ":", "\n", "\t\t", "self", ".", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "super", "(", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.hp.GHP.get_inten_num": [[86, 91], ["None"], "methods", ["None"], ["", "def", "get_inten_num", "(", "self", ")", ":", "\n", "\t\t", "\"\"\"\n\t\treturn # of intensities to be computed in this model\n\t\t\"\"\"", "\n", "return", "self", ".", "coarse_num", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.hp.GHP.get_target": [[92, 103], ["event_tensor.size", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "event_tensor[].clone().detach", "event_tensor[].clone"], "methods", ["None"], ["", "def", "get_target", "(", "self", ",", "event_tensor", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tmake target variables and masks \n\t\ti.e., set >= event_num to 0, also mask them out \n\t\t\"\"\"", "\n", "batch_size", ",", "T_plus_2", "=", "event_tensor", ".", "size", "(", ")", "\n", "mask", "=", "torch", ".", "ones", "(", "(", "batch_size", ",", "T_plus_2", "-", "1", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "target_data", "=", "event_tensor", "[", ":", ",", "1", ":", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "mask", "[", "target_data", ">=", "self", ".", "event_num", "]", "=", "0.0", "\n", "target_data", "[", "target_data", ">=", "self", ".", "event_num", "]", "=", "0", "# PAD to be 0", "\n", "return", "target_data", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.hp.GHP.get_states": [[104, 118], ["hp.GHP.coarse_to_fine.get_coarse_for_given_fine", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_coarse_for_given_fine"], ["", "def", "get_states", "(", "self", ",", "event_tensor", ",", "dtime_tensor", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tinput \n\t\t\tevent_tensor [B x T+2] : tensor of event types \n\t\t\tdtime_tensor [B x T+2] : tensor of dtimes\n\t\treturn \n\t\t\tpast_event [B x T]\n\t\t\tpast_time [B x T]\n\t\t\"\"\"", "\n", "past_event", "=", "event_tensor", "[", ":", ",", "1", ":", "-", "1", "]", "# discard BOS EOS ", "\n", "past_event", "[", "past_event", ">=", "self", ".", "event_num", "]", "=", "0", "\n", "past_event", "=", "self", ".", "coarse_to_fine", ".", "get_coarse_for_given_fine", "(", "past_event", ")", "\n", "past_time", "=", "torch", ".", "cumsum", "(", "dtime_tensor", ",", "dim", "=", "-", "1", ")", "[", ":", ",", "1", ":", "-", "1", "]", "\n", "return", "past_event", ",", "past_time", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.hp.GHP.get_intensities": [[120, 173], ["time_tensor.size", "past_time.size", "torch.softplus", "torch.softplus", "torch.softplus", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "range", "hp.GHP.coarse_to_fine.get_fine_probs_all_types", "torch.softplus", "torch.softplus", "torch.softplus", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.softplus().unsqueeze().unsqueeze", "torch.softplus().unsqueeze().unsqueeze", "torch.softplus().unsqueeze().unsqueeze", "past_time_i.unsqueeze", "past_alpha_i.unsqueeze", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.zeros.unsqueeze", "torch.zeros.unsqueeze", "torch.zeros.unsqueeze", "torch.softplus().unsqueeze", "torch.softplus().unsqueeze", "torch.softplus().unsqueeze", "elapsed_time.unsqueeze", "past_delta_i.unsqueeze", "torch.softplus", "torch.softplus", "torch.softplus"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_fine_probs_all_types"], ["", "def", "get_intensities", "(", "self", ",", "past_event", ",", "past_time", ",", "time_tensor", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tget intensities given types \n\t\te.g., for MLE, compute intensities for the sum term in log-likelihood\n\t\te.g., for NCE, compute intensities for times drawn from p or q \n\t\t\"\"\"", "\n", "batch_size", ",", "Tp", "=", "time_tensor", ".", "size", "(", ")", "\n", "_", ",", "T", "=", "past_time", ".", "size", "(", ")", "\n", "\n", "past_alpha", "=", "F", ".", "softplus", "(", "self", ".", "alpha", "[", "past_event", ",", ":", "]", ")", "\n", "past_delta", "=", "F", ".", "softplus", "(", "self", ".", "delta", "[", "past_event", ",", ":", "]", ")", "+", "self", ".", "eps", "\n", "# B x T x C", "\n", "\n", "all_inten", "=", "torch", ".", "ones", "(", "\n", "[", "batch_size", ",", "Tp", ",", "self", ".", "coarse_num", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", "\n", ")", "\n", "# B x T' x C", "\n", "\n", "for", "i", "in", "range", "(", "T", ")", ":", "\n", "\t\t\t", "\"\"\"\n\t\t\tT is just seq length that any model (e.g., NHP) needs to loop over\n\t\t\tT' can be arbitrarily large so we parallelize that\n\t\t\t\"\"\"", "\n", "past_alpha_i", "=", "past_alpha", "[", ":", ",", "i", ",", ":", "]", "# B x C", "\n", "past_delta_i", "=", "past_delta", "[", ":", ",", "i", ",", ":", "]", "# B x C", "\n", "past_time_i", "=", "past_time", "[", ":", ",", "i", "]", "# B", "\n", "\n", "\"\"\"\n\t\t\tcompute effect to accumulate to any future event\n\t\t\t\"\"\"", "\n", "use", "=", "torch", ".", "zeros", "(", "\n", "[", "batch_size", ",", "Tp", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", "\n", ")", "\n", "elapsed_time", "=", "time_tensor", "-", "past_time_i", ".", "unsqueeze", "(", "-", "1", ")", "\n", "use", "[", "elapsed_time", ">", "self", ".", "eps", "]", "=", "1.0", "\n", "elapsed_time", "[", "elapsed_time", "<", "self", ".", "eps", "]", "=", "0.0", "\n", "\n", "# B x T' ", "\n", "effect", "=", "past_alpha_i", ".", "unsqueeze", "(", "1", ")", "*", "torch", ".", "exp", "(", "\n", "-", "past_delta_i", ".", "unsqueeze", "(", "1", ")", "*", "elapsed_time", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "\n", "# B x T' x C", "\n", "\n", "effect", "=", "effect", "*", "use", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "all_inten", "+=", "effect", "\n", "\n", "", "all_inten", "=", "effect", "+", "F", ".", "softplus", "(", "self", ".", "mu", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "# B x T' x C", "\n", "fine_inten", "=", "self", ".", "coarse_to_fine", ".", "get_fine_probs_all_types", "(", "all_inten", ")", "\n", "# B x T' x K ", "\n", "\n", "return", "fine_inten", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.hp.GHP.get_mc_samples": [[175, 195], ["dtime_tensor.size", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones.uniform_", "torch.ones.uniform_", "torch.ones.uniform_", "duration_tensor.unsqueeze"], "methods", ["None"], ["", "def", "get_mc_samples", "(", "self", ",", "dtime_tensor", ",", "\n", "mc_sample_num_tensor", ",", "duration_tensor", ",", "mask_tensor", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tsimilar to get_mc_samples in GNHP\n\t\t\"\"\"", "\n", "all_time_inter", "=", "[", "]", "\n", "all_mask_inter", "=", "[", "]", "\n", "\n", "batch_size", ",", "T_plus_1", "=", "dtime_tensor", ".", "size", "(", ")", "\n", "\n", "mc_max", "=", "torch", ".", "max", "(", "mc_sample_num_tensor", ")", "\n", "mc_max", "=", "mc_max", "if", "mc_max", ">", "1", "else", "1", "\n", "u", "=", "torch", ".", "ones", "(", "size", "=", "[", "batch_size", ",", "mc_max", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "u", ",", "_", "=", "torch", ".", "sort", "(", "u", ".", "uniform_", "(", "0.0", ",", "1.0", ")", ")", "# batch_size x mc_max ", "\n", "sampled_time", "=", "u", "*", "duration_tensor", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "all_time_inter", "=", "sampled_time", "\n", "all_mask_inter", "=", "torch", ".", "ones_like", "(", "all_time_inter", ")", "\n", "\n", "return", "all_time_inter", ",", "all_mask_inter", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.hp.GHP.get_noise_samples": [[202, 206], ["None"], "methods", ["None"], ["def", "get_noise_samples", "(", "self", ",", "method", ",", "\n", "event_tensor", ",", "dtime_tensor", ",", "target_tensor", ",", "mask_tensor", ",", "duration_tensor", ",", "\n", "noise_process_num", ",", "noise_type_num", ",", "over", ")", ":", "\n", "\t\t", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.hp.GHP.get_noise_samples_given_states": [[208, 213], ["None"], "methods", ["None"], ["", "def", "get_noise_samples_given_states", "(", "self", ",", "nce_method", ",", "\n", "target_tensor", ",", "mask_tensor", ",", "\n", "dtime_tensor", ",", "duration_tensor", ",", "\n", "noise_process_num", ",", "noise_type_num", ",", "over", ")", ":", "\n", "\t\t", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.hp.GHP.draw_noise_samples_per_interval": [[215, 218], ["None"], "methods", ["None"], ["", "def", "draw_noise_samples_per_interval", "(", "self", ",", "nce_method", ",", "\n", "target", ",", "dtime", ",", "M1", ",", "M2", ",", "over", ",", "type_mask", "=", "None", ")", ":", "\n", "\t\t", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.hp.GHP.draw_seq": [[225, 227], ["None"], "methods", ["None"], ["def", "draw_seq", "(", "self", ",", "num", ")", ":", "\n", "\t\t", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.hp.GHP.update": [[228, 230], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ")", ":", "\n", "\t\t", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.hp.GHP.draw_next": [[231, 233], ["None"], "methods", ["None"], ["", "def", "draw_next", "(", "self", ")", ":", "\n", "\t\t", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.__init__": [[11, 60], ["torch.Module.__init__", "torch.device", "torch.device", "torch.device", "torch.device", "dict", "fine_to_coarse.items", "dict.items", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "dict.items", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.Parameter", "torch.Parameter", "numpy.finfo", "aux[].append", "enumerate", "list", "len", "len"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.__init__"], ["def", "__init__", "(", "self", ",", "*", ",", "coarse_num", ",", "event_num", ",", "fine_to_coarse", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "super", "(", "CF", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "device", "=", "device", "or", "'cpu'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "self", ".", "eps", "=", "np", ".", "finfo", "(", "float", ")", ".", "eps", "\n", "\n", "self", ".", "coarse_num", "=", "coarse_num", "# # of coarse event types ", "\n", "self", ".", "event_num", "=", "event_num", "# # of fine event types ", "\n", "\"\"\"\n\t\tfor each coarse type c, track its fine types\n\t\t\"\"\"", "\n", "aux", "=", "dict", "(", ")", "\n", "for", "k", ",", "c", "in", "fine_to_coarse", ".", "items", "(", ")", ":", "\n", "\t\t\t", "if", "c", "not", "in", "aux", ":", "\n", "\t\t\t\t", "aux", "[", "c", "]", "=", "list", "(", ")", "\n", "", "aux", "[", "c", "]", ".", "append", "(", "k", ")", "\n", "", "max_Kc", "=", "-", "1", "\n", "for", "c", ",", "ck", "in", "aux", ".", "items", "(", ")", ":", "\n", "\t\t\t", "if", "len", "(", "ck", ")", ">", "max_Kc", ":", "\n", "\t\t\t\t", "max_Kc", "=", "len", "(", "ck", ")", "\n", "", "", "assert", "max_Kc", ">", "0", ",", "\"c has no k???!!!\"", "\n", "\"\"\"\n\t\tgroup k into coarse-grained c : \n\t\tcoarse_to_fine : tensor of c -> k (many k each c)\n\t\tfine_to_coarse : tensor of k -> c (one c each k)\n\t\tmask : mask out padding for each c \n\t\tindices : k-th = (c,i) : k-th type is c,i-th of coarse_to_fine\n\t\tprobs : for c, probs over its fine types\n\t\t\"\"\"", "\n", "self", ".", "coarse_to_fine", "=", "torch", ".", "zeros", "(", "\n", "self", ".", "coarse_num", ",", "max_Kc", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "fine_to_coarse", "=", "torch", ".", "zeros", "(", "\n", "self", ".", "event_num", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "mask", "=", "torch", ".", "zeros", "(", "\n", "self", ".", "coarse_num", ",", "max_Kc", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "indices", "=", "torch", ".", "zeros", "(", "\n", "self", ".", "event_num", ",", "2", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "for", "c", ",", "ck", "in", "aux", ".", "items", "(", ")", ":", "\n", "# c : ck = [ many fine types ]", "\n", "\t\t\t", "for", "i", ",", "k", "in", "enumerate", "(", "ck", ")", ":", "\n", "\t\t\t\t", "self", ".", "coarse_to_fine", "[", "c", ",", "i", "]", "=", "k", "\n", "self", ".", "fine_to_coarse", "[", "k", "]", "=", "c", "\n", "self", ".", "mask", "[", "c", ",", "i", "]", "=", "1.0", "\n", "self", ".", "indices", "[", "k", ",", "0", "]", "=", "c", "\n", "self", ".", "indices", "[", "k", ",", "1", "]", "=", "i", "\n", "", "", "probs_data", "=", "torch", ".", "zeros", "(", "\n", "self", ".", "coarse_num", ",", "max_Kc", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "self", ".", "probs", "=", "nn", ".", "Parameter", "(", "probs_data", ")", "# parameter probs ", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.cuda": [[61, 66], ["torch.device", "torch.device", "torch.device", "torch.device", "super().cuda"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["", "def", "cuda", "(", "self", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "device", "=", "device", "or", "'cuda:0'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "assert", "self", ".", "device", ".", "type", "==", "'cuda'", "\n", "super", "(", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.cpu": [[67, 70], ["torch.device", "torch.device", "torch.device", "torch.device", "super().cuda"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["", "def", "cpu", "(", "self", ")", ":", "\n", "\t\t", "self", ".", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "super", "(", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_probs": [[71, 79], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "masked_probs.sum", "torch.abs", "torch.abs", "torch.abs", "torch.abs"], "methods", ["None"], ["", "def", "get_probs", "(", "self", ")", ":", "\n", "# when each c has only one k, learning this parameters makes no difference ", "\n", "\t\t", "positive_mass", "=", "torch", ".", "exp", "(", "-", "torch", ".", "abs", "(", "self", ".", "probs", ")", ")", "\n", "# exp(-|x|) : no underflow or overflow ", "\n", "masked_probs", "=", "self", ".", "mask", "*", "positive_mass", "+", "self", ".", "eps", "# mask c->k structure", "\n", "norm_probs", "=", "masked_probs", "/", "masked_probs", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "# normalize", "\n", "# C x Kmax", "\n", "return", "norm_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_coarse_for_given_fine": [[80, 87], ["None"], "methods", ["None"], ["", "def", "get_coarse_for_given_fine", "(", "self", ",", "fine_types", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tfor a tensor of fine types ids, find their coarse types \n\t\te.g., for a GNHP, we only want intensity of a given fine type \n\t\tthen we have to find the corresponding coarse type first \n\t\t\"\"\"", "\n", "return", "self", ".", "fine_to_coarse", "[", "fine_types", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_fine_probs_all_types": [[88, 101], ["layers.CF.get_fine_probs_all_types_Ceq1", "layers.CF.get_fine_probs_all_types_Cneq1"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_fine_probs_all_types_Ceq1", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_fine_probs_all_types_Cneq1"], ["", "def", "get_fine_probs_all_types", "(", "self", ",", "coarse_probs", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tinput\n\t\t\tcoarse_probs : unnormalized probs \n\t\t\ta tensor of D_1 x ... x D_N x coarse_num\n\t\treturn \n\t\t\tfine_probs : unormalized probs \n\t\t\ta tensor of D_1 x ... x D_N x event_num\n\t\t\"\"\"", "\n", "if", "self", ".", "coarse_num", "==", "1", ":", "\n", "\t\t\t", "return", "self", ".", "get_fine_probs_all_types_Ceq1", "(", "coarse_probs", ")", "\n", "", "else", ":", "\n", "\t\t\t", "return", "self", ".", "get_fine_probs_all_types_Cneq1", "(", "coarse_probs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_fine_probs_all_types_Cneq1": [[102, 117], ["coarse_probs.unsqueeze", "layers.CF.get_probs"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_probs"], ["", "", "def", "get_fine_probs_all_types_Cneq1", "(", "self", ",", "coarse_probs", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tC != 1 : need a general method\n\t\t\"\"\"", "\n", "coarse_probs_divided", "=", "coarse_probs", ".", "unsqueeze", "(", "-", "1", ")", "*", "self", ".", "get_probs", "(", ")", "\n", "# D_1 x ... x D_N x coarse_num * Kmax", "\n", "\"\"\"\n\t\tfor efficiency, we only consider N == 2 \n\t\tD1 = batch_size, D2 = # times\n\t\tother cases need clever transpose or indexing case by case \n\t\twhich might be slower \n\t\t\"\"\"", "\n", "fine_probs", "=", "coarse_probs_divided", "[", ":", ",", ":", ",", "self", ".", "indices", "[", ":", ",", "0", "]", ",", "self", ".", "indices", "[", ":", ",", "1", "]", "]", "\n", "# D_1 x ... x D_N x K", "\n", "return", "fine_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_fine_probs_all_types_Ceq1": [[118, 126], ["layers.CF.get_probs"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_probs"], ["", "def", "get_fine_probs_all_types_Ceq1", "(", "self", ",", "coarse_probs", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tC == 1 : has a fast special implementation\n\t\tNOTE : having this special case is very important \n\t\tbecause C=1 is often used as noise distribution\n\t\tso its speed is very important to get a good wall-clock time\n\t\t\"\"\"", "\n", "return", "coarse_probs", "*", "self", ".", "get_probs", "(", ")", "[", "0", ",", ":", "]", "\n", "#return torch.matmul(coarse_probs, self.get_probs() )", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_fine_probs_given_types": [[129, 142], ["layers.CF.get_probs"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_probs"], ["", "def", "get_fine_probs_given_types", "(", "self", ",", "coarse_probs", ",", "coarse_types", ",", "fine_types", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tinput \n\t\t\tcoarse_probs : unnormalized probs, D_1 x ... x D_N\n\t\t\tcoarse_types : D_1 x ... x D_N\n\t\t\tfine_types : D_1 x ... x D_N\n\t\t\"\"\"", "\n", "all_cf_probs", "=", "self", ".", "get_probs", "(", ")", "# C x Kmax", "\n", "col_idx", "=", "self", ".", "indices", "[", "fine_types", ",", "1", "]", "\n", "# D_1 x ... x D_N ", "\n", "cf_probs", "=", "all_cf_probs", "[", "coarse_types", ",", "col_idx", "]", "\n", "# D_1 x ... x D_N", "\n", "return", "cf_probs", "*", "coarse_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.LinearEmbedding.__init__": [[153, 166], ["torch.Module.__init__", "torch.device", "torch.device", "torch.device", "torch.device", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.Embedding", "torch.Embedding", "numpy.finfo"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.__init__"], ["def", "__init__", "(", "self", ",", "*", ",", "num_embeddings", ",", "embedding_dim", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "super", "(", "LinearEmbedding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "device", "=", "device", "or", "'cpu'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "self", ".", "eps", "=", "np", ".", "finfo", "(", "float", ")", ".", "eps", "\n", "\n", "self", ".", "num_embeddings", "=", "num_embeddings", "# # of embeddings", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "# dimension", "\n", "self", ".", "ranger", "=", "torch", ".", "arange", "(", "\n", "0", ",", "num_embeddings", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "self", ".", "emb", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.LinearEmbedding.cuda": [[167, 172], ["torch.device", "torch.device", "torch.device", "torch.device", "super().cuda"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["", "def", "cuda", "(", "self", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "device", "=", "device", "or", "'cuda:0'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "assert", "self", ".", "device", ".", "type", "==", "'cuda'", "\n", "super", "(", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.LinearEmbedding.cpu": [[173, 176], ["torch.device", "torch.device", "torch.device", "torch.device", "super().cuda"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["", "def", "cpu", "(", "self", ")", ":", "\n", "\t\t", "self", ".", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "super", "(", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.LinearEmbedding.get_embeddings_all_types": [[177, 179], ["layers.LinearEmbedding.emb"], "methods", ["None"], ["", "def", "get_embeddings_all_types", "(", "self", ")", ":", "\n", "\t\t", "return", "self", ".", "emb", "(", "self", ".", "ranger", ")", "# num_embeddings x embedding_dim", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.LinearEmbedding.get_embeddings_given_types": [[180, 183], ["layers.LinearEmbedding.emb"], "methods", ["None"], ["", "def", "get_embeddings_given_types", "(", "self", ",", "event_tensor", ")", ":", "\n", "# event_tensor : D1 x ... x DN", "\n", "\t\t", "return", "self", ".", "emb", "(", "event_tensor", ")", "# D1 x ... x DN x embedding_dim", "", "", "", ""]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.__init__": [[20, 55], ["torch.Module.__init__", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "ncempp.models.layers.LinearEmbedding", "ncempp.models.layers.CF", "numpy.finfo", "numpy.finfo"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.__init__"], ["def", "__init__", "(", "self", ",", "*", ",", "\n", "coarse_num", ",", "event_num", ",", "fine_to_coarse", ",", "\n", "beta", "=", "1.0", ",", "noise_mode", "=", "'multinomial'", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "super", "(", "GPP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\"\"\"\n\t\tinput \n\t\t\tcoarse_num : # of coarse event types \n\t\t\tevent_num : # of fine event types  \n\t\t\tfine_to_coarse : dictionary k -> c\n\t\t\tnoise_mode : how to sample noise types when used as noise dist q\n\t\t\"\"\"", "\n", "\n", "device", "=", "device", "or", "'cpu'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "self", ".", "eps", "=", "np", ".", "finfo", "(", "float", ")", ".", "eps", "\n", "self", ".", "max", "=", "np", ".", "finfo", "(", "float", ")", ".", "max", "\n", "self", ".", "noise_mode", "=", "noise_mode", "\n", "\n", "self", ".", "coarse_num", "=", "coarse_num", "# # of coarse event types ", "\n", "self", ".", "event_num", "=", "event_num", "# # of fine event types ", "\n", "self", ".", "beta", "=", "beta", "\n", "\n", "self", ".", "idx_BOS", "=", "self", ".", "event_num", "\n", "self", ".", "idx_EOS", "=", "self", ".", "event_num", "+", "1", "\n", "self", ".", "idx_PAD", "=", "self", ".", "event_num", "+", "2", "\n", "\n", "self", ".", "out_emb", "=", "LinearEmbedding", "(", "\n", "num_embeddings", "=", "self", ".", "coarse_num", ",", "\n", "embedding_dim", "=", "1", ",", "\n", "device", "=", "self", ".", "device", "\n", ")", "\n", "self", ".", "coarse_to_fine", "=", "CF", "(", "\n", "coarse_num", "=", "coarse_num", ",", "event_num", "=", "event_num", ",", "\n", "fine_to_coarse", "=", "fine_to_coarse", ",", "\n", "device", "=", "self", ".", "device", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda": [[57, 62], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "super().cuda"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["", "def", "cuda", "(", "self", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "device", "=", "device", "or", "'cuda:0'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "assert", "self", ".", "device", ".", "type", "==", "'cuda'", "\n", "super", "(", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cpu": [[63, 66], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "super().cuda"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.cuda"], ["", "def", "cpu", "(", "self", ")", ":", "\n", "\t\t", "self", ".", "device", "=", "torch", ".", "device", "(", "'cpu'", ")", "\n", "super", "(", ")", ".", "cuda", "(", "self", ".", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_inten_num": [[67, 72], ["None"], "methods", ["None"], ["", "def", "get_inten_num", "(", "self", ")", ":", "\n", "\t\t", "\"\"\"\n\t\treturn # of intensities to be computed in this model\n\t\t\"\"\"", "\n", "return", "self", ".", "coarse_num", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_target": [[73, 84], ["event_tensor.size", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "event_tensor[].clone().detach", "event_tensor[].clone"], "methods", ["None"], ["", "def", "get_target", "(", "self", ",", "event_tensor", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tmake target variables and masks \n\t\ti.e., set >= event_num to 0, also mask them out \n\t\t\"\"\"", "\n", "batch_size", ",", "T_plus_2", "=", "event_tensor", ".", "size", "(", ")", "\n", "mask", "=", "torch", ".", "ones", "(", "(", "batch_size", ",", "T_plus_2", "-", "1", ")", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "target_data", "=", "event_tensor", "[", ":", ",", "1", ":", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "mask", "[", "target_data", ">=", "self", ".", "event_num", "]", "=", "0.0", "\n", "target_data", "[", "target_data", ">=", "self", ".", "event_num", "]", "=", "0", "# PAD to be 0", "\n", "return", "target_data", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_intensities_given_types": [[85, 103], ["pp.GPP.coarse_to_fine.get_coarse_for_given_fine", "pp.GPP.out_emb.get_embeddings_given_types", "torch.softplus().squeeze", "torch.softplus().squeeze", "torch.softplus().squeeze", "pp.GPP.coarse_to_fine.get_fine_probs_given_types", "torch.softplus", "torch.softplus", "torch.softplus"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_coarse_for_given_fine", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.LinearEmbedding.get_embeddings_given_types", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_fine_probs_given_types"], ["", "def", "get_intensities_given_types", "(", "self", ",", "event_tensor", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tget intensities given types \n\t\te.g., for MLE, compute intensities for the sum term in log-likelihood\n\t\te.g., for NCE, compute intensities for times drawn from p or q \n\t\tnote that Poisson intensities do NOT change with time\n\t\t\"\"\"", "\n", "coarse_types", "=", "self", ".", "coarse_to_fine", ".", "get_coarse_for_given_fine", "(", "event_tensor", ")", "\n", "# batch_size x T+1 x N (N can be 1)", "\n", "coarse_intensities_signed", "=", "self", ".", "out_emb", ".", "get_embeddings_given_types", "(", "coarse_types", ")", "\n", "# batch_size x (T+1) x N x 1", "\n", "coarse_intensities", "=", "F", ".", "softplus", "(", "\n", "coarse_intensities_signed", ",", "beta", "=", "self", ".", "beta", "\n", ")", ".", "squeeze", "(", "-", "1", ")", "# batch_size x T+1 x N ", "\n", "fine_intensities", "=", "self", ".", "coarse_to_fine", ".", "get_fine_probs_given_types", "(", "\n", "coarse_intensities", ",", "coarse_types", ",", "event_tensor", ")", "\n", "# batch_size x T+1 x N ", "\n", "return", "fine_intensities", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_intensities_all_coarse_types": [[104, 116], ["pp.GPP.out_emb.get_embeddings_all_types().squeeze", "torch.softplus", "torch.softplus", "torch.softplus", "pp.GPP.out_emb.get_embeddings_all_types"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.LinearEmbedding.get_embeddings_all_types"], ["", "def", "get_intensities_all_coarse_types", "(", "self", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tget intensities for all coarse types \n\t\te.g., compute total intensity in thinning algorithm\n\t\ttotal_coarse_intensity == total_fine_intensity\n\t\t\"\"\"", "\n", "coarse_intensities_signed", "=", "self", ".", "out_emb", ".", "get_embeddings_all_types", "(", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "# C x 1 -> C ", "\n", "coarse_intensities", "=", "F", ".", "softplus", "(", "\n", "coarse_intensities_signed", ",", "beta", "=", "self", ".", "beta", ")", "\n", "# C", "\n", "return", "coarse_intensities", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_intensities_all_fine_types": [[117, 130], ["pp.GPP.get_intensities_all_coarse_types", "pp.GPP.unsqueeze().unsqueeze", "pp.GPP.coarse_to_fine.get_fine_probs_all_types", "pp.GPP.squeeze().squeeze", "pp.GPP.unsqueeze", "pp.GPP.squeeze"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_intensities_all_coarse_types", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_fine_probs_all_types"], ["", "def", "get_intensities_all_fine_types", "(", "self", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tget intensities for all types \n\t\te.g., compute all intensities for integral term in log-likelihood\n\t\t\"\"\"", "\n", "coarse_intensities", "=", "self", ".", "get_intensities_all_coarse_types", "(", ")", "\n", "# C ", "\n", "expand_coarse_intensities", "=", "coarse_intensities", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "# 1 x 1 x C", "\n", "# CF implementation assumes dimensions for speedup", "\n", "expand_fine_intensities", "=", "self", ".", "coarse_to_fine", ".", "get_fine_probs_all_types", "(", "\n", "expand_coarse_intensities", ")", "\n", "return", "expand_fine_intensities", ".", "squeeze", "(", "0", ")", ".", "squeeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_noise_samples": [[131, 142], ["pp.GPP.get_noise_samples_given_states"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_noise_samples_given_states"], ["", "def", "get_noise_samples", "(", "self", ",", "method", ",", "\n", "event_tensor", ",", "dtime_tensor", ",", "target_tensor", ",", "mask_tensor", ",", "duration_tensor", ",", "\n", "noise_process_num", ",", "noise_type_num", ",", "over", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tdraw noise samples from q and evaluate these samples\n\t\tNOTE : we keep the format and method names consistent with GNHP\n\t\t\"\"\"", "\n", "return", "self", ".", "get_noise_samples_given_states", "(", "\n", "method", ",", "\n", "target_tensor", ",", "mask_tensor", ",", "dtime_tensor", "[", ":", ",", "1", ":", "]", ",", "duration_tensor", ",", "\n", "noise_process_num", ",", "noise_type_num", ",", "over", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_noise_samples_given_states": [[146, 227], ["target_tensor.size", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "pp.GPP.draw_noise_samples_per_interval", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.stack.append", "torch.stack.append", "torch.stack.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "all_S.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "float", "mask_tensor[].unsqueeze", "mask_tensor[].unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.draw_noise_samples_per_interval"], ["", "def", "get_noise_samples_given_states", "(", "self", ",", "nce_method", ",", "\n", "target_tensor", ",", "mask_tensor", ",", "\n", "dtime_tensor", ",", "duration_tensor", ",", "\n", "noise_process_num", ",", "noise_type_num", ",", "over", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tfor NCE method, sample noise times and event types \n\t\twhen object of this class is used as a noise distribution q \n\t\t\"\"\"", "\n", "\"\"\"\n\t\tinput \n\t\t\tnce_method : nce_frac or nce_async or nce_sync\n\t\t\tnoise_process_num [0] : # noise processes in parallel \n\t\t\tnoise_type_num [0] : # noise types per noise and actual time\n\t\t\tduration_tensor [B] : duration of each sequence\n\t\t\tmask_tensor [B x T+1] : 1.0/0.0 mask of each token of each seq\n\t\t\"\"\"", "\n", "\"\"\"\n\t\t_time : _noise == at noise times \n\t\t_time_type : _actual_noise == at actual times, of noise types \n\t\t_both : at both times (or of both actual and noise types, subj. to context)\n\t\t\"\"\"", "\n", "all_type_actual_noise", "=", "[", "]", "\n", "all_type_noise_noise", "=", "[", "]", "\n", "all_dtime_noise", "=", "[", "]", "\n", "all_mask_noise", "=", "[", "]", "\n", "inten_q_actual_both", "=", "[", "]", "# these intensities no need to compute again outside", "\n", "inten_q_noise_noise", "=", "[", "]", "\n", "all_accept_prob_noise", "=", "[", "]", "\n", "all_S", "=", "[", "]", "\n", "all_inten_num_noise", "=", "0", "\n", "# count # of intensities computed in this sampling algorithm", "\n", "\n", "_", ",", "T_plus_1", "=", "target_tensor", ".", "size", "(", ")", "\n", "for", "i", "in", "range", "(", "T_plus_1", ")", ":", "\n", "\t\t\t", "\"\"\"\n\t\t\tdraw noise times and noise types \n\t\t\t\"\"\"", "\n", "type_both_noise", ",", "dtime_noise", ",", "mask_noise", ",", "fine_inten_actual_both", ",", "fine_inten_noise_noise", ",", "accept_prob_noise", ",", "S", ",", "inten_num_noise", "=", "self", ".", "draw_noise_samples_per_interval", "(", "\n", "nce_method", ",", "\n", "target_tensor", "[", ":", ",", "i", "]", ",", "dtime_tensor", "[", ":", ",", "i", "]", ",", "\n", "noise_process_num", ",", "noise_type_num", ",", "over", "\n", ")", "\n", "\"\"\"\n\t\t\ttype_both_noise : B x (S + 1) x noise_type_num # -1 th is actual time\n\t\t\tdtime_noise, mask_noise, accept_prob : B x S\n\t\t\tfine_inten_both : B x (S + 1) x K\n\t\t\t\"\"\"", "\n", "all_type_noise_noise", ".", "append", "(", "type_both_noise", "[", ":", ",", ":", "-", "1", ",", ":", "]", ")", "\n", "all_type_actual_noise", ".", "append", "(", "type_both_noise", "[", ":", ",", "-", "1", ",", ":", "]", ")", "\n", "all_dtime_noise", ".", "append", "(", "dtime_noise", ")", "\n", "inten_q_actual_both", ".", "append", "(", "fine_inten_actual_both", ")", "\n", "inten_q_noise_noise", ".", "append", "(", "fine_inten_noise_noise", ")", "\n", "all_accept_prob_noise", ".", "append", "(", "accept_prob_noise", ")", "\n", "all_S", ".", "append", "(", "S", ")", "\n", "\"\"\"\n\t\t\tmask_noise all set to 0.0 if this token is masked out \n\t\t\t\"\"\"", "\n", "mask_noise", "=", "mask_noise", "*", "mask_tensor", "[", ":", ",", "i", "]", ".", "unsqueeze", "(", "1", ")", "\n", "all_mask_noise", ".", "append", "(", "mask_noise", ")", "\n", "\"\"\"\n\t\t\tproperly mask out fake # of inten and sum them\n\t\t\t\"\"\"", "\n", "inten_num_noise", "=", "inten_num_noise", "*", "mask_tensor", "[", ":", ",", "i", "]", ".", "unsqueeze", "(", "1", ")", "\n", "inten_num_noise", "=", "float", "(", "torch", ".", "sum", "(", "inten_num_noise", ")", ")", "\n", "all_inten_num_noise", "+=", "inten_num_noise", "\n", "\n", "", "all_type_actual_noise", "=", "torch", ".", "stack", "(", "all_type_actual_noise", ",", "dim", "=", "1", ")", "\n", "all_type_noise_noise", "=", "torch", ".", "cat", "(", "all_type_noise_noise", ",", "dim", "=", "1", ")", "\n", "all_dtime_noise", "=", "torch", ".", "cat", "(", "all_dtime_noise", ",", "dim", "=", "1", ")", "\n", "all_mask_noise", "=", "torch", ".", "cat", "(", "all_mask_noise", ",", "dim", "=", "1", ")", "\n", "inten_q_actual_both", "=", "torch", ".", "stack", "(", "inten_q_actual_both", ",", "dim", "=", "1", ")", "\n", "inten_q_noise_noise", "=", "torch", ".", "cat", "(", "inten_q_noise_noise", ",", "dim", "=", "1", ")", "\n", "all_accept_prob_noise", "=", "torch", ".", "cat", "(", "all_accept_prob_noise", ",", "dim", "=", "1", ")", "\n", "\n", "return", "all_type_actual_noise", ",", "all_type_noise_noise", ",", "all_dtime_noise", ",", "all_mask_noise", ",", "inten_q_actual_both", ",", "inten_q_noise_noise", ",", "all_accept_prob_noise", ",", "all_S", ",", "all_inten_num_noise", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.draw_noise_samples_per_interval": [[229, 344], ["pp.GPP.get_intensities_all_coarse_types", "pp.GPP.sum", "int", "target.size", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty.exponential_", "torch.empty.exponential_", "torch.empty.exponential_", "sampled_dt.cumsum.cumsum.cumsum", "to_collect.float", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "torch.ones_like", "pp.GPP.unsqueeze().unsqueeze", "pp.GPP.coarse_to_fine.get_fine_probs_all_types", "ncempp.models.utils.sample_noise_types", "ncempp.models.utils.sample_noise_types.view", "pp.GPP.expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "dtime.unsqueeze", "pp.GPP.unsqueeze", "target.unsqueeze", "Exception"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.get_intensities_all_coarse_types", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.layers.CF.get_fine_probs_all_types", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.utils.sample_noise_types"], ["", "def", "draw_noise_samples_per_interval", "(", "self", ",", "nce_method", ",", "\n", "target", ",", "dtime", ",", "M1", ",", "M2", ",", "over", ",", "type_mask", "=", "None", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tinput \n\t\t\tnce_method [str] : nce_frac or nce_async or nce_sync\n\t\t\ttarget [B] : actual event type \n\t\t\tdtime [B] : actual time intervals between last and next actual event \n\t\t\tM1 [0] : # of noise processes in parallel \n\t\t\tM2 [0] : # of noise TYPEs per atual/noise time\n\t\t\tover [0] : over-sampling rate\n\t\t\ttype_mask [B x K] : 1.0/0.0 mask for possible/valid event types of this interval\n\t\t\"\"\"", "\n", "\"\"\"\n\t\tNOTE : why type_mask? \n\t\tfor some complex model p, the valid event types may change over time \n\t\tthen we only want to propose the possible types \n\t\tso we use the type_mask to maks out the impossible ones \n\t\twhy we only use it here but NOT in get_noise_samples? \n\t\tbecause for such complex model p, \n\t\twe would draw noise samples on-the-fly of training\n\t\tmeaing that get_noise_samples won't be called in that case \n\t\tso we leave it out of get_noise_samples \n\t\twhich also makes code run faster\n\t\t\"\"\"", "\n", "if", "nce_method", "==", "'nce_frac'", ":", "\n", "\t\t\t", "\"\"\"\n\t\t\tfractional thinning algorithm : all noise times are used and reweighted by prob\n\t\t\t\"\"\"", "\n", "fractional", "=", "True", "\n", "", "elif", "nce_method", "==", "'nce_sync'", "or", "nce_method", "==", "'nce_async'", ":", "\n", "\t\t\t", "\"\"\"\n\t\t\tthinning algorithm : noise times might be rejected \n\t\t\t\"\"\"", "\n", "fractional", "=", "False", "\n", "", "elif", "nce_method", "==", "'nce_binary'", ":", "\n", "\t\t\t", "\"\"\"\n\t\t\tbinary-classification-NCE: noise times might be rejected\n\t\t\t\"\"\"", "\n", "fractional", "=", "False", "\n", "", "else", ":", "\n", "\t\t\t", "raise", "Exception", "(", "f\"Unknown NCE method : {nce_method}\"", ")", "\n", "", "\"\"\"\n\t\tNOTE : drawing from Poisson process with constant rates \n\t\tvery easy and fast --- no thinning at all \n\t\t\"\"\"", "\n", "coarse_inten", "=", "self", ".", "get_intensities_all_coarse_types", "(", ")", "# C", "\n", "total_coarse_inten", "=", "coarse_inten", ".", "sum", "(", ")", "# scalar ", "\n", "sample_rate", "=", "total_coarse_inten", "\n", "\n", "sample_num_per_seq", "=", "int", "(", "over", "*", "M1", "+", "self", ".", "eps", ")", "\n", "sample_num_per_seq", "=", "1", "if", "sample_num_per_seq", "<", "1", "else", "sample_num_per_seq", "\n", "sample_num_max", "=", "sample_num_per_seq", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "Exp_numbers", "=", "torch", ".", "empty", "(", "\n", "size", "=", "[", "batch_size", ",", "sample_num_max", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "self", ".", "device", ")", "\n", "Exp_numbers", ".", "exponential_", "(", "1.0", ")", "\n", "sampled_dt", "=", "Exp_numbers", "/", "(", "sample_rate", "*", "M1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "sampled_dt", "=", "sampled_dt", ".", "cumsum", "(", "dim", "=", "-", "1", ")", "# batch_size x sample_num_max", "\n", "\"\"\"\n\t\tsince no thinning is used, we use all sampled times as noise times \n\t\tmeaning that we ``accept'' all of them so all accept probs are 1.0\n\t\t\"\"\"", "\n", "dtime_noise", "=", "sampled_dt", "\n", "to_collect", "=", "sampled_dt", "<", "dtime", ".", "unsqueeze", "(", "-", "1", ")", "\n", "mask_noise", "=", "to_collect", ".", "float", "(", ")", "\n", "accept_prob_noise", "=", "torch", ".", "ones_like", "(", "dtime_noise", ")", "\n", "S", "=", "sample_num_max", "\n", "\"\"\"\n\t\tcount # of intensities to be computed for sampling noise times and types\n\t\tfor this model, it is 0 because nothing is neural!!!\n\t\tnon-neural intensities are very cheap to compute!!!\n\t\t\"\"\"", "\n", "inten_num_noise", "=", "0", "\n", "\"\"\"\n\t\tsample event types at noise times and actual time \n\t\t\"\"\"", "\n", "\"\"\"\n\t\tNOTE : coarse intensities are same across sequences and intervals\n\t\twe can leverage this fact to speed up code \n\t\tSLOW and naive : for each noise time, have a prob vector and sample types \n\t\tFAST : only one prob vector, (over-)sample types and then reshape \n\t\t\"\"\"", "\n", "expand_coarse_inten", "=", "coarse_inten", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "# 1 x 1 x C", "\n", "fine_inten", "=", "self", ".", "coarse_to_fine", ".", "get_fine_probs_all_types", "(", "expand_coarse_inten", ")", "\n", "# 1 x 1 x K ", "\n", "if", "type_mask", "is", "not", "None", ":", "\n", "\t\t\t", "fine_inten", "=", "fine_inten", "*", "type_mask", "\n", "\n", "", "sampled_types", "=", "sample_noise_types", "(", "\n", "fine_inten", ",", "1", ",", "1", ",", "batch_size", "*", "(", "S", "+", "1", ")", "*", "M2", ",", "\n", "self", ".", "event_num", ",", "self", ".", "noise_mode", ",", "self", ".", "device", "\n", ")", "# 1 x 1 x ( batch_size x (S+1) x M2 )", "\n", "type_both_noise", "=", "sampled_types", ".", "view", "(", "batch_size", ",", "S", "+", "1", ",", "M2", ")", "\n", "\n", "fine_inten_both", "=", "fine_inten", ".", "expand", "(", "batch_size", ",", "S", "+", "1", ",", "self", ".", "event_num", ")", "\n", "\n", "\"\"\"\n\t\tgather intensities at actual and noise times \n\t\tof actual and noise types \n\t\t\"\"\"", "\n", "type_actual_both", "=", "torch", ".", "cat", "(", "\n", "[", "target", ".", "unsqueeze", "(", "-", "1", ")", ",", "type_both_noise", "[", ":", ",", "-", "1", ",", ":", "]", "]", ",", "dim", "=", "-", "1", "\n", ")", "# batch_size x (1 + M2)", "\n", "fine_inten_actual_both", "=", "torch", ".", "gather", "(", "\n", "fine_inten_both", "[", ":", ",", "-", "1", ",", ":", "]", ",", "# batch_size x K ", "\n", "1", ",", "type_actual_both", "\n", ")", "# batch_size x (1 + M2)", "\n", "fine_inten_noise_noise", "=", "torch", ".", "gather", "(", "\n", "fine_inten_both", "[", ":", ",", ":", "-", "1", ",", ":", "]", ",", "# batch_size x S x K", "\n", "2", ",", "type_both_noise", "[", ":", ",", ":", "-", "1", ",", ":", "]", "\n", ")", "# batch_size x S x M2", "\n", "return", "type_both_noise", ",", "dtime_noise", ",", "mask_noise", ",", "fine_inten_actual_both", ",", "fine_inten_noise_noise", ",", "accept_prob_noise", ",", "S", ",", "inten_num_noise", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.draw_seq": [[351, 353], ["None"], "methods", ["None"], ["def", "draw_seq", "(", "self", ",", "num", ")", ":", "\n", "\t\t", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.update": [[354, 356], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ")", ":", "\n", "\t\t", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.pp.GPP.draw_next": [[357, 359], ["None"], "methods", ["None"], ["", "def", "draw_next", "(", "self", ")", ":", "\n", "\t\t", "raise", "NotImplementedError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.utils.draw_mc_samples": [[15, 54], ["torch.max", "torch.max", "torch.max", "c.size", "torch.ones", "torch.ones", "torch.ones", "u.uniform_.uniform_", "dtime.unsqueeze", "c.unsqueeze().expand", "cb.unsqueeze().expand", "d.unsqueeze().expand", "o.unsqueeze().expand", "torch.ones", "torch.ones", "torch.ones", "torch.arange", "torch.arange", "torch.arange", "mask_inter.cumprod.cumprod", "c.unsqueeze", "cb.unsqueeze", "d.unsqueeze", "o.unsqueeze"], "function", ["None"], ["def", "draw_mc_samples", "(", "c", ",", "cb", ",", "d", ",", "o", ",", "dtime", ",", "M", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n    input\n        c [B x D] : c_i in NHP\n        cb [B x D] : \\bar{c}_i in NHP\n        d [B x D] : d_i in NHP, how fast c(t) goes from c_i to \\bar{c}_i\n        o [B x D] :  o_i in NHP\n        dtime [B] : actual time intervals between last and next actual event \n        M [B] : # of MC samples per interval of each sequence in batch\n    \"\"\"", "\n", "#print(f\"start sampling MC samples\")", "\n", "#print(f'memory afterwards : {process.memory_info().rss/1000000:.3f} MB')", "\n", "M_max", "=", "torch", ".", "max", "(", "M", ")", "\n", "batch_size", ",", "D", "=", "c", ".", "size", "(", ")", "\n", "u", "=", "torch", ".", "ones", "(", "\n", "size", "=", "[", "batch_size", ",", "M_max", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "u", "=", "u", ".", "uniform_", "(", "0.0", ",", "1.0", ")", "\n", "dtime_inter", "=", "dtime", ".", "unsqueeze", "(", "-", "1", ")", "\n", "dtime_inter", "=", "dtime_inter", "*", "u", "# uniformly sample dtimes over interval", "\n", "\n", "c_inter", "=", "c", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "M_max", ",", "D", ")", "\n", "cb_inter", "=", "cb", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "M_max", ",", "D", ")", "\n", "d_inter", "=", "d", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "M_max", ",", "D", ")", "\n", "o_inter", "=", "o", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "M_max", ",", "D", ")", "\n", "\n", "\"\"\"\n    mask out the padded samples \n    overhead for the padded elements can't be avoided\n    \"\"\"", "\n", "mask_inter", "=", "torch", ".", "ones", "(", "\n", "size", "=", "[", "batch_size", ",", "M_max", "+", "1", "]", ",", "dtype", "=", "torch", ".", "float32", ",", "device", "=", "device", ")", "\n", "# init as all 1.0", "\n", "r", "=", "torch", ".", "arange", "(", "0", ",", "batch_size", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "mask_inter", "[", "r", ",", "M", "]", "=", "0.0", "# for each seq, set 0.0 at its length", "\n", "mask_inter", "=", "mask_inter", ".", "cumprod", "(", "dim", "=", "1", ")", "# roll 0.0 over to the end", "\n", "mask_inter", "=", "mask_inter", "[", ":", ",", ":", "-", "1", "]", "\n", "#print(f\"after sampling MC samples\")", "\n", "#print(f'memory afterwards : {process.memory_info().rss/1000000:.3f} MB')", "\n", "return", "c_inter", ",", "cb_inter", ",", "d_inter", ",", "o_inter", ",", "dtime_inter", ",", "mask_inter", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.utils.sample_noise_types": [[59, 89], ["utils.sample_uniform", "Exception", "utils.sample_multinomial_numpy", "utils.sample_multinomial_torch", "Exception"], "function", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.utils.sample_uniform", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.utils.sample_multinomial_numpy", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.utils.sample_multinomial_torch"], ["def", "sample_noise_types", "(", "probs", ",", "s0", ",", "s1", ",", "num", ",", "event_num", ",", "noise_mode", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n    input \n        probs [tensor of s0 x s1 x K] : probabilities over K types\n        s0 [int] : size-0 of probs \n        s1 [int] : size-1 of probs \n        num [int] : # of i.i.d. samples per probs[i,j]\n    \"\"\"", "\n", "\"\"\"\n    NOTE : sampling from multinomial is slow\n    SOLUTION : we sample case by case\n    we can choose to always sample uniformly : cuz it is fast\n    otherwise\n        if it is on CPU : \n            convert it to numpy and do multinomial sampling there\n        if it is on GPU : \n            use torch.multinomial()\n    \"\"\"", "\n", "if", "noise_mode", "==", "'uniform'", ":", "\n", "        ", "rst", "=", "sample_uniform", "(", "s0", ",", "s1", ",", "num", ",", "event_num", ")", "\n", "", "elif", "noise_mode", "==", "'multinomial'", ":", "\n", "        ", "if", "device", ".", "type", "==", "'cpu'", ":", "\n", "            ", "rst", "=", "sample_multinomial_numpy", "(", "probs", ",", "s0", ",", "s1", ",", "num", ",", "event_num", ")", "\n", "", "elif", "device", ".", "type", "==", "'cuda'", ":", "\n", "            ", "rst", "=", "sample_multinomial_torch", "(", "probs", ",", "s0", ",", "s1", ",", "num", ",", "event_num", ")", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "f\"Unknown device type : {device.type}\"", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "f\"Unknow noise mode : {noise_mode}\"", ")", "\n", "", "return", "rst", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.utils.sample_multinomial_torch": [[90, 97], ["probs.view", "torch.multinomial", "torch.multinomial", "torch.multinomial", "rst.view.view"], "function", ["None"], ["", "def", "sample_multinomial_torch", "(", "probs", ",", "s0", ",", "s1", ",", "num", ",", "event_num", ")", ":", "\n", "# probs are unnormalized ", "\n", "    ", "probs_view", "=", "probs", ".", "view", "(", "-", "1", ",", "event_num", ")", "\n", "rst", "=", "torch", ".", "multinomial", "(", "\n", "probs_view", ",", "num", ",", "replacement", "=", "True", ")", "\n", "rst", "=", "rst", ".", "view", "(", "s0", ",", "s1", ",", "num", ")", "# s0 x s1 x NUM", "\n", "return", "rst", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.utils.sample_multinomial_numpy": [[98, 111], ["probs.view", "probs.view.numpy", "probs_view.numpy.cumsum", "numpy.random.uniform", "torch.from_numpy().long", "torch.from_numpy().long", "torch.from_numpy().long", "rst.view.view", "numpy.sum", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "function", ["None"], ["", "def", "sample_multinomial_numpy", "(", "probs", ",", "s0", ",", "s1", ",", "num", ",", "event_num", ")", ":", "\n", "# probs are unnormalized ", "\n", "    ", "probs_view", "=", "probs", ".", "view", "(", "-", "1", ",", "event_num", ")", "# s0*s1 x K ", "\n", "probs_np", "=", "probs_view", ".", "numpy", "(", ")", "\n", "cum_probs_np", "=", "probs_np", ".", "cumsum", "(", "axis", "=", "1", ")", "# s0*s1 x K ", "\n", "unif", "=", "np", ".", "random", ".", "uniform", "(", "0.0", ",", "1.0", ",", "size", "=", "[", "s0", "*", "s1", ",", "num", "]", ")", "# s0*s1 x NUM", "\n", "bound", "=", "cum_probs_np", "[", ":", ",", "-", "1", "]", "*", "unif", ".", "T", "# NUM x s0*s1", "\n", "acc", "=", "cum_probs_np", "[", "np", ".", "newaxis", ",", ":", ",", ":", "]", "<", "bound", "[", ":", ",", ":", ",", "np", ".", "newaxis", "]", "\n", "# NUM x s0*s1 x K ", "\n", "acc", "=", "np", ".", "sum", "(", "acc", ",", "axis", "=", "2", ")", ".", "T", "# s0*s1 x NUM", "\n", "rst", "=", "torch", ".", "from_numpy", "(", "acc", ")", ".", "long", "(", ")", "\n", "rst", "=", "rst", ".", "view", "(", "s0", ",", "s1", ",", "num", ")", "# s0 x s1 x NUM", "\n", "return", "rst", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.models.utils.sample_uniform": [[112, 117], ["torch.zeros().uniform_", "torch.zeros().uniform_", "torch.zeros().uniform_", "torch.zeros", "torch.zeros", "torch.zeros"], "function", ["None"], ["", "def", "sample_uniform", "(", "s0", ",", "s1", ",", "num", ",", "event_num", ")", ":", "\n", "# probs are unnormalized", "\n", "    ", "probs", "=", "torch", ".", "zeros", "(", "s0", ",", "s1", ",", "num", ",", "device", "=", "device", ")", ".", "uniform_", "(", "0.0", ",", "1.0", ")", "\n", "rst", "=", "(", "probs", "*", "event_num", ")", ".", "long", "(", ")", "# s0 x s1 x NUM", "\n", "return", "rst", "\n", "", ""]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.data.DataProcessor.__init__": [[7, 16], ["torch.device", "numpy.finfo"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ",", "\n", "idx_BOS", ",", "idx_EOS", ",", "idx_PAD", ",", "device", "=", "None", ")", ":", "\n", "\t\t", "self", ".", "idx_BOS", "=", "idx_BOS", "\n", "self", ".", "idx_EOS", "=", "idx_EOS", "\n", "self", ".", "idx_PAD", "=", "idx_PAD", "\n", "\n", "device", "=", "device", "or", "'cpu'", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "self", ".", "eps", "=", "np", ".", "finfo", "(", "float", ")", ".", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.data.DataProcessor.process_seq": [[17, 41], ["torch.zeros().long", "torch.zeros", "enumerate", "len", "int", "float", "torch.zeros"], "methods", ["None"], ["", "def", "process_seq", "(", "self", ",", "seq", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tThe process seq function is moved to the class.\n\t\t:param list seq:\n\t\t\"\"\"", "\n", "# including BOS and EOS", "\n", "len_seq", "=", "len", "(", "seq", ")", "+", "2", "\n", "event", "=", "torch", ".", "zeros", "(", "\n", "size", "=", "[", "len_seq", "]", ",", "device", "=", "self", ".", "device", ",", "dtype", "=", "torch", ".", "int64", ")", ".", "long", "(", ")", "\n", "event", "[", "-", "1", "]", "=", "self", ".", "idx_EOS", "\n", "event", "[", "0", "]", "=", "self", ".", "idx_BOS", "\n", "\n", "dtime", "=", "torch", ".", "zeros", "(", "\n", "size", "=", "[", "len_seq", "]", ",", "device", "=", "self", ".", "device", ",", "dtype", "=", "torch", ".", "float32", ")", "\n", "for", "token_idx", ",", "token", "in", "enumerate", "(", "seq", ")", ":", "\n", "\t\t\t", "event", "[", "token_idx", "+", "1", "]", "=", "int", "(", "token", "[", "'name'", "]", ")", "\n", "dtime", "[", "token_idx", "+", "1", "]", "=", "float", "(", "token", "[", "'time_since_last_event'", "]", ")", "\n", "\n", "", "dtime", "[", "-", "1", "]", "=", "0.1", "\n", "duration", "=", "seq", "[", "-", "1", "]", "[", "'time'", "]", "+", "self", ".", "eps", "\n", "\n", "return", "event", ",", "dtime", ",", "len_seq", "-", "2", ",", "duration", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.data.DataProcessor.process_batch": [[42, 72], ["len", "data.DataProcessor.process_seq", "input.append", "input_lens.append", "batched_lens.append", "data.DataProcessor.org_batch", "batched_data.append", "batched_noise.append", "len", "torch.tensor().view", "len", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.data.DataProcessor.process_seq", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.data.DataProcessor.org_batch"], ["", "def", "process_batch", "(", "self", ",", "data", ",", "batch_size", ")", ":", "\n", "\t\t", "data_size", "=", "len", "(", "data", ")", "\n", "idx_seq", "=", "0", "\n", "\n", "batched_data", "=", "[", "]", "\n", "batched_lens", "=", "[", "]", "\n", "batched_noise", "=", "[", "]", "\n", "\n", "input", "=", "[", "]", "\n", "input_lens", "=", "[", "]", "\n", "\n", "while", "idx_seq", "<", "data_size", ":", "\n", "\t\t\t", "one_seq", "=", "data", "[", "idx_seq", "]", "\n", "event", ",", "dtime", ",", "len_seq", ",", "duration", "=", "self", ".", "process_seq", "(", "one_seq", ")", "\n", "input", ".", "append", "(", "(", "event", ",", "dtime", ",", "len_seq", ",", "duration", ")", ")", "\n", "input_lens", ".", "append", "(", "len_seq", ")", "\n", "\n", "if", "len", "(", "input", ")", ">=", "batch_size", "or", "idx_seq", "==", "data_size", "-", "1", ":", "\n", "\t\t\t\t", "batched_lens", ".", "append", "(", "\n", "torch", ".", "tensor", "(", "\n", "input_lens", ",", "device", "=", "self", ".", "device", ")", ".", "view", "(", "len", "(", "input", ")", ",", "1", ")", ")", "\n", "input_lens", "=", "[", "]", "\n", "\n", "batchdata_seqs", "=", "self", ".", "org_batch", "(", "input", ")", "\n", "batched_data", ".", "append", "(", "batchdata_seqs", ")", "\n", "batched_noise", ".", "append", "(", "None", ")", "\n", "input", "=", "[", "]", "\n", "\n", "", "idx_seq", "=", "idx_seq", "+", "1", "\n", "", "return", "batched_data", ",", "batched_noise", "#, batched_lens", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.data.DataProcessor.org_batch": [[74, 102], ["len", "torch.zeros().fill_().long", "torch.zeros().fill_", "torch.zeros().long", "torch.zeros", "enumerate", "event_dtime_tuple[].size", "event_dtime_tuple[].size", "torch.zeros().fill_", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "def", "org_batch", "(", "self", ",", "batch_of_seqs", ")", ":", "\n", "\n", "\t\t", "batch_size", "=", "len", "(", "batch_of_seqs", ")", "\n", "max_len", "=", "-", "1", "\n", "\n", "for", "event_dtime_tuple", "in", "batch_of_seqs", ":", "\n", "\t\t\t", "seq_len", "=", "event_dtime_tuple", "[", "0", "]", ".", "size", "(", "0", ")", "\n", "if", "seq_len", ">", "max_len", ":", "\n", "\t\t\t\t", "max_len", "=", "seq_len", "\n", "\n", "", "", "event_tensor", "=", "torch", ".", "zeros", "(", "size", "=", "[", "batch_size", ",", "max_len", "]", ",", "device", "=", "self", ".", "device", ")", ".", "fill_", "(", "self", ".", "idx_PAD", ")", ".", "long", "(", ")", "\n", "dtime_tensor", "=", "torch", ".", "zeros", "(", "size", "=", "[", "batch_size", ",", "max_len", "]", ",", "device", "=", "self", ".", "device", ")", ".", "fill_", "(", "0.1", ")", "#may need to change", "\n", "token_num_tensor", "=", "torch", ".", "zeros", "(", "size", "=", "[", "batch_size", "]", ",", "device", "=", "self", ".", "device", ")", ".", "long", "(", ")", "\n", "duration_tensor", "=", "torch", ".", "zeros", "(", "size", "=", "[", "batch_size", "]", ",", "device", "=", "self", ".", "device", ")", "\n", "\n", "for", "i_batch", ",", "event_dtime_tuple", "in", "enumerate", "(", "batch_of_seqs", ")", ":", "\n", "\t\t\t", "seq_len", "=", "event_dtime_tuple", "[", "0", "]", ".", "size", "(", "0", ")", "\n", "\n", "event_tensor", "[", "i_batch", ",", ":", "seq_len", "]", "=", "event_dtime_tuple", "[", "0", "]", "\n", "dtime_tensor", "[", "i_batch", ",", ":", "seq_len", "]", "=", "event_dtime_tuple", "[", "1", "]", "\n", "token_num_tensor", "[", "i_batch", "]", "=", "event_dtime_tuple", "[", "2", "]", "\n", "duration_tensor", "[", "i_batch", "]", "=", "event_dtime_tuple", "[", "3", "]", "\n", "\n", "", "return", "event_tensor", ",", "dtime_tensor", ",", "token_num_tensor", ",", "duration_tensor", "\n", "", "", ""]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogWriter.__init__": [[10, 21], ["open", "f.write", "f.write", "f.write", "f.write"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ",", "path", ",", "args", ")", ":", "\n", "\t\t", "if", "''", "in", "args", ":", "\n", "\t\t\t", "del", "args", "[", "''", "]", "\n", "", "self", ".", "path", "=", "path", "\n", "self", ".", "args", "=", "args", "\n", "with", "open", "(", "self", ".", "path", ",", "'w'", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "\"Training Log\\n\"", ")", "\n", "f", ".", "write", "(", "\"Specifications\\n\"", ")", "\n", "for", "argname", "in", "self", ".", "args", ":", "\n", "\t\t\t\t", "f", ".", "write", "(", "\"{} : {}\\n\"", ".", "format", "(", "argname", ",", "self", ".", "args", "[", "argname", "]", ")", ")", "\n", "", "f", ".", "write", "(", "\"Checkpoints:\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogWriter.checkpoint": [[22, 25], ["open", "f.write"], "methods", ["None"], ["", "", "def", "checkpoint", "(", "self", ",", "to_write", ")", ":", "\n", "\t\t", "with", "open", "(", "self", ".", "path", ",", "'a'", ")", "as", "f", ":", "\n", "\t\t\t", "f", ".", "write", "(", "to_write", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.__init__": [[29, 33], ["open", "f.read"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ",", "path", ")", ":", "\n", "\t\t", "self", ".", "path", "=", "path", "\n", "with", "open", "(", "self", ".", "path", ",", "'r'", ")", "as", "f", ":", "\n", "\t\t\t", "self", ".", "doc", "=", "f", ".", "read", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.isfloat": [[34, 40], ["float"], "methods", ["None"], ["", "", "def", "isfloat", "(", "self", ",", "str", ")", ":", "\n", "\t\t", "try", ":", "\n", "\t\t\t", "float", "(", "str", ")", "\n", "return", "True", "\n", "", "except", "ValueError", ":", "\n", "\t\t\t", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.cast_type": [[41, 52], ["str.isdigit", "int", "log.LogReader.isfloat", "float"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.isfloat"], ["", "", "def", "cast_type", "(", "self", ",", "str", ")", ":", "\n", "\t\t", "res", "=", "None", "\n", "if", "str", ".", "isdigit", "(", ")", ":", "\n", "\t\t\t", "res", "=", "int", "(", "str", ")", "\n", "", "elif", "self", ".", "isfloat", "(", "str", ")", ":", "\n", "\t\t\t", "res", "=", "float", "(", "str", ")", "\n", "", "elif", "str", "==", "'True'", "or", "str", "==", "'False'", ":", "\n", "\t\t\t", "res", "=", "True", "if", "str", "==", "'True'", "else", "False", "\n", "", "else", ":", "\n", "\t\t\t", "res", "=", "str", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.finished": [[53, 55], ["None"], "methods", ["None"], ["", "def", "finished", "(", "self", ")", ":", "\n", "\t\t", "return", "'training finished'", "in", "self", ".", "doc", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.get_args": [[56, 65], ["block_args.split", "dict", "log.LogReader.doc.split", "block_args.split", "line.split", "log.LogReader.cast_type"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.cast_type"], ["", "def", "get_args", "(", "self", ")", ":", "\n", "\t\t", "block_args", "=", "self", ".", "doc", ".", "split", "(", "'Specifications\\n'", ")", "[", "-", "1", "]", "\n", "block_args", "=", "block_args", ".", "split", "(", "'Checkpoints:\\n'", ")", "[", "0", "]", "\n", "lines_args", "=", "block_args", ".", "split", "(", "'\\n'", ")", "\n", "res", "=", "dict", "(", ")", "\n", "for", "line", "in", "lines_args", ":", "\n", "\t\t\t", "items", "=", "line", ".", "split", "(", "' : '", ")", "\n", "res", "[", "items", "[", "0", "]", "]", "=", "self", ".", "cast_type", "(", "items", "[", "-", "1", "]", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.get_best": [[66, 84], ["block_score.split", "log.LogReader.doc.split", "log.LogReader.cast_type", "log.LogReader.cast_type", "log.LogReader.cast_type", "line.split", "log.LogReader.split", "line.split", "log.LogReader.split", "line.split", "log.LogReader.split"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.cast_type", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.cast_type", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.cast_type"], ["", "def", "get_best", "(", "self", ")", ":", "\n", "\t\t", "block_score", "=", "self", ".", "doc", ".", "split", "(", "'Checkpoints:\\n'", ")", "[", "-", "1", "]", "\n", "lines_score", "=", "block_score", ".", "split", "(", "'\\n'", ")", "\n", "best_score", "=", "''", "\n", "best_batch", "=", "''", "\n", "best_epoch", "=", "''", "\n", "for", "line", "in", "lines_score", ":", "\n", "\t\t\t", "if", "'Current best loglik is'", "in", "line", ":", "\n", "\t\t\t\t", "best_score", "=", "line", ".", "split", "(", "'Current best loglik is '", ")", "[", "-", "1", "]", "\n", "best_score", "=", "best_score", ".", "split", "(", "' (updated at'", ")", "[", "0", "]", "\n", "best_batch", "=", "line", ".", "split", "(", "'(updated at '", ")", "[", "-", "1", "]", "\n", "best_batch", "=", "best_batch", ".", "split", "(", "'-th batch'", ")", "[", "0", "]", "\n", "best_epoch", "=", "line", ".", "split", "(", "'-th batch of '", ")", "[", "1", "]", "\n", "best_epoch", "=", "best_epoch", ".", "split", "(", "'-th epoch'", ")", "[", "0", "]", "\n", "best_score", "=", "self", ".", "cast_type", "(", "best_score", ")", "\n", "best_batch", "=", "self", ".", "cast_type", "(", "best_batch", ")", "\n", "best_epoch", "=", "self", ".", "cast_type", "(", "best_epoch", ")", "\n", "", "", "return", "best_score", ",", "best_batch", ",", "best_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.get_times_and_iteration": [[85, 107], ["block_times.split", "enumerate", "log.LogReader.doc.split", "line.split.split.split", "log.LogReader.cast_type", "log.LogReader.cast_type", "log.LogReader.cast_type", "log_liks.append", "iterations.append", "times.append", "line_time.split", "len"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.cast_type", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.cast_type", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.cast_type"], ["", "def", "get_times_and_iteration", "(", "self", ")", ":", "\n", "\t\t", "block_times", "=", "self", ".", "doc", ".", "split", "(", "'Checkpoints:\\n'", ")", "[", "1", "]", "\n", "line_times", "=", "block_times", ".", "split", "(", "'\\n'", ")", "\n", "log_liks", "=", "[", "]", "\n", "iterations", "=", "[", "]", "\n", "times", "=", "[", "0", "]", "\n", "for", "i_line", ",", "line", "in", "enumerate", "(", "line_times", ")", ":", "\n", "\t\t\t", "if", "'eval:'", "in", "line", ":", "\n", "\t\t\t\t", "line", "=", "line", ".", "split", "(", "' '", ")", "\n", "loglik", "=", "self", ".", "cast_type", "(", "line", "[", "-", "1", "]", ")", "\n", "iteration", "=", "self", ".", "cast_type", "(", "line", "[", "1", "]", ")", "\n", "\n", "if", "i_line", "<", "len", "(", "line_times", ")", "-", "1", ":", "\n", "\t\t\t\t\t", "line_time", "=", "line_times", "[", "i_line", "+", "1", "]", "\n", "\n", "", "time", "=", "line_time", ".", "split", "(", "' '", ")", "[", "0", "]", "\n", "time", "=", "self", ".", "cast_type", "(", "time", ")", "\n", "\n", "log_liks", ".", "append", "(", "loglik", ")", "\n", "iterations", ".", "append", "(", "iteration", ")", "\n", "times", ".", "append", "(", "time", "+", "times", "[", "-", "1", "]", ")", "\n", "", "", "return", "log_liks", ",", "iterations", ",", "times", "[", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.get_vals": [[108, 129], ["block_vals.split", "len", "list", "enumerate", "log.LogReader.doc.split", "line.split.split.split", "log.LogReader.cast_type", "log.LogReader.cast_type", "log.LogReader.cast_type", "log.LogReader.cast_type", "list.append", "lines[].split", "lines[].split"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.cast_type", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.cast_type", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.cast_type", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.cast_type"], ["", "def", "get_vals", "(", "self", ")", ":", "\n", "\t\t", "block_vals", "=", "self", ".", "doc", ".", "split", "(", "'Checkpoints:\\n'", ")", "[", "-", "1", "]", "\n", "lines", "=", "block_vals", ".", "split", "(", "'\\n'", ")", "\n", "total_len", "=", "len", "(", "lines", ")", "\n", "rst", "=", "list", "(", ")", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "\t\t\t", "if", "'eval: '", "in", "line", "and", "i", "<", "total_len", "-", "2", ":", "\n", "\t\t\t\t", "\"\"\"\n\t\t\t\ttrack loglik, train time, and # of intensities computed\n\t\t\t\tif any of them is missing, we discard all of them\n\t\t\t\t\"\"\"", "\n", "line", "=", "line", ".", "split", "(", "' '", ")", "\n", "loglik", "=", "self", ".", "cast_type", "(", "line", "[", "-", "1", "]", ")", "\n", "i_iter", "=", "self", ".", "cast_type", "(", "line", "[", "1", "]", ")", "\n", "# i : eval : ...", "\n", "assert", "'seconds for training since last validation'", "in", "lines", "[", "i", "+", "1", "]", "\n", "t", "=", "self", ".", "cast_type", "(", "lines", "[", "i", "+", "1", "]", ".", "split", "(", "' '", ")", "[", "0", "]", ")", "\n", "assert", "'# of intensities computed = '", "in", "lines", "[", "i", "+", "2", "]", "\n", "c", "=", "self", ".", "cast_type", "(", "lines", "[", "i", "+", "2", "]", ".", "split", "(", "' '", ")", "[", "-", "4", "]", ")", "\n", "rst", ".", "append", "(", "f'iter{i_iter}|{t}|{c}|{loglik}'", ")", "\n", "", "", "return", "rst", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.get_all": [[130, 139], ["log.LogReader.get_args", "len", "log.LogReader.get_vals", "log.LogReader.get_best"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.get_args", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.get_vals", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.get_best"], ["", "def", "get_all", "(", "self", ")", ":", "\n", "\t\t", "rst", "=", "self", ".", "get_args", "(", ")", "\n", "i", "=", "len", "(", "rst", ")", "\n", "rst", "[", "'Values'", "]", "=", "self", ".", "get_vals", "(", ")", "\n", "best_score", ",", "best_batch", ",", "best_epoch", "=", "self", ".", "get_best", "(", ")", "\n", "rst", "[", "'_best_score'", "]", "=", "best_score", "\n", "rst", "[", "'_best_batch'", "]", "=", "best_batch", "\n", "rst", "[", "'_best_epoch'", "]", "=", "best_epoch", "\n", "return", "rst", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.__init__": [[142, 153], ["list", "log.LogBatchReader.walklevel", "fnmatch.filter", "os.path.join", "log.LogBatchReader.all_readers.append", "log.LogReader"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.walklevel"], ["\t", "def", "__init__", "(", "self", ",", "path", ",", "name", ")", ":", "\n", "\t\t", "self", ".", "path", "=", "path", "\n", "self", ".", "name", "=", "name", "\n", "\"\"\"\n\t\tgiven domain path, find all the log folders and get their results\n\t\t\"\"\"", "\n", "self", ".", "all_readers", "=", "list", "(", ")", "\n", "for", "root", ",", "dirs", ",", "files", "in", "self", ".", "walklevel", "(", "path", ")", ":", "\n", "\t\t\t", "for", "file_name", "in", "fnmatch", ".", "filter", "(", "files", ",", "'log.txt'", ")", ":", "\n", "\t\t\t\t", "full_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "file_name", ")", "\n", "self", ".", "all_readers", ".", "append", "(", "LogReader", "(", "full_path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.walklevel": [[154, 163], ["some_dir.rstrip.rstrip.rstrip", "os.path.isdir", "some_dir.rstrip.rstrip.count", "os.walk", "root.count"], "methods", ["None"], ["", "", "", "def", "walklevel", "(", "self", ",", "some_dir", ",", "level", "=", "1", ")", ":", "\n", "\t\t", "some_dir", "=", "some_dir", ".", "rstrip", "(", "os", ".", "path", ".", "sep", ")", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "some_dir", ")", "\n", "num_sep", "=", "some_dir", ".", "count", "(", "os", ".", "path", ".", "sep", ")", "\n", "for", "root", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "some_dir", ")", ":", "\n", "\t\t\t", "yield", "root", ",", "dirs", ",", "files", "\n", "num_sep_this", "=", "root", ".", "count", "(", "os", ".", "path", ".", "sep", ")", "\n", "if", "num_sep", "+", "level", "<=", "num_sep_this", ":", "\n", "\t\t\t\t", "del", "dirs", "[", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.write_csv": [[164, 213], ["os.path.join", "print", "log.LogBatchReader.make_header", "dict", "print", "sorted", "os.path.join", "print", "print", "print", "open", "csv.DictWriter", "csv.DictWriter.writeheader", "enumerate", "dict.keys", "open", "csv.DictWriter", "csv.DictWriter.writeheader", "range", "log_reader.get_all", "log.LogBatchReader.process_info", "csv.DictWriter.writerow", "log_reader.finished", "dict", "csv.DictWriter.writerow", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.make_header", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.get_all", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.process_info", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.finished"], ["", "", "", "def", "write_csv", "(", "self", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tNOTE : it is possible that the Values field is TOO long \n\t\tso microsoft excel may not show it \n\t\tin that case, we can create two sheets: \n\t\t(1) each row is a run, each col is a field, not including Values \n\t\t(2) each col is a run---all its values...\n\t\t\"\"\"", "\n", "path_save_meta", "=", "os", ".", "path", ".", "join", "(", "self", ".", "path", ",", "f\"{self.name}_meta.csv\"", ")", "\n", "print", "(", "f\"writing {path_save_meta}\"", ")", "\n", "names_field", "=", "self", ".", "make_header", "(", ")", "\n", "c", "=", "0", "\n", "i_log_values", "=", "dict", "(", ")", "\n", "max_log", "=", "-", "1", "\n", "\"\"\"\n\t\twrite meta info\n\t\t\"\"\"", "\n", "with", "open", "(", "path_save_meta", ",", "'w'", ")", "as", "file_csv", ":", "\n", "\t\t\t", "writer_csv", "=", "csv", ".", "DictWriter", "(", "file_csv", ",", "fieldnames", "=", "names_field", ")", "\n", "writer_csv", ".", "writeheader", "(", ")", "\n", "for", "i_log", ",", "log_reader", "in", "enumerate", "(", "self", ".", "all_readers", ")", ":", "\n", "\t\t\t\t", "dict_rst", "=", "log_reader", ".", "get_all", "(", ")", "\n", "i_log_values", "[", "i_log", "]", "=", "dict_rst", "[", "'Values'", "]", "\n", "if", "len", "(", "dict_rst", "[", "'Values'", "]", ")", ">", "max_log", ":", "\n", "\t\t\t\t\t", "max_log", "=", "len", "(", "dict_rst", "[", "'Values'", "]", ")", "\n", "", "self", ".", "process_info", "(", "dict_rst", ",", "i_log", ")", "\n", "writer_csv", ".", "writerow", "(", "dict_rst", ")", "\n", "if", "log_reader", ".", "finished", "(", ")", ":", "\n", "\t\t\t\t\t", "c", "+=", "1", "\n", "", "", "", "print", "(", "f\"meta csv finished\"", ")", "\n", "\"\"\"\n\t\twrite log details\n\t\t\"\"\"", "\n", "names_field", "=", "sorted", "(", "i_log_values", ".", "keys", "(", ")", ")", "\n", "path_save_log", "=", "os", ".", "path", ".", "join", "(", "self", ".", "path", ",", "f\"{self.name}_log.csv\"", ")", "\n", "print", "(", "f\"writing {path_save_log}\"", ")", "\n", "with", "open", "(", "path_save_log", ",", "'w'", ")", "as", "file_csv", ":", "\n", "\t\t\t", "writer_csv", "=", "csv", ".", "DictWriter", "(", "file_csv", ",", "fieldnames", "=", "names_field", ")", "\n", "writer_csv", ".", "writeheader", "(", ")", "\n", "for", "i_row", "in", "range", "(", "max_log", ")", ":", "\n", "\t\t\t\t", "dict_row", "=", "dict", "(", ")", "\n", "for", "i_log", "in", "names_field", ":", "\n", "\t\t\t\t\t", "if", "i_row", "<", "len", "(", "i_log_values", "[", "i_log", "]", ")", ":", "\n", "\t\t\t\t\t\t", "dict_row", "[", "i_log", "]", "=", "i_log_values", "[", "i_log", "]", "[", "i_row", "]", "\n", "", "else", ":", "\n", "\t\t\t\t\t\t", "dict_row", "[", "i_log", "]", "=", "''", "\n", "", "", "writer_csv", ".", "writerow", "(", "dict_row", ")", "\n", "", "", "print", "(", "f\"log csv finished\"", ")", "\n", "print", "(", "f\"{c} out of {len(self.all_readers)} organized logs finished training\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.make_header": [[214, 235], ["set", "enumerate", "list.add", "list.add", "list", "log.LogBatchReader.get_to_show", "log_reader.get_all", "log.LogBatchReader.process_info", "heapq.heappush", "rst.append", "list.add", "heapq.heappop"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.get_to_show", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogReader.get_all", "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.process_info"], ["", "def", "make_header", "(", "self", ")", ":", "\n", "\t\t", "names_field", "=", "set", "(", ")", "\n", "for", "i_log", ",", "log_reader", "in", "enumerate", "(", "self", ".", "all_readers", ")", ":", "\n", "\t\t\t", "dict_rst", "=", "log_reader", ".", "get_all", "(", ")", "\n", "self", ".", "process_info", "(", "dict_rst", ",", "i_log", ")", "\n", "for", "k", "in", "dict_rst", ":", "\n", "\t\t\t\t", "names_field", ".", "add", "(", "k", ")", "\n", "", "", "names_field", ".", "add", "(", "'_index'", ")", "\n", "names_field", ".", "add", "(", "'_keep'", ")", "\n", "names_field", "=", "list", "(", "names_field", ")", "\n", "hq", "=", "[", "]", "\n", "to_show", "=", "self", ".", "get_to_show", "(", ")", "\n", "\"\"\"\n\t\theader is sorted based on to_show value\n\t\t\"\"\"", "\n", "rst", "=", "[", "]", "\n", "for", "nf", "in", "names_field", ":", "\n", "\t\t\t", "heapq", ".", "heappush", "(", "hq", ",", "(", "to_show", "[", "nf", "]", ",", "nf", ")", ")", "\n", "", "while", "hq", ":", "\n", "\t\t\t", "rst", ".", "append", "(", "heapq", ".", "heappop", "(", "hq", ")", "[", "1", "]", ")", "\n", "", "return", "rst", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.process_info": [[236, 247], ["log.LogBatchReader.get_to_show", "to_del.append"], "methods", ["home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.get_to_show"], ["", "def", "process_info", "(", "self", ",", "x", ",", "i", ")", ":", "\n", "# or to delete? ", "\n", "\t\t", "to_show", "=", "self", ".", "get_to_show", "(", ")", "\n", "to_del", "=", "[", "]", "\n", "for", "k", "in", "x", ":", "\n", "\t\t\t", "if", "k", "not", "in", "to_show", ":", "\n", "\t\t\t\t", "to_del", ".", "append", "(", "k", ")", "\n", "", "", "for", "k", "in", "to_del", ":", "\n", "\t\t\t", "del", "x", "[", "k", "]", "\n", "", "x", "[", "'_index'", "]", "=", "i", "\n", "x", "[", "'_keep'", "]", "=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.HMEIatJHU_nce-mpp.io.log.LogBatchReader.get_to_show": [[248, 267], ["None"], "methods", ["None"], ["", "def", "get_to_show", "(", "self", ")", ":", "\n", "\t\t", "to_show", "=", "{", "\n", "'TrainMethod'", ":", "0", ",", "\n", "'Model'", ":", "1", ",", "\n", "'DimLSTM'", ":", "2", ",", "'Config'", ":", "3", ",", "\n", "'SizeBatchCompute'", ":", "4", ",", "'SizeBatchUpdate'", ":", "5", ",", "\n", "'TrackPeriod'", ":", "6", ",", "\n", "'TrainRatio'", ":", "7", ",", "'DevRatio'", ":", "8", ",", "\n", "'MaxEpoch'", ":", "9", ",", "'MCSample'", ":", "10", ",", "'NoiseFolder'", ":", "11", ",", "\n", "'ReDrawProb'", ":", "12", ",", "\n", "'NoiseProcess'", ":", "13", ",", "'NoiseType'", ":", "14", ",", "'NoiseMode'", ":", "15", ",", "\n", "'OverRate'", ":", "16", ",", "#'LearnRate', ", "\n", "'Seed'", ":", "17", ",", "'UseGPU'", ":", "18", ",", "'ID'", ":", "19", ",", "\n", "'_best_score'", ":", "20", ",", "'_best_batch'", ":", "21", ",", "'_best_epoch'", ":", "22", ",", "\n", "'_index'", ":", "23", ",", "\n", "#'Values' : 21, ", "\n", "'_keep'", ":", "24", ",", "\n", "}", "\n", "return", "to_show", "\n", "", "", ""]]}