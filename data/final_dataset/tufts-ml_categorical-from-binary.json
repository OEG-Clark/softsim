{"home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.None.help.read_makefile": [[27, 30], ["open", "f.readlines"], "function", ["None"], ["", "def", "read_makefile", "(", "makefile", "=", "\"Makefile_ds.mk\"", ")", ":", "\n", "    ", "with", "open", "(", "makefile", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "return", "f", ".", "readlines", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.None.help.parse_commands": [[32, 39], ["enumerate", "re.match", "help.get_doc", "re.match.group", "re.match.group"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.None.help.get_doc"], ["", "", "def", "parse_commands", "(", "lines", ")", ":", "\n", "    ", "commands", "=", "{", "}", "\n", "for", "line_no", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "        ", "m", "=", "re", ".", "match", "(", "r\"^([a-z-]+):\"", ",", "line", ")", "\n", "if", "m", "and", "m", ".", "group", "(", ")", "!=", "\"force:\"", ":", "\n", "            ", "commands", "[", "m", ".", "group", "(", ")", "]", "=", "get_doc", "(", "lines", "[", ":", "line_no", "]", ")", "\n", "", "", "return", "commands", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.None.help.get_doc": [[41, 50], ["reversed", "list", "line.startswith", "reversed", "list.append"], "function", ["None"], ["", "def", "get_doc", "(", "lines", ")", ":", "\n", "    ", "doc", "=", "[", "]", "\n", "for", "line", "in", "reversed", "(", "lines", ")", ":", "\n", "        ", "if", "line", ".", "startswith", "(", "\"#\"", ")", ":", "\n", "            ", "doc", ".", "append", "(", "line", ")", "\n", "", "else", ":", "\n", "            ", "break", "\n", "", "", "doc", "=", "list", "(", "reversed", "(", "doc", ")", ")", "\n", "return", "\"\"", ".", "join", "(", "doc", ")", ".", "strip", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.None.help.print_commands": [[52, 62], ["commands.items", "print", "print", "print", "len", "re.sub"], "function", ["None"], ["", "def", "print_commands", "(", "commands", ")", ":", "\n", "    ", "for", "k", ",", "v", "in", "commands", ".", "items", "(", ")", ":", "\n", "        ", "if", "len", "(", "k", ")", "<", "TAB_LEN", "and", "v", ":", "\n", "            ", "end", "=", "\"\"", "\n", "", "else", ":", "\n", "            ", "end", "=", "\"\\n\"", "\n", "", "print", "(", "bcolors", ".", "OKGREEN", "+", "k", "+", "bcolors", ".", "ENDC", ",", "end", "=", "end", ")", "\n", "if", "v", ":", "\n", "            ", "print", "(", "re", ".", "sub", "(", "\"#+\"", ",", "\"\\t\"", ",", "v", ")", ")", "\n", "", "print", "(", "end", "=", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.None.setup.get_version": [[13, 17], ["VERSION_RE.search().group", "open", "fh.read().strip", "VERSION_RE.search", "fh.read"], "function", ["None"], ["def", "get_version", "(", ")", ":", "\n", "    ", "with", "open", "(", "\"VERSION\"", ",", "\"r\"", ")", "as", "fh", ":", "\n", "        ", "init", "=", "fh", ".", "read", "(", ")", ".", "strip", "(", ")", "\n", "", "return", "VERSION_RE", ".", "search", "(", "init", ")", ".", "group", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.None.setup.requirement_specification": [[19, 37], ["EDITABLE_INSTALL_RE.match", "requirements_line.strip", "EDITABLE_INSTALL_RE.match.group", "editable_requirement.group.split"], "function", ["None"], ["", "def", "requirement_specification", "(", "requirements_line", ")", ":", "\n", "    ", "\"\"\"Extract the requirement specification from a line of a pip requirements.txt\n\n  Usually the line is already a requirement specification compatible with\n  setuptools and nothing needs to be done, but sometimes it'll be of the form\n  '-e <path>' to tell pip to install a local copy of a dependency in editable\n  mode for cross-package development; in this case, the last component of the\n  path is passed to setuptools as the requirement (version can't be specified).\n\n  For example, if the line is '-e ../../cylance/identity_utilities', then the\n  requirement specification is 'identity_utilities'.\n  \"\"\"", "\n", "editable_requirement", "=", "EDITABLE_INSTALL_RE", ".", "match", "(", "requirements_line", ")", "\n", "if", "editable_requirement", "is", "None", ":", "\n", "        ", "return", "requirements_line", ".", "strip", "(", ")", "\n", "", "else", ":", "\n", "        ", "path", "=", "editable_requirement", ".", "group", "(", "1", ")", "\n", "return", "path", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.None.setup.get_requirements": [[39, 43], ["open", "f.read().splitlines", "setup.requirement_specification", "f.read"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.None.setup.requirement_specification"], ["", "", "def", "get_requirements", "(", ")", ":", "\n", "    ", "with", "open", "(", "\"requirements.txt\"", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "return", "[", "requirement_specification", "(", "l", ")", "for", "l", "in", "lines", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.sklearn.fit_sklearn_binary_logistic_regression": [[13, 49], ["sklearn.linear_model.LogisticRegression().fit", "ValueError", "sklearn.linear_model.LogisticRegression", "ValueError"], "function", ["None"], ["def", "fit_sklearn_binary_logistic_regression", "(", "\n", "features", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray1D", ",", "\n", "sklearn_logistic_regression_C", ":", "Optional", "[", "float", "]", ",", "\n", "penalty", ":", "str", ",", "\n", "solver", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", "->", "LogisticRegression", ":", "\n", "    ", "\"\"\"\n    `features` should NOT include a column of ones for intercept\n    \"\"\"", "\n", "\n", "if", "(", "features", "[", ":", ",", "0", "]", "==", "1", ")", ".", "all", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"The features should not include a column of all 1's for the intercept; \"", "\n", "\"sklearn will add on the intercept AND not penalize it.\"", "\n", ")", "\n", "\n", "", "if", "penalty", "==", "\"l2\"", "and", "solver", "is", "None", ":", "\n", "        ", "solver", "=", "\"newton-cg\"", "\n", "", "elif", "penalty", "==", "\"l1\"", "and", "solver", "is", "None", ":", "\n", "        ", "solver", "=", "\"liblinear\"", "\n", "", "elif", "solver", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Not sure what to use as default solver, consult sklearn for guidance\"", "\n", ")", "\n", "\n", "", "X", "=", "features", "\n", "y", "=", "labels", "\n", "\n", "clf", "=", "LogisticRegression", "(", "\n", "penalty", "=", "penalty", ",", "\n", "solver", "=", "solver", ",", "\n", "random_state", "=", "0", ",", "\n", "C", "=", "sklearn_logistic_regression_C", ",", "\n", ")", ".", "fit", "(", "X", ",", "y", ")", "\n", "return", "clf", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.sklearn.fit_sklearn_multiclass_logistic_regression": [[51, 81], ["numpy.argmax", "sklearn.linear_model.LogisticRegression().fit", "sklearn.linear_model.LogisticRegression", "ValueError"], "function", ["None"], ["", "def", "fit_sklearn_multiclass_logistic_regression", "(", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray2D", ",", "\n", "sklearn_logistic_regression_C", ":", "float", "=", "1.0", ",", "\n", "penalty", ":", "str", "=", "\"l2\"", ",", "\n", "solver", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", "->", "LogisticRegression", ":", "\n", "\n", "    ", "X", "=", "covariates", "\n", "y", "=", "np", ".", "argmax", "(", "labels", ",", "1", ")", "\n", "\n", "if", "penalty", "==", "\"l2\"", "and", "solver", "is", "None", ":", "\n", "        ", "solver", "=", "\"newton-cg\"", "\n", "", "elif", "penalty", "==", "\"l1\"", "and", "solver", "is", "None", ":", "\n", "        ", "solver", "=", "\"saga\"", "\n", "", "elif", "solver", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Not sure what to use as default solver, consult sklearn for guidance\"", "\n", ")", "\n", "\n", "### Get variable selection decisions for logistic regression, possibly with lasso", "\n", "", "clf", "=", "LogisticRegression", "(", "\n", "penalty", "=", "penalty", ",", "\n", "solver", "=", "solver", ",", "\n", "random_state", "=", "0", ",", "\n", "multi_class", "=", "\"multinomial\"", ",", "\n", "C", "=", "sklearn_logistic_regression_C", ",", "\n", "fit_intercept", "=", "False", ",", "\n", ")", ".", "fit", "(", "X", ",", "y", ")", "\n", "return", "clf", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.model_algo_meta_results.str_from_mamr": [[34, 36], ["None"], "function", ["None"], ["", "def", "str_from_mamr", "(", "mamr", ":", "ModelAlgoMetaResults", ")", ":", "\n", "    ", "return", "f\"{mamr.model.name}+{mamr.algo.name}+{mamr.meta_str}\"", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.tables.table_from_dict": [[8, 25], ["numpy.set_printoptions", "texttable.Texttable", "texttable.Texttable.set_cols_align", "texttable.Texttable.set_cols_valign", "texttable.Texttable.set_cols_dtype", "texttable.Texttable.add_rows", "list", "my_dict.items", "field.replace"], "function", ["None"], ["def", "table_from_dict", "(", "my_dict", ":", "Dict", ")", "->", "texttable", ".", "Texttable", ":", "\n", "# TODO: make alignment choices a function argument with defaults", "\n", "    ", "np", ".", "set_printoptions", "(", "precision", "=", "3", ",", "suppress", "=", "True", ")", "\n", "table", "=", "texttable", ".", "Texttable", "(", ")", "\n", "table", ".", "set_cols_align", "(", "[", "\"p{0.35\\linewidth} \"", ",", "\"p{0.6\\linewidth} \"", "]", ")", "\n", "table", ".", "set_cols_valign", "(", "[", "\"t\"", ",", "\"t\"", "]", ")", "\n", "table", ".", "set_cols_dtype", "(", "\n", "[", "\n", "\"t\"", ",", "# text", "\n", "\"a\"", ",", "# auto", "\n", "]", "\n", ")", "\n", "table_rows", "=", "[", "\n", "list", "(", "(", "field", ".", "replace", "(", "\"_\"", ",", "\" \"", ")", ",", "value", ")", ")", "for", "(", "field", ",", "value", ")", "in", "my_dict", ".", "items", "(", ")", "\n", "]", "\n", "table", ".", "add_rows", "(", "table_rows", ")", "\n", "return", "table", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.tables.table_from_namedtuple": [[27, 29], ["tables.table_from_dict", "my_namedtuple._asdict"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.tables.table_from_dict"], ["", "def", "table_from_namedtuple", "(", "my_namedtuple", ")", "->", "texttable", ".", "Texttable", ":", "\n", "    ", "return", "table_from_dict", "(", "my_namedtuple", ".", "_asdict", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.tables.print_namedtuple": [[31, 34], ["tables.table_from_namedtuple", "print", "table_from_namedtuple.draw"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.tables.table_from_namedtuple"], ["", "def", "print_namedtuple", "(", "my_namedtuple", ")", "->", "None", ":", "\n", "    ", "table", "=", "table_from_namedtuple", "(", "my_namedtuple", ")", "\n", "print", "(", "table", ".", "draw", "(", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.tables.print_namedtuple_as_latex_table": [[36, 40], ["tables.table_from_namedtuple", "print", "print", "table_from_namedtuple.draw", "latextable.draw_latex"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.tables.table_from_namedtuple"], ["", "def", "print_namedtuple_as_latex_table", "(", "my_namedtuple", ",", "caption", ")", "->", "None", ":", "\n", "    ", "table", "=", "table_from_namedtuple", "(", "my_namedtuple", ")", "\n", "print", "(", "table", ".", "draw", "(", ")", "+", "\"\\n\"", ")", "\n", "print", "(", "latextable", ".", "draw_latex", "(", "table", ",", "caption", "=", "caption", ")", "+", "\"\\n\"", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.mst_time.get_mst_time": [[7, 13], ["datetime.datetime.now", "date.astimezone.astimezone", "date.astimezone.strftime", "pytz.timezone"], "function", ["None"], ["def", "get_mst_time", "(", ")", ":", "\n", "    ", "date_format", "=", "\"%m_%d_%Y_%H_%M_%S_%Z\"", "\n", "date", "=", "datetime", ".", "now", "(", "tz", "=", "pytz", ".", "utc", ")", "\n", "date", "=", "date", ".", "astimezone", "(", "timezone", "(", "\"US/Mountain\"", ")", ")", "\n", "mstDateTime", "=", "date", ".", "strftime", "(", "date_format", ")", "\n", "return", "mstDateTime", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.profiling.profile_me": [[7, 32], ["functools.wraps", "tempfile.mktemp", "cProfile.Profile", "cProfile.Profile.runcall", "cProfile.Profile.dump_stats", "pstats.Stats", "pstats.Stats.strip_dirs().sort_stats().print_stats", "pstats.Stats.strip_dirs().sort_stats", "pstats.Stats.strip_dirs"], "function", ["None"], ["def", "profile_me", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    A function decorator which can be used to profile code in line.\n    Results are print to screen.\n\n    The decorator currently eats the functions natural return value, but this could\n    be adjusted (for an example, see categorical_from_binary.timing)\n\n    Usage:\n        profile_me(my_function)(arguments_of_function)\n\n    Reference:\n        https://towardsdatascience.com/how-to-profile-your-code-in-python-e70c834fad89\n    \"\"\"", "\n", "\n", "@", "functools", ".", "wraps", "(", "func", ")", "\n", "def", "wraps", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "file", "=", "tempfile", ".", "mktemp", "(", ")", "\n", "profiler", "=", "cProfile", ".", "Profile", "(", ")", "\n", "profiler", ".", "runcall", "(", "func", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "profiler", ".", "dump_stats", "(", "file", ")", "\n", "metrics", "=", "pstats", ".", "Stats", "(", "file", ")", "\n", "metrics", ".", "strip_dirs", "(", ")", ".", "sort_stats", "(", "\"time\"", ")", ".", "print_stats", "(", "100", ")", "\n", "\n", "", "return", "wraps", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.data_generation_configs.get_num_parameters_from_num_covariates_and_num_categories": [[20, 26], ["None"], "function", ["None"], ["", "def", "get_num_parameters_from_num_covariates_and_num_categories", "(", "\n", "num_categories", ":", "int", ",", "\n", "num_covariates", ":", "int", ",", "\n", ")", ":", "\n", "    ", "K", ",", "M", "=", "num_categories", ",", "num_covariates", "\n", "return", "K", "*", "(", "M", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.data_generation_configs.make_data_generation_configs": [[28, 57], ["data_generation_configs.get_num_parameters_from_num_covariates_and_num_categories", "data_generation_configs.DataGenerationConfig", "data_generation_configs.append"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.data_generation_configs.get_num_parameters_from_num_covariates_and_num_categories"], ["", "def", "make_data_generation_configs", "(", "\n", "list_of_n_categories", ":", "List", "[", "int", "]", ",", "\n", "multipliers_on_n_categories_to_create_n_covariates", ":", "List", "[", "int", "]", ",", "\n", "multipliers_on_n_parameters_to_create_n_samples", ":", "List", "[", "int", "]", ",", "\n", "list_of_scales_for_predictive_categories", ":", "List", "[", "float", "]", ",", "\n", "seed", ":", "int", "=", "1", ",", "\n", ")", "->", "List", "[", "DataGenerationConfig", "]", ":", "\n", "    ", "\"\"\"\n    Uses the provided arguments to create the info needed to generate categorical regression\n    datasets; namey, (K,M,N,ssq_high), where K is the number of categories, M is the number of covariates,\n    N is the number of samples, and ssq_high controls the categorical response predictability.\n\n    Then takes the Cartesian product of these things to create a list of Data Generation Configs.\n    \"\"\"", "\n", "data_generation_configs", "=", "[", "]", "\n", "for", "K", "in", "list_of_n_categories", ":", "\n", "        ", "for", "(", "\n", "multiplier_to_create_n_covariates", "\n", ")", "in", "multipliers_on_n_categories_to_create_n_covariates", ":", "\n", "            ", "M", "=", "K", "*", "multiplier_to_create_n_covariates", "\n", "P", "=", "get_num_parameters_from_num_covariates_and_num_categories", "(", "K", ",", "M", ")", "\n", "for", "(", "\n", "multiplier_to_create_n_samples", "\n", ")", "in", "multipliers_on_n_parameters_to_create_n_samples", ":", "\n", "                ", "N", "=", "P", "*", "multiplier_to_create_n_samples", "\n", "for", "scale", "in", "list_of_scales_for_predictive_categories", ":", "\n", "                    ", "data_generation_config", "=", "DataGenerationConfig", "(", "seed", ",", "K", ",", "M", ",", "N", ",", "scale", ")", "\n", "data_generation_configs", ".", "append", "(", "data_generation_config", ")", "\n", "", "", "", "", "return", "data_generation_configs", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.io.write_json": [[5, 8], ["open", "json.dump"], "function", ["None"], ["def", "write_json", "(", "data", ",", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "data", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.io.read_json": [[10, 13], ["open", "json.load"], "function", ["None"], ["", "", "def", "read_json", "(", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ")", "as", "f", ":", "\n", "        ", "return", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.io.ensure_dir": [[15, 27], ["os.path.isdir", "os.makedirs"], "function", ["None"], ["", "", "def", "ensure_dir", "(", "directory", ")", ":", "\n", "    ", "\"\"\"\n    Description:\n    Makes sure directory exists before saving to it.\n\n    Parameters:\n            directory: An string naming the directory on the local machine where we will save stuff.\n\n    \"\"\"", "\n", "# alternative: os.makedirs(directory, exist_ok=True)", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "directory", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "directory", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.dists._soften_probs": [[9, 20], ["sum"], "function", ["None"], ["def", "_soften_probs", "(", "probs", ":", "np", ".", "ndarray", ",", "epsilon", "=", "1e-6", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Motivations:\n        * sample_from_categorical function returns error if it is too close to a vertex\n            (e.g., [1,0,0], in the case of 3 categories)\n        * sample_from_categorical can error out if the sum is slightly different than 1.0,\n            and in fact dividing the unnormalized probabilities by the normalizing constant\n            does not fix the problem (the sum can still be slightly different than 1.0)\n    \"\"\"", "\n", "probs", "[", "probs", "<", "epsilon", "]", "=", "0.0", "\n", "return", "probs", "/", "sum", "(", "probs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.dists.sample_from_categorical": [[22, 45], ["dists._soften_probs", "numpy.argmax", "numpy.random.multinomial"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.dists._soften_probs"], ["", "def", "sample_from_categorical", "(", "probs", ":", "np", ".", "ndarray", ",", "one_indexed", ":", "bool", "=", "False", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Returns a (numerically-labeled) category sampled from a categorical distribution.\n    \"\"\"", "\n", "probs", "=", "_soften_probs", "(", "probs", ")", "\n", "category", "=", "np", ".", "argmax", "(", "np", ".", "random", ".", "multinomial", "(", "n", "=", "1", ",", "pvals", "=", "probs", ")", ">", "0", ")", "\n", "# TODO:  sample_from_categorical seems to fails when some probabilities get too close", "\n", "# to 0 or 1, and the issue traces back to the call to np.random.multinomial:", "\n", "\"\"\"\n        70     probs = _soften_probs(probs)\n    ---> 71     category = np.argmax(np.random.multinomial(n=1, pvals=probs) > 0)\n        72     if one_indexed:\n        73         category += 1\n\n    mtrand.pyx in numpy.random.mtrand.RandomState.multinomial()\n\n    _common.pyx in numpy.random._common.check_array_constraint()\n\n    ValueError: pvals < 0, pvals > 1 or pvals contains NaNs\n    \"\"\"", "\n", "if", "one_indexed", ":", "\n", "        ", "category", "+=", "1", "\n", "", "return", "category", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.math.logdiffexp": [[4, 7], ["math.log1mexp"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.math.log1mexp"], ["def", "logdiffexp", "(", "a", ",", "b", ")", ":", "\n", "    ", "\"\"\"log(exp(a) - exp(b)).  Borrowed from pymc3 library.\"\"\"", "\n", "return", "a", "+", "log1mexp", "(", "b", "-", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.math.log1mexp": [[9, 25], ["numpy.asarray", "numpy.empty_like", "numpy.log1p", "numpy.log", "ValueError", "numpy.exp", "numpy.expm1"], "function", ["None"], ["", "def", "log1mexp", "(", "x", ")", ":", "\n", "    ", "\"\"\"Return log(1 - exp(x)).\n    This function is numerically more stable than the naive approach.\n    For details, see\n    https://cran.r-project.org/web/packages/Rmpfr/vignettes/log1mexp-note.pdf.\n    Borrowed from pymc3 library.\n    \"\"\"", "\n", "x", "=", "np", ".", "asarray", "(", "x", ",", "dtype", "=", "\"float\"", ")", "\n", "if", "not", "(", "x", "<=", "0", ")", ".", "all", "(", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"All components of x must be negative.\"", ")", "\n", "", "out", "=", "np", ".", "empty_like", "(", "x", ")", "\n", "mask", "=", "x", "<", "-", "0.6931471805599453", "# log(1/2)", "\n", "out", "[", "mask", "]", "=", "np", ".", "log1p", "(", "-", "np", ".", "exp", "(", "x", "[", "mask", "]", ")", ")", "\n", "mask", "=", "~", "mask", "\n", "out", "[", "mask", "]", "=", "np", ".", "log", "(", "-", "np", ".", "expm1", "(", "x", "[", "mask", "]", ")", ")", "\n", "return", "out", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics._get_probs_of_choices": [[39, 62], ["numpy.argmax", "numpy.array", "enumerate"], "function", ["None"], ["", "def", "_get_probs_of_choices", "(", "\n", "probs", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray2D", ",", "\n", "min_allowable_prob", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Get probabilities of the observed categories (the choices)\n\n    Arguments:\n        probs: np.ndarray with shape: (n_samples, n_categories)\n            Each row sums to 1\n        labels: np.ndarray  with shape: (n_samples, n_categories)\n            Each row has exactly one 1.\n        min_allowable_prob: If not None, we effectively take the probabilities over response categories, replace\n            each component prob_k with min(min_allowable_prob, prob_k), and then renormalize.\n    \"\"\"", "\n", "choices", "=", "np", ".", "argmax", "(", "labels", ",", "1", ")", "\n", "probs_of_choices", "=", "np", ".", "array", "(", "\n", "[", "probs", "[", "i", ",", "choice", "]", "for", "(", "i", ",", "choice", ")", "in", "enumerate", "(", "choices", ")", "]", "\n", ")", "\n", "if", "min_allowable_prob", "is", "not", "None", ":", "\n", "        ", "probs_of_choices", "+=", "min_allowable_prob", "\n", "", "return", "probs_of_choices", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.compute_mean_log_likelihood": [[64, 80], ["metrics._get_probs_of_choices", "numpy.nanmean", "numpy.log"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics._get_probs_of_choices"], ["", "def", "compute_mean_log_likelihood", "(", "\n", "probs", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray2D", ",", "\n", "min_allowable_prob", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        probs: np.ndarray with shape: (n_samples, n_categories)\n            Each row sums to 1\n        labels: np.ndarray  with shape: (n_samples, n_categories)\n            Each row has exactly one 1.\n        min_allowable_prob: If not None, we effectively take the probabilities over response categories, replace\n            each component prob_k with min(min_allowable_prob, prob_k), and then renormalize.\n    \"\"\"", "\n", "probs_of_choices", "=", "_get_probs_of_choices", "(", "probs", ",", "labels", ",", "min_allowable_prob", ")", "\n", "return", "np", ".", "nanmean", "(", "np", ".", "log", "(", "probs_of_choices", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.compute_mean_likelihood": [[82, 98], ["metrics._get_probs_of_choices", "numpy.nanmean"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics._get_probs_of_choices"], ["", "def", "compute_mean_likelihood", "(", "\n", "probs", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray2D", ",", "\n", "min_allowable_prob", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        probs: np.ndarray with shape: (n_samples, n_categories)\n            Each row sums to 1\n        labels: np.ndarray  with shape: (n_samples, n_categories)\n            Each row has exactly one 1.\n        min_allowable_prob: If not None, we effectively take the probabilities over response categories, replace\n            each component prob_k with min(min_allowable_prob, prob_k), and then renormalize.\n    \"\"\"", "\n", "probs_of_choices", "=", "_get_probs_of_choices", "(", "probs", ",", "labels", ",", "min_allowable_prob", ")", "\n", "return", "np", ".", "nanmean", "(", "probs_of_choices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.compute_mean_log_likelihood_from_features_and_beta": [[100, 105], ["categorical_from_binary.data_generation.bayes_multiclass_reg.construct_category_probs", "metrics.compute_mean_log_likelihood"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.compute_mean_log_likelihood"], ["", "def", "compute_mean_log_likelihood_from_features_and_beta", "(", "\n", "features", ":", "NumpyArray2D", ",", "beta", ":", "NumpyArray2D", ",", "labels", ":", "NumpyArray2D", ",", "link", ":", "Link", "\n", ")", ":", "\n", "    ", "category_probs", "=", "construct_category_probs", "(", "features", ",", "beta", ",", "link", ")", "\n", "return", "compute_mean_log_likelihood", "(", "category_probs", ",", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.compute_accuracy": [[112, 148], ["numpy.sum", "scipy.sparse.issparse", "numpy.sum", "numpy.mean", "probs.max", "labels.astype().todense.astype().todense", "labels.astype().todense.astype"], "function", ["None"], ["", "def", "compute_accuracy", "(", "probs", ":", "NumpyArray2D", ",", "labels", ":", "NumpyArray2D", ")", ":", "\n", "    ", "\"\"\"\n    If `S` multiple labels  attained the maximum cat probability,\n    the accuracy status for the given observation is 1/S rather than 1. Thus,\n    if there are `K` total category probabilities then under a uniform\n    category probability distribution, the accuracy will be 1/K.\n\n    Arguments:\n        probs: np.ndarray with shape: (n_samples, n_categories)\n            Each row sums to 1\n        labels: np.ndarray  with shape: (n_samples, n_categories)\n            Each row has exactly one 1.\n    \"\"\"", "\n", "# Previous/naive method for computing accuracy below.  We discarded this because np.argmax takes the FIRST index", "\n", "# attaining the max.  So for instance under uniform category probabilities it reports", "\n", "# the number of times that the chosen response was the 0th category -- obviously a meaningless", "\n", "# computation, since indices are assigned to categories arbitrarily.", "\n", "#   return np.mean(np.argmax(probs, 1) == np.argmax(labels, 1))", "\n", "\n", "booleans_giving_attainment_of_max_cat_prob", "=", "probs", "==", "probs", ".", "max", "(", "1", ",", "keepdims", "=", "True", ")", "\n", "num_cats_with_max_cat_prob", "=", "np", ".", "sum", "(", "booleans_giving_attainment_of_max_cat_prob", ",", "1", ")", "\n", "# TODO: Move this conversion WAY higher up in the code, like when we create sparse datasets", "\n", "# such as cyber", "\n", "if", "scipy", ".", "sparse", ".", "issparse", "(", "labels", ")", ":", "\n", "        ", "labels", "=", "labels", ".", "astype", "(", "bool", ")", ".", "todense", "(", ")", "\n", "\n", "", "booleans_stating_whether_choice_attained_max_cat_prob", "=", "(", "\n", "booleans_giving_attainment_of_max_cat_prob", "&", "labels", "\n", ")", "\n", "# if two labels attained the maximum cat probability, the accuracy status is 1/2 rather than 1.", "\n", "accuracy_status_per_observation", "=", "np", ".", "sum", "(", "\n", "booleans_stating_whether_choice_attained_max_cat_prob", "\n", "/", "num_cats_with_max_cat_prob", "[", ":", ",", "np", ".", "newaxis", "]", ",", "\n", "1", ",", "\n", ")", "\n", "return", "np", ".", "mean", "(", "accuracy_status_per_observation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics._compute_balanced_accuracy": [[150, 192], ["numpy.sum", "numpy.sum", "scipy.sparse.issparse", "numpy.nanmean", "probs.max", "labels.astype().todense.astype().todense", "numpy.sum", "labels.astype().todense.astype"], "function", ["None"], ["", "def", "_compute_balanced_accuracy", "(", "probs", ":", "NumpyArray2D", ",", "labels", ":", "NumpyArray2D", ")", ":", "\n", "    ", "\"\"\"\n    Experimental function.  Currently not used.\n\n    Reference:\n        https://www.michaelchughes.com/papers/HuangEtAl_MLHC_2021.pdf#page=15\n\n    Arguments:\n        probs: np.ndarray with shape: (n_samples, n_categories)\n            Each row sums to 1\n        labels: np.ndarray  with shape: (n_samples, n_categories)\n            Each row has exactly one 1.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "number_of_examples_selecting_each_category", "=", "np", ".", "sum", "(", "labels", ",", "0", ")", "\n", "booleans_giving_attainment_of_max_cat_prob", "=", "probs", "==", "probs", ".", "max", "(", "\n", "1", ",", "keepdims", "=", "True", "\n", ")", "\n", "num_cats_with_max_cat_prob", "=", "np", ".", "sum", "(", "\n", "booleans_giving_attainment_of_max_cat_prob", ",", "1", "\n", ")", "\n", "\n", "if", "scipy", ".", "sparse", ".", "issparse", "(", "labels", ")", ":", "\n", "            ", "labels", "=", "labels", ".", "astype", "(", "bool", ")", ".", "todense", "(", ")", "\n", "\n", "", "booleans_stating_whether_choice_attained_max_cat_prob", "=", "(", "\n", "booleans_giving_attainment_of_max_cat_prob", "&", "labels", "\n", ")", "\n", "adjusted_true_positive_status", "=", "(", "\n", "booleans_stating_whether_choice_attained_max_cat_prob", "\n", "/", "num_cats_with_max_cat_prob", "[", ":", ",", "np", ".", "newaxis", "]", "\n", ")", "\n", "# `adjusted_true_positive_status` gives 1/S rather than 1 if S different categories tied for the maximum cat prob for that example", "\n", "adjusted_accuracy_per_category", "=", "(", "\n", "np", ".", "sum", "(", "adjusted_true_positive_status", ",", "0", ")", "\n", "/", "number_of_examples_selecting_each_category", "\n", ")", "\n", "# categories with no examples selecting that category are ignored.", "\n", "balanced_accuracy", "=", "np", ".", "nanmean", "(", "adjusted_accuracy_per_category", ")", "\n", "", "except", ":", "\n", "        ", "balanced_accuracy", "=", "np", ".", "nan", "\n", "", "return", "balanced_accuracy", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.compute_choice_ranks": [[198, 224], ["numpy.argmax", "len", "numpy.zeros", "range", "numpy.argwhere"], "function", ["None"], ["", "def", "compute_choice_ranks", "(", "probs", ":", "NumpyArray2D", ",", "labels", ":", "NumpyArray2D", ")", ":", "\n", "    ", "\"\"\"\n    Given a set of model probabilities for each category and then actual observed categories (\"choices\"),\n    we report the choice ranks for each sample.\n\n    We compare this to the choice ranks for a baserate model, which simply makes predictions based on the\n    empirical frequencies in the training set, completely ignoring the covariates.\n\n    Arguments:\n        probs: np.ndarray with shape: (n_samples, n_categories)\n            Each row sums to 1\n        labels: np.ndarray  with shape: (n_samples, n_categories)\n            Each row has exactly one 1.\n    \"\"\"", "\n", "\n", "ranks_of_predicted_categories_high_to_low", "=", "(", "-", "1", "*", "probs", ")", ".", "argsort", "(", ")", "\n", "\n", "choices", "=", "np", ".", "argmax", "(", "labels", ",", "1", ")", "\n", "\n", "n_samples", "=", "len", "(", "choices", ")", "\n", "choice_ranks_zero_indexed", "=", "np", ".", "zeros", "(", "n_samples", ",", "dtype", "=", "int", ")", "\n", "for", "i", "in", "range", "(", "n_samples", ")", ":", "\n", "        ", "choice_ranks_zero_indexed", "[", "i", "]", "=", "np", ".", "argwhere", "(", "\n", "ranks_of_predicted_categories_high_to_low", "[", "i", "]", "==", "choices", "[", "i", "]", "\n", ")", "[", "0", "]", "[", "0", "]", "\n", "", "return", "choice_ranks_zero_indexed", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.compute_metrics": [[231, 254], ["metrics.compute_mean_likelihood", "metrics.compute_mean_log_likelihood", "metrics.compute_accuracy", "numpy.mean", "metrics.Metrics", "metrics.compute_choice_ranks"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.compute_mean_likelihood", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.compute_mean_log_likelihood", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.compute_accuracy", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.compute_choice_ranks"], ["", "def", "compute_metrics", "(", "\n", "probs", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray2D", ",", "\n", "min_allowable_prob", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", ")", "->", "Metrics", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        probs: np.ndarray with shape: (n_samples, n_categories)\n            Each row sums to 1\n        labels: np.ndarray  with shape: (n_samples, n_categories)\n            Each row has exactly one 1.\n        min_allowable_prob: If not None, we effectively take the probabilities over response categories, replace\n            each component prob_k with min(min_allowable_prob, prob_k), and then renormalize.\n    \"\"\"", "\n", "mean_likelihood", "=", "compute_mean_likelihood", "(", "probs", ",", "labels", ",", "min_allowable_prob", ")", "\n", "mean_log_likelihood", "=", "compute_mean_log_likelihood", "(", "probs", ",", "labels", ",", "min_allowable_prob", ")", "\n", "accuracy", "=", "compute_accuracy", "(", "probs", ",", "labels", ")", "\n", "mean_choice_rank", "=", "np", ".", "mean", "(", "compute_choice_ranks", "(", "probs", ",", "labels", ")", ")", "\n", "return", "Metrics", "(", "\n", "mean_likelihood", ",", "\n", "mean_log_likelihood", ",", "\n", "accuracy", ",", "\n", "mean_choice_rank", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.append_metrics_dict_for_one_dataset_to_results_dict": [[260, 298], ["metrics_dict_for_one_dataset.items", "collections.defaultdict", "dataclasses.asdict().items", "results_dict[].append", "dataclasses.asdict"], "function", ["None"], ["", "def", "append_metrics_dict_for_one_dataset_to_results_dict", "(", "\n", "metrics_dict_for_one_dataset", ":", "Dict", "[", "str", ",", "Metrics", "]", ",", "\n", "results_dict", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        metrics_dict_for_one_dataset:  Dict, maps the name of an inference technique to an instance of a Metrics object\n        results_dict: Optional[Dict].  Pre-existing results dict.\n\n    Returns:\n        results_dict, mapping the Cartesian product (inference_approach x metric name) to a list of values.  If the list contains\n        multiple values, then this function must have been called multiple times, successively mutating the results_dict,\n        and each item in the list represents the result for a single seed.\n\n    Example:\n        metrics_dict_for_one_dataset:\n            {'dgp': Metrics(mean_log_like=-0.8681106384500588, accuracy=0.7, mean_choice_rank=1.525),\n            'multi_logit_pga_gibbs': Metrics(mean_log_like=-2.020928394329602, accuracy=0.4, mean_choice_rank=2.65),\n            'IB_CAVI_plus_BMA': Metrics(mean_log_like=-1.5077224060628591, accuracy=0.45, mean_choice_rank=2.35)}\n        results_dict:\n            defaultdict(list,\n            {'dgp_mean_log_like': [-0.8681106384500588],\n             'dgp_accuracy': [0.7],\n             'dgp_mean_choice_rank': [1.525],\n             'multi_logit_pga_gibbs_mean_log_like': [-2.020928394329602],\n             'multi_logit_pga_gibbs_accuracy': [0.4],\n             'multi_logit_pga_gibbs_mean_choice_rank': [2.65],\n             'IB_CAVI_plus_BMA_mean_log_like': [-1.5077224060628591],\n             'IB_CAVI_plus_BMA_accuracy': [0.45],\n             'IB_CAVI_plus_BMA_mean_choice_rank': [2.35]})\n\n    \"\"\"", "\n", "if", "results_dict", "is", "None", ":", "\n", "        ", "results_dict", "=", "defaultdict", "(", "list", ")", "\n", "", "for", "inference_approach", ",", "metrics", "in", "metrics_dict_for_one_dataset", ".", "items", "(", ")", ":", "\n", "        ", "for", "metric_name", ",", "metric_value", "in", "asdict", "(", "metrics", ")", ".", "items", "(", ")", ":", "\n", "            ", "results_dict", "[", "f\"{inference_approach}_{metric_name}\"", "]", ".", "append", "(", "metric_value", ")", "\n", "", "", "return", "results_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.print_performance_report": [[303, 359], ["categorical_from_binary.data_generation.bayes_multiclass_reg.construct_category_probs", "metrics.compute_metrics", "print", "categorical_from_binary.baserate.compute_probs_for_baserate_model", "metrics.compute_metrics", "print", "len", "numpy.argmax", "numpy.argmax", "numpy.mean", "print", "numpy.mean", "print", "collections.Counter().most_common", "collections.Counter().most_common", "print", "print", "scipy.stats.mode", "collections.Counter", "collections.Counter"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.compute_metrics", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.baserate.compute_probs_for_baserate_model", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.compute_metrics"], ["", "def", "print_performance_report", "(", "\n", "covariates_test", ":", "NumpyArray2D", ",", "\n", "labels_test", ":", "NumpyArray2D", ",", "\n", "labels_train", ":", "NumpyArray2D", ",", "\n", "beta_star", ":", "NumpyArray2D", ",", "\n", "link", ":", "Link", ",", "\n", "verbose", ":", "bool", "=", "True", ",", "\n", ")", "->", "None", ":", "\n", "\n", "    ", "probs_test", "=", "construct_category_probs", "(", "covariates_test", ",", "beta_star", ",", "link", ")", "\n", "metrics", "=", "compute_metrics", "(", "probs_test", ",", "labels_test", ")", "\n", "print", "(", "f\"\\n Metrics with {link}: {metrics}\"", ")", "\n", "\n", "probs_test_with_baserate_model", "=", "compute_probs_for_baserate_model", "(", "\n", "labels_train", ",", "len", "(", "labels_test", ")", "\n", ")", "\n", "metrics_with_baserate_model", "=", "compute_metrics", "(", "\n", "probs_test_with_baserate_model", ",", "labels_test", "\n", ")", "\n", "print", "(", "f\"\\n Metrics with baserate model: {metrics_with_baserate_model}\"", ")", "\n", "\n", "###", "\n", "# Below are some other computations that aren't including in the metrics above.", "\n", "###", "\n", "\n", "if", "verbose", ":", "\n", "        ", "observed_labels", "=", "np", ".", "argmax", "(", "labels_test", ",", "1", ")", "\n", "predicted_labels", "=", "np", ".", "argmax", "(", "probs_test", ",", "1", ")", "\n", "\n", "### how often is correct decision the dominant one", "\n", "most_common_label_test", "=", "scipy", ".", "stats", ".", "mode", "(", "observed_labels", ")", ".", "mode", "[", "0", "]", "\n", "\n", "correct_prediction_over_samples", "=", "predicted_labels", "==", "observed_labels", "\n", "percentage_of_time_dominant_category_was_observed", "=", "np", ".", "mean", "(", "\n", "predicted_labels", "==", "most_common_label_test", "\n", ")", "\n", "print", "(", "\n", "f\"The percentage of time the dominant category was observed in test set: {percentage_of_time_dominant_category_was_observed :.03f}\"", "\n", ")", "\n", "\n", "percentage_correct_prediction_was_dominant_category", "=", "np", ".", "mean", "(", "\n", "predicted_labels", "[", "correct_prediction_over_samples", "]", "==", "most_common_label_test", "\n", ")", "\n", "print", "(", "\n", "f\"The percentage of time the correct prediction was the dominant category: {percentage_correct_prediction_was_dominant_category:.03f}\"", "\n", ")", "\n", "\n", "# Counts of observed vs predicted", "\n", "most_common_predicted_labels", "=", "Counter", "(", "predicted_labels", ")", ".", "most_common", "(", "15", ")", "\n", "most_common_observed_labels", "=", "Counter", "(", "observed_labels", ")", ".", "most_common", "(", "15", ")", "\n", "\n", "print", "(", "\n", "f\"Most common predicted labels (label_id, count): {most_common_predicted_labels}\"", "\n", ")", "\n", "print", "(", "\n", "f\"Most common observed labels (label_id, count): {most_common_observed_labels}\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.timing.time_me": [[6, 35], ["functools.wraps", "time.time", "func", "time.time"], "function", ["None"], ["def", "time_me", "(", "func", ":", "Callable", ")", "->", "Callable", ":", "\n", "    ", "\"\"\"\n    A function decorator.\n\n    Given function foo, do\n        foo_with_time=timeit(foo)\n    and this new function will return a tuple whose 1st element is the normal function result\n    and whose second element is the elapsed time (in seconds)\n\n    Usage:\n        def double(x):\n            return x*2\n\n        result, time= time_me(double)(3)\n        print(f\"result={result}, time={time}\")\n        > result=9, time=9.5367431640625e-07\n    \"\"\"", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "_time_it", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "start", "=", "time", ".", "time", "(", ")", "\n", "try", ":", "\n", "            ", "result", "=", "func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "finally", ":", "\n", "            ", "end", "=", "time", ".", "time", "(", ")", "\n", "elapsed", "=", "end", "-", "start", "\n", "return", "result", ",", "elapsed", "\n", "\n", "", "", "return", "_time_it", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.vi_params.VI_params_from_CAVI_results": [[65, 74], ["vi_params.VI_Params"], "function", ["None"], ["", "def", "VI_params_from_CAVI_results", "(", "\n", "CAVI_results", ":", "CAVI_Results", ",", "\n", ")", ":", "\n", "    ", "return", "VI_Params", "(", "\n", "VI_type", "=", "VI_Type", ".", "IB_CAVI", ",", "\n", "mean", "=", "CAVI_results", ".", "variational_params", ".", "beta", ".", "mean", ",", "\n", "cov", "=", "CAVI_results", ".", "variational_params", ".", "beta", ".", "cov", ",", "\n", "stds", "=", "None", ",", "\n", "VI_hyperparams", "=", "\"\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.vi_params.VI_params_from_ADVI_means_and_stds": [[92, 103], ["vi_params.VI_Params"], "function", ["None"], ["", "def", "VI_params_from_ADVI_means_and_stds", "(", "\n", "beta_mean_ADVI", ":", "NumpyArray2D", ",", "\n", "beta_std_ADVI", ":", "NumpyArray2D", ",", "\n", "lr", ":", "float", ",", "\n", ")", ":", "\n", "    ", "return", "VI_Params", "(", "\n", "VI_type", "=", "VI_Type", ".", "ADVI", ",", "\n", "mean", "=", "beta_mean_ADVI", ",", "\n", "cov", "=", "None", ",", "\n", "stds", "=", "beta_std_ADVI", ",", "\n", "VI_hyperparams", "=", "f\"lr={lr}\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.vi_params.write_VI_params": [[106, 147], ["os.path.join", "categorical_from_binary.io.ensure_dir", "scipy.sparse.issparse", "os.path.join", "scipy.sparse.save_npz", "os.path.join", "numpy.save", "scipy.sparse.issparse", "scipy.sparse.issparse", "os.path.join", "scipy.sparse.save_npz", "os.path.join", "numpy.save", "os.path.join", "scipy.sparse.save_npz", "os.path.join", "numpy.save"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.io.ensure_dir"], ["", "def", "write_VI_params", "(", "\n", "VI_params", ":", "VI_Params", ",", "\n", "save_dir", ":", "str", ",", "\n", "time_info", ":", "str", ",", "\n", ")", "->", "None", ":", "\n", "    ", "detailed_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "save_dir", ",", "\n", "\"betas\"", ",", "\n", "VI_params", ".", "VI_type", ".", "name", ",", "\n", "VI_params", ".", "VI_hyperparams", ",", "\n", "time_info", ",", "\n", ")", "\n", "\n", "ensure_dir", "(", "detailed_dir", ")", "\n", "\n", "# Save beta mean", "\n", "beta_mean", "=", "VI_params", ".", "mean", "\n", "if", "scipy", ".", "sparse", ".", "issparse", "(", "beta_mean", ")", ":", "\n", "        ", "path_to_beta_mean", "=", "os", ".", "path", ".", "join", "(", "detailed_dir", ",", "\"beta_mean.npz\"", ")", "\n", "scipy", ".", "sparse", ".", "save_npz", "(", "path_to_beta_mean", ",", "beta_mean", ")", "\n", "", "else", ":", "\n", "        ", "path_to_beta_mean", "=", "os", ".", "path", ".", "join", "(", "detailed_dir", ",", "\"beta_mean.npy\"", ")", "\n", "np", ".", "save", "(", "path_to_beta_mean", ",", "beta_mean", ")", "\n", "\n", "# Save beta variation information (MxM cov matrix for IB-CAVI; MxK stds for ADVI)", "\n", "", "beta_cov", "=", "VI_params", ".", "cov", "\n", "if", "beta_cov", "is", "not", "None", ":", "\n", "        ", "if", "scipy", ".", "sparse", ".", "issparse", "(", "beta_cov", ")", ":", "\n", "            ", "path_to_beta_cov", "=", "os", ".", "path", ".", "join", "(", "detailed_dir", ",", "\"beta_cov.npz\"", ")", "\n", "scipy", ".", "sparse", ".", "save_npz", "(", "path_to_beta_cov", ",", "beta_cov", ")", "\n", "", "else", ":", "\n", "            ", "path_to_beta_cov", "=", "os", ".", "path", ".", "join", "(", "detailed_dir", ",", "\"beta_cov.npy\"", ")", "\n", "np", ".", "save", "(", "path_to_beta_cov", ",", "beta_cov", ")", "\n", "", "", "beta_stds", "=", "VI_params", ".", "stds", "\n", "if", "beta_stds", "is", "not", "None", ":", "\n", "        ", "if", "scipy", ".", "sparse", ".", "issparse", "(", "beta_stds", ")", ":", "\n", "            ", "path_to_beta_stds", "=", "os", ".", "path", ".", "join", "(", "detailed_dir", ",", "\"beta_stds.npz\"", ")", "\n", "scipy", ".", "sparse", ".", "save_npz", "(", "path_to_beta_stds", ",", "beta_stds", ")", "\n", "", "else", ":", "\n", "            ", "path_to_beta_stds", "=", "os", ".", "path", ".", "join", "(", "detailed_dir", ",", "\"beta_stds.npy\"", ")", "\n", "np", ".", "save", "(", "path_to_beta_stds", ",", "beta_stds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.vi_params.write_VI_params_from_CAVI_results": [[149, 156], ["vi_params.VI_params_from_CAVI_results", "vi_params.write_VI_params"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.vi_params.VI_params_from_CAVI_results", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.vi_params.write_VI_params"], ["", "", "", "def", "write_VI_params_from_CAVI_results", "(", "\n", "CAVI_results", ":", "CAVI_Results", ",", "\n", "save_dir", ":", "str", ",", "\n", "time_info", ":", "str", ",", "\n", ")", ":", "\n", "    ", "VI_params", "=", "VI_params_from_CAVI_results", "(", "CAVI_results", ")", "\n", "write_VI_params", "(", "VI_params", ",", "save_dir", ",", "time_info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.vi_params.write_VI_params_from_ADVI_means_and_stds": [[170, 179], ["vi_params.VI_params_from_ADVI_means_and_stds", "vi_params.write_VI_params"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.vi_params.VI_params_from_ADVI_means_and_stds", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.vi_params.write_VI_params"], ["", "def", "write_VI_params_from_ADVI_means_and_stds", "(", "\n", "beta_mean_ADVI", ":", "NumpyArray2D", ",", "\n", "beta_std_ADVI", ":", "NumpyArray2D", ",", "\n", "lr", ":", "float", ",", "\n", "save_dir", ":", "str", ",", "\n", "time_info", ":", "str", ",", "\n", ")", ":", "\n", "    ", "VI_params", "=", "VI_params_from_ADVI_means_and_stds", "(", "beta_mean_ADVI", ",", "beta_std_ADVI", ",", "lr", ")", "\n", "write_VI_params", "(", "VI_params", ",", "save_dir", ",", "time_info", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.numpy_helpers.enforce_bounds_on_prob_vector": [[6, 17], ["numpy.sum", "numpy.sum"], "function", ["None"], ["def", "enforce_bounds_on_prob_vector", "(", "prob_vector", ":", "NumpyArray1D", ")", "->", "NumpyArray1D", ":", "\n", "    ", "\"\"\"\n    Sometimes numerical computation causes some elements to be slightly less than 0\n    or slightly more than 1.  We fix this and renormalize.\n    \"\"\"", "\n", "EPSILON", "=", "1e-12", "# chosen somewhat arbitrarily", "\n", "prob_vector", "+=", "EPSILON", "# this fixes numbers just less than 0", "\n", "prob_vector", "/=", "np", ".", "sum", "(", "prob_vector", ")", "# renormalize", "\n", "prob_vector", "*", "(", "1.0", "-", "EPSILON", ")", "# this fixes numbers just greater than 1", "\n", "prob_vector", "/=", "np", ".", "sum", "(", "prob_vector", ")", "# renormalize", "\n", "return", "prob_vector", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.covariate_dict.sorted_covariate_names_from_covariate_dict": [[26, 38], ["max", "range", "covariate_dict.items", "covariate_dict.values", "sorted_covariate_names.append"], "function", ["None"], ["", "def", "sorted_covariate_names_from_covariate_dict", "(", "\n", "covariate_dict", ":", "Dict", "[", "str", ",", "VariableInfo", "]", "\n", ")", "->", "List", "[", "str", "]", ":", "\n", "    ", "max_index", "=", "max", "(", "\n", "[", "covariate_info", ".", "index", "for", "covariate_info", "in", "covariate_dict", ".", "values", "(", ")", "]", "\n", ")", "\n", "sorted_covariate_names", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "0", ",", "max_index", "+", "1", ")", ":", "\n", "        ", "for", "covariate_name", ",", "covariate_info", "in", "covariate_dict", ".", "items", "(", ")", ":", "\n", "            ", "if", "covariate_info", ".", "index", "==", "i", ":", "\n", "                ", "sorted_covariate_names", ".", "append", "(", "covariate_name", ")", "\n", "", "", "", "return", "sorted_covariate_names", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.pandas_helpers.filter_df_rows_by_column_values": [[6, 15], ["isinstance", "df[].isin"], "function", ["None"], ["def", "filter_df_rows_by_column_values", "(", "\n", "df", ":", "DataFrame", ",", "col", ":", "str", ",", "values", ":", "Union", "[", "str", ",", "List", "[", "str", "]", "]", "\n", ")", "->", "DataFrame", ":", "\n", "    ", "\"\"\"\n    Filter out rows of a pandas dataframe based on the presence of value(s) in a column\n    \"\"\"", "\n", "if", "isinstance", "(", "values", ",", "str", ")", ":", "\n", "        ", "values", "=", "[", "values", "]", "\n", "", "return", "df", "[", "~", "df", "[", "col", "]", ".", "isin", "(", "values", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.pandas_helpers.filter_df_rows_by_column_value_starts": [[17, 25], ["df[].str.startswith"], "function", ["None"], ["", "def", "filter_df_rows_by_column_value_starts", "(", "\n", "df", ":", "DataFrame", ",", "col", ":", "str", ",", "start", ":", "str", "\n", ")", "->", "DataFrame", ":", "\n", "    ", "\"\"\"\n    Filter out rows of a pandas dataframe based on the presence of value(s) in a column\n    which begin with something\n    \"\"\"", "\n", "return", "df", "[", "df", "[", "col", "]", ".", "str", ".", "startswith", "(", "start", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.pandas_helpers.keep_df_rows_by_column_values": [[27, 36], ["isinstance", "df[].isin"], "function", ["None"], ["", "def", "keep_df_rows_by_column_values", "(", "\n", "df", ":", "DataFrame", ",", "col", ":", "str", ",", "values", ":", "Union", "[", "str", ",", "List", "[", "str", "]", "]", "\n", ")", "->", "DataFrame", ":", "\n", "    ", "\"\"\"\n    Keep rows of a pandas dataframe based on the presence of value(s) in a column\n    \"\"\"", "\n", "if", "isinstance", "(", "values", ",", "str", ")", ":", "\n", "        ", "values", "=", "[", "values", "]", "\n", "", "return", "df", "[", "df", "[", "col", "]", ".", "isin", "(", "values", ")", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.sigmoid": [[7, 9], ["numpy.exp"], "function", ["None"], ["def", "sigmoid", "(", "x", ":", "float", ")", "->", "float", ":", "\n", "    ", "return", "1", "/", "(", "1", "+", "np", ".", "exp", "(", "-", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.compute_kl_mvn": [[11, 44], ["numpy.linalg.inv", "numpy.trace", "numpy.log", "numpy.linalg.det", "numpy.linalg.det"], "function", ["None"], ["", "def", "compute_kl_mvn", "(", "\n", "m0", ":", "NumpyArray1D", ",", "\n", "S0", ":", "NumpyArray2D", ",", "\n", "m1", ":", "NumpyArray1D", ",", "\n", "S1", ":", "NumpyArray2D", ",", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Computes the Kullback-Liebler divergence from Gaussian p1 (with mean m1, var S1)\n    to Gaussian p0 (with mean m0, var S0).\n\n    From wikipedia\n    KL(p0||p1)\n         = .5 * ( tr(S1^{-1} S0) + log |S1|/|S0| +\n                  (m1 - m0)^T S1^{-1} (m1 - m0) - N )\n\n    References:\n        https://stackoverflow.com/questions/44549369/kullback-leibler-divergence-from-gaussian-pm-pv-to-gaussian-qm-qv/55688087\n        https://mr-easy.github.io/2020-04-16-kl-divergence-between-2-gaussian-distributions/\n    \"\"\"", "\n", "# TODO: This function must exist somewhere in a python library.  It would be better to import", "\n", "# and use that; no point in reinventing the wheel.  Said function would already be unit tested,", "\n", "# would be more flexible to input types, etc.", "\n", "\n", "# store inv diag covariance of S1 and diff between means", "\n", "N", "=", "m0", ".", "shape", "[", "0", "]", "\n", "iS1", "=", "np", ".", "linalg", ".", "inv", "(", "S1", ")", "\n", "diff", "=", "m1", "-", "m0", "\n", "\n", "# kl is made of three terms", "\n", "tr_term", "=", "np", ".", "trace", "(", "iS1", "@", "S0", ")", "\n", "det_term", "=", "np", ".", "log", "(", "np", ".", "linalg", ".", "det", "(", "S1", ")", "/", "np", ".", "linalg", ".", "det", "(", "S0", ")", ")", "\n", "quad_term", "=", "diff", ".", "T", "@", "iS1", "@", "diff", "\n", "return", "0.5", "*", "(", "tr_term", "+", "det_term", "+", "quad_term", "-", "N", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.compute_kl_inverse_wishart": [[46, 81], ["numpy.linalg.inv", "numpy.trace", "numpy.log", "scipy.special.multigammaln", "scipy.special.multigammaln", "numpy.sum", "numpy.linalg.det", "scipy.special.digamma", "range"], "function", ["None"], ["", "def", "compute_kl_inverse_wishart", "(", "\n", "v1", ":", "float", ",", "\n", "S1", ":", "NumpyArray2D", ",", "\n", "v2", ":", "float", ",", "\n", "S2", ":", "NumpyArray2D", ",", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Computes the Kullback-Liebler divergence from Inverse Wishart p2 (with dof v2, residual sum of squares S2)\n    to Inverse Wishart p1 (with dof v1, residual sum of squares S1).\n\n    References:\n        Maya Gupta and Santosh Srivastava. Parametric bayesian estimation of differential entropy and relative\n            entropy.  Entropy, 12(4):818--843, 2010.\n        Wojnowicz, Michael.  Exponential families.  Available upon request.\n    \"\"\"", "\n", "# TODO: Write unit test or find external library to call.", "\n", "# Example unit test:  For fixed degrees of freedom, as means diverge, so should KL divergence.", "\n", "# For fixed means, KL divergence should increase as d.o.f. (i.e certainty) v1 and v2 spread farther and", "\n", "# father apart", "\n", "\n", "# precomputations", "\n", "N", "=", "S1", ".", "shape", "[", "0", "]", "\n", "iS1", "=", "np", ".", "linalg", ".", "inv", "(", "S1", ")", "\n", "iS1xS2", "=", "iS1", "@", "S2", "\n", "\n", "# kl is made of five terms", "\n", "tr_term", "=", "0.5", "*", "v1", "*", "np", ".", "trace", "(", "iS1xS2", ")", "\n", "det_term", "=", "0.5", "*", "v2", "*", "np", ".", "log", "(", "np", ".", "linalg", ".", "det", "(", "iS1xS2", ")", ")", "\n", "gamma_term", "=", "multigammaln", "(", "0.5", "*", "v2", ",", "N", ")", "-", "multigammaln", "(", "0.5", "*", "v1", ",", "N", ")", "\n", "digamma_term", "=", "(", "\n", "0.5", "*", "(", "v2", "-", "v1", ")", "*", "np", ".", "sum", "(", "[", "digamma", "(", "0.5", "*", "(", "v1", "-", "N", "+", "i", ")", ")", "for", "i", "in", "range", "(", "1", ",", "N", "+", "1", ")", "]", ")", "\n", ")", "\n", "simple_term", "=", "0.5", "*", "v1", "*", "N", "\n", "\n", "return", "gamma_term", "+", "tr_term", "-", "simple_term", "-", "det_term", "-", "digamma_term", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.compute_expected_log_det_of_inverse_wishart_rv": [[83, 99], ["numpy.sum", "numpy.log", "numpy.log", "numpy.linalg.det", "scipy.special.digamma", "range"], "function", ["None"], ["", "def", "compute_expected_log_det_of_inverse_wishart_rv", "(", "\n", "v", ":", "float", ",", "\n", "S", ":", "NumpyArray2D", ",", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        v : degrees of freedom\n        S : Residual sum of squares\n    \"\"\"", "\n", "# TODO: Write unit test", "\n", "\n", "N", "=", "S", ".", "shape", "[", "0", "]", "\n", "return", "(", "\n", "-", "N", "*", "np", ".", "log", "(", "2", ")", "\n", "+", "np", ".", "log", "(", "np", ".", "linalg", ".", "det", "(", "S", ")", ")", "\n", "-", "np", ".", "sum", "(", "[", "digamma", "(", "0.5", "*", "(", "v", "-", "N", "+", "i", ")", ")", "for", "i", "in", "range", "(", "1", ",", "N", "+", "1", ")", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.compute_expected_kl_divergence_wrt_independent_Normal_and_IW_distributions_on_params_of_second_argument": [[102, 149], ["numpy.trace", "kl.compute_expected_log_det_of_inverse_wishart_rv", "numpy.log", "numpy.linalg.det", "numpy.linalg.inv"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.compute_expected_log_det_of_inverse_wishart_rv"], ["", "def", "compute_expected_kl_divergence_wrt_independent_Normal_and_IW_distributions_on_params_of_second_argument", "(", "\n", "mu_0", ":", "NumpyArray1D", ",", "\n", "Sigma_0", ":", "NumpyArray2D", ",", "\n", "m", ":", "NumpyArray1D", ",", "\n", "V", ":", "NumpyArray2D", ",", "\n", "nu", ":", "float", ",", "\n", "S", ":", "NumpyArray2D", ",", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Gives the expected KL divergence between two multivariate Gaussians,\n        E_q(mu_1, Sigma_1)  KL (  p_0(X | mu_0, Sigma_0)  || p_1(X | mu_1, Sigma_1))\n    in the specific case where the expectation is taken with respect to independent Gaussian\n    and Inverse Wishart distributions on the parameters of the second argument of the KL divergence.\n\n    We notate parameters by\n        q(mu_1, Sigma_1) =  q(mu_1 | m, V) q(Sigma_1 | nu,  S)\n\n    Arguments:\n        mu_0 : NumpyArray1D,\n            The mean parameter of the Gaussian of the first argument to the KL divergence\n        Sigma_0 : NumpyArray2D,\n            The covariance parameter of the Gaussian of the first argument to the KL divergence\n        m : NumpyArray1D,\n            The mean parameter of the Gaussian distribution on mu_1,  which is the mean\n            of the Gaussian of the second argument to the KL divergence\n        V : NumpyArray2D,\n            The covariance parameter of the Gaussian distribution on mu_1,  which is the mean\n            of the Gaussian of the second argument to the KL divergence\n        nu : float,\n            The degrees of freedom parameter of the Inverse Wishart distribution on Sigma_1,\n            which is the covariance of the Gaussian of the second argument to the KL divergence\n        S : NumpyArray2D,\n            The residual sum of squares parameter of the Inverse Wishart distribution on Sigma_1,\n            which is the covariance of the Gaussian of the second argument to the KL divergence\n    \"\"\"", "\n", "# TODO: Write checks that dimensionalities match", "\n", "\n", "N", "=", "S", ".", "shape", "[", "0", "]", "\n", "\n", "return", "0.5", "*", "(", "\n", "compute_expected_log_det_of_inverse_wishart_rv", "(", "nu", ",", "S", ")", "\n", "-", "np", ".", "log", "(", "np", ".", "linalg", ".", "det", "(", "Sigma_0", ")", ")", "\n", "-", "N", "\n", "+", "np", ".", "trace", "(", "\n", "nu", "\n", "*", "np", ".", "linalg", ".", "inv", "(", "S", ")", "\n", "@", "(", "mu_0", "@", "mu_0", ".", "T", "-", "mu_0", "@", "m", ".", "T", "-", "m", "@", "mu_0", ".", "T", "+", "V", "+", "m", "@", "m", ".", "T", "+", "Sigma_0", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.util.one_hot_encoded_array_from_categorical_indices": [[10, 43], ["len", "warnings.warn", "scipy.sparse.csr_matrix", "numpy.zeros", "max", "numpy.arange"], "function", ["None"], ["def", "one_hot_encoded_array_from_categorical_indices", "(", "\n", "categorical_indices", ":", "NumpyArray1D", ",", "\n", "number_of_possible_categories", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "sparse_representation", ":", "bool", "=", "False", ",", "\n", ")", "->", "np", ".", "array", ":", "\n", "    ", "\"\"\"\n    Takes a one-dim numpy array of integers and expands it to a two-dim numpy array\n    that is one-hot encoded\n    \"\"\"", "\n", "\n", "# TODO: This function currently assumes that we should assign a column for every", "\n", "# integer within 0 and the maximal categorical index.   This should be related", "\n", "\n", "if", "number_of_possible_categories", "is", "None", ":", "\n", "# If `number_of_possible_categories` is not provided, we will infer it to be the maximum value", "\n", "# plus one, due to zero-indexing, but this potentially dangerous to do under the hood.  Is 0 a", "\n", "# legitimate value? If the max value is far higher than the number of possible values, do we really", "\n", "# want to represent everything between zero and the max?", "\n", "        ", "number_of_possible_categories", "=", "max", "(", "categorical_indices", ")", "+", "1", "\n", "warnings", ".", "warn", "(", "\n", "f\"Inferring the number of possible values to be {number_of_possible_categories}. \"", "\n", "f\"Does that seem corect?\"", "\n", ")", "\n", "\n", "", "N", "=", "len", "(", "categorical_indices", ")", "\n", "K", "=", "number_of_possible_categories", "\n", "if", "sparse_representation", ":", "\n", "        ", "one_hot_matrix", "=", "csr_matrix", "(", "(", "N", ",", "K", ")", ")", "\n", "", "else", ":", "\n", "        ", "one_hot_matrix", "=", "np", ".", "zeros", "(", "(", "N", ",", "K", ")", ",", "dtype", "=", "int", ")", "\n", "\n", "", "one_hot_matrix", "[", "(", "np", ".", "arange", "(", "N", ")", ",", "categorical_indices", ")", "]", "=", "1", "\n", "return", "one_hot_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.util.construct_standardized_design_matrix": [[45, 48], ["numpy.std", "numpy.mean"], "function", ["None"], ["", "def", "construct_standardized_design_matrix", "(", "design_matrix", ":", "np", ".", "array", ")", ":", "\n", "    ", "return", "(", "design_matrix", "-", "np", ".", "mean", "(", "design_matrix", ",", "axis", "=", "0", ")", ")", "/", "np", ".", "std", "(", "\n", "design_matrix", ",", "axis", "=", "0", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.plot_helpers.create_hot_pairplot": [[8, 33], ["seaborn.PairGrid", "sns.PairGrid.map_diag", "sns.PairGrid.map_offdiag", "seaborn.light_palette", "matplotlib.pyplot.hist2d", "kws.pop"], "function", ["None"], ["def", "create_hot_pairplot", "(", "df", ":", "DataFrame", ",", "n_bins", "=", "20", ")", "->", "sns", ".", "axisgrid", ".", "PairGrid", ":", "\n", "    ", "\"\"\"\n    Create a pairwise plot where the diagonals show histograms and the off diagonals show\n    heatmaps.\n\n    The more direct way of creating pair plots, via `sns.pairplot(df)`, has scatterplots on the\n    off-diagonals, which is hard to interpret for large datasets, due to points overlapping.\n\n    Returns:\n        Subplot grid for plotting pairwise relationships in a dataset.\n        Can be shown by calling plt.show() after runnign the function\n\n    Reference:\n        https://stackoverflow.com/questions/43924280/pair-plot-with-heat-maps-possibly-logarithmic?rq=1\n\n    \"\"\"", "\n", "g", "=", "sns", ".", "PairGrid", "(", "df", ")", "\n", "g", ".", "map_diag", "(", "plt", ".", "hist", ",", "bins", "=", "n_bins", ")", "\n", "\n", "def", "pairgrid_heatmap", "(", "x", ",", "y", ",", "**", "kws", ")", ":", "\n", "        ", "cmap", "=", "sns", ".", "light_palette", "(", "kws", ".", "pop", "(", "\"color\"", ")", ",", "as_cmap", "=", "True", ")", "\n", "plt", ".", "hist2d", "(", "x", ",", "y", ",", "cmap", "=", "cmap", ",", "cmin", "=", "1", ",", "**", "kws", ")", "\n", "\n", "", "g", ".", "map_offdiag", "(", "pairgrid_heatmap", ",", "bins", "=", "n_bins", ")", "\n", "return", "g", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.plot_helpers.make_linear_regression_plot": [[35, 106], ["seaborn.regplot", "ax.yaxis.set_tick_params", "ax.set", "ax.set_title", "seaborn.set_style", "matplotlib.pyplot.subplots", "seaborn.light_palette", "ax.hist2d", "matplotlib.pyplot.colorbar", "ax.scatter", "ax.hlines", "seaborn.regplot", "min", "max"], "function", ["None"], ["", "def", "make_linear_regression_plot", "(", "\n", "df", ":", "DataFrame", ",", "\n", "x_col_name", ":", "str", ",", "\n", "y_col_name", ":", "str", ",", "\n", "x_axis_label", ":", "str", ",", "\n", "y_axis_label", ":", "str", ",", "\n", "title", ":", "str", ",", "\n", "reg_line_label", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "add_y_equals_x_line", "=", "True", ",", "\n", "add_y_equals_0_line", "=", "True", ",", "\n", "lowess", "=", "False", ",", "\n", "ax", "=", "None", ",", "\n", "plot_points_as_density_not_scatter", "=", "True", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        plot_points_as_density_not_scatter:  Defaults to True because a density plot is much\n            easier to grok than a scatter plot when there are lots of points - can more easily tell\n            how unlikely it is to get an outlier value.\n    \"\"\"", "\n", "if", "ax", "is", "None", ":", "\n", "        ", "sns", ".", "set_style", "(", "\"whitegrid\"", ")", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "figsize", "=", "(", "6", ",", "6", ")", ")", "\n", "\n", "", "if", "plot_points_as_density_not_scatter", ":", "\n", "        ", "cmap", "=", "sns", ".", "light_palette", "(", "\"seagreen\"", ",", "as_cmap", "=", "True", ")", "\n", "counts", ",", "xedges", ",", "yedges", ",", "im", "=", "ax", ".", "hist2d", "(", "\n", "df", "[", "x_col_name", "]", ",", "df", "[", "y_col_name", "]", ",", "cmap", "=", "cmap", ",", "cmin", "=", "1", "\n", ")", "\n", "plt", ".", "colorbar", "(", "im", ",", "ax", "=", "ax", ")", "\n", "\n", "", "else", ":", "\n", "        ", "ax", ".", "scatter", "(", "df", "[", "x_col_name", "]", ",", "df", "[", "y_col_name", "]", ",", "color", "=", "\"red\"", ",", "alpha", "=", "0.5", ")", "\n", "\n", "", "if", "add_y_equals_0_line", ":", "\n", "        ", "ax", ".", "hlines", "(", "\n", "y", "=", "0", ",", "\n", "xmin", "=", "min", "(", "df", "[", "x_col_name", "]", ")", ",", "\n", "xmax", "=", "max", "(", "df", "[", "x_col_name", "]", ")", ",", "\n", "colors", "=", "\"k\"", ",", "\n", "linestyles", "=", "\"--\"", ",", "\n", ")", "\n", "\n", "", "sns", ".", "regplot", "(", "\n", "x", "=", "x_col_name", ",", "\n", "y", "=", "y_col_name", ",", "\n", "data", "=", "df", ",", "\n", "fit_reg", "=", "True", ",", "\n", "ci", "=", "None", ",", "\n", "label", "=", "reg_line_label", ",", "\n", "scatter", "=", "False", ",", "\n", "color", "=", "\"black\"", ",", "\n", "lowess", "=", "lowess", ",", "\n", "ax", "=", "ax", ",", "\n", ")", "\n", "if", "add_y_equals_x_line", ":", "\n", "        ", "sns", ".", "regplot", "(", "\n", "x", "=", "x_col_name", ",", "\n", "y", "=", "x_col_name", ",", "\n", "data", "=", "df", ",", "\n", "fit_reg", "=", "True", ",", "\n", "ci", "=", "None", ",", "\n", "label", "=", "\"y=x\"", ",", "\n", "scatter", "=", "False", ",", "\n", "color", "=", "\"black\"", ",", "\n", "ax", "=", "ax", ",", "\n", ")", "\n", "", "ax", ".", "yaxis", ".", "set_tick_params", "(", "labelleft", "=", "True", ")", "\n", "ax", ".", "set", "(", "ylabel", "=", "y_axis_label", ",", "xlabel", "=", "x_axis_label", ")", "\n", "ax", ".", "set_title", "(", "title", ")", "\n", "return", "ax", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.baserate.compute_probs_for_baserate_model": [[6, 13], ["numpy.mean", "numpy.repeat"], "function", ["None"], ["def", "compute_probs_for_baserate_model", "(", "labels_train", ":", "NumpyArray2D", ",", "n_samples", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    We create a baserate model just looks at the frequency of each category in the training set and then\n    predicts categories in that order for every sample, regardless of covariate.\n    \"\"\"", "\n", "probs_for_each_sample", "=", "np", ".", "mean", "(", "labels_train", ",", "0", ")", "\n", "return", "np", ".", "repeat", "(", "probs_for_each_sample", "[", ":", ",", "np", ".", "newaxis", "]", ",", "n_samples", ",", "axis", "=", "1", ")", ".", "T", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.core.compute_posterior_prob_of_scaled_neighborhood_around_zero": [[21, 80], ["numpy.shape", "numpy.zeros", "range", "pandas.DataFrame", "numpy.repeat", "range", "categorical_from_binary.covariate_dict.sorted_covariate_names_from_covariate_dict", "list", "label_dict.keys", "scipy.stats.norm().cdf", "scipy.stats.norm().cdf", "scipy.stats.norm", "scipy.stats.norm"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.covariate_dict.sorted_covariate_names_from_covariate_dict"], ["def", "compute_posterior_prob_of_scaled_neighborhood_around_zero", "(", "\n", "beta_mean", ":", "NumpyArray2D", ",", "\n", "beta_stds", ":", "Union", "[", "NumpyArray1D", ",", "NumpyArray2D", "]", ",", "\n", "neighborhood_radius_in_units_of_std_devs", ":", "float", "=", "1.0", ",", "\n", "covariate_dict", ":", "Optional", "[", "Dict", "[", "str", ",", "VariableInfo", "]", "]", "=", "None", ",", "\n", "label_dict", ":", "Optional", "[", "Dict", "[", "str", ",", "VariableInfo", "]", "]", "=", "None", ",", "\n", ")", "->", "DataFrame", ":", "\n", "    ", "\"\"\"\n    If `r` refers to `neighborhood_radius_in_units_of_std_devs`, this computes the  posterior probability of 0 being within\n    some epislon-ball around zero,\n        P{beta_j in scaled neighborhood around 0) := P_{posterior on beta_j}( - epsilon  <= 0 <= epsilon)\n    where epsilon =  r * std(beta_j)\n\n    Note that the variational posterior distribution on betas is normal.\n\n    Reference:\n        Li, Q., & Lin, N. (2010). The Bayesian elastic net. Bayesian analysis, 5(1), 151-170,\n        Sections 2.5 and 3.\n\n    Arguments:\n        beta_mean: has shape (M,K), where M is number of covariates and K is the\n            number of categories\n        beta_stds: has shape (M,) where M is the number of covariates\n            OR has shape (M,K), where M is number of covariates and K is the\n            number of categories\n    \"\"\"", "\n", "# handle the binary (two-category) case. here it looks like there is only one \"category\",", "\n", "# although that's just a function of how binary probit is structured.", "\n", "if", "beta_mean", ".", "ndim", "==", "1", ":", "\n", "        ", "beta_mean", "=", "beta_mean", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "\n", "", "n_covariates", ",", "n_categories", "=", "np", ".", "shape", "(", "beta_mean", ")", "\n", "\n", "if", "beta_stds", ".", "ndim", "==", "1", ":", "\n", "        ", "beta_stds", "=", "np", ".", "repeat", "(", "beta_stds", "[", ":", ",", "np", ".", "newaxis", "]", ",", "n_categories", ",", "axis", "=", "1", ")", "\n", "\n", "", "posterior_probs_in_neighborhood", "=", "np", ".", "zeros", "(", "(", "n_covariates", ",", "n_categories", ")", ")", "\n", "for", "p", "in", "range", "(", "n_covariates", ")", ":", "\n", "        ", "for", "k", "in", "range", "(", "n_categories", ")", ":", "\n", "            ", "mean", ",", "std", "=", "beta_mean", "[", "p", ",", "k", "]", ",", "beta_stds", "[", "p", ",", "k", "]", "\n", "epsilon", "=", "neighborhood_radius_in_units_of_std_devs", "*", "std", "\n", "posterior_probs_in_neighborhood", "[", "p", ",", "k", "]", "=", "norm", "(", "mean", ",", "std", ")", ".", "cdf", "(", "epsilon", ")", "-", "norm", "(", "\n", "mean", ",", "std", "\n", ")", ".", "cdf", "(", "-", "epsilon", ")", "\n", "\n", "", "", "if", "covariate_dict", "is", "not", "None", ":", "\n", "        ", "index", "=", "sorted_covariate_names_from_covariate_dict", "(", "covariate_dict", ")", "\n", "", "else", ":", "\n", "        ", "index", "=", "None", "\n", "\n", "", "if", "label_dict", "is", "not", "None", ":", "\n", "        ", "columns", "=", "list", "(", "label_dict", ".", "keys", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "columns", "=", "None", "\n", "\n", "", "return", "pd", ".", "DataFrame", "(", "\n", "data", "=", "posterior_probs_in_neighborhood", ",", "\n", "index", "=", "index", ",", "\n", "columns", "=", "columns", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.core.compute_feature_inclusion_data_frame_using_scaled_neighborhood_method": [[83, 129], ["core.compute_posterior_prob_of_scaled_neighborhood_around_zero", "inclusion_matrix_as_boolean.astype"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.core.compute_posterior_prob_of_scaled_neighborhood_around_zero"], ["", "def", "compute_feature_inclusion_data_frame_using_scaled_neighborhood_method", "(", "\n", "beta_mean", ":", "NumpyArray2D", ",", "\n", "beta_stds", ":", "Union", "[", "NumpyArray1D", ",", "NumpyArray2D", "]", ",", "\n", "neighborhood_probability_threshold_for_exclusion", ":", "float", ",", "\n", "neighborhood_radius_in_units_of_std_devs", ":", "float", ",", "\n", "covariate_dict", ":", "Optional", "[", "Dict", "[", "str", ",", "VariableInfo", "]", "]", "=", "None", ",", "\n", "label_dict", ":", "Optional", "[", "Dict", "[", "str", ",", "VariableInfo", "]", "]", "=", "None", ",", "\n", ")", "->", "DataFrame", ":", "\n", "    ", "\"\"\"\n    If `r` refers to `neighborhood_radius_in_units_of_std_devs`, we first compute the  posterior probability of 0 being within\n    some epsilon-ball around zero,\n        P({beta_j in scaled neighborhood around 0}) := P_{posterior on beta_j}( - epsilon  <= 0 <= epsilon)\n    where epsilon =  r * std(beta_j)\n\n    We then exclude from the model any predictor beta_j such that\n        P({beta_j in scaled neighborhood around 0}) >= neighborhood_probability_threshold_for_exclusion.\n\n    Note that the variational posterior distribution on betas is normal.\n\n    Reference:\n        Li, Q., & Lin, N. (2010). The Bayesian elastic net. Bayesian analysis, 5(1), 151-170,\n        Sections 2.5 and 3.\n\n    Arguments:\n        beta_mean: has shape (M,K), where M is number of covariates and K is the\n            number of categories\n        beta_stds: has shape (M,) where M is the number of covariates\n            OR has shape (M,K), where M is number of covariates and K is the\n            number of categories\n        neighborhood_probability_threshold_for_exclusion: A predictor is excluded if the\n            posterior probability of being in a (-std beta_j, +std beta_j)\n            exceeds this probability neighborhood_probability_threshold_for_exclusion and is retained otherwise.\n    \"\"\"", "\n", "scaled_neighborhood_probs", "=", "(", "\n", "compute_posterior_prob_of_scaled_neighborhood_around_zero", "(", "\n", "beta_mean", ",", "\n", "beta_stds", ",", "\n", "neighborhood_radius_in_units_of_std_devs", ",", "\n", "covariate_dict", ",", "\n", "label_dict", ",", "\n", ")", "\n", ")", "\n", "inclusion_matrix_as_boolean", "=", "(", "\n", "scaled_neighborhood_probs", "<", "neighborhood_probability_threshold_for_exclusion", "\n", ")", "\n", "return", "(", "inclusion_matrix_as_boolean", ")", ".", "astype", "(", "int", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.sklearn.get_sklearn_beta_vector_from_logistic_regression": [[30, 61], ["categorical_from_binary.sklearn.fit_sklearn_multiclass_logistic_regression", "categorical_from_binary.sklearn.fit_sklearn_binary_logistic_regression", "numpy.matrix.flatten", "numpy.insert", "numpy.vstack"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.sklearn.fit_sklearn_multiclass_logistic_regression", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.sklearn.fit_sklearn_binary_logistic_regression"], ["", "if", "penalty", "==", "\"l2\"", "and", "solver", "is", "None", ":", "\n", "        ", "solver", "=", "\"newton-cg\"", "\n", "", "elif", "penalty", "==", "\"l1\"", "and", "solver", "is", "None", ":", "\n", "        ", "solver", "=", "\"liblinear\"", "\n", "", "elif", "solver", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Not sure what to use as default solver, consult sklearn for guidance\"", "\n", ")", "\n", "\n", "", "X", "=", "features", "\n", "y", "=", "labels", "\n", "\n", "clf", "=", "LogisticRegression", "(", "\n", "penalty", "=", "penalty", ",", "\n", "solver", "=", "solver", ",", "\n", "random_state", "=", "0", ",", "\n", "C", "=", "sklearn_logistic_regression_C", ",", "\n", ")", ".", "fit", "(", "X", ",", "y", ")", "\n", "return", "clf", "\n", "\n", "\n", "", "def", "fit_sklearn_multiclass_logistic_regression", "(", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray2D", ",", "\n", "sklearn_logistic_regression_C", ":", "float", "=", "1.0", ",", "\n", "penalty", ":", "str", "=", "\"l2\"", ",", "\n", "solver", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", "->", "LogisticRegression", ":", "\n", "\n", "    ", "X", "=", "covariates", "\n", "y", "=", "np", ".", "argmax", "(", "labels", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.sklearn.get_sklearn_variable_selection_results_using_logistic_regression": [[64, 88], ["sklearn.get_sklearn_beta_vector_from_logistic_regression", "numpy.array", "pandas.DataFrame", "sklearn.SklearnVariableSelectionResults", "abs"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.sklearn.get_sklearn_beta_vector_from_logistic_regression"], ["", "elif", "penalty", "==", "\"l1\"", "and", "solver", "is", "None", ":", "\n", "        ", "solver", "=", "\"saga\"", "\n", "", "elif", "solver", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Not sure what to use as default solver, consult sklearn for guidance\"", "\n", ")", "\n", "\n", "### Get variable selection decisions for logistic regression, possibly with lasso", "\n", "", "clf", "=", "LogisticRegression", "(", "\n", "penalty", "=", "penalty", ",", "\n", "solver", "=", "solver", ",", "\n", "random_state", "=", "0", ",", "\n", "multi_class", "=", "\"multinomial\"", ",", "\n", "C", "=", "sklearn_logistic_regression_C", ",", "\n", "fit_intercept", "=", "False", ",", "\n", ")", ".", "fit", "(", "X", ",", "y", ")", "\n", "return", "clf", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.sklearn.get_evaluation_results_by_sklearn_Cs": [[90, 126], ["print", "categorical_from_binary.selection.evaluate.get_evaluation_result", "sklearn.get_sklearn_variable_selection_results_using_logistic_regression"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.evaluate.get_evaluation_result", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.sklearn.get_sklearn_variable_selection_results_using_logistic_regression"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.evaluate.get_evaluation_result": [[26, 41], ["numpy.ndim", "evaluate.get_evaluation_result_for_binary_data", "numpy.ndim", "evaluate.get_evaluation_result_for_multiclass_data", "ValueError"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.evaluate.get_evaluation_result_for_binary_data", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.evaluate.get_evaluation_result_for_multiclass_data"], ["", "def", "get_evaluation_result", "(", "\n", "beta_true", ":", "Union", "[", "NumpyArray1D", ",", "NumpyArray2D", "]", ",", "\n", "model_inclusion_decision", ":", "Union", "[", "NumpyArray1D", ",", "NumpyArray2D", ",", "DataFrame", "]", ",", "\n", ")", ":", "\n", "    ", "if", "np", ".", "ndim", "(", "beta_true", ")", "==", "1", ":", "\n", "        ", "return", "get_evaluation_result_for_binary_data", "(", "\n", "beta_true", ",", "model_inclusion_decision", "\n", ")", "\n", "", "elif", "np", ".", "ndim", "(", "beta_true", ")", "==", "2", ":", "\n", "        ", "return", "get_evaluation_result_for_multiclass_data", "(", "\n", "beta_true", ",", "model_inclusion_decision", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Not sure how to handle the dimensionality of the provided true beta\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.evaluate.get_evaluation_result_for_multiclass_data": [[44, 79], ["isinstance", "numpy.shape", "numpy.sum", "numpy.vstack", "numpy.mean", "evaluate.EvaluationResult", "model_inclusion_decision.to_numpy.to_numpy", "ValueError", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.ones", "numpy.zeros", "numpy.logical_and", "numpy.logical_and"], "function", ["None"], ["", "", "def", "get_evaluation_result_for_multiclass_data", "(", "\n", "beta_true", ":", "NumpyArray2D", ",", "\n", "model_inclusion_decision", ":", "Union", "[", "NumpyArray2D", ",", "DataFrame", "]", ",", "\n", ")", "->", "EvaluationResult", ":", "\n", "    ", "\"\"\"\n    Gets tpr, fpr, and accuracy\n\n    Arguments:\n        model_inclusion_decision: array (possibly data of a DataFrame) with shape (M,K), where M is number of covariates and K is\n        number of categories\n    \"\"\"", "\n", "if", "isinstance", "(", "model_inclusion_decision", ",", "DataFrame", ")", ":", "\n", "        ", "model_inclusion_decision", "=", "model_inclusion_decision", ".", "to_numpy", "(", ")", "\n", "\n", "", "m", ",", "k", "=", "np", ".", "shape", "(", "beta_true", ")", "\n", "s_by_category", "=", "np", ".", "sum", "(", "\n", "beta_true", "==", "0.0", ",", "axis", "=", "0", "\n", ")", "# sparsity by category; assumed to be the last s entries", "\n", "if", "(", "s_by_category", "==", "s_by_category", "[", "0", "]", ")", ".", "all", "(", ")", ":", "\n", "        ", "s", "=", "s_by_category", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"This function assumes the true sparsity pattern is identical across categories\"", "\n", ")", "\n", "\n", "", "true_inclusion_decision", "=", "np", ".", "vstack", "(", "(", "np", ".", "ones", "(", "(", "m", "-", "s", ",", "k", ")", ")", ",", "np", ".", "zeros", "(", "(", "s", ",", "k", ")", ")", ")", ")", "\n", "\n", "false_positive_rate", "=", "np", ".", "sum", "(", "\n", "np", ".", "logical_and", "(", "model_inclusion_decision", "==", "1", ",", "true_inclusion_decision", "==", "0", ")", "\n", ")", "/", "(", "np", ".", "sum", "(", "true_inclusion_decision", "==", "0", ")", ")", "\n", "true_positive_rate", "=", "np", ".", "sum", "(", "\n", "np", ".", "logical_and", "(", "model_inclusion_decision", "==", "1", ",", "true_inclusion_decision", "==", "1", ")", "\n", ")", "/", "(", "np", ".", "sum", "(", "true_inclusion_decision", "==", "1", ")", ")", "\n", "accuracy", "=", "np", ".", "mean", "(", "model_inclusion_decision", "==", "true_inclusion_decision", ")", "\n", "return", "EvaluationResult", "(", "false_positive_rate", ",", "true_positive_rate", ",", "accuracy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.evaluate.get_evaluation_result_for_binary_data": [[81, 112], ["isinstance", "numpy.sum", "numpy.hstack", "numpy.mean", "evaluate.EvaluationResult", "numpy.ndim", "NotImplementedError", "model_inclusion_decision.to_numpy.to_numpy", "numpy.shape", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.ones", "numpy.zeros", "numpy.logical_and", "numpy.logical_and"], "function", ["None"], ["", "def", "get_evaluation_result_for_binary_data", "(", "\n", "beta_true", ":", "NumpyArray1D", ",", "\n", "model_inclusion_decision", ":", "Union", "[", "NumpyArray1D", ",", "DataFrame", "]", ",", "\n", ")", "->", "EvaluationResult", ":", "\n", "    ", "\"\"\"\n    Warning:\n        Has only been used on binary data so far.\n\n    Arguments:\n        model_inclusion_decision: DataFrame whose data has shape (M,), where M is number of covariates\n    \"\"\"", "\n", "if", "np", ".", "ndim", "(", "beta_true", ")", "!=", "1", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\n", "\"So far, this fucntion has only been developed and applied to binary models\"", "\n", ")", "\n", "\n", "", "if", "isinstance", "(", "model_inclusion_decision", ",", "DataFrame", ")", ":", "\n", "        ", "model_inclusion_decision", "=", "model_inclusion_decision", ".", "to_numpy", "(", ")", "\n", "\n", "", "p", "=", "np", ".", "shape", "(", "beta_true", ")", "[", "0", "]", "# number of predictors", "\n", "s", "=", "np", ".", "sum", "(", "beta_true", "==", "0.0", ")", "# sparsity; assumed to be the last s entries", "\n", "true_inclusion_decision", "=", "np", ".", "hstack", "(", "(", "np", ".", "ones", "(", "p", "-", "s", ")", ",", "np", ".", "zeros", "(", "s", ")", ")", ")", "\n", "\n", "false_positive_rate", "=", "np", ".", "sum", "(", "\n", "np", ".", "logical_and", "(", "model_inclusion_decision", "==", "1", ",", "true_inclusion_decision", "==", "0", ")", "\n", ")", "/", "(", "np", ".", "sum", "(", "true_inclusion_decision", "==", "0", ")", ")", "\n", "true_positive_rate", "=", "np", ".", "sum", "(", "\n", "np", ".", "logical_and", "(", "model_inclusion_decision", "==", "1", ",", "true_inclusion_decision", "==", "1", ")", "\n", ")", "/", "(", "np", ".", "sum", "(", "true_inclusion_decision", "==", "1", ")", ")", "\n", "accuracy", "=", "np", ".", "mean", "(", "model_inclusion_decision", "==", "true_inclusion_decision", ")", "\n", "return", "EvaluationResult", "(", "false_positive_rate", ",", "true_positive_rate", ",", "accuracy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.evaluate.print_report_on_variable_selection_decisions": [[114, 182], ["sklearn.linear_model.LogisticRegression().fit", "numpy.matrix.flatten", "numpy.array", "numpy.hstack", "numpy.sum", "numpy.hstack", "numpy.mean", "print", "numpy.ndim", "NotImplementedError", "numpy.shape", "numpy.vstack", "print", "numpy.mean", "sklearn.linear_model.LogisticRegression", "int", "numpy.ones", "numpy.zeros", "abs"], "function", ["None"], ["", "def", "print_report_on_variable_selection_decisions", "(", "\n", "X", ":", "NumpyArray2D", ",", "\n", "y", ":", "NumpyArray1D", ",", "\n", "beta_mean", ":", "NumpyArray1D", ",", "\n", "beta_variational_stds", ":", "NumpyArray1D", ",", "\n", "beta_true", ":", "NumpyArray1D", ",", "\n", "feature_inclusion_df", ":", "DataFrame", ",", "\n", "sklearn_logistic_lasso_regression_C", ":", "float", "=", "1.0", ",", "\n", "verbose", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Addresses the question:\n        how does our variatinal inference scheme compare to scikit's logistic lasso regression in terms\n        of making variable selection decisions?\n\n    Arguments:\n        feature_inclusion_df: has shape (M,K), where M is number of covariates and K is the\n            number of categories\n    \"\"\"", "\n", "# TODO: Align with `get_evaluation_result`", "\n", "\n", "if", "np", ".", "ndim", "(", "beta_true", ")", "!=", "1", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\n", "\"So far, this fucntion has only been developed and applied to binary models\"", "\n", ")", "\n", "\n", "", "p", "=", "np", ".", "shape", "(", "beta_true", ")", "[", "0", "]", "# number of predictors", "\n", "\n", "variational_inclusion_decision", "=", "feature_inclusion_df", "\n", "\n", "### Get variable selection decisions for logistic regression, possibly with lasso", "\n", "# TODO: the sklearn fucntion should be factored out of this code; I have similar code for sklearn", "\n", "# within the marksmanship subpackage.", "\n", "clf", "=", "LogisticRegression", "(", "\n", "penalty", "=", "\"l1\"", ",", "\n", "solver", "=", "\"liblinear\"", ",", "\n", "random_state", "=", "0", ",", "\n", "C", "=", "sklearn_logistic_lasso_regression_C", ",", "\n", ")", ".", "fit", "(", "X", ",", "y", ")", "\n", "scikit_beta", "=", "np", ".", "matrix", ".", "flatten", "(", "np", ".", "vstack", "(", "(", "clf", ".", "intercept_", ",", "clf", ".", "coef_", ".", "T", ")", ")", ")", "\n", "scikit_inclusion_decision", "=", "np", ".", "array", "(", "[", "int", "(", "x", ")", "for", "x", "in", "abs", "(", "scikit_beta", ")", ">", "0.0", "]", ")", "\n", "\n", "info", "=", "np", ".", "hstack", "(", "\n", "(", "\n", "beta_true", "[", ":", ",", "np", ".", "newaxis", "]", ",", "\n", "scikit_beta", "[", ":", ",", "np", ".", "newaxis", "]", ",", "\n", "scikit_inclusion_decision", "[", ":", ",", "np", ".", "newaxis", "]", ",", "\n", "beta_mean", "[", ":", ",", "np", ".", "newaxis", "]", ",", "\n", "beta_variational_stds", "[", ":", ",", "np", ".", "newaxis", "]", ",", "\n", "variational_inclusion_decision", ",", "\n", ")", "\n", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\n", "f\"\\nBeta true, scikit beta, scikit inclusion decision, variational mean beta, variational beta stds, variational inclusion decision: \\n {info}\"", "\n", ")", "\n", "\n", "### get accuracy in variable selection decisions", "\n", "", "s", "=", "np", ".", "sum", "(", "beta_true", "==", "0.0", ")", "# sparsity; assumed to be the last s entries", "\n", "true_inclusion_decision", "=", "np", ".", "hstack", "(", "(", "np", ".", "ones", "(", "p", "-", "s", ")", ",", "np", ".", "zeros", "(", "s", ")", ")", ")", "\n", "scikit_inclusion_accuracy", "=", "np", ".", "mean", "(", "\n", "scikit_inclusion_decision", "==", "true_inclusion_decision", "\n", ")", "\n", "variational_inclusion_accuracy", "=", "np", ".", "mean", "(", "\n", "variational_inclusion_decision", "==", "true_inclusion_decision", "[", ":", ",", "np", ".", "newaxis", "]", "\n", ")", "[", "0", "]", "\n", "print", "(", "\n", "f\"Inclusion decision accuracy -- scikit: {scikit_inclusion_accuracy:.02}, variational: {variational_inclusion_accuracy:.02}\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.hyperparameters.gamma_parameter_from_lambda_and_desired_marginal_beta_variance": [[26, 36], ["numpy.sqrt"], "function", ["None"], ["", "def", "gamma_parameter_from_lambda_and_desired_marginal_beta_variance", "(", "\n", "variance", ":", "float", ",", "lambda_", ":", "float", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Determine the gamma hyperparameter for a normal gamma prior, given:\n        1) the other hyperparameter, lambda_, which controls the prior expectation on sparsity\n        (lower values means more sparse)\n        2) the desired variance in the regression weights\n    \"\"\"", "\n", "return", "np", ".", "sqrt", "(", "variance", "/", "(", "2", "*", "lambda_", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.hyperparameters.hyperparameters_from_lambda_and_desired_marginal_beta_variance": [[38, 46], ["hyperparameters.gamma_parameter_from_lambda_and_desired_marginal_beta_variance", "hyperparameters.Hyperparameters"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.hyperparameters.gamma_parameter_from_lambda_and_desired_marginal_beta_variance"], ["", "def", "hyperparameters_from_lambda_and_desired_marginal_beta_variance", "(", "\n", "variance", ":", "float", ",", "lambda_", ":", "float", "\n", ")", "->", "Hyperparameters", ":", "\n", "    ", "gamma", "=", "gamma_parameter_from_lambda_and_desired_marginal_beta_variance", "(", "\n", "variance", ",", "\n", "lambda_", ",", "\n", ")", "\n", "return", "Hyperparameters", "(", "lambda_", ",", "gamma", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.roc.get_evaluation_results_for_variational_bayes_by_lambdas_": [[30, 118], ["numpy.logspace", "print", "categorical_from_binary.selection.hyperparameters.hyperparameters_from_lambda_and_desired_marginal_beta_variance", "inference_function", "categorical_from_binary.ib_cavi.multi.ib_probit.util.beta_stds_from_beta_cov", "categorical_from_binary.selection.core.compute_feature_inclusion_data_frame_using_scaled_neighborhood_method", "categorical_from_binary.selection.evaluate.get_evaluation_result"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.hyperparameters.hyperparameters_from_lambda_and_desired_marginal_beta_variance", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit.util.beta_stds_from_beta_cov", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.core.compute_feature_inclusion_data_frame_using_scaled_neighborhood_method", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.evaluate.get_evaluation_result"], ["def", "get_evaluation_results_for_variational_bayes_by_lambdas_", "(", "\n", "labels", ",", "\n", "covariates", ",", "\n", "beta_true", ":", "NumpyArray1D", ",", "\n", "multiclass", ":", "bool", ",", "\n", "max_n_iterations", ":", "int", "=", "10", ",", "\n", "lambdas_", ":", "Optional", "[", "NumpyArray1D", "]", "=", "None", ",", "\n", ")", "->", "Dict", "[", "float", ",", "EvaluationResult", "]", ":", "\n", "    ", "\"\"\"\n    Function to find a good hyperparameter lambda_ for variable selection when applying CAVI to the\n    binary probit model.   Note that this function holds three other hyperparmeters fixed [the variance\n    of beta (another hyperparameter), plus two variable selection related hyperparameters).\n\n    Usage:\n\n        # evaluation results for variational bayes model\n        lambdas_ = np.logspace(start=-5, stop=2.5, num=15, base=10)\n        evaluation_results_by_lambdas_ = get_evaluation_results_for_variational_bayes_by_lambdas_(\n            labels, covariates, dataset.beta, lambdas_\n        )\n\n        # evaluation results with sklearn\n        from categorical_from_binary.selection.sklearn import get_evaluation_results_by_sklearn_Cs\n        sklearn_logistic_lasso_regression_Cs = np.logspace(start=-2, stop=0, num=24, base=10)\n        evaluation_results_by_sklearn_Cs = get_evaluation_results_by_sklearn_Cs(\n            dataset.features, dataset.labels, dataset.beta, sklearn_logistic_lasso_regression_Cs\n        )\n\n    Notes:\n        `features` should NOT include a column of ones for intercept\n    Arguments:\n        scikit_inclusion_decision: the return value of `get_sklearn_inclusion_decision_matrix_from_logistic_lasso_regression`\n    \"\"\"", "\n", "\n", "if", "lambdas_", "is", "None", ":", "\n", "        ", "lambdas_", "=", "np", ".", "logspace", "(", "start", "=", "-", "5", ",", "stop", "=", "2.5", ",", "num", "=", "15", ",", "base", "=", "10", ")", "\n", "\n", "", "evaluation_results_by_lambdas_", "=", "{", "}", "\n", "\n", "for", "lambda_", "in", "lambdas_", ":", "\n", "        ", "print", "(", "\n", "f\"Now evaluating the variable selection decisions of CAVI with lambda_ value of {lambda_:.03f}\"", "\n", ")", "\n", "variance", "=", "1.0", "\n", "hyperparameters", "=", "(", "\n", "hyperparameters_from_lambda_and_desired_marginal_beta_variance", "(", "\n", "variance", ",", "lambda_", "\n", ")", "\n", ")", "\n", "if", "multiclass", ":", "\n", "            ", "inference_function", "=", "compute_multiclass_probit_vi_with_normal_gamma_prior", "\n", "", "else", ":", "\n", "            ", "inference_function", "=", "compute_probit_vi_with_normal_gamma_prior", "\n", "\n", "", "variational_params", "=", "inference_function", "(", "\n", "labels", ",", "\n", "covariates", ",", "\n", "variational_params_init", "=", "None", ",", "\n", "max_n_iterations", "=", "max_n_iterations", ",", "\n", "convergence_criterion_drop_in_elbo", "=", "-", "np", ".", "inf", ",", "\n", "hyperparameters", "=", "hyperparameters", ",", "\n", ")", "\n", "\n", "# TODO: Make this a function argument, don't hardcode it.", "\n", "neighborhood_probability_threshold_for_exclusion", "=", "0.90", "\n", "neighborhood_radius_in_units_of_std_devs", "=", "3", "\n", "\n", "beta_mean", "=", "variational_params", ".", "beta", ".", "mean", "\n", "beta_stds", "=", "beta_stds_from_beta_cov", "(", "variational_params", ".", "beta", ".", "cov", ")", "\n", "\n", "feature_inclusion_df", "=", "(", "\n", "compute_feature_inclusion_data_frame_using_scaled_neighborhood_method", "(", "\n", "beta_mean", ",", "\n", "beta_stds", ",", "\n", "neighborhood_probability_threshold_for_exclusion", ",", "\n", "neighborhood_radius_in_units_of_std_devs", ",", "\n", ")", "\n", ")", "\n", "# TODO: if this stops working in the binary case, change the code so that it does the", "\n", "# following below in the binary case.", "\n", "#", "\n", "# variational_inclusion_decision = np.matrix.flatten(", "\n", "#    feature_inclusion_df.to_numpy()", "\n", "# )", "\n", "evaluation_result_vb", "=", "get_evaluation_result", "(", "beta_true", ",", "feature_inclusion_df", ")", "\n", "evaluation_results_by_lambdas_", "[", "lambda_", "]", "=", "evaluation_result_vb", "\n", "\n", "", "return", "evaluation_results_by_lambdas_", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.gig.compute_expected_reciprocal_of_gig_random_variable_with_wikipedia_parameter_labeling": [[15, 27], ["numpy.sqrt", "numpy.sqrt", "scipy.special.kv", "scipy.special.kv", "numpy.sqrt", "numpy.sqrt"], "function", ["None"], ["def", "compute_expected_reciprocal_of_gig_random_variable_with_wikipedia_parameter_labeling", "(", "\n", "a", ":", "float", ",", "\n", "b", ":", "float", ",", "\n", "p", ":", "float", ",", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Computes E[1/X], where X~GeneralizedInverseGaussian(a,b,p) with parameterization\n    given in Wikipedia.\n    \"\"\"", "\n", "return", "(", "np", ".", "sqrt", "(", "a", ")", "/", "np", ".", "sqrt", "(", "b", ")", ")", "*", "(", "\n", "bessel2", "(", "p", "+", "1", ",", "np", ".", "sqrt", "(", "a", "*", "b", ")", ")", "/", "bessel2", "(", "p", ",", "np", ".", "sqrt", "(", "a", "*", "b", ")", ")", "\n", ")", "-", "(", "2", "*", "p", "/", "b", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.gig.compute_expected_reciprocal_of_gig_random_variable_with_my_parameter_labeling": [[29, 41], ["numpy.sqrt", "numpy.sqrt", "scipy.special.kv", "scipy.special.kv", "numpy.sqrt", "numpy.sqrt"], "function", ["None"], ["", "def", "compute_expected_reciprocal_of_gig_random_variable_with_my_parameter_labeling", "(", "\n", "a", ":", "float", ",", "\n", "c", ":", "float", ",", "\n", "d", ":", "float", ",", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Computes E[1/X], where X~GeneralizedInverseGaussian(a,b,p) with parameters labeled as in my\n    categorical_from_binary report\n    \"\"\"", "\n", "return", "(", "np", ".", "sqrt", "(", "c", ")", "/", "np", ".", "sqrt", "(", "d", ")", ")", "*", "(", "\n", "bessel2", "(", "a", "+", "1", ",", "np", ".", "sqrt", "(", "c", "*", "d", ")", ")", "/", "bessel2", "(", "a", ",", "np", ".", "sqrt", "(", "c", "*", "d", ")", ")", "\n", ")", "-", "(", "2", "*", "a", "/", "d", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.load.construct_process_start_features_and_labels_for_one_cyber_user": [[19, 70], ["categorical_from_binary.datasets.cyber.data_frame.load_human_process_start_df", "categorical_from_binary.datasets.cyber.util.compute_sorted_sample_sizes_for_users", "categorical_from_binary.pandas_helpers.keep_df_rows_by_column_values", "categorical_from_binary.datasets.cyber.util.construct_minimal_process_id_by_process_id", "categorical_from_binary.datasets.cyber.util.compute_num_of_unique_processes_from_dict_of_minimal_process_id_by_process_id", "print", "categorical_from_binary.datasets.cyber.util.compute_sorted_sample_sizes_for_users", "print", "categorical_from_binary.pandas_helpers.keep_df_rows_by_column_values", "categorical_from_binary.datasets.cyber.featurize.construct_labels", "categorical_from_binary.datasets.cyber.featurize.construct_features"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.data_frame.load_human_process_start_df", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.util.compute_sorted_sample_sizes_for_users", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.pandas_helpers.keep_df_rows_by_column_values", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.util.construct_minimal_process_id_by_process_id", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.util.compute_num_of_unique_processes_from_dict_of_minimal_process_id_by_process_id", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.util.compute_sorted_sample_sizes_for_users", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.pandas_helpers.keep_df_rows_by_column_values", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.featurize.construct_labels", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.featurize.construct_features"], ["def", "construct_process_start_features_and_labels_for_one_cyber_user", "(", "\n", "path_to_human_process_start_data", ":", "str", ",", "\n", "subset_initial_user_idx_when_sorting_most_to_fewest_events", ":", "int", ",", "\n", "subset_number_of_users", ":", "int", ",", "\n", "user_idx_relative_to_subset", ":", "int", ",", "\n", "window_size", ":", "int", ",", "\n", "temperature", ":", "float", ",", "\n", "include_intercept", ":", "bool", ",", "\n", ")", "->", "Tuple", "[", "NumpyArray2D", ",", "NumpyArray2D", ",", "str", "]", ":", "\n", "    ", "\"\"\"\n    The number of processes/categories represented (i.e. the number of columns of the one-hot-encoded `labels`)\n    will be given by the number of unique categories launched across a subset of users, which is determined\n    by grabbing data from users indexed from ` subset_initial_user_idx_when_sorting_most_to_fewest_events`\n    to that value plus `subset_number_of_users`.\n    \"\"\"", "\n", "df_all", "=", "load_human_process_start_df", "(", "path_to_human_process_start_data", ")", "\n", "\n", "# get a subset of all user domains, from which we determine the number of categories to use for processing.", "\n", "sorted_sample_sizes_for_users", "=", "compute_sorted_sample_sizes_for_users", "(", "df_all", ")", "\n", "user_domains_in_subset", "=", "sorted_sample_sizes_for_users", ".", "index", "[", "\n", "subset_initial_user_idx_when_sorting_most_to_fewest_events", ":", "subset_initial_user_idx_when_sorting_most_to_fewest_events", "\n", "+", "subset_number_of_users", "\n", "]", "\n", "df_subset", "=", "keep_df_rows_by_column_values", "(", "\n", "df_all", ",", "col", "=", "\"user@domain\"", ",", "values", "=", "user_domains_in_subset", "\n", ")", "\n", "minimal_process_id_by_process_id", "=", "construct_minimal_process_id_by_process_id", "(", "\n", "df_subset", "\n", ")", "\n", "# `K` is the number of unique processes", "\n", "K", "=", "compute_num_of_unique_processes_from_dict_of_minimal_process_id_by_process_id", "(", "\n", "minimal_process_id_by_process_id", "\n", ")", "\n", "print", "(", "\n", "f\"The total number of distinct processes started in this subset of users is {K}.\"", "\n", ")", "\n", "\n", "### Get data for one user", "\n", "sorted_sample_sizes_for_users", "=", "compute_sorted_sample_sizes_for_users", "(", "df_all", ")", "\n", "user_domain", "=", "user_domains_in_subset", "[", "user_idx_relative_to_subset", "]", "\n", "print", "(", "f\"The user domain whose data is being grabbed is {user_domain}.\"", ")", "\n", "df", "=", "keep_df_rows_by_column_values", "(", "df_all", ",", "col", "=", "\"user@domain\"", ",", "values", "=", "user_domain", ")", "\n", "labels", "=", "construct_labels", "(", "df", ",", "minimal_process_id_by_process_id", ",", "window_size", ")", "\n", "features", "=", "construct_features", "(", "\n", "df", ",", "\n", "minimal_process_id_by_process_id", ",", "\n", "window_size", ",", "\n", "temperature", ",", "\n", "include_intercept", "=", "include_intercept", ",", "\n", ")", "\n", "return", "features", ",", "labels", ",", "user_domain", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.data_frame.extract_human_process_starts_from_df": [[10, 20], ["categorical_from_binary.pandas_helpers.filter_df_rows_by_column_values", "categorical_from_binary.pandas_helpers.filter_df_rows_by_column_value_starts"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.pandas_helpers.filter_df_rows_by_column_values", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.pandas_helpers.filter_df_rows_by_column_value_starts"], ["def", "extract_human_process_starts_from_df", "(", "df_full", ":", "DataFrame", ")", "->", "DataFrame", ":", "\n", "    ", "\"\"\"\n    Takes the full cybersecurity process starts dataframe, and retain only the process starts (not process ends),\n    and retain only rows that correspond to human user activity (i.e. user@domain starts with `U`)\n    \"\"\"", "\n", "df_starts", "=", "filter_df_rows_by_column_values", "(", "\n", "df_full", ",", "col", "=", "\"Start or End\"", ",", "values", "=", "\"End\"", "\n", ")", "\n", "return", "filter_df_rows_by_column_value_starts", "(", "\n", "df_starts", ",", "col", "=", "\"user@domain\"", ",", "start", "=", "\"U\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.data_frame.load_preprocessed_df_in_chunks": [[23, 67], ["print", "print", "print", "pandas.DataFrame", "pandas.read_csv", "print", "print", "data_frame.extract_human_process_starts_from_df", "pandas.concat"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.data_frame.extract_human_process_starts_from_df"], ["", "def", "load_preprocessed_df_in_chunks", "(", "path", ":", "str", ",", "chunk_size", ":", "int", "=", "100000", ")", "->", "DataFrame", ":", "\n", "    ", "\"\"\"\n    Load cybersecurity data as dataframe in chunks and preprocess along the way\n\n    Arguments:\n        path: Path to the uncompressed version of proc.txt.gz located at https://csr.lanl.gov/data/cyber1.\n        chunk_size: The number of lines to grab from the raw file at a time, before preprocessing\n            and adding to a slowly growing DataFrame.\n\n            For reference, the uncompressed version of proc.txt.gz referenced above has\n            L=426,045,096 lines.   So one would expect processing to be complete after\n            the number of chunks processed equals chunk_size/L.\n\n            I have gotten good results with chunk_size being 1,000,000 (and so requiring 427 chunks).\n\n    Returns:\n        dataframe with dimensionality (N,E)\n        where N is the number of process starts\n        and E is the number of events, described in the form\n        \"time,user@domain,computer,process name,start or end\u201d\n\n        For more information, see https://csr.lanl.gov/data/cyber1/ proc.txt.gz\n    \"\"\"", "\n", "print", "(", "\"--------------------\"", ")", "\n", "print", "(", "\"Loading \"", "+", "path", ")", "\n", "print", "(", "\"--------------------\"", ")", "\n", "df", "=", "pd", ".", "DataFrame", "(", ")", "\n", "\n", "column_names", "=", "[", "\"time\"", ",", "\"user@domain\"", ",", "\"computer\"", ",", "\"process name\"", ",", "\"Start or End\"", "]", "\n", "chunk_num", "=", "0", "\n", "for", "df_chunk_full", "in", "pd", ".", "read_csv", "(", "\n", "path", ",", "\n", "delimiter", "=", "\",\"", ",", "\n", "names", "=", "column_names", ",", "\n", "iterator", "=", "True", ",", "\n", "chunksize", "=", "chunk_size", ",", "\n", ")", ":", "\n", "        ", "chunk_num", "+=", "1", "\n", "print", "(", "f\"Now processing chunk {chunk_num}\"", ",", "end", "=", "\"\\r\"", ")", "\n", "df_chunk", "=", "extract_human_process_starts_from_df", "(", "df_chunk_full", ")", "\n", "df", "=", "pd", ".", "concat", "(", "[", "df", ",", "df_chunk", "]", ")", "\n", "\n", "", "print", "(", "\"\\nComplete\"", ")", "\n", "return", "df", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.data_frame.load_raw_process_df": [[69, 92], ["print", "print", "print", "pandas.read_csv", "print"], "function", ["None"], ["", "def", "load_raw_process_df", "(", "path", ":", "str", ")", "->", "DataFrame", ":", "\n", "    ", "\"\"\"\n    Load cybersecurity process start and end data as dataframe.  Note that there is not yet\n    any filtering to process starts or human users.\n\n    Arguments:\n        path: Path to the uncompressed version of proc.txt.gz located at https://csr.lanl.gov/data/cyber1.\n\n    Returns:\n        dataframe with dimensionality (N,E)\n        where N is the number of process starts\n        and E is the number of events, described in the form\n        \"time,user@domain,computer,process name,start or end\u201d\n\n        For more information, see https://csr.lanl.gov/data/cyber1/ proc.txt.gz\n    \"\"\"", "\n", "print", "(", "\"--------------------\"", ")", "\n", "print", "(", "\"Loading \"", "+", "path", ")", "\n", "print", "(", "\"--------------------\"", ")", "\n", "column_names", "=", "[", "\"time\"", ",", "\"user@domain\"", ",", "\"computer\"", ",", "\"process name\"", ",", "\"Start or End\"", "]", "\n", "data", "=", "pd", ".", "read_csv", "(", "path", ",", "delimiter", "=", "\",\"", ",", "names", "=", "column_names", ")", "\n", "print", "(", "\"Complete\"", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.data_frame.load_human_process_start_df": [[94, 112], ["pandas.read_csv"], "function", ["None"], ["", "def", "load_human_process_start_df", "(", "path", ")", ":", "\n", "    ", "\"\"\"\n    Load the human process start dataframe, which was effectively created by\n    running load_raw_process_df() on  the uncompressed version of proc.txt.gz\n    located at https://csr.lanl.gov/data/cyber1, and then running extract_human_process_starts_from_df() on\n    the result -- i.e.\n\n        PATH_BIG =  \"/cluster/tufts/hugheslab/mwojno01/data/proc_unzipped\"  # 15 GB (426,045,096 lines)\n        df_raw = load_raw_process_df(PATH_BIG)\n        df = extract_human_process_starts_from_df(df_raw)\n\n    In actuality, due to memory constraints, this dataframe was created by running\n    load_preprocessed_df_in_chunks().  [The above codeblock might work (haven't tried it), but if not, one\n    can always construct a smaller file via e.g. head -1000 /cluster/tufts/hugheslab/mwojno01/data/proc_unzipped > new_filename\n    and then run the same code on this path.]\n    \"\"\"", "\n", "return", "pd", ".", "read_csv", "(", "\n", "path", ",", "delimiter", "=", "\",\"", ",", "usecols", "=", "[", "\"time\"", ",", "\"user@domain\"", ",", "\"computer\"", ",", "\"process name\"", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.featurize.construct_labels": [[16, 45], ["categorical_from_binary.datasets.cyber.util.compute_num_of_unique_processes_from_dict_of_minimal_process_id_by_process_id", "categorical_from_binary.util.one_hot_encoded_array_from_categorical_indices", "int"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.util.compute_num_of_unique_processes_from_dict_of_minimal_process_id_by_process_id", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.util.one_hot_encoded_array_from_categorical_indices"], ["def", "construct_labels", "(", "\n", "df", ":", "DataFrame", ",", "\n", "minimal_process_id_by_process_id", ":", "bidict", ",", "\n", "window_size", ":", "int", ",", "\n", "sparse_representation", ":", "bool", "=", "True", ",", "\n", ")", "->", "NumpyArray2D", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        df: DataFrame, the return value of `load_human_process_start_df`\n        minimal_process_id_by_process_id: the return value of construct_minimal_process_id_by_process_id()\n            Among other things, contains information about the number of processes represented\n        window_size: Size of lookback window of most recently launched processes that are used in the featurization\n    \"\"\"", "\n", "label_ints_original", "=", "[", "int", "(", "x", "[", "1", ":", "]", ")", "for", "x", "in", "df", "[", "\"process name\"", "]", "]", "\n", "label_ints_minimal", "=", "[", "\n", "minimal_process_id_by_process_id", "[", "x", "]", "for", "x", "in", "label_ints_original", "\n", "]", "\n", "number_of_unique_processes", "=", "(", "\n", "compute_num_of_unique_processes_from_dict_of_minimal_process_id_by_process_id", "(", "\n", "minimal_process_id_by_process_id", "\n", ")", "\n", ")", "\n", "# To compute `number_of_unique_processes`, we must add one to the maximum value to account for zero-indexing", "\n", "labels_minimal_one_hot", "=", "one_hot_encoded_array_from_categorical_indices", "(", "\n", "label_ints_minimal", ",", "\n", "number_of_unique_processes", ",", "\n", "sparse_representation", ",", "\n", ")", "\n", "return", "labels_minimal_one_hot", "[", "window_size", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.featurize.construct_features": [[47, 105], ["list", "categorical_from_binary.datasets.cyber.util.compute_num_of_unique_processes_from_dict_of_minimal_process_id_by_process_id", "range", "int", "len", "scipy.sparse.lil_matrix", "numpy.zeros", "numpy.exp", "zip", "categorical_from_binary.data_generation.util.prepend_features_with_column_of_all_ones_for_intercept"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.util.compute_num_of_unique_processes_from_dict_of_minimal_process_id_by_process_id", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.util.prepend_features_with_column_of_all_ones_for_intercept"], ["", "def", "construct_features", "(", "\n", "df", ":", "DataFrame", ",", "\n", "minimal_process_id_by_process_id", ":", "bidict", ",", "\n", "window_size", ":", "int", ",", "\n", "temperature", ":", "float", ",", "\n", "include_intercept", ":", "bool", ",", "\n", "sparse_representation", ":", "bool", "=", "True", ",", "\n", ")", "->", "NumpyArray2D", ":", "\n", "    ", "\"\"\"\n    Take a lookback window of `window_size` processes, and then featurize as\n    exp(-timedelta/temperature) seconds.  This featurization makes sense e.g. because there can be simultaneous\n    launches, so it is not possible to impose an order.  It also adds some robustness to minor permutations in\n    process launches.\n\n    The window_size could be justified by plotting the distribution on the number of simulatneous\n    process launches, and saying that the window size is the whatever-th percentile of that distribution\n\n    Arguments:\n        df: DataFrame, the return value of `load_human_process_start_df`\n        minimal_process_id_by_process_id: the return value of construct_minimal_process_id_by_process_id()\n            Among other things, contains information about the number of processes represented\n        window_size: Size of lookback window of most recently launched processes that are used in the featurization\n        temperature: Controls how much the strength of influence of previously launched features decays over time.\n        include_intercept:\n            If True, the 0-th row of the beta matrix will correspond to the intercept, and the 0-th column\n            of the features matrix will be a column of all 1's.  If False, neither condition will be true.\n    \"\"\"", "\n", "label_ints_original", "=", "[", "int", "(", "x", "[", "1", ":", "]", ")", "for", "x", "in", "df", "[", "\"process name\"", "]", "]", "\n", "label_ints_minimal", "=", "[", "\n", "minimal_process_id_by_process_id", "[", "x", "]", "for", "x", "in", "label_ints_original", "\n", "]", "\n", "times", "=", "list", "(", "df", "[", "\"time\"", "]", ".", "values", ")", "\n", "N", "=", "len", "(", "label_ints_minimal", ")", "-", "window_size", "\n", "K", "=", "compute_num_of_unique_processes_from_dict_of_minimal_process_id_by_process_id", "(", "\n", "minimal_process_id_by_process_id", "\n", ")", "\n", "if", "sparse_representation", ":", "\n", "        ", "features_without_ones_column", "=", "lil_matrix", "(", "(", "N", ",", "K", ")", ")", "\n", "", "else", ":", "\n", "        ", "features_without_ones_column", "=", "np", ".", "zeros", "(", "(", "N", ",", "K", ")", ")", "\n", "", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "        ", "window_start", ",", "curr_idx", "=", "i", ",", "i", "+", "window_size", "\n", "reference_time", "=", "times", "[", "curr_idx", "]", "\n", "lookback_labels", "=", "label_ints_minimal", "[", "window_start", ":", "curr_idx", "]", "\n", "lookback_time_deltas", "=", "reference_time", "-", "times", "[", "window_start", ":", "curr_idx", "]", "\n", "lookback_feature_values", "=", "np", ".", "exp", "(", "-", "lookback_time_deltas", "/", "temperature", ")", "\n", "# Note: if the same process was launched multiple times in the lookback window,", "\n", "# this code will use the minimum time.", "\n", "for", "label", ",", "feature_value", "in", "zip", "(", "lookback_labels", ",", "lookback_feature_values", ")", ":", "\n", "            ", "features_without_ones_column", "[", "i", ",", "label", "]", "=", "feature_value", "\n", "\n", "", "", "if", "include_intercept", ":", "\n", "        ", "features", "=", "prepend_features_with_column_of_all_ones_for_intercept", "(", "\n", "features_without_ones_column", "\n", ")", "\n", "", "else", ":", "\n", "        ", "features", "=", "features_without_ones_column", "\n", "", "return", "features", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.util.construct_minimal_process_id_by_process_id": [[12, 36], ["set", "numpy.sort", "bidict.bidict", "enumerate", "int"], "function", ["None"], ["number_of_possible_categories", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "sparse_representation", ":", "bool", "=", "False", ",", "\n", ")", "->", "np", ".", "array", ":", "\n", "    ", "\"\"\"\n    Takes a one-dim numpy array of integers and expands it to a two-dim numpy array\n    that is one-hot encoded\n    \"\"\"", "\n", "\n", "# TODO: This function currently assumes that we should assign a column for every", "\n", "# integer within 0 and the maximal categorical index.   This should be related", "\n", "\n", "if", "number_of_possible_categories", "is", "None", ":", "\n", "# If `number_of_possible_categories` is not provided, we will infer it to be the maximum value", "\n", "# plus one, due to zero-indexing, but this potentially dangerous to do under the hood.  Is 0 a", "\n", "# legitimate value? If the max value is far higher than the number of possible values, do we really", "\n", "# want to represent everything between zero and the max?", "\n", "        ", "number_of_possible_categories", "=", "max", "(", "categorical_indices", ")", "+", "1", "\n", "warnings", ".", "warn", "(", "\n", "f\"Inferring the number of possible values to be {number_of_possible_categories}. \"", "\n", "f\"Does that seem corect?\"", "\n", ")", "\n", "\n", "", "N", "=", "len", "(", "categorical_indices", ")", "\n", "K", "=", "number_of_possible_categories", "\n", "if", "sparse_representation", ":", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.util.compute_num_of_unique_processes_from_dict_of_minimal_process_id_by_process_id": [[38, 43], ["max", "minimal_process_id_by_process_id.values"], "function", ["None"], ["", "else", ":", "\n", "        ", "one_hot_matrix", "=", "np", ".", "zeros", "(", "(", "N", ",", "K", ")", ",", "dtype", "=", "int", ")", "\n", "\n", "", "one_hot_matrix", "[", "(", "np", ".", "arange", "(", "N", ")", ",", "categorical_indices", ")", "]", "=", "1", "\n", "return", "one_hot_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.util.compute_sorted_sample_sizes_for_users": [[45, 74], ["[].agg", "[].agg.sort_values", "df.groupby"], "function", ["None"], ["", "def", "construct_standardized_design_matrix", "(", "design_matrix", ":", "np", ".", "array", ")", ":", "\n", "    ", "return", "(", "design_matrix", "-", "np", ".", "mean", "(", "design_matrix", ",", "axis", "=", "0", ")", ")", "/", "np", ".", "std", "(", "\n", "design_matrix", ",", "axis", "=", "0", "\n", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.generic.load.construct_data_split": [[37, 57], ["load_dataset", "split_dataset"], "function", ["None"], ["sorted_sample_sizes_for_users", "=", "compute_sorted_sample_sizes_for_users", "(", "df_all", ")", "\n", "user_domains_in_subset", "=", "sorted_sample_sizes_for_users", ".", "index", "[", "\n", "subset_initial_user_idx_when_sorting_most_to_fewest_events", ":", "subset_initial_user_idx_when_sorting_most_to_fewest_events", "\n", "+", "subset_number_of_users", "\n", "]", "\n", "df_subset", "=", "keep_df_rows_by_column_values", "(", "\n", "df_all", ",", "col", "=", "\"user@domain\"", ",", "values", "=", "user_domains_in_subset", "\n", ")", "\n", "minimal_process_id_by_process_id", "=", "construct_minimal_process_id_by_process_id", "(", "\n", "df_subset", "\n", ")", "\n", "# `K` is the number of unique processes", "\n", "K", "=", "compute_num_of_unique_processes_from_dict_of_minimal_process_id_by_process_id", "(", "\n", "minimal_process_id_by_process_id", "\n", ")", "\n", "print", "(", "\n", "f\"The total number of distinct processes started in this subset of users is {K}.\"", "\n", ")", "\n", "\n", "### Get data for one user", "\n", "sorted_sample_sizes_for_users", "=", "compute_sorted_sample_sizes_for_users", "(", "df_all", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass.load.construct_glass_identification_data_split": [[19, 56], ["load.construct_glass_identification_data_split_and_return_individual_components", "categorical_from_binary.data_generation.splitter.SplitDataset"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass.load.construct_glass_identification_data_split_and_return_individual_components"], ["def", "construct_process_start_features_and_labels_for_one_cyber_user", "(", "\n", "path_to_human_process_start_data", ":", "str", ",", "\n", "subset_initial_user_idx_when_sorting_most_to_fewest_events", ":", "int", ",", "\n", "subset_number_of_users", ":", "int", ",", "\n", "user_idx_relative_to_subset", ":", "int", ",", "\n", "window_size", ":", "int", ",", "\n", "temperature", ":", "float", ",", "\n", "include_intercept", ":", "bool", ",", "\n", ")", "->", "Tuple", "[", "NumpyArray2D", ",", "NumpyArray2D", ",", "str", "]", ":", "\n", "    ", "\"\"\"\n    The number of processes/categories represented (i.e. the number of columns of the one-hot-encoded `labels`)\n    will be given by the number of unique categories launched across a subset of users, which is determined\n    by grabbing data from users indexed from ` subset_initial_user_idx_when_sorting_most_to_fewest_events`\n    to that value plus `subset_number_of_users`.\n    \"\"\"", "\n", "df_all", "=", "load_human_process_start_df", "(", "path_to_human_process_start_data", ")", "\n", "\n", "# get a subset of all user domains, from which we determine the number of categories to use for processing.", "\n", "sorted_sample_sizes_for_users", "=", "compute_sorted_sample_sizes_for_users", "(", "df_all", ")", "\n", "user_domains_in_subset", "=", "sorted_sample_sizes_for_users", ".", "index", "[", "\n", "subset_initial_user_idx_when_sorting_most_to_fewest_events", ":", "subset_initial_user_idx_when_sorting_most_to_fewest_events", "\n", "+", "subset_number_of_users", "\n", "]", "\n", "df_subset", "=", "keep_df_rows_by_column_values", "(", "\n", "df_all", ",", "col", "=", "\"user@domain\"", ",", "values", "=", "user_domains_in_subset", "\n", ")", "\n", "minimal_process_id_by_process_id", "=", "construct_minimal_process_id_by_process_id", "(", "\n", "df_subset", "\n", ")", "\n", "# `K` is the number of unique processes", "\n", "K", "=", "compute_num_of_unique_processes_from_dict_of_minimal_process_id_by_process_id", "(", "\n", "minimal_process_id_by_process_id", "\n", ")", "\n", "print", "(", "\n", "f\"The total number of distinct processes started in this subset of users is {K}.\"", "\n", ")", "\n", "\n", "### Get data for one user", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass.load.construct_glass_identification_data_split_and_return_individual_components": [[58, 108], ["data[].astype", "numpy.zeros().astype", "ORIGINAL_LABELS_BY_NEW_LABELS.items", "numpy.insert", "int", "random.seed", "random.sample", "list", "len", "categorical_from_binary.util.one_hot_encoded_array_from_categorical_indices", "categorical_from_binary.util.one_hot_encoded_array_from_categorical_indices", "numpy.shape", "categorical_from_binary.util.construct_standardized_design_matrix", "range", "set().difference", "numpy.zeros", "set", "numpy.where", "set", "range"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.util.one_hot_encoded_array_from_categorical_indices", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.util.one_hot_encoded_array_from_categorical_indices", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.util.construct_standardized_design_matrix"], ["user_domain", "=", "user_domains_in_subset", "[", "user_idx_relative_to_subset", "]", "\n", "print", "(", "f\"The user domain whose data is being grabbed is {user_domain}.\"", ")", "\n", "df", "=", "keep_df_rows_by_column_values", "(", "df_all", ",", "col", "=", "\"user@domain\"", ",", "values", "=", "user_domain", ")", "\n", "labels", "=", "construct_labels", "(", "df", ",", "minimal_process_id_by_process_id", ",", "window_size", ")", "\n", "features", "=", "construct_features", "(", "\n", "df", ",", "\n", "minimal_process_id_by_process_id", ",", "\n", "window_size", ",", "\n", "temperature", ",", "\n", "include_intercept", "=", "include_intercept", ",", "\n", ")", "\n", "return", "features", ",", "labels", ",", "user_domain", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass.load.load_glass_identification_data": [[110, 113], ["numpy.genfromtxt"], "function", ["None"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.frogs.load.load_frog_data": [[19, 28], ["pandas.read_csv"], "function", ["None"], ["def", "construct_process_start_features_and_labels_for_one_cyber_user", "(", "\n", "path_to_human_process_start_data", ":", "str", ",", "\n", "subset_initial_user_idx_when_sorting_most_to_fewest_events", ":", "int", ",", "\n", "subset_number_of_users", ":", "int", ",", "\n", "user_idx_relative_to_subset", ":", "int", ",", "\n", "window_size", ":", "int", ",", "\n", "temperature", ":", "float", ",", "\n", "include_intercept", ":", "bool", ",", "\n", ")", "->", "Tuple", "[", "NumpyArray2D", ",", "NumpyArray2D", ",", "str", "]", ":", "\n", "    "]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.frogs.load.construct_frog_data_split": [[35, 70], ["load.construct_frog_data_split_and_return_individual_components", "categorical_from_binary.data_generation.splitter.SplitDataset"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.frogs.load.construct_frog_data_split_and_return_individual_components"], ["\n", "# get a subset of all user domains, from which we determine the number of categories to use for processing.", "\n", "sorted_sample_sizes_for_users", "=", "compute_sorted_sample_sizes_for_users", "(", "df_all", ")", "\n", "user_domains_in_subset", "=", "sorted_sample_sizes_for_users", ".", "index", "[", "\n", "subset_initial_user_idx_when_sorting_most_to_fewest_events", ":", "subset_initial_user_idx_when_sorting_most_to_fewest_events", "\n", "+", "subset_number_of_users", "\n", "]", "\n", "df_subset", "=", "keep_df_rows_by_column_values", "(", "\n", "df_all", ",", "col", "=", "\"user@domain\"", ",", "values", "=", "user_domains_in_subset", "\n", ")", "\n", "minimal_process_id_by_process_id", "=", "construct_minimal_process_id_by_process_id", "(", "\n", "df_subset", "\n", ")", "\n", "# `K` is the number of unique processes", "\n", "K", "=", "compute_num_of_unique_processes_from_dict_of_minimal_process_id_by_process_id", "(", "\n", "minimal_process_id_by_process_id", "\n", ")", "\n", "print", "(", "\n", "f\"The total number of distinct processes started in this subset of users is {K}.\"", "\n", ")", "\n", "\n", "### Get data for one user", "\n", "sorted_sample_sizes_for_users", "=", "compute_sorted_sample_sizes_for_users", "(", "df_all", ")", "\n", "user_domain", "=", "user_domains_in_subset", "[", "user_idx_relative_to_subset", "]", "\n", "print", "(", "f\"The user domain whose data is being grabbed is {user_domain}.\"", ")", "\n", "df", "=", "keep_df_rows_by_column_values", "(", "df_all", ",", "col", "=", "\"user@domain\"", ",", "values", "=", "user_domain", ")", "\n", "labels", "=", "construct_labels", "(", "df", ",", "minimal_process_id_by_process_id", ",", "window_size", ")", "\n", "features", "=", "construct_features", "(", "\n", "df", ",", "\n", "minimal_process_id_by_process_id", ",", "\n", "window_size", ",", "\n", "temperature", ",", "\n", "include_intercept", "=", "include_intercept", ",", "\n", ")", "\n", "return", "features", ",", "labels", ",", "user_domain", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.frogs.load.construct_frog_data_split_and_return_individual_components": [[72, 122], ["list", "numpy.zeros().astype", "range", "data.iloc[].to_numpy", "numpy.insert", "int", "random.seed", "random.sample", "list", "len", "categorical_from_binary.util.one_hot_encoded_array_from_categorical_indices", "categorical_from_binary.util.one_hot_encoded_array_from_categorical_indices", "numpy.shape", "set", "list.index", "categorical_from_binary.util.construct_standardized_design_matrix", "range", "set().difference", "numpy.zeros", "set", "set", "range"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.util.one_hot_encoded_array_from_categorical_indices", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.util.one_hot_encoded_array_from_categorical_indices", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.util.construct_standardized_design_matrix"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.detergent.load.load_detergent_data": [[19, 28], ["pandas.read_csv"], "function", ["None"], ["def", "construct_process_start_features_and_labels_for_one_cyber_user", "(", "\n", "path_to_human_process_start_data", ":", "str", ",", "\n", "subset_initial_user_idx_when_sorting_most_to_fewest_events", ":", "int", ",", "\n", "subset_number_of_users", ":", "int", ",", "\n", "user_idx_relative_to_subset", ":", "int", ",", "\n", "window_size", ":", "int", ",", "\n", "temperature", ":", "float", ",", "\n", "include_intercept", ":", "bool", ",", "\n", ")", "->", "Tuple", "[", "NumpyArray2D", ",", "NumpyArray2D", ",", "str", "]", ":", "\n", "    "]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.detergent.load.construct_detergent_data_split": [[35, 70], ["load.construct_detergent_data_split_and_return_individual_components", "categorical_from_binary.data_generation.splitter.SplitDataset"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.detergent.load.construct_detergent_data_split_and_return_individual_components"], ["\n", "# get a subset of all user domains, from which we determine the number of categories to use for processing.", "\n", "sorted_sample_sizes_for_users", "=", "compute_sorted_sample_sizes_for_users", "(", "df_all", ")", "\n", "user_domains_in_subset", "=", "sorted_sample_sizes_for_users", ".", "index", "[", "\n", "subset_initial_user_idx_when_sorting_most_to_fewest_events", ":", "subset_initial_user_idx_when_sorting_most_to_fewest_events", "\n", "+", "subset_number_of_users", "\n", "]", "\n", "df_subset", "=", "keep_df_rows_by_column_values", "(", "\n", "df_all", ",", "col", "=", "\"user@domain\"", ",", "values", "=", "user_domains_in_subset", "\n", ")", "\n", "minimal_process_id_by_process_id", "=", "construct_minimal_process_id_by_process_id", "(", "\n", "df_subset", "\n", ")", "\n", "# `K` is the number of unique processes", "\n", "K", "=", "compute_num_of_unique_processes_from_dict_of_minimal_process_id_by_process_id", "(", "\n", "minimal_process_id_by_process_id", "\n", ")", "\n", "print", "(", "\n", "f\"The total number of distinct processes started in this subset of users is {K}.\"", "\n", ")", "\n", "\n", "### Get data for one user", "\n", "sorted_sample_sizes_for_users", "=", "compute_sorted_sample_sizes_for_users", "(", "df_all", ")", "\n", "user_domain", "=", "user_domains_in_subset", "[", "user_idx_relative_to_subset", "]", "\n", "print", "(", "f\"The user domain whose data is being grabbed is {user_domain}.\"", ")", "\n", "df", "=", "keep_df_rows_by_column_values", "(", "df_all", ",", "col", "=", "\"user@domain\"", ",", "values", "=", "user_domain", ")", "\n", "labels", "=", "construct_labels", "(", "df", ",", "minimal_process_id_by_process_id", ",", "window_size", ")", "\n", "features", "=", "construct_features", "(", "\n", "df", ",", "\n", "minimal_process_id_by_process_id", ",", "\n", "window_size", ",", "\n", "temperature", ",", "\n", "include_intercept", "=", "include_intercept", ",", "\n", ")", "\n", "return", "features", ",", "labels", ",", "user_domain", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.detergent.load.construct_detergent_data_split_and_return_individual_components": [[72, 122], ["list", "numpy.zeros().astype", "range", "data.iloc[].to_numpy", "numpy.insert", "int", "random.seed", "random.sample", "list", "len", "categorical_from_binary.util.one_hot_encoded_array_from_categorical_indices", "categorical_from_binary.util.one_hot_encoded_array_from_categorical_indices", "numpy.shape", "set", "list.index", "categorical_from_binary.util.construct_standardized_design_matrix", "range", "set().difference", "numpy.zeros", "set", "set", "range"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.util.one_hot_encoded_array_from_categorical_indices", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.util.one_hot_encoded_array_from_categorical_indices", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.util.construct_standardized_design_matrix"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hmc.core._get_n_free_categories": [[56, 68], ["None"], "function", ["None"], ["\n", "", "posterior_probs_in_neighborhood", "=", "np", ".", "zeros", "(", "(", "n_covariates", ",", "n_categories", ")", ")", "\n", "for", "p", "in", "range", "(", "n_covariates", ")", ":", "\n", "        ", "for", "k", "in", "range", "(", "n_categories", ")", ":", "\n", "            ", "mean", ",", "std", "=", "beta_mean", "[", "p", ",", "k", "]", ",", "beta_stds", "[", "p", ",", "k", "]", "\n", "epsilon", "=", "neighborhood_radius_in_units_of_std_devs", "*", "std", "\n", "posterior_probs_in_neighborhood", "[", "p", ",", "k", "]", "=", "norm", "(", "mean", ",", "std", ")", ".", "cdf", "(", "epsilon", ")", "-", "norm", "(", "\n", "mean", ",", "std", "\n", ")", ".", "cdf", "(", "-", "epsilon", ")", "\n", "\n", "", "", "if", "covariate_dict", "is", "not", "None", ":", "\n", "        ", "index", "=", "sorted_covariate_names_from_covariate_dict", "(", "covariate_dict", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hmc.core.create_categorical_model": [[70, 172], ["core._get_n_free_categories", "numpyro.sample", "numpyro.sample", "numpyro.sample", "numpyro.sample", "jax.dot", "NotImplementedError", "numpy.shape", "numpy.ones", "numpy.shape", "numpyro.Normal().expand", "jax.append", "numpyro.sample", "numpyro.sample", "numpyro.sample", "numpyro.sample", "numpy.append", "jax.zeros", "numpyro.Bernoulli().expand", "numpyro.sample", "numpyro.sample", "numpyro.sample", "numpyro.sample", "numpyro.sample", "numpyro.sample", "numpyro.sample", "numpyro.sample", "numpy.ones", "numpyro.Normal", "numpyro.Bernoulli().expand", "numpyro.Categorical().expand", "numpyro.Bernoulli", "jax.norm.cdf", "jax.norm.cdf", "jax.norm.cdf", "jax.sum", "y_one_hot_NK[].argmax", "numpyro.Bernoulli", "numpyro.Categorical", "jax.norm.cdf", "jax.logistic.cdf", "jax.logistic.cdf", "jax.logistic.cdf", "jax.logistic.cdf", "jax.exp"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hmc.core._get_n_free_categories"], ["\n", "", "if", "label_dict", "is", "not", "None", ":", "\n", "        ", "columns", "=", "list", "(", "label_dict", ".", "keys", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "columns", "=", "None", "\n", "\n", "", "return", "pd", ".", "DataFrame", "(", "\n", "data", "=", "posterior_probs_in_neighborhood", ",", "\n", "index", "=", "index", ",", "\n", "columns", "=", "columns", ",", "\n", ")", "\n", "\n", "\n", "", "def", "compute_feature_inclusion_data_frame_using_scaled_neighborhood_method", "(", "\n", "beta_mean", ":", "NumpyArray2D", ",", "\n", "beta_stds", ":", "Union", "[", "NumpyArray1D", ",", "NumpyArray2D", "]", ",", "\n", "neighborhood_probability_threshold_for_exclusion", ":", "float", ",", "\n", "neighborhood_radius_in_units_of_std_devs", ":", "float", ",", "\n", "covariate_dict", ":", "Optional", "[", "Dict", "[", "str", ",", "VariableInfo", "]", "]", "=", "None", ",", "\n", "label_dict", ":", "Optional", "[", "Dict", "[", "str", ",", "VariableInfo", "]", "]", "=", "None", ",", "\n", ")", "->", "DataFrame", ":", "\n", "    ", "\"\"\"\n    If `r` refers to `neighborhood_radius_in_units_of_std_devs`, we first compute the  posterior probability of 0 being within\n    some epsilon-ball around zero,\n        P({beta_j in scaled neighborhood around 0}) := P_{posterior on beta_j}( - epsilon  <= 0 <= epsilon)\n    where epsilon =  r * std(beta_j)\n\n    We then exclude from the model any predictor beta_j such that\n        P({beta_j in scaled neighborhood around 0}) >= neighborhood_probability_threshold_for_exclusion.\n\n    Note that the variational posterior distribution on betas is normal.\n\n    Reference:\n        Li, Q., & Lin, N. (2010). The Bayesian elastic net. Bayesian analysis, 5(1), 151-170,\n        Sections 2.5 and 3.\n\n    Arguments:\n        beta_mean: has shape (M,K), where M is number of covariates and K is the\n            number of categories\n        beta_stds: has shape (M,) where M is the number of covariates\n            OR has shape (M,K), where M is number of covariates and K is the\n            number of categories\n        neighborhood_probability_threshold_for_exclusion: A predictor is excluded if the\n            posterior probability of being in a (-std beta_j, +std beta_j)\n            exceeds this probability neighborhood_probability_threshold_for_exclusion and is retained otherwise.\n    \"\"\"", "\n", "scaled_neighborhood_probs", "=", "(", "\n", "compute_posterior_prob_of_scaled_neighborhood_around_zero", "(", "\n", "beta_mean", ",", "\n", "beta_stds", ",", "\n", "neighborhood_radius_in_units_of_std_devs", ",", "\n", "covariate_dict", ",", "\n", "label_dict", ",", "\n", ")", "\n", ")", "\n", "inclusion_matrix_as_boolean", "=", "(", "\n", "scaled_neighborhood_probs", "<", "neighborhood_probability_threshold_for_exclusion", "\n", ")", "\n", "return", "(", "inclusion_matrix_as_boolean", ")", ".", "astype", "(", "int", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hmc.core.run_nuts_on_categorical_data": [[175, 260], ["dict", "scipy.sparse.isspmatrix", "scipy.sparse.isspmatrix", "enumerate", "numpy.array", "numpy.array", "jax.random.PRNGKey", "jax.random.PRNGKey", "jax.random.PRNGKey", "jax.random.split", "jax.random.split", "jax.random.split", "core._get_n_free_categories", "numpyro.infer.NUTS", "numpyro.infer.NUTS", "numpyro.infer.NUTS", "numpyro.infer.NUTS", "numpyro.infer.MCMC", "numpyro.infer.MCMC", "numpyro.infer.MCMC", "numpyro.infer.MCMC", "numpyro.infer.MCMC.run", "np.ones.todense", "np.array.todense", "numpy.ones", "numpyro.infer.MCMC.get_samples", "numpy.shape", "numpy.shape", "numpyro.infer.init_to_value", "jax.zeros"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hmc.core._get_n_free_categories"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hmc.generate.generate_categorical_data_with_covariates_using_multilogit_link": [[36, 79], ["numpy.random.RandomState", "np.random.RandomState.randn", "numpy.hstack", "numpy.hstack", "generate.generate_categorical_data_with_covariates_using_multilogit_link.calc_category_probs_NK"], "function", ["None"], ["def", "generate_categorical_data_with_covariates_using_multilogit_link", "(", "\n", "num_samples", ":", "int", ",", "\n", "num_categories", ":", "int", ",", "\n", "num_covariates_not_counting_bias", ":", "int", ",", "\n", "random_seed", ":", "int", "=", "0", ",", "\n", ")", "->", "Tuple", "[", "np", ".", "array", ",", "np", ".", "array", ",", "np", ".", "array", ",", "np", ".", "array", "]", ":", "\n", "    ", "\"\"\"\n    Generate categorical data with covariates, using a multilogit (a.k.a softmax) link\n    \"\"\"", "\n", "# Using MCH's naming convention here, which is to give the dimensionality of each array", "\n", "# after the last underscore", "\n", "\n", "N", "=", "num_samples", "\n", "K", "=", "num_categories", "\n", "M", "=", "num_covariates_not_counting_bias", "+", "1", "\n", "\n", "# Note: a numpy RandomState instance has methods for sampling from many distributions!", "\n", "# Reference: https://numpy.org/doc/1.16/reference/generated/numpy.random.RandomState.html", "\n", "# This seems like a stripped-down version of the distributions in scipy.stats (which seem", "\n", "# to provide more distributions, but also more methods, like mean, entropy, etc.).  However,", "\n", "# the parametrization in numpy seems more intuitive.", "\n", "prng", "=", "np", ".", "random", ".", "RandomState", "(", "random_seed", ")", "\n", "\n", "true_beta_KM", "=", "prng", ".", "randn", "(", "K", ",", "M", ")", "\n", "x_train_NM", "=", "np", ".", "hstack", "(", "[", "prng", ".", "randn", "(", "N", ",", "M", "-", "1", ")", ",", "np", ".", "ones", "(", "(", "N", ",", "1", ")", ")", "]", ")", "\n", "x_test_NM", "=", "np", ".", "hstack", "(", "[", "prng", ".", "randn", "(", "N", ",", "M", "-", "1", ")", ",", "np", ".", "ones", "(", "(", "N", ",", "1", ")", ")", "]", ")", "\n", "\n", "def", "calc_category_probs_NK", "(", "x_NM", ",", "true_beta_KM", ")", ":", "\n", "        ", "\"\"\"\n        Note: This data generating process using a multi-logit (i.e. softmax) link\n        \"\"\"", "\n", "logp_NK", "=", "np", ".", "dot", "(", "x_NM", ",", "true_beta_KM", ".", "T", ")", "\n", "logp_NK", "-=", "scipy", ".", "special", ".", "logsumexp", "(", "logp_NK", ",", "axis", "=", "1", ",", "keepdims", "=", "1", ")", "\n", "return", "np", ".", "exp", "(", "logp_NK", ")", "\n", "\n", "", "p_train_NK", "=", "calc_category_probs_NK", "(", "x_train_NM", ",", "true_beta_KM", ")", "\n", "y_train_N", "=", "[", "prng", ".", "choice", "(", "np", ".", "arange", "(", "K", ")", ",", "p", "=", "p_train_NK", "[", "n", "]", ")", "for", "n", "in", "range", "(", "N", ")", "]", "\n", "p_test_NK", "=", "calc_category_probs_NK", "(", "x_test_NM", ",", "true_beta_KM", ")", "\n", "y_test_N", "=", "[", "prng", ".", "choice", "(", "np", ".", "arange", "(", "K", ")", ",", "p", "=", "p_test_NK", "[", "n", "]", ")", "for", "n", "in", "range", "(", "N", ")", "]", "\n", "\n", "y_train__one_hot_NK", "=", "one_hot_encoded_array_from_categorical_indices", "(", "y_train_N", ",", "K", ")", "\n", "y_test__one_hot_NK", "=", "one_hot_encoded_array_from_categorical_indices", "(", "y_test_N", ",", "K", ")", "\n", "return", "y_train__one_hot_NK", ",", "y_test__one_hot_NK", ",", "x_train_NM", ",", "x_test_NM", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hmc.generate.generate_intercepts_only_categorical_data": [[81, 107], ["len", "numpy.random.RandomState", "np.random.RandomState.choice", "np.random.RandomState.choice", "categorical_from_binary.util.one_hot_encoded_array_from_categorical_indices", "categorical_from_binary.util.one_hot_encoded_array_from_categorical_indices", "numpy.arange", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.util.one_hot_encoded_array_from_categorical_indices", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.util.one_hot_encoded_array_from_categorical_indices"], ["", "def", "generate_intercepts_only_categorical_data", "(", "\n", "true_category_probs_K", ":", "np", ".", "array", ",", "\n", "num_samples", ":", "int", ",", "\n", "random_seed", ":", "int", "=", "0", ",", "\n", ")", "->", "Tuple", "[", "np", ".", "array", ",", "np", ".", "array", "]", ":", "\n", "    ", "\"\"\"\n    Generate (intercepts-only) categorical data\n    \"\"\"", "\n", "# Using MCH's naming convention here, which is to give the dimensionality of each array", "\n", "# after the last underscore", "\n", "\n", "K", "=", "len", "(", "true_category_probs_K", ")", "\n", "N", "=", "num_samples", "\n", "\n", "# Note: a numpy RandomState instance has methods for sampling from many distributions!", "\n", "# Reference: https://numpy.org/doc/1.16/reference/generated/numpy.random.RandomState.html", "\n", "# This seems like a stripped-down version of the distributions in scipy.stats (which seem", "\n", "# to provide more distributions, but also more methods, like mean, entropy, etc.).  However,", "\n", "# the parametrization in numpy seems more intuitive.", "\n", "prng", "=", "np", ".", "random", ".", "RandomState", "(", "random_seed", ")", "\n", "y_train_N", "=", "prng", ".", "choice", "(", "np", ".", "arange", "(", "K", ")", ",", "p", "=", "true_category_probs_K", ",", "size", "=", "N", ",", "replace", "=", "True", ")", "\n", "y_test_N", "=", "prng", ".", "choice", "(", "np", ".", "arange", "(", "K", ")", ",", "p", "=", "true_category_probs_K", ",", "size", "=", "N", ",", "replace", "=", "True", ")", "\n", "\n", "y_train__one_hot_NK", "=", "one_hot_encoded_array_from_categorical_indices", "(", "y_train_N", ",", "K", ")", "\n", "y_test__one_hot_NK", "=", "one_hot_encoded_array_from_categorical_indices", "(", "y_test_N", ",", "K", ")", "\n", "return", "y_train__one_hot_NK", ",", "y_test__one_hot_NK", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.compare_to_mle.plot_helpers._alter_font_size_and_title_and_labels_for_legend_of_facetgrid": [[38, 56], ["g.get_legend", "matplotlib.pyplot.setp", "matplotlib.pyplot.setp", "g.get_legend.set_title", "zip", "g.get_legend.get_texts", "g.get_legend.get_title", "t.set_text"], "function", ["None"], ["y_col_name", ":", "str", ",", "\n", "x_axis_label", ":", "str", ",", "\n", "y_axis_label", ":", "str", ",", "\n", "title", ":", "str", ",", "\n", "reg_line_label", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "add_y_equals_x_line", "=", "True", ",", "\n", "add_y_equals_0_line", "=", "True", ",", "\n", "lowess", "=", "False", ",", "\n", "ax", "=", "None", ",", "\n", "plot_points_as_density_not_scatter", "=", "True", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        plot_points_as_density_not_scatter:  Defaults to True because a density plot is much\n            easier to grok than a scatter plot when there are lots of points - can more easily tell\n            how unlikely it is to get an outlier value.\n    \"\"\"", "\n", "if", "ax", "is", "None", ":", "\n", "        ", "sns", ".", "set_style", "(", "\"whitegrid\"", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.compare_to_mle.plot_helpers.make_plot_of_performance_results_for_one_context": [[58, 143], ["df.query", "set", "dff.query.round", "dff.query.melt", "seaborn.set", "seaborn.lineplot", "_alter_font_size_and_title_and_labels_for_legend_of_facetgrid.set_title", "_alter_font_size_and_title_and_labels_for_legend_of_facetgrid.set_ylabel", "_alter_font_size_and_title_and_labels_for_legend_of_facetgrid.set_xlabel", "dff.query.query", "dff[].mean_covariate_conditional_entropy_of_true_category_probabilities.mean", "plot_helpers._alter_font_size_and_title_and_labels_for_legend_of_facetgrid", "int", "dff.query.columns.str.endswith", "dff.query.columns.str.startswith"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.compare_to_mle.plot_helpers._alter_font_size_and_title_and_labels_for_legend_of_facetgrid"], ["\n", "", "if", "plot_points_as_density_not_scatter", ":", "\n", "        ", "cmap", "=", "sns", ".", "light_palette", "(", "\"seagreen\"", ",", "as_cmap", "=", "True", ")", "\n", "counts", ",", "xedges", ",", "yedges", ",", "im", "=", "ax", ".", "hist2d", "(", "\n", "df", "[", "x_col_name", "]", ",", "df", "[", "y_col_name", "]", ",", "cmap", "=", "cmap", ",", "cmin", "=", "1", "\n", ")", "\n", "plt", ".", "colorbar", "(", "im", ",", "ax", "=", "ax", ")", "\n", "\n", "", "else", ":", "\n", "        ", "ax", ".", "scatter", "(", "df", "[", "x_col_name", "]", ",", "df", "[", "y_col_name", "]", ",", "color", "=", "\"red\"", ",", "alpha", "=", "0.5", ")", "\n", "\n", "", "if", "add_y_equals_0_line", ":", "\n", "        ", "ax", ".", "hlines", "(", "\n", "y", "=", "0", ",", "\n", "xmin", "=", "min", "(", "df", "[", "x_col_name", "]", ")", ",", "\n", "xmax", "=", "max", "(", "df", "[", "x_col_name", "]", ")", ",", "\n", "colors", "=", "\"k\"", ",", "\n", "linestyles", "=", "\"--\"", ",", "\n", ")", "\n", "\n", "", "sns", ".", "regplot", "(", "\n", "x", "=", "x_col_name", ",", "\n", "y", "=", "y_col_name", ",", "\n", "data", "=", "df", ",", "\n", "fit_reg", "=", "True", ",", "\n", "ci", "=", "None", ",", "\n", "label", "=", "reg_line_label", ",", "\n", "scatter", "=", "False", ",", "\n", "color", "=", "\"black\"", ",", "\n", "lowess", "=", "lowess", ",", "\n", "ax", "=", "ax", ",", "\n", ")", "\n", "if", "add_y_equals_x_line", ":", "\n", "        ", "sns", ".", "regplot", "(", "\n", "x", "=", "x_col_name", ",", "\n", "y", "=", "x_col_name", ",", "\n", "data", "=", "df", ",", "\n", "fit_reg", "=", "True", ",", "\n", "ci", "=", "None", ",", "\n", "label", "=", "\"y=x\"", ",", "\n", "scatter", "=", "False", ",", "\n", "color", "=", "\"black\"", ",", "\n", "ax", "=", "ax", ",", "\n", ")", "\n", "", "ax", ".", "yaxis", ".", "set_tick_params", "(", "labelleft", "=", "True", ")", "\n", "ax", ".", "set", "(", "ylabel", "=", "y_axis_label", ",", "xlabel", "=", "x_axis_label", ")", "\n", "ax", ".", "set_title", "(", "title", ")", "\n", "return", "ax", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.compare_to_mle.plot_helpers.plot_performance_results_for_many_data_contexts_in_succession": [[145, 198], ["list", "list", "list", "set", "set", "set", "print", "plot_helpers.make_plot_of_performance_results_for_one_context", "matplotlib.pyplot.tight_layout", "matplotlib.pyplot.close", "os.path.join", "categorical_from_binary.io.ensure_dir", "os.path.join", "matplotlib.pyplot.savefig", "matplotlib.pyplot.show"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.compare_to_mle.plot_helpers.make_plot_of_performance_results_for_one_context", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.io.ensure_dir"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.compare_to_mle.results_collector.make_df_from_directory_taking_one_file_for_each_seed": [[7, 38], ["glob.glob", "pandas.concat", "int", "seeds_used_so_far.append", "print", "pandas.read_csv", "df_list.append", "[].split", "filename.split", "pd.read_csv.columns.str.contains"], "function", ["None"], ["def", "make_df_from_directory_taking_one_file_for_each_seed", "(", "\n", "results_dir", ":", "str", ",", "\n", "prefix_for_filenames_of_interest", ":", "str", "=", "\"sim_results_CAVI_vs_MLE_\"", ",", "\n", "verbose", ":", "bool", "=", "False", ",", "\n", ")", "->", "DataFrame", ":", "\n", "    ", "\"\"\"\n    Read separate files from disk and concatenate into a single dataframe.\n    Each file from disk corresponds to results from a different seed, but contains\n    results from many data contexts (K,M,N,sigma_high).\n\n    The returned concatentated DataFrame has one row per seed x data context.\n\n    The code assumes the filenames contain the string \"seed={seed}_\" in there somewhere.\n    We only take one file from each seed, since sometimes on the cluster I launch multiple attempts\n    simultaneously on different partitions (hugheslab, batch, ccpu, etc.), so there can be files\n    with redundant information.\n    \"\"\"", "\n", "df_list", "=", "[", "]", "\n", "seeds_used_so_far", "=", "[", "]", "\n", "for", "filename", "in", "glob", ".", "glob", "(", "f\"{results_dir}/{prefix_for_filenames_of_interest}*\"", ")", ":", "\n", "        ", "if", "verbose", ":", "\n", "            ", "print", "(", "f\"Now scanning {filename}\"", ")", "\n", "", "seed", "=", "int", "(", "filename", ".", "split", "(", "\"seed=\"", ")", "[", "1", "]", ".", "split", "(", "\"_\"", ")", "[", "0", "]", ")", "\n", "if", "seed", "not", "in", "seeds_used_so_far", ":", "\n", "            ", "df_for_one_seed", "=", "pd", ".", "read_csv", "(", "filename", ")", "\n", "df_for_one_seed", "=", "df_for_one_seed", ".", "loc", "[", "\n", ":", ",", "~", "df_for_one_seed", ".", "columns", ".", "str", ".", "contains", "(", "\"Unnamed\"", ")", "\n", "]", "\n", "df_list", ".", "append", "(", "df_for_one_seed", ")", "\n", "", "seeds_used_so_far", ".", "append", "(", "seed", ")", "\n", "", "return", "pd", ".", "concat", "(", "df_list", ",", "ignore_index", "=", "True", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.main.run_comparison_to_mle.run_CAVI_vs_MLE_simulations": [[40, 257], ["categorical_from_binary.data_generation_configs.make_data_generation_configs", "collections.defaultdict", "enumerate", "categorical_from_binary.io.ensure_dir", "time.strftime", "os.path.join", "pandas.DataFrame", "print", "pd.DataFrame.to_csv", "print", "categorical_from_binary.data_generation.bayes_multiclass_reg.ControlCategoryPredictability", "categorical_from_binary.data_generation.bayes_multiclass_reg.generate_multiclass_regression_dataset", "int", "numpy.mean", "pandas.set_option", "print", "numpy.zeros", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_category_probs", "categorical_from_binary.baserate.compute_probs_for_baserate_model", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_category_probs", "categorical_from_binary.ib_cavi.cbm_vs_cbc.bma.compute_weight_on_CBC_from_bayesian_model_averaging", "categorical_from_binary.ib_cavi.cbm_vs_cbc.bma.construct_category_probabilities_from_bayesian_model_averaging", "categorical_from_binary.metrics.compute_metrics", "categorical_from_binary.metrics.compute_metrics", "categorical_from_binary.metrics.compute_metrics", "categorical_from_binary.metrics.compute_metrics", "categorical_from_binary.metrics.append_metrics_dict_for_one_dataset_to_results_dict", "results_dict[].append", "results_dict[].append", "results_dict[].append", "results_dict[].append", "results_dict[].append", "results_dict[].append", "results_dict[].append", "results_dict[].append", "results_dict[].append", "results_dict[].append", "ib_model_as_string.upper", "data_generating_link_as_string.upper", "categorical_from_binary.data_generation.bayes_multiclass_reg.compute_covariate_conditional_entropies_of_true_category_probabilities", "print", "categorical_from_binary.timing.time_me", "print", "categorical_from_binary.timing.time_me", "len", "print", "categorical_from_binary.metrics.append_metrics_dict_for_one_dataset_to_results_dict.items", "print"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.data_generation_configs.make_data_generation_configs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.io.ensure_dir", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_multiclass_regression_dataset", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.baserate.compute_probs_for_baserate_model", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.bma.compute_weight_on_CBC_from_bayesian_model_averaging", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.bma.construct_category_probabilities_from_bayesian_model_averaging", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.compute_metrics", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.compute_metrics", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.compute_metrics", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.compute_metrics", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.append_metrics_dict_for_one_dataset_to_results_dict", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.compute_covariate_conditional_entropies_of_true_category_probabilities", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.timing.time_me", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.timing.time_me"], ["def", "run_CAVI_vs_MLE_simulations", "(", "\n", "seed", ":", "int", ",", "\n", "list_of_n_categories", ":", "List", "[", "int", "]", ",", "\n", "multipliers_on_n_categories_to_create_n_covariates", ":", "List", "[", "int", "]", ",", "\n", "multipliers_on_n_parameters_to_create_n_samples", ":", "List", "[", "int", "]", ",", "\n", "list_of_scales_for_predictive_categories", ":", "List", "[", "float", "]", ",", "\n", "ib_model_as_string", ":", "str", ",", "\n", "data_generating_link_as_string", ":", "str", ",", "\n", "convergence_criterion_drop_in_mean_elbo", ":", "float", ",", "\n", "results_dir", ":", "str", ",", "\n", "test_run", ":", "bool", "=", "False", ",", "\n", "min_allowable_prob", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "verbose", ":", "bool", "=", "True", ",", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Runs simulations.  Generates one dataset per \"data context\" (K,M,N, ssq_high).\n    Computes holdout likelhood for MLE and IB CAVI, as well as using baserate probs and true probs\n    from the data generating process.\n\n    Fixes the seed to some seed (so the whole suite of analyses can be distributed across HPC\n    machines, with each one handling a different seed).\n\n    Arguments:\n        test_run: If True, we override the default results_dir and save things to a temp directory.\n\n    Returns:\n        None. Writes pandas dataframe to disk as csv.\n    \"\"\"", "\n", "# data generation configs that vary across data contexts", "\n", "data_generation_configs", "=", "make_data_generation_configs", "(", "\n", "list_of_n_categories", ",", "\n", "multipliers_on_n_categories_to_create_n_covariates", ",", "\n", "multipliers_on_n_parameters_to_create_n_samples", ",", "\n", "list_of_scales_for_predictive_categories", ",", "\n", "seed", ",", "\n", ")", "\n", "\n", "if", "test_run", ":", "\n", "        ", "results_dir", "=", "\"./tmp\"", "\n", "\n", "# items that are fixed across data contexts", "\n", "", "beta_0", "=", "None", "\n", "include_intercept", "=", "True", "\n", "ib_model", "=", "IB_Model", "[", "ib_model_as_string", ".", "upper", "(", ")", "]", "\n", "link_for_data_generation", "=", "Link", "[", "data_generating_link_as_string", ".", "upper", "(", ")", "]", "\n", "\n", "results_dict", "=", "defaultdict", "(", "list", ")", "\n", "for", "(", "s", ",", "dgc", ")", "in", "enumerate", "(", "data_generation_configs", ")", ":", "\n", "        ", "print", "(", "f\"\\n---Now running simulation with configs {dgc}---\\n\"", ")", "\n", "beta_category_strategy", "=", "ControlCategoryPredictability", "(", "\n", "scale_for_predictive_categories", "=", "dgc", ".", "scale_for_predictive_categories", "\n", ")", "\n", "\n", "###", "\n", "# Construct dataset and data metrics", "\n", "###", "\n", "dataset", "=", "generate_multiclass_regression_dataset", "(", "\n", "n_samples", "=", "dgc", ".", "n_samples", ",", "\n", "n_features", "=", "dgc", ".", "n_features", ",", "\n", "n_categories", "=", "dgc", ".", "n_categories", ",", "\n", "beta_0", "=", "beta_0", ",", "\n", "link", "=", "link_for_data_generation", ",", "\n", "seed", "=", "seed", ",", "\n", "include_intercept", "=", "include_intercept", ",", "\n", "beta_category_strategy", "=", "beta_category_strategy", ",", "\n", ")", "\n", "\n", "# Prep training / test split", "\n", "n_train_samples", "=", "int", "(", "0.8", "*", "dgc", ".", "n_samples", ")", "\n", "covariates_train", "=", "dataset", ".", "features", "[", ":", "n_train_samples", "]", "\n", "labels_train", "=", "dataset", ".", "labels", "[", ":", "n_train_samples", "]", "\n", "covariates_test", "=", "dataset", ".", "features", "[", "n_train_samples", ":", "]", "\n", "labels_test", "=", "dataset", ".", "labels", "[", "n_train_samples", ":", "]", "\n", "\n", "# compute entropy", "\n", "mean_covariate_conditional_entropy_of_true_category_probabilities", "=", "np", ".", "mean", "(", "\n", "(", "\n", "compute_covariate_conditional_entropies_of_true_category_probabilities", "(", "\n", "dataset", ".", "features", ",", "dataset", ".", "beta", ",", "link_for_data_generation", "\n", ")", "\n", ")", "\n", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "\n", "f\"\\nMean covariate conditional entropy of true category probs: {mean_covariate_conditional_entropy_of_true_category_probabilities}.\\n\"", "\n", ")", "\n", "\n", "###", "\n", "# Inference", "\n", "###", "\n", "\n", "# IB-CAVI", "\n", "", "results_CAVI", ",", "time_for_IB_CAVI", "=", "time_me", "(", "compute_ib_cavi_with_normal_prior", ")", "(", "\n", "ib_model", ",", "\n", "labels_train", ",", "\n", "covariates_train", ",", "\n", "labels_test", "=", "labels_test", ",", "\n", "covariates_test", "=", "covariates_test", ",", "\n", "variational_params_init", "=", "None", ",", "\n", "convergence_criterion_drop_in_mean_elbo", "=", "convergence_criterion_drop_in_mean_elbo", ",", "\n", ")", "\n", "variational_beta", "=", "results_CAVI", ".", "variational_params", ".", "beta", "\n", "pd", ".", "set_option", "(", "\"display.max_columns\"", ",", "None", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "f\"\\n{results_CAVI.holdout_performance_over_time}\"", ")", "\n", "\n", "# MNL-MLE", "\n", "", "print", "(", "\"Now fitting softmax with MLE\"", ")", "\n", "beta_init", "=", "np", ".", "zeros", "(", "(", "dgc", ".", "n_features", "+", "1", ",", "dgc", ".", "n_categories", ")", ")", "\n", "beta_star_softmax_MLE", ",", "time_for_softmax_MLE", "=", "time_me", "(", "\n", "optimize_beta_for_softmax_model", "\n", ")", "(", "\n", "beta_init", ",", "\n", "covariates_train", ",", "\n", "labels_train", ",", "\n", "verbose", "=", "verbose", ",", "\n", ")", "\n", "\n", "###", "\n", "# Category probs", "\n", "###", "\n", "probs_test_true", "=", "construct_category_probs", "(", "\n", "covariates_test", ",", "\n", "dataset", ".", "beta", ",", "\n", "link_for_data_generation", ",", "\n", ")", "\n", "\n", "probs_test_baserate", "=", "compute_probs_for_baserate_model", "(", "\n", "labels_train", ",", "len", "(", "labels_test", ")", "\n", ")", "\n", "probs_test_softmax_MLE", "=", "construct_category_probs", "(", "\n", "covariates_test", ",", "\n", "beta_star_softmax_MLE", ",", "\n", "Link", ".", "SOFTMAX", ",", "\n", ")", "\n", "\n", "# Bayesian Model Averaging", "\n", "# TODO: Write a wrapper function around these two mini functions", "\n", "n_monte_carlo_samples", "=", "10", "\n", "CBC_weight", "=", "compute_weight_on_CBC_from_bayesian_model_averaging", "(", "\n", "covariates_train", ",", "\n", "labels_train", ",", "\n", "variational_beta", ",", "\n", "n_monte_carlo_samples", ",", "\n", "ib_model", ",", "\n", ")", "\n", "probs_test_IB_CAVI_with_BMA", "=", "(", "\n", "construct_category_probabilities_from_bayesian_model_averaging", "(", "\n", "covariates_test", ",", "\n", "variational_beta", ".", "mean", ",", "\n", "CBC_weight", ",", "\n", "ib_model", ",", "\n", ")", "\n", ")", "\n", "\n", "###", "\n", "# Metrics", "\n", "###", "\n", "metrics_dict_for_one_dataset", "=", "{", "}", "\n", "metrics_dict_for_one_dataset", "[", "\"dgp\"", "]", "=", "compute_metrics", "(", "\n", "probs_test_true", ",", "labels_test", ",", "min_allowable_prob", "\n", ")", "\n", "metrics_dict_for_one_dataset", "[", "\"baserate\"", "]", "=", "compute_metrics", "(", "\n", "probs_test_baserate", ",", "labels_test", ",", "min_allowable_prob", "\n", ")", "\n", "metrics_dict_for_one_dataset", "[", "\"softmax_MLE\"", "]", "=", "compute_metrics", "(", "\n", "probs_test_softmax_MLE", ",", "labels_test", ",", "min_allowable_prob", "\n", ")", "\n", "metrics_dict_for_one_dataset", "[", "\"IB_CAVI_plus_BMA\"", "]", "=", "compute_metrics", "(", "\n", "probs_test_IB_CAVI_with_BMA", ",", "labels_test", ",", "min_allowable_prob", "\n", ")", "\n", "\n", "results_dict", "=", "append_metrics_dict_for_one_dataset_to_results_dict", "(", "\n", "metrics_dict_for_one_dataset", ",", "results_dict", "\n", ")", "\n", "\n", "###", "\n", "# Update results dict", "\n", "###", "\n", "results_dict", "[", "\"N\"", "]", ".", "append", "(", "dgc", ".", "n_samples", ")", "\n", "results_dict", "[", "\"K\"", "]", ".", "append", "(", "dgc", ".", "n_categories", ")", "\n", "results_dict", "[", "\"M\"", "]", ".", "append", "(", "dgc", ".", "n_features", ")", "\n", "results_dict", "[", "\"scale_for_predictive_categories\"", "]", ".", "append", "(", "\n", "dgc", ".", "scale_for_predictive_categories", "\n", ")", "\n", "results_dict", "[", "\"seed\"", "]", ".", "append", "(", "seed", ")", "\n", "results_dict", "[", "\"convergence_criterion_drop_in_mean_elbo\"", "]", ".", "append", "(", "\n", "convergence_criterion_drop_in_mean_elbo", "\n", ")", "\n", "results_dict", "[", "\"last_train_idx\"", "]", ".", "append", "(", "n_train_samples", ")", "\n", "results_dict", "[", "\n", "\"mean_covariate_conditional_entropy_of_true_category_probabilities\"", "\n", "]", ".", "append", "(", "mean_covariate_conditional_entropy_of_true_category_probabilities", ")", "\n", "# timing results", "\n", "results_dict", "[", "\"time for softmax MLE\"", "]", ".", "append", "(", "time_for_softmax_MLE", ")", "\n", "results_dict", "[", "\"time for IB CAVI\"", "]", ".", "append", "(", "time_for_IB_CAVI", ")", "\n", "\n", "###", "\n", "# Print stuff", "\n", "###", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "f\"----Results----\"", ")", "\n", "for", "k", ",", "v", "in", "results_dict", ".", "items", "(", ")", ":", "\n", "                ", "print", "(", "f\"{k} : {v[-1]:.03f}\"", ")", "\n", "\n", "###", "\n", "# Save results as data frame", "\n", "###", "\n", "", "", "", "ensure_dir", "(", "results_dir", ")", "\n", "time_string", "=", "time", ".", "strftime", "(", "\"%Y%m%d-%H%M%S\"", ")", "\n", "path_to_results", "=", "os", ".", "path", ".", "join", "(", "\n", "results_dir", ",", "\n", "f\"sim_results_CAVI_vs_MLE_seed={seed}_when_run={time_string}.csv\"", ",", "\n", ")", "\n", "results_dict_df", "=", "pd", ".", "DataFrame", "(", "results_dict", ")", "\n", "print", "(", "f\"\\nNow writing results to {path_to_results}.\"", ")", "\n", "results_dict_df", ".", "to_csv", "(", "path_to_results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.main.run_comparison_to_mle._get_argument_parser": [[259, 326], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["", "def", "_get_argument_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Run CAVI vs MLE simulations\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--seed\"", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "f\"The seed used for each dataset in the cartesian product of # categories, # covariates, # samples, ssq_high.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--list_of_n_categories\"", ",", "\n", "type", "=", "int", ",", "\n", "nargs", "=", "\"+\"", ",", "\n", "default", "=", "[", "3", "]", ",", "\n", "help", "=", "f\"List of integers reflecting the number of categories we want for each run.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--multipliers_on_n_categories_to_create_n_covariates\"", ",", "\n", "type", "=", "int", ",", "\n", "nargs", "=", "\"+\"", ",", "\n", "default", "=", "[", "1", "]", ",", "\n", "help", "=", "f\"List of integers reflecting multipliers on # categories to create # covariates.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--multipliers_on_n_parameters_to_create_n_samples\"", ",", "\n", "type", "=", "int", ",", "\n", "nargs", "=", "\"+\"", ",", "\n", "default", "=", "[", "10", "]", ",", "\n", "help", "=", "f\"List of integers reflecting multipliers on # parameters to create # samples.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--list_of_scales_for_predictive_categories\"", ",", "\n", "type", "=", "float", ",", "\n", "nargs", "=", "\"+\"", ",", "\n", "default", "=", "[", "0.1", "]", ",", "\n", "help", "=", "f\"List of floats reflecting the value of ssq_high when generating data.\"", "\n", "f\"Higher values make the responses more predictable from the covariates\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--ib_model_as_string\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"probit\"", ",", "\n", "help", "=", "f\"The type of IB model we want to fit (which describes H^inv, the link function).  One of: probit, logit.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_generating_link_as_string\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"multi_logit\"", ",", "\n", "help", "=", "f\"Link for generating data.  Needs to be a member of the Link Enum.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--convergence_criterion_drop_in_mean_elbo\"", ",", "\n", "type", "=", "float", ",", "\n", "default", "=", "0.1", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--results_dir\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"/cluster/tufts/hugheslab/mwojno01/data/results/sims/no_dir_specified/\"", ",", "\n", "help", "=", "f\"directory for saving results of the run (assuming we're not running a test)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--test_run\"", ",", "\n", "type", "=", "bool", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "f\"If this flag is present, we override the default results_dir and save things to a temp directory\"", ",", "\n", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.intrusion_detection.make_plot.model_user_domain_from_basename": [[19, 21], ["[].split", "basename.split"], "function", ["None"], ["def", "model_user_domain_from_basename", "(", "basename", ")", ":", "\n", "    ", "return", "basename", ".", "split", "(", "\"model_user=\"", ")", "[", "1", "]", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.intrusion_detection.make_plot.get_model_user_domains": [[23, 27], ["make_plot.model_user_domain_from_basename", "os.listdir"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.intrusion_detection.make_plot.model_user_domain_from_basename"], ["", "def", "get_model_user_domains", "(", "local_results_dir", ")", ":", "\n", "    ", "return", "[", "\n", "model_user_domain_from_basename", "(", "basename", ")", "\n", "for", "basename", "in", "os", ".", "listdir", "(", "local_results_dir", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.intrusion_detection.make_plot.get_grand_mean_log_likes_with_user_domain_labels": [[30, 57], ["sorted", "len", "numpy.zeros", "os.listdir", "set", "make_plot.get_model_user_domains", "os.path.join", "pandas.read_csv", "make_plot.model_user_domain_from_basename", "sorted.index", "pd.read_csv.squeeze().iteritems", "sorted.index", "pd.read_csv.squeeze"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.intrusion_detection.make_plot.get_model_user_domains", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.intrusion_detection.make_plot.model_user_domain_from_basename"], ["", "def", "get_grand_mean_log_likes_with_user_domain_labels", "(", "\n", "local_results_dir", ":", "str", ",", "cavi_or_advi_string", ":", "str", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        grand_mean_log_likes: np.array, (i,j)th entry gives mean log like when the i-th user model\n            scores holdout data from the j-th user.\n        user_domains\n    \"\"\"", "\n", "user_domains", "=", "sorted", "(", "set", "(", "get_model_user_domains", "(", "local_results_dir", ")", ")", ")", "\n", "N_users", "=", "len", "(", "user_domains", ")", "\n", "grand_mean_log_likes", "=", "np", ".", "zeros", "(", "(", "N_users", ",", "N_users", ")", ")", "# model user X data user", "\n", "for", "basename", "in", "os", ".", "listdir", "(", "local_results_dir", ")", ":", "\n", "        ", "if", "cavi_or_advi_string", "in", "basename", ":", "\n", "            ", "full_path_for_one_user_model", "=", "os", ".", "path", ".", "join", "(", "local_results_dir", ",", "basename", ")", "\n", "df_mean_log_likes_for_one_user_model", "=", "pd", ".", "read_csv", "(", "\n", "full_path_for_one_user_model", ",", "index_col", "=", "0", "\n", ")", "\n", "model_user_domain", "=", "model_user_domain_from_basename", "(", "basename", ")", "\n", "model_user_idx", "=", "user_domains", ".", "index", "(", "model_user_domain", ")", "\n", "for", "(", "\n", "data_user_domain", ",", "\n", "mean_log_like", ",", "\n", ")", "in", "df_mean_log_likes_for_one_user_model", ".", "squeeze", "(", ")", ".", "iteritems", "(", ")", ":", "\n", "                ", "data_user_idx", "=", "user_domains", ".", "index", "(", "data_user_domain", ")", "\n", "grand_mean_log_likes", "[", "model_user_idx", ",", "data_user_idx", "]", "=", "mean_log_like", "\n", "", "", "", "return", "grand_mean_log_likes", ",", "user_domains", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.intrusion_detection.make_plot.restrict_grand_mean_log_likes_with_user_domain_labels_to_active_directory_domains": [[59, 74], ["enumerate", "numpy.ix_"], "function", ["None"], ["", "def", "restrict_grand_mean_log_likes_with_user_domain_labels_to_active_directory_domains", "(", "\n", "grand_mean_log_likes", ",", "user_domains", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Active directory domain account are the user_domains which end with @DOM1.\n    \"\"\"", "\n", "active_directory_indices", "=", "[", "\n", "i", "for", "(", "i", ",", "ud", ")", "in", "enumerate", "(", "user_domains", ")", "if", "\"@DOM1\"", "in", "ud", "\n", "]", "\n", "active_directory_user_domains", "=", "[", "user_domains", "[", "i", "]", "for", "i", "in", "active_directory_indices", "]", "\n", "active_directory_mean_log_likes", "=", "grand_mean_log_likes", "[", "\n", "np", ".", "ix_", "(", "active_directory_indices", ",", "active_directory_indices", ")", "\n", "]", "\n", "# np.ix_ does subsetting via a cartesian product.", "\n", "return", "active_directory_mean_log_likes", ",", "active_directory_user_domains", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.intrusion_detection.round_robin._get_argument_parser": [[34, 65], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "_get_argument_parser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Run performance over time from path to yaml configs\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--path_to_configs\"", ",", "\n", "type", "=", "str", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cyber_user_idx_relative_to_subset_override\"", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "f\"Can be used to override user idx relative to subset when operating on cyber data\"", ",", "\n", "default", "=", "None", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--scoring_results_dir\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "f\"Directory to where we write scoring results\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cavi_time_units\"", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "f\"Determines how long training was for IB-CAVI before grabbing betas\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--advi_time_units\"", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "f\"Determines how long training was for ADVI before grabbing betas\"", ",", "\n", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.intrusion_detection.round_robin.load_beta_mean_and_get_user_domain_for_cyber_user": [[67, 120], ["os.path.join", "scipy.sparse.load_npz", "next", "numpy.load", "ValueError", "os.walk", "cavi_or_advi_string.upper", "next", "next", "next", "os.walk", "os.walk", "os.walk"], "function", ["None"], ["", "def", "load_beta_mean_and_get_user_domain_for_cyber_user", "(", "\n", "user_idx", ":", "int", ",", "\n", "cavi_or_advi_string", ":", "str", ",", "\n", "cavi_time_units", ":", "int", ",", "\n", "advi_time_units", ":", "int", ",", "\n", "training_results_master_dir", ":", "str", "=", "\"/cluster/tufts/hugheslab/mwojno01/data/intrusion/\"", ",", "\n", ")", "->", "Tuple", "[", "np", ".", "array", ",", "str", "]", ":", "\n", "    ", "\"\"\"\n    This function makes a VERY specific assumption that the betas were stored at locations with a particular structure.\n    This structure is currently imposed by the performance over time training function.\n\n\n    Example path:\n        \"/cluster/tufts/hugheslab/mwojno01/data/intrusion/user_300/U137@C808/05_19_2022_18_31_26_MDT_advi/betas/ADVI/lr=1.0/save_every_secs=1200.0_units_of_save_every=8_secs_elapsed=10486.810/beta_mean.npy\"\n    \"\"\"", "\n", "user_dir", "=", "f\"{training_results_master_dir}user_{user_idx}\"", "\n", "user_domain", "=", "next", "(", "os", ".", "walk", "(", "user_dir", ")", ")", "[", "1", "]", "[", "0", "]", "\n", "user_dir_with_user_domain", "=", "f\"{user_dir}/{user_domain}/\"", "\n", "date_method", "=", "[", "\n", "date_method", "\n", "for", "date_method", "in", "next", "(", "os", ".", "walk", "(", "user_dir_with_user_domain", ")", ")", "[", "1", "]", "\n", "if", "cavi_or_advi_string", "in", "date_method", "\n", "]", "[", "0", "]", "\n", "user_beta_master_dir", "=", "f\"{user_dir_with_user_domain}/{date_method}/betas/\"", "\n", "inference_type_with_hyperparam", "=", "(", "\n", "\"IB_CAVI\"", "\n", "if", "cavi_or_advi_string", "==", "\"cavi\"", "\n", "else", "f\"{cavi_or_advi_string.upper()}/lr=1.0/\"", "\n", ")", "\n", "user_beta_dir_with_inference", "=", "(", "\n", "f\"{user_beta_master_dir}/{inference_type_with_hyperparam}/\"", "\n", ")", "\n", "time_units", "=", "cavi_time_units", "if", "cavi_or_advi_string", "==", "\"cavi\"", "else", "advi_time_units", "\n", "beta_snapshot", "=", "[", "\n", "beta_snap", "\n", "for", "beta_snap", "in", "next", "(", "os", ".", "walk", "(", "user_beta_dir_with_inference", ")", ")", "[", "1", "]", "\n", "if", "f\"units_of_save_every={time_units}\"", "in", "beta_snap", "\n", "]", "[", "0", "]", "\n", "total_child_dir", "=", "f\"{user_beta_dir_with_inference}/{beta_snapshot}/\"", "\n", "beta_mean_basename", "=", "[", "\n", "basename", "\n", "for", "basename", "in", "next", "(", "os", ".", "walk", "(", "total_child_dir", ")", ")", "[", "2", "]", "\n", "if", "f\"beta_mean\"", "in", "basename", "\n", "]", "[", "0", "]", "\n", "\n", "beta_mean_path", "=", "os", ".", "path", ".", "join", "(", "total_child_dir", ",", "beta_mean_basename", ")", "\n", "if", "\".npz\"", "in", "beta_mean_path", ":", "\n", "        ", "beta_mean", "=", "scipy", ".", "sparse", ".", "load_npz", "(", "beta_mean_path", ")", "\n", "", "elif", "\".npy\"", "in", "beta_mean_path", ":", "\n", "        ", "beta_mean", "=", "np", ".", "load", "(", "beta_mean_path", ")", "# not sure if this works.", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"I don't know how to load betas.\"", ")", "\n", "", "return", "beta_mean", ",", "user_domain", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.intrusion_detection.round_robin.score_all_data_with_one_users_model_from_loaded_configs": [[126, 212], ["round_robin.load_beta_mean_and_get_user_domain_for_cyber_user", "range", "categorical_from_binary.io.ensure_dir", "os.path.join", "pandas.DataFrame", "pd.DataFrame.to_csv", "categorical_from_binary.datasets.cyber.load.construct_process_start_features_and_labels_for_one_cyber_user", "data_user_domains.append", "int", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_category_probs", "categorical_from_binary.metrics.compute_metrics", "print", "mean_log_likes.append", "categorical_from_binary.data_generation.bayes_multiclass_reg.Link", "print", "mean_log_likes.append", "numpy.shape"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.intrusion_detection.round_robin.load_beta_mean_and_get_user_domain_for_cyber_user", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.io.ensure_dir", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.load.construct_process_start_features_and_labels_for_one_cyber_user", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.compute_metrics"], ["", "def", "score_all_data_with_one_users_model_from_loaded_configs", "(", "\n", "configs", ":", "Configs", ",", "\n", "user_idx_relative_to_subset", ":", "int", ",", "\n", "scoring_results_dir", ":", "str", ",", "\n", "cavi_time_units", ":", "int", ",", "\n", "advi_time_units", ":", "int", ",", "\n", ")", ":", "\n", "\n", "    ", "mean_log_likes", "=", "[", "]", "\n", "data_user_domains", "=", "[", "]", "\n", "\n", "for", "cavi_or_advi_string", "in", "[", "\"cavi\"", ",", "\"advi\"", "]", ":", "\n", "\n", "### Load model for model_user_idx", "\n", "        ", "model_user_idx", "=", "(", "\n", "configs", ".", "data", ".", "cyber", ".", "subset_initial_user_idx_when_sorting_most_to_fewest_events", "\n", "+", "user_idx_relative_to_subset", "\n", ")", "\n", "(", "\n", "beta_mean", ",", "\n", "model_user_domain", ",", "\n", ")", "=", "load_beta_mean_and_get_user_domain_for_cyber_user", "(", "\n", "model_user_idx", ",", "cavi_or_advi_string", ",", "cavi_time_units", ",", "advi_time_units", "\n", ")", "\n", "\n", "### Get TEST data to score from many users (self and others)", "\n", "for", "user_idx_relative_to_subset", "in", "range", "(", "\n", "configs", ".", "data", ".", "cyber", ".", "subset_number_of_users", "\n", ")", ":", "\n", "            ", "(", "\n", "covariates", ",", "\n", "labels", ",", "\n", "data_user_domain", ",", "\n", ")", "=", "construct_process_start_features_and_labels_for_one_cyber_user", "(", "\n", "configs", ".", "data", ".", "cyber", ".", "path_to_human_process_start_data", ",", "\n", "configs", ".", "data", ".", "cyber", ".", "subset_initial_user_idx_when_sorting_most_to_fewest_events", ",", "\n", "configs", ".", "data", ".", "cyber", ".", "subset_number_of_users", ",", "\n", "user_idx_relative_to_subset", ",", "\n", "configs", ".", "data", ".", "cyber", ".", "window_size", ",", "# TODO: should be obtained from file / metadata", "\n", "configs", ".", "data", ".", "cyber", ".", "temperature", ",", "# TODO: should be obtained from file /metadata", "\n", "configs", ".", "data", ".", "cyber", ".", "include_intercept", ",", "# TODO: should be obtained from file / metadata", "\n", ")", "# noqa", "\n", "\n", "data_user_domains", ".", "append", "(", "data_user_domain", ")", "\n", "\n", "# Grab TEST data!", "\n", "n_train_samples", "=", "int", "(", "\n", "configs", ".", "data", ".", "cyber", ".", "pct_training", "*", "np", ".", "shape", "(", "covariates", ")", "[", "0", "]", "\n", ")", "\n", "covariates_test", "=", "covariates", "[", "n_train_samples", ":", "]", "\n", "labels_test", "=", "labels", "[", "n_train_samples", ":", "]", "\n", "\n", "### Scoring", "\n", "try", ":", "\n", "# TODO: Add BMA instead of assuming that PROBIT is the right model.", "\n", "                ", "link", "=", "(", "\n", "Link", ".", "CBC_PROBIT", "\n", "if", "cavi_or_advi_string", "==", "\"cavi\"", "\n", "else", "Link", "(", "configs", ".", "holdout_performance", ".", "advi", ".", "link", ")", "\n", ")", "\n", "probs_test", "=", "construct_category_probs", "(", "\n", "covariates_test", ",", "\n", "beta_mean", ",", "\n", "link", ",", "\n", ")", "\n", "metrics", "=", "compute_metrics", "(", "probs_test", ",", "labels_test", ")", "\n", "mean_log_like", "=", "metrics", ".", "mean_log_like", "\n", "print", "(", "\n", "f\"\\t The mean log like for {model_user_domain} scoring {data_user_domain} was {mean_log_like}\"", "\n", ")", "\n", "\n", "mean_log_likes", ".", "append", "(", "mean_log_like", ")", "\n", "", "except", ":", "# some users don't have data for some reason", "\n", "                ", "print", "(", "\n", "f\"Could not process model_user {model_user_domain}, data user {data_user_domain}\"", "\n", ")", "\n", "mean_log_likes", ".", "append", "(", "np", ".", "nan", ")", "\n", "\n", "# save results", "\n", "", "", "ensure_dir", "(", "scoring_results_dir", ")", "\n", "scoring_results_df_path", "=", "os", ".", "path", ".", "join", "(", "\n", "scoring_results_dir", ",", "\n", "f\"{cavi_or_advi_string}_model_user={model_user_domain}_model_user_idx_={model_user_idx}_mean_log_likes_round_robin.csv\"", ",", "\n", ")", "\n", "df_metrics", "=", "pd", ".", "DataFrame", "(", "mean_log_likes", ",", "index", "=", "data_user_domains", ")", "\n", "df_metrics", ".", "to_csv", "(", "scoring_results_df_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.intrusion_detection.round_robin.score_all_data_with_one_users_model": [[214, 237], ["categorical_from_binary.performance_over_time.main.load_configs", "categorical_from_binary.performance_over_time.main.update_configs_via_optional_overrides", "round_robin.score_all_data_with_one_users_model_from_loaded_configs"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.configs_util.load_configs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.main.update_configs_via_optional_overrides", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.intrusion_detection.round_robin.score_all_data_with_one_users_model_from_loaded_configs"], ["", "", "def", "score_all_data_with_one_users_model", "(", "\n", "path_to_configs", ":", "str", ",", "\n", "cyber_user_idx_relative_to_subset_override", ",", "\n", "scoring_results_dir", ",", "\n", "cavi_time_units", ",", "\n", "advi_time_units", ",", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Score all data with one users model from yaml configs, but allow overrides (so we can control which user model\n    we are scoring with from command line, which allows for easy parallelization on the cluster)\n    \"\"\"", "\n", "\n", "configs", "=", "load_configs", "(", "path_to_configs", ")", "\n", "configs", "=", "update_configs_via_optional_overrides", "(", "\n", "configs", ",", "\n", "cyber_user_idx_relative_to_subset_override", "=", "cyber_user_idx_relative_to_subset_override", ",", "\n", ")", "\n", "score_all_data_with_one_users_model_from_loaded_configs", "(", "\n", "configs", ",", "\n", "cyber_user_idx_relative_to_subset_override", ",", "\n", "scoring_results_dir", ",", "\n", "cavi_time_units", ",", "\n", "advi_time_units", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.core.compute_performance_over_time": [[35, 211], ["categorical_from_binary.performance_over_time.classes.PerformanceOverTimeResults", "numpy.shape", "categorical_from_binary.kucukelbir.inference.Metadata", "categorical_from_binary.ib_cavi.multi.inference.compute_ib_cavi_with_normal_prior", "print", "categorical_from_binary.ib_cavi.multi.inference.compute_ib_cavi_with_normal_prior", "print", "numpy.array", "categorical_from_binary.performance_over_time.for_mcmc.construct_performance_over_time_for_MCMC", "print", "int", "categorical_from_binary.performance_over_time.for_mcmc.construct_performance_over_time_for_MCMC", "print", "numpy.shape", "print", "categorical_from_binary.kucukelbir.inference.do_advi_inference_via_kucukelbir_algo", "categorical_from_binary.kucukelbir.inference.ADVI_Results", "print", "numpy.shape", "categorical_from_binary.timing.time_me", "categorical_from_binary.timing.time_me"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.inference.compute_ib_cavi_with_normal_prior", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.inference.compute_ib_cavi_with_normal_prior", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.for_mcmc.construct_performance_over_time_for_MCMC", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.for_mcmc.construct_performance_over_time_for_MCMC", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.do_advi_inference_via_kucukelbir_algo", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.timing.time_me", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.timing.time_me"], ["\n", "# handle the binary (two-category) case. here it looks like there is only one \"category\",", "\n", "# although that's just a function of how binary probit is structured.", "\n", "if", "beta_mean", ".", "ndim", "==", "1", ":", "\n", "        ", "beta_mean", "=", "beta_mean", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "\n", "", "n_covariates", ",", "n_categories", "=", "np", ".", "shape", "(", "beta_mean", ")", "\n", "\n", "if", "beta_stds", ".", "ndim", "==", "1", ":", "\n", "        ", "beta_stds", "=", "np", ".", "repeat", "(", "beta_stds", "[", ":", ",", "np", ".", "newaxis", "]", ",", "n_categories", ",", "axis", "=", "1", ")", "\n", "\n", "", "posterior_probs_in_neighborhood", "=", "np", ".", "zeros", "(", "(", "n_covariates", ",", "n_categories", ")", ")", "\n", "for", "p", "in", "range", "(", "n_covariates", ")", ":", "\n", "        ", "for", "k", "in", "range", "(", "n_categories", ")", ":", "\n", "            ", "mean", ",", "std", "=", "beta_mean", "[", "p", ",", "k", "]", ",", "beta_stds", "[", "p", ",", "k", "]", "\n", "epsilon", "=", "neighborhood_radius_in_units_of_std_devs", "*", "std", "\n", "posterior_probs_in_neighborhood", "[", "p", ",", "k", "]", "=", "norm", "(", "mean", ",", "std", ")", ".", "cdf", "(", "epsilon", ")", "-", "norm", "(", "\n", "mean", ",", "std", "\n", ")", ".", "cdf", "(", "-", "epsilon", ")", "\n", "\n", "", "", "if", "covariate_dict", "is", "not", "None", ":", "\n", "        ", "index", "=", "sorted_covariate_names_from_covariate_dict", "(", "covariate_dict", ")", "\n", "", "else", ":", "\n", "        ", "index", "=", "None", "\n", "\n", "", "if", "label_dict", "is", "not", "None", ":", "\n", "        ", "columns", "=", "list", "(", "label_dict", ".", "keys", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "columns", "=", "None", "\n", "\n", "", "return", "pd", ".", "DataFrame", "(", "\n", "data", "=", "posterior_probs_in_neighborhood", ",", "\n", "index", "=", "index", ",", "\n", "columns", "=", "columns", ",", "\n", ")", "\n", "\n", "\n", "", "def", "compute_feature_inclusion_data_frame_using_scaled_neighborhood_method", "(", "\n", "beta_mean", ":", "NumpyArray2D", ",", "\n", "beta_stds", ":", "Union", "[", "NumpyArray1D", ",", "NumpyArray2D", "]", ",", "\n", "neighborhood_probability_threshold_for_exclusion", ":", "float", ",", "\n", "neighborhood_radius_in_units_of_std_devs", ":", "float", ",", "\n", "covariate_dict", ":", "Optional", "[", "Dict", "[", "str", ",", "VariableInfo", "]", "]", "=", "None", ",", "\n", "label_dict", ":", "Optional", "[", "Dict", "[", "str", ",", "VariableInfo", "]", "]", "=", "None", ",", "\n", ")", "->", "DataFrame", ":", "\n", "    ", "\"\"\"\n    If `r` refers to `neighborhood_radius_in_units_of_std_devs`, we first compute the  posterior probability of 0 being within\n    some epsilon-ball around zero,\n        P({beta_j in scaled neighborhood around 0}) := P_{posterior on beta_j}( - epsilon  <= 0 <= epsilon)\n    where epsilon =  r * std(beta_j)\n\n    We then exclude from the model any predictor beta_j such that\n        P({beta_j in scaled neighborhood around 0}) >= neighborhood_probability_threshold_for_exclusion.\n\n    Note that the variational posterior distribution on betas is normal.\n\n    Reference:\n        Li, Q., & Lin, N. (2010). The Bayesian elastic net. Bayesian analysis, 5(1), 151-170,\n        Sections 2.5 and 3.\n\n    Arguments:\n        beta_mean: has shape (M,K), where M is number of covariates and K is the\n            number of categories\n        beta_stds: has shape (M,) where M is the number of covariates\n            OR has shape (M,K), where M is number of covariates and K is the\n            number of categories\n        neighborhood_probability_threshold_for_exclusion: A predictor is excluded if the\n            posterior probability of being in a (-std beta_j, +std beta_j)\n            exceeds this probability neighborhood_probability_threshold_for_exclusion and is retained otherwise.\n    \"\"\"", "\n", "scaled_neighborhood_probs", "=", "(", "\n", "compute_posterior_prob_of_scaled_neighborhood_around_zero", "(", "\n", "beta_mean", ",", "\n", "beta_stds", ",", "\n", "neighborhood_radius_in_units_of_std_devs", ",", "\n", "covariate_dict", ",", "\n", "label_dict", ",", "\n", ")", "\n", ")", "\n", "inclusion_matrix_as_boolean", "=", "(", "\n", "scaled_neighborhood_probs", "<", "neighborhood_probability_threshold_for_exclusion", "\n", ")", "\n", "return", "(", "inclusion_matrix_as_boolean", ")", ".", "astype", "(", "int", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.configs_util.load_configs": [[135, 138], ["open", "configs_util.Configs", "yaml.full_load"], "function", ["None"], ["", "def", "load_configs", "(", "path_to_configs", ":", "str", ")", ":", "\n", "    ", "with", "open", "(", "path_to_configs", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "return", "Configs", "(", "**", "yaml", ".", "full_load", "(", "f", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.main._get_argument_parser": [[36, 63], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["compute_ib_cavi_with_normal_prior", ",", "\n", ")", "\n", "\n", "\n", "###", "\n", "# Configs", "\n", "###", "\n", "\n", "### Data generating configs", "\n", "Ks", "=", "[", "3", ",", "10", "]", "\n", "multipliers_on_K_to_create_M", "=", "[", "1", ",", "2", "]", "\n", "multipliers_on_P_to_create_N", "=", "[", "10", ",", "20", ",", "40", ",", "80", ",", "160", "]", "\n", "sigma_highs", "=", "[", "0.1", ",", "2.0", "]", "\n", "seed", "=", "6", "\n", "beta_0", "=", "None", "\n", "include_intercept", "=", "True", "\n", "link", "=", "Link", ".", "MULTI_LOGIT", "\n", "ib_model", "=", "IB_Model", ".", "LOGIT", "\n", "\n", "### Inference configs", "\n", "convergence_criterion_drop_in_mean_elbo", "=", "0.1", "\n", "\n", "### Plotting configs", "\n", "sns_style", "=", "\"darkgrid\"", "\n", "sns", ".", "set", "(", "style", "=", "sns_style", ")", "\n", "save_filepath", "=", "f\"data/results/bma/new_bma_plots_{ib_model.name}_{sns_style}\"", "\n", "\n", "###", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.main.run_performance_over_time_from_loaded_configs": [[65, 249], ["categorical_from_binary.performance_over_time.metadata.MetaData", "print", "categorical_from_binary.mst_time.get_mst_time", "os.path.join", "categorical_from_binary.io.ensure_dir", "categorical_from_binary.performance_over_time.core.compute_performance_over_time", "categorical_from_binary.io.write_json", "categorical_from_binary.io.write_json", "categorical_from_binary.performance_over_time.write.write_performance_over_time_results", "categorical_from_binary.data_generation.bayes_multiclass_reg.generate_multiclass_regression_dataset", "int", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_category_probs", "categorical_from_binary.metrics.compute_metrics", "print", "categorical_from_binary.metrics.Metrics", "numpy.shape", "configs.dict", "os.path.join", "os.path.join", "os.path.join", "categorical_from_binary.datasets.generic.load.construct_data_split", "numpy.log", "configs.holdout_performance.dict().items", "categorical_from_binary.data_generation.bayes_multiclass_reg.ControlCategoryPredictability", "categorical_from_binary.datasets.cyber.load.construct_process_start_features_and_labels_for_one_cyber_user", "int", "categorical_from_binary.performance_over_time.plotter.plot_performance_over_time_results", "configs.holdout_performance.dict", "os.path.join", "numpy.shape"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.mst_time.get_mst_time", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.io.ensure_dir", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.core.compute_performance_over_time", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.io.write_json", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.io.write_json", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.write.write_performance_over_time_results", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_multiclass_regression_dataset", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.compute_metrics", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.generic.load.construct_data_split", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cyber.load.construct_process_start_features_and_labels_for_one_cyber_user", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.plotter.plot_performance_over_time_results"], ["###", "\n", "data_generation_configs", "=", "make_data_generation_configs", "(", "\n", "Ks", ",", "\n", "multipliers_on_K_to_create_M", ",", "\n", "multipliers_on_P_to_create_N", ",", "\n", "sigma_highs", ",", "\n", "seed", "=", "seed", ",", "\n", ")", "\n", "print", "(", "f\"The data generation configs are {data_generation_configs}\"", ")", "\n", "\n", "\n", "results_dict", "=", "defaultdict", "(", "list", ")", "\n", "for", "(", "s", ",", "dgc", ")", "in", "enumerate", "(", "data_generation_configs", ")", ":", "\n", "    ", "print", "(", "f\"----Now running simulation {s+1}/{len(data_generation_configs)}--\"", ")", "\n", "\n", "beta_category_strategy", "=", "ControlCategoryPredictability", "(", "\n", "scale_for_predictive_categories", "=", "dgc", ".", "scale_for_predictive_categories", "\n", ")", "\n", "dataset", "=", "generate_multiclass_regression_dataset", "(", "\n", "n_samples", "=", "dgc", ".", "n_samples", ",", "\n", "n_features", "=", "dgc", ".", "n_features", ",", "\n", "n_categories", "=", "dgc", ".", "n_categories", ",", "\n", "beta_0", "=", "beta_0", ",", "\n", "link", "=", "link", ",", "\n", "seed", "=", "dgc", ".", "seed", ",", "\n", "include_intercept", "=", "include_intercept", ",", "\n", "beta_category_strategy", "=", "beta_category_strategy", ",", "\n", ")", "\n", "\n", "# Prep training / test split", "\n", "n_train_samples", "=", "int", "(", "0.8", "*", "dgc", ".", "n_samples", ")", "\n", "covariates_train", "=", "dataset", ".", "features", "[", ":", "n_train_samples", "]", "\n", "labels_train", "=", "dataset", ".", "labels", "[", ":", "n_train_samples", "]", "\n", "covariates_test", "=", "dataset", ".", "features", "[", "n_train_samples", ":", "]", "\n", "labels_test", "=", "dataset", ".", "labels", "[", "n_train_samples", ":", "]", "\n", "\n", "cbm_link", "=", "cbm_link_from_ib_model", "(", "ib_model", ")", "\n", "cbc_link", "=", "cbc_link_from_ib_model", "(", "ib_model", ")", "\n", "\n", "results", "=", "compute_ib_cavi_with_normal_prior", "(", "\n", "ib_model", ",", "\n", "labels_train", ",", "\n", "covariates_train", ",", "\n", "labels_test", "=", "labels_test", ",", "\n", "covariates_test", "=", "covariates_test", ",", "\n", "variational_params_init", "=", "None", ",", "\n", "convergence_criterion_drop_in_mean_elbo", "=", "convergence_criterion_drop_in_mean_elbo", ",", "\n", ")", "\n", "variational_beta", "=", "results", ".", "variational_params", ".", "beta", "\n", "\n", "# Approximate ELBO for each", "\n", "n_monte_carlo_samples", "=", "10", "\n", "CBC_weight", "=", "compute_weight_on_CBC_from_bayesian_model_averaging", "(", "\n", "covariates_train", ",", "\n", "labels_train", ",", "\n", "variational_beta", ",", "\n", "n_monte_carlo_samples", ",", "\n", "ib_model", ",", "\n", ")", "\n", "print", "(", "f\"For IB model {ib_model}, CBC weight is {CBC_weight}\"", ")", "\n", "\n", "### check - does the weight make sense (compared to true!)", "\n", "probs_true", "=", "construct_category_probs", "(", "\n", "covariates_test", ",", "dataset", ".", "beta", ",", "link", "=", "Link", ".", "MULTI_LOGIT", "\n", ")", "\n", "probs_CBM", "=", "construct_category_probs", "(", "\n", "covariates_test", ",", "\n", "variational_beta", ".", "mean", ",", "\n", "link", "=", "cbm_link", ",", "\n", ")", "\n", "probs_CBC", "=", "construct_category_probs", "(", "\n", "covariates_test", ",", "\n", "variational_beta", ".", "mean", ",", "\n", "link", "=", "cbc_link", ",", "\n", ")", "\n", "probs_BMA", "=", "construct_category_probabilities_from_bayesian_model_averaging", "(", "\n", "covariates_test", ",", "\n", "variational_beta", ".", "mean", ",", "\n", "CBC_weight", ",", "\n", "ib_model", ",", "\n", ")", "\n", "\n", "divergence_from_CBM_to_true", "=", "(", "\n", "compute_kl_divergence_from_estimated_to_true_category_probs", "(", "\n", "probs_CBM", ",", "probs_true", "\n", ")", "\n", ")", "\n", "divergence_from_CBC_to_true", "=", "(", "\n", "compute_kl_divergence_from_estimated_to_true_category_probs", "(", "\n", "probs_CBC", ",", "probs_true", "\n", ")", "\n", ")", "\n", "divergence_from_BMA_to_true", "=", "(", "\n", "compute_kl_divergence_from_estimated_to_true_category_probs", "(", "\n", "probs_BMA", ",", "probs_true", "\n", ")", "\n", ")", "\n", "print", "(", "\n", "f\"Mean divergence from CBM to true: {np.mean(divergence_from_CBM_to_true) }.  \"", "\n", "f\"Mean divergence from CBC to true: {np.mean(divergence_from_CBC_to_true)} \"", "\n", "f\"Mean divergence from BMA to true: {np.mean(divergence_from_BMA_to_true)}\"", "\n", ")", "\n", "\n", "results_dict", "[", "\"N\"", "]", ".", "append", "(", "dgc", ".", "n_samples", ")", "\n", "results_dict", "[", "\"K\"", "]", ".", "append", "(", "dgc", ".", "n_categories", ")", "\n", "results_dict", "[", "\"M\"", "]", ".", "append", "(", "dgc", ".", "n_features", ")", "\n", "results_dict", "[", "\"sigma_high\"", "]", ".", "append", "(", "dgc", ".", "scale_for_predictive_categories", ")", "\n", "results_dict", "[", "\"ib_model\"", "]", ".", "append", "(", "str", "(", "ib_model", ")", ")", "\n", "results_dict", "[", "\"CBC weight\"", "]", ".", "append", "(", "CBC_weight", ")", "\n", "results_dict", "[", "\"Mean KL divergence from CBM to true\"", "]", ".", "append", "(", "\n", "np", ".", "mean", "(", "divergence_from_CBM_to_true", ")", "\n", ")", "\n", "results_dict", "[", "\"Mean KL divergence from CBC to true\"", "]", ".", "append", "(", "\n", "np", ".", "mean", "(", "divergence_from_CBC_to_true", ")", "\n", ")", "\n", "results_dict", "[", "\"Mean KL divergence from BMA to true\"", "]", ".", "append", "(", "\n", "np", ".", "mean", "(", "divergence_from_BMA_to_true", ")", "\n", ")", "\n", "\n", "", "df_results", "=", "pd", ".", "DataFrame", "(", "results_dict", ")", "\n", "pd", ".", "set_option", "(", "\"display.float_format\"", ",", "lambda", "x", ":", "\"%.6f\"", "%", "x", ")", "\n", "df_results", "\n", "\n", "# If I want to convert the results dataframe to LateX, without the IB_Model.LOGIT column,", "\n", "# print(df_results[df_results.columns.drop('ib_model')].to_latex(index=True, float_format=\"%.3f\"))", "\n", "\n", "\n", "df_results_melted", "=", "pd", ".", "melt", "(", "\n", "df_results", ",", "\n", "id_vars", "=", "[", "\"N\"", ",", "\"K\"", ",", "\"M\"", ",", "\"sigma_high\"", ",", "\"ib_model\"", ",", "\"CBC weight\"", "]", ",", "\n", "var_name", "=", "\"Inference target\"", ",", "\n", "value_vars", "=", "[", "\n", "\"Mean KL divergence from CBM to true\"", ",", "\n", "\"Mean KL divergence from CBC to true\"", ",", "\n", "\"Mean KL divergence from BMA to true\"", ",", "\n", "]", ",", "\n", "value_name", "=", "\"Mean KL divergence\"", ",", "\n", "ignore_index", "=", "False", ",", "\n", ")", "\n", "# make the index an actual column, with a name, so we can tell the plotter to use it on one of the axes", "\n", "df_results_melted", "=", "df_results_melted", ".", "rename_axis", "(", "\"dataset_id\"", ")", ".", "reset_index", "(", ")", "\n", "df_results_melted", "=", "df_results_melted", ".", "replace", "(", "\n", "\"Mean KL divergence from CBM to true\"", ",", "\"CBM\"", "\n", ")", "\n", "df_results_melted", "=", "df_results_melted", ".", "replace", "(", "\n", "\"Mean KL divergence from CBC to true\"", ",", "\"CBC\"", "\n", ")", "\n", "df_results_melted", "=", "df_results_melted", ".", "replace", "(", "\n", "\"Mean KL divergence from BMA to true\"", ",", "\"BMA\"", "\n", ")", "\n", "\n", "\n", "####", "\n", "#  Make plots showing asymptotic decrease in error for each context", "\n", "###", "\n", "\n", "# Reference for row and column headers:", "\n", "# https://stackoverflow.com/questions/25812255/row-and-column-headers-in-matplotlibs-subplots", "\n", "fig", ",", "axes", "=", "plt", ".", "subplots", "(", "4", ",", "2", ",", "sharey", "=", "True", ",", "sharex", "=", "True", ",", "squeeze", "=", "True", ")", "\n", "df_results", "=", "pd", ".", "DataFrame", "(", "results_dict", ")", "\n", "contexts", "=", "[", "]", "\n", "for", "(", "s", ",", "sigma_high", ")", "in", "enumerate", "(", "sigma_highs", ")", ":", "\n", "    ", "row", "=", "-", "1", "\n", "for", "K", "in", "Ks", ":", "\n", "        ", "for", "multiplier_on_K_to_create_M", "in", "multipliers_on_K_to_create_M", ":", "\n", "            ", "M", "=", "K", "*", "multiplier_on_K_to_create_M", "\n", "P", "=", "P", "=", "get_num_parameters_from_num_covariates_and_num_categories", "(", "K", ",", "M", ")", "\n", "df_results_context", "=", "df_results", "[", "\n", "(", "df_results", "[", "\"K\"", "]", "==", "K", ")", "\n", "&", "(", "df_results", "[", "\"M\"", "]", "==", "M", ")", "\n", "&", "(", "df_results", "[", "\"sigma_high\"", "]", "==", "sigma_high", ")", "\n", "]", "\n", "row", "+=", "1", "\n", "contexts", ".", "append", "(", "f\"K={K}\\n M={M}\"", ")", "\n", "n_multipliers_for_for_subplot", "=", "[", "]", "\n", "kl_divs_from_BMA_for_subplot", "=", "[", "]", "\n", "kl_divs_from_CBC_for_subplot", "=", "[", "]", "\n", "kl_divs_from_CBM_for_subplot", "=", "[", "]", "\n", "for", "(", "n", ",", "multiplier_on_P_to_create_N", ")", "in", "enumerate", "(", "\n", "multipliers_on_P_to_create_N", "\n", ")", ":", "\n", "                ", "N", "=", "P", "*", "multiplier_on_P_to_create_N", "\n", "n_multipliers_for_for_subplot", ".", "append", "(", "multiplier_on_P_to_create_N", ")", "\n", "kl_div_from_BMA", "=", "df_results_context", ".", "query", "(", "f\"N == {N}\"", ")", "[", "\n", "\"Mean KL divergence from BMA to true\"", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.main.update_configs_via_optional_overrides": [[252, 296], ["categorical_from_binary.performance_over_time.classes.InferenceType", "inference_string_by_inference_type_to_remove.values", "os.path.join", "setattr"], "function", ["None"], ["\"Mean KL divergence from CBM to true\"", "\n", "]", ".", "values", "[", "0", "]", "\n", "kl_div_from_CBC", "=", "df_results_context", ".", "query", "(", "f\"N == {N}\"", ")", "[", "\n", "\"Mean KL divergence from CBC to true\"", "\n", "]", ".", "values", "[", "0", "]", "\n", "kl_divs_from_BMA_for_subplot", ".", "append", "(", "kl_div_from_BMA", ")", "\n", "kl_divs_from_CBM_for_subplot", ".", "append", "(", "kl_div_from_CBM", ")", "\n", "kl_divs_from_CBC_for_subplot", ".", "append", "(", "kl_div_from_CBC", ")", "\n", "", "axes", "[", "row", ",", "s", "]", ".", "plot", "(", "\n", "n_multipliers_for_for_subplot", ",", "\n", "kl_divs_from_CBM_for_subplot", ",", "\n", "\"-bo\"", ",", "\n", "label", "=", "f\"CBM-{ib_model.name}\"", ",", "\n", "clip_on", "=", "False", ",", "\n", ")", "\n", "axes", "[", "row", ",", "s", "]", ".", "plot", "(", "\n", "n_multipliers_for_for_subplot", ",", "\n", "kl_divs_from_CBC_for_subplot", ",", "\n", "\"-r^\"", ",", "\n", "label", "=", "f\"CBC-{ib_model.name}\"", ",", "\n", "clip_on", "=", "False", ",", "\n", ")", "\n", "axes", "[", "row", ",", "s", "]", ".", "plot", "(", "\n", "n_multipliers_for_for_subplot", ",", "\n", "kl_divs_from_BMA_for_subplot", ",", "\n", "\"-kx\"", ",", "\n", "label", "=", "\"BMA\"", ",", "\n", "clip_on", "=", "False", ",", "\n", "markersize", "=", "10", ",", "\n", ")", "\n", "axes", "[", "row", ",", "s", "]", ".", "set_xticks", "(", "\n", "[", "n", "for", "n", "in", "n_multipliers_for_for_subplot", "]", ",", "\n", "labels", "=", "[", "n", "for", "n", "in", "n_multipliers_for_for_subplot", "]", ",", "\n", "size", "=", "\"x-small\"", ",", "\n", ")", "\n", "# axes[row,s].set_ylim(bottom=0)", "\n", "\n", "", "", "", "fig", ".", "supylabel", "(", "\"Mean KL divergence to true probabilities\"", ")", "\n", "fig", ".", "supxlabel", "(", "\"                    Ratio of sample size to number of parameters\"", ")", "\n", "\n", "cols", "=", "[", "\n", "r\"$\\sigma_{high}$ = \"", "+", "f\"{sigma_highs[0]}\"", ",", "\n", "r\"$\\sigma_{high}$ = \"", "+", "f\"{sigma_highs[1]}\"", ",", "\n", "]", "\n", "rows", "=", "contexts", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.main.run_performance_over_time": [[298, 323], ["categorical_from_binary.performance_over_time.configs_util.load_configs", "main.update_configs_via_optional_overrides", "main.run_performance_over_time_from_loaded_configs", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.configs_util.load_configs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.main.update_configs_via_optional_overrides", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.main.run_performance_over_time_from_loaded_configs"], ["# plt.setp(axes.flat, xlabel='X-label', ylabel='Y-label')", "\n", "\n", "pad", "=", "5", "# in points", "\n", "\n", "for", "ax", ",", "col", "in", "zip", "(", "axes", "[", "0", "]", ",", "cols", ")", ":", "\n", "    ", "ax", ".", "annotate", "(", "\n", "col", ",", "\n", "xy", "=", "(", "0.5", ",", "1", ")", ",", "\n", "xytext", "=", "(", "0", ",", "pad", ")", ",", "\n", "xycoords", "=", "\"axes fraction\"", ",", "\n", "textcoords", "=", "\"offset points\"", ",", "\n", "size", "=", "\"medium\"", ",", "\n", "ha", "=", "\"center\"", ",", "\n", "va", "=", "\"baseline\"", ",", "\n", ")", "\n", "\n", "", "for", "ax", ",", "row", "in", "zip", "(", "axes", "[", ":", ",", "0", "]", ",", "rows", ")", ":", "\n", "    ", "ax", ".", "annotate", "(", "\n", "row", ",", "\n", "xy", "=", "(", "0", ",", "0.5", ")", ",", "\n", "xytext", "=", "(", "-", "ax", ".", "yaxis", ".", "labelpad", "-", "pad", ",", "0", ")", ",", "\n", "xycoords", "=", "ax", ".", "yaxis", ".", "label", ",", "\n", "textcoords", "=", "\"offset points\"", ",", "\n", "size", "=", "\"medium\"", ",", "\n", "ha", "=", "\"right\"", ",", "\n", "va", "=", "\"center\"", ",", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.write.write_performance_over_time_for_various_methods": [[11, 42], ["categorical_from_binary.io.ensure_dir", "os.path.join", "performance_softmax_via_pga_and_gibbs.to_csv", "os.path.join", "performance_nuts.to_csv", "os.path.join", "performance_cavi_probit.to_csv", "os.path.join", "performance_cavi_logit.to_csv", "advi_results_by_lr.keys", "os.path.join", "advi_results_by_lr[].performance_ADVI.to_csv"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.io.ensure_dir"], ["def", "write_performance_over_time_for_various_methods", "(", "\n", "save_dir", ":", "str", ",", "\n", "performance_cavi_probit", ":", "Optional", "[", "DataFrame", "]", "=", "None", ",", "\n", "performance_cavi_logit", ":", "Optional", "[", "DataFrame", "]", "=", "None", ",", "\n", "performance_softmax_via_pga_and_gibbs", ":", "Optional", "[", "DataFrame", "]", "=", "None", ",", "\n", "performance_nuts", ":", "Optional", "[", "DataFrame", "]", "=", "None", ",", "\n", "advi_results_by_lr", ":", "Optional", "[", "Dict", "[", "float", ",", "ADVI_Results", "]", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "\n", "    ", "ensure_dir", "(", "save_dir", ")", "\n", "\n", "if", "performance_softmax_via_pga_and_gibbs", "is", "not", "None", ":", "\n", "        ", "fp", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"perf_softmax_via_pga_and_gibbs.csv\"", ")", "\n", "performance_softmax_via_pga_and_gibbs", ".", "to_csv", "(", "fp", ")", "\n", "\n", "", "if", "performance_nuts", "is", "not", "None", ":", "\n", "        ", "fp", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"perf_nuts.csv\"", ")", "\n", "performance_nuts", ".", "to_csv", "(", "fp", ")", "\n", "\n", "", "if", "performance_cavi_probit", "is", "not", "None", ":", "\n", "        ", "fp", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"perf_cavi_probit.csv\"", ")", "\n", "performance_cavi_probit", ".", "to_csv", "(", "fp", ")", "\n", "\n", "", "if", "performance_cavi_logit", "is", "not", "None", ":", "\n", "        ", "fp", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"perf_cavi_logit.csv\"", ")", "\n", "performance_cavi_logit", ".", "to_csv", "(", "fp", ")", "\n", "\n", "", "if", "advi_results_by_lr", "is", "not", "None", ":", "\n", "        ", "for", "lr", "in", "advi_results_by_lr", ".", "keys", "(", ")", ":", "\n", "            ", "fp", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "f\"perf_advi_{lr}.csv\"", ")", "\n", "advi_results_by_lr", "[", "lr", "]", ".", "performance_ADVI", ".", "to_csv", "(", "fp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.write.write_performance_over_time_results": [[44, 55], ["write.write_performance_over_time_for_various_methods"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.write.write_performance_over_time_for_various_methods"], ["", "", "", "def", "write_performance_over_time_results", "(", "\n", "performance_over_time_results", ":", "PerformanceOverTimeResults", ",", "\n", "save_dir", ":", "str", ",", "\n", ")", ":", "\n", "    ", "return", "write_performance_over_time_for_various_methods", "(", "\n", "save_dir", ",", "\n", "performance_over_time_results", ".", "df_performance_cavi_probit", ",", "\n", "performance_over_time_results", ".", "df_performance_cavi_logit", ",", "\n", "performance_over_time_results", ".", "df_performance_softmax_via_pga_and_gibbs", ",", "\n", "performance_over_time_results", ".", "df_performance_nuts", ",", "\n", "performance_over_time_results", ".", "advi_results_by_lr", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.plotter.plot_performance_over_time": [[24, 387], ["matplotlib.pyplot.clf", "warnings.warn", "seaborn.color_palette", "seaborn.color_palette", "seaborn.color_palette", "enumerate", "perf_cavi_probit[].to_numpy", "perf_cavi_probit[].to_numpy", "numpy.nanmax", "numpy.nanmin", "matplotlib.pyplot.plot", "enumerate", "matplotlib.pyplot.xlim", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.xscale", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.xticks", "matplotlib.pyplot.yticks", "matplotlib.pyplot.tight_layout", "matplotlib.pyplot.clf", "len", "perf_cavi_logit[].to_numpy", "perf_cavi_logit[].to_numpy", "numpy.nanmax", "numpy.nanmin", "matplotlib.pyplot.plot", "df_performance_advi_by_lr.items", "perf_advi[].to_numpy", "perf_advi[].to_numpy", "numpy.nanmax", "numpy.nanmin", "len", "perf_nuts[].to_numpy", "perf_nuts[].to_numpy", "numpy.nanmax", "numpy.nanmin", "matplotlib.pyplot.plot", "perf_gibbs[].to_numpy", "perf_gibbs[].to_numpy", "numpy.nanmax", "numpy.nanmin", "matplotlib.pyplot.plot", "numpy.nanmax", "numpy.nanmin", "matplotlib.pyplot.axhline", "numpy.nanmax", "numpy.nanmin", "matplotlib.pyplot.axhline", "numpy.nanmax", "numpy.nanmin", "matplotlib.pyplot.axhline", "numpy.nanmax", "numpy.nanmin", "matplotlib.pyplot.axhline", "isinstance", "matplotlib.pyplot.legend", "categorical_from_binary.io.ensure_dir", "metric_as_string.replace", "os.path.join", "matplotlib.pyplot.savefig", "matplotlib.pyplot.show", "numpy.nanmax", "numpy.nanmin", "int", "numpy.isnan", "matplotlib.pyplot.plot", "matplotlib.pyplot.ylim", "matplotlib.pyplot.ylim", "matplotlib.pyplot.ylim", "matplotlib.pyplot.ylim", "matplotlib.pyplot.legend", "fig.canvas.draw", "plt.legend.get_window_extent().transformed", "os.path.join", "fig.savefig", "numpy.nanmax", "numpy.nanmin", "numpy.nanmax", "numpy.nanmin", "numpy.nanmax", "numpy.nanmin", "numpy.nanmax", "numpy.nanmin", "metric_as_string.capitalize", "fig.dpi_scale_trans.inverted", "len", "plt.legend.get_window_extent", "len", "len"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.io.ensure_dir"], ["def", "plot_performance_over_time", "(", "\n", "df_performance_advi_by_lr", ":", "Dict", "[", "float", ",", "DataFrame", "]", ",", "\n", "df_performance_cavi_probit", ":", "DataFrame", ",", "\n", "df_performance_cavi_logit", ":", "Optional", "[", "DataFrame", "]", "=", "None", ",", "\n", "df_performance_nuts", ":", "Optional", "[", "DataFrame", "]", "=", "None", ",", "\n", "df_performance_softmax_via_pga_and_gibbs", ":", "Optional", "[", "DataFrame", "]", "=", "None", ",", "\n", "save_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "log_like_data_generating_process", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "accuracy_data_generating_process", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "log_like_random_guessing", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "accuracy_random_guessing", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "min_pct_iterates_with_non_nan_metrics_in_order_to_plot_curve", "=", "0.0", ",", "\n", "min_log_likelihood_for_y_axis", ":", "Optional", "[", "Union", "[", "str", ",", "float", "]", "]", "=", "None", ",", "\n", "max_log_likelihood_for_y_axis", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "add_legend_to_plot", ":", "bool", "=", "True", ",", "\n", "show_cb_logit", ":", "bool", "=", "True", ",", "\n", "label_advi_lrs_by_index", ":", "bool", "=", "False", ",", "\n", "save_legend_separately", ":", "bool", "=", "False", ",", "\n", "CBC_name", ":", "str", "=", "\"CBC\"", ",", "\n", "CBM_name", ":", "str", "=", "\"CBM\"", ",", "\n", "SOFTMAX_name", ":", "str", "=", "\"MULTI_LOGIT_NON_IDENTIFIED\"", ",", "\n", "nuts_link_name_formatted_for_legend", ":", "str", "=", "\"Softmax\"", ",", "\n", "nuts_link_name", ":", "str", "=", "\"SOFTMAX\"", ",", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Arguments:\n         df_performance_advi_by_lr: Dict mapping learning rate to a pandas Dataframe showing\n            holdout performance metrics over time.\n        df_performance_cavi_probit: One return value of the IB_CAVI optimizer. A pandas Dataframe showing\n            holdout performance metrics over time.\n        min_log_likelihood_for_y_axis : float or \"random guessing\"\n            if  \"random guessing\" and log_like_random_guessing /  accuracy_random_guessing is not None\n            we use random guessing as the bottom of the y-axis\n        min_pct_iterates_with_non_nan_metrics_in_order_to_plot_curve: Optional float.\n            Moving this up from the default of 0.0\n            can prevent situations where we give legend entries to curves that are not there.\n        CBC_name: Can be set to \"DO\" for backwards compatability\n        CBM_name: Can be set to \"SDO\" for backwards compatability\n        SOFTMAX_name: Can be set to \"MULTI_LOGIT_NON_IDENTIFIED\" for backwards compatibility,\n        nuts_link_name: Can be set to something other than \"SOFTMAX\" (which was used in the experiments);\n            Need to extend code so we can have various links for other methods too (at least ADVI)\n    \"\"\"", "\n", "# TODO: This function currently makes some assumptions about which links were used with which inference", "\n", "# methods (e.g., softmax for ADVI).   Relax those -- just need to be able to grab the links from", "\n", "# the configs (as written to disk if plotting retroactively), so that the code doesn't error out", "\n", "# when trying to grab pandas columns that don't exist", "\n", "\n", "plt", ".", "clf", "(", ")", "\n", "\n", "EPSILON_TO_AVOID_EXACT_ZERO_SECONDS_WHEN_LOGGING", "=", "(", "\n", "df_performance_cavi_probit", "[", "\"seconds elapsed\"", "]", "[", "1", "]", "/", "2", "\n", ")", "\n", "\n", "warnings", ".", "warn", "(", "\n", "f\"We log time on the x-axis. But to do this, \"", "\n", "f\"we do some surgery on the initial timestamp from each method, replacing it with some epsilon.\"", "\n", "f\"This could wreak havoc if the initial performance measurement is NOT taken at time zero, as assumed.\"", "\n", ")", "\n", "\n", "# TODO: Construct an enum so we give consistent names to the various methods.", "\n", "\n", "# construct color palettes", "\n", "# Reference: https://colorbrewer2.org/#type=sequential&scheme=BuGn&n=6", "\n", "colors_for_advi", "=", "sns", ".", "color_palette", "(", "\n", "palette", "=", "\"BuPu\"", ",", "n_colors", "=", "len", "(", "df_performance_advi_by_lr", ")", "\n", ")", "\n", "colors_for_cavi", "=", "sns", ".", "color_palette", "(", "palette", "=", "\"YlOrRd\"", ",", "n_colors", "=", "2", ")", "\n", "colors_for_other_methods", "=", "sns", ".", "color_palette", "(", "palette", "=", "\"BuGn\"", ",", "n_colors", "=", "6", ")", "\n", "\n", "list_of_metrics_as_strings", "=", "[", "\n", "\"test mean log likelihood\"", ",", "\n", "\"test mean likelihood\"", ",", "\n", "\"test accuracy\"", ",", "\n", "\"train mean log likelihood\"", ",", "\n", "\"train mean likelihood\"", ",", "\n", "\"train accuracy\"", ",", "\n", "]", "\n", "for", "(", "m", ",", "metric_as_string", ")", "in", "enumerate", "(", "list_of_metrics_as_strings", ")", ":", "\n", "\n", "# Keep track of the best performing method (so we can set ylim)", "\n", "        ", "max_metric", "=", "-", "np", ".", "inf", "\n", "min_metric", "=", "np", ".", "inf", "\n", "\n", "###", "\n", "#  CAVI-Probit", "\n", "###", "\n", "\n", "# Pick link for CB-Probit using \"cheap BMA\"", "\n", "last_train_ll_CBC", "=", "df_performance_cavi_probit", "[", "\n", "f\"train mean log likelihood with {CBC_name}_PROBIT\"", "\n", "]", ".", "iloc", "[", "-", "1", "]", "\n", "last_train_ll_CBM", "=", "df_performance_cavi_probit", "[", "\n", "f\"train mean log likelihood with {CBM_name}_PROBIT\"", "\n", "]", ".", "iloc", "[", "-", "1", "]", "\n", "if", "last_train_ll_CBC", ">", "last_train_ll_CBM", ":", "\n", "            ", "cb_probit_link_as_string_with_cheap_BMA", "=", "f\"{CBC_name}_PROBIT\"", "\n", "", "else", ":", "\n", "            ", "cb_probit_link_as_string_with_cheap_BMA", "=", "f\"{CBM_name}_PROBIT\"", "\n", "\n", "# compute line to plot", "\n", "", "perf_cavi_probit", "=", "df_performance_cavi_probit", "\n", "secs_cavi_probit", "=", "perf_cavi_probit", "[", "\"seconds elapsed\"", "]", ".", "to_numpy", "(", ")", "\n", "secs_cavi_probit", "[", "0", "]", "=", "EPSILON_TO_AVOID_EXACT_ZERO_SECONDS_WHEN_LOGGING", "\n", "metric_cavi_probit", "=", "perf_cavi_probit", "[", "\n", "f\"{metric_as_string} with {cb_probit_link_as_string_with_cheap_BMA}\"", "\n", "]", ".", "to_numpy", "(", ")", "\n", "max_metric", "=", "np", ".", "nanmax", "(", "[", "max_metric", ",", "np", ".", "nanmax", "(", "metric_cavi_probit", ")", "]", ")", "\n", "min_metric", "=", "np", ".", "nanmin", "(", "[", "min_metric", ",", "np", ".", "nanmin", "(", "metric_cavi_probit", ")", "]", ")", "\n", "plt", ".", "plot", "(", "\n", "secs_cavi_probit", ",", "\n", "metric_cavi_probit", ",", "\n", "label", "=", "\"CB-Probit+IB-CAVI\"", ",", "\n", "linewidth", "=", "4", ",", "\n", "color", "=", "colors_for_cavi", "[", "-", "1", "]", ",", "\n", ")", "\n", "\n", "###", "\n", "#  CAVI-Logit", "\n", "###", "\n", "# Optionally make a line for CAVI-Logit", "\n", "if", "df_performance_cavi_logit", "is", "not", "None", "and", "show_cb_logit", "is", "True", ":", "\n", "# Pick link for CB-Logit using \"cheap BMA\"", "\n", "            ", "last_train_ll_CBC", "=", "df_performance_cavi_logit", "[", "\n", "f\"train mean log likelihood with {CBC_name}_LOGIT\"", "\n", "]", ".", "iloc", "[", "-", "1", "]", "\n", "last_train_ll_CBM", "=", "df_performance_cavi_logit", "[", "\n", "f\"train mean log likelihood with {CBM_name}_LOGIT\"", "\n", "]", ".", "iloc", "[", "-", "1", "]", "\n", "if", "last_train_ll_CBC", ">", "last_train_ll_CBM", ":", "\n", "                ", "cb_logit_link_as_string_with_cheap_BMA", "=", "f\"{CBC_name}_LOGIT\"", "\n", "", "else", ":", "\n", "                ", "cb_logit_link_as_string_with_cheap_BMA", "=", "f\"{CBM_name}_LOGIT\"", "\n", "\n", "", "perf_cavi_logit", "=", "df_performance_cavi_logit", "\n", "secs_cavi_logit", "=", "perf_cavi_logit", "[", "\"seconds elapsed\"", "]", ".", "to_numpy", "(", ")", "\n", "secs_cavi_logit", "[", "0", "]", "=", "EPSILON_TO_AVOID_EXACT_ZERO_SECONDS_WHEN_LOGGING", "\n", "metric_cavi_logit", "=", "perf_cavi_logit", "[", "\n", "f\"{metric_as_string} with {cb_logit_link_as_string_with_cheap_BMA}\"", "\n", "]", ".", "to_numpy", "(", ")", "\n", "max_metric", "=", "np", ".", "nanmax", "(", "[", "max_metric", ",", "np", ".", "nanmax", "(", "metric_cavi_logit", ")", "]", ")", "\n", "min_metric", "=", "np", ".", "nanmin", "(", "[", "min_metric", ",", "np", ".", "nanmin", "(", "metric_cavi_logit", ")", "]", ")", "\n", "plt", ".", "plot", "(", "\n", "secs_cavi_logit", ",", "\n", "metric_cavi_logit", ",", "\n", "label", "=", "\"CB-Logit+IB-CAVI\"", ",", "\n", "linewidth", "=", "4", ",", "\n", "color", "=", "colors_for_cavi", "[", "-", "2", "]", ",", "\n", ")", "\n", "\n", "###", "\n", "# ADVI", "\n", "###", "\n", "\n", "# make a line for ADVI for each learning rate", "\n", "", "for", "i", ",", "(", "lr", ",", "perf_advi", ")", "in", "enumerate", "(", "df_performance_advi_by_lr", ".", "items", "(", ")", ")", ":", "\n", "            ", "secs_advi", "=", "perf_advi", "[", "\"seconds elapsed\"", "]", ".", "to_numpy", "(", ")", "\n", "secs_advi", "[", "0", "]", "=", "EPSILON_TO_AVOID_EXACT_ZERO_SECONDS_WHEN_LOGGING", "\n", "# TODO: Don't hardcode the link here", "\n", "metric_advi", "=", "perf_advi", "[", "\n", "f\"{metric_as_string} with {SOFTMAX_name}\"", "\n", "]", ".", "to_numpy", "(", ")", "\n", "max_metric", "=", "np", ".", "nanmax", "(", "[", "max_metric", ",", "np", ".", "nanmax", "(", "metric_advi", ")", "]", ")", "\n", "min_metric", "=", "np", ".", "nanmin", "(", "[", "min_metric", ",", "np", ".", "nanmin", "(", "metric_advi", ")", "]", ")", "\n", "total_n_its", "=", "len", "(", "metric_advi", ")", "\n", "iterate_to_check_for_nan", "=", "(", "\n", "int", "(", "\n", "min_pct_iterates_with_non_nan_metrics_in_order_to_plot_curve", "\n", "*", "total_n_its", "\n", ")", "\n", "-", "1", "\n", ")", "\n", "if", "not", "np", ".", "isnan", "(", "metric_advi", "[", "iterate_to_check_for_nan", "]", ")", ":", "\n", "                ", "if", "label_advi_lrs_by_index", ":", "\n", "                    ", "label_advi", "=", "r\"Softmax+ADVI (lr=$\\mathcal{L}$\"", "+", "f\"[{i}])\"", "\n", "", "else", ":", "\n", "                    ", "label_advi", "=", "f\"Softmax+ADVI (lr={lr})\"", "\n", "# we reduce alpha (visibility) for higher LR's, since for our expts those suck", "\n", "", "plt", ".", "plot", "(", "\n", "secs_advi", ",", "\n", "metric_advi", ",", "\n", "label", "=", "label_advi", ",", "\n", "alpha", "=", "1.0", "-", "(", "i", "+", "1", ")", "/", "(", "len", "(", "df_performance_advi_by_lr", ")", "+", "1", ")", ",", "\n", "linewidth", "=", "4", ",", "\n", "color", "=", "colors_for_advi", "[", "i", "]", ",", "\n", ")", "\n", "\n", "###", "\n", "# NUTS", "\n", "###", "\n", "# Optionally make a line for NUTS", "\n", "", "", "if", "df_performance_nuts", "is", "not", "None", ":", "\n", "            ", "perf_nuts", "=", "df_performance_nuts", "\n", "secs_nuts", "=", "perf_nuts", "[", "\"seconds elapsed\"", "]", ".", "to_numpy", "(", ")", "\n", "# secs_nuts[0] = EPSILON_TO_AVOID_EXACT_ZERO_SECONDS_WHEN_LOGGING", "\n", "# TODO: don't hardcode the link here", "\n", "metric_nuts", "=", "perf_nuts", "[", "\n", "f\"{metric_as_string} with {nuts_link_name}\"", "\n", "]", ".", "to_numpy", "(", ")", "\n", "max_metric", "=", "np", ".", "nanmax", "(", "[", "max_metric", ",", "np", ".", "nanmax", "(", "metric_nuts", ")", "]", ")", "\n", "min_metric", "=", "np", ".", "nanmin", "(", "[", "min_metric", ",", "np", ".", "nanmin", "(", "metric_nuts", ")", "]", ")", "\n", "plt", ".", "plot", "(", "\n", "secs_nuts", ",", "\n", "metric_nuts", ",", "\n", "label", "=", "f\"{nuts_link_name_formatted_for_legend}+NUTS\"", ",", "\n", "linewidth", "=", "4", ",", "\n", "color", "=", "colors_for_other_methods", "[", "-", "1", "]", ",", "\n", "# alpha=1.0 - 1 / (len(colors_for_other_methods) + 1),", "\n", ")", "\n", "\n", "###", "\n", "# Gibbs for Softmax with PGA", "\n", "###", "\n", "# Optionally make a line for Gibbs softmax with PGA", "\n", "", "if", "df_performance_softmax_via_pga_and_gibbs", "is", "not", "None", ":", "\n", "            ", "perf_gibbs", "=", "df_performance_softmax_via_pga_and_gibbs", "\n", "secs_gibbs", "=", "perf_gibbs", "[", "\"seconds elapsed\"", "]", ".", "to_numpy", "(", ")", "\n", "# secs_gibbs[0] = EPSILON_TO_AVOID_EXACT_ZERO_SECONDS_WHEN_LOGGING", "\n", "# TODO: don't hardcode the link here", "\n", "metric_gibbs", "=", "perf_gibbs", "[", "\n", "f\"{metric_as_string} with {SOFTMAX_name}\"", "\n", "]", ".", "to_numpy", "(", ")", "\n", "max_metric", "=", "np", ".", "nanmax", "(", "[", "max_metric", ",", "np", ".", "nanmax", "(", "metric_gibbs", ")", "]", ")", "\n", "min_metric", "=", "np", ".", "nanmin", "(", "[", "min_metric", ",", "np", ".", "nanmin", "(", "metric_gibbs", ")", "]", ")", "\n", "plt", ".", "plot", "(", "\n", "secs_gibbs", ",", "\n", "metric_gibbs", ",", "\n", "label", "=", "\"Softmax+PGA-Gibbs\"", ",", "\n", "linewidth", "=", "4", ",", "\n", "color", "=", "colors_for_other_methods", "[", "-", "2", "]", ",", "\n", "alpha", "=", "1.0", "-", "2", "/", "(", "len", "(", "colors_for_other_methods", ")", "+", "1", ")", ",", "\n", ")", "\n", "\n", "###", "\n", "# Anchors", "\n", "###", "\n", "\n", "# Optionally make a horizontal line for data generating process", "\n", "", "if", "(", "\n", "\"log likelihood\"", "in", "metric_as_string", "\n", "and", "log_like_data_generating_process", "is", "not", "None", "\n", ")", ":", "\n", "            ", "max_metric", "=", "np", ".", "nanmax", "(", "[", "max_metric", ",", "log_like_data_generating_process", "]", ")", "\n", "min_metric", "=", "np", ".", "nanmin", "(", "[", "min_metric", ",", "log_like_data_generating_process", "]", ")", "\n", "plt", ".", "axhline", "(", "\n", "y", "=", "log_like_data_generating_process", ",", "\n", "color", "=", "\"k\"", ",", "\n", "label", "=", "\"True Model (Softmax)\"", ",", "\n", "linestyle", "=", "\"--\"", ",", "\n", ")", "\n", "\n", "# Optionally make a horizontal line for random guessing", "\n", "", "if", "(", "\n", "\"log likelihood\"", "in", "metric_as_string", "\n", "and", "log_like_random_guessing", "is", "not", "None", "\n", ")", ":", "\n", "            ", "max_metric", "=", "np", ".", "nanmax", "(", "[", "max_metric", ",", "log_like_random_guessing", "]", ")", "\n", "min_metric", "=", "np", ".", "nanmin", "(", "[", "min_metric", ",", "log_like_random_guessing", "]", ")", "\n", "plt", ".", "axhline", "(", "\n", "y", "=", "log_like_random_guessing", ",", "\n", "color", "=", "\"k\"", ",", "\n", "label", "=", "\"Random guessing\"", ",", "\n", "linestyle", "=", "\"-\"", ",", "\n", ")", "\n", "\n", "# Optionally make a horizontal line for data generating process", "\n", "", "if", "(", "\n", "\"accuracy\"", "in", "metric_as_string", "\n", "and", "accuracy_data_generating_process", "is", "not", "None", "\n", ")", ":", "\n", "            ", "max_metric", "=", "np", ".", "nanmax", "(", "[", "max_metric", ",", "accuracy_data_generating_process", "]", ")", "\n", "min_metric", "=", "np", ".", "nanmin", "(", "[", "min_metric", ",", "accuracy_data_generating_process", "]", ")", "\n", "plt", ".", "axhline", "(", "\n", "y", "=", "accuracy_data_generating_process", ",", "\n", "color", "=", "\"k\"", ",", "\n", "label", "=", "\"True Model (Softmax)\"", ",", "\n", "linestyle", "=", "\"--\"", ",", "\n", ")", "\n", "\n", "# Optionally make a horizontal line for random guessing", "\n", "", "if", "\"accuracy\"", "in", "metric_as_string", "and", "accuracy_random_guessing", "is", "not", "None", ":", "\n", "            ", "max_metric", "=", "np", ".", "nanmax", "(", "[", "max_metric", ",", "accuracy_random_guessing", "]", ")", "\n", "min_metric", "=", "np", ".", "nanmin", "(", "[", "min_metric", ",", "accuracy_random_guessing", "]", ")", "\n", "plt", ".", "axhline", "(", "\n", "y", "=", "accuracy_random_guessing", ",", "\n", "color", "=", "\"k\"", ",", "\n", "label", "=", "\"Random guessing\"", ",", "\n", "linestyle", "=", "\"-\"", ",", "\n", ")", "\n", "\n", "###", "\n", "# Set y and x limits", "\n", "###", "\n", "\n", "", "if", "\"log likelihood\"", "in", "metric_as_string", ":", "\n", "            ", "if", "isinstance", "(", "min_log_likelihood_for_y_axis", ",", "float", ")", ":", "\n", "                ", "plt", ".", "ylim", "(", "bottom", "=", "min_log_likelihood_for_y_axis", ")", "\n", "", "else", ":", "\n", "                ", "if", "min_log_likelihood_for_y_axis", "==", "\"random guessing\"", ":", "\n", "                    ", "bottom_base", "=", "log_like_random_guessing", "\n", "", "else", ":", "\n", "                    ", "bottom_base", "=", "min_metric", "\n", "", "multiplier", "=", "1.20", "if", "bottom_base", "<", "0.0", "else", "0.80", "\n", "plt", ".", "ylim", "(", "bottom", "=", "bottom_base", "*", "multiplier", ")", "\n", "", "if", "max_log_likelihood_for_y_axis", "is", "not", "None", ":", "\n", "                ", "plt", ".", "ylim", "(", "top", "=", "max_log_likelihood_for_y_axis", ")", "\n", "# elif log_like_data_generating_process is not None:", "\n", "#     # default value for y max, will be overriden", "\n", "#     # if max_log_likelihood_for_y_axis is not None", "\n", "#     plt.ylim(", "\n", "#         top=log_like_data_generating_process * dilation_factor_for_top_y", "\n", "#     )", "\n", "", "else", ":", "\n", "                ", "multiplier", "=", "0.975", "if", "max_metric", "<", "0", "else", "1.025", "\n", "plt", ".", "ylim", "(", "top", "=", "max_metric", "*", "multiplier", ")", "\n", "\n", "", "", "plt", ".", "xlim", "(", "left", "=", "EPSILON_TO_AVOID_EXACT_ZERO_SECONDS_WHEN_LOGGING", ")", "\n", "\n", "# add labels and legend", "\n", "plt", ".", "xlabel", "(", "\"Time (secs)\"", ",", "fontsize", "=", "24", ")", "\n", "plt", ".", "xscale", "(", "\"log\"", ")", "\n", "plt", ".", "ylabel", "(", "f\"{metric_as_string.capitalize()}\"", ",", "fontsize", "=", "24", ")", "\n", "plt", ".", "xticks", "(", "fontsize", "=", "24", ")", "\n", "plt", ".", "yticks", "(", "fontsize", "=", "24", ")", "\n", "\n", "if", "add_legend_to_plot", ":", "\n", "            ", "legend", "=", "plt", ".", "legend", "(", "\n", "shadow", "=", "True", ",", "\n", "fancybox", "=", "True", ",", "\n", "bbox_to_anchor", "=", "(", "1", ",", "0.5", ",", "0.3", ",", "0.2", ")", ",", "\n", "borderaxespad", "=", "0", ",", "\n", ")", "\n", "# plt.legend(bbox_to_anchor=(1.05, 1.0, 0.3, 0.2), loc='upper left')", "\n", "# The above code means the legend box is positioned at the axes coordinate", "\n", "# (1.05, 1.0) that has the width of 0.3 and the height of 0.2,", "\n", "# where (1.05, 1.0) is the coordinate of the upper left corner of the legend bounding box.", "\n", "\n", "", "plt", ".", "tight_layout", "(", ")", "\n", "\n", "# save or show", "\n", "if", "save_dir", "is", "not", "None", ":", "\n", "            ", "ensure_dir", "(", "save_dir", ")", "\n", "metric_as_string_no_spaces", "=", "metric_as_string", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", "\n", "basename", "=", "f\"{metric_as_string_no_spaces}_show_CB_logit={show_cb_logit}_legend={add_legend_to_plot}.png\"", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "basename", ")", "\n", "plt", ".", "savefig", "(", "filepath", ",", "bbox_inches", "=", "\"tight\"", ")", "\n", "if", "save_legend_separately", "and", "m", "==", "len", "(", "list_of_metrics_as_strings", ")", "-", "1", ":", "\n", "                ", "legend", "=", "plt", ".", "legend", "(", "\n", "shadow", "=", "True", ",", "\n", "fancybox", "=", "True", ",", "\n", "bbox_to_anchor", "=", "(", "1", ",", "0.5", ",", "0.3", ",", "0.2", ")", ",", "\n", "borderaxespad", "=", "0", ",", "\n", ")", "\n", "fig", "=", "legend", ".", "figure", "\n", "fig", ".", "canvas", ".", "draw", "(", ")", "\n", "bbox", "=", "legend", ".", "get_window_extent", "(", ")", ".", "transformed", "(", "\n", "fig", ".", "dpi_scale_trans", ".", "inverted", "(", ")", "\n", ")", "\n", "basename", "=", "f\"legend_only_show_CB_logit={show_cb_logit}.png\"", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "basename", ")", "\n", "fig", ".", "savefig", "(", "filepath", ",", "dpi", "=", "\"figure\"", ",", "bbox_inches", "=", "bbox", ")", "\n", "", "", "else", ":", "\n", "            ", "plt", ".", "show", "(", ")", "\n", "", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.plotter.plot_performance_over_time_results": [[389, 437], ["performance_over_time_results.advi_results_by_lr.items", "plotter.plot_performance_over_time"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.plotter.plot_performance_over_time"], ["", "", "def", "plot_performance_over_time_results", "(", "\n", "performance_over_time_results", ":", "PerformanceOverTimeResults", ",", "\n", "save_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "log_like_data_generating_process", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "accuracy_data_generating_process", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "log_like_random_guessing", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "accuracy_random_guessing", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "min_pct_iterates_with_non_nan_metrics_in_order_to_plot_curve", "=", "0.0", ",", "\n", "min_log_likelihood_for_y_axis", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "max_log_likelihood_for_y_axis", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "add_legend_to_plot", ":", "bool", "=", "True", ",", "\n", "show_cb_logit", ":", "bool", "=", "True", ",", "\n", "label_advi_lrs_by_index", ":", "bool", "=", "False", ",", "\n", "save_legend_separately", ":", "bool", "=", "False", ",", "\n", "CBC_name", ":", "str", "=", "\"CBC\"", ",", "\n", "CBM_name", ":", "str", "=", "\"CBM\"", ",", "\n", "SOFTMAX_name", ":", "str", "=", "\"MULTI_LOGIT_NON_IDENTIFIED\"", ",", "\n", "nuts_link_name", ":", "str", "=", "\"SOFTMAX\"", ",", "\n", ")", ":", "\n", "# convert advi_results_by_lr to df_performance_advi_by_lr", "\n", "# then we can feed `plot_performance_over_time` a DataFrame (or dict of DataFrames)", "\n", "# for each inference method", "\n", "    ", "df_performance_advi_by_lr", "=", "{", "}", "\n", "for", "lr", ",", "advi_results", "in", "performance_over_time_results", ".", "advi_results_by_lr", ".", "items", "(", ")", ":", "\n", "        ", "df_performance_advi_by_lr", "[", "lr", "]", "=", "advi_results", ".", "performance_ADVI", "\n", "\n", "", "return", "plot_performance_over_time", "(", "\n", "df_performance_advi_by_lr", ",", "\n", "performance_over_time_results", ".", "df_performance_cavi_probit", ",", "\n", "performance_over_time_results", ".", "df_performance_cavi_logit", ",", "\n", "performance_over_time_results", ".", "df_performance_nuts", ",", "\n", "performance_over_time_results", ".", "df_performance_softmax_via_pga_and_gibbs", ",", "\n", "save_dir", ",", "\n", "log_like_data_generating_process", ",", "\n", "accuracy_data_generating_process", ",", "\n", "log_like_random_guessing", ",", "\n", "accuracy_random_guessing", ",", "\n", "min_pct_iterates_with_non_nan_metrics_in_order_to_plot_curve", ",", "\n", "min_log_likelihood_for_y_axis", ",", "\n", "max_log_likelihood_for_y_axis", ",", "\n", "add_legend_to_plot", ",", "\n", "show_cb_logit", ",", "\n", "label_advi_lrs_by_index", ",", "\n", "save_legend_separately", ",", "\n", "CBC_name", "=", "CBC_name", ",", "\n", "CBM_name", "=", "CBM_name", ",", "\n", "SOFTMAX_name", "=", "SOFTMAX_name", ",", "\n", "nuts_link_name", "=", "nuts_link_name", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.plot_dataframes_from_disk._get_pandas_dataframe_or_return_none": [[15, 22], ["pandas.read_csv", "os.path.join"], "function", ["None"], ["def", "_get_pandas_dataframe_or_return_none", "(", "\n", "results_dir", ":", "str", ",", "dir_tail", ":", "str", "\n", ")", "->", "Optional", "[", "DataFrame", "]", ":", "\n", "    ", "if", "dir_tail", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "else", ":", "\n", "        ", "return", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "results_dir", ",", "dir_tail", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.plot_dataframes_from_disk.make_performance_over_time_plots_from_dataframes_on_disk": [[24, 140], ["plot_dataframes_from_disk._get_pandas_dataframe_or_return_none", "plot_dataframes_from_disk._get_pandas_dataframe_or_return_none", "plot_dataframes_from_disk._get_pandas_dataframe_or_return_none", "plot_dataframes_from_disk._get_pandas_dataframe_or_return_none", "sorted", "str", "categorical_from_binary.io.read_json", "categorical_from_binary.performance_over_time.metadata.MetaData", "os.path.join", "categorical_from_binary.io.ensure_dir", "dir_tails_to_advi.keys", "plot_dataframes_from_disk._get_pandas_dataframe_or_return_none", "os.path.join", "categorical_from_binary.performance_over_time.plotter.plot_performance_over_time", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.plot_dataframes_from_disk._get_pandas_dataframe_or_return_none", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.plot_dataframes_from_disk._get_pandas_dataframe_or_return_none", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.plot_dataframes_from_disk._get_pandas_dataframe_or_return_none", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.plot_dataframes_from_disk._get_pandas_dataframe_or_return_none", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.io.read_json", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.io.ensure_dir", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.plot_dataframes_from_disk._get_pandas_dataframe_or_return_none", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.plotter.plot_performance_over_time"], ["", "", "def", "make_performance_over_time_plots_from_dataframes_on_disk", "(", "\n", "results_dir", ":", "str", ",", "\n", "dir_tail_to_cavi_probit", ":", "Optional", "[", "str", "]", ",", "\n", "dir_tail_to_cavi_logit", ":", "Optional", "[", "str", "]", ",", "\n", "dir_tail_to_nuts", ":", "Optional", "[", "str", "]", ",", "\n", "dir_tail_to_gibbs", ":", "Optional", "[", "str", "]", ",", "\n", "dir_tails_to_advi", ":", "Optional", "[", "Dict", "[", "float", ",", "str", "]", "]", ",", "\n", "dir_tail_for_writing_plots", ":", "Optional", "[", "str", "]", "=", "\"plots/\"", ",", "\n", "min_pct_iterates_with_non_nan_metrics_in_order_to_plot_curve", ":", "Optional", "[", "float", "]", "=", "0.0", ",", "\n", "min_log_likelihood_for_y_axis", ":", "Optional", "[", "Union", "[", "float", ",", "str", "]", "]", "=", "None", ",", "\n", "max_log_likelihood_for_y_axis", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "CBC_name", ":", "str", "=", "\"CBC\"", ",", "\n", "CBM_name", ":", "str", "=", "\"CBM\"", ",", "\n", "SOFTMAX_name", ":", "str", "=", "\"MULTI_LOGIT_NON_IDENTIFIED\"", ",", "\n", "nuts_link_name", ":", "str", "=", "\"MULTI_LOGIT_NON_IDENTIFIED\"", ",", "\n", "nuts_link_name_formatted_for_legend", ":", "str", "=", "\"Softmax\"", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n\n    Plot performance over time results based on performance over time dataframes\n    that are stored on disk.\n\n    Usage:\n\n    ### first specify paths to dataframes\n    RESULTS_DIR=\"/data/results/arxiv_prep/cluster/larger_sims/\"\n\n    dir_tail_to_cavi_probit=\"04_29_2022_15_27_05_MDT_ONLY_CAVI_PROBIT/result_data_frames/perf_cavi_probit.csv\"\n    dir_tail_to_gibbs=\"05_04_2022_08_18_44_MDT_ONLY_SOFTMAX_VIA_PGA_AND_GIBBS/result_data_frames/perf_softmax_via_pga_and_gibbs.csv\"\n    dir_tail_to_nuts=\"05_01_2022_17_56_19_MDT_ONLY_NUTS/result_data_frames/perf_nuts.csv\"\n    dir_tails_to_advi={\n        0.1: \"04_30_2022_00_46_30_MDT_ONLY_ADVI/result_data_frames/perf_advi_0.1.csv\",\n        0.01: \"04_30_2022_00_46_30_MDT_ONLY_ADVI/result_data_frames/perf_advi_0.01.csv\",\n        0.001: \"05_04_2022_00_58_34_MDT_ONLY_ADVI/result_data_frames/perf_advi_0.001.csv\",\n    }\n    dir_tail_to_cavi_logit = None\n\n    # plot configs\n    dir_tail_for_writing_plots = \"tmp/\"\n    min_pct_iterates_with_non_nan_metrics_in_order_to_plot_curve = 0.5\n    min_log_likelihood_for_y_axis = \"random guessing\"\n    max_log_likelihood_for_y_axis = None\n\n    make_performance_over_time_plots_from_dataframes_on_disk(\n        RESULTS_DIR,\n        dir_tail_to_cavi_probit,\n        dir_tail_to_cavi_logit,\n        dir_tail_to_nuts,\n        dir_tail_to_gibbs,\n        dir_tails_to_advi,\n        dir_tail_for_writing_plots,\n        min_pct_iterates_with_non_nan_metrics_in_order_to_plot_curve,\n        min_log_likelihood_for_y_axis,\n        max_log_likelihood_for_y_axis,\n    )\n    \"\"\"", "\n", "\n", "### now load in the dataframes (or None if dir tails given as none)", "\n", "df_performance_cavi_probit", "=", "_get_pandas_dataframe_or_return_none", "(", "\n", "results_dir", ",", "dir_tail_to_cavi_probit", "\n", ")", "\n", "df_performance_cavi_logit", "=", "_get_pandas_dataframe_or_return_none", "(", "\n", "results_dir", ",", "dir_tail_to_cavi_logit", "\n", ")", "\n", "df_performance_nuts", "=", "_get_pandas_dataframe_or_return_none", "(", "\n", "results_dir", ",", "dir_tail_to_nuts", "\n", ")", "\n", "df_performance_softmax_via_pga_and_gibbs", "=", "_get_pandas_dataframe_or_return_none", "(", "\n", "results_dir", ",", "dir_tail_to_gibbs", "\n", ")", "\n", "\n", "lrs", "=", "sorted", "(", "dir_tails_to_advi", ".", "keys", "(", ")", ")", "\n", "df_performance_advi_by_lr", "=", "{", "}", "\n", "for", "lr", "in", "lrs", ":", "\n", "        ", "df_performance_advi_by_lr", "[", "lr", "]", "=", "_get_pandas_dataframe_or_return_none", "(", "\n", "results_dir", ",", "dir_tails_to_advi", "[", "lr", "]", "\n", ")", "\n", "\n", "### now load in metadata", "\n", "# the metadata lives in all directories, here we take it from probit.", "\n", "", "dir_with_probit", "=", "str", "(", "Path", "(", "dir_tail_to_cavi_probit", ")", ".", "parent", ".", "parent", ")", "\n", "dir_tail_to_metadata", "=", "f\"{dir_with_probit}/metadata.json\"", "\n", "metadata_as_dict", "=", "read_json", "(", "os", ".", "path", ".", "join", "(", "results_dir", ",", "dir_tail_to_metadata", ")", ")", "\n", "metadata", "=", "MetaData", "(", "**", "metadata_as_dict", ")", "\n", "\n", "### now plot", "\n", "plot_dir", "=", "os", ".", "path", ".", "join", "(", "results_dir", ",", "dir_tail_for_writing_plots", ")", "\n", "ensure_dir", "(", "plot_dir", ")", "\n", "\n", "for", "show_cb_logit", "in", "[", "True", ",", "False", "]", ":", "\n", "        ", "for", "add_legend_to_plot", "in", "[", "True", ",", "False", "]", ":", "\n", "            ", "save_legend_separately", "=", "not", "add_legend_to_plot", "\n", "label_advi_lrs_by_index", "=", "save_legend_separately", "\n", "plot_performance_over_time", "(", "\n", "df_performance_advi_by_lr", ",", "\n", "df_performance_cavi_probit", ",", "\n", "df_performance_cavi_logit", ",", "\n", "df_performance_nuts", ",", "\n", "df_performance_softmax_via_pga_and_gibbs", ",", "\n", "plot_dir", ",", "\n", "metadata", ".", "mean_log_like_data_generating_process", ",", "\n", "metadata", ".", "accuracy_data_generating_process", ",", "\n", "metadata", ".", "mean_log_like_random_guessing", ",", "\n", "metadata", ".", "accuracy_random_guessing", ",", "\n", "min_pct_iterates_with_non_nan_metrics_in_order_to_plot_curve", "=", "min_pct_iterates_with_non_nan_metrics_in_order_to_plot_curve", ",", "\n", "min_log_likelihood_for_y_axis", "=", "min_log_likelihood_for_y_axis", ",", "\n", "max_log_likelihood_for_y_axis", "=", "max_log_likelihood_for_y_axis", ",", "\n", "add_legend_to_plot", "=", "add_legend_to_plot", ",", "\n", "show_cb_logit", "=", "show_cb_logit", ",", "\n", "label_advi_lrs_by_index", "=", "label_advi_lrs_by_index", ",", "\n", "save_legend_separately", "=", "save_legend_separately", ",", "\n", "CBC_name", "=", "CBC_name", ",", "\n", "CBM_name", "=", "CBM_name", ",", "\n", "SOFTMAX_name", "=", "SOFTMAX_name", ",", "\n", "nuts_link_name", "=", "nuts_link_name", ",", "\n", "nuts_link_name_formatted_for_legend", "=", "nuts_link_name_formatted_for_legend", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.results.update_performance_results": [[12, 52], ["performance_dict[].append", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_category_probs", "categorical_from_binary.metrics.compute_metrics", "performance_dict[].append", "performance_dict[].append", "performance_dict[].append", "ValueError"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.metrics.compute_metrics"], ["\n", "from", "categorical_from_binary", ".", "data_generation", ".", "bayes_multiclass_reg", "import", "Link", "\n", "from", "categorical_from_binary", ".", "data_generation", ".", "splitter", "import", "SplitDataset", "\n", "\n", "\n", "@", "dataclass", "\n", "class", "ResultsOnOneSplit", ":", "\n", "    ", "\"\"\"\n    Attributes:\n        seed: The random seed used to split the data into train/test data\n        split_dataset : SplitDataset\n        beta_samples_by_model_type:  a dictionary mapping a Link to an np.array.\n            The np.array are regression weight betas with dimensionality SKM, where S is the number of MCMC\n            samples, K is the number of categories, and M is the number of covariates (including bias).\n            Used for MCMC sampling\n        beta_mean_by_model_type:  np.array.\n            The np.array are variational expectations for betas with dimensionality KM, where K is the number of categories,\n            and M is the number of covariates (including bias).\n            Used for variational inference.\n        beta_cov_by_model_type: np.array.\n            The np.array are are variational covariances for betas.\n            Used for variational inference.\n    \"\"\"", "\n", "\n", "seed", ":", "int", "=", "None", "\n", "split_dataset", ":", "SplitDataset", "=", "None", "\n", "beta_samples_by_model_type", ":", "Dict", "[", "Link", ",", "np", ".", "array", "]", "=", "None", "\n", "beta_mean", ":", "np", ".", "array", "=", "None", "\n", "beta_cov", ":", "np", ".", "array", "=", "None", "\n", "link_for_generating_data", ":", "Link", "=", "None", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.results.get_most_recent_performance_results_as_string": [[54, 67], ["performance_dict.items"], "function", ["None"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.for_mcmc.construct_performance_over_time_for_MCMC": [[14, 74], ["warnings.warn", "collections.defaultdict", "range", "pandas.DataFrame", "numpy.shape", "int", "beta_samples_MCMC_without_warmup[].mean", "categorical_from_binary.performance_over_time.results.update_performance_results"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.results.update_performance_results"], ["def", "construct_performance_over_time_for_MCMC", "(", "\n", "beta_samples_MCMC_without_warmup", ":", "NumpyArray3D", ",", "\n", "time_for_MCMC_with_warmup", ":", "float", ",", "\n", "covariates_train", ":", "NumpyArray2D", ",", "\n", "labels_train", ":", "NumpyArray2D", ",", "\n", "covariates_test", ":", "NumpyArray2D", ",", "\n", "labels_test", ":", "NumpyArray2D", ",", "\n", "link", ":", "Link", ",", "\n", "stride", ":", "Optional", "[", "int", "]", "=", "1", ",", "\n", "n_warmup_samples", ":", "Optional", "[", "int", "]", "=", "0", ",", "\n", "one_beta_sample_has_transposed_orientation", ":", "bool", "=", "False", ",", "\n", ")", "->", "DataFrame", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        beta_samples_MCMC_without_warmup: array of shape (S,K,M) or (S,M,K), where S is the number of MCMC samples\n            (not including warmup), K is the number of categories,\n            and M is the number of covariates (including intercept).\n\n            If one_beta_sample_has_transposed_orientation=True, then the shape is taken to be (S,K,M).\n            Otherwise, the shape is taken to be (S,M,K).\n        time_for_MCMC_with_warmup: time it took to run MCMC.  This includes warmup.\n        n_warmup_samples: the number of warmup samples.  ONLY change this from the default (=0)\n            if warmup samples were computed separately (then discarded) for some initial percentage\n            of `time_for_MCMC_with_warmup`, and then we must post-correct the time estimates.  For instance, we must\n            do this when using numpyro's HMC.\n        one_beta_sample_has_transposed_orientation : Determines the orientation of beta_samples_MCMC_without_warmup. See beta_samples_MCMC_without_warmup.\n    \"\"\"", "\n", "warnings", ".", "warn", "(", "\n", "\"The beta samples provided should ALREADY have the warmup samples excluded.\"", "\n", ")", "\n", "n_useable_samples", "=", "np", ".", "shape", "(", "beta_samples_MCMC_without_warmup", ")", "[", "0", "]", "\n", "pct_time_warming_up", "=", "n_warmup_samples", "/", "(", "n_warmup_samples", "+", "n_useable_samples", ")", "\n", "estimated_time_for_warmup", "=", "pct_time_warming_up", "*", "time_for_MCMC_with_warmup", "\n", "estimated_time_for_useable_samples", "=", "(", "\n", "time_for_MCMC_with_warmup", "-", "estimated_time_for_warmup", "\n", ")", "\n", "\n", "performance_over_time_as_dict", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "n_useable_samples", ",", "int", "(", "stride", ")", ")", ":", "\n", "        ", "sample_idx", "=", "i", "+", "1", "\n", "beta_mean_mcmc_so_far", "=", "beta_samples_MCMC_without_warmup", "[", "\n", ":", "sample_idx", ",", ":", ",", ":", "\n", "]", ".", "mean", "(", "axis", "=", "0", ")", "\n", "if", "one_beta_sample_has_transposed_orientation", ":", "\n", "            ", "beta_mean_mcmc_so_far", "=", "beta_mean_mcmc_so_far", ".", "T", "\n", "", "seconds_elapsed", "=", "(", "\n", "estimated_time_for_warmup", "\n", "+", "(", "sample_idx", "/", "n_useable_samples", ")", "*", "estimated_time_for_useable_samples", "\n", ")", "\n", "update_performance_results", "(", "\n", "performance_over_time_as_dict", ",", "\n", "covariates_train", ",", "\n", "labels_train", ",", "\n", "beta_mean_mcmc_so_far", ",", "\n", "seconds_elapsed", ",", "\n", "link", "=", "link", ",", "\n", "covariates_test", "=", "covariates_test", ",", "\n", "labels_test", "=", "labels_test", ",", "\n", ")", "\n", "", "return", "pd", ".", "DataFrame", "(", "performance_over_time_as_dict", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.hmc_helpers.get_beta_samples_for_categorical_model_via_HMC": [[28, 66], ["categorical_from_binary.hmc.core.run_nuts_on_categorical_data", "numpy.swapaxes", "numpy.shape"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hmc.core.run_nuts_on_categorical_data"], ["def", "get_beta_samples_for_categorical_model_via_HMC", "(", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray2D", ",", "\n", "link", ":", "Link", ",", "\n", "num_warmup_samples", ":", "int", ",", "\n", "num_mcmc_samples", ":", "int", ",", "\n", "prior_mean", ":", "float", "=", "0.0", ",", "\n", "prior_stddev", ":", "float", "=", "1.0", ",", "\n", "random_seed", ":", "int", "=", "1", ",", "\n", ")", "->", "NumpyArray3D", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        covariates: np.array of shape (N,M), where N is the number of samples and M\n            is the number of covariates\n        labels: np.array of shape (N,K), where N is the number of samples and K\n            is the number of categories\n\n    Returns:\n        beta samples of shape (S,M,K), where S is the number of Monte Carlo samples,\n        M is the number of covariates, and K is the number of categories\n\n    \"\"\"", "\n", "n_samples", "=", "np", ".", "shape", "(", "labels", ")", "[", "0", "]", "\n", "Nseen_list", "=", "[", "n_samples", "]", "\n", "betas_SLM_by_N", "=", "run_nuts_on_categorical_data", "(", "\n", "num_warmup_samples", ",", "\n", "num_mcmc_samples", ",", "\n", "Nseen_list", ",", "\n", "create_categorical_model", ",", "\n", "link", ",", "\n", "labels", ",", "\n", "covariates", ",", "\n", "prior_mean", ",", "\n", "prior_stddev", ",", "\n", "random_seed", ",", "\n", ")", "\n", "betas_SKM", "=", "betas_SLM_by_N", "[", "n_samples", "]", "\n", "return", "np", ".", "swapaxes", "(", "betas_SKM", ",", "1", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.hmc_helpers.get_mean_log_like_from_beta_samples": [[68, 93], ["isinstance", "beta_samples.to_py.mean", "category_probability_function", "numpy.mean", "beta_samples.to_py.to_py", "numpy.log", "numpy.where"], "function", ["None"], ["", "def", "get_mean_log_like_from_beta_samples", "(", "\n", "beta_samples", ":", "Union", "[", "NumpyArray3D", ",", "jaxlib", ".", "xla_extension", ".", "DeviceArray", "]", ",", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray2D", ",", "\n", "link", ":", "Link", ",", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        beta samples: has shape (S,M,K), where S is the number of Monte Carlo samples,\n            M is the number of covariates, and K is the number of categories\n        covariates: np.array of shape (N,M), where N is the number of samples and M\n            is the number of covariates\n        labels: np.array of shape (N,K), where N is the number of samples and K\n            is the number of categories\n    \"\"\"", "\n", "# jax's DeviceArray's don't support item assignment, so if that's the type of the beta samples", "\n", "# convert it to numpy, so that the functions for computing category probabilities in our", "\n", "# data generation module can run without raising an error.", "\n", "if", "isinstance", "(", "beta_samples", ",", "jaxlib", ".", "xla_extension", ".", "DeviceArray", ")", ":", "\n", "        ", "beta_samples", "=", "beta_samples", ".", "to_py", "(", ")", "\n", "", "beta_mean", "=", "beta_samples", ".", "mean", "(", "axis", "=", "0", ")", "\n", "category_probability_function", "=", "CATEGORY_PROBABILITY_FUNCTION_BY_MODEL_TYPE", "[", "link", "]", "\n", "category_probs", "=", "category_probability_function", "(", "covariates", ",", "beta_mean", ")", "\n", "choice_probs", "=", "category_probs", "[", "np", ".", "where", "(", "labels", ")", "]", "\n", "return", "np", ".", "mean", "(", "np", ".", "log", "(", "choice_probs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.hmc_helpers.get_accuracy_from_beta_samples": [[95, 119], ["isinstance", "beta_samples.to_py.mean", "category_probability_function", "numpy.mean", "beta_samples.to_py.to_py", "numpy.argmax", "numpy.where"], "function", ["None"], ["", "def", "get_accuracy_from_beta_samples", "(", "\n", "beta_samples", ":", "Union", "[", "NumpyArray3D", ",", "jaxlib", ".", "xla_extension", ".", "DeviceArray", "]", ",", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray2D", ",", "\n", "link", ":", "Link", ",", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        beta samples: has shape (S,M,K), where S is the number of Monte Carlo samples,\n            M is the number of covariates, and K is the number of categories\n        covariates: np.array of shape (N,M), where N is the number of samples and M\n            is the number of covariates\n        labels: np.array of shape (N,K), where N is the number of samples and K\n            is the number of categories\n    \"\"\"", "\n", "# jax's DeviceArray's don't support item assignment, so if that's the type of the beta samples", "\n", "# convert it to numpy, so that the functions for computing category probabilities in our", "\n", "# data generation module can run without raising an error.", "\n", "if", "isinstance", "(", "beta_samples", ",", "jaxlib", ".", "xla_extension", ".", "DeviceArray", ")", ":", "\n", "        ", "beta_samples", "=", "beta_samples", ".", "to_py", "(", ")", "\n", "", "beta_mean", "=", "beta_samples", ".", "mean", "(", "axis", "=", "0", ")", "\n", "category_probability_function", "=", "CATEGORY_PROBABILITY_FUNCTION_BY_MODEL_TYPE", "[", "link", "]", "\n", "category_probs", "=", "category_probability_function", "(", "covariates", ",", "beta_mean", ")", "\n", "return", "np", ".", "mean", "(", "np", ".", "argmax", "(", "category_probs", ",", "1", ")", "==", "np", ".", "where", "(", "labels", ")", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.analysis.get_holdout_loglikes": [[17, 34], ["analysis.get_relevant_metrics_for_cbm_vs_cbc_on_test_sets_for_numerous_data_splits", "analysis.HoldoutLogLikes"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.analysis.get_relevant_metrics_for_cbm_vs_cbc_on_test_sets_for_numerous_data_splits"], ["", "def", "get_holdout_loglikes", "(", "\n", "measurements_on_all_splits", ":", "List", "[", "List", "[", "Measurement", "]", "]", ",", "\n", ")", "->", "HoldoutLogLikes", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        measurements_on_all_splits: A list of lists of measurements.\n            For the outer list, each element gives results for a different data split.\n            For the inner list, each element is a different measurement\n    \"\"\"", "\n", "(", "\n", "holdout_log_likes_for_ib_plus_sdo", ",", "\n", "holdout_log_likes_for_ib_plus_do", ",", "\n", ")", "=", "get_relevant_metrics_for_cbm_vs_cbc_on_test_sets_for_numerous_data_splits", "(", "\n", "measurements_on_all_splits", ",", "relevant_metric", "=", "Metric", ".", "MEAN_LOG_LIKELIHOOD", "\n", ")", "\n", "return", "HoldoutLogLikes", "(", "\n", "holdout_log_likes_for_ib_plus_sdo", ",", "holdout_log_likes_for_ib_plus_do", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.analysis.get_misclassification_rates": [[37, 54], ["analysis.get_relevant_metrics_for_cbm_vs_cbc_on_test_sets_for_numerous_data_splits", "analysis.MisclassificationRates"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.analysis.get_relevant_metrics_for_cbm_vs_cbc_on_test_sets_for_numerous_data_splits"], ["", "def", "get_misclassification_rates", "(", "\n", "measurements_on_all_splits", ":", "List", "[", "List", "[", "Measurement", "]", "]", ",", "\n", ")", "->", "MisclassificationRates", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        measurements_on_all_splits: A list of lists of measurements.\n            For the outer list, each element gives results for a different data split.\n            For the inner list, each element is a different measurement\n    \"\"\"", "\n", "(", "\n", "misclassification_rates_for_ib_plus_sdo", ",", "\n", "misclassification_rates_for_ib_plus_do", ",", "\n", ")", "=", "get_relevant_metrics_for_cbm_vs_cbc_on_test_sets_for_numerous_data_splits", "(", "\n", "measurements_on_all_splits", ",", "relevant_metric", "=", "Metric", ".", "MISCLASSIFICATION_RATE", "\n", ")", "\n", "return", "MisclassificationRates", "(", "\n", "misclassification_rates_for_ib_plus_sdo", ",", "misclassification_rates_for_ib_plus_do", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.analysis.get_relevant_metrics_for_cbm_vs_cbc_on_test_sets_for_numerous_data_splits": [[57, 93], ["analysis.get_relevant_metrics_for_cbm_vs_cbc_on_test_sets_for_numerous_data_splits.measurement_is_relevant"], "function", ["None"], ["", "def", "get_relevant_metrics_for_cbm_vs_cbc_on_test_sets_for_numerous_data_splits", "(", "\n", "measurements_on_all_splits", ":", "List", "[", "List", "[", "Measurement", "]", "]", ",", "relevant_metric", ":", "Metric", "\n", ")", "->", "Tuple", "[", "List", "[", "float", "]", ",", "List", "[", "float", "]", "]", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        measurements_on_all_splits: A list of lists of measurements.\n            For the outer list, each element gives results for a different data split.\n            For the inner list, each element is a different measurement\n    \"\"\"", "\n", "\n", "def", "measurement_is_relevant", "(", "measurement", ":", "Measurement", ")", "->", "bool", ":", "\n", "        ", "return", "(", "\n", "measurement", ".", "context", ".", "data_type", "==", "DataType", ".", "TEST", "\n", "and", "measurement", ".", "context", ".", "metric", "==", "relevant_metric", "\n", ")", "\n", "\n", "", "def", "measurement_uses_do_formula", "(", "measurement", ":", "Measurement", ")", "->", "bool", ":", "\n", "        ", "return", "measurement", ".", "context", ".", "link_for_category_probabilities", "==", "Link", ".", "CBC_PROBIT", "\n", "\n", "", "def", "measurement_uses_sdo_formula", "(", "measurement", ":", "Measurement", ")", "->", "bool", ":", "\n", "        ", "return", "measurement", ".", "context", ".", "link_for_category_probabilities", "==", "Link", ".", "CBM_PROBIT", "\n", "\n", "", "relevant_metric_for_ib_plus_sdo", "=", "[", "\n", "m", ".", "value", "\n", "for", "one_split_measurements", "in", "measurements_on_all_splits", "\n", "for", "m", "in", "one_split_measurements", "\n", "if", "measurement_is_relevant", "(", "m", ")", "and", "measurement_uses_sdo_formula", "(", "m", ")", "\n", "]", "\n", "\n", "relevant_metric_for_ib_plus_do", "=", "[", "\n", "m", ".", "value", "\n", "for", "one_split_measurements", "in", "measurements_on_all_splits", "\n", "for", "m", "in", "one_split_measurements", "\n", "if", "measurement_is_relevant", "(", "m", ")", "and", "measurement_uses_do_formula", "(", "m", ")", "\n", "]", "\n", "return", "relevant_metric_for_ib_plus_sdo", ",", "relevant_metric_for_ib_plus_do", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.calibration_analysis.get_calibration_curve_results_on_one_data_split": [[34, 84], ["numpy.argmax", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_category_probs", "numpy.array", "numpy.delete", "numpy.array", "numpy.hstack", "sklearn.calibration.calibration_curve", "calibration_analysis.CalibrationCurveResults", "enumerate", "enumerate", "len", "len"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs"], ["def", "get_calibration_curve_results_on_one_data_split", "(", "\n", "results_on_one_split", ":", "ResultsOnOneSplit", ",", "n_bins", ":", "int", "\n", ")", "->", "Dict", "[", "Link", ",", "CalibrationCurveResults", "]", ":", "\n", "    ", "\"\"\"\n    We use the \"quantile\" strategy rather than the default strategy to ensure that\n        a) all bins are populated (otherwise the number of points on the curve could differ\n            for CBC and CBM, which can complicate  downstream metrics, like sum of squared errors)\n        b) get more towards a notion of expected calibration error, but locating points in places\n            on the x-axis (predicted probabilities) that the model actually PUTS points!\n    \"\"\"", "\n", "covariates", ",", "labels", "=", "(", "\n", "results_on_one_split", ".", "split_dataset", ".", "covariates_test", ",", "\n", "results_on_one_split", ".", "split_dataset", ".", "labels_test", ",", "\n", ")", "\n", "choices", "=", "np", ".", "argmax", "(", "labels", ",", "1", ")", "\n", "\n", "calibration_curve_results_by_link_for_category_probabilities", "=", "{", "}", "\n", "\n", "for", "link_for_category_probabilities", "in", "LINKS_FOR_CATEGORY_PROBABILITIES", ":", "\n", "        ", "beta", "=", "results_on_one_split", ".", "beta_mean", "\n", "\n", "category_probs", "=", "construct_category_probs", "(", "\n", "covariates", ",", "\n", "beta", ",", "\n", "link_for_category_probabilities", ",", "\n", ")", "\n", "\n", "choice_probs", "=", "np", ".", "array", "(", "\n", "[", "category_probs", "[", "i", ",", "choice", "]", "for", "(", "i", ",", "choice", ")", "in", "enumerate", "(", "choices", ")", "]", "\n", ")", "\n", "non_choice_probs", "=", "np", ".", "delete", "(", "\n", "category_probs", ",", "[", "(", "i", ",", "choice", ")", "for", "(", "i", ",", "choice", ")", "in", "enumerate", "(", "choices", ")", "]", "\n", ")", "\n", "\n", "choice_indicators", "=", "np", ".", "array", "(", "\n", "[", "1", "]", "*", "len", "(", "choice_probs", ")", "+", "[", "0", "]", "*", "len", "(", "non_choice_probs", ")", "\n", ")", "\n", "probs", "=", "np", ".", "hstack", "(", "(", "choice_probs", ",", "non_choice_probs", ")", ")", "\n", "\n", "fraction_of_positives", ",", "mean_predicted_prob", "=", "calibration_curve", "(", "\n", "choice_indicators", ",", "probs", ",", "n_bins", "=", "n_bins", ",", "strategy", "=", "\"quantile\"", "\n", ")", "\n", "calibration_curve_results", "=", "CalibrationCurveResults", "(", "\n", "fraction_of_positives", ",", "mean_predicted_prob", "\n", ")", "\n", "calibration_curve_results_by_link_for_category_probabilities", "[", "\n", "link_for_category_probabilities", "\n", "]", "=", "calibration_curve_results", "\n", "\n", "", "return", "calibration_curve_results_by_link_for_category_probabilities", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.calibration_analysis.compute_sum_of_squared_calibration_error_by_link_on_one_data_split": [[86, 105], ["numpy.sum"], "function", ["None"], ["", "def", "compute_sum_of_squared_calibration_error_by_link_on_one_data_split", "(", "\n", "calibration_curve_results_by_link_for_category_probabilities", ":", "Dict", "[", "\n", "Link", ",", "CalibrationCurveResults", "\n", "]", "\n", ")", "->", "Dict", "[", "Link", ",", "float", "]", ":", "\n", "    ", "\"\"\"\n    For each point sampled on the calibration curve, we compute the squared vertical distance to the y=x line.\n    We sum these up across sample points to get an overall metric of calibration error.\n    \"\"\"", "\n", "sse_by_link", "=", "{", "}", "\n", "for", "link", "in", "LINKS_FOR_CATEGORY_PROBABILITIES", ":", "\n", "        ", "ccr", "=", "calibration_curve_results_by_link_for_category_probabilities", "[", "link", "]", "\n", "x", "=", "ccr", ".", "mean_predicted_prob", "\n", "y", "=", "ccr", ".", "fraction_of_positives", "\n", "sse", "=", "np", ".", "sum", "(", "\n", "(", "x", "-", "y", ")", "**", "2", "\n", ")", "# sum of squared vertical distance from the y=x line of perfect calibration", "\n", "sse_by_link", "[", "link", "]", "=", "sse", "\n", "", "return", "sse_by_link", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.calibration_analysis.compute_sum_of_squared_calibration_errors_by_link_from_results_on_many_splits": [[107, 131], ["calibration_analysis.get_calibration_curve_results_on_one_data_split", "calibration_analysis.compute_sum_of_squared_calibration_error_by_link_on_one_data_split", "compute_sum_of_squared_calibration_error_by_link_on_one_data_split.items", "sses_by_link[].append"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.calibration_analysis.get_calibration_curve_results_on_one_data_split", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.calibration_analysis.compute_sum_of_squared_calibration_error_by_link_on_one_data_split"], ["", "def", "compute_sum_of_squared_calibration_errors_by_link_from_results_on_many_splits", "(", "\n", "results_on_many_splits", ":", "List", "[", "ResultsOnOneSplit", "]", ",", "\n", "n_bins", ":", "int", ",", "\n", ")", "->", "Dict", "[", "Link", ",", "List", "[", "float", "]", "]", ":", "\n", "    ", "\"\"\"\n    Returns:\n        a dictionary mapping the category probability link to a list of sum of squared calibration errors.\n        Each element in the list is that error for one data split\n    \"\"\"", "\n", "sses_by_link", "=", "{", "link", ":", "[", "]", "for", "link", "in", "LINKS_FOR_CATEGORY_PROBABILITIES", "}", "\n", "for", "results_on_one_split", "in", "results_on_many_splits", ":", "\n", "        ", "calibration_curve_results_by_link_for_category_probabilities", "=", "(", "\n", "get_calibration_curve_results_on_one_data_split", "(", "\n", "results_on_one_split", ",", "n_bins", "\n", ")", "\n", ")", "\n", "sse_by_link", "=", "(", "\n", "compute_sum_of_squared_calibration_error_by_link_on_one_data_split", "(", "\n", "calibration_curve_results_by_link_for_category_probabilities", "\n", ")", "\n", ")", "\n", "for", "link", ",", "sse", "in", "sse_by_link", ".", "items", "(", ")", ":", "\n", "            ", "sses_by_link", "[", "link", "]", ".", "append", "(", "sse", ")", "\n", "", "", "return", "sses_by_link", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.calibration_analysis.plot_calibration_curves_by_link_for_one_data_split": [[133, 161], ["matplotlib.figure", "matplotlib.subplot2grid", "plt.subplot2grid.plot", "calibration_curve_results_by_link_for_category_probabilities.items", "plt.subplot2grid.set_ylabel", "plt.subplot2grid.set_ylim", "plt.subplot2grid.legend", "plt.subplot2grid.set_title", "matplotlib.tight_layout", "matplotlib.show", "plt.subplot2grid.plot"], "function", ["None"], ["", "def", "plot_calibration_curves_by_link_for_one_data_split", "(", "\n", "calibration_curve_results_by_link_for_category_probabilities", ":", "Dict", "[", "\n", "Link", ",", "CalibrationCurveResults", "\n", "]", ",", "\n", ")", ":", "\n", "    ", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "10", ")", ")", "\n", "ax", "=", "plt", ".", "subplot2grid", "(", "(", "3", ",", "1", ")", ",", "(", "0", ",", "0", ")", ",", "rowspan", "=", "2", ")", "\n", "ax", ".", "plot", "(", "[", "0", ",", "1", "]", ",", "[", "0", ",", "1", "]", ",", "\"k:\"", ",", "label", "=", "\"Perfectly calibrated\"", ")", "\n", "\n", "for", "(", "\n", "link_for_category_probabilities", ",", "\n", "calibration_curve_results", ",", "\n", ")", "in", "calibration_curve_results_by_link_for_category_probabilities", ".", "items", "(", ")", ":", "\n", "        ", "ccr", "=", "calibration_curve_results", "\n", "ax", ".", "plot", "(", "\n", "ccr", ".", "mean_predicted_prob", ",", "\n", "ccr", ".", "fraction_of_positives", ",", "\n", "\"s-\"", ",", "\n", "label", "=", "\"%s\"", "%", "(", "link_for_category_probabilities", ".", "name", ",", ")", ",", "\n", ")", "\n", "\n", "", "ax", ".", "set_ylabel", "(", "\"Fraction of positives\"", ")", "\n", "ax", ".", "set_ylim", "(", "[", "-", "0.05", ",", "1.05", "]", ")", "\n", "ax", ".", "legend", "(", "loc", "=", "\"lower right\"", ")", "\n", "ax", ".", "set_title", "(", "\"Calibration plots  (reliability curve)\"", ")", "\n", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.calibration_analysis.plot_calibration_curves_for_one_data_split_at_a_time": [[163, 185], ["calibration_analysis.compute_sum_of_squared_calibration_errors_by_link_from_results_on_many_splits", "enumerate", "print", "calibration_analysis.get_calibration_curve_results_on_one_data_split", "calibration_analysis.plot_calibration_curves_by_link_for_one_data_split", "input"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.calibration_analysis.compute_sum_of_squared_calibration_errors_by_link_from_results_on_many_splits", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.calibration_analysis.get_calibration_curve_results_on_one_data_split", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.calibration_analysis.plot_calibration_curves_by_link_for_one_data_split"], ["", "def", "plot_calibration_curves_for_one_data_split_at_a_time", "(", "\n", "results_on_many_splits", ":", "List", "[", "ResultsOnOneSplit", "]", ",", "\n", "n_bins", ":", "int", ",", "\n", ")", ":", "\n", "    ", "sses_by_link", "=", "(", "\n", "compute_sum_of_squared_calibration_errors_by_link_from_results_on_many_splits", "(", "\n", "results_on_many_splits", ",", "n_bins", "\n", ")", "\n", ")", "\n", "for", "i", ",", "results_on_one_split", "in", "enumerate", "(", "results_on_many_splits", ")", ":", "\n", "        ", "print", "(", "\n", "f\"On this split, calibration sses were {sses_by_link[Link.CBC_PROBIT][i]:.03} for CBC and {sses_by_link[Link.CBM_PROBIT][i]:.03} for CBM\"", "\n", ")", "\n", "calibration_curve_results_by_link_for_category_probabilities", "=", "(", "\n", "get_calibration_curve_results_on_one_data_split", "(", "\n", "results_on_one_split", ",", "n_bins", "\n", ")", "\n", ")", "\n", "plot_calibration_curves_by_link_for_one_data_split", "(", "\n", "calibration_curve_results_by_link_for_category_probabilities", "\n", ")", "\n", "input", "(", "\"Press Enter to continue...\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.calibration_analysis.plot_CBM_calibration_advantage_curves": [[187, 235], ["matplotlib.figure", "matplotlib.subplot2grid", "len", "seaborn.color_palette", "enumerate", "plt.subplot2grid.set_xlabel", "plt.subplot2grid.set_ylabel", "matplotlib.legend", "matplotlib.hlines", "matplotlib.tight_layout", "matplotlib.show", "calibration_analysis.get_calibration_curve_results_on_one_data_split", "enumerate", "plt.subplot2grid.plot", "abs", "abs", "abs", "ys_snip.append", "xs.append", "ys.append", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.calibration_analysis.get_calibration_curve_results_on_one_data_split"], ["", "", "def", "plot_CBM_calibration_advantage_curves", "(", "\n", "results_on_many_splits", ":", "List", "[", "ResultsOnOneSplit", "]", ",", "\n", "n_bins", ":", "int", ",", "\n", ")", ":", "\n", "    ", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "10", ")", ")", "\n", "ax", "=", "plt", ".", "subplot2grid", "(", "(", "3", ",", "1", ")", ",", "(", "0", ",", "0", ")", ",", "rowspan", "=", "2", ")", "\n", "n_curves", "=", "len", "(", "results_on_many_splits", ")", "\n", "palette", "=", "sns", ".", "color_palette", "(", "None", ",", "n_curves", ")", "\n", "\n", "for", "(", "i", ",", "results_on_one_split", ")", "in", "enumerate", "(", "results_on_many_splits", ")", ":", "\n", "        ", "calibration_curve_results_by_link_for_category_probabilities", "=", "(", "\n", "get_calibration_curve_results_on_one_data_split", "(", "\n", "results_on_one_split", ",", "n_bins", "\n", ")", "\n", ")", "\n", "rbl", "=", "calibration_curve_results_by_link_for_category_probabilities", "\n", "pred_CBC", "=", "rbl", "[", "Link", ".", "CBC_PROBIT", "]", ".", "mean_predicted_prob", "\n", "pred_CBM", "=", "rbl", "[", "Link", ".", "CBM_PROBIT", "]", ".", "mean_predicted_prob", "\n", "actual_CBC", "=", "rbl", "[", "Link", ".", "CBC_PROBIT", "]", ".", "fraction_of_positives", "\n", "# actual_CBM = rbl[Link.CBC_PROBIT].fraction_of_positives", "\n", "actual", "=", "actual_CBC", "# they are the same (actual_CBM=actual_CBC)", "\n", "overshoot_CBM", "=", "pred_CBM", "-", "actual", "\n", "overshoot_CBC", "=", "pred_CBC", "-", "actual", "\n", "advantage_is_positive", "=", "abs", "(", "overshoot_CBM", ")", "<", "abs", "(", "overshoot_CBC", ")", "\n", "sign", "=", "advantage_is_positive", "*", "2", "-", "1", "\n", "advantage_CBM", "=", "abs", "(", "overshoot_CBC", "-", "overshoot_CBM", ")", "*", "sign", "\n", "\n", "# Merge locations which are identical", "\n", "xs", "=", "[", "]", "\n", "ys", "=", "[", "]", "\n", "ys_snip", "=", "[", "]", "\n", "x_prev", "=", "-", "np", ".", "inf", "\n", "for", "(", "j", ",", "x", ")", "in", "enumerate", "(", "actual", ")", ":", "\n", "            ", "ys_snip", ".", "append", "(", "advantage_CBM", "[", "j", "]", ")", "\n", "if", "x", "!=", "x_prev", ":", "\n", "                ", "xs", ".", "append", "(", "x", ")", "\n", "ys", ".", "append", "(", "np", ".", "mean", "(", "ys_snip", ")", ")", "\n", "ys_snip", "=", "[", "]", "\n", "", "x_prev", "=", "x", "\n", "\n", "", "ax", ".", "plot", "(", "xs", ",", "ys", ",", "color", "=", "palette", "[", "i", "]", ",", "label", "=", "i", ")", "\n", "\n", "", "ax", ".", "set_xlabel", "(", "\"Bin, indexed by empirical probability of category\"", ")", "\n", "ax", ".", "set_ylabel", "(", "\"CBM calibration advantage\"", ")", "\n", "plt", ".", "legend", "(", "title", "=", "\"Data fold\"", ")", "\n", "plt", ".", "hlines", "(", "0", ",", "0", ",", "1", ",", "color", "=", "\"k\"", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "show", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.plot_vi.make_plot_comparing_holdout_log_likes_for_ib_plus_sdo_vs_ib_plus_do": [[13, 50], ["len", "numpy.exp", "numpy.exp", "pandas.DataFrame", "seaborn.barplot", "matplotlib.legend", "matplotlib.show", "numpy.argsort", "numpy.argsort", "pandas.Series", "pandas.Series", "pandas.Series", "range"], "function", ["None"], ["def", "make_plot_comparing_holdout_log_likes_for_ib_plus_sdo_vs_ib_plus_do", "(", "\n", "holdout_loglikes", ":", "HoldoutLogLikes", ",", "\n", ")", ":", "\n", "\n", "    ", "n_splits", "=", "len", "(", "holdout_loglikes", ".", "ib_plus_sdo", ")", "\n", "geom_means_sdo", "=", "np", ".", "exp", "(", "holdout_loglikes", ".", "ib_plus_sdo", ")", "\n", "geom_means_do", "=", "np", ".", "exp", "(", "holdout_loglikes", ".", "ib_plus_do", ")", "\n", "diffs_in_geom_means", "=", "geom_means_sdo", "-", "geom_means_do", "\n", "\n", "geom_means_sdo_sorted", "=", "[", "geom_means_sdo", "[", "i", "]", "for", "i", "in", "np", ".", "argsort", "(", "diffs_in_geom_means", ")", "]", "\n", "geom_means_do_sorted", "=", "[", "geom_means_do", "[", "i", "]", "for", "i", "in", "np", ".", "argsort", "(", "diffs_in_geom_means", ")", "]", "\n", "\n", "geom_means", "=", "geom_means_do_sorted", "+", "geom_means_sdo_sorted", "\n", "model_type", "=", "[", "\"IB+CBC\"", "]", "*", "n_splits", "+", "[", "\"IB+CBM\"", "]", "*", "n_splits", "\n", "split_ids", "=", "[", "i", "+", "1", "for", "i", "in", "range", "(", "n_splits", ")", "]", "*", "2", "\n", "\n", "df", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "\"split id\"", ":", "pd", ".", "Series", "(", "split_ids", ")", ",", "\n", "\"holdout log-likelihood (geometric mean)\"", ":", "pd", ".", "Series", "(", "geom_means", ")", ",", "\n", "\"model_type\"", ":", "pd", ".", "Series", "(", "model_type", ")", ",", "\n", "}", "\n", ")", "\n", "\n", "sns", ".", "barplot", "(", "\n", "x", "=", "\"split id\"", ",", "\n", "y", "=", "\"holdout log-likelihood (geometric mean)\"", ",", "\n", "hue", "=", "\"model_type\"", ",", "\n", "data", "=", "df", ",", "\n", ")", "\n", "# https://stackoverflow.com/questions/4700614/how-to-put-the-legend-out-of-the-plot", "\n", "# we can supply a rectangle box that the whole subplots area (including legend) will fit into", "\n", "# plt.tight_layout(rect=[0, 0, 0.8, 0.95])", "\n", "# plt.legend(title=\"Model\", bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)", "\n", "# plt.title(\"Mean probability across occurrences of the RAREST overall category\")", "\n", "plt", ".", "legend", "(", "loc", "=", "\"upper right\"", ",", "frameon", "=", "False", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.glass_supplementary.plot_vi.make_violin_plot_of_differences_in_geometric_mean_log_likes_for_ib_plus_sdo_vs_ib_plus_do": [[52, 68], ["numpy.exp", "numpy.exp", "pandas.DataFrame", "seaborn.violinplot", "matplotlib.show", "pandas.Series"], "function", ["None"], ["", "def", "make_violin_plot_of_differences_in_geometric_mean_log_likes_for_ib_plus_sdo_vs_ib_plus_do", "(", "\n", "holdout_loglikes", ":", "HoldoutLogLikes", ",", "\n", ")", ":", "\n", "\n", "    ", "geom_means_sdo", "=", "np", ".", "exp", "(", "holdout_loglikes", ".", "ib_plus_sdo", ")", "\n", "geom_means_do", "=", "np", ".", "exp", "(", "holdout_loglikes", ".", "ib_plus_do", ")", "\n", "diffs_in_geom_means", "=", "geom_means_sdo", "-", "geom_means_do", "\n", "\n", "df", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "\"differences in geometric means\"", ":", "pd", ".", "Series", "(", "diffs_in_geom_means", ")", ",", "\n", "}", "\n", ")", "\n", "\n", "sns", ".", "violinplot", "(", "x", "=", "\"differences in geometric means\"", ",", "data", "=", "df", ")", "\n", "plt", ".", "show", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.quality_of_posterior_predictive.helpers.sample_beta_cavi": [[40, 55], ["numpy.random.seed", "numpy.sqrt", "numpy.shape", "numpy.zeros_like", "range", "numpy.diag", "numpy.random.normal"], "function", ["None"], ["", "def", "sample_beta_cavi", "(", "beta_mean", ",", "beta_cov_across_M_for_all_K", ",", "seed", ")", ":", "\n", "    ", "\"\"\"\n    beta_mean: (M,K)\n    beta_cov_across_M_for_all_K: (M,M)  (uniform across K)\n    \"\"\"", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "beta_stds_across_M_for_all_K", "=", "np", ".", "sqrt", "(", "np", ".", "diag", "(", "beta_cov_across_M_for_all_K", ")", ")", "\n", "M", ",", "K", "=", "np", ".", "shape", "(", "beta_mean", ")", "\n", "beta_matrix_sample", "=", "np", ".", "zeros_like", "(", "beta_mean", ")", "\n", "for", "k", "in", "range", "(", "K", ")", ":", "\n", "        ", "beta_matrix_sample", "[", ":", ",", "k", "]", "=", "np", ".", "random", ".", "normal", "(", "\n", "loc", "=", "beta_mean", "[", ":", ",", "k", "]", ",", "scale", "=", "beta_stds_across_M_for_all_K", "\n", ")", "\n", "", "return", "beta_matrix_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.quality_of_posterior_predictive.helpers.sample_beta_advi": [[57, 72], ["numpy.random.seed", "numpy.shape", "numpy.zeros_like", "range", "range", "numpy.random.normal"], "function", ["None"], ["", "def", "sample_beta_advi", "(", "beta_mean", ",", "beta_stds", ",", "seed", ")", ":", "\n", "    ", "\"\"\"\n    beta_mean: (M,L), where L in {K-1, K} depending on link function\n    beta_stds: (M,L), where L in {K-1, K} depending on link function\n    \"\"\"", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "\n", "M", ",", "L", "=", "np", ".", "shape", "(", "beta_mean", ")", "\n", "beta_matrix_sample", "=", "np", ".", "zeros_like", "(", "beta_mean", ")", "\n", "for", "m", "in", "range", "(", "M", ")", ":", "\n", "        ", "for", "l", "in", "range", "(", "L", ")", ":", "\n", "            ", "beta_matrix_sample", "[", "m", ",", "l", "]", "=", "np", ".", "random", ".", "normal", "(", "\n", "loc", "=", "beta_mean", "[", "m", ",", "l", "]", ",", "scale", "=", "beta_stds", "[", "m", ",", "l", "]", "\n", ")", "\n", "", "", "return", "beta_matrix_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.quality_of_posterior_predictive.helpers.cat_prob_samples_from_beta_samples": [[79, 98], ["numpy.shape", "numpy.zeros", "range", "numpy.shape", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_category_probs", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_category_probs"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs"], ["", "def", "cat_prob_samples_from_beta_samples", "(", "\n", "feature_vector", ",", "beta_samples", ":", "NumpyArray3D", ",", "link", ":", "Link", "\n", ")", "->", "NumpyArray2D", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        beta_samples : array of shape (S,M,L)\n            where S is the num of samples from the posterior, M is the num of covariates (incl intercept), and L\n            is the number of \"free\" categories (i.e. those without an identifiability constraint imposed)\n    \"\"\"", "\n", "num_mcmc_samples", ",", "_", ",", "L", "=", "np", ".", "shape", "(", "beta_samples", ")", "\n", "K", "=", "np", ".", "shape", "(", "construct_category_probs", "(", "feature_vector", ",", "beta_samples", "[", "0", ",", ":", ",", ":", "]", ",", "link", ")", ")", "[", "\n", "1", "\n", "]", "\n", "cat_prob_samples", "=", "np", ".", "zeros", "(", "(", "num_mcmc_samples", ",", "K", ")", ")", "\n", "for", "i", "in", "range", "(", "num_mcmc_samples", ")", ":", "\n", "        ", "cat_prob_samples", "[", "i", ",", ":", "]", "=", "construct_category_probs", "(", "\n", "feature_vector", ",", "beta_samples", "[", "i", ",", ":", ",", ":", "]", ",", "link", "\n", ")", "\n", "", "return", "cat_prob_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.quality_of_posterior_predictive.helpers.construct_cat_prob_data_by_method": [[100, 113], ["dict", "beta_samples_and_link_by_method.items", "helpers.cat_prob_samples_from_beta_samples", "helpers.CatProbData"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.quality_of_posterior_predictive.helpers.cat_prob_samples_from_beta_samples"], ["", "def", "construct_cat_prob_data_by_method", "(", "\n", "feature_vector", ",", "beta_samples_and_link_by_method", ":", "Dict", "[", "str", ",", "BetaSamplesAndLink", "]", "\n", ")", "->", "Dict", "[", "str", ",", "CatProbData", "]", ":", "\n", "    ", "cat_prob_data_by_method", "=", "dict", "(", ")", "\n", "for", "method", ",", "beta_samples_and_link", "in", "beta_samples_and_link_by_method", ".", "items", "(", ")", ":", "\n", "        ", "bsl", "=", "beta_samples_and_link", "\n", "cat_prob_samples", "=", "cat_prob_samples_from_beta_samples", "(", "\n", "feature_vector", ",", "bsl", ".", "samples", ",", "bsl", ".", "link", "\n", ")", "\n", "cat_prob_data_by_method", "[", "method", "]", "=", "CatProbData", "(", "\n", "feature_vector", ",", "cat_prob_samples", ",", "bsl", ".", "link", "\n", ")", "\n", "", "return", "cat_prob_data_by_method", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.quality_of_posterior_predictive.helpers.add_bma_to_cat_prob_data_by_method": [[115, 145], ["numpy.zeros_like", "range", "helpers.CatProbData", "len", "ValueError"], "function", ["None"], ["", "def", "add_bma_to_cat_prob_data_by_method", "(", "\n", "cat_prob_data_by_method", ":", "Dict", "[", "str", ",", "CatProbData", "]", ",", "\n", "CBC_weight", ":", "float", ",", "\n", "ib_model", ":", "IB_Model", ",", "\n", ")", "->", "Dict", "[", "str", ",", "CatProbData", "]", ":", "\n", "# TODO: Make method+link an actual class so we don't have to get the", "\n", "# strings exactly right", "\n", "    ", "if", "ib_model", "==", "IB_Model", ".", "PROBIT", ":", "\n", "        ", "cbc_method", "=", "\"CBC_PROBIT+IB-CAVI\"", "\n", "cbm_method", "=", "\"CBM_PROBIT+IB-CAVI\"", "\n", "bma_method", "=", "\"BMA_PROBIT+IB-CAVI\"", "\n", "bma_link", "=", "Link", ".", "BMA_PROBIT", "\n", "", "elif", "ib_model", "==", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "cbc_method", "=", "\"CBC_LOGIT+IB-CAVI\"", "\n", "cbm_method", "=", "\"CBM_LOGIT+IB-CAVI\"", "\n", "bma_method", "=", "\"BMA_LOGIT+IB-CAVI\"", "\n", "bma_link", "=", "Link", ".", "BMA_LOGIT", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"What is the ib_model?!\"", ")", "\n", "\n", "", "feature_vector", "=", "cat_prob_data_by_method", "[", "cbc_method", "]", ".", "feature_vector", "\n", "samples_BMA", "=", "np", ".", "zeros_like", "(", "cat_prob_data_by_method", "[", "cbc_method", "]", ".", "samples", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "samples_BMA", ")", ")", ":", "\n", "        ", "probs_CBC", "=", "cat_prob_data_by_method", "[", "cbc_method", "]", ".", "samples", "[", "i", "]", "\n", "probs_CBM", "=", "cat_prob_data_by_method", "[", "cbm_method", "]", ".", "samples", "[", "i", "]", "\n", "probs_BMA", "=", "CBC_weight", "*", "probs_CBC", "+", "(", "1", "-", "CBC_weight", ")", "*", "probs_CBM", "\n", "samples_BMA", "[", "i", "]", "=", "probs_BMA", "\n", "", "cat_prob_data_with_bma", "=", "CatProbData", "(", "feature_vector", ",", "samples_BMA", ",", "bma_link", ")", "\n", "cat_prob_data_by_method", "[", "bma_method", "]", "=", "cat_prob_data_with_bma", "\n", "return", "cat_prob_data_by_method", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.quality_of_posterior_predictive.helpers.make_df_of_sampled_category_probs_for_each_method_and_covariate_vector": [[147, 200], ["collections.defaultdict", "list", "pandas.DataFrame", "pandas.Categorical", "pandas.Categorical", "colors_by_methods_to_plot.keys", "print", "numpy.array", "helpers.construct_cat_prob_data_by_method", "helpers.add_bma_to_cat_prob_data_by_method", "range", "range", "d[].append", "d[].append", "d[].append", "d[].append"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.quality_of_posterior_predictive.helpers.construct_cat_prob_data_by_method", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.quality_of_posterior_predictive.helpers.add_bma_to_cat_prob_data_by_method"], ["", "def", "make_df_of_sampled_category_probs_for_each_method_and_covariate_vector", "(", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "CBC_weight", ":", "float", ",", "\n", "beta_samples_and_link_by_method", ":", "Dict", "[", "str", ",", "BetaSamplesAndLink", "]", ",", "\n", "example_idxs", ":", "List", "[", "int", "]", ",", "\n", "colors_by_methods_to_plot", ":", "Dict", "[", "str", ",", "str", "]", ",", "\n", "n_categories", ":", "int", ",", "\n", "num_mcmc_samples", ":", "int", ",", "\n", "ib_model", ":", "IB_Model", ",", "\n", ")", "->", "DataFrame", ":", "\n", "\n", "# TODO: Autoinfer `n_categories` and `num_mcmc_samples`", "\n", "\n", "    ", "d", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "\n", "###", "\n", "# Make flattened dataframe of posterior category prob samples for each sample (example) in example_idx", "\n", "###", "\n", "\n", "K", "=", "n_categories", "\n", "methods", "=", "list", "(", "colors_by_methods_to_plot", ".", "keys", "(", ")", ")", "\n", "\n", "for", "example_idx", "in", "example_idxs", ":", "\n", "        ", "print", "(", "\n", "f\"Obtaining sampled posterior category probabilities for example index {example_idx}\"", "\n", ")", "\n", "\n", "###", "\n", "# Get posterior samples of category probs for one feature vector", "\n", "###", "\n", "feature_vector", "=", "np", ".", "array", "(", "[", "covariates", "[", "example_idx", ",", ":", "]", "]", ")", "\n", "cat_prob_data_by_method", "=", "construct_cat_prob_data_by_method", "(", "\n", "feature_vector", ",", "beta_samples_and_link_by_method", "\n", ")", "\n", "\n", "cat_prob_data_by_method", "=", "add_bma_to_cat_prob_data_by_method", "(", "\n", "cat_prob_data_by_method", ",", "\n", "CBC_weight", ",", "\n", "ib_model", ",", "\n", ")", "\n", "\n", "for", "k", "in", "range", "(", "K", ")", ":", "\n", "# TODO: auto infer num mcmc samples", "\n", "            ", "for", "i", "in", "range", "(", "num_mcmc_samples", ")", ":", "\n", "                ", "for", "method", "in", "methods", ":", "\n", "                    ", "d", "[", "\"prob\"", "]", ".", "append", "(", "cat_prob_data_by_method", "[", "method", "]", ".", "samples", "[", "i", ",", "k", "]", ")", "\n", "d", "[", "\"category\"", "]", ".", "append", "(", "k", "+", "1", ")", "\n", "d", "[", "\"method\"", "]", ".", "append", "(", "method", ")", "\n", "d", "[", "\"example\"", "]", ".", "append", "(", "example_idx", ")", "\n", "", "", "", "", "df", "=", "pd", ".", "DataFrame", "(", "d", ")", "\n", "df", "[", "\"method\"", "]", "=", "pd", ".", "Categorical", "(", "df", ".", "method", ")", "# necessary?", "\n", "df", "[", "\"category\"", "]", "=", "pd", ".", "Categorical", "(", "df", ".", "category", ")", "# necessary?", "\n", "return", "df", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_density_normal_plus": [[26, 46], ["isinstance", "scipy.stats.norm().pdf", "scipy.stats.norm().pdf", "scipy.stats.norm().cdf", "scipy.stats.norm().cdf", "scipy.stats.norm", "scipy.stats.norm", "scipy.stats.norm", "scipy.stats.norm"], "function", ["None"], ["def", "compute_density_normal_plus", "(", "mu", ":", "float", ",", "x", ":", "Union", "[", "float", ",", "Iterable", "]", ")", ":", "\n", "    ", "\"\"\"\n    \"Normal plus\" is the distribution obtained by taking a univariate normal distribution with mean mu and sd 1\n    and THEN left truncating it at 0.\n\n    Arguments:\n        mu: The expected value of the PARENT gaussian distribution (i.e., pre-truncation)\n        x: The point or points at which we wish to take the density\n\n    Returns:\n        The density of the truncated distribution, evaluated at x\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "x", ",", "Iterable", ")", ":", "\n", "        ", "if", "x", "<", "0", ":", "\n", "            ", "return", "0.0", "\n", "", "return", "norm", "(", "mu", ",", "1", ")", ".", "pdf", "(", "x", ")", "/", "(", "1", "-", "norm", "(", "mu", ",", "1", ")", ".", "cdf", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "        ", "densities", "=", "norm", "(", "mu", ",", "1", ")", ".", "pdf", "(", "x", ")", "/", "(", "1", "-", "norm", "(", "mu", ",", "1", ")", ".", "cdf", "(", "0", ")", ")", "\n", "densities", "[", "x", "<", "0", "]", "=", "0.0", "\n", "return", "densities", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_density_normal_minus": [[48, 68], ["isinstance", "scipy.stats.norm().pdf", "scipy.stats.norm().cdf", "scipy.stats.norm().pdf", "scipy.stats.norm().cdf", "scipy.stats.norm", "scipy.stats.norm", "scipy.stats.norm", "scipy.stats.norm"], "function", ["None"], ["", "", "def", "compute_density_normal_minus", "(", "mu", ":", "float", ",", "x", ":", "Union", "[", "float", ",", "Iterable", "]", ")", ":", "\n", "    ", "\"\"\"\n    \"Normal minus\" is the distribution obtained by taking a univariate normal distribution with mean mu and sd 1\n    and THEN right truncating it at 0.\n\n    Arguments:\n        mu: The expected value of the PARENT gaussian distribution (i.e., pre-truncation)\n        x: The point or points at which we wish to take the density\n\n    Returns:\n        The density of the truncated distribution, evaluated at x\n    \"\"\"", "\n", "if", "not", "isinstance", "(", "x", ",", "Iterable", ")", ":", "\n", "        ", "if", "x", ">", "0", ":", "\n", "            ", "return", "0.0", "\n", "", "return", "norm", "(", "mu", ",", "1", ")", ".", "pdf", "(", "x", ")", "/", "norm", "(", "mu", ",", "1", ")", ".", "cdf", "(", "0", ")", "\n", "", "else", ":", "\n", "        ", "densities", "=", "norm", "(", "mu", ",", "1", ")", ".", "pdf", "(", "x", ")", "/", "norm", "(", "mu", ",", "1", ")", ".", "cdf", "(", "0", ")", "\n", "densities", "[", "x", ">", "0", "]", "=", "0.0", "\n", "return", "densities", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_mean_shift_normal_plus": [[70, 94], ["numpy.sqrt", "numpy.exp", "scipy.stats.norm.logpdf", "categorical_from_binary.math.logdiffexp", "scipy.stats.norm.logcdf"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.math.logdiffexp"], ["", "", "def", "compute_mean_shift_normal_plus", "(", "mu", ":", "float", ",", "var", ":", "Optional", "[", "float", "]", "=", "None", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    \"Normal plus\" is the distribution obtained by taking a univariate normal distribution with mean mu and variance var\n    and THEN left truncating it at 0.\n\n    Arguments:\n        mu: The expected value of the PARENT gaussian distribution (i.e., pre-truncation)\n        var: The variance of the PARENT gaussian distribution (i.e., pre-truncation)\n\n    Returns:\n        The \"mean shift\", i.e. the difference between the mean of the truncated random variable\n        and the mean of the parent random variable.\n\n        In other words, we return E[X]-mu, where X ~ N_+(mu, 1)\n    \"\"\"", "\n", "if", "var", "is", "None", ":", "\n", "        ", "var", "=", "1.0", "\n", "\n", "", "std", "=", "np", ".", "sqrt", "(", "var", ")", "\n", "snr", "=", "mu", "/", "std", "# signal noise ratio", "\n", "# more intutively, the return value of the computation is", "\n", "#   (norm.pdf(-snr) / (1 - norm.cdf(-snr))) * std", "\n", "# but this can lead to numerical precision issues", "\n", "return", "np", ".", "exp", "(", "norm", ".", "logpdf", "(", "-", "snr", ")", "-", "logdiffexp", "(", "0", ",", "norm", ".", "logcdf", "(", "-", "snr", ")", ")", ")", "*", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_mean_shift_normal_minus": [[96, 120], ["numpy.sqrt", "numpy.exp", "scipy.stats.norm.logpdf", "scipy.stats.norm.logcdf"], "function", ["None"], ["", "def", "compute_mean_shift_normal_minus", "(", "mu", ":", "float", ",", "var", ":", "Optional", "[", "float", "]", "=", "None", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    \"Normal minus\" is the distribution obtained by taking a univariate  normal distribution with mean mu and variance var\n    and THEN right truncating it at 0.\n\n    Arguments:\n        mu: The expected value of the PARENT gaussian distribution (i.e., pre-truncation)\n        var: The variance of the PARENT gaussian distribution (i.e., pre-truncation)\n\n    Returns:\n        The \"mean shift\", i.e. the difference between the mean of the truncated random variable\n        and the mean of the parent random variable.\n\n        In other words, we return E[X]-mu, where X ~ N_-(mu, 1)\n    \"\"\"", "\n", "if", "var", "is", "None", ":", "\n", "        ", "var", "=", "1.0", "\n", "\n", "", "std", "=", "np", ".", "sqrt", "(", "var", ")", "\n", "snr", "=", "mu", "/", "std", "# signal noise ratio", "\n", "# more intutively, the return value of the computation is", "\n", "#   (-norm.pdf(-snr) / norm.cdf(-snr)) * std", "\n", "# but this can lead to numerical precision issues", "\n", "return", "-", "np", ".", "exp", "(", "norm", ".", "logpdf", "(", "-", "snr", ")", "-", "norm", ".", "logcdf", "(", "-", "snr", ")", ")", "*", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_expected_value_normal_plus": [[122, 138], ["trunc_norm.compute_mean_shift_normal_plus"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_mean_shift_normal_plus"], ["", "def", "compute_expected_value_normal_plus", "(", "mu", ":", "float", ",", "var", ":", "Optional", "[", "float", "]", "=", "None", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    \"Normal plus\" is the distribution obtained by taking a univariate normal distribution with mean mu and variance var\n    and THEN left truncating it at 0.\n\n    Arguments:\n        mu: The expected value of the PARENT gaussian distribution (i.e., pre-truncation)\n        var: The variance of the PARENT gaussian distribution (i.e., pre-truncation)\n\n    Returns:\n        The expected value of a random variable following a normal plus distribution\n    \"\"\"", "\n", "if", "var", "is", "None", ":", "\n", "        ", "var", "=", "1.0", "\n", "", "mean_shift", "=", "compute_mean_shift_normal_plus", "(", "mu", ",", "var", ")", "\n", "return", "mu", "+", "mean_shift", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_expected_value_normal_minus": [[140, 158], ["trunc_norm.compute_mean_shift_normal_minus"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_mean_shift_normal_minus"], ["", "def", "compute_expected_value_normal_minus", "(", "\n", "mu", ":", "float", ",", "var", ":", "Optional", "[", "float", "]", "=", "None", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    \"Normal minus\" is the distribution obtained by taking a univariate normal distribution with mean mu and variance var\n    and THEN right truncating it at 0.\n\n    Arguments:\n        mu: The expected value of the PARENT gaussian distribution (i.e., pre-truncation)\n        var: The variance of the PARENT gaussian distribution (i.e., pre-truncation)\n\n    Returns:\n        The expected value of a random variable following a normal minus distribution\n    \"\"\"", "\n", "if", "var", "is", "None", ":", "\n", "        ", "var", "=", "1.0", "\n", "", "mean_shift", "=", "compute_mean_shift_normal_minus", "(", "mu", ",", "var", ")", "\n", "return", "mu", "+", "mean_shift", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_variance_normal_plus": [[160, 177], ["trunc_norm.compute_mean_shift_normal_plus"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_mean_shift_normal_plus"], ["", "def", "compute_variance_normal_plus", "(", "mu", ":", "float", ",", "var", ":", "Optional", "[", "float", "]", "=", "None", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    \"Normal plus\" is the distribution obtained by taking a univariate normal distribution with mean mu and variance var\n    and THEN left truncating it at 0.\n\n    Arguments:\n        mu: The expected value of the PARENT gaussian distribution (i.e., pre-truncation)\n        var: The variance of the PARENT gaussian distribution (i.e., pre-truncation)\n\n    Returns:\n        The variance of the truncated distribution\n    \"\"\"", "\n", "if", "var", "is", "None", ":", "\n", "        ", "var", "=", "1.0", "\n", "\n", "", "expectation_shift", "=", "compute_mean_shift_normal_plus", "(", "mu", ",", "var", ")", "\n", "return", "var", "-", "mu", "*", "expectation_shift", "-", "expectation_shift", "**", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_variance_normal_minus": [[179, 195], ["trunc_norm.compute_mean_shift_normal_minus"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_mean_shift_normal_minus"], ["", "def", "compute_variance_normal_minus", "(", "mu", ":", "float", ",", "var", ":", "Optional", "[", "float", "]", "=", "None", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    \"Normal minus\" is the distribution obtained by taking a univariate normal distribution with mean mu and variance var\n    and THEN right truncating it at 0.\n\n    Arguments:\n        mu: The expected value of the PARENT gaussian distribution (i.e., pre-truncation)\n        var: The variance of the PARENT gaussian distribution (i.e., pre-truncation)\n\n    Returns:\n        The variance of the truncated distribution\n    \"\"\"", "\n", "if", "var", "is", "None", ":", "\n", "        ", "var", "=", "1.0", "\n", "", "expectation_shift", "=", "compute_mean_shift_normal_minus", "(", "mu", ",", "var", ")", "\n", "return", "var", "-", "mu", "*", "expectation_shift", "-", "expectation_shift", "**", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_entropy_normal_plus": [[197, 212], ["trunc_norm.compute_expected_value_normal_plus", "numpy.log", "numpy.sqrt", "scipy.stats.norm.cdf"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_expected_value_normal_plus"], ["", "def", "compute_entropy_normal_plus", "(", "mu", ":", "float", ")", ":", "\n", "    ", "\"\"\"\n    \"Normal plus\" is the distribution obtained by taking a univariate normal distribution with mean mu and sd 1\n    and THEN left truncating it at 0.\n\n    Arguments:\n        mu: The expected value of the PARENT gaussian distribution (i.e., pre-truncation)\n\n    Returns:\n        The entropy of the truncated distribution\n    \"\"\"", "\n", "expectation_shift", "=", "compute_expected_value_normal_plus", "(", "mu", ")", "-", "mu", "\n", "return", "(", "\n", "np", ".", "log", "(", "np", ".", "sqrt", "(", "2", "*", "np", ".", "pi", "*", "np", ".", "e", ")", "*", "(", "1", "-", "norm", ".", "cdf", "(", "-", "mu", ")", ")", ")", "\n", "-", "mu", "*", "expectation_shift", "/", "2", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_entropy_normal_minus": [[215, 229], ["trunc_norm.compute_expected_value_normal_minus", "numpy.log", "numpy.sqrt", "scipy.stats.norm.cdf"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_expected_value_normal_minus"], ["", "def", "compute_entropy_normal_minus", "(", "mu", ":", "float", ")", ":", "\n", "    ", "\"\"\"\n    \"Normal minus\" is the distribution obtained by taking a univariate normal distribution with mean mu and sd 1\n    and THEN right truncating it at 0.\n\n    Arguments:\n        mu: The expected value of the PARENT gaussian distribution (i.e., pre-truncation)\n\n    Returns:\n        The variance of the truncated distribution\n    \"\"\"", "\n", "expectation_shift", "=", "compute_expected_value_normal_minus", "(", "mu", ")", "-", "mu", "\n", "return", "(", "\n", "np", ".", "log", "(", "np", ".", "sqrt", "(", "2", "*", "np", ".", "pi", "*", "np", ".", "e", ")", "*", "norm", ".", "cdf", "(", "-", "mu", ")", ")", "-", "mu", "*", "expectation_shift", "/", "2", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_inv_cdf_normal_plus": [[232, 247], ["scipy.stats.norm", "scipy.stats.norm.ppf", "scipy.stats.norm.cdf", "scipy.stats.norm.cdf"], "function", ["None"], ["", "def", "compute_inv_cdf_normal_plus", "(", "mu", ":", "float", ",", "p", ":", "Union", "[", "float", ",", "np", ".", "array", "]", ")", ":", "\n", "    ", "\"\"\"\n    \"Normal plus\" is the distribution obtained by taking a univariate normal distribution with mean mu and sd 1\n    and THEN left truncating it at 0.\n\n    Arguments:\n        mu: The expected value of the PARENT gaussian distribution (i.e., pre-truncation)\n        p: The percentile or percentiles whose inverse we want to compute\n\n    Returns:\n        The inverse cdf of the truncated distribution at percentile p\n    \"\"\"", "\n", "parent", "=", "norm", "(", "mu", ",", "1", ")", "\n", "# ppf is what scipy.stats calls an inverse cdf", "\n", "return", "parent", ".", "ppf", "(", "parent", ".", "cdf", "(", "0", ")", "+", "p", "*", "(", "1", "-", "parent", ".", "cdf", "(", "0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_inv_cdf_normal_minus": [[249, 264], ["scipy.stats.norm", "scipy.stats.norm.ppf", "scipy.stats.norm.cdf"], "function", ["None"], ["", "def", "compute_inv_cdf_normal_minus", "(", "mu", ":", "float", ",", "p", ":", "Union", "[", "float", ",", "np", ".", "array", "]", ")", ":", "\n", "    ", "\"\"\"\n    \"Normal minus\" is the distribution obtained by taking a univariate normal distribution with mean mu and sd 1\n    and THEN right truncating it at 0.\n\n    Arguments:\n        mu: The expected value of the PARENT gaussian distribution (i.e., pre-truncation)\n        p: The percentile or percentiles whose inverse we want to compute\n\n    Returns:\n        The inverse cdf of the truncated distribution at percentile p\n    \"\"\"", "\n", "parent", "=", "norm", "(", "mu", ",", "1", ")", "\n", "# ppf is what scipy.stats calls an inverse cdf", "\n", "return", "parent", ".", "ppf", "(", "p", "*", "parent", ".", "cdf", "(", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.sample_normal_plus": [[266, 292], ["scipy.stats.uniform.rvs", "trunc_norm.compute_inv_cdf_normal_plus"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_inv_cdf_normal_plus"], ["", "def", "sample_normal_plus", "(", "\n", "mu", ":", "float", ",", "\n", "size", ":", "Optional", "[", "Union", "[", "int", ",", "Tuple", "[", "int", "]", "]", "]", "=", "None", ",", "\n", "random_state", ":", "Optional", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    \"Normal plus\" is the distribution obtained by taking a univariate normal distribution with mean mu and sd 1\n    and THEN left truncating it at 0.\n\n    Arguments:\n        mu: The expected value of the PARENT gaussian distribution (i.e., pre-truncation)\n        size : int or tuple of ints, optional\n            Defining number of random variates (default is 1).\n        random_state : {None, int, `~np.random.RandomState`, `~np.random.Generator`}, optional\n            If `seed` is `None` the `~np.random.RandomState` singleton is used.\n            If `seed` is an int, a new ``RandomState`` instance is used, seeded\n            with seed.\n            If `seed` is already a ``RandomState`` or ``Generator`` instance,\n            then that object is used.\n            Default is None.\n\n    Returns:\n        A random sample of size `size` from the Normal plus distribution\n    \"\"\"", "\n", "uniform_samples", "=", "uniform", ".", "rvs", "(", "size", "=", "size", ",", "random_state", "=", "random_state", ")", "\n", "return", "compute_inv_cdf_normal_plus", "(", "mu", ",", "uniform_samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.sample_normal_minus": [[294, 320], ["scipy.stats.uniform.rvs", "trunc_norm.compute_inv_cdf_normal_minus"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_inv_cdf_normal_minus"], ["", "def", "sample_normal_minus", "(", "\n", "mu", ":", "float", ",", "\n", "size", ":", "Optional", "[", "Union", "[", "int", ",", "Tuple", "[", "int", "]", "]", "]", "=", "None", ",", "\n", "random_state", ":", "Optional", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    \"Normal minus\" is the distribution obtained by taking a univariate normal distribution with mean mu and sd 1\n    and THEN right truncating it at 0.\n\n    Arguments:\n        mu: The expected value of the PARENT gaussian distribution (i.e., pre-truncation)\n        size : int or tuple of ints, optional\n            Defining number of random variates (default is 1).\n        random_state : {None, int, `~np.random.RandomState`, `~np.random.Generator`}, optional\n            If `seed` is `None` the `~np.random.RandomState` singleton is used.\n            If `seed` is an int, a new ``RandomState`` instance is used, seeded\n            with seed.\n            If `seed` is already a ``RandomState`` or ``Generator`` instance,\n            then that object is used.\n            Default is None.\n\n    Returns:\n        A random sample of size `size` from the Normal minus distribution\n    \"\"\"", "\n", "uniform_samples", "=", "uniform", ".", "rvs", "(", "size", "=", "size", ",", "random_state", "=", "random_state", ")", "\n", "return", "compute_inv_cdf_normal_minus", "(", "mu", ",", "uniform_samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.sample_from_a_normal_plus_distribution_with_non_unity_parent_standard_deviation": [[322, 357], ["list", "list", "scipy.stats.truncnorm.rvs", "compute_a", "compute_b", "len", "zip", "zip", "len"], "function", ["None"], ["", "def", "sample_from_a_normal_plus_distribution_with_non_unity_parent_standard_deviation", "(", "\n", "mu", ":", "Union", "[", "float", ",", "Iterable", "[", "float", "]", "]", ",", "\n", "sigma", ":", "Union", "[", "float", ",", "Iterable", "[", "float", "]", "]", ",", "\n", ")", "->", "Union", "[", "float", ",", "NumpyArray1D", "]", ":", "\n", "    ", "\"\"\"\n    An alternate method for sampling from the normal plus distribution.  Advantages over `sample_normal_plus`:\n        1. Allows for drawing  multiple samples simultaneously.  Draws a single sample for each value of mu\n        2. Can sample from truncated normal whose parent standard deviation is something other than 1.\n\n    Documentation:\n        https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.truncnorm.html\n\n    Arguments:\n        mu: The expected value(s) of the PARENT gaussian distribution (i.e., pre-truncation)\n        sigma: The standard deviation(s) of the PARENT gaussian distribution (i.e., pre-truncation)\n\n    Returns:\n        Float if mu was float, np.array if mu was iterable\n    \"\"\"", "\n", "lower", "=", "0", "\n", "upper", "=", "np", ".", "inf", "\n", "\n", "mus", "=", "list", "(", "mu", ")", "\n", "sigmas", "=", "list", "(", "sigma", ")", "\n", "\n", "compute_a", "=", "lambda", "mu", ",", "sigma", ":", "(", "lower", "-", "mu", ")", "/", "sigma", "\n", "compute_b", "=", "lambda", "mu", ",", "sigma", ":", "(", "upper", "-", "mu", ")", "/", "sigma", "\n", "a_vec", "=", "[", "compute_a", "(", "mu", ",", "sigma", ")", "for", "(", "mu", ",", "sigma", ")", "in", "zip", "(", "mus", ",", "sigmas", ")", "]", "\n", "b_vec", "=", "[", "compute_b", "(", "mu", ",", "sigma", ")", "for", "(", "mu", ",", "sigma", ")", "in", "zip", "(", "mus", ",", "sigmas", ")", "]", "\n", "\n", "samples", "=", "truncnorm", ".", "rvs", "(", "a_vec", ",", "b_vec", ",", "loc", "=", "mus", ",", "scale", "=", "sigmas", ",", "size", "=", "len", "(", "mus", ")", ")", "\n", "\n", "if", "len", "(", "samples", ")", "==", "1", ":", "\n", "        ", "return", "samples", "[", "0", "]", "\n", "", "return", "samples", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.sample_from_a_normal_minus_distribution_with_non_unity_parent_standard_deviation": [[359, 395], ["list", "list", "scipy.stats.truncnorm.rvs", "compute_a", "compute_b", "len", "zip", "zip", "len"], "function", ["None"], ["", "def", "sample_from_a_normal_minus_distribution_with_non_unity_parent_standard_deviation", "(", "\n", "mu", ":", "Union", "[", "float", ",", "Iterable", "[", "float", "]", "]", ",", "\n", "sigma", ":", "Union", "[", "float", ",", "Iterable", "[", "float", "]", "]", ",", "\n", ")", "->", "Union", "[", "float", ",", "NumpyArray1D", "]", ":", "\n", "    ", "\"\"\"\n    An alternate method for sampling from the normal minus distribution.  Advantages over `sample_normal_minus`:\n        1. Allows for drawing  multiple samples simultaneously.  Draws a single sample for each value of mu\n        2. Can sample from truncated normal whose parent standard deviation is something other than 1.\n\n    Documentation:\n        https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.truncnorm.html\n\n    Arguments:\n        mu: The expected value(s) of the PARENT gaussian distribution (i.e., pre-truncation)\n        sigma: The standard deviation(s) of the PARENT gaussian distribution (i.e., pre-truncation)\n\n    Returns:\n        Float if mu was float, np.array if mu was iterable\n    \"\"\"", "\n", "\n", "lower", "=", "-", "np", ".", "inf", "\n", "upper", "=", "0", "\n", "\n", "mus", "=", "list", "(", "mu", ")", "\n", "sigmas", "=", "list", "(", "sigma", ")", "\n", "\n", "compute_a", "=", "lambda", "mu", ",", "sigma", ":", "(", "lower", "-", "mu", ")", "/", "sigma", "\n", "compute_b", "=", "lambda", "mu", ",", "sigma", ":", "(", "upper", "-", "mu", ")", "/", "sigma", "\n", "a_vec", "=", "[", "compute_a", "(", "mu", ",", "sigma", ")", "for", "(", "mu", ",", "sigma", ")", "in", "zip", "(", "mus", ",", "sigmas", ")", "]", "\n", "b_vec", "=", "[", "compute_b", "(", "mu", ",", "sigma", ")", "for", "(", "mu", ",", "sigma", ")", "in", "zip", "(", "mus", ",", "sigmas", ")", "]", "\n", "\n", "samples", "=", "truncnorm", ".", "rvs", "(", "a_vec", ",", "b_vec", ",", "loc", "=", "mus", ",", "scale", "=", "sigmas", ",", "size", "=", "len", "(", "mus", ")", ")", "\n", "\n", "if", "len", "(", "samples", ")", "==", "1", ":", "\n", "        ", "return", "samples", "[", "0", "]", "\n", "", "return", "samples", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.compute_variational_entropy_of_individual_entries_of_z": [[20, 41], ["numpy.zeros", "enumerate", "numpy.shape", "zip", "categorical_from_binary.ib_cavi.trunc_norm.compute_entropy_normal_plus", "categorical_from_binary.ib_cavi.trunc_norm.compute_entropy_normal_minus", "ValueError"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_entropy_normal_plus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_entropy_normal_minus"], ["def", "compute_variational_entropy_of_individual_entries_of_z", "(", "\n", "labels", ":", "NumpyArray1D", ",", "\n", "z_natural_parameters", ":", "NumpyArray1D", ",", "\n", ")", "->", "NumpyArray1D", ":", "\n", "    ", "\"\"\"\n    Returns:\n        Array of shape (n_observations, ), where the i-th entry is the variational entropy\n        of the latent variable associated with the i-th observation.\n    \"\"\"", "\n", "n_obs", "=", "np", ".", "shape", "(", "z_natural_parameters", ")", "[", "0", "]", "\n", "entropy_zs", "=", "np", ".", "zeros", "(", "n_obs", ")", "\n", "for", "i", ",", "(", "label", ",", "z_natural_parameter", ")", "in", "enumerate", "(", "zip", "(", "labels", ",", "z_natural_parameters", ")", ")", ":", "\n", "        ", "if", "label", "==", "1", ":", "\n", "            ", "entropy_zs", "[", "i", "]", "=", "compute_entropy_normal_plus", "(", "mu", "=", "z_natural_parameter", ")", "\n", "", "elif", "label", "==", "0", ":", "\n", "            ", "entropy_zs", "[", "i", "]", "=", "compute_entropy_normal_minus", "(", "mu", "=", "z_natural_parameter", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Found label of {label}, but the only legal values are 0 and 1.\"", "\n", ")", "\n", "", "", "return", "entropy_zs", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.compute_variational_entropy_of_z": [[43, 56], ["numpy.sum", "elbo.compute_variational_entropy_of_individual_entries_of_z"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.compute_variational_entropy_of_individual_entries_of_z"], ["", "def", "compute_variational_entropy_of_z", "(", "\n", "labels", ":", "NumpyArray1D", ",", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "beta_mean", ":", "NumpyArray1D", ",", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Returns:\n        The entropy of z, the vector of latent variables associated with the observations\n    \"\"\"", "\n", "z_natural_parameters", "=", "covariates", "@", "beta_mean", "\n", "return", "np", ".", "sum", "(", "\n", "compute_variational_entropy_of_individual_entries_of_z", "(", "\n", "labels", ",", "z_natural_parameters", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.compute_variational_entropy_of_beta": [[60, 65], ["scipy.stats.multivariate_normal().entropy", "scipy.stats.multivariate_normal"], "function", ["None"], ["", "def", "compute_variational_entropy_of_beta", "(", "\n", "beta_mean", ":", "NumpyArray1D", ",", "\n", "beta_cov", ":", "NumpyArray2D", ",", "\n", ")", "->", "float", ":", "\n", "    ", "return", "scipy", ".", "stats", ".", "multivariate_normal", "(", "beta_mean", ",", "beta_cov", ")", ".", "entropy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.compute_variational_entropy": [[67, 76], ["elbo.compute_variational_entropy_of_z", "elbo.compute_variational_entropy_of_beta"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.elbo.compute_variational_entropy_of_z", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit.elbo.compute_variational_entropy_of_beta"], ["", "def", "compute_variational_entropy", "(", "\n", "labels", ":", "NumpyArray1D", ",", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "beta_mean", ":", "NumpyArray1D", ",", "\n", "beta_cov", ":", "NumpyArray2D", ",", "\n", ")", "->", "float", ":", "\n", "    ", "entropy_z", "=", "compute_variational_entropy_of_z", "(", "labels", ",", "covariates", ",", "beta_mean", ")", "\n", "entropy_beta", "=", "compute_variational_entropy_of_beta", "(", "beta_mean", ",", "beta_cov", ")", "\n", "return", "entropy_z", "+", "entropy_beta", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.compute_variational_expectation_of_complete_data_likelihood": [[78, 94], ["numpy.shape", "numpy.sum", "numpy.sum", "numpy.log", "range", "len"], "function", ["None"], ["", "def", "compute_variational_expectation_of_complete_data_likelihood", "(", "\n", "z_mean", ":", "NumpyArray1D", ",", "\n", "beta_mean", ":", "NumpyArray1D", ",", "\n", "beta_cov", ":", "NumpyArray2D", ",", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", ")", ":", "\n", "    ", "N", "=", "np", ".", "shape", "(", "covariates", ")", "[", "0", "]", "\n", "x", "=", "covariates", "\n", "z_mean_shifts", "=", "z_mean", "-", "x", "@", "beta_mean", "\n", "# `z_mean_shifts` are the amount by which the variational expected value of the", "\n", "# latent z_i's, as truncated normal random variables, differ from the expected value", "\n", "# of the pre-truncated parent distributions.", "\n", "return", "(", "\n", "-", "0.5", "*", "N", "*", "(", "np", ".", "log", "(", "2", "*", "np", ".", "pi", ")", "+", "1", ")", "\n", "+", "0.5", "*", "np", ".", "sum", "(", "z_mean_shifts", "*", "(", "x", "@", "beta_mean", ")", ")", "\n", "-", "0.5", "*", "np", ".", "sum", "(", "[", "x", "[", "i", "]", ".", "T", "@", "beta_cov", "@", "x", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "x", ")", ")", "]", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.compute_variational_expectation_of_prior": [[97, 105], ["numpy.sum", "numpy.shape", "numpy.diag", "numpy.log"], "function", ["None"], ["", "def", "compute_variational_expectation_of_prior", "(", "beta_mean", ",", "beta_cov", ")", ":", "\n", "    ", "\"\"\"\n    This is the cross entropy of two gaussians.\n    Note that the form is simpler than in general since the prior is zero mean, unit variance.\n    \"\"\"", "\n", "M", "=", "np", ".", "shape", "(", "beta_mean", ")", "[", "0", "]", "\n", "trace_beta_cov", "=", "np", ".", "sum", "(", "np", ".", "diag", "(", "beta_cov", ")", ")", "\n", "return", "-", "0.5", "*", "(", "beta_mean", "@", "beta_mean", "+", "trace_beta_cov", "+", "M", "*", "np", ".", "log", "(", "2", "*", "np", ".", "pi", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.compute_variational_energy": [[107, 122], ["print", "elbo.compute_variational_expectation_of_prior", "elbo.compute_variational_expectation_of_complete_data_likelihood", "elbo.compute_variational_expectation_of_prior", "elbo.compute_variational_expectation_of_complete_data_likelihood"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.compute_variational_expectation_of_prior", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.elbo.compute_variational_expectation_of_complete_data_likelihood", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.compute_variational_expectation_of_prior", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.elbo.compute_variational_expectation_of_complete_data_likelihood"], ["", "def", "compute_variational_energy", "(", "\n", "beta_mean", ":", "NumpyArray1D", ",", "\n", "beta_cov", ":", "NumpyArray2D", ",", "\n", "z_mean", ":", "NumpyArray1D", ",", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "verbose", ":", "bool", "=", "False", ",", "\n", ")", "->", "float", ":", "\n", "    ", "print", "(", "\n", "f\"prior energy: {compute_variational_expectation_of_prior(beta_mean, beta_cov)} \"", "\n", "f\"likelihood energy:  { compute_variational_expectation_of_complete_data_likelihood(z_mean, beta_mean, beta_cov, covariates)}\"", "\n", ")", "if", "verbose", "else", "None", "\n", "return", "compute_variational_expectation_of_prior", "(", "\n", "beta_mean", ",", "beta_cov", "\n", ")", "+", "compute_variational_expectation_of_complete_data_likelihood", "(", "\n", "z_mean", ",", "beta_mean", ",", "beta_cov", ",", "covariates", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.compute_elbo": [[125, 138], ["elbo.compute_variational_entropy", "elbo.compute_variational_energy"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit.elbo.compute_variational_entropy", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit.elbo.compute_variational_energy"], ["", "def", "compute_elbo", "(", "\n", "beta_mean", ":", "NumpyArray1D", ",", "\n", "beta_cov", ":", "NumpyArray2D", ",", "\n", "z_mean", ":", "NumpyArray1D", ",", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray1D", ",", "\n", "verbose", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "    ", "entropy", "=", "compute_variational_entropy", "(", "labels", ",", "covariates", ",", "beta_mean", ",", "beta_cov", ")", "\n", "energy", "=", "compute_variational_energy", "(", "\n", "beta_mean", ",", "beta_cov", ",", "z_mean", ",", "covariates", ",", "verbose", "\n", ")", "\n", "return", "energy", "+", "entropy", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.sample_z_from_natural_parameters": [[145, 163], ["numpy.zeros", "range", "numpy.shape", "categorical_from_binary.ib_cavi.trunc_norm.sample_normal_plus", "categorical_from_binary.ib_cavi.trunc_norm.sample_normal_minus", "ValueError"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.sample_normal_plus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.sample_normal_minus"], ["", "def", "sample_z_from_natural_parameters", "(", "\n", "labels", ":", "NumpyArray1D", ",", "natural_parameters", ":", "NumpyArray1D", ",", "n_samples", ":", "int", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        np.array of shape ((n_observations, n_samples))\n    \"\"\"", "\n", "\n", "n_obs", "=", "np", ".", "shape", "(", "natural_parameters", ")", "[", "0", "]", "\n", "z_samples", "=", "np", ".", "zeros", "(", "(", "n_obs", ",", "n_samples", ")", ")", "\n", "for", "i", "in", "range", "(", "n_obs", ")", ":", "\n", "        ", "if", "labels", "[", "i", "]", "==", "1", ":", "\n", "            ", "z_samples", "[", "i", ",", ":", "]", "=", "sample_normal_plus", "(", "natural_parameters", "[", "i", "]", ",", "size", "=", "n_samples", ")", "\n", "", "elif", "labels", "[", "i", "]", "==", "0", ":", "\n", "            ", "z_samples", "[", "i", ",", ":", "]", "=", "sample_normal_minus", "(", "natural_parameters", "[", "i", "]", ",", "size", "=", "n_samples", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Label must be either 0 or 1\"", ")", "\n", "", "", "return", "z_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.compute_density_of_z_entry": [[165, 172], ["categorical_from_binary.ib_cavi.trunc_norm.compute_density_normal_plus", "categorical_from_binary.ib_cavi.trunc_norm.compute_density_normal_minus", "ValueError"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_density_normal_plus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_density_normal_minus"], ["", "def", "compute_density_of_z_entry", "(", "z", ":", "float", ",", "natural_parameter", ":", "float", ",", "label", ":", "int", ")", ":", "\n", "    ", "if", "label", "==", "1", ":", "\n", "        ", "return", "compute_density_normal_plus", "(", "natural_parameter", ",", "z", ")", "\n", "", "elif", "label", "==", "0", ":", "\n", "        ", "return", "compute_density_normal_minus", "(", "natural_parameter", ",", "z", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Label must be either 0 or 1\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.compute_monte_carlo_approximate_entropy_for_z": [[174, 204], ["zip", "numpy.mean", "numpy.log", "elbo.compute_density_of_z_entry"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.compute_density_of_z_entry"], ["", "", "def", "compute_monte_carlo_approximate_entropy_for_z", "(", "\n", "z_samples", ":", "NumpyArray2D", ",", "\n", "z_natural_params", ":", "NumpyArray1D", ",", "\n", "labels", ":", "NumpyArray1D", ",", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Arguments\n        z_samples: has shape (n_observations, n_samples)\n            The i-th row gives a bunch of Monte carlo samples for i-th latent variable z_i,\n            for i=1,.., N observations.\n        z_natural_params: has shape (n_observations, )\n            The i-th entry is the variational natural parameter for the i-th distribution on z.\n        labels: has shape (n_observations, )\n            These are the binary observations for the probit regression\n\n    Returns:\n        An estimate of the entropy of the z-vector\n    \"\"\"", "\n", "approximate_entropy_for_z", "=", "0", "\n", "for", "z_samples_i", ",", "label_i", ",", "z_natural_parameter_i", "in", "zip", "(", "\n", "z_samples", ",", "labels", ",", "z_natural_params", "\n", ")", ":", "\n", "# take the mean of many monte carlo samples to get an estimate", "\n", "        ", "approximate_entropy_for_z_entry", "=", "np", ".", "mean", "(", "\n", "-", "np", ".", "log", "(", "\n", "compute_density_of_z_entry", "(", "z_samples_i", ",", "z_natural_parameter_i", ",", "label_i", ")", "\n", ")", "\n", ")", "\n", "approximate_entropy_for_z", "+=", "approximate_entropy_for_z_entry", "\n", "", "return", "approximate_entropy_for_z", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.compute_monte_carlo_approximate_likelihood_energy": [[206, 231], ["numpy.shape", "enumerate", "numpy.mean", "numpy.log", "zip", "numpy.sum", "numpy.ones"], "function", ["None"], ["", "def", "compute_monte_carlo_approximate_likelihood_energy", "(", "\n", "z_samples", ",", "\n", "beta_samples", ",", "\n", "covariates", ",", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Forms a Monte Carlo approximation of the variational expectation of the complete\n    data log likelihood,  i.e. sum_{i=1}^N log p(y_i, z_i \\cond \\beta)\n\n    Arguments:\n        z_samples: np.array of shape (n_observations, n_samples)\n        beta_samples: np.array of shape (n_samples, beta_dim)\n        covariates:  np.array of shape (n_observations, beta_dim)\n    \"\"\"", "\n", "n_observations", ",", "n_mc_samples", "=", "np", ".", "shape", "(", "z_samples", ")", "\n", "expected_ll_for_monte_carlo_parameter_samples", "=", "(", "\n", "np", ".", "ones", "(", "n_mc_samples", ")", "*", "-", "0.5", "*", "n_observations", "*", "np", ".", "log", "(", "2", "*", "np", ".", "pi", ")", "\n", ")", "\n", "# TODO: Re: the transpose --", "\n", "# Should I restructure z_samples using n_samples as the first array dimension?", "\n", "for", "s", ",", "(", "z_sample", ",", "beta_sample", ")", "in", "enumerate", "(", "zip", "(", "z_samples", ".", "T", ",", "beta_samples", ")", ")", ":", "\n", "        ", "expected_ll_for_monte_carlo_parameter_samples", "[", "s", "]", "+=", "-", "0.5", "*", "np", ".", "sum", "(", "\n", "(", "z_sample", "-", "covariates", "@", "beta_sample", ")", "**", "2", "\n", ")", "\n", "", "return", "np", ".", "mean", "(", "expected_ll_for_monte_carlo_parameter_samples", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.sanity.compute_class_probabilities": [[6, 9], ["scipy.stats.norm.cdf"], "function", ["None"], ["def", "compute_class_probabilities", "(", "covariates", ",", "beta", ")", ":", "\n", "    ", "linear_predictors", "=", "covariates", "@", "beta", "\n", "return", "norm", ".", "cdf", "(", "linear_predictors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.sanity.print_table_comparing_class_probs_to_labels": [[11, 19], ["numpy.transpose", "tabulate.tabulate", "print"], "function", ["None"], ["", "def", "print_table_comparing_class_probs_to_labels", "(", "class_probs", ",", "labels", ")", ":", "\n", "    ", "titles", "=", "[", "\n", "\"training data label\"", ",", "\n", "\"modeled class probs\"", ",", "\n", "]", "\n", "results", "=", "np", ".", "transpose", "(", "[", "class_probs", ",", "labels", "]", ")", "\n", "table", "=", "tabulate", "(", "results", ",", "titles", ",", "tablefmt", "=", "\"fancy_grid\"", ")", "\n", "print", "(", "table", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_variational_expectation_of_z": [[45, 64], ["scipy.sparse.issparse", "scipy.sparse.issparse", "main.compute_variational_expectation_of_z_with_sparse_inputs", "main.compute_variational_expectation_of_z_with_dense_inputs"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_variational_expectation_of_z_with_sparse_inputs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_variational_expectation_of_z_with_dense_inputs"], ["Ks", "=", "[", "3", ",", "10", "]", "\n", "multipliers_on_K_to_create_M", "=", "[", "1", ",", "2", "]", "\n", "multipliers_on_P_to_create_N", "=", "[", "10", ",", "20", ",", "40", ",", "80", ",", "160", "]", "\n", "sigma_highs", "=", "[", "0.1", ",", "2.0", "]", "\n", "seed", "=", "6", "\n", "beta_0", "=", "None", "\n", "include_intercept", "=", "True", "\n", "link", "=", "Link", ".", "MULTI_LOGIT", "\n", "ib_model", "=", "IB_Model", ".", "LOGIT", "\n", "\n", "### Inference configs", "\n", "convergence_criterion_drop_in_mean_elbo", "=", "0.1", "\n", "\n", "### Plotting configs", "\n", "sns_style", "=", "\"darkgrid\"", "\n", "sns", ".", "set", "(", "style", "=", "sns_style", ")", "\n", "save_filepath", "=", "f\"data/results/bma/new_bma_plots_{ib_model.name}_{sns_style}\"", "\n", "\n", "###", "\n", "# Code", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.update_taus": [[173, 207], ["numpy.shape", "numpy.zeros", "numpy.zeros", "range", "categorical_from_binary.ib_cavi.multi.structs.VariationalTaus", "numpy.array", "range", "numpy.sum", "numpy.where", "numpy.sum", "numpy.diag", "range"], "function", ["None"], ["results_dict", "[", "\"CBC weight\"", "]", ".", "append", "(", "CBC_weight", ")", "\n", "results_dict", "[", "\"Mean KL divergence from CBM to true\"", "]", ".", "append", "(", "\n", "np", ".", "mean", "(", "divergence_from_CBM_to_true", ")", "\n", ")", "\n", "results_dict", "[", "\"Mean KL divergence from CBC to true\"", "]", ".", "append", "(", "\n", "np", ".", "mean", "(", "divergence_from_CBC_to_true", ")", "\n", ")", "\n", "results_dict", "[", "\"Mean KL divergence from BMA to true\"", "]", ".", "append", "(", "\n", "np", ".", "mean", "(", "divergence_from_BMA_to_true", ")", "\n", ")", "\n", "\n", "", "df_results", "=", "pd", ".", "DataFrame", "(", "results_dict", ")", "\n", "pd", ".", "set_option", "(", "\"display.float_format\"", ",", "lambda", "x", ":", "\"%.6f\"", "%", "x", ")", "\n", "df_results", "\n", "\n", "# If I want to convert the results dataframe to LateX, without the IB_Model.LOGIT column,", "\n", "# print(df_results[df_results.columns.drop('ib_model')].to_latex(index=True, float_format=\"%.3f\"))", "\n", "\n", "\n", "df_results_melted", "=", "pd", ".", "melt", "(", "\n", "df_results", ",", "\n", "id_vars", "=", "[", "\"N\"", ",", "\"K\"", ",", "\"M\"", ",", "\"sigma_high\"", ",", "\"ib_model\"", ",", "\"CBC weight\"", "]", ",", "\n", "var_name", "=", "\"Inference target\"", ",", "\n", "value_vars", "=", "[", "\n", "\"Mean KL divergence from CBM to true\"", ",", "\n", "\"Mean KL divergence from CBC to true\"", ",", "\n", "\"Mean KL divergence from BMA to true\"", ",", "\n", "]", ",", "\n", "value_name", "=", "\"Mean KL divergence\"", ",", "\n", "ignore_index", "=", "False", ",", "\n", ")", "\n", "# make the index an actual column, with a name, so we can tell the plotter to use it on one of the axes", "\n", "df_results_melted", "=", "df_results_melted", ".", "rename_axis", "(", "\"dataset_id\"", ")", ".", "reset_index", "(", ")", "\n", "df_results_melted", "=", "df_results_melted", ".", "replace", "(", "\n", "\"Mean KL divergence from CBM to true\"", ",", "\"CBM\"", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_variational_parameters_for_beta_under_normal_prior": [[237, 271], ["categorical_from_binary.ib_cavi.multi.structs.VariationalBeta", "numpy.ndim", "numpy.einsum"], "function", ["None"], ["row", "+=", "1", "\n", "contexts", ".", "append", "(", "f\"K={K}\\n M={M}\"", ")", "\n", "n_multipliers_for_for_subplot", "=", "[", "]", "\n", "kl_divs_from_BMA_for_subplot", "=", "[", "]", "\n", "kl_divs_from_CBC_for_subplot", "=", "[", "]", "\n", "kl_divs_from_CBM_for_subplot", "=", "[", "]", "\n", "for", "(", "n", ",", "multiplier_on_P_to_create_N", ")", "in", "enumerate", "(", "\n", "multipliers_on_P_to_create_N", "\n", ")", ":", "\n", "                ", "N", "=", "P", "*", "multiplier_on_P_to_create_N", "\n", "n_multipliers_for_for_subplot", ".", "append", "(", "multiplier_on_P_to_create_N", ")", "\n", "kl_div_from_BMA", "=", "df_results_context", ".", "query", "(", "f\"N == {N}\"", ")", "[", "\n", "\"Mean KL divergence from BMA to true\"", "\n", "]", ".", "values", "[", "0", "]", "\n", "kl_div_from_CBM", "=", "df_results_context", ".", "query", "(", "f\"N == {N}\"", ")", "[", "\n", "\"Mean KL divergence from CBM to true\"", "\n", "]", ".", "values", "[", "0", "]", "\n", "kl_div_from_CBC", "=", "df_results_context", ".", "query", "(", "f\"N == {N}\"", ")", "[", "\n", "\"Mean KL divergence from CBC to true\"", "\n", "]", ".", "values", "[", "0", "]", "\n", "kl_divs_from_BMA_for_subplot", ".", "append", "(", "kl_div_from_BMA", ")", "\n", "kl_divs_from_CBM_for_subplot", ".", "append", "(", "kl_div_from_CBM", ")", "\n", "kl_divs_from_CBC_for_subplot", ".", "append", "(", "kl_div_from_CBC", ")", "\n", "", "axes", "[", "row", ",", "s", "]", ".", "plot", "(", "\n", "n_multipliers_for_for_subplot", ",", "\n", "kl_divs_from_CBM_for_subplot", ",", "\n", "\"-bo\"", ",", "\n", "label", "=", "f\"CBM-{ib_model.name}\"", ",", "\n", "clip_on", "=", "False", ",", "\n", ")", "\n", "axes", "[", "row", ",", "s", "]", ".", "plot", "(", "\n", "n_multipliers_for_for_subplot", ",", "\n", "kl_divs_from_CBC_for_subplot", ",", "\n", "\"-r^\"", ",", "\n", "label", "=", "f\"CBC-{ib_model.name}\"", ",", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_variational_parameters_for_beta_under_normal_gamma_prior": [[273, 297], ["categorical_from_binary.ib_cavi.multi.ib_probit.inference.tau_helpers.compute_expected_tau_reciprocal_array", "numpy.shape", "numpy.zeros", "range", "numpy.einsum", "categorical_from_binary.ib_cavi.multi.structs.VariationalBeta", "numpy.linalg.inv"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.tau_helpers.compute_expected_tau_reciprocal_array"], [")", "\n", "axes", "[", "row", ",", "s", "]", ".", "plot", "(", "\n", "n_multipliers_for_for_subplot", ",", "\n", "kl_divs_from_BMA_for_subplot", ",", "\n", "\"-kx\"", ",", "\n", "label", "=", "\"BMA\"", ",", "\n", "clip_on", "=", "False", ",", "\n", "markersize", "=", "10", ",", "\n", ")", "\n", "axes", "[", "row", ",", "s", "]", ".", "set_xticks", "(", "\n", "[", "n", "for", "n", "in", "n_multipliers_for_for_subplot", "]", ",", "\n", "labels", "=", "[", "n", "for", "n", "in", "n_multipliers_for_for_subplot", "]", ",", "\n", "size", "=", "\"x-small\"", ",", "\n", ")", "\n", "# axes[row,s].set_ylim(bottom=0)", "\n", "\n", "", "", "", "fig", ".", "supylabel", "(", "\"Mean KL divergence to true probabilities\"", ")", "\n", "fig", ".", "supxlabel", "(", "\"                    Ratio of sample size to number of parameters\"", ")", "\n", "\n", "cols", "=", "[", "\n", "r\"$\\sigma_{high}$ = \"", "+", "f\"{sigma_highs[0]}\"", ",", "\n", "r\"$\\sigma_{high}$ = \"", "+", "f\"{sigma_highs[1]}\"", ",", "\n", "]", "\n", "rows", "=", "contexts", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_probit_vi_with_normal_gamma_prior": [[111, 138], ["main._compute_probit_vi"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main._compute_probit_vi"], ["convergence_criterion_drop_in_mean_elbo", "=", "convergence_criterion_drop_in_mean_elbo", ",", "\n", ")", "\n", "variational_beta", "=", "results", ".", "variational_params", ".", "beta", "\n", "\n", "# Approximate ELBO for each", "\n", "n_monte_carlo_samples", "=", "10", "\n", "CBC_weight", "=", "compute_weight_on_CBC_from_bayesian_model_averaging", "(", "\n", "covariates_train", ",", "\n", "labels_train", ",", "\n", "variational_beta", ",", "\n", "n_monte_carlo_samples", ",", "\n", "ib_model", ",", "\n", ")", "\n", "print", "(", "f\"For IB model {ib_model}, CBC weight is {CBC_weight}\"", ")", "\n", "\n", "### check - does the weight make sense (compared to true!)", "\n", "probs_true", "=", "construct_category_probs", "(", "\n", "covariates_test", ",", "dataset", ".", "beta", ",", "link", "=", "Link", ".", "MULTI_LOGIT", "\n", ")", "\n", "probs_CBM", "=", "construct_category_probs", "(", "\n", "covariates_test", ",", "\n", "variational_beta", ".", "mean", ",", "\n", "link", "=", "cbm_link", ",", "\n", ")", "\n", "probs_CBC", "=", "construct_category_probs", "(", "\n", "covariates_test", ",", "\n", "variational_beta", ".", "mean", ",", "\n", "link", "=", "cbc_link", ",", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_probit_vi_with_normal_prior": [[141, 168], ["main._compute_probit_vi"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main._compute_probit_vi"], ["covariates_test", ",", "\n", "variational_beta", ".", "mean", ",", "\n", "CBC_weight", ",", "\n", "ib_model", ",", "\n", ")", "\n", "\n", "divergence_from_CBM_to_true", "=", "(", "\n", "compute_kl_divergence_from_estimated_to_true_category_probs", "(", "\n", "probs_CBM", ",", "probs_true", "\n", ")", "\n", ")", "\n", "divergence_from_CBC_to_true", "=", "(", "\n", "compute_kl_divergence_from_estimated_to_true_category_probs", "(", "\n", "probs_CBC", ",", "probs_true", "\n", ")", "\n", ")", "\n", "divergence_from_BMA_to_true", "=", "(", "\n", "compute_kl_divergence_from_estimated_to_true_category_probs", "(", "\n", "probs_BMA", ",", "probs_true", "\n", ")", "\n", ")", "\n", "print", "(", "\n", "f\"Mean divergence from CBM to true: {np.mean(divergence_from_CBM_to_true) }.  \"", "\n", "f\"Mean divergence from CBC to true: {np.mean(divergence_from_CBC_to_true)} \"", "\n", "f\"Mean divergence from BMA to true: {np.mean(divergence_from_BMA_to_true)}\"", "\n", ")", "\n", "\n", "results_dict", "[", "\"N\"", "]", ".", "append", "(", "dgc", ".", "n_samples", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main._compute_probit_vi": [[171, 282], ["numpy.shape", "print", "categorical_from_binary.ib_cavi.binary_probit.inference.structs.VariationalZs", "categorical_from_binary.ib_cavi.binary_probit.inference.structs.VariationalParams", "warnings.warn", "ValueError", "ValueError", "ValueError", "warnings.warn", "categorical_from_binary.ib_cavi.binary_probit.inference.structs.VariationalBeta", "main.compute_variational_expectation_of_z", "main.compute_variational_parameters_for_beta_under_normal_prior", "print", "categorical_from_binary.ib_cavi.binary_probit.elbo.compute_elbo", "print", "numpy.zeros", "numpy.eye", "main.update_taus", "main.compute_variational_parameters_for_beta_under_normal_gamma_prior", "ValueError"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_variational_expectation_of_z", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_variational_parameters_for_beta_under_normal_prior", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.inference.compute_elbo", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.update_taus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_variational_parameters_for_beta_under_normal_gamma_prior"], ["results_dict", "[", "\"sigma_high\"", "]", ".", "append", "(", "dgc", ".", "scale_for_predictive_categories", ")", "\n", "results_dict", "[", "\"ib_model\"", "]", ".", "append", "(", "str", "(", "ib_model", ")", ")", "\n", "results_dict", "[", "\"CBC weight\"", "]", ".", "append", "(", "CBC_weight", ")", "\n", "results_dict", "[", "\"Mean KL divergence from CBM to true\"", "]", ".", "append", "(", "\n", "np", ".", "mean", "(", "divergence_from_CBM_to_true", ")", "\n", ")", "\n", "results_dict", "[", "\"Mean KL divergence from CBC to true\"", "]", ".", "append", "(", "\n", "np", ".", "mean", "(", "divergence_from_CBC_to_true", ")", "\n", ")", "\n", "results_dict", "[", "\"Mean KL divergence from BMA to true\"", "]", ".", "append", "(", "\n", "np", ".", "mean", "(", "divergence_from_BMA_to_true", ")", "\n", ")", "\n", "\n", "", "df_results", "=", "pd", ".", "DataFrame", "(", "results_dict", ")", "\n", "pd", ".", "set_option", "(", "\"display.float_format\"", ",", "lambda", "x", ":", "\"%.6f\"", "%", "x", ")", "\n", "df_results", "\n", "\n", "# If I want to convert the results dataframe to LateX, without the IB_Model.LOGIT column,", "\n", "# print(df_results[df_results.columns.drop('ib_model')].to_latex(index=True, float_format=\"%.3f\"))", "\n", "\n", "\n", "df_results_melted", "=", "pd", ".", "melt", "(", "\n", "df_results", ",", "\n", "id_vars", "=", "[", "\"N\"", ",", "\"K\"", ",", "\"M\"", ",", "\"sigma_high\"", ",", "\"ib_model\"", ",", "\"CBC weight\"", "]", ",", "\n", "var_name", "=", "\"Inference target\"", ",", "\n", "value_vars", "=", "[", "\n", "\"Mean KL divergence from CBM to true\"", ",", "\n", "\"Mean KL divergence from CBC to true\"", ",", "\n", "\"Mean KL divergence from BMA to true\"", ",", "\n", "]", ",", "\n", "value_name", "=", "\"Mean KL divergence\"", ",", "\n", "ignore_index", "=", "False", ",", "\n", ")", "\n", "# make the index an actual column, with a name, so we can tell the plotter to use it on one of the axes", "\n", "df_results_melted", "=", "df_results_melted", ".", "rename_axis", "(", "\"dataset_id\"", ")", ".", "reset_index", "(", ")", "\n", "df_results_melted", "=", "df_results_melted", ".", "replace", "(", "\n", "\"Mean KL divergence from CBM to true\"", ",", "\"CBM\"", "\n", ")", "\n", "df_results_melted", "=", "df_results_melted", ".", "replace", "(", "\n", "\"Mean KL divergence from CBC to true\"", ",", "\"CBC\"", "\n", ")", "\n", "df_results_melted", "=", "df_results_melted", ".", "replace", "(", "\n", "\"Mean KL divergence from BMA to true\"", ",", "\"BMA\"", "\n", ")", "\n", "\n", "\n", "####", "\n", "#  Make plots showing asymptotic decrease in error for each context", "\n", "###", "\n", "\n", "# Reference for row and column headers:", "\n", "# https://stackoverflow.com/questions/25812255/row-and-column-headers-in-matplotlibs-subplots", "\n", "fig", ",", "axes", "=", "plt", ".", "subplots", "(", "4", ",", "2", ",", "sharey", "=", "True", ",", "sharex", "=", "True", ",", "squeeze", "=", "True", ")", "\n", "df_results", "=", "pd", ".", "DataFrame", "(", "results_dict", ")", "\n", "contexts", "=", "[", "]", "\n", "for", "(", "s", ",", "sigma_high", ")", "in", "enumerate", "(", "sigma_highs", ")", ":", "\n", "    ", "row", "=", "-", "1", "\n", "for", "K", "in", "Ks", ":", "\n", "        ", "for", "multiplier_on_K_to_create_M", "in", "multipliers_on_K_to_create_M", ":", "\n", "            ", "M", "=", "K", "*", "multiplier_on_K_to_create_M", "\n", "P", "=", "P", "=", "get_num_parameters_from_num_covariates_and_num_categories", "(", "K", ",", "M", ")", "\n", "df_results_context", "=", "df_results", "[", "\n", "(", "df_results", "[", "\"K\"", "]", "==", "K", ")", "\n", "&", "(", "df_results", "[", "\"M\"", "]", "==", "M", ")", "\n", "&", "(", "df_results", "[", "\"sigma_high\"", "]", "==", "sigma_high", ")", "\n", "]", "\n", "row", "+=", "1", "\n", "contexts", ".", "append", "(", "f\"K={K}\\n M={M}\"", ")", "\n", "n_multipliers_for_for_subplot", "=", "[", "]", "\n", "kl_divs_from_BMA_for_subplot", "=", "[", "]", "\n", "kl_divs_from_CBC_for_subplot", "=", "[", "]", "\n", "kl_divs_from_CBM_for_subplot", "=", "[", "]", "\n", "for", "(", "n", ",", "multiplier_on_P_to_create_N", ")", "in", "enumerate", "(", "\n", "multipliers_on_P_to_create_N", "\n", ")", ":", "\n", "                ", "N", "=", "P", "*", "multiplier_on_P_to_create_N", "\n", "n_multipliers_for_for_subplot", ".", "append", "(", "multiplier_on_P_to_create_N", ")", "\n", "kl_div_from_BMA", "=", "df_results_context", ".", "query", "(", "f\"N == {N}\"", ")", "[", "\n", "\"Mean KL divergence from BMA to true\"", "\n", "]", ".", "values", "[", "0", "]", "\n", "kl_div_from_CBM", "=", "df_results_context", ".", "query", "(", "f\"N == {N}\"", ")", "[", "\n", "\"Mean KL divergence from CBM to true\"", "\n", "]", ".", "values", "[", "0", "]", "\n", "kl_div_from_CBC", "=", "df_results_context", ".", "query", "(", "f\"N == {N}\"", ")", "[", "\n", "\"Mean KL divergence from CBC to true\"", "\n", "]", ".", "values", "[", "0", "]", "\n", "kl_divs_from_BMA_for_subplot", ".", "append", "(", "kl_div_from_BMA", ")", "\n", "kl_divs_from_CBM_for_subplot", ".", "append", "(", "kl_div_from_CBM", ")", "\n", "kl_divs_from_CBC_for_subplot", ".", "append", "(", "kl_div_from_CBC", ")", "\n", "", "axes", "[", "row", ",", "s", "]", ".", "plot", "(", "\n", "n_multipliers_for_for_subplot", ",", "\n", "kl_divs_from_CBM_for_subplot", ",", "\n", "\"-bo\"", ",", "\n", "label", "=", "f\"CBM-{ib_model.name}\"", ",", "\n", "clip_on", "=", "False", ",", "\n", ")", "\n", "axes", "[", "row", ",", "s", "]", ".", "plot", "(", "\n", "n_multipliers_for_for_subplot", ",", "\n", "kl_divs_from_CBC_for_subplot", ",", "\n", "\"-r^\"", ",", "\n", "label", "=", "f\"CBC-{ib_model.name}\"", ",", "\n", "clip_on", "=", "False", ",", "\n", ")", "\n", "axes", "[", "row", ",", "s", "]", ".", "plot", "(", "\n", "n_multipliers_for_for_subplot", ",", "\n", "kl_divs_from_BMA_for_subplot", ",", "\n", "\"-kx\"", ",", "\n", "label", "=", "\"BMA\"", ",", "\n", "clip_on", "=", "False", ",", "\n", "markersize", "=", "10", ",", "\n", ")", "\n", "axes", "[", "row", ",", "s", "]", ".", "set_xticks", "(", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.tau_helpers.compute_expected_reciprocal_of_tau_component": [[40, 56], ["scipy.special.kv", "scipy.special.kv", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt"], "function", ["None"], ["def", "compute_expected_reciprocal_of_tau_component", "(", "\n", "variational_tau_d_component", ":", "float", ",", "hyperparameters", ":", "Hyperparameters", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Each regression coefficient beta_m has its own variance tau_m.  This computes the variational\n    expectation of E[1/tau_m], which is needed in the coordinate ascent variational inference.\n\n    Arguments:\n        variational_tau_d_component: One component of the `d` vector from the\n            VariationalTau object.\n    \"\"\"", "\n", "hp", "=", "hyperparameters", "\n", "qd_m", "=", "variational_tau_d_component", "\n", "return", "(", "bessel2", "(", "hp", ".", "lambda_", "+", "0.5", ",", "np", ".", "sqrt", "(", "qd_m", ")", "/", "hp", ".", "gamma", ")", ")", "/", "(", "\n", "hp", ".", "gamma", "*", "np", ".", "sqrt", "(", "qd_m", ")", "*", "(", "bessel2", "(", "hp", ".", "lambda_", "-", "0.5", ",", "np", ".", "sqrt", "(", "qd_m", ")", "/", "hp", ".", "gamma", ")", ")", "\n", ")", "-", "(", "2", "*", "hp", ".", "lambda_", "-", "1", ")", "/", "(", "qd_m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.tau_helpers.compute_expected_tau_reciprocal_matrix": [[58, 78], ["len", "numpy.eye", "range", "tau_helpers.compute_expected_reciprocal_of_tau_component"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.tau_helpers.compute_expected_reciprocal_of_tau_component"], ["", "def", "compute_expected_tau_reciprocal_matrix", "(", "\n", "variational_taus", ":", "VariationalTaus", ",", "hyperparameters", ":", "Hyperparameters", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Returns expected_tau_reciprocal_matrix. This bascially does `expected_reciprocal_of_tau_component`\n    for all components simultaneously, and stores the results in a (diagonal) matrix.\n\n    Arguments:\n        lambda_ : hyperparameter for the normal-gamma prior on the regression weights\n        gamma : hyperparameter for the normal-gamma prior on the regression weights\n    \"\"\"", "\n", "M", "=", "len", "(", "variational_taus", ".", "d", ")", "\n", "expected_tau_reciprocal_matrix", "=", "np", ".", "eye", "(", "M", ")", "\n", "for", "m", "in", "range", "(", "M", ")", ":", "\n", "        ", "expected_tau_reciprocal_matrix", "[", "\n", "m", ",", "m", "\n", "]", "=", "compute_expected_reciprocal_of_tau_component", "(", "\n", "variational_taus", ".", "d", "[", "m", "]", ",", "hyperparameters", "\n", ")", "\n", "", "return", "expected_tau_reciprocal_matrix", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_variational_expectation_of_z_with_dense_inputs": [[67, 87], ["scipy.stats.norm.logpdf", "scipy.special.log_ndtr", "categorical_from_binary.math.logdiffexp", "numpy.exp", "numpy.exp"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.math.logdiffexp"], ["Ks", ",", "\n", "multipliers_on_K_to_create_M", ",", "\n", "multipliers_on_P_to_create_N", ",", "\n", "sigma_highs", ",", "\n", "seed", "=", "seed", ",", "\n", ")", "\n", "print", "(", "f\"The data generation configs are {data_generation_configs}\"", ")", "\n", "\n", "\n", "results_dict", "=", "defaultdict", "(", "list", ")", "\n", "for", "(", "s", ",", "dgc", ")", "in", "enumerate", "(", "data_generation_configs", ")", ":", "\n", "    ", "print", "(", "f\"----Now running simulation {s+1}/{len(data_generation_configs)}--\"", ")", "\n", "\n", "beta_category_strategy", "=", "ControlCategoryPredictability", "(", "\n", "scale_for_predictive_categories", "=", "dgc", ".", "scale_for_predictive_categories", "\n", ")", "\n", "dataset", "=", "generate_multiclass_regression_dataset", "(", "\n", "n_samples", "=", "dgc", ".", "n_samples", ",", "\n", "n_features", "=", "dgc", ".", "n_features", ",", "\n", "n_categories", "=", "dgc", ".", "n_categories", ",", "\n", "beta_0", "=", "beta_0", ",", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_variational_expectation_of_z_with_sparse_inputs": [[90, 144], ["numpy.shape", "scipy.sparse.csr_matrix", "scipy.stats.norm.logpdf", "scipy.special.log_ndtr", "categorical_from_binary.math.logdiffexp", "eta.nonzero", "numpy.array", "scipy.sparse.coo_matrix", "scipy.sparse.csr_matrix", "scipy.sparse.csr_matrix", "numpy.exp", "numpy.exp", "scipy.stats.norm.pdf", "scipy.stats.norm.pdf"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.math.logdiffexp"], ["include_intercept", "=", "include_intercept", ",", "\n", "beta_category_strategy", "=", "beta_category_strategy", ",", "\n", ")", "\n", "\n", "# Prep training / test split", "\n", "n_train_samples", "=", "int", "(", "0.8", "*", "dgc", ".", "n_samples", ")", "\n", "covariates_train", "=", "dataset", ".", "features", "[", ":", "n_train_samples", "]", "\n", "labels_train", "=", "dataset", ".", "labels", "[", ":", "n_train_samples", "]", "\n", "covariates_test", "=", "dataset", ".", "features", "[", "n_train_samples", ":", "]", "\n", "labels_test", "=", "dataset", ".", "labels", "[", "n_train_samples", ":", "]", "\n", "\n", "cbm_link", "=", "cbm_link_from_ib_model", "(", "ib_model", ")", "\n", "cbc_link", "=", "cbc_link_from_ib_model", "(", "ib_model", ")", "\n", "\n", "results", "=", "compute_ib_cavi_with_normal_prior", "(", "\n", "ib_model", ",", "\n", "labels_train", ",", "\n", "covariates_train", ",", "\n", "labels_test", "=", "labels_test", ",", "\n", "covariates_test", "=", "covariates_test", ",", "\n", "variational_params_init", "=", "None", ",", "\n", "convergence_criterion_drop_in_mean_elbo", "=", "convergence_criterion_drop_in_mean_elbo", ",", "\n", ")", "\n", "variational_beta", "=", "results", ".", "variational_params", ".", "beta", "\n", "\n", "# Approximate ELBO for each", "\n", "n_monte_carlo_samples", "=", "10", "\n", "CBC_weight", "=", "compute_weight_on_CBC_from_bayesian_model_averaging", "(", "\n", "covariates_train", ",", "\n", "labels_train", ",", "\n", "variational_beta", ",", "\n", "n_monte_carlo_samples", ",", "\n", "ib_model", ",", "\n", ")", "\n", "print", "(", "f\"For IB model {ib_model}, CBC weight is {CBC_weight}\"", ")", "\n", "\n", "### check - does the weight make sense (compared to true!)", "\n", "probs_true", "=", "construct_category_probs", "(", "\n", "covariates_test", ",", "dataset", ".", "beta", ",", "link", "=", "Link", ".", "MULTI_LOGIT", "\n", ")", "\n", "probs_CBM", "=", "construct_category_probs", "(", "\n", "covariates_test", ",", "\n", "variational_beta", ".", "mean", ",", "\n", "link", "=", "cbm_link", ",", "\n", ")", "\n", "probs_CBC", "=", "construct_category_probs", "(", "\n", "covariates_test", ",", "\n", "variational_beta", ".", "mean", ",", "\n", "link", "=", "cbc_link", ",", "\n", ")", "\n", "probs_BMA", "=", "construct_category_probabilities_from_bayesian_model_averaging", "(", "\n", "covariates_test", ",", "\n", "variational_beta", ".", "mean", ",", "\n", "CBC_weight", ",", "\n", "ib_model", ",", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_variational_expectation_of_z_in_an_intuitive_way": [[146, 171], ["numpy.shape", "numpy.argmax", "numpy.zeros", "range", "range", "categorical_from_binary.ib_cavi.trunc_norm.compute_expected_value_normal_plus", "categorical_from_binary.ib_cavi.trunc_norm.compute_expected_value_normal_minus"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_expected_value_normal_plus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_expected_value_normal_minus"], ["\n", "divergence_from_CBM_to_true", "=", "(", "\n", "compute_kl_divergence_from_estimated_to_true_category_probs", "(", "\n", "probs_CBM", ",", "probs_true", "\n", ")", "\n", ")", "\n", "divergence_from_CBC_to_true", "=", "(", "\n", "compute_kl_divergence_from_estimated_to_true_category_probs", "(", "\n", "probs_CBC", ",", "probs_true", "\n", ")", "\n", ")", "\n", "divergence_from_BMA_to_true", "=", "(", "\n", "compute_kl_divergence_from_estimated_to_true_category_probs", "(", "\n", "probs_BMA", ",", "probs_true", "\n", ")", "\n", ")", "\n", "print", "(", "\n", "f\"Mean divergence from CBM to true: {np.mean(divergence_from_CBM_to_true) }.  \"", "\n", "f\"Mean divergence from CBC to true: {np.mean(divergence_from_CBC_to_true)} \"", "\n", "f\"Mean divergence from BMA to true: {np.mean(divergence_from_BMA_to_true)}\"", "\n", ")", "\n", "\n", "results_dict", "[", "\"N\"", "]", ".", "append", "(", "dgc", ".", "n_samples", ")", "\n", "results_dict", "[", "\"K\"", "]", ".", "append", "(", "dgc", ".", "n_categories", ")", "\n", "results_dict", "[", "\"M\"", "]", ".", "append", "(", "dgc", ".", "n_features", ")", "\n", "results_dict", "[", "\"sigma_high\"", "]", ".", "append", "(", "dgc", ".", "scale_for_predictive_categories", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main._compute_covariance_of_beta_under_normal_prior": [[210, 235], ["scipy.sparse.issparse", "scipy.sparse.identity", "numpy.shape", "scipy.sparse.linalg.inv", "numpy.asarray", "numpy.linalg.inv"], "function", ["None"], ["\"Mean KL divergence from CBC to true\"", ",", "\"CBC\"", "\n", ")", "\n", "df_results_melted", "=", "df_results_melted", ".", "replace", "(", "\n", "\"Mean KL divergence from BMA to true\"", ",", "\"BMA\"", "\n", ")", "\n", "\n", "\n", "####", "\n", "#  Make plots showing asymptotic decrease in error for each context", "\n", "###", "\n", "\n", "# Reference for row and column headers:", "\n", "# https://stackoverflow.com/questions/25812255/row-and-column-headers-in-matplotlibs-subplots", "\n", "fig", ",", "axes", "=", "plt", ".", "subplots", "(", "4", ",", "2", ",", "sharey", "=", "True", ",", "sharex", "=", "True", ",", "squeeze", "=", "True", ")", "\n", "df_results", "=", "pd", ".", "DataFrame", "(", "results_dict", ")", "\n", "contexts", "=", "[", "]", "\n", "for", "(", "s", ",", "sigma_high", ")", "in", "enumerate", "(", "sigma_highs", ")", ":", "\n", "    ", "row", "=", "-", "1", "\n", "for", "K", "in", "Ks", ":", "\n", "        ", "for", "multiplier_on_K_to_create_M", "in", "multipliers_on_K_to_create_M", ":", "\n", "            ", "M", "=", "K", "*", "multiplier_on_K_to_create_M", "\n", "P", "=", "P", "=", "get_num_parameters_from_num_covariates_and_num_categories", "(", "K", ",", "M", ")", "\n", "df_results_context", "=", "df_results", "[", "\n", "(", "df_results", "[", "\"K\"", "]", "==", "K", ")", "\n", "&", "(", "df_results", "[", "\"M\"", "]", "==", "M", ")", "\n", "&", "(", "df_results", "[", "\"sigma_high\"", "]", "==", "sigma_high", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.initialize_variational_params": [[299, 344], ["categorical_from_binary.ib_cavi.multi.structs.VariationalParams", "numpy.shape", "warnings.warn", "categorical_from_binary.ib_cavi.multi.structs.VariationalBeta", "main._compute_covariance_of_beta_under_normal_prior", "numpy.zeros", "numpy.eye"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main._compute_covariance_of_beta_under_normal_prior"], ["\n", "pad", "=", "5", "# in points", "\n", "\n", "for", "ax", ",", "col", "in", "zip", "(", "axes", "[", "0", "]", ",", "cols", ")", ":", "\n", "    ", "ax", ".", "annotate", "(", "\n", "col", ",", "\n", "xy", "=", "(", "0.5", ",", "1", ")", ",", "\n", "xytext", "=", "(", "0", ",", "pad", ")", ",", "\n", "xycoords", "=", "\"axes fraction\"", ",", "\n", "textcoords", "=", "\"offset points\"", ",", "\n", "size", "=", "\"medium\"", ",", "\n", "ha", "=", "\"center\"", ",", "\n", "va", "=", "\"baseline\"", ",", "\n", ")", "\n", "\n", "", "for", "ax", ",", "row", "in", "zip", "(", "axes", "[", ":", ",", "0", "]", ",", "rows", ")", ":", "\n", "    ", "ax", ".", "annotate", "(", "\n", "row", ",", "\n", "xy", "=", "(", "0", ",", "0.5", ")", ",", "\n", "xytext", "=", "(", "-", "ax", ".", "yaxis", ".", "labelpad", "-", "pad", ",", "0", ")", ",", "\n", "xycoords", "=", "ax", ".", "yaxis", ".", "label", ",", "\n", "textcoords", "=", "\"offset points\"", ",", "\n", "size", "=", "\"medium\"", ",", "\n", "ha", "=", "\"right\"", ",", "\n", "va", "=", "\"center\"", ",", "\n", ")", "\n", "\n", "\n", "", "fig", ".", "subplots_adjust", "(", "left", "=", "0.25", ",", "top", "=", "0.75", ")", "\n", "### Get labels from last axes and make legend", "\n", "handles", ",", "labels", "=", "axes", "[", "0", ",", "0", "]", ".", "get_legend_handles_labels", "(", ")", "\n", "fig", ".", "legend", "(", "\n", "handles", ",", "\n", "labels", ",", "\n", "loc", "=", "\"upper left\"", ",", "\n", "bbox_to_anchor", "=", "(", "0.5", ",", "0.95", ",", "0.5", ",", "0.075", ")", ",", "\n", "fontsize", "=", "\"small\"", ",", "\n", ")", "\n", "# tight_layout doesn't take these labels into account. We'll need", "\n", "# to make some room. These numbers are are manually tweaked.", "\n", "# You could automatically calculate them, but it's a pain.", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "save_filepath", ",", "bbox_inches", "=", "\"tight\"", ")", "\n", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_precomputables": [[346, 372], ["categorical_from_binary.ib_cavi.multi.structs.Precomputables", "categorical_from_binary.ib_cavi.multi.ib_probit.inference.shrinkage_groups.make_shrinkage_groups"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.shrinkage_groups.make_shrinkage_groups"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.update_variational_params_and_elbo_stats": [[375, 442], ["main.compute_variational_expectation_of_z", "categorical_from_binary.ib_cavi.multi.structs.VariationalParams", "numpy.shape", "main.compute_variational_parameters_for_beta_under_normal_prior", "categorical_from_binary.ib_cavi.multi.ib_probit.elbo.compute_elbo", "categorical_from_binary.ib_cavi.multi.structs.ELBO_Stats", "main.update_taus", "main.compute_variational_parameters_for_beta_under_normal_gamma_prior", "ValueError"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_variational_expectation_of_z", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_variational_parameters_for_beta_under_normal_prior", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.inference.compute_elbo", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.update_taus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_variational_parameters_for_beta_under_normal_gamma_prior"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_multiclass_probit_vi_with_normal_gamma_prior": [[444, 489], ["categorical_from_binary.ib_cavi.multi.inference_wrapper.compute_ib_cavi"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.inference_wrapper.compute_ib_cavi"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_multiclass_probit_vi_with_normal_prior": [[492, 549], ["categorical_from_binary.ib_cavi.multi.inference_wrapper.compute_ib_cavi"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.inference_wrapper.compute_ib_cavi"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.shrinkage_groups.make_shrinkage_groups": [[14, 36], ["numpy.shape", "numpy.array().reshape", "numpy.array", "range", "ValueError", "range", "range", "range", "range", "range"], "function", ["None"], ["", "def", "make_shrinkage_groups", "(", "\n", "shrinkage_grouping_strategy", ":", "ShrinkageGroupingStrategy", ",", "beta_mean", ":", "NumpyArray2D", "\n", ")", "->", "NumpyArray2D", ":", "\n", "    ", "num_covariates", ",", "num_categories", "=", "np", ".", "shape", "(", "beta_mean", ")", "\n", "if", "shrinkage_grouping_strategy", "==", "ShrinkageGroupingStrategy", ".", "FREE", ":", "\n", "        ", "indices", "=", "[", "i", "for", "i", "in", "range", "(", "num_covariates", "*", "num_categories", ")", "]", "\n", "", "elif", "(", "\n", "shrinkage_grouping_strategy", "\n", "==", "ShrinkageGroupingStrategy", ".", "FREE_INTERCEPTS_BUT_GROUPS_FOR_OTHER_COVARIATES", "\n", ")", ":", "\n", "        ", "indices_for_intercepts", "=", "[", "i", "for", "i", "in", "range", "(", "num_categories", ")", "]", "\n", "indices_for_other_covariates", "=", "[", "\n", "i", "+", "num_categories", "\n", "for", "i", "in", "range", "(", "(", "num_covariates", "-", "1", ")", ")", "\n", "for", "j", "in", "range", "(", "num_categories", ")", "\n", "]", "\n", "indices", "=", "indices_for_intercepts", "+", "indices_for_other_covariates", "\n", "", "elif", "shrinkage_grouping_strategy", "==", "ShrinkageGroupingStrategy", ".", "COVARIATES", ":", "\n", "        ", "indices", "=", "[", "i", "for", "i", "in", "range", "(", "num_covariates", ")", "for", "j", "in", "range", "(", "num_categories", ")", "]", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"I don't understand the shrinkage grouping strategy\"", ")", "\n", "", "return", "np", ".", "array", "(", "indices", ")", ".", "reshape", "(", "num_covariates", ",", "num_categories", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.tau_helpers.compute_expected_tau_reciprocal_array": [[42, 64], ["numpy.shape", "numpy.zeros", "range", "range", "categorical_from_binary.selection.gig.compute_expected_reciprocal_of_gig_random_variable_with_my_parameter_labeling"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.selection.gig.compute_expected_reciprocal_of_gig_random_variable_with_my_parameter_labeling"], [")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Each regression coefficient beta_m has its own variance tau_m.  This computes the variational\n    expectation of E[1/tau_m], which is needed in the coordinate ascent variational inference.\n\n    Arguments:\n        variational_tau_d_component: One component of the `d` vector from the\n            VariationalTau object.\n    \"\"\"", "\n", "hp", "=", "hyperparameters", "\n", "qd_m", "=", "variational_tau_d_component", "\n", "return", "(", "bessel2", "(", "hp", ".", "lambda_", "+", "0.5", ",", "np", ".", "sqrt", "(", "qd_m", ")", "/", "hp", ".", "gamma", ")", ")", "/", "(", "\n", "hp", ".", "gamma", "*", "np", ".", "sqrt", "(", "qd_m", ")", "*", "(", "bessel2", "(", "hp", ".", "lambda_", "-", "0.5", ",", "np", ".", "sqrt", "(", "qd_m", ")", "/", "hp", ".", "gamma", ")", ")", "\n", ")", "-", "(", "2", "*", "hp", ".", "lambda_", "-", "1", ")", "/", "(", "qd_m", ")", "\n", "\n", "\n", "", "def", "compute_expected_tau_reciprocal_matrix", "(", "\n", "variational_taus", ":", "VariationalTaus", ",", "hyperparameters", ":", "Hyperparameters", "\n", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.approximation_error.compute_approximation_error_in_category_probs_using_l1_distance": [[6, 14], ["numpy.sum", "numpy.abs"], "function", ["None"], ["def", "compute_approximation_error_in_category_probs_using_l1_distance", "(", "\n", "cat_probs_1", ":", "NumpyArray2D", ",", "\n", "cat_probs_2", ":", "NumpyArray2D", ",", "\n", ")", "->", "NumpyArray1D", ":", "\n", "    ", "\"\"\"\n    cat probs have shape (N,K), where N is the number of samples and K is the number of categories.\n    \"\"\"", "\n", "return", "np", ".", "sum", "(", "np", ".", "abs", "(", "cat_probs_1", "-", "cat_probs_2", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.approximation_error.compute_mean_approximation_error_in_category_probs_using_l1_distance": [[16, 24], ["numpy.mean", "numpy.abs"], "function", ["None"], ["", "def", "compute_mean_approximation_error_in_category_probs_using_l1_distance", "(", "\n", "cat_probs_1", ":", "NumpyArray2D", ",", "\n", "cat_probs_2", ":", "NumpyArray2D", ",", "\n", ")", "->", "NumpyArray1D", ":", "\n", "    ", "\"\"\"\n    cat probs have shape (N,K), where N is the number of samples and K is the number of categories.\n    \"\"\"", "\n", "return", "np", ".", "mean", "(", "np", ".", "abs", "(", "cat_probs_1", "-", "cat_probs_2", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.approximation_error.compute_signed_error_in_largest_category_probs": [[26, 37], ["numpy.argmax", "numpy.array", "numpy.array", "enumerate", "enumerate"], "function", ["None"], ["", "def", "compute_signed_error_in_largest_category_probs", "(", "\n", "cat_probs_estimated", ":", "NumpyArray2D", ",", "\n", "cat_probs_ground_truth", ":", "NumpyArray2D", ",", "\n", ")", "->", "NumpyArray1D", ":", "\n", "    ", "predicted_categories", "=", "np", ".", "argmax", "(", "cat_probs_estimated", ",", "1", ")", "\n", "# TODO: there should be a simpler way to write the below.  I basically want", "\n", "# cat_probs_estimated[:,predicted_categories]-cat_probs_ground_truth[:,predicted_categories]", "\n", "return", "np", ".", "array", "(", "\n", "[", "cat_probs_estimated", "[", "i", ",", "k", "]", "for", "(", "i", ",", "k", ")", "in", "enumerate", "(", "predicted_categories", ")", "]", "\n", ")", "-", "np", ".", "array", "(", "\n", "[", "cat_probs_ground_truth", "[", "i", ",", "k", "]", "for", "(", "i", ",", "k", ")", "in", "enumerate", "(", "predicted_categories", ")", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.approximation_error.compute_kl_divergence_from_estimated_to_true_category_probs": [[40, 62], ["numpy.sum", "numpy.sum", "numpy.log", "numpy.log"], "function", ["None"], ["", "def", "compute_kl_divergence_from_estimated_to_true_category_probs", "(", "\n", "cat_probs_estimated", ":", "NumpyArray2D", ",", "\n", "cat_probs_true", ":", "NumpyArray2D", ",", "\n", "epsilon", ":", "float", "=", "1e-20", ",", "\n", ")", "->", "NumpyArray1D", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        cat_probs_estimated: has shape (N,K), where N is the number of samples and K is the number of categories.\n        cat_probs_true: has shape (N,K), where N is the number of samples and K is the number of categories.\n        epsilon: minimum value for a probability component; must be bounded away from 0, because the KL\n            divergence requires computing log(p_ik), which is NaN if p_ik=0.\n    Returns:\n        array of shape (N,)\n    \"\"\"", "\n", "# lower bound probability vector components to be slightly away from zero, because KL divergence requires", "\n", "# computing log(p_ik)", "\n", "for", "cat_probs", "in", "[", "cat_probs_estimated", ",", "cat_probs_true", "]", ":", "\n", "        ", "cat_probs", "+=", "epsilon", "\n", "cat_probs", "/=", "np", ".", "sum", "(", "cat_probs", ",", "1", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "\n", "", "return", "np", ".", "sum", "(", "\n", "cat_probs_true", "*", "(", "np", ".", "log", "(", "cat_probs_true", ")", "-", "np", ".", "log", "(", "cat_probs_estimated", ")", ")", ",", "1", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.normalizing_constants.compute_log_Cs_CBC_probit": [[15, 40], ["numpy.zeros", "range", "numpy.shape", "numpy.shape", "range", "numpy.log", "numpy.prod", "numpy.ones", "H"], "function", ["None"], ["def", "compute_log_Cs_CBC_probit", "(", "\n", "covariates", ":", "NumpyArray2D", ",", "beta", ":", "NumpyArray2D", "\n", ")", "->", "NumpyArray1D", ":", "\n", "    ", "\"\"\"\n    Returns the normalizing constant for the complete data likelihood of the\n    CBC probit model. There is one for each observation.\n\n    These are called \"C\" in the UAI-TPM workshop paper.\n    \"\"\"", "\n", "H", "=", "scipy", ".", "stats", ".", "norm", ".", "cdf", "\n", "X", "=", "covariates", "\n", "K", "=", "np", ".", "shape", "(", "beta", ")", "[", "1", "]", "\n", "N", "=", "np", ".", "shape", "(", "X", ")", "[", "0", "]", "\n", "log_Cs", "=", "np", ".", "zeros", "(", "N", ")", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "        ", "C_i", "=", "0", "\n", "x_i", "=", "X", "[", "i", ",", ":", "]", "\n", "etas_i", "=", "x_i", "@", "beta", "\n", "for", "k", "in", "range", "(", "K", ")", ":", "\n", "            ", "signs", "=", "-", "np", ".", "ones", "(", "K", ")", "\n", "signs", "[", "k", "]", "=", "1", "\n", "signed_etas_i", "=", "etas_i", "*", "signs", "\n", "C_i", "+=", "np", ".", "prod", "(", "H", "(", "signed_etas_i", ")", ")", "\n", "", "log_Cs", "[", "i", "]", "=", "np", ".", "log", "(", "C_i", ")", "\n", "", "return", "log_Cs", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.normalizing_constants.compute_log_Cs_CBM_probit": [[42, 70], ["numpy.argmax", "numpy.zeros", "range", "numpy.shape", "numpy.shape", "range", "numpy.log", "numpy.delete", "H", "numpy.prod", "H"], "function", ["None"], ["", "def", "compute_log_Cs_CBM_probit", "(", "\n", "covariates", ":", "NumpyArray2D", ",", "beta", ":", "NumpyArray2D", ",", "labels", ":", "NumpyArray2D", "\n", ")", "->", "NumpyArray1D", ":", "\n", "    ", "\"\"\"\n    Returns the normalizing constant for the complete data likelihood of the\n    CBM probit model. There is one for each observation.\n\n    These are called \"C\" in the UAI-TPM workshop paper.\n    \"\"\"", "\n", "choices", "=", "np", ".", "argmax", "(", "labels", ",", "1", ")", "\n", "H", "=", "scipy", ".", "stats", ".", "norm", ".", "cdf", "\n", "X", "=", "covariates", "\n", "K", "=", "np", ".", "shape", "(", "beta", ")", "[", "1", "]", "\n", "N", "=", "np", ".", "shape", "(", "X", ")", "[", "0", "]", "\n", "log_Cs", "=", "np", ".", "zeros", "(", "N", ")", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "        ", "C_i", "=", "0", "\n", "x_i", "=", "X", "[", "i", ",", ":", "]", "\n", "etas_i", "=", "x_i", "@", "beta", "\n", "choice_id", "=", "choices", "[", "i", "]", "\n", "negative_etas_i_nonselected", "=", "-", "np", ".", "delete", "(", "etas_i", ",", "choice_id", ")", "\n", "for", "k", "in", "range", "(", "K", ")", ":", "\n", "            ", "cdf_of_eta_for_current_category", "=", "H", "(", "etas_i", "[", "k", "]", ")", "\n", "C_i", "+=", "cdf_of_eta_for_current_category", "*", "np", ".", "prod", "(", "\n", "H", "(", "negative_etas_i_nonselected", ")", "\n", ")", "\n", "", "log_Cs", "[", "i", "]", "=", "np", ".", "log", "(", "C_i", ")", "\n", "", "return", "log_Cs", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.normalizing_constants.compute_sum_of_IB_probs": [[72, 86], ["H", "numpy.sum"], "function", ["None"], ["", "def", "compute_sum_of_IB_probs", "(", "\n", "covariates", ":", "NumpyArray2D", ",", "beta", ":", "NumpyArray2D", "\n", ")", "->", "NumpyArray1D", ":", "\n", "    ", "\"\"\"\n    The sum of IB probs is the the normalizing constant for the\n    CBM's MARGINAL data likelihood (i.e. category probability formula, after\n    marginalizing out the CBC variable \"z\").\n\n    There is one for each observation.\n    \"\"\"", "\n", "H", "=", "scipy", ".", "stats", ".", "norm", ".", "cdf", "\n", "etas", "=", "covariates", "@", "beta", "\n", "IB_probs", "=", "H", "(", "etas", ")", "\n", "return", "np", ".", "sum", "(", "IB_probs", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.normalizing_constants.compute_log_sum_of_psis": [[88, 106], ["numpy.sum", "numpy.log", "H", "H"], "function", ["None"], ["", "def", "compute_log_sum_of_psis", "(", "\n", "covariates", ":", "NumpyArray2D", ",", "beta", ":", "NumpyArray2D", "\n", ")", "->", "NumpyArray1D", ":", "\n", "    ", "\"\"\"\n    The sum of psis is the the normalizing constant for the\n    CBC's MARGINAL data likelihood (i.e. category probability formula, after\n    marginalizing out the CBC variable \"z\"), when using the ALTERNATE expression\n    (called \"psi\" in the UAI-TPM workshop paper and various reports by Mike H and I).\n\n    We return the log because these can get VERY large.\n\n    There is one for each observation.\n    \"\"\"", "\n", "H", "=", "scipy", ".", "stats", ".", "norm", ".", "cdf", "\n", "etas", "=", "covariates", "@", "beta", "\n", "psis", "=", "H", "(", "etas", ")", "/", "H", "(", "-", "etas", ")", "# psi is the name from the UAI-TPM workshop paper", "\n", "sum_of_psis", "=", "np", ".", "sum", "(", "psis", ",", "1", ")", "\n", "return", "np", ".", "log", "(", "sum_of_psis", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.bma.compute_weight_on_CBC_from_bayesian_model_averaging": [[23, 61], ["categorical_from_binary.ib_cavi.multi.inference.cbm_link_from_ib_model", "categorical_from_binary.ib_cavi.multi.inference.cbc_link_from_ib_model", "categorical_from_binary.ib_cavi.cbm_vs_cbc.real_elbo.approximate_true_elbo_with_samples", "categorical_from_binary.ib_cavi.cbm_vs_cbc.real_elbo.approximate_true_elbo_with_samples", "numpy.exp", "scipy.special.logsumexp"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.inference.cbm_link_from_ib_model", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.inference.cbc_link_from_ib_model", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.real_elbo.approximate_true_elbo_with_samples", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.real_elbo.approximate_true_elbo_with_samples"], ["def", "compute_weight_on_CBC_from_bayesian_model_averaging", "(", "\n", "covariates_train", ":", "NumpyArray2D", ",", "\n", "labels_train", ":", "NumpyArray2D", ",", "\n", "variational_beta", ":", "VariationalBeta", ",", "\n", "n_monte_carlo_samples", ":", "int", ",", "\n", "ib_model", ":", "IB_Model", ",", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Compute weight on CBC model in an (approximate) Bayesian Model Averaging of CBC and CBM\n    using the approximate posterior from IB fit with mean-field variational inference.\n    Assumes the CBC and CBM are equally weighted in the prior.\n\n    The Bayesian Model Averaging is approximate because we use ELBO_m as approximations to\n    the evidence p_m(x) for models m in set(CBM, CBC).\n    \"\"\"", "\n", "cbm_link", "=", "cbm_link_from_ib_model", "(", "ib_model", ")", "\n", "cbc_link", "=", "cbc_link_from_ib_model", "(", "ib_model", ")", "\n", "\n", "elbo_hat_CBM", "=", "approximate_true_elbo_with_samples", "(", "\n", "covariates_train", ",", "\n", "labels_train", ",", "\n", "cbm_link", ",", "\n", "variational_beta", ",", "\n", "n_monte_carlo_samples", ",", "\n", ")", "\n", "elbo_hat_CBC", "=", "approximate_true_elbo_with_samples", "(", "\n", "covariates_train", ",", "\n", "labels_train", ",", "\n", "cbc_link", ",", "\n", "variational_beta", ",", "\n", "n_monte_carlo_samples", ",", "\n", ")", "\n", "\n", "# use that to derive model weight (assuming 50/50 prior on each )", "\n", "CBC_weight", "=", "np", ".", "exp", "(", "\n", "elbo_hat_CBC", "-", "scipy", ".", "special", ".", "logsumexp", "(", "[", "elbo_hat_CBM", ",", "elbo_hat_CBC", "]", ")", "\n", ")", "\n", "return", "CBC_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.bma.construct_category_probabilities_from_bayesian_model_averaging": [[63, 79], ["categorical_from_binary.ib_cavi.multi.inference.cbm_link_from_ib_model", "categorical_from_binary.ib_cavi.multi.inference.cbc_link_from_ib_model", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_category_probs", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_category_probs"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.inference.cbm_link_from_ib_model", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.inference.cbc_link_from_ib_model", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs"], ["", "def", "construct_category_probabilities_from_bayesian_model_averaging", "(", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "variational_beta_point_estimate", ":", "NumpyArray2D", ",", "\n", "CBC_weight", ":", "float", ",", "\n", "ib_model", ":", "IB_Model", ",", "\n", ")", "->", "NumpyArray2D", ":", "\n", "\n", "    ", "cbm_link", "=", "cbm_link_from_ib_model", "(", "ib_model", ")", "\n", "cbc_link", "=", "cbc_link_from_ib_model", "(", "ib_model", ")", "\n", "probs_CBM", "=", "construct_category_probs", "(", "\n", "covariates", ",", "variational_beta_point_estimate", ",", "cbm_link", "\n", ")", "\n", "probs_CBC", "=", "construct_category_probs", "(", "\n", "covariates", ",", "variational_beta_point_estimate", ",", "cbc_link", "\n", ")", "\n", "return", "CBC_weight", "*", "probs_CBC", "+", "(", "1", "-", "CBC_weight", ")", "*", "probs_CBM", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.combinations.choose_IB_plus_CBC_iff_sum_of_IB_probs_exceeds_unity": [[25, 44], ["numpy.copy"], "function", ["None"], ["", "def", "choose_IB_plus_CBC_iff_sum_of_IB_probs_exceeds_unity", "(", "\n", "CBC_predictions_with_IB_MLE", ":", "NumpyArray2D", ",", "\n", "CBM_predictions_with_IB_MLE", ":", "NumpyArray1D", ",", "\n", "sum_of_IB_probs", ":", "NumpyArray1D", ",", "\n", ")", "->", "NumpyArray2D", ":", "\n", "    ", "\"\"\"\n    Returns:\n        New category probabilities that select, on a per sample basis,\n        from the two input category probabilities.  This is\n        an array of shape (N,K), where K is the number of categories.\n        The n-th row gives a point on the simplex - a pmf over {1,...,K}.\n    \"\"\"", "\n", "\n", "# make combined predictions (need to convert to numpy arrays first)", "\n", "combined_predictions_with_IB_MLE", "=", "np", ".", "copy", "(", "CBC_predictions_with_IB_MLE", ")", "\n", "combined_predictions_with_IB_MLE", "[", "\n", "sum_of_IB_probs", "<=", "1", "\n", "]", "=", "CBM_predictions_with_IB_MLE", "[", "sum_of_IB_probs", "<=", "1", "]", "\n", "return", "combined_predictions_with_IB_MLE", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.combinations.choose_IB_plus_CBC_iff_prob_cbc_exceeds_half": [[46, 81], ["numpy.copy", "numpy.exp"], "function", ["None"], ["", "def", "choose_IB_plus_CBC_iff_prob_cbc_exceeds_half", "(", "\n", "CBC_predictions_with_IB_MLE", ":", "NumpyArray2D", ",", "\n", "CBM_predictions_with_IB_MLE", ":", "NumpyArray1D", ",", "\n", "log_Cs_CBC", ":", "NumpyArray1D", ",", "\n", ")", "->", "NumpyArray2D", ":", "\n", "    ", "\"\"\"\n    If probability mass in the set of diagonally opposed orthants where exactly one component is positive\n    (i.e. where exactly one binary one-vs-rest classifier assigns the probability\n    of success to be greater than .50) exceeds half, then we consider things predictable,\n    and so we prefer CBC over CBM.\n\n    Warning:\n        It is highly recommended that you use `combine_plus_CBC_and_plus_CBM_via_cbc_probability`\n        instead.   This is a similar function, but it weights the IB+CBM and IB+CBC category probabilities\n        according to the probability mass in the CBC set, instead of making a hard selection.\n\n        Why prefer the averaged approach?\n        First off, the threshold whereby the probability mass contained in the CBC set\n        \"exceeds half\" is arbitrary, and may not scale as K or other settings change.  Second, early\n        empirical results suggest that the averaged approach does much better in reducing error without\n        incurring a cost.\n\n    Returns:\n        New category probabilities that select, on a per sample basis,\n        from the two input category probabilities.  This is\n        an array of shape (N,K), where K is the number of categories.\n        The n-th row gives a point on the simplex - a pmf over {1,...,K}.\n    \"\"\"", "\n", "# make combined predictions (need to convert to numpy arrays first)", "\n", "combined_predictions_with_IB_MLE", "=", "np", ".", "copy", "(", "CBM_predictions_with_IB_MLE", ")", "\n", "prob_cbc", "=", "np", ".", "exp", "(", "log_Cs_CBC", ")", "\n", "combined_predictions_with_IB_MLE", "[", "prob_cbc", ">=", "0.5", "]", "=", "CBC_predictions_with_IB_MLE", "[", "\n", "prob_cbc", ">=", "0.5", "\n", "]", "\n", "return", "combined_predictions_with_IB_MLE", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.combinations.weigh_ib_plus_do_via_probability_that_ib_is_in_do_region": [[83, 93], ["combinations._combine_plus_CBC_and_plus_CBM_via_cbc_probability"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.combinations._combine_plus_CBC_and_plus_CBM_via_cbc_probability"], ["", "def", "weigh_ib_plus_do_via_probability_that_ib_is_in_do_region", "(", "\n", "CBC_predictions_with_IB_MLE", ":", "NumpyArray2D", ",", "\n", "CBM_predictions_with_IB_MLE", ":", "NumpyArray1D", ",", "\n", "log_Cs_CBC", ":", "NumpyArray1D", ",", "\n", ")", ":", "\n", "    ", "return", "_combine_plus_CBC_and_plus_CBM_via_cbc_probability", "(", "\n", "CBC_predictions_with_IB_MLE", ",", "\n", "CBM_predictions_with_IB_MLE", ",", "\n", "log_Cs_CBC", ",", "\n", "override_to_only_use_IB_plus_CBM_when_IB_assigns_less_than_half_of_its_mass_to_the_CBC_set", "=", "False", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.combinations.weigh_ib_plus_do_via_probability_that_ib_is_in_do_region_but_override_to_only_use_ib_plus_sdo_when_ib_assigns_less_than_half_of_its_mass_to_the_do_set": [[96, 106], ["combinations._combine_plus_CBC_and_plus_CBM_via_cbc_probability"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.combinations._combine_plus_CBC_and_plus_CBM_via_cbc_probability"], ["", "def", "weigh_ib_plus_do_via_probability_that_ib_is_in_do_region_but_override_to_only_use_ib_plus_sdo_when_ib_assigns_less_than_half_of_its_mass_to_the_do_set", "(", "\n", "CBC_predictions_with_IB_MLE", ":", "NumpyArray2D", ",", "\n", "CBM_predictions_with_IB_MLE", ":", "NumpyArray1D", ",", "\n", "log_Cs_CBC", ":", "NumpyArray1D", ",", "\n", ")", ":", "\n", "    ", "return", "_combine_plus_CBC_and_plus_CBM_via_cbc_probability", "(", "\n", "CBC_predictions_with_IB_MLE", ",", "\n", "CBM_predictions_with_IB_MLE", ",", "\n", "log_Cs_CBC", ",", "\n", "override_to_only_use_IB_plus_CBM_when_IB_assigns_less_than_half_of_its_mass_to_the_CBC_set", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.combinations._combine_plus_CBC_and_plus_CBM_via_cbc_probability": [[109, 138], ["numpy.exp"], "function", ["None"], ["", "def", "_combine_plus_CBC_and_plus_CBM_via_cbc_probability", "(", "\n", "CBC_predictions_with_IB_MLE", ":", "NumpyArray2D", ",", "\n", "CBM_predictions_with_IB_MLE", ":", "NumpyArray1D", ",", "\n", "log_Cs_CBC", ":", "NumpyArray1D", ",", "\n", "override_to_only_use_IB_plus_CBM_when_IB_assigns_less_than_half_of_its_mass_to_the_CBC_set", ":", "bool", ",", "\n", ")", "->", "NumpyArray2D", ":", "\n", "    ", "\"\"\"\n    The higher the probability mass that the IB model assigns to the set of\n    diagonally opposed orthants where exactly one component is positive,\n    (i.e. where exactly one binary one-vs-rest classifier assigns the probability\n    of success to be greater than .50), the more predictable things are, and the more we prefer CBC.\n\n    Returns:\n        New category probabilities that select, on a per sample basis,\n        from the two input category probabilities.  This is\n        an array of shape (N,K), where K is the number of categories.\n        The n-th row gives a point on the simplex - a pmf over {1,...,K}.\n    \"\"\"", "\n", "# make combined predictions (need to convert to numpy arrays first)", "\n", "prob_cbc", "=", "np", ".", "exp", "(", "log_Cs_CBC", ")", "\n", "combined_predictions", "=", "(", "\n", "prob_cbc", "[", ":", ",", "np", ".", "newaxis", "]", "*", "CBC_predictions_with_IB_MLE", "\n", "+", "(", "1", "-", "prob_cbc", "[", ":", ",", "np", ".", "newaxis", "]", ")", "*", "CBM_predictions_with_IB_MLE", "\n", ")", "\n", "if", "override_to_only_use_IB_plus_CBM_when_IB_assigns_less_than_half_of_its_mass_to_the_CBC_set", ":", "\n", "        ", "combined_predictions", "[", "prob_cbc", "<=", "0.5", "]", "=", "CBM_predictions_with_IB_MLE", "[", "\n", "prob_cbc", "<=", "0.5", "\n", "]", "\n", "", "return", "combined_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.combinations.construct_combined_category_probabilities": [[148, 177], ["function_to_combine_category_probabilities", "ValueError"], "function", ["None"], ["def", "construct_combined_category_probabilities", "(", "\n", "CBC_predictions_with_IB_MLE", ":", "NumpyArray2D", ",", "\n", "CBM_predictions_with_IB_MLE", ":", "NumpyArray1D", ",", "\n", "log_Cs_CBC", ":", "NumpyArray1D", ",", "\n", "sum_of_IB_probs", ":", "NumpyArray1D", ",", "\n", "combination_rule", ":", "CombinationRule", ",", "\n", ")", ":", "\n", "    ", "if", "(", "\n", "combination_rule", "\n", "==", "CombinationRule", ".", "IB_PLUS_CBC_IFF_SUM_OF_IB_PROBS_EXCEEDS_UNITY", "\n", ")", ":", "\n", "        ", "combination_basis", "=", "sum_of_IB_probs", "\n", "", "elif", "(", "\n", "combination_rule", "\n", "==", "CombinationRule", ".", "IB_PLUS_CBC_IFF_SUM_OF_IB_PROBS_EXCEEDS_UNITY", "\n", "or", "combination_rule", "\n", "==", "CombinationRule", ".", "WEIGH_IB_PLUS_CBC_VIA_PROBABILITY_THAT_IB_IS_IN_CBC_REGION", "\n", "or", "combination_rule", "\n", "==", "CombinationRule", ".", "WEIGH_IB_PLUS_CBC_VIA_PROBABILITY_THAT_IB_IS_IN_CBC_REGION_BUT_OVERRIDE_TO_ONLY_USE_IB_PLUS_CBM_WHEN_IB_ASSIGNS_LESS_THAN_HALF_OF_ITS_MASS_TO_THE_CBC_SET", "\n", ")", ":", "\n", "        ", "combination_basis", "=", "log_Cs_CBC", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"I don't understand the combination rule {combination_rule}\"", ")", "\n", "\n", "", "function_to_combine_category_probabilities", "=", "(", "\n", "COMBINATION_FUNCTION_BY_COMBINATION_RULE", "[", "combination_rule", "]", "\n", ")", "\n", "return", "function_to_combine_category_probabilities", "(", "\n", "CBC_predictions_with_IB_MLE", ",", "CBM_predictions_with_IB_MLE", ",", "combination_basis", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.real_elbo.estimate_energy_with_one_sample": [[17, 53], ["numpy.shape", "numpy.argmax", "numpy.shape", "numpy.zeros", "range", "range", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_category_probs", "numpy.log", "numpy.zeros", "numpy.eye", "scipy.stats.multivariate_normal().rvs", "scipy.stats.multivariate_normal().logpdf", "numpy.array", "numpy.sum", "numpy.ndim", "numpy.ndim", "ValueError", "scipy.stats.multivariate_normal", "scipy.stats.multivariate_normal", "enumerate"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs"], ["def", "estimate_energy_with_one_sample", "(", "\n", "features", ",", "labels", ",", "link", ",", "variational_beta", ",", "prior_beta_mean", "=", "None", ",", "prior_beta_cov", "=", "None", "\n", ")", "->", "float", ":", "\n", "    ", "beta_mean", ",", "beta_cov", "=", "variational_beta", ".", "mean", ",", "variational_beta", ".", "cov", "\n", "M", ",", "K", "=", "np", ".", "shape", "(", "beta_mean", ")", "\n", "\n", "if", "prior_beta_mean", "is", "None", ":", "\n", "        ", "prior_beta_mean", "=", "np", ".", "zeros", "(", "(", "M", ",", "K", ")", ")", "\n", "", "if", "prior_beta_cov", "is", "None", ":", "\n", "        ", "prior_beta_cov", "=", "np", ".", "eye", "(", "M", ")", "\n", "\n", "", "choices", "=", "np", ".", "argmax", "(", "labels", ",", "1", ")", "\n", "M", ",", "K", "=", "np", ".", "shape", "(", "beta_mean", ")", "\n", "beta_sample", "=", "np", ".", "zeros", "(", "(", "M", ",", "K", ")", ")", "\n", "for", "k", "in", "range", "(", "K", ")", ":", "\n", "        ", "if", "np", ".", "ndim", "(", "beta_cov", ")", "==", "3", ":", "\n", "            ", "beta_cov_for_this_category", "=", "beta_cov", "[", ":", ",", ":", ",", "k", "]", "\n", "", "elif", "np", ".", "ndim", "(", "beta_cov", ")", "==", "2", ":", "\n", "            ", "beta_cov_for_this_category", "=", "beta_cov", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Not sure how to get beta covariance for one category.\"", ")", "\n", "\n", "", "beta_sample", "[", ":", ",", "k", "]", "=", "scipy", ".", "stats", ".", "multivariate_normal", "(", "\n", "beta_mean", "[", ":", ",", "k", "]", ",", "beta_cov_for_this_category", "\n", ")", ".", "rvs", "(", ")", "\n", "\n", "# compute log_prior", "\n", "", "log_prior", "=", "0", "\n", "for", "k", "in", "range", "(", "K", ")", ":", "\n", "        ", "log_prior", "+=", "scipy", ".", "stats", ".", "multivariate_normal", "(", "\n", "prior_beta_mean", "[", ":", ",", "k", "]", ",", "prior_beta_cov", "\n", ")", ".", "logpdf", "(", "beta_sample", "[", ":", ",", "k", "]", ")", "\n", "\n", "", "probs", "=", "construct_category_probs", "(", "features", ",", "beta_sample", ",", "link", ")", "\n", "log_choice_probs", "=", "np", ".", "log", "(", "np", ".", "array", "(", "[", "probs", "[", "i", ",", "k", "]", "for", "(", "i", ",", "k", ")", "in", "enumerate", "(", "choices", ")", "]", ")", ")", "\n", "return", "log_prior", "+", "np", ".", "sum", "(", "log_choice_probs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.real_elbo.approximate_true_elbo_with_samples": [[55, 81], ["numpy.mean", "categorical_from_binary.ib_cavi.multi.ib_probit.elbo.compute_variational_entropy_of_beta", "real_elbo.estimate_energy_with_one_sample", "range"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit.elbo.compute_variational_entropy_of_beta", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cbm_vs_cbc.real_elbo.estimate_energy_with_one_sample"], ["", "def", "approximate_true_elbo_with_samples", "(", "\n", "features", ",", "\n", "labels", ",", "\n", "link", ",", "\n", "variational_beta", ",", "\n", "n_monte_carlo_samples", ",", "\n", "prior_beta_mean", "=", "None", ",", "\n", "prior_beta_cov", "=", "None", ",", "\n", ")", "->", "float", ":", "\n", "    ", "energy_hat", "=", "np", ".", "mean", "(", "\n", "[", "\n", "estimate_energy_with_one_sample", "(", "\n", "features", ",", "\n", "labels", ",", "\n", "link", ",", "\n", "variational_beta", ",", "\n", "prior_beta_mean", ",", "\n", "prior_beta_cov", ",", "\n", ")", "\n", "for", "s", "in", "range", "(", "n_monte_carlo_samples", ")", "\n", "]", "\n", ")", "\n", "entropy_exact", "=", "compute_variational_entropy_of_beta", "(", "\n", "variational_beta", ".", "mean", ",", "variational_beta", ".", "cov", "\n", ")", "\n", "return", "energy_hat", "+", "entropy_exact", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.design_matrix.construct_design_matrix": [[10, 64], ["numpy.shape", "warnings.warn", "numpy.vstack", "numpy.hstack", "warnings.warn", "numpy.shape", "numpy.eye", "numpy.shape", "numpy.ones"], "function", ["None"], ["def", "construct_design_matrix", "(", "\n", "covariates", ":", "Union", "[", "NumpyArray2D", ",", "spmatrix", "]", ",", "\n", "labels", ":", "Union", "[", "NumpyArray2D", ",", "spmatrix", "]", ",", "\n", "use_autoregressive_design_matrix", ":", "bool", "=", "False", ",", "\n", ")", "->", "Union", "[", "NumpyArray2D", ",", "spmatrix", "]", ":", "\n", "    ", "\"\"\"\n    Construct a design matrix for a CBC model.\n\n    If we are using an autoregressive model, we:\n        * Ensure there is not already a column of all ones in the provided covariates matrix\n        * Prepend one-hot encoded representation of the previous categories as predictors for the upcoming category.\n\n    Note that the category labels are only actually needed to construct the design matrix if we are using an autoregressive\n    model.\n\n    Returns:\n        A sparse matrix if `covariates` was sparse, else a dense np.array.\n    \"\"\"", "\n", "n_samples", ",", "n_categories", "=", "np", ".", "shape", "(", "labels", ")", "\n", "\n", "if", "not", "use_autoregressive_design_matrix", ":", "\n", "        ", "design_matrix", "=", "covariates", "\n", "", "else", ":", "\n", "# Covariates shouldnt have a vector of all ones for the autoregressive model.", "\n", "# If the model is autoregressive, we remove that column.", "\n", "        ", "first_column_of_covariates_is_all_ones", "=", "(", "\n", "covariates", "[", ":", ",", "0", "]", "\n", "==", "np", ".", "ones", "(", "\n", "n_samples", ",", "\n", ")", "\n", ")", ".", "all", "(", ")", "\n", "if", "first_column_of_covariates_is_all_ones", ":", "\n", "            ", "warnings", ".", "warn", "(", "\n", "f\" The first column of covariates is all ones. We do not construct \"", "\n", "f\"the design matrix in this way for the autoregressive setting, because we decompose \"", "\n", "f\"the intercept term into K intercept terms, one for each of the K possible classes \"", "\n", "f\"that were inhabited at the preceding time step\"", "\n", ")", "\n", "covariates_to_use", "=", "covariates", "[", ":", ",", "1", ":", "]", "\n", "", "else", ":", "\n", "            ", "covariates_to_use", "=", "covariates", "\n", "\n", "# TODO: Automatically check that the code doesn't have", "\n", "", "n_covariates_to_use", "=", "np", ".", "shape", "(", "covariates_to_use", ")", "[", "1", "]", "\n", "\n", "# Construct previous labels, and prepend to covariates to make design matrix", "\n", "warnings", ".", "warn", "(", "\"Taking the initial category to be the smallest one.\"", ")", "\n", "label_init", "=", "np", ".", "eye", "(", "n_categories", ")", "[", "0", "]", "# init label is arbitrary", "\n", "# TODO: need better handling for 0th label.... don't know what the previous label is ....", "\n", "# current init label scheme is going to be crappy... but using it for now.", "\n", "labels_prev", "=", "np", ".", "vstack", "(", "(", "label_init", ",", "labels", "[", ":", "-", "1", ",", ":", "]", ")", ")", "\n", "design_matrix", "=", "np", ".", "hstack", "(", "(", "labels_prev", ",", "covariates_to_use", ")", ")", "\n", "assert", "np", ".", "shape", "(", "design_matrix", ")", "[", "1", "]", "==", "n_categories", "+", "n_covariates_to_use", "\n", "", "return", "design_matrix", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.inference.compute_ib_cavi_with_normal_prior": [[31, 67], ["inference_function", "ValueError"], "function", ["None"], ["", "def", "compute_ib_cavi_with_normal_prior", "(", "\n", "ib_model", ":", "IB_Model", ",", "\n", "labels", ":", "Union", "[", "NumpyArray2D", ",", "spmatrix", "]", ",", "\n", "covariates", ":", "Union", "[", "NumpyArray2D", ",", "spmatrix", "]", ",", "\n", "max_n_iterations", ":", "float", "=", "np", ".", "inf", ",", "\n", "convergence_criterion_drop_in_mean_elbo", ":", "float", "=", "-", "np", ".", "inf", ",", "\n", "use_autoregressive_design_matrix", ":", "bool", "=", "False", ",", "\n", "labels_test", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "covariates_test", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "prior_beta_mean", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "prior_beta_precision", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "variational_params_init", ":", "Optional", "[", "VariationalParams", "]", "=", "None", ",", "\n", "save_beta_every_secs", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "save_beta_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "verbose", ":", "bool", "=", "True", ",", "\n", ")", "->", "CAVI_Results", ":", "\n", "    ", "if", "ib_model", "is", "IB_Model", ".", "PROBIT", ":", "\n", "        ", "inference_function", "=", "compute_multiclass_probit_vi_with_normal_prior", "\n", "", "elif", "ib_model", "is", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "inference_function", "=", "compute_multiclass_logit_vi_with_polya_gamma_augmentation", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"I don't understand the model type {ib_model}\"", ")", "\n", "", "return", "inference_function", "(", "\n", "labels", ",", "\n", "covariates", ",", "\n", "max_n_iterations", ",", "\n", "convergence_criterion_drop_in_mean_elbo", ",", "\n", "use_autoregressive_design_matrix", ",", "\n", "labels_test", ",", "\n", "covariates_test", ",", "\n", "prior_beta_mean", ",", "\n", "prior_beta_precision", ",", "\n", "variational_params_init", ",", "\n", "save_beta_every_secs", ",", "\n", "save_beta_dir", ",", "\n", "verbose", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.inference.cbm_link_from_ib_model": [[70, 77], ["None"], "function", ["None"], ["", "def", "cbm_link_from_ib_model", "(", "ib_model", ":", "IB_Model", ")", ":", "\n", "    ", "if", "ib_model", "==", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "return", "Link", ".", "CBM_LOGIT", "\n", "", "elif", "ib_model", "==", "IB_Model", ".", "PROBIT", ":", "\n", "        ", "return", "Link", ".", "CBM_PROBIT", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.inference.cbc_link_from_ib_model": [[79, 86], ["None"], "function", ["None"], ["", "", "def", "cbc_link_from_ib_model", "(", "ib_model", ":", "IB_Model", ")", ":", "\n", "    ", "if", "ib_model", "==", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "return", "Link", ".", "CBC_LOGIT", "\n", "", "elif", "ib_model", "==", "IB_Model", ".", "PROBIT", ":", "\n", "        ", "return", "Link", ".", "CBC_PROBIT", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.inference_wrapper.compute_precomputables_dummy": [[40, 47], ["categorical_from_binary.ib_cavi.multi.structs.Precomputables"], "function", ["None"], ["def", "compute_precomputables_dummy", "(", "\n", "variational_params_init", ":", "VariationalParams", ",", "\n", "design_matrix", ":", "NumpyArray2D", ",", "\n", "prior_type", ":", "PriorType", "=", "PriorType", ".", "NORMAL", ",", "\n", "shrinkage_grouping_strategy", ":", "Optional", "[", "ShrinkageGroupingStrategy", "]", "=", "None", ",", "\n", ")", "->", "Precomputables", ":", "\n", "    ", "return", "Precomputables", "(", "None", ",", "None", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.inference_wrapper.compute_ib_cavi": [[49, 360], ["time.time", "categorical_from_binary.ib_cavi.multi.design_matrix.construct_design_matrix", "numpy.shape", "initialize_variational_params", "compute_precomputables", "time.time", "collections.defaultdict", "categorical_from_binary.ib_cavi.multi.structs.ELBO_Stats", "pandas.DataFrame", "categorical_from_binary.ib_cavi.multi.structs.CAVI_Results", "NotImplementedError", "warnings.warn", "ValueError", "ValueError", "scipy.sparse.issparse", "NotImplementedError", "ValueError", "print", "print", "categorical_from_binary.ib_cavi.multi.design_matrix.construct_design_matrix", "categorical_from_binary.ib_cavi.multi.design_matrix.construct_design_matrix", "enumerate", "performance_over_time_as_dict[].append", "performance_over_time_as_dict[].append", "time.time", "update_variational_params_and_elbo_stats", "time.time", "categorical_from_binary.performance_over_time.results.update_performance_results", "time.time", "categorical_from_binary.ib_cavi.multi.design_matrix.construct_design_matrix", "categorical_from_binary.ib_cavi.multi.design_matrix.construct_design_matrix", "enumerate", "time.time", "performance_over_time_as_dict[].append", "performance_over_time_as_dict[].append", "print", "sys.stdout.flush", "categorical_from_binary.performance_over_time.results.update_performance_results", "int", "categorical_from_binary.vi_params.write_VI_params_from_CAVI_results", "categorical_from_binary.ib_cavi.multi.structs.CAVI_Results", "categorical_from_binary.performance_over_time.results.get_most_recent_performance_results_as_string", "divmod"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.design_matrix.construct_design_matrix", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.initialize_variational_params", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_precomputables", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.design_matrix.construct_design_matrix", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.design_matrix.construct_design_matrix", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.update_variational_params_and_elbo_stats", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.results.update_performance_results", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.design_matrix.construct_design_matrix", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.design_matrix.construct_design_matrix", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.results.update_performance_results", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.vi_params.write_VI_params_from_CAVI_results", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.results.get_most_recent_performance_results_as_string"], ["", "def", "compute_ib_cavi", "(", "\n", "labels", ":", "Union", "[", "NumpyArray2D", ",", "spmatrix", "]", ",", "\n", "covariates", ":", "Union", "[", "NumpyArray2D", ",", "spmatrix", "]", ",", "\n", "links_for_category_probabilities", ":", "List", "[", "Link", "]", ",", "\n", "initialize_variational_params", ":", "Callable", ",", "\n", "update_variational_params_and_elbo_stats", ":", "Callable", ",", "\n", "compute_precomputables", ":", "Callable", ",", "\n", "max_n_iterations", ":", "float", "=", "np", ".", "inf", ",", "\n", "convergence_criterion_drop_in_mean_elbo", ":", "float", "=", "-", "np", ".", "inf", ",", "\n", "use_autoregressive_design_matrix", ":", "bool", "=", "False", ",", "\n", "labels_test", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "covariates_test", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "prior_beta_mean", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "prior_beta_precision", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "variational_params_init", ":", "Optional", "[", "VariationalParams", "]", "=", "None", ",", "\n", "prior_type", ":", "PriorType", "=", "PriorType", ".", "NORMAL", ",", "\n", "hyperparameters", ":", "Optional", "[", "Hyperparameters", "]", "=", "None", ",", "\n", "shrinkage_grouping_strategy", ":", "Optional", "[", "ShrinkageGroupingStrategy", "]", "=", "None", ",", "\n", "save_beta_every_secs", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "save_beta_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "verbose", ":", "bool", "=", "True", ",", "\n", ")", "->", "CAVI_Results", ":", "\n", "    ", "\"\"\"\n    A general inference wrapper for doing coordinate ascent variational inference with\n    categorical models.  The inference is done on an\n    independent binary model (Wojnowicz et al 2021), and so one can choose different category probability\n    formulas within which to plug in the resulting betas.  The initial release of this was used by (S)CBC-Probit and CBC-Logit\n    with polya gamma augmentation.\n\n    Arguments:\n        labels: array with shape (n_obs, n_categories)\n            one-hot encoded representations of response categories\n        covariates: array with shape (n_obs, n_covariates)\n            In the autoregressive case, the covariates are only the exogenous covariates;\n            the code automatically constructs the previous category as a feature.\n        convergence_criterion_drop_in_mean_elbo:  We base our convergence criterion on mean ELBO not ELBO!\n            For example, a drop of 1.0 in the ELBO would be HUGE for a small dataset but MINISCULE\n            for a large dataset.  In particular we divide the elbo by NxK, where N is the number of samples and K\n            is the number of categories. So this specification should at least make a good value independent of\n            sample size and number of categories.\n        use_autoregressive_design_matrix: bool\n            If true, the response categories (i.e. labels) are taken to be a sequence, and the model uses\n            the previous response category as a predictor of the upcoming response category.\n        labels_test : Optional\n            If present, we will compute holdout likelihood over time\n        covariates_test : Optional\n            If present, we will compute holdout likelihood over time\n        beta_variational_mean_init: Optional\n            array with shape (beta_dim, )\n            where, if the covariates contain an intercept term,\n                beta_dim = n_covariates (in the non-autoregressive case)\n                         = (n_covariates - 1) + n_categories (in the AR case, if the covariates contain an intercept term)\n                         = n_covariates + n_categories (in the AR case, if the covariates don't contain an intercept term)\n        hyperparameters:  Optional, does not need to be specified if prior_type is NORMAL.\n            does need to be specified if prior_type is NORMAL_GAMMA\n        shrinkage_grouping_strategy: Optional, does not need to be specified if prior_type is NORMAL.\n            does need to be specified if prior_type is NORMAL_GAMMA\n    Returns:\n        CAVI_Results. Includes VariationalParameters.  Which in turn includes:\n            beta_mean, beta_cov: The variational parameters for the normal distribution.\n                beta_mean is an array with shape (beta_dim, n_categories)\n                beta_cov is an array with shape (beta_dim, beta_dim)\n                    note that the covariance is the same for each category, so\n                    we just return a single beta_cov instead of an array\n                    of them with shape (n_categories, )\n    Notes:\n        - (On sparse processing):\n            If we pass in a sparse `covariates` matrix (X), and prior_type is NORMAL,\n            we notice this and do a bunch of sparse computations along the way, including but not necessarily limited to:\n                * We computing XtX in a sparse manner\n                * We compute cov(beta)=(I+XtX)^{-1} in a sparse manner\n                * We compute E_q[Z] in a sparse manner\n            all of which can dramatically speed up the up-front computations when matrices are large and sparse, and can\n            save on memory costs.  Note that we should extend this to the category probability computation and the ELBO.\n\n            We also sparsify the design matrix on the test set data, which\n            can speed up computations of category probabilities due to speeding up of the computation of the linear\n            predictor X_test'beta.\n\n    \"\"\"", "\n", "if", "prior_beta_mean", "is", "not", "None", "or", "prior_beta_precision", "is", "not", "None", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\n", "\"Some computations may still currently assume the prior on beta is N(0,I). Need to double check function body.\"", "\n", ")", "\n", "\n", "", "if", "prior_type", "==", "PriorType", ".", "NORMAL", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "\"We currently assume the prior on beta is N(0,I). Does that mean and variance make sense?\"", "\n", ")", "\n", "\n", "", "if", "prior_type", "==", "PriorType", ".", "NORMAL_GAMMA", "and", "hyperparameters", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"If prior type is NORMAL_GAMMA, you must provide hyperparameters.\"", "\n", ")", "\n", "\n", "", "if", "(", "\n", "max_n_iterations", "==", "np", ".", "inf", "\n", "and", "convergence_criterion_drop_in_mean_elbo", "==", "-", "np", ".", "inf", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"You must change max_n_iterations and/or convergence_criterion_drop_in_elbo \"", "\n", "f\"from the default value so that the algorithm knows when to stop\"", "\n", ")", "\n", "\n", "", "if", "convergence_criterion_drop_in_mean_elbo", "!=", "-", "np", ".", "inf", "and", "scipy", ".", "sparse", ".", "issparse", "(", "\n", "covariates", "\n", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\n", "f\"You've passed in a sparse `covariates` matrix, so the function will do sparse computations along the way. \"", "\n", "f\"But the ELBO code is not currently constructed in such a way so as to be able to handle sparse matrices. \"", "\n", "f\"Would it work to use `max_n_iterations` as a stopping criterion instead? If not, you'll probably need \"", "\n", "f\"to do some code development.\"", "\n", ")", "\n", "\n", "", "if", "(", "\n", "prior_type", "==", "PriorType", ".", "NORMAL_GAMMA", "\n", "and", "convergence_criterion_drop_in_mean_elbo", "!=", "-", "np", ".", "inf", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"We do not currently have a way to compute the ELBO under the normal-gamma prior.\"", "\n", ")", "\n", "\n", "### Start timer", "\n", "", "start_time_for_up_front_computations", "=", "time", ".", "time", "(", ")", "\n", "secs_elapsed_at_last_beta_save", "=", "0.0", "\n", "\n", "### Prepare training data", "\n", "design_matrix", "=", "construct_design_matrix", "(", "\n", "covariates", ",", "\n", "labels", ",", "\n", "use_autoregressive_design_matrix", ",", "\n", ")", "\n", "\n", "# initalize", "\n", "n_samples", ",", "n_categories", "=", "np", ".", "shape", "(", "labels", ")", "\n", "variational_params", "=", "initialize_variational_params", "(", "\n", "design_matrix", ",", "\n", "n_categories", ",", "\n", "variational_params_init", ",", "\n", ")", "\n", "precomputables", "=", "compute_precomputables", "(", "\n", "variational_params", ",", "design_matrix", ",", "prior_type", ",", "shrinkage_grouping_strategy", "\n", ")", "\n", "\n", "### Report time for up-front computations", "\n", "end_time_for_up_front_computations", "=", "time", ".", "time", "(", ")", "\n", "elapsed_secs_for_up_front_computations", "=", "(", "\n", "end_time_for_up_front_computations", "-", "start_time_for_up_front_computations", "\n", ")", "\n", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\n", "f\"\\nMax # iterations: {max_n_iterations}.  Convergence criterion (drop in mean ELBO): {convergence_criterion_drop_in_mean_elbo}\"", ",", "\n", "end", "=", "\"\\n\"", ",", "\n", ")", "\n", "print", "(", "\n", "f\"Elapsed time (secs) for up front computations: {elapsed_secs_for_up_front_computations:.3f}\"", ",", "\n", "end", "=", "\"\\n\\n\"", ",", "\n", ")", "\n", "\n", "", "elapsed_secs_for_cavi_iterations", "=", "0.0", "\n", "elapsed_secs_for_computing_category_probabilities", "=", "0.0", "\n", "\n", "### Prepare holdout performance computation (if using)", "\n", "performance_over_time_as_dict", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "compute_performance_over_time", "=", "(", "\n", "labels_test", "is", "not", "None", "and", "covariates_test", "is", "not", "None", "\n", ")", "\n", "# `TODO` Right now, we assume that we `compute_performance_over_time` if test data is passed in.", "\n", "# But we might want to at least compute performance over time on training data only, which is always", "\n", "# possible.  Fix this up by making `compute_performance_over_time` a boolean, and update the logic", "\n", "# accordingly.", "\n", "if", "compute_performance_over_time", ":", "\n", "\n", "# TODO: The construction of autoregressive design matrix should be done OUTSIDE", "\n", "# of the inference function.", "\n", "\n", "        ", "design_matrix_train", "=", "construct_design_matrix", "(", "\n", "covariates", ",", "\n", "labels", ",", "\n", "use_autoregressive_design_matrix", ",", "\n", ")", "\n", "design_matrix_test", "=", "construct_design_matrix", "(", "\n", "covariates_test", ",", "\n", "labels_test", ",", "\n", "use_autoregressive_design_matrix", ",", "\n", ")", "\n", "\n", "for", "(", "l", ",", "link", ")", "in", "enumerate", "(", "links_for_category_probabilities", ")", ":", "\n", "            ", "update_performance_results", "(", "\n", "performance_over_time_as_dict", ",", "\n", "covariates_train", "=", "design_matrix_train", ",", "\n", "labels_train", "=", "labels", ",", "\n", "beta_mean", "=", "variational_params", ".", "beta", ".", "mean", ",", "\n", "secs_elapsed", "=", "elapsed_secs_for_cavi_iterations", ",", "\n", "link", "=", "link", ",", "\n", "covariates_test", "=", "covariates_test", ",", "\n", "labels_test", "=", "labels_test", ",", "\n", "update_secs_elapsed", "=", "l", ",", "\n", ")", "\n", "", "performance_over_time_as_dict", "[", "\"ELBO (mean over N,K)\"", "]", ".", "append", "(", "-", "np", ".", "inf", ")", "\n", "performance_over_time_as_dict", "[", "\"seconds elapsed (category probs)\"", "]", ".", "append", "(", "\n", "elapsed_secs_for_computing_category_probabilities", "\n", ")", "\n", "\n", "", "secs_elapsed_at_last_beta_save", "=", "0", "\n", "\n", "### Inference", "\n", "n_iterations_so_far", "=", "0", "\n", "elbo_stats", "=", "ELBO_Stats", "(", "\n", "convergence_criterion_drop_in_mean_elbo", ",", "\n", "previous_mean_elbo", "=", "-", "np", ".", "inf", ",", "\n", "mean_elbo", "=", "-", "np", ".", "inf", ",", "\n", "drop_in_mean_elbo", "=", "np", ".", "inf", ",", "\n", ")", "\n", "\n", "while", "(", "\n", "n_iterations_so_far", "<", "max_n_iterations", "\n", "and", "elbo_stats", ".", "drop_in_mean_elbo", "\n", ">=", "elbo_stats", ".", "convergence_criterion_drop_in_mean_elbo", "\n", ")", ":", "\n", "        ", "start_time_for_this_cavi_iteration", "=", "time", ".", "time", "(", ")", "\n", "\n", "variational_params", ",", "elbo_stats", "=", "update_variational_params_and_elbo_stats", "(", "\n", "variational_params", ",", "\n", "elbo_stats", ",", "\n", "design_matrix", ",", "\n", "labels", ",", "\n", "prior_beta_mean", ",", "\n", "prior_beta_precision", ",", "\n", "precomputables", ",", "\n", "hyperparameters", ",", "\n", "prior_type", ",", "\n", ")", "\n", "\n", "n_iterations_so_far", "+=", "1", "\n", "\n", "end_time_for_this_cavi_iteration", "=", "time", ".", "time", "(", ")", "\n", "elapsed_secs_for_cavi_iterations", "+=", "(", "\n", "end_time_for_this_cavi_iteration", "-", "start_time_for_this_cavi_iteration", "\n", ")", "\n", "\n", "### Compute performance metrics on train and test set", "\n", "if", "compute_performance_over_time", ":", "\n", "            ", "start_time_for_computing_these_cat_probs", "=", "time", ".", "time", "(", ")", "\n", "\n", "# TODO: The construction of autoregressive design matrix should be done OUTSIDE", "\n", "# of the inference function.", "\n", "design_matrix_train", "=", "construct_design_matrix", "(", "\n", "covariates", ",", "\n", "labels", ",", "\n", "use_autoregressive_design_matrix", ",", "\n", ")", "\n", "design_matrix_test", "=", "construct_design_matrix", "(", "\n", "covariates_test", ",", "\n", "labels_test", ",", "\n", "use_autoregressive_design_matrix", ",", "\n", ")", "\n", "\n", "secs_elapsed", "=", "(", "\n", "elapsed_secs_for_up_front_computations", "\n", "+", "elapsed_secs_for_cavi_iterations", "\n", ")", "\n", "for", "(", "l", ",", "link", ")", "in", "enumerate", "(", "links_for_category_probabilities", ")", ":", "\n", "                ", "update_performance_results", "(", "\n", "performance_over_time_as_dict", ",", "\n", "covariates_train", "=", "design_matrix_train", ",", "\n", "labels_train", "=", "labels", ",", "\n", "beta_mean", "=", "variational_params", ".", "beta", ".", "mean", ",", "\n", "secs_elapsed", "=", "secs_elapsed", ",", "\n", "link", "=", "link", ",", "\n", "covariates_test", "=", "design_matrix_test", ",", "\n", "labels_test", "=", "labels_test", ",", "\n", "update_secs_elapsed", "=", "not", "l", ",", "\n", ")", "\n", "\n", "", "end_time_for_computing_these_cat_probs", "=", "time", ".", "time", "(", ")", "\n", "elapsed_secs_for_computing_category_probabilities", "+=", "(", "\n", "end_time_for_computing_these_cat_probs", "\n", "-", "start_time_for_computing_these_cat_probs", "\n", ")", "\n", "\n", "performance_over_time_as_dict", "[", "\"ELBO (mean over N,K)\"", "]", ".", "append", "(", "\n", "elbo_stats", ".", "mean_elbo", "\n", ")", "\n", "performance_over_time_as_dict", "[", "\"seconds elapsed (category probs)\"", "]", ".", "append", "(", "\n", "elapsed_secs_for_computing_category_probabilities", "\n", ")", "\n", "\n", "# save intermediate betas if desired", "\n", "", "if", "save_beta_every_secs", "is", "not", "None", ":", "\n", "            ", "if", "(", "\n", "secs_elapsed", "-", "secs_elapsed_at_last_beta_save", ">", "save_beta_every_secs", "\n", ")", "or", "n_iterations_so_far", "==", "max_n_iterations", ":", "\n", "                ", "units_of_save_every", "=", "int", "(", "divmod", "(", "secs_elapsed", ",", "save_beta_every_secs", ")", "[", "0", "]", ")", "\n", "time_info", "=", "f\"save_every_secs={save_beta_every_secs}_units_of_save_every={units_of_save_every}_secs_elapsed={secs_elapsed:.03f}\"", "\n", "write_VI_params_from_CAVI_results", "(", "\n", "CAVI_Results", "(", "variational_params", ",", "None", ")", ",", "save_beta_dir", ",", "time_info", "\n", ")", "\n", "secs_elapsed_at_last_beta_save", "=", "secs_elapsed", "\n", "\n", "", "", "if", "verbose", ":", "\n", "            ", "info_to_display", "=", "(", "\n", "f\"Iteration: {n_iterations_so_far}. \\n\"", "\n", "f\"{get_most_recent_performance_results_as_string(performance_over_time_as_dict)}\"", "\n", ")", "\n", "print", "(", "info_to_display", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "\n", "", "", "performance_over_time", "=", "pd", ".", "DataFrame", "(", "performance_over_time_as_dict", ")", "\n", "return", "CAVI_Results", "(", "variational_params", ",", "performance_over_time", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit_with_DO_aux_var.inference._initialize_beta_covariance_for_one_category": [[41, 53], ["scipy.sparse.identity", "numpy.asarray", "numpy.shape", "numpy.linalg.inv"], "function", ["None"], ["prior_beta_precision", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "variational_params_init", ":", "Optional", "[", "VariationalParams", "]", "=", "None", ",", "\n", "save_beta_every_secs", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "save_beta_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "verbose", ":", "bool", "=", "True", ",", "\n", ")", "->", "CAVI_Results", ":", "\n", "    ", "if", "ib_model", "is", "IB_Model", ".", "PROBIT", ":", "\n", "        ", "inference_function", "=", "compute_multiclass_probit_vi_with_normal_prior", "\n", "", "elif", "ib_model", "is", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "inference_function", "=", "compute_multiclass_logit_vi_with_polya_gamma_augmentation", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"I don't understand the model type {ib_model}\"", ")", "\n", "", "return", "inference_function", "(", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit_with_DO_aux_var.inference.compute_z_expectations": [[55, 82], ["numpy.shape", "numpy.argmax", "numpy.zeros", "range", "numpy.full", "range", "categorical_from_binary.ib_cavi.trunc_norm.compute_expected_value_normal_plus", "categorical_from_binary.ib_cavi.trunc_norm.compute_expected_value_normal_minus"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_expected_value_normal_plus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_expected_value_normal_minus"], ["covariates", ",", "\n", "max_n_iterations", ",", "\n", "convergence_criterion_drop_in_mean_elbo", ",", "\n", "use_autoregressive_design_matrix", ",", "\n", "labels_test", ",", "\n", "covariates_test", ",", "\n", "prior_beta_mean", ",", "\n", "prior_beta_precision", ",", "\n", "variational_params_init", ",", "\n", "save_beta_every_secs", ",", "\n", "save_beta_dir", ",", "\n", "verbose", ",", "\n", ")", "\n", "\n", "\n", "", "def", "cbm_link_from_ib_model", "(", "ib_model", ":", "IB_Model", ")", ":", "\n", "    ", "if", "ib_model", "==", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "return", "Link", ".", "CBM_LOGIT", "\n", "", "elif", "ib_model", "==", "IB_Model", ".", "PROBIT", ":", "\n", "        ", "return", "Link", ".", "CBM_PROBIT", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "\n", "\n", "\n", "", "", "def", "cbc_link_from_ib_model", "(", "ib_model", ":", "IB_Model", ")", ":", "\n", "    ", "if", "ib_model", "==", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "return", "Link", ".", "CBC_LOGIT", "\n", "", "elif", "ib_model", "==", "IB_Model", ".", "PROBIT", ":", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit_with_DO_aux_var.inference.compute_z_variances": [[84, 111], ["numpy.shape", "numpy.argmax", "numpy.zeros", "range", "numpy.full", "range", "categorical_from_binary.ib_cavi.trunc_norm.compute_variance_normal_plus", "categorical_from_binary.ib_cavi.trunc_norm.compute_variance_normal_minus"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_variance_normal_plus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_variance_normal_minus"], ["", "else", ":", "\n", "        ", "raise", "ValueError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit_with_DO_aux_var.inference.update_omegas": [[113, 139], ["numpy.shape", "inference.compute_z_expectations", "inference.compute_z_variances", "numpy.zeros", "range", "categorical_from_binary.ib_cavi.multi.structs.VariationalOmegas", "range", "numpy.ones_like", "numpy.sqrt"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit_with_DO_aux_var.inference.compute_z_expectations", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit_with_DO_aux_var.inference.compute_z_variances"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit_with_DO_aux_var.inference.estimate_expected_square_root_of_polya_gamma": [[141, 145], ["pypolyagamma.PyPolyaGamma", "numpy.array", "numpy.mean", "numpy.sqrt", "pypolyagamma.PyPolyaGamma.pgdraw", "range"], "function", ["None"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit_with_DO_aux_var.inference.compute_expected_value_of_polya_gamma_random_variable": [[147, 151], ["ValueError", "numpy.exp", "numpy.exp"], "function", ["None"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit_with_DO_aux_var.inference.compute_expected_omegas": [[153, 164], ["numpy.shape", "numpy.zeros_like", "range", "range", "inference.compute_expected_value_of_polya_gamma_random_variable"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.compute_expected_value_of_polya_gamma_random_variable"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit_with_DO_aux_var.inference.update_zs": [[166, 181], ["numpy.zeros_like", "numpy.shape", "range", "categorical_from_binary.ib_cavi.multi.structs.VariationalZs", "range", "inference.estimate_expected_square_root_of_polya_gamma"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit_with_DO_aux_var.inference.estimate_expected_square_root_of_polya_gamma"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit_with_DO_aux_var.inference.update_beta_covariance_for_one_category": [[183, 200], ["numpy.diag", "numpy.linalg.inv", "numpy.shape", "numpy.eye"], "function", ["None"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit_with_DO_aux_var.inference.update_beta": [[202, 245], ["inference.compute_expected_omegas", "inference.compute_z_expectations", "numpy.zeros", "range", "numpy.einsum", "categorical_from_binary.ib_cavi.multi.structs.VariationalBeta", "numpy.shape", "numpy.shape", "numpy.zeros", "numpy.eye", "inference.update_beta_covariance_for_one_category"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.compute_expected_omegas", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit_with_DO_aux_var.inference.compute_z_expectations", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.update_beta_covariance_for_one_category"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit_with_DO_aux_var.inference.compute_variational_expectation_of_z_in_an_intuitive_way": [[247, 272], ["numpy.shape", "numpy.argmax", "numpy.zeros", "range", "range", "categorical_from_binary.ib_cavi.trunc_norm.compute_expected_value_normal_plus", "categorical_from_binary.ib_cavi.trunc_norm.compute_expected_value_normal_minus"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_expected_value_normal_plus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_expected_value_normal_minus"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit_with_DO_aux_var.inference.initialize_variational_params": [[274, 314], ["categorical_from_binary.ib_cavi.multi.structs.VariationalParams", "numpy.shape", "warnings.warn", "numpy.zeros", "categorical_from_binary.ib_cavi.multi.structs.VariationalBeta", "numpy.ones_like", "categorical_from_binary.ib_cavi.multi.structs.VariationalZs", "numpy.array", "inference._initialize_beta_covariance_for_one_category", "range"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference._initialize_beta_covariance_for_one_category"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit_with_DO_aux_var.inference.update_variational_params_and_elbo_stats": [[316, 349], ["inference.update_omegas", "inference.update_zs", "inference.update_beta", "categorical_from_binary.ib_cavi.multi.structs.VariationalParams"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.update_omegas", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit_with_DO_aux_var.inference.update_zs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.update_beta"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit_with_DO_aux_var.inference.compute_multiclass_logit_vi_with_CBC_aux_var_and_polya_gamma_augmentation": [[351, 442], ["scipy.sparse.issparse", "categorical_from_binary.ib_cavi.multi.inference_wrapper.compute_ib_cavi", "NotImplementedError", "NotImplementedError"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.inference_wrapper.compute_ib_cavi"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit.elbo._beta_cov_for_category_from_beta_cov": [[16, 28], ["numpy.ndim", "numpy.ndim", "ValueError"], "function", ["None"], ["# ELBO -- as used in inference", "\n", "###", "\n", "\n", "\n", "def", "compute_variational_entropy_of_individual_entries_of_z", "(", "\n", "labels", ":", "NumpyArray1D", ",", "\n", "z_natural_parameters", ":", "NumpyArray1D", ",", "\n", ")", "->", "NumpyArray1D", ":", "\n", "    ", "\"\"\"\n    Returns:\n        Array of shape (n_observations, ), where the i-th entry is the variational entropy\n        of the latent variable associated with the i-th observation.\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit.elbo.compute_variational_entropy_of_z": [[31, 66], ["scipy.stats.norm.logpdf", "scipy.special.log_ndtr", "categorical_from_binary.math.logdiffexp", "numpy.exp", "numpy.log", "numpy.sum", "numpy.exp", "numpy.sqrt"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.math.logdiffexp"], ["for", "i", ",", "(", "label", ",", "z_natural_parameter", ")", "in", "enumerate", "(", "zip", "(", "labels", ",", "z_natural_parameters", ")", ")", ":", "\n", "        ", "if", "label", "==", "1", ":", "\n", "            ", "entropy_zs", "[", "i", "]", "=", "compute_entropy_normal_plus", "(", "mu", "=", "z_natural_parameter", ")", "\n", "", "elif", "label", "==", "0", ":", "\n", "            ", "entropy_zs", "[", "i", "]", "=", "compute_entropy_normal_minus", "(", "mu", "=", "z_natural_parameter", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Found label of {label}, but the only legal values are 0 and 1.\"", "\n", ")", "\n", "", "", "return", "entropy_zs", "\n", "\n", "\n", "", "def", "compute_variational_entropy_of_z", "(", "\n", "labels", ":", "NumpyArray1D", ",", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "beta_mean", ":", "NumpyArray1D", ",", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Returns:\n        The entropy of z, the vector of latent variables associated with the observations\n    \"\"\"", "\n", "z_natural_parameters", "=", "covariates", "@", "beta_mean", "\n", "return", "np", ".", "sum", "(", "\n", "compute_variational_entropy_of_individual_entries_of_z", "(", "\n", "labels", ",", "z_natural_parameters", "\n", ")", "\n", ")", "\n", "\n", "\n", "", "def", "compute_variational_entropy_of_beta", "(", "\n", "beta_mean", ":", "NumpyArray1D", ",", "\n", "beta_cov", ":", "NumpyArray2D", ",", "\n", ")", "->", "float", ":", "\n", "    ", "return", "scipy", ".", "stats", ".", "multivariate_normal", "(", "beta_mean", ",", "beta_cov", ")", ".", "entropy", "(", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit.elbo.compute_variational_entropy_of_beta": [[69, 91], ["range", "numpy.shape", "elbo._beta_cov_for_category_from_beta_cov", "categorical_from_binary.ib_cavi.binary_probit.elbo.compute_variational_entropy_of_beta"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit.elbo._beta_cov_for_category_from_beta_cov", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit.elbo.compute_variational_entropy_of_beta"], ["covariates", ":", "NumpyArray2D", ",", "\n", "beta_mean", ":", "NumpyArray1D", ",", "\n", "beta_cov", ":", "NumpyArray2D", ",", "\n", ")", "->", "float", ":", "\n", "    ", "entropy_z", "=", "compute_variational_entropy_of_z", "(", "labels", ",", "covariates", ",", "beta_mean", ")", "\n", "entropy_beta", "=", "compute_variational_entropy_of_beta", "(", "beta_mean", ",", "beta_cov", ")", "\n", "return", "entropy_z", "+", "entropy_beta", "\n", "\n", "\n", "", "def", "compute_variational_expectation_of_complete_data_likelihood", "(", "\n", "z_mean", ":", "NumpyArray1D", ",", "\n", "beta_mean", ":", "NumpyArray1D", ",", "\n", "beta_cov", ":", "NumpyArray2D", ",", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", ")", ":", "\n", "    ", "N", "=", "np", ".", "shape", "(", "covariates", ")", "[", "0", "]", "\n", "x", "=", "covariates", "\n", "z_mean_shifts", "=", "z_mean", "-", "x", "@", "beta_mean", "\n", "# `z_mean_shifts` are the amount by which the variational expected value of the", "\n", "# latent z_i's, as truncated normal random variables, differ from the expected value", "\n", "# of the pre-truncated parent distributions.", "\n", "return", "(", "\n", "-", "0.5", "*", "N", "*", "(", "np", ".", "log", "(", "2", "*", "np", ".", "pi", ")", "+", "1", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit.elbo.compute_variational_entropy": [[93, 103], ["elbo.compute_variational_entropy_of_z", "categorical_from_binary.ib_cavi.binary_probit.elbo.compute_variational_entropy_of_beta"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.elbo.compute_variational_entropy_of_z", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit.elbo.compute_variational_entropy_of_beta"], ["-", "0.5", "*", "np", ".", "sum", "(", "[", "x", "[", "i", "]", ".", "T", "@", "beta_cov", "@", "x", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "x", ")", ")", "]", ")", "\n", ")", "\n", "\n", "\n", "", "def", "compute_variational_expectation_of_prior", "(", "beta_mean", ",", "beta_cov", ")", ":", "\n", "    ", "\"\"\"\n    This is the cross entropy of two gaussians.\n    Note that the form is simpler than in general since the prior is zero mean, unit variance.\n    \"\"\"", "\n", "M", "=", "np", ".", "shape", "(", "beta_mean", ")", "[", "0", "]", "\n", "trace_beta_cov", "=", "np", ".", "sum", "(", "np", ".", "diag", "(", "beta_cov", ")", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit.elbo.compute_variational_energy": [[105, 123], ["range", "numpy.shape", "elbo._beta_cov_for_category_from_beta_cov", "categorical_from_binary.ib_cavi.binary_probit.elbo.compute_variational_energy"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit.elbo._beta_cov_for_category_from_beta_cov", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit.elbo.compute_variational_energy"], ["\n", "\n", "", "def", "compute_variational_energy", "(", "\n", "beta_mean", ":", "NumpyArray1D", ",", "\n", "beta_cov", ":", "NumpyArray2D", ",", "\n", "z_mean", ":", "NumpyArray1D", ",", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "verbose", ":", "bool", "=", "False", ",", "\n", ")", "->", "float", ":", "\n", "    ", "print", "(", "\n", "f\"prior energy: {compute_variational_expectation_of_prior(beta_mean, beta_cov)} \"", "\n", "f\"likelihood energy:  { compute_variational_expectation_of_complete_data_likelihood(z_mean, beta_mean, beta_cov, covariates)}\"", "\n", ")", "if", "verbose", "else", "None", "\n", "return", "compute_variational_expectation_of_prior", "(", "\n", "beta_mean", ",", "beta_cov", "\n", ")", "+", "compute_variational_expectation_of_complete_data_likelihood", "(", "\n", "z_mean", ",", "beta_mean", ",", "beta_cov", ",", "covariates", "\n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit.elbo.compute_elbo": [[125, 164], ["scipy.sparse.issparse", "elbo.compute_variational_entropy", "categorical_from_binary.ib_cavi.binary_probit.elbo.compute_variational_energy", "design_matrix.toarray.toarray"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit.elbo.compute_variational_entropy", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit.elbo.compute_variational_energy"], ["", "def", "compute_elbo", "(", "\n", "beta_mean", ":", "NumpyArray1D", ",", "\n", "beta_cov", ":", "NumpyArray2D", ",", "\n", "z_mean", ":", "NumpyArray1D", ",", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray1D", ",", "\n", "verbose", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "    ", "entropy", "=", "compute_variational_entropy", "(", "labels", ",", "covariates", ",", "beta_mean", ",", "beta_cov", ")", "\n", "energy", "=", "compute_variational_energy", "(", "\n", "beta_mean", ",", "beta_cov", ",", "z_mean", ",", "covariates", ",", "verbose", "\n", ")", "\n", "return", "energy", "+", "entropy", "\n", "\n", "\n", "###", "\n", "# Monte Carlo Approximations to ELBO -- Used in unit testing", "\n", "###", "\n", "\n", "\n", "", "def", "sample_z_from_natural_parameters", "(", "\n", "labels", ":", "NumpyArray1D", ",", "natural_parameters", ":", "NumpyArray1D", ",", "n_samples", ":", "int", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        np.array of shape ((n_observations, n_samples))\n    \"\"\"", "\n", "\n", "n_obs", "=", "np", ".", "shape", "(", "natural_parameters", ")", "[", "0", "]", "\n", "z_samples", "=", "np", ".", "zeros", "(", "(", "n_obs", ",", "n_samples", ")", ")", "\n", "for", "i", "in", "range", "(", "n_obs", ")", ":", "\n", "        ", "if", "labels", "[", "i", "]", "==", "1", ":", "\n", "            ", "z_samples", "[", "i", ",", ":", "]", "=", "sample_normal_plus", "(", "natural_parameters", "[", "i", "]", ",", "size", "=", "n_samples", ")", "\n", "", "elif", "labels", "[", "i", "]", "==", "0", ":", "\n", "            ", "z_samples", "[", "i", ",", ":", "]", "=", "sample_normal_minus", "(", "natural_parameters", "[", "i", "]", ",", "size", "=", "n_samples", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Label must be either 0 or 1\"", ")", "\n", "", "", "return", "z_samples", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit.util.beta_stds_from_beta_cov": [[8, 26], ["numpy.sqrt", "numpy.diag", "ValueError", "numpy.shape", "numpy.array", "numpy.sqrt", "numpy.diag", "range"], "function", ["None"], ["\n", "\n", "def", "one_hot_encoded_array_from_categorical_indices", "(", "\n", "categorical_indices", ":", "NumpyArray1D", ",", "\n", "number_of_possible_categories", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "sparse_representation", ":", "bool", "=", "False", ",", "\n", ")", "->", "np", ".", "array", ":", "\n", "    ", "\"\"\"\n    Takes a one-dim numpy array of integers and expands it to a two-dim numpy array\n    that is one-hot encoded\n    \"\"\"", "\n", "\n", "# TODO: This function currently assumes that we should assign a column for every", "\n", "# integer within 0 and the maximal categorical index.   This should be related", "\n", "\n", "if", "number_of_possible_categories", "is", "None", ":", "\n", "# If `number_of_possible_categories` is not provided, we will infer it to be the maximum value", "\n", "# plus one, due to zero-indexing, but this potentially dangerous to do under the hood.  Is 0 a", "\n", "# legitimate value? If the max value is far higher than the number of possible values, do we really", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit._elbo_intuitive.compute_elbo_intuitive": [[11, 60], ["range", "numpy.shape", "categorical_from_binary.ib_cavi.binary_probit.elbo.compute_elbo", "numpy.ndim", "numpy.ndim", "ValueError"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.inference.compute_elbo"], ["def", "compute_elbo_intuitive", "(", "\n", "beta_mean", ":", "NumpyArray2D", ",", "\n", "beta_cov", ":", "Union", "[", "NumpyArray2D", ",", "NumpyArray3D", "]", ",", "\n", "z_expected", ":", "NumpyArray2D", ",", "\n", "design_matrix", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray2D", ",", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    This gives the intuitive procedure for computing the ELBO for do-probit. However, it is much slower than compute_elbo,\n    so we do not use it in our main code.\n\n    The independence structure of the model (and variational approximation),  combined with the one-vs-rest\n    labeling strategy to make the model identifiable, makes the ELBO for the CBC-Probit model equal to the sum\n    of K ELBOs from K separate binary probit regressions.\n\n    Arguments:\n        beta_mean : array with shape (n_features, n_categories)\n        beta_cov : Two possibilities:\n                1) array with shape (n_features, n_features)\n                    This is, at least with the current N(0,I) prior on each beta_k, identical for each of the\n                    K categories, so we only store it once rather than K copies of it.\n                2) array with shape (n_features, n_features, n_categories)\n        z_expected : array with shape (n_obs, n_categories)\n        design_matrix: array with shape (n_obs, n_features)\n        labels: array with shape (n_obs, n_categories)\n            one-hot encoded representations of response categories\n    \"\"\"", "\n", "n_categories", "=", "np", ".", "shape", "(", "labels", ")", "[", "1", "]", "\n", "elbo", "=", "0", "\n", "for", "k", "in", "range", "(", "n_categories", ")", ":", "\n", "\n", "        ", "if", "np", ".", "ndim", "(", "beta_cov", ")", "==", "2", ":", "\n", "            ", "beta_cov_for_category", "=", "beta_cov", "\n", "", "elif", "np", ".", "ndim", "(", "beta_cov", ")", "==", "3", ":", "\n", "            ", "beta_cov_for_category", "=", "beta_cov", "[", ":", ",", ":", ",", "k", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"I am not sure how to get the beta covariance for each category\"", "\n", ")", "\n", "\n", "", "elbo", "+=", "compute_elbo_for_one_category", "(", "\n", "beta_mean", "[", ":", ",", "k", "]", ",", "\n", "beta_cov_for_category", ",", "\n", "z_expected", "[", ":", ",", "k", "]", ",", "\n", "design_matrix", ",", "\n", "labels", "[", ":", ",", "k", "]", ",", "\n", "verbose", "=", "False", ",", "\n", ")", "\n", "", "return", "elbo", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.insights.plot_nature_of_CBC_vs_CBM_link_function.compute_do_potential_from_linear_predictor": [[17, 20], ["cdf", "cdf"], "function", ["None"], ["def", "compute_do_potential_from_linear_predictor", "(", "eta", ")", ":", "\n", "    ", "\"\"\"eta is the linear predictor, covariates dotted with regression weights\"\"\"", "\n", "return", "cdf", "(", "eta", ")", "/", "cdf", "(", "-", "eta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.insights.plot_nature_of_CBC_vs_CBM_link_function.compute_sdo_potential_from_linear_predictor": [[22, 25], ["cdf"], "function", ["None"], ["", "def", "compute_sdo_potential_from_linear_predictor", "(", "eta", ")", ":", "\n", "    ", "\"\"\"eta is the linear predictor, covariates dotted with regression weights\"\"\"", "\n", "return", "cdf", "(", "eta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.insights.plot_nature_of_CBC_vs_CBM_link_function.compute_do_potential_from_sdo_potential": [[27, 31], ["inv_cdf", "plot_nature_of_CBC_vs_CBM_link_function.compute_do_potential_from_linear_predictor"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.insights.plot_nature_of_CBC_vs_CBM_link_function.compute_do_potential_from_linear_predictor"], ["", "def", "compute_do_potential_from_sdo_potential", "(", "y", ")", ":", "\n", "    ", "\"\"\"y = cdf(eta) is the sdo potential\"\"\"", "\n", "eta", "=", "inv_cdf", "(", "y", ")", "\n", "return", "compute_do_potential_from_linear_predictor", "(", "eta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.core.warping.run_warping_simulations_on_softmax_data": [[42, 310], ["collections.defaultdict", "pandas.DataFrame", "print", "d[].append", "d[].append", "d[].append", "d[].append", "categorical_from_binary.data_generation.bayes_multiclass_reg.generate_multiclass_regression_dataset", "jax.zeros", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_cbc_probit_probabilities", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_cbm_probit_probabilities", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_multi_logit_probabilities", "categorical_from_binary.autodiff.simplex_distances.compute_mean_l1_distance", "categorical_from_binary.autodiff.simplex_distances.compute_mean_l1_distance", "print", "d[].append", "d[].append", "d[].append", "print", "range", "categorical_from_binary.timing.time_me", "categorical_from_binary.autodiff.jax_helpers.compute_CBC_Probit_predictions", "categorical_from_binary.autodiff.simplex_distances.compute_mean_l1_distance", "categorical_from_binary.autodiff.jax_helpers.compute_CBM_Probit_predictions", "categorical_from_binary.autodiff.simplex_distances.compute_mean_l1_distance", "print", "d[].append", "d[].append", "d[].append", "d[].append", "d[].append", "d[].append", "d[].append", "d[].append", "categorical_from_binary.autodiff.jax_helpers.compute_softmax_predictions", "categorical_from_binary.autodiff.simplex_distances.compute_mean_l1_distance", "print", "d[].append", "d[].append", "d[].append", "d[].append", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_cbc_probit_probabilities", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_cbm_probit_probabilities", "categorical_from_binary.autodiff.simplex_distances.compute_mean_l1_distance", "categorical_from_binary.autodiff.simplex_distances.compute_mean_l1_distance", "print", "d[].append", "d[].append", "d[].append", "d[].append", "d[].append", "d[].append", "categorical_from_binary.timing.time_me", "categorical_from_binary.timing.time_me", "categorical_from_binary.timing.time_me", "categorical_from_binary.timing.time_me"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_multiclass_regression_dataset", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_cbc_probit_probabilities", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_cbm_probit_probabilities", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_multi_logit_probabilities", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.simplex_distances.compute_mean_l1_distance", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.simplex_distances.compute_mean_l1_distance", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.timing.time_me", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.jax_helpers.compute_CBC_Probit_predictions", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.simplex_distances.compute_mean_l1_distance", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.jax_helpers.compute_CBM_Probit_predictions", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.simplex_distances.compute_mean_l1_distance", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.jax_helpers.compute_softmax_predictions", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.simplex_distances.compute_mean_l1_distance", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_cbc_probit_probabilities", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_cbm_probit_probabilities", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.simplex_distances.compute_mean_l1_distance", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.simplex_distances.compute_mean_l1_distance", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.timing.time_me", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.timing.time_me", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.timing.time_me", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.timing.time_me"], ["def", "run_warping_simulations_on_softmax_data", "(", "\n", "Ks", ":", "List", "[", "int", "]", ",", "\n", "Ns", ":", "List", "[", "int", "]", ",", "\n", "Ms", ":", "List", "[", "int", "]", ",", "\n", "n_datasets_per_data_dimension", ":", "int", ",", "\n", "run_softmax", ":", "bool", "=", "True", ",", "\n", "run_sdo_and_do_mle", ":", "bool", "=", "True", ",", "\n", "run_sdo_and_do_mle_only_if_num_coefficients_is_less_than_this", ":", "Optional", "[", "\n", "float", "\n", "]", "=", "None", ",", "\n", "run_cavi", ":", "bool", "=", "False", ",", "\n", "run_cavi_only_for_one_seed", ":", "bool", "=", "False", ",", "\n", "verbose_cavi", "=", "False", ",", "\n", "max_n_cavi_iterations", ":", "float", "=", "np", ".", "inf", ",", "\n", "convergence_criterion_drop_in_mean_elbo", ":", "float", "=", "-", "np", ".", "inf", ",", "\n", ")", "->", "DataFrame", ":", "\n", "    ", "\"\"\"\n    Generate data from softmax with given specifications (N samples, K categories, M covariates); compute the MLE of\n    beta from the IB model (which is a proxy for the posterior mean beta from IB-CAVI); and then compare the distance\n    in category probabilities to the ground truth.\n\n    Note:\n        This function is older than the one in simulations.core.performance; perhaps see that function first for a\n        possibly better structure.\n    \"\"\"", "\n", "\n", "SKIPPED_FLAG", "=", "\"skipped\"", "\n", "\n", "d", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "# `collections.defaultdict(list)` lets me append to lists that aren't there yet by", "\n", "#   d[\"my list\"].append(new_item)", "\n", "#", "\n", "\n", "for", "K", "in", "Ks", ":", "\n", "        ", "for", "M", "in", "Ms", ":", "\n", "            ", "for", "N", "in", "Ns", ":", "\n", "                ", "seeds", "=", "[", "i", "for", "i", "in", "range", "(", "n_datasets_per_data_dimension", ")", "]", "\n", "for", "seed", "in", "seeds", ":", "\n", "\n", "                    ", "if", "run_cavi_only_for_one_seed", ":", "\n", "                        ", "run_cavi", "=", "seed", "==", "0", "\n", "\n", "", "if", "(", "\n", "run_sdo_and_do_mle_only_if_num_coefficients_is_less_than_this", "\n", "is", "not", "None", "\n", ")", ":", "\n", "                        ", "run_sdo_and_do_mle", "=", "(", "\n", "K", "*", "M", "\n", "<", "run_sdo_and_do_mle_only_if_num_coefficients_is_less_than_this", "\n", ")", "\n", "\n", "", "print", "(", "f\"\\n --- Now analyzing K={K}, M={M}, N={N}, seed={seed} --- \"", ")", "\n", "d", "[", "\"K\"", "]", ".", "append", "(", "K", ")", "\n", "d", "[", "\"M\"", "]", ".", "append", "(", "M", ")", "\n", "d", "[", "\"N\"", "]", ".", "append", "(", "N", ")", "\n", "d", "[", "\"seed\"", "]", ".", "append", "(", "seed", ")", "\n", "\n", "###", "\n", "# Construct dataset", "\n", "###", "\n", "n_categories", "=", "K", "\n", "n_features", "=", "M", "\n", "n_samples", "=", "N", "\n", "include_intercept", "=", "True", "\n", "link", "=", "Link", ".", "MULTI_LOGIT", "# Link.MULTI_LOGIT  # Link.CBC_PROBIT", "\n", "dataset", "=", "generate_multiclass_regression_dataset", "(", "\n", "n_samples", "=", "n_samples", ",", "\n", "n_features", "=", "n_features", ",", "\n", "n_categories", "=", "n_categories", ",", "\n", "beta_0", "=", "None", ",", "\n", "link", "=", "link", ",", "\n", "seed", "=", "seed", ",", "\n", "include_intercept", "=", "include_intercept", ",", "\n", ")", "\n", "\n", "beta_init", "=", "np", ".", "zeros", "(", "(", "n_features", "+", "1", ",", "n_categories", ")", ")", "\n", "\n", "beta_star_IB_MLE", ",", "time_for_IB_MLE", "=", "time_me", "(", "\n", "optimize_beta_for_IB_model", "\n", ")", "(", "\n", "beta_init", ",", "\n", "dataset", ".", "features", ",", "\n", "dataset", ".", "labels", ",", "\n", "verbose", "=", "verbose_cavi", ",", "\n", ")", "\n", "\n", "category_probs_CBC_with_IB_MLE", "=", "construct_cbc_probit_probabilities", "(", "\n", "dataset", ".", "features", ",", "beta_star_IB_MLE", "\n", ")", "\n", "\n", "category_probs_CBM_with_IB_MLE", "=", "construct_cbm_probit_probabilities", "(", "\n", "dataset", ".", "features", ",", "beta_star_IB_MLE", "\n", ")", "\n", "\n", "category_probs_true", "=", "construct_multi_logit_probabilities", "(", "\n", "dataset", ".", "features", ",", "dataset", ".", "beta", "\n", ")", "\n", "\n", "# Comparing IB beta to CBM/CBC beta is hard becuase of non-identifiability.  Very different betas", "\n", "# can give essentially the same category probs.  An example:  beta_star_IB_MLE and beta_star_CBM_MLE", "\n", "# are very different, but they give essentially the same CBM category probs.", "\n", "#", "\n", "# To get around this problem while still comparing CBM to CBC, we could perhaps propose that", "\n", "# Difference_in_some_sense( CBM_probs(beta_star_IB_MLE), CBM_probs(beta_star_CBM_MLE) )  is less than", "\n", "# Difference_in_some_sense( CBC_probs(beta_star_IB_MLE), CBC_probs(beta_star_CBC_MLE) )", "\n", "\n", "error_to_ground_truth_probs_when_using_IB_MLE_plus_CBC", "=", "(", "\n", "compute_mean_l1_distance", "(", "\n", "category_probs_CBC_with_IB_MLE", ",", "category_probs_true", "\n", ")", "\n", ")", "\n", "error_to_ground_truth_probs_when_using_IB_MLE_plus_CBM", "=", "(", "\n", "compute_mean_l1_distance", "(", "\n", "category_probs_CBM_with_IB_MLE", ",", "category_probs_true", "\n", ")", "\n", ")", "\n", "print", "(", "\n", "f\"Error compared to ground truth. IB MLE + CBM: {error_to_ground_truth_probs_when_using_IB_MLE_plus_CBM :.03f}, IB MLE + CBC: {error_to_ground_truth_probs_when_using_IB_MLE_plus_CBC :.03f}\"", "\n", ")", "\n", "# TODO: show category probs for CAVI -> category probs for MLE as n to infinity.  just for funsies / sanity check.", "\n", "\n", "d", "[", "\"error with IB MLE and CBM\"", "]", ".", "append", "(", "\n", "error_to_ground_truth_probs_when_using_IB_MLE_plus_CBM", "\n", ")", "\n", "d", "[", "\"error with IB MLE and CBC\"", "]", ".", "append", "(", "\n", "error_to_ground_truth_probs_when_using_IB_MLE_plus_CBC", "\n", ")", "\n", "d", "[", "\"time for IB MLE\"", "]", ".", "append", "(", "time_for_IB_MLE", ")", "\n", "\n", "if", "run_sdo_and_do_mle", ":", "\n", "                        ", "beta_star_CBC_MLE", ",", "time_for_CBC_MLE", "=", "time_me", "(", "\n", "optimize_beta_for_CBC_model", "\n", ")", "(", "\n", "beta_init", ",", "\n", "dataset", ".", "features", ",", "\n", "dataset", ".", "labels", ",", "\n", "verbose", "=", "False", ",", "\n", ")", "\n", "category_probs_with_CBC_MLE", "=", "(", "\n", "compute_CBC_Probit_predictions_with_autodiff_MLE", "(", "\n", "beta_star_CBC_MLE", ",", "dataset", ".", "features", "\n", ")", "\n", ")", "\n", "\n", "error_to_ground_truth_probs_when_using_CBC_MLE", "=", "(", "\n", "compute_mean_l1_distance", "(", "\n", "category_probs_with_CBC_MLE", ",", "category_probs_true", "\n", ")", "\n", ")", "\n", "\n", "beta_star_CBM_MLE", ",", "time_for_CBM_MLE", "=", "time_me", "(", "\n", "optimize_beta_for_CBM_model", "\n", ")", "(", "\n", "beta_init", ",", "\n", "dataset", ".", "features", ",", "\n", "dataset", ".", "labels", ",", "\n", "verbose", "=", "False", ",", "\n", ")", "\n", "category_probs_with_CBM_MLE", "=", "(", "\n", "compute_CBM_Probit_predictions_with_autodiff_MLE", "(", "\n", "beta_star_CBM_MLE", ",", "dataset", ".", "features", "\n", ")", "\n", ")", "\n", "\n", "error_to_ground_truth_probs_when_using_CBM_MLE", "=", "(", "\n", "compute_mean_l1_distance", "(", "\n", "category_probs_with_CBM_MLE", ",", "category_probs_true", "\n", ")", "\n", ")", "\n", "\n", "print", "(", "\n", "f\"Error compared to ground truth. CBM MLE: {error_to_ground_truth_probs_when_using_CBM_MLE :.03f}, CBC MLE: {error_to_ground_truth_probs_when_using_CBC_MLE :.03f}\"", "\n", ")", "\n", "\n", "d", "[", "\"error with CBM MLE\"", "]", ".", "append", "(", "\n", "error_to_ground_truth_probs_when_using_CBM_MLE", "\n", ")", "\n", "d", "[", "\"error with CBC MLE\"", "]", ".", "append", "(", "\n", "error_to_ground_truth_probs_when_using_CBC_MLE", "\n", ")", "\n", "d", "[", "\"time for CBM MLE\"", "]", ".", "append", "(", "time_for_CBM_MLE", ")", "\n", "d", "[", "\"time for CBC MLE\"", "]", ".", "append", "(", "time_for_CBC_MLE", ")", "\n", "", "else", ":", "\n", "                        ", "d", "[", "\"error with CBM MLE\"", "]", ".", "append", "(", "SKIPPED_FLAG", ")", "\n", "d", "[", "\"error with CBC MLE\"", "]", ".", "append", "(", "SKIPPED_FLAG", ")", "\n", "d", "[", "\"time for CBM MLE\"", "]", ".", "append", "(", "SKIPPED_FLAG", ")", "\n", "d", "[", "\"time for CBC MLE\"", "]", ".", "append", "(", "SKIPPED_FLAG", ")", "\n", "", "if", "run_softmax", ":", "\n", "                        ", "beta_star_softmax_MLE", ",", "time_for_softmax_MLE", "=", "time_me", "(", "\n", "optimize_beta_for_softmax_model", "\n", ")", "(", "\n", "beta_init", ",", "\n", "dataset", ".", "features", ",", "\n", "dataset", ".", "labels", ",", "\n", "verbose", "=", "False", ",", "\n", ")", "\n", "category_probs_with_softmax_MLE", "=", "compute_softmax_predictions", "(", "\n", "beta_star_softmax_MLE", ",", "\n", "dataset", ".", "features", ",", "\n", ")", "\n", "\n", "error_to_ground_truth_probs_when_using_softmax_MLE", "=", "(", "\n", "compute_mean_l1_distance", "(", "\n", "category_probs_with_softmax_MLE", ",", "category_probs_true", "\n", ")", "\n", ")", "\n", "print", "(", "\n", "f\"Error compared to ground truth. softmax MLE: {error_to_ground_truth_probs_when_using_softmax_MLE :.03f}\"", "\n", ")", "\n", "d", "[", "\"error with softmax MLE\"", "]", ".", "append", "(", "\n", "error_to_ground_truth_probs_when_using_softmax_MLE", "\n", ")", "\n", "d", "[", "\"time for softmax MLE\"", "]", ".", "append", "(", "time_for_softmax_MLE", ")", "\n", "", "else", ":", "\n", "                        ", "d", "[", "\"error with softmax MLE\"", "]", ".", "append", "(", "SKIPPED_FLAG", ")", "\n", "d", "[", "\"time for softmax MLE\"", "]", ".", "append", "(", "SKIPPED_FLAG", ")", "\n", "", "if", "run_cavi", ":", "\n", "                        ", "results", ",", "time_for_IB_CAVI", "=", "time_me", "(", "\n", "compute_multiclass_probit_vi_with_normal_prior", "\n", ")", "(", "\n", "dataset", ".", "labels", ",", "\n", "dataset", ".", "features", ",", "\n", "variational_params_init", "=", "None", ",", "\n", "convergence_criterion_drop_in_mean_elbo", "=", "convergence_criterion_drop_in_mean_elbo", ",", "\n", "max_n_iterations", "=", "max_n_cavi_iterations", ",", "\n", "verbose", "=", "False", ",", "\n", ")", "\n", "beta_CAVI_mean", "=", "results", ".", "variational_params", ".", "beta", ".", "mean", "\n", "\n", "category_probs_CBC_with_IB_CAVI_mean", "=", "(", "\n", "construct_cbc_probit_probabilities", "(", "\n", "dataset", ".", "features", ",", "beta_CAVI_mean", "\n", ")", "\n", ")", "\n", "\n", "category_probs_CBM_with_IB_CAVI_mean", "=", "(", "\n", "construct_cbm_probit_probabilities", "(", "\n", "dataset", ".", "features", ",", "beta_CAVI_mean", "\n", ")", "\n", ")", "\n", "error_to_ground_truth_probs_when_using_CBM_variational_posterior_mean", "=", "compute_mean_l1_distance", "(", "\n", "category_probs_CBM_with_IB_CAVI_mean", ",", "category_probs_true", "\n", ")", "\n", "error_to_ground_truth_probs_when_using_CBC_variational_posterior_mean", "=", "compute_mean_l1_distance", "(", "\n", "category_probs_CBC_with_IB_CAVI_mean", ",", "category_probs_true", "\n", ")", "\n", "print", "(", "\n", "f\"Error compared to ground truth. IB CAVI mean + CBM: {error_to_ground_truth_probs_when_using_CBM_variational_posterior_mean :.03f}, IB CAVI mean + CBC: {error_to_ground_truth_probs_when_using_CBC_variational_posterior_mean :.03f}\"", "\n", ")", "\n", "d", "[", "\"error with IB CAVI mean and CBM\"", "]", ".", "append", "(", "\n", "error_to_ground_truth_probs_when_using_CBM_variational_posterior_mean", "\n", ")", "\n", "d", "[", "\"error with IB CAVI mean and CBC\"", "]", ".", "append", "(", "\n", "error_to_ground_truth_probs_when_using_CBC_variational_posterior_mean", "\n", ")", "\n", "d", "[", "\"time for IB CAVI\"", "]", ".", "append", "(", "time_for_IB_CAVI", ")", "\n", "", "else", ":", "\n", "                        ", "d", "[", "\"error with IB CAVI mean and CBM\"", "]", ".", "append", "(", "SKIPPED_FLAG", ")", "\n", "d", "[", "\"error with IB CAVI mean and CBC\"", "]", ".", "append", "(", "SKIPPED_FLAG", ")", "\n", "d", "[", "\"time for IB CAVI\"", "]", ".", "append", "(", "SKIPPED_FLAG", ")", "\n", "", "print", "(", "\n", "f'Running times: IB-MLE: {d[\"time for IB MLE\"][-1]}, '", "\n", "f'softmax MLE: {d[\"time for softmax MLE\"][-1]}, '", "\n", "f'CBM MLE: {d[\"time for CBM MLE\"][-1]}, '", "\n", "f'CBC MLE: {d[\"time for CBC MLE\"][-1]}, '", "\n", "f'IB CAVI: {d[\"time for IB CAVI\"][-1]}, '", "\n", ")", "\n", "", "", "", "", "return", "pd", ".", "DataFrame", "(", "d", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.elbo.compute_variational_expectation_of_complete_data_likelihood": [[30, 46], ["categorical_from_binary.ib_cavi.multi.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "range", "range", "categorical_from_binary.ib_cavi.binary_probit.elbo.compute_variational_expectation_of_complete_data_likelihood"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.elbo.compute_variational_expectation_of_complete_data_likelihood"], ["entropy_zs", "=", "np", ".", "zeros", "(", "n_obs", ")", "\n", "for", "i", ",", "(", "label", ",", "z_natural_parameter", ")", "in", "enumerate", "(", "zip", "(", "labels", ",", "z_natural_parameters", ")", ")", ":", "\n", "        ", "if", "label", "==", "1", ":", "\n", "            ", "entropy_zs", "[", "i", "]", "=", "compute_entropy_normal_plus", "(", "mu", "=", "z_natural_parameter", ")", "\n", "", "elif", "label", "==", "0", ":", "\n", "            ", "entropy_zs", "[", "i", "]", "=", "compute_entropy_normal_minus", "(", "mu", "=", "z_natural_parameter", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Found label of {label}, but the only legal values are 0 and 1.\"", "\n", ")", "\n", "", "", "return", "entropy_zs", "\n", "\n", "\n", "", "def", "compute_variational_entropy_of_z", "(", "\n", "labels", ":", "NumpyArray1D", ",", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "beta_mean", ":", "NumpyArray1D", ",", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.elbo.compute_variational_entropy_of_z": [[48, 63], ["categorical_from_binary.ib_cavi.multi.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "range", "range", "categorical_from_binary.ib_cavi.binary_probit.elbo.compute_variational_entropy_of_z"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.elbo.compute_variational_entropy_of_z"], ["    ", "\"\"\"\n    Returns:\n        The entropy of z, the vector of latent variables associated with the observations\n    \"\"\"", "\n", "z_natural_parameters", "=", "covariates", "@", "beta_mean", "\n", "return", "np", ".", "sum", "(", "\n", "compute_variational_entropy_of_individual_entries_of_z", "(", "\n", "labels", ",", "z_natural_parameters", "\n", ")", "\n", ")", "\n", "\n", "\n", "", "def", "compute_variational_entropy_of_beta", "(", "\n", "beta_mean", ":", "NumpyArray1D", ",", "\n", "beta_cov", ":", "NumpyArray2D", ",", "\n", ")", "->", "float", ":", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.elbo.compute_kl_divergence_of_mus": [[65, 85], ["categorical_from_binary.ib_cavi.multi.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "range", "categorical_from_binary.kl.compute_kl_mvn"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.compute_kl_mvn"], ["\n", "\n", "", "def", "compute_variational_entropy", "(", "\n", "labels", ":", "NumpyArray1D", ",", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "beta_mean", ":", "NumpyArray1D", ",", "\n", "beta_cov", ":", "NumpyArray2D", ",", "\n", ")", "->", "float", ":", "\n", "    ", "entropy_z", "=", "compute_variational_entropy_of_z", "(", "labels", ",", "covariates", ",", "beta_mean", ")", "\n", "entropy_beta", "=", "compute_variational_entropy_of_beta", "(", "beta_mean", ",", "beta_cov", ")", "\n", "return", "entropy_z", "+", "entropy_beta", "\n", "\n", "\n", "", "def", "compute_variational_expectation_of_complete_data_likelihood", "(", "\n", "z_mean", ":", "NumpyArray1D", ",", "\n", "beta_mean", ":", "NumpyArray1D", ",", "\n", "beta_cov", ":", "NumpyArray2D", ",", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", ")", ":", "\n", "    ", "N", "=", "np", ".", "shape", "(", "covariates", ")", "[", "0", "]", "\n", "x", "=", "covariates", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.elbo.compute_kl_divergence_of_Sigmas": [[87, 107], ["categorical_from_binary.ib_cavi.multi.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "range", "categorical_from_binary.kl.compute_kl_inverse_wishart"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.compute_kl_inverse_wishart"], ["# `z_mean_shifts` are the amount by which the variational expected value of the", "\n", "# latent z_i's, as truncated normal random variables, differ from the expected value", "\n", "# of the pre-truncated parent distributions.", "\n", "return", "(", "\n", "-", "0.5", "*", "N", "*", "(", "np", ".", "log", "(", "2", "*", "np", ".", "pi", ")", "+", "1", ")", "\n", "+", "0.5", "*", "np", ".", "sum", "(", "z_mean_shifts", "*", "(", "x", "@", "beta_mean", ")", ")", "\n", "-", "0.5", "*", "np", ".", "sum", "(", "[", "x", "[", "i", "]", ".", "T", "@", "beta_cov", "@", "x", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "x", ")", ")", "]", ")", "\n", ")", "\n", "\n", "\n", "", "def", "compute_variational_expectation_of_prior", "(", "beta_mean", ",", "beta_cov", ")", ":", "\n", "    ", "\"\"\"\n    This is the cross entropy of two gaussians.\n    Note that the form is simpler than in general since the prior is zero mean, unit variance.\n    \"\"\"", "\n", "M", "=", "np", ".", "shape", "(", "beta_mean", ")", "[", "0", "]", "\n", "trace_beta_cov", "=", "np", ".", "sum", "(", "np", ".", "diag", "(", "beta_cov", ")", ")", "\n", "return", "-", "0.5", "*", "(", "beta_mean", "@", "beta_mean", "+", "trace_beta_cov", "+", "M", "*", "np", ".", "log", "(", "2", "*", "np", ".", "pi", ")", ")", "\n", "\n", "\n", "", "def", "compute_variational_energy", "(", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.elbo.compute_variational_expectation_of_kl_divergence_of_betas": [[109, 140], ["categorical_from_binary.ib_cavi.multi.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "range", "range", "categorical_from_binary.kl.compute_expected_kl_divergence_wrt_independent_Normal_and_IW_distributions_on_params_of_second_argument"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.compute_expected_kl_divergence_wrt_independent_Normal_and_IW_distributions_on_params_of_second_argument"], ["beta_cov", ":", "NumpyArray2D", ",", "\n", "z_mean", ":", "NumpyArray1D", ",", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "verbose", ":", "bool", "=", "False", ",", "\n", ")", "->", "float", ":", "\n", "    ", "print", "(", "\n", "f\"prior energy: {compute_variational_expectation_of_prior(beta_mean, beta_cov)} \"", "\n", "f\"likelihood energy:  { compute_variational_expectation_of_complete_data_likelihood(z_mean, beta_mean, beta_cov, covariates)}\"", "\n", ")", "if", "verbose", "else", "None", "\n", "return", "compute_variational_expectation_of_prior", "(", "\n", "beta_mean", ",", "beta_cov", "\n", ")", "+", "compute_variational_expectation_of_complete_data_likelihood", "(", "\n", "z_mean", ",", "beta_mean", ",", "beta_cov", ",", "covariates", "\n", ")", "\n", "\n", "\n", "", "def", "compute_elbo", "(", "\n", "beta_mean", ":", "NumpyArray1D", ",", "\n", "beta_cov", ":", "NumpyArray2D", ",", "\n", "z_mean", ":", "NumpyArray1D", ",", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray1D", ",", "\n", "verbose", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "    ", "entropy", "=", "compute_variational_entropy", "(", "labels", ",", "covariates", ",", "beta_mean", ",", "beta_cov", ")", "\n", "energy", "=", "compute_variational_energy", "(", "\n", "beta_mean", ",", "beta_cov", ",", "z_mean", ",", "covariates", ",", "verbose", "\n", ")", "\n", "return", "energy", "+", "entropy", "\n", "\n", "\n", "###", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.elbo.compute_elbo": [[142, 154], ["elbo.compute_variational_expectation_of_kl_divergence_of_betas", "elbo.compute_kl_divergence_of_Sigmas", "elbo.compute_kl_divergence_of_mus", "categorical_from_binary.ib_cavi.binary_probit.elbo.compute_variational_expectation_of_complete_data_likelihood", "categorical_from_binary.ib_cavi.binary_probit.elbo.compute_variational_entropy_of_z"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.elbo.compute_variational_expectation_of_kl_divergence_of_betas", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.elbo.compute_kl_divergence_of_Sigmas", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.elbo.compute_kl_divergence_of_mus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.elbo.compute_variational_expectation_of_complete_data_likelihood", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.elbo.compute_variational_entropy_of_z"], ["###", "\n", "\n", "\n", "", "def", "sample_z_from_natural_parameters", "(", "\n", "labels", ":", "NumpyArray1D", ",", "natural_parameters", ":", "NumpyArray1D", ",", "n_samples", ":", "int", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Returns:\n        np.array of shape ((n_observations, n_samples))\n    \"\"\"", "\n", "\n", "n_obs", "=", "np", ".", "shape", "(", "natural_parameters", ")", "[", "0", "]", "\n", "z_samples", "=", "np", ".", "zeros", "(", "(", "n_obs", ",", "n_samples", ")", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.inference.construct_default_hyperparameters": [[33, 36], ["categorical_from_binary.ib_cavi.multi.hierarchical_ib_probit.structs.Hyperparameters", "numpy.eye", "numpy.zeros", "numpy.eye"], "function", ["None"], ["labels", ":", "Union", "[", "NumpyArray2D", ",", "spmatrix", "]", ",", "\n", "covariates", ":", "Union", "[", "NumpyArray2D", ",", "spmatrix", "]", ",", "\n", "max_n_iterations", ":", "float", "=", "np", ".", "inf", ",", "\n", "convergence_criterion_drop_in_mean_elbo", ":", "float", "=", "-", "np", ".", "inf", ",", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.inference.initialize_variational_params": [[38, 110], ["categorical_from_binary.ib_cavi.multi.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "range", "numpy.zeros", "range", "numpy.zeros", "range", "numpy.zeros", "range", "numpy.zeros", "range", "numpy.zeros", "categorical_from_binary.ib_cavi.multi.hierarchical_ib_probit.structs.VariationalParams", "numpy.zeros", "numpy.ones", "numpy.linalg.inv", "range", "numpy.linalg.inv"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset"], ["labels_test", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "covariates_test", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "prior_beta_mean", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "prior_beta_precision", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "variational_params_init", ":", "Optional", "[", "VariationalParams", "]", "=", "None", ",", "\n", "save_beta_every_secs", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "save_beta_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "verbose", ":", "bool", "=", "True", ",", "\n", ")", "->", "CAVI_Results", ":", "\n", "    ", "if", "ib_model", "is", "IB_Model", ".", "PROBIT", ":", "\n", "        ", "inference_function", "=", "compute_multiclass_probit_vi_with_normal_prior", "\n", "", "elif", "ib_model", "is", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "inference_function", "=", "compute_multiclass_logit_vi_with_polya_gamma_augmentation", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"I don't understand the model type {ib_model}\"", ")", "\n", "", "return", "inference_function", "(", "\n", "labels", ",", "\n", "covariates", ",", "\n", "max_n_iterations", ",", "\n", "convergence_criterion_drop_in_mean_elbo", ",", "\n", "use_autoregressive_design_matrix", ",", "\n", "labels_test", ",", "\n", "covariates_test", ",", "\n", "prior_beta_mean", ",", "\n", "prior_beta_precision", ",", "\n", "variational_params_init", ",", "\n", "save_beta_every_secs", ",", "\n", "save_beta_dir", ",", "\n", "verbose", ",", "\n", ")", "\n", "\n", "\n", "", "def", "cbm_link_from_ib_model", "(", "ib_model", ":", "IB_Model", ")", ":", "\n", "    ", "if", "ib_model", "==", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "return", "Link", ".", "CBM_LOGIT", "\n", "", "elif", "ib_model", "==", "IB_Model", ".", "PROBIT", ":", "\n", "        ", "return", "Link", ".", "CBM_PROBIT", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "\n", "\n", "\n", "", "", "def", "cbc_link_from_ib_model", "(", "ib_model", ":", "IB_Model", ")", ":", "\n", "    ", "if", "ib_model", "==", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "return", "Link", ".", "CBC_LOGIT", "\n", "", "elif", "ib_model", "==", "IB_Model", ".", "PROBIT", ":", "\n", "        ", "return", "Link", ".", "CBC_PROBIT", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.inference.optimize_zs": [[113, 149], ["categorical_from_binary.ib_cavi.multi.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "range", "range", "range", "numpy.zeros", "numpy.argmax", "range", "range", "categorical_from_binary.ib_cavi.trunc_norm.compute_expected_value_normal_plus", "categorical_from_binary.ib_cavi.trunc_norm.compute_expected_value_normal_minus"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_expected_value_normal_plus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_expected_value_normal_minus"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.inference.optimize_betas": [[151, 177], ["categorical_from_binary.ib_cavi.multi.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "numpy.zeros", "numpy.zeros", "range", "range", "numpy.linalg.inv", "numpy.linalg.inv"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.inference.optimize_mus": [[179, 206], ["categorical_from_binary.ib_cavi.multi.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "numpy.zeros", "numpy.zeros", "range", "numpy.linalg.inv", "numpy.linalg.inv", "numpy.sum", "numpy.linalg.inv", "numpy.linalg.inv"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.inference.optimize_Sigmas": [[208, 238], ["categorical_from_binary.ib_cavi.multi.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "numpy.zeros", "numpy.zeros", "range", "sum", "numpy.sum", "numpy.outer", "range"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.inference.run_hierarchical_multiclass_probit_vi": [[240, 307], ["categorical_from_binary.ib_cavi.multi.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "print", "pprint.pprint", "inference.initialize_variational_params", "print", "NotImplementedError", "inference.construct_default_hyperparameters", "construct_default_hyperparameters._asdict", "inference.optimize_zs", "inference.optimize_betas", "inference.optimize_mus", "inference.optimize_Sigmas", "categorical_from_binary.ib_cavi.multi.hierarchical_ib_probit.elbo.compute_elbo", "print"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.initialize_variational_params", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.inference.construct_default_hyperparameters", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.inference.optimize_zs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.inference.optimize_betas", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.inference.optimize_mus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.inference.optimize_Sigmas", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.inference.compute_elbo"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset": [[91, 106], ["len", "numpy.shape", "structs.DataDimensions", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.elbo.compute_elbo": [[11, 64], ["numpy.zeros", "numpy.eye", "range", "numpy.shape", "numpy.shape", "categorical_from_binary.polya_gamma.binary_logreg_vi.inference.compute_elbo", "numpy.ndim", "numpy.ndim", "ValueError"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.inference.compute_elbo"], [")", "\n", "from", "categorical_from_binary", ".", "types", "import", "NumpyArray1D", ",", "NumpyArray2D", "\n", "\n", "\n", "###", "\n", "# ELBO -- as used in inference", "\n", "###", "\n", "\n", "\n", "def", "compute_variational_entropy_of_individual_entries_of_z", "(", "\n", "labels", ":", "NumpyArray1D", ",", "\n", "z_natural_parameters", ":", "NumpyArray1D", ",", "\n", ")", "->", "NumpyArray1D", ":", "\n", "    ", "\"\"\"\n    Returns:\n        Array of shape (n_observations, ), where the i-th entry is the variational entropy\n        of the latent variable associated with the i-th observation.\n    \"\"\"", "\n", "n_obs", "=", "np", ".", "shape", "(", "z_natural_parameters", ")", "[", "0", "]", "\n", "entropy_zs", "=", "np", ".", "zeros", "(", "n_obs", ")", "\n", "for", "i", ",", "(", "label", ",", "z_natural_parameter", ")", "in", "enumerate", "(", "zip", "(", "labels", ",", "z_natural_parameters", ")", ")", ":", "\n", "        ", "if", "label", "==", "1", ":", "\n", "            ", "entropy_zs", "[", "i", "]", "=", "compute_entropy_normal_plus", "(", "mu", "=", "z_natural_parameter", ")", "\n", "", "elif", "label", "==", "0", ":", "\n", "            ", "entropy_zs", "[", "i", "]", "=", "compute_entropy_normal_minus", "(", "mu", "=", "z_natural_parameter", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Found label of {label}, but the only legal values are 0 and 1.\"", "\n", ")", "\n", "", "", "return", "entropy_zs", "\n", "\n", "\n", "", "def", "compute_variational_entropy_of_z", "(", "\n", "labels", ":", "NumpyArray1D", ",", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "beta_mean", ":", "NumpyArray1D", ",", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Returns:\n        The entropy of z, the vector of latent variables associated with the observations\n    \"\"\"", "\n", "z_natural_parameters", "=", "covariates", "@", "beta_mean", "\n", "return", "np", ".", "sum", "(", "\n", "compute_variational_entropy_of_individual_entries_of_z", "(", "\n", "labels", ",", "z_natural_parameters", "\n", ")", "\n", ")", "\n", "\n", "\n", "", "def", "compute_variational_entropy_of_beta", "(", "\n", "beta_mean", ":", "NumpyArray1D", ",", "\n", "beta_cov", ":", "NumpyArray2D", ",", "\n", ")", "->", "float", ":", "\n", "    ", "return", "scipy", ".", "stats", ".", "multivariate_normal", "(", "beta_mean", ",", "beta_cov", ")", ".", "entropy", "(", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference._initialize_beta_covariance_for_one_category": [[34, 46], ["scipy.sparse.identity", "numpy.asarray", "numpy.shape", "numpy.linalg.inv"], "function", ["None"], ["covariates", ":", "Union", "[", "NumpyArray2D", ",", "spmatrix", "]", ",", "\n", "max_n_iterations", ":", "float", "=", "np", ".", "inf", ",", "\n", "convergence_criterion_drop_in_mean_elbo", ":", "float", "=", "-", "np", ".", "inf", ",", "\n", "use_autoregressive_design_matrix", ":", "bool", "=", "False", ",", "\n", "labels_test", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "covariates_test", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "prior_beta_mean", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "prior_beta_precision", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "variational_params_init", ":", "Optional", "[", "VariationalParams", "]", "=", "None", ",", "\n", "save_beta_every_secs", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "save_beta_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "verbose", ":", "bool", "=", "True", ",", "\n", ")", "->", "CAVI_Results", ":", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.update_omegas": [[48, 64], ["numpy.shape", "numpy.zeros", "range", "numpy.ones_like", "categorical_from_binary.ib_cavi.multi.structs.VariationalOmegas", "range", "numpy.sqrt"], "function", ["None"], ["        ", "inference_function", "=", "compute_multiclass_probit_vi_with_normal_prior", "\n", "", "elif", "ib_model", "is", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "inference_function", "=", "compute_multiclass_logit_vi_with_polya_gamma_augmentation", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"I don't understand the model type {ib_model}\"", ")", "\n", "", "return", "inference_function", "(", "\n", "labels", ",", "\n", "covariates", ",", "\n", "max_n_iterations", ",", "\n", "convergence_criterion_drop_in_mean_elbo", ",", "\n", "use_autoregressive_design_matrix", ",", "\n", "labels_test", ",", "\n", "covariates_test", ",", "\n", "prior_beta_mean", ",", "\n", "prior_beta_precision", ",", "\n", "variational_params_init", ",", "\n", "save_beta_every_secs", ",", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.compute_expected_value_of_polya_gamma_random_variable": [[66, 70], ["ValueError", "numpy.exp", "numpy.exp"], "function", ["None"], ["verbose", ",", "\n", ")", "\n", "\n", "\n", "", "def", "cbm_link_from_ib_model", "(", "ib_model", ":", "IB_Model", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.compute_expected_omegas": [[72, 83], ["numpy.shape", "numpy.zeros_like", "range", "range", "inference.compute_expected_value_of_polya_gamma_random_variable"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.compute_expected_value_of_polya_gamma_random_variable"], ["        ", "return", "Link", ".", "CBM_LOGIT", "\n", "", "elif", "ib_model", "==", "IB_Model", ".", "PROBIT", ":", "\n", "        ", "return", "Link", ".", "CBM_PROBIT", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "\n", "\n", "\n", "", "", "def", "cbc_link_from_ib_model", "(", "ib_model", ":", "IB_Model", ")", ":", "\n", "    ", "if", "ib_model", "==", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "return", "Link", ".", "CBC_LOGIT", "\n", "", "elif", "ib_model", "==", "IB_Model", ".", "PROBIT", ":", "\n", "        ", "return", "Link", ".", "CBC_PROBIT", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.update_beta_covariance_for_one_category": [[85, 102], ["scipy.sparse.diags", "numpy.linalg.inv", "numpy.shape", "numpy.eye"], "function", ["None"], ["        ", "raise", "ValueError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.update_beta": [[104, 144], ["inference.compute_expected_omegas", "numpy.zeros", "range", "numpy.einsum", "categorical_from_binary.ib_cavi.multi.structs.VariationalBeta", "numpy.shape", "numpy.shape", "numpy.zeros", "numpy.eye", "inference.update_beta_covariance_for_one_category"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.compute_expected_omegas", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.update_beta_covariance_for_one_category"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.initialize_variational_params": [[146, 179], ["categorical_from_binary.ib_cavi.multi.structs.VariationalParams", "numpy.shape", "warnings.warn", "numpy.zeros", "categorical_from_binary.ib_cavi.multi.structs.VariationalBeta", "numpy.array", "inference._initialize_beta_covariance_for_one_category", "range"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference._initialize_beta_covariance_for_one_category"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.update_variational_params_and_elbo_stats": [[181, 226], ["inference.update_omegas", "inference.update_beta", "categorical_from_binary.ib_cavi.multi.structs.VariationalParams", "numpy.shape", "categorical_from_binary.ib_cavi.multi.ib_logit.elbo.compute_elbo", "categorical_from_binary.ib_cavi.multi.structs.ELBO_Stats"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.update_omegas", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.update_beta", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.inference.compute_elbo"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit.inference.compute_multiclass_logit_vi_with_polya_gamma_augmentation": [[228, 324], ["scipy.sparse.isspmatrix", "scipy.sparse.isspmatrix", "scipy.sparse.isspmatrix", "scipy.sparse.isspmatrix", "categorical_from_binary.ib_cavi.multi.inference_wrapper.compute_ib_cavi", "warnings.warn", "numpy.array", "warnings.warn", "numpy.array", "numpy.array", "numpy.array", "np.array.todense", "np.array.todense", "np.array.todense", "np.array.todense"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multi.inference_wrapper.compute_ib_cavi"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logit_with_pga_and_albert_chib_aug.gibbs.prior_info_from_prior_params": [[27, 38], ["numpy.linalg.inv", "gibbs.PriorInfo"], "function", ["None"], ["", "def", "prior_info_from_prior_params", "(", "\n", "mu_0", ":", "NumpyArray1D", ",", "Sigma_0", ":", "NumpyArray2D", "\n", ")", "->", "PriorInfo", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        mu_0: prior mean\n        Sigma_0: prior variance\n    \"\"\"", "\n", "precision", "=", "np", ".", "linalg", ".", "inv", "(", "Sigma_0", ")", "\n", "precision_weighted_mean", "=", "precision", "@", "mu_0", "\n", "return", "PriorInfo", "(", "precision", ",", "precision_weighted_mean", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logit_with_pga_and_albert_chib_aug.gibbs.sample_omega": [[40, 60], ["pypolyagamma.PyPolyaGamma", "numpy.array", "pypolyagamma.PyPolyaGamma.pgdraw"], "function", ["None"], ["", "def", "sample_omega", "(", "\n", "covariates", ":", "NumpyArray2D", ",", "beta_sample", ":", "NumpyArray2D", ",", "z_sample", ":", "NumpyArray1D", "\n", ")", "->", "NumpyArray1D", ":", "\n", "    ", "\"\"\"\n    Sample omega (the polya gamma augmentation variable) from the Polya Gamma distribution\n    according to its complete conditional.\n\n    Arguments:\n        covariates: has shape (N,M), where N is the number of samples and M is the number of covariates\n        beta_sample: has shape (M,), where M is the number of covariates\n        z_sample: has shape (N,), where N is the number of samples\n\n    Returns:\n        a sample of omega.  Has shape (N,), where N is the number of samples\n\n    \"\"\"", "\n", "b", "=", "2", "\n", "c_per_sample", "=", "covariates", "@", "beta_sample", "-", "z_sample", "\n", "pg", "=", "PyPolyaGamma", "(", ")", "\n", "return", "np", ".", "array", "(", "[", "pg", ".", "pgdraw", "(", "b", ",", "c", ")", "for", "c", "in", "c_per_sample", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logit_with_pga_and_albert_chib_aug.gibbs.sample_beta": [[62, 88], ["numpy.linalg.inv", "scipy.stats.multivariate_normal.rvs", "numpy.diag", "numpy.diag"], "function", ["None"], ["", "def", "sample_beta", "(", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "z_sample", ":", "NumpyArray1D", ",", "\n", "omega_sample", ":", "NumpyArray1D", ",", "\n", "prior_info", ":", "PriorInfo", ",", "\n", ")", "->", "NumpyArray1D", ":", "\n", "    ", "\"\"\"\n    Sample beta (the regression weights) according to its multivariate normal complete conditional.\n\n    Arguments:\n        covariates: has shape (N,M), where N is the number of samples and M is the number of covariates\n        omega_sample: has shape (N,), where N is the number of samples\n        z_sample: has shape (N,), where N is the number of samples\n\n    Returns:\n        a sample of beta. Has shape (M,), where M is the number of covariates\n\n    \"\"\"", "\n", "Sigma", "=", "np", ".", "linalg", ".", "inv", "(", "\n", "prior_info", ".", "precision", "+", "covariates", ".", "T", "@", "np", ".", "diag", "(", "omega_sample", ")", "@", "covariates", "\n", ")", "\n", "mu", "=", "Sigma", "@", "(", "\n", "prior_info", ".", "precision_weighted_mean", "\n", "+", "covariates", ".", "T", "@", "np", ".", "diag", "(", "omega_sample", ")", "@", "z_sample", "\n", ")", "\n", "return", "mvn", ".", "rvs", "(", "mu", ",", "Sigma", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logit_with_pga_and_albert_chib_aug.gibbs.sample_z": [[90, 127], ["range", "numpy.shape", "numpy.sqrt", "scipy.stats.norm.rvs"], "function", ["None"], ["", "def", "sample_z", "(", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray1D", ",", "\n", "beta_sample", ":", "NumpyArray1D", ",", "\n", "omega_sample", ":", "NumpyArray1D", ",", "\n", ")", "->", "NumpyArray1D", ":", "\n", "    ", "\"\"\"\n    Sample z, the Diagonal Orthant augmentation variable (which in 2D is just the standard Albert & Chib augmentation\n    variable), from its (truncated normal) complete conditional\n\n    Arguments:\n        covariates: has shape (N,M), where N is the number of samples and M is the number of covariates\n        labels: array with shape (N,), whose elements are either a 1 or 0.\n        beta_sample: has shape (M,), where M is the number of covariates\n        omega_sample: has shape (N,), where N is the number of samples\n\n    Returns:\n        a sample of z. Has shape (N,), where N is the number of samples\n\n    \"\"\"", "\n", "N", "=", "np", ".", "shape", "(", "covariates", ")", "[", "0", "]", "\n", "\n", "mu_zs", "=", "covariates", "@", "beta_sample", "\n", "ssq_zs", "=", "1", "/", "np", ".", "sqrt", "(", "omega_sample", ")", "\n", "\n", "z_samples", "=", "[", "None", "]", "*", "N", "\n", "# A crappy truncated normal sampler via rejection sampling.  Can do better if desired.", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "        ", "acceptance", "=", "False", "\n", "while", "not", "acceptance", ":", "\n", "            ", "sample_proposed", "=", "norm", ".", "rvs", "(", "mu_zs", "[", "i", "]", ",", "ssq_zs", "[", "i", "]", ")", "\n", "if", "(", "labels", "[", "i", "]", "==", "0", "and", "sample_proposed", "<", "0", ")", "or", "(", "\n", "labels", "[", "i", "]", "==", "1", "and", "sample_proposed", ">", "0", "\n", ")", ":", "\n", "                ", "acceptance", "=", "True", "\n", "z_samples", "[", "i", "]", "=", "sample_proposed", "\n", "", "", "", "return", "z_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logit_with_pga_and_albert_chib_aug.gibbs.sample_from_posterior": [[129, 165], ["numpy.shape", "numpy.zeros", "range", "numpy.zeros", "numpy.zeros", "print", "sys.stdout.flush", "gibbs.sample_omega", "gibbs.sample_beta", "gibbs.sample_z"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multiclass_logreg_gibbs.inference.sample_omega", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multiclass_logreg_gibbs.inference.sample_beta", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logit_with_pga_and_albert_chib_aug.gibbs.sample_z"], ["", "def", "sample_from_posterior", "(", "\n", "covariates", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray1D", ",", "\n", "prior_info", ":", "PriorInfo", ",", "\n", "num_MCMC_samples", ":", "int", ",", "\n", "z_init", ":", "Optional", "[", "NumpyArray1D", "]", "=", "None", ",", "\n", "beta_init", ":", "Optional", "[", "NumpyArray1D", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Sample from the posterior of the Binary Logistic Regression model with both diagonal orthant\n    and polya gamma augmentation.  Note that in this special case of binary data, diagonal orthant\n    augmentation is the same as Albert and Chib augmentation.\n    \"\"\"", "\n", "# initialize sampler", "\n", "N", ",", "M", "=", "np", ".", "shape", "(", "covariates", ")", "\n", "if", "z_init", "is", "None", ":", "\n", "        ", "z_init", "=", "np", ".", "zeros", "(", "N", ")", "\n", "", "if", "beta_init", "is", "None", ":", "\n", "        ", "beta_init", "=", "np", ".", "zeros", "(", "M", ")", "\n", "", "z_sample", "=", "z_init", "\n", "beta_sample", "=", "beta_init", "\n", "\n", "beta_MCMC_samples", "=", "np", ".", "zeros", "(", "(", "M", ",", "num_MCMC_samples", ")", ")", "\n", "for", "s", "in", "range", "(", "num_MCMC_samples", ")", ":", "\n", "        ", "END_OF_PRINT_STATEMENT", "=", "\"\\n\"", "\n", "# \"\\r\" is better if working locally, but won't show up in logs in cluster", "\n", "print", "(", "f\"Now running MCMC iterate {s}\"", ",", "end", "=", "END_OF_PRINT_STATEMENT", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "omega_sample", "=", "sample_omega", "(", "covariates", ",", "beta_sample", ",", "z_sample", ")", "\n", "beta_sample", "=", "sample_beta", "(", "covariates", ",", "z_sample", ",", "omega_sample", ",", "prior_info", ")", "\n", "z_sample", "=", "sample_z", "(", "covariates", ",", "labels", ",", "beta_sample", ",", "omega_sample", ")", "\n", "\n", "# store what i want to retain", "\n", "beta_MCMC_samples", "[", ":", ",", "s", "]", "=", "beta_sample", "\n", "\n", "", "return", "beta_MCMC_samples", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cat_models_report.why_IB_plus_CBC_overemphasizes_dominant_categories.make_CBC_arg_from_IB_arg": [[25, 27], ["functools.partial"], "function", ["None"], ["def", "make_CBC_arg_from_IB_arg", "(", "constraint", ")", ":", "\n", "    ", "return", "partial", "(", "CBC_arg_from_IB_arg_and_constraint", ",", "constraint", "=", "constraint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.cat_models_report.why_IB_plus_CBC_overemphasizes_dominant_categories.make_CBM_arg_from_IB_arg": [[29, 31], ["functools.partial"], "function", ["None"], ["", "def", "make_CBM_arg_from_IB_arg", "(", "constraint", ")", ":", "\n", "    ", "return", "partial", "(", "CBM_arg_from_IB_arg_and_constraint", ",", "constraint", "=", "constraint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.uai.plot_CBM_vs_CBC.context_is_relevant": [[23, 28], ["None"], "function", ["None"], ["def", "context_is_relevant", "(", "context", ",", "data_generating_link_of_interest", ")", ":", "\n", "    ", "return", "(", "\n", "context", ".", "data_type", "==", "DataType", ".", "TEST", "\n", "and", "context", ".", "metric", "==", "Metric", ".", "MEAN_LOG_LIKELIHOOD", "\n", "and", "context", ".", "link_for_generating_data", "==", "data_generating_link_of_interest", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.uai.plot_CBM_vs_CBC.make_relevant_subdict": [[31, 37], ["d.items", "plot_CBM_vs_CBC.context_is_relevant"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.uai.plot_CBM_vs_CBC.context_is_relevant"], ["", "def", "make_relevant_subdict", "(", "d", ",", "data_generating_link_of_interest", ")", ":", "\n", "    ", "subdict", "=", "{", "}", "\n", "for", "context", ",", "values", "in", "d", ".", "items", "(", ")", ":", "\n", "        ", "if", "context_is_relevant", "(", "context", ",", "data_generating_link_of_interest", ")", ":", "\n", "            ", "subdict", "[", "context", "]", "=", "values", "\n", "", "", "return", "subdict", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.uai.plot_CBM_vs_CBC.make_figure_comparing_CBM_and_CBC_across_data_generating_links": [[39, 132], ["categorical_from_binary.evaluate.multiclass.form_dict_mapping_measurement_context_to_values", "pandas.DataFrame", "matplotlib.figure", "seaborn.boxplot", "seaborn.swarmplot", "list", "plot_CBM_vs_CBC.make_relevant_subdict", "make_relevant_subdict.items", "f", "f", "f", "print", "error_reductions.extend", "data_generating_links.extend", "set", "len", "pandas.Series", "pandas.Series", "numpy.array", "numpy.mean", "numpy.mean", "ValueError"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.multiclass.form_dict_mapping_measurement_context_to_values", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.uai.plot_CBM_vs_CBC.make_relevant_subdict"], ["", "def", "make_figure_comparing_CBM_and_CBC_across_data_generating_links", "(", "\n", "measurements", ":", "List", "[", "Measurement", "]", ",", "\n", "data_generating_links_of_interest", ":", "Optional", "[", "List", "[", "Link", "]", "]", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Make a figure comparing IB+CBM vs IB+CBC across various data generating links.\n    The figure is a seaborn boxplot (https://seaborn.pydata.org/generated/seaborn.boxplot.html).\n    Along the way, we create a pandas dataframe showing reduction of relative error that could be\n    split off into its own function.\n\n    Arguments:\n        data_generating_links_of_interest: By default, this is inferred from the data generating\n        links that exist in the measurements, but it can be specified if one wants the figure to\n        present them in a certain order (or if one wants to plot a mere subset of what's available\n        in the measurements).\n    Returns:\n        Instance of matplotlib.axes._subplots.AxesSubplot\n    \"\"\"", "\n", "\n", "d", "=", "form_dict_mapping_measurement_context_to_values", "(", "measurements", ")", "\n", "\n", "data_generating_links", "=", "[", "]", "\n", "error_reductions", "=", "[", "]", "\n", "\n", "if", "data_generating_links_of_interest", "is", "None", ":", "\n", "        ", "data_generating_links_of_interest", "=", "list", "(", "\n", "set", "(", "[", "m", ".", "context", ".", "link_for_generating_data", "for", "m", "in", "measurements", "]", ")", "\n", ")", "\n", "\n", "", "for", "data_generating_link_of_interest", "in", "data_generating_links_of_interest", ":", "\n", "        ", "sd", "=", "make_relevant_subdict", "(", "d", ",", "data_generating_link_of_interest", ")", "\n", "for", "context", ",", "values", "in", "sd", ".", "items", "(", ")", ":", "\n", "            ", "if", "(", "\n", "context", ".", "link_for_category_probabilities", "==", "Link", ".", "CBC_PROBIT", "\n", "and", "context", ".", "beta_type", "==", "BetaType", ".", "VARIATIONAL_POSTERIOR_MEAN", "\n", ")", ":", "\n", "                ", "values_with_CBC_probit_estimator", "=", "values", "\n", "", "elif", "(", "\n", "context", ".", "link_for_category_probabilities", "==", "Link", ".", "CBM_PROBIT", "\n", "and", "context", ".", "beta_type", "==", "BetaType", ".", "VARIATIONAL_POSTERIOR_MEAN", "\n", ")", ":", "\n", "                ", "values_with_CBM_probit_estimator", "=", "values", "\n", "", "elif", "(", "\n", "context", ".", "link_for_category_probabilities", "\n", "==", "data_generating_link_of_interest", "\n", "and", "context", ".", "beta_type", "==", "BetaType", ".", "GROUND_TRUTH", "\n", ")", ":", "\n", "                ", "values_ground_truth", "=", "values", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\"Something weird happened\"", ")", "\n", "\n", "", "", "f", "=", "lambda", "x", ":", "np", ".", "array", "(", "x", ")", "*", "1", "# f=np.exp", "\n", "CBC", "=", "f", "(", "values_with_CBC_probit_estimator", ")", "\n", "CBM", "=", "f", "(", "values_with_CBM_probit_estimator", ")", "\n", "GT", "=", "f", "(", "values_ground_truth", ")", "\n", "print", "(", "\n", "f\"For data generating link {data_generating_link_of_interest} \"", "\n", "f\"the mean held out log likelihood for CBM was {np.mean(CBM):.02} and \"", "\n", "f\"with the ground truth was  {np.mean(GT):.02} \"", "\n", ")", "\n", "\n", "CBC_dists", "=", "GT", "-", "CBC", "\n", "CBM_dists", "=", "GT", "-", "CBM", "\n", "error_reductions_curr", "=", "(", "CBC_dists", "-", "CBM_dists", ")", "/", "CBC_dists", "\n", "data_generating_links_curr", "=", "[", "data_generating_link_of_interest", ".", "name", "]", "*", "len", "(", "\n", "error_reductions_curr", "\n", ")", "\n", "# print(f\"{error_reductions_curr}\")", "\n", "error_reductions", ".", "extend", "(", "error_reductions_curr", ")", "\n", "data_generating_links", ".", "extend", "(", "data_generating_links_curr", ")", "\n", "\n", "", "df", "=", "pd", ".", "DataFrame", "(", "\n", "{", "\n", "\"relative error reduction\"", ":", "pd", ".", "Series", "(", "error_reductions", ")", ",", "\n", "\"data generating link\"", ":", "pd", ".", "Series", "(", "data_generating_links", ")", ",", "\n", "}", "\n", ")", "\n", "\n", "# TODO: split above off into its own function. The construction of the pandas", "\n", "# dataframe should be its own function", "\n", "\n", "###", "\n", "# This part makes the figure", "\n", "###", "\n", "\n", "# boxplot", "\n", "# https://seaborn.pydata.org/generated/seaborn.boxplot.html", "\n", "plt", ".", "figure", "(", ")", "\n", "ax", "=", "sns", ".", "boxplot", "(", "x", "=", "\"data generating link\"", ",", "y", "=", "\"relative error reduction\"", ",", "data", "=", "df", ")", "\n", "ax", "=", "sns", ".", "swarmplot", "(", "\n", "x", "=", "\"data generating link\"", ",", "y", "=", "\"relative error reduction\"", ",", "data", "=", "df", ",", "color", "=", "\".25\"", "\n", ")", "\n", "return", "ax", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.polya_gamma.polya_gamma.compute_polya_gamma_expectation": [[4, 41], ["ValueError", "ValueError", "abs", "numpy.exp", "numpy.exp"], "function", ["None"], ["def", "compute_polya_gamma_expectation", "(", "\n", "b", ":", "float", ",", "c", ":", "float", ",", "allow_b_to_be_zero", ":", "bool", "=", "False", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    The code implements the top right equation on pp. 1341 of\n    Polson, Scott, Windle (2013), JASA,  with the exception that the implementation\n    bounds c away from 0 with an epsilon-ball.  This is due to the fact that the\n    paper's provided expression for the expectation is is undefined at b==0, even\n    though the expectation is actually defined.  (I have not proven that it is, but I have\n    this on supposition based on Monte Carlo approximations combined with a first foray into\n    proving it.)\n\n    Arguments:\n        b:  first parameter of the Polya-Gamma distribution.  Must be >0.\n        c:  second parameter of the Polya-Gamma distribution.  Must be real-valued.\n        allow_b_to_be_zero:  False by default, due to the support of the Polya-Gamma distribution.\n            If True, then we always return an expectation of 0 when b equals 0, which has computational\n            advantages.\n    Reference:\n        Polson, Scott, Windle,  JASA,  2013.\n    \"\"\"", "\n", "if", "b", "<", "0", ":", "\n", "        ", "raise", "ValueError", "(", "f\"b={b}, but it cannot be less than 0\"", ")", "\n", "", "if", "b", "==", "0", "and", "not", "allow_b_to_be_zero", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"b={b}, but it cannot equal 0, unless the allow_b_to_be_zero flag is set to True\"", "\n", ")", "\n", "", "if", "b", "==", "0", "and", "allow_b_to_be_zero", ":", "\n", "        ", "return", "0", "\n", "\n", "# If c is too close to 0, we replace it with epsilon, because the paper's formula", "\n", "# is undefined at c==0, even though the expectation has a known value.", "\n", "", "EPSILON", "=", "1e-10", "\n", "if", "abs", "(", "c", ")", "<", "EPSILON", ":", "\n", "        ", "c", "=", "EPSILON", "\n", "\n", "", "return", "b", "/", "(", "2", "*", "c", ")", "*", "(", "np", ".", "exp", "(", "c", ")", "-", "1", ")", "/", "(", "1", "+", "np", ".", "exp", "(", "c", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multiclass_logreg_gibbs.inference.compute_log_sum_exponentiated_utilities_for_non_self_categories": [[33, 66], ["categorical_from_binary.data_generation.bayes_multiclass_reg.compute_linear_predictors_preventing_downstream_overflow", "numpy.exp", "numpy.zeros", "range", "numpy.ones", "numpy.compress", "numpy.log", "numpy.shape", "numpy.shape", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.compute_linear_predictors_preventing_downstream_overflow"], ["labels", ":", "Union", "[", "NumpyArray2D", ",", "spmatrix", "]", ",", "\n", "covariates", ":", "Union", "[", "NumpyArray2D", ",", "spmatrix", "]", ",", "\n", "max_n_iterations", ":", "float", "=", "np", ".", "inf", ",", "\n", "convergence_criterion_drop_in_mean_elbo", ":", "float", "=", "-", "np", ".", "inf", ",", "\n", "use_autoregressive_design_matrix", ":", "bool", "=", "False", ",", "\n", "labels_test", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "covariates_test", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "prior_beta_mean", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "prior_beta_precision", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "variational_params_init", ":", "Optional", "[", "VariationalParams", "]", "=", "None", ",", "\n", "save_beta_every_secs", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "save_beta_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "verbose", ":", "bool", "=", "True", ",", "\n", ")", "->", "CAVI_Results", ":", "\n", "    ", "if", "ib_model", "is", "IB_Model", ".", "PROBIT", ":", "\n", "        ", "inference_function", "=", "compute_multiclass_probit_vi_with_normal_prior", "\n", "", "elif", "ib_model", "is", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "inference_function", "=", "compute_multiclass_logit_vi_with_polya_gamma_augmentation", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"I don't understand the model type {ib_model}\"", ")", "\n", "", "return", "inference_function", "(", "\n", "labels", ",", "\n", "covariates", ",", "\n", "max_n_iterations", ",", "\n", "convergence_criterion_drop_in_mean_elbo", ",", "\n", "use_autoregressive_design_matrix", ",", "\n", "labels_test", ",", "\n", "covariates_test", ",", "\n", "prior_beta_mean", ",", "\n", "prior_beta_precision", ",", "\n", "variational_params_init", ",", "\n", "save_beta_every_secs", ",", "\n", "save_beta_dir", ",", "\n", "verbose", ",", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multiclass_logreg_gibbs.inference.prior_info_from_prior_params": [[88, 99], ["numpy.linalg.inv", "inference.PriorInfo"], "function", ["None"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multiclass_logreg_gibbs.inference.sample_omega": [[106, 138], ["categorical_from_binary.data_generation.bayes_multiclass_reg.compute_linear_predictors_preventing_downstream_overflow", "inference..", "numpy.zeros", "range", "range", "numpy.shape", "numpy.shape", "polya_gamma_sampler.pgdraw"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.compute_linear_predictors_preventing_downstream_overflow"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multiclass_logreg_gibbs.inference.sample_beta": [[140, 176], ["inference..", "numpy.zeros", "range", "scipy.sparse.diags", "numpy.linalg.inv", "scipy.stats.multivariate_normal.rvs", "numpy.shape", "numpy.shape"], "function", ["None"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multiclass_logreg_gibbs.inference.sample_from_posterior_of_multiclass_logistic_regression_with_pga": [[183, 244], ["numpy.shape", "pypolyagamma.PyPolyaGamma", "scipy.sparse.isspmatrix", "scipy.sparse.isspmatrix", "numpy.zeros", "range", "numpy.shape", "numpy.zeros", "numpy.eye", "inference.prior_info_from_prior_params", "numpy.zeros", "numpy.array", "numpy.array", "print", "sys.stdout.flush", "sys.stdout.flush", "inference.sample_omega", "inference.sample_beta", "numpy.shape", "np.array.todense", "np.array.todense"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multiclass_logreg_gibbs.inference.prior_info_from_prior_params", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multiclass_logreg_gibbs.inference.sample_omega", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.multiclass_logreg_gibbs.inference.sample_beta"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.inference.compute_expected_value_of_c_parameter_for_polya_gamma": [[27, 39], ["numpy.array", "numpy.sqrt", "numpy.transpose"], "function", ["None"], ["    ", "LOGIT", "=", "1", "\n", "PROBIT", "=", "2", "\n", "\n", "\n", "", "def", "compute_ib_cavi_with_normal_prior", "(", "\n", "ib_model", ":", "IB_Model", ",", "\n", "labels", ":", "Union", "[", "NumpyArray2D", ",", "spmatrix", "]", ",", "\n", "covariates", ":", "Union", "[", "NumpyArray2D", ",", "spmatrix", "]", ",", "\n", "max_n_iterations", ":", "float", "=", "np", ".", "inf", ",", "\n", "convergence_criterion_drop_in_mean_elbo", ":", "float", "=", "-", "np", ".", "inf", ",", "\n", "use_autoregressive_design_matrix", ":", "bool", "=", "False", ",", "\n", "labels_test", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "covariates_test", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.inference.compute_kl_divergence_from_prior_to_variational_beta": [[46, 74], ["categorical_from_binary.polya_gamma.binary_logreg_vi.util.compute_log_abs_det", "categorical_from_binary.polya_gamma.binary_logreg_vi.util.compute_log_abs_det", "len", "categorical_from_binary.polya_gamma.binary_logreg_vi.util.compute_matrix_inverse", "numpy.trace", "numpy.transpose"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.util.compute_log_abs_det", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.util.compute_log_abs_det", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.util.compute_matrix_inverse"], [")", "->", "CAVI_Results", ":", "\n", "    ", "if", "ib_model", "is", "IB_Model", ".", "PROBIT", ":", "\n", "        ", "inference_function", "=", "compute_multiclass_probit_vi_with_normal_prior", "\n", "", "elif", "ib_model", "is", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "inference_function", "=", "compute_multiclass_logit_vi_with_polya_gamma_augmentation", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"I don't understand the model type {ib_model}\"", ")", "\n", "", "return", "inference_function", "(", "\n", "labels", ",", "\n", "covariates", ",", "\n", "max_n_iterations", ",", "\n", "convergence_criterion_drop_in_mean_elbo", ",", "\n", "use_autoregressive_design_matrix", ",", "\n", "labels_test", ",", "\n", "covariates_test", ",", "\n", "prior_beta_mean", ",", "\n", "prior_beta_precision", ",", "\n", "variational_params_init", ",", "\n", "save_beta_every_secs", ",", "\n", "save_beta_dir", ",", "\n", "verbose", ",", "\n", ")", "\n", "\n", "\n", "", "def", "cbm_link_from_ib_model", "(", "ib_model", ":", "IB_Model", ")", ":", "\n", "    ", "if", "ib_model", "==", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "return", "Link", ".", "CBM_LOGIT", "\n", "", "elif", "ib_model", "==", "IB_Model", ".", "PROBIT", ":", "\n", "        ", "return", "Link", ".", "CBM_PROBIT", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.inference.compute_expected_log_likelihood_plus_omega_entropy": [[76, 91], ["inference.compute_expected_value_of_c_parameter_for_polya_gamma", "numpy.sum", "numpy.log", "numpy.exp"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.inference.compute_expected_value_of_c_parameter_for_polya_gamma"], ["        ", "raise", "ValueError", "\n", "\n", "\n", "", "", "def", "cbc_link_from_ib_model", "(", "ib_model", ":", "IB_Model", ")", ":", "\n", "    ", "if", "ib_model", "==", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "return", "Link", ".", "CBC_LOGIT", "\n", "", "elif", "ib_model", "==", "IB_Model", ".", "PROBIT", ":", "\n", "        ", "return", "Link", ".", "CBC_PROBIT", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.inference.compute_elbo": [[94, 124], ["inference.compute_kl_divergence_from_prior_to_variational_beta", "inference.compute_expected_log_likelihood_plus_omega_entropy"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.inference.compute_kl_divergence_from_prior_to_variational_beta", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.inference.compute_expected_log_likelihood_plus_omega_entropy"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.inference.run_polya_gamma_variational_inference_for_bayesian_logistic_regression": [[131, 212], ["numpy.linalg.inv", "categorical_from_binary.data_generation.util.prepend_features_with_column_of_all_ones_for_intercept", "numpy.transpose", "ValueError", "print", "print", "inference.compute_expected_value_of_c_parameter_for_polya_gamma", "numpy.array", "numpy.linalg.inv", "inference.VariationalParameters", "categorical_from_binary.data_generation.util.prepend_features_with_column_of_all_ones_for_intercept", "inference.compute_elbo", "print", "categorical_from_binary.polya_gamma.polya_gamma.compute_polya_gamma_expectation"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.util.prepend_features_with_column_of_all_ones_for_intercept", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.inference.compute_expected_value_of_c_parameter_for_polya_gamma", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.util.prepend_features_with_column_of_all_ones_for_intercept", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.inference.compute_elbo", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.polya_gamma.polya_gamma.compute_polya_gamma_expectation"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.util.compute_matrix_inverse": [[6, 13], ["numpy.linalg.inv"], "function", ["None"], ["\n", "from", "categorical_from_binary", ".", "types", "import", "NumpyArray1D", "\n", "\n", "\n", "def", "one_hot_encoded_array_from_categorical_indices", "(", "\n", "categorical_indices", ":", "NumpyArray1D", ",", "\n", "number_of_possible_categories", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "sparse_representation", ":", "bool", "=", "False", ",", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.util.compute_log_abs_det": [[15, 21], ["numpy.linalg.slogdet"], "function", ["None"], ["    ", "\"\"\"\n    Takes a one-dim numpy array of integers and expands it to a two-dim numpy array\n    that is one-hot encoded\n    \"\"\"", "\n", "\n", "# TODO: This function currently assumes that we should assign a column for every", "\n", "# integer within 0 and the maximal categorical index.   This should be related", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.stickbreak_multiclass_logreg_vi.inference.compute_num_trials": [[34, 50], ["numpy.cumsum", "numpy.insert"], "function", ["None"], ["covariates", ":", "Union", "[", "NumpyArray2D", ",", "spmatrix", "]", ",", "\n", "max_n_iterations", ":", "float", "=", "np", ".", "inf", ",", "\n", "convergence_criterion_drop_in_mean_elbo", ":", "float", "=", "-", "np", ".", "inf", ",", "\n", "use_autoregressive_design_matrix", ":", "bool", "=", "False", ",", "\n", "labels_test", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "covariates_test", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "prior_beta_mean", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "prior_beta_precision", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "variational_params_init", ":", "Optional", "[", "VariationalParams", "]", "=", "None", ",", "\n", "save_beta_every_secs", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "save_beta_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "verbose", ":", "bool", "=", "True", ",", "\n", ")", "->", "CAVI_Results", ":", "\n", "    ", "if", "ib_model", "is", "IB_Model", ".", "PROBIT", ":", "\n", "        ", "inference_function", "=", "compute_multiclass_probit_vi_with_normal_prior", "\n", "", "elif", "ib_model", "is", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "inference_function", "=", "compute_multiclass_logit_vi_with_polya_gamma_augmentation", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.stickbreak_multiclass_logreg_vi.inference.compute_kappa": [[52, 70], ["None"], "function", ["None"], ["        ", "raise", "ValueError", "(", "f\"I don't understand the model type {ib_model}\"", ")", "\n", "", "return", "inference_function", "(", "\n", "labels", ",", "\n", "covariates", ",", "\n", "max_n_iterations", ",", "\n", "convergence_criterion_drop_in_mean_elbo", ",", "\n", "use_autoregressive_design_matrix", ",", "\n", "labels_test", ",", "\n", "covariates_test", ",", "\n", "prior_beta_mean", ",", "\n", "prior_beta_precision", ",", "\n", "variational_params_init", ",", "\n", "save_beta_every_secs", ",", "\n", "save_beta_dir", ",", "\n", "verbose", ",", "\n", ")", "\n", "\n", "\n", "", "def", "cbm_link_from_ib_model", "(", "ib_model", ":", "IB_Model", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.stickbreak_multiclass_logreg_vi.inference.run_polya_gamma_variational_inference_for_bayesian_multiclass_logistic_regression": [[77, 177], ["numpy.transpose", "inference.compute_num_trials", "numpy.shape", "inference.compute_kappa", "ValueError", "NotImplementedError", "numpy.linalg.inv", "copy.copy", "copy.copy", "print", "print", "print", "range", "inference.VariationalParameters_MulticlassLogisticRegression", "categorical_from_binary.polya_gamma.binary_logreg_vi.inference.compute_expected_value_of_c_parameter_for_polya_gamma", "numpy.array", "numpy.linalg.inv", "print", "categorical_from_binary.polya_gamma.polya_gamma.compute_polya_gamma_expectation", "enumerate"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.stickbreak_multiclass_logreg_vi.inference.compute_num_trials", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.stickbreak_multiclass_logreg_vi.inference.compute_kappa", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.inference.compute_expected_value_of_c_parameter_for_polya_gamma", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.polya_gamma.polya_gamma.compute_polya_gamma_expectation"], ["\n", "\n", "", "", "def", "cbc_link_from_ib_model", "(", "ib_model", ":", "IB_Model", ")", ":", "\n", "    ", "if", "ib_model", "==", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "return", "Link", ".", "CBC_LOGIT", "\n", "", "elif", "ib_model", "==", "IB_Model", ".", "PROBIT", ":", "\n", "        ", "return", "Link", ".", "CBC_PROBIT", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.show.heatmap.plot_heatmap": [[16, 92], ["list", "list", "int", "numpy.ndarray.flatten().tolist", "numpy.percentile().tolist", "numpy.round", "matplotlib.colors.BoundaryNorm", "matplotlib.pyplot.subplots", "ax.imshow", "matplotlib.pyplot.xticks", "matplotlib.pyplot.yticks", "ax.set_xticklabels", "fig.colorbar", "matplotlib.pyplot.tight_layout", "matplotlib.pyplot.show", "beta_mean[].tolist", "list", "numpy.sort", "numpy.arange", "numpy.arange", "textwrap.fill", "map", "function_to_clean_covariate_names", "numpy.ndarray.flatten", "numpy.percentile", "set", "len", "len", "x.get_text", "ax.get_xticklabels", "list", "range"], "function", ["None"], ["def", "plot_heatmap", "(", "\n", "beta_mean", ":", "NumpyArray2D", ",", "\n", "feature_inclusion_df", ":", "DataFrame", ",", "\n", "white_out_excluded_covariates", ":", "bool", ",", "\n", "x_ticks_fontsize", ":", "float", "=", "8", ",", "\n", "function_to_clean_covariate_names", ":", "Optional", "[", "Callable", "]", "=", "None", ",", "\n", "give_each_intercept_term_its_own_heatmap_color", ":", "bool", "=", "False", ",", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Plot heatmap of model's regression weights across covariates and categories.\n    Can zero out all non-included features.\n\n    Arguments:\n        beta_mean: has shape (M,K), where M is number of covariates and K is the\n            number of categories\n        feature_inclusion_df: has shape (M,K), where M is number of covariates and K is the\n            number of categories\n    \"\"\"", "\n", "# handle the binary (two-category) case. here it looks like there is only one \"category\",", "\n", "# although that's just a function of how binary probit is structured.", "\n", "if", "beta_mean", ".", "ndim", "==", "1", ":", "\n", "        ", "beta_mean", "=", "beta_mean", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "\n", "", "if", "feature_inclusion_df", "is", "not", "None", ":", "\n", "        ", "matrix_to_show_transposed", "=", "feature_inclusion_df", "*", "beta_mean", "\n", "", "else", ":", "\n", "        ", "matrix_to_show_transposed", "=", "beta_mean", "\n", "\n", "# tranpose this so we show the labels on the y-axis", "\n", "", "matrix_to_show", "=", "matrix_to_show_transposed", ".", "T", "\n", "\n", "if", "white_out_excluded_covariates", ":", "\n", "        ", "matrix_to_show", "[", "matrix_to_show", "==", "0.0", "]", "=", "np", ".", "nan", "\n", "\n", "### Get covariate names (shorten them so plot doesn't eat them)", "\n", "", "covariate_names", "=", "list", "(", "feature_inclusion_df", ".", "index", ")", "\n", "if", "function_to_clean_covariate_names", "is", "not", "None", ":", "\n", "        ", "covariate_names", "=", "[", "\n", "function_to_clean_covariate_names", "(", "x", ")", "for", "x", "in", "covariate_names", "\n", "]", "\n", "", "label_names", "=", "list", "(", "feature_inclusion_df", ".", "columns", ")", "\n", "\n", "cmap", "=", "matplotlib", ".", "cm", ".", "viridis", "\n", "\n", "# get boundaries for heatmap", "\n", "n_bins", "=", "10", "\n", "spacing", "=", "int", "(", "100", "/", "n_bins", ")", "\n", "values", "=", "np", ".", "ndarray", ".", "flatten", "(", "beta_mean", ")", ".", "tolist", "(", ")", "\n", "percentiles", "=", "np", ".", "percentile", "(", "\n", "values", ",", "q", "=", "list", "(", "range", "(", "0", ",", "100", "+", "spacing", ",", "spacing", ")", ")", "\n", ")", ".", "tolist", "(", ")", "\n", "if", "give_each_intercept_term_its_own_heatmap_color", ":", "\n", "        ", "intercepts", "=", "beta_mean", "[", "0", ",", ":", "]", ".", "tolist", "(", ")", "\n", "percentiles", "=", "list", "(", "set", "(", "percentiles", "+", "intercepts", ")", ")", "\n", "", "bounds", "=", "np", ".", "round", "(", "np", ".", "sort", "(", "percentiles", "+", "[", "0", "]", ")", ",", "3", ")", "\n", "norm", "=", "matplotlib", ".", "colors", ".", "BoundaryNorm", "(", "bounds", ",", "cmap", ".", "N", ")", "\n", "\n", "### Make image plot", "\n", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "im", "=", "ax", ".", "imshow", "(", "matrix_to_show", ",", "cmap", "=", "cmap", ",", "norm", "=", "norm", ")", "\n", "plt", ".", "xticks", "(", "\n", "np", ".", "arange", "(", "len", "(", "covariate_names", ")", ")", ",", "\n", "covariate_names", ",", "\n", "rotation", "=", "80", ",", "\n", "fontsize", "=", "x_ticks_fontsize", ",", "\n", ")", "\n", "plt", ".", "yticks", "(", "np", ".", "arange", "(", "len", "(", "label_names", ")", ")", ",", "label_names", ")", "\n", "\n", "# try wrapping long names", "\n", "f", "=", "lambda", "x", ":", "textwrap", ".", "fill", "(", "x", ".", "get_text", "(", ")", ",", "30", ")", "\n", "ax", ".", "set_xticklabels", "(", "map", "(", "f", ",", "ax", ".", "get_xticklabels", "(", ")", ")", ")", "\n", "\n", "fig", ".", "colorbar", "(", "im", ",", "ax", "=", "ax", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "show", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.hierarchical_multiclass_reg.generate_hierarchical_multiclass_regression_dataset": [[76, 269], ["numpy.random.seed", "categorical_from_binary.data_generation.design.Design", "numpy.random.normal", "numpy.zeros", "range", "range", "hierarchical_multiclass_reg.HierarchicalMulticlassRegressionDataset", "NotImplementedError", "ValueError", "ValueError", "ValueError", "warnings.warn", "numpy.eye", "numpy.random.multivariate_normal", "categorical_from_binary.data_generation.bayes_binary_reg.generate_features", "categorical_from_binary.data_generation.bayes_multiclass_reg.generate_designed_features_and_multiclass_labels", "categorical_from_binary.data_generation.bayes_multiclass_reg.MulticlassRegressionDataset", "categorical_from_binary.data_generation.util.prepend_features_with_column_of_all_ones_for_intercept", "numpy.shape"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.generate_features", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_designed_features_and_multiclass_labels", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.util.prepend_features_with_column_of_all_ones_for_intercept"], ["", "def", "generate_hierarchical_multiclass_regression_dataset", "(", "\n", "n_samples", ":", "int", ",", "\n", "n_features_exogenous", ":", "int", ",", "\n", "n_categories", ":", "int", ",", "\n", "n_groups", ":", "int", ",", "\n", "s2_beta", ":", "float", "=", "1", ",", "\n", "s2_beta_expected", ":", "float", "=", "1", ",", "\n", "link", ":", "Link", "=", "Link", ".", "CBC_PROBIT", ",", "\n", "seed", ":", "int", "=", "None", ",", "\n", "include_intercept", ":", "bool", "=", "True", ",", "\n", "beta_0_expected", ":", "Optional", "[", "NumpyArray1D", "]", "=", "None", ",", "\n", "is_autoregressive", ":", "bool", "=", "False", ",", "\n", "beta_transition_expected", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "beta_exogenous_expected", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "indices_of_exogenous_features_that_are_binary", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "None", ",", "\n", "success_probs_for_exogenous_features_that_are_binary", ":", "Optional", "[", "List", "[", "float", "]", "]", "=", "None", ",", "\n", ")", "->", "HierarchicalMulticlassRegressionDataset", ":", "\n", "    ", "\"\"\"\n    Generate multiclass regression data in the presence of `n_groups` groups.\n\n    We first compute expected betas (where the expectation is taken across groups).  Recall that\n    in this setting, betas have dimension (n_designed_features, n_categories).  See\n    `get_num_features_designed` for how this is computed\n\n    We then sample each group's beta given the expected betas above, and a covariance matrix that is\n    constant across groups, and set to be s2*I, for some scalar s2, and where I has dimesionality\n    (n_designed_features, n_designed_features).  Note that as s2 increases, the regression weights become\n    more dissimilar across groups.\n\n    Finally, we can then generate a bunch of group-specific multiclass regression data in the same way\n    as we do in the non-hierarchical setting (see `generate_multiclass_regression_dataset`)\n\n    Arguments:\n        n_features_exogenous:\n            This is the number of features or predictors, not including the intercept or the transition feature\n        s2_beta_expected:\n            The expected beta for the m-th covariate in the design matrix and k-th category is sampled from\n                N(0, s2_beta_expected)\n            So higher values of s2_beta_expected makes the regression weights more variable across\n            covariates and categories (and therefore increases the tendency of those covariates to \"matter\"\n            in determining the category probabilities).  Note that this effect can be partially overriden\n            if one provides `beta_0_expected` and/or `beta_transition_expected`.\n        s2_beta:\n            For any response category (k), betas for each group are sampled from\n                N(beta_expected_for_response_category_k, Sigma_k)\n            And we set Sigma_k := s2_beta * I.\n            So higher values of s2_beta makes the regression weights more variable across groups;\n            lower values of s2_beta make regression weights more similar across groups.\n        link:\n            The link function used for the multiclass logistic regression.  Note that the link function\n            determines the dimensionality of beta\n        include_intercept:\n            If True, the 0-th row of the beta matrix will correspond to the intercept, and the 0-th column\n            of the features matrix will be a column of all 1's.  If False, neither condition will be true.\n        beta_0_expected:\n            Optional.  If present, include_intercept must be True.\n            If present, it's a numpy array of size (K,),  where K is the number of categories.\n            When present, we don't simulate beta_0_expected randomly, but use the provided value instead.\n            `beta_0_expected` is the expected intercept across all the groups.\n        is_autoregressive:\n            If True,\n            Note that if True, one does not need include_intercept to be True.\n        beta_transition_expected:\n            Optional. If present, is_autoregressive must be True.\n            Allows one to overwrite the bottom KxK block of beta_expected so that we can control the\n            influence of categories on each other (e.g., we can encourage self-transitions.)  Note that if\n            we use this, we likely want to also diminish the influence of external covariates by reducing\n            the size of s2_beta_expected.\n        beta_exogenous_expected:\n            Optional.  Allows one to overwrite the (n_features_exogenous X K) block of beta_expected so\n            that we can control the influence of exogenous covariates on category probabilities.\n        indices_of_exogenous_features_that_are_binary:\n            Optional.  If present, the exogenous features with the provided indices\n            (with ZERO-INDEXING and in EXOGENOUS FEATURE COORDINATES, i.e.\n            from i=0,...,n_features_exogenous-1) are made to be binary, with success probabilities\n            given by `success_probs_for_exogenous_features_that_are_binary`\n    \"\"\"", "\n", "\n", "###", "\n", "# Generate expected (across groups) beta coefficients", "\n", "###", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "if", "link", "!=", "Link", ".", "CBC_PROBIT", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\n", "f\"Only Link.CBC_PROBIT is currently supported. For example, Link.STICK_BREAKING \"", "\n", "f\"and Link.MULTI_LOGIT use one less column for beta than the number of categories. This function needs \"", "\n", "f\"to be adjusted to handle that.  For guidance, see the data generation model for the non-hierarchical case.\"", "\n", ")", "\n", "", "if", "beta_0_expected", "is", "not", "None", "and", "include_intercept", "==", "False", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"You have provided a `beta_0_expected` but don't want to include an intercept.  WTF, man?\"", "\n", ")", "\n", "", "if", "beta_transition_expected", "is", "not", "None", "and", "is_autoregressive", "==", "False", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"You have provided a ` beta_transition_expected` but don't want to include \"", "\n", "f\"simulate data autoregressively.  WTF, man?\"", "\n", ")", "\n", "", "if", "(", "\n", "beta_exogenous_expected", "is", "not", "None", "\n", "and", "np", ".", "shape", "(", "beta_exogenous_expected", ")", "[", "0", "]", "!=", "n_features_exogenous", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"You have specified expected betas for the exogenous covariates, but the number of rows \"", "\n", "f\"does not match what you have specified in `n_features_exogenous`.\"", "\n", ")", "\n", "", "if", "include_intercept", "and", "is_autoregressive", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "f\"You have turned on both `include_intercept` and `is_autoregressive`.  Is this \"", "\n", "f\"definitely what you want?  If the latter is True, there is no longer a need for the former. \"", "\n", "f\"On the other hand, apparently Bayesians can use non-identified models, and the CBC-Probit \"", "\n", "f\"is non-identified anyways.\"", "\n", ")", "\n", "", "if", "indices_of_exogenous_features_that_are_binary", "is", "None", ":", "\n", "        ", "indices_of_exogenous_features_that_are_binary", "=", "[", "]", "\n", "", "if", "success_probs_for_exogenous_features_that_are_binary", "is", "None", ":", "\n", "        ", "success_probs_for_exogenous_features_that_are_binary", "=", "[", "]", "\n", "\n", "", "design", "=", "Design", "(", "\n", "n_features_exogenous", ",", "include_intercept", ",", "n_categories", "*", "is_autoregressive", "\n", ")", "\n", "\n", "# TODO: Allow control over the relative influence of category probabilities", "\n", "beta_expected", "=", "np", ".", "random", ".", "normal", "(", "\n", "loc", "=", "0", ",", "scale", "=", "s2_beta_expected", ",", "size", "=", "(", "design", ".", "num_features_designed", ",", "n_categories", ")", "\n", ")", "\n", "\n", "# Overwrite beta expected with desired terms.", "\n", "if", "beta_0_expected", "is", "not", "None", ":", "\n", "        ", "beta_expected", "[", "0", ",", ":", "]", "=", "beta_0_expected", "\n", "", "if", "beta_transition_expected", "is", "not", "None", ":", "\n", "        ", "beta_expected", "[", "-", "n_categories", ":", ",", "-", "n_categories", ":", "]", "=", "beta_transition_expected", "\n", "", "if", "beta_exogenous_expected", "is", "not", "None", ":", "\n", "        ", "f", ",", "l", "=", "design", ".", "index_bounds_exogenous_features", "\n", "beta_expected", "[", "f", ":", "l", ",", ":", "]", "=", "beta_exogenous_expected", "\n", "\n", "# TODO: Add option to provide beta_transition_expected, a KxK np.array, which will allow us", "\n", "# to favor self transitions.  Note that to not have this favoring outweighed by the exogenous", "\n", "# features or the intercept, we will need to check our provided values against the variance", "\n", "# from those blocks.", "\n", "\n", "###", "\n", "# Generate betas across group and categories", "\n", "###", "\n", "", "beta_cov", "=", "s2_beta", "*", "np", ".", "eye", "(", "design", ".", "num_features_designed", ")", "\n", "betas_across_groups_and_categories", "=", "np", ".", "zeros", "(", "\n", "(", "n_groups", ",", "design", ".", "num_features_designed", ",", "n_categories", ")", "\n", ")", "\n", "for", "k", "in", "range", "(", "n_categories", ")", ":", "\n", "        ", "betas_across_groups_and_categories", "[", ":", ",", ":", ",", "k", "]", "=", "np", ".", "random", ".", "multivariate_normal", "(", "\n", "mean", "=", "beta_expected", "[", ":", ",", "k", "]", ",", "cov", "=", "beta_cov", ",", "size", "=", "n_groups", "\n", ")", "\n", "\n", "###", "\n", "# Construct dataset (betas, features, labels) for each group", "\n", "###", "\n", "\n", "", "datasets", "=", "[", "None", "]", "*", "n_groups", "\n", "\n", "for", "j", "in", "range", "(", "n_groups", ")", ":", "\n", "\n", "# generate non autoregressive features", "\n", "        ", "features_exogenous", "=", "generate_features", "(", "\n", "n_samples", ",", "\n", "design", ".", "num_features_exogenous", ",", "\n", "mean", "=", "0.0", ",", "\n", "scale", "=", "1.0", ",", "\n", "bernoulli_indices", "=", "indices_of_exogenous_features_that_are_binary", ",", "\n", "bernoulli_probs", "=", "success_probs_for_exogenous_features_that_are_binary", ",", "\n", ")", "\n", "\n", "if", "include_intercept", ":", "\n", "            ", "features_non_autoregressive", "=", "(", "\n", "prepend_features_with_column_of_all_ones_for_intercept", "(", "\n", "features_exogenous", "\n", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "features_non_autoregressive", "=", "features_exogenous", "\n", "\n", "", "beta_for_group", "=", "betas_across_groups_and_categories", "[", "j", ",", ":", ",", ":", "]", "\n", "designed_features", ",", "labels", "=", "generate_designed_features_and_multiclass_labels", "(", "\n", "features_non_autoregressive", ",", "\n", "beta_for_group", ",", "\n", "link", ",", "\n", "is_autoregressive", ",", "\n", ")", "\n", "\n", "datasets", "[", "j", "]", "=", "MulticlassRegressionDataset", "(", "\n", "designed_features", ",", "labels", ",", "beta_for_group", ",", "link", ",", "seed", "\n", ")", "\n", "\n", "", "return", "HierarchicalMulticlassRegressionDataset", "(", "\n", "datasets", ",", "beta_expected", ",", "beta_cov", ",", "link", ",", "seed", ",", "is_autoregressive", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.splitter.split_multiclass_regression_dataset": [[34, 57], ["categorical_from_binary.data_generation.bayes_multiclass_reg.MulticlassRegressionDataset", "categorical_from_binary.data_generation.bayes_multiclass_reg.MulticlassRegressionDataset"], "function", ["None"], ["", "def", "split_multiclass_regression_dataset", "(", "\n", "data", ":", "MulticlassRegressionDataset", ",", "\n", "n_train_samples", ":", "int", ",", "\n", ")", "->", "Tuple", "[", "MulticlassRegressionDataset", ",", "MulticlassRegressionDataset", "]", ":", "\n", "    ", "\"\"\"\n    Split a `MulticlassRegressionDataset` into a training dataset and a test dataset\n    via a simple routine:  We take the first `n_train_samples` from each dataset\n    \"\"\"", "\n", "data_train", "=", "MulticlassRegressionDataset", "(", "\n", "data", ".", "features", "[", ":", "n_train_samples", "]", ",", "\n", "data", ".", "labels", "[", ":", "n_train_samples", "]", ",", "\n", "data", ".", "beta", ",", "\n", "data", ".", "link", ",", "\n", "data", ".", "seed", ",", "\n", ")", "\n", "data_test", "=", "MulticlassRegressionDataset", "(", "\n", "data", ".", "features", "[", "n_train_samples", ":", "]", ",", "\n", "data", ".", "labels", "[", "n_train_samples", ":", "]", ",", "\n", "data", ".", "beta", ",", "\n", "data", ".", "link", ",", "\n", "data", ".", "seed", ",", "\n", ")", "\n", "return", "data_train", ",", "data_test", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.splitter.split_hierarchical_multiclass_regression_dataset": [[59, 90], ["categorical_from_binary.data_generation.hierarchical_multiclass_reg.HierarchicalMulticlassRegressionDataset", "categorical_from_binary.data_generation.hierarchical_multiclass_reg.HierarchicalMulticlassRegressionDataset", "splitter.split_multiclass_regression_dataset"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.splitter.split_multiclass_regression_dataset"], ["", "def", "split_hierarchical_multiclass_regression_dataset", "(", "\n", "hd", ":", "HierarchicalMulticlassRegressionDataset", ",", "n_train_samples", ":", "int", "\n", ")", "->", "Tuple", "[", "\n", "HierarchicalMulticlassRegressionDataset", ",", "HierarchicalMulticlassRegressionDataset", "\n", "]", ":", "\n", "    ", "\"\"\"\n    Split a `HierarchicalMulticlassRegressionDataset` into a training dataset and a test dataset\n    via a simple routine:  We take the first `n_train_samples` from each dataset\n    \"\"\"", "\n", "datasets_split", "=", "[", "\n", "split_multiclass_regression_dataset", "(", "dataset", ",", "n_train_samples", ")", "\n", "for", "dataset", "in", "hd", ".", "datasets", "\n", "]", "\n", "\n", "hierarchical_data_train", "=", "HierarchicalMulticlassRegressionDataset", "(", "\n", "[", "dataset_split", "[", "0", "]", "for", "dataset_split", "in", "datasets_split", "]", ",", "\n", "hd", ".", "beta_expected", ",", "\n", "hd", ".", "beta_cov", ",", "\n", "hd", ".", "link", ",", "\n", "hd", ".", "seed", ",", "\n", "hd", ".", "is_autoregressive", ",", "\n", ")", "\n", "hierarchical_data_test", "=", "HierarchicalMulticlassRegressionDataset", "(", "\n", "[", "dataset_split", "[", "1", "]", "for", "dataset_split", "in", "datasets_split", "]", ",", "\n", "hd", ".", "beta_expected", ",", "\n", "hd", ".", "beta_cov", ",", "\n", "hd", ".", "link", ",", "\n", "hd", ".", "seed", ",", "\n", "hd", ".", "is_autoregressive", ",", "\n", ")", "\n", "return", "hierarchical_data_train", ",", "hierarchical_data_test", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.generate_logistic_regression_dataset": [[61, 87], ["bayes_binary_reg.generate_binary_regression_dataset"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.generate_binary_regression_dataset"], ["", "def", "generate_logistic_regression_dataset", "(", "\n", "n_samples", ":", "int", ",", "\n", "n_features", ":", "int", ",", "\n", "n_sparse_features", ":", "int", "=", "0", ",", "\n", "n_bounded_from_zero_features", ":", "int", "=", "0", ",", "\n", "lower_bound_for_bounded_from_zero_features", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "mean", ":", "float", "=", "0.0", ",", "\n", "scale_for_linear_predictor", ":", "float", "=", "1.0", ",", "\n", "linear_predictor_scale_allocator", ":", "LinearPredictorScaleAllocator", "=", "LinearPredictorScaleAllocator", ".", "MAKE_UNIFORM_FEATURES", ",", "\n", "mean_for_intercept", ":", "float", "=", "0.0", ",", "\n", "scale_for_intercept", ":", "float", "=", "0.25", ",", "\n", "seed", ":", "int", "=", "1", ",", "\n", ")", "->", "BinaryRegressionDataset", ":", "\n", "    ", "return", "generate_binary_regression_dataset", "(", "\n", "n_samples", ",", "\n", "n_features", ",", "\n", "Link", ".", "LOGISTIC", ",", "\n", "n_sparse_features", ",", "\n", "n_bounded_from_zero_features", ",", "\n", "lower_bound_for_bounded_from_zero_features", ",", "\n", "mean", ",", "\n", "scale_for_linear_predictor", ",", "\n", "linear_predictor_scale_allocator", ",", "\n", "mean_for_intercept", ",", "\n", "scale_for_intercept", ",", "\n", "seed", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.generate_probit_regression_dataset": [[90, 116], ["bayes_binary_reg.generate_binary_regression_dataset"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.generate_binary_regression_dataset"], ["", "def", "generate_probit_regression_dataset", "(", "\n", "n_samples", ":", "int", ",", "\n", "n_features", ":", "int", ",", "\n", "n_sparse_features", ":", "int", "=", "0", ",", "\n", "n_bounded_from_zero_features", ":", "int", "=", "0", ",", "\n", "lower_bound_for_bounded_from_zero_features", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "mean", ":", "float", "=", "0.0", ",", "\n", "scale_for_linear_predictor", ":", "float", "=", "1.0", ",", "\n", "linear_predictor_scale_allocator", ":", "LinearPredictorScaleAllocator", "=", "LinearPredictorScaleAllocator", ".", "MAKE_UNIFORM_FEATURES", ",", "\n", "mean_for_intercept", ":", "float", "=", "0.0", ",", "\n", "scale_for_intercept", ":", "float", "=", "0.25", ",", "\n", "seed", ":", "int", "=", "1", ",", "\n", ")", "->", "BinaryRegressionDataset", ":", "\n", "    ", "return", "generate_binary_regression_dataset", "(", "\n", "n_samples", ",", "\n", "n_features", ",", "\n", "Link", ".", "PROBIT", ",", "\n", "n_sparse_features", ",", "\n", "n_bounded_from_zero_features", ",", "\n", "lower_bound_for_bounded_from_zero_features", ",", "\n", "mean", ",", "\n", "scale_for_linear_predictor", ",", "\n", "linear_predictor_scale_allocator", ",", "\n", "mean_for_intercept", ",", "\n", "scale_for_intercept", ",", "\n", "seed", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.generate_binary_regression_dataset": [[119, 158], ["numpy.random.normal", "bayes_binary_reg.generate_regression_coefficients_for_features", "numpy.insert", "bayes_binary_reg.generate_features_via_independent_normals", "bayes_binary_reg.generate_labels_via_features_and_binary_regression_weights", "bayes_binary_reg.BinaryRegressionDataset"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.generate_regression_coefficients_for_features", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.generate_features_via_independent_normals", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.generate_labels_via_features_and_binary_regression_weights"], ["", "def", "generate_binary_regression_dataset", "(", "\n", "n_samples", ":", "int", ",", "\n", "n_features", ":", "int", ",", "\n", "link", ":", "Link", ",", "\n", "n_sparse_features", ":", "int", "=", "0", ",", "\n", "n_bounded_from_zero_features", ":", "int", "=", "0", ",", "\n", "lower_bound_for_bounded_from_zero_features", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "mean", ":", "float", "=", "0.0", ",", "\n", "scale_for_linear_predictor", ":", "float", "=", "1.0", ",", "\n", "linear_predictor_scale_allocator", ":", "LinearPredictorScaleAllocator", "=", "LinearPredictorScaleAllocator", ".", "MAKE_UNIFORM_FEATURES", ",", "\n", "mean_for_intercept", ":", "float", "=", "0.0", ",", "\n", "scale_for_intercept", ":", "float", "=", "0.25", ",", "\n", "seed", ":", "int", "=", "1", ",", "\n", ")", "->", "BinaryRegressionDataset", ":", "\n", "\n", "# TODO: extend purview of seed to reach beta_0 as well", "\n", "    ", "beta_0", "=", "np", ".", "random", ".", "normal", "(", "loc", "=", "mean_for_intercept", ",", "scale", "=", "scale_for_intercept", ")", "\n", "beta_for_features", "=", "generate_regression_coefficients_for_features", "(", "\n", "n_features", ",", "\n", "n_sparse_features", ",", "\n", "n_bounded_from_zero_features", ",", "\n", "lower_bound_for_bounded_from_zero_features", ",", "\n", "mean", ",", "\n", "scale_for_linear_predictor", ",", "\n", "linear_predictor_scale_allocator", ",", "\n", "seed", ",", "\n", "positive_and_negative", "=", "True", ",", "\n", ")", "\n", "beta", "=", "np", ".", "insert", "(", "beta_for_features", ",", "0", ",", "beta_0", ")", "\n", "\n", "features", "=", "generate_features_via_independent_normals", "(", "\n", "n_samples", ",", "n_features", ",", "mean", "=", "0.0", ",", "scale", "=", "1.0", "\n", ")", "\n", "labels", "=", "generate_labels_via_features_and_binary_regression_weights", "(", "\n", "features", ",", "\n", "beta", ",", "\n", "link", ",", "\n", ")", "\n", "return", "BinaryRegressionDataset", "(", "features", ",", "labels", ",", "beta", ",", "link", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.generate_regression_coefficients_for_features": [[160, 230], ["numpy.random.seed", "numpy.random.normal().tolist", "numpy.array", "numpy.array", "ValueError", "numpy.ones", "range", "numpy.sqrt", "range", "ValueError", "numpy.random.normal", "scipy.stats.truncnorm().rvs", "categorical_from_binary.data_generation.util.construct_random_signs_as_integers", "numpy.sqrt", "range", "betas_bounded_from_zero.tolist", "scipy.stats.truncnorm"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.util.construct_random_signs_as_integers"], ["", "def", "generate_regression_coefficients_for_features", "(", "\n", "n_features", ":", "int", ",", "\n", "n_sparse_features", ":", "int", "=", "0", ",", "\n", "n_bounded_from_zero_features", ":", "int", "=", "0", ",", "\n", "lower_bound_for_bounded_from_zero_features", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "mean", ":", "float", "=", "0.0", ",", "\n", "scale_for_linear_predictor", ":", "float", "=", "1.0", ",", "\n", "linear_predictor_scale_allocator", ":", "LinearPredictorScaleAllocator", "=", "LinearPredictorScaleAllocator", ".", "MAKE_UNIFORM_FEATURES", ",", "\n", "seed", ":", "int", "=", "1", ",", "\n", "positive_and_negative", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    The features are ordered as:\n        (all other features, bounded from zero features, sparse features)\n\n    Arguments:\n        linear_predictor_scale_allocator: Allocates how scale for linear predictor is allocated across the m covariats\n    \"\"\"", "\n", "if", "n_sparse_features", "+", "n_bounded_from_zero_features", ">", "n_features", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"The number of sparse features plus the number of \"", "\n", "\"bounded from zero features cannot exceed the total number of features.\"", "\n", ")", "\n", "", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "n_regular_features", "=", "n_features", "-", "n_sparse_features", "-", "n_bounded_from_zero_features", "\n", "scales_for_regular_features", "=", "(", "\n", "np", ".", "ones", "(", "n_regular_features", ")", "*", "scale_for_linear_predictor", "\n", ")", "\n", "if", "(", "\n", "linear_predictor_scale_allocator", "\n", "==", "LinearPredictorScaleAllocator", ".", "MAKE_PREFERRED_FEATURES", "\n", ")", ":", "\n", "        ", "for", "r", "in", "range", "(", "n_regular_features", ")", ":", "\n", "            ", "scales_for_regular_features", "[", "r", "]", "*=", "np", ".", "sqrt", "(", "\n", "2", "*", "(", "r", "+", "1", ")", "/", "(", "(", "n_regular_features", ")", "*", "(", "n_regular_features", "+", "1", ")", ")", "\n", ")", "\n", "", "", "elif", "(", "\n", "linear_predictor_scale_allocator", "\n", "==", "LinearPredictorScaleAllocator", ".", "MAKE_UNIFORM_FEATURES", "\n", ")", ":", "\n", "        ", "for", "r", "in", "range", "(", "n_regular_features", ")", ":", "\n", "            ", "scales_for_regular_features", "[", "r", "]", "*=", "np", ".", "sqrt", "(", "1", "/", "(", "n_regular_features", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"I am not sure how you want me to control the beta feature scale\"", "\n", ")", "\n", "", "betas_regular", "=", "np", ".", "random", ".", "normal", "(", "\n", "loc", "=", "mean", ",", "scale", "=", "scales_for_regular_features", ",", "size", "=", "n_regular_features", "\n", ")", ".", "tolist", "(", ")", "\n", "betas_bounded_from_zero_all_positive", "=", "np", ".", "array", "(", "\n", "[", "\n", "scipy", ".", "stats", ".", "truncnorm", "(", "\n", "a", "=", "lower_bound_for_bounded_from_zero_features", ",", "\n", "b", "=", "np", ".", "inf", ",", "\n", "loc", "=", "mean", ",", "\n", "scale", "=", "scale_for_linear_predictor", ",", "\n", ")", ".", "rvs", "(", ")", "\n", "for", "i", "in", "range", "(", "n_bounded_from_zero_features", ")", "\n", "]", "\n", ")", "\n", "if", "positive_and_negative", ":", "\n", "        ", "betas_bounded_from_zero", "=", "(", "\n", "betas_bounded_from_zero_all_positive", "\n", "*", "construct_random_signs_as_integers", "(", "n_bounded_from_zero_features", ")", "\n", ")", "\n", "", "else", ":", "\n", "        ", "betas_bounded_from_zero", "=", "betas_bounded_from_zero_all_positive", "\n", "", "betas_sparse", "=", "[", "0.0", "]", "*", "n_sparse_features", "\n", "beta", "=", "np", ".", "array", "(", "betas_regular", "+", "betas_bounded_from_zero", ".", "tolist", "(", ")", "+", "betas_sparse", ")", "\n", "return", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.generate_features_via_independent_normals": [[232, 247], ["numpy.zeros", "range", "numpy.random.normal"], "function", ["None"], ["", "def", "generate_features_via_independent_normals", "(", "\n", "n_samples", ":", "int", ",", "\n", "n_features", ":", "int", ",", "\n", "mean", ":", "float", "=", "0.0", ",", "\n", "scale", ":", "float", "=", "1.0", ",", "\n", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Returns:\n        features, an np.array of shape (n_samples, n_features)\n    \"\"\"", "\n", "features", "=", "np", ".", "zeros", "(", "(", "n_samples", ",", "n_features", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "for", "i", "in", "range", "(", "n_samples", ")", ":", "\n", "        ", "features_for_sample", "=", "np", ".", "random", ".", "normal", "(", "loc", "=", "mean", ",", "scale", "=", "scale", ",", "size", "=", "n_features", ")", "\n", "features", "[", "i", ",", ":", "]", "=", "features_for_sample", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.generate_features": [[249, 281], ["numpy.zeros", "range", "ValueError", "numpy.random.normal", "zip", "max", "numpy.random.binomial"], "function", ["None"], ["", "def", "generate_features", "(", "\n", "n_samples", ":", "int", ",", "\n", "n_features", ":", "int", ",", "\n", "mean", ":", "float", "=", "0.0", ",", "\n", "scale", ":", "float", "=", "1.0", ",", "\n", "bernoulli_indices", ":", "List", "[", "int", "]", "=", "None", ",", "\n", "bernoulli_probs", ":", "List", "[", "float", "]", "=", "None", ",", "\n", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Generates features from IID Gaussians, unless bernoulli_indices are specified.:\n\n    Returns:\n        features, an np.array of shape (n_samples, n_features)\n    \"\"\"", "\n", "if", "bernoulli_indices", "and", "max", "(", "bernoulli_indices", ")", ">", "n_features", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"You've provided indices for bernoulli features that exceeds \"", "\n", "f\" the total number of specified features.\"", "\n", ")", "\n", "\n", "", "features", "=", "np", ".", "zeros", "(", "(", "n_samples", ",", "n_features", ")", ",", "dtype", "=", "np", ".", "float", ")", "\n", "\n", "# first pretend like all features are normal", "\n", "for", "i", "in", "range", "(", "n_samples", ")", ":", "\n", "        ", "features_for_sample", "=", "np", ".", "random", ".", "normal", "(", "loc", "=", "mean", ",", "scale", "=", "scale", ",", "size", "=", "n_features", ")", "\n", "features", "[", "i", ",", ":", "]", "=", "features_for_sample", "\n", "\n", "# now overwrite the appropriate feature indices with binary variables", "\n", "", "if", "bernoulli_indices", ":", "\n", "        ", "for", "j", ",", "prob", "in", "zip", "(", "bernoulli_indices", ",", "bernoulli_probs", ")", ":", "\n", "            ", "features", "[", ":", ",", "j", "]", "=", "np", ".", "random", ".", "binomial", "(", "1", ",", "prob", ",", "size", "=", "n_samples", ")", "\n", "", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.generate_labels_via_features_and_binary_regression_weights": [[283, 310], ["numpy.zeros", "range", "numpy.shape", "numpy.random.binomial", "numpy.dot", "categorical_from_binary.kl.sigmoid", "scipy.stats.norm.cdf"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.sigmoid"], ["", "def", "generate_labels_via_features_and_binary_regression_weights", "(", "\n", "features", ":", "np", ".", "ndarray", ",", "\n", "beta", ":", "np", ".", "ndarray", ",", "\n", "link", ":", "Link", ",", "\n", ")", "->", "np", ".", "ndarray", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        features: an np.array of shape (n_samples, n_features)\n        beta: regression weights with shape (n_features+1, )\n\n    Returns:\n        labels:  an np.array of shape (n_samples, ) and dtype int.\n    \"\"\"", "\n", "# TODO: Update this, and callers, to utilize the more streamlined functions", "\n", "# `construct_binary_logistic_probs` and `construct_binary_probit_probs`", "\n", "n_samples", "=", "np", ".", "shape", "(", "features", ")", "[", "0", "]", "\n", "labels", "=", "np", ".", "zeros", "(", "(", "n_samples", ",", ")", ",", "dtype", "=", "np", ".", "int", ")", "\n", "for", "i", "in", "range", "(", "n_samples", ")", ":", "\n", "        ", "features_for_sample", "=", "features", "[", "i", ",", ":", "]", "\n", "linear_predictor", "=", "beta", "[", "0", "]", "+", "np", ".", "dot", "(", "beta", "[", "1", ":", "]", ",", "features_for_sample", ")", "\n", "if", "link", "==", "Link", ".", "LOGISTIC", ":", "\n", "            ", "prob", "=", "sigmoid", "(", "linear_predictor", ")", "\n", "", "elif", "link", "==", "Link", ".", "PROBIT", ":", "\n", "            ", "prob", "=", "norm", ".", "cdf", "(", "linear_predictor", ")", "\n", "", "label", "=", "np", ".", "random", ".", "binomial", "(", "n", "=", "1", ",", "p", "=", "prob", ")", "\n", "labels", "[", "i", "]", "=", "label", "\n", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.construct_binary_logistic_probs": [[312, 317], ["categorical_from_binary.kl.sigmoid"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.sigmoid"], ["", "def", "construct_binary_logistic_probs", "(", "\n", "beta", ":", "NumpyArray1D", ",", "covariates", ":", "NumpyArray2D", "\n", ")", "->", "NumpyArray1D", ":", "\n", "    ", "linear_predictors", "=", "covariates", "@", "beta", "\n", "return", "sigmoid", "(", "linear_predictors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.construct_binary_probit_probs": [[319, 324], ["scipy.stats.norm.cdf"], "function", ["None"], ["", "def", "construct_binary_probit_probs", "(", "\n", "beta", ":", "NumpyArray1D", ",", "covariates", ":", "NumpyArray2D", "\n", ")", "->", "NumpyArray1D", ":", "\n", "    ", "linear_predictors", "=", "covariates", "@", "beta", "\n", "return", "norm", ".", "cdf", "(", "linear_predictors", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.util.prepend_features_with_column_of_all_ones_for_intercept": [[10, 32], ["scipy.sparse.issparse", "numpy.ones", "numpy.shape", "scipy.sparse.hstack().tocsc", "numpy.hstack", "scipy.sparse.hstack"], "function", ["None"], ["def", "one_hot_encoded_array_from_categorical_indices", "(", "\n", "categorical_indices", ":", "NumpyArray1D", ",", "\n", "number_of_possible_categories", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "sparse_representation", ":", "bool", "=", "False", ",", "\n", ")", "->", "np", ".", "array", ":", "\n", "    ", "\"\"\"\n    Takes a one-dim numpy array of integers and expands it to a two-dim numpy array\n    that is one-hot encoded\n    \"\"\"", "\n", "\n", "# TODO: This function currently assumes that we should assign a column for every", "\n", "# integer within 0 and the maximal categorical index.   This should be related", "\n", "\n", "if", "number_of_possible_categories", "is", "None", ":", "\n", "# If `number_of_possible_categories` is not provided, we will infer it to be the maximum value", "\n", "# plus one, due to zero-indexing, but this potentially dangerous to do under the hood.  Is 0 a", "\n", "# legitimate value? If the max value is far higher than the number of possible values, do we really", "\n", "# want to represent everything between zero and the max?", "\n", "        ", "number_of_possible_categories", "=", "max", "(", "categorical_indices", ")", "+", "1", "\n", "warnings", ".", "warn", "(", "\n", "f\"Inferring the number of possible values to be {number_of_possible_categories}. \"", "\n", "f\"Does that seem corect?\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.util.prod_of_columns_except": [[34, 36], ["numpy.prod", "numpy.delete"], "function", ["None"], ["", "N", "=", "len", "(", "categorical_indices", ")", "\n", "K", "=", "number_of_possible_categories", "\n", "if", "sparse_representation", ":", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.util.construct_random_signs_as_integers": [[38, 40], ["numpy.random.randint"], "function", ["None"], ["", "else", ":", "\n", "        ", "one_hot_matrix", "=", "np", ".", "zeros", "(", "(", "N", ",", "K", ")", ",", "dtype", "=", "int", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.hierarchical_logreg.generate_hierarchical_logistic_regression_dataset": [[21, 55], ["numpy.random.seed", "numpy.random.normal", "numpy.random.normal", "numpy.concatenate", "range", "hierarchical_logreg.HierarchicalLogisticRegressionDataset", "numpy.random.normal", "numpy.random.normal", "numpy.concatenate", "categorical_from_binary.data_generation.bayes_binary_reg.generate_features_via_independent_normals", "categorical_from_binary.data_generation.bayes_binary_reg.generate_labels_via_features_and_binary_regression_weights", "categorical_from_binary.data_generation.bayes_binary_reg.BinaryRegressionDataset", "log_reg_datasets.append"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.generate_features_via_independent_normals", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.generate_labels_via_features_and_binary_regression_weights"], ["", "def", "generate_hierarchical_logistic_regression_dataset", "(", "\n", "n_samples", ":", "int", ",", "n_features", ":", "int", ",", "n_groups", ":", "int", ",", "seed", ":", "int", "=", "1", "\n", ")", "->", "HierarchicalLogisticRegressionDataset", ":", "\n", "\n", "# generate global regression coefficients", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "beta_0_global", "=", "np", ".", "random", ".", "normal", "(", "loc", "=", "0", ",", "scale", "=", "0.25", ")", "\n", "beta_for_features_global", "=", "np", ".", "random", ".", "normal", "(", "loc", "=", "0", ",", "scale", "=", "1", ",", "size", "=", "n_features", ")", "\n", "beta_global", "=", "np", ".", "concatenate", "(", "(", "[", "beta_0_global", "]", ",", "beta_for_features_global", ")", ")", "\n", "\n", "log_reg_datasets", "=", "[", "]", "\n", "\n", "for", "group", "in", "range", "(", "n_groups", ")", ":", "\n", "# generate perturbations for each group", "\n", "# TODO: Have the betas be nonindependent.", "\n", "        ", "beta_0_noise", "=", "np", ".", "random", ".", "normal", "(", "loc", "=", "0", ",", "scale", "=", "0.1", ")", "\n", "beta_for_features_noise", "=", "np", ".", "random", ".", "normal", "(", "loc", "=", "0", ",", "scale", "=", "0.33", ",", "size", "=", "n_features", ")", "\n", "beta_noise", "=", "np", ".", "concatenate", "(", "(", "[", "beta_0_noise", "]", ",", "beta_for_features_noise", ")", ")", "\n", "\n", "beta_for_this_group", "=", "beta_global", "+", "beta_noise", "\n", "\n", "features", "=", "generate_features_via_independent_normals", "(", "\n", "n_samples", ",", "n_features", ",", "mean", "=", "0.0", ",", "scale", "=", "1.0", "\n", ")", "\n", "labels", "=", "generate_labels_via_features_and_binary_regression_weights", "(", "\n", "features", ",", "beta_for_this_group", ",", "Link", ".", "LOGISTIC", "\n", ")", "\n", "\n", "log_reg_dataset_for_this_group", "=", "BinaryRegressionDataset", "(", "\n", "features", ",", "labels", ",", "beta_for_this_group", ",", "Link", ".", "LOGISTIC", "\n", ")", "\n", "log_reg_datasets", ".", "append", "(", "log_reg_dataset_for_this_group", ")", "\n", "\n", "", "return", "HierarchicalLogisticRegressionDataset", "(", "log_reg_datasets", ",", "beta_global", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.design.Design.__init__": [[22, 31], ["int", "int", "int"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "num_exogenous", ":", "int", ",", "\n", "num_intercept", ":", "Union", "[", "bool", ",", "int", "]", "=", "1", ",", "\n", "num_autoregressive", ":", "Union", "[", "bool", ",", "int", "]", "=", "0", ",", "\n", ")", ":", "\n", "        ", "self", ".", "num_features_intercept", "=", "int", "(", "num_intercept", ")", "\n", "self", ".", "num_features_exogenous", "=", "int", "(", "num_exogenous", ")", "\n", "self", ".", "num_features_autoregressive", "=", "int", "(", "num_autoregressive", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.design.Design.num_features_designed": [[34, 40], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_features_designed", "(", "self", ")", ":", "\n", "        ", "return", "(", "\n", "self", ".", "num_features_intercept", "\n", "+", "self", ".", "num_features_exogenous", "\n", "+", "self", ".", "num_features_autoregressive", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.design.Design.num_features_non_intercept": [[42, 45], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_features_non_intercept", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_features_exogenous", "+", "self", ".", "num_features_autoregressive", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.design.Design.num_features_non_autoregressive": [[46, 49], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_features_non_autoregressive", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_features_intercept", "+", "self", ".", "num_features_exogenous", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.design.Design.index_bounds_exogenous_features": [[50, 53], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "index_bounds_exogenous_features", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "num_features_intercept", ",", "self", ".", "num_features_non_autoregressive", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.get_num_beta_columns": [[111, 134], ["None"], "function", ["None"], ["def", "get_num_beta_columns", "(", "link", ":", "Link", ",", "n_categories", ":", "int", ")", "->", "int", ":", "\n", "    ", "\"\"\"\n    The beta matrix has shape (n_features+1, num_beta_columns),\n    The num_beta_columns depends on the number of categories in a way determined by the link function.\n    The value differs due to identifiability considerations.\n\n    This function determines the number of beta columns based on the link function and\n    the number of response categories.\n    \"\"\"", "\n", "if", "link", "==", "Link", ".", "MULTI_LOGIT", "or", "link", "==", "Link", ".", "STICK_BREAKING", ":", "\n", "        ", "num_beta_columns", "=", "n_categories", "-", "1", "\n", "", "elif", "(", "\n", "link", "==", "Link", ".", "CBC_PROBIT", "\n", "or", "link", "==", "Link", ".", "CBM_PROBIT", "\n", "or", "link", "==", "Link", ".", "MULTI_PROBIT", "\n", "or", "link", "==", "Link", ".", "CBC_LOGIT", "\n", "or", "link", "==", "Link", ".", "CBM_LOGIT", "\n", "or", "link", "==", "Link", ".", "SOFTMAX", "\n", ")", ":", "\n", "        ", "num_beta_columns", "=", "n_categories", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "return", "num_beta_columns", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_multiclass_regression_dataset": [[172, 237], ["bayes_multiclass_reg.ControlCategoryPredictability", "bayes_multiclass_reg.generate_regression_coefficients", "categorical_from_binary.data_generation.bayes_binary_reg.generate_features_via_independent_normals", "bayes_multiclass_reg.generate_multiclass_labels_for_nonautoregressive_case", "bayes_multiclass_reg.MulticlassRegressionDataset", "categorical_from_binary.data_generation.util.prepend_features_with_column_of_all_ones_for_intercept"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_regression_coefficients", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.generate_features_via_independent_normals", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_multiclass_labels_for_nonautoregressive_case", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.util.prepend_features_with_column_of_all_ones_for_intercept"], ["", "def", "generate_multiclass_regression_dataset", "(", "\n", "n_samples", ":", "int", ",", "\n", "n_features", ":", "int", ",", "\n", "n_categories", ":", "int", ",", "\n", "beta_0", ":", "Optional", "[", "NumpyArray1D", "]", "=", "None", ",", "\n", "link", ":", "Link", "=", "Link", ".", "MULTI_LOGIT", ",", "\n", "n_sparse_features", ":", "int", "=", "0", ",", "\n", "n_categories_where_all_beta_coefficients_are_sparse", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "n_bounded_from_zero_features", ":", "int", "=", "0", ",", "\n", "lower_bound_for_bounded_from_zero_features", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "beta_category_strategy", ":", "Optional", "[", "\n", "BetaCategoryStrategy", "\n", "]", "=", "ControlCategoryPredictability", "(", ")", ",", "\n", "mean_for_intercept", ":", "float", "=", "0.0", ",", "\n", "scale_for_intercept", ":", "float", "=", "0.25", ",", "\n", "seed", ":", "int", "=", "None", ",", "\n", "include_intercept", ":", "bool", "=", "True", ",", "\n", ")", "->", "MulticlassRegressionDataset", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        n_features:\n            This is the number of features or predictors, not including the intercept.\n        beta_0:\n            Optional.  If present, we don't simulate beta_0 randomly, but use the provided value instead.\n        link:\n            The link function used for the multiclass logistic regression.  Note that the link function\n            determines the dimensionality of beta\n        include_intercept:\n            If True, the 0-th row of the beta matrix will correspond to the intercept, and the 0-th column\n            of the features matrix will be a column of all 1's.  If False, neither condition will be true.\n    \"\"\"", "\n", "beta", "=", "generate_regression_coefficients", "(", "\n", "n_features", ",", "\n", "n_categories", ",", "\n", "link", ",", "\n", "beta_0", ",", "\n", "n_sparse_features", ",", "\n", "n_categories_where_all_beta_coefficients_are_sparse", ",", "\n", "n_bounded_from_zero_features", ",", "\n", "lower_bound_for_bounded_from_zero_features", ",", "\n", "beta_category_strategy", ",", "\n", "mean_for_intercept", ",", "\n", "scale_for_intercept", ",", "\n", "seed", ",", "\n", "include_intercept", ",", "\n", ")", "\n", "\n", "# generate features and labels", "\n", "features_without_ones_column", "=", "generate_features_via_independent_normals", "(", "\n", "n_samples", ",", "n_features", ",", "mean", "=", "0.0", ",", "scale", "=", "1.0", "\n", ")", "\n", "\n", "if", "include_intercept", ":", "\n", "        ", "features", "=", "prepend_features_with_column_of_all_ones_for_intercept", "(", "\n", "features_without_ones_column", "\n", ")", "\n", "", "else", ":", "\n", "        ", "features", "=", "features_without_ones_column", "\n", "\n", "", "labels", "=", "generate_multiclass_labels_for_nonautoregressive_case", "(", "\n", "features", ",", "\n", "beta", ",", "\n", "link", ",", "\n", ")", "\n", "return", "MulticlassRegressionDataset", "(", "features", ",", "labels", ",", "beta", ",", "link", ",", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.make_stick_breaking_multinomial_regression_intercepts_such_that_category_probabilities_are_symmetric": [[239, 259], ["numpy.array", "numpy.log", "range"], "function", ["None"], ["", "def", "make_stick_breaking_multinomial_regression_intercepts_such_that_category_probabilities_are_symmetric", "(", "\n", "n_categories", ":", "int", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    When our multiclass logistic regression uses the stick-breaking link instead of the\n    canonical multiclass-logit (aka softmax) link, we can no longer make category probablilities\n    symmetric (in the no-feature case) by setting beta_0's equal to 0.\n\n    Here we provide the beta_0's to make the category probabilities symmetric in the no-feature case.\n\n    For the full-feature case, if\n        * E[beta_k^0] = b_k, where b_k is what this function returns,\n        * E[beta_k^m] = 0 for categories k=1,...,K-1 and covariates m=1,..,M-1\n    then\n        * E[nu_{ik}] = b_k for all observations i=1,..,N.\n\n    But note that due to the sigmoid nonlinearity I don't think we have symmetric category probabilities anymore.\n    \"\"\"", "\n", "K", "=", "n_categories", "\n", "return", "np", ".", "array", "(", "[", "-", "np", ".", "log", "(", "K", "-", "k", ")", "for", "k", "in", "range", "(", "1", ",", "K", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_intercepts": [[261, 346], ["numpy.zeros", "range", "isinstance", "numpy.random.normal", "numpy.zeros", "numpy.ones", "range", "isinstance", "warnings.warn", "bayes_multiclass_reg.make_stick_breaking_multinomial_regression_intercepts_such_that_category_probabilities_are_symmetric", "numpy.ones", "ValueError", "numpy.sqrt", "isinstance", "ValueError"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.make_stick_breaking_multinomial_regression_intercepts_such_that_category_probabilities_are_symmetric"], ["", "def", "generate_intercepts", "(", "\n", "link", ":", "Link", ",", "\n", "n_categories", ":", "int", ",", "\n", "num_beta_columns", ":", "int", ",", "\n", "n_columns_with_nonzero_beta_coeffs", ":", "int", ",", "\n", "mean_for_intercept", ":", "float", ",", "\n", "scale_for_intercept", ":", "float", ",", "\n", "beta_category_strategy", ":", "BetaCategoryStrategy", ",", "\n", ")", "->", "NumpyArray1D", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        num_beta_columns: The number of columns for the beta matrix (covariates x columns).\n            The number of columns is affected by:\n                * link function -- e.g. multi-logit has K-1 columns whereas do-probit has K columns,\n                    where K is the number of categories.\n         n_columns_with_nonzero_beta_coeffs: This accounts for\n            * user-desired sparsity - callers can force a certain number of categories to have 0 values\n                for all regression coefficients (including intercepts)\n    \"\"\"", "\n", "# regardless of link, we want the prior expectation of beta_0 to assume symmetry across categories", "\n", "if", "(", "\n", "link", "==", "Link", ".", "MULTI_LOGIT", "\n", "or", "link", "==", "Link", ".", "CBC_PROBIT", "\n", "or", "link", "==", "Link", ".", "CBM_PROBIT", "\n", "or", "link", "==", "Link", ".", "MULTI_PROBIT", "\n", "or", "link", "==", "Link", ".", "CBC_LOGIT", "\n", "or", "link", "==", "Link", ".", "CBM_LOGIT", "\n", "or", "link", "==", "Link", ".", "SOFTMAX", "\n", ")", ":", "\n", "# TODO: Make this not hardcoded....Probably should create a NamedTuple where one specifies", "\n", "# The link function and the prior mean nad variance on the beta's before sampling.", "\n", "        ", "beta_oh_means", "=", "np", ".", "zeros", "(", "num_beta_columns", ")", "+", "mean_for_intercept", "\n", "beta_oh_sds", "=", "np", ".", "ones", "(", "num_beta_columns", ")", "*", "scale_for_intercept", "\n", "if", "isinstance", "(", "beta_category_strategy", ",", "MakePreferredCategories", ")", ":", "\n", "# \"Effectively\" samples matrix entry beta_{mk} to have variance sqrt(1/(k*M)), where m is indexes", "\n", "# the covariate and k indexes the cateogry.", "\n", "\n", "# This strategy makes var(eta_k) = 1/k, so that we can try to make some categories (the larger ones)", "\n", "# preferred.", "\n", "#", "\n", "# To implement, we notice that since the entires of X and entries of beta are all independent with mean", "\n", "# zero, then for each category Var(eta) = Var(x'beta) can be reduced to sum_m var(x_m) var(beta_m).", "\n", "#", "\n", "# The qualifier \"effectively\" is used because we only range through k's with non-zero coefficients; some", "\n", "# may be excluded via `n_categories_where_all_beta_coefficients_are_sparse`.", "\n", "            ", "for", "col", "in", "range", "(", "n_columns_with_nonzero_beta_coeffs", ")", ":", "\n", "                ", "multiplier_on_scale_for_beta_column", "=", "np", ".", "sqrt", "(", "\n", "(", "col", "+", "1", ")", "/", "(", "n_columns_with_nonzero_beta_coeffs", ")", "\n", ")", "\n", "beta_oh_sds", "[", "col", "]", "*=", "multiplier_on_scale_for_beta_column", "\n", "", "", "elif", "isinstance", "(", "beta_category_strategy", ",", "MakeUniformCategories", ")", ":", "\n", "            ", "pass", "\n", "", "elif", "isinstance", "(", "beta_category_strategy", ",", "ControlCategoryPredictability", ")", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"I am not sure how to adjust the intercept term by column\"", ")", "\n", "\n", "", "", "elif", "link", "==", "Link", ".", "STICK_BREAKING", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "f\"Ignoring specifed mean for intercept and scale for intercept, because I am calling a function \"", "\n", "f\" that is attempting, albiet poorly, to make category probabilities symmetric.  Also overriding \"", "\n", "f\" the information about desired sparsity contained in `n_columns_with_nonzero_beta_coeffs` \"", "\n", ")", "\n", "beta_oh_means", "=", "make_stick_breaking_multinomial_regression_intercepts_such_that_category_probabilities_are_symmetric", "(", "\n", "n_categories", ",", "\n", ")", "\n", "# to do: how to determine good variance for this?", "\n", "beta_oh_sds", "=", "np", ".", "ones", "(", "n_categories", "-", "1", ")", "\n", "\n", "## Note: I tried using Linderman's compute_psi_cmoments function, but this didn't work", "\n", "# as expected...even in the intercepts-only case, it does not produce uniform", "\n", "# category probabilities.  Possibly, there is user error", "\n", "#", "\n", "# from pypolyagamma.utils import compute_psi_cmoments", "\n", "# beta_oh_means, beta_oh_vars = compute_psi_cmoments(np.ones(n_categories))", "\n", "# beta_oh_sds = np.sqrt(beta_oh_vars)", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Link is {link}, but I don't know what that is\"", ")", "\n", "\n", "", "beta_0", "=", "np", ".", "zeros", "(", "\n", "num_beta_columns", ",", "\n", ")", "\n", "for", "k", "in", "range", "(", "n_columns_with_nonzero_beta_coeffs", ")", ":", "\n", "        ", "beta_0", "[", "k", "]", "=", "np", ".", "random", ".", "normal", "(", "loc", "=", "beta_oh_means", "[", "k", "]", ",", "scale", "=", "beta_oh_sds", "[", "k", "]", ",", "size", "=", "1", ")", "\n", "", "return", "beta_0", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.get_scale_for_beta_column": [[348, 375], ["isinstance", "isinstance", "numpy.sqrt", "isinstance", "ValueError"], "function", ["None"], ["", "def", "get_scale_for_beta_column", "(", "\n", "beta_category_strategy", ":", "BetaCategoryStrategy", ",", "\n", "n_columns_with_nonzero_beta_coeffs", ":", "int", ",", "\n", "column_index", ":", "int", ",", "\n", ")", "->", "float", ":", "\n", "    ", "if", "isinstance", "(", "beta_category_strategy", ",", "MakeUniformCategories", ")", ":", "\n", "        ", "scale_for_beta_column", "=", "beta_category_strategy", ".", "scale_for_linear_predictor", "\n", "", "elif", "isinstance", "(", "beta_category_strategy", ",", "MakePreferredCategories", ")", ":", "\n", "# This strategy makes var(eta_k) = 1/k * variance_for_linear_predictor,", "\n", "# so that we can try to make some categories (the larger ones) preferred.", "\n", "#", "\n", "# The qualifier \"effectively\" is used because we only range through k's with non-zero coefficients; some", "\n", "# may be excluded via `n_categories_where_all_beta_coefficients_are_sparse`.", "\n", "        ", "multiplier_on_scale_for_beta_column", "=", "np", ".", "sqrt", "(", "\n", "(", "column_index", "+", "1", ")", "/", "(", "n_columns_with_nonzero_beta_coeffs", ")", "\n", ")", "\n", "scale_for_beta_column", "=", "(", "\n", "beta_category_strategy", ".", "scale_for_linear_predictor", "\n", "*", "multiplier_on_scale_for_beta_column", "\n", ")", "\n", "", "elif", "isinstance", "(", "beta_category_strategy", ",", "ControlCategoryPredictability", ")", ":", "\n", "        ", "return", "np", ".", "nan", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"I cannot determine the scale for sampling regression coefficients for features.\"", "\n", ")", "\n", "", "return", "scale_for_beta_column", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_betas_for_features": [[377, 421], ["isinstance", "isinstance", "numpy.zeros", "range", "isinstance", "bayes_multiclass_reg.get_scale_for_beta_column", "categorical_from_binary.data_generation.bayes_binary_reg.generate_regression_coefficients_for_features", "bayes_multiclass_reg.generate_betas_for_features_under_predictive_category_strategy", "ValueError"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.get_scale_for_beta_column", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.generate_regression_coefficients_for_features", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_betas_for_features_under_predictive_category_strategy"], ["", "def", "generate_betas_for_features", "(", "\n", "n_features", ":", "int", ",", "\n", "num_beta_columns", ":", "int", ",", "\n", "n_columns_with_nonzero_beta_coeffs", ":", "int", ",", "\n", "n_sparse_features", ":", "int", ",", "\n", "n_bounded_from_zero_features", ":", "int", ",", "\n", "lower_bound_for_bounded_from_zero_features", ":", "int", ",", "\n", "beta_category_strategy", ":", "BetaCategoryStrategy", ",", "\n", "seed", ":", "int", ",", "\n", ")", "->", "NumpyArray2D", ":", "\n", "\n", "    ", "if", "isinstance", "(", "beta_category_strategy", ",", "MakeUniformCategories", ")", "or", "isinstance", "(", "\n", "beta_category_strategy", ",", "MakePreferredCategories", "\n", ")", ":", "\n", "        ", "betas_for_features", "=", "np", ".", "zeros", "(", "(", "n_features", ",", "num_beta_columns", ")", ")", "\n", "for", "col", "in", "range", "(", "n_columns_with_nonzero_beta_coeffs", ")", ":", "\n", "            ", "scale_for_beta_column", "=", "get_scale_for_beta_column", "(", "\n", "beta_category_strategy", ",", "\n", "n_columns_with_nonzero_beta_coeffs", ",", "\n", "column_index", "=", "col", ",", "\n", ")", "\n", "betas_for_features", "[", "\n", ":", ",", "col", "\n", "]", "=", "generate_regression_coefficients_for_features_for_one_column", "(", "\n", "n_features", ",", "\n", "n_sparse_features", ",", "\n", "n_bounded_from_zero_features", ",", "\n", "lower_bound_for_bounded_from_zero_features", ",", "\n", "beta_category_strategy", ".", "mean", ",", "\n", "scale_for_linear_predictor", "=", "scale_for_beta_column", ",", "\n", "linear_predictor_scale_allocator", "=", "beta_category_strategy", ".", "linear_predictor_scale_allocator", ",", "\n", "seed", "=", "seed", ",", "\n", ")", "\n", "", "return", "betas_for_features", "\n", "", "elif", "isinstance", "(", "beta_category_strategy", ",", "ControlCategoryPredictability", ")", ":", "\n", "        ", "return", "generate_betas_for_features_under_predictive_category_strategy", "(", "\n", "n_features", ",", "\n", "num_beta_columns", ",", "\n", "beta_category_strategy", ".", "scale_for_predictive_categories", ",", "\n", "beta_category_strategy", ".", "scale_for_non_predictive_categories", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"I don't understand the beta category strategy, which is needed to \"", "\n", "f\"generate regresssion coefficients for the features\"", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_betas_for_features_under_predictive_category_strategy": [[425, 464], ["numpy.zeros", "range", "ValueError", "range", "int", "numpy.random.normal", "numpy.floor"], "function", ["None"], ["", "", "def", "generate_betas_for_features_under_predictive_category_strategy", "(", "\n", "num_features", ":", "int", ",", "\n", "num_beta_columns", ":", "int", ",", "\n", "scale_for_predictive_categories", ":", "float", ",", "\n", "scale_for_non_predictive_categories", ":", "float", ",", "\n", ")", "->", "NumpyArray2D", ":", "\n", "    ", "\"\"\"\n    Idea:\n        Let's suppose we map each covariate to a category.\n            So high values of covariate 1 or 2 might \"signal\" category 1, etc.\n            So high values of covariate 3 or 4 might \"signal\" category 2, etc.\n\n        Then, generate covariates by:\n\n        1. Selecting a subset of covariates to \"matter\"\n        2. Draw these from a Normal(0, scale_for_predictive_categories)\n        3. Draw remaining covariates from a Normal(0, scale_for_non_predictive_categories)\n    \"\"\"", "\n", "if", "scale_for_non_predictive_categories", ">", "scale_for_predictive_categories", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"Are you doing this right? scale for predictive categories should \"", "\n", "f\"not be less than the scale for non-predictive categories\"", "\n", ")", "\n", "\n", "", "betas_for_features", "=", "np", ".", "zeros", "(", "(", "num_features", ",", "num_beta_columns", ")", ")", "\n", "num_predictive_features_per_category", "=", "num_features", "/", "num_beta_columns", "\n", "\n", "for", "k", "in", "range", "(", "num_beta_columns", ")", ":", "\n", "        ", "for", "m", "in", "range", "(", "num_features", ")", ":", "\n", "            ", "category_this_feature_predicts", "=", "int", "(", "\n", "np", ".", "floor", "(", "m", "/", "num_predictive_features_per_category", ")", "\n", ")", "\n", "\n", "if", "k", "==", "category_this_feature_predicts", ":", "\n", "                ", "scale", "=", "scale_for_predictive_categories", "\n", "", "else", ":", "\n", "                ", "scale", "=", "scale_for_non_predictive_categories", "\n", "", "betas_for_features", "[", "m", ",", "k", "]", "=", "np", ".", "random", ".", "normal", "(", "loc", "=", "0", ",", "scale", "=", "scale", ",", "size", "=", "1", ")", "\n", "", "", "return", "betas_for_features", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_regression_coefficients": [[466, 530], ["bayes_multiclass_reg.ControlCategoryPredictability", "numpy.random.seed", "bayes_multiclass_reg.get_num_beta_columns", "bayes_multiclass_reg.generate_betas_for_features", "bayes_multiclass_reg.generate_intercepts", "numpy.zeros", "ValueError"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.get_num_beta_columns", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_betas_for_features", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_intercepts"], ["", "def", "generate_regression_coefficients", "(", "\n", "n_features", ":", "int", ",", "\n", "n_categories", ":", "int", ",", "\n", "link", ":", "Link", ",", "\n", "beta_0", ":", "Optional", "[", "NumpyArray1D", "]", ",", "\n", "n_sparse_features", ":", "int", "=", "0", ",", "\n", "n_categories_where_all_beta_coefficients_are_sparse", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "n_bounded_from_zero_features", ":", "int", "=", "0", ",", "\n", "lower_bound_for_bounded_from_zero_features", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "beta_category_strategy", ":", "BetaCategoryStrategy", "=", "ControlCategoryPredictability", "(", ")", ",", "\n", "mean_for_intercept", ":", "float", "=", "0.0", ",", "\n", "scale_for_intercept", ":", "float", "=", "0.25", ",", "\n", "seed", ":", "int", "=", "None", ",", "\n", "include_intercept", ":", "bool", "=", "True", ",", "\n", ")", ":", "\n", "# generate regression coefficients", "\n", "    ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "num_beta_columns", "=", "get_num_beta_columns", "(", "link", ",", "n_categories", ")", "\n", "if", "(", "\n", "not", "n_categories_where_all_beta_coefficients_are_sparse", "\n", ")", ":", "# covers 0 or None cases", "\n", "        ", "n_columns_with_nonzero_beta_coeffs", "=", "num_beta_columns", "\n", "", "else", ":", "\n", "        ", "n_columns_with_nonzero_beta_coeffs", "=", "(", "\n", "n_categories", "-", "n_categories_where_all_beta_coefficients_are_sparse", "\n", ")", "\n", "if", "n_columns_with_nonzero_beta_coeffs", ">", "num_beta_columns", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Num columns with nonzero coefficients can't exceed the number of beta columns\"", "\n", ")", "\n", "\n", "# generate intercepts:", "\n", "", "", "if", "beta_0", "is", "None", ":", "\n", "        ", "beta_0", "=", "generate_intercepts", "(", "\n", "link", ",", "\n", "n_categories", ",", "\n", "num_beta_columns", ",", "\n", "n_columns_with_nonzero_beta_coeffs", ",", "\n", "mean_for_intercept", ",", "\n", "scale_for_intercept", ",", "\n", "beta_category_strategy", ",", "\n", ")", "\n", "\n", "# generate regression coefficients for all columns corresponding to categories", "\n", "# that are not sparse.", "\n", "", "betas_for_features", "=", "generate_betas_for_features", "(", "\n", "n_features", ",", "\n", "num_beta_columns", ",", "\n", "n_columns_with_nonzero_beta_coeffs", ",", "\n", "n_sparse_features", ",", "\n", "n_bounded_from_zero_features", ",", "\n", "lower_bound_for_bounded_from_zero_features", ",", "\n", "beta_category_strategy", ",", "\n", "seed", ",", "\n", ")", "\n", "\n", "if", "include_intercept", ":", "\n", "# concatenate the intercept and feature terms into a single beta object", "\n", "        ", "beta", "=", "np", ".", "zeros", "(", "(", "n_features", "+", "1", ",", "num_beta_columns", ")", ")", "\n", "beta", "[", "0", ",", ":", "]", "=", "beta_0", "\n", "beta", "[", "1", ":", ",", ":", "]", "=", "betas_for_features", "\n", "", "else", ":", "\n", "        ", "beta", "=", "betas_for_features", "\n", "", "return", "beta", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.compute_linear_predictors_preventing_downstream_overflow": [[532, 545], ["None"], "function", ["None"], ["", "def", "compute_linear_predictors_preventing_downstream_overflow", "(", "\n", "features", ":", "NumpyArray2D", ",", "\n", "beta", ":", "NumpyArray2D", ",", "\n", ")", "->", "NumpyArray2D", ":", "\n", "    ", "\"\"\"\n    We want to be sure to prevent downstream overflow, since construction of category\n    probabilities can make these exponentially large - consider the multi-logit link,\n    which constructs category probabilities by exponentiating the linear predictors\n    \"\"\"", "\n", "MAX_LINEAR_PREDICTOR", "=", "500", "# to prevent overflow; value chosen somewhat arbitrarily, but I know 828 is too large", "\n", "eta", "=", "features", "@", "beta", "\n", "eta", "[", "eta", ">", "MAX_LINEAR_PREDICTOR", "]", "=", "MAX_LINEAR_PREDICTOR", "\n", "return", "eta", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_multi_logit_probabilities": [[547, 572], ["numpy.zeros", "bayes_multiclass_reg.compute_linear_predictors_preventing_downstream_overflow", "numpy.exp", "range", "numpy.shape", "numpy.sum", "numpy.sum", "numpy.shape"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.compute_linear_predictors_preventing_downstream_overflow"], ["", "def", "construct_multi_logit_probabilities", "(", "\n", "features", ":", "NumpyArray2D", ",", "\n", "beta", ":", "NumpyArray2D", ",", "\n", ")", "->", "NumpyArray2D", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        features: an np.array of shape (n_samples, n_features+1)\n            Includes a ones column for the intercept term!\n        beta: regression weights with shape (n_features+1, n_categories-1)\n\n    Returns:\n        np.array of shape (n_samples, n_categories)\n    \"\"\"", "\n", "n_samples", "=", "np", ".", "shape", "(", "features", ")", "[", "0", "]", "\n", "n_categories", "=", "np", ".", "shape", "(", "beta", ")", "[", "1", "]", "+", "1", "\n", "probs", "=", "np", ".", "zeros", "(", "(", "n_samples", ",", "n_categories", ")", ")", "\n", "eta", "=", "compute_linear_predictors_preventing_downstream_overflow", "(", "features", ",", "beta", ")", "\n", "exponentiated_linear_predictors", "=", "np", ".", "exp", "(", "eta", ")", "\n", "normalizers_by_observations", "=", "np", ".", "sum", "(", "exponentiated_linear_predictors", ",", "1", ")", "+", "1.0", "\n", "for", "k", "in", "range", "(", "n_categories", "-", "1", ")", ":", "\n", "        ", "probs", "[", ":", ",", "k", "]", "=", "(", "\n", "exponentiated_linear_predictors", "[", ":", ",", "k", "]", "/", "normalizers_by_observations", "\n", ")", "\n", "", "probs", "[", ":", ",", "-", "1", "]", "=", "1.0", "-", "np", ".", "sum", "(", "probs", ",", "1", ")", "\n", "return", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_non_identified_softmax_probabilities": [[574, 594], ["numpy.shape", "numpy.sum", "numpy.array", "numpy.array", "numpy.exp", "range", "numpy.exp", "range"], "function", ["None"], ["", "def", "construct_non_identified_softmax_probabilities", "(", "\n", "features", ":", "NumpyArray2D", ",", "\n", "beta", ":", "NumpyArray2D", ",", "\n", ")", "->", "NumpyArray2D", ":", "\n", "    ", "\"\"\"\n    Note: This computation is not the identifiable one used during simulation.\n\n    Arguments:\n        features: an np.array of shape (n_samples, n_features+1)\n            Includes a ones column for the intercept term!\n        beta: regression weights with shape (n_features+1, n_categories)\n\n    Returns:\n        np.array of shape (n_samples, n_categories)\n    \"\"\"", "\n", "M", ",", "K", "=", "np", ".", "shape", "(", "beta", ")", "\n", "etas", "=", "features", "@", "beta", "# N times K", "\n", "\n", "Z", "=", "np", ".", "sum", "(", "np", ".", "array", "(", "[", "np", ".", "exp", "(", "etas", "[", ":", ",", "k", "]", ")", "for", "k", "in", "range", "(", "K", ")", "]", ")", ",", "0", ")", "\n", "return", "np", ".", "array", "(", "[", "np", ".", "exp", "(", "etas", "[", ":", ",", "k", "]", ")", "/", "Z", "for", "k", "in", "range", "(", "K", ")", "]", ")", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_multi_probit_probabilities": [[596, 641], ["numpy.zeros", "range", "numpy.zeros", "range", "numpy.shape", "numpy.shape", "numpy.random.normal", "numpy.argmax", "numpy.mean"], "function", ["None"], ["", "def", "construct_multi_probit_probabilities", "(", "\n", "features", ":", "NumpyArray2D", ",", "\n", "beta", ":", "NumpyArray2D", ",", "\n", "n_simulations", ":", "int", "=", "100000", ",", "\n", "assume_that_random_components_of_utilities_are_independent_across_categories", ":", "bool", "=", "True", ",", "\n", ")", "->", "NumpyArray2D", ":", "\n", "    ", "\"\"\"\n    We use a simulated probability method via Lerman and Manski (1981). It is\n    summarized very nicely on pp. 120 of Kenneth Train\u2019s book,\n    Discrete Choice Models with Simulations:\n\n    We assume the error components are drawn from a multivariate normal N(O,I)\n\n    Arguments:\n        features: an np.array of shape (n_samples, n_features+1)\n            Includes a ones column for the intercept term!\n        beta: regression weights with shape (n_features+1, n_categories-1)\n\n    Returns:\n        np.array of shape (n_samples, n_categories)\n    \"\"\"", "\n", "if", "not", "assume_that_random_components_of_utilities_are_independent_across_categories", ":", "\n", "# TODO: Implement this.  Unlike softmax/multi-logit, multi-probit has additional", "\n", "# flexibility due to the correlated latent factors, which allows for departure", "\n", "# from the IIA assumption.  We might want to investigate behavior in this regime.", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "n_samples", "=", "np", ".", "shape", "(", "features", ")", "[", "0", "]", "\n", "n_categories", "=", "np", ".", "shape", "(", "beta", ")", "[", "1", "]", "\n", "linear_predictors", "=", "features", "@", "beta", "\n", "\n", "choices_by_simulation", "=", "np", ".", "zeros", "(", "(", "n_samples", ",", "n_simulations", ")", ",", "dtype", "=", "int", ")", "\n", "for", "s", "in", "range", "(", "n_simulations", ")", ":", "\n", "# Here is where we assume that the random components are uncorrelated.", "\n", "        ", "random_contributions", "=", "np", ".", "random", ".", "normal", "(", "loc", "=", "0", ",", "scale", "=", "1", ",", "size", "=", "n_categories", ")", "\n", "random_utilities", "=", "(", "\n", "linear_predictors", "+", "random_contributions", "\n", ")", "# (n_samples x n_categories)", "\n", "choices", "=", "np", ".", "argmax", "(", "random_utilities", ",", "1", ")", "# (n_sample,)", "\n", "choices_by_simulation", "[", ":", ",", "s", "]", "=", "choices", "\n", "\n", "", "probs_approx", "=", "np", ".", "zeros", "(", "(", "n_samples", ",", "n_categories", ")", ")", "\n", "for", "k", "in", "range", "(", "n_categories", ")", ":", "\n", "        ", "probs_approx", "[", ":", ",", "k", "]", "=", "np", ".", "mean", "(", "choices_by_simulation", "==", "k", ",", "1", ")", "\n", "", "return", "probs_approx", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_stickbreaking_multinomial_probabilities": [[643, 673], ["categorical_from_binary.kl.sigmoid", "numpy.ones", "range", "numpy.shape", "range", "numpy.sum", "numpy.shape"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.sigmoid"], ["", "def", "construct_stickbreaking_multinomial_probabilities", "(", "\n", "features", ":", "NumpyArray2D", ",", "\n", "beta", ":", "NumpyArray2D", ",", "\n", ")", "->", "NumpyArray2D", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        features: an np.array of shape (n_samples, n_features+1)\n            Includes a ones column for the intercept term!\n        beta: regression weights with shape (n_features+1, n_categories-1)\n\n    Returns:\n        np.array of shape (n_samples, n_categories)\n    \"\"\"", "\n", "n_samples", "=", "np", ".", "shape", "(", "features", ")", "[", "0", "]", "\n", "n_categories", "=", "np", ".", "shape", "(", "beta", ")", "[", "1", "]", "+", "1", "\n", "\n", "# to do, better name", "\n", "bernoulli_yes", "=", "sigmoid", "(", "features", "@", "beta", ")", "\n", "# bernoulli_yes = sigmoid(np.transpose(np.tile(beta_0[:,np.newaxis],n_samples))) #intercept only", "\n", "bernoulli_no", "=", "1.0", "-", "bernoulli_yes", "\n", "\n", "probs", "=", "np", ".", "ones", "(", "(", "n_samples", ",", "n_categories", ")", ")", "\n", "for", "k", "in", "range", "(", "n_categories", "-", "1", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "k", ")", ":", "\n", "            ", "probs", "[", ":", ",", "k", "]", "*=", "bernoulli_no", "[", ":", ",", "j", "]", "\n", "", "probs", "[", ":", ",", "k", "]", "*=", "bernoulli_yes", "[", ":", ",", "k", "]", "\n", "\n", "# the final category is determined by what makes everything sum to 1.0", "\n", "", "probs", "[", ":", ",", "-", "1", "]", "=", "1.0", "-", "np", ".", "sum", "(", "probs", "[", ":", ",", ":", "-", "1", "]", ",", "1", ")", "\n", "return", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_cbc_probit_probabilities": [[675, 693], ["bayes_multiclass_reg._construct_general_cbc_probabilities"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg._construct_general_cbc_probabilities"], ["", "def", "construct_cbc_probit_probabilities", "(", "\n", "features", ":", "NumpyArray2D", ",", "\n", "beta", ":", "NumpyArray2D", ",", "\n", ")", "->", "NumpyArray2D", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        features: an np.array of shape (n_samples, n_features+1)\n            Includes a ones column for the intercept term!\n        beta: regression weights with shape (n_features+1, n_categories)\n\n    Notes:\n        CBC-probit gives beta an extra element compared to the logit constructions!!!\n\n    Returns:\n        np.array of shape (n_samples, n_categories)\n    \"\"\"", "\n", "log_cdf", "=", "scipy", ".", "stats", ".", "norm", ".", "logcdf", "\n", "return", "_construct_general_cbc_probabilities", "(", "features", ",", "beta", ",", "log_cdf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_cbc_logit_probabilities": [[695, 713], ["bayes_multiclass_reg._construct_general_cbc_probabilities"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg._construct_general_cbc_probabilities"], ["", "def", "construct_cbc_logit_probabilities", "(", "\n", "features", ":", "NumpyArray2D", ",", "\n", "beta", ":", "NumpyArray2D", ",", "\n", ")", "->", "NumpyArray2D", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        features: an np.array of shape (n_samples, n_features+1)\n            Includes a ones column for the intercept term!\n        beta: regression weights with shape (n_features+1, n_categories)\n\n    Notes:\n        CBC-probit gives beta an extra element compared to the logit constructions!!!\n\n    Returns:\n        np.array of shape (n_samples, n_categories)\n    \"\"\"", "\n", "log_cdf", "=", "scipy", ".", "stats", ".", "logistic", ".", "logcdf", "\n", "return", "_construct_general_cbc_probabilities", "(", "features", ",", "beta", ",", "log_cdf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg._construct_general_cbc_probabilities": [[715, 763], ["bayes_multiclass_reg.compute_linear_predictors_preventing_downstream_overflow", "scipy.sparse.issparse", "numpy.exp", "numpy.sum", "utilities.toarray.toarray", "log_cdf", "log_cdf"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.compute_linear_predictors_preventing_downstream_overflow"], ["", "def", "_construct_general_cbc_probabilities", "(", "\n", "features", ":", "NumpyArray2D", ",", "\n", "beta", ":", "NumpyArray2D", ",", "\n", "log_cdf", ":", "Callable", ",", "\n", ")", "->", "NumpyArray2D", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        features: an np.array of shape (n_samples, n_features+1)\n            Includes a ones column for the intercept term!\n        beta: regression weights with shape (n_features+1, n_categories)\n        log_cdf :  log cumulative distribution function for some symmetric location-scale family.\n\n    Returns:\n        np.array of shape (n_samples, n_categories)\n    \"\"\"", "\n", "# TODO: align \"features\" and \"covariates\"", "\n", "#   (sometimes I use the latter to designate the result of prepending the column of all 1's)", "\n", "#   (maybe calling this \"design_matrix\" might be even clearer)", "\n", "# TODO: align \"utilities\" and \"linear predictors\"", "\n", "\n", "utilities", "=", "compute_linear_predictors_preventing_downstream_overflow", "(", "features", ",", "beta", ")", "\n", "# TODO: support sparse computation here", "\n", "if", "scipy", ".", "sparse", ".", "issparse", "(", "utilities", ")", ":", "\n", "        ", "utilities", "=", "utilities", ".", "toarray", "(", ")", "\n", "\n", "# What this is doing is can perhaps be better understood as follows:", "\n", "#", "\n", "#  1. Construction of potentials using the CBC-Probit category probs directly from Johndrow et al (2013)", "\n", "#  from categorical_from_binary.data_generation.util import  prod_of_columns_except", "\n", "#", "\n", "#   n_obs = np.shape(features)[0]", "\n", "#   n_categories = np.shape(beta)[1]", "\n", "#   cdf = scipy.stats.norm.cdf", "\n", "#   cdf_neg_utilities = cdf(-utilities)", "\n", "#   potentials = np.zeros((n_obs, n_categories))", "\n", "#   for k in range(n_categories):", "\n", "#         potentials[:, k] = (1 - cdf_neg_utilities[:, k]) * prod_of_columns_except(", "\n", "#         cdf_neg_utilities, k", "\n", "#       )", "\n", "#", "\n", "# 2. Alternate construction of potentials, using the expression from the categorical models notes", "\n", "#      potentials=cdf(utilities)/cdf(-utilities)", "\n", "#", "\n", "# The version below though is more numerically stable", "\n", "\n", "", "potentials", "=", "np", ".", "exp", "(", "log_cdf", "(", "utilities", ")", "-", "log_cdf", "(", "-", "utilities", ")", ")", "\n", "normalizing_constants", "=", "np", ".", "sum", "(", "potentials", ",", "1", ")", "\n", "return", "potentials", "/", "normalizing_constants", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_cbm_probit_probabilities": [[765, 782], ["bayes_multiclass_reg._construct_general_cbm_probabilities"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg._construct_general_cbm_probabilities"], ["", "def", "construct_cbm_probit_probabilities", "(", "\n", "features", ":", "NumpyArray2D", ",", "\n", "beta", ":", "NumpyArray2D", ",", "\n", ")", "->", "NumpyArray2D", ":", "\n", "    ", "\"\"\"\n    Construct probabiliites using the CBM-Probit model\n\n    Arguments:\n        features: an np.array of shape (n_samples, n_features+1)\n            Includes a ones column for the intercept term!\n        beta: regression weights with shape (n_features+1, n_categories)\n\n    Returns:\n        np.array of shape (n_samples, n_categories)\n    \"\"\"", "\n", "cdf", "=", "scipy", ".", "stats", ".", "norm", ".", "cdf", "\n", "return", "_construct_general_cbm_probabilities", "(", "features", ",", "beta", ",", "cdf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_cbm_logit_probabilities": [[784, 801], ["bayes_multiclass_reg._construct_general_cbm_probabilities"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg._construct_general_cbm_probabilities"], ["", "def", "construct_cbm_logit_probabilities", "(", "\n", "features", ":", "NumpyArray2D", ",", "\n", "beta", ":", "NumpyArray2D", ",", "\n", ")", "->", "NumpyArray2D", ":", "\n", "    ", "\"\"\"\n    Construct probabiliites using the CBM-Logit model\n\n    Arguments:\n        features: an np.array of shape (n_samples, n_features+1)\n            Includes a ones column for the intercept term!\n        beta: regression weights with shape (n_features+1, n_categories)\n\n    Returns:\n        np.array of shape (n_samples, n_categories)\n    \"\"\"", "\n", "cdf", "=", "scipy", ".", "stats", ".", "logistic", ".", "cdf", "\n", "return", "_construct_general_cbm_probabilities", "(", "features", ",", "beta", ",", "cdf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg._construct_general_cbm_probabilities": [[803, 830], ["bayes_multiclass_reg.compute_linear_predictors_preventing_downstream_overflow", "scipy.sparse.issparse", "cdf", "utilities.toarray.toarray", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.compute_linear_predictors_preventing_downstream_overflow"], ["", "def", "_construct_general_cbm_probabilities", "(", "\n", "features", ":", "NumpyArray2D", ",", "\n", "beta", ":", "NumpyArray2D", ",", "\n", "cdf", ":", "Callable", ",", "\n", ")", "->", "NumpyArray2D", ":", "\n", "    ", "\"\"\"\n    Construct probabiliites using the CBM model\n\n    Arguments:\n        features: an np.array of shape (n_samples, n_features+1)\n            Includes a ones column for the intercept term!\n        beta: regression weights with shape (n_features+1, n_categories)\n        cdf : cumulative distribution function for some symmetric location-scale family.\n\n    Returns:\n        np.array of shape (n_samples, n_categories)\n    \"\"\"", "\n", "# TODO: align \"features\" and \"covariates\"", "\n", "#   (sometimes I use the latter to designate the result of prepending the column of all 1's)", "\n", "#   (maybe calling this \"design_matrix\" might be even clearer)", "\n", "# TODO: align \"utilities\" and \"linear predictors\"", "\n", "utilities", "=", "compute_linear_predictors_preventing_downstream_overflow", "(", "features", ",", "beta", ")", "\n", "# TODO: support sparse computation here", "\n", "if", "scipy", ".", "sparse", ".", "issparse", "(", "utilities", ")", ":", "\n", "        ", "utilities", "=", "utilities", ".", "toarray", "(", ")", "\n", "", "cdf_utilities", "=", "cdf", "(", "utilities", ")", "\n", "return", "cdf_utilities", "/", "np", ".", "sum", "(", "cdf_utilities", ",", "1", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs": [[846, 849], ["function_to_construct_category_probs"], "function", ["None"], ["def", "construct_category_probs", "(", "features", ":", "NumpyArray2D", ",", "beta", ":", "NumpyArray2D", ",", "link", ":", "Link", ")", ":", "\n", "    ", "function_to_construct_category_probs", "=", "CATEGORY_PROBABILITY_FUNCTION_BY_LINK", "[", "link", "]", "\n", "return", "function_to_construct_category_probs", "(", "features", ",", "beta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.compute_mean_log_likelihood": [[851, 856], ["bayes_multiclass_reg.construct_category_probs", "bayes_multiclass_reg.compute_mean_log_likelihood_from_category_probs"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.compute_mean_log_likelihood_from_category_probs"], ["", "def", "compute_mean_log_likelihood", "(", "\n", "features", ":", "NumpyArray2D", ",", "labels", ":", "NumpyArray2D", ",", "beta", ":", "NumpyArray2D", ",", "link", ":", "Link", "\n", ")", ":", "\n", "    ", "category_probs", "=", "construct_category_probs", "(", "features", ",", "beta", ",", "link", ")", "\n", "return", "compute_mean_log_likelihood_from_category_probs", "(", "category_probs", ",", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.compute_mean_log_likelihood_from_category_probs": [[858, 866], ["numpy.argmax", "numpy.nanmean", "numpy.log", "enumerate"], "function", ["None"], ["", "def", "compute_mean_log_likelihood_from_category_probs", "(", "\n", "category_probs", ":", "NumpyArray2D", ",", "labels", ":", "NumpyArray2D", "\n", ")", ":", "\n", "    ", "choices", "=", "np", ".", "argmax", "(", "labels", ",", "1", ")", "\n", "category_probs_of_choices", "=", "[", "\n", "category_probs", "[", "i", ",", "choice", "]", "for", "(", "i", ",", "choice", ")", "in", "enumerate", "(", "choices", ")", "\n", "]", "\n", "return", "np", ".", "nanmean", "(", "np", ".", "log", "(", "category_probs_of_choices", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_designed_features_and_multiclass_labels": [[868, 901], ["bayes_multiclass_reg.generate_designed_features_and_multiclass_labels_for_autoregressive_case", "bayes_multiclass_reg.generate_multiclass_labels_for_nonautoregressive_case"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_designed_features_and_multiclass_labels_for_autoregressive_case", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_multiclass_labels_for_nonautoregressive_case"], ["", "def", "generate_designed_features_and_multiclass_labels", "(", "\n", "features_non_autoregressive", ":", "NumpyArray2D", ",", "\n", "beta", ":", "NumpyArray2D", ",", "\n", "link", ":", "Link", ",", "\n", "is_autoregressive", ":", "bool", "=", "False", ",", "\n", ")", "->", "Tuple", "[", "NumpyArray2D", "]", ":", "\n", "    ", "\"\"\"\n    Returns:\n        designed_features : an np.array of shape(n_samples, n_features_designed);\n            The first `n_features_non_autoregressive` features are the input features\n            The next `n_categories` features are the previous labels.\n        labels:  an np.array of shape (n_samples, n_categories);\n            each row is one-hot encoded\n    \"\"\"", "\n", "# TODO: Come up with a constructive name for features that don't include autoregressive features.", "\n", "\n", "if", "is_autoregressive", ":", "\n", "        ", "(", "\n", "designed_features", ",", "\n", "labels", ",", "\n", ")", "=", "generate_designed_features_and_multiclass_labels_for_autoregressive_case", "(", "\n", "features_non_autoregressive", ",", "\n", "beta", ",", "\n", "link", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "labels", "=", "generate_multiclass_labels_for_nonautoregressive_case", "(", "\n", "features_non_autoregressive", ",", "\n", "beta", ",", "\n", "link", ",", "\n", ")", "\n", "designed_features", "=", "features_non_autoregressive", "\n", "", "return", "designed_features", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_multiclass_labels_for_nonautoregressive_case": [[903, 929], ["bayes_multiclass_reg.construct_category_probs", "numpy.zeros", "range", "numpy.shape", "numpy.shape", "categorical_from_binary.numpy_helpers.enforce_bounds_on_prob_vector", "numpy.random.multinomial"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.numpy_helpers.enforce_bounds_on_prob_vector"], ["", "def", "generate_multiclass_labels_for_nonautoregressive_case", "(", "\n", "features", ":", "NumpyArray2D", ",", "\n", "beta", ":", "NumpyArray2D", ",", "\n", "link", ":", "Link", ",", "\n", ")", "->", "NumpyArray2D", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        features: an np.array of shape (n_samples, n_features+1)\n            Includes a ones column for the intercept term!\n        beta: regression weights with shape (n_features+1, num_beta_columns)\n                num_beta_columns depends on the link function:\n                    num_beta_columns = n_categories - 1 for Link.MULTI_LOGIT and Link.STICK_BREAKING\n                    num_beta_columns = n_categories for Link.CBC_PROBIT\n                Note that if the former is used with an extra beta weight, that column will just be ignored.\n    Returns:\n        labels:  an np.array of shape (n_samples, n_categories);\n            each row is one-hot encoded\n    \"\"\"", "\n", "n_samples", "=", "np", ".", "shape", "(", "features", ")", "[", "0", "]", "\n", "probs", "=", "construct_category_probs", "(", "features", ",", "beta", ",", "link", ")", "\n", "n_categories", "=", "np", ".", "shape", "(", "probs", ")", "[", "1", "]", "\n", "labels", "=", "np", ".", "zeros", "(", "(", "n_samples", ",", "n_categories", ")", ",", "dtype", "=", "np", ".", "int", ")", "\n", "for", "i", "in", "range", "(", "n_samples", ")", ":", "\n", "        ", "category_probs_for_sample", "=", "enforce_bounds_on_prob_vector", "(", "probs", "[", "i", ",", ":", "]", ")", "\n", "labels", "[", "i", "]", "=", "np", ".", "random", ".", "multinomial", "(", "1", ",", "category_probs_for_sample", ")", "\n", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_designed_features_and_multiclass_labels_for_autoregressive_case": [[931, 992], ["warnings.warn", "numpy.zeros", "numpy.zeros", "range", "numpy.shape", "numpy.shape", "numpy.shape", "numpy.shape", "ValueError", "numpy.ones", "numpy.random.multinomial", "numpy.hstack", "bayes_multiclass_reg.construct_category_probs"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs"], ["", "def", "generate_designed_features_and_multiclass_labels_for_autoregressive_case", "(", "\n", "features_non_autoregressive", ":", "NumpyArray2D", ",", "\n", "beta", ":", "NumpyArray2D", ",", "\n", "link", ":", "Link", "=", "Link", ".", "CBC_PROBIT", ",", "\n", ")", "->", "Tuple", "[", "NumpyArray2D", "]", ":", "\n", "    ", "\"\"\"\n    The function `generate_multiclass_labels_for_non_autoregressive_case` constructs all the category probs\n    in advance, before seeing what labels are selected.  We cannot do that here.  In the autoregressive case,\n    we need to know the previous label before we can give the category probabilities are.  Thus,\n    we construct the pair (category_prob, label) one by one.\n\n    Arguments:\n        features_non_autoregressive: an np.array of shape (n_samples, n_features_non_autoregressive)\n        beta: regression weights with shape (n_features_designed, num_beta_columns)\n            The first n_features_non_autoregressive rows of beta are for the intercept (if used)\n            and the external covariates.  The remaining rows govern transitions.\n    Returns:\n        designed_features : an np.array of shape(n_samples, n_features_designed);\n            The first `n_features_non_autoregressive` features are the input features\n            The next `n_categories` features are the previous labels.\n        labels:  an np.array of shape (n_samples, n_categories);\n            each row is one-hot encoded\n    \"\"\"", "\n", "if", "link", "!=", "Link", ".", "CBC_PROBIT", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "", "n_samples", "=", "np", ".", "shape", "(", "features_non_autoregressive", ")", "[", "0", "]", "\n", "n_features_non_autoregressive", "=", "np", ".", "shape", "(", "features_non_autoregressive", ")", "[", "1", "]", "\n", "n_entries_for_beta_per_category", "=", "np", ".", "shape", "(", "beta", ")", "[", "0", "]", "\n", "n_categories", "=", "np", ".", "shape", "(", "beta", ")", "[", "1", "]", "\n", "n_features_designed", "=", "n_features_non_autoregressive", "+", "n_categories", "\n", "\n", "if", "(", "\n", "not", "n_features_non_autoregressive", "+", "n_categories", "\n", "==", "n_entries_for_beta_per_category", "\n", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"This function expects the regression weight (beta) for each category \"", "\n", "f\"to have a number of entries which equals the number of non-autoregressive features (i.e. \"", "\n", "f\"external covariates + optional intercept) plus the number of categories.\"", "\n", ")", "\n", "\n", "", "warnings", ".", "warn", "(", "\n", "\"Making a mock previous label which is an equal-sized proportion of all possible ones.\"", "\n", ")", "\n", "prev_label", "=", "np", ".", "ones", "(", "n_categories", ")", "/", "n_categories", "# make a fake initial label", "\n", "\n", "labels", "=", "np", ".", "zeros", "(", "(", "n_samples", ",", "n_categories", ")", ",", "dtype", "=", "np", ".", "int", ")", "\n", "designed_features", "=", "np", ".", "zeros", "(", "(", "n_samples", ",", "n_features_designed", ")", ")", "\n", "for", "i", "in", "range", "(", "n_samples", ")", ":", "\n", "        ", "designed_features_for_one_sample", "=", "np", ".", "hstack", "(", "\n", "(", "features_non_autoregressive", "[", "i", ",", ":", "]", ",", "prev_label", ")", "\n", ")", "[", "np", ".", "newaxis", ",", ":", "]", "\n", "probs_for_sample", "=", "construct_category_probs", "(", "\n", "designed_features_for_one_sample", ",", "beta", ",", "link", "\n", ")", "[", "0", "]", "\n", "label", "=", "np", ".", "random", ".", "multinomial", "(", "1", ",", "probs_for_sample", ")", "\n", "labels", "[", "i", ",", ":", "]", "=", "label", "\n", "prev_label", "=", "label", "\n", "designed_features", "[", "i", ",", ":", "]", "=", "designed_features_for_one_sample", "\n", "", "return", "designed_features", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.compute_covariate_conditional_entropies_of_true_category_probabilities": [[994, 1001], ["bayes_multiclass_reg.construct_category_probs", "scipy.stats.entropy", "categorical_from_binary.numpy_helpers.enforce_bounds_on_prob_vector"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.numpy_helpers.enforce_bounds_on_prob_vector"], ["", "def", "compute_covariate_conditional_entropies_of_true_category_probabilities", "(", "\n", "covariates", ",", "\n", "beta_true", ",", "\n", "link", ",", "\n", ")", ":", "\n", "    ", "probs", "=", "construct_category_probs", "(", "covariates", ",", "beta_true", ",", "link", ")", "\n", "return", "scipy", ".", "stats", ".", "entropy", "(", "enforce_bounds_on_prob_vector", "(", "probs", ")", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.compute_mean_entropies_of_true_category_probabilities_by_label": [[1003, 1024], ["bayes_multiclass_reg.construct_category_probs", "scipy.stats.entropy", "numpy.argmax", "range", "numpy.shape", "numpy.round", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs"], ["", "def", "compute_mean_entropies_of_true_category_probabilities_by_label", "(", "\n", "covariates", ",", "labels", ",", "beta_true", ",", "link", "\n", ")", ":", "\n", "    ", "\"\"\"\n    This can be used to understand how much of the generative process is\n    choosing various categories/labels due to \"signal\" (e.g. covariates + weights clearly preferring the category)\n    versus \"noise\".   If entropy is low for a given category, it's more of a signal.  If entropy is high\n    for a given category, it's more luck.\n\n    To interpret a given entropy value, we could use Mike H's approach:  Generate discrete probability vectors\n    with some subset near 0, and plot the entropy.\n    \"\"\"", "\n", "probs", "=", "construct_category_probs", "(", "covariates", ",", "beta_true", ",", "link", ")", "\n", "entropies", "=", "scipy", ".", "stats", ".", "entropy", "(", "probs", ",", "axis", "=", "1", ")", "\n", "choices", "=", "np", ".", "argmax", "(", "labels", ",", "1", ")", "\n", "\n", "n_categories", "=", "np", ".", "shape", "(", "labels", ")", "[", "1", "]", "\n", "mean_entropies_by_label", "=", "{", "}", "\n", "for", "k", "in", "range", "(", "n_categories", ")", ":", "\n", "        ", "mean_entropies_by_label", "[", "k", "]", "=", "np", ".", "round", "(", "np", ".", "mean", "(", "entropies", "[", "choices", "==", "k", "]", ")", ",", "3", ")", "\n", "", "return", "mean_entropies_by_label", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.hierarchical_multiclass.find_rarest_category": [[24, 30], ["numpy.argmin", "sum", "numpy.mean"], "function", ["None"], ["", "def", "find_rarest_category", "(", "\n", "data", ":", "HierarchicalMulticlassRegressionDataset", ",", "\n", ")", "->", "int", ":", "\n", "    ", "category_counts_per_sequence", "=", "[", "sum", "(", "dataset", ".", "labels", ",", "0", ")", "for", "dataset", "in", "data", ".", "datasets", "]", "\n", "rarest_category", "=", "np", ".", "argmin", "(", "np", ".", "mean", "(", "category_counts_per_sequence", ",", "0", ")", ")", "\n", "return", "rarest_category", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.hierarchical_multiclass.compute_metrics_for_hierarchical_multiclass_regression": [[32, 72], ["categorical_from_binary.ib_cavi.multi.hierarchical_ib_probit.inference.data_dimensions_from_hierarchical_dataset", "hierarchical_multiclass.compute_choice_probs_for_hierarchical_multiclass_regression", "hierarchical_multiclass.compute_choice_probs_for_hierarchical_multiclass_regression", "hierarchical_multiclass.HierarchicalMetrics", "numpy.mean", "hierarchical_multiclass.find_rarest_category", "numpy.nanmean"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.hierarchical_multiclass.compute_choice_probs_for_hierarchical_multiclass_regression", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.hierarchical_multiclass.compute_choice_probs_for_hierarchical_multiclass_regression", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.hierarchical_multiclass.find_rarest_category"], ["", "def", "compute_metrics_for_hierarchical_multiclass_regression", "(", "\n", "variational_params", ":", "VariationalParams", ",", "\n", "data", ":", "HierarchicalMulticlassRegressionDataset", ",", "\n", "rarest_category", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", "->", "HierarchicalMetrics", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        rarest_category:\n            Optional.  If not provided, computed from the dataset.\n    \"\"\"", "\n", "\n", "J", ",", "M", ",", "K", ",", "Ns", "=", "data_dimensions_from_hierarchical_dataset", "(", "data", ")", "\n", "\n", "# Ns_are_all_equal=Ns[1:]==Ns[:-1]", "\n", "# if not Ns_are_all_equal:", "\n", "#     raise NotImplementedError(f\"Currently assuming all sequences are of the same\"", "\n", "#     f\"length just out of laziness, so that I can use matrices instead of lists\")", "\n", "# N=Ns[0]", "\n", "\n", "choice_probs_by_group", "=", "compute_choice_probs_for_hierarchical_multiclass_regression", "(", "\n", "variational_params", ",", "data", "\n", ")", "\n", "mean_choice_probs_by_group", "=", "[", "\n", "np", ".", "mean", "(", "choice_probs", ")", "for", "choice_probs", "in", "choice_probs_by_group", "\n", "]", "\n", "\n", "if", "rarest_category", "is", "None", ":", "\n", "        ", "rarest_category", "=", "find_rarest_category", "(", "data", ")", "\n", "", "choice_probs_by_group_for_rarest_category", "=", "(", "\n", "compute_choice_probs_for_hierarchical_multiclass_regression", "(", "\n", "variational_params", ",", "data", ",", "focal_choice", "=", "rarest_category", "\n", ")", "\n", ")", "\n", "mean_choice_probs_by_group_for_rarest_category", "=", "[", "\n", "np", ".", "nanmean", "(", "choice_probs", ")", "\n", "for", "choice_probs", "in", "choice_probs_by_group_for_rarest_category", "\n", "]", "\n", "return", "HierarchicalMetrics", "(", "\n", "mean_choice_probs_by_group", ",", "\n", "mean_choice_probs_by_group_for_rarest_category", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.hierarchical_multiclass.compute_mean_choice_probs_for_hierarchical_multiclass_regression": [[75, 83], ["hierarchical_multiclass.compute_choice_probs_for_hierarchical_multiclass_regression", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.hierarchical_multiclass.compute_choice_probs_for_hierarchical_multiclass_regression"], ["", "def", "compute_mean_choice_probs_for_hierarchical_multiclass_regression", "(", "\n", "variational_params", ":", "VariationalParams", ",", "\n", "data", ":", "HierarchicalMulticlassRegressionDataset", ",", "\n", ")", "->", "List", "[", "List", "[", "float", "]", "]", ":", "\n", "    ", "choice_probs_by_group", "=", "compute_choice_probs_for_hierarchical_multiclass_regression", "(", "\n", "variational_params", ",", "data", "\n", ")", "\n", "return", "[", "np", ".", "mean", "(", "choice_probs", ")", "for", "choice_probs", "in", "choice_probs_by_group", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.hierarchical_multiclass.compute_mean_log_choice_probs_for_hierarchical_multiclass_regression": [[85, 93], ["hierarchical_multiclass.compute_choice_probs_for_hierarchical_multiclass_regression", "numpy.mean", "numpy.log"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.hierarchical_multiclass.compute_choice_probs_for_hierarchical_multiclass_regression"], ["", "def", "compute_mean_log_choice_probs_for_hierarchical_multiclass_regression", "(", "\n", "variational_params", ":", "VariationalParams", ",", "\n", "data", ":", "HierarchicalMulticlassRegressionDataset", ",", "\n", ")", "->", "List", "[", "List", "[", "float", "]", "]", ":", "\n", "    ", "choice_probs_by_group", "=", "compute_choice_probs_for_hierarchical_multiclass_regression", "(", "\n", "variational_params", ",", "data", "\n", ")", "\n", "return", "[", "np", ".", "mean", "(", "np", ".", "log", "(", "choice_probs", ")", ")", "for", "choice_probs", "in", "choice_probs_by_group", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.hierarchical_multiclass.compute_choice_probs_for_hierarchical_multiclass_regression": [[95, 137], ["categorical_from_binary.ib_cavi.multi.hierarchical_ib_probit.inference.data_dimensions_from_hierarchical_dataset", "range", "numpy.argmax", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_category_probs", "list", "enumerate", "numpy.array"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs"], ["", "def", "compute_choice_probs_for_hierarchical_multiclass_regression", "(", "\n", "variational_params", ":", "VariationalParams", ",", "\n", "data", ":", "HierarchicalMulticlassRegressionDataset", ",", "\n", "focal_choice", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", "->", "List", "[", "List", "[", "float", "]", "]", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        focal_choice:\n            Optional.  If present, only return the choice probs when the label was\n            the `focal_choice`.  Otherwise, return all choice probs.\n    Returns:\n        A List of Lists of floats.  The outer list is indexed by group.\n        The inner list is the probability assigned by the model to categorical\n        observations for that group.  By default, all such probabilities are returned.\n        If `focal_choice` is provided, then a restricted set of choice probabilities are\n        provided.\n    \"\"\"", "\n", "\n", "J", ",", "M", ",", "K", ",", "Ns", "=", "data_dimensions_from_hierarchical_dataset", "(", "data", ")", "\n", "\n", "choice_probs", "=", "[", "None", "]", "*", "J", "\n", "for", "j", "in", "range", "(", "J", ")", ":", "\n", "        ", "labels_j", "=", "data", ".", "datasets", "[", "j", "]", ".", "labels", "\n", "choices_j", "=", "np", ".", "argmax", "(", "labels_j", ",", "1", ")", "# index of selected category", "\n", "\n", "features_j", "=", "data", ".", "datasets", "[", "j", "]", ".", "features", "\n", "beta_expected_j", "=", "variational_params", ".", "beta_means", "[", "j", ",", ":", ",", ":", "]", "\n", "\n", "category_probs_j", "=", "construct_category_probs", "(", "\n", "features_j", ",", "beta_expected_j", ",", "Link", ".", "CBM_PROBIT", "\n", ")", "\n", "choice_probs_j", "=", "[", "\n", "category_probs_j", "[", "i", ",", "choice", "]", "for", "(", "i", ",", "choice", ")", "in", "enumerate", "(", "choices_j", ")", "\n", "]", "\n", "if", "focal_choice", "is", "not", "None", ":", "\n", "            ", "choice_probs_j_filtered", "=", "list", "(", "\n", "np", ".", "array", "(", "choice_probs_j", ")", "[", "choices_j", "==", "focal_choice", "]", "\n", ")", "\n", "choice_probs", "[", "j", "]", "=", "choice_probs_j_filtered", "\n", "", "else", ":", "\n", "            ", "choice_probs", "[", "j", "]", "=", "choice_probs_j", "\n", "", "", "return", "choice_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.hierarchical_multiclass.evaluate_variational_model_for_hierarchical_multiclass_regression": [[139, 181], ["warnings.warn", "categorical_from_binary.ib_cavi.multi.hierarchical_ib_probit.inference.data_dimensions_from_hierarchical_dataset", "print", "range", "print", "numpy.argmax", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_category_probs", "print", "choice_probs_all.extend", "numpy.mean", "enumerate", "numpy.mean", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.structs.data_dimensions_from_hierarchical_dataset", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs"], ["", "def", "evaluate_variational_model_for_hierarchical_multiclass_regression", "(", "\n", "variational_params", ":", "VariationalParams", ",", "\n", "data", ":", "HierarchicalMulticlassRegressionDataset", ",", "\n", ")", ":", "\n", "    ", "warnings", ".", "warn", "(", "\n", "f\"We are currently using the expected beta instead of the posterior predictive \"", "\n", "f\"when computing category probabilities with the variational approximation.\"", "\n", ")", "\n", "\n", "# TODO: Improve this to use the posterior predictive.", "\n", "\n", "J", ",", "M", ",", "K", ",", "Ns", "=", "data_dimensions_from_hierarchical_dataset", "(", "data", ")", "\n", "\n", "choice_probs_all", "=", "[", "]", "\n", "\n", "print", "(", "\n", "f\"\\n\\nNum groups: {J}, mean number of observations per group: {np.mean(Ns):.03}, \"", "\n", "f\"num categories: {K}, num designed features: {M} \\n\"", "\n", ")", "\n", "\n", "for", "j", "in", "range", "(", "J", ")", ":", "\n", "        ", "labels_j", "=", "data", ".", "datasets", "[", "j", "]", ".", "labels", "\n", "choices_j", "=", "np", ".", "argmax", "(", "labels_j", ",", "1", ")", "# index of selected category", "\n", "\n", "features_j", "=", "data", ".", "datasets", "[", "j", "]", ".", "features", "\n", "beta_expected_j", "=", "variational_params", ".", "beta_means", "[", "j", ",", ":", ",", ":", "]", "\n", "\n", "category_probs_j", "=", "construct_category_probs", "(", "\n", "features_j", ",", "beta_expected_j", ",", "Link", ".", "CBC_PROBIT", "\n", ")", "\n", "choice_probs_j", "=", "[", "\n", "category_probs_j", "[", "i", ",", "choice", "]", "for", "(", "i", ",", "choice", ")", "in", "enumerate", "(", "choices_j", ")", "\n", "]", "\n", "print", "(", "\n", "f\"The variational model's mean choice probability for group {j}/{J} \"", "\n", "f\"is {np.mean(choice_probs_j):.03}\"", "\n", ")", "\n", "\n", "choice_probs_all", ".", "extend", "(", "choice_probs_j", ")", "\n", "\n", "", "print", "(", "\n", "f\"\\nThe variational model's overall mean choice probability (across groups) \"", "\n", "f\"is {np.mean(choice_probs_all):.03}\"", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.multiclass.get_sklearn_category_probabilities": [[15, 40], ["sklearn.linear_model.LogisticRegression().fit", "LogisticRegression().fit.predict_proba", "numpy.nonzero", "sklearn.linear_model.LogisticRegression"], "function", ["None"], ["def", "get_sklearn_category_probabilities", "(", "\n", "features", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray1D", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    We use these to compare quality of models.\n    sklearn doesn't hardcode the beta for the last category to be 0\n    (not sure how it gets away with this.  mean overparametrization?)\n\n    However, we CAN compare the category probabilities instead.\n    \"\"\"", "\n", "# sklearn doesn't want the all-ones column", "\n", "features_without_all_ones_column", "=", "features", "[", ":", ",", "1", ":", "]", "\n", "choices", "=", "np", ".", "nonzero", "(", "labels", ")", "[", "1", "]", "# labels (one-hot-encoded) as class indicators", "\n", "lr", "=", "LogisticRegression", "(", "random_state", "=", "0", ",", "**", "kwargs", ")", ".", "fit", "(", "\n", "features_without_all_ones_column", ",", "\n", "choices", ",", "\n", ")", "\n", "# sklearn_betas = np.transpose(np.hstack((lr.intercept_[:, np.newaxis], lr.coef_)))", "\n", "# sklearn_betas has shape (n_features+1, n_categories)", "\n", "# ugh, hard to compare because sklearn doesn't hardcode the beta for hte last category to be 0.  wtf. how does it do this?", "\n", "# we could perhaps compare the predicted probabilities", "\n", "sklearn_category_probs", "=", "lr", ".", "predict_proba", "(", "features_without_all_ones_column", ")", "\n", "return", "sklearn_category_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.multiclass.compute_choice_probs_for_multiclass_regression": [[42, 54], ["numpy.argmax", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_category_probs", "enumerate"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs"], ["", "def", "compute_choice_probs_for_multiclass_regression", "(", "\n", "features", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray2D", ",", "\n", "beta_expected", ":", "NumpyArray2D", ",", "\n", "link_for_category_probabilities", ":", "Link", ",", "\n", ")", "->", "float", ":", "\n", "# `choices` converts one-hot encoded representation to index of selected category", "\n", "    ", "choices", "=", "np", ".", "argmax", "(", "labels", ",", "1", ")", "\n", "category_probs", "=", "construct_category_probs", "(", "\n", "features", ",", "beta_expected", ",", "link_for_category_probabilities", "\n", ")", "\n", "return", "[", "category_probs", "[", "i", ",", "choice", "]", "for", "(", "i", ",", "choice", ")", "in", "enumerate", "(", "choices", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.multiclass.compute_mean_likelihood_for_multiclass_regression": [[68, 82], ["multiclass.compute_metric_for_multiclass_regression"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.multiclass.compute_metric_for_multiclass_regression"], ["def", "compute_mean_likelihood_for_multiclass_regression", "(", "\n", "features", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray2D", ",", "\n", "beta_expected", ":", "NumpyArray2D", ",", "\n", "link_for_category_probabilities", ":", "Link", ",", "\n", "focal_choice", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", "->", "float", ":", "\n", "    ", "return", "compute_metric_for_multiclass_regression", "(", "\n", "features", ",", "\n", "labels", ",", "\n", "beta_expected", ",", "\n", "link_for_category_probabilities", ",", "\n", "Metric", ".", "MEAN_LIKELIHOOD", ",", "\n", "focal_choice", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.multiclass.compute_mean_log_likelihood_for_multiclass_regression": [[85, 99], ["multiclass.compute_metric_for_multiclass_regression"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.multiclass.compute_metric_for_multiclass_regression"], ["", "def", "compute_mean_log_likelihood_for_multiclass_regression", "(", "\n", "features", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray2D", ",", "\n", "beta_expected", ":", "NumpyArray2D", ",", "\n", "link_for_category_probabilities", ":", "Link", ",", "\n", "focal_choice", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", "->", "float", ":", "\n", "    ", "return", "compute_metric_for_multiclass_regression", "(", "\n", "features", ",", "\n", "labels", ",", "\n", "beta_expected", ",", "\n", "link_for_category_probabilities", ",", "\n", "Metric", ".", "MEAN_LOG_LIKELIHOOD", ",", "\n", "focal_choice", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.multiclass.compute_metric_for_multiclass_regression": [[102, 136], ["numpy.argmax", "multiclass.compute_choice_probs_for_multiclass_regression", "functional", "list", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_category_probs", "numpy.mean", "ValueError", "numpy.array", "numpy.argmax", "numpy.where"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.multiclass.compute_choice_probs_for_multiclass_regression", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_category_probs"], ["", "def", "compute_metric_for_multiclass_regression", "(", "\n", "features", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray2D", ",", "\n", "beta_expected", ":", "NumpyArray2D", ",", "\n", "link_for_category_probabilities", ":", "Link", ",", "\n", "metric", ":", "Metric", ",", "\n", "focal_choice", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        focal_choice:\n            Optional.  If present, only return the mean choice probs for only when the label was\n            the `focal_choice`.  Only relevant for Metric. MEAN_LOG_LIKELIHOOD and Metric.MEAN_LIKELIHOOD\n    \"\"\"", "\n", "# `choices` converts one-hot encoded representation to index of selected category", "\n", "if", "metric", "==", "Metric", ".", "MEAN_LIKELIHOOD", "or", "metric", "==", "Metric", ".", "MEAN_LOG_LIKELIHOOD", ":", "\n", "        ", "choices", "=", "np", ".", "argmax", "(", "labels", ",", "1", ")", "\n", "choice_probs", "=", "compute_choice_probs_for_multiclass_regression", "(", "\n", "features", ",", "labels", ",", "beta_expected", ",", "link_for_category_probabilities", "\n", ")", "\n", "if", "focal_choice", "is", "not", "None", ":", "\n", "            ", "choice_probs_to_use", "=", "list", "(", "np", ".", "array", "(", "choice_probs", ")", "[", "choices", "==", "focal_choice", "]", ")", "\n", "", "else", ":", "\n", "            ", "choice_probs_to_use", "=", "choice_probs", "\n", "\n", "", "functional", "=", "EVALUATION_FUNCTIONAL_BY_METRIC_FOR_SOME_METRICS", "[", "metric", "]", "\n", "return", "functional", "(", "choice_probs_to_use", ")", "\n", "", "elif", "metric", "==", "Metric", ".", "MISCLASSIFICATION_RATE", ":", "\n", "        ", "category_probs", "=", "construct_category_probs", "(", "\n", "features", ",", "beta_expected", ",", "link_for_category_probabilities", "\n", ")", "\n", "return", "np", ".", "mean", "(", "np", ".", "argmax", "(", "category_probs", ",", "1", ")", "!=", "np", ".", "where", "(", "labels", ")", "[", "1", "]", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Not sure how to handle metric {metric}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.multiclass.evaluate_multiclass_regression_with_beta_estimate": [[143, 172], ["multiclass.compute_metric_for_multiclass_regression", "print"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.multiclass.compute_metric_for_multiclass_regression"], ["", "def", "evaluate_multiclass_regression_with_beta_estimate", "(", "\n", "features", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray2D", ",", "\n", "beta_estimate", ":", "NumpyArray2D", ",", "\n", "link_for_category_probabilities", ":", "Link", ",", "\n", "metric", ":", "Metric", ",", "\n", "verbose", ":", "bool", "=", "True", ",", "\n", "beta_type", ":", "BetaType", "=", "BetaType", ".", "VARIATIONAL_POSTERIOR_MEAN", ",", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        link_for_category_probabilities: Link function of the ***variational model***; the link function of the data\n            generating process could be different\n    \"\"\"", "\n", "# TODO: Improve this to use the posterior predictive.", "\n", "metric_variational_model", "=", "compute_metric_for_multiclass_regression", "(", "\n", "features", ",", "\n", "labels", ",", "\n", "beta_estimate", ",", "\n", "link_for_category_probabilities", ",", "\n", "metric", ",", "\n", ")", "\n", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\n", "f\"The {metric} from plugging the {beta_type} beta  \"", "\n", "f\"into the category probabilities of {link_for_category_probabilities} is {metric_variational_model:.03}\"", "\n", ")", "\n", "", "return", "metric_variational_model", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.multiclass.evaluate_sklearn_on_multiclass_regression": [[174, 206], ["numpy.argmax", "multiclass.get_sklearn_category_probabilities", "functional", "print", "enumerate"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.multiclass.get_sklearn_category_probabilities"], ["", "def", "evaluate_sklearn_on_multiclass_regression", "(", "\n", "features", ":", "NumpyArray2D", ",", "\n", "labels", ":", "NumpyArray2D", ",", "\n", "metric", ":", "Metric", ",", "\n", "verbose", ":", "bool", "=", "True", ",", "\n", "**", "kwargs_for_sklearn", ",", "\n", ")", "->", "float", ":", "\n", "\n", "    ", "if", "(", "\n", "not", "metric", "==", "Metric", ".", "MEAN_LIKELIHOOD", "\n", "and", "not", "metric", "==", "Metric", ".", "MEAN_LOG_LIKELIHOOD", "\n", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "# TODO: This block of code violates DRY; this logic is already written up elsewhere; call it here.", "\n", "", "choices", "=", "np", ".", "argmax", "(", "\n", "labels", ",", "1", "\n", ")", "# converts one-hot encoded representation to index of selected category", "\n", "\n", "category_probs_sklearn", "=", "get_sklearn_category_probabilities", "(", "\n", "features", ",", "labels", ",", "**", "kwargs_for_sklearn", "\n", ")", "\n", "category_probs_of_choices_sklearn", "=", "[", "\n", "category_probs_sklearn", "[", "i", ",", "choice", "]", "for", "(", "i", ",", "choice", ")", "in", "enumerate", "(", "choices", ")", "\n", "]", "\n", "\n", "functional", "=", "EVALUATION_FUNCTIONAL_BY_METRIC_FOR_SOME_METRICS", "[", "metric", "]", "\n", "metric_sklearn", "=", "functional", "(", "category_probs_of_choices_sklearn", ")", "\n", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "f\"The {metric} for the sklearn model is {metric_sklearn:.03}\"", ")", "\n", "", "return", "metric_sklearn", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.multiclass.take_measurements_comparing_CBM_and_CBC_estimators": [[227, 339], ["dataset_parts.items", "print", "print", "multiclass.evaluate_multiclass_regression_with_beta_estimate", "measurements.append", "multiclass.evaluate_multiclass_regression_with_beta_estimate", "measurements.append", "multiclass.evaluate_multiclass_regression_with_beta_estimate", "measurements.append", "multiclass.Measurement", "multiclass.Measurement", "multiclass.evaluate_sklearn_on_multiclass_regression", "multiclass.Measurement", "multiclass.MeasurementContext", "multiclass.MeasurementContext", "multiclass.MeasurementContext"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.multiclass.evaluate_multiclass_regression_with_beta_estimate", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.multiclass.evaluate_multiclass_regression_with_beta_estimate", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.multiclass.evaluate_multiclass_regression_with_beta_estimate", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.multiclass.evaluate_sklearn_on_multiclass_regression"], ["", "def", "take_measurements_comparing_CBM_and_CBC_estimators", "(", "\n", "split_dataset", ":", "SplitDataset", ",", "\n", "beta_mean", ":", "NumpyArray2D", ",", "\n", "link_for_generating_data", ":", "Optional", "[", "Link", "]", "=", "None", ",", "\n", "beta_ground_truth", ":", "Optional", "[", "NumpyArray2D", "]", "=", "None", ",", "\n", "compare_to_sklearn", ":", "bool", "=", "False", ",", "\n", "verbose", ":", "bool", "=", "True", ",", "\n", "**", "kwargs_for_sklearn", ",", "\n", ")", "->", "List", "[", "Measurement", "]", ":", "\n", "    ", "\"\"\"\n    The CBM estimator is the Categorical From Binary via Marginalization estimator (see arxiv paper)\n    The CBC estimator is the Categorical From Binary via Conditioning estimator (see arxiv paper)\n    \"\"\"", "\n", "\n", "dataset_parts", "=", "{", "\n", "DataType", ".", "TRAIN", ":", "(", "split_dataset", ".", "covariates_train", ",", "split_dataset", ".", "labels_train", ")", ",", "\n", "DataType", ".", "TEST", ":", "(", "split_dataset", ".", "covariates_test", ",", "split_dataset", ".", "labels_test", ")", ",", "\n", "}", "\n", "\n", "measurements", "=", "[", "]", "\n", "for", "data_type", ",", "(", "covariates", ",", "labels", ")", "in", "dataset_parts", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "f\"\\n\\n---Now running evaluations on {data_type} data---\"", ")", "\n", "for", "metric", "in", "Metric", ":", "\n", "            ", "print", "(", "f\"\"", ")", "\n", "# first compute ground truth, if one is provided", "\n", "if", "beta_ground_truth", "is", "not", "None", ":", "\n", "                ", "beta_type", "=", "BetaType", ".", "GROUND_TRUTH", "\n", "link_for_category_probabilities", "=", "link_for_generating_data", "\n", "metric_value", "=", "evaluate_multiclass_regression_with_beta_estimate", "(", "\n", "covariates", ",", "\n", "labels", ",", "\n", "beta_ground_truth", ",", "\n", "link_for_category_probabilities", ",", "\n", "metric", "=", "metric", ",", "\n", "beta_type", "=", "beta_type", ",", "\n", ")", "\n", "\n", "measurements", ".", "append", "(", "\n", "Measurement", "(", "\n", "metric_value", ",", "\n", "MeasurementContext", "(", "\n", "metric", ",", "\n", "beta_type", ",", "\n", "link_for_category_probabilities", ",", "\n", "link_for_generating_data", ",", "\n", "data_type", ",", "\n", "other_info", "=", "\"\"", ",", "\n", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "# now compute metrics with the variational approximations, using different constructions for the", "\n", "# category probabilities", "\n", "", "beta_type", "=", "BetaType", ".", "VARIATIONAL_POSTERIOR_MEAN", "\n", "link_for_category_probabilities", "=", "Link", ".", "CBC_PROBIT", "\n", "\n", "metric_value", "=", "evaluate_multiclass_regression_with_beta_estimate", "(", "\n", "covariates", ",", "\n", "labels", ",", "\n", "beta_mean", ",", "\n", "link_for_category_probabilities", ",", "\n", "metric", "=", "metric", ",", "\n", "beta_type", "=", "beta_type", ",", "\n", "verbose", "=", "verbose", ",", "\n", ")", "\n", "measurements", ".", "append", "(", "\n", "Measurement", "(", "\n", "metric_value", ",", "\n", "MeasurementContext", "(", "\n", "metric", ",", "\n", "beta_type", ",", "\n", "link_for_category_probabilities", ",", "\n", "link_for_generating_data", ",", "\n", "data_type", ",", "\n", "other_info", "=", "\"\"", ",", "\n", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "# TODO: need to compute the actual posterior predictive for this;", "\n", "# i.e. integrate over our uncertainty about model parameters.", "\n", "link_for_category_probabilities", "=", "Link", ".", "CBM_PROBIT", "\n", "metric_value", "=", "evaluate_multiclass_regression_with_beta_estimate", "(", "\n", "covariates", ",", "\n", "labels", ",", "\n", "beta_mean", ",", "\n", "link_for_category_probabilities", ",", "\n", "metric", "=", "metric", ",", "\n", "beta_type", "=", "beta_type", ",", "\n", "verbose", "=", "verbose", ",", "\n", ")", "\n", "measurements", ".", "append", "(", "\n", "Measurement", "(", "\n", "metric_value", ",", "\n", "MeasurementContext", "(", "\n", "metric", ",", "\n", "beta_type", ",", "\n", "link_for_category_probabilities", ",", "\n", "link_for_generating_data", ",", "\n", "data_type", ",", "\n", "other_info", "=", "\"\"", ",", "\n", ")", ",", "\n", ")", "\n", ")", "\n", "\n", "if", "compare_to_sklearn", ":", "\n", "# TODO: we don't currently create `measurements` for sklearn; just printouts.", "\n", "                ", "evaluate_sklearn_on_multiclass_regression", "(", "\n", "covariates", ",", "labels", ",", "metric", ",", "verbose", ",", "**", "kwargs_for_sklearn", "\n", ")", "\n", "\n", "", "", "", "return", "measurements", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.multiclass.form_dict_mapping_measurement_context_to_values": [[341, 361], ["list", "set", "list", "filter"], "function", ["None"], ["", "def", "form_dict_mapping_measurement_context_to_values", "(", "\n", "measurements", ":", "List", "[", "Measurement", "]", ",", "\n", ")", "->", "Dict", "[", "MeasurementContext", ",", "List", "[", "float", "]", "]", ":", "\n", "    ", "\"\"\"\n    given a set of measurements, find the set of unique measurement contexts,\n    and collect all the values for that measurement context into a list\n    \"\"\"", "\n", "contexts", "=", "[", "m", ".", "context", "for", "m", "in", "measurements", "]", "\n", "context_space", "=", "list", "(", "set", "(", "contexts", ")", ")", "\n", "\n", "measurement_context_to_values", "=", "{", "}", "\n", "\n", "for", "context", "in", "context_space", ":", "\n", "        ", "measurements_filtered", "=", "list", "(", "\n", "filter", "(", "lambda", "x", ":", "x", ".", "context", "==", "context", ",", "measurements", ")", "\n", ")", "\n", "values", "=", "[", "m", ".", "value", "for", "m", "in", "measurements_filtered", "]", "\n", "measurement_context_to_values", "[", "context", "]", "=", "values", "\n", "\n", "", "return", "measurement_context_to_values", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.jax_helpers.compute_softmax_predictions": [[13, 28], ["jax.shape", "jax.sum", "jax.array", "jax.array", "jax.exp", "range", "jax.exp", "range"], "function", ["None"], ["def", "compute_softmax_predictions", "(", "beta", ":", "jnp", ".", "array", ",", "X", ":", "jnp", ".", "array", ")", "->", "jnp", ".", "array", ":", "\n", "    ", "\"\"\"\n    Note: This computation is not the identifiable one used during simulation.\n\n    Arguments:\n        beta: MxK\n        X: NxM\n    Returns:\n        probs: NxK\n    \"\"\"", "\n", "M", ",", "K", "=", "jnp", ".", "shape", "(", "beta", ")", "\n", "etas", "=", "X", "@", "beta", "# N times K", "\n", "\n", "Z", "=", "jnp", ".", "sum", "(", "jnp", ".", "array", "(", "[", "jnp", ".", "exp", "(", "etas", "[", ":", ",", "k", "]", ")", "for", "k", "in", "range", "(", "K", ")", "]", ")", ",", "0", ")", "\n", "return", "jnp", ".", "array", "(", "[", "jnp", ".", "exp", "(", "etas", "[", ":", ",", "k", "]", ")", "/", "Z", "for", "k", "in", "range", "(", "K", ")", "]", ")", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.jax_helpers.compute_CBM_Probit_predictions": [[30, 49], ["jax.shape", "jax.sum", "jax.array", "jax.array", "numpy.copy", "jax.scipy.stats.norm.cdf", "range", "jax.scipy.stats.norm.cdf", "range"], "function", ["None"], ["", "def", "compute_CBM_Probit_predictions", "(", "\n", "beta", ":", "jnp", ".", "array", ",", "X", ":", "jnp", ".", "array", ",", "return_numpy", ":", "bool", "=", "False", "\n", ")", "->", "jnp", ".", "array", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        beta: MxK\n        X: NxM\n    Returns:\n        probs: NxK\n    \"\"\"", "\n", "M", ",", "K", "=", "jnp", ".", "shape", "(", "beta", ")", "\n", "etas", "=", "X", "@", "beta", "# N times K", "\n", "\n", "Z", "=", "jnp", ".", "sum", "(", "jnp", ".", "array", "(", "[", "jcdf", "(", "etas", "[", ":", ",", "k", "]", ")", "for", "k", "in", "range", "(", "K", ")", "]", ")", ",", "0", ")", "\n", "CBM_predictions", "=", "jnp", ".", "array", "(", "[", "jcdf", "(", "etas", "[", ":", ",", "k", "]", ")", "/", "Z", "for", "k", "in", "range", "(", "K", ")", "]", ")", ".", "T", "\n", "if", "return_numpy", ":", "\n", "        ", "return", "np", ".", "copy", "(", "CBM_predictions", ")", "\n", "", "else", ":", "\n", "        ", "return", "CBM_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.jax_helpers.compute_CBC_Probit_predictions": [[51, 73], ["jax.shape", "jax.sum", "jax.scipy.stats.norm.cdf", "numpy.copy", "jax.scipy.stats.norm.cdf"], "function", ["None"], ["", "", "def", "compute_CBC_Probit_predictions", "(", "\n", "beta", ":", "jnp", ".", "array", ",", "X", ":", "jnp", ".", "array", ",", "return_numpy", ":", "bool", "=", "False", "\n", ")", "->", "jnp", ".", "array", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        beta: MxK\n        X: NxM\n    Returns:\n        probs: NxK\n    \"\"\"", "\n", "EPSILON", "=", "1e-10", "\n", "\n", "M", ",", "K", "=", "jnp", ".", "shape", "(", "beta", ")", "\n", "etas", "=", "X", "@", "beta", "# N times K", "\n", "# Add epsilon to avoid psi taking the form of 1/0.", "\n", "psis", "=", "jcdf", "(", "etas", ")", "/", "(", "jcdf", "(", "-", "etas", ")", "+", "EPSILON", ")", "\n", "Z", "=", "jnp", ".", "sum", "(", "psis", ",", "1", ")", "\n", "CBC_predictions", "=", "(", "psis", ".", "T", "/", "Z", ")", ".", "T", "\n", "if", "return_numpy", ":", "\n", "        ", "return", "np", ".", "copy", "(", "CBC_predictions", ")", "\n", "", "else", ":", "\n", "        ", "return", "CBC_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.jax_helpers.compute_IB_Probit_predictions": [[75, 87], ["jax.shape", "jax.array", "jax.scipy.stats.norm.cdf", "range"], "function", ["None"], ["", "", "def", "compute_IB_Probit_predictions", "(", "beta", ":", "jnp", ".", "array", ",", "X", ":", "jnp", ".", "array", ")", "->", "jnp", ".", "array", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        beta: MxK\n        X: NxM\n    Returns:\n        probs: NxK\n    \"\"\"", "\n", "M", ",", "K", "=", "jnp", ".", "shape", "(", "beta", ")", "\n", "etas", "=", "X", "@", "beta", "# N times K", "\n", "\n", "return", "jnp", ".", "array", "(", "[", "jcdf", "(", "etas", "[", ":", ",", "k", "]", ")", "for", "k", "in", "range", "(", "K", ")", "]", ")", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.jax_helpers.compute_training_loss": [[89, 109], ["category_probability_function", "jax.mean", "jax.mean", "jax.log", "jax.log"], "function", ["None"], ["", "def", "compute_training_loss", "(", "\n", "beta", ",", "X", ",", "y", ",", "category_probability_function", ":", "Callable", ",", "is_truly_categorical", ":", "bool", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        beta: MxK\n        X: NxM\n        y: NxK (one-hot encoded)\n        category_probability_function: Callable\n            arguments are beta and X, returns NxK category probabilities\n        is_truly_categorical : bool\n            this is fully determined by the category probability function\n            this determines how the training loss is computed\n    \"\"\"", "\n", "preds", "=", "category_probability_function", "(", "beta", ",", "X", ")", "\n", "if", "is_truly_categorical", ":", "\n", "        ", "return", "-", "jnp", ".", "mean", "(", "jnp", ".", "log", "(", "preds", "[", "y", "==", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "binary_probs", "=", "preds", "*", "y", "+", "(", "1", "-", "preds", ")", "*", "(", "1", "-", "y", ")", "\n", "return", "-", "jnp", ".", "mean", "(", "jnp", ".", "log", "(", "binary_probs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.jax_helpers.compute_training_loss_with_beta_flattened": [[111, 142], ["jax.reshape", "jax_helpers.compute_training_loss"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.jax_helpers.compute_training_loss"], ["", "", "def", "compute_training_loss_with_beta_flattened", "(", "\n", "beta_flattened", ",", "\n", "M", ":", "int", ",", "\n", "K", ":", "int", ",", "\n", "X", ",", "\n", "y", ",", "\n", "category_probability_function", ":", "Callable", ",", "\n", "is_truly_categorical", ":", "bool", ",", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        beta_flattened: (MxK, 1)\n            This can be taken to be the result of taking (M,K) beta array called `beta` upon which is performed\n            jnp.ravel(beta). This produces a (MxK, 1) beta array which is flattened by rows (i.e. the entire first\n            row is followed by the entire second row, and so forth).  We use beta_flattened instead of the beta matrix\n            because jax's scipy.optimize requires the ijnput to be a 1D array\n        M: first dimension for beta once we \"unflatten\" beta_flattened\n        K: first dimension for beta once we \"unflatten\" beta_flattened\n        X: NxM\n        y: NxK (one-hot encoded)\n        category_probability_function: Callable\n            arguments are beta and X, returns NxK category probabilities\n        is_truly_categorical : bool\n            this is fully determined by the category probability function\n            this determines how the training loss is computed\n    Returns:\n        probs: NxK\n    \"\"\"", "\n", "beta", "=", "jnp", ".", "reshape", "(", "beta_flattened", ",", "(", "M", ",", "K", ")", ")", "\n", "return", "compute_training_loss", "(", "\n", "beta", ",", "X", ",", "y", ",", "category_probability_function", ",", "is_truly_categorical", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.jax_helpers.optimize_beta_and_return_beta_star_and_loss": [[145, 191], ["jax.shape", "jax.ravel", "jax.scipy.optimize.minimize", "jax.scipy.optimize.minimize.fun.tolist", "jax.reshape", "print", "print", "print", "print", "numpy.array", "jax_helpers.compute_training_loss", "jax_helpers.compute_training_loss", "category_probability_function", "category_probability_function"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.jax_helpers.compute_training_loss", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.jax_helpers.compute_training_loss"], ["", "def", "optimize_beta_and_return_beta_star_and_loss", "(", "\n", "beta", ":", "jnp", ".", "array", ",", "\n", "X", ":", "jnp", ".", "array", ",", "\n", "y", ":", "jnp", ".", "array", ",", "\n", "category_probability_function", ":", "Callable", ",", "\n", "is_truly_categorical", ":", "bool", ",", "\n", "verbose", ":", "bool", "=", "True", ",", "\n", ")", "->", "Tuple", "[", "np", ".", "array", ",", "float", "]", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        beta: MxK\n        X: NxM\n        y: NxK (one-hot encoded)\n        category_probability_function: Callable\n            arguments are beta and X, returns NxK category probabilities\n    \"\"\"", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\n", "f\"Inital training loss:{compute_training_loss(beta, X, y, category_probability_function, is_truly_categorical)} \"", "\n", ")", "\n", "print", "(", "\n", "f\"Initial predictions (first five samples):{category_probability_function(beta,X)[:5]}\"", "\n", ")", "\n", "\n", "", "M", ",", "K", "=", "jnp", ".", "shape", "(", "beta", ")", "\n", "beta_flattened", "=", "jnp", ".", "ravel", "(", "beta", ")", "\n", "\n", "result", "=", "minimize", "(", "\n", "compute_training_loss_with_beta_flattened", ",", "\n", "beta_flattened", ",", "\n", "args", "=", "(", "M", ",", "K", ",", "X", ",", "y", ",", "category_probability_function", ",", "is_truly_categorical", ")", ",", "\n", "method", "=", "\"BFGS\"", ",", "\n", ")", "\n", "train_loss", "=", "result", ".", "fun", ".", "tolist", "(", ")", "\n", "beta_star_flattened", "=", "result", ".", "x", "\n", "beta_star", "=", "jnp", ".", "reshape", "(", "beta_star_flattened", ",", "(", "M", ",", "K", ")", ")", "\n", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\n", "f\"New training loss: {compute_training_loss(beta_star, X, y, category_probability_function, is_truly_categorical)}\"", "\n", ")", "\n", "print", "(", "\n", "f\"New predictions (first five samples):{category_probability_function(beta_star,X)[:5]}\"", "\n", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "beta_star", ")", ",", "train_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.jax_helpers.optimize_beta": [[193, 213], ["jax_helpers.optimize_beta_and_return_beta_star_and_loss"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.jax_helpers.optimize_beta_and_return_beta_star_and_loss"], ["", "def", "optimize_beta", "(", "\n", "beta", ":", "jnp", ".", "array", ",", "\n", "X", ":", "jnp", ".", "array", ",", "\n", "y", ":", "jnp", ".", "array", ",", "\n", "category_probability_function", ":", "Callable", ",", "\n", "is_truly_categorical", ":", "bool", ",", "\n", "verbose", ":", "bool", "=", "True", ",", "\n", ")", "->", "np", ".", "array", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        beta: MxK\n        X: NxM\n        y: NxK (one-hot encoded)\n        category_probability_function: Callable\n            arguments are beta and X, returns NxK category probabilities\n    \"\"\"", "\n", "beta_star", ",", "loss", "=", "optimize_beta_and_return_beta_star_and_loss", "(", "\n", "beta", ",", "X", ",", "y", ",", "category_probability_function", ",", "is_truly_categorical", ",", "verbose", "\n", ")", "\n", "return", "beta_star", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.autodiff.simplex_distances.compute_mean_l1_distance": [[6, 25], ["numpy.shape", "numpy.shape", "ValueError", "numpy.sum", "numpy.abs"], "function", ["None"], ["def", "compute_mean_l1_distance", "(", "\n", "discrete_probs_1", ":", "NumpyArray2D", ",", "discrete_probs_2", ":", "NumpyArray2D", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Compute the mean l1 norm.  Note the l1 norm is double the total variation distance.\n\n    Arguments:\n        discrete_probs_1: array with shape (N,K) where N is the number of samples and K is the\n            number of categories\n        discrete_probs_2: array with shape (N,K) where N is the number of samples and K is the\n            number of categories\n    \"\"\"", "\n", "N", ",", "K", "=", "np", ".", "shape", "(", "discrete_probs_1", ")", "\n", "N2", ",", "K2", "=", "np", ".", "shape", "(", "discrete_probs_2", ")", "\n", "\n", "if", "not", "N", "==", "N2", "and", "K", "==", "K2", ":", "\n", "        ", "raise", "ValueError", "(", "\"Dimensionalities of discrete probability arrays must match\"", ")", "\n", "\n", "", "return", "np", ".", "sum", "(", "np", ".", "abs", "(", "discrete_probs_1", "-", "discrete_probs_2", ")", ")", "/", "N", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.compute_CBC_probit_probabilities_using_jax": [[45, 93], ["jax.exp", "jax.clip", "jax.sum", "log_cdf", "log_cdf", "jax.sum"], "function", ["None"], ["verbose", ":", "bool", "=", "True", ",", "\n", ")", "->", "CAVI_Results", ":", "\n", "    ", "if", "ib_model", "is", "IB_Model", ".", "PROBIT", ":", "\n", "        ", "inference_function", "=", "compute_multiclass_probit_vi_with_normal_prior", "\n", "", "elif", "ib_model", "is", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "inference_function", "=", "compute_multiclass_logit_vi_with_polya_gamma_augmentation", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"I don't understand the model type {ib_model}\"", ")", "\n", "", "return", "inference_function", "(", "\n", "labels", ",", "\n", "covariates", ",", "\n", "max_n_iterations", ",", "\n", "convergence_criterion_drop_in_mean_elbo", ",", "\n", "use_autoregressive_design_matrix", ",", "\n", "labels_test", ",", "\n", "covariates_test", ",", "\n", "prior_beta_mean", ",", "\n", "prior_beta_precision", ",", "\n", "variational_params_init", ",", "\n", "save_beta_every_secs", ",", "\n", "save_beta_dir", ",", "\n", "verbose", ",", "\n", ")", "\n", "\n", "\n", "", "def", "cbm_link_from_ib_model", "(", "ib_model", ":", "IB_Model", ")", ":", "\n", "    ", "if", "ib_model", "==", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "return", "Link", ".", "CBM_LOGIT", "\n", "", "elif", "ib_model", "==", "IB_Model", ".", "PROBIT", ":", "\n", "        ", "return", "Link", ".", "CBM_PROBIT", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "\n", "\n", "\n", "", "", "def", "cbc_link_from_ib_model", "(", "ib_model", ":", "IB_Model", ")", ":", "\n", "    ", "if", "ib_model", "==", "IB_Model", ".", "LOGIT", ":", "\n", "        ", "return", "Link", ".", "CBC_LOGIT", "\n", "", "elif", "ib_model", "==", "IB_Model", ".", "PROBIT", ":", "\n", "        ", "return", "Link", ".", "CBC_PROBIT", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.compute_linear_predictors_preventing_downstream_overflow": [[95, 108], ["jax.clip"], "function", ["None"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.construct_jax_softmax_probabilities": [[111, 131], ["numpy.shape", "inference.compute_linear_predictors_preventing_downstream_overflow", "jax.sum", "jax.array", "jax.array", "jax.exp", "range", "jax.exp", "range"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.compute_linear_predictors_preventing_downstream_overflow"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.construct_multi_probit_probabilities": [[133, 197], ["warnings.warn", "jax.random.PRNGKey", "jax.random.PRNGKey", "inference.compute_linear_predictors_preventing_downstream_overflow", "jax.zeros", "range", "numpy.shape", "numpy.shape", "jax.random.split", "jax.random.split", "jax.random.normal", "jax.random.normal", "jax.argmax", "jax.nn.one_hot", "jax.nn.one_hot"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.compute_linear_predictors_preventing_downstream_overflow"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.get_P": [[213, 222], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.beta_matrix_from_vector": [[224, 238], ["beta_vector.reshape"], "function", ["None"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.standardize": [[240, 242], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.unstandardize": [[244, 246], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.sample_from_standard_gaussian_P_times_and_return_new_rng_key": [[248, 254], ["jax.random.split", "jax.random.split", "jax.random.normal", "jax.random.normal"], "function", ["None"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.compute_log_like": [[256, 274], ["inference.beta_matrix_from_vector", "function_to_make_cat_probs", "len", "jax.log().sum", "jax.arange", "jax.log"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.beta_matrix_from_vector"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.compute_log_prior": [[280, 284], ["jax.scipy.stats.norm.logpdf().sum", "jax.scipy.stats.norm.logpdf().sum", "jax.scipy.stats.norm.logpdf", "jax.scipy.stats.norm.logpdf"], "function", ["None"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.compute_log_joint": [[286, 296], ["inference.compute_log_like", "inference.compute_log_prior"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.compute_log_like", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.compute_log_prior"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.compute_grad_omegas_from_grad_log_joint": [[302, 324], ["jax.exp"], "function", ["None"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.initialize_emas_and_return_rng_key": [[332, 362], ["inference.get_P", "inference.sample_from_standard_gaussian_P_times_and_return_new_rng_key", "inference.unstandardize", "compute_grad_log_joint", "inference.compute_grad_omegas_from_grad_log_joint", "jax.exp"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.get_P", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.sample_from_standard_gaussian_P_times_and_return_new_rng_key", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.unstandardize", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.compute_grad_omegas_from_grad_log_joint"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.update_ewa_of_squared_gradients": [[364, 366], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.compute_step_size": [[368, 370], ["jax.sqrt"], "function", ["None"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.do_advi_inference_via_kucukelbir_algo": [[377, 571], ["jax.random.PRNGKey", "jax.random.PRNGKey", "scipy.sparse.isspmatrix", "scipy.sparse.isspmatrix", "scipy.sparse.isspmatrix", "scipy.sparse.isspmatrix", "jax.array", "jax.array", "inference.get_P", "len", "jax.zeros", "jax.zeros", "inference.initialize_emas_and_return_rng_key", "collections.defaultdict", "numpy.array", "categorical_from_binary.performance_over_time.results.update_performance_results", "print", "jax.arange", "inference.beta_matrix_from_vector", "inference.beta_matrix_from_vector", "pandas.DataFrame", "NotImplementedError", "warnings.warn", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.argmax", "inference.beta_matrix_from_vector", "time.time", "print", "sys.stdout.flush", "jax.isnan", "inference.sample_from_standard_gaussian_P_times_and_return_new_rng_key", "inference.unstandardize", "compute_grad_log_joint", "inference.update_ewa_of_squared_gradients", "inference.compute_step_size", "inference.compute_grad_omegas_from_grad_log_joint", "inference.update_ewa_of_squared_gradients", "inference.compute_step_size", "time.time", "jax.exp", "numpy.array", "numpy.array", "np.array.todense", "np.array.todense", "np.array.todense", "np.array.todense", "jax.exp", "numpy.array", "categorical_from_binary.performance_over_time.results.update_performance_results", "inference.beta_matrix_from_vector", "int", "inference.beta_matrix_from_vector", "inference.beta_matrix_from_vector", "categorical_from_binary.vi_params.write_VI_params_from_ADVI_means_and_stds", "jax.exp", "numpy.array", "numpy.array", "divmod"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.get_P", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.initialize_emas_and_return_rng_key", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.results.update_performance_results", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.beta_matrix_from_vector", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.beta_matrix_from_vector", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.beta_matrix_from_vector", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.sample_from_standard_gaussian_P_times_and_return_new_rng_key", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.unstandardize", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.update_ewa_of_squared_gradients", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.compute_step_size", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.compute_grad_omegas_from_grad_log_joint", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.update_ewa_of_squared_gradients", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.compute_step_size", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.results.update_performance_results", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.beta_matrix_from_vector", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.beta_matrix_from_vector", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.inference.beta_matrix_from_vector", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.vi_params.write_VI_params_from_ADVI_means_and_stds"], []], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.kucukelbir.plot_holdout_likelihoods.plot_performance_over_time_ADVI_vs_IB_CAVI": [[15, 63], ["perf_advi[].to_numpy", "perf_cavi[].to_numpy", "perf_advi[].to_numpy", "matplotlib.pyplot.plot", "matplotlib.pyplot.plot", "matplotlib.pyplot.legend", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.clf", "perf_cavi[].to_numpy", "perf_cavi[].to_numpy", "categorical_from_binary.io.ensure_dir", "metric_as_string.replace", "os.path.join", "matplotlib.pyplot.savefig", "matplotlib.pyplot.show"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.io.ensure_dir"], ["def", "plot_performance_over_time_ADVI_vs_IB_CAVI", "(", "\n", "df_performance_advi", ":", "DataFrame", ",", "\n", "df_performance_cavi", ":", "DataFrame", ",", "\n", "save_dir", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", "experiment_description_for_filename_postfix", ":", "Optional", "[", "str", "]", "=", "None", ",", "\n", ")", "->", "None", ":", "\n", "    ", "\"\"\"\n    Arguments:\n        df_performance_advi: One return value of the ADVI optimizer. A pandas Dataframe showing\n            holdout performance metrics over time.\n        df_performance_cavi: One return value of the IB_CAVI optimizer. A pandas Dataframe showing\n            holdout performance metrics over time.\n    \"\"\"", "\n", "\n", "# aliases", "\n", "perf_advi", "=", "df_performance_advi", "\n", "perf_cavi", "=", "df_performance_cavi", "\n", "\n", "# time", "\n", "secs_advi", "=", "perf_advi", "[", "\"seconds elapsed\"", "]", ".", "to_numpy", "(", ")", "\n", "secs_cavi", "=", "perf_cavi", "[", "\"seconds elapsed (cavi)\"", "]", ".", "to_numpy", "(", ")", "\n", "\n", "# function:", "\n", "for", "metric_as_string", "in", "[", "\n", "\"mean holdout log likelihood\"", ",", "\n", "\"mean holdout likelihood\"", ",", "\n", "\"correct classification rate\"", ",", "\n", "]", ":", "\n", "\n", "        ", "metric_advi", "=", "perf_advi", "[", "f\"{metric_as_string}\"", "]", ".", "to_numpy", "(", ")", "\n", "if", "metric_as_string", "==", "\"correct classification rate\"", ":", "\n", "            ", "metric_cavi", "=", "perf_cavi", "[", "f\"{metric_as_string}\"", "]", ".", "to_numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "metric_cavi", "=", "perf_cavi", "[", "f\"{metric_as_string} for CBC_PROBIT\"", "]", ".", "to_numpy", "(", ")", "\n", "", "plt", ".", "plot", "(", "secs_cavi", ",", "metric_cavi", ",", "linewidth", "=", "4", ")", "\n", "plt", ".", "plot", "(", "secs_advi", ",", "metric_advi", ",", "linewidth", "=", "4", ")", "\n", "plt", ".", "legend", "(", "[", "\"IB-CAVI\"", ",", "\"ADVI\"", "]", ",", "fontsize", "=", "16", ")", "\n", "plt", ".", "xlabel", "(", "\"Time (secs)\"", ",", "fontsize", "=", "16", ")", "\n", "plt", ".", "ylabel", "(", "f\"{metric_as_string}\"", ",", "fontsize", "=", "16", ")", "\n", "if", "save_dir", "is", "not", "None", ":", "\n", "            ", "ensure_dir", "(", "save_dir", ")", "\n", "metric_as_string_no_spaces", "=", "metric_as_string", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", "\n", "basename", "=", "f\"{metric_as_string_no_spaces}_{experiment_description_for_filename_postfix}.png\"", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "save_dir", ",", "basename", ")", "\n", "plt", ".", "savefig", "(", "filepath", ",", "bbox_inches", "=", "\"tight\"", ")", "\n", "", "else", ":", "\n", "            ", "plt", ".", "show", "(", ")", "\n", "", "plt", ".", "clf", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.fixtures.logistic_regression.logistic_regression_dataset": [[8, 11], ["pytest.fixture", "categorical_from_binary.data_generation.bayes_binary_reg.generate_logistic_regression_dataset"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.generate_logistic_regression_dataset"], ["@", "pytest", ".", "fixture", "(", ")", "\n", "def", "logistic_regression_dataset", "(", "n_samples", "=", "1000", ",", "n_features", "=", "5", ")", ":", "\n", "    ", "return", "generate_logistic_regression_dataset", "(", "n_samples", ",", "n_features", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.unit.test_util.test_compute_kl_mvn": [[12, 24], ["scipy.stats.multivariate_normal().rvs", "scipy.stats.wishart.rvs", "scipy.stats.multivariate_normal().rvs", "scipy.stats.wishart.rvs", "numpy.isclose", "numpy.isclose", "categorical_from_binary.kl.compute_kl_mvn", "categorical_from_binary.kl.compute_kl_mvn", "categorical_from_binary.kl.compute_kl_mvn", "categorical_from_binary.kl.compute_kl_mvn", "scipy.stats.multivariate_normal", "numpy.eye", "scipy.stats.multivariate_normal", "numpy.eye", "numpy.zeros", "numpy.zeros"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.compute_kl_mvn", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.compute_kl_mvn", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.compute_kl_mvn", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.compute_kl_mvn"], ["def", "test_compute_kl_mvn", "(", ")", ":", "\n", "# TODO: What else can I test about KL besides its non-negativity and 0 property?", "\n", "    ", "dim", ",", "df", "=", "2", ",", "3", "\n", "m0", "=", "scipy", ".", "stats", ".", "multivariate_normal", "(", "mean", "=", "np", ".", "zeros", "(", "dim", ")", ")", ".", "rvs", "(", "random_state", "=", "0", ")", "\n", "S0", "=", "scipy", ".", "stats", ".", "wishart", ".", "rvs", "(", "df", "=", "df", ",", "scale", "=", "np", ".", "eye", "(", "dim", ")", ",", "random_state", "=", "0", ")", "\n", "m1", "=", "scipy", ".", "stats", ".", "multivariate_normal", "(", "mean", "=", "np", ".", "zeros", "(", "dim", ")", ")", ".", "rvs", "(", "random_state", "=", "1", ")", "\n", "S1", "=", "scipy", ".", "stats", ".", "wishart", ".", "rvs", "(", "df", "=", "df", ",", "scale", "=", "np", ".", "eye", "(", "dim", ")", ",", "random_state", "=", "1", ")", "\n", "\n", "assert", "compute_kl_mvn", "(", "m0", ",", "S0", ",", "m1", ",", "S1", ")", ">", "0", "\n", "assert", "compute_kl_mvn", "(", "m1", ",", "S1", ",", "m0", ",", "S0", ")", ">", "0", "\n", "assert", "np", ".", "isclose", "(", "compute_kl_mvn", "(", "m0", ",", "S0", ",", "m0", ",", "S0", ")", ",", "0.0", ")", "\n", "assert", "np", ".", "isclose", "(", "compute_kl_mvn", "(", "m1", ",", "S1", ",", "m1", ",", "S1", ")", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.unit.test_util.test_compute_kl_inverse_wishart": [[26, 38], ["scipy.stats.wishart.rvs", "scipy.stats.wishart.rvs", "numpy.isclose", "numpy.isclose", "categorical_from_binary.kl.compute_kl_inverse_wishart", "categorical_from_binary.kl.compute_kl_inverse_wishart", "categorical_from_binary.kl.compute_kl_inverse_wishart", "categorical_from_binary.kl.compute_kl_inverse_wishart", "numpy.eye", "numpy.eye"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.compute_kl_inverse_wishart", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.compute_kl_inverse_wishart", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.compute_kl_inverse_wishart", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.compute_kl_inverse_wishart"], ["", "def", "test_compute_kl_inverse_wishart", "(", ")", ":", "\n", "# TODO: What else can I test about KL besides its non-negativity and 0 property?", "\n", "    ", "dim", "=", "2", "\n", "df_gen", "=", "2", "\n", "S0", "=", "scipy", ".", "stats", ".", "wishart", ".", "rvs", "(", "df", "=", "df_gen", ",", "scale", "=", "np", ".", "eye", "(", "dim", ")", ",", "random_state", "=", "0", ")", "\n", "S1", "=", "scipy", ".", "stats", ".", "wishart", ".", "rvs", "(", "df", "=", "df_gen", ",", "scale", "=", "np", ".", "eye", "(", "dim", ")", ",", "random_state", "=", "1", ")", "\n", "\n", "df0", ",", "df1", "=", "4", ",", "6", "\n", "assert", "compute_kl_inverse_wishart", "(", "df0", ",", "S0", ",", "df1", ",", "S1", ")", ">", "0", "\n", "assert", "compute_kl_inverse_wishart", "(", "df1", ",", "S1", ",", "df0", ",", "S0", ")", ">", "0", "\n", "assert", "np", ".", "isclose", "(", "compute_kl_inverse_wishart", "(", "df0", ",", "S0", ",", "df0", ",", "S0", ")", ",", "0.0", ")", "\n", "assert", "np", ".", "isclose", "(", "compute_kl_inverse_wishart", "(", "df1", ",", "S1", ",", "df1", ",", "S1", ")", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.unit.test_util.compute_approximate_expected_kl_divergence_wrt_independent_Normal_and_IW_distributions_on_params_of_second_argument": [[40, 82], ["scipy.stats.multivariate_normal().rvs", "scipy.stats.invwishart.rvs", "numpy.log", "zip", "numpy.linalg.det", "numpy.linalg.inv", "scipy.stats.multivariate_normal", "numpy.trace", "numpy.log", "numpy.linalg.det"], "function", ["None"], ["", "def", "compute_approximate_expected_kl_divergence_wrt_independent_Normal_and_IW_distributions_on_params_of_second_argument", "(", "\n", "mu_0", ":", "NumpyArray1D", ",", "\n", "Sigma_0", ":", "NumpyArray2D", ",", "\n", "m", ":", "NumpyArray1D", ",", "\n", "V", ":", "NumpyArray2D", ",", "\n", "nu", ":", "float", ",", "\n", "S", ":", "NumpyArray2D", ",", "\n", "num_mc_samples", ":", "int", ",", "\n", ")", "->", "float", ":", "\n", "    ", "\"\"\"\n    Use Monte Carlo samples to compute an approximation to the term computed by the function\n    `compute_expected_kl_divergence_wrt_independent_Normal_and_IW_distributions_on_params_of_second_argument`\n\n    Arguments\n        ADD\n\n    Returns:\n        An estimate of ADD\n    \"\"\"", "\n", "mu_1_samples", "=", "scipy", ".", "stats", ".", "multivariate_normal", "(", "mean", "=", "m", ",", "cov", "=", "V", ")", ".", "rvs", "(", "\n", "random_state", "=", "0", ",", "size", "=", "num_mc_samples", "\n", ")", "\n", "Sigma_1_samples", "=", "scipy", ".", "stats", ".", "invwishart", ".", "rvs", "(", "\n", "df", "=", "nu", ",", "scale", "=", "S", ",", "random_state", "=", "0", ",", "size", "=", "num_mc_samples", "\n", ")", "\n", "\n", "N", "=", "S", ".", "shape", "[", "0", "]", "\n", "log_det_Sigma_0", "=", "np", ".", "log", "(", "np", ".", "linalg", ".", "det", "(", "Sigma_0", ")", ")", "\n", "\n", "mc_sum", "=", "0", "\n", "for", "(", "mu_1_sample", ",", "Sigma_1_sample", ")", "in", "zip", "(", "mu_1_samples", ",", "Sigma_1_samples", ")", ":", "\n", "        ", "iSigma_1_sample", "=", "np", ".", "linalg", ".", "inv", "(", "Sigma_1_sample", ")", "\n", "mc_sum", "+=", "0.5", "*", "(", "\n", "np", ".", "log", "(", "np", ".", "linalg", ".", "det", "(", "Sigma_1_sample", ")", ")", "\n", "-", "log_det_Sigma_0", "\n", "-", "N", "\n", "+", "(", "mu_0", "-", "mu_1_sample", ")", ".", "T", "@", "iSigma_1_sample", "@", "(", "mu_0", "-", "mu_1_sample", ")", "\n", "+", "np", ".", "trace", "(", "iSigma_1_sample", "@", "Sigma_0", ")", "\n", ")", "\n", "\n", "", "mc_approx", "=", "mc_sum", "/", "num_mc_samples", "\n", "return", "mc_approx", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.unit.test_util.test_compute_expected_kl_divergence_wrt_independent_Normal_and_IW_distributions_on_params_of_second_argument": [[84, 112], ["scipy.stats.multivariate_normal().rvs", "scipy.stats.wishart.rvs", "scipy.stats.multivariate_normal().rvs", "scipy.stats.wishart.rvs", "scipy.stats.wishart.rvs", "test_util.compute_approximate_expected_kl_divergence_wrt_independent_Normal_and_IW_distributions_on_params_of_second_argument", "categorical_from_binary.kl.compute_expected_kl_divergence_wrt_independent_Normal_and_IW_distributions_on_params_of_second_argument", "numpy.isclose", "scipy.stats.multivariate_normal", "numpy.eye", "scipy.stats.multivariate_normal", "numpy.eye", "numpy.eye", "numpy.zeros", "numpy.zeros"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.unit.test_util.compute_approximate_expected_kl_divergence_wrt_independent_Normal_and_IW_distributions_on_params_of_second_argument", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.categorical_from_binary.kl.compute_expected_kl_divergence_wrt_independent_Normal_and_IW_distributions_on_params_of_second_argument"], ["", "def", "test_compute_expected_kl_divergence_wrt_independent_Normal_and_IW_distributions_on_params_of_second_argument", "(", ")", ":", "\n", "    ", "\"\"\"\n    This test checks (most of) the derivation of the propostion on expected KL divergence in the categorical models\n    document, as well as its implementation.\n    \"\"\"", "\n", "dim", ",", "df", "=", "2", ",", "3", "\n", "mu_0", "=", "scipy", ".", "stats", ".", "multivariate_normal", "(", "mean", "=", "np", ".", "zeros", "(", "dim", ")", ")", ".", "rvs", "(", "random_state", "=", "0", ")", "\n", "Sigma_0", "=", "scipy", ".", "stats", ".", "wishart", ".", "rvs", "(", "df", "=", "df", ",", "scale", "=", "np", ".", "eye", "(", "dim", ")", ",", "random_state", "=", "0", ")", "\n", "m", "=", "scipy", ".", "stats", ".", "multivariate_normal", "(", "mean", "=", "np", ".", "zeros", "(", "dim", ")", ")", ".", "rvs", "(", "random_state", "=", "0", ")", "\n", "V", "=", "scipy", ".", "stats", ".", "wishart", ".", "rvs", "(", "df", "=", "df", ",", "scale", "=", "np", ".", "eye", "(", "dim", ")", ",", "random_state", "=", "0", ")", "\n", "S", "=", "scipy", ".", "stats", ".", "wishart", ".", "rvs", "(", "df", "=", "df", ",", "scale", "=", "np", ".", "eye", "(", "dim", ")", ",", "random_state", "=", "0", ")", "\n", "nu", "=", "10", "\n", "\n", "num_monte_carlo_samples", "=", "10000", "\n", "\n", "expected_kl_approx", "=", "compute_approximate_expected_kl_divergence_wrt_independent_Normal_and_IW_distributions_on_params_of_second_argument", "(", "\n", "mu_0", ",", "\n", "Sigma_0", ",", "\n", "m", ",", "\n", "V", ",", "\n", "nu", ",", "\n", "S", ",", "\n", "num_monte_carlo_samples", ",", "\n", ")", "\n", "expected_kl_computed", "=", "compute_expected_kl_divergence_wrt_independent_Normal_and_IW_distributions_on_params_of_second_argument", "(", "\n", "mu_0", ",", "Sigma_0", ",", "m", ",", "V", ",", "nu", ",", "S", "\n", ")", "\n", "assert", "np", ".", "isclose", "(", "expected_kl_approx", ",", "expected_kl_computed", ",", "atol", "=", "0.33", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_hmc.test_hmc__demo_intercepts_only.test_hmc___demo_intercepts_only": [[13, 49], ["numpy.asarray", "categorical_from_binary.hmc.generate.generate_intercepts_only_categorical_data", "categorical_from_binary.hmc.core.run_nuts_on_categorical_data"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hmc.generate.generate_intercepts_only_categorical_data", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hmc.core.run_nuts_on_categorical_data"], ["def", "test_hmc___demo_intercepts_only", "(", ")", ":", "\n", "    ", "\"\"\"\n    We just test that the demo function runs without error.\n    \"\"\"", "\n", "\n", "# TODO: Break this up into proper unit tests", "\n", "# TODO: Find a way to run this test without the high start-up costs of leading in HMC.", "\n", "\n", "# Configs", "\n", "random_seed", "=", "42", "\n", "num_samples", "=", "10", "\n", "true_category_probs_K", "=", "np", ".", "asarray", "(", "[", "0.05", ",", "0.95", "]", ")", "\n", "\n", "# Generate (intercepts-only) categorical data", "\n", "(", "\n", "y_train__one_hot_NK", ",", "\n", "y_test__one_hot_NK", ",", "\n", ")", "=", "generate_intercepts_only_categorical_data", "(", "\n", "true_category_probs_K", ",", "\n", "num_samples", ",", "\n", "random_seed", "=", "random_seed", ",", "\n", ")", "\n", "\n", "num_warmup", ",", "num_mcmc_samples", "=", "0", ",", "10", "\n", "Nseen_list", "=", "[", "10", "]", "\n", "link", "=", "Link", ".", "MULTI_LOGIT", "\n", "betas_SLM_by_N", "=", "run_nuts_on_categorical_data", "(", "\n", "num_warmup", ",", "\n", "num_mcmc_samples", ",", "\n", "Nseen_list", ",", "\n", "create_categorical_model", ",", "\n", "link", ",", "\n", "y_train__one_hot_NK", ",", "\n", "random_seed", "=", "random_seed", ",", "\n", ")", "\n", "assert", "betas_SLM_by_N", "is", "not", "None", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_evaluate.test_evaluate_multiclass.test_take_measurements_comparing_CBM_and_CBC_estimators": [[20, 78], ["categorical_from_binary.data_generation.bayes_multiclass_reg.generate_multiclass_regression_dataset", "categorical_from_binary.ib_cavi.multi.ib_probit.inference.main.compute_multiclass_probit_vi_with_normal_prior", "categorical_from_binary.evaluate.multiclass.SplitDataset", "categorical_from_binary.evaluate.multiclass.take_measurements_comparing_CBM_and_CBC_estimators"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_multiclass_regression_dataset", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_multiclass_probit_vi_with_normal_prior", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.evaluate.multiclass.take_measurements_comparing_CBM_and_CBC_estimators"], ["def", "test_take_measurements_comparing_CBM_and_CBC_estimators", "(", ")", ":", "\n", "\n", "###", "\n", "# Construct dataset", "\n", "###", "\n", "    ", "seed", "=", "1", "\n", "n_categories", "=", "2", "\n", "n_features", "=", "2", "\n", "n_samples", "=", "50", "\n", "n_train_samples", "=", "40", "\n", "include_intercept", "=", "True", "\n", "link_for_generating_data", "=", "Link", ".", "CBC_PROBIT", "\n", "dataset", "=", "generate_multiclass_regression_dataset", "(", "\n", "n_samples", "=", "n_samples", ",", "\n", "n_features", "=", "n_features", ",", "\n", "n_categories", "=", "n_categories", ",", "\n", "beta_0", "=", "None", ",", "\n", "link", "=", "link_for_generating_data", ",", "\n", "seed", "=", "seed", ",", "\n", "include_intercept", "=", "include_intercept", ",", "\n", ")", "\n", "\n", "# Prep training data", "\n", "covariates_train", "=", "dataset", ".", "features", "[", ":", "n_train_samples", "]", "\n", "labels_train", "=", "dataset", ".", "labels", "[", ":", "n_train_samples", "]", "\n", "# `labels_train` gives one-hot encoded representation of category", "\n", "\n", "####", "\n", "# Variational Inference", "\n", "####", "\n", "convergence_criterion_drop_in_mean_elbo", "=", "1", "\n", "results", "=", "compute_multiclass_probit_vi_with_normal_prior", "(", "\n", "labels_train", ",", "\n", "covariates_train", ",", "\n", "variational_params_init", "=", "None", ",", "\n", "convergence_criterion_drop_in_mean_elbo", "=", "convergence_criterion_drop_in_mean_elbo", ",", "\n", "max_n_iterations", "=", "2", ",", "\n", ")", "\n", "beta_mean", "=", "results", ".", "variational_params", ".", "beta", ".", "mean", "\n", "\n", "###", "\n", "# Evaluate the model quality", "\n", "###", "\n", "\n", "covariates_test", "=", "dataset", ".", "features", "[", "n_train_samples", ":", "]", "\n", "labels_test", "=", "dataset", ".", "labels", "[", "n_train_samples", ":", "]", "\n", "\n", "split_dataset", "=", "SplitDataset", "(", "\n", "covariates_train", ",", "labels_train", ",", "covariates_test", ",", "labels_test", "\n", ")", "\n", "measurements", "=", "take_measurements_comparing_CBM_and_CBC_estimators", "(", "\n", "split_dataset", ",", "\n", "beta_mean", ",", "\n", "link_for_generating_data", ",", "\n", "beta_ground_truth", "=", "dataset", ".", "beta", ",", "\n", ")", "\n", "# TODO: test that the non-value fields for measurements all have unique values.", "\n", "assert", "measurements", "is", "not", "None", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_multi_probit_ib_inference_main.test_matching_results_for__compute_variational_expectation_of_z_with_dense_inputs__and_compute_variational_expectation_of_z_with_sparse_inputs": [[16, 39], ["numpy.array", "numpy.array", "numpy.array", "categorical_from_binary.ib_cavi.multi.ib_probit.inference.main.compute_variational_expectation_of_z_with_dense_inputs", "categorical_from_binary.ib_cavi.multi.ib_probit.inference.main.compute_variational_expectation_of_z_with_sparse_inputs", "ez_sparse.toarray.toarray", "numpy.isclose().all", "numpy.array", "categorical_from_binary.ib_cavi.multi.ib_probit.inference.main.compute_variational_expectation_of_z_with_dense_inputs", "categorical_from_binary.ib_cavi.multi.ib_probit.inference.main.compute_variational_expectation_of_z_with_sparse_inputs", "ez_sparse.toarray.toarray", "numpy.isclose().all", "numpy.isclose", "numpy.isclose"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_variational_expectation_of_z_with_dense_inputs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_variational_expectation_of_z_with_sparse_inputs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_variational_expectation_of_z_with_dense_inputs", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_variational_expectation_of_z_with_sparse_inputs"], ["def", "test_matching_results_for__compute_variational_expectation_of_z_with_dense_inputs__and_compute_variational_expectation_of_z_with_sparse_inputs", "(", ")", ":", "\n", "# Small dataset: M=2, K=3, N=4", "\n", "    ", "labels", "=", "np", ".", "array", "(", "[", "[", "1", ",", "0", ",", "0", "]", ",", "[", "1", ",", "0", ",", "0", "]", ",", "[", "0", ",", "1", ",", "0", "]", ",", "[", "0", ",", "0", ",", "1", "]", "]", ")", "\n", "design_matrix", "=", "np", ".", "array", "(", "[", "[", "-", "0.3", ",", "0.3", "]", ",", "[", "-", "0.2", ",", "0.2", "]", ",", "[", "-", "10", ",", "-", "10", "]", ",", "[", "10", ",", "10", "]", "]", ")", "\n", "beta_mean", "=", "np", ".", "array", "(", "[", "[", "1", ",", "0", ",", "0", "]", ",", "[", "1", ",", "0", ",", "0", "]", "]", ")", "\n", "ez_true", "=", "compute_variational_expectation_of_z_with_dense_inputs", "(", "\n", "labels", ",", "design_matrix", ",", "beta_mean", "\n", ")", "\n", "ez_sparse", "=", "compute_variational_expectation_of_z_with_sparse_inputs", "(", "\n", "labels", ",", "design_matrix", ",", "beta_mean", "\n", ")", "\n", "ez_sparse", "=", "ez_sparse", ".", "toarray", "(", ")", "\n", "assert", "np", ".", "isclose", "(", "ez_true", ",", "ez_sparse", ")", ".", "all", "(", ")", "\n", "\n", "beta_mean", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", ",", "0", "]", ",", "[", "0", ",", "0", ",", "0", "]", "]", ")", "\n", "ez_true", "=", "compute_variational_expectation_of_z_with_dense_inputs", "(", "\n", "labels", ",", "design_matrix", ",", "beta_mean", "\n", ")", "\n", "ez_sparse", "=", "compute_variational_expectation_of_z_with_sparse_inputs", "(", "\n", "labels", ",", "design_matrix", ",", "beta_mean", "\n", ")", "\n", "ez_sparse", "=", "ez_sparse", ".", "toarray", "(", ")", "\n", "assert", "np", ".", "isclose", "(", "ez_true", ",", "ez_sparse", ")", ".", "all", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_multi_probit_ib_inference_main.dataset": [[41, 56], ["categorical_from_binary.data_generation.bayes_multiclass_reg.generate_multiclass_regression_dataset"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_multiclass_regression_dataset"], ["", "@", "pytest", ".", "fixture", "\n", "def", "dataset", "(", ")", ":", "\n", "    ", "n_categories", "=", "3", "\n", "n_features", "=", "3", "\n", "n_samples", "=", "1000", "\n", "include_intercept", "=", "True", "\n", "link", "=", "Link", ".", "MULTI_LOGIT", "# Link.MULTI_LOGIT  # Link.CBC_PROBIT", "\n", "return", "generate_multiclass_regression_dataset", "(", "\n", "n_samples", "=", "n_samples", ",", "\n", "n_features", "=", "n_features", ",", "\n", "n_categories", "=", "n_categories", ",", "\n", "beta_0", "=", "None", ",", "\n", "link", "=", "link", ",", "\n", "seed", "=", "None", ",", "\n", "include_intercept", "=", "include_intercept", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_multi_probit_ib_inference_main.test__compute_multiclass_probit_vi_with_normal_prior__gives_same_variational_beta_mean_under_sparse_and_dense_computation": [[59, 93], ["len", "int", "categorical_from_binary.ib_cavi.multi.ib_probit.inference.main.compute_multiclass_probit_vi_with_normal_prior", "categorical_from_binary.ib_cavi.multi.ib_probit.inference.main.compute_multiclass_probit_vi_with_normal_prior", "numpy.isclose().all", "scipy.sparse.csc_matrix", "scipy.sparse.csc_matrix", "scipy.sparse.csc_matrix", "scipy.sparse.csc_matrix", "numpy.isclose", "beta_mean_sparse.toarray"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_multiclass_probit_vi_with_normal_prior", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_multiclass_probit_vi_with_normal_prior"], ["", "def", "test__compute_multiclass_probit_vi_with_normal_prior__gives_same_variational_beta_mean_under_sparse_and_dense_computation", "(", "\n", "dataset", ",", "\n", ")", ":", "\n", "\n", "# Prep training / test split", "\n", "    ", "n_samples", "=", "len", "(", "dataset", ".", "labels", ")", "\n", "n_train_samples", "=", "int", "(", "0.8", "*", "n_samples", ")", "\n", "covariates_train", "=", "dataset", ".", "features", "[", ":", "n_train_samples", "]", "\n", "labels_train", "=", "dataset", ".", "labels", "[", ":", "n_train_samples", "]", "\n", "covariates_test", "=", "dataset", ".", "features", "[", "n_train_samples", ":", "]", "\n", "labels_test", "=", "dataset", ".", "labels", "[", "n_train_samples", ":", "]", "\n", "\n", "max_n_iterations", "=", "5", "\n", "\n", "results_dense", "=", "compute_multiclass_probit_vi_with_normal_prior", "(", "\n", "labels_train", ",", "\n", "covariates_train", ",", "\n", "labels_test", "=", "labels_test", ",", "\n", "covariates_test", "=", "covariates_test", ",", "\n", "max_n_iterations", "=", "max_n_iterations", ",", "\n", ")", "\n", "\n", "results_sparse", "=", "compute_multiclass_probit_vi_with_normal_prior", "(", "\n", "csc_matrix", "(", "labels_train", ")", ",", "\n", "csc_matrix", "(", "covariates_train", ")", ",", "\n", "labels_test", "=", "csc_matrix", "(", "labels_test", ")", ",", "\n", "covariates_test", "=", "csc_matrix", "(", "covariates_test", ")", ",", "\n", "max_n_iterations", "=", "max_n_iterations", ",", "\n", ")", "\n", "\n", "beta_mean_dense", "=", "results_dense", ".", "variational_params", ".", "beta", ".", "mean", "\n", "beta_mean_sparse", "=", "results_sparse", ".", "variational_params", ".", "beta", ".", "mean", "\n", "\n", "assert", "np", ".", "isclose", "(", "beta_mean_sparse", ".", "toarray", "(", ")", ",", "beta_mean_dense", ")", ".", "all", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm._samples_of_normal_plus": [[37, 42], ["int", "scipy.stats.norm().rvs", "scipy.stats.norm().cdf", "scipy.stats.norm", "scipy.stats.norm"], "function", ["None"], ["def", "_samples_of_normal_plus", "(", "mu", ",", "target_n_samples", ")", ":", "\n", "    ", "sample_rejection_rate", "=", "1", "-", "scipy", ".", "stats", ".", "norm", "(", "mu", ",", "1", ")", ".", "cdf", "(", "0", ")", "\n", "num_samples_to_use", "=", "int", "(", "target_n_samples", "/", "sample_rejection_rate", ")", "\n", "samples_of_normal", "=", "scipy", ".", "stats", ".", "norm", "(", "mu", ",", "1", ")", ".", "rvs", "(", "size", "=", "num_samples_to_use", ")", "\n", "return", "samples_of_normal", "[", "samples_of_normal", ">", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm._samples_of_normal_minus": [[44, 49], ["int", "scipy.stats.norm().rvs", "scipy.stats.norm().cdf", "scipy.stats.norm", "scipy.stats.norm"], "function", ["None"], ["", "def", "_samples_of_normal_minus", "(", "mu", ",", "target_n_samples", ")", ":", "\n", "    ", "sample_rejection_rate", "=", "1", "-", "scipy", ".", "stats", ".", "norm", "(", "mu", ",", "1", ")", ".", "cdf", "(", "0", ")", "\n", "num_samples_to_use", "=", "int", "(", "target_n_samples", "/", "sample_rejection_rate", ")", "\n", "samples_of_normal", "=", "scipy", ".", "stats", ".", "norm", "(", "mu", ",", "1", ")", ".", "rvs", "(", "size", "=", "num_samples_to_use", ")", "\n", "return", "samples_of_normal", "[", "samples_of_normal", "<", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm.test_compute_expected_value_normal_plus": [[51, 58], ["numpy.mean", "categorical_from_binary.ib_cavi.trunc_norm.compute_expected_value_normal_plus", "numpy.isclose", "test_probit_vi_truncnorm._samples_of_normal_plus"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_expected_value_normal_plus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm._samples_of_normal_plus"], ["", "def", "test_compute_expected_value_normal_plus", "(", ")", ":", "\n", "    ", "mu_values", "=", "[", "-", "1", ",", "-", "0.5", ",", "0", ",", "0.5", ",", "1", "]", "\n", "target_n_samples", "=", "10000", "\n", "for", "mu", "in", "mu_values", ":", "\n", "        ", "sample_mean", "=", "np", ".", "mean", "(", "_samples_of_normal_plus", "(", "mu", ",", "target_n_samples", ")", ")", "\n", "computed_mean", "=", "compute_expected_value_normal_plus", "(", "mu", ")", "\n", "assert", "np", ".", "isclose", "(", "sample_mean", ",", "computed_mean", ",", "atol", "=", "0.05", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm.test_compute_expected_value_normal_minus": [[60, 67], ["numpy.mean", "categorical_from_binary.ib_cavi.trunc_norm.compute_expected_value_normal_minus", "numpy.isclose", "test_probit_vi_truncnorm._samples_of_normal_minus"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_expected_value_normal_minus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm._samples_of_normal_minus"], ["", "", "def", "test_compute_expected_value_normal_minus", "(", ")", ":", "\n", "    ", "mu_values", "=", "[", "-", "1", ",", "-", "0.5", ",", "0", ",", "0.5", ",", "1", "]", "\n", "target_n_samples", "=", "10000", "\n", "for", "mu", "in", "mu_values", ":", "\n", "        ", "sample_mean", "=", "np", ".", "mean", "(", "_samples_of_normal_minus", "(", "mu", ",", "target_n_samples", ")", ")", "\n", "computed_mean", "=", "compute_expected_value_normal_minus", "(", "mu", ")", "\n", "assert", "np", ".", "isclose", "(", "sample_mean", ",", "computed_mean", ",", "atol", "=", "0.05", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm.test_compute_variance_normal_plus": [[69, 76], ["numpy.var", "categorical_from_binary.ib_cavi.trunc_norm.compute_variance_normal_plus", "numpy.isclose", "test_probit_vi_truncnorm._samples_of_normal_plus"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_variance_normal_plus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm._samples_of_normal_plus"], ["", "", "def", "test_compute_variance_normal_plus", "(", ")", ":", "\n", "    ", "mu_values", "=", "[", "-", "1", ",", "-", "0.5", ",", "0", ",", "0.5", ",", "1", "]", "\n", "target_n_samples", "=", "10000", "\n", "for", "mu", "in", "mu_values", ":", "\n", "        ", "sample_var", "=", "np", ".", "var", "(", "_samples_of_normal_plus", "(", "mu", ",", "target_n_samples", ")", ")", "\n", "computed_var", "=", "compute_variance_normal_plus", "(", "mu", ")", "\n", "assert", "np", ".", "isclose", "(", "sample_var", ",", "computed_var", ",", "atol", "=", "0.05", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm.test_compute_variance_normal_minus": [[78, 85], ["numpy.var", "categorical_from_binary.ib_cavi.trunc_norm.compute_variance_normal_minus", "numpy.isclose", "test_probit_vi_truncnorm._samples_of_normal_minus"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_variance_normal_minus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm._samples_of_normal_minus"], ["", "", "def", "test_compute_variance_normal_minus", "(", ")", ":", "\n", "    ", "mu_values", "=", "[", "-", "1", ",", "-", "0.5", ",", "0", ",", "0.5", ",", "1", "]", "\n", "target_n_samples", "=", "10000", "\n", "for", "mu", "in", "mu_values", ":", "\n", "        ", "sample_var", "=", "np", ".", "var", "(", "_samples_of_normal_minus", "(", "mu", ",", "target_n_samples", ")", ")", "\n", "computed_var", "=", "compute_variance_normal_minus", "(", "mu", ")", "\n", "assert", "np", ".", "isclose", "(", "sample_var", ",", "computed_var", ",", "atol", "=", "0.05", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm._compute_entropy_contribution": [[87, 92], ["numpy.log"], "function", ["None"], ["", "", "def", "_compute_entropy_contribution", "(", "density_at_point", ")", ":", "\n", "    ", "if", "density_at_point", "==", "0", ":", "\n", "        ", "return", "0", "\n", "", "else", ":", "\n", "        ", "return", "-", "density_at_point", "*", "np", ".", "log", "(", "density_at_point", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm._numerically_approximate_entropy": [[94, 99], ["numpy.linspace", "scipy.integrate.simps", "test_probit_vi_truncnorm._compute_entropy_contribution", "categorical_from_binary.ib_cavi.trunc_norm.compute_density_normal_plus", "categorical_from_binary.ib_cavi.trunc_norm.compute_density_normal_minus"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm._compute_entropy_contribution", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_density_normal_plus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_density_normal_minus"], ["", "", "def", "_numerically_approximate_entropy", "(", "mu", ":", "float", ",", "density_function", ":", "Callable", ")", ":", "\n", "    ", "xs", "=", "np", ".", "linspace", "(", "-", "10", ",", "10", ",", "500", ")", "\n", "densities", "=", "[", "density_function", "(", "mu", ",", "x", ")", "for", "x", "in", "xs", "]", "\n", "entropy_contributions", "=", "[", "_compute_entropy_contribution", "(", "d", ")", "for", "d", "in", "densities", "]", "\n", "return", "simps", "(", "entropy_contributions", ",", "xs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm.test_compute_entropy_normal_plus": [[101, 109], ["test_probit_vi_truncnorm._numerically_approximate_entropy", "categorical_from_binary.ib_cavi.trunc_norm.compute_entropy_normal_plus", "numpy.isclose"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm._numerically_approximate_entropy", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_entropy_normal_plus"], ["", "def", "test_compute_entropy_normal_plus", "(", ")", ":", "\n", "    ", "mu_values", "=", "[", "-", "1", ",", "1", "]", "\n", "for", "mu", "in", "mu_values", ":", "\n", "        ", "entropy_numeric", "=", "_numerically_approximate_entropy", "(", "\n", "mu", ",", "compute_density_normal_plus", "\n", ")", "\n", "entropy_computed", "=", "compute_entropy_normal_plus", "(", "mu", ")", "\n", "assert", "np", ".", "isclose", "(", "entropy_computed", ",", "entropy_numeric", ",", "atol", "=", "0.005", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm.test_compute_entropy_normal_minus": [[111, 119], ["test_probit_vi_truncnorm._numerically_approximate_entropy", "categorical_from_binary.ib_cavi.trunc_norm.compute_entropy_normal_minus", "numpy.isclose"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm._numerically_approximate_entropy", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_entropy_normal_minus"], ["", "", "def", "test_compute_entropy_normal_minus", "(", ")", ":", "\n", "    ", "mu_values", "=", "[", "-", "1", ",", "1", "]", "\n", "for", "mu", "in", "mu_values", ":", "\n", "        ", "entropy_numeric", "=", "_numerically_approximate_entropy", "(", "\n", "mu", ",", "compute_density_normal_minus", "\n", ")", "\n", "entropy_computed", "=", "compute_entropy_normal_minus", "(", "mu", ")", "\n", "assert", "np", ".", "isclose", "(", "entropy_computed", ",", "entropy_numeric", ",", "atol", "=", "0.005", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm.test_compute_inv_cdf_normal_plus": [[121, 133], ["categorical_from_binary.ib_cavi.trunc_norm.compute_inv_cdf_normal_plus", "numpy.isclose", "categorical_from_binary.ib_cavi.trunc_norm.compute_inv_cdf_normal_plus"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_inv_cdf_normal_plus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_inv_cdf_normal_plus"], ["", "", "def", "test_compute_inv_cdf_normal_plus", "(", ")", ":", "\n", "    ", "for", "parent_mean", "in", "[", "-", "5", ",", "-", "2", ",", "-", "1", ",", "0", ",", "1", ",", "2", ",", "5", "]", ":", "\n", "# a normal distribution truncated from the left at 0 should have invcdf(0)=0", "\n", "# regardless of the mean of the parent distribution", "\n", "        ", "inv_cdf_computed", "=", "compute_inv_cdf_normal_plus", "(", "parent_mean", ",", "0", ")", "\n", "inv_cdf_expected", "=", "0.0", "\n", "assert", "np", ".", "isclose", "(", "inv_cdf_computed", ",", "inv_cdf_expected", ",", "atol", "=", "0.001", ")", "\n", "\n", "# a normal distribution truncated from the left at 0 should have invcdf(.5)>parent_mean;", "\n", "# i.e. the mean should be shifted upwards due to the truncation", "\n", "inv_cdf_computed", "=", "compute_inv_cdf_normal_plus", "(", "parent_mean", ",", "0.5", ")", "\n", "assert", "inv_cdf_computed", ">", "parent_mean", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm.test_compute_inv_cdf_normal_minus": [[135, 147], ["categorical_from_binary.ib_cavi.trunc_norm.compute_inv_cdf_normal_minus", "numpy.isclose", "categorical_from_binary.ib_cavi.trunc_norm.compute_inv_cdf_normal_minus"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_inv_cdf_normal_minus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_inv_cdf_normal_minus"], ["", "", "def", "test_compute_inv_cdf_normal_minus", "(", ")", ":", "\n", "    ", "for", "parent_mean", "in", "[", "-", "5", ",", "-", "2", ",", "-", "1", ",", "0", ",", "1", ",", "2", ",", "5", "]", ":", "\n", "# a normal distribution truncated from the right at 0 should have invcdf(1)=0", "\n", "# regardless of the mean of the parent distribution", "\n", "        ", "inv_cdf_computed", "=", "compute_inv_cdf_normal_minus", "(", "parent_mean", ",", "1", ")", "\n", "inv_cdf_expected", "=", "0.0", "\n", "assert", "np", ".", "isclose", "(", "inv_cdf_computed", ",", "inv_cdf_expected", ",", "atol", "=", "0.001", ")", "\n", "\n", "# a normal distribution truncated from the right at 0 should have invcdf(.5)<parent_mean;", "\n", "# i.e. the mean should be shifted downwards due to the truncation", "\n", "inv_cdf_computed", "=", "compute_inv_cdf_normal_minus", "(", "parent_mean", ",", "0.5", ")", "\n", "assert", "inv_cdf_computed", "<", "parent_mean", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm.test_sample_normal_plus": [[149, 155], ["categorical_from_binary.ib_cavi.trunc_norm.sample_normal_plus", "numpy.mean", "categorical_from_binary.ib_cavi.trunc_norm.compute_expected_value_normal_plus", "numpy.isclose"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.sample_normal_plus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_expected_value_normal_plus"], ["", "", "def", "test_sample_normal_plus", "(", ")", ":", "\n", "    ", "for", "parent_mean", "in", "[", "-", "5", ",", "-", "2", ",", "-", "1", ",", "0", ",", "1", ",", "2", ",", "5", "]", ":", "\n", "        ", "samples", "=", "sample_normal_plus", "(", "parent_mean", ",", "size", "=", "10000", ",", "random_state", "=", "1", ")", "\n", "mean_empirical", "=", "np", ".", "mean", "(", "samples", ")", "\n", "mean_expected", "=", "compute_expected_value_normal_plus", "(", "parent_mean", ")", "\n", "assert", "np", ".", "isclose", "(", "mean_empirical", ",", "mean_expected", ",", "atol", "=", "0.05", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_probit_vi_truncnorm.test_sample_normal_minus": [[157, 163], ["categorical_from_binary.ib_cavi.trunc_norm.sample_normal_minus", "numpy.mean", "categorical_from_binary.ib_cavi.trunc_norm.compute_expected_value_normal_minus", "numpy.isclose"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.sample_normal_minus", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_cavi.trunc_norm.compute_expected_value_normal_minus"], ["", "", "def", "test_sample_normal_minus", "(", ")", ":", "\n", "    ", "for", "parent_mean", "in", "[", "-", "5", ",", "-", "2", ",", "-", "1", ",", "0", ",", "1", ",", "2", ",", "5", "]", ":", "\n", "        ", "samples", "=", "sample_normal_minus", "(", "parent_mean", ",", "size", "=", "10000", ",", "random_state", "=", "1", ")", "\n", "mean_empirical", "=", "np", ".", "mean", "(", "samples", ")", "\n", "mean_expected", "=", "compute_expected_value_normal_minus", "(", "parent_mean", ")", "\n", "assert", "np", ".", "isclose", "(", "mean_empirical", ",", "mean_expected", ",", "atol", "=", "0.05", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_binary_probit_vi_elbo.test_compute_variational_expectation_of_prior_function": [[31, 52], ["zip", "numpy.array", "scipy.stats.multivariate_normal().entropy", "numpy.array", "categorical_from_binary.ib_cavi.binary_probit.elbo.compute_variational_expectation_of_prior", "scipy.stats.multivariate_normal"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.compute_variational_expectation_of_prior"], ["def", "test_compute_variational_expectation_of_prior_function", "(", ")", ":", "\n", "# TODO: randomly sample these", "\n", "    ", "RHOS", "=", "[", "-", "0.99", ",", "-", "0.5", ",", "0.0", ",", "0.5", ",", "0.99", "]", "\n", "MUS", "=", "[", "-", "2", ",", "-", "1", ",", "0", ",", "1", ",", "2", "]", "\n", "VAR_SCALES", "=", "[", "0.1", ",", "1.0", ",", "10.0", "]", "\n", "\n", "for", "rho", "in", "RHOS", ":", "\n", "        ", "for", "mu1", ",", "mu2", "in", "zip", "(", "MUS", ",", "MUS", ")", ":", "\n", "            ", "for", "var_scale", "in", "VAR_SCALES", ":", "\n", "                ", "beta_mean", "=", "np", ".", "array", "(", "[", "mu1", ",", "mu2", "]", ")", "\n", "beta_cov", "=", "var_scale", "*", "np", ".", "array", "(", "[", "[", "1.0", ",", "rho", "]", ",", "[", "rho", ",", "1.0", "]", "]", ")", "\n", "\n", "beta_cross_entropy", "=", "-", "compute_variational_expectation_of_prior", "(", "\n", "beta_mean", ",", "beta_cov", "\n", ")", "\n", "beta_entropy", "=", "scipy", ".", "stats", ".", "multivariate_normal", "(", "\n", "beta_mean", ",", "beta_cov", "\n", ")", ".", "entropy", "(", ")", "\n", "beta_kl", "=", "beta_cross_entropy", "-", "beta_entropy", "\n", "\n", "assert", "beta_kl", ">=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_binary_probit_vi_elbo.dataset": [[55, 58], ["categorical_from_binary.data_generation.bayes_binary_reg.generate_probit_regression_dataset"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.generate_probit_regression_dataset"], ["", "", "", "", "@", "pytest", ".", "fixture", "\n", "def", "dataset", "(", ")", ":", "\n", "    ", "return", "generate_probit_regression_dataset", "(", "n_samples", "=", "10", ",", "n_features", "=", "1", ",", "seed", "=", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_binary_probit_vi_elbo.covariates": [[60, 63], ["categorical_from_binary.data_generation.util.prepend_features_with_column_of_all_ones_for_intercept"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.util.prepend_features_with_column_of_all_ones_for_intercept"], ["", "@", "pytest", ".", "fixture", "\n", "def", "covariates", "(", "dataset", ")", ":", "\n", "    ", "return", "prepend_features_with_column_of_all_ones_for_intercept", "(", "dataset", ".", "features", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_binary_probit_vi_elbo.labels": [[65, 68], ["None"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "\n", "def", "labels", "(", "dataset", ")", ":", "\n", "    ", "return", "dataset", ".", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_binary_probit_vi_elbo.variational_params": [[70, 84], ["numpy.zeros", "numpy.eye", "categorical_from_binary.ib_cavi.binary_probit.inference.structs.VariationalBeta", "categorical_from_binary.ib_cavi.binary_probit.inference.structs.VariationalZs", "categorical_from_binary.ib_cavi.binary_probit.inference.structs.VariationalParams", "numpy.shape"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "\n", "def", "variational_params", "(", "covariates", ")", ":", "\n", "# crappy MF posterior approximation; didn't actually run VI", "\n", "    ", "n_covariates", "=", "np", ".", "shape", "(", "covariates", ")", "[", "1", "]", "\n", "beta_mean", "=", "np", ".", "zeros", "(", "\n", "n_covariates", ",", "\n", ")", "\n", "beta_cov", "=", "np", ".", "eye", "(", "\n", "n_covariates", ",", "\n", ")", "\n", "variational_beta", "=", "VariationalBeta", "(", "beta_mean", ",", "beta_cov", ")", "\n", "z_natural_params", "=", "covariates", "@", "beta_mean", "\n", "variational_zs", "=", "VariationalZs", "(", "z_natural_params", ")", "\n", "return", "VariationalParams", "(", "variational_beta", ",", "variational_zs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_binary_probit_vi_elbo.n_samples": [[86, 89], ["None"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "\n", "def", "n_samples", "(", ")", ":", "\n", "    ", "return", "10000", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_binary_probit_vi_elbo.beta_samples": [[91, 95], ["scipy.stats.multivariate_normal.rvs", "scipy.stats.multivariate_normal"], "function", ["None"], ["", "@", "pytest", ".", "fixture", "\n", "def", "beta_samples", "(", "variational_params", ",", "n_samples", ")", ":", "\n", "    ", "return", "mvn", "(", "variational_params", ".", "beta", ".", "mean", ",", "variational_params", ".", "beta", ".", "cov", ")", ".", "rvs", "(", "\n", "size", "=", "n_samples", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_binary_probit_vi_elbo.z_samples": [[98, 102], ["categorical_from_binary.ib_cavi.binary_probit.elbo.sample_z_from_natural_parameters"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.sample_z_from_natural_parameters"], ["", "@", "pytest", ".", "fixture", "\n", "def", "z_samples", "(", "variational_params", ",", "n_samples", ",", "labels", ")", ":", "\n", "    ", "vp", "=", "variational_params", "\n", "return", "sample_z_from_natural_parameters", "(", "labels", ",", "vp", ".", "zs", ".", "parent_mean", ",", "n_samples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_binary_probit_vi_elbo.test_compute_variational_entropy_of_beta": [[104, 110], ["categorical_from_binary.ib_cavi.binary_probit.elbo.compute_variational_entropy_of_beta", "numpy.isclose", "numpy.mean", "scipy.stats.multivariate_normal.logpdf", "scipy.stats.multivariate_normal"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_probit.elbo.compute_variational_entropy_of_beta"], ["", "def", "test_compute_variational_entropy_of_beta", "(", "variational_params", ",", "beta_samples", ")", ":", "\n", "    ", "\"\"\"The `regression weights entropy` term of the ELBO\"\"\"", "\n", "beta_mean", ",", "beta_cov", "=", "variational_params", ".", "beta", ".", "mean", ",", "variational_params", ".", "beta", ".", "cov", "\n", "entropy_beta_empirical", "=", "-", "np", ".", "mean", "(", "mvn", "(", "beta_mean", ",", "beta_cov", ")", ".", "logpdf", "(", "beta_samples", ")", ")", "\n", "entropy_beta_computed", "=", "compute_variational_entropy_of_beta", "(", "beta_mean", ",", "beta_cov", ")", "\n", "assert", "np", ".", "isclose", "(", "entropy_beta_empirical", ",", "entropy_beta_computed", ",", "atol", "=", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_binary_probit_vi_elbo.test_compute_variational_entropy_of_z": [[112, 123], ["categorical_from_binary.ib_cavi.binary_probit.elbo.compute_monte_carlo_approximate_entropy_for_z", "categorical_from_binary.ib_cavi.binary_probit.elbo.compute_variational_entropy_of_z", "numpy.isclose"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.compute_monte_carlo_approximate_entropy_for_z", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.elbo.compute_variational_entropy_of_z"], ["", "def", "test_compute_variational_entropy_of_z", "(", "\n", "variational_params", ",", "labels", ",", "covariates", ",", "z_samples", "\n", ")", ":", "\n", "    ", "\"\"\"The `latent variable entropy` term of the ELBO\"\"\"", "\n", "beta_mean", "=", "variational_params", ".", "beta", ".", "mean", "\n", "z_natural_params", "=", "variational_params", ".", "zs", ".", "parent_mean", "\n", "entropy_z_empirical", "=", "compute_monte_carlo_approximate_entropy_for_z", "(", "\n", "z_samples", ",", "z_natural_params", ",", "labels", "\n", ")", "\n", "entropy_z_computed", "=", "compute_variational_entropy_of_z", "(", "labels", ",", "covariates", ",", "beta_mean", ")", "\n", "assert", "np", ".", "isclose", "(", "entropy_z_empirical", ",", "entropy_z_computed", ",", "atol", "=", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_binary_probit_vi_elbo.test_compute_variational_expectation_of_prior": [[125, 133], ["numpy.mean", "categorical_from_binary.ib_cavi.binary_probit.elbo.compute_variational_expectation_of_prior", "numpy.isclose", "scipy.stats.multivariate_normal.logpdf", "scipy.stats.multivariate_normal"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.compute_variational_expectation_of_prior"], ["", "def", "test_compute_variational_expectation_of_prior", "(", "variational_params", ",", "beta_samples", ")", ":", "\n", "    ", "\"\"\"The `prior energy` term of the ELBO\"\"\"", "\n", "beta_mean", ",", "beta_cov", "=", "variational_params", ".", "beta", ".", "mean", ",", "variational_params", ".", "beta", ".", "cov", "\n", "prior_energy_beta_empirical", "=", "np", ".", "mean", "(", "mvn", "(", "beta_mean", ",", "beta_cov", ")", ".", "logpdf", "(", "beta_samples", ")", ")", "\n", "prior_energy_beta_computed", "=", "compute_variational_expectation_of_prior", "(", "\n", "beta_mean", ",", "beta_cov", "\n", ")", "\n", "assert", "np", ".", "isclose", "(", "prior_energy_beta_empirical", ",", "prior_energy_beta_computed", ",", "atol", "=", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_binary_probit_vi_elbo.test_compute_variational_expectation_of_complete_data_likelihood": [[135, 152], ["categorical_from_binary.ib_cavi.binary_probit.inference.main.compute_variational_expectation_of_z", "categorical_from_binary.ib_cavi.binary_probit.elbo.compute_variational_expectation_of_complete_data_likelihood", "categorical_from_binary.ib_cavi.binary_probit.elbo.compute_monte_carlo_approximate_likelihood_energy", "numpy.isclose"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.inference.main.compute_variational_expectation_of_z", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.hierarchical_ib_probit.elbo.compute_variational_expectation_of_complete_data_likelihood", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_probit.elbo.compute_monte_carlo_approximate_likelihood_energy"], ["", "def", "test_compute_variational_expectation_of_complete_data_likelihood", "(", "\n", "variational_params", ",", "labels", ",", "covariates", ",", "beta_samples", ",", "z_samples", "\n", ")", ":", "\n", "    ", "\"\"\"The `likelihood energy` term of the ELBO\"\"\"", "\n", "beta_mean", ",", "beta_cov", "=", "variational_params", ".", "beta", ".", "mean", ",", "variational_params", ".", "beta", ".", "cov", "\n", "z_mean", "=", "compute_variational_expectation_of_z", "(", "labels", ",", "covariates", ",", "beta_mean", ")", "\n", "likelihood_energy_computed", "=", "(", "\n", "compute_variational_expectation_of_complete_data_likelihood", "(", "\n", "z_mean", ",", "beta_mean", ",", "beta_cov", ",", "covariates", "\n", ")", "\n", ")", "\n", "likelihood_energy_empirical", "=", "compute_monte_carlo_approximate_likelihood_energy", "(", "\n", "z_samples", ",", "\n", "beta_samples", ",", "\n", "covariates", ",", "\n", ")", "\n", "assert", "np", ".", "isclose", "(", "likelihood_energy_empirical", ",", "likelihood_energy_computed", ",", "atol", "=", "0.1", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_multi_logit_ib_inference.dataset": [[14, 33], ["categorical_from_binary.data_generation.bayes_multiclass_reg.ControlCategoryPredictability", "categorical_from_binary.data_generation.bayes_multiclass_reg.generate_multiclass_regression_dataset"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_multiclass_regression_dataset"], ["@", "pytest", ".", "fixture", "\n", "def", "dataset", "(", ")", ":", "\n", "    ", "n_categories", "=", "3", "\n", "n_features", "=", "3", "\n", "n_samples", "=", "100", "\n", "include_intercept", "=", "True", "\n", "link", "=", "Link", ".", "MULTI_LOGIT", "# Link.MULTI_LOGIT  # Link.CBC_PROBIT", "\n", "beta_category_strategy", "=", "ControlCategoryPredictability", "(", "\n", "scale_for_predictive_categories", "=", "4.0", "\n", ")", "\n", "return", "generate_multiclass_regression_dataset", "(", "\n", "n_samples", "=", "n_samples", ",", "\n", "n_features", "=", "n_features", ",", "\n", "n_categories", "=", "n_categories", ",", "\n", "beta_0", "=", "None", ",", "\n", "link", "=", "link", ",", "\n", "seed", "=", "None", ",", "\n", "include_intercept", "=", "include_intercept", ",", "\n", "beta_category_strategy", "=", "beta_category_strategy", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_ib_cavi.test_multi_logit_ib_inference.test__compute_multiclass_logit_vi_with_CBC_aux_var_and_polya_gamma_augmentation__gives_non_negligible_accuracy": [[36, 61], ["numpy.shape", "int", "categorical_from_binary.ib_cavi.multi.ib_logit_with_DO_aux_var.inference.compute_multiclass_logit_vi_with_CBC_aux_var_and_polya_gamma_augmentation", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.ib_logit_with_DO_aux_var.inference.compute_multiclass_logit_vi_with_CBC_aux_var_and_polya_gamma_augmentation"], ["", "def", "test__compute_multiclass_logit_vi_with_CBC_aux_var_and_polya_gamma_augmentation__gives_non_negligible_accuracy", "(", "\n", "dataset", ",", "\n", ")", ":", "\n", "\n", "# Prep training / test split", "\n", "    ", "n_samples", ",", "n_categories", "=", "np", ".", "shape", "(", "dataset", ".", "labels", ")", "\n", "n_train_samples", "=", "int", "(", "0.8", "*", "n_samples", ")", "\n", "covariates_train", "=", "dataset", ".", "features", "[", ":", "n_train_samples", "]", "\n", "labels_train", "=", "dataset", ".", "labels", "[", ":", "n_train_samples", "]", "\n", "covariates_test", "=", "dataset", ".", "features", "[", "n_train_samples", ":", "]", "\n", "labels_test", "=", "dataset", ".", "labels", "[", "n_train_samples", ":", "]", "\n", "\n", "max_n_iterations", "=", "3", "\n", "\n", "results", "=", "compute_multiclass_logit_vi_with_CBC_aux_var_and_polya_gamma_augmentation", "(", "\n", "labels_train", ",", "\n", "covariates_train", ",", "\n", "labels_test", "=", "labels_test", ",", "\n", "covariates_test", "=", "covariates_test", ",", "\n", "variational_params_init", "=", "None", ",", "\n", "max_n_iterations", "=", "max_n_iterations", ",", "\n", ")", "\n", "accuracy", "=", "results", ".", "performance_over_time", "[", "\"test accuracy with CBM_LOGIT\"", "]", "\n", "minimum_acceptable_accuracy", "=", "1.25", "/", "(", "n_categories", ")", "\n", "assert", "np", ".", "mean", "(", "accuracy", ")", ">", "minimum_acceptable_accuracy", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_performance_over_time.test_performance_over_time.test_that_performance_over_time_runs_on_demo_sims_without_crashing": [[4, 7], ["categorical_from_binary.performance_over_time.main.run_performance_over_time"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.performance_over_time.main.run_performance_over_time"], ["def", "test_that_performance_over_time_runs_on_demo_sims_without_crashing", "(", ")", ":", "\n", "    ", "path_to_configs", "=", "\"configs/performance_over_time/demo_sims.yaml\"", "\n", "run_performance_over_time", "(", "path_to_configs", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_polya_gamma_vi.test_polya_gamma_vi_for_bayes_logreg.test_run_polya_gamma_variational_inference_for_bayesian_logistic_regression": [[15, 43], ["categorical_from_binary.data_generation.bayes_binary_reg.generate_logistic_regression_dataset", "len", "numpy.zeros", "numpy.eye", "categorical_from_binary.polya_gamma.binary_logreg_vi.inference.PriorParameters", "categorical_from_binary.polya_gamma.binary_logreg_vi.inference.run_polya_gamma_variational_inference_for_bayesian_logistic_regression", "sklearn.linear_model.LogisticRegression().fit", "numpy.concatenate", "numpy.isclose().all", "sklearn.linear_model.LogisticRegression", "numpy.isclose"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_binary_reg.generate_logistic_regression_dataset", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.inference.run_polya_gamma_variational_inference_for_bayesian_logistic_regression"], ["def", "test_run_polya_gamma_variational_inference_for_bayesian_logistic_regression", "(", ")", ":", "\n", "    ", "\"\"\"\n    Check our polya gamma VI algorithm for bayesian logistic regrression.\n    In particular, we check that the variational mean for the regression weights is similar to the regression weights\n    provided by sklearn.\n    \"\"\"", "\n", "dataset", "=", "generate_logistic_regression_dataset", "(", "n_samples", "=", "1000", ",", "n_features", "=", "5", ")", "\n", "\n", "# set up prior", "\n", "beta_dim", "=", "len", "(", "dataset", ".", "beta", ")", "\n", "prior_mean_beta", "=", "np", ".", "zeros", "(", "beta_dim", ")", "\n", "prior_cov_beta", "=", "np", ".", "eye", "(", "beta_dim", ")", "\n", "prior_params", "=", "PriorParameters", "(", "prior_mean_beta", ",", "prior_cov_beta", ")", "\n", "\n", "variational_params", "=", "(", "\n", "run_polya_gamma_variational_inference_for_bayesian_logistic_regression", "(", "\n", "dataset", ",", "\n", "prior_params", ",", "\n", "verbose", "=", "True", ",", "\n", "convergence_criterion_drop_in_elbo", "=", "0.01", ",", "\n", ")", "\n", ")", "\n", "variational_mean_beta", "=", "variational_params", ".", "mean_beta", "\n", "\n", "lr", "=", "LogisticRegression", "(", "random_state", "=", "0", ")", ".", "fit", "(", "dataset", ".", "features", ",", "dataset", ".", "labels", ")", "\n", "sklearn_beta", "=", "np", ".", "concatenate", "(", "(", "lr", ".", "intercept_", ",", "lr", ".", "coef_", "[", "0", ",", ":", "]", ")", ")", "\n", "\n", "assert", "np", ".", "isclose", "(", "variational_mean_beta", ",", "sklearn_beta", ",", "atol", "=", "0.01", ",", "rtol", "=", "0.05", ")", ".", "all", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_polya_gamma_vi.test_polya_gamma_vi_for_bayes_logreg.test_that_compute_kl_divergence_from_prior_to_variational_beta_is_zero_when_distributions_are_identical": [[45, 64], ["scipy.stats.multivariate_normal().rvs", "scipy.stats.invwishart().rvs", "zip", "numpy.zeros", "numpy.eye", "categorical_from_binary.polya_gamma.binary_logreg_vi.inference.compute_kl_divergence_from_prior_to_variational_beta", "numpy.isclose", "scipy.stats.multivariate_normal", "scipy.stats.invwishart", "numpy.zeros", "numpy.eye"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.binary_logreg_vi.inference.compute_kl_divergence_from_prior_to_variational_beta"], ["", "def", "test_that_compute_kl_divergence_from_prior_to_variational_beta_is_zero_when_distributions_are_identical", "(", ")", ":", "\n", "\n", "    ", "dim", "=", "10", "# arbitary choice", "\n", "\n", "random_mean", "=", "scipy", ".", "stats", ".", "multivariate_normal", "(", "mean", "=", "np", ".", "zeros", "(", "dim", ")", ")", ".", "rvs", "(", ")", "\n", "random_cov", "=", "scipy", ".", "stats", ".", "invwishart", "(", "df", "=", "dim", ",", "scale", "=", "np", ".", "eye", "(", "dim", ")", ")", ".", "rvs", "(", ")", "\n", "\n", "mean_list", "=", "[", "np", ".", "zeros", "(", "dim", ")", ",", "random_mean", "]", "\n", "cov_list", "=", "[", "np", ".", "eye", "(", "dim", ")", ",", "random_cov", "]", "\n", "\n", "for", "mean", ",", "cov", "in", "zip", "(", "mean_list", ",", "cov_list", ")", ":", "\n", "        ", "expected_kl", "=", "0", "\n", "computed_kl", "=", "compute_kl_divergence_from_prior_to_variational_beta", "(", "\n", "mean", ",", "\n", "cov", ",", "\n", "mean", ",", "\n", "cov", ",", "\n", ")", "\n", "assert", "np", ".", "isclose", "(", "computed_kl", ",", "expected_kl", ",", "atol", "=", "1e-5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_polya_gamma_vi.test_polya_gamma.test_compute_polya_gamma_expectation": [[9, 33], ["hypothesis.given", "pypolyagamma.PyPolyaGamma", "numpy.mean", "categorical_from_binary.polya_gamma.polya_gamma.compute_polya_gamma_expectation", "numpy.isclose", "hypothesis.floats", "hypothesis.floats", "pypolyagamma.PyPolyaGamma.pgdraw", "range"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.polya_gamma.polya_gamma.compute_polya_gamma_expectation"], ["@", "given", "(", "\n", "b", "=", "st", ".", "floats", "(", "min_value", "=", "1", ",", "max_value", "=", "1", ")", ",", "\n", "c", "=", "st", ".", "floats", "(", "min_value", "=", "-", "100", ",", "max_value", "=", "100", ")", ",", "\n", ")", "\n", "\n", "# The `b` parameter was fixed at 1.0 because it is always 1.0 for logistic regression", "\n", "# (It can be larger than one when doing binomial regression more generally).", "\n", "# I didn't really have a good reason for setting the `c` limits,  other than having them", "\n", "# not get too large based on the fact that c = x_i^T beta.  We might want to ask the user (or provide a routine)", "\n", "# for normalizing continuous covariates before feeding into the algorithm,  as very large values may cause issues.", "\n", "\n", "\n", "def", "test_compute_polya_gamma_expectation", "(", "b", ",", "c", ")", ":", "\n", "\n", "# Test that our computed polya gamma expectation for a PG(b,c) distribution", "\n", "# is close to the empirical mean of a bunch of samples (obtained from the pypolyagamma library)", "\n", "\n", "    ", "pg", "=", "PyPolyaGamma", "(", ")", "\n", "empirical_mean", "=", "np", ".", "mean", "(", "[", "pg", ".", "pgdraw", "(", "b", ",", "c", ")", "for", "i", "in", "range", "(", "10000", ")", "]", ")", "\n", "computed_mean", "=", "compute_polya_gamma_expectation", "(", "b", ",", "c", ")", "\n", "# print(", "\n", "#     f\"For b={b}, c={c}, the Monte Carlo mean was {empirical_mean}, and my function's value was {computed_mean}\"", "\n", "# )", "\n", "assert", "np", ".", "isclose", "(", "empirical_mean", ",", "computed_mean", ",", "atol", "=", "0.01", ",", "rtol", "=", "0.05", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_data_generation.test_data_generation_bayes_multiclass_reg.test_generate_multiclass_regression_dataset": [[16, 40], ["categorical_from_binary.data_generation.bayes_multiclass_reg.generate_multiclass_regression_dataset", "numpy.shape"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_multiclass_regression_dataset"], ["def", "test_generate_multiclass_regression_dataset", "(", ")", ":", "\n", "    ", "\"\"\"\n    We test that we can run the function for various link functions and get the right\n    number of categories in the responses, even though the beta dimensionality differs\n    from link function to link function\n    \"\"\"", "\n", "n_categories", ",", "n_features", ",", "n_samples", "=", "4", ",", "5", ",", "10", "\n", "include_intercept", "=", "False", "\n", "for", "link", "in", "[", "\n", "Link", ".", "CBC_PROBIT", ",", "\n", "Link", ".", "MULTI_LOGIT", ",", "\n", "Link", ".", "STICK_BREAKING", ",", "\n", "Link", ".", "CBC_LOGIT", ",", "\n", "]", ":", "\n", "        ", "dataset", "=", "generate_multiclass_regression_dataset", "(", "\n", "n_samples", "=", "n_samples", ",", "\n", "n_features", "=", "n_features", ",", "\n", "n_categories", "=", "n_categories", ",", "\n", "beta_0", "=", "None", ",", "\n", "link", "=", "link", ",", "\n", "seed", "=", "None", ",", "\n", "include_intercept", "=", "include_intercept", ",", "\n", ")", "\n", "assert", "np", ".", "shape", "(", "dataset", ".", "labels", ")", "[", "1", "]", "==", "n_categories", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_data_generation.test_data_generation_bayes_multiclass_reg.multiclass_logistic_regression_dataset": [[42, 46], ["categorical_from_binary.data_generation.bayes_multiclass_reg.generate_multiclass_regression_dataset"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_multiclass_regression_dataset"], ["", "", "@", "pytest", ".", "fixture", "\n", "def", "multiclass_logistic_regression_dataset", "(", ")", ":", "\n", "    ", "return", "generate_multiclass_regression_dataset", "(", "\n", "n_samples", "=", "10", ",", "n_features", "=", "6", ",", "n_categories", "=", "3", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_data_generation.test_data_generation_bayes_multiclass_reg.test_that_the_construct_multi_logit_probabilities_function_returns_object_whose_rows_sum_to_unity": [[49, 55], ["categorical_from_binary.data_generation.bayes_multiclass_reg.construct_multi_logit_probabilities", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_multi_logit_probabilities"], ["", "def", "test_that_the_construct_multi_logit_probabilities_function_returns_object_whose_rows_sum_to_unity", "(", "\n", "multiclass_logistic_regression_dataset", ",", "\n", ")", ":", "\n", "    ", "dataset", "=", "multiclass_logistic_regression_dataset", "\n", "probs", "=", "construct_multi_logit_probabilities", "(", "dataset", ".", "features", ",", "dataset", ".", "beta", ")", "\n", "assert", "(", "np", ".", "sum", "(", "probs", ",", "1", ")", "==", "1.0", ")", ".", "all", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_data_generation.test_data_generation_bayes_multiclass_reg.test_that_the_construct_stickbreaking_multinomial_probabilities_function_returns_object_whose_rows_sum_to_unity": [[57, 65], ["categorical_from_binary.data_generation.bayes_multiclass_reg.construct_stickbreaking_multinomial_probabilities", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_stickbreaking_multinomial_probabilities"], ["", "def", "test_that_the_construct_stickbreaking_multinomial_probabilities_function_returns_object_whose_rows_sum_to_unity", "(", "\n", "multiclass_logistic_regression_dataset", ",", "\n", ")", ":", "\n", "    ", "dataset", "=", "multiclass_logistic_regression_dataset", "\n", "probs", "=", "construct_stickbreaking_multinomial_probabilities", "(", "\n", "dataset", ".", "features", ",", "dataset", ".", "beta", "\n", ")", "\n", "assert", "(", "np", ".", "sum", "(", "probs", ",", "1", ")", "==", "1.0", ")", ".", "all", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_data_generation.test_data_generation_bayes_multiclass_reg.test_make_stick_breaking_multinomial_regression_intercepts_such_that_category_probabilities_are_symmetric": [[67, 79], ["numpy.ones", "categorical_from_binary.data_generation.bayes_multiclass_reg.construct_stickbreaking_multinomial_probabilities", "numpy.isclose().all", "categorical_from_binary.data_generation.bayes_multiclass_reg.make_stick_breaking_multinomial_regression_intercepts_such_that_category_probabilities_are_symmetric", "numpy.ones", "numpy.isclose"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.construct_stickbreaking_multinomial_probabilities", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.make_stick_breaking_multinomial_regression_intercepts_such_that_category_probabilities_are_symmetric"], ["", "def", "test_make_stick_breaking_multinomial_regression_intercepts_such_that_category_probabilities_are_symmetric", "(", ")", ":", "\n", "# we make a regression where this is a single sample and where the only feature is an intercept term.", "\n", "    ", "n_samples", ",", "n_categories", "=", "1", ",", "4", "\n", "features", "=", "np", ".", "ones", "(", "(", "n_samples", ",", "1", ")", ")", "\n", "beta", "=", "make_stick_breaking_multinomial_regression_intercepts_such_that_category_probabilities_are_symmetric", "(", "\n", "n_categories", "\n", ")", "[", "\n", "np", ".", "newaxis", ",", ":", "\n", "]", "\n", "probs", "=", "construct_stickbreaking_multinomial_probabilities", "(", "features", ",", "beta", ")", "\n", "expected_category_probs", "=", "np", ".", "ones", "(", "n_categories", ")", "/", "n_categories", "\n", "assert", "np", ".", "isclose", "(", "probs", ",", "expected_category_probs", ")", ".", "all", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_data_generation.test_data_generation_bayes_multiclass_reg.test_generate_multiclass_regression_dataset_with_stick_breaking_link": [[81, 99], ["categorical_from_binary.data_generation.bayes_multiclass_reg.generate_multiclass_regression_dataset", "numpy.mean", "numpy.isclose().all", "numpy.ones", "categorical_from_binary.data_generation.bayes_multiclass_reg.make_stick_breaking_multinomial_regression_intercepts_such_that_category_probabilities_are_symmetric", "numpy.isclose"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_multiclass_regression_dataset", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.make_stick_breaking_multinomial_regression_intercepts_such_that_category_probabilities_are_symmetric"], ["", "def", "test_generate_multiclass_regression_dataset_with_stick_breaking_link", "(", ")", ":", "\n", "    ", "\"\"\"\n    We test that the function has the correct label proportions when there are no features\n    \"\"\"", "\n", "n_categories", "=", "4", "\n", "dataset", "=", "generate_multiclass_regression_dataset", "(", "\n", "n_samples", "=", "10000", ",", "\n", "n_features", "=", "0", ",", "\n", "n_categories", "=", "n_categories", ",", "\n", "beta_0", "=", "make_stick_breaking_multinomial_regression_intercepts_such_that_category_probabilities_are_symmetric", "(", "\n", "n_categories", "\n", ")", ",", "\n", "link", "=", "Link", ".", "STICK_BREAKING", ",", "\n", "seed", "=", "2", ",", "\n", ")", "\n", "label_proportions", "=", "np", ".", "mean", "(", "dataset", ".", "labels", ",", "0", ")", "\n", "expected_label_proportions", "=", "np", ".", "ones", "(", "n_categories", ")", "/", "n_categories", "\n", "assert", "np", ".", "isclose", "(", "label_proportions", ",", "expected_label_proportions", ",", "atol", "=", "0.03", ")", ".", "all", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_data_generation.test_data_generation_bayes_multiclass_reg.test_generate_multiclass_labels_for_nonautoregressive_case": [[101, 128], ["numpy.random.normal", "categorical_from_binary.data_generation.bayes_multiclass_reg.get_num_beta_columns", "numpy.random.normal", "categorical_from_binary.data_generation.bayes_multiclass_reg.generate_multiclass_labels_for_nonautoregressive_case"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.get_num_beta_columns", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_multiclass_labels_for_nonautoregressive_case"], ["", "def", "test_generate_multiclass_labels_for_nonautoregressive_case", "(", ")", ":", "\n", "    ", "num_features_nonautoregressive", "=", "5", "\n", "num_categories", "=", "3", "\n", "num_samples", "=", "100", "\n", "features_non_autoregressive", "=", "np", ".", "random", ".", "normal", "(", "\n", "loc", "=", "0", ",", "scale", "=", "1", ",", "size", "=", "(", "num_samples", ",", "num_features_nonautoregressive", ")", "\n", ")", "\n", "links_to_use", "=", "[", "\n", "Link", ".", "MULTI_LOGIT", ",", "\n", "Link", ".", "STICK_BREAKING", ",", "\n", "Link", ".", "CBC_LOGIT", ",", "\n", "Link", ".", "CBM_LOGIT", ",", "\n", "Link", ".", "CBC_PROBIT", ",", "\n", "Link", ".", "CBM_PROBIT", ",", "\n", "Link", ".", "SOFTMAX", ",", "\n", "]", "\n", "for", "link", "in", "links_to_use", ":", "\n", "        ", "num_beta_columns", "=", "get_num_beta_columns", "(", "link", ",", "num_categories", ")", "\n", "beta", "=", "np", ".", "random", ".", "normal", "(", "\n", "loc", "=", "0", ",", "scale", "=", "1", ",", "size", "=", "(", "num_features_nonautoregressive", ",", "num_beta_columns", ")", "\n", ")", "\n", "labels", "=", "generate_multiclass_labels_for_nonautoregressive_case", "(", "\n", "features_non_autoregressive", ",", "\n", "beta", ",", "\n", "link", ",", "\n", ")", "\n", "assert", "labels", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_data_generation.test_data_generation_bayes_multiclass_reg.test_generate_designed_features_and_multiclass_labels_for_autoregressive_case": [[130, 153], ["numpy.random.normal", "numpy.random.normal", "categorical_from_binary.data_generation.bayes_multiclass_reg.generate_designed_features_and_multiclass_labels_for_autoregressive_case", "numpy.shape", "numpy.shape"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.bayes_multiclass_reg.generate_designed_features_and_multiclass_labels_for_autoregressive_case"], ["", "", "def", "test_generate_designed_features_and_multiclass_labels_for_autoregressive_case", "(", ")", ":", "\n", "    ", "num_features_nonautoregressive", "=", "5", "\n", "num_categories", "=", "3", "\n", "num_samples", "=", "100", "\n", "features_non_autoregressive", "=", "np", ".", "random", ".", "normal", "(", "\n", "loc", "=", "0", ",", "scale", "=", "1", ",", "size", "=", "(", "num_samples", ",", "num_features_nonautoregressive", ")", "\n", ")", "\n", "\n", "beta", "=", "np", ".", "random", ".", "normal", "(", "\n", "loc", "=", "0", ",", "\n", "scale", "=", "1", ",", "\n", "size", "=", "(", "num_features_nonautoregressive", "+", "num_categories", ",", "num_categories", ")", ",", "\n", ")", "\n", "\n", "(", "\n", "designed_features", ",", "\n", "labels", ",", "\n", ")", "=", "generate_designed_features_and_multiclass_labels_for_autoregressive_case", "(", "\n", "features_non_autoregressive", ",", "\n", "beta", ",", "\n", ")", "\n", "assert", "labels", "is", "not", "None", "\n", "assert", "np", ".", "shape", "(", "designed_features", ")", "[", "1", "]", ">", "np", ".", "shape", "(", "features_non_autoregressive", ")", "[", "1", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_data_generation.test_data_generation_hierarchical_multiclass_reg._compute_mean_variance_in_betas_across_groups": [[9, 20], ["numpy.array", "numpy.mean", "numpy.var"], "function", ["None"], ["def", "_compute_mean_variance_in_betas_across_groups", "(", "\n", "hierarchical_dataset", ":", "HierarchicalMulticlassRegressionDataset", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Computes the variance in the beta across the groups,\n    and then takes the mean across all elements of the (n_designed_features x n_categories)\n    beta matrix\n    \"\"\"", "\n", "group_betas", "=", "np", ".", "array", "(", "[", "dataset", ".", "beta", "for", "dataset", "in", "hierarchical_dataset", ".", "datasets", "]", ")", "\n", "mean_variance", "=", "np", ".", "mean", "(", "np", ".", "var", "(", "group_betas", ",", "0", ")", ")", "\n", "return", "mean_variance", "\n", "\n"]], "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_data_generation.test_data_generation_hierarchical_multiclass_reg.test_generate_hierarchical_multiclass_regression_dataset": [[22, 58], ["categorical_from_binary.data_generation.hierarchical_multiclass_reg.generate_hierarchical_multiclass_regression_dataset", "test_data_generation_hierarchical_multiclass_reg._compute_mean_variance_in_betas_across_groups", "categorical_from_binary.data_generation.hierarchical_multiclass_reg.generate_hierarchical_multiclass_regression_dataset", "test_data_generation_hierarchical_multiclass_reg._compute_mean_variance_in_betas_across_groups"], "function", ["home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.hierarchical_multiclass_reg.generate_hierarchical_multiclass_regression_dataset", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_data_generation.test_data_generation_hierarchical_multiclass_reg._compute_mean_variance_in_betas_across_groups", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.data_generation.hierarchical_multiclass_reg.generate_hierarchical_multiclass_regression_dataset", "home.repos.pwc.inspect_result.tufts-ml_categorical-from-binary.test_data_generation.test_data_generation_hierarchical_multiclass_reg._compute_mean_variance_in_betas_across_groups"], ["", "def", "test_generate_hierarchical_multiclass_regression_dataset", "(", ")", ":", "\n", "    ", "\"\"\"\n    We test that the function runs without error, and also that\n    the beta's for each group are more dissimilar as s2 increases.\n    \"\"\"", "\n", "n_samples", "=", "50", "\n", "n_features_exogenous", "=", "5", "\n", "n_categories", "=", "3", "\n", "n_groups", "=", "10", "\n", "\n", "for", "is_autoregressive", "in", "[", "True", ",", "False", "]", ":", "\n", "        ", "hd", "=", "generate_hierarchical_multiclass_regression_dataset", "(", "\n", "n_samples", ",", "\n", "n_features_exogenous", ",", "\n", "n_categories", ",", "\n", "n_groups", ",", "\n", "s2_beta", "=", "0.1", ",", "\n", "is_autoregressive", "=", "is_autoregressive", ",", "\n", ")", "\n", "mean_variance_when_expecting_small_variance_in_beta_across_groups", "=", "(", "\n", "_compute_mean_variance_in_betas_across_groups", "(", "hd", ")", "\n", ")", "\n", "hd", "=", "generate_hierarchical_multiclass_regression_dataset", "(", "\n", "n_samples", ",", "\n", "n_features_exogenous", ",", "\n", "n_categories", ",", "\n", "n_groups", ",", "\n", "s2_beta", "=", "2.0", ",", "\n", "is_autoregressive", "=", "is_autoregressive", ",", "\n", ")", "\n", "mean_variance_when_expecting_large_variance_in_beta_across_groups", "=", "(", "\n", "_compute_mean_variance_in_betas_across_groups", "(", "hd", ")", "\n", ")", "\n", "assert", "(", "\n", "mean_variance_when_expecting_small_variance_in_beta_across_groups", "\n", "<", "mean_variance_when_expecting_large_variance_in_beta_across_groups", "\n", ")", "\n"]]}