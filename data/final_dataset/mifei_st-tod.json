{"home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_smd.read_langs_turn": [[9, 50], ["print", "open", "json.load", "enumerate", "data.append", "[].lower().strip", "utils_function.get_input_example", "list", "dialog_history.append", "dialog_history.append", "data.append", "[].lower().strip", "[].lower", "[].lower"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.get_input_example"], ["def", "read_langs_turn", "(", "args", ",", "file_name", ",", "max_line", "=", "None", ",", "ds_name", "=", "\"\"", ")", ":", "\n", "    ", "print", "(", "(", "\"Reading from {} for read_langs_turn\"", ".", "format", "(", "file_name", ")", ")", ")", "\n", "\n", "data", "=", "[", "]", "\n", "\n", "with", "open", "(", "file_name", ")", "as", "f", ":", "\n", "        ", "dials", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "cnt_lin", "=", "1", "\n", "for", "dial_dict", "in", "dials", ":", "\n", "            ", "dialog_history", "=", "[", "]", "\n", "\n", "turn_usr", "=", "\"\"", "\n", "turn_sys", "=", "\"\"", "\n", "for", "ti", ",", "turn", "in", "enumerate", "(", "dial_dict", "[", "\"dialogue\"", "]", ")", ":", "\n", "                ", "if", "turn", "[", "\"turn\"", "]", "==", "\"driver\"", ":", "\n", "                    ", "turn_usr", "=", "turn", "[", "\"data\"", "]", "[", "\"utterance\"", "]", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "\n", "data_detail", "=", "get_input_example", "(", "\"turn\"", ")", "\n", "data_detail", "[", "\"ID\"", "]", "=", "\"{}-{}\"", ".", "format", "(", "ds_name", ",", "cnt_lin", ")", "\n", "data_detail", "[", "\"turn_id\"", "]", "=", "ti", "%", "2", "\n", "data_detail", "[", "\"turn_usr\"", "]", "=", "turn_usr", "\n", "data_detail", "[", "\"turn_sys\"", "]", "=", "turn_sys", "\n", "data_detail", "[", "\"dialog_history\"", "]", "=", "list", "(", "dialog_history", ")", "\n", "\n", "if", "(", "not", "args", "[", "\"only_last_turn\"", "]", ")", ":", "\n", "                        ", "data", ".", "append", "(", "data_detail", ")", "\n", "\n", "", "dialog_history", ".", "append", "(", "turn_sys", ")", "\n", "dialog_history", ".", "append", "(", "turn_usr", ")", "\n", "", "elif", "turn", "[", "\"turn\"", "]", "==", "\"assistant\"", ":", "\n", "                    ", "turn_sys", "=", "turn", "[", "\"data\"", "]", "[", "\"utterance\"", "]", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "\n", "", "", "if", "args", "[", "\"only_last_turn\"", "]", ":", "\n", "                ", "data", ".", "append", "(", "data_detail", ")", "\n", "\n", "", "cnt_lin", "+=", "1", "\n", "if", "(", "max_line", "and", "cnt_lin", ">=", "max_line", ")", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_smd.read_langs_dial": [[52, 55], ["print"], "function", ["None"], ["", "def", "read_langs_dial", "(", "file_name", ",", "ontology", ",", "dialog_act", ",", "max_line", "=", "None", ",", "domain_act_flag", "=", "False", ")", ":", "\n", "    ", "print", "(", "(", "\"Reading from {} for read_langs_dial\"", ".", "format", "(", "file_name", ")", ")", ")", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_smd.prepare_data_smd": [[58, 80], ["os.path.join", "os.path.join", "os.path.join", "print", "print", "print", "globals", "globals", "globals", "len", "len", "len"], "function", ["None"], ["", "def", "prepare_data_smd", "(", "args", ")", ":", "\n", "    ", "ds_name", "=", "\"SMD\"", "\n", "\n", "example_type", "=", "args", "[", "\"example_type\"", "]", "\n", "max_line", "=", "args", "[", "\"max_line\"", "]", "\n", "\n", "file_trn", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "\"kvret/kvret_train_public.json\"", ")", "\n", "file_dev", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "\"kvret/kvret_dev_public.json\"", ")", "\n", "file_tst", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "\"kvret/kvret_test_public.json\"", ")", "\n", "\n", "_example_type", "=", "\"dial\"", "if", "\"dial\"", "in", "example_type", "else", "example_type", "\n", "pair_trn", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "args", ",", "file_trn", ",", "max_line", ",", "ds_name", ")", "\n", "pair_dev", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "args", ",", "file_dev", ",", "max_line", ",", "ds_name", ")", "\n", "pair_tst", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "args", ",", "file_tst", ",", "max_line", ",", "ds_name", ")", "\n", "\n", "print", "(", "\"Read {} pairs train from {}\"", ".", "format", "(", "len", "(", "pair_trn", ")", ",", "ds_name", ")", ")", "\n", "print", "(", "\"Read {} pairs valid from {}\"", ".", "format", "(", "len", "(", "pair_dev", ")", ",", "ds_name", ")", ")", "\n", "print", "(", "\"Read {} pairs test  from {}\"", ".", "format", "(", "len", "(", "pair_tst", ")", ",", "ds_name", ")", ")", "\n", "\n", "meta_data", "=", "{", "\"num_labels\"", ":", "0", "}", "\n", "\n", "return", "pair_trn", ",", "pair_dev", ",", "pair_tst", ",", "meta_data", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_universal_act.read_langs_turn": [[7, 53], ["print", "open", "json.load", "print", "len", "enumerate", "utils_function.get_input_example", "list", "turn[].strip", "[].strip", "data.append", "dialog_history.append", "dialog_history.append", "turn[].strip", "data.append", "dialog_history.append", "dialog_history.append", "[].strip"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.get_input_example"], ["def", "read_langs_turn", "(", "file_name", ",", "max_line", "=", "None", ")", ":", "\n", "    ", "print", "(", "(", "\"Reading from {} for read_langs_turn\"", ".", "format", "(", "file_name", ")", ")", ")", "\n", "\n", "data", "=", "[", "]", "\n", "domain_counter", "=", "{", "}", "\n", "\n", "with", "open", "(", "file_name", ")", "as", "f", ":", "\n", "        ", "dials", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "print", "(", "\"len dials\"", ",", "len", "(", "dials", ")", ")", "\n", "\n", "cnt_lin", "=", "1", "\n", "for", "dial_list", "in", "dials", ":", "\n", "            ", "dialog_history", "=", "[", "]", "\n", "\n", "sys_first_flag", "=", "1", "if", "(", "dial_list", "[", "0", "]", "[", "\"speaker\"", "]", "==", "\"[SYS]\"", ")", "else", "0", "\n", "\n", "# Reading data", "\n", "for", "ti", ",", "turn", "in", "enumerate", "(", "dial_list", ")", ":", "\n", "\n", "                ", "data_detail", "=", "get_input_example", "(", "\"turn\"", ")", "\n", "data_detail", "[", "\"ID\"", "]", "=", "turn", "[", "\"conv_id\"", "]", "\n", "data_detail", "[", "\"dialog_history\"", "]", "=", "list", "(", "dialog_history", ")", "\n", "\n", "if", "sys_first_flag", "and", "ti", "%", "2", "==", "1", ":", "\n", "                    ", "data_detail", "[", "\"turn_id\"", "]", "=", "ti", "//", "2", "\n", "data_detail", "[", "\"turn_usr\"", "]", "=", "turn", "[", "\"raw_text\"", "]", ".", "strip", "(", ")", "\n", "data_detail", "[", "\"turn_sys\"", "]", "=", "dial_list", "[", "ti", "-", "1", "]", "[", "\"raw_text\"", "]", ".", "strip", "(", ")", "\n", "data_detail", "[", "\"sys_act\"", "]", "=", "dial_list", "[", "ti", "-", "1", "]", "[", "\"label\"", "]", "\n", "data", ".", "append", "(", "data_detail", ")", "\n", "dialog_history", ".", "append", "(", "data_detail", "[", "\"turn_sys\"", "]", ")", "\n", "dialog_history", ".", "append", "(", "data_detail", "[", "\"turn_usr\"", "]", ")", "\n", "", "elif", "not", "sys_first_flag", "and", "ti", "%", "2", "==", "0", ":", "\n", "                    ", "data_detail", "[", "\"turn_id\"", "]", "=", "(", "ti", "+", "1", ")", "//", "2", "\n", "data_detail", "[", "\"turn_usr\"", "]", "=", "turn", "[", "\"raw_text\"", "]", ".", "strip", "(", ")", "\n", "data_detail", "[", "\"turn_sys\"", "]", "=", "dial_list", "[", "ti", "-", "1", "]", "[", "\"raw_text\"", "]", ".", "strip", "(", ")", "if", "ti", ">", "0", "else", "\"\"", "\n", "data_detail", "[", "\"sys_act\"", "]", "=", "dial_list", "[", "ti", "-", "1", "]", "[", "\"label\"", "]", "if", "ti", ">", "0", "else", "[", "]", "\n", "data", ".", "append", "(", "data_detail", ")", "\n", "dialog_history", ".", "append", "(", "data_detail", "[", "\"turn_sys\"", "]", ")", "\n", "dialog_history", ".", "append", "(", "data_detail", "[", "\"turn_usr\"", "]", ")", "\n", "\n", "", "", "cnt_lin", "+=", "1", "\n", "if", "(", "max_line", "and", "cnt_lin", ">=", "max_line", ")", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_universal_act.read_langs_dial": [[55, 57], ["None"], "function", ["None"], ["", "def", "read_langs_dial", "(", "file_name", ",", "label_dict", ",", "max_line", "=", "None", ")", ":", "\n", "    ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_universal_act.prepare_data_universal_act_dstc2": [[59, 83], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "print", "print", "print", "print", "line.replace", "len", "enumerate", "globals", "globals", "globals", "len", "len", "len", "open().readlines", "open"], "function", ["None"], ["", "def", "prepare_data_universal_act_dstc2", "(", "args", ")", ":", "\n", "    ", "example_type", "=", "args", "[", "\"example_type\"", "]", "\n", "max_line", "=", "args", "[", "\"max_line\"", "]", "\n", "\n", "file_trn", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'universal_dialog_act/dstc2/train.json'", ")", "\n", "file_dev", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'universal_dialog_act/dstc2/valid.json'", ")", "\n", "file_tst", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'universal_dialog_act/dstc2/test.json'", ")", "\n", "file_label", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'universal_dialog_act/dstc2/labels.txt'", ")", "\n", "#file_label = '/export/home/dialog_datasets/universal_dialog_act/acts.txt'", "\n", "label_dict", "=", "{", "line", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ":", "i", "for", "i", ",", "line", "in", "enumerate", "(", "open", "(", "file_label", ",", "\"r\"", ")", ".", "readlines", "(", ")", ")", "}", "\n", "\n", "_example_type", "=", "\"dial\"", "if", "\"dial\"", "in", "example_type", "else", "example_type", "\n", "pair_trn", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "file_trn", ",", "max_line", ")", "\n", "pair_dev", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "file_dev", ",", "max_line", ")", "\n", "pair_tst", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "file_tst", ",", "max_line", ")", "\n", "\n", "print", "(", "\"Read {} pairs train from {}\"", ".", "format", "(", "len", "(", "pair_trn", ")", ",", "file_trn", ")", ")", "\n", "print", "(", "\"Read {} pairs valid from {}\"", ".", "format", "(", "len", "(", "pair_dev", ")", ",", "file_dev", ")", ")", "\n", "print", "(", "\"Read {} pairs test from  {}\"", ".", "format", "(", "len", "(", "pair_tst", ")", ",", "file_tst", ")", ")", "\n", "\n", "meta_data", "=", "{", "\"sysact\"", ":", "label_dict", ",", "\"num_labels\"", ":", "len", "(", "label_dict", ")", "}", "\n", "print", "(", "\"meta_data\"", ",", "meta_data", ")", "\n", "\n", "return", "pair_trn", ",", "pair_dev", ",", "pair_tst", ",", "meta_data", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_universal_act.prepare_data_universal_act_sim_joint": [[85, 109], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "print", "print", "print", "print", "line.replace", "len", "enumerate", "globals", "globals", "globals", "len", "len", "len", "open().readlines", "open"], "function", ["None"], ["", "def", "prepare_data_universal_act_sim_joint", "(", "args", ")", ":", "\n", "    ", "example_type", "=", "args", "[", "\"example_type\"", "]", "\n", "max_line", "=", "args", "[", "\"max_line\"", "]", "\n", "\n", "file_trn", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'universal_dialog_act/sim_joint/train.json'", ")", "\n", "file_dev", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'universal_dialog_act/sim_joint/valid.json'", ")", "\n", "file_tst", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'universal_dialog_act/sim_joint/test.json'", ")", "\n", "file_label", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'universal_dialog_act/sim_joint/labels.txt'", ")", "\n", "#file_label = '/export/home/dialog_datasets/universal_dialog_act/acts.txt'", "\n", "label_dict", "=", "{", "line", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ":", "i", "for", "i", ",", "line", "in", "enumerate", "(", "open", "(", "file_label", ",", "\"r\"", ")", ".", "readlines", "(", ")", ")", "}", "\n", "\n", "_example_type", "=", "\"dial\"", "if", "\"dial\"", "in", "example_type", "else", "example_type", "\n", "pair_trn", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "file_trn", ",", "max_line", ")", "\n", "pair_dev", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "file_dev", ",", "max_line", ")", "\n", "pair_tst", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "file_tst", ",", "max_line", ")", "\n", "\n", "print", "(", "\"Read {} pairs train from {}\"", ".", "format", "(", "len", "(", "pair_trn", ")", ",", "file_trn", ")", ")", "\n", "print", "(", "\"Read {} pairs valid from {}\"", ".", "format", "(", "len", "(", "pair_dev", ")", ",", "file_dev", ")", ")", "\n", "print", "(", "\"Read {} pairs test from  {}\"", ".", "format", "(", "len", "(", "pair_tst", ")", ",", "file_tst", ")", ")", "\n", "\n", "meta_data", "=", "{", "\"sysact\"", ":", "label_dict", ",", "\"num_labels\"", ":", "len", "(", "label_dict", ")", "}", "\n", "print", "(", "\"meta_data\"", ",", "meta_data", ")", "\n", "\n", "return", "pair_trn", ",", "pair_dev", ",", "pair_tst", ",", "meta_data", "\n", "", ""]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_frames.read_langs_turn": [[9, 51], ["print", "open", "json.load", "enumerate", "data.append", "turn[].lower().strip", "utils_function.get_input_example", "list", "dialog_history.append", "dialog_history.append", "data.append", "turn[].lower().strip", "turn[].lower", "turn[].lower"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.get_input_example"], ["def", "read_langs_turn", "(", "args", ",", "file_name", ",", "max_line", "=", "None", ",", "ds_name", "=", "\"\"", ")", ":", "\n", "    ", "print", "(", "(", "\"Reading from {} for read_langs_turn\"", ".", "format", "(", "file_name", ")", ")", ")", "\n", "\n", "data", "=", "[", "]", "\n", "\n", "with", "open", "(", "file_name", ")", "as", "f", ":", "\n", "        ", "dials", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "cnt_lin", "=", "1", "\n", "for", "dial_dict", "in", "dials", ":", "\n", "            ", "dialog_history", "=", "[", "]", "\n", "\n", "turn_usr", "=", "\"\"", "\n", "turn_sys", "=", "\"\"", "\n", "for", "ti", ",", "turn", "in", "enumerate", "(", "dial_dict", "[", "\"turns\"", "]", ")", ":", "\n", "                ", "if", "turn", "[", "\"author\"", "]", "==", "\"user\"", ":", "\n", "                    ", "turn_usr", "=", "turn", "[", "\"text\"", "]", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "\n", "data_detail", "=", "get_input_example", "(", "\"turn\"", ")", "\n", "data_detail", "[", "\"ID\"", "]", "=", "\"{}-{}\"", ".", "format", "(", "ds_name", ",", "cnt_lin", ")", "\n", "data_detail", "[", "\"turn_id\"", "]", "=", "ti", "%", "2", "\n", "data_detail", "[", "\"turn_usr\"", "]", "=", "turn_usr", "\n", "data_detail", "[", "\"turn_sys\"", "]", "=", "turn_sys", "\n", "data_detail", "[", "\"dialog_history\"", "]", "=", "list", "(", "dialog_history", ")", "\n", "\n", "if", "not", "args", "[", "\"only_last_turn\"", "]", ":", "\n", "                        ", "data", ".", "append", "(", "data_detail", ")", "\n", "\n", "", "dialog_history", ".", "append", "(", "turn_sys", ")", "\n", "dialog_history", ".", "append", "(", "turn_usr", ")", "\n", "\n", "", "elif", "turn", "[", "\"author\"", "]", "==", "\"wizard\"", ":", "\n", "                    ", "turn_sys", "=", "turn", "[", "\"text\"", "]", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "\n", "", "", "if", "args", "[", "\"only_last_turn\"", "]", ":", "\n", "                ", "data", ".", "append", "(", "data_detail", ")", "\n", "\n", "", "cnt_lin", "+=", "1", "\n", "if", "(", "max_line", "and", "cnt_lin", ">=", "max_line", ")", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_frames.read_langs_dial": [[53, 57], ["print"], "function", ["None"], ["", "def", "read_langs_dial", "(", "file_name", ",", "ontology", ",", "dialog_act", ",", "max_line", "=", "None", ",", "domain_act_flag", "=", "False", ")", ":", "\n", "    ", "print", "(", "(", "\"Reading from {} for read_langs_dial\"", ".", "format", "(", "file_name", ")", ")", ")", "\n", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_frames.prepare_data_frames": [[60, 80], ["os.path.join", "print", "print", "print", "globals", "len", "len", "len"], "function", ["None"], ["", "def", "prepare_data_frames", "(", "args", ")", ":", "\n", "    ", "ds_name", "=", "\"FRAMES\"", "\n", "\n", "example_type", "=", "args", "[", "\"example_type\"", "]", "\n", "max_line", "=", "args", "[", "\"max_line\"", "]", "\n", "\n", "file_trn", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "\"frames.json\"", ")", "\n", "\n", "_example_type", "=", "\"dial\"", "if", "\"dial\"", "in", "example_type", "else", "example_type", "\n", "pair_trn", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "args", ",", "file_trn", ",", "max_line", ",", "ds_name", ")", "\n", "pair_dev", "=", "[", "]", "\n", "pair_tst", "=", "[", "]", "\n", "\n", "print", "(", "\"Read {} pairs train from {}\"", ".", "format", "(", "len", "(", "pair_trn", ")", ",", "ds_name", ")", ")", "\n", "print", "(", "\"Read {} pairs valid from {}\"", ".", "format", "(", "len", "(", "pair_dev", ")", ",", "ds_name", ")", ")", "\n", "print", "(", "\"Read {} pairs test  from {}\"", ".", "format", "(", "len", "(", "pair_tst", ")", ",", "ds_name", ")", ")", "\n", "\n", "meta_data", "=", "{", "\"num_labels\"", ":", "0", "}", "\n", "\n", "return", "pair_trn", ",", "pair_dev", ",", "pair_tst", ",", "meta_data", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_metalwoz.read_langs_turn": [[9, 50], ["print", "open", "open.readlines", "json.loads", "enumerate", "data.append", "turn.lower().strip", "turn.lower().strip", "utils_function.get_input_example", "list", "dialog_history.append", "dialog_history.append", "data.append", "turn.lower", "turn.lower"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.get_input_example"], ["def", "read_langs_turn", "(", "args", ",", "dial_files", ",", "max_line", "=", "None", ",", "ds_name", "=", "\"\"", ")", ":", "\n", "    ", "print", "(", "(", "\"Reading from {} for read_langs_turn\"", ".", "format", "(", "ds_name", ")", ")", ")", "\n", "\n", "data", "=", "[", "]", "\n", "\n", "cnt_lin", "=", "1", "\n", "for", "dial_file", "in", "dial_files", ":", "\n", "\n", "        ", "f_dials", "=", "open", "(", "dial_file", ",", "'r'", ")", "\n", "dials", "=", "f_dials", ".", "readlines", "(", ")", "\n", "\n", "for", "dial", "in", "dials", ":", "\n", "            ", "dialog_history", "=", "[", "]", "\n", "dial_dict", "=", "json", ".", "loads", "(", "dial", ")", "\n", "# Reading data", "\n", "for", "ti", ",", "turn", "in", "enumerate", "(", "dial_dict", "[", "\"turns\"", "]", ")", ":", "\n", "                ", "if", "ti", "%", "2", "==", "0", ":", "\n", "                    ", "turn_sys", "=", "turn", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "", "else", ":", "\n", "                    ", "turn_usr", "=", "turn", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "data_detail", "=", "get_input_example", "(", "\"turn\"", ")", "\n", "data_detail", "[", "\"ID\"", "]", "=", "\"{}-{}\"", ".", "format", "(", "ds_name", ",", "cnt_lin", ")", "\n", "data_detail", "[", "\"turn_id\"", "]", "=", "ti", "%", "2", "\n", "data_detail", "[", "\"turn_usr\"", "]", "=", "turn_usr", "\n", "data_detail", "[", "\"turn_sys\"", "]", "=", "turn_sys", "\n", "data_detail", "[", "\"dialog_history\"", "]", "=", "list", "(", "dialog_history", ")", "\n", "\n", "if", "not", "args", "[", "\"only_last_turn\"", "]", ":", "\n", "                        ", "data", ".", "append", "(", "data_detail", ")", "\n", "\n", "", "dialog_history", ".", "append", "(", "turn_sys", ")", "\n", "dialog_history", ".", "append", "(", "turn_usr", ")", "\n", "\n", "", "", "if", "args", "[", "\"only_last_turn\"", "]", ":", "\n", "                ", "data", ".", "append", "(", "data_detail", ")", "\n", "\n", "", "cnt_lin", "+=", "1", "\n", "if", "(", "max_line", "and", "cnt_lin", ">=", "max_line", ")", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_metalwoz.read_langs_dial": [[52, 56], ["print"], "function", ["None"], ["", "def", "read_langs_dial", "(", "file_name", ",", "ontology", ",", "dialog_act", ",", "max_line", "=", "None", ",", "domain_act_flag", "=", "False", ")", ":", "\n", "    ", "print", "(", "(", "\"Reading from {} for read_langs_dial\"", ".", "format", "(", "file_name", ")", ")", ")", "\n", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_metalwoz.prepare_data_metalwoz": [[59, 79], ["print", "print", "print", "os.path.join", "os.listdir", "globals", "len", "len", "len", "os.path.join"], "function", ["None"], ["", "def", "prepare_data_metalwoz", "(", "args", ")", ":", "\n", "    ", "ds_name", "=", "\"MetaLWOZ\"", "\n", "\n", "example_type", "=", "args", "[", "\"example_type\"", "]", "\n", "max_line", "=", "args", "[", "\"max_line\"", "]", "\n", "\n", "onlyfiles", "=", "[", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'metalwoz/dialogues/{}'", ".", "format", "(", "f", ")", ")", "for", "f", "in", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "\"metalwoz/dialogues/\"", ")", ")", "if", "\".txt\"", "in", "f", "]", "\n", "\n", "_example_type", "=", "\"dial\"", "if", "\"dial\"", "in", "example_type", "else", "example_type", "\n", "pair_trn", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "args", ",", "onlyfiles", ",", "max_line", ",", "ds_name", ")", "\n", "pair_dev", "=", "[", "]", "\n", "pair_tst", "=", "[", "]", "\n", "\n", "print", "(", "\"Read {} pairs train from {}\"", ".", "format", "(", "len", "(", "pair_trn", ")", ",", "ds_name", ")", ")", "\n", "print", "(", "\"Read {} pairs valid from {}\"", ".", "format", "(", "len", "(", "pair_dev", ")", ",", "ds_name", ")", ")", "\n", "print", "(", "\"Read {} pairs test  from {}\"", ".", "format", "(", "len", "(", "pair_tst", ")", ",", "ds_name", ")", ")", "\n", "\n", "meta_data", "=", "{", "\"num_labels\"", ":", "0", "}", "\n", "\n", "return", "pair_trn", ",", "pair_dev", ",", "pair_tst", ",", "meta_data", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_woz.read_langs_turn": [[9, 48], ["print", "open", "json.load", "enumerate", "turn[].lower().strip", "turn[].lower().strip", "utils_function.get_input_example", "list", "dialog_history.append", "dialog_history.append", "data.append", "data.append", "turn[].lower", "turn[].lower"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.get_input_example"], ["def", "read_langs_turn", "(", "args", ",", "file_name", ",", "max_line", "=", "None", ",", "ds_name", "=", "\"\"", ")", ":", "\n", "    ", "print", "(", "(", "\"Reading from {} for read_langs_turn\"", ".", "format", "(", "file_name", ")", ")", ")", "\n", "\n", "data", "=", "[", "]", "\n", "\n", "with", "open", "(", "file_name", ")", "as", "f", ":", "\n", "        ", "dials", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "cnt_lin", "=", "1", "\n", "for", "dial_dict", "in", "dials", ":", "\n", "            ", "dialog_history", "=", "[", "]", "\n", "\n", "# Reading data", "\n", "for", "ti", ",", "turn", "in", "enumerate", "(", "dial_dict", "[", "\"dialogue\"", "]", ")", ":", "\n", "                ", "assert", "ti", "==", "turn", "[", "\"turn_idx\"", "]", "\n", "turn_usr", "=", "turn", "[", "\"transcript\"", "]", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "turn_sys", "=", "turn", "[", "\"system_transcript\"", "]", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "\n", "data_detail", "=", "get_input_example", "(", "\"turn\"", ")", "\n", "data_detail", "[", "\"ID\"", "]", "=", "\"{}-{}\"", ".", "format", "(", "ds_name", ",", "cnt_lin", ")", "\n", "data_detail", "[", "\"turn_id\"", "]", "=", "turn", "[", "\"turn_idx\"", "]", "\n", "data_detail", "[", "\"turn_usr\"", "]", "=", "turn_usr", "\n", "data_detail", "[", "\"turn_sys\"", "]", "=", "turn_sys", "\n", "data_detail", "[", "\"dialog_history\"", "]", "=", "list", "(", "dialog_history", ")", "\n", "\n", "if", "not", "args", "[", "\"only_last_turn\"", "]", ":", "\n", "                    ", "data", ".", "append", "(", "data_detail", ")", "\n", "\n", "", "dialog_history", ".", "append", "(", "turn_sys", ")", "\n", "dialog_history", ".", "append", "(", "turn_usr", ")", "\n", "\n", "", "if", "args", "[", "\"only_last_turn\"", "]", ":", "\n", "                ", "data", ".", "append", "(", "data_detail", ")", "\n", "\n", "", "cnt_lin", "+=", "1", "\n", "if", "(", "max_line", "and", "cnt_lin", ">=", "max_line", ")", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_woz.read_langs_dial": [[50, 53], ["print"], "function", ["None"], ["", "def", "read_langs_dial", "(", "file_name", ",", "ontology", ",", "dialog_act", ",", "max_line", "=", "None", ",", "domain_act_flag", "=", "False", ")", ":", "\n", "    ", "print", "(", "(", "\"Reading from {} for read_langs_dial\"", ".", "format", "(", "file_name", ")", ")", ")", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_woz.prepare_data_woz": [[55, 77], ["os.path.join", "os.path.join", "os.path.join", "print", "print", "print", "globals", "globals", "globals", "len", "len", "len"], "function", ["None"], ["", "def", "prepare_data_woz", "(", "args", ")", ":", "\n", "    ", "ds_name", "=", "\"WOZ\"", "\n", "\n", "example_type", "=", "args", "[", "\"example_type\"", "]", "\n", "max_line", "=", "args", "[", "\"max_line\"", "]", "\n", "\n", "file_trn", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "\"neural-belief-tracker/data/woz/woz_train_en.json\"", ")", "\n", "file_dev", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "\"neural-belief-tracker/data/woz/woz_validate_en.json\"", ")", "\n", "file_tst", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "\"neural-belief-tracker/data/woz/woz_test_en.json\"", ")", "\n", "\n", "_example_type", "=", "\"dial\"", "if", "\"dial\"", "in", "example_type", "else", "example_type", "\n", "pair_trn", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "args", ",", "file_trn", ",", "max_line", ",", "ds_name", ")", "\n", "pair_dev", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "args", ",", "file_dev", ",", "max_line", ",", "ds_name", ")", "\n", "pair_tst", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "args", ",", "file_tst", ",", "max_line", ",", "ds_name", ")", "\n", "\n", "print", "(", "\"Read {} pairs train from {}\"", ".", "format", "(", "len", "(", "pair_trn", ")", ",", "ds_name", ")", ")", "\n", "print", "(", "\"Read {} pairs valid from {}\"", ".", "format", "(", "len", "(", "pair_dev", ")", ",", "ds_name", ")", ")", "\n", "print", "(", "\"Read {} pairs test  from {}\"", ".", "format", "(", "len", "(", "pair_tst", ")", ",", "ds_name", ")", ")", "\n", "\n", "meta_data", "=", "{", "\"num_labels\"", ":", "0", "}", "\n", "\n", "return", "pair_trn", ",", "pair_dev", ",", "pair_tst", ",", "meta_data", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda": [[6, 9], ["torch.cuda.is_available", "x.cuda.cuda"], "function", ["None"], ["def", "to_cuda", "(", "x", ")", ":", "\n", "    ", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "x", "=", "x", ".", "cuda", "(", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge": [[11, 24], ["enumerate", "padded_seqs.detach.detach", "len", "max", "torch.ones().long", "type", "type", "max", "torch.ones", "len"], "function", ["None"], ["", "def", "merge", "(", "sequences", ",", "ignore_idx", "=", "None", ")", ":", "\n", "    ", "'''\n    merge from batch * sent_len to batch * max_len \n    '''", "\n", "pad_token", "=", "PAD_token", "if", "type", "(", "ignore_idx", ")", "==", "type", "(", "None", ")", "else", "ignore_idx", "\n", "lengths", "=", "[", "len", "(", "seq", ")", "for", "seq", "in", "sequences", "]", "\n", "max_len", "=", "1", "if", "max", "(", "lengths", ")", "==", "0", "else", "max", "(", "lengths", ")", "\n", "padded_seqs", "=", "torch", ".", "ones", "(", "len", "(", "sequences", ")", ",", "max_len", ")", ".", "long", "(", ")", "*", "pad_token", "\n", "for", "i", ",", "seq", "in", "enumerate", "(", "sequences", ")", ":", "\n", "        ", "end", "=", "lengths", "[", "i", "]", "\n", "padded_seqs", "[", "i", ",", ":", "end", "]", "=", "seq", "[", ":", "end", "]", "\n", "", "padded_seqs", "=", "padded_seqs", ".", "detach", "(", ")", "#torch.tensor(padded_seqs)", "\n", "return", "padded_seqs", ",", "lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge_multi_response": [[26, 46], ["max", "torch.tensor().long", "torch.tensor", "torch.tensor.append", "torch.tensor().long.append", "type", "type", "len", "max", "pad_seq.append", "torch.tensor", "len"], "function", ["None"], ["", "def", "merge_multi_response", "(", "sequences", ",", "ignore_idx", "=", "None", ")", ":", "\n", "    ", "'''\n    merge from batch * nb_slot * slot_len to batch * nb_slot * max_slot_len\n    '''", "\n", "pad_token", "=", "PAD_token", "if", "type", "(", "ignore_idx", ")", "==", "type", "(", "None", ")", "else", "ignore_idx", "\n", "lengths", "=", "[", "]", "\n", "for", "bsz_seq", "in", "sequences", ":", "\n", "        ", "length", "=", "[", "len", "(", "v", ")", "for", "v", "in", "bsz_seq", "]", "\n", "lengths", ".", "append", "(", "length", ")", "\n", "", "max_len", "=", "max", "(", "[", "max", "(", "l", ")", "for", "l", "in", "lengths", "]", ")", "\n", "padded_seqs", "=", "[", "]", "\n", "for", "bsz_seq", "in", "sequences", ":", "\n", "        ", "pad_seq", "=", "[", "]", "\n", "for", "v", "in", "bsz_seq", ":", "\n", "            ", "v", "=", "v", "+", "[", "pad_token", "]", "*", "(", "max_len", "-", "len", "(", "v", ")", ")", "\n", "pad_seq", ".", "append", "(", "v", ")", "\n", "", "padded_seqs", ".", "append", "(", "pad_seq", ")", "\n", "", "padded_seqs", "=", "torch", ".", "tensor", "(", "padded_seqs", ")", ".", "long", "(", ")", "\n", "lengths", "=", "torch", ".", "tensor", "(", "lengths", ")", "\n", "return", "padded_seqs", ",", "lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge_sent_and_word": [[48, 70], ["max", "max", "enumerate", "torch.LongTensor", "padded_seqs.detach.detach", "lengths.append", "numpy.ones", "enumerate", "len", "len", "type", "type", "numpy.array", "len", "len"], "function", ["None"], ["", "def", "merge_sent_and_word", "(", "sequences", ",", "ignore_idx", "=", "None", ")", ":", "\n", "    ", "'''\n    merge from batch * nb_sent * nb_word to batch * max_nb_sent * max_nb_word\n    '''", "\n", "\n", "max_nb_sent", "=", "max", "(", "[", "len", "(", "seq", ")", "for", "seq", "in", "sequences", "]", ")", "\n", "max_nb_word", ",", "lengths", "=", "[", "]", ",", "[", "]", "\n", "for", "seq", "in", "sequences", ":", "\n", "        ", "length", "=", "[", "len", "(", "sent", ")", "for", "sent", "in", "seq", "]", "\n", "max_nb_word", "+=", "length", "\n", "lengths", ".", "append", "(", "length", ")", "\n", "", "max_nb_word", "=", "max", "(", "max_nb_word", ")", "\n", "\n", "pad_token", "=", "PAD_token", "if", "type", "(", "ignore_idx", ")", "==", "type", "(", "None", ")", "else", "ignore_idx", "\n", "padded_seqs", "=", "np", ".", "ones", "(", "(", "len", "(", "sequences", ")", ",", "max_nb_sent", ",", "max_nb_word", ")", ")", "*", "pad_token", "\n", "\n", "for", "i", ",", "seq", "in", "enumerate", "(", "sequences", ")", ":", "\n", "        ", "for", "ii", ",", "sent", "in", "enumerate", "(", "seq", ")", ":", "\n", "            ", "padded_seqs", "[", "i", ",", "ii", ",", ":", "len", "(", "sent", ")", "]", "=", "np", ".", "array", "(", "sent", ")", "\n", "", "", "padded_seqs", "=", "torch", ".", "LongTensor", "(", "padded_seqs", ")", "\n", "padded_seqs", "=", "padded_seqs", ".", "detach", "(", ")", "\n", "return", "padded_seqs", ",", "lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.get_input_example": [[72, 125], ["None"], "function", ["None"], ["", "def", "get_input_example", "(", "example_type", ")", ":", "\n", "\n", "    ", "if", "example_type", "==", "\"turn\"", ":", "\n", "\n", "        ", "data_detail", "=", "{", "\n", "\"ID\"", ":", "\"\"", ",", "\n", "\"turn_id\"", ":", "0", ",", "\n", "\"domains\"", ":", "[", "]", ",", "\n", "\"turn_domain\"", ":", "[", "]", ",", "\n", "\"turn_usr\"", ":", "\"\"", ",", "\n", "\"turn_sys\"", ":", "\"\"", ",", "\n", "\"turn_usr_delex\"", ":", "\"\"", ",", "\n", "\"turn_sys_delex\"", ":", "\"\"", ",", "\n", "\"belief_state_vec\"", ":", "[", "]", ",", "\n", "\"db_pointer\"", ":", "[", "]", ",", "\n", "\"dialog_history\"", ":", "[", "]", ",", "\n", "\"dialog_history_delex\"", ":", "[", "]", ",", "\n", "\"belief\"", ":", "{", "}", ",", "\n", "\"del_belief\"", ":", "{", "}", ",", "\n", "\"slot_gate\"", ":", "[", "]", ",", "\n", "\"slot_values\"", ":", "[", "]", ",", "\n", "\"slots\"", ":", "[", "]", ",", "\n", "\"sys_act\"", ":", "[", "]", ",", "\n", "\"usr_act\"", ":", "[", "]", ",", "\n", "\"intent\"", ":", "\"\"", ",", "\n", "\"turn_slot\"", ":", "[", "]", "}", "\n", "\n", "", "elif", "example_type", "==", "\"dial\"", ":", "\n", "\n", "        ", "data_detail", "=", "{", "\n", "\"ID\"", ":", "\"\"", ",", "\n", "\"turn_id\"", ":", "[", "]", ",", "\n", "\"domains\"", ":", "[", "]", ",", "\n", "\"turn_domain\"", ":", "[", "]", ",", "\n", "\"turn_usr\"", ":", "[", "]", ",", "\n", "\"turn_sys\"", ":", "[", "]", ",", "\n", "\"turn_usr_delex\"", ":", "[", "]", ",", "\n", "\"turn_sys_delex\"", ":", "[", "]", ",", "\n", "\"belief_state_vec\"", ":", "[", "]", ",", "\n", "\"db_pointer\"", ":", "[", "]", ",", "\n", "\"dialog_history\"", ":", "[", "]", ",", "\n", "\"dialog_history_delex\"", ":", "[", "]", ",", "\n", "\"belief\"", ":", "[", "]", ",", "\n", "\"del_belief\"", ":", "[", "]", ",", "\n", "\"slot_gate\"", ":", "[", "]", ",", "\n", "\"slot_values\"", ":", "[", "]", ",", "\n", "\"slots\"", ":", "[", "]", ",", "\n", "\"sys_act\"", ":", "[", "]", ",", "\n", "\"usr_act\"", ":", "[", "]", ",", "\n", "\"intent\"", ":", "[", "]", ",", "\n", "\"turn_slot\"", ":", "[", "]", "}", "\n", "\n", "", "return", "data_detail", "\n", "", ""]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlg.Dataset_nlg.__init__": [[11, 36], ["len", "list", "random.shuffle"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_info", ",", "tokenizer", ",", "args", ",", "unified_meta", ",", "mode", ",", "max_length", "=", "512", ",", "max_sys_resp_len", "=", "50", ")", ":", "\n", "        ", "\"\"\"Reads source and target sequences from txt files.\"\"\"", "\n", "self", ".", "data", "=", "data_info", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "num_total_seqs", "=", "len", "(", "data_info", "[", "\"ID\"", "]", ")", "\n", "self", ".", "usr_token", "=", "args", "[", "\"usr_token\"", "]", "\n", "self", ".", "sys_token", "=", "args", "[", "\"sys_token\"", "]", "\n", "self", ".", "unified_meta", "=", "unified_meta", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "mode", "=", "mode", "\n", "\n", "if", "\"bert\"", "in", "self", ".", "args", "[", "\"model_type\"", "]", "or", "\"electra\"", "in", "self", ".", "args", "[", "\"model_type\"", "]", ":", "\n", "            ", "self", ".", "start_token", "=", "self", ".", "tokenizer", ".", "cls_token", "\n", "self", ".", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", "\n", "", "else", ":", "\n", "            ", "self", ".", "start_token", "=", "self", ".", "tokenizer", ".", "bos_token", "\n", "self", ".", "sep_token", "=", "self", ".", "tokenizer", ".", "eos_token", "\n", "\n", "", "self", ".", "resp_cand_trn", "=", "list", "(", "self", ".", "unified_meta", "[", "\"resp_cand_trn\"", "]", ")", "\n", "random", ".", "shuffle", "(", "self", ".", "resp_cand_trn", ")", "\n", "self", ".", "max_sys_resp_len", "=", "max_sys_resp_len", "\n", "self", ".", "others", "=", "unified_meta", "[", "\"others\"", "]", "\n", "\n", "self", ".", "context_plain", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlg.Dataset_nlg.__getitem__": [[37, 115], ["dataloader_nlg.Dataset_nlg.get_concat_context", "dataloader_nlg.Dataset_nlg.preprocess", "dataloader_nlg.Dataset_nlg.preprocess", "dataloader_nlg.Dataset_nlg.preprocess", "dataloader_nlg.Dataset_nlg.preprocess", "dataloader_nlg.Dataset_nlg.preprocess", "dataloader_nlg.Dataset_nlg.context_plain.get", "dataloader_nlg.Dataset_nlg.get_concat_context", "dataloader_nlg.Dataset_nlg.preprocess", "random.randint", "neg_resp_idx_arr.append", "neg_resp_arr.append", "min", "dataloader_nlg.Dataset_nlg.preprocess", "len", "random.randint", "random.randint", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_usdl.Dataset_usdl.get_concat_context", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.preprocess", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.preprocess", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.preprocess", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.preprocess", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.preprocess", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_usdl.Dataset_usdl.get_concat_context", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.preprocess", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.preprocess"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Returns one data pair (source and target).\"\"\"", "\n", "\n", "if", "self", ".", "args", "[", "\"example_type\"", "]", "==", "\"turn\"", ":", "\n", "\n", "            ", "if", "not", "self", ".", "context_plain", ".", "get", "(", "index", ")", ":", "\n", "                ", "context_plain", "=", "self", ".", "get_concat_context", "(", "self", ".", "data", "[", "\"dialog_history\"", "]", "[", "index", "]", ")", "\n", "self", ".", "context_plain", "[", "index", "]", "=", "context_plain", "\n", "", "else", ":", "\n", "                ", "context_plain", "=", "self", ".", "context_plain", "[", "index", "]", "\n", "\n", "", "context_plain_delex", "=", "self", ".", "get_concat_context", "(", "self", ".", "data", "[", "\"dialog_history_delex\"", "]", "[", "index", "]", ")", "\n", "\n", "context", "=", "self", ".", "preprocess", "(", "context_plain", ")", "\n", "context_delex", "=", "self", ".", "preprocess", "(", "context_plain_delex", ")", "\n", "\n", "response_plain", "=", "\"{} \"", ".", "format", "(", "self", ".", "sys_token", ")", "+", "self", ".", "data", "[", "\"turn_sys\"", "]", "[", "index", "]", "\n", "response", "=", "self", ".", "preprocess", "(", "response_plain", ")", "[", ":", "self", ".", "max_sys_resp_len", "]", "\n", "\n", "response_plain_delex", "=", "\"{} \"", ".", "format", "(", "self", ".", "sys_token", ")", "+", "self", ".", "data", "[", "\"turn_sys_delex\"", "]", "[", "index", "]", "\n", "response_delex", "=", "self", ".", "preprocess", "(", "response_plain_delex", ")", "\n", "\n", "utterance_plain", "=", "\"{} \"", ".", "format", "(", "self", ".", "usr_token", ")", "+", "self", ".", "data", "[", "\"turn_usr\"", "]", "[", "index", "]", "\n", "utterance", "=", "self", ".", "preprocess", "(", "utterance_plain", ")", "\n", "\n", "utterance_plain_delex", "=", "\"{} \"", ".", "format", "(", "self", ".", "usr_token", ")", "+", "self", ".", "data", "[", "\"turn_usr_delex\"", "]", "[", "index", "]", "\n", "utterance_delex", "=", "self", ".", "preprocess", "(", "utterance_plain_delex", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "item_info", "=", "{", "\n", "\"index\"", ":", "index", ",", "# return data index to update pesudo labels", "\n", "\"ID\"", ":", "self", ".", "data", "[", "\"ID\"", "]", "[", "index", "]", ",", "\n", "\"turn_id\"", ":", "self", ".", "data", "[", "\"turn_id\"", "]", "[", "index", "]", ",", "\n", "\"context\"", ":", "context", ",", "\n", "\"context_plain\"", ":", "context_plain", ",", "\n", "\"context_delex\"", ":", "context_delex", ",", "\n", "\"context_plain_delex\"", ":", "context_plain_delex", ",", "\n", "\"response\"", ":", "response", ",", "\n", "\"response_plain\"", ":", "response_plain", ",", "\n", "\"response_delex\"", ":", "response_delex", ",", "\n", "\"response_plain_delex\"", ":", "response_plain_delex", ",", "\n", "\"utterance\"", ":", "utterance", ",", "\n", "\"utterance_plain\"", ":", "utterance_plain", ",", "\n", "\"utterance_delex\"", ":", "utterance_delex", ",", "\n", "\"utterance_plain_delex\"", ":", "utterance_plain_delex", "}", "\n", "\n", "if", "self", ".", "args", "[", "\"nb_neg_sample_rs\"", "]", "!=", "0", "and", "self", ".", "mode", "==", "\"train\"", ":", "\n", "\n", "            ", "if", "self", ".", "args", "[", "\"sample_negative_by_kmeans\"", "]", ":", "\n", "                ", "try", ":", "\n", "                    ", "cur_cluster", "=", "self", ".", "others", "[", "\"ToD_BERT_SYS_UTTR_KMEANS\"", "]", "[", "self", ".", "data", "[", "\"turn_sys\"", "]", "[", "index", "]", "]", "\n", "candidates", "=", "self", ".", "others", "[", "\"KMEANS_to_SENTS\"", "]", "[", "cur_cluster", "]", "\n", "nb_selected", "=", "min", "(", "self", ".", "args", "[", "\"nb_neg_sample_rs\"", "]", ",", "len", "(", "candidates", ")", ")", "\n", "try", ":", "\n", "                        ", "start_pos", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "candidates", ")", "-", "nb_selected", "-", "1", ")", "\n", "", "except", ":", "\n", "                        ", "start_pos", "=", "0", "\n", "", "sampled_neg_resps", "=", "candidates", "[", "start_pos", ":", "start_pos", "+", "nb_selected", "]", "\n", "\n", "", "except", ":", "\n", "                    ", "start_pos", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "resp_cand_trn", ")", "-", "self", ".", "args", "[", "\"nb_neg_sample_rs\"", "]", "-", "1", ")", "\n", "sampled_neg_resps", "=", "self", ".", "resp_cand_trn", "[", "start_pos", ":", "start_pos", "+", "self", ".", "args", "[", "\"nb_neg_sample_rs\"", "]", "]", "\n", "", "", "else", ":", "\n", "                ", "start_pos", "=", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "resp_cand_trn", ")", "-", "self", ".", "args", "[", "\"nb_neg_sample_rs\"", "]", "-", "1", ")", "\n", "sampled_neg_resps", "=", "self", ".", "resp_cand_trn", "[", "start_pos", ":", "start_pos", "+", "self", ".", "args", "[", "\"nb_neg_sample_rs\"", "]", "]", "\n", "\n", "", "neg_resp_arr", ",", "neg_resp_idx_arr", "=", "[", "]", ",", "[", "]", "\n", "for", "neg_resp", "in", "sampled_neg_resps", ":", "\n", "                ", "neg_resp_plain", "=", "\"{} \"", ".", "format", "(", "self", ".", "sys_token", ")", "+", "neg_resp", "\n", "neg_resp_idx", "=", "self", ".", "preprocess", "(", "neg_resp_plain", ")", "[", ":", "self", ".", "max_sys_resp_len", "]", "\n", "neg_resp_idx_arr", ".", "append", "(", "neg_resp_idx", ")", "\n", "neg_resp_arr", ".", "append", "(", "neg_resp_plain", ")", "\n", "\n", "", "item_info", "[", "\"neg_resp_idx_arr\"", "]", "=", "neg_resp_idx_arr", "\n", "item_info", "[", "\"neg_resp_arr\"", "]", "=", "neg_resp_arr", "\n", "\n", "", "return", "item_info", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlg.Dataset_nlg.__len__": [[116, 118], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_total_seqs", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlg.Dataset_nlg.preprocess": [[119, 124], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "dataloader_nlg.Dataset_nlg.tokenizer.tokenize", "dataloader_nlg.Dataset_nlg.tokenizer.convert_tokens_to_ids", "dataloader_nlg.Dataset_nlg.tokenizer.tokenize"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"Converts words to ids.\"\"\"", "\n", "tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "self", ".", "start_token", ")", "+", "self", ".", "tokenizer", ".", "tokenize", "(", "sequence", ")", "[", "-", "self", ".", "max_length", "+", "1", ":", "]", "\n", "story", "=", "torch", ".", "Tensor", "(", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", ")", "\n", "return", "story", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlg.Dataset_nlg.set_pesudo_label": [[125, 131], ["zip"], "methods", ["None"], ["", "def", "set_pesudo_label", "(", "self", ",", "indexes", ",", "text_labels", ")", ":", "\n", "        ", "'''set labels to indexes'''", "\n", "for", "ind", ",", "label", "in", "zip", "(", "indexes", ",", "text_labels", ")", ":", "\n", "# print (self.data[\"turn_sys\"][ind])", "\n", "# print (label)", "\n", "            ", "self", ".", "data", "[", "\"turn_sys\"", "]", "[", "ind", "]", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlg.Dataset_nlg.get_concat_context": [[132, 141], ["enumerate", "dialog_history_str.strip.strip.strip"], "methods", ["None"], ["", "", "def", "get_concat_context", "(", "self", ",", "dialog_history", ")", ":", "\n", "        ", "dialog_history_str", "=", "\"\"", "\n", "for", "ui", ",", "uttr", "in", "enumerate", "(", "dialog_history", ")", ":", "\n", "            ", "if", "ui", "%", "2", "==", "0", ":", "\n", "                ", "dialog_history_str", "+=", "\"{} {} \"", ".", "format", "(", "self", ".", "sys_token", ",", "uttr", ")", "\n", "", "else", ":", "\n", "                ", "dialog_history_str", "+=", "\"{} {} \"", ".", "format", "(", "self", ".", "usr_token", ",", "uttr", ")", "\n", "", "", "dialog_history_str", "=", "dialog_history_str", ".", "strip", "(", ")", "\n", "return", "dialog_history_str", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlg.Dataset_nlg.reset_nlg_context": [[142, 144], ["None"], "methods", ["None"], ["", "def", "reset_nlg_context", "(", "self", ",", "index", ",", "new_sent", ")", ":", "\n", "        ", "self", ".", "context_plain", "[", "index", "]", "=", "new_sent", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlg.collate_fn_nlg_turn": [[146, 191], ["torch.sort", "data[].keys", "utils_function.merge", "utils_function.merge", "utils_function.merge", "utils_function.merge", "utils_function.merge", "utils_function.merge", "utils_function.to_cuda", "utils_function.to_cuda", "utils_function.to_cuda", "item_info.keys", "enumerate", "enumerate", "len"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda"], ["", "", "def", "collate_fn_nlg_turn", "(", "data", ")", ":", "\n", "# sort a list by sequence length (descending order) to use pack_padded_sequence", "\n", "    ", "data", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "'context'", "]", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "item_info", "=", "{", "}", "\n", "for", "key", "in", "data", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "        ", "item_info", "[", "key", "]", "=", "[", "d", "[", "key", "]", "for", "d", "in", "data", "]", "\n", "\n", "# augment negative samples", "\n", "", "if", "\"neg_resp_idx_arr\"", "in", "item_info", ".", "keys", "(", ")", ":", "\n", "        ", "neg_resp_idx_arr", "=", "[", "]", "\n", "for", "arr", "in", "item_info", "[", "'neg_resp_idx_arr'", "]", ":", "\n", "            ", "neg_resp_idx_arr", "+=", "arr", "\n", "\n", "# remove neg samples that are the same as one of the gold responses", "\n", "#print('item_info[\"response\"]', item_info[\"response\"])", "\n", "#print('neg_resp_idx_arr', neg_resp_idx_arr)", "\n", "\n", "", "for", "bi", ",", "arr", "in", "enumerate", "(", "item_info", "[", "'neg_resp_arr'", "]", ")", ":", "\n", "            ", "for", "ri", ",", "neg_resp", "in", "enumerate", "(", "arr", ")", ":", "\n", "                ", "if", "neg_resp", "not", "in", "item_info", "[", "\"response_plain\"", "]", ":", "\n", "                    ", "item_info", "[", "\"response\"", "]", "+=", "[", "item_info", "[", "'neg_resp_idx_arr'", "]", "[", "bi", "]", "[", "ri", "]", "]", "\n", "\n", "#neg_resp_idx_arr = [ng for ng in neg_resp_idx_arr if ng not in item_info[\"response\"]] ", "\n", "#item_info[\"response\"] += neg_resp_idx_arr", "\n", "\n", "# merge sequences    ", "\n", "", "", "", "", "context", ",", "context_lengths", "=", "merge", "(", "item_info", "[", "'context'", "]", ")", "\n", "context_delex", ",", "context_delex_lengths", "=", "merge", "(", "item_info", "[", "'context_delex'", "]", ")", "\n", "response", ",", "response_lengths", "=", "merge", "(", "item_info", "[", "\"response\"", "]", ")", "\n", "response_delex", ",", "response_delex_lengths", "=", "merge", "(", "item_info", "[", "\"response_delex\"", "]", ")", "\n", "utterance", ",", "utterance_lengths", "=", "merge", "(", "item_info", "[", "\"utterance\"", "]", ")", "\n", "utterance_delex", ",", "utterance_delex_lengths", "=", "merge", "(", "item_info", "[", "\"utterance_delex\"", "]", ")", "\n", "\n", "#print(\"context\", context.size())", "\n", "#print(\"response\", response.size())", "\n", "\n", "item_info", "[", "\"context\"", "]", "=", "to_cuda", "(", "context", ")", "\n", "item_info", "[", "\"context_lengths\"", "]", "=", "context_lengths", "\n", "item_info", "[", "\"response\"", "]", "=", "to_cuda", "(", "response", ")", "\n", "item_info", "[", "\"response_lengths\"", "]", "=", "response_lengths", "\n", "item_info", "[", "\"utterance\"", "]", "=", "to_cuda", "(", "utterance", ")", "\n", "item_info", "[", "\"utterance_lengths\"", "]", "=", "response_lengths", "\n", "\n", "return", "item_info", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_camrest676.read_langs_turn": [[9, 48], ["print", "open", "json.load", "enumerate", "[].lower().strip", "[].lower().strip", "utils_function.get_input_example", "list", "dialog_history.append", "dialog_history.append", "data.append", "str", "data.append", "[].lower", "[].lower"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.get_input_example"], ["def", "read_langs_turn", "(", "args", ",", "file_name", ",", "max_line", "=", "None", ")", ":", "\n", "    ", "print", "(", "(", "\"Reading from {} for read_langs_turn\"", ".", "format", "(", "file_name", ")", ")", ")", "\n", "\n", "data", "=", "[", "]", "\n", "\n", "with", "open", "(", "file_name", ")", "as", "f", ":", "\n", "        ", "dials", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "cnt_lin", "=", "1", "\n", "for", "dial_dict", "in", "dials", ":", "\n", "            ", "dialog_history", "=", "[", "\"\"", "]", "\n", "\n", "# Reading data", "\n", "for", "ti", ",", "turn", "in", "enumerate", "(", "dial_dict", "[", "\"dial\"", "]", ")", ":", "\n", "                ", "assert", "ti", "==", "turn", "[", "\"turn\"", "]", "\n", "turn_usr", "=", "turn", "[", "\"usr\"", "]", "[", "\"transcript\"", "]", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "turn_sys", "=", "turn", "[", "\"sys\"", "]", "[", "\"sent\"", "]", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "\n", "data_detail", "=", "get_input_example", "(", "\"turn\"", ")", "\n", "data_detail", "[", "\"ID\"", "]", "=", "\"camrest676-\"", "+", "str", "(", "cnt_lin", ")", "\n", "data_detail", "[", "\"turn_id\"", "]", "=", "turn", "[", "\"turn\"", "]", "\n", "data_detail", "[", "\"turn_usr\"", "]", "=", "turn_usr", "\n", "data_detail", "[", "\"turn_sys\"", "]", "=", "turn_sys", "\n", "data_detail", "[", "\"dialog_history\"", "]", "=", "list", "(", "dialog_history", ")", "\n", "\n", "if", "not", "args", "[", "\"only_last_turn\"", "]", ":", "\n", "                    ", "data", ".", "append", "(", "data_detail", ")", "\n", "\n", "", "dialog_history", ".", "append", "(", "turn_usr", ")", "\n", "dialog_history", ".", "append", "(", "turn_sys", ")", "\n", "\n", "", "if", "args", "[", "\"only_last_turn\"", "]", ":", "\n", "                ", "data", ".", "append", "(", "data_detail", ")", "\n", "\n", "", "cnt_lin", "+=", "1", "\n", "if", "(", "max_line", "and", "cnt_lin", ">=", "max_line", ")", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_camrest676.read_langs_dial": [[50, 54], ["print"], "function", ["None"], ["", "def", "read_langs_dial", "(", "file_name", ",", "ontology", ",", "dialog_act", ",", "max_line", "=", "None", ",", "domain_act_flag", "=", "False", ")", ":", "\n", "    ", "print", "(", "(", "\"Reading from {} for read_langs_dial\"", ".", "format", "(", "file_name", ")", ")", ")", "\n", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_camrest676.prepare_data_camrest676": [[57, 73], ["os.path.join", "print", "globals", "len"], "function", ["None"], ["", "def", "prepare_data_camrest676", "(", "args", ")", ":", "\n", "    ", "example_type", "=", "args", "[", "\"example_type\"", "]", "\n", "max_line", "=", "args", "[", "\"max_line\"", "]", "\n", "\n", "file_trn", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'CamRest676/CamRest676.json'", ")", "\n", "\n", "_example_type", "=", "\"dial\"", "if", "\"dial\"", "in", "example_type", "else", "example_type", "\n", "pair_trn", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "args", ",", "file_trn", ",", "max_line", ")", "\n", "pair_dev", "=", "[", "]", "\n", "pair_tst", "=", "[", "]", "\n", "\n", "print", "(", "\"Read %s pairs train from CamRest676\"", "%", "len", "(", "pair_trn", ")", ")", "\n", "\n", "meta_data", "=", "{", "\"num_labels\"", ":", "0", "}", "\n", "\n", "return", "pair_trn", ",", "pair_dev", ",", "pair_tst", ",", "meta_data", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_taskmaster.read_langs_turn": [[9, 48], ["print", "enumerate", "data.append", "turn[].lower().strip", "utils_function.get_input_example", "list", "dialog_history.append", "dialog_history.append", "data.append", "turn[].lower().strip", "turn[].lower", "turn[].lower"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.get_input_example"], ["def", "read_langs_turn", "(", "args", ",", "dials", ",", "ds_name", ",", "max_line", ")", ":", "\n", "    ", "print", "(", "(", "\"Reading from {} for read_langs_turn\"", ".", "format", "(", "ds_name", ")", ")", ")", "\n", "\n", "data", "=", "[", "]", "\n", "turn_sys", "=", "\"\"", "\n", "turn_usr", "=", "\"\"", "\n", "\n", "cnt_lin", "=", "1", "\n", "for", "dial", "in", "dials", ":", "\n", "        ", "dialog_history", "=", "[", "]", "\n", "for", "ti", ",", "turn", "in", "enumerate", "(", "dial", "[", "\"utterances\"", "]", ")", ":", "\n", "            ", "if", "turn", "[", "\"speaker\"", "]", "==", "\"USER\"", ":", "\n", "                ", "turn_usr", "=", "turn", "[", "\"text\"", "]", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "\n", "data_detail", "=", "get_input_example", "(", "\"turn\"", ")", "\n", "data_detail", "[", "\"ID\"", "]", "=", "\"{}-{}\"", ".", "format", "(", "ds_name", ",", "cnt_lin", ")", "\n", "data_detail", "[", "\"turn_id\"", "]", "=", "ti", "%", "2", "\n", "data_detail", "[", "\"turn_usr\"", "]", "=", "turn_usr", "\n", "data_detail", "[", "\"turn_sys\"", "]", "=", "turn_sys", "\n", "data_detail", "[", "\"dialog_history\"", "]", "=", "list", "(", "dialog_history", ")", "\n", "\n", "if", "(", "not", "args", "[", "\"only_last_turn\"", "]", ")", ":", "\n", "                    ", "data", ".", "append", "(", "data_detail", ")", "\n", "\n", "", "dialog_history", ".", "append", "(", "turn_sys", ")", "\n", "dialog_history", ".", "append", "(", "turn_usr", ")", "\n", "", "elif", "turn", "[", "\"speaker\"", "]", "==", "\"ASSISTANT\"", ":", "\n", "                ", "turn_sys", "=", "turn", "[", "\"text\"", "]", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "", "else", ":", "\n", "                ", "turn_usr", "+=", "\" {}\"", ".", "format", "(", "turn", "[", "\"text\"", "]", ")", "\n", "\n", "", "", "if", "args", "[", "\"only_last_turn\"", "]", ":", "\n", "            ", "data", ".", "append", "(", "data_detail", ")", "\n", "\n", "", "cnt_lin", "+=", "1", "\n", "if", "(", "max_line", "and", "cnt_lin", ">=", "max_line", ")", ":", "\n", "            ", "break", "\n", "\n", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_taskmaster.read_langs_dial": [[50, 54], ["print"], "function", ["None"], ["", "def", "read_langs_dial", "(", "file_name", ",", "ontology", ",", "dialog_act", ",", "max_line", "=", "None", ",", "domain_act_flag", "=", "False", ")", ":", "\n", "    ", "print", "(", "(", "\"Reading from {} for read_langs_dial\"", ".", "format", "(", "file_name", ")", ")", ")", "\n", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_taskmaster.prepare_data_taskmaster": [[57, 86], ["open", "open", "fr_trn_id.readlines.readlines", "fr_dev_id.readlines.readlines", "open", "open", "print", "print", "print", "os.path.join", "os.path.join", "_id.replace().replace", "_id.replace().replace", "os.path.join", "os.path.join", "json.load", "json.load", "globals", "len", "len", "len", "_id.replace", "_id.replace"], "function", ["None"], ["", "def", "prepare_data_taskmaster", "(", "args", ")", ":", "\n", "    ", "ds_name", "=", "\"TaskMaster\"", "\n", "\n", "example_type", "=", "args", "[", "\"example_type\"", "]", "\n", "max_line", "=", "args", "[", "\"max_line\"", "]", "\n", "\n", "fr_trn_id", "=", "open", "(", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'Taskmaster/TM-1-2019/train-dev-test/train.csv'", ")", ",", "'r'", ")", "\n", "fr_dev_id", "=", "open", "(", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'Taskmaster/TM-1-2019/train-dev-test/dev.csv'", ")", ",", "'r'", ")", "\n", "fr_trn_id", "=", "fr_trn_id", ".", "readlines", "(", ")", "\n", "fr_dev_id", "=", "fr_dev_id", ".", "readlines", "(", ")", "\n", "fr_trn_id", "=", "[", "_id", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\",\"", ",", "\"\"", ")", "for", "_id", "in", "fr_trn_id", "]", "\n", "fr_dev_id", "=", "[", "_id", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ".", "replace", "(", "\",\"", ",", "\"\"", ")", "for", "_id", "in", "fr_dev_id", "]", "\n", "\n", "fr_data_woz", "=", "open", "(", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'Taskmaster/TM-1-2019/woz-dialogs.json'", ")", ",", "'r'", ")", "\n", "fr_data_self", "=", "open", "(", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'Taskmaster/TM-1-2019/self-dialogs.json'", ")", ",", "'r'", ")", "\n", "dials_all", "=", "json", ".", "load", "(", "fr_data_woz", ")", "+", "json", ".", "load", "(", "fr_data_self", ")", "\n", "\n", "_example_type", "=", "\"dial\"", "if", "\"dial\"", "in", "example_type", "else", "example_type", "\n", "pair_trn", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "args", ",", "dials_all", ",", "ds_name", ",", "max_line", ")", "\n", "pair_dev", "=", "[", "]", "\n", "pair_tst", "=", "[", "]", "\n", "\n", "print", "(", "\"Read {} pairs train from {}\"", ".", "format", "(", "len", "(", "pair_trn", ")", ",", "ds_name", ")", ")", "\n", "print", "(", "\"Read {} pairs valid from {}\"", ".", "format", "(", "len", "(", "pair_dev", ")", ",", "ds_name", ")", ")", "\n", "print", "(", "\"Read {} pairs test  from {}\"", ".", "format", "(", "len", "(", "pair_tst", ")", ",", "ds_name", ")", ")", "\n", "\n", "meta_data", "=", "{", "\"num_labels\"", ":", "0", "}", "\n", "\n", "return", "pair_trn", ",", "pair_dev", ",", "pair_tst", ",", "meta_data", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_general.get_loader": [[30, 115], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "print", "print", "len", "print", "combined_ds[].keys", "int", "random.Random().shuffle", "combined_ds[].keys", "data_info[].append", "globals", "random.Random().shuffle", "random.Random().shuffle", "len", "globals", "random.Random", "pair_trn_new.append", "pair_trn_new.append", "random.Random", "random.Random", "int", "int", "len", "len"], "function", ["None"], ["def", "get_loader", "(", "args", ",", "mode", ",", "tokenizer", ",", "datasets", ",", "unified_meta", ",", "shuffle", "=", "False", ",", "for_unlabeled", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Get the initial datasets\n    :param args: global configration\n    :param mode: train/dev/test\n    :param tokenizer: bert tokenizer\n    :param datasets: datasets to be used\n    :param unified_meta: meta information for the dataset\n    :param: shuffle: whether to shuffle the dataset or not\n    :param: for_unlabeled: whether to get the unlabeled instances from the original training dataset\n    :return: train dataset or dev dataset or test dataset or unlabeled dataset\n    \"\"\"", "\n", "task", "=", "args", "[", "\"task\"", "]", "\n", "batch_size", "=", "args", "[", "\"batch_size\"", "]", "if", "mode", "==", "\"train\"", "else", "args", "[", "\"eval_batch_size\"", "]", "\n", "\n", "combined_ds", "=", "[", "]", "\n", "for", "ds", "in", "datasets", ":", "\n", "        ", "combined_ds", "+=", "datasets", "[", "ds", "]", "[", "mode", "]", "\n", "\n", "# do not consider empty system responses", "\n", "", "if", "(", "args", "[", "\"task_name\"", "]", "==", "\"rs\"", ")", "or", "(", "args", "[", "\"task\"", "]", "==", "\"dm\"", ")", ":", "\n", "        ", "print", "(", "\"[Info] Remove turns with empty system response...\"", ")", "\n", "combined_ds", "=", "[", "d", "for", "d", "in", "combined_ds", "if", "d", "[", "\"turn_sys\"", "]", "!=", "\"\"", "]", "\n", "\n", "", "if", "(", "args", "[", "\"task_name\"", "]", "==", "\"rs\"", ")", ":", "\n", "        ", "print", "(", "\"[Info] Remove turn=0 system response...\"", ")", "\n", "combined_ds", "=", "[", "d", "for", "d", "in", "combined_ds", "if", "d", "[", "\"turn_id\"", "]", "!=", "0", "]", "\n", "\n", "# control data ratio", "\n", "", "data_ratio", "=", "args", "[", "\"train_data_ratio\"", "]", "\n", "if", "(", "data_ratio", "!=", "1", "or", "args", "[", "\"nb_shots\"", "]", "!=", "-", "1", ")", "and", "(", "mode", "==", "\"train\"", ")", ":", "\n", "        ", "original_len", "=", "len", "(", "combined_ds", ")", "\n", "\n", "if", "(", "\"oos_intent\"", "in", "args", "[", "\"dataset\"", "]", ")", ":", "\n", "            ", "nb_train_sample_per_class", "=", "int", "(", "100", "*", "data_ratio", ")", "\n", "class_count", "=", "{", "k", ":", "0", "for", "k", "in", "unified_meta", "[", "\"intent\"", "]", "}", "\n", "random", ".", "Random", "(", "args", "[", "\"rand_seed\"", "]", ")", ".", "shuffle", "(", "combined_ds", ")", "\n", "pair_trn_new", "=", "[", "]", "\n", "for", "d", "in", "combined_ds", ":", "\n", "                ", "if", "for_unlabeled", ":", "# take the first nb_train_sample_per_class data for this class", "\n", "                    ", "if", "class_count", "[", "d", "[", "\"intent\"", "]", "]", "<", "nb_train_sample_per_class", ":", "# skip the first nb_train_sample_per_class data for this class", "\n", "                        ", "class_count", "[", "d", "[", "\"intent\"", "]", "]", "+=", "1", "\n", "", "else", ":", "\n", "                        ", "pair_trn_new", ".", "append", "(", "d", ")", "\n", "", "", "else", ":", "\n", "                    ", "if", "class_count", "[", "d", "[", "\"intent\"", "]", "]", "<", "nb_train_sample_per_class", ":", "\n", "                        ", "pair_trn_new", ".", "append", "(", "d", ")", "\n", "class_count", "[", "d", "[", "\"intent\"", "]", "]", "+=", "1", "\n", "\n", "", "", "", "combined_ds", "=", "pair_trn_new", "\n", "", "else", ":", "\n", "            ", "if", "data_ratio", "!=", "1", ":", "\n", "                ", "random", ".", "Random", "(", "args", "[", "\"rand_seed\"", "]", ")", ".", "shuffle", "(", "combined_ds", ")", "\n", "if", "for_unlabeled", ":", "\n", "                    ", "combined_ds", "=", "combined_ds", "[", "int", "(", "len", "(", "combined_ds", ")", "*", "data_ratio", ")", ":", "]", "\n", "", "else", ":", "\n", "                    ", "combined_ds", "=", "combined_ds", "[", ":", "int", "(", "len", "(", "combined_ds", ")", "*", "data_ratio", ")", "]", "\n", "", "", "else", ":", "\n", "                ", "random", ".", "Random", "(", "args", "[", "\"rand_seed\"", "]", ")", ".", "shuffle", "(", "combined_ds", ")", "\n", "if", "not", "for_unlabeled", ":", "\n", "                    ", "combined_ds", "=", "combined_ds", "[", ":", "args", "[", "\"nb_shots\"", "]", "]", "\n", "", "else", ":", "\n", "                    ", "combined_ds", "=", "combined_ds", "[", "args", "[", "\"nb_shots\"", "]", ":", "]", "\n", "\n", "", "", "", "print", "(", "\"[INFO] Use Training Data: from {} to {}\"", ".", "format", "(", "original_len", ",", "len", "(", "combined_ds", ")", ")", ")", "\n", "\n", "", "data_info", "=", "{", "k", ":", "[", "]", "for", "k", "in", "\n", "combined_ds", "[", "0", "]", ".", "keys", "(", ")", "}", "# from [{turn_usr:, intent:},.] pairs to {turn_usr:[], intent:[], ...}", "\n", "for", "d", "in", "combined_ds", ":", "\n", "        ", "for", "k", "in", "combined_ds", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "            ", "data_info", "[", "k", "]", ".", "append", "(", "d", "[", "k", "]", ")", "\n", "\n", "", "", "dataset", "=", "globals", "(", ")", "[", "\"Dataset_\"", "+", "task", "]", "(", "data_info", ",", "tokenizer", ",", "args", ",", "unified_meta", ",", "mode", ",", "args", "[", "\"max_seq_length\"", "]", ")", "\n", "\n", "bool_shuffle", "=", "(", "mode", "==", "\"train\"", "or", "shuffle", ")", "\n", "\n", "data_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "bool_shuffle", ",", "\n", "collate_fn", "=", "globals", "(", ")", "[", "\n", "\"collate_fn_{}_{}\"", ".", "format", "(", "task", ",", "args", "[", "\"example_type\"", "]", ")", "]", "\n", ")", "\n", "\n", "return", "data_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_general.get_remaining_loader": [[117, 157], ["torch.utils.data.Subset", "torch.utils.data.Subset", "torch.utils.data.Subset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "list", "random.Random().sample", "len", "random.Random().sample", "set", "set", "int", "globals", "random.Random", "random.Random", "range", "len"], "function", ["None"], ["", "def", "get_remaining_loader", "(", "\n", "args", ",", "\n", "unlabeled_dataset", ",", "\n", "new_candidate_num", ",", "\n", "seen_ind", ",", "\n", "use_confidence", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Get the get_remaining_loader dataloader\n    :param args:\n    :param unlabeled_dataset: the whole unlabeled dataset\n    :param new_candidate_num: number of new samples to be considered in each iteration\n    :param seen_ind: indexes of unlabeled samples seen so far\n    :return: candidate_loader\n    \"\"\"", "\n", "if", "new_candidate_num", ">", "0", ":", "\n", "        ", "remaining_ind", "=", "list", "(", "\n", "set", "(", "[", "i", "for", "i", "in", "range", "(", "len", "(", "unlabeled_dataset", ")", ")", "]", ")", "-", "set", "(", "seen_ind", ")", "\n", ")", "\n", "\n", "if", "args", "[", "'task'", "]", "==", "'dst'", ":", "\n", "            ", "remaining_ind", "=", "random", ".", "Random", "(", "args", "[", "\"rand_seed\"", "]", ")", ".", "sample", "(", "remaining_ind", ",", "int", "(", "\n", "new_candidate_num", "/", "args", "[", "'confidence_top_ratio'", "]", ")", ")", "\n", "\n", "", "assert", "new_candidate_num", "<=", "len", "(", "remaining_ind", ")", "\n", "if", "not", "use_confidence", ":", "\n", "            ", "remaining_ind", "=", "random", ".", "Random", "(", "args", "[", "\"rand_seed\"", "]", ")", ".", "sample", "(", "remaining_ind", ",", "new_candidate_num", ")", "\n", "\n", "", "", "dataset_to_label", "=", "torch", ".", "utils", ".", "data", ".", "Subset", "(", "unlabeled_dataset", ",", "remaining_ind", ")", "# the subset we want to pesudo label", "\n", "\n", "candidate_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "dataset_to_label", ",", "\n", "batch_size", "=", "args", "[", "\"eval_batch_size\"", "]", ",", "\n", "shuffle", "=", "True", ",", "\n", "collate_fn", "=", "globals", "(", ")", "[", "\n", "\"collate_fn_{}_{}\"", ".", "format", "(", "args", "[", "\"task\"", "]", ",", "args", "[", "\"example_type\"", "]", ")", "\n", "]", "\n", ")", "\n", "\n", "return", "candidate_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_general.get_unified_meta": [[159, 178], ["[].items", "unified_meta.keys", "type", "unified_meta[].keys", "len"], "function", ["None"], ["", "def", "get_unified_meta", "(", "datasets", ")", ":", "\n", "    ", "\"\"\"\n    A helper function to get the meta info for a given dataset\n    :param datasets: list of datasets to be processed\n    :return the a dictionary of meta information\n    \"\"\"", "\n", "unified_meta", "=", "{", "\"others\"", ":", "None", "}", "\n", "for", "ds", "in", "datasets", ":", "\n", "        ", "for", "key", ",", "value", "in", "datasets", "[", "ds", "]", "[", "\"meta\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "not", "in", "unified_meta", ".", "keys", "(", ")", ":", "\n", "                ", "unified_meta", "[", "key", "]", "=", "{", "}", "\n", "", "if", "type", "(", "value", ")", "==", "list", ":", "\n", "                ", "for", "v", "in", "value", ":", "\n", "                    ", "if", "v", "not", "in", "unified_meta", "[", "key", "]", ".", "keys", "(", ")", ":", "\n", "                        ", "unified_meta", "[", "key", "]", "[", "v", "]", "=", "len", "(", "unified_meta", "[", "key", "]", ")", "\n", "", "", "", "else", ":", "\n", "                ", "unified_meta", "[", "key", "]", "=", "value", "\n", "\n", "", "", "", "return", "unified_meta", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_general.merge_loaders": [[180, 200], ["torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.Subset", "torch.utils.data.Subset", "torch.utils.data.Subset"], "function", ["None"], ["", "def", "merge_loaders", "(", "task", ",", "dataloaders", ",", "seen_ind", ")", ":", "\n", "    ", "\"\"\"\n    A helper function to merge the original train dataset and pseudo-labeled dataset\n    :param task: task name\n    :param dataloaders: list of dataloaders\n    :param seen_ind: a list of indices in the unlabeled dataset that are already pseudo-labeled\n    :return a merged dataset L (contains the original train dataset and pseudo-labeled dataset)\n    \"\"\"", "\n", "merged_dataset", "=", "torch", ".", "utils", ".", "data", ".", "ConcatDataset", "(", "\n", "[", "\n", "dataloaders", "[", "0", "]", ".", "dataset", ",", "\n", "torch", ".", "utils", ".", "data", ".", "Subset", "(", "dataloaders", "[", "1", "]", ".", "dataset", ".", "dataset", ",", "seen_ind", ")", "\n", "]", "\n", ")", "\n", "\n", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "merged_dataset", ",", "\n", "batch_size", "=", "dataloaders", "[", "0", "]", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "collate_fn", "=", "dataloaders", "[", "0", "]", ".", "collate_fn", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_general.get_pseudo_label_loader": [[203, 371], ["utils_general.get_remaining_loader", "tqdm.tqdm", "model.eval", "enumerate", "torch.utils.data.Subset", "torch.utils.data.Subset", "torch.utils.data.Subset", "enumerate", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "unlabeled_data_info[].extend", "unlabeled_data_info[].extend", "unlabeled_data_info[].extend", "tqdm.tqdm.set_description", "logging.info", "logging.info", "unlabeled_dataset.set_pesudo_label", "unlabeled_dataset.set_pesudo_label", "torch.no_grad", "torch.no_grad", "torch.no_grad", "model", "unlabeled_data_info[].extend", "unlabeled_data_info[].extend", "unlabeled_data_info[].extend", "unlabeled_data_info[].extend", "unlabeled_data_info[].extend", "enumerate", "int", "list", "int", "d[].detach().cpu().tolist", "d[].detach().cpu().tolist", "d[].bool().detach().cpu().tolist", "len", "[].append", "[].append", "[].append", "[].append", "unlabeled_data_info_for_classes.keys", "selected_info[].extend", "selected_info[].extend", "selected_info[].extend", "selected_info[].extend", "numpy.argsort", "globals", "range", "text_labels.append", "unlabeled_data_info_for_classes.keys", "len", "numpy.argsort", "sum", "float", "d[].detach().cpu", "d[].detach().cpu", "d[].bool().detach().cpu", "[].replace", "d[].detach().cpu().tolist", "list", "numpy.mean", "text_labels.append", "unlabeled_data_info_for_classes.keys", "[].replace", "d[].detach", "d[].detach", "d[].bool().detach", "[].replace", "d[].detach().cpu", "numpy.sum().astype", "len", "d[].bool", "d[].detach", "numpy.sum", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_general.get_remaining_loader", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.set_pesudo_label", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.set_pesudo_label"], ["", "def", "get_pseudo_label_loader", "(", "\n", "args", ",", "\n", "model", ",", "\n", "unlabeled_dataset", ",", "\n", "seen_ind", ",", "\n", "ind_to_conf_map", "\n", ")", ":", "\n", "    ", "\"\"\"\n    :param args: global config\n    :param model: teacher model F^T\n    :param unlabeled_dataset: the global unlabeled dataset U\n    :param seen_ind: list of indices in U that are already pseudo-labeled\n    :return: a loader for the new subset to label, all pesudo labeled indexes so far, and updated index-to-confidence map\n    \"\"\"", "\n", "\n", "# candidate loader with remaining unlabeled data", "\n", "candidate_loader", "=", "get_remaining_loader", "(", "\n", "args", "=", "args", ",", "\n", "unlabeled_dataset", "=", "unlabeled_dataset", ",", "\n", "new_candidate_num", "=", "args", "[", "'new_candidate_num'", "]", ",", "\n", "seen_ind", "=", "seen_ind", ",", "\n", "use_confidence", "=", "args", "[", "'confidence_selection'", "]", "\n", ")", "\n", "\n", "candidate_pbar", "=", "tqdm", "(", "candidate_loader", ")", "\n", "\n", "# evaluation on all unlabeled data using the current model", "\n", "unlabeled_data_info_for_classes", "=", "{", "}", "\n", "# pred_raw is only useful for RS: because we don't have mapping from label index to text", "\n", "unlabeled_data_info", "=", "{", "'data_index'", ":", "[", "]", ",", "'confidence'", ":", "[", "]", ",", "'pred'", ":", "[", "]", ",", "'pred_raw'", ":", "[", "]", ",", "'ground_truth'", ":", "[", "]", "}", "\n", "model", ".", "eval", "(", ")", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "candidate_pbar", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "outputs", "=", "model", "(", "d", ")", "\n", "\n", "", "unlabeled_data_info", "[", "'data_index'", "]", ".", "extend", "(", "d", "[", "'index'", "]", ")", "\n", "unlabeled_data_info", "[", "'confidence'", "]", ".", "extend", "(", "outputs", "[", "'confidence'", "]", ")", "\n", "unlabeled_data_info", "[", "'pred'", "]", ".", "extend", "(", "outputs", "[", "'pred'", "]", ")", "\n", "\n", "if", "args", "[", "'task'", "]", "==", "'dst'", ":", "\n", "            ", "unlabeled_data_info", "[", "'ground_truth'", "]", ".", "extend", "(", "d", "[", "task_to_target", "[", "args", "[", "'task_name'", "]", "]", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ")", "\n", "", "if", "args", "[", "'task_name'", "]", "==", "'intent'", ":", "\n", "            ", "unlabeled_data_info", "[", "'ground_truth'", "]", ".", "extend", "(", "d", "[", "'intent'", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ")", "\n", "", "if", "args", "[", "'task_name'", "]", "==", "'rs'", ":", "\n", "            ", "unlabeled_data_info", "[", "'ground_truth'", "]", ".", "extend", "(", "d", "[", "'response_plain'", "]", ")", "\n", "", "if", "args", "[", "'task_name'", "]", "==", "'sysact'", ":", "\n", "            ", "unlabeled_data_info", "[", "'ground_truth'", "]", ".", "extend", "(", "d", "[", "'sysact'", "]", ".", "bool", "(", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ")", "\n", "\n", "", "if", "args", "[", "'task_name'", "]", "==", "'rs'", ":", "\n", "            ", "label_name", "=", "'response_plain'", "\n", "text_labels", "=", "[", "]", "\n", "for", "pred", "in", "outputs", "[", "'pred'", "]", ":", "\n", "                ", "batch_size", "=", "len", "(", "d", "[", "label_name", "]", ")", "\n", "if", "batch_size", "<", "args", "[", "'eval_batch_size'", "]", ":", "\n", "                    ", "for", "ind", "in", "range", "(", "batch_size", ")", ":", "\n", "                        ", "valid_pred_ind", "=", "pred", "[", "-", "1", "*", "(", "ind", "+", "1", ")", "]", "\n", "if", "valid_pred_ind", "<", "batch_size", ":", "\n", "                            ", "text_labels", ".", "append", "(", "d", "[", "label_name", "]", "[", "valid_pred_ind", "]", ".", "replace", "(", "\"{} \"", ".", "format", "(", "args", "[", "'sys_token'", "]", ")", ",", "\n", "\"\"", ")", ")", "# append the text of top prediction", "\n", "break", "\n", "", "", "", "else", ":", "\n", "                    ", "text_labels", ".", "append", "(", "d", "[", "label_name", "]", "[", "pred", "[", "-", "1", "]", "]", ".", "replace", "(", "\"{} \"", ".", "format", "(", "args", "[", "'sys_token'", "]", ")", ",", "\n", "\"\"", ")", ")", "# append the text of top prediction", "\n", "", "", "unlabeled_data_info", "[", "'pred_raw'", "]", ".", "extend", "(", "text_labels", ")", "\n", "\n", "", "if", "(", "\"oos_intent\"", "in", "args", "[", "\"dataset\"", "]", ")", "and", "args", "[", "'confidence_selection'", "]", ":", "\n", "            ", "for", "j", ",", "label", "in", "enumerate", "(", "outputs", "[", "'pred'", "]", ")", ":", "\n", "                ", "if", "label", "not", "in", "unlabeled_data_info_for_classes", ".", "keys", "(", ")", ":", "\n", "                    ", "unlabeled_data_info_for_classes", "[", "label", "]", "=", "{", "'data_index'", ":", "[", "]", ",", "'confidence'", ":", "[", "]", ",", "'pred'", ":", "[", "]", ",", "\n", "'ground_truth'", ":", "[", "]", "}", "\n", "\n", "", "unlabeled_data_info_for_classes", "[", "label", "]", "[", "'data_index'", "]", ".", "append", "(", "d", "[", "'index'", "]", "[", "j", "]", ")", "\n", "unlabeled_data_info_for_classes", "[", "label", "]", "[", "'confidence'", "]", ".", "append", "(", "outputs", "[", "'confidence'", "]", "[", "j", "]", ")", "\n", "unlabeled_data_info_for_classes", "[", "label", "]", "[", "'pred'", "]", ".", "append", "(", "outputs", "[", "'pred'", "]", "[", "j", "]", ")", "\n", "unlabeled_data_info_for_classes", "[", "label", "]", "[", "'ground_truth'", "]", ".", "append", "(", "d", "[", "'intent'", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "[", "j", "]", ")", "\n", "\n", "", "", "candidate_pbar", ".", "set_description", "(", "\"Update pesudo labels on remaining dataset\"", ")", "\n", "\n", "# selection based on confidence", "\n", "", "if", "args", "[", "'confidence_selection'", "]", ":", "\n", "        ", "if", "(", "\"oos_intent\"", "in", "args", "[", "\"dataset\"", "]", ")", ":", "\n", "            ", "nb_train_sample_per_class", "=", "int", "(", "args", "[", "'new_candidate_num'", "]", "/", "\n", "len", "(", "list", "(", "unlabeled_data_info_for_classes", ".", "keys", "(", ")", ")", ")", "\n", ")", "\n", "selected_info", "=", "{", "'index'", ":", "[", "]", ",", "'confidence'", ":", "[", "]", ",", "'pred'", ":", "[", "]", ",", "'correct_prediction'", ":", "[", "]", "}", "\n", "for", "label", "in", "list", "(", "unlabeled_data_info_for_classes", ".", "keys", "(", ")", ")", ":", "\n", "                ", "selected_args", "=", "np", ".", "argsort", "(", "unlabeled_data_info_for_classes", "[", "label", "]", "[", "'confidence'", "]", ")", "[", "\n", "-", "nb_train_sample_per_class", ":", "]", "\n", "selected_info", "[", "'index'", "]", ".", "extend", "(", "\n", "[", "unlabeled_data_info_for_classes", "[", "label", "]", "[", "'data_index'", "]", "[", "arg", "]", "for", "arg", "in", "selected_args", "]", ")", "\n", "selected_info", "[", "'pred'", "]", ".", "extend", "(", "\n", "[", "unlabeled_data_info_for_classes", "[", "label", "]", "[", "'pred'", "]", "[", "arg", "]", "for", "arg", "in", "selected_args", "]", ")", "\n", "selected_info", "[", "'confidence'", "]", ".", "extend", "(", "\n", "[", "unlabeled_data_info_for_classes", "[", "label", "]", "[", "'confidence'", "]", "[", "arg", "]", "for", "arg", "in", "selected_args", "]", ")", "\n", "selected_info", "[", "'correct_prediction'", "]", ".", "extend", "(", "\n", "[", "unlabeled_data_info_for_classes", "[", "label", "]", "[", "'pred'", "]", "[", "arg", "]", "==", "\n", "unlabeled_data_info_for_classes", "[", "label", "]", "[", "'ground_truth'", "]", "[", "arg", "]", "for", "arg", "in", "selected_args", "]", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "unlabeled_numb", "=", "int", "(", "args", "[", "'new_candidate_num'", "]", ")", "\n", "selected_args", "=", "np", ".", "argsort", "(", "unlabeled_data_info", "[", "'confidence'", "]", ")", "[", "-", "unlabeled_numb", ":", "]", "\n", "\n", "if", "args", "[", "'task_name'", "]", "==", "'rs'", ":", "\n", "                ", "selected_info", "=", "{", "\n", "'index'", ":", "[", "unlabeled_data_info", "[", "'data_index'", "]", "[", "arg", "]", "for", "arg", "in", "selected_args", "]", ",", "\n", "'pred'", ":", "[", "unlabeled_data_info", "[", "'pred'", "]", "[", "arg", "]", "for", "arg", "in", "selected_args", "]", ",", "\n", "'pred_raw'", ":", "[", "unlabeled_data_info", "[", "'pred_raw'", "]", "[", "arg", "]", "for", "arg", "in", "selected_args", "]", ",", "\n", "'confidence'", ":", "[", "unlabeled_data_info", "[", "'confidence'", "]", "[", "arg", "]", "for", "arg", "in", "selected_args", "]", ",", "\n", "'correct_prediction'", ":", "[", "\n", "unlabeled_data_info", "[", "'pred_raw'", "]", "[", "arg", "]", "==", "unlabeled_data_info", "[", "'ground_truth'", "]", "[", "arg", "]", ".", "replace", "(", "\n", "\"{} \"", ".", "format", "(", "args", "[", "'sys_token'", "]", ")", ",", "\"\"", ")", "for", "\n", "arg", "in", "selected_args", "]", "\n", "}", "\n", "", "elif", "args", "[", "'task'", "]", "==", "'dst'", ":", "\n", "                ", "selected_info", "=", "{", "\n", "'index'", ":", "[", "unlabeled_data_info", "[", "'data_index'", "]", "[", "arg", "]", "for", "arg", "in", "selected_args", "]", ",", "\n", "'pred'", ":", "[", "unlabeled_data_info", "[", "'pred'", "]", "[", "arg", "]", "for", "arg", "in", "selected_args", "]", ",", "\n", "'confidence'", ":", "[", "unlabeled_data_info", "[", "'confidence'", "]", "[", "arg", "]", "for", "arg", "in", "selected_args", "]", ",", "\n", "'correct_prediction'", ":", "np", ".", "mean", "(", "\n", "[", "\n", "np", ".", "sum", "(", "\n", "np", ".", "array", "(", "unlabeled_data_info", "[", "'pred'", "]", "[", "arg", "]", ")", "==", "np", ".", "array", "(", "\n", "unlabeled_data_info", "[", "'ground_truth'", "]", "[", "arg", "]", ")", "\n", ")", ".", "astype", "(", "float", ")", "/", "len", "(", "unlabeled_data_info", "[", "'pred'", "]", "[", "arg", "]", ")", "\n", "for", "arg", "in", "selected_args", "\n", "]", "\n", ")", "\n", "}", "\n", "", "else", ":", "\n", "                ", "selected_info", "=", "{", "\n", "'index'", ":", "[", "unlabeled_data_info", "[", "'data_index'", "]", "[", "arg", "]", "for", "arg", "in", "selected_args", "]", ",", "\n", "'pred'", ":", "[", "unlabeled_data_info", "[", "'pred'", "]", "[", "arg", "]", "for", "arg", "in", "selected_args", "]", ",", "\n", "'confidence'", ":", "[", "unlabeled_data_info", "[", "'confidence'", "]", "[", "arg", "]", "for", "arg", "in", "selected_args", "]", ",", "\n", "'correct_prediction'", ":", "[", "unlabeled_data_info", "[", "'pred'", "]", "[", "arg", "]", "==", "unlabeled_data_info", "[", "'ground_truth'", "]", "[", "arg", "]", "\n", "for", "arg", "in", "selected_args", "]", "\n", "}", "\n", "\n", "", "", "", "del", "unlabeled_data_info", ",", "unlabeled_data_info_for_classes", "\n", "\n", "if", "args", "[", "\"task_name\"", "]", "==", "\"dst\"", ":", "\n", "        ", "logging", ".", "info", "(", "'Correct Prediction on Pesudo Label: {}'", ".", "format", "(", "selected_info", "[", "'correct_prediction'", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "info", "(", "'Correct Prediction on Pesudo Label: {}'", ".", "format", "(", "\n", "sum", "(", "selected_info", "[", "'correct_prediction'", "]", ")", "/", "float", "(", "args", "[", "'new_candidate_num'", "]", ")", ")", ")", "\n", "\n", "", "if", "args", "[", "'task_name'", "]", "==", "'rs'", ":", "\n", "        ", "unlabeled_dataset", ".", "set_pesudo_label", "(", "selected_info", "[", "'index'", "]", ",", "selected_info", "[", "'pred_raw'", "]", ")", "\n", "", "else", ":", "\n", "        ", "unlabeled_dataset", ".", "set_pesudo_label", "(", "selected_info", "[", "'index'", "]", ",", "selected_info", "[", "'pred'", "]", ")", "\n", "\n", "# get the new subset to label in an iteration", "\n", "", "dataset_to_label", "=", "torch", ".", "utils", ".", "data", ".", "Subset", "(", "unlabeled_dataset", ",", "\n", "selected_info", "[", "'index'", "]", ")", "# the subset we want to pesudo label", "\n", "\n", "# update the ind_to_conf_map", "\n", "for", "i", ",", "ind", "in", "enumerate", "(", "selected_info", "[", "'index'", "]", ")", ":", "\n", "        ", "ind_to_conf_map", "[", "ind", "]", "=", "selected_info", "[", "'confidence'", "]", "[", "i", "]", "\n", "\n", "", "pseudo_label_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "dataset_to_label", ",", "\n", "batch_size", "=", "args", "[", "\"batch_size\"", "]", ",", "\n", "shuffle", "=", "True", ",", "\n", "collate_fn", "=", "globals", "(", ")", "[", "\n", "\"collate_fn_{}_{}\"", ".", "format", "(", "args", "[", "\"task\"", "]", ",", "args", "[", "\"example_type\"", "]", ")", "\n", "]", "\n", ")", "\n", "\n", "return", "pseudo_label_loader", ",", "seen_ind", "+", "selected_info", "[", "'index'", "]", ",", "ind_to_conf_map", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_general.build_gradient_map": [[373, 419], ["max", "torch.stack", "torch.stack", "torch.stack", "Interpret.smooth_gradient.SmoothGradient", "Interpret.smooth_gradient.SmoothGradient.saliency_interpret", "torch.pad", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "torch.stack.cuda", "tokenizer.encode", "utils_general.sentence_encode", "torch.stack.cuda", "len", "torch.stack.cuda", "torch.stack.cuda"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.Interpret.smooth_gradient.SmoothGradient.saliency_interpret", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_general.sentence_encode"], ["", "def", "build_gradient_map", "(", "args", ",", "\n", "model", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "tokenizer", ",", "\n", "batch_sents", ",", "\n", "labels_tensor", ")", ":", "\n", "    ", "\"\"\"\n    The function the builds up a saliency map for input instances conditioned on the downstream task\n    :param args: global configs\n    :param model: current task model for evaluating gradients, i.e. F^T\n    :param tokenizer: tokenizer for string input\n    :param batch_sents: batch of sentences\n    :param labels_tensor: tensor of labels y\n    :return: list of gradient map for each sentence. each gradient map is a dictionary\n    \"\"\"", "\n", "if", "args", "[", "\"task_name\"", "]", "==", "\"intent\"", ":", "\n", "        ", "tokens", "=", "[", "torch", ".", "tensor", "(", "tokenizer", ".", "encode", "(", "sample", ",", "add_special_tokens", "=", "True", ")", ")", "for", "sample", "in", "batch_sents", "]", "\n", "", "else", ":", "\n", "        ", "tokens", "=", "[", "torch", ".", "tensor", "(", "sentence_encode", "(", "tokenizer", ",", "sample", ",", "max_length", "=", "args", "[", "\"max_seq_length\"", "]", ")", ")", "for", "sample", "in", "batch_sents", "]", "\n", "\n", "# pad", "\n", "", "max_len", "=", "max", "(", "[", "len", "(", "tok", ")", "for", "tok", "in", "tokens", "]", ")", "\n", "tokens", "=", "[", "F", ".", "pad", "(", "tok", ",", "[", "0", ",", "max_len", "-", "len", "(", "tok", ")", "]", ",", "'constant'", ",", "tokenizer", ".", "pad_token_id", ")", "for", "tok", "in", "tokens", "]", "\n", "tokens", "=", "torch", ".", "stack", "(", "tokens", ")", "\n", "\n", "gradient_calc_input", "=", "None", "\n", "\n", "if", "args", "[", "\"task_name\"", "]", "==", "\"dst\"", ":", "\n", "        ", "gradient_calc_input", "=", "{", "\"context\"", ":", "tokens", ".", "cuda", "(", ")", ",", "\"belief_ontology\"", ":", "labels_tensor", "}", "\n", "", "elif", "args", "[", "\"task_name\"", "]", "==", "\"sysact\"", ":", "\n", "        ", "gradient_calc_input", "=", "{", "args", "[", "\"input_name\"", "]", ":", "tokens", ".", "cuda", "(", ")", ",", "args", "[", "\"task_name\"", "]", ":", "labels_tensor", "}", "\n", "", "elif", "args", "[", "\"task_name\"", "]", "==", "\"rs\"", ":", "\n", "        ", "gradient_calc_input", "=", "{", "\"context\"", ":", "tokens", ".", "cuda", "(", ")", ",", "\"response\"", ":", "labels_tensor", "}", "\n", "", "elif", "args", "[", "\"task_name\"", "]", "==", "\"intent\"", ":", "\n", "        ", "gradient_calc_input", "=", "{", "args", "[", "\"input_name\"", "]", ":", "tokens", ".", "cuda", "(", ")", ",", "args", "[", "\"task_name\"", "]", ":", "labels_tensor", "}", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n", "# use smooth saliency map to calculate gradient of each token", "\n", "", "grad_calc", "=", "SmoothGradient", "(", "\n", "model", "=", "model", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "show_progress", "=", "True", ",", "\n", ")", "\n", "\n", "gradient_map", "=", "grad_calc", ".", "saliency_interpret", "(", "gradient_calc_input", ",", "use_truth", "=", "True", ")", "\n", "return", "gradient_map", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_general.mlm_augment_data": [[421, 684], ["transformers.AutoModelForMaskedLM.from_pretrained", "tokenizer_class.from_pretrained", "AutoModelForMaskedLM.from_pretrained.eval", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "tqdm.tqdm", "enumerate", "numpy.full", "tokenizer_class.from_pretrained.vocab.items", "numpy.full", "tokenizer_class.from_pretrained.vocab.items", "AutoModelForMaskedLM.from_pretrained.cuda", "range", "range", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "utils_general.fill_batch", "tqdm.tqdm.set_description", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "torch.utils.data.ConcatDataset", "len", "copy.deepcopy", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "augmented_datasets.append", "copy.deepcopy", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "augmented_datasets.append", "len", "utils_general.fill_batch", "range", "max", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "utils_general.hf_reconstruction_prob_tok", "range", "list", "len", "torch.utils.data.Subset", "torch.utils.data.Subset", "torch.utils.data.Subset", "tuple", "list", "utils_general.build_gradient_map", "utils_general.build_gradient_map", "range", "len", "len", "utils_general.hf_masked_encode", "toks.cuda.append", "masks.cuda.append", "torch.pad", "torch.pad", "toks.cuda.cuda", "masks.cuda.cuda", "len", "rec[].cpu().tolist", "str", "torch.utils.data.Subset", "torch.utils.data.Subset", "torch.utils.data.Subset", "list", "globals", "s.strip().split", "zip", "len", "sents.pop", "num_gen.pop", "gen_index.pop", "l.pop", "enumerate", "len", "tuple", "tuple", "sents[].append", "range", "range", "globals", "globals", "rec[].cpu", "s.strip", "s.strip", "tuple", "len", "len", "len", "s.strip", "augmented_datasets[].dataset.reset_dm_context", "len", "len", "tokenizer_class.from_pretrained.decode().split", "tokenizer_class.from_pretrained.decode().split", "tuple", "augmented_datasets[].dataset.reset_dst_context", "tokenizer_class.from_pretrained.decode", "tokenizer_class.from_pretrained.decode", "repr", "augmented_datasets[].dataset.reset_nlu_context", "augmented_datasets[].dataset.reset_nlg_context", "repr", "repr", "new_sent.split", "repr"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_general.fill_batch", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_general.fill_batch", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_general.hf_reconstruction_prob_tok", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_general.build_gradient_map", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_general.build_gradient_map", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_general.hf_masked_encode", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dm.Dataset_dm.reset_dm_context", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dst.Dataset_dst.reset_dst_context", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.reset_nlu_context", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlg.Dataset_nlg.reset_nlg_context"], ["", "def", "mlm_augment_data", "(", "args", ",", "\n", "model", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "original_dataset", ":", "torch", ".", "utils", ".", "data", ".", "DataLoader", ",", "\n", "is_subset", ":", "bool", ",", "\n", "new_subset_indices", ":", "set", "=", "None", ",", "\n", "prev_augmented_data", ":", "torch", ".", "utils", ".", "data", ".", "ConcatDataset", "=", "None", ",", "\n", "use_gradient", ":", "bool", "=", "False", ",", "\n", "augmentation_factor", ":", "int", "=", "3", ")", "->", "torch", ".", "utils", ".", "data", ".", "ConcatDataset", ":", "\n", "    ", "\"\"\"\n    Augment the original dataset to the augmented dataset\n    :param args: global configs\n    :param model: teacher model F^T\n    :param original_dataset: the dataset to be augmented\n    :param is_subset: whether the incoming dataset is a subset or not.\n                        if the incoming dataset is a labeled dataset, then is_subset is False.\n                        if the incoming dataset is pseudo-labeled, then it is a subset.\n    :param new_subset_indices: the indices of a given full dataset (to extract the desired subset)\n    :param prev_augmented_data: the augmented data from previous iteration.\n                                in this iteration, based on the previous data, augment based on `new_subset_indices`\n    :param use_gradient:\n    :param augmentation_factor:\n    :return: a ConcatDataset which consists of a concatenation of `augmentation_factor` pieces of the modified dataset.\n    \"\"\"", "\n", "\n", "# prepare models and configs", "\n", "model_class", ",", "tokenizer_class", ",", "config_class", "=", "BertModel", ",", "BertTokenizer", ",", "BertConfig", "\n", "encoder", "=", "AutoModelForMaskedLM", ".", "from_pretrained", "(", "args", "[", "\"model_name_or_path\"", "]", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", "[", "\"model_name_or_path\"", "]", ",", "cache_dir", "=", "args", "[", "\"cache_dir\"", "]", ")", "\n", "\n", "if", "args", "[", "\"model_name_or_path\"", "]", "==", "\"bert-base-uncased\"", ":", "\n", "        ", "softmax_mask", "=", "np", ".", "full", "(", "len", "(", "tokenizer", ".", "vocab", ")", ",", "False", ")", "\n", "softmax_mask", "[", "tokenizer", ".", "all_special_ids", "]", "=", "True", "\n", "for", "k", ",", "v", "in", "tokenizer", ".", "vocab", ".", "items", "(", ")", ":", "\n", "            ", "if", "'[unused'", "in", "k", ":", "\n", "                ", "softmax_mask", "[", "v", "]", "=", "True", "\n", "\n", "", "", "", "else", ":", "\n", "# remove unused vocab and special ids from sampling, add two additional tokens [usr] [sys]", "\n", "        ", "softmax_mask", "=", "np", ".", "full", "(", "len", "(", "tokenizer", ".", "vocab", ")", "+", "2", ",", "False", ")", "\n", "softmax_mask", "[", "tokenizer", ".", "all_special_ids", "]", "=", "True", "\n", "for", "k", ",", "v", "in", "tokenizer", ".", "vocab", ".", "items", "(", ")", ":", "\n", "            ", "if", "'[unused'", "in", "k", ":", "\n", "                ", "softmax_mask", "[", "v", "]", "=", "True", "\n", "", "", "softmax_mask", "[", "-", "2", ":", "]", "=", "True", "\n", "\n", "", "encoder", ".", "eval", "(", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "encoder", ".", "cuda", "(", ")", "\n", "\n", "", "augmented_datasets", "=", "[", "]", "\n", "prev_subset_indices", "=", "[", "]", "\n", "\n", "if", "is_subset", "and", "prev_augmented_data", ":", "\n", "# called until the 2nd iteration of augmenting unlabeled data", "\n", "        ", "prev_subset_indices", "=", "prev_augmented_data", ".", "datasets", "[", "0", "]", ".", "indices", "\n", "for", "it", "in", "range", "(", "augmentation_factor", ")", ":", "\n", "# get the full dataset (some of indices correspond to the augmented data)", "\n", "            ", "dataset_copy", "=", "copy", ".", "deepcopy", "(", "prev_augmented_data", ".", "datasets", "[", "it", "]", ".", "dataset", ")", "\n", "dataloader_copy", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "dataset_copy", ",", "\n", "batch_size", "=", "original_dataset", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "collate_fn", "=", "globals", "(", ")", "[", "\"collate_fn_{}_{}\"", ".", "format", "(", "args", "[", "\"task\"", "]", ",", "args", "[", "\"example_type\"", "]", ")", "]", "\n", ")", "\n", "augmented_datasets", ".", "append", "(", "dataloader_copy", ")", "\n", "", "", "else", ":", "\n", "# incoming data is the whole train loader with labels", "\n", "# OR", "\n", "# incoming data is the unlabeled data, and during 1st iteration of augmenting unlabeled data", "\n", "        ", "for", "it", "in", "range", "(", "augmentation_factor", ")", ":", "\n", "            ", "dataset_copy", "=", "copy", ".", "deepcopy", "(", "original_dataset", ".", "dataset", ")", "\n", "dataloader_copy", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "dataset_copy", ",", "\n", "batch_size", "=", "original_dataset", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "collate_fn", "=", "globals", "(", ")", "[", "\"collate_fn_{}_{}\"", ".", "format", "(", "args", "[", "\"task\"", "]", ",", "args", "[", "\"example_type\"", "]", ")", "]", "\n", ")", "\n", "augmented_datasets", ".", "append", "(", "dataloader_copy", ")", "\n", "\n", "", "", "if", "is_subset", ":", "\n", "# only iterate over `new_subset_indices`, i.e., previously augmented data are ignored", "\n", "        ", "original_dataset", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "dataset", "=", "torch", ".", "utils", ".", "data", ".", "Subset", "(", "original_dataset", ".", "dataset", ",", "list", "(", "new_subset_indices", ")", ")", ",", "\n", "batch_size", "=", "original_dataset", ".", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "\n", "collate_fn", "=", "globals", "(", ")", "[", "\"collate_fn_{}_{}\"", ".", "format", "(", "args", "[", "\"task\"", "]", ",", "args", "[", "\"example_type\"", "]", ")", "]", "\n", ")", "\n", "\n", "", "original_dataset_bar", "=", "tqdm", "(", "original_dataset", ")", "\n", "\n", "for", "ind", ",", "d", "in", "enumerate", "(", "original_dataset_bar", ")", ":", "\n", "\n", "        ", "num_lines", ",", "index", ",", "lines", "=", "len", "(", "d", "[", "\"context_plain\"", "]", ")", ",", "d", "[", "\"index\"", "]", ",", "[", "tuple", "(", "s", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", ")", "for", "s", "in", "d", "[", "\"context_plain\"", "]", "]", "\n", "\n", "labels", "=", "None", "\n", "\n", "if", "args", "[", "\"task_name\"", "]", "==", "\"dst\"", ":", "\n", "            ", "labels", "=", "d", "[", "\"belief_ontology\"", "]", "\n", "", "if", "args", "[", "\"task_name\"", "]", "==", "\"intent\"", ":", "\n", "            ", "labels", "=", "d", "[", "\"intent_plain\"", "]", "\n", "", "if", "args", "[", "\"task_name\"", "]", "==", "\"sysact\"", ":", "\n", "            ", "labels", "=", "d", "[", "\"sysact_plain\"", "]", "\n", "", "if", "args", "[", "\"task_name\"", "]", "==", "\"rs\"", ":", "\n", "            ", "labels", "=", "d", "[", "\"response_plain\"", "]", "\n", "\n", "# max_len_in_d = max(d['context_len'])", "\n", "", "lines", "=", "[", "[", "[", "s", "]", "for", "s", "in", "s_list", "]", "for", "s_list", "in", "list", "(", "zip", "(", "*", "lines", ")", ")", "]", "\n", "\n", "# sentences and labels to process", "\n", "sents", "=", "[", "]", "\n", "l", "=", "[", "]", "\n", "# number sentences generated", "\n", "num_gen", "=", "[", "]", "\n", "# sentence index to noise from", "\n", "gen_index", "=", "[", "]", "\n", "# number of tries generating a new sentence", "\n", "num_tries", "=", "[", "]", "\n", "# next sentence index to draw from", "\n", "next_sent", "=", "0", "\n", "\n", "sents", ",", "l", ",", "next_sent", ",", "num_gen", ",", "num_tries", ",", "gen_index", "=", "fill_batch", "(", "tokenizer", ",", "sents", ",", "l", ",", "lines", ",", "labels", ",", "next_sent", ",", "num_gen", ",", "num_tries", ",", "gen_index", ")", "\n", "\n", "gradient_map", "=", "None", "\n", "all_candidate_sents", "=", "[", "sent", "[", "0", "]", "[", "0", "]", "for", "sent", "in", "sents", "]", "\n", "\n", "if", "use_gradient", ":", "\n", "            ", "if", "args", "[", "\"task_name\"", "]", "==", "\"rs\"", ":", "\n", "                ", "gradient_map", "=", "build_gradient_map", "(", "args", ",", "model", ",", "tokenizer", ",", "all_candidate_sents", ",", "d", "[", "\"response\"", "]", ")", "\n", "", "else", ":", "\n", "                ", "gradient_map", "=", "build_gradient_map", "(", "args", ",", "model", ",", "tokenizer", ",", "all_candidate_sents", ",", "d", "[", "args", "[", "\"task_name\"", "]", "]", ")", "\n", "\n", "", "", "while", "sents", ":", "\n", "# remove any sentences that are done generating and dump to file", "\n", "            ", "for", "i", "in", "range", "(", "len", "(", "num_gen", ")", ")", "[", ":", ":", "-", "1", "]", ":", "\n", "                ", "if", "num_gen", "[", "i", "]", ">=", "augmentation_factor", "or", "num_tries", "[", "i", "]", ">", "5", ":", "\n", "# get sent info", "\n", "                    ", "gen_sents", "=", "sents", ".", "pop", "(", "i", ")", "\n", "num_gen", ".", "pop", "(", "i", ")", "\n", "gen_index", ".", "pop", "(", "i", ")", "\n", "label", "=", "l", ".", "pop", "(", "i", ")", "\n", "\n", "# write generated sentences", "\n", "for", "sample_i", ",", "sg", "in", "enumerate", "(", "gen_sents", "[", "1", ":", "]", ")", ":", "\n", "                        ", "if", "args", "[", "\"task_name\"", "]", "==", "\"sysact\"", ":", "\n", "                            ", "new_sent", "=", "\" \"", ".", "join", "(", "[", "repr", "(", "val", ")", "[", "1", ":", "-", "1", "]", "for", "val", "in", "sg", "]", ")", "\n", "augmented_datasets", "[", "sample_i", "]", ".", "dataset", ".", "reset_dm_context", "(", "index", "[", "i", "]", ",", "new_sent", ")", "\n", "", "elif", "args", "[", "\"task_name\"", "]", "==", "\"dst\"", ":", "\n", "                            ", "new_sent", "=", "\" \"", ".", "join", "(", "[", "repr", "(", "val", ")", "[", "1", ":", "-", "1", "]", "for", "val", "in", "sg", "]", ")", "\n", "augmented_datasets", "[", "sample_i", "]", ".", "dataset", ".", "reset_dst_context", "(", "index", "[", "i", "]", ",", "new_sent", ")", "\n", "", "elif", "args", "[", "\"task_name\"", "]", "==", "\"intent\"", ":", "\n", "                            ", "new_sent", "=", "\" \"", ".", "join", "(", "[", "repr", "(", "val", ")", "[", "1", ":", "-", "1", "]", "for", "val", "in", "sg", "]", ")", "\n", "# skip [cls] [sys] [usr]", "\n", "if", "args", "[", "\"model_name_or_path\"", "]", "==", "\"bert-base-uncased\"", ":", "\n", "                                ", "augmented_datasets", "[", "sample_i", "]", ".", "dataset", ".", "reset_nlu_context", "(", "index", "[", "i", "]", ",", "new_sent", ")", "\n", "", "else", ":", "\n", "                                ", "new_sent", "=", "\" \"", ".", "join", "(", "new_sent", ".", "split", "(", "\" \"", ")", "[", "3", ":", "]", ")", "\n", "augmented_datasets", "[", "sample_i", "]", ".", "dataset", ".", "data", "[", "\"turn_usr\"", "]", "[", "index", "[", "i", "]", "]", "=", "new_sent", "\n", "", "", "elif", "args", "[", "\"task_name\"", "]", "==", "\"rs\"", ":", "\n", "                            ", "new_sent", "=", "\" \"", ".", "join", "(", "[", "repr", "(", "val", ")", "[", "1", ":", "-", "1", "]", "for", "val", "in", "sg", "]", ")", "\n", "augmented_datasets", "[", "sample_i", "]", ".", "dataset", ".", "reset_nlg_context", "(", "index", "[", "i", "]", ",", "new_sent", ")", "\n", "", "else", ":", "\n", "                            ", "raise", "NotImplementedError", "\n", "\n", "\n", "# fill batch", "\n", "", "", "", "", "sents", ",", "l", ",", "next_sent", ",", "num_gen", ",", "num_tries", ",", "gen_index", "=", "fill_batch", "(", "tokenizer", ",", "sents", ",", "l", ",", "lines", ",", "labels", ",", "next_sent", ",", "num_gen", ",", "num_tries", ",", "gen_index", ")", "\n", "\n", "# break if done dumping", "\n", "if", "len", "(", "sents", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "# build batch", "\n", "", "toks", "=", "[", "]", "\n", "masks", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "gen_index", ")", ")", ":", "\n", "                ", "s", "=", "sents", "[", "i", "]", "[", "gen_index", "[", "i", "]", "]", "\n", "tok", ",", "mask", "=", "hf_masked_encode", "(", "\n", "args", ",", "\n", "tokenizer", ",", "\n", "*", "s", ",", "\n", "noise_prob", "=", "0.15", ",", "\n", "random_token_prob", "=", "0.1", ",", "\n", "leave_unmasked_prob", "=", "0.1", ",", "\n", "use_gradient", "=", "use_gradient", ",", "\n", "gradient_map", "=", "gradient_map", ",", "\n", "ind_of_gradient_map", "=", "i", "\n", ")", "\n", "toks", ".", "append", "(", "tok", ")", "\n", "masks", ".", "append", "(", "mask", ")", "\n", "\n", "# pad up to max len input", "\n", "", "max_len", "=", "max", "(", "[", "len", "(", "tok", ")", "for", "tok", "in", "toks", "]", ")", "\n", "pad_tok", "=", "tokenizer", ".", "pad_token_id", "\n", "\n", "toks", "=", "[", "F", ".", "pad", "(", "tok", ",", "[", "0", ",", "max_len", "-", "len", "(", "tok", ")", "]", ",", "'constant'", ",", "pad_tok", ")", "for", "tok", "in", "toks", "]", "\n", "masks", "=", "[", "F", ".", "pad", "(", "mask", ",", "[", "0", ",", "max_len", "-", "len", "(", "mask", ")", "]", ",", "'constant'", ",", "pad_tok", ")", "for", "mask", "in", "masks", "]", "\n", "toks", "=", "torch", ".", "stack", "(", "toks", ")", "\n", "masks", "=", "torch", ".", "stack", "(", "masks", ")", "\n", "\n", "# load to GPU if available", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "toks", "=", "toks", ".", "cuda", "(", ")", "\n", "masks", "=", "masks", ".", "cuda", "(", ")", "\n", "\n", "# predict reconstruction", "\n", "", "rec", ",", "rec_masks", "=", "hf_reconstruction_prob_tok", "(", "toks", ",", "masks", ",", "tokenizer", ",", "encoder", ",", "softmax_mask", ",", "\n", "reconstruct", "=", "True", ",", "topk", "=", "10", ")", "\n", "\n", "# decode reconstructions and append to lists", "\n", "for", "i", "in", "range", "(", "len", "(", "rec", ")", ")", ":", "\n", "                ", "rec_work", "=", "rec", "[", "i", "]", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "if", "args", "[", "\"task_name\"", "]", "==", "\"intent\"", ":", "\n", "                    ", "s_rec", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "\n", "tokenizer", ".", "decode", "(", "[", "val", "for", "val", "in", "rec_work", "if", "val", "!=", "tokenizer", ".", "pad_token_id", "]", "[", "1", ":", "-", "1", "]", ")", ".", "split", "(", "\n", "tokenizer", ".", "sep_token", ")", "]", "\n", "s_rec", "=", "tuple", "(", "s_rec", ")", "\n", "", "else", ":", "\n", "                    ", "s_rec", "=", "[", "s", ".", "strip", "(", ")", "for", "s", "in", "\n", "tokenizer", ".", "decode", "(", "[", "val", "for", "val", "in", "rec_work", "if", "(", "val", "!=", "tokenizer", ".", "pad_token_id", "\n", "and", "val", "!=", "tokenizer", ".", "cls_token_id", ")", "]", ")", ".", "split", "(", "\n", "tokenizer", ".", "sep_token", ")", "]", "\n", "\n", "# rejoining sentences that are separated by [sep]", "\n", "", "if", "args", "[", "\"task_name\"", "]", "==", "\"dst\"", ":", "\n", "                    ", "s_rec", "=", "tuple", "(", "[", "\" [sep] \"", ".", "join", "(", "s_rec", ")", "]", ")", "\n", "", "elif", "args", "[", "\"task_name\"", "]", "==", "\"sysact\"", ":", "\n", "                    ", "s_rec", "=", "tuple", "(", "[", "\" [sep] \"", ".", "join", "(", "s_rec", ")", "]", ")", "\n", "", "elif", "args", "[", "\"task_name\"", "]", "==", "\"rs\"", ":", "\n", "                    ", "s_rec", "=", "tuple", "(", "s_rec", ")", "\n", "\n", "# check if identical reconstruction or empty", "\n", "# s_rec not in sents[i] and", "\n", "", "if", "''", "not", "in", "s_rec", ":", "\n", "                    ", "sents", "[", "i", "]", ".", "append", "(", "s_rec", ")", "\n", "num_gen", "[", "i", "]", "+=", "1", "\n", "num_tries", "[", "i", "]", "=", "0", "\n", "gen_index", "[", "i", "]", "=", "0", "\n", "\n", "# otherwise try next sentence", "\n", "", "else", ":", "\n", "                    ", "num_tries", "[", "i", "]", "+=", "1", "\n", "gen_index", "[", "i", "]", "+=", "1", "\n", "if", "gen_index", "[", "i", "]", "==", "len", "(", "sents", "[", "i", "]", ")", ":", "\n", "                        ", "gen_index", "[", "i", "]", "=", "0", "\n", "\n", "# clean up tensors", "\n", "", "", "", "del", "toks", "\n", "del", "masks", "\n", "\n", "", "original_dataset_bar", ".", "set_description", "(", "\"augmenting training data, using gradient: \"", "+", "str", "(", "use_gradient", ")", ")", "\n", "\n", "", "if", "is_subset", ":", "\n", "        ", "all_indices", "=", "prev_subset_indices", "+", "list", "(", "new_subset_indices", ")", "\n", "return", "torch", ".", "utils", ".", "data", ".", "ConcatDataset", "(", "[", "torch", ".", "utils", ".", "data", ".", "Subset", "(", "augmented_datasets", "[", "i", "]", ".", "dataset", ",", "all_indices", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "augmented_datasets", ")", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "torch", ".", "utils", ".", "data", ".", "ConcatDataset", "(", "[", "augmented_datasets", "[", "i", "]", ".", "dataset", "for", "i", "in", "range", "(", "len", "(", "augmented_datasets", ")", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_general.fill_batch": [[686, 723], ["len", "len", "sents.append", "l.append", "num_gen.append", "num_tries.append", "gen_index.append", "len", "tokenizer.encode", "list", "zip"], "function", ["None"], ["", "", "def", "fill_batch", "(", "tokenizer", ",", "\n", "sents", ",", "\n", "l", ",", "\n", "lines", ",", "\n", "labels", ",", "\n", "next_sent", ",", "\n", "num_gen", ",", "\n", "num_tries", ",", "\n", "gen_index", ")", ":", "\n", "# search for the next valid sentence", "\n", "    ", "while", "True", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "if", "next_sent", ">=", "len", "(", "lines", "[", "0", "]", ")", ":", "\n", "                ", "break", "\n", "\n", "", "next_sents", "=", "[", "s_list", "[", "next_sent", "]", "[", "0", "]", "for", "s_list", "in", "lines", "]", "\n", "next_len", "=", "len", "(", "tokenizer", ".", "encode", "(", "*", "next_sents", ")", ")", "\n", "\n", "# skip input if too short or long", "\n", "if", "2", "<", "next_len", "<", "1024", ":", "\n", "                ", "break", "\n", "", "next_sent", "+=", "1", "\n", "\n", "# add it to our lists", "\n", "", "if", "next_sent", "<", "len", "(", "lines", "[", "0", "]", ")", ":", "\n", "            ", "next_sent_lists", "=", "[", "s_list", "[", "next_sent", "]", "for", "s_list", "in", "lines", "]", "\n", "sents", ".", "append", "(", "list", "(", "zip", "(", "*", "next_sent_lists", ")", ")", ")", "\n", "l", ".", "append", "(", "labels", "[", "next_sent", "]", ")", "\n", "\n", "num_gen", ".", "append", "(", "0", ")", "\n", "num_tries", ".", "append", "(", "0", ")", "\n", "gen_index", ".", "append", "(", "0", ")", "\n", "next_sent", "+=", "1", "\n", "", "else", ":", "\n", "            ", "break", "\n", "\n", "", "", "return", "sents", ",", "l", ",", "next_sent", ",", "num_gen", ",", "num_tries", ",", "gen_index", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_general.sentence_encode": [[725, 732], ["tokenizer.convert_tokens_to_ids", "tokenizer.tokenize", "tokenizer.tokenize"], "function", ["None"], ["", "def", "sentence_encode", "(", "tokenizer", ",", "sentence", ",", "*", "addl_sentences", ",", "max_length", ")", ":", "\n", "    ", "\"\"\"\n    Encode a sentence of tokens to token ids \n    \"\"\"", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "tokenizer", ".", "cls_token", ")", "+", "tokenizer", ".", "tokenize", "(", "sentence", ",", "*", "addl_sentences", ")", "[", "-", "max_length", "+", "1", ":", "]", "\n", "story", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "return", "story", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_general.hf_masked_encode": [[734, 838], ["len", "numpy.full", "int", "numpy.ones", "range", "numpy.full", "numpy.asarray", "numpy.asarray", "np.ones.sum", "numpy.array", "np.ones.sum", "len", "rand_mask.sum", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "numpy.ones", "tokenizer.vocab.items", "numpy.ones", "tokenizer.vocab.items", "tokenizer.encode", "utils_general.sentence_encode", "numpy.random.rand", "numpy.random.choice", "len", "np.ones.sum", "np.ones.sum", "list", "numpy.random.rand", "numpy.random.rand", "numpy.random.choice", "numpy.random.choice", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "len", "tokenizer.added_tokens_encoder.values", "numpy.ptp", "numpy.random.rand", "len", "numpy.min", "len"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_general.sentence_encode"], ["", "def", "hf_masked_encode", "(", "args", ",", "\n", "tokenizer", ",", "\n", "sentence", ":", "str", ",", "\n", "*", "addl_sentences", ",", "\n", "noise_prob", "=", "0.0", ",", "\n", "random_token_prob", "=", "0.0", ",", "\n", "leave_unmasked_prob", "=", "0.0", ",", "\n", "use_gradient", ":", "bool", "=", "False", ",", "\n", "gradient_map", ":", "list", "=", "None", ",", "\n", "ind_of_gradient_map", ":", "int", ")", ":", "\n", "    ", "if", "random_token_prob", ">", "0.0", ":", "\n", "# add two special token for [usr] and [sys]", "\n", "        ", "if", "args", "[", "\"model_name_or_path\"", "]", "==", "\"bert-base-uncased\"", ":", "\n", "            ", "weights", "=", "np", ".", "ones", "(", "len", "(", "tokenizer", ".", "vocab", ")", ")", "\n", "weights", "[", "tokenizer", ".", "all_special_ids", "]", "=", "0", "\n", "for", "k", ",", "v", "in", "tokenizer", ".", "vocab", ".", "items", "(", ")", ":", "\n", "                ", "if", "'[unused'", "in", "k", ":", "\n", "                    ", "weights", "[", "v", "]", "=", "0", "\n", "", "", "weights", "=", "weights", "/", "weights", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "            ", "weights", "=", "np", ".", "ones", "(", "len", "(", "tokenizer", ".", "vocab", ")", "+", "2", ")", "\n", "weights", "[", "tokenizer", ".", "all_special_ids", "]", "=", "0", "\n", "weights", "[", "-", "2", ":", "]", "=", "0", "\n", "for", "k", ",", "v", "in", "tokenizer", ".", "vocab", ".", "items", "(", ")", ":", "\n", "                ", "if", "'[unused'", "in", "k", ":", "\n", "                    ", "weights", "[", "v", "]", "=", "0", "\n", "", "", "weights", "=", "weights", "/", "weights", ".", "sum", "(", ")", "\n", "\n", "", "", "if", "args", "[", "\"task_name\"", "]", "==", "\"intent\"", ":", "\n", "        ", "tokens", "=", "np", ".", "asarray", "(", "tokenizer", ".", "encode", "(", "sentence", ",", "*", "addl_sentences", ",", "add_special_tokens", "=", "True", ")", ")", "\n", "", "else", ":", "\n", "        ", "tokens", "=", "np", ".", "asarray", "(", "sentence_encode", "(", "tokenizer", ",", "sentence", ",", "*", "addl_sentences", ",", "max_length", "=", "args", "[", "\"max_seq_length\"", "]", ")", ")", "\n", "\n", "", "if", "noise_prob", "==", "0.0", ":", "\n", "        ", "return", "tokens", "\n", "\n", "", "sz", "=", "len", "(", "tokens", ")", "\n", "mask", "=", "np", ".", "full", "(", "sz", ",", "False", ")", "\n", "num_mask", "=", "int", "(", "noise_prob", "*", "sz", "+", "np", ".", "random", ".", "rand", "(", ")", ")", "\n", "\n", "mask_choice_p", "=", "np", ".", "ones", "(", "sz", ")", "\n", "for", "i", "in", "range", "(", "sz", ")", ":", "\n", "        ", "if", "tokens", "[", "i", "]", "in", "[", "tokenizer", ".", "sep_token_id", ",", "tokenizer", ".", "cls_token_id", ",", "tokenizer", ".", "pad_token_id", "]", ":", "\n", "            ", "mask_choice_p", "[", "i", "]", "=", "0", "\n", "# add two special token for [usr] and [sys]", "\n", "", "if", "args", "[", "\"model_name_or_path\"", "]", "!=", "\"bert-base-uncased\"", "and", "tokens", "[", "i", "]", "in", "list", "(", "tokenizer", ".", "added_tokens_encoder", ".", "values", "(", ")", ")", ":", "\n", "            ", "mask_choice_p", "[", "i", "]", "=", "0", "\n", "", "", "mask_choice_p", "=", "mask_choice_p", "/", "mask_choice_p", ".", "sum", "(", ")", "\n", "\n", "if", "use_gradient", ":", "\n", "# dict_keys(['tokens', 'grad', 'label', 'prob'])", "\n", "        ", "curr_grad", "=", "np", ".", "array", "(", "gradient_map", "[", "ind_of_gradient_map", "]", "[", "'grad'", "]", ")", "\n", "if", "mask_choice_p", ".", "shape", "==", "curr_grad", ".", "shape", ":", "\n", "            ", "eps", "=", "np", ".", "random", ".", "rand", "(", ")", "/", "20", "\n", "# scale the gradient to [0, 1]", "\n", "curr_grad", "=", "(", "curr_grad", "-", "np", ".", "min", "(", "curr_grad", ")", "+", "eps", ")", "/", "(", "np", ".", "ptp", "(", "curr_grad", ")", "+", "eps", ")", "\n", "curr_grad", "=", "1", "/", "curr_grad", "\n", "mask_choice_p", "=", "mask_choice_p", "*", "curr_grad", "\n", "\n", "", "", "mask_choice_p", "=", "mask_choice_p", "/", "mask_choice_p", ".", "sum", "(", ")", "\n", "mask", "[", "np", ".", "random", ".", "choice", "(", "sz", ",", "num_mask", ",", "replace", "=", "False", ",", "p", "=", "mask_choice_p", ")", "]", "=", "True", "\n", "\n", "mask_targets", "=", "np", ".", "full", "(", "len", "(", "mask", ")", ",", "tokenizer", ".", "pad_token_id", ")", "\n", "mask_targets", "[", "mask", "]", "=", "tokens", "[", "mask", "==", "1", "]", "\n", "\n", "# decide unmasking and random replacement", "\n", "rand_or_unmask_prob", "=", "random_token_prob", "+", "leave_unmasked_prob", "\n", "if", "rand_or_unmask_prob", ">", "0.0", ":", "\n", "        ", "rand_or_unmask", "=", "mask", "&", "(", "np", ".", "random", ".", "rand", "(", "sz", ")", "<", "rand_or_unmask_prob", ")", "\n", "if", "random_token_prob", "==", "0.0", ":", "\n", "            ", "unmask", "=", "rand_or_unmask", "\n", "rand_mask", "=", "None", "\n", "", "elif", "leave_unmasked_prob", "==", "0.0", ":", "\n", "            ", "unmask", "=", "None", "\n", "rand_mask", "=", "rand_or_unmask", "\n", "", "else", ":", "\n", "            ", "unmask_prob", "=", "leave_unmasked_prob", "/", "rand_or_unmask_prob", "\n", "decision", "=", "np", ".", "random", ".", "rand", "(", "sz", ")", "<", "unmask_prob", "\n", "unmask", "=", "rand_or_unmask", "&", "decision", "\n", "rand_mask", "=", "rand_or_unmask", "&", "(", "~", "decision", ")", "\n", "", "", "else", ":", "\n", "        ", "unmask", "=", "rand_mask", "=", "None", "\n", "\n", "", "if", "unmask", "is", "not", "None", ":", "\n", "        ", "mask", "=", "mask", "^", "unmask", "\n", "\n", "", "tokens", "[", "mask", "]", "=", "tokenizer", ".", "mask_token_id", "\n", "if", "rand_mask", "is", "not", "None", ":", "\n", "        ", "num_rand", "=", "rand_mask", ".", "sum", "(", ")", "\n", "if", "num_rand", ">", "0", ":", "\n", "            ", "if", "args", "[", "\"model_name_or_path\"", "]", "==", "\"bert-base-uncased\"", ":", "\n", "                ", "tokens", "[", "rand_mask", "]", "=", "np", ".", "random", ".", "choice", "(", "\n", "len", "(", "tokenizer", ".", "vocab", ")", ",", "\n", "num_rand", ",", "\n", "p", "=", "weights", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "tokens", "[", "rand_mask", "]", "=", "np", ".", "random", ".", "choice", "(", "\n", "len", "(", "tokenizer", ".", "vocab", ")", "+", "2", ",", "\n", "num_rand", ",", "\n", "p", "=", "weights", ",", "\n", ")", "\n", "\n", "", "", "", "return", "torch", ".", "tensor", "(", "tokens", ")", ".", "long", "(", ")", ",", "torch", ".", "tensor", "(", "mask", ")", ".", "long", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_general.hf_reconstruction_prob_tok": [[840, 915], ["model.eval", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.ones_like", "torch.ones_like", "torch.ones_like", "model", "logits.softmax", "torch.sum().item", "torch.sum().item", "torch.sum().item", "model.cuda", "masked_tokens.unsqueeze.dim", "masked_tokens.unsqueeze.unsqueeze", "target_tokens.unsqueeze.unsqueeze", "len", "list", "masked_tokens.unsqueeze.long().to", "float", "range", "logits.softmax.topk", "values.softmax", "torch.sum", "torch.sum", "torch.sum", "len", "masked_tokens.unsqueeze.long", "len", "torch.cat", "torch.cat", "torch.cat", "len", "torch.cat", "torch.cat", "torch.cat", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.log", "torch.log", "torch.log", "next", "model.parameters", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "torch.multinomial", "zip", "torch.multinomial", "torch.multinomial", "torch.multinomial"], "function", ["None"], ["", "def", "hf_reconstruction_prob_tok", "(", "masked_tokens", ",", "\n", "target_tokens", ",", "\n", "tokenizer", ",", "\n", "model", ",", "\n", "softmax_mask", ",", "\n", "reconstruct", "=", "False", ",", "\n", "topk", "=", "1", ")", ":", "\n", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "model", ".", "cuda", "(", ")", "\n", "\n", "", "single", "=", "False", "\n", "\n", "# expand batch size 1", "\n", "if", "masked_tokens", ".", "dim", "(", ")", "==", "1", ":", "\n", "        ", "single", "=", "True", "\n", "masked_tokens", "=", "masked_tokens", ".", "unsqueeze", "(", "0", ")", "\n", "target_tokens", "=", "target_tokens", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "masked_fill", "=", "torch", ".", "ones_like", "(", "masked_tokens", ")", "\n", "\n", "masked_index", "=", "(", "target_tokens", "!=", "tokenizer", ".", "pad_token_id", ")", ".", "nonzero", "(", "as_tuple", "=", "True", ")", "\n", "masked_orig_index", "=", "target_tokens", "[", "masked_index", "]", "\n", "\n", "# edge case of no masked tokens", "\n", "if", "len", "(", "masked_orig_index", ")", "==", "0", ":", "\n", "        ", "if", "reconstruct", ":", "\n", "            ", "return", "masked_tokens", ",", "masked_fill", "\n", "", "else", ":", "\n", "            ", "return", "1.0", "\n", "\n", "", "", "masked_orig_enum", "=", "[", "list", "(", "range", "(", "len", "(", "masked_orig_index", ")", ")", ")", ",", "masked_orig_index", "]", "\n", "\n", "outputs", "=", "model", "(", "\n", "masked_tokens", ".", "long", "(", ")", ".", "to", "(", "device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", ")", ",", "\n", "masked_lm_labels", "=", "target_tokens", "\n", ")", "\n", "\n", "# b * max_len * vocab_size (30524)", "\n", "features", "=", "outputs", "[", "1", "]", "\n", "\n", "logits", "=", "features", "[", "masked_index", "]", "\n", "for", "l", "in", "logits", ":", "\n", "        ", "l", "[", "softmax_mask", "]", "=", "float", "(", "'-inf'", ")", "\n", "", "probs", "=", "logits", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n", "if", "reconstruct", ":", "\n", "# sample from topk", "\n", "        ", "if", "topk", "!=", "-", "1", ":", "\n", "            ", "values", ",", "indices", "=", "probs", ".", "topk", "(", "k", "=", "topk", ",", "dim", "=", "-", "1", ")", "\n", "kprobs", "=", "values", ".", "softmax", "(", "dim", "=", "-", "1", ")", "\n", "if", "len", "(", "masked_index", ")", ">", "1", ":", "\n", "                ", "samples", "=", "torch", ".", "cat", "(", "[", "idx", "[", "torch", ".", "multinomial", "(", "kprob", ",", "1", ")", "]", "for", "kprob", ",", "idx", "in", "zip", "(", "kprobs", ",", "indices", ")", "]", ")", "\n", "", "else", ":", "\n", "                ", "samples", "=", "indices", "[", "torch", ".", "multinomial", "(", "kprobs", ",", "1", ")", "]", "\n", "\n", "# unrestricted sampling", "\n", "", "", "else", ":", "\n", "            ", "if", "len", "(", "masked_index", ")", ">", "1", ":", "\n", "                ", "samples", "=", "torch", ".", "cat", "(", "[", "torch", ".", "multinomial", "(", "prob", ",", "1", ")", "for", "prob", "in", "probs", "]", ")", "\n", "", "else", ":", "\n", "                ", "samples", "=", "torch", ".", "multinomial", "(", "probs", ",", "1", ")", "\n", "\n", "# set samples", "\n", "", "", "masked_tokens", "[", "masked_index", "]", "=", "samples", "\n", "masked_fill", "[", "masked_index", "]", "=", "samples", "\n", "\n", "if", "single", ":", "\n", "            ", "return", "masked_tokens", "[", "0", "]", ",", "masked_fill", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "return", "masked_tokens", ",", "masked_fill", "\n", "\n", "", "", "return", "torch", ".", "sum", "(", "torch", ".", "log", "(", "probs", "[", "masked_orig_enum", "]", ")", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_multiwoz.read_langs_turn": [[12, 125], ["print", "set", "set", "open", "json.load", "ontology.keys", "enumerate", "multiwoz.fix_label.fix_general_label_error", "multiwoz.fix_label.fix_general_label_error", "list", "utils_function.get_input_example", "turn[].strip", "turn[].strip", "turn[].strip", "turn[].strip", "ast.literal_eval", "ast.literal_eval", "list", "list", "dialog_history.append", "dialog_history.append", "dialog_history_delex.append", "dialog_history_delex.append", "set.add", "data.append", "domain_counter.keys", "set", "set", "data.append", "str", "str", "multiwoz.fix_label.fix_general_label_error.items", "str", "multiwoz.fix_label.fix_general_label_error.items", "multiwoz.fix_label.fix_general_label_error.keys", "slot_values.append", "slot_values.append", "gates.append", "str", "dialog_act[].keys", "set", "str", "str", "ontology[].keys", "len", "gates.append", "gates.append", "set", "k.split", "multiwoz.fix_label.fix_general_label_error.items", "ontology[].keys", "set.add", "set", "set", "str", "str", "dial_dict[].replace", "dial_dict[].replace", "dial_dict[].replace", "key.lower", "[].lower", "set.keys", "set.keys", "key.split"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.fix_label.fix_general_label_error", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.fix_label.fix_general_label_error", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.get_input_example"], ["def", "read_langs_turn", "(", "args", ",", "file_name", ",", "ontology", ",", "dialog_act", ",", "max_line", "=", "None", ",", "domain_act_flag", "=", "False", ",", "update_ont_flag", "=", "False", ")", ":", "\n", "    ", "print", "(", "(", "\"Reading from {} for read_langs_turn\"", ".", "format", "(", "file_name", ")", ")", ")", "\n", "\n", "data", "=", "[", "]", "\n", "SLOTS", "=", "[", "k", "for", "k", "in", "ontology", ".", "keys", "(", ")", "]", "\n", "max_resp_len", ",", "max_value_len", "=", "0", ",", "0", "\n", "domain_counter", "=", "{", "}", "\n", "response_candidates", "=", "set", "(", ")", "\n", "add_slot_values", "=", "set", "(", ")", "\n", "\n", "with", "open", "(", "file_name", ")", "as", "f", ":", "\n", "        ", "dials", "=", "json", ".", "load", "(", "f", ")", "\n", "\n", "cnt_lin", "=", "1", "\n", "for", "dial_dict", "in", "dials", ":", "\n", "            ", "dialog_history", ",", "dialog_history_delex", "=", "[", "]", ",", "[", "]", "\n", "\n", "# Filtering and counting domains", "\n", "for", "domain", "in", "dial_dict", "[", "\"domains\"", "]", ":", "\n", "                ", "if", "domain", "not", "in", "EXPERIMENT_DOMAINS", ":", "\n", "                    ", "continue", "\n", "", "if", "domain", "not", "in", "domain_counter", ".", "keys", "(", ")", ":", "\n", "                    ", "domain_counter", "[", "domain", "]", "=", "0", "\n", "", "domain_counter", "[", "domain", "]", "+=", "1", "\n", "\n", "# Reading data", "\n", "", "for", "ti", ",", "turn", "in", "enumerate", "(", "dial_dict", "[", "\"dialogue\"", "]", ")", ":", "\n", "\n", "                ", "belief_dict", "=", "fix_general_label_error", "(", "turn", "[", "\"belief_state\"", "]", ",", "False", ",", "SLOTS", ",", "args", "[", "\"ontology_version\"", "]", ")", "\n", "belief_list", "=", "[", "str", "(", "k", ")", "+", "'-'", "+", "str", "(", "v", ")", "for", "k", ",", "v", "in", "belief_dict", ".", "items", "(", ")", "]", "\n", "turn_slot_dict", "=", "fix_general_label_error", "(", "turn", "[", "\"turn_label\"", "]", ",", "True", ",", "SLOTS", ",", "args", "[", "\"ontology_version\"", "]", ")", "\n", "turn_slot_list", "=", "[", "str", "(", "k", ")", "+", "'-'", "+", "str", "(", "v", ")", "for", "k", ",", "v", "in", "turn_slot_dict", ".", "items", "(", ")", "]", "\n", "turn_slot", "=", "list", "(", "set", "(", "[", "k", ".", "split", "(", "\"-\"", ")", "[", "1", "]", "for", "k", ",", "v", "in", "turn_slot_dict", ".", "items", "(", ")", "]", ")", ")", "\n", "\n", "slot_values", ",", "gates", "=", "[", "]", ",", "[", "]", "\n", "for", "slot", "in", "SLOTS", ":", "\n", "                    ", "if", "slot", "in", "belief_dict", ".", "keys", "(", ")", ":", "\n", "\n", "# update ontology", "\n", "                        ", "if", "\"the {}\"", ".", "format", "(", "belief_dict", "[", "slot", "]", ")", "in", "ontology", "[", "slot", "]", ".", "keys", "(", ")", ":", "\n", "                            ", "belief_dict", "[", "slot", "]", "=", "\"the {}\"", ".", "format", "(", "belief_dict", "[", "slot", "]", ")", "\n", "\n", "", "if", "belief_dict", "[", "slot", "]", "not", "in", "ontology", "[", "slot", "]", ".", "keys", "(", ")", "and", "update_ont_flag", ":", "\n", "                            ", "if", "slot", "+", "\"-\"", "+", "belief_dict", "[", "slot", "]", "not", "in", "add_slot_values", ":", "\n", "# print(\"[Info] Adding Slot: {} with value: [{}]\".format(slot, belief_dict[slot]))", "\n", "                                ", "add_slot_values", ".", "add", "(", "slot", "+", "\"-\"", "+", "belief_dict", "[", "slot", "]", ")", "\n", "\n", "", "ontology", "[", "slot", "]", "[", "belief_dict", "[", "slot", "]", "]", "=", "len", "(", "ontology", "[", "slot", "]", ")", "\n", "\n", "", "slot_values", ".", "append", "(", "belief_dict", "[", "slot", "]", ")", "\n", "\n", "if", "belief_dict", "[", "slot", "]", "==", "\"none\"", ":", "\n", "                            ", "gates", ".", "append", "(", "0", ")", "\n", "", "else", ":", "\n", "                            ", "gates", ".", "append", "(", "1", ")", "\n", "", "", "else", ":", "\n", "                        ", "slot_values", ".", "append", "(", "\"none\"", ")", "\n", "gates", ".", "append", "(", "0", ")", "\n", "\n", "# dialgoue act (exclude domain)", "\n", "", "", "if", "turn", "[", "\"turn_idx\"", "]", "==", "0", "and", "turn", "[", "\"system_transcript\"", "]", "==", "\"\"", ":", "\n", "                    ", "cur_sys_acts", "=", "set", "(", ")", "\n", "", "elif", "str", "(", "turn", "[", "\"turn_idx\"", "]", ")", "not", "in", "dialog_act", "[", "dial_dict", "[", "\"dialogue_idx\"", "]", ".", "replace", "(", "\".json\"", ",", "\"\"", ")", "]", ".", "keys", "(", ")", ":", "\n", "                    ", "cur_sys_acts", "=", "set", "(", ")", "\n", "", "elif", "dialog_act", "[", "dial_dict", "[", "\"dialogue_idx\"", "]", ".", "replace", "(", "\".json\"", ",", "\"\"", ")", "]", "[", "str", "(", "turn", "[", "\"turn_idx\"", "]", ")", "]", "==", "\"No Annotation\"", ":", "\n", "                    ", "cur_sys_acts", "=", "set", "(", ")", "\n", "", "else", ":", "\n", "                    ", "cur_sys_acts", "=", "dialog_act", "[", "dial_dict", "[", "\"dialogue_idx\"", "]", ".", "replace", "(", "\".json\"", ",", "\"\"", ")", "]", "[", "str", "(", "turn", "[", "\"turn_idx\"", "]", ")", "]", "\n", "\n", "if", "domain_act_flag", ":", "\n", "                        ", "cur_sys_acts", "=", "set", "(", "[", "key", ".", "lower", "(", ")", "for", "key", "in", "cur_sys_acts", ".", "keys", "(", ")", "]", ")", "\n", "", "else", ":", "\n", "                        ", "cur_sys_acts", "=", "set", "(", "[", "key", ".", "split", "(", "\"-\"", ")", "[", "1", "]", ".", "lower", "(", ")", "for", "key", "in", "cur_sys_acts", ".", "keys", "(", ")", "]", ")", "\n", "\n", "", "", "data_detail", "=", "get_input_example", "(", "\"turn\"", ")", "\n", "data_detail", "[", "\"slots\"", "]", "=", "SLOTS", "\n", "data_detail", "[", "\"ID\"", "]", "=", "dial_dict", "[", "\"dialogue_idx\"", "]", "\n", "data_detail", "[", "\"turn_id\"", "]", "=", "turn", "[", "\"turn_idx\"", "]", "\n", "data_detail", "[", "\"domains\"", "]", "=", "dial_dict", "[", "\"domains\"", "]", "\n", "data_detail", "[", "\"turn_domain\"", "]", "=", "turn", "[", "\"domain\"", "]", "\n", "data_detail", "[", "\"turn_usr\"", "]", "=", "turn", "[", "\"transcript\"", "]", ".", "strip", "(", ")", "\n", "data_detail", "[", "\"turn_sys\"", "]", "=", "turn", "[", "\"system_transcript\"", "]", ".", "strip", "(", ")", "\n", "data_detail", "[", "\"turn_usr_delex\"", "]", "=", "turn", "[", "\"transcript_delex\"", "]", ".", "strip", "(", ")", "\n", "data_detail", "[", "\"turn_sys_delex\"", "]", "=", "turn", "[", "\"system_transcript_delex\"", "]", ".", "strip", "(", ")", "\n", "data_detail", "[", "\"belief_state_vec\"", "]", "=", "ast", ".", "literal_eval", "(", "turn", "[", "\"belief_state_vec\"", "]", ")", "\n", "data_detail", "[", "\"db_pointer\"", "]", "=", "ast", ".", "literal_eval", "(", "turn", "[", "\"db_pointer\"", "]", ")", "\n", "data_detail", "[", "\"dialog_history\"", "]", "=", "list", "(", "dialog_history", ")", "\n", "data_detail", "[", "\"dialog_history_delex\"", "]", "=", "list", "(", "dialog_history_delex", ")", "\n", "data_detail", "[", "\"belief\"", "]", "=", "belief_dict", "\n", "data_detail", "[", "\"del_belief\"", "]", "=", "turn_slot_dict", "\n", "data_detail", "[", "\"slot_gate\"", "]", "=", "gates", "\n", "data_detail", "[", "\"slot_values\"", "]", "=", "slot_values", "\n", "data_detail", "[", "\"sys_act\"", "]", "=", "cur_sys_acts", "\n", "data_detail", "[", "\"turn_slot\"", "]", "=", "turn_slot", "\n", "\n", "if", "not", "args", "[", "\"only_last_turn\"", "]", ":", "\n", "                    ", "data", ".", "append", "(", "data_detail", ")", "\n", "\n", "", "dialog_history", ".", "append", "(", "turn", "[", "\"system_transcript\"", "]", ")", "\n", "dialog_history", ".", "append", "(", "turn", "[", "\"transcript\"", "]", ")", "\n", "dialog_history_delex", ".", "append", "(", "turn", "[", "\"system_transcript_delex\"", "]", ")", "\n", "dialog_history_delex", ".", "append", "(", "turn", "[", "\"transcript_delex\"", "]", ")", "\n", "response_candidates", ".", "add", "(", "str", "(", "data_detail", "[", "\"turn_sys\"", "]", ")", ")", "\n", "\n", "", "if", "args", "[", "\"only_last_turn\"", "]", ":", "\n", "                ", "data", ".", "append", "(", "data_detail", ")", "\n", "\n", "", "cnt_lin", "+=", "1", "\n", "if", "(", "max_line", "and", "cnt_lin", ">=", "max_line", ")", ":", "\n", "                ", "break", "\n", "\n", "#print(\"MultiWOZ domain counter: \", domain_counter)", "\n", "", "", "", "return", "data", ",", "ontology", ",", "response_candidates", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_multiwoz.read_langs_dial": [[127, 130], ["print"], "function", ["None"], ["", "def", "read_langs_dial", "(", "args", ",", "file_name", ",", "ontology", ",", "dialog_act", ",", "max_line", "=", "None", ",", "domain_act_flag", "=", "False", ",", "update_ont_flag", "=", "False", ")", ":", "\n", "    ", "print", "(", "(", "\"Reading from {} for read_langs_dial\"", ".", "format", "(", "file_name", ")", ")", ")", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_multiwoz.get_slot_information": [[132, 146], ["dict", "collections.OrderedDict", "dict.items", "k.replace().lower", "k.lower", "clean_original_ontology", "ontology.items", "ontology_new[].keys", "len", "k.replace", "k.split"], "function", ["None"], ["", "def", "get_slot_information", "(", "args", ",", "ontology", ")", ":", "\n", "    ", "ontology_domains", "=", "dict", "(", "[", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "ontology", ".", "items", "(", ")", "if", "k", ".", "split", "(", "\"-\"", ")", "[", "0", "]", "in", "EXPERIMENT_DOMAINS", "]", ")", "\n", "ontology_new", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "ontology_domains", ".", "items", "(", ")", ":", "\n", "        ", "name", "=", "k", ".", "replace", "(", "\" \"", ",", "\"\"", ")", ".", "lower", "(", ")", "if", "(", "\"book\"", "not", "in", "k", ")", "else", "k", ".", "lower", "(", ")", "\n", "\n", "if", "args", "[", "\"ontology_version\"", "]", "!=", "\"\"", ":", "\n", "            ", "v", "=", "clean_original_ontology", "(", "v", ")", "\n", "\n", "", "ontology_new", "[", "name", "]", "=", "{", "\"none\"", ":", "0", ",", "\"do n't care\"", ":", "1", "}", "\n", "for", "vv", "in", "v", ":", "\n", "            ", "if", "vv", "not", "in", "ontology_new", "[", "name", "]", ".", "keys", "(", ")", ":", "\n", "                ", "ontology_new", "[", "name", "]", "[", "vv", "]", "=", "len", "(", "ontology_new", "[", "name", "]", ")", "\n", "", "", "", "return", "ontology_new", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_multiwoz.prepare_data_multiwoz": [[148, 251], ["print", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "json.load", "print", "print", "print", "print", "json.load", "print", "json.load", "utils_multiwoz.get_slot_information", "open", "os.path.exists", "print", "json.dump", "open", "open", "os.path.join", "globals", "globals", "globals", "open", "len", "len", "len", "len", "set", "os.path.join", "len", "list", "enumerate", "set", "len", "set", "print", "enumerate", "len", "len", "print", "print", "print", "enumerate", "len", "len", "len", "type", "set.update", "set.update"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_multiwoz.get_slot_information"], ["", "def", "prepare_data_multiwoz", "(", "args", ")", ":", "\n", "    ", "example_type", "=", "args", "[", "\"example_type\"", "]", "\n", "max_line", "=", "args", "[", "\"max_line\"", "]", "\n", "\n", "version", "=", "\"2.1\"", "\n", "print", "(", "\"[Info] Using Version\"", ",", "version", ")", "\n", "\n", "file_trn", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'MultiWOZ-{}/train_dials.json'", ".", "format", "(", "version", ")", ")", "\n", "file_dev", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'MultiWOZ-{}/dev_dials.json'", ".", "format", "(", "version", ")", ")", "\n", "file_tst", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'MultiWOZ-{}/test_dials.json'", ".", "format", "(", "version", ")", ")", "\n", "\n", "path_to_ontology_mapping", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "\n", "\"MultiWOZ-{}/ontology-mapping{}.json\"", ".", "format", "(", "version", ",", "args", "[", "\"ontology_version\"", "]", ")", ")", "\n", "\n", "if", "os", ".", "path", ".", "exists", "(", "path_to_ontology_mapping", ")", ":", "\n", "        ", "print", "(", "\"[Info] Load from old complete ontology from version {}...\"", ".", "format", "(", "args", "[", "\"ontology_version\"", "]", ")", ")", "\n", "ontology_mapping", "=", "json", ".", "load", "(", "open", "(", "path_to_ontology_mapping", ",", "'r'", ")", ")", "\n", "update_ont_flag", "=", "False", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"[Info] Creating new ontology for version {}...\"", ".", "format", "(", "args", "[", "\"ontology_version\"", "]", ")", ")", "\n", "ontology", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "\"MultiWOZ-{}/ontology.json\"", ".", "format", "(", "version", ")", ")", ",", "'r'", ")", ")", "\n", "ontology_mapping", "=", "get_slot_information", "(", "args", ",", "ontology", ")", "\n", "update_ont_flag", "=", "True", "\n", "\n", "", "dialog_act", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "\"MultiWOZ-{}/dialogue_acts.json\"", ".", "format", "(", "version", ")", ")", ",", "'r'", ")", ")", "\n", "\n", "_example_type", "=", "\"dial\"", "if", "\"dial\"", "in", "example_type", "else", "example_type", "\n", "\n", "pair_trn", ",", "ontology_mapping", ",", "resp_cand_trn", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "args", ",", "\n", "file_trn", ",", "\n", "ontology_mapping", ",", "\n", "dialog_act", ",", "\n", "max_line", ",", "\n", "args", "[", "\"domain_act\"", "]", ",", "\n", "update_ont_flag", ")", "\n", "\n", "pair_dev", ",", "ontology_mapping", ",", "resp_cand_dev", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "args", ",", "\n", "file_dev", ",", "\n", "ontology_mapping", ",", "\n", "dialog_act", ",", "\n", "max_line", ",", "\n", "args", "[", "\"domain_act\"", "]", ",", "\n", "update_ont_flag", ")", "\n", "\n", "pair_tst", ",", "ontology_mapping", ",", "resp_cand_tst", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "args", ",", "\n", "file_tst", ",", "\n", "ontology_mapping", ",", "\n", "dialog_act", ",", "\n", "max_line", ",", "\n", "args", "[", "\"domain_act\"", "]", ",", "\n", "update_ont_flag", ")", "\n", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "path_to_ontology_mapping", ")", ":", "\n", "        ", "print", "(", "\"[Info] Dumping complete ontology...\"", ")", "\n", "json", ".", "dump", "(", "ontology_mapping", ",", "open", "(", "path_to_ontology_mapping", ",", "\"w\"", ")", ",", "indent", "=", "4", ")", "\n", "\n", "", "print", "(", "\"Read %s pairs train from MultiWOZ\"", "%", "len", "(", "pair_trn", ")", ")", "\n", "print", "(", "\"Read %s pairs valid from MultiWOZ\"", "%", "len", "(", "pair_dev", ")", ")", "\n", "print", "(", "\"Read %s pairs test from MultiWOZ\"", "%", "len", "(", "pair_tst", ")", ")", "\n", "\n", "# print('args[\"task_name\"]', args[\"task_name\"])", "\n", "\n", "if", "args", "[", "\"task_name\"", "]", "==", "\"dst\"", ":", "\n", "        ", "meta_data", "=", "{", "\"slots\"", ":", "ontology_mapping", ",", "\"num_labels\"", ":", "len", "(", "ontology_mapping", ")", "}", "\n", "\n", "", "elif", "args", "[", "\"task_name\"", "]", "==", "\"turn_domain\"", ":", "\n", "        ", "domain_set", "=", "set", "(", "[", "d", "[", "\"turn_domain\"", "]", "for", "d", "in", "pair_trn", "]", ")", "\n", "domain_dict", "=", "{", "d", ":", "i", "for", "i", ",", "d", "in", "enumerate", "(", "domain_set", ")", "}", "\n", "meta_data", "=", "{", "\"turn_domain\"", ":", "domain_dict", ",", "\"num_labels\"", ":", "len", "(", "domain_dict", ")", "}", "\n", "\n", "", "elif", "args", "[", "\"task_name\"", "]", "==", "\"turn_slot\"", ":", "\n", "        ", "turn_slot_list", "=", "[", "]", "\n", "for", "d", "in", "pair_trn", ":", "\n", "            ", "turn_slot_list", "+=", "d", "[", "\"turn_slot\"", "]", "\n", "", "turn_slot_list", "=", "list", "(", "set", "(", "turn_slot_list", ")", ")", "\n", "turn_slot_mapping", "=", "{", "d", ":", "i", "for", "i", ",", "d", "in", "enumerate", "(", "turn_slot_list", ")", "}", "\n", "meta_data", "=", "{", "\"turn_slot\"", ":", "turn_slot_mapping", ",", "\"num_labels\"", ":", "len", "(", "turn_slot_mapping", ")", "}", "\n", "\n", "", "elif", "args", "[", "\"task_name\"", "]", "==", "\"sysact\"", ":", "\n", "        ", "act_set", "=", "set", "(", ")", "\n", "for", "pair", "in", "[", "pair_tst", ",", "pair_dev", ",", "pair_trn", "]", ":", "\n", "            ", "for", "p", "in", "pair", ":", "\n", "                ", "if", "type", "(", "p", "[", "\"sys_act\"", "]", ")", "==", "list", ":", "\n", "                    ", "for", "sysact", "in", "p", "[", "\"sys_act\"", "]", ":", "\n", "                        ", "act_set", ".", "update", "(", "sysact", ")", "\n", "", "", "else", ":", "\n", "                    ", "act_set", ".", "update", "(", "p", "[", "\"sys_act\"", "]", ")", "\n", "\n", "", "", "", "print", "(", "\"act_set\"", ",", "len", "(", "act_set", ")", ",", "act_set", ")", "\n", "sysact_lookup", "=", "{", "sysact", ":", "i", "for", "i", ",", "sysact", "in", "enumerate", "(", "act_set", ")", "}", "\n", "meta_data", "=", "{", "\"sysact\"", ":", "sysact_lookup", ",", "\"num_labels\"", ":", "len", "(", "act_set", ")", "}", "\n", "\n", "", "elif", "args", "[", "\"task_name\"", "]", "==", "\"rs\"", ":", "\n", "        ", "print", "(", "\"resp_cand_trn\"", ",", "len", "(", "resp_cand_trn", ")", ")", "\n", "print", "(", "\"resp_cand_dev\"", ",", "len", "(", "resp_cand_dev", ")", ")", "\n", "print", "(", "\"resp_cand_tst\"", ",", "len", "(", "resp_cand_tst", ")", ")", "\n", "meta_data", "=", "{", "\"num_labels\"", ":", "0", ",", "\"resp_cand_trn\"", ":", "resp_cand_trn", "}", "\n", "\n", "", "else", ":", "\n", "        ", "meta_data", "=", "{", "\"num_labels\"", ":", "0", "}", "\n", "\n", "", "return", "pair_trn", ",", "pair_dev", ",", "pair_tst", ",", "meta_data", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dst.Dataset_dst.__init__": [[10, 27], ["len", "list", "tokenizer.convert_tokens_to_ids", "tokenizer.convert_tokens_to_ids", "unified_meta[].keys"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_info", ",", "tokenizer", ",", "args", ",", "unified_meta", ",", "mode", ",", "max_length", "=", "512", ")", ":", "\n", "        ", "\"\"\"Reads source and target sequences from txt files.\"\"\"", "\n", "self", ".", "data", "=", "data_info", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "num_total_seqs", "=", "len", "(", "data_info", "[", "\"ID\"", "]", ")", "\n", "self", ".", "usr_token", "=", "args", "[", "\"usr_token\"", "]", "\n", "self", ".", "sys_token", "=", "args", "[", "\"sys_token\"", "]", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "unified_meta", "=", "unified_meta", "\n", "self", ".", "slots", "=", "list", "(", "unified_meta", "[", "\"slots\"", "]", ".", "keys", "(", ")", ")", "\n", "self", ".", "mask_token_idx", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "\"[MASK]\"", ")", "\n", "self", ".", "sep_token_idx", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "\"[SEP]\"", ")", "\n", "\n", "self", ".", "start_token", "=", "self", ".", "tokenizer", ".", "cls_token", "if", "\"bert\"", "in", "self", ".", "args", "[", "\"model_type\"", "]", "else", "self", ".", "tokenizer", ".", "bos_token", "\n", "self", ".", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", "if", "\"bert\"", "in", "self", ".", "args", "[", "\"model_type\"", "]", "else", "self", ".", "tokenizer", ".", "eos_token", "\n", "self", ".", "context_plain", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dst.Dataset_dst.__getitem__": [[28, 85], ["dataloader_dst.Dataset_dst.get_concat_context", "dataloader_dst.Dataset_dst.preprocess_slot", "set", "set.add", "dataloader_dst.Dataset_dst.preprocess", "enumerate", "dataloader_dst.Dataset_dst.context_plain.get", "dataloader_dst.Dataset_dst.concat_dh_sys_usr", "len", "NotImplemented", "ontology_idx.append", "domain_slot.split", "[].keys", "print", "print", "print", "ontology_idx.append", "s.split"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_usdl.Dataset_usdl.get_concat_context", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_usdl.Dataset_usdl.preprocess_slot", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.preprocess", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_usdl.Dataset_usdl.concat_dh_sys_usr"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Returns one data pair (source and target).\"\"\"", "\n", "\n", "if", "self", ".", "args", "[", "\"example_type\"", "]", "==", "\"turn\"", ":", "\n", "            ", "dialog_history_str", "=", "self", ".", "get_concat_context", "(", "self", ".", "data", "[", "\"dialog_history\"", "]", "[", "index", "]", ")", "\n", "gate_label", "=", "self", ".", "data", "[", "\"slot_gate\"", "]", "[", "index", "]", "\n", "if", "not", "self", ".", "context_plain", ".", "get", "(", "index", ")", ":", "\n", "                ", "context_plain", "=", "self", ".", "concat_dh_sys_usr", "(", "dialog_history_str", ",", "\n", "self", ".", "data", "[", "\"turn_sys\"", "]", "[", "index", "]", ",", "\n", "self", ".", "data", "[", "\"turn_usr\"", "]", "[", "index", "]", ")", "\n", "self", ".", "context_plain", "[", "index", "]", "=", "context_plain", "\n", "", "else", ":", "\n", "                ", "context_plain", "=", "self", ".", "context_plain", "[", "index", "]", "\n", "\n", "", "slot_values_plain", "=", "self", ".", "data", "[", "\"slot_values\"", "]", "[", "index", "]", "\n", "slot_values", "=", "self", ".", "preprocess_slot", "(", "slot_values_plain", ")", "\n", "\n", "triggered_domains", "=", "set", "(", "[", "domain_slot", ".", "split", "(", "\"-\"", ")", "[", "0", "]", "for", "domain_slot", "in", "self", ".", "data", "[", "\"belief\"", "]", "[", "index", "]", ".", "keys", "(", ")", "]", ")", "\n", "triggered_domains", ".", "add", "(", "self", ".", "data", "[", "\"turn_domain\"", "]", "[", "index", "]", ")", "\n", "assert", "len", "(", "triggered_domains", ")", "!=", "0", "\n", "\n", "triggered_ds_mask", "=", "[", "1", "if", "s", ".", "split", "(", "\"-\"", ")", "[", "0", "]", "in", "triggered_domains", "else", "0", "for", "s", "in", "self", ".", "slots", "]", "\n", "triggered_ds_idx", "=", "[", "]", "\n", "triggered_ds_pos", "=", "[", "]", "\n", "\n", "context", "=", "self", ".", "preprocess", "(", "context_plain", ")", "\n", "\n", "ontology_idx", "=", "[", "]", "\n", "for", "si", ",", "sv", "in", "enumerate", "(", "slot_values_plain", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "ontology_idx", ".", "append", "(", "self", ".", "unified_meta", "[", "\"slots\"", "]", "[", "self", ".", "slots", "[", "si", "]", "]", "[", "sv", "]", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                    ", "print", "(", "\"Not In Ontology\"", ")", "\n", "print", "(", "e", ")", "\n", "print", "(", "self", ".", "slots", "[", "si", "]", ",", "sv", ")", "\n", "ontology_idx", ".", "append", "(", "-", "1", ")", "\n", "\n", "", "", "", "elif", "self", ".", "args", "[", "\"example_type\"", "]", "==", "\"dial\"", ":", "\n", "            ", "raise", "NotImplemented", "(", ")", "\n", "\n", "", "item_info", "=", "{", "\n", "'index'", ":", "index", ",", "\n", "\"ID\"", ":", "self", ".", "data", "[", "\"ID\"", "]", "[", "index", "]", ",", "\n", "\"turn_id\"", ":", "self", ".", "data", "[", "\"turn_id\"", "]", "[", "index", "]", ",", "\n", "\"del_belief\"", ":", "self", ".", "data", "[", "\"del_belief\"", "]", "[", "index", "]", ",", "\n", "\"slot_gate\"", ":", "gate_label", ",", "\n", "\"context\"", ":", "context", ",", "\n", "\"context_plain\"", ":", "context_plain", ",", "\n", "\"slot_values\"", ":", "slot_values", ",", "\n", "\"belief\"", ":", "self", ".", "data", "[", "\"belief\"", "]", "[", "index", "]", ",", "\n", "\"slots\"", ":", "self", ".", "data", "[", "\"slots\"", "]", "[", "index", "]", ",", "\n", "\"belief_ontology\"", ":", "ontology_idx", ",", "\n", "\"triggered_ds_mask\"", ":", "triggered_ds_mask", ",", "\n", "\"triggered_ds_idx\"", ":", "triggered_ds_idx", ",", "\n", "\"triggered_ds_pos\"", ":", "triggered_ds_pos", "}", "\n", "\n", "return", "item_info", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dst.Dataset_dst.__len__": [[86, 88], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_total_seqs", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dst.Dataset_dst.concat_dh_sys_usr": [[89, 91], ["None"], "methods", ["None"], ["", "def", "concat_dh_sys_usr", "(", "self", ",", "dialog_history", ",", "sys", ",", "usr", ")", ":", "\n", "        ", "return", "dialog_history", "+", "\" {} \"", ".", "format", "(", "self", ".", "sep_token", ")", "+", "\" {} \"", ".", "format", "(", "self", ".", "sys_token", ")", "+", "sys", "+", "\" {} \"", ".", "format", "(", "self", ".", "usr_token", ")", "+", "usr", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dst.Dataset_dst.preprocess": [[92, 98], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "dataloader_dst.Dataset_dst.tokenizer.tokenize", "dataloader_dst.Dataset_dst.tokenizer.convert_tokens_to_ids", "dataloader_dst.Dataset_dst.tokenizer.tokenize"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"Converts words to ids.\"\"\"", "\n", "#story = torch.Tensor(self.tokenizer.encode(sequence))", "\n", "tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "self", ".", "start_token", ")", "+", "self", ".", "tokenizer", ".", "tokenize", "(", "sequence", ")", "[", "-", "self", ".", "max_length", "+", "1", ":", "]", "\n", "story", "=", "torch", ".", "Tensor", "(", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", ")", "\n", "return", "story", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dst.Dataset_dst.preprocess_slot": [[99, 106], ["list", "story.append", "dataloader_dst.Dataset_dst.tokenizer.encode"], "methods", ["None"], ["", "def", "preprocess_slot", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"Converts words to ids.\"\"\"", "\n", "story", "=", "[", "]", "\n", "for", "value", "in", "sequence", ":", "\n", "            ", "v", "=", "list", "(", "self", ".", "tokenizer", ".", "encode", "(", "value", "+", "\" {}\"", ".", "format", "(", "self", ".", "sep_token", ")", ")", ")", "\n", "story", ".", "append", "(", "v", ")", "\n", "", "return", "story", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dst.Dataset_dst.get_concat_context": [[107, 116], ["enumerate", "dialog_history_str.strip.strip.strip"], "methods", ["None"], ["", "def", "get_concat_context", "(", "self", ",", "dialog_history", ")", ":", "\n", "        ", "dialog_history_str", "=", "\"\"", "\n", "for", "ui", ",", "uttr", "in", "enumerate", "(", "dialog_history", ")", ":", "\n", "            ", "if", "ui", "%", "2", "==", "0", ":", "\n", "                ", "dialog_history_str", "+=", "\"{} {} \"", ".", "format", "(", "self", ".", "sys_token", ",", "uttr", ")", "\n", "", "else", ":", "\n", "                ", "dialog_history_str", "+=", "\"{} {} \"", ".", "format", "(", "self", ".", "usr_token", ",", "uttr", ")", "\n", "", "", "dialog_history_str", "=", "dialog_history_str", ".", "strip", "(", ")", "\n", "return", "dialog_history_str", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dst.Dataset_dst.set_pesudo_label": [[117, 128], ["zip", "enumerate", "[].items"], "methods", ["None"], ["", "def", "set_pesudo_label", "(", "self", ",", "indexes", ",", "pseudo_labels", ")", ":", "\n", "        ", "'''set labels to indexes'''", "\n", "for", "ind", ",", "pseudo_label", "in", "zip", "(", "indexes", ",", "pseudo_labels", ")", ":", "\n", "            ", "for", "slot_ind", ",", "pseudo_slot_label", "in", "enumerate", "(", "pseudo_label", ")", ":", "\n", "                ", "slot_name", "=", "self", ".", "slots", "[", "slot_ind", "]", "\n", "# print('slot_name', slot_name)", "\n", "for", "slot_value_plain", ",", "_label", "in", "self", ".", "unified_meta", "[", "\"slots\"", "]", "[", "slot_name", "]", ".", "items", "(", ")", ":", "\n", "                    ", "if", "_label", "==", "pseudo_slot_label", ":", "\n", "# print('pseudo_slot_label', pseudo_slot_label)", "\n", "# print('old', self.data['slot_values'][ind])", "\n", "                        ", "self", ".", "data", "[", "'slot_values'", "]", "[", "ind", "]", "[", "slot_ind", "]", "=", "slot_value_plain", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dst.Dataset_dst.reset_dst_context": [[129, 131], ["None"], "methods", ["None"], ["", "", "", "", "", "def", "reset_dst_context", "(", "self", ",", "index", ",", "new_sent", ")", ":", "\n", "        ", "self", ".", "context_plain", "[", "index", "]", "=", "new_sent", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dst.collate_fn_dst_turn": [[132, 156], ["torch.sort", "data[].keys", "utils_function.merge", "utils_function.merge_multi_response", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "utils_function.to_cuda", "utils_function.to_cuda", "utils_function.to_cuda", "utils_function.to_cuda", "utils_function.to_cuda", "len"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge_multi_response", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda"], ["", "", "def", "collate_fn_dst_turn", "(", "data", ")", ":", "\n", "# sort a list by sequence length (descending order) to use pack_padded_sequence", "\n", "    ", "data", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "'context'", "]", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "item_info", "=", "{", "}", "\n", "for", "key", "in", "data", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "        ", "item_info", "[", "key", "]", "=", "[", "d", "[", "key", "]", "for", "d", "in", "data", "]", "\n", "\n", "# merge sequences", "\n", "", "src_seqs", ",", "src_lengths", "=", "merge", "(", "item_info", "[", "'context'", "]", ")", "\n", "y_seqs", ",", "y_lengths", "=", "merge_multi_response", "(", "item_info", "[", "\"slot_values\"", "]", ")", "\n", "gates", "=", "torch", ".", "tensor", "(", "item_info", "[", "\"slot_gate\"", "]", ")", "\n", "belief_ontology", "=", "torch", ".", "tensor", "(", "item_info", "[", "\"belief_ontology\"", "]", ")", "\n", "triggered_ds_mask", "=", "torch", ".", "tensor", "(", "item_info", "[", "\"triggered_ds_mask\"", "]", ")", "\n", "\n", "item_info", "[", "\"context\"", "]", "=", "to_cuda", "(", "src_seqs", ")", "\n", "item_info", "[", "\"context_len\"", "]", "=", "src_lengths", "\n", "item_info", "[", "\"slot_gate\"", "]", "=", "to_cuda", "(", "gates", ")", "\n", "item_info", "[", "\"slot_values\"", "]", "=", "to_cuda", "(", "y_seqs", ")", "\n", "item_info", "[", "\"slot_values_len\"", "]", "=", "y_lengths", "\n", "item_info", "[", "\"belief_ontology\"", "]", "=", "to_cuda", "(", "belief_ontology", ")", "\n", "item_info", "[", "\"triggered_ds_mask\"", "]", "=", "to_cuda", "(", "triggered_ds_mask", ")", "\n", "\n", "return", "item_info", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dst.collate_fn_dst_dial": [[157, 180], ["torch.sort", "data[].keys", "utils_function.merge_sent_and_word", "utils_function.merge_sent_and_word", "torch.tensor", "torch.tensor", "utils_function.to_cuda", "utils_function.to_cuda", "utils_function.merge_multi_response", "utils_function.to_cuda", "len"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge_sent_and_word", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge_sent_and_word", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge_multi_response", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda"], ["", "def", "collate_fn_dst_dial", "(", "data", ")", ":", "\n", "# sort a list by sequence length (descending order) to use pack_padded_sequence", "\n", "    ", "data", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "'context'", "]", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "item_info", "=", "{", "}", "\n", "for", "key", "in", "data", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "        ", "item_info", "[", "key", "]", "=", "[", "d", "[", "key", "]", "for", "d", "in", "data", "]", "\n", "\n", "# merge sequences", "\n", "", "src_seqs", ",", "src_lengths", "=", "merge_sent_and_word", "(", "item_info", "[", "'context'", "]", ")", "\n", "y", "=", "[", "merge_multi_response", "(", "sv", ")", "for", "sv", "in", "item_info", "[", "\"slot_values\"", "]", "]", "\n", "y_seqs", "=", "[", "_y", "[", "0", "]", "for", "_y", "in", "y", "]", "\n", "y_lengths", "=", "[", "_y", "[", "1", "]", "for", "_y", "in", "y", "]", "\n", "gates", ",", "gate_lengths", "=", "merge_sent_and_word", "(", "item_info", "[", "'slot_gate'", "]", ",", "ignore_idx", "=", "-", "1", ")", "\n", "belief_ontology", "=", "torch", ".", "tensor", "(", "item_info", "[", "\"belief_ontology\"", "]", ")", "\n", "\n", "item_info", "[", "\"context\"", "]", "=", "to_cuda", "(", "src_seqs", ")", "\n", "item_info", "[", "\"context_len\"", "]", "=", "src_lengths", "\n", "item_info", "[", "\"slot_gate\"", "]", "=", "to_cuda", "(", "gates", ")", "\n", "item_info", "[", "\"slot_values\"", "]", "=", "[", "to_cuda", "(", "y", ")", "for", "y", "in", "y_seqs", "]", "# TODO", "\n", "item_info", "[", "\"slot_values_len\"", "]", "=", "y_lengths", "# TODO", "\n", "\n", "return", "item_info", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_oos_intent.read_langs": [[8, 32], ["print", "utils_function.get_input_example", "data.append", "len", "intent_counter.keys"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.get_input_example"], ["def", "read_langs", "(", "args", ",", "dtype", ",", "_data", ",", "_oos_data", ")", ":", "\n", "    ", "print", "(", "(", "\"Reading [OOS Intent] for read_langs {}\"", ".", "format", "(", "dtype", ")", ")", ")", "\n", "\n", "data", "=", "[", "]", "\n", "intent_counter", "=", "{", "}", "\n", "\n", "for", "cur_data", "in", "[", "_data", ",", "_oos_data", "]", ":", "\n", "        ", "for", "d", "in", "cur_data", ":", "\n", "            ", "sentence", ",", "label", "=", "d", "[", "0", "]", ",", "d", "[", "1", "]", "\n", "\n", "data_detail", "=", "get_input_example", "(", "\"turn\"", ")", "\n", "data_detail", "[", "\"ID\"", "]", "=", "\"OOS-INTENT-{}-{}\"", ".", "format", "(", "dtype", ",", "len", "(", "data", ")", ")", "\n", "data_detail", "[", "\"turn_usr\"", "]", "=", "sentence", "\n", "data_detail", "[", "\"intent\"", "]", "=", "label", "\n", "data", ".", "append", "(", "data_detail", ")", "\n", "\n", "# count number of each label", "\n", "if", "label", "not", "in", "intent_counter", ".", "keys", "(", ")", ":", "\n", "                ", "intent_counter", "[", "label", "]", "=", "0", "\n", "", "intent_counter", "[", "label", "]", "+=", "1", "\n", "\n", "#print(\"len of OOS Intent counter: \", len(intent_counter))", "\n", "\n", "", "", "return", "data", ",", "intent_counter", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_oos_intent.prepare_data_oos_intent": [[34, 84], ["os.path.join", "print", "json.load", "utils_oos_intent.read_langs", "utils_oos_intent.read_langs", "utils_oos_intent.read_langs", "print", "print", "print", "list", "print", "open", "intent_counter_trn.keys", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_oos_intent.read_langs", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_oos_intent.read_langs", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_oos_intent.read_langs"], ["", "def", "prepare_data_oos_intent", "(", "args", ")", ":", "\n", "    ", "example_type", "=", "args", "[", "\"example_type\"", "]", "\n", "max_line", "=", "args", "[", "\"max_line\"", "]", "\n", "\n", "file_input", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'oos-intent/data/data_full.json'", ")", "\n", "print", "(", "file_input", ")", "\n", "data", "=", "json", ".", "load", "(", "open", "(", "file_input", ",", "\"r\"", ")", ")", "\n", "\n", "\"\"\"\n    {\n    'ID': 'OOS-INTENT-trn-0', \n    'turn_id': 0, \n    'domains': [], \n    'turn_domain': [], \n    'turn_usr': 'what expression would i use to say i love you if i were an italian', \n    'turn_sys': '', \n    'turn_usr_delex': '', \n    'turn_sys_delex': '', \n    'belief_state_vec': [], \n    'db_pointer': [], \n    'dialog_history': [], \n    'dialog_history_delex': [], \n    'belief': {}, \n    'del_belief': {}, \n    'slot_gate': [], \n    'slot_values': [], \n    'slots': [], \n    'sys_act': [], \n    'usr_act': [], \n    'intent': 'translate', \n    'turn_slot': []\n    }\n    \"\"\"", "\n", "#15100", "\n", "pair_trn", ",", "intent_counter_trn", "=", "read_langs", "(", "args", ",", "\"trn\"", ",", "data", "[", "\"train\"", "]", ",", "data", "[", "\"oos_train\"", "]", ")", "\n", "#3100", "\n", "pair_dev", ",", "intent_counter_dev", "=", "read_langs", "(", "args", ",", "\"dev\"", ",", "data", "[", "\"val\"", "]", ",", "data", "[", "\"oos_val\"", "]", ")", "\n", "#5500", "\n", "pair_tst", ",", "intent_counter_tst", "=", "read_langs", "(", "args", ",", "\"tst\"", ",", "data", "[", "\"test\"", "]", ",", "data", "[", "\"oos_test\"", "]", ")", "\n", "\n", "print", "(", "\"Read %s pairs train from OOS Intent\"", "%", "len", "(", "pair_trn", ")", ")", "\n", "print", "(", "\"Read %s pairs valid from OOS Intent\"", "%", "len", "(", "pair_dev", ")", ")", "\n", "print", "(", "\"Read %s pairs test  from OOS Intent\"", "%", "len", "(", "pair_tst", ")", ")", "\n", "\n", "intent_class", "=", "list", "(", "intent_counter_trn", ".", "keys", "(", ")", ")", "\n", "\n", "meta_data", "=", "{", "\"intent\"", ":", "intent_class", ",", "\"num_labels\"", ":", "len", "(", "intent_class", ")", "}", "\n", "print", "(", "\"len(intent_class)\"", ",", "len", "(", "intent_class", ")", ")", "\n", "\n", "return", "pair_trn", ",", "pair_dev", ",", "pair_tst", ",", "meta_data", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_msre2e.read_langs_turn": [[9, 60], ["print", "open", "f.readlines", "dial.split", "Message.lower().strip", "utils_function.get_input_example", "list", "dialog_history.append", "dialog_history.append", "data.append", "data.append", "Message.lower().strip", "Message.lower", "Message.lower"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.get_input_example"], ["def", "read_langs_turn", "(", "args", ",", "file_name", ",", "max_line", "=", "None", ",", "ds_name", "=", "\"\"", ")", ":", "\n", "    ", "print", "(", "(", "\"Reading from {} for read_langs_turn\"", ".", "format", "(", "file_name", ")", ")", ")", "\n", "\n", "data", "=", "[", "]", "\n", "\n", "with", "open", "(", "file_name", ")", "as", "f", ":", "\n", "        ", "dials", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "cnt_lin", "=", "1", "\n", "dialog_history", "=", "[", "]", "\n", "turn_usr", "=", "\"\"", "\n", "turn_sys", "=", "\"\"", "\n", "turn_idx", "=", "0", "\n", "\n", "for", "dial", "in", "dials", "[", "1", ":", "]", ":", "\n", "            ", "dial_split", "=", "dial", ".", "split", "(", "\"\\t\"", ")", "\n", "session_ID", ",", "Message_ID", ",", "Message_from", ",", "Message", "=", "dial_split", "[", "0", "]", ",", "dial_split", "[", "1", "]", ",", "dial_split", "[", "3", "]", ",", "dial_split", "[", "4", "]", "\n", "\n", "if", "Message_ID", "==", "\"1\"", "and", "turn_sys", "!=", "\"\"", ":", "\n", "\n", "                ", "if", "args", "[", "\"only_last_turn\"", "]", ":", "\n", "                    ", "data", ".", "append", "(", "data_detail", ")", "\n", "\n", "", "turn_usr", "=", "\"\"", "\n", "turn_sys", "=", "\"\"", "\n", "dialog_history", "=", "[", "]", "\n", "cnt_lin", "+=", "1", "\n", "turn_idx", "=", "0", "\n", "\n", "", "if", "Message_from", "==", "\"user\"", ":", "\n", "                ", "turn_usr", "=", "Message", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "data_detail", "=", "get_input_example", "(", "\"turn\"", ")", "\n", "data_detail", "[", "\"ID\"", "]", "=", "\"{}-{}\"", ".", "format", "(", "ds_name", ",", "cnt_lin", ")", "\n", "data_detail", "[", "\"turn_id\"", "]", "=", "turn_idx", "\n", "data_detail", "[", "\"turn_usr\"", "]", "=", "turn_usr", "\n", "data_detail", "[", "\"turn_sys\"", "]", "=", "turn_sys", "\n", "data_detail", "[", "\"dialog_history\"", "]", "=", "list", "(", "dialog_history", ")", "\n", "\n", "if", "not", "args", "[", "\"only_last_turn\"", "]", ":", "\n", "                    ", "data", ".", "append", "(", "data_detail", ")", "\n", "\n", "", "dialog_history", ".", "append", "(", "turn_sys", ")", "\n", "dialog_history", ".", "append", "(", "turn_usr", ")", "\n", "turn_idx", "+=", "1", "\n", "", "elif", "Message_from", "==", "\"agent\"", ":", "\n", "                ", "turn_sys", "=", "Message", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "\n", "", "if", "(", "max_line", "and", "cnt_lin", ">=", "max_line", ")", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_msre2e.read_langs_dial": [[62, 66], ["print"], "function", ["None"], ["", "def", "read_langs_dial", "(", "file_name", ",", "ontology", ",", "dialog_act", ",", "max_line", "=", "None", ",", "domain_act_flag", "=", "False", ")", ":", "\n", "    ", "print", "(", "(", "\"Reading from {} for read_langs_dial\"", ".", "format", "(", "file_name", ")", ")", ")", "\n", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_msre2e.prepare_data_msre2e": [[69, 95], ["os.path.join", "os.path.join", "os.path.join", "print", "print", "print", "globals", "globals", "globals", "len", "len", "len"], "function", ["None"], ["", "def", "prepare_data_msre2e", "(", "args", ")", ":", "\n", "    ", "ds_name", "=", "\"MSR-E2E\"", "\n", "\n", "example_type", "=", "args", "[", "\"example_type\"", "]", "\n", "max_line", "=", "args", "[", "\"max_line\"", "]", "\n", "\n", "file_mov", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'e2e_dialog_challenge/data/movie_all.tsv'", ")", "\n", "file_rst", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'e2e_dialog_challenge/data/restaurant_all.tsv'", ")", "\n", "file_tax", "=", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'e2e_dialog_challenge/data/taxi_all.tsv'", ")", "\n", "\n", "_example_type", "=", "\"dial\"", "if", "\"dial\"", "in", "example_type", "else", "example_type", "\n", "pair_mov", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "args", ",", "file_mov", ",", "max_line", ",", "ds_name", "+", "\"-mov\"", ")", "\n", "pair_rst", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "args", ",", "file_rst", ",", "max_line", ",", "ds_name", "+", "\"-rst\"", ")", "\n", "pair_tax", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "args", ",", "file_tax", ",", "max_line", ",", "ds_name", "+", "\"-tax\"", ")", "\n", "\n", "pair_trn", "=", "pair_mov", "+", "pair_rst", "+", "pair_tax", "\n", "pair_dev", "=", "[", "]", "\n", "pair_tst", "=", "[", "]", "\n", "\n", "print", "(", "\"Read {} pairs train from {}\"", ".", "format", "(", "len", "(", "pair_trn", ")", ",", "ds_name", ")", ")", "\n", "print", "(", "\"Read {} pairs valid from {}\"", ".", "format", "(", "len", "(", "pair_dev", ")", ",", "ds_name", ")", ")", "\n", "print", "(", "\"Read {} pairs test  from {}\"", ".", "format", "(", "len", "(", "pair_tst", ")", ",", "ds_name", ")", ")", "\n", "\n", "meta_data", "=", "{", "\"num_labels\"", ":", "0", "}", "\n", "\n", "return", "pair_trn", ",", "pair_dev", ",", "pair_tst", ",", "meta_data", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_schema.read_langs_turn": [[9, 53], ["print", "open", "json.load", "enumerate", "data.append", "turn[].lower().strip", "utils_function.get_input_example", "list", "dialog_history.append", "dialog_history.append", "data.append", "turn[].lower().strip", "turn[].lower", "turn[].lower"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.get_input_example"], ["def", "read_langs_turn", "(", "args", ",", "dial_files", ",", "max_line", "=", "None", ",", "ds_name", "=", "\"\"", ")", ":", "\n", "    ", "print", "(", "(", "\"Reading from {} for read_langs_turn\"", ".", "format", "(", "ds_name", ")", ")", ")", "\n", "\n", "data", "=", "[", "]", "\n", "\n", "cnt_lin", "=", "1", "\n", "for", "dial_file", "in", "dial_files", ":", "\n", "\n", "        ", "f_dials", "=", "open", "(", "dial_file", ",", "'r'", ")", "\n", "\n", "dials", "=", "json", ".", "load", "(", "f_dials", ")", "\n", "\n", "turn_sys", "=", "\"\"", "\n", "turn_usr", "=", "\"\"", "\n", "\n", "for", "dial_dict", "in", "dials", ":", "\n", "            ", "dialog_history", "=", "[", "]", "\n", "for", "ti", ",", "turn", "in", "enumerate", "(", "dial_dict", "[", "\"turns\"", "]", ")", ":", "\n", "                ", "if", "turn", "[", "\"speaker\"", "]", "==", "\"USER\"", ":", "\n", "                    ", "turn_usr", "=", "turn", "[", "\"utterance\"", "]", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "data_detail", "=", "get_input_example", "(", "\"turn\"", ")", "\n", "data_detail", "[", "\"ID\"", "]", "=", "\"{}-{}\"", ".", "format", "(", "ds_name", ",", "cnt_lin", ")", "\n", "data_detail", "[", "\"turn_id\"", "]", "=", "ti", "%", "2", "\n", "data_detail", "[", "\"turn_usr\"", "]", "=", "turn_usr", "\n", "data_detail", "[", "\"turn_sys\"", "]", "=", "turn_sys", "\n", "data_detail", "[", "\"dialog_history\"", "]", "=", "list", "(", "dialog_history", ")", "\n", "\n", "if", "(", "not", "args", "[", "\"only_last_turn\"", "]", ")", ":", "\n", "                        ", "data", ".", "append", "(", "data_detail", ")", "\n", "\n", "", "dialog_history", ".", "append", "(", "turn_sys", ")", "\n", "dialog_history", ".", "append", "(", "turn_usr", ")", "\n", "\n", "", "elif", "turn", "[", "\"speaker\"", "]", "==", "\"SYSTEM\"", ":", "\n", "                    ", "turn_sys", "=", "turn", "[", "\"utterance\"", "]", ".", "lower", "(", ")", ".", "strip", "(", ")", "\n", "\n", "", "", "if", "args", "[", "\"only_last_turn\"", "]", ":", "\n", "                ", "data", ".", "append", "(", "data_detail", ")", "\n", "\n", "", "cnt_lin", "+=", "1", "\n", "if", "(", "max_line", "and", "cnt_lin", ">=", "max_line", ")", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_schema.read_langs_dial": [[55, 58], ["print"], "function", ["None"], ["", "def", "read_langs_dial", "(", "file_name", ",", "ontology", ",", "dialog_act", ",", "max_line", "=", "None", ",", "domain_act_flag", "=", "False", ")", ":", "\n", "    ", "print", "(", "(", "\"Reading from {} for read_langs_dial\"", ".", "format", "(", "file_name", ")", ")", ")", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_schema.prepare_data_schema": [[61, 83], ["print", "print", "print", "os.path.join", "os.path.join", "os.path.join", "os.listdir", "os.listdir", "os.listdir", "globals", "globals", "globals", "len", "len", "len", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "prepare_data_schema", "(", "args", ")", ":", "\n", "    ", "ds_name", "=", "\"Schema\"", "\n", "\n", "example_type", "=", "args", "[", "\"example_type\"", "]", "\n", "max_line", "=", "args", "[", "\"max_line\"", "]", "\n", "\n", "onlyfiles_trn", "=", "[", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'dstc8-schema-guided-dialogue/train/{}'", ".", "format", "(", "f", ")", ")", "for", "f", "in", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "\"dstc8-schema-guided-dialogue/train/\"", ")", ")", "if", "\"dialogues\"", "in", "f", "]", "\n", "onlyfiles_dev", "=", "[", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'dstc8-schema-guided-dialogue/dev/{}'", ".", "format", "(", "f", ")", ")", "for", "f", "in", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "\"dstc8-schema-guided-dialogue/dev/\"", ")", ")", "if", "\"dialogues\"", "in", "f", "]", "\n", "onlyfiles_tst", "=", "[", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "'dstc8-schema-guided-dialogue/test/{}'", ".", "format", "(", "f", ")", ")", "for", "f", "in", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "args", "[", "\"data_path\"", "]", ",", "\"dstc8-schema-guided-dialogue/test/\"", ")", ")", "if", "\"dialogues\"", "in", "f", "]", "\n", "\n", "_example_type", "=", "\"dial\"", "if", "\"dial\"", "in", "example_type", "else", "example_type", "\n", "pair_trn", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "args", ",", "onlyfiles_trn", ",", "max_line", ",", "ds_name", ")", "\n", "pair_dev", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "args", ",", "onlyfiles_dev", ",", "max_line", ",", "ds_name", ")", "\n", "pair_tst", "=", "globals", "(", ")", "[", "\"read_langs_{}\"", ".", "format", "(", "_example_type", ")", "]", "(", "args", ",", "onlyfiles_tst", ",", "max_line", ",", "ds_name", ")", "\n", "\n", "print", "(", "\"Read {} pairs train from {}\"", ".", "format", "(", "len", "(", "pair_trn", ")", ",", "ds_name", ")", ")", "\n", "print", "(", "\"Read {} pairs valid from {}\"", ".", "format", "(", "len", "(", "pair_dev", ")", ",", "ds_name", ")", ")", "\n", "print", "(", "\"Read {} pairs test  from {}\"", ".", "format", "(", "len", "(", "pair_tst", ")", ",", "ds_name", ")", ")", "\n", "\n", "meta_data", "=", "{", "\"num_labels\"", ":", "0", "}", "\n", "\n", "return", "pair_trn", ",", "pair_dev", ",", "pair_tst", ",", "meta_data", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dm.Dataset_dm.__init__": [[8, 31], ["len", "dataloader_dm.Dataset_dm.unified_meta[].items"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_info", ",", "tokenizer", ",", "args", ",", "unified_meta", ",", "mode", ",", "max_length", "=", "512", ")", ":", "\n", "        ", "\"\"\"Reads source and target sequences from txt files.\"\"\"", "\n", "self", ".", "data", "=", "data_info", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "num_total_seqs", "=", "len", "(", "data_info", "[", "\"ID\"", "]", ")", "\n", "self", ".", "usr_token", "=", "args", "[", "\"usr_token\"", "]", "\n", "self", ".", "sys_token", "=", "args", "[", "\"sys_token\"", "]", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "unified_meta", "=", "unified_meta", "\n", "\n", "self", ".", "reverse_sys_act_map", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "unified_meta", "[", "\"sysact\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "reverse_sys_act_map", "[", "v", "]", "=", "k", "\n", "\n", "", "if", "\"bert\"", "in", "self", ".", "args", "[", "\"model_type\"", "]", "or", "\"electra\"", "in", "self", ".", "args", "[", "\"model_type\"", "]", ":", "\n", "            ", "self", ".", "start_token", "=", "self", ".", "tokenizer", ".", "cls_token", "\n", "self", ".", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", "\n", "", "else", ":", "\n", "            ", "self", ".", "start_token", "=", "self", ".", "tokenizer", ".", "bos_token", "\n", "self", ".", "sep_token", "=", "self", ".", "tokenizer", ".", "eos_token", "\n", "\n", "", "self", ".", "context_plain", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dm.Dataset_dm.__getitem__": [[32, 71], ["dataloader_dm.Dataset_dm.get_concat_context", "dataloader_dm.Dataset_dm.preprocess", "dataloader_dm.Dataset_dm.preprocess", "dataloader_dm.Dataset_dm.context_plain.get", "dataloader_dm.Dataset_dm.concat_dh_sys_usr", "len", "print"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_usdl.Dataset_usdl.get_concat_context", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.preprocess", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.preprocess", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_usdl.Dataset_usdl.concat_dh_sys_usr"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Returns one data pair (source and target).\"\"\"", "\n", "\n", "if", "self", ".", "args", "[", "\"example_type\"", "]", "==", "\"turn\"", ":", "\n", "            ", "dialog_history_str", "=", "self", ".", "get_concat_context", "(", "self", ".", "data", "[", "\"dialog_history\"", "]", "[", "index", "]", ")", "\n", "\n", "if", "not", "self", ".", "context_plain", ".", "get", "(", "index", ")", ":", "\n", "                ", "context_plain", "=", "self", ".", "concat_dh_sys_usr", "(", "dialog_history_str", ",", "\n", "self", ".", "data", "[", "\"turn_sys\"", "]", "[", "index", "]", ",", "\n", "self", ".", "data", "[", "\"turn_usr\"", "]", "[", "index", "]", ")", "\n", "self", ".", "context_plain", "[", "index", "]", "=", "context_plain", "\n", "", "else", ":", "\n", "                ", "context_plain", "=", "self", ".", "context_plain", "[", "index", "]", "\n", "\n", "", "context", "=", "self", ".", "preprocess", "(", "context_plain", ")", "\n", "act_plain", "=", "self", ".", "data", "[", "\"sys_act\"", "]", "[", "index", "]", "\n", "\n", "turn_sys_plain", "=", "\"{} {}\"", ".", "format", "(", "self", ".", "sys_token", ",", "self", ".", "data", "[", "\"turn_sys\"", "]", "[", "index", "]", ")", "\n", "turn_sys", "=", "self", ".", "preprocess", "(", "turn_sys_plain", ")", "\n", "\n", "act_one_hot", "=", "[", "0", "]", "*", "len", "(", "self", ".", "unified_meta", "[", "\"sysact\"", "]", ")", "\n", "for", "act", "in", "act_plain", ":", "\n", "                ", "act_one_hot", "[", "self", ".", "unified_meta", "[", "\"sysact\"", "]", "[", "act", "]", "]", "=", "1", "\n", "\n", "", "", "elif", "self", ".", "args", "[", "\"example_type\"", "]", "==", "\"dial\"", ":", "\n", "#TODO", "\n", "            ", "print", "(", "\"Not Implemented dial for nlu yet...\"", ")", "\n", "\n", "", "item_info", "=", "{", "\n", "\"index\"", ":", "index", ",", "# return data index to update pesudo labels", "\n", "\"ID\"", ":", "self", ".", "data", "[", "\"ID\"", "]", "[", "index", "]", ",", "\n", "\"turn_id\"", ":", "self", ".", "data", "[", "\"turn_id\"", "]", "[", "index", "]", ",", "\n", "\"context\"", ":", "context", ",", "\n", "\"context_plain\"", ":", "context_plain", ",", "\n", "\"sysact\"", ":", "act_one_hot", ",", "\n", "\"sysact_plain\"", ":", "act_plain", ",", "\n", "\"turn_sys\"", ":", "turn_sys", "}", "\n", "\n", "return", "item_info", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dm.Dataset_dm.__len__": [[72, 74], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_total_seqs", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dm.Dataset_dm.preprocess": [[75, 80], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "dataloader_dm.Dataset_dm.tokenizer.tokenize", "dataloader_dm.Dataset_dm.tokenizer.convert_tokens_to_ids", "dataloader_dm.Dataset_dm.tokenizer.tokenize"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"Converts words to ids.\"\"\"", "\n", "tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "self", ".", "start_token", ")", "+", "self", ".", "tokenizer", ".", "tokenize", "(", "sequence", ")", "[", "-", "self", ".", "max_length", "+", "1", ":", "]", "\n", "story", "=", "torch", ".", "Tensor", "(", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", ")", "\n", "return", "story", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dm.Dataset_dm.set_pesudo_label": [[81, 93], ["zip", "[].tolist", "pred_multi_text_label.append", "numpy.nonzero"], "methods", ["None"], ["", "def", "set_pesudo_label", "(", "self", ",", "indexes", ",", "labels", ")", ":", "\n", "        ", "'''set labels to indexes'''", "\n", "for", "ind", ",", "label", "in", "zip", "(", "indexes", ",", "labels", ")", ":", "\n", "# this 'label' is a binary vec for multi-label", "\n", "            ", "pred_multi_text_label", "=", "[", "]", "\n", "for", "t", "in", "np", ".", "nonzero", "(", "label", ")", "[", "0", "]", ".", "tolist", "(", ")", ":", "\n", "                ", "pred_multi_text_label", ".", "append", "(", "self", ".", "reverse_sys_act_map", "[", "t", "]", ")", "\n", "\n", "# print (self.data[\"sys_act\"][ind])", "\n", "# print (pred_multi_text_label)", "\n", "\n", "", "self", ".", "data", "[", "\"sys_act\"", "]", "[", "ind", "]", "=", "pred_multi_text_label", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dm.Dataset_dm.concat_dh_sys_usr": [[94, 96], ["None"], "methods", ["None"], ["", "", "def", "concat_dh_sys_usr", "(", "self", ",", "dialog_history", ",", "sys", ",", "usr", ")", ":", "\n", "        ", "return", "dialog_history", "+", "\" {} \"", ".", "format", "(", "self", ".", "sys_token", ")", "+", "\" {} \"", ".", "format", "(", "self", ".", "sep_token", ")", "+", "sys", "+", "\" {} \"", ".", "format", "(", "self", ".", "usr_token", ")", "+", "usr", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dm.Dataset_dm.get_concat_context": [[97, 106], ["enumerate", "dialog_history_str.strip.strip.strip"], "methods", ["None"], ["", "def", "get_concat_context", "(", "self", ",", "dialog_history", ")", ":", "\n", "        ", "dialog_history_str", "=", "\"\"", "\n", "for", "ui", ",", "uttr", "in", "enumerate", "(", "dialog_history", ")", ":", "\n", "            ", "if", "ui", "%", "2", "==", "0", ":", "\n", "                ", "dialog_history_str", "+=", "\"{} {} \"", ".", "format", "(", "self", ".", "sys_token", ",", "uttr", ")", "\n", "", "else", ":", "\n", "                ", "dialog_history_str", "+=", "\"{} {} \"", ".", "format", "(", "self", ".", "usr_token", ",", "uttr", ")", "\n", "", "", "dialog_history_str", "=", "dialog_history_str", ".", "strip", "(", ")", "\n", "return", "dialog_history_str", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dm.Dataset_dm.reset_dm_context": [[107, 109], ["None"], "methods", ["None"], ["", "def", "reset_dm_context", "(", "self", ",", "index", ",", "new_sent", ")", ":", "\n", "        ", "self", ".", "context_plain", "[", "index", "]", "=", "new_sent", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dm.collate_fn_dm_turn": [[111, 130], ["torch.sort", "data[].keys", "utils_function.merge", "utils_function.merge", "torch.tensor().float", "torch.tensor().float", "utils_function.to_cuda", "utils_function.to_cuda", "utils_function.to_cuda", "torch.tensor", "torch.tensor", "len"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda"], ["", "", "def", "collate_fn_dm_turn", "(", "data", ")", ":", "\n", "# sort a list by sequence length (descending order) to use pack_padded_sequence", "\n", "    ", "data", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "'context'", "]", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "item_info", "=", "{", "}", "\n", "for", "key", "in", "data", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "        ", "item_info", "[", "key", "]", "=", "[", "d", "[", "key", "]", "for", "d", "in", "data", "]", "\n", "\n", "# merge sequences", "\n", "", "src_seqs", ",", "src_lengths", "=", "merge", "(", "item_info", "[", "'context'", "]", ")", "\n", "turn_sys", ",", "_", "=", "merge", "(", "item_info", "[", "\"turn_sys\"", "]", ")", "\n", "sysact", "=", "torch", ".", "tensor", "(", "item_info", "[", "\"sysact\"", "]", ")", ".", "float", "(", ")", "\n", "\n", "item_info", "[", "\"context\"", "]", "=", "to_cuda", "(", "src_seqs", ")", "\n", "item_info", "[", "\"context_len\"", "]", "=", "src_lengths", "\n", "item_info", "[", "\"sysact\"", "]", "=", "to_cuda", "(", "sysact", ")", "\n", "item_info", "[", "\"turn_sys\"", "]", "=", "to_cuda", "(", "turn_sys", ")", "\n", "\n", "return", "item_info", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_dm.collate_fn_nlu_dial": [[132, 135], ["None"], "function", ["None"], ["", "def", "collate_fn_nlu_dial", "(", "data", ")", ":", "\n", "# TODO", "\n", "    ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_usdl.Dataset_usdl.__init__": [[7, 22], ["len", "dataloader_usdl.Dataset_usdl.tokenizer.convert_tokens_to_ids", "dataloader_usdl.Dataset_usdl.tokenizer.convert_tokens_to_ids"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_info", ",", "tokenizer", ",", "args", ",", "unified_meta", ",", "mode", ",", "max_length", "=", "512", ")", ":", "\n", "        ", "\"\"\"Reads source and target sequences from txt files.\"\"\"", "\n", "self", ".", "data", "=", "data_info", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "num_total_seqs", "=", "len", "(", "data_info", "[", "\"ID\"", "]", ")", "\n", "self", ".", "usr_token", "=", "args", "[", "\"usr_token\"", "]", "\n", "self", ".", "sys_token", "=", "args", "[", "\"sys_token\"", "]", "\n", "self", ".", "usr_token_id", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "args", "[", "\"usr_token\"", "]", ")", "\n", "self", ".", "sys_token_id", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "args", "[", "\"sys_token\"", "]", ")", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "unified_meta", "=", "unified_meta", "\n", "self", ".", "start_token", "=", "self", ".", "tokenizer", ".", "cls_token", "if", "\"bert\"", "in", "self", ".", "args", "[", "\"model_type\"", "]", "else", "self", ".", "tokenizer", ".", "bos_token", "\n", "self", ".", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", "if", "\"bert\"", "in", "self", ".", "args", "[", "\"model_type\"", "]", "else", "self", ".", "tokenizer", ".", "eos_token", "\n", "self", ".", "mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_usdl.Dataset_usdl.__getitem__": [[23, 45], ["dataloader_usdl.Dataset_usdl.get_concat_context", "dataloader_usdl.Dataset_usdl.concat_dh_sys_usr", "dataloader_usdl.Dataset_usdl.preprocess", "dataloader_usdl.Dataset_usdl.preprocess_slot"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_usdl.Dataset_usdl.get_concat_context", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_usdl.Dataset_usdl.concat_dh_sys_usr", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.preprocess", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_usdl.Dataset_usdl.preprocess_slot"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Returns one data pair (source and target).\"\"\"", "\n", "item_info", "=", "{", "}", "\n", "\n", "if", "self", ".", "args", "[", "\"example_type\"", "]", "==", "\"turn\"", ":", "\n", "            ", "dialog_history_str", "=", "self", ".", "get_concat_context", "(", "self", ".", "data", "[", "\"dialog_history\"", "]", "[", "index", "]", ")", "\n", "context_plain", "=", "self", ".", "concat_dh_sys_usr", "(", "dialog_history_str", ",", "\n", "self", ".", "data", "[", "\"turn_sys\"", "]", "[", "index", "]", ",", "\n", "self", ".", "data", "[", "\"turn_usr\"", "]", "[", "index", "]", ")", "\n", "\n", "context", "=", "self", ".", "preprocess", "(", "context_plain", ")", "\n", "\n", "", "elif", "self", ".", "args", "[", "\"example_type\"", "]", "==", "\"dial\"", ":", "\n", "            ", "context_plain", "=", "self", ".", "data", "[", "\"dialog_history\"", "]", "[", "index", "]", "\n", "context", "=", "self", ".", "preprocess_slot", "(", "context_plain", ")", "\n", "\n", "", "item_info", "[", "\"ID\"", "]", "=", "self", ".", "data", "[", "\"ID\"", "]", "[", "index", "]", "\n", "item_info", "[", "\"turn_id\"", "]", "=", "self", ".", "data", "[", "\"turn_id\"", "]", "[", "index", "]", "\n", "item_info", "[", "\"context\"", "]", "=", "context", "\n", "item_info", "[", "\"context_plain\"", "]", "=", "context_plain", "\n", "\n", "return", "item_info", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_usdl.Dataset_usdl.__len__": [[46, 48], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_total_seqs", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_usdl.Dataset_usdl.concat_dh_sys_usr": [[49, 51], ["None"], "methods", ["None"], ["", "def", "concat_dh_sys_usr", "(", "self", ",", "dialog_history", ",", "sys", ",", "usr", ")", ":", "\n", "        ", "return", "dialog_history", "+", "\" {} \"", ".", "format", "(", "self", ".", "sys_token", ")", "+", "sys", "+", "\" {} \"", ".", "format", "(", "self", ".", "usr_token", ")", "+", "usr", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_usdl.Dataset_usdl.preprocess": [[52, 57], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "dataloader_usdl.Dataset_usdl.tokenizer.tokenize", "dataloader_usdl.Dataset_usdl.tokenizer.convert_tokens_to_ids", "dataloader_usdl.Dataset_usdl.tokenizer.tokenize"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"Converts words to ids.\"\"\"", "\n", "tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "self", ".", "start_token", ")", "+", "self", ".", "tokenizer", ".", "tokenize", "(", "sequence", ")", "[", "-", "self", ".", "max_length", "+", "1", ":", "]", "\n", "story", "=", "torch", ".", "Tensor", "(", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", ")", "\n", "return", "story", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_usdl.Dataset_usdl.preprocess_slot": [[58, 66], ["list", "story.append", "dataloader_usdl.Dataset_usdl.tokenizer.convert_tokens_to_ids", "dataloader_usdl.Dataset_usdl.tokenizer.tokenize"], "methods", ["None"], ["", "def", "preprocess_slot", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"Converts words to ids.\"\"\"", "\n", "story", "=", "[", "]", "\n", "for", "value", "in", "sequence", ":", "\n", "#v = list(self.tokenizer.encode(value))# + self.tokenizer.encode(\"[SEP]\"))", "\n", "            ", "v", "=", "list", "(", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "self", ".", "tokenizer", ".", "tokenize", "(", "value", ")", ")", ")", "\n", "story", ".", "append", "(", "v", ")", "\n", "", "return", "story", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_usdl.Dataset_usdl.get_concat_context": [[67, 77], ["enumerate", "dialog_history_str.strip.strip.strip"], "methods", ["None"], ["", "def", "get_concat_context", "(", "self", ",", "dialog_history", ")", ":", "\n", "        ", "candidate_sys_responses", "=", "[", "]", "\n", "dialog_history_str", "=", "\"\"", "\n", "for", "ui", ",", "uttr", "in", "enumerate", "(", "dialog_history", ")", ":", "\n", "            ", "if", "ui", "%", "2", "==", "0", ":", "\n", "                ", "dialog_history_str", "+=", "\"{} {} \"", ".", "format", "(", "self", ".", "sys_token", ",", "uttr", ")", "\n", "", "else", ":", "\n", "                ", "dialog_history_str", "+=", "\"{} {} \"", ".", "format", "(", "self", ".", "usr_token", ",", "uttr", ")", "\n", "", "", "dialog_history_str", "=", "dialog_history_str", ".", "strip", "(", ")", "\n", "return", "dialog_history_str", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_usdl.collate_fn_usdl_turn": [[79, 94], ["torch.sort", "data[].keys", "utils_function.merge", "utils_function.to_cuda", "len"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda"], ["", "", "def", "collate_fn_usdl_turn", "(", "data", ")", ":", "\n", "# sort a list by sequence length (descending order) to use pack_padded_sequence", "\n", "    ", "data", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "'context'", "]", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "item_info", "=", "{", "}", "\n", "for", "key", "in", "data", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "        ", "item_info", "[", "key", "]", "=", "[", "d", "[", "key", "]", "for", "d", "in", "data", "]", "\n", "\n", "# merge sequences", "\n", "", "src_seqs", ",", "src_lengths", "=", "merge", "(", "item_info", "[", "'context'", "]", ")", "\n", "\n", "item_info", "[", "\"context\"", "]", "=", "to_cuda", "(", "src_seqs", ")", "\n", "item_info", "[", "\"context_len\"", "]", "=", "src_lengths", "\n", "\n", "return", "item_info", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_usdl.collate_fn_usdl_dial": [[95, 110], ["torch.sort", "data[].keys", "utils_function.merge_sent_and_word", "utils_function.to_cuda", "len"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge_sent_and_word", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda"], ["", "def", "collate_fn_usdl_dial", "(", "data", ")", ":", "\n", "# sort a list by sequence length (descending order) to use pack_padded_sequence", "\n", "    ", "data", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "'context'", "]", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "item_info", "=", "{", "}", "\n", "for", "key", "in", "data", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "        ", "item_info", "[", "key", "]", "=", "[", "d", "[", "key", "]", "for", "d", "in", "data", "]", "\n", "\n", "# merge sequences", "\n", "", "src_seqs", ",", "src_lengths", "=", "merge_sent_and_word", "(", "item_info", "[", "'context'", "]", ")", "\n", "\n", "item_info", "[", "\"context\"", "]", "=", "to_cuda", "(", "src_seqs", ")", "\n", "item_info", "[", "\"context_len\"", "]", "=", "src_lengths", "\n", "\n", "return", "item_info", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_usdl.collate_fn_usdl_dial_flat": [[111, 131], ["torch.sort", "data[].keys", "utils_function.merge", "utils_function.merge_sent_and_word", "utils_function.merge", "utils_function.to_cuda", "utils_function.to_cuda", "utils_function.to_cuda", "len"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge_sent_and_word", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda"], ["", "def", "collate_fn_usdl_dial_flat", "(", "data", ")", ":", "\n", "# sort a list by sequence length (descending order) to use pack_padded_sequence", "\n", "    ", "data", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "'context_flat'", "]", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "item_info", "=", "{", "}", "\n", "for", "key", "in", "data", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "        ", "item_info", "[", "key", "]", "=", "[", "d", "[", "key", "]", "for", "d", "in", "data", "]", "\n", "\n", "# merge sequences", "\n", "", "src_flat_seqs", ",", "src_flat_lengths", "=", "merge", "(", "item_info", "[", "'context_flat'", "]", ")", "\n", "src_seqs", ",", "src_lengths", "=", "merge_sent_and_word", "(", "item_info", "[", "'context'", "]", ")", "\n", "src_pos_seqs", ",", "src_pos_lengths", "=", "merge", "(", "item_info", "[", "\"sys_usr_id_positions\"", "]", ")", "\n", "\n", "item_info", "[", "\"context\"", "]", "=", "to_cuda", "(", "src_seqs", ")", "\n", "item_info", "[", "\"context_len\"", "]", "=", "src_lengths", "\n", "item_info", "[", "\"context_flat\"", "]", "=", "to_cuda", "(", "src_flat_seqs", ")", "\n", "item_info", "[", "\"context_flat_len\"", "]", "=", "src_flat_lengths", "\n", "item_info", "[", "\"sys_usr_id_positions\"", "]", "=", "to_cuda", "(", "src_pos_seqs", ")", "\n", "\n", "return", "item_info", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.__init__": [[8, 31], ["len", "dataloader_nlu.Dataset_nlu.unified_meta[].items"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_info", ",", "tokenizer", ",", "args", ",", "unified_meta", ",", "mode", ",", "max_length", "=", "512", ")", ":", "\n", "        ", "\"\"\"Reads source and target sequences from txt files.\"\"\"", "\n", "self", ".", "data", "=", "data_info", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "num_total_seqs", "=", "len", "(", "data_info", "[", "\"ID\"", "]", ")", "\n", "self", ".", "usr_token", "=", "args", "[", "\"usr_token\"", "]", "\n", "self", ".", "sys_token", "=", "args", "[", "\"sys_token\"", "]", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "unified_meta", "=", "unified_meta", "\n", "# create a mapping from intent-id to intent-plain, this is a helper variable for pesudo labeling", "\n", "self", ".", "reverse_intent_map", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "unified_meta", "[", "\"intent\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "reverse_intent_map", "[", "v", "]", "=", "k", "\n", "\n", "", "if", "\"bert\"", "in", "self", ".", "args", "[", "\"model_type\"", "]", "or", "\"electra\"", "in", "self", ".", "args", "[", "\"model_type\"", "]", ":", "\n", "            ", "self", ".", "start_token", "=", "self", ".", "tokenizer", ".", "cls_token", "\n", "self", ".", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", "\n", "", "else", ":", "\n", "            ", "self", ".", "start_token", "=", "self", ".", "tokenizer", ".", "bos_token", "\n", "self", ".", "sep_token", "=", "self", ".", "tokenizer", ".", "eos_token", "\n", "\n", "", "self", ".", "context_plain", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.__getitem__": [[32, 90], ["dataloader_nlu.Dataset_nlu.preprocess", "dataloader_nlu.Dataset_nlu.preprocess", "dataloader_nlu.Dataset_nlu.context_plain.get", "print", "len"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.preprocess", "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.preprocess"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"Returns one data pair (source and target).\"\"\"", "\n", "\n", "if", "self", ".", "args", "[", "\"example_type\"", "]", "==", "\"turn\"", ":", "\n", "\n", "            ", "if", "not", "self", ".", "context_plain", ".", "get", "(", "index", ")", ":", "\n", "                ", "context_plain", "=", "\"{} {} {} {} {}\"", ".", "format", "(", "self", ".", "start_token", ",", "\n", "self", ".", "sys_token", ",", "\n", "self", ".", "data", "[", "\"turn_sys\"", "]", "[", "index", "]", ",", "\n", "self", ".", "usr_token", ",", "\n", "self", ".", "data", "[", "\"turn_usr\"", "]", "[", "index", "]", ")", "\n", "self", ".", "context_plain", "[", "index", "]", "=", "context_plain", "\n", "", "else", ":", "\n", "                ", "context_plain", "=", "self", ".", "context_plain", "[", "index", "]", "\n", "\n", "", "context", "=", "self", ".", "preprocess", "(", "context_plain", ")", "\n", "intent_plain", "=", "self", ".", "data", "[", "\"intent\"", "]", "[", "index", "]", "\n", "\n", "turn_sys_plain", "=", "\"{} {}\"", ".", "format", "(", "self", ".", "sys_token", ",", "self", ".", "data", "[", "\"turn_sys\"", "]", "[", "index", "]", ")", "\n", "turn_sys", "=", "self", ".", "preprocess", "(", "turn_sys_plain", ")", "\n", "\n", "try", ":", "\n", "                ", "intent_idx", "=", "self", ".", "unified_meta", "[", "\"intent\"", "]", "[", "intent_plain", "]", "\n", "", "except", ":", "\n", "                ", "intent_idx", "=", "-", "100", "\n", "\n", "", "try", ":", "\n", "                ", "domain_idx", "=", "self", ".", "unified_meta", "[", "\"turn_domain\"", "]", "[", "self", ".", "data", "[", "\"turn_domain\"", "]", "[", "index", "]", "]", "\n", "", "except", ":", "\n", "                ", "domain_idx", "=", "-", "100", "\n", "\n", "", "try", ":", "\n", "                ", "turn_slot_one_hot", "=", "[", "0", "]", "*", "len", "(", "self", ".", "unified_meta", "[", "\"turn_slot\"", "]", ")", "\n", "for", "ts", "in", "self", ".", "data", "[", "\"turn_slot\"", "]", "[", "index", "]", ":", "\n", "                    ", "turn_slot_one_hot", "[", "self", ".", "unified_meta", "[", "\"turn_slot\"", "]", "[", "ts", "]", "]", "=", "1", "\n", "", "", "except", ":", "\n", "                ", "turn_slot_one_hot", "=", "-", "100", "\n", "\n", "", "", "elif", "self", ".", "args", "[", "\"example_type\"", "]", "==", "\"dial\"", ":", "\n", "            ", "print", "(", "\"Not Implemented dial for nlu yet...\"", ")", "\n", "\n", "", "item_info", "=", "{", "\n", "\"index\"", ":", "index", ",", "# return data index to update pesudo labels", "\n", "\"ID\"", ":", "self", ".", "data", "[", "\"ID\"", "]", "[", "index", "]", ",", "\n", "\"turn_id\"", ":", "self", ".", "data", "[", "\"turn_id\"", "]", "[", "index", "]", ",", "\n", "\"turn_domain\"", ":", "self", ".", "data", "[", "\"turn_domain\"", "]", "[", "index", "]", ",", "\n", "\"context\"", ":", "context", ",", "\n", "\"context_plain\"", ":", "context_plain", ",", "\n", "\"intent\"", ":", "intent_idx", ",", "\n", "\"intent_plain\"", ":", "intent_plain", ",", "\n", "\"domain_plain\"", ":", "self", ".", "data", "[", "\"turn_domain\"", "]", "[", "index", "]", ",", "\n", "\"turn_domain\"", ":", "domain_idx", ",", "\n", "\"turn_sys\"", ":", "turn_sys", ",", "\n", "\"turn_slot\"", ":", "turn_slot_one_hot", ",", "\n", "\"turn_sys_plain\"", ":", "turn_sys_plain", "\n", "}", "\n", "\n", "return", "item_info", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.__len__": [[91, 93], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_total_seqs", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.preprocess": [[94, 99], ["torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "dataloader_nlu.Dataset_nlu.tokenizer.tokenize", "dataloader_nlu.Dataset_nlu.tokenizer.convert_tokens_to_ids", "dataloader_nlu.Dataset_nlu.tokenizer.tokenize"], "methods", ["None"], ["", "def", "preprocess", "(", "self", ",", "sequence", ")", ":", "\n", "        ", "\"\"\"Converts words to ids.\"\"\"", "\n", "tokens", "=", "self", ".", "tokenizer", ".", "tokenize", "(", "self", ".", "start_token", ")", "+", "self", ".", "tokenizer", ".", "tokenize", "(", "sequence", ")", "[", "-", "self", ".", "max_length", "+", "1", ":", "]", "\n", "story", "=", "torch", ".", "Tensor", "(", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", ")", "\n", "return", "story", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.set_pesudo_label": [[100, 104], ["zip"], "methods", ["None"], ["", "def", "set_pesudo_label", "(", "self", ",", "indexes", ",", "labels", ")", ":", "\n", "        ", "'''set labels to indexes'''", "\n", "for", "ind", ",", "label", "in", "zip", "(", "indexes", ",", "labels", ")", ":", "\n", "            ", "self", ".", "data", "[", "\"intent\"", "]", "[", "ind", "]", "=", "self", ".", "reverse_intent_map", "[", "label", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.Dataset_nlu.reset_nlu_context": [[105, 107], ["None"], "methods", ["None"], ["", "", "def", "reset_nlu_context", "(", "self", ",", "index", ",", "new_sent", ")", ":", "\n", "        ", "self", ".", "context_plain", "[", "index", "]", "=", "new_sent", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.collate_fn_nlu_turn": [[108, 131], ["torch.sort", "data[].keys", "utils_function.merge", "utils_function.merge", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor().float", "torch.tensor().float", "utils_function.to_cuda", "utils_function.to_cuda", "utils_function.to_cuda", "utils_function.to_cuda", "utils_function.to_cuda", "torch.tensor", "torch.tensor", "len"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.merge", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda", "home.repos.pwc.inspect_result.mifei_st-tod.utils.utils_function.to_cuda"], ["", "", "def", "collate_fn_nlu_turn", "(", "data", ")", ":", "\n", "# sort a list by sequence length (descending order) to use pack_padded_sequence", "\n", "    ", "data", ".", "sort", "(", "key", "=", "lambda", "x", ":", "len", "(", "x", "[", "'context'", "]", ")", ",", "reverse", "=", "True", ")", "\n", "\n", "item_info", "=", "{", "}", "\n", "for", "key", "in", "data", "[", "0", "]", ".", "keys", "(", ")", ":", "\n", "        ", "item_info", "[", "key", "]", "=", "[", "d", "[", "key", "]", "for", "d", "in", "data", "]", "\n", "\n", "# merge sequences", "\n", "", "src_seqs", ",", "src_lengths", "=", "merge", "(", "item_info", "[", "'context'", "]", ")", "\n", "turn_sys", ",", "_", "=", "merge", "(", "item_info", "[", "\"turn_sys\"", "]", ")", "\n", "intent", "=", "torch", ".", "tensor", "(", "item_info", "[", "\"intent\"", "]", ")", "\n", "turn_domain", "=", "torch", ".", "tensor", "(", "item_info", "[", "\"turn_domain\"", "]", ")", "\n", "turn_slot", "=", "torch", ".", "tensor", "(", "item_info", "[", "\"turn_slot\"", "]", ")", ".", "float", "(", ")", "\n", "\n", "item_info", "[", "\"context\"", "]", "=", "to_cuda", "(", "src_seqs", ")", "\n", "item_info", "[", "\"context_len\"", "]", "=", "src_lengths", "\n", "item_info", "[", "\"intent\"", "]", "=", "to_cuda", "(", "intent", ")", "\n", "item_info", "[", "\"turn_domain\"", "]", "=", "to_cuda", "(", "turn_domain", ")", "\n", "item_info", "[", "\"turn_sys\"", "]", "=", "to_cuda", "(", "turn_sys", ")", "\n", "item_info", "[", "\"turn_slot\"", "]", "=", "to_cuda", "(", "turn_slot", ")", "\n", "\n", "return", "item_info", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.utils.dataloader_nlu.collate_fn_nlu_dial": [[133, 136], ["None"], "function", ["None"], ["", "def", "collate_fn_nlu_dial", "(", "data", ")", ":", "\n", "# TODO", "\n", "    ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.loss_function.masked_cross_entropy.sequence_mask": [[8, 20], ["sequence_length.size", "torch.arange().long", "torch.arange().long", "torch.arange().long.unsqueeze().expand", "torch.autograd.Variable", "sequence_length.unsqueeze().expand_as", "sequence_length.data.max", "seq_range_expand.cuda.cuda", "torch.arange", "torch.arange", "torch.arange().long.unsqueeze", "sequence_length.unsqueeze"], "function", ["None"], ["def", "sequence_mask", "(", "sequence_length", ",", "max_len", "=", "None", ")", ":", "\n", "    ", "if", "max_len", "is", "None", ":", "\n", "        ", "max_len", "=", "sequence_length", ".", "data", ".", "max", "(", ")", "\n", "", "batch_size", "=", "sequence_length", ".", "size", "(", "0", ")", "\n", "seq_range", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ")", ".", "long", "(", ")", "\n", "seq_range_expand", "=", "seq_range", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_size", ",", "max_len", ")", "\n", "seq_range_expand", "=", "Variable", "(", "seq_range_expand", ")", "\n", "if", "sequence_length", ".", "is_cuda", ":", "\n", "        ", "seq_range_expand", "=", "seq_range_expand", ".", "cuda", "(", ")", "\n", "", "seq_length_expand", "=", "(", "sequence_length", ".", "unsqueeze", "(", "1", ")", "\n", ".", "expand_as", "(", "seq_range_expand", ")", ")", "\n", "return", "seq_range_expand", "<", "seq_length_expand", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.loss_function.masked_cross_entropy.cross_entropy": [[21, 27], ["logits.size", "torch.nn.functional.log_softmax", "torch.gather", "torch.gather", "losses_flat.sum"], "function", ["None"], ["", "def", "cross_entropy", "(", "logits", ",", "target", ")", ":", "\n", "    ", "batch_size", "=", "logits", ".", "size", "(", "0", ")", "\n", "log_probs_flat", "=", "functional", ".", "log_softmax", "(", "logits", ")", "\n", "losses_flat", "=", "-", "torch", ".", "gather", "(", "log_probs_flat", ",", "dim", "=", "1", ",", "index", "=", "target", ")", "\n", "loss", "=", "losses_flat", ".", "sum", "(", ")", "/", "batch_size", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.loss_function.masked_cross_entropy.masked_cross_entropy": [[28, 63], ["logits.view", "torch.nn.functional.log_softmax", "target.view", "losses_flat.view", "masked_cross_entropy.sequence_mask", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "logits.size", "torch.gather", "torch.gather", "sequence_mask.float", "losses_flat.view.sum", "torch.autograd.Variable.float().sum", "torch.LongTensor", "torch.LongTensor", "target.size", "target.size", "torch.autograd.Variable", "torch.autograd.Variable.float", "torch.LongTensor", "torch.LongTensor"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.loss_function.masked_cross_entropy.sequence_mask"], ["", "def", "masked_cross_entropy", "(", "logits", ",", "target", ",", "length", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        logits: A Variable containing a FloatTensor of size\n            (batch, max_len, num_classes) which contains the\n            unnormalized probability for each class.\n        target: A Variable containing a LongTensor of size\n            (batch, max_len) which contains the index of the true\n            class for each corresponding step.\n        length: A Variable containing a LongTensor of size (batch,)\n            which contains the length of each data in a batch.\n\n    Returns:\n        loss: An average loss value masked by the length.\n    \"\"\"", "\n", "if", "USE_CUDA", ":", "\n", "        ", "length", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "length", ")", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "length", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "length", ")", ")", "\n", "\n", "# logits_flat: (batch * max_len, num_classes)", "\n", "", "logits_flat", "=", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "-", "1", ")", ")", "## -1 means infered from other dimentions", "\n", "# log_probs_flat: (batch * max_len, num_classes)", "\n", "log_probs_flat", "=", "functional", ".", "log_softmax", "(", "logits_flat", ",", "dim", "=", "1", ")", "\n", "# target_flat: (batch * max_len, 1)", "\n", "target_flat", "=", "target", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "# losses_flat: (batch * max_len, 1)", "\n", "losses_flat", "=", "-", "torch", ".", "gather", "(", "log_probs_flat", ",", "dim", "=", "1", ",", "index", "=", "target_flat", ")", "\n", "# losses: (batch, max_len)", "\n", "losses", "=", "losses_flat", ".", "view", "(", "*", "target", ".", "size", "(", ")", ")", "\n", "# mask: (batch, max_len)", "\n", "mask", "=", "sequence_mask", "(", "sequence_length", "=", "length", ",", "max_len", "=", "target", ".", "size", "(", "1", ")", ")", "\n", "losses", "=", "losses", "*", "mask", ".", "float", "(", ")", "\n", "loss", "=", "losses", ".", "sum", "(", ")", "/", "length", ".", "float", "(", ")", ".", "sum", "(", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.loss_function.masked_cross_entropy.masked_binary_cross_entropy": [[64, 81], ["torch.BCEWithLogitsLoss", "range", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "logits.size", "range", "torch.autograd.Variable.float().sum", "torch.LongTensor", "torch.LongTensor", "logits.size", "torch.autograd.Variable", "nn.BCEWithLogitsLoss.", "torch.autograd.Variable.float", "torch.LongTensor", "torch.LongTensor"], "function", ["None"], ["", "def", "masked_binary_cross_entropy", "(", "logits", ",", "target", ",", "length", ")", ":", "\n", "    ", "'''\n    logits: (batch, max_len, num_class)\n    target: (batch, max_len, num_class)\n    '''", "\n", "if", "USE_CUDA", ":", "\n", "        ", "length", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "length", ")", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "length", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "length", ")", ")", "\n", "", "bce_criterion", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "loss", "=", "0", "\n", "for", "bi", "in", "range", "(", "logits", ".", "size", "(", "0", ")", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "logits", ".", "size", "(", "1", ")", ")", ":", "\n", "            ", "if", "i", "<", "length", "[", "bi", "]", ":", "\n", "                ", "loss", "+=", "bce_criterion", "(", "logits", "[", "bi", "]", "[", "i", "]", ",", "target", "[", "bi", "]", "[", "i", "]", ")", "\n", "", "", "", "loss", "=", "loss", "/", "length", ".", "float", "(", ")", ".", "sum", "(", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.loss_function.masked_cross_entropy.masked_cross_entropy_": [[83, 104], ["logits.view", "target.view", "losses_flat.view", "masked_cross_entropy.sequence_mask", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "logits.size", "torch.log", "torch.log", "torch.gather", "torch.gather", "sequence_mask.float", "losses_flat.view.sum", "torch.autograd.Variable.float().sum", "torch.LongTensor", "torch.LongTensor", "target.size", "target.size", "torch.autograd.Variable", "torch.autograd.Variable.float", "torch.LongTensor", "torch.LongTensor"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.loss_function.masked_cross_entropy.sequence_mask"], ["", "def", "masked_cross_entropy_", "(", "logits", ",", "target", ",", "length", ",", "take_log", "=", "False", ")", ":", "\n", "    ", "if", "USE_CUDA", ":", "\n", "        ", "length", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "length", ")", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "length", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "length", ")", ")", "\n", "\n", "# logits_flat: (batch * max_len, num_classes)", "\n", "", "logits_flat", "=", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "-", "1", ")", ")", "## -1 means infered from other dimentions", "\n", "if", "take_log", ":", "\n", "        ", "logits_flat", "=", "torch", ".", "log", "(", "logits_flat", ")", "\n", "# target_flat: (batch * max_len, 1)", "\n", "", "target_flat", "=", "target", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "# losses_flat: (batch * max_len, 1)", "\n", "losses_flat", "=", "-", "torch", ".", "gather", "(", "logits_flat", ",", "dim", "=", "1", ",", "index", "=", "target_flat", ")", "\n", "# losses: (batch, max_len)", "\n", "losses", "=", "losses_flat", ".", "view", "(", "*", "target", ".", "size", "(", ")", ")", "\n", "# mask: (batch, max_len)", "\n", "mask", "=", "sequence_mask", "(", "sequence_length", "=", "length", ",", "max_len", "=", "target", ".", "size", "(", "1", ")", ")", "\n", "losses", "=", "losses", "*", "mask", ".", "float", "(", ")", "\n", "loss", "=", "losses", ".", "sum", "(", ")", "/", "length", ".", "float", "(", ")", ".", "sum", "(", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.loss_function.masked_cross_entropy.masked_coverage_loss": [[105, 116], ["masked_cross_entropy.sequence_mask", "torch.min", "torch.min", "mask.unsqueeze().expand_as.unsqueeze().expand_as", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "mask.unsqueeze().expand_as.float", "torch.min.sum", "torch.LongTensor", "torch.LongTensor", "mask.unsqueeze().expand_as.unsqueeze", "len", "torch.autograd.Variable", "torch.LongTensor", "torch.LongTensor"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.loss_function.masked_cross_entropy.sequence_mask"], ["", "def", "masked_coverage_loss", "(", "coverage", ",", "attention", ",", "length", ")", ":", "\n", "    ", "if", "USE_CUDA", ":", "\n", "        ", "length", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "length", ")", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "length", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "length", ")", ")", "\n", "", "mask", "=", "sequence_mask", "(", "sequence_length", "=", "length", ")", "\n", "min_", "=", "torch", ".", "min", "(", "coverage", ",", "attention", ")", "\n", "mask", "=", "mask", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "min_", ")", "\n", "min_", "=", "min_", "*", "mask", ".", "float", "(", ")", "\n", "loss", "=", "min_", ".", "sum", "(", ")", "/", "(", "len", "(", "length", ")", "*", "1.0", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.loss_function.masked_cross_entropy.masked_cross_entropy_for_slot": [[117, 135], ["logits.view", "target.view", "losses_flat.view", "logits.size", "torch.nn.functional.log_softmax", "torch.gather", "torch.gather", "mask.float", "losses_flat.view.sum", "target.size", "losses_flat.view.size", "losses_flat.view.size"], "function", ["None"], ["", "def", "masked_cross_entropy_for_slot", "(", "logits", ",", "target", ",", "mask", ",", "use_softmax", "=", "True", ")", ":", "\n", "# print(\"logits\", logits)", "\n", "# print(\"target\", target)", "\n", "    ", "logits_flat", "=", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "-", "1", ")", ")", "## -1 means infered from other dimentions", "\n", "# print(logits_flat.size())", "\n", "if", "use_softmax", ":", "\n", "        ", "log_probs_flat", "=", "functional", ".", "log_softmax", "(", "logits_flat", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "        ", "log_probs_flat", "=", "logits_flat", "#torch.log(logits_flat)", "\n", "# print(\"log_probs_flat\", log_probs_flat)", "\n", "", "target_flat", "=", "target", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "# print(\"target_flat\", target_flat)", "\n", "losses_flat", "=", "-", "torch", ".", "gather", "(", "log_probs_flat", ",", "dim", "=", "1", ",", "index", "=", "target_flat", ")", "\n", "losses", "=", "losses_flat", ".", "view", "(", "*", "target", ".", "size", "(", ")", ")", "# b * |s|", "\n", "losses", "=", "losses", "*", "mask", ".", "float", "(", ")", "\n", "loss", "=", "losses", ".", "sum", "(", ")", "/", "(", "losses", ".", "size", "(", "0", ")", "*", "losses", ".", "size", "(", "1", ")", ")", "\n", "# print(\"loss inside\", loss)", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.loss_function.masked_cross_entropy.masked_cross_entropy_for_value": [[136, 150], ["logits.view", "torch.log", "torch.log", "target.view", "losses_flat.view", "masked_cross_entropy.masking", "logits.size", "torch.gather", "torch.gather", "target.size"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.loss_function.masked_cross_entropy.masking"], ["", "def", "masked_cross_entropy_for_value", "(", "logits", ",", "target", ",", "mask", ")", ":", "\n", "# logits: b * |s| * m * |v|", "\n", "# target: b * |s| * m", "\n", "# mask:   b * |s|", "\n", "    ", "logits_flat", "=", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "-", "1", ")", ")", "## -1 means infered from other dimentions", "\n", "# print(logits_flat.size())", "\n", "log_probs_flat", "=", "torch", ".", "log", "(", "logits_flat", ")", "\n", "# print(\"log_probs_flat\", log_probs_flat)", "\n", "target_flat", "=", "target", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "# print(\"target_flat\", target_flat)", "\n", "losses_flat", "=", "-", "torch", ".", "gather", "(", "log_probs_flat", ",", "dim", "=", "1", ",", "index", "=", "target_flat", ")", "\n", "losses", "=", "losses_flat", ".", "view", "(", "*", "target", ".", "size", "(", ")", ")", "# b * |s| * m", "\n", "loss", "=", "masking", "(", "losses", ",", "mask", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.loss_function.masked_cross_entropy.masking": [[151, 169], ["mask.size", "losses.size", "range", "torch.stack", "torch.stack", "mask_.cuda.transpose", "mask.size", "torch.arange().long", "torch.arange().long", "torch.arange().long.unsqueeze().expand", "mask[].unsqueeze().expand_as", "mask_.cuda.append", "mask_.cuda.cuda", "mask_.cuda.float", "losses.sum", "mask_.cuda.sum().float", "seq_range_expand.cuda.cuda", "torch.arange", "torch.arange", "torch.arange().long.unsqueeze", "mask[].unsqueeze", "mask_.cuda.sum"], "function", ["None"], ["", "def", "masking", "(", "losses", ",", "mask", ")", ":", "\n", "    ", "mask_", "=", "[", "]", "\n", "batch_size", "=", "mask", ".", "size", "(", "0", ")", "\n", "max_len", "=", "losses", ".", "size", "(", "2", ")", "\n", "for", "si", "in", "range", "(", "mask", ".", "size", "(", "1", ")", ")", ":", "\n", "        ", "seq_range", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ")", ".", "long", "(", ")", "\n", "seq_range_expand", "=", "seq_range", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_size", ",", "max_len", ")", "\n", "if", "mask", "[", ":", ",", "si", "]", ".", "is_cuda", ":", "\n", "            ", "seq_range_expand", "=", "seq_range_expand", ".", "cuda", "(", ")", "\n", "", "seq_length_expand", "=", "mask", "[", ":", ",", "si", "]", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "seq_range_expand", ")", "\n", "mask_", ".", "append", "(", "(", "seq_range_expand", "<", "seq_length_expand", ")", ")", "\n", "", "mask_", "=", "torch", ".", "stack", "(", "mask_", ")", "\n", "mask_", "=", "mask_", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "losses", ".", "is_cuda", ":", "\n", "        ", "mask_", "=", "mask_", ".", "cuda", "(", ")", "\n", "", "losses", "=", "losses", "*", "mask_", ".", "float", "(", ")", "\n", "loss", "=", "losses", ".", "sum", "(", ")", "/", "(", "mask_", ".", "sum", "(", ")", ".", "float", "(", ")", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.Interpret.saliency_interpreter.SaliencyInterpreter.__init__": [[11, 24], ["torch.device", "model.to", "torch.cuda.is_available"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "tokenizer", ",", "\n", "show_progress", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "\n", "        ", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda'", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "self", ".", "model", "=", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "show_progress", "=", "show_progress", "\n", "self", ".", "kwargs", "=", "kwargs", "\n", "# to save outputs in saliency_interpret", "\n", "self", ".", "batch_output", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.Interpret.saliency_interpreter.SaliencyInterpreter._get_gradients": [[25, 48], ["saliency_interpreter.SaliencyInterpreter.model.named_parameters", "saliency_interpreter.SaliencyInterpreter._register_embedding_gradient_hooks", "saliency_interpreter.SaliencyInterpreter.model.zero_grad", "saliency_interpreter.SaliencyInterpreter.forward_step", "saliency_interpreter.SaliencyInterpreter.model.named_parameters", "hook.remove"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.Interpret.saliency_interpreter.SaliencyInterpreter._register_embedding_gradient_hooks", "home.repos.pwc.inspect_result.mifei_st-tod.Interpret.saliency_interpreter.SaliencyInterpreter.forward_step"], ["", "def", "_get_gradients", "(", "self", ",", "batch", ",", "use_truth", ")", ":", "\n", "# set requires_grad to true for all parameters, but save original values to", "\n", "# restore them later", "\n", "        ", "original_param_name_to_requires_grad_dict", "=", "{", "}", "\n", "for", "param_name", ",", "param", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "original_param_name_to_requires_grad_dict", "[", "param_name", "]", "=", "param", ".", "requires_grad", "\n", "param", ".", "requires_grad", "=", "True", "\n", "", "embedding_gradients", "=", "[", "]", "\n", "hooks", "=", "self", ".", "_register_embedding_gradient_hooks", "(", "embedding_gradients", ")", "\n", "\n", "self", ".", "model", ".", "zero_grad", "(", ")", "\n", "\n", "# feed data and calculate gradient", "\n", "self", ".", "forward_step", "(", "batch", ",", "use_truth", ")", "\n", "\n", "for", "hook", "in", "hooks", ":", "\n", "            ", "hook", ".", "remove", "(", ")", "\n", "\n", "# restore the original requires_grad values of the parameters", "\n", "", "for", "param_name", ",", "param", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "original_param_name_to_requires_grad_dict", "[", "param_name", "]", "\n", "\n", "", "return", "embedding_gradients", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.Interpret.saliency_interpreter.SaliencyInterpreter._register_embedding_gradient_hooks": [[49, 69], ["saliency_interpreter.SaliencyInterpreter.kwargs.get", "backward_hooks.append", "embedding_gradients.append", "embedding_layer.register_backward_hook", "saliency_interpreter.SaliencyInterpreter.model.__getattr__"], "methods", ["None"], ["", "def", "_register_embedding_gradient_hooks", "(", "self", ",", "embedding_gradients", ")", ":", "\n", "        ", "\"\"\"\n        Registers a backward hook on the\n        Used to save the gradients of the embeddings for use in get_gradients()\n        When there are multiple inputs (e.g., a passage and question), the hook\n        will be called multiple times. We append all the embeddings gradients\n        to a list.\n        \"\"\"", "\n", "\n", "def", "hook_layers", "(", "module", ",", "grad_in", ",", "grad_out", ")", ":", "\n", "            ", "embedding_gradients", ".", "append", "(", "grad_out", "[", "0", "]", ")", "\n", "\n", "", "backward_hooks", "=", "[", "]", "\n", "encoder", "=", "self", ".", "kwargs", ".", "get", "(", "\"encoder\"", ")", "\n", "if", "encoder", ":", "\n", "            ", "embedding_layer", "=", "self", ".", "model", ".", "__getattr__", "(", "encoder", ")", ".", "embeddings", "\n", "", "else", ":", "\n", "            ", "embedding_layer", "=", "self", ".", "model", ".", "utterance_encoder", ".", "embeddings", "\n", "", "backward_hooks", ".", "append", "(", "embedding_layer", ".", "register_backward_hook", "(", "hook_layers", ")", ")", "\n", "return", "backward_hooks", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.Interpret.saliency_interpreter.SaliencyInterpreter.forward_step": [[70, 73], ["saliency_interpreter.SaliencyInterpreter.model"], "methods", ["None"], ["", "def", "forward_step", "(", "self", ",", "batch", ",", "use_truth", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "model", "(", "data", "=", "batch", ",", "evaluate_gradient", "=", "True", ",", "use_truth", "=", "use_truth", ")", "\n", "self", ".", "batch_output", "=", "[", "batch", "[", "\"context\"", "]", ",", "outputs", "[", "'logits'", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.Interpret.saliency_interpreter.SaliencyInterpreter.update_output": [[74, 107], ["torch.nn.functional.softmax", "torch.max", "grads.sum", "torch.norm", "enumerate", "zip", "saliency_interpreter.SaliencyInterpreter.tokenizer.convert_ids_to_tokens", "dict", "example_label.item", "example_prob.item", "batch_output.append", "torch.abs", "example_grad.cpu().tolist", "len", "example_grad.cpu"], "methods", ["None"], ["", "def", "update_output", "(", "self", ")", ":", "\n", "\n", "        ", "input_ids", ",", "outputs", ",", "grads", "=", "self", ".", "batch_output", "\n", "\n", "probs", "=", "softmax", "(", "outputs", ",", "dim", "=", "-", "1", ")", "\n", "probs", ",", "labels", "=", "torch", ".", "max", "(", "probs", ",", "dim", "=", "-", "1", ")", "\n", "\n", "tokens", "=", "[", "\n", "self", ".", "tokenizer", ".", "convert_ids_to_tokens", "(", "input_ids_", ")", "\n", "for", "input_ids_", "in", "input_ids", "\n", "]", "\n", "\n", "embedding_grads", "=", "grads", ".", "sum", "(", "dim", "=", "2", ")", "\n", "# norm for each sequence", "\n", "norms", "=", "torch", ".", "norm", "(", "embedding_grads", ",", "dim", "=", "1", ",", "p", "=", "1", ")", "\n", "# normalizing", "\n", "for", "i", ",", "norm", "in", "enumerate", "(", "norms", ")", ":", "\n", "            ", "embedding_grads", "[", "i", "]", "=", "torch", ".", "abs", "(", "embedding_grads", "[", "i", "]", ")", "/", "norm", "\n", "\n", "", "batch_output", "=", "[", "]", "\n", "for", "example_tokens", ",", "example_prob", ",", "example_grad", ",", "example_label", "in", "zip", "(", "tokens", ",", "\n", "probs", ",", "\n", "embedding_grads", ",", "\n", "labels", ")", ":", "\n", "            ", "example_dict", "=", "dict", "(", ")", "\n", "# as we do it by batches we has a padding so we need to remove it", "\n", "example_tokens", "=", "[", "t", "for", "t", "in", "example_tokens", "if", "t", "!=", "'[PAD]'", "]", "\n", "example_dict", "[", "'tokens'", "]", "=", "example_tokens", "\n", "example_dict", "[", "'grad'", "]", "=", "example_grad", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "[", ":", "len", "(", "example_tokens", ")", "]", "\n", "example_dict", "[", "'label'", "]", "=", "example_label", ".", "item", "(", ")", "\n", "example_dict", "[", "'prob'", "]", "=", "example_prob", ".", "item", "(", ")", "\n", "batch_output", ".", "append", "(", "example_dict", ")", "\n", "", "return", "batch_output", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.Interpret.vanilla_gradient.VanillaGradient.__init__": [[13, 19], ["utils.Interpret.saliency_interpreter.SaliencyInterpreter.__init__"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.models.dual_encoder_ranking.dual_encoder_ranking.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "tokenizer", ",", "\n", "show_progress", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "tokenizer", ",", "show_progress", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.Interpret.vanilla_gradient.VanillaGradient.saliency_interpret": [[20, 29], ["vanilla_gradient.VanillaGradient._vanilla_grads", "vanilla_gradient.VanillaGradient.update_output", "instances_with_grads.extend"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.Interpret.vanilla_gradient.VanillaGradient._vanilla_grads", "home.repos.pwc.inspect_result.mifei_st-tod.Interpret.saliency_interpreter.SaliencyInterpreter.update_output"], ["", "def", "saliency_interpret", "(", "self", ",", "data", ",", "use_truth", "=", "True", ")", ":", "\n", "\n", "        ", "instances_with_grads", "=", "[", "]", "\n", "self", ".", "batch_output", "=", "[", "]", "\n", "self", ".", "_vanilla_grads", "(", "data", ",", "use_truth", ")", "\n", "batch_output", "=", "self", ".", "update_output", "(", ")", "\n", "instances_with_grads", ".", "extend", "(", "batch_output", ")", "\n", "\n", "return", "instances_with_grads", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.Interpret.vanilla_gradient.VanillaGradient._register_forward_hook": [[30, 47], ["vanilla_gradient.VanillaGradient.kwargs.get", "embedding_layer.register_forward_hook", "vanilla_gradient.VanillaGradient.model.__getattr__"], "methods", ["None"], ["", "def", "_register_forward_hook", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Register a forward hook on the embedding layer.\n        Used for one term in the SmoothGrad sum.\n        \"\"\"", "\n", "\n", "def", "forward_hook", "(", "module", ",", "inputs", ",", "output", ")", ":", "\n", "            ", "pass", "\n", "\n", "# Register the hook", "\n", "", "encoder", "=", "self", ".", "kwargs", ".", "get", "(", "\"encoder\"", ")", "\n", "if", "encoder", ":", "\n", "            ", "embedding_layer", "=", "self", ".", "model", ".", "__getattr__", "(", "encoder", ")", ".", "embeddings", "\n", "", "else", ":", "\n", "            ", "embedding_layer", "=", "self", ".", "model", ".", "utterance_encoder", ".", "embeddings", "\n", "", "handle", "=", "embedding_layer", ".", "register_forward_hook", "(", "forward_hook", ")", "\n", "return", "handle", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.Interpret.vanilla_gradient.VanillaGradient._vanilla_grads": [[48, 55], ["vanilla_gradient.VanillaGradient._register_forward_hook", "vanilla_gradient.VanillaGradient._get_gradients", "vanilla_gradient.VanillaGradient.remove", "vanilla_gradient.VanillaGradient.batch_output.append"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.Interpret.smooth_gradient.SmoothGradient._register_forward_hook", "home.repos.pwc.inspect_result.mifei_st-tod.Interpret.saliency_interpreter.SaliencyInterpreter._get_gradients"], ["", "def", "_vanilla_grads", "(", "self", ",", "batch", ",", "use_truth", ")", ":", "\n", "\n", "        ", "handle", "=", "self", ".", "_register_forward_hook", "(", ")", "\n", "grads", "=", "self", ".", "_get_gradients", "(", "batch", ",", "use_truth", ")", "\n", "handle", ".", "remove", "(", ")", "\n", "\n", "self", ".", "batch_output", ".", "append", "(", "grads", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mifei_st-tod.Interpret.smooth_gradient.SmoothGradient.__init__": [[13, 24], ["utils.Interpret.saliency_interpreter.SaliencyInterpreter.__init__"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.models.dual_encoder_ranking.dual_encoder_ranking.__init__"], ["def", "__init__", "(", "self", ",", "\n", "model", ",", "\n", "tokenizer", ",", "\n", "stdev", "=", "0.01", ",", "\n", "num_samples", "=", "20", ",", "\n", "show_progress", "=", "True", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "tokenizer", ",", "show_progress", ",", "**", "kwargs", ")", "\n", "# Hyperparameters", "\n", "self", ".", "stdev", "=", "stdev", "\n", "self", ".", "num_samples", "=", "num_samples", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.Interpret.smooth_gradient.SmoothGradient.saliency_interpret": [[25, 34], ["smooth_gradient.SmoothGradient._smooth_grads", "smooth_gradient.SmoothGradient.update_output", "instances_with_grads.extend"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.Interpret.smooth_gradient.SmoothGradient._smooth_grads", "home.repos.pwc.inspect_result.mifei_st-tod.Interpret.saliency_interpreter.SaliencyInterpreter.update_output"], ["", "def", "saliency_interpret", "(", "self", ",", "data", ",", "use_truth", "=", "True", ")", ":", "\n", "\n", "        ", "instances_with_grads", "=", "[", "]", "\n", "self", ".", "batch_output", "=", "[", "]", "\n", "self", ".", "_smooth_grads", "(", "data", ",", "use_truth", ")", "\n", "batch_output", "=", "self", ".", "update_output", "(", ")", "\n", "instances_with_grads", ".", "extend", "(", "batch_output", ")", "\n", "\n", "return", "instances_with_grads", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.Interpret.smooth_gradient.SmoothGradient._register_forward_hook": [[35, 59], ["smooth_gradient.SmoothGradient.kwargs.get", "embedding_layer.register_forward_hook", "output.add_", "output.detach().max", "output.detach().min", "smooth_gradient.SmoothGradient.model.__getattr__", "torch.randn().to", "output.detach", "output.detach", "torch.randn"], "methods", ["None"], ["", "def", "_register_forward_hook", "(", "self", ",", "stdev", ":", "float", ")", ":", "\n", "        ", "\"\"\"\n        Register a forward hook on the embedding layer which adds random noise to every embedding.\n        Used for one term in the SmoothGrad sum.  \n        \"\"\"", "\n", "\n", "def", "forward_hook", "(", "module", ",", "inputs", ",", "output", ")", ":", "\n", "# module: Embedding", "\n", "#", "\n", "# Random noise = N(0, stdev * (max-min))", "\n", "            ", "scale", "=", "output", ".", "detach", "(", ")", ".", "max", "(", ")", "-", "output", ".", "detach", "(", ")", ".", "min", "(", ")", "\n", "noise", "=", "torch", ".", "randn", "(", "output", ".", "shape", ")", ".", "to", "(", "output", ".", "device", ")", "*", "stdev", "*", "scale", "\n", "\n", "# Add the random noise", "\n", "output", ".", "add_", "(", "noise", ")", "\n", "\n", "# Register the hook", "\n", "", "encoder", "=", "self", ".", "kwargs", ".", "get", "(", "\"encoder\"", ")", "\n", "if", "encoder", ":", "\n", "            ", "embedding_layer", "=", "self", ".", "model", ".", "__getattr__", "(", "encoder", ")", ".", "embeddings", "\n", "", "else", ":", "\n", "            ", "embedding_layer", "=", "self", ".", "model", ".", "utterance_encoder", ".", "embeddings", "\n", "", "handle", "=", "embedding_layer", ".", "register_forward_hook", "(", "forward_hook", ")", "\n", "return", "handle", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.Interpret.smooth_gradient.SmoothGradient._smooth_grads": [[60, 76], ["range", "smooth_gradient.SmoothGradient.batch_output.append", "smooth_gradient.SmoothGradient._register_forward_hook", "smooth_gradient.SmoothGradient._get_gradients", "smooth_gradient.SmoothGradient.remove"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.Interpret.smooth_gradient.SmoothGradient._register_forward_hook", "home.repos.pwc.inspect_result.mifei_st-tod.Interpret.saliency_interpreter.SaliencyInterpreter._get_gradients"], ["", "def", "_smooth_grads", "(", "self", ",", "batch", ",", "use_truth", ")", ":", "\n", "        ", "total_gradients", "=", "None", "\n", "for", "_", "in", "range", "(", "self", ".", "num_samples", ")", ":", "\n", "            ", "handle", "=", "self", ".", "_register_forward_hook", "(", "self", ".", "stdev", ")", "\n", "grads", "=", "self", ".", "_get_gradients", "(", "batch", ",", "use_truth", ")", "\n", "handle", ".", "remove", "(", ")", "\n", "\n", "# Sum gradients", "\n", "if", "total_gradients", "is", "None", ":", "\n", "                ", "total_gradients", "=", "grads", "\n", "", "else", ":", "\n", "                ", "total_gradients", "=", "total_gradients", "+", "grads", "\n", "\n", "", "", "total_gradients", "/=", "self", ".", "num_samples", "\n", "\n", "self", ".", "batch_output", ".", "append", "(", "total_gradients", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.mifei_st-tod.metrics.measures.word_error_rate": [[15, 38], ["numpy.zeros().reshape", "numpy.zeros().reshape", "range", "range", "range", "range", "numpy.zeros", "numpy.zeros", "len", "len", "float", "len", "len", "len", "len", "len", "min", "len", "len", "len", "len"], "function", ["None"], ["def", "word_error_rate", "(", "r", ",", "h", ")", ":", "\n", "    ", "\"\"\"\n    This is a function that calculate the word error rate in ASR.\n    You can use it like this: wer(\"what is it\".split(), \"what is\".split()) \n    \"\"\"", "\n", "#build the matrix", "\n", "d", "=", "numpy", ".", "zeros", "(", "(", "len", "(", "r", ")", "+", "1", ")", "*", "(", "len", "(", "h", ")", "+", "1", ")", ",", "dtype", "=", "numpy", ".", "uint8", ")", ".", "reshape", "(", "(", "len", "(", "r", ")", "+", "1", ",", "len", "(", "h", ")", "+", "1", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "r", ")", "+", "1", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "h", ")", "+", "1", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "d", "[", "0", "]", "[", "j", "]", "=", "j", "\n", "elif", "j", "==", "0", ":", "d", "[", "i", "]", "[", "0", "]", "=", "i", "\n", "", "", "for", "i", "in", "range", "(", "1", ",", "len", "(", "r", ")", "+", "1", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "1", ",", "len", "(", "h", ")", "+", "1", ")", ":", "\n", "            ", "if", "r", "[", "i", "-", "1", "]", "==", "h", "[", "j", "-", "1", "]", ":", "\n", "                ", "d", "[", "i", "]", "[", "j", "]", "=", "d", "[", "i", "-", "1", "]", "[", "j", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "substitute", "=", "d", "[", "i", "-", "1", "]", "[", "j", "-", "1", "]", "+", "1", "\n", "insert", "=", "d", "[", "i", "]", "[", "j", "-", "1", "]", "+", "1", "\n", "delete", "=", "d", "[", "i", "-", "1", "]", "[", "j", "]", "+", "1", "\n", "d", "[", "i", "]", "[", "j", "]", "=", "min", "(", "substitute", ",", "insert", ",", "delete", ")", "\n", "", "", "", "result", "=", "float", "(", "d", "[", "len", "(", "r", ")", "]", "[", "len", "(", "h", ")", "]", ")", "/", "len", "(", "r", ")", "*", "100", "\n", "# result = str(\"%.2f\" % result) + \"%\"", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.metrics.measures.moses_multi_bleu": [[57, 117], ["tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "tempfile.NamedTemporaryFile", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.write", "tempfile.NamedTemporaryFile.flush", "tempfile.NamedTemporaryFile.close", "tempfile.NamedTemporaryFile.close", "numpy.size", "numpy.float32", "six.moves.urllib.request.urlretrieve", "os.chmod", "open", "print", "os.path.dirname", "os.path.abspath", "os.path.join", "subprocess.check_output", "bleu_out.decode.decode", "re.search().group", "float", "os.path.realpath", "os.path.join", "re.search", "print", "print", "numpy.float32"], "function", ["None"], ["def", "moses_multi_bleu", "(", "hypotheses", ",", "references", ",", "lowercase", "=", "False", ")", ":", "\n", "    ", "\"\"\"Calculate the bleu score for hypotheses and references\n    using the MOSES ulti-bleu.perl script.\n    Args:\n    hypotheses: A numpy array of strings where each string is a single example.\n    references: A numpy array of strings where each string is a single example.\n    lowercase: If true, pass the \"-lc\" flag to the multi-bleu script\n    Returns:\n    The BLEU score as a float32 value.\n    \"\"\"", "\n", "\n", "if", "np", ".", "size", "(", "hypotheses", ")", "==", "0", ":", "\n", "        ", "return", "np", ".", "float32", "(", "0.0", ")", "\n", "\n", "\n", "# Get MOSES multi-bleu script", "\n", "", "try", ":", "\n", "        ", "multi_bleu_path", ",", "_", "=", "urllib", ".", "request", ".", "urlretrieve", "(", "\n", "\"https://raw.githubusercontent.com/moses-smt/mosesdecoder/\"", "\n", "\"master/scripts/generic/multi-bleu.perl\"", ")", "\n", "os", ".", "chmod", "(", "multi_bleu_path", ",", "0o755", ")", "\n", "", "except", ":", "#pylint: disable=W0702", "\n", "        ", "print", "(", "\"Unable to fetch multi-bleu.perl script, using local.\"", ")", "\n", "metrics_dir", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", "\n", "bin_dir", "=", "os", ".", "path", ".", "abspath", "(", "os", ".", "path", ".", "join", "(", "metrics_dir", ",", "\"..\"", ",", "\"..\"", ",", "\"bin\"", ")", ")", "\n", "multi_bleu_path", "=", "os", ".", "path", ".", "join", "(", "bin_dir", ",", "\"tools/multi-bleu.perl\"", ")", "\n", "\n", "\n", "# Dump hypotheses and references to tempfiles", "\n", "", "hypothesis_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "hypothesis_file", ".", "write", "(", "\"\\n\"", ".", "join", "(", "hypotheses", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "hypothesis_file", ".", "write", "(", "b\"\\n\"", ")", "\n", "hypothesis_file", ".", "flush", "(", ")", "\n", "reference_file", "=", "tempfile", ".", "NamedTemporaryFile", "(", ")", "\n", "reference_file", ".", "write", "(", "\"\\n\"", ".", "join", "(", "references", ")", ".", "encode", "(", "\"utf-8\"", ")", ")", "\n", "reference_file", ".", "write", "(", "b\"\\n\"", ")", "\n", "reference_file", ".", "flush", "(", ")", "\n", "\n", "\n", "# Calculate BLEU using multi-bleu script", "\n", "with", "open", "(", "hypothesis_file", ".", "name", ",", "\"r\"", ")", "as", "read_pred", ":", "\n", "        ", "bleu_cmd", "=", "[", "multi_bleu_path", "]", "\n", "if", "lowercase", ":", "\n", "            ", "bleu_cmd", "+=", "[", "\"-lc\"", "]", "\n", "", "bleu_cmd", "+=", "[", "reference_file", ".", "name", "]", "\n", "try", ":", "\n", "            ", "bleu_out", "=", "subprocess", ".", "check_output", "(", "bleu_cmd", ",", "stdin", "=", "read_pred", ",", "stderr", "=", "subprocess", ".", "STDOUT", ")", "\n", "bleu_out", "=", "bleu_out", ".", "decode", "(", "\"utf-8\"", ")", "\n", "bleu_score", "=", "re", ".", "search", "(", "r\"BLEU = (.+?),\"", ",", "bleu_out", ")", ".", "group", "(", "1", ")", "\n", "bleu_score", "=", "float", "(", "bleu_score", ")", "\n", "", "except", "subprocess", ".", "CalledProcessError", "as", "error", ":", "\n", "            ", "if", "error", ".", "output", "is", "not", "None", ":", "\n", "                ", "print", "(", "\"multi-bleu.perl script returned non-zero exit code\"", ")", "\n", "print", "(", "error", ".", "output", ")", "\n", "bleu_score", "=", "np", ".", "float32", "(", "0.0", ")", "\n", "\n", "# Close temp files", "\n", "", "", "", "hypothesis_file", ".", "close", "(", ")", "\n", "reference_file", ".", "close", "(", ")", "\n", "return", "bleu_score", "", "", ""]], "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.delexicalize.prepareSlotValuesIndependent": [[20, 125], ["open", "simplejson.load", "open.close", "dic.extend", "dic.extend", "dic.extend", "ent.items", "dic.append", "open", "simplejson.load", "open.close", "dic.append", "dic.append", "dic.append", "dic.append", "dic.append", "dic.append", "dic.append", "ent.items", "dic.append", "dic.append", "dic.append", "dic.append", "dic.append", "dic.append", "nlp.normalize", "nlp.normalize", "nlp.normalize", "nlp.normalize", "nlp.normalize", "nlp.normalize", "nlp.normalize", "nlp.normalize", "nlp.normalize", "dic.append", "val.replace.replace", "dic.append", "dic.append", "nlp.normalize", "val.replace.replace", "dic.append", "val.replace.replace", "dic.append", "dic.append", "nlp.normalize", "val.replace.replace", "dic.append", "nlp.normalize", "val.replace.replace", "dic.append", "dic.append", "nlp.normalize", "val.replace.replace", "dic.append", "nlp.normalize", "val.replace.replace", "dic.append", "nlp.normalize", "dic.append", "nlp.normalize", "nlp.normalize", "val.replace.replace", "dic.append", "dic.append", "nlp.normalize", "nlp.normalize", "nlp.normalize", "dic_area.append", "nlp.normalize", "nlp.normalize", "dic_food.append", "nlp.normalize", "dic_price.append", "nlp.normalize", "nlp.normalize"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize"], ["def", "prepareSlotValuesIndependent", "(", ")", ":", "\n", "    ", "domains", "=", "[", "'restaurant'", ",", "'hotel'", ",", "'attraction'", ",", "'train'", ",", "'taxi'", ",", "'hospital'", ",", "'police'", "]", "\n", "requestables", "=", "[", "'phone'", ",", "'address'", ",", "'postcode'", ",", "'reference'", ",", "'id'", "]", "\n", "dic", "=", "[", "]", "\n", "dic_area", "=", "[", "]", "\n", "dic_food", "=", "[", "]", "\n", "dic_price", "=", "[", "]", "\n", "\n", "# read databases", "\n", "for", "domain", "in", "domains", ":", "\n", "        ", "try", ":", "\n", "            ", "fin", "=", "open", "(", "'data/multi-woz/db/'", "+", "domain", "+", "'_db.json'", ",", "'r'", ")", "\n", "db_json", "=", "json", ".", "load", "(", "fin", ")", "\n", "fin", ".", "close", "(", ")", "\n", "\n", "for", "ent", "in", "db_json", ":", "\n", "                ", "for", "key", ",", "val", "in", "ent", ".", "items", "(", ")", ":", "\n", "                    ", "if", "val", "==", "'?'", "or", "val", "==", "'free'", ":", "\n", "                        ", "pass", "\n", "", "elif", "key", "==", "'address'", ":", "\n", "                        ", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "if", "\"road\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"road\"", ",", "\"rd\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "", "elif", "\"rd\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"rd\"", ",", "\"road\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "", "elif", "\"st\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"st\"", ",", "\"street\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "", "elif", "\"street\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"street\"", ",", "\"st\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "", "", "elif", "key", "==", "'name'", ":", "\n", "                        ", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "if", "\"b & b\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"b & b\"", ",", "\"bed and breakfast\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "", "elif", "\"bed and breakfast\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"bed and breakfast\"", ",", "\"b & b\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "", "elif", "\"hotel\"", "in", "val", "and", "'gonville'", "not", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"hotel\"", ",", "\"\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "", "elif", "\"restaurant\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"restaurant\"", ",", "\"\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "", "", "elif", "key", "==", "'postcode'", ":", "\n", "                        ", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'postcode'", "+", "']'", ")", ")", "\n", "", "elif", "key", "==", "'phone'", ":", "\n", "                        ", "dic", ".", "append", "(", "(", "val", ",", "'['", "+", "domain", "+", "'_'", "+", "'phone'", "+", "']'", ")", ")", "\n", "", "elif", "key", "==", "'trainID'", ":", "\n", "                        ", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'id'", "+", "']'", ")", ")", "\n", "", "elif", "key", "==", "'department'", ":", "\n", "                        ", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'department'", "+", "']'", ")", ")", "\n", "\n", "# NORMAL DELEX", "\n", "", "elif", "key", "==", "'area'", ":", "\n", "                        ", "dic_area", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "'value'", "+", "'_'", "+", "'area'", "+", "']'", ")", ")", "\n", "", "elif", "key", "==", "'food'", ":", "\n", "                        ", "dic_food", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "'value'", "+", "'_'", "+", "'food'", "+", "']'", ")", ")", "\n", "", "elif", "key", "==", "'pricerange'", ":", "\n", "                        ", "dic_price", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "'value'", "+", "'_'", "+", "'pricerange'", "+", "']'", ")", ")", "\n", "", "else", ":", "\n", "                        ", "pass", "\n", "# TODO car type?", "\n", "", "", "", "", "except", ":", "\n", "            ", "pass", "\n", "\n", "", "if", "domain", "==", "'hospital'", ":", "\n", "            ", "dic", ".", "append", "(", "(", "normalize", "(", "'Hills Rd'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "'Hills Road'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "'CB20QQ'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'postcode'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "'01223245151'", ",", "'['", "+", "domain", "+", "'_'", "+", "'phone'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "'1223245151'", ",", "'['", "+", "domain", "+", "'_'", "+", "'phone'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "'0122324515'", ",", "'['", "+", "domain", "+", "'_'", "+", "'phone'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "'Addenbrookes Hospital'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "\n", "", "elif", "domain", "==", "'police'", ":", "\n", "            ", "dic", ".", "append", "(", "(", "normalize", "(", "'Parkside'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "'CB11JG'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'postcode'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "'01223358966'", ",", "'['", "+", "domain", "+", "'_'", "+", "'phone'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "'1223358966'", ",", "'['", "+", "domain", "+", "'_'", "+", "'phone'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "'Parkside Police Station'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "\n", "# add at the end places from trains", "\n", "", "", "fin", "=", "open", "(", "'data/multi-woz/db/'", "+", "'train'", "+", "'_db.json'", ",", "'r'", ")", "\n", "db_json", "=", "json", ".", "load", "(", "fin", ")", "\n", "fin", ".", "close", "(", ")", "\n", "\n", "for", "ent", "in", "db_json", ":", "\n", "        ", "for", "key", ",", "val", "in", "ent", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "==", "'departure'", "or", "key", "==", "'destination'", ":", "\n", "                ", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "'value'", "+", "'_'", "+", "'place'", "+", "']'", ")", ")", "\n", "\n", "# add specific values:", "\n", "", "", "", "for", "key", "in", "[", "'monday'", ",", "'tuesday'", ",", "'wednesday'", ",", "'thursday'", ",", "'friday'", ",", "'saturday'", ",", "'sunday'", "]", ":", "\n", "        ", "dic", ".", "append", "(", "(", "normalize", "(", "key", ")", ",", "'['", "+", "'value'", "+", "'_'", "+", "'day'", "+", "']'", ")", ")", "\n", "\n", "# more general values add at the end", "\n", "", "dic", ".", "extend", "(", "dic_area", ")", "\n", "dic", ".", "extend", "(", "dic_food", ")", "\n", "dic", ".", "extend", "(", "dic_price", ")", "\n", "\n", "return", "dic", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.delexicalize.delexicalise": [[127, 133], ["None"], "function", ["None"], ["", "def", "delexicalise", "(", "utt", ",", "dictionary", ")", ":", "\n", "    ", "for", "key", ",", "val", "in", "dictionary", ":", "\n", "        ", "utt", "=", "(", "' '", "+", "utt", "+", "' '", ")", ".", "replace", "(", "' '", "+", "key", "+", "' '", ",", "' '", "+", "val", "+", "' '", ")", "\n", "utt", "=", "utt", "[", "1", ":", "-", "1", "]", "# why this?", "\n", "\n", "", "return", "utt", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.delexicalize.delexicaliseDomain": [[135, 146], ["None"], "function", ["None"], ["", "def", "delexicaliseDomain", "(", "utt", ",", "dictionary", ",", "domain", ")", ":", "\n", "    ", "for", "key", ",", "val", "in", "dictionary", ":", "\n", "        ", "if", "key", "==", "domain", "or", "key", "==", "'value'", ":", "\n", "            ", "utt", "=", "(", "' '", "+", "utt", "+", "' '", ")", ".", "replace", "(", "' '", "+", "key", "+", "' '", ",", "' '", "+", "val", "+", "' '", ")", "\n", "utt", "=", "utt", "[", "1", ":", "-", "1", "]", "# why this?", "\n", "\n", "# go through rest of domain in case we are missing something out?", "\n", "", "", "for", "key", ",", "val", "in", "dictionary", ":", "\n", "        ", "utt", "=", "(", "' '", "+", "utt", "+", "' '", ")", ".", "replace", "(", "' '", "+", "key", "+", "' '", ",", "' '", "+", "val", "+", "' '", ")", "\n", "utt", "=", "utt", "[", "1", ":", "-", "1", "]", "# why this?", "\n", "", "return", "utt", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.BLEUScorer.__init__": [[127, 129], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.BLEUScorer.score": [[130, 189], ["zip", "math.fsum", "enumerate", "math.exp", "math.exp", "type", "ref.split", "range", "len", "range", "hyp.split", "hyp.split", "collections.Counter", "sum", "dict", "sum", "abs", "float", "float", "math.log", "zip", "nltk.util.ngrams", "collections.Counter.values", "collections.Counter", "dict.values", "len", "float", "float", "nltk.util.ngrams", "max", "len", "len", "max_counts.get", "min", "collections.Counter.items"], "methods", ["None"], ["", "def", "score", "(", "self", ",", "hypothesis", ",", "corpus", ",", "n", "=", "1", ")", ":", "\n", "# containers", "\n", "        ", "count", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "clip_count", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "r", "=", "0", "\n", "c", "=", "0", "\n", "weights", "=", "[", "0.25", ",", "0.25", ",", "0.25", ",", "0.25", "]", "\n", "\n", "# accumulate ngram statistics", "\n", "for", "hyps", ",", "refs", "in", "zip", "(", "hypothesis", ",", "corpus", ")", ":", "\n", "            ", "if", "type", "(", "hyps", "[", "0", "]", ")", "is", "list", ":", "\n", "                ", "hyps", "=", "[", "hyp", ".", "split", "(", ")", "for", "hyp", "in", "hyps", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "                ", "hyps", "=", "[", "hyp", ".", "split", "(", ")", "for", "hyp", "in", "hyps", "]", "\n", "\n", "", "refs", "=", "[", "ref", ".", "split", "(", ")", "for", "ref", "in", "refs", "]", "\n", "\n", "# Shawn's evaluation", "\n", "refs", "[", "0", "]", "=", "[", "u'GO_'", "]", "+", "refs", "[", "0", "]", "+", "[", "u'EOS_'", "]", "\n", "hyps", "[", "0", "]", "=", "[", "u'GO_'", "]", "+", "hyps", "[", "0", "]", "+", "[", "u'EOS_'", "]", "\n", "\n", "for", "idx", ",", "hyp", "in", "enumerate", "(", "hyps", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "# accumulate ngram counts", "\n", "                    ", "hypcnts", "=", "Counter", "(", "ngrams", "(", "hyp", ",", "i", "+", "1", ")", ")", "\n", "cnt", "=", "sum", "(", "hypcnts", ".", "values", "(", ")", ")", "\n", "count", "[", "i", "]", "+=", "cnt", "\n", "\n", "# compute clipped counts", "\n", "max_counts", "=", "{", "}", "\n", "for", "ref", "in", "refs", ":", "\n", "                        ", "refcnts", "=", "Counter", "(", "ngrams", "(", "ref", ",", "i", "+", "1", ")", ")", "\n", "for", "ng", "in", "hypcnts", ":", "\n", "                            ", "max_counts", "[", "ng", "]", "=", "max", "(", "max_counts", ".", "get", "(", "ng", ",", "0", ")", ",", "refcnts", "[", "ng", "]", ")", "\n", "", "", "clipcnt", "=", "dict", "(", "(", "ng", ",", "min", "(", "count", ",", "max_counts", "[", "ng", "]", ")", ")", "for", "ng", ",", "count", "in", "hypcnts", ".", "items", "(", ")", ")", "\n", "clip_count", "[", "i", "]", "+=", "sum", "(", "clipcnt", ".", "values", "(", ")", ")", "\n", "\n", "# accumulate r & c", "\n", "", "bestmatch", "=", "[", "1000", ",", "1000", "]", "\n", "for", "ref", "in", "refs", ":", "\n", "                    ", "if", "bestmatch", "[", "0", "]", "==", "0", ":", "break", "\n", "diff", "=", "abs", "(", "len", "(", "ref", ")", "-", "len", "(", "hyp", ")", ")", "\n", "if", "diff", "<", "bestmatch", "[", "0", "]", ":", "\n", "                        ", "bestmatch", "[", "0", "]", "=", "diff", "\n", "bestmatch", "[", "1", "]", "=", "len", "(", "ref", ")", "\n", "", "", "r", "+=", "bestmatch", "[", "1", "]", "\n", "c", "+=", "len", "(", "hyp", ")", "\n", "if", "n", "==", "1", ":", "\n", "                    ", "break", "\n", "# computing bleu score", "\n", "", "", "", "p0", "=", "1e-7", "\n", "bp", "=", "1", "if", "c", ">", "r", "else", "math", ".", "exp", "(", "1", "-", "float", "(", "r", ")", "/", "float", "(", "c", ")", ")", "\n", "p_ns", "=", "[", "float", "(", "clip_count", "[", "i", "]", ")", "/", "float", "(", "count", "[", "i", "]", "+", "p0", ")", "+", "p0", "for", "i", "in", "range", "(", "4", ")", "]", "\n", "s", "=", "math", ".", "fsum", "(", "w", "*", "math", ".", "log", "(", "p_n", ")", "for", "w", ",", "p_n", "in", "zip", "(", "weights", ",", "p_ns", ")", "if", "p_n", ")", "\n", "bleu", "=", "bp", "*", "math", ".", "exp", "(", "s", ")", "\n", "return", "bleu", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.GentScorer.__init__": [[192, 194], ["nlp.BLEUScorer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "detectfile", ")", ":", "\n", "        ", "self", ".", "bleuscorer", "=", "BLEUScorer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.GentScorer.scoreBLEU": [[195, 197], ["nlp.GentScorer.bleuscorer.score"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.BLEUScorer.score"], ["", "def", "scoreBLEU", "(", "self", ",", "parallel_corpus", ")", ":", "\n", "        ", "return", "self", ".", "bleuscorer", ".", "score", "(", "parallel_corpus", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.insertSpace": [[18, 35], ["text.find", "re.match", "re.match", "len", "len", "len", "len"], "function", ["None"], ["", "def", "insertSpace", "(", "token", ",", "text", ")", ":", "\n", "    ", "sidx", "=", "0", "\n", "while", "True", ":", "\n", "        ", "sidx", "=", "text", ".", "find", "(", "token", ",", "sidx", ")", "\n", "if", "sidx", "==", "-", "1", ":", "\n", "            ", "break", "\n", "", "if", "sidx", "+", "1", "<", "len", "(", "text", ")", "and", "re", ".", "match", "(", "'[0-9]'", ",", "text", "[", "sidx", "-", "1", "]", ")", "and", "re", ".", "match", "(", "'[0-9]'", ",", "text", "[", "sidx", "+", "1", "]", ")", ":", "\n", "            ", "sidx", "+=", "1", "\n", "continue", "\n", "", "if", "text", "[", "sidx", "-", "1", "]", "!=", "' '", ":", "\n", "            ", "text", "=", "text", "[", ":", "sidx", "]", "+", "' '", "+", "text", "[", "sidx", ":", "]", "\n", "sidx", "+=", "1", "\n", "", "if", "sidx", "+", "len", "(", "token", ")", "<", "len", "(", "text", ")", "and", "text", "[", "sidx", "+", "len", "(", "token", ")", "]", "!=", "' '", ":", "\n", "            ", "text", "=", "text", "[", ":", "sidx", "+", "1", "]", "+", "' '", "+", "text", "[", "sidx", "+", "1", ":", "]", "\n", "", "sidx", "+=", "1", "\n", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize": [[37, 121], ["text.replace.lower", "re.sub", "re.sub", "re.sub", "re.sub", "text.replace.replace", "re.sub", "text.replace.replace", "text.replace.replace", "re.sub", "nlp.insertSpace", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "text.replace.split", "re.findall", "re.findall", "re.sub", "re.sub", "nlp.insertSpace", "len", "text.replace.replace", "re.match", "re.match", "text.replace.find", "text.replace.replace", "text.replace.find", "text.replace.find", "len", "len", "re.sub"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.insertSpace", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.insertSpace"], ["", "def", "normalize", "(", "text", ",", "clean_value", "=", "True", ")", ":", "\n", "# lower case every word", "\n", "    ", "text", "=", "text", ".", "lower", "(", ")", "\n", "\n", "# replace white spaces in front and end", "\n", "text", "=", "re", ".", "sub", "(", "r'^\\s*|\\s*$'", ",", "''", ",", "text", ")", "\n", "\n", "# hotel domain pfb30", "\n", "text", "=", "re", ".", "sub", "(", "r\"b&b\"", ",", "\"bed and breakfast\"", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r\"b and b\"", ",", "\"bed and breakfast\"", ",", "text", ")", "\n", "\n", "if", "clean_value", ":", "\n", "# normalize phone number", "\n", "        ", "ms", "=", "re", ".", "findall", "(", "'\\(?(\\d{3})\\)?[-.\\s]?(\\d{3})[-.\\s]?(\\d{4,5})'", ",", "text", ")", "\n", "if", "ms", ":", "\n", "            ", "sidx", "=", "0", "\n", "for", "m", "in", "ms", ":", "\n", "                ", "sidx", "=", "text", ".", "find", "(", "m", "[", "0", "]", ",", "sidx", ")", "\n", "if", "text", "[", "sidx", "-", "1", "]", "==", "'('", ":", "\n", "                    ", "sidx", "-=", "1", "\n", "", "eidx", "=", "text", ".", "find", "(", "m", "[", "-", "1", "]", ",", "sidx", ")", "+", "len", "(", "m", "[", "-", "1", "]", ")", "\n", "text", "=", "text", ".", "replace", "(", "text", "[", "sidx", ":", "eidx", "]", ",", "''", ".", "join", "(", "m", ")", ")", "\n", "\n", "# normalize postcode", "\n", "", "", "ms", "=", "re", ".", "findall", "(", "'([a-z]{1}[\\. ]?[a-z]{1}[\\. ]?\\d{1,2}[, ]+\\d{1}[\\. ]?[a-z]{1}[\\. ]?[a-z]{1}|[a-z]{2}\\d{2}[a-z]{2})'", ",", "\n", "text", ")", "\n", "if", "ms", ":", "\n", "            ", "sidx", "=", "0", "\n", "for", "m", "in", "ms", ":", "\n", "                ", "sidx", "=", "text", ".", "find", "(", "m", ",", "sidx", ")", "\n", "eidx", "=", "sidx", "+", "len", "(", "m", ")", "\n", "text", "=", "text", "[", ":", "sidx", "]", "+", "re", ".", "sub", "(", "'[,\\. ]'", ",", "''", ",", "m", ")", "+", "text", "[", "eidx", ":", "]", "\n", "\n", "# weird unicode bug", "\n", "", "", "", "text", "=", "re", ".", "sub", "(", "u\"(\\u2018|\\u2019)\"", ",", "\"'\"", ",", "text", ")", "\n", "\n", "if", "clean_value", ":", "\n", "# replace time and and price", "\n", "        ", "text", "=", "re", ".", "sub", "(", "timepat", ",", "' [value_time] '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "pricepat", ",", "' [value_price] '", ",", "text", ")", "\n", "#text = re.sub(pricepat2, '[value_price]', text)", "\n", "\n", "# replace st.", "\n", "", "text", "=", "text", ".", "replace", "(", "';'", ",", "','", ")", "\n", "text", "=", "re", ".", "sub", "(", "'$\\/'", ",", "''", ",", "text", ")", "\n", "text", "=", "text", ".", "replace", "(", "'/'", ",", "' and '", ")", "\n", "\n", "# replace other special characters", "\n", "text", "=", "text", ".", "replace", "(", "'-'", ",", "' '", ")", "\n", "text", "=", "re", ".", "sub", "(", "'[\\\"\\<>@\\(\\)]'", ",", "''", ",", "text", ")", "# remove", "\n", "\n", "# insert white space before and after tokens:", "\n", "for", "token", "in", "[", "'?'", ",", "'.'", ",", "','", ",", "'!'", "]", ":", "\n", "        ", "text", "=", "insertSpace", "(", "token", ",", "text", ")", "\n", "\n", "# insert white space for 's", "\n", "", "text", "=", "insertSpace", "(", "'\\'s'", ",", "text", ")", "\n", "\n", "# replace it's, does't, you'd ... etc", "\n", "text", "=", "re", ".", "sub", "(", "'^\\''", ",", "''", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "'\\'$'", ",", "''", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "'\\'\\s'", ",", "' '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "'\\s\\''", ",", "' '", ",", "text", ")", "\n", "for", "fromx", ",", "tox", "in", "replacements", ":", "\n", "        ", "text", "=", "' '", "+", "text", "+", "' '", "\n", "text", "=", "text", ".", "replace", "(", "fromx", ",", "tox", ")", "[", "1", ":", "-", "1", "]", "\n", "\n", "# remove multiple spaces", "\n", "", "text", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "text", ")", "\n", "\n", "# concatenate numbers", "\n", "tmp", "=", "text", "\n", "tokens", "=", "text", ".", "split", "(", ")", "\n", "i", "=", "1", "\n", "while", "i", "<", "len", "(", "tokens", ")", ":", "\n", "        ", "if", "re", ".", "match", "(", "u'^\\d+$'", ",", "tokens", "[", "i", "]", ")", "and", "re", ".", "match", "(", "u'\\d+$'", ",", "tokens", "[", "i", "-", "1", "]", ")", ":", "\n", "            ", "tokens", "[", "i", "-", "1", "]", "+=", "tokens", "[", "i", "]", "\n", "del", "tokens", "[", "i", "]", "\n", "", "else", ":", "\n", "            ", "i", "+=", "1", "\n", "", "", "text", "=", "' '", ".", "join", "(", "tokens", ")", "\n", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.sentence_bleu_4": [[199, 240], ["range", "len", "math.exp", "math.fsum", "collections.Counter", "sum", "dict", "sum", "abs", "math.exp", "nltk.util.ngrams", "collections.Counter.values", "collections.Counter", "dict.values", "len", "abs", "range", "nltk.util.ngrams", "max", "len", "len", "float", "float", "math.log", "zip", "max_counts.get", "min", "collections.Counter.items", "float", "float"], "function", ["None"], ["", "", "def", "sentence_bleu_4", "(", "hyp", ",", "refs", ",", "weights", "=", "[", "0.25", ",", "0.25", ",", "0.25", ",", "0.25", "]", ")", ":", "\n", "# input : single sentence, multiple references", "\n", "    ", "count", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "clip_count", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "r", "=", "0", "\n", "c", "=", "0", "\n", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "        ", "hypcnts", "=", "Counter", "(", "ngrams", "(", "hyp", ",", "i", "+", "1", ")", ")", "\n", "cnt", "=", "sum", "(", "hypcnts", ".", "values", "(", ")", ")", "\n", "count", "[", "i", "]", "+=", "cnt", "\n", "\n", "# compute clipped counts", "\n", "max_counts", "=", "{", "}", "\n", "for", "ref", "in", "refs", ":", "\n", "            ", "refcnts", "=", "Counter", "(", "ngrams", "(", "ref", ",", "i", "+", "1", ")", ")", "\n", "for", "ng", "in", "hypcnts", ":", "\n", "                ", "max_counts", "[", "ng", "]", "=", "max", "(", "max_counts", ".", "get", "(", "ng", ",", "0", ")", ",", "refcnts", "[", "ng", "]", ")", "\n", "", "", "clipcnt", "=", "dict", "(", "(", "ng", ",", "min", "(", "count", ",", "max_counts", "[", "ng", "]", ")", ")", "for", "ng", ",", "count", "in", "hypcnts", ".", "items", "(", ")", ")", "\n", "clip_count", "[", "i", "]", "+=", "sum", "(", "clipcnt", ".", "values", "(", ")", ")", "\n", "\n", "", "bestmatch", "=", "[", "1000", ",", "1000", "]", "\n", "for", "ref", "in", "refs", ":", "\n", "        ", "if", "bestmatch", "[", "0", "]", "==", "0", ":", "\n", "            ", "break", "\n", "", "diff", "=", "abs", "(", "len", "(", "ref", ")", "-", "len", "(", "hyp", ")", ")", "\n", "if", "diff", "<", "bestmatch", "[", "0", "]", ":", "\n", "            ", "bestmatch", "[", "0", "]", "=", "diff", "\n", "bestmatch", "[", "1", "]", "=", "len", "(", "ref", ")", "\n", "", "", "r", "=", "bestmatch", "[", "1", "]", "\n", "c", "=", "len", "(", "hyp", ")", "\n", "\n", "p0", "=", "1e-7", "\n", "bp", "=", "math", ".", "exp", "(", "-", "abs", "(", "1.0", "-", "float", "(", "r", ")", "/", "float", "(", "c", "+", "p0", ")", ")", ")", "\n", "\n", "p_ns", "=", "[", "float", "(", "clip_count", "[", "i", "]", ")", "/", "float", "(", "count", "[", "i", "]", "+", "p0", ")", "+", "p0", "for", "i", "in", "range", "(", "4", ")", "]", "\n", "s", "=", "math", ".", "fsum", "(", "w", "*", "math", ".", "log", "(", "p_n", ")", "for", "w", ",", "p_n", "in", "zip", "(", "weights", ",", "p_ns", ")", "if", "p_n", ")", "\n", "bleu_hyp", "=", "bp", "*", "math", ".", "exp", "(", "s", ")", "\n", "\n", "return", "bleu_hyp", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.dbPointer.oneHotVector": [[19, 52], ["domains.index", "domains.index", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "function", ["None"], ["", "def", "oneHotVector", "(", "num", ",", "domain", ",", "vector", ")", ":", "\n", "    ", "\"\"\"Return number of available entities for particular domain.\"\"\"", "\n", "number_of_options", "=", "6", "\n", "if", "domain", "!=", "'train'", ":", "\n", "        ", "idx", "=", "domains", ".", "index", "(", "domain", ")", "\n", "if", "num", "==", "0", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "num", "==", "1", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "num", "==", "2", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "num", "==", "3", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "num", "==", "4", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", "]", ")", "\n", "", "elif", "num", ">=", "5", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "idx", "=", "domains", ".", "index", "(", "domain", ")", "\n", "if", "num", "==", "0", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "num", "<=", "2", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "num", "<=", "5", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "num", "<=", "10", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "num", "<=", "40", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", "]", ")", "\n", "", "elif", "num", ">", "40", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", "]", ")", "\n", "\n", "", "", "return", "vector", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.dbPointer.queryResult": [[53, 93], ["[].items", "len", "dbs[].execute().fetchall", "val.replace", "val.replace", "dbs[].execute"], "function", ["None"], ["", "def", "queryResult", "(", "domain", ",", "turn", ")", ":", "\n", "    ", "\"\"\"Returns the list of entities for a given domain\n    based on the annotation of the belief state\"\"\"", "\n", "# query the db", "\n", "sql_query", "=", "\"select * from {}\"", ".", "format", "(", "domain", ")", "\n", "\n", "flag", "=", "True", "\n", "#print turn['metadata'][domain]['semi']", "\n", "for", "key", ",", "val", "in", "turn", "[", "'metadata'", "]", "[", "domain", "]", "[", "'semi'", "]", ".", "items", "(", ")", ":", "\n", "        ", "if", "val", "==", "\"\"", "or", "val", "==", "\"dont care\"", "or", "val", "==", "'not mentioned'", "or", "val", "==", "\"don't care\"", "or", "val", "==", "\"dontcare\"", "or", "val", "==", "\"do n't care\"", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "if", "flag", ":", "\n", "                ", "sql_query", "+=", "\" where \"", "\n", "val2", "=", "val", ".", "replace", "(", "\"'\"", ",", "\"''\"", ")", "\n", "#val2 = normalize(val2)", "\n", "# change query for trains", "\n", "if", "key", "==", "'leaveAt'", ":", "\n", "                    ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\" > \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "elif", "key", "==", "'arriveBy'", ":", "\n", "                    ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\" < \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "else", ":", "\n", "                    ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\"=\"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "flag", "=", "False", "\n", "", "else", ":", "\n", "                ", "val2", "=", "val", ".", "replace", "(", "\"'\"", ",", "\"''\"", ")", "\n", "#val2 = normalize(val2)", "\n", "if", "key", "==", "'leaveAt'", ":", "\n", "                    ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\" > \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "elif", "key", "==", "'arriveBy'", ":", "\n", "                    ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\" < \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "else", ":", "\n", "                    ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\"=\"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "\n", "#try:  # \"select * from attraction  where name = 'queens college'\"", "\n", "#print sql_query", "\n", "#print domain", "\n", "", "", "", "", "num_entities", "=", "len", "(", "dbs", "[", "domain", "]", ".", "execute", "(", "sql_query", ")", ".", "fetchall", "(", ")", ")", "\n", "\n", "return", "num_entities", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.dbPointer.queryResultVenues": [[95, 173], ["turn.items", "dbs[].execute().fetchall", "[].items", "val.replace", "nlp.normalize", "val.replace", "nlp.normalize", "dbs[].execute", "slot[].split", "slot[].split", "dbs[].execute().fetchall", "val.replace", "nlp.normalize", "val.replace", "nlp.normalize", "dbs[].execute"], "function", ["home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.nlp.normalize"], ["", "def", "queryResultVenues", "(", "domain", ",", "turn", ",", "real_belief", "=", "False", ")", ":", "\n", "# query the db", "\n", "    ", "sql_query", "=", "\"select * from {}\"", ".", "format", "(", "domain", ")", "\n", "\n", "if", "real_belief", "==", "True", ":", "\n", "        ", "items", "=", "turn", ".", "items", "(", ")", "\n", "", "elif", "real_belief", "==", "'tracking'", ":", "\n", "        ", "for", "slot", "in", "turn", "[", "domain", "]", ":", "\n", "            ", "key", "=", "slot", "[", "0", "]", ".", "split", "(", "\"-\"", ")", "[", "1", "]", "\n", "val", "=", "slot", "[", "0", "]", ".", "split", "(", "\"-\"", ")", "[", "2", "]", "\n", "if", "key", "==", "\"price range\"", ":", "\n", "                ", "key", "=", "\"pricerange\"", "\n", "", "elif", "key", "==", "\"leave at\"", ":", "\n", "                ", "key", "=", "\"leaveAt\"", "\n", "", "elif", "key", "==", "\"arrive by\"", ":", "\n", "                ", "key", "=", "\"arriveBy\"", "\n", "", "if", "val", "==", "\"do n't care\"", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "if", "flag", ":", "\n", "                    ", "sql_query", "+=", "\" where \"", "\n", "val2", "=", "val", ".", "replace", "(", "\"'\"", ",", "\"''\"", ")", "\n", "val2", "=", "normalize", "(", "val2", ")", "\n", "if", "key", "==", "'leaveAt'", ":", "\n", "                        ", "sql_query", "+=", "key", "+", "\" > \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "elif", "key", "==", "'arriveBy'", ":", "\n", "                        ", "sql_query", "+=", "key", "+", "\" < \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "else", ":", "\n", "                        ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\"=\"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "flag", "=", "False", "\n", "", "else", ":", "\n", "                    ", "val2", "=", "val", ".", "replace", "(", "\"'\"", ",", "\"''\"", ")", "\n", "val2", "=", "normalize", "(", "val2", ")", "\n", "if", "key", "==", "'leaveAt'", ":", "\n", "                        ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\" > \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "elif", "key", "==", "'arriveBy'", ":", "\n", "                        ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\" < \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "else", ":", "\n", "                        ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\"=\"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "\n", "", "", "", "try", ":", "# \"select * from attraction  where name = 'queens college'\"", "\n", "                ", "return", "dbs", "[", "domain", "]", ".", "execute", "(", "sql_query", ")", ".", "fetchall", "(", ")", "\n", "", "except", ":", "\n", "                ", "return", "[", "]", "# TODO test it", "\n", "", "", "pass", "\n", "", "else", ":", "\n", "        ", "items", "=", "turn", "[", "'metadata'", "]", "[", "domain", "]", "[", "'semi'", "]", ".", "items", "(", ")", "\n", "\n", "", "flag", "=", "True", "\n", "for", "key", ",", "val", "in", "items", ":", "\n", "        ", "if", "val", "==", "\"\"", "or", "val", "==", "\"dontcare\"", "or", "val", "==", "'not mentioned'", "or", "val", "==", "\"don't care\"", "or", "val", "==", "\"dont care\"", "or", "val", "==", "\"do n't care\"", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "if", "flag", ":", "\n", "                ", "sql_query", "+=", "\" where \"", "\n", "val2", "=", "val", ".", "replace", "(", "\"'\"", ",", "\"''\"", ")", "\n", "val2", "=", "normalize", "(", "val2", ")", "\n", "if", "key", "==", "'leaveAt'", ":", "\n", "                    ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\" > \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "elif", "key", "==", "'arriveBy'", ":", "\n", "                    ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\" < \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "else", ":", "\n", "                    ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\"=\"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "flag", "=", "False", "\n", "", "else", ":", "\n", "                ", "val2", "=", "val", ".", "replace", "(", "\"'\"", ",", "\"''\"", ")", "\n", "val2", "=", "normalize", "(", "val2", ")", "\n", "if", "key", "==", "'leaveAt'", ":", "\n", "                    ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\" > \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "elif", "key", "==", "'arriveBy'", ":", "\n", "                    ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\" < \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "else", ":", "\n", "                    ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\"=\"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "\n", "", "", "", "", "try", ":", "# \"select * from attraction  where name = 'queens college'\"", "\n", "        ", "return", "dbs", "[", "domain", "]", ".", "execute", "(", "sql_query", ")", ".", "fetchall", "(", ")", "\n", "", "except", ":", "\n", "        ", "return", "[", "]", "# TODO test it", "", "", "", ""]], "home.repos.pwc.inspect_result.mifei_st-tod.multiwoz.fix_label.fix_general_label_error": [[2, 405], ["dict", "dict", "label_dict.keys", "GENERAL_TYPO.keys", "label_dict[].replace", "label_dict[].replace().replace", "label_dict[].replace"], "function", ["None"], ["def", "fix_general_label_error", "(", "labels", ",", "type", ",", "slots", ",", "ontology_version", "=", "\"\"", ")", ":", "\n", "    ", "label_dict", "=", "dict", "(", "[", "(", "l", "[", "0", "]", ",", "l", "[", "1", "]", ")", "for", "l", "in", "labels", "]", ")", "if", "type", "else", "dict", "(", "[", "(", "l", "[", "\"slots\"", "]", "[", "0", "]", "[", "0", "]", ",", "l", "[", "\"slots\"", "]", "[", "0", "]", "[", "1", "]", ")", "for", "l", "in", "labels", "]", ")", "\n", "\n", "GENERAL_TYPO", "=", "{", "\n", "# type", "\n", "\"guesthouse\"", ":", "\"guest house\"", ",", "\"guesthouses\"", ":", "\"guest house\"", ",", "\"guest\"", ":", "\"guest house\"", ",", "\"mutiple sports\"", ":", "\"multiple sports\"", ",", "\n", "\"mutliple sports\"", ":", "\"multiple sports\"", ",", "\"sports\"", ":", "\"multiple sports\"", ",", "\"swimmingpool\"", ":", "\"swimming pool\"", ",", "\n", "\"concerthall\"", ":", "\"concert hall\"", ",", "\"concert\"", ":", "\"concert hall\"", ",", "\"pool\"", ":", "\"swimming pool\"", ",", "\"night club\"", ":", "\"nightclub\"", ",", "\"mus\"", ":", "\"museum\"", ",", "\n", "\"colleges\"", ":", "\"college\"", ",", "\"coll\"", ":", "\"college\"", ",", "\"architectural\"", ":", "\"architecture\"", ",", "\"musuem\"", ":", "\"museum\"", ",", "\"churches\"", ":", "\"church\"", ",", "\n", "\n", "# area", "\n", "\"center\"", ":", "\"centre\"", ",", "\"center of town\"", ":", "\"centre\"", ",", "\"near city center\"", ":", "\"centre\"", ",", "\"in the north\"", ":", "\"north\"", ",", "\n", "\"cen\"", ":", "\"centre\"", ",", "\"east side\"", ":", "\"east\"", ",", "\"east area\"", ":", "\"east\"", ",", "\"west part of town\"", ":", "\"west\"", ",", "\"ce\"", ":", "\"centre\"", ",", "\n", "\"town center\"", ":", "\"centre\"", ",", "\"centre of cambridge\"", ":", "\"centre\"", ",", "\n", "\"city center\"", ":", "\"centre\"", ",", "\"the south\"", ":", "\"south\"", ",", "\"scentre\"", ":", "\"centre\"", ",", "\"town centre\"", ":", "\"centre\"", ",", "\"in town\"", ":", "\"centre\"", ",", "\n", "\"north part of town\"", ":", "\"north\"", ",", "\"centre of town\"", ":", "\"centre\"", ",", "\"cb30aq\"", ":", "\"none\"", ",", "\n", "\n", "# price", "\n", "\"mode\"", ":", "\"moderate\"", ",", "\"moderate -ly\"", ":", "\"moderate\"", ",", "\"mo\"", ":", "\"moderate\"", ",", "\n", "\n", "# day", "\n", "\"monda\"", ":", "\"monday\"", ",", "\n", "\n", "# parking", "\n", "\"free parking\"", ":", "\"free\"", ",", "\n", "\n", "# internet", "\n", "\"free internet\"", ":", "\"yes\"", ",", "\n", "\n", "# star", "\n", "\"4 star\"", ":", "\"4\"", ",", "\"4 stars\"", ":", "\"4\"", ",", "\"0 star rarting\"", ":", "\"none\"", ",", "\n", "\n", "# others ", "\n", "\"y\"", ":", "\"yes\"", ",", "\"any\"", ":", "\"do n't care\"", ",", "\"does not care\"", ":", "\"do n't care\"", ",", "\"not men\"", ":", "\"none\"", ",", "\"not\"", ":", "\"none\"", ",", "\n", "\"not mentioned\"", ":", "\"none\"", ",", "''", ":", "\"none\"", ",", "\"not mendtioned\"", ":", "\"none\"", ",", "\"3 .\"", ":", "\"3\"", ",", "\"does not\"", ":", "\"no\"", ",", "\"fun\"", ":", "\"none\"", ",", "\n", "}", "\n", "\n", "for", "slot", "in", "slots", ":", "\n", "        ", "if", "slot", "in", "label_dict", ".", "keys", "(", ")", ":", "\n", "\n", "# general typos", "\n", "            ", "if", "label_dict", "[", "slot", "]", "in", "GENERAL_TYPO", ".", "keys", "(", ")", ":", "\n", "                ", "label_dict", "[", "slot", "]", "=", "label_dict", "[", "slot", "]", ".", "replace", "(", "label_dict", "[", "slot", "]", ",", "GENERAL_TYPO", "[", "label_dict", "[", "slot", "]", "]", ")", "\n", "\n", "# do not care", "\n", "", "if", "label_dict", "[", "slot", "]", "in", "[", "\"doesn't care\"", ",", "\"don't care\"", ",", "\"dont care\"", ",", "\"does not care\"", ",", "\"do not care\"", ",", "\"dontcare\"", "]", ":", "\n", "                ", "label_dict", "[", "slot", "]", "=", "\"do n't care\"", "\n", "\n", "# miss match slot and value ", "\n", "", "if", "slot", "==", "\"hotel-type\"", "and", "label_dict", "[", "slot", "]", "in", "[", "\"nigh\"", ",", "\"moderate -ly priced\"", ",", "\"bed and breakfast\"", ",", "\"centre\"", ",", "\"venetian\"", ",", "\"intern\"", ",", "\"a cheap -er hotel\"", "]", ":", "\n", "                ", "label_dict", "[", "slot", "]", "=", "\"none\"", "\n", "", "if", "slot", "==", "\"hotel-internet\"", "and", "label_dict", "[", "slot", "]", "==", "\"4\"", ":", "\n", "                ", "label_dict", "[", "slot", "]", "=", "\"none\"", "\n", "", "if", "slot", "==", "\"hotel-internet\"", "and", "label_dict", "[", "slot", "]", "==", "\"4\"", ":", "\n", "                ", "label_dict", "[", "slot", "]", "=", "\"none\"", "\n", "", "if", "slot", "==", "\"hotel-pricerange\"", "and", "label_dict", "[", "slot", "]", "==", "\"2\"", ":", "\n", "                ", "label_dict", "[", "slot", "]", "=", "\"none\"", "\n", "", "if", "\"area\"", "in", "slot", "and", "label_dict", "[", "slot", "]", "in", "[", "\"moderate\"", "]", ":", "\n", "                ", "label_dict", "[", "slot", "]", "=", "\"none\"", "\n", "", "if", "\"day\"", "in", "slot", "and", "label_dict", "[", "slot", "]", "==", "\"t\"", ":", "\n", "                ", "label_dict", "[", "slot", "]", "=", "\"none\"", "\n", "", "if", "slot", "==", "\"hotel-type\"", "and", "label_dict", "[", "slot", "]", "in", "[", "\"hotel with free parking and free wifi\"", ",", "\"4\"", ",", "\"3 star hotel\"", "]", ":", "\n", "                ", "label_dict", "[", "slot", "]", "=", "\"hotel\"", "\n", "", "if", "slot", "==", "\"hotel-star\"", "and", "label_dict", "[", "slot", "]", "==", "\"3 star hotel\"", ":", "\n", "                ", "label_dict", "[", "slot", "]", "=", "\"3\"", "\n", "\n", "", "if", "\"area\"", "in", "slot", ":", "\n", "                ", "if", "label_dict", "[", "slot", "]", "==", "\"no\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"north\"", "\n", "", "elif", "label_dict", "[", "slot", "]", "==", "\"we\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"west\"", "\n", "", "elif", "label_dict", "[", "slot", "]", "==", "\"cent\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"centre\"", "\n", "\n", "", "", "if", "\"day\"", "in", "slot", ":", "\n", "                ", "if", "label_dict", "[", "slot", "]", "==", "\"we\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"wednesday\"", "\n", "", "elif", "label_dict", "[", "slot", "]", "==", "\"no\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"none\"", "\n", "\n", "", "", "if", "\"price\"", "in", "slot", "and", "label_dict", "[", "slot", "]", "==", "\"ch\"", ":", "\n", "                ", "label_dict", "[", "slot", "]", "=", "\"cheap\"", "\n", "", "if", "\"internet\"", "in", "slot", "and", "label_dict", "[", "slot", "]", "==", "\"free\"", ":", "\n", "                ", "label_dict", "[", "slot", "]", "=", "\"yes\"", "\n", "\n", "\n", "# Add on May, 2020", "\n", "", "if", "ontology_version", "in", "[", "\"1.0\"", "]", ":", "\n", "\n", "                ", "label_dict", "[", "slot", "]", "=", "label_dict", "[", "slot", "]", ".", "replace", "(", "\"theater\"", ",", "\"theatre\"", ")", ".", "replace", "(", "\"guesthouse\"", ",", "\"guest house\"", ")", "\n", "\n", "# Typo or naming", "\n", "if", "label_dict", "[", "slot", "]", "==", "\"cafe uno\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"caffe uno\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"alpha milton guest house\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"alpha-milton guest house\"", "\n", "", "if", "label_dict", "[", "slot", "]", "in", "[", "\"churchills college\"", ",", "\"churchhill college\"", ",", "\"churchill\"", ",", "\"the churchill college\"", "]", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"churchill college\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"portugese\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"portuguese\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"pizza hut fenditton\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"pizza hut fen ditton\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"restaurant 17\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"restaurant one seven\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"restaurant 2 two\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"restaurant two two\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"gallery at 12 a high street\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"gallery at twelve a high street\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"museum of archaelogy\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"museum of archaelogy and anthropology\"", "\n", "", "if", "label_dict", "[", "slot", "]", "in", "[", "\"huntingdon marriot hotel\"", ",", "\"marriot hotel\"", "]", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"huntingdon marriott hotel\"", "\n", "", "if", "label_dict", "[", "slot", "]", "in", "[", "\"sheeps green and lammas land park fen causeway\"", ",", "\"sheeps green and lammas land park\"", "]", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"sheep's green and lammas land park fen causeway\"", "\n", "", "if", "label_dict", "[", "slot", "]", "in", "[", "\"cambridge and country folk museum\"", ",", "\"county folk museum\"", "]", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"cambridge and county folk museum\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"ambridge\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"cambridge\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"cambridge contemporary art museum\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"cambridge contemporary art\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"molecular gastonomy\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"molecular gastronomy\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"2 two and cote\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"two two and cote\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"caribbeanindian\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"caribbean|indian\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"whipple museum\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"whipple museum of the history of science\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"ian hong\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"ian hong house\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"sundaymonday\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"sunday|monday\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"mondaythursday\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"monday|thursday\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"fridaytuesday\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"friday|tuesday\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"cheapmoderate\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"cheap|moderate\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"golden house                            golden house\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"the golden house\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"golden house\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"the golden house\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"sleeperz\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"sleeperz hotel\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"jamaicanchinese\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"jamaican|chinese\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"shiraz\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"shiraz restaurant\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"museum of archaelogy and anthropogy\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"museum of archaelogy and anthropology\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"yipee noodle bar\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"yippee noodle bar\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"abc theatre\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"adc theatre\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"wankworth house\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"warkworth house\"", "\n", "", "if", "label_dict", "[", "slot", "]", "in", "[", "\"cherry hinton water play park\"", ",", "\"cherry hinton water park\"", "]", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"cherry hinton water play\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"the gallery at 12\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"the gallery at twelve\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"barbequemodern european\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"barbeque|modern european\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"north americanindian\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"north american|indian\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"chiquito\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"chiquito restaurant bar\"", "\n", "\n", "\n", "# Abbreviation", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"city centre north bed and breakfast\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"city centre north b and b\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"north bed and breakfast\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"north b and b\"", "\n", "\n", "# Article and 's", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"christ college\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"christ's college\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"kings college\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"king's college\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"saint johns college\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"saint john's college\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"kettles yard\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"kettle's yard\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"rosas bed and breakfast\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"rosa's bed and breakfast\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"saint catharines college\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"saint catharine's college\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"little saint marys church\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"little saint mary's church\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"great saint marys church\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"great saint mary's church\"", "\n", "", "if", "label_dict", "[", "slot", "]", "in", "[", "\"queens college\"", ",", "\"queens' college\"", "]", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"queen's college\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"peoples portraits exhibition at girton college\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"people's portraits exhibition at girton college\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"st johns college\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"saint john's college\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"whale of time\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"whale of a time\"", "\n", "", "if", "label_dict", "[", "slot", "]", "in", "[", "\"st catharines college\"", ",", "\"saint catharines college\"", "]", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"saint catharine's college\"", "\n", "\n", "# Time", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"16,15\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"16:15\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"1330\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"13:30\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"1430\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"14:30\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"1532\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"15:32\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"845\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"08:45\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"1145\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"11:45\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"1545\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"15:45\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"1329\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"13:29\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"1345\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"13:45\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"1715\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"17:15\"", "\n", "", "if", "label_dict", "[", "slot", "]", "==", "\"929\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"09:29\"", "\n", "\n", "\n", "# restaurant", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "\"meze bar\"", "in", "label_dict", "[", "slot", "]", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"meze bar restaurant\"", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"alimentum\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"restaurant alimentum\"", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"good luck\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"the good luck chinese food takeaway\"", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"grafton hotel\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"grafton hotel restaurant\"", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"2 two\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"restaurant two two\"", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"hotpot\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"the hotpot\"", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"hobsons house\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"hobson house\"", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"shanghai\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"shanghai family restaurant\"", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"17\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"restaurant one seven\"", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "label_dict", "[", "slot", "]", "in", "[", "\"22\"", ",", "\"restaurant 22\"", "]", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"restaurant two two\"", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"the maharajah tandoor\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"maharajah tandoori restaurant\"", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"the grafton hotel\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"grafton hotel restaurant\"", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"gardenia\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"the gardenia\"", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"el shaddia guest house\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"el shaddai\"", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"the bedouin\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"bedouin\"", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"the kohinoor\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"kohinoor\"", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"the peking\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"peking restaurant\"", "\n", "", "if", "slot", "==", "\"restaurant-book time\"", "and", "label_dict", "[", "slot", "]", "==", "\"7pm\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"19:00\"", "\n", "", "if", "slot", "==", "\"restaurant-book time\"", "and", "label_dict", "[", "slot", "]", "==", "\"4pm\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"16:00\"", "\n", "", "if", "slot", "==", "\"restaurant-book time\"", "and", "label_dict", "[", "slot", "]", "==", "\"8pm\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"20:00\"", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"sitar\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"sitar tandoori\"", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"binh\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"thanh binh\"", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"mahal\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"mahal of cambridge\"", "\n", "\n", "# attraction", "\n", "", "if", "slot", "==", "\"attraction-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"scudamore\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"scudamores punting co\"", "\n", "", "if", "slot", "==", "\"attraction-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"salsa\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"club salsa\"", "\n", "", "if", "slot", "==", "\"attraction-name\"", "and", "label_dict", "[", "slot", "]", "in", "[", "\"abbey pool\"", ",", "\"abbey pool and astroturf\"", "]", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"abbey pool and astroturf pitch\"", "\n", "", "if", "slot", "==", "\"attraction-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"cherry hinton hall\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"cherry hinton hall and grounds\"", "\n", "", "if", "slot", "==", "\"attraction-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"trinity street college\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"trinity college\"", "\n", "", "if", "slot", "==", "\"attraction-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"the wandlebury\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"wandlebury country park\"", "\n", "", "if", "slot", "==", "\"attraction-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"king hedges learner pool\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"kings hedges learner pool\"", "\n", "", "if", "slot", "==", "\"attraction-name\"", "and", "label_dict", "[", "slot", "]", "in", "[", "\"botanic gardens\"", ",", "\"cambridge botanic gardens\"", "]", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"cambridge university botanic gardens\"", "\n", "", "if", "slot", "==", "\"attraction-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"soultree\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"soul tree nightclub\"", "\n", "", "if", "slot", "==", "\"attraction-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"queens\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"queen's college\"", "\n", "", "if", "slot", "==", "\"attraction-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"sheeps green\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"sheep's green and lammas land park fen causeway\"", "\n", "", "if", "slot", "==", "\"attraction-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"jesus green\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"jesus green outdoor pool\"", "\n", "", "if", "slot", "==", "\"attraction-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"adc\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"adc theatre\"", "\n", "", "if", "slot", "==", "\"attraction-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"hobsons house\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"hobson house\"", "\n", "", "if", "slot", "==", "\"attraction-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"cafe jello museum\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"cafe jello gallery\"", "\n", "", "if", "slot", "==", "\"attraction-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"whippple museum\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"whipple museum of the history of science\"", "\n", "", "if", "slot", "==", "\"attraction-type\"", "and", "label_dict", "[", "slot", "]", "==", "\"boating\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"boat\"", "\n", "", "if", "slot", "==", "\"attraction-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"peoples portraits exhibition\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"people's portraits exhibition at girton college\"", "\n", "", "if", "slot", "==", "\"attraction-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"lammas land park\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"sheep's green and lammas land park fen causeway\"", "\n", "\n", "# taxi", "\n", "", "if", "slot", "in", "[", "\"taxi-destination\"", ",", "\"taxi-departure\"", "]", "and", "label_dict", "[", "slot", "]", "==", "\"meze bar\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"meze bar restaurant\"", "\n", "", "if", "slot", "in", "[", "\"taxi-destination\"", ",", "\"taxi-departure\"", "]", "and", "label_dict", "[", "slot", "]", "==", "\"el shaddia guest house\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"el shaddai\"", "\n", "", "if", "slot", "==", "\"taxi-departure\"", "and", "label_dict", "[", "slot", "]", "==", "\"centre of town at my hotel\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"hotel\"", "\n", "\n", "# train", "\n", "", "if", "slot", "==", "\"train-departure\"", "and", "label_dict", "[", "slot", "]", "in", "[", "\"liverpool\"", ",", "\"london liverpool\"", "]", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"london liverpool street\"", "\n", "", "if", "slot", "==", "\"train-destination\"", "and", "label_dict", "[", "slot", "]", "==", "\"liverpool street\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"london liverpool street\"", "\n", "", "if", "slot", "==", "\"train-departure\"", "and", "label_dict", "[", "slot", "]", "==", "\"alpha milton\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"alpha-milton\"", "\n", "\n", "# hotel", "\n", "", "if", "slot", "==", "\"hotel-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"el shaddia guest house\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"el shaddai\"", "\n", "", "if", "slot", "==", "\"hotel-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"alesbray lodge guest house\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"aylesbray lodge guest house\"", "\n", "", "if", "slot", "==", "\"hotel-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"the gonvile hotel\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"the gonville hotel\"", "\n", "", "if", "slot", "==", "\"hotel-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"no\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"none\"", "\n", "", "if", "slot", "==", "\"hotel-name\"", "and", "label_dict", "[", "slot", "]", "in", "[", "\"holiday inn\"", ",", "\"holiday inn cambridge\"", "]", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"express by holiday inn cambridge\"", "\n", "", "if", "slot", "==", "\"hotel-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"wartworth\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"warkworth house\"", "\n", "\n", "# Suppose to be a wrong annotation", "\n", "", "if", "slot", "==", "\"restaurant-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"south\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"none\"", "\n", "", "if", "slot", "==", "\"attraction-type\"", "and", "label_dict", "[", "slot", "]", "==", "\"churchill college\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"none\"", "\n", "", "if", "slot", "==", "\"attraction-name\"", "and", "label_dict", "[", "slot", "]", "==", "\"boat\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"none\"", "\n", "", "if", "slot", "==", "\"attraction-type\"", "and", "label_dict", "[", "slot", "]", "==", "\"museum kettles yard\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"none\"", "\n", "", "if", "slot", "==", "\"attraction-type\"", "and", "label_dict", "[", "slot", "]", "==", "\"hotel\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"none\"", "\n", "", "if", "slot", "==", "\"attraction-type\"", "and", "label_dict", "[", "slot", "]", "==", "\"camboats\"", ":", "\n", "                    ", "label_dict", "[", "slot", "]", "=", "\"boat\"", "\n", "\n", "\n", "# TODO: Need to check with dialogue data to deal with strange labels before", "\n", "\n", "# if slot == \"restaurant-name\" and label_dict[slot] == \"eraina and michaelhouse cafe\": ", "\n", "#    label_dict[slot] = \"eraina|michaelhouse cafe\"", "\n", "# if slot == \"attraction-name\" and label_dict[slot] == \"gonville hotel\": ", "\n", "#    label_dict[slot] = \"none\"", "\n", "# if label_dict[slot] == \"good luck\": ", "\n", "#    label_dict[slot] = \"the good luck chinese food takeaway\"", "\n", "# if slot == \"restaurant-book time\" and label_dict[slot] == \"9\": ", "\n", "#    label_dict[slot] = \"21:00\"", "\n", "# if slot == \"taxi-departure\" and label_dict[slot] == \"girton college\": ", "\n", "#    label_dict[slot] = \"people's portraits exhibition at girton college\"", "\n", "# if slot == \"restaurant-name\" and label_dict[slot] == \"molecular gastronomy\": ", "\n", "#    label_dict[slot] = \"none\"", "\n", "# [Info] Adding Slot: restaurant-name with value: primavera", "\n", "# [Info] Adding Slot: train-departure with value: huntingdon", "\n", "# [Info] Adding Slot: attraction-name with value: aylesbray lodge guest house", "\n", "# [Info] Adding Slot: attraction-name with value: gallery", "\n", "# [Info] Adding Slot: hotel-name with value: eraina", "\n", "# [Info] Adding Slot: restaurant-name with value: india west", "\n", "# [Info] Adding Slot: restaurant-name with value: autumn house", "\n", "# [Info] Adding Slot: train-destination with value: norway", "\n", "# [Info] Adding Slot: attraction-name with value: cinema cinema", "\n", "# [Info] Adding Slot: hotel-name with value: lan hon", "\n", "# [Info] Adding Slot: restaurant-food with value: sushi", "\n", "# [Info] Adding Slot: attraction-name with value: university arms hotel", "\n", "# [Info] Adding Slot: train-departure with value: stratford", "\n", "# [Info] Adding Slot: attraction-name with value: history of science museum", "\n", "# [Info] Adding Slot: restaurant-name with value: nil", "\n", "# [Info] Adding Slot: train-leaveat with value: 9", "\n", "# [Info] Adding Slot: restaurant-name with value: ashley hotel", "\n", "# [Info] Adding Slot: taxi-destination with value: the cambridge shop", "\n", "# [Info] Adding Slot: hotel-name with value: acorn place", "\n", "# [Info] Adding Slot: restaurant-name with value: de luca cucina and bar riverside brasserie", "\n", "# [Info] Adding Slot: hotel-name with value: super 5", "\n", "# [Info] Adding Slot: attraction-name with value: archway house", "\n", "# [Info] Adding Slot: train-arriveby with value: 8", "\n", "# [Info] Adding Slot: train-leaveat with value: 10", "\n", "# [Info] Adding Slot: restaurant-book time with value: 9", "\n", "# [Info] Adding Slot: hotel-name with value: nothamilton lodge", "\n", "# [Info] Adding Slot: attraction-name with value: st christs college", "\n", "\n", "", "", "", "", "return", "label_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.models.multi_class_classifier.multi_class_classifier.__init__": [[18, 63], ["torch.Module.__init__", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "args[].from_pretrained", "torch.Linear", "torch.Linear", "torch.Linear", "AdamW", "print", "multi_class_classifier.multi_class_classifier.utterance_encoder.parameters", "torch.Linear", "torch.Linear", "torch.Linear", "multi_class_classifier.multi_class_classifier.__init__.get_optimizer_grouped_parameters"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.models.dual_encoder_ranking.dual_encoder_ranking.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "#, num_labels, device):", "\n", "        ", "super", "(", "multi_class_classifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "hidden_dim", "=", "args", "[", "\"hdd_size\"", "]", "\n", "self", ".", "rnn_num_layers", "=", "args", "[", "\"num_rnn_layers\"", "]", "\n", "self", ".", "num_labels", "=", "args", "[", "\"num_labels\"", "]", "\n", "self", ".", "xeloss", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "n_gpu", "=", "args", "[", "\"n_gpu\"", "]", "\n", "self", ".", "training", "=", "args", "[", "\"do_train\"", "]", "\n", "\n", "### Utterance Encoder", "\n", "self", ".", "utterance_encoder", "=", "args", "[", "\"model_class\"", "]", ".", "from_pretrained", "(", "self", ".", "args", "[", "\"model_name_or_path\"", "]", ")", "\n", "\n", "self", ".", "bert_output_dim", "=", "args", "[", "\"config\"", "]", ".", "hidden_size", "\n", "\n", "if", "self", ".", "args", "[", "\"fix_encoder\"", "]", ":", "\n", "            ", "print", "(", "\"[Info] Fixing Encoder...\"", ")", "\n", "for", "p", "in", "self", ".", "utterance_encoder", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "if", "self", ".", "args", "[", "\"more_linear_mapping\"", "]", ":", "\n", "            ", "self", ".", "one_more_layer", "=", "nn", ".", "Linear", "(", "self", ".", "bert_output_dim", ",", "self", ".", "bert_output_dim", ")", "\n", "\n", "", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "self", ".", "bert_output_dim", ",", "self", ".", "num_labels", ")", "\n", "\n", "## Prepare Optimizer", "\n", "def", "get_optimizer_grouped_parameters", "(", "model", ")", ":", "\n", "            ", "param_optimizer", "=", "[", "(", "n", ",", "p", ")", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.01", ",", "\n", "'lr'", ":", "args", "[", "\"learning_rate\"", "]", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", ",", "\n", "'lr'", ":", "args", "[", "\"learning_rate\"", "]", "}", ",", "\n", "]", "\n", "return", "optimizer_grouped_parameters", "\n", "\n", "", "if", "self", ".", "n_gpu", "==", "1", ":", "\n", "            ", "optimizer_grouped_parameters", "=", "get_optimizer_grouped_parameters", "(", "self", ")", "\n", "", "else", ":", "\n", "            ", "optimizer_grouped_parameters", "=", "get_optimizer_grouped_parameters", "(", "self", ".", "module", ")", "\n", "\n", "\n", "", "self", ".", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "args", "[", "\"learning_rate\"", "]", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.models.multi_class_classifier.multi_class_classifier.optimize": [[65, 69], ["multi_class_classifier.multi_class_classifier.loss_grad.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "multi_class_classifier.multi_class_classifier.optimizer.step", "multi_class_classifier.multi_class_classifier.parameters"], "methods", ["None"], ["", "def", "optimize", "(", "self", ")", ":", "\n", "        ", "self", ".", "loss_grad", ".", "backward", "(", ")", "\n", "clip_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "parameters", "(", ")", ",", "self", ".", "args", "[", "\"grad_clip\"", "]", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.models.multi_class_classifier.multi_class_classifier.forward": [[70, 194], ["multi_class_classifier.multi_class_classifier.optimizer.zero_grad", "multi_class_classifier.multi_class_classifier.classifier", "len", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "hidden_norm.repeat().transpose.repeat().transpose.repeat().transpose", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Softmax.", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "multi_class_classifier.multi_class_classifier.optimizer.zero_grad", "multi_class_classifier.multi_class_classifier.classifier", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "nn.CrossEntropyLoss.backward", "multi_class_classifier.multi_class_classifier.one_more_layer", "multi_class_classifier.multi_class_classifier.classifier", "multi_class_classifier.multi_class_classifier.classifier", "multi_class_classifier.multi_class_classifier.xeloss", "multi_class_classifier.multi_class_classifier.xeloss", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss.", "nn.CrossEntropyLoss.mean", "multi_class_classifier.multi_class_classifier.optimize", "nn.CrossEntropyLoss.item", "predictions.detach().cpu().tolist", "data[].detach().cpu().numpy", "confidence.detach().cpu().tolist", "torch.CrossEntropyLoss.", "torch.CrossEntropyLoss.", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "hidden.mean", "hidden_norm.repeat().transpose.repeat().transpose.repeat", "data[].repeat", "weights.cuda.cuda.cuda", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "multi_class_classifier.multi_class_classifier.utterance_encoder", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "hidden.mean", "multi_class_classifier.multi_class_classifier.utterance_encoder", "transformer_outputs.mean", "transformer_outputs.mean.size", "transformer_outputs.mean.repeat", "transformer_outputs.mean.repeat", "weights.cuda.cuda.append", "predictions.detach().cpu", "data[].detach().cpu", "confidence.detach().cpu", "multi_class_classifier.multi_class_classifier.utterance_encoder", "multi_class_classifier.multi_class_classifier.utterance_encoder", "transformer_outputs.mean", "multi_class_classifier.multi_class_classifier.utterance_encoder.transformer", "multi_class_classifier.multi_class_classifier.utterance_encoder", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "weights.cuda.cuda.append", "weights.cuda.cuda.append", "multi_class_classifier.multi_class_classifier.utterance_encoder.transformer", "multi_class_classifier.multi_class_classifier.utterance_encoder", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "predictions.detach", "data[].detach", "confidence.detach", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "transformer_outputs.mean.repeat().size", "transformer_outputs.mean.repeat().size", "transformer_outputs.mean.repeat", "transformer_outputs.mean.repeat"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.models.dual_encoder_ranking.dual_encoder_ranking.optimize"], ["", "def", "forward", "(", "self", ",", "data", ",", "ind_to_conf_map", "=", "None", ",", "evaluate_gradient", "=", "False", ",", "use_truth", "=", "True", ")", ":", "\n", "\n", "        ", "if", "not", "evaluate_gradient", ":", "\n", "            ", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "inputs", "=", "{", "\"input_ids\"", ":", "data", "[", "self", ".", "args", "[", "\"input_name\"", "]", "]", ",", "\"attention_mask\"", ":", "(", "data", "[", "self", ".", "args", "[", "\"input_name\"", "]", "]", ">", "0", ")", ".", "long", "(", ")", "}", "\n", "\n", "if", "self", ".", "args", "[", "\"fix_encoder\"", "]", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "if", "\"gpt2\"", "in", "self", ".", "args", "[", "\"model_type\"", "]", ":", "\n", "                        ", "hidden", "=", "self", ".", "utterance_encoder", "(", "**", "inputs", ")", "[", "0", "]", "\n", "hidden_head", "=", "hidden", ".", "mean", "(", "1", ")", "\n", "", "elif", "self", ".", "args", "[", "\"model_type\"", "]", "==", "\"dialogpt\"", ":", "\n", "                        ", "transformer_outputs", "=", "self", ".", "utterance_encoder", ".", "transformer", "(", "\n", "inputs", "[", "\"input_ids\"", "]", ",", "\n", "attention_mask", "=", "(", "inputs", "[", "\"input_ids\"", "]", ">", "0", ")", ".", "long", "(", ")", ")", "[", "0", "]", "\n", "hidden_head", "=", "transformer_outputs", ".", "mean", "(", "1", ")", "\n", "", "else", ":", "\n", "                        ", "hidden", "=", "self", ".", "utterance_encoder", "(", "**", "inputs", ")", "[", "0", "]", "\n", "hidden_head", "=", "hidden", "[", ":", ",", "0", ",", ":", "]", "\n", "", "", "", "else", ":", "\n", "                ", "if", "\"gpt2\"", "in", "self", ".", "args", "[", "\"model_type\"", "]", ":", "\n", "                    ", "hidden", "=", "self", ".", "utterance_encoder", "(", "**", "inputs", ")", "[", "0", "]", "\n", "hidden_head", "=", "hidden", ".", "mean", "(", "1", ")", "\n", "", "elif", "self", ".", "args", "[", "\"model_type\"", "]", "==", "\"dialogpt\"", ":", "\n", "                    ", "transformer_outputs", "=", "self", ".", "utterance_encoder", ".", "transformer", "(", "\n", "inputs", "[", "\"input_ids\"", "]", ",", "\n", "attention_mask", "=", "(", "inputs", "[", "\"input_ids\"", "]", ">", "0", ")", ".", "long", "(", ")", ")", "[", "0", "]", "\n", "hidden_head", "=", "transformer_outputs", ".", "mean", "(", "1", ")", "\n", "", "else", ":", "\n", "                    ", "hidden", "=", "self", ".", "utterance_encoder", "(", "**", "inputs", ")", "[", "0", "]", "\n", "hidden_head", "=", "hidden", "[", ":", ",", "0", ",", ":", "]", "\n", "\n", "# loss", "\n", "", "", "if", "self", ".", "args", "[", "\"more_linear_mapping\"", "]", ":", "\n", "                ", "hidden_head", "=", "self", ".", "one_more_layer", "(", "hidden_head", ")", "\n", "\n", "", "logits", "=", "self", ".", "classifier", "(", "hidden_head", ")", "\n", "\n", "batch_size", "=", "len", "(", "data", "[", "self", ".", "args", "[", "\"task_name\"", "]", "]", ")", "\n", "noise_ratio", "=", "1", "\n", "hidden_norm", "=", "torch", ".", "norm", "(", "hidden_head", ",", "dim", "=", "1", ")", "\n", "\n", "hidden_norm", "=", "hidden_norm", ".", "repeat", "(", "hidden_head", ".", "size", "(", "1", ")", ",", "1", ")", ".", "transpose", "(", "0", ",", "1", ")", "\n", "if", "self", ".", "args", "[", "'noise_weight_type'", "]", "==", "'samplewise'", ":", "\n", "                ", "logits_noised", "=", "self", ".", "classifier", "(", "hidden_head", ".", "repeat", "(", "noise_ratio", ",", "1", ")", "+", "self", ".", "args", "[", "'lambda'", "]", "*", "hidden_norm", "*", "torch", ".", "randn", "(", "hidden_head", ".", "repeat", "(", "noise_ratio", ",", "1", ")", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", ")", "\n", "", "if", "self", ".", "args", "[", "'noise_weight_type'", "]", "==", "'elementwise'", ":", "\n", "                ", "logits_noised", "=", "self", ".", "classifier", "(", "\n", "hidden_head", ".", "repeat", "(", "noise_ratio", ",", "1", ")", "+", "self", ".", "args", "[", "'lambda'", "]", "*", "torch", ".", "abs", "(", "hidden_head", ")", "*", "torch", ".", "randn", "(", "\n", "hidden_head", ".", "repeat", "(", "noise_ratio", ",", "1", ")", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", ")", "\n", "\n", "\n", "", "if", "self", ".", "args", "[", "'embedding_noise'", "]", ":", "# add gaussian noise to embedding", "\n", "                ", "loss1", "=", "self", ".", "xeloss", "(", "logits", ",", "data", "[", "self", ".", "args", "[", "\"task_name\"", "]", "]", ")", "\n", "loss2", "=", "self", ".", "xeloss", "(", "logits_noised", ",", "data", "[", "self", ".", "args", "[", "\"task_name\"", "]", "]", ".", "repeat", "(", "noise_ratio", ")", ")", "\n", "loss", "=", "(", "loss1", "*", "batch_size", "+", "loss2", "*", "batch_size", "*", "noise_ratio", ")", "/", "(", "noise_ratio", "+", "1", ")", "\n", "\n", "", "else", ":", "\n", "                ", "weights", "=", "[", "]", "\n", "for", "idx", "in", "data", "[", "'index'", "]", ":", "\n", "                    ", "if", "ind_to_conf_map", "and", "idx", "in", "ind_to_conf_map", ":", "\n", "                        ", "if", "self", ".", "args", "[", "'confidence_weighting'", "]", ":", "\n", "                            ", "weights", ".", "append", "(", "self", ".", "args", "[", "'lambda'", "]", "*", "ind_to_conf_map", "[", "idx", "]", ")", "# weight samples based on confidence", "\n", "", "else", ":", "\n", "                            ", "weights", ".", "append", "(", "self", ".", "args", "[", "'lambda'", "]", ")", "# weight pseudo labeled samples by lambda", "\n", "", "", "else", ":", "\n", "                        ", "weights", ".", "append", "(", "1", ")", "\n", "", "", "weights", "=", "torch", ".", "FloatTensor", "(", "weights", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "weights", "=", "weights", ".", "cuda", "(", ")", "\n", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", "\n", "losses", "=", "criterion", "(", "logits", ",", "data", "[", "self", ".", "args", "[", "\"task_name\"", "]", "]", ")", "\n", "\n", "loss", "=", "losses", "*", "weights", "\n", "loss", "=", "loss", ".", "mean", "(", ")", "\n", "\n", "", "if", "self", ".", "training", ":", "\n", "                ", "self", ".", "loss_grad", "=", "loss", "\n", "self", ".", "optimize", "(", ")", "\n", "\n", "", "softmax", "=", "nn", ".", "Softmax", "(", "-", "1", ")", "\n", "prob", "=", "softmax", "(", "logits", ")", "\n", "confidence", ",", "predictions", "=", "torch", ".", "max", "(", "prob", ",", "dim", "=", "-", "1", ")", "\n", "\n", "outputs", "=", "{", "\"loss\"", ":", "loss", ".", "item", "(", ")", ",", "\n", "\"logits\"", ":", "logits", ",", "\n", "\"pred\"", ":", "predictions", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ",", "\n", "\"label\"", ":", "data", "[", "self", ".", "args", "[", "\"task_name\"", "]", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "\"prob\"", ":", "prob", ",", "\n", "'confidence'", ":", "confidence", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "}", "\n", "return", "outputs", "\n", "\n", "# only evaluate the gradient wrt input", "\n", "", "else", ":", "\n", "            ", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "inputs", "=", "{", "\"input_ids\"", ":", "data", "[", "self", ".", "args", "[", "\"input_name\"", "]", "]", ",", "\n", "\"attention_mask\"", ":", "(", "data", "[", "self", ".", "args", "[", "\"input_name\"", "]", "]", ">", "0", ")", ".", "long", "(", ")", "}", "\n", "\n", "if", "self", ".", "args", "[", "\"fix_encoder\"", "]", ":", "\n", "                ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "hidden", "=", "self", ".", "utterance_encoder", "(", "**", "inputs", ")", "[", "0", "]", "\n", "hidden_head", "=", "hidden", "[", ":", ",", "0", ",", ":", "]", "\n", "", "", "else", ":", "\n", "                ", "hidden", "=", "self", ".", "utterance_encoder", "(", "**", "inputs", ")", "[", "0", "]", "\n", "hidden_head", "=", "hidden", "[", ":", ",", "0", ",", ":", "]", "\n", "\n", "", "logits", "=", "self", ".", "classifier", "(", "hidden_head", ")", "\n", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'mean'", ")", "\n", "if", "use_truth", ":", "\n", "                ", "loss", "=", "criterion", "(", "logits", ",", "data", "[", "self", ".", "args", "[", "\"task_name\"", "]", "]", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "criterion", "(", "logits", ",", "torch", ".", "argmax", "(", "logits", ",", "-", "1", ")", ")", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "outputs", "=", "{", "\n", "\"logits\"", ":", "logits", ",", "\n", "\"label\"", ":", "data", "[", "self", ".", "args", "[", "\"task_name\"", "]", "]", "\n", "}", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.models.multi_class_classifier.multi_class_classifier.evaluation": [[195, 229], ["numpy.array", "numpy.array", "range", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "len", "numpy.array.append", "numpy.array.append", "numpy.array.append", "numpy.array.append", "int", "int"], "methods", ["None"], ["", "", "def", "evaluation", "(", "self", ",", "preds", ",", "labels", ")", ":", "\n", "        ", "preds", "=", "np", ".", "array", "(", "preds", ")", "\n", "labels", "=", "np", ".", "array", "(", "labels", ")", "\n", "\n", "if", "self", ".", "args", "[", "\"task_name\"", "]", "==", "\"intent\"", ":", "\n", "            ", "oos_idx", "=", "self", ".", "args", "[", "\"unified_meta\"", "]", "[", "\"intent\"", "]", "[", "\"oos\"", "]", "\n", "acc", "=", "(", "preds", "==", "labels", ")", ".", "mean", "(", ")", "\n", "oos_labels", ",", "oos_preds", "=", "[", "]", ",", "[", "]", "\n", "ins_labels", ",", "ins_preds", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "preds", ")", ")", ":", "\n", "                ", "if", "labels", "[", "i", "]", "!=", "oos_idx", ":", "\n", "                    ", "ins_preds", ".", "append", "(", "preds", "[", "i", "]", ")", "\n", "ins_labels", ".", "append", "(", "labels", "[", "i", "]", ")", "\n", "\n", "", "oos_labels", ".", "append", "(", "int", "(", "labels", "[", "i", "]", "==", "oos_idx", ")", ")", "\n", "oos_preds", ".", "append", "(", "int", "(", "preds", "[", "i", "]", "==", "oos_idx", ")", ")", "\n", "\n", "", "ins_preds", "=", "np", ".", "array", "(", "ins_preds", ")", "\n", "ins_labels", "=", "np", ".", "array", "(", "ins_labels", ")", "\n", "oos_preds", "=", "np", ".", "array", "(", "oos_preds", ")", "\n", "oos_labels", "=", "np", ".", "array", "(", "oos_labels", ")", "\n", "ins_acc", "=", "(", "ins_preds", "==", "ins_labels", ")", ".", "mean", "(", ")", "\n", "oos_acc", "=", "(", "oos_preds", "==", "oos_labels", ")", ".", "mean", "(", ")", "\n", "\n", "# for oos samples recall = tp / (tp + fn) ", "\n", "TP", "=", "(", "oos_labels", "&", "oos_preds", ")", ".", "sum", "(", ")", "\n", "FN", "=", "(", "(", "oos_labels", "-", "oos_preds", ")", ">", "0", ")", ".", "sum", "(", ")", "\n", "recall", "=", "TP", "/", "(", "TP", "+", "FN", ")", "\n", "results", "=", "{", "\"acc\"", ":", "acc", ",", "\"ins_acc\"", ":", "ins_acc", ",", "\"oos_acc\"", ":", "oos_acc", ",", "\"oos_recall\"", ":", "recall", "}", "\n", "", "else", ":", "\n", "            ", "acc", "=", "(", "preds", "==", "labels", ")", ".", "mean", "(", ")", "\n", "results", "=", "{", "\"acc\"", ":", "acc", "}", "\n", "\n", "", "return", "results", "", "", "", ""]], "home.repos.pwc.inspect_result.mifei_st-tod.models.multi_label_classifier.multi_label_classifier.__init__": [[18, 64], ["torch.Module.__init__", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "args[].from_pretrained", "torch.Linear", "torch.Linear", "torch.Linear", "print", "AdamW", "print", "multi_label_classifier.multi_label_classifier.utterance_encoder.parameters", "torch.Linear", "torch.Linear", "torch.Linear", "multi_label_classifier.multi_label_classifier.__init__.get_optimizer_grouped_parameters"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.models.dual_encoder_ranking.dual_encoder_ranking.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "multi_label_classifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "hidden_dim", "=", "args", "[", "\"hdd_size\"", "]", "\n", "self", ".", "rnn_num_layers", "=", "args", "[", "\"num_rnn_layers\"", "]", "\n", "self", ".", "num_labels", "=", "args", "[", "\"num_labels\"", "]", "\n", "self", ".", "bce", "=", "nn", ".", "BCELoss", "(", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "n_gpu", "=", "args", "[", "\"n_gpu\"", "]", "\n", "\n", "### Utterance Encoder", "\n", "self", ".", "utterance_encoder", "=", "args", "[", "\"model_class\"", "]", ".", "from_pretrained", "(", "self", ".", "args", "[", "\"model_name_or_path\"", "]", ")", "\n", "\n", "self", ".", "bert_output_dim", "=", "args", "[", "\"config\"", "]", ".", "hidden_size", "\n", "\n", "if", "self", ".", "args", "[", "\"fix_encoder\"", "]", ":", "\n", "            ", "print", "(", "\"[Info] fix_encoder\"", ")", "\n", "for", "p", "in", "self", ".", "utterance_encoder", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "", "", "if", "self", ".", "args", "[", "\"more_linear_mapping\"", "]", ":", "\n", "            ", "self", ".", "one_more_layer", "=", "nn", ".", "Linear", "(", "self", ".", "bert_output_dim", ",", "self", ".", "bert_output_dim", ")", "\n", "\n", "", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "self", ".", "bert_output_dim", ",", "self", ".", "num_labels", ")", "\n", "print", "(", "\"self.classifier\"", ",", "self", ".", "bert_output_dim", ",", "self", ".", "num_labels", ")", "\n", "\n", "## Prepare Optimizer", "\n", "def", "get_optimizer_grouped_parameters", "(", "model", ")", ":", "\n", "            ", "param_optimizer", "=", "[", "(", "n", ",", "p", ")", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.01", ",", "\n", "'lr'", ":", "args", "[", "\"learning_rate\"", "]", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", ",", "\n", "'lr'", ":", "args", "[", "\"learning_rate\"", "]", "}", ",", "\n", "]", "\n", "return", "optimizer_grouped_parameters", "\n", "\n", "", "if", "self", ".", "n_gpu", "==", "1", ":", "\n", "            ", "optimizer_grouped_parameters", "=", "get_optimizer_grouped_parameters", "(", "self", ")", "\n", "", "else", ":", "\n", "            ", "optimizer_grouped_parameters", "=", "get_optimizer_grouped_parameters", "(", "self", ".", "module", ")", "\n", "\n", "\n", "", "self", ".", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "args", "[", "\"learning_rate\"", "]", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.models.multi_label_classifier.multi_label_classifier.optimize": [[65, 69], ["multi_label_classifier.multi_label_classifier.loss_grad.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "multi_label_classifier.multi_label_classifier.optimizer.step", "multi_label_classifier.multi_label_classifier.parameters"], "methods", ["None"], ["", "def", "optimize", "(", "self", ")", ":", "\n", "        ", "self", ".", "loss_grad", ".", "backward", "(", ")", "\n", "clip_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "parameters", "(", ")", ",", "self", ".", "args", "[", "\"grad_clip\"", "]", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.models.multi_label_classifier.multi_label_classifier.forward": [[70, 181], ["multi_label_classifier.multi_label_classifier.optimizer.zero_grad", "multi_label_classifier.multi_label_classifier.classifier", "multi_label_classifier.multi_label_classifier.sigmoid", "len", "multi_label_classifier.multi_label_classifier.classifier", "multi_label_classifier.multi_label_classifier.sigmoid", "enumerate", "multi_label_classifier.multi_label_classifier.optimizer.zero_grad", "multi_label_classifier.multi_label_classifier.classifier", "multi_label_classifier.multi_label_classifier.sigmoid", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "nn.BCELoss.backward", "hidden.mean", "multi_label_classifier.multi_label_classifier.one_more_layer", "multi_label_classifier.multi_label_classifier.bce", "multi_label_classifier.multi_label_classifier.bce", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "weights.cuda.cuda.view().repeat", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss", "torch.BCELoss.", "weighted_loss.mean", "multi_label_classifier.multi_label_classifier.optimize", "nn.BCELoss.item", "predictions.detach().cpu().tolist", "data[].detach().cpu().numpy", "multi_label_classifier.multi_label_classifier.utterance_encoder", "multi_label_classifier.multi_label_classifier.one_more_layer", "torch.BCELoss.", "torch.BCELoss.", "nn.BCELoss.item", "predictions.detach().cpu().tolist", "data[].detach().cpu().numpy", "multi_label_classifier.multi_label_classifier.utterance_encoder", "transformer_outputs.mean", "transformer_outputs.mean.repeat", "data[].repeat", "weights.cuda.cuda.cuda", "multi_label_classifier.multi_label_classifier.size", "sum", "avg_pre_prob.append", "avg_pre_prob.append", "predictions.float", "multi_label_classifier.multi_label_classifier.utterance_encoder.transformer", "multi_label_classifier.multi_label_classifier.utterance_encoder", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "weights.cuda.cuda.append", "weights.cuda.cuda.view", "[].mean().item", "predictions.detach().cpu", "data[].detach().cpu", "predictions.detach().cpu", "data[].detach().cpu", "weights.cuda.cuda.append", "weights.cuda.cuda.append", "multi_label_classifier.multi_label_classifier.size", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "[].mean", "predictions.detach", "data[].detach", "predictions.detach", "data[].detach", "transformer_outputs.mean.repeat().size", "transformer_outputs.mean.repeat"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.models.dual_encoder_ranking.dual_encoder_ranking.optimize"], ["", "def", "forward", "(", "self", ",", "data", ",", "ind_to_conf_map", "=", "None", ",", "evaluate_gradient", "=", "False", ",", "use_truth", "=", "True", ")", ":", "\n", "\n", "        ", "if", "not", "evaluate_gradient", ":", "\n", "            ", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "inputs", "=", "{", "\"input_ids\"", ":", "data", "[", "self", ".", "args", "[", "\"input_name\"", "]", "]", ",", "\"attention_mask\"", ":", "(", "data", "[", "self", ".", "args", "[", "\"input_name\"", "]", "]", ">", "0", ")", ".", "long", "(", ")", "}", "\n", "\n", "if", "\"gpt2\"", "in", "self", ".", "args", "[", "\"model_type\"", "]", ":", "\n", "                ", "hidden", "=", "self", ".", "utterance_encoder", "(", "**", "inputs", ")", "[", "0", "]", "\n", "hidden_head", "=", "hidden", ".", "mean", "(", "1", ")", "\n", "", "elif", "self", ".", "args", "[", "\"model_type\"", "]", "==", "\"dialogpt\"", ":", "\n", "                ", "transformer_outputs", "=", "self", ".", "utterance_encoder", ".", "transformer", "(", "\n", "inputs", "[", "\"input_ids\"", "]", ",", "\n", "attention_mask", "=", "(", "inputs", "[", "\"input_ids\"", "]", ">", "0", ")", ".", "long", "(", ")", ")", "[", "0", "]", "\n", "hidden_head", "=", "transformer_outputs", ".", "mean", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "hidden", "=", "self", ".", "utterance_encoder", "(", "**", "inputs", ")", "[", "0", "]", "\n", "hidden_head", "=", "hidden", "[", ":", ",", "0", ",", ":", "]", "\n", "\n", "# loss", "\n", "", "if", "self", ".", "args", "[", "\"more_linear_mapping\"", "]", ":", "\n", "                ", "hidden_head", "=", "self", ".", "one_more_layer", "(", "hidden_head", ")", "\n", "\n", "", "logits", "=", "self", ".", "classifier", "(", "hidden_head", ")", "\n", "prob", "=", "self", ".", "sigmoid", "(", "logits", ")", "\n", "\n", "\n", "batch_size", "=", "len", "(", "data", "[", "self", ".", "args", "[", "\"task_name\"", "]", "]", ")", "\n", "noise_ratio", "=", "1", "\n", "logits_noised", "=", "self", ".", "classifier", "(", "hidden_head", ".", "repeat", "(", "noise_ratio", ",", "1", ")", "+", "1.0", "*", "torch", ".", "randn", "(", "\n", "hidden_head", ".", "repeat", "(", "noise_ratio", ",", "1", ")", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", ")", "\n", "prob_noised", "=", "self", ".", "sigmoid", "(", "logits_noised", ")", "\n", "\n", "if", "self", ".", "args", "[", "'embedding_noise'", "]", ":", "# add gaussian noise to embedding", "\n", "                ", "loss1", "=", "self", ".", "bce", "(", "prob", ",", "data", "[", "self", ".", "args", "[", "\"task_name\"", "]", "]", ")", "\n", "loss2", "=", "self", ".", "bce", "(", "prob_noised", ",", "data", "[", "self", ".", "args", "[", "\"task_name\"", "]", "]", ".", "repeat", "(", "noise_ratio", ",", "1", ")", ")", "\n", "loss", "=", "(", "loss1", "*", "batch_size", "+", "loss2", "*", "batch_size", "*", "noise_ratio", ")", "/", "(", "noise_ratio", "+", "1", ")", "\n", "\n", "", "else", ":", "\n", "                ", "weights", "=", "[", "]", "\n", "for", "idx", "in", "data", "[", "'index'", "]", ":", "\n", "                    ", "if", "ind_to_conf_map", "and", "idx", "in", "ind_to_conf_map", ":", "\n", "                        ", "if", "self", ".", "args", "[", "'confidence_weighting'", "]", ":", "\n", "                            ", "weights", ".", "append", "(", "self", ".", "args", "[", "'lambda'", "]", "*", "ind_to_conf_map", "[", "idx", "]", ")", "# weight samples based on confidence", "\n", "", "else", ":", "\n", "                            ", "weights", ".", "append", "(", "self", ".", "args", "[", "'lambda'", "]", ")", "# weight pseudo labeled samples by lambda", "\n", "", "", "else", ":", "\n", "                        ", "weights", ".", "append", "(", "1", ")", "\n", "", "", "weights", "=", "torch", ".", "FloatTensor", "(", "weights", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "weights", "=", "weights", ".", "cuda", "(", ")", "\n", "\n", "weights", "=", "weights", ".", "view", "(", "prob", ".", "size", "(", "0", ")", ",", "-", "1", ")", ".", "repeat", "(", "1", ",", "prob", ".", "size", "(", "1", ")", ")", "\n", "\n", "criterion", "=", "nn", ".", "BCELoss", "(", "reduction", "=", "'none'", ")", "\n", "losses", "=", "criterion", "(", "prob", ",", "data", "[", "self", ".", "args", "[", "\"task_name\"", "]", "]", ")", "\n", "\n", "weighted_loss", "=", "losses", "*", "weights", "\n", "loss", "=", "weighted_loss", ".", "mean", "(", ")", "\n", "\n", "\n", "", "if", "self", ".", "training", ":", "\n", "                ", "self", ".", "loss_grad", "=", "loss", "\n", "self", ".", "optimize", "(", ")", "\n", "\n", "", "predictions", "=", "(", "prob", ">", "0.5", ")", "\n", "avg_pre_prob", "=", "[", "]", "\n", "for", "i", ",", "pred", "in", "enumerate", "(", "predictions", ")", ":", "\n", "                ", "if", "sum", "(", "pred", ")", "==", "0", ":", "\n", "                    ", "avg_pre_prob", ".", "append", "(", "0", ")", "\n", "", "else", ":", "\n", "                    ", "avg_pre_prob", ".", "append", "(", "prob", "[", "i", "]", "[", "pred", "]", ".", "mean", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "", "", "outputs", "=", "{", "\"loss\"", ":", "loss", ".", "item", "(", ")", ",", "\n", "\"pred\"", ":", "predictions", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ",", "\n", "\"label\"", ":", "data", "[", "self", ".", "args", "[", "\"task_name\"", "]", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "'confidence'", ":", "avg_pre_prob", "}", "\n", "\n", "return", "outputs", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "inputs", "=", "{", "\"input_ids\"", ":", "data", "[", "self", ".", "args", "[", "\"input_name\"", "]", "]", ",", "\n", "\"attention_mask\"", ":", "(", "data", "[", "self", ".", "args", "[", "\"input_name\"", "]", "]", ">", "0", ")", ".", "long", "(", ")", "}", "\n", "\n", "hidden", "=", "self", ".", "utterance_encoder", "(", "**", "inputs", ")", "[", "0", "]", "\n", "hidden_head", "=", "hidden", "[", ":", ",", "0", ",", ":", "]", "\n", "\n", "# loss", "\n", "if", "self", ".", "args", "[", "\"more_linear_mapping\"", "]", ":", "\n", "                ", "hidden_head", "=", "self", ".", "one_more_layer", "(", "hidden_head", ")", "\n", "\n", "", "logits", "=", "self", ".", "classifier", "(", "hidden_head", ")", "\n", "prob", "=", "self", ".", "sigmoid", "(", "logits", ")", "\n", "predictions", "=", "(", "prob", ">", "0.5", ")", "\n", "\n", "criterion", "=", "nn", ".", "BCELoss", "(", ")", "\n", "\n", "if", "use_truth", ":", "\n", "                ", "loss", "=", "criterion", "(", "prob", ",", "data", "[", "self", ".", "args", "[", "\"task_name\"", "]", "]", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "criterion", "(", "prob", ",", "predictions", ".", "float", "(", ")", ")", "\n", "", "loss", ".", "backward", "(", ")", "\n", "\n", "outputs", "=", "{", "\"loss\"", ":", "loss", ".", "item", "(", ")", ",", "\n", "\"pred\"", ":", "predictions", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ",", "\n", "\"label\"", ":", "data", "[", "self", ".", "args", "[", "\"task_name\"", "]", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "\"logits\"", ":", "logits", "\n", "}", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.models.multi_label_classifier.multi_label_classifier.evaluation": [[182, 191], ["numpy.array", "numpy.array", "sklearn.metrics.f1_score"], "methods", ["None"], ["", "", "def", "evaluation", "(", "self", ",", "preds", ",", "labels", ")", ":", "\n", "        ", "preds", "=", "np", ".", "array", "(", "preds", ")", "\n", "labels", "=", "np", ".", "array", "(", "labels", ")", "\n", "results", "=", "{", "}", "\n", "for", "avg_name", "in", "[", "'micro'", ",", "'macro'", ",", "'weighted'", ",", "'samples'", "]", ":", "\n", "            ", "my_f1_score", "=", "f1_score", "(", "y_true", "=", "labels", ",", "y_pred", "=", "preds", ",", "average", "=", "avg_name", ")", "\n", "results", "[", "\"f1_{}\"", ".", "format", "(", "avg_name", ")", "]", "=", "my_f1_score", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.models.BERT_DST_Picklist.BeliefTracker.__init__": [[23, 100], ["torch.Module.__init__", "len", "BERT_DST_Picklist.BeliefTracker.slot_value2id_dict.items", "print", "args[].from_pretrained", "args[].from_pretrained", "print", "BERT_DST_Picklist.BeliefTracker.sv_encoder.parameters", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "torch.ModuleList", "BERT_DST_Picklist.BeliefTracker.__init__.get_optimizer_grouped_parameters"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.models.dual_encoder_ranking.dual_encoder_ranking.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "BeliefTracker", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "n_gpu", "=", "args", "[", "\"n_gpu\"", "]", "\n", "self", ".", "hidden_dim", "=", "args", "[", "\"hdd_size\"", "]", "\n", "self", ".", "rnn_num_layers", "=", "args", "[", "\"num_rnn_layers\"", "]", "\n", "self", ".", "zero_init_rnn", "=", "args", "[", "\"zero_init_rnn\"", "]", "\n", "self", ".", "num_direct", "=", "2", "if", "self", ".", "args", "[", "\"bidirect\"", "]", "else", "1", "\n", "self", ".", "num_labels", "=", "[", "len", "(", "v", ")", "for", "k", ",", "v", "in", "args", "[", "\"unified_meta\"", "]", "[", "\"slots\"", "]", ".", "items", "(", ")", "]", "\n", "self", ".", "num_slots", "=", "len", "(", "self", ".", "num_labels", ")", "\n", "self", ".", "tokenizer", "=", "args", "[", "\"tokenizer\"", "]", "\n", "\n", "self", ".", "slots", "=", "[", "k", "for", "k", ",", "v", "in", "self", ".", "args", "[", "\"unified_meta\"", "]", "[", "\"slots\"", "]", ".", "items", "(", ")", "]", "\n", "self", ".", "slot_value2id_dict", "=", "self", ".", "args", "[", "\"unified_meta\"", "]", "[", "\"slots\"", "]", "\n", "self", ".", "slot_id2value_dict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "self", ".", "slot_value2id_dict", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "slot_id2value_dict", "[", "k", "]", "=", "{", "vv", ":", "kk", "for", "kk", ",", "vv", "in", "v", ".", "items", "(", ")", "}", "\n", "\n", "", "print", "(", "\"self.num_slots\"", ",", "self", ".", "num_slots", ")", "\n", "\n", "### Utterance Encoder", "\n", "self", ".", "utterance_encoder", "=", "args", "[", "\"model_class\"", "]", ".", "from_pretrained", "(", "self", ".", "args", "[", "\"model_name_or_path\"", "]", ")", "\n", "\n", "self", ".", "bert_output_dim", "=", "args", "[", "\"config\"", "]", ".", "hidden_size", "\n", "#self.hidden_dropout_prob = self.utterance_encoder.config.hidden_dropout_prob", "\n", "\n", "if", "self", ".", "args", "[", "\"fix_encoder\"", "]", ":", "\n", "            ", "print", "(", "\"[Info] Utterance Encoder does not requires grad...\"", ")", "\n", "for", "p", "in", "self", ".", "utterance_encoder", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "### slot, slot-value Encoder (not trainable)", "\n", "", "", "self", ".", "sv_encoder", "=", "args", "[", "\"model_class\"", "]", ".", "from_pretrained", "(", "self", ".", "args", "[", "\"model_name_or_path\"", "]", ")", "\n", "print", "(", "\"[Info] SV Encoder does not requires grad...\"", ")", "\n", "for", "p", "in", "self", ".", "sv_encoder", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "#self.slot_lookup = nn.Embedding(self.num_slots, self.bert_output_dim)", "\n", "", "self", ".", "value_lookup", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Embedding", "(", "num_label", ",", "self", ".", "bert_output_dim", ")", "for", "num_label", "in", "self", ".", "num_labels", "]", ")", "\n", "\n", "### Classifier", "\n", "self", ".", "nll", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "\n", "### My Add", "\n", "self", ".", "project_W_1", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "self", ".", "bert_output_dim", ",", "self", ".", "bert_output_dim", ")", "for", "_", "in", "range", "(", "self", ".", "num_slots", ")", "]", ")", "\n", "self", ".", "project_W_2", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "2", "*", "self", ".", "bert_output_dim", ",", "self", ".", "bert_output_dim", ")", "for", "_", "in", "range", "(", "self", ".", "num_slots", ")", "]", ")", "\n", "self", ".", "project_W_3", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Linear", "(", "self", ".", "bert_output_dim", ",", "1", ")", "for", "_", "in", "range", "(", "self", ".", "num_slots", ")", "]", ")", "\n", "\n", "if", "self", ".", "args", "[", "\"gate_supervision_for_dst\"", "]", ":", "\n", "            ", "self", ".", "gate_classifier", "=", "nn", ".", "Linear", "(", "self", ".", "bert_output_dim", ",", "2", ")", "\n", "\n", "", "self", ".", "start_token", "=", "self", ".", "tokenizer", ".", "cls_token", "if", "\"bert\"", "in", "self", ".", "args", "[", "\"model_type\"", "]", "else", "self", ".", "tokenizer", ".", "bos_token", "\n", "self", ".", "sep_token", "=", "self", ".", "tokenizer", ".", "sep_token", "if", "\"bert\"", "in", "self", ".", "args", "[", "\"model_type\"", "]", "else", "self", ".", "tokenizer", ".", "eos_token", "\n", "\n", "## Prepare Optimizer", "\n", "def", "get_optimizer_grouped_parameters", "(", "model", ")", ":", "\n", "            ", "param_optimizer", "=", "[", "(", "n", ",", "p", ")", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.01", ",", "\n", "'lr'", ":", "args", "[", "\"learning_rate\"", "]", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", ",", "\n", "'lr'", ":", "args", "[", "\"learning_rate\"", "]", "}", ",", "\n", "]", "\n", "return", "optimizer_grouped_parameters", "\n", "\n", "", "optimizer_grouped_parameters", "=", "get_optimizer_grouped_parameters", "(", "self", ")", "\n", "\n", "\n", "self", ".", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "args", "[", "\"learning_rate\"", "]", ",", ")", "\n", "\n", "self", ".", "initialize_slot_value_lookup", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.models.BERT_DST_Picklist.BeliefTracker.optimize": [[101, 105], ["BERT_DST_Picklist.BeliefTracker.loss_grad.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "BERT_DST_Picklist.BeliefTracker.optimizer.step", "BERT_DST_Picklist.BeliefTracker.parameters"], "methods", ["None"], ["", "def", "optimize", "(", "self", ")", ":", "\n", "        ", "self", ".", "loss_grad", ".", "backward", "(", ")", "\n", "clip_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "parameters", "(", ")", ",", "self", ".", "args", "[", "\"grad_clip\"", "]", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.models.BERT_DST_Picklist.BeliefTracker.initialize_slot_value_lookup": [[107, 152], ["BERT_DST_Picklist.BeliefTracker.sv_encoder.eval", "[].items", "enumerate", "print", "range", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "label_ids.append", "transformer_outputs.mean.detach", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "torch.Embedding.from_pretrained", "len", "BERT_DST_Picklist.BeliefTracker.tokenizer.convert_tokens_to_ids", "len", "torch.tensor().long.append", "torch.tensor().long.append", "torch.tensor().long.append", "BERT_DST_Picklist.BeliefTracker.utterance_encoder.embeddings().sum", "value_dict.items", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "BERT_DST_Picklist.BeliefTracker.tokenizer.tokenize", "len", "BERT_DST_Picklist.BeliefTracker.utterance_encoder.embeddings", "BERT_DST_Picklist.BeliefTracker.sv_encoder", "transformer_outputs.mean.mean", "label.split", "BERT_DST_Picklist.BeliefTracker.sv_encoder", "transformer_outputs.mean", "BERT_DST_Picklist.BeliefTracker.sv_encoder.transformer"], "methods", ["None"], ["", "def", "initialize_slot_value_lookup", "(", "self", ",", "max_seq_length", "=", "32", ")", ":", "\n", "\n", "        ", "self", ".", "sv_encoder", ".", "eval", "(", ")", "\n", "\n", "label_ids", "=", "[", "]", "\n", "for", "dslot", ",", "value_dict", "in", "self", ".", "args", "[", "\"unified_meta\"", "]", "[", "\"slots\"", "]", ".", "items", "(", ")", ":", "\n", "            ", "label_id", "=", "[", "]", "\n", "value_dict_rev", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "value_dict", ".", "items", "(", ")", "}", "\n", "for", "i", "in", "range", "(", "len", "(", "value_dict", ")", ")", ":", "\n", "                ", "label", "=", "value_dict_rev", "[", "i", "]", "\n", "label", "=", "\" \"", ".", "join", "(", "[", "i", "for", "i", "in", "label", ".", "split", "(", "\" \"", ")", "if", "i", "!=", "\"\"", "]", ")", "\n", "\n", "label_tokens", "=", "[", "self", ".", "start_token", "]", "+", "self", ".", "tokenizer", ".", "tokenize", "(", "label", ")", "+", "[", "self", ".", "sep_token", "]", "\n", "label_token_ids", "=", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "label_tokens", ")", "\n", "label_len", "=", "len", "(", "label_token_ids", ")", "\n", "\n", "label_padding", "=", "[", "0", "]", "*", "(", "max_seq_length", "-", "len", "(", "label_token_ids", ")", ")", "\n", "label_token_ids", "+=", "label_padding", "\n", "assert", "len", "(", "label_token_ids", ")", "==", "max_seq_length", "\n", "label_id", ".", "append", "(", "label_token_ids", ")", "\n", "\n", "", "label_id", "=", "torch", ".", "tensor", "(", "label_id", ")", ".", "long", "(", ")", "\n", "label_ids", ".", "append", "(", "label_id", ")", "\n", "\n", "", "for", "s", ",", "label_id", "in", "enumerate", "(", "label_ids", ")", ":", "\n", "            ", "inputs", "=", "{", "\"input_ids\"", ":", "label_id", ",", "\"attention_mask\"", ":", "(", "label_id", ">", "0", ")", ".", "long", "(", ")", "}", "\n", "\n", "if", "self", ".", "args", "[", "\"sum_token_emb_for_value\"", "]", ":", "\n", "                ", "hid_label", "=", "self", ".", "utterance_encoder", ".", "embeddings", "(", "input_ids", "=", "label_id", ")", ".", "sum", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "if", "\"bert\"", "in", "self", ".", "args", "[", "\"model_type\"", "]", ":", "\n", "                    ", "hid_label", "=", "self", ".", "sv_encoder", "(", "**", "inputs", ")", "[", "0", "]", "\n", "hid_label", "=", "hid_label", "[", ":", ",", "0", ",", ":", "]", "\n", "", "elif", "self", ".", "args", "[", "\"model_type\"", "]", "==", "\"gpt2\"", ":", "\n", "                    ", "hid_label", "=", "self", ".", "sv_encoder", "(", "**", "inputs", ")", "[", "0", "]", "\n", "hid_label", "=", "hid_label", ".", "mean", "(", "1", ")", "\n", "", "elif", "self", ".", "args", "[", "\"model_type\"", "]", "==", "\"dialogpt\"", ":", "\n", "                    ", "transformer_outputs", "=", "self", ".", "sv_encoder", ".", "transformer", "(", "**", "inputs", ")", "[", "0", "]", "\n", "hid_label", "=", "transformer_outputs", ".", "mean", "(", "1", ")", "\n", "\n", "", "", "hid_label", "=", "hid_label", ".", "detach", "(", ")", "\n", "self", ".", "value_lookup", "[", "s", "]", "=", "nn", ".", "Embedding", ".", "from_pretrained", "(", "hid_label", ",", "freeze", "=", "True", ")", "\n", "self", ".", "value_lookup", "[", "s", "]", ".", "padding_idx", "=", "-", "1", "\n", "\n", "", "print", "(", "\"Complete initialization of slot and value lookup\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.models.BERT_DST_Picklist.BeliefTracker.forward": [[153, 328], ["data[].size", "data[].size", "range", "torch.cat().detach().cpu().tolist", "torch.cat().detach().cpu().tolist", "torch.cat().detach().cpu().tolist", "torch.cat().detach().cpu().tolist", "torch.cat().detach().cpu().tolist", "torch.cat().detach().cpu().tolist", "torch.cat().detach().cpu().tolist", "torch.cat().detach().cpu().tolist", "torch.cat().detach().cpu().tolist", "torch.cat().detach().cpu().mean().tolist", "torch.cat().detach().cpu().mean().tolist", "torch.cat().detach().cpu().mean().tolist", "torch.cat().detach().cpu().mean().tolist", "torch.cat().detach().cpu().mean().tolist", "torch.cat().detach().cpu().mean().tolist", "torch.cat().detach().cpu().mean().tolist", "torch.cat().detach().cpu().mean().tolist", "torch.cat().detach().cpu().mean().tolist", "labels.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "range", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "torch.cat().numpy", "labels.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "range", "torch.cat().detach().cpu().tolist", "torch.cat().detach().cpu().tolist", "torch.cat().detach().cpu().tolist", "torch.cat().detach().cpu().tolist", "torch.cat().detach().cpu().tolist", "torch.cat().detach().cpu().tolist", "torch.cat().detach().cpu().tolist", "torch.cat().detach().cpu().tolist", "torch.cat().detach().cpu().tolist", "torch.cat().detach().cpu().mean().tolist", "torch.cat().detach().cpu().mean().tolist", "torch.cat().detach().cpu().mean().tolist", "torch.cat().detach().cpu().mean().tolist", "torch.cat().detach().cpu().mean().tolist", "torch.cat().detach().cpu().mean().tolist", "torch.cat().detach().cpu().mean().tolist", "torch.cat().detach().cpu().mean().tolist", "torch.cat().detach().cpu().mean().tolist", "labels.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "BERT_DST_Picklist.BeliefTracker.optimize", "enumerate", "loss.item", "BERT_DST_Picklist.BeliefTracker.utterance_encoder", "hid_label.size", "BERT_DST_Picklist._gelu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "BERT_DST_Picklist._gelu", "_gelu.squeeze", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Softmax.", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "pred_slot.append", "confidence_slot.append", "loss.item", "BERT_DST_Picklist.BeliefTracker.utterance_encoder", "hidden.mean", "range", "pred_slot.append", "hid_label.size", "BERT_DST_Picklist._gelu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "BERT_DST_Picklist._gelu", "_gelu.squeeze", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Softmax.", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "pred_slot.append", "confidence_slot.append", "zip", "enumerate", "pred.unsqueeze", "torch.cat().detach().cpu().mean().tolist.unsqueeze", "torch.cat().detach().cpu().mean().tolist.unsqueeze", "torch.cat().detach().cpu().mean().tolist.unsqueeze", "BERT_DST_Picklist.BeliefTracker.nll", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu().mean", "torch.cat().detach().cpu().mean", "torch.cat().detach().cpu().mean", "torch.cat().detach().cpu().mean", "torch.cat().detach().cpu().mean", "torch.cat().detach().cpu().mean", "torch.cat().detach().cpu().mean", "torch.cat().detach().cpu().mean", "torch.cat().detach().cpu().mean", "labels.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "BERT_DST_Picklist.BeliefTracker.utterance_encoder", "BERT_DST_Picklist.BeliefTracker.utterance_encoder.transformer", "hidden.mean", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.tensor().unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "labels.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "pred.unsqueeze", "torch.cat().detach().cpu().mean().tolist.unsqueeze", "torch.cat().detach().cpu().mean().tolist.unsqueeze", "torch.cat().detach().cpu().mean().tolist.unsqueeze", "BERT_DST_Picklist.BeliefTracker.nll", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu().mean", "torch.cat().detach().cpu().mean", "torch.cat().detach().cpu().mean", "torch.cat().detach().cpu().mean", "torch.cat().detach().cpu().mean", "torch.cat().detach().cpu().mean", "torch.cat().detach().cpu().mean", "torch.cat().detach().cpu().mean", "torch.cat().detach().cpu().mean", "labels.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "numpy.array", "numpy.array", "len", "len", "pred_arr.append", "gold_arr.append", "len", "print", "print", "print", "print", "hid_label.unsqueeze().repeat", "_gelu.unsqueeze().repeat", "hidden_bsz[].unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.mm().transpose", "torch.mm().transpose", "torch.mm().transpose", "torch.mm().transpose", "torch.mm().transpose", "torch.mm().transpose", "torch.mm().transpose", "torch.mm().transpose", "torch.mm().transpose", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "pred.item", "pred_slot_local.append", "pred_slot_local.append", "hid_label.unsqueeze().repeat", "_gelu.unsqueeze().repeat", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "labels.detach().cpu().numpy.detach().cpu().numpy.detach", "len", "BERT_DST_Picklist.BeliefTracker.gate_classifier", "BERT_DST_Picklist.BeliefTracker.nll", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "labels.detach().cpu().numpy.detach().cpu().numpy.detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "torch.cat().detach().cpu", "labels.detach().cpu().numpy.detach().cpu().numpy.detach", "gold_str.split", "hid_label.unsqueeze", "_gelu.unsqueeze", "enumerate", "hidden_bsz[].unsqueeze", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "BERT_DST_Picklist.BeliefTracker.nll", "torch.cat.transpose", "torch.cat.transpose", "torch.cat.transpose", "[].unsqueeze", "[].item", "hid_label.unsqueeze", "_gelu.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat.transpose", "torch.cat.transpose", "torch.cat.transpose", "labels[].unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "torch.cat().detach", "s.split", "s.split", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.models.dual_encoder_ranking.dual_encoder_ranking.optimize", "home.repos.pwc.inspect_result.mifei_st-tod.models.BERT_DST_Picklist._gelu", "home.repos.pwc.inspect_result.mifei_st-tod.models.BERT_DST_Picklist._gelu", "home.repos.pwc.inspect_result.mifei_st-tod.models.BERT_DST_Picklist._gelu", "home.repos.pwc.inspect_result.mifei_st-tod.models.BERT_DST_Picklist._gelu"], ["", "def", "forward", "(", "self", ",", "data", ",", "evaluate_gradient", "=", "False", ")", ":", "\n", "        ", "if", "not", "evaluate_gradient", ":", "\n", "            ", "batch_size", "=", "data", "[", "\"context\"", "]", ".", "size", "(", "0", ")", "\n", "labels", "=", "data", "[", "\"belief_ontology\"", "]", "\n", "\n", "# Utterance encoding", "\n", "inputs", "=", "{", "\"input_ids\"", ":", "data", "[", "\"context\"", "]", ",", "\"attention_mask\"", ":", "(", "data", "[", "\"context\"", "]", ">", "0", ")", ".", "long", "(", ")", "}", "\n", "\n", "if", "\"bert\"", "in", "self", ".", "args", "[", "\"model_type\"", "]", ":", "\n", "                ", "hidden", "=", "self", ".", "utterance_encoder", "(", "**", "inputs", ")", "[", "0", "]", "\n", "hidden_rep", "=", "hidden", "[", ":", ",", "0", ",", ":", "]", "\n", "", "elif", "self", ".", "args", "[", "\"model_type\"", "]", "==", "\"gpt2\"", ":", "\n", "                ", "hidden", "=", "self", ".", "utterance_encoder", "(", "**", "inputs", ")", "[", "0", "]", "\n", "hidden_rep", "=", "hidden", ".", "mean", "(", "1", ")", "\n", "", "elif", "self", ".", "args", "[", "\"model_type\"", "]", "==", "\"dialogpt\"", ":", "\n", "                ", "transformer_outputs", "=", "self", ".", "utterance_encoder", ".", "transformer", "(", "\n", "data", "[", "\"context\"", "]", ",", "\n", "attention_mask", "=", "(", "data", "[", "\"context\"", "]", ">", "0", ")", ".", "long", "(", ")", "\n", ")", "\n", "hidden", "=", "transformer_outputs", "[", "0", "]", "\n", "hidden_rep", "=", "hidden", ".", "mean", "(", "1", ")", "\n", "\n", "# Label (slot-value) encoding", "\n", "", "loss", "=", "0", "\n", "pred_slot", "=", "[", "]", "\n", "confidence_slot", "=", "[", "]", "\n", "\n", "if", "self", ".", "args", "[", "\"oracle_domain\"", "]", ":", "\n", "\n", "                ", "for", "slot_id", "in", "range", "(", "self", ".", "num_slots", ")", ":", "\n", "                    ", "pred_slot_local", "=", "[", "]", "\n", "for", "bsz_i", "in", "range", "(", "batch_size", ")", ":", "\n", "                        ", "hidden_bsz", "=", "hidden", "[", "bsz_i", ",", ":", ",", ":", "]", "\n", "\n", "if", "slot_id", "in", "data", "[", "\"triggered_ds_idx\"", "]", "[", "bsz_i", "]", ":", "\n", "\n", "                            ", "temp", "=", "[", "i", "for", "i", ",", "idx", "in", "enumerate", "(", "data", "[", "\"triggered_ds_idx\"", "]", "[", "bsz_i", "]", ")", "if", "idx", "==", "slot_id", "]", "\n", "assert", "len", "(", "temp", ")", "==", "1", "\n", "ds_pos", "=", "data", "[", "\"triggered_ds_pos\"", "]", "[", "bsz_i", "]", "[", "temp", "[", "0", "]", "]", "\n", "\n", "hid_label", "=", "self", ".", "value_lookup", "[", "slot_id", "]", ".", "weight", "# v * d", "\n", "hidden_ds", "=", "hidden_bsz", "[", "ds_pos", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", "# d * 1", "\n", "hidden_ds", "=", "torch", ".", "cat", "(", "[", "hidden_ds", ",", "hidden_bsz", "[", "0", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", "]", ",", "0", ")", "# 2d * 1", "\n", "hidden_ds", "=", "self", ".", "project_W_2", "[", "0", "]", "(", "hidden_ds", ".", "transpose", "(", "1", ",", "0", ")", ")", ".", "transpose", "(", "1", ",", "0", ")", "# d * 1", "\n", "\n", "_dist", "=", "torch", ".", "mm", "(", "hid_label", ",", "hidden_ds", ")", ".", "transpose", "(", "1", ",", "0", ")", "# 1 * v, 51.6%", "\n", "\n", "_", ",", "pred", "=", "torch", ".", "max", "(", "_dist", ",", "-", "1", ")", "\n", "pred_item", "=", "pred", ".", "item", "(", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "\n", "                                ", "if", "(", "self", ".", "args", "[", "\"gate_supervision_for_dst\"", "]", "and", "labels", "[", "bsz_i", ",", "slot_id", "]", "!=", "0", ")", "or", "(", "not", "self", ".", "args", "[", "\"gate_supervision_for_dst\"", "]", ")", ":", "\n", "                                    ", "_loss", "=", "self", ".", "nll", "(", "_dist", ",", "labels", "[", "bsz_i", ",", "slot_id", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "loss", "+=", "_loss", "\n", "\n", "", "", "if", "self", ".", "args", "[", "\"gate_supervision_for_dst\"", "]", ":", "\n", "                                ", "_dist_gate", "=", "self", ".", "gate_classifier", "(", "hidden_ds", ".", "transpose", "(", "1", ",", "0", ")", ")", "\n", "_loss_gate", "=", "self", ".", "nll", "(", "_dist_gate", ",", "data", "[", "\"slot_gate\"", "]", "[", "bsz_i", ",", "slot_id", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "loss", "+=", "_loss_gate", "\n", "\n", "if", "torch", ".", "max", "(", "_dist_gate", ",", "-", "1", ")", "[", "1", "]", ".", "item", "(", ")", "==", "0", ":", "\n", "                                    ", "pred_item", "=", "0", "\n", "\n", "", "", "pred_slot_local", ".", "append", "(", "pred_item", ")", "\n", "", "else", ":", "\n", "                            ", "pred_slot_local", ".", "append", "(", "0", ")", "\n", "\n", "", "", "pred_slot", ".", "append", "(", "torch", ".", "tensor", "(", "pred_slot_local", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "\n", "", "predictions", "=", "torch", ".", "cat", "(", "pred_slot", ",", "1", ")", ".", "numpy", "(", ")", "\n", "labels", "=", "labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "else", ":", "\n", "                ", "for", "slot_id", "in", "range", "(", "self", ".", "num_slots", ")", ":", "## note: target_slots are successive", "\n", "# loss calculation", "\n", "                    ", "hid_label", "=", "self", ".", "value_lookup", "[", "slot_id", "]", ".", "weight", "# v * d", "\n", "num_slot_labels", "=", "hid_label", ".", "size", "(", "0", ")", "\n", "\n", "_hidden", "=", "_gelu", "(", "self", ".", "project_W_1", "[", "slot_id", "]", "(", "hidden_rep", ")", ")", "\n", "_hidden", "=", "torch", ".", "cat", "(", "[", "hid_label", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "batch_size", ",", "1", ",", "1", ")", ",", "_hidden", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "num_slot_labels", ",", "1", ")", "]", ",", "dim", "=", "2", ")", "\n", "_hidden", "=", "_gelu", "(", "self", ".", "project_W_2", "[", "slot_id", "]", "(", "_hidden", ")", ")", "\n", "_hidden", "=", "self", ".", "project_W_3", "[", "slot_id", "]", "(", "_hidden", ")", "\n", "_dist", "=", "_hidden", ".", "squeeze", "(", "2", ")", "# to b * num_slot_labels", "\n", "\n", "softmax", "=", "nn", ".", "Softmax", "(", "-", "1", ")", "\n", "prob", "=", "softmax", "(", "_dist", ")", "\n", "confidence", ",", "pred", "=", "torch", ".", "max", "(", "prob", ",", "dim", "=", "-", "1", ")", "\n", "\n", "pred_slot", ".", "append", "(", "pred", ".", "unsqueeze", "(", "1", ")", ")", "\n", "confidence_slot", ".", "append", "(", "confidence", ".", "unsqueeze", "(", "dim", "=", "1", ")", ")", "\n", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "                        ", "_loss", "=", "self", ".", "nll", "(", "_dist", ",", "labels", "[", ":", ",", "slot_id", "]", ")", "\n", "loss", "+=", "_loss", "\n", "\n", "", "", "predictions", "=", "torch", ".", "cat", "(", "pred_slot", ",", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "confidence", "=", "torch", ".", "cat", "(", "confidence_slot", ",", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "mean", "(", "dim", "=", "1", ")", ".", "tolist", "(", ")", "\n", "labels", "=", "labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "if", "self", ".", "training", ":", "\n", "                ", "self", ".", "loss_grad", "=", "loss", "\n", "self", ".", "optimize", "(", ")", "\n", "\n", "", "if", "self", ".", "args", "[", "\"error_analysis\"", "]", ":", "\n", "                ", "for", "bsz_i", ",", "(", "pred", ",", "label", ")", "in", "enumerate", "(", "zip", "(", "np", ".", "array", "(", "predictions", ")", ",", "np", ".", "array", "(", "labels", ")", ")", ")", ":", "\n", "                    ", "assert", "len", "(", "pred", ")", "==", "len", "(", "label", ")", "\n", "joint", "=", "0", "\n", "pred_arr", ",", "gold_arr", "=", "[", "]", ",", "[", "]", "\n", "for", "i", ",", "p", "in", "enumerate", "(", "pred", ")", ":", "\n", "                        ", "pred_str", "=", "self", ".", "slot_id2value_dict", "[", "self", ".", "slots", "[", "i", "]", "]", "[", "p", "]", "\n", "gold_str", "=", "self", ".", "slot_id2value_dict", "[", "self", ".", "slots", "[", "i", "]", "]", "[", "label", "[", "i", "]", "]", "\n", "pred_arr", ".", "append", "(", "self", ".", "slots", "[", "i", "]", "+", "\"-\"", "+", "pred_str", ")", "\n", "gold_arr", ".", "append", "(", "self", ".", "slots", "[", "i", "]", "+", "\"-\"", "+", "gold_str", ")", "\n", "if", "pred_str", "==", "gold_str", "or", "pred_str", "in", "gold_str", ".", "split", "(", "\"|\"", ")", ":", "\n", "                            ", "joint", "+=", "1", "\n", "", "", "if", "joint", "!=", "len", "(", "pred", ")", ":", "\n", "                        ", "print", "(", "data", "[", "\"context_plain\"", "]", "[", "bsz_i", "]", ")", "\n", "print", "(", "\"Gold:\"", ",", "[", "s", "for", "s", "in", "gold_arr", "if", "s", ".", "split", "(", "\"-\"", ")", "[", "2", "]", "!=", "\"none\"", "]", ")", "\n", "print", "(", "\"Pred:\"", ",", "[", "s", "for", "s", "in", "pred_arr", "if", "s", ".", "split", "(", "\"-\"", ")", "[", "2", "]", "!=", "\"none\"", "]", ")", "\n", "print", "(", ")", "\n", "\n", "\n", "", "", "", "outputs", "=", "{", "\"loss\"", ":", "loss", ".", "item", "(", ")", ",", "\"pred\"", ":", "predictions", ",", "\"label\"", ":", "labels", ",", "'confidence'", ":", "confidence", "}", "\n", "\n", "return", "outputs", "\n", "\n", "", "else", ":", "\n", "            ", "batch_size", "=", "data", "[", "\"context\"", "]", ".", "size", "(", "0", ")", "\n", "labels", "=", "data", "[", "\"belief_ontology\"", "]", "\n", "\n", "# Utterance encoding", "\n", "inputs", "=", "{", "\"input_ids\"", ":", "data", "[", "\"context\"", "]", ",", "\"attention_mask\"", ":", "(", "data", "[", "\"context\"", "]", ">", "0", ")", ".", "long", "(", ")", "}", "\n", "\n", "hidden", "=", "self", ".", "utterance_encoder", "(", "**", "inputs", ")", "[", "0", "]", "\n", "hidden_rep", "=", "hidden", "[", ":", ",", "0", ",", ":", "]", "\n", "\n", "# Label (slot-value) encoding", "\n", "loss", "=", "0", "\n", "pred_slot", "=", "[", "]", "\n", "confidence_slot", "=", "[", "]", "\n", "\n", "\n", "for", "slot_id", "in", "range", "(", "self", ".", "num_slots", ")", ":", "## note: target_slots are successive", "\n", "# loss calculation", "\n", "                ", "hid_label", "=", "self", ".", "value_lookup", "[", "slot_id", "]", ".", "weight", "# v * d", "\n", "num_slot_labels", "=", "hid_label", ".", "size", "(", "0", ")", "\n", "\n", "_hidden", "=", "_gelu", "(", "self", ".", "project_W_1", "[", "slot_id", "]", "(", "hidden_rep", ")", ")", "\n", "_hidden", "=", "torch", ".", "cat", "(", "[", "hid_label", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "batch_size", ",", "1", ",", "1", ")", ",", "\n", "_hidden", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "1", ",", "num_slot_labels", ",", "1", ")", "]", ",", "dim", "=", "2", ")", "\n", "_hidden", "=", "_gelu", "(", "self", ".", "project_W_2", "[", "slot_id", "]", "(", "_hidden", ")", ")", "\n", "_hidden", "=", "self", ".", "project_W_3", "[", "slot_id", "]", "(", "_hidden", ")", "\n", "_dist", "=", "_hidden", ".", "squeeze", "(", "2", ")", "# to b * num_slot_labels", "\n", "\n", "softmax", "=", "nn", ".", "Softmax", "(", "-", "1", ")", "\n", "prob", "=", "softmax", "(", "_dist", ")", "\n", "confidence", ",", "pred", "=", "torch", ".", "max", "(", "prob", ",", "dim", "=", "-", "1", ")", "\n", "\n", "pred_slot", ".", "append", "(", "pred", ".", "unsqueeze", "(", "1", ")", ")", "\n", "confidence_slot", ".", "append", "(", "confidence", ".", "unsqueeze", "(", "dim", "=", "1", ")", ")", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "                    ", "_loss", "=", "self", ".", "nll", "(", "_dist", ",", "labels", "[", ":", ",", "slot_id", "]", ")", "\n", "loss", "+=", "_loss", "\n", "\n", "", "", "predictions", "=", "torch", ".", "cat", "(", "pred_slot", ",", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "confidence", "=", "torch", ".", "cat", "(", "confidence_slot", ",", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "mean", "(", "dim", "=", "1", ")", ".", "tolist", "(", ")", "\n", "labels", "=", "labels", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "outputs", "=", "{", "\"loss\"", ":", "loss", ".", "item", "(", ")", ",", "\"pred\"", ":", "predictions", ",", "\"label\"", ":", "labels", ",", "'confidence'", ":", "confidence", "}", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.models.BERT_DST_Picklist.BeliefTracker.evaluation": [[329, 359], ["numpy.array", "numpy.array", "zip", "print", "enumerate", "len", "len", "len", "gold_str.split"], "methods", ["None"], ["", "", "def", "evaluation", "(", "self", ",", "preds", ",", "labels", ")", ":", "\n", "        ", "preds", "=", "np", ".", "array", "(", "preds", ")", "\n", "labels", "=", "np", ".", "array", "(", "labels", ")", "\n", "\n", "slot_acc", ",", "joint_acc", ",", "slot_acc_total", ",", "joint_acc_total", "=", "0", ",", "0", ",", "0", ",", "0", "\n", "for", "pred", ",", "label", "in", "zip", "(", "preds", ",", "labels", ")", ":", "\n", "            ", "joint", "=", "0", "\n", "\n", "assert", "len", "(", "pred", ")", "==", "len", "(", "label", ")", "\n", "\n", "for", "i", ",", "p", "in", "enumerate", "(", "pred", ")", ":", "\n", "                ", "pred_str", "=", "self", ".", "slot_id2value_dict", "[", "self", ".", "slots", "[", "i", "]", "]", "[", "p", "]", "\n", "gold_str", "=", "self", ".", "slot_id2value_dict", "[", "self", ".", "slots", "[", "i", "]", "]", "[", "label", "[", "i", "]", "]", "\n", "\n", "if", "pred_str", "==", "gold_str", "or", "pred_str", "in", "gold_str", ".", "split", "(", "\"|\"", ")", ":", "\n", "                    ", "slot_acc", "+=", "1", "\n", "joint", "+=", "1", "\n", "", "slot_acc_total", "+=", "1", "\n", "\n", "", "if", "joint", "==", "len", "(", "pred", ")", ":", "\n", "                ", "joint_acc", "+=", "1", "\n", "\n", "", "joint_acc_total", "+=", "1", "\n", "\n", "", "joint_acc", "=", "joint_acc", "/", "joint_acc_total", "\n", "slot_acc", "=", "slot_acc", "/", "slot_acc_total", "\n", "results", "=", "{", "\"joint_acc\"", ":", "joint_acc", ",", "\"slot_acc\"", ":", "slot_acc", "}", "\n", "print", "(", "\"Results 1: \"", ",", "results", ")", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.models.BERT_DST_Picklist._gelu": [[13, 20], ["torch.erf", "torch.erf", "torch.erf", "math.sqrt"], "function", ["None"], ["def", "_gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\" Original Implementation of the gelu activation function in Google Bert repo when initialy created.\n        For information: OpenAI GPT's gelu is slightly different (and gives slightly different results):\n        0.5 * x * (1 + torch.tanh(math.sqrt(2 / math.pi) * (x + 0.044715 * torch.pow(x, 3))))\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "return", "x", "*", "0.5", "*", "(", "1.0", "+", "torch", ".", "erf", "(", "x", "/", "math", ".", "sqrt", "(", "2.0", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.models.dual_encoder_ranking.dual_encoder_ranking.__init__": [[18, 51], ["torch.Module.__init__", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "args[].from_pretrained", "AdamW", "dual_encoder_ranking.dual_encoder_ranking.utterance_encoder.parameters", "dual_encoder_ranking.dual_encoder_ranking.__init__.get_optimizer_grouped_parameters"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.models.dual_encoder_ranking.dual_encoder_ranking.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", "dual_encoder_ranking", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "xeloss", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "n_gpu", "=", "args", "[", "\"n_gpu\"", "]", "\n", "\n", "### Utterance Encoder", "\n", "self", ".", "utterance_encoder", "=", "args", "[", "\"model_class\"", "]", ".", "from_pretrained", "(", "self", ".", "args", "[", "\"model_name_or_path\"", "]", ")", "\n", "\n", "if", "self", ".", "args", "[", "\"fix_encoder\"", "]", ":", "\n", "            ", "for", "p", "in", "self", ".", "utterance_encoder", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "False", "\n", "\n", "## Prepare Optimizer", "\n", "", "", "def", "get_optimizer_grouped_parameters", "(", "model", ")", ":", "\n", "            ", "param_optimizer", "=", "[", "(", "n", ",", "p", ")", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "p", ".", "requires_grad", "]", "\n", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.01", ",", "\n", "'lr'", ":", "args", "[", "\"learning_rate\"", "]", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "param_optimizer", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", ",", "\n", "'lr'", ":", "args", "[", "\"learning_rate\"", "]", "}", ",", "\n", "]", "\n", "return", "optimizer_grouped_parameters", "\n", "\n", "", "if", "self", ".", "n_gpu", "==", "1", ":", "\n", "            ", "optimizer_grouped_parameters", "=", "get_optimizer_grouped_parameters", "(", "self", ")", "\n", "", "else", ":", "\n", "            ", "optimizer_grouped_parameters", "=", "get_optimizer_grouped_parameters", "(", "self", ".", "module", ")", "\n", "\n", "\n", "", "self", ".", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "args", "[", "\"learning_rate\"", "]", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.models.dual_encoder_ranking.dual_encoder_ranking.optimize": [[53, 57], ["dual_encoder_ranking.dual_encoder_ranking.loss_grad.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "dual_encoder_ranking.dual_encoder_ranking.optimizer.step", "dual_encoder_ranking.dual_encoder_ranking.parameters"], "methods", ["None"], ["", "def", "optimize", "(", "self", ")", ":", "\n", "        ", "self", ".", "loss_grad", ".", "backward", "(", ")", "\n", "clip_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "self", ".", "parameters", "(", ")", ",", "self", ".", "args", "[", "\"grad_clip\"", "]", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.models.dual_encoder_ranking.dual_encoder_ranking.forward": [[58, 225], ["dual_encoder_ranking.dual_encoder_ranking.optimizer.zero_grad", "data[].size", "list", "zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "numpy.argsort", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Softmax.", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "dual_encoder_ranking.dual_encoder_ranking.optimizer.zero_grad", "data[].size", "list", "zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss.", "numpy.argsort", "nn.CrossEntropyLoss.backward", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Softmax.", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "numpy.arange", "context_outputs.append", "response_outputs.append", "response_outputs.append", "final_context_output.cuda.cuda.cuda", "final_response_output.cuda.cuda.cuda", "final_response_output.cuda.cuda.cpu", "final_response_output.cuda.cuda.transpose", "numpy.arange", "labels.cuda.cuda.cuda", "final_response_output.cuda.cuda.transpose", "response_noised.transpose", "dual_encoder_ranking.dual_encoder_ranking.xeloss", "dual_encoder_ranking.dual_encoder_ranking.xeloss", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss.", "weighted_loss.mean", "dual_encoder_ranking.dual_encoder_ranking.optimize", "torch.matmul.detach().cpu().numpy", "torch.matmul.detach().cpu().numpy", "torch.matmul.detach().cpu().numpy", "weighted_loss.mean.item", "numpy.arange", "confidence.detach().cpu().tolist", "numpy.arange", "dual_encoder_ranking.dual_encoder_ranking.utterance_encoder", "context_outputs.append", "response_outputs.append", "final_context_output.cuda.cuda.cuda", "final_response_output.cuda.cuda.cuda", "final_response_output.cuda.cuda.transpose", "numpy.arange", "labels.cuda.cuda.cuda", "torch.matmul.detach().cpu().numpy", "torch.matmul.detach().cpu().numpy", "torch.matmul.detach().cpu().numpy", "nn.CrossEntropyLoss.item", "numpy.arange", "confidence.detach().cpu().tolist", "dual_encoder_ranking.dual_encoder_ranking.utterance_encoder", "dual_encoder_ranking.dual_encoder_ranking.utterance_encoder", "transformer_outputs[].mean.cpu", "transformer_outputs[].mean.cpu", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "torch.randn().cuda", "weights.cuda.cuda.cuda", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "dual_encoder_ranking.dual_encoder_ranking.utterance_encoder", "transformer_outputs[].mean.cpu", "transformer_outputs[].mean.cpu", "[].mean", "[].mean", "weights.cuda.cuda.append", "torch.matmul.detach().cpu", "torch.matmul.detach().cpu", "torch.matmul.detach().cpu", "confidence.detach().cpu", "torch.matmul.detach().cpu", "torch.matmul.detach().cpu", "torch.matmul.detach().cpu", "confidence.detach().cpu", "dual_encoder_ranking.dual_encoder_ranking.utterance_encoder.transformer", "transformer_outputs[].mean", "dual_encoder_ranking.dual_encoder_ranking.utterance_encoder.transformer", "transformer_outputs[].mean", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "weights.cuda.cuda.append", "weights.cuda.cuda.append", "final_context_output.cuda.cuda.size", "final_response_output.cuda.cuda.size", "torch.matmul.detach", "torch.matmul.detach", "torch.matmul.detach", "confidence.detach", "torch.matmul.detach", "torch.matmul.detach", "torch.matmul.detach", "confidence.detach", "dual_encoder_ranking.dual_encoder_ranking.utterance_encoder", "dual_encoder_ranking.dual_encoder_ranking.utterance_encoder"], "methods", ["home.repos.pwc.inspect_result.mifei_st-tod.models.dual_encoder_ranking.dual_encoder_ranking.optimize"], ["", "def", "forward", "(", "self", ",", "data", ",", "ind_to_conf_map", "=", "None", ",", "evaluate_gradient", "=", "False", ",", "use_truth", "=", "True", ")", ":", "\n", "\n", "        ", "if", "not", "evaluate_gradient", ":", "\n", "            ", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "batch_size", "=", "data", "[", "\"context\"", "]", ".", "size", "(", "0", ")", "\n", "\n", "interval", "=", "25", "\n", "start_list", "=", "list", "(", "np", ".", "arange", "(", "0", ",", "batch_size", ",", "interval", ")", ")", "\n", "end_list", "=", "start_list", "[", "1", ":", "]", "+", "[", "None", "]", "\n", "context_outputs", ",", "response_outputs", "=", "[", "]", ",", "[", "]", "\n", "\n", "for", "start", ",", "end", "in", "zip", "(", "start_list", ",", "end_list", ")", ":", "\n", "\n", "                ", "inputs_con", "=", "{", "\"input_ids\"", ":", "data", "[", "\"context\"", "]", "[", "start", ":", "end", "]", ",", "\n", "\"attention_mask\"", ":", "(", "data", "[", "\"context\"", "]", "[", "start", ":", "end", "]", ">", "0", ")", ".", "long", "(", ")", "}", "\n", "inputs_res", "=", "{", "\"input_ids\"", ":", "data", "[", "\"response\"", "]", "[", "start", ":", "end", "]", ",", "\n", "\"attention_mask\"", ":", "(", "data", "[", "\"response\"", "]", "[", "start", ":", "end", "]", ">", "0", ")", ".", "long", "(", ")", "}", "\n", "\n", "if", "\"bert\"", "in", "self", ".", "args", "[", "\"model_type\"", "]", ":", "\n", "                    ", "_", ",", "context_output", "=", "self", ".", "utterance_encoder", "(", "**", "inputs_con", ")", "\n", "_", ",", "response_output", "=", "self", ".", "utterance_encoder", "(", "**", "inputs_res", ")", "\n", "", "elif", "self", ".", "args", "[", "\"model_type\"", "]", "==", "\"gpt2\"", ":", "\n", "                    ", "context_output", "=", "self", ".", "utterance_encoder", "(", "**", "inputs_con", ")", "[", "0", "]", ".", "mean", "(", "1", ")", "\n", "response_output", "=", "self", ".", "utterance_encoder", "(", "**", "inputs_res", ")", "[", "0", "]", ".", "mean", "(", "1", ")", "\n", "", "elif", "self", ".", "args", "[", "\"model_type\"", "]", "==", "\"dialogpt\"", ":", "\n", "                    ", "transformer_outputs", "=", "self", ".", "utterance_encoder", ".", "transformer", "(", "**", "inputs_con", ")", "\n", "context_output", "=", "transformer_outputs", "[", "0", "]", ".", "mean", "(", "1", ")", "\n", "transformer_outputs", "=", "self", ".", "utterance_encoder", ".", "transformer", "(", "**", "inputs_res", ")", "\n", "response_output", "=", "transformer_outputs", "[", "0", "]", ".", "mean", "(", "1", ")", "\n", "\n", "", "context_outputs", ".", "append", "(", "context_output", ".", "cpu", "(", ")", ")", "\n", "response_outputs", ".", "append", "(", "response_output", ".", "cpu", "(", ")", ")", "\n", "\n", "# evaluation for k-to-100", "\n", "", "if", "(", "not", "self", ".", "training", ")", "and", "(", "batch_size", "<", "100", ")", ":", "\n", "                ", "response_outputs", ".", "append", "(", "self", ".", "final_response_output", "[", ":", "100", "-", "batch_size", ",", ":", "]", ")", "\n", "\n", "", "final_context_output", "=", "torch", ".", "cat", "(", "context_outputs", ",", "0", ")", "\n", "final_response_output", "=", "torch", ".", "cat", "(", "response_outputs", ",", "0", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "final_context_output", "=", "final_context_output", ".", "cuda", "(", ")", "\n", "final_response_output", "=", "final_response_output", ".", "cuda", "(", ")", "\n", "\n", "", "if", "not", "self", ".", "training", ":", "\n", "                ", "self", ".", "final_response_output", "=", "final_response_output", ".", "cpu", "(", ")", "\n", "\n", "# mat", "\n", "", "logits", "=", "torch", ".", "matmul", "(", "final_context_output", ",", "final_response_output", ".", "transpose", "(", "1", ",", "0", ")", ")", "\n", "\n", "# loss", "\n", "labels", "=", "torch", ".", "tensor", "(", "np", ".", "arange", "(", "batch_size", ")", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "labels", "=", "labels", ".", "cuda", "(", ")", "\n", "\n", "context_noised", "=", "final_context_output", "+", "0.5", "*", "torch", ".", "randn", "(", "final_context_output", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", "\n", "response_noised", "=", "final_response_output", "+", "0.5", "*", "torch", ".", "randn", "(", "final_response_output", ".", "size", "(", ")", ")", ".", "cuda", "(", ")", "\n", "\n", "logits_context_noised", "=", "torch", ".", "matmul", "(", "context_noised", ",", "final_response_output", ".", "transpose", "(", "1", ",", "0", ")", ")", "\n", "logits_response_noised", "=", "torch", ".", "matmul", "(", "final_context_output", ",", "response_noised", ".", "transpose", "(", "1", ",", "0", ")", ")", "\n", "\n", "if", "self", ".", "args", "[", "'embedding_noise'", "]", ":", "# add gaussian noise to embedding", "\n", "\n", "                ", "loss1", "=", "self", ".", "xeloss", "(", "logits", ",", "labels", ")", "\n", "loss2", "=", "self", ".", "xeloss", "(", "logits_context_noised", ",", "labels", ")", "\n", "\n", "loss", "=", "(", "loss1", "+", "loss2", ")", "/", "2", "\n", "\n", "", "else", ":", "\n", "\n", "                ", "weights", "=", "[", "]", "\n", "for", "idx", "in", "data", "[", "'index'", "]", ":", "\n", "                    ", "if", "ind_to_conf_map", "and", "idx", "in", "ind_to_conf_map", ":", "\n", "                        ", "if", "self", ".", "args", "[", "'confidence_weighting'", "]", ":", "\n", "                            ", "weights", ".", "append", "(", "self", ".", "args", "[", "'lambda'", "]", "*", "ind_to_conf_map", "[", "idx", "]", ")", "# weight samples based on confidence", "\n", "", "else", ":", "\n", "                            ", "weights", ".", "append", "(", "self", ".", "args", "[", "'lambda'", "]", ")", "# weight pseudo labeled samples by lambda", "\n", "", "", "else", ":", "\n", "                        ", "weights", ".", "append", "(", "1", ")", "\n", "", "", "weights", "=", "torch", ".", "FloatTensor", "(", "weights", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "weights", "=", "weights", ".", "cuda", "(", ")", "\n", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", "\n", "losses", "=", "criterion", "(", "logits", ",", "labels", ")", "\n", "\n", "weighted_loss", "=", "losses", "*", "weights", "\n", "loss", "=", "weighted_loss", ".", "mean", "(", ")", "\n", "\n", "\n", "", "if", "self", ".", "training", ":", "\n", "                ", "self", ".", "loss_grad", "=", "loss", "\n", "self", ".", "optimize", "(", ")", "\n", "\n", "", "predictions", "=", "np", ".", "argsort", "(", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "1", ")", "#torch.argmax(logits, -1)", "\n", "\n", "softmax", "=", "nn", ".", "Softmax", "(", "-", "1", ")", "\n", "prob", "=", "softmax", "(", "logits", ")", "\n", "confidence", ",", "_", "=", "torch", ".", "max", "(", "prob", ",", "dim", "=", "-", "1", ")", "\n", "\n", "outputs", "=", "{", "\"loss\"", ":", "loss", ".", "item", "(", ")", ",", "\n", "\"pred\"", ":", "predictions", ",", "\n", "\"label\"", ":", "np", ".", "arange", "(", "batch_size", ")", ",", "\n", "\"prob\"", ":", "prob", ",", "\n", "'confidence'", ":", "confidence", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "}", "\n", "\n", "return", "outputs", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "batch_size", "=", "data", "[", "\"context\"", "]", ".", "size", "(", "0", ")", "\n", "\n", "interval", "=", "25", "\n", "start_list", "=", "list", "(", "np", ".", "arange", "(", "0", ",", "batch_size", ",", "interval", ")", ")", "\n", "end_list", "=", "start_list", "[", "1", ":", "]", "+", "[", "None", "]", "\n", "context_outputs", ",", "response_outputs", "=", "[", "]", ",", "[", "]", "\n", "\n", "for", "start", ",", "end", "in", "zip", "(", "start_list", ",", "end_list", ")", ":", "\n", "\n", "                ", "inputs_con", "=", "{", "\"input_ids\"", ":", "data", "[", "\"context\"", "]", "[", "start", ":", "end", "]", ",", "\n", "\"attention_mask\"", ":", "(", "data", "[", "\"context\"", "]", "[", "start", ":", "end", "]", ">", "0", ")", ".", "long", "(", ")", "}", "\n", "inputs_res", "=", "{", "\"input_ids\"", ":", "data", "[", "\"response\"", "]", "[", "start", ":", "end", "]", ",", "\n", "\"attention_mask\"", ":", "(", "data", "[", "\"response\"", "]", "[", "start", ":", "end", "]", ">", "0", ")", ".", "long", "(", ")", "}", "\n", "\n", "_", ",", "context_output", "=", "self", ".", "utterance_encoder", "(", "**", "inputs_con", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "_", ",", "response_output", "=", "self", ".", "utterance_encoder", "(", "**", "inputs_res", ")", "\n", "\n", "", "context_outputs", ".", "append", "(", "context_output", ".", "cpu", "(", ")", ")", "\n", "response_outputs", ".", "append", "(", "response_output", ".", "cpu", "(", ")", ")", "\n", "\n", "", "final_context_output", "=", "torch", ".", "cat", "(", "context_outputs", ",", "0", ")", "\n", "final_response_output", "=", "torch", ".", "cat", "(", "response_outputs", ",", "0", ")", "\n", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "final_context_output", "=", "final_context_output", ".", "cuda", "(", ")", "\n", "final_response_output", "=", "final_response_output", ".", "cuda", "(", ")", "\n", "\n", "# mat", "\n", "", "logits", "=", "torch", ".", "matmul", "(", "final_context_output", ",", "final_response_output", ".", "transpose", "(", "1", ",", "0", ")", ")", "\n", "\n", "# loss", "\n", "labels", "=", "torch", ".", "tensor", "(", "np", ".", "arange", "(", "batch_size", ")", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "                ", "labels", "=", "labels", ".", "cuda", "(", ")", "\n", "\n", "", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'mean'", ")", "\n", "losses", "=", "criterion", "(", "logits", ",", "labels", ")", "\n", "\n", "predictions", "=", "np", ".", "argsort", "(", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "1", ")", "# torch.argmax(logits, -1)", "\n", "\n", "losses", ".", "backward", "(", ")", "\n", "\n", "softmax", "=", "nn", ".", "Softmax", "(", "-", "1", ")", "\n", "prob", "=", "softmax", "(", "logits", ")", "\n", "confidence", ",", "_", "=", "torch", ".", "max", "(", "prob", ",", "dim", "=", "-", "1", ")", "\n", "\n", "outputs", "=", "{", "\"loss\"", ":", "losses", ".", "item", "(", ")", ",", "\n", "\"pred\"", ":", "predictions", ",", "\n", "\"label\"", ":", "np", ".", "arange", "(", "batch_size", ")", ",", "\n", "\"prob\"", ":", "prob", ",", "\n", "'confidence'", ":", "confidence", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", ",", "\n", "\"logits\"", ":", "logits", "\n", "}", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.mifei_st-tod.models.dual_encoder_ranking.dual_encoder_ranking.evaluation": [[226, 248], ["numpy.array", "numpy.array", "print", "len", "len", "enumerate", "dual_encoder_ranking.dual_encoder_ranking.evaluation._recall_topk"], "methods", ["None"], ["", "", "def", "evaluation", "(", "self", ",", "preds", ",", "labels", ")", ":", "\n", "        ", "assert", "len", "(", "preds", ")", "==", "len", "(", "labels", ")", "\n", "\n", "preds", "=", "np", ".", "array", "(", "preds", ")", "\n", "labels", "=", "np", ".", "array", "(", "labels", ")", "\n", "\n", "def", "_recall_topk", "(", "preds_top10", ",", "labels", ",", "k", ")", ":", "\n", "            ", "preds", "=", "preds_top10", "[", ":", ",", "-", "k", ":", "]", "\n", "acc", "=", "0", "\n", "for", "li", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "                ", "if", "label", "in", "preds", "[", "li", "]", ":", "acc", "+=", "1", "\n", "", "acc", "=", "acc", "/", "len", "(", "labels", ")", "\n", "return", "acc", "\n", "\n", "", "results", "=", "{", "\"top-1\"", ":", "_recall_topk", "(", "preds", ",", "labels", ",", "1", ")", ",", "\n", "\"top-3\"", ":", "_recall_topk", "(", "preds", ",", "labels", ",", "3", ")", ",", "\n", "\"top-5\"", ":", "_recall_topk", "(", "preds", ",", "labels", ",", "5", ")", ",", "\n", "\"top-10\"", ":", "_recall_topk", "(", "preds", ",", "labels", ",", "10", ")", "}", "\n", "\n", "print", "(", "results", ")", "\n", "\n", "return", "results", "\n", "", "", ""]]}