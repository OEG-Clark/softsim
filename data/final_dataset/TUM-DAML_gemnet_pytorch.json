{"home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.None.fit_scaling.run": [[34, 164], ["torch.manual_seed", "os.path.exists", "gemnet.model.layers.scaling.AutomaticFit.set2fitmode", "logging.info", "gemnet.model.gemnet.GemNet", "logging.info", "gemnet.training.data_container.DataContainer", "gemnet.training.data_provider.DataProvider", "gemnet.training.data_provider.DataProvider.get_dataset", "logging.info", "gemnet.training.trainer.Trainer", "gemnet.training.metrics.Metrics", "logging.info", "logging.info", "gemnet.model.utils.write_json", "print", "fit_scaling.run.init"], "function", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.AutomaticFit.set2fitmode", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.get_dataset", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.utils.write_json"], ["def", "run", "(", "\n", "nBatches", ",", "\n", "num_spherical", ",", "\n", "num_radial", ",", "\n", "num_blocks", ",", "\n", "emb_size_atom", ",", "\n", "emb_size_edge", ",", "\n", "emb_size_trip", ",", "\n", "emb_size_quad", ",", "\n", "emb_size_rbf", ",", "\n", "emb_size_cbf", ",", "\n", "emb_size_sbf", ",", "\n", "num_before_skip", ",", "\n", "num_after_skip", ",", "\n", "num_concat", ",", "\n", "num_atom", ",", "\n", "emb_size_bil_quad", ",", "\n", "emb_size_bil_trip", ",", "\n", "triplets_only", ",", "\n", "forces_coupled", ",", "\n", "direct_forces", ",", "\n", "mve", ",", "\n", "cutoff", ",", "\n", "int_cutoff", ",", "\n", "envelope_exponent", ",", "\n", "extensive", ",", "\n", "output_init", ",", "\n", "scale_file", ",", "\n", "data_seed", ",", "\n", "val_dataset", ",", "\n", "tfseed", ",", "\n", "batch_size", ",", "\n", "comment", ",", "\n", "overwrite_mode", "=", "1", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Run this function to automatically fit all scaling factors in the network.\n    \"\"\"", "\n", "torch", ".", "manual_seed", "(", "tfseed", ")", "\n", "\n", "def", "init", "(", "scale_file", ")", ":", "\n", "# initialize file", "\n", "# same for all models", "\n", "        ", "preset", "=", "{", "\"comment\"", ":", "comment", "}", "\n", "write_json", "(", "scale_file", ",", "preset", ")", "\n", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "scale_file", ")", ":", "\n", "        ", "print", "(", "f\"Already found existing file: {scale_file}\"", ")", "\n", "if", "str", "(", "overwrite_mode", ")", "==", "\"1\"", ":", "\n", "            ", "print", "(", "\"Selected: Overwrite the current file.\"", ")", "\n", "init", "(", "scale_file", ")", "\n", "", "elif", "str", "(", "overwrite_mode", ")", "==", "\"2\"", ":", "\n", "            ", "print", "(", "\"Selected: Only fit unfitted variables.\"", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Selected: Exit script\"", ")", "\n", "return", "\n", "", "", "else", ":", "\n", "        ", "init", "(", "scale_file", ")", "\n", "\n", "", "AutomaticFit", ".", "set2fitmode", "(", ")", "\n", "\n", "logging", ".", "info", "(", "\"Initialize model\"", ")", "\n", "model", "=", "GemNet", "(", "\n", "num_spherical", "=", "num_spherical", ",", "\n", "num_radial", "=", "num_radial", ",", "\n", "num_blocks", "=", "num_blocks", ",", "\n", "emb_size_atom", "=", "emb_size_atom", ",", "\n", "emb_size_edge", "=", "emb_size_edge", ",", "\n", "emb_size_trip", "=", "emb_size_trip", ",", "\n", "emb_size_quad", "=", "emb_size_quad", ",", "\n", "emb_size_rbf", "=", "emb_size_rbf", ",", "\n", "emb_size_cbf", "=", "emb_size_cbf", ",", "\n", "emb_size_sbf", "=", "emb_size_sbf", ",", "\n", "num_before_skip", "=", "num_before_skip", ",", "\n", "num_after_skip", "=", "num_after_skip", ",", "\n", "num_concat", "=", "num_concat", ",", "\n", "num_atom", "=", "num_atom", ",", "\n", "emb_size_bil_quad", "=", "emb_size_bil_quad", ",", "\n", "emb_size_bil_trip", "=", "emb_size_bil_trip", ",", "\n", "num_targets", "=", "2", "if", "mve", "else", "1", ",", "\n", "cutoff", "=", "cutoff", ",", "\n", "int_cutoff", "=", "int_cutoff", ",", "\n", "envelope_exponent", "=", "envelope_exponent", ",", "\n", "forces_coupled", "=", "forces_coupled", ",", "\n", "direct_forces", "=", "True", ",", "# evaluates faster", "\n", "triplets_only", "=", "triplets_only", ",", "\n", "activation", "=", "\"swish\"", ",", "\n", "extensive", "=", "extensive", ",", "\n", "output_init", "=", "output_init", ",", "\n", "scale_file", "=", "scale_file", ",", "\n", ")", "\n", "\n", "logging", ".", "info", "(", "\"Load dataset\"", ")", "\n", "# Initialize validation datasets", "\n", "val_data_container", "=", "DataContainer", "(", "\n", "val_dataset", ",", "cutoff", "=", "cutoff", ",", "int_cutoff", "=", "int_cutoff", ",", "triplets_only", "=", "triplets_only", "\n", ")", "\n", "val_data_provider", "=", "DataProvider", "(", "\n", "val_data_container", ",", "\n", "0", ",", "\n", "nBatches", "*", "batch_size", ",", "\n", "batch_size", ",", "\n", "seed", "=", "data_seed", ",", "\n", "shuffle", "=", "True", ",", "\n", "random_split", "=", "True", ",", "\n", ")", "\n", "\n", "# Initialize datasets", "\n", "dataset_iter", "=", "val_data_provider", ".", "get_dataset", "(", "\"val\"", ")", "\n", "logging", ".", "info", "(", "\"Prepare training\"", ")", "\n", "\n", "# Initialize trainer", "\n", "trainer", "=", "Trainer", "(", "model", ",", "mve", "=", "mve", ")", "\n", "metrics", "=", "Metrics", "(", "\"train\"", ",", "trainer", ".", "tracked_metrics", ",", "None", ")", "\n", "\n", "# Training loop", "\n", "logging", ".", "info", "(", "\"Start training\"", ")", "\n", "\n", "while", "not", "AutomaticFit", ".", "fitting_completed", "(", ")", ":", "\n", "        ", "for", "step", "in", "trange", "(", "0", ",", "nBatches", ",", "desc", "=", "\"Training...\"", ")", ":", "\n", "            ", "trainer", ".", "test_on_batch", "(", "dataset_iter", ",", "metrics", ")", "\n", "\n", "", "current_var", "=", "AutomaticFit", ".", "activeVar", "\n", "if", "current_var", "is", "not", "None", ":", "\n", "            ", "current_var", ".", "fit", "(", ")", "# fit current variable", "\n", "", "else", ":", "\n", "            ", "print", "(", "\"Found no variable to fit. Something went wrong!\"", ")", "\n", "\n", "", "", "logging", ".", "info", "(", "f\"\\n Fitting done. Results saved to: {scale_file}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.None.ase_calculator.Molecule.__init__": [[27, 69], ["numpy.array", "numpy.zeros().reshape", "numpy.zeros", "numpy.concatenate", "ase_calculator.Molecule.get_dtypes", "ase_calculator.Molecule.dtypes.update", "len", "len", "numpy.zeros", "len", "numpy.cumsum"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer.get_dtypes", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.update"], ["def", "__init__", "(", "self", ",", "R", ",", "Z", ",", "cutoff", ",", "int_cutoff", ",", "triplets_only", "=", "False", ")", ":", "\n", "        ", "self", ".", "index_keys", "=", "[", "\n", "\"batch_seg\"", ",", "\n", "\"id_undir\"", ",", "\n", "\"id_swap\"", ",", "\n", "\"id_c\"", ",", "\n", "\"id_a\"", ",", "\n", "\"id3_expand_ba\"", ",", "\n", "\"id3_reduce_ca\"", ",", "\n", "\"Kidx3\"", ",", "\n", "]", "\n", "if", "not", "triplets_only", ":", "\n", "            ", "self", ".", "index_keys", "+=", "[", "\n", "\"id4_int_b\"", ",", "\n", "\"id4_int_a\"", ",", "\n", "\"id4_reduce_ca\"", ",", "\n", "\"id4_expand_db\"", ",", "\n", "\"id4_reduce_cab\"", ",", "\n", "\"id4_expand_abd\"", ",", "\n", "\"Kidx4\"", ",", "\n", "\"id4_reduce_intm_ca\"", ",", "\n", "\"id4_expand_intm_db\"", ",", "\n", "\"id4_reduce_intm_ab\"", ",", "\n", "\"id4_expand_intm_ab\"", ",", "\n", "]", "\n", "", "self", ".", "triplets_only", "=", "triplets_only", "\n", "self", ".", "cutoff", "=", "cutoff", "\n", "self", ".", "int_cutoff", "=", "int_cutoff", "\n", "self", ".", "keys", "=", "[", "\"N\"", ",", "\"Z\"", ",", "\"R\"", ",", "\"F\"", ",", "\"E\"", "]", "\n", "\n", "assert", "R", ".", "shape", "==", "(", "len", "(", "Z", ")", ",", "3", ")", "\n", "self", ".", "R", "=", "R", "\n", "self", ".", "Z", "=", "Z", "\n", "self", ".", "N", "=", "np", ".", "array", "(", "[", "len", "(", "Z", ")", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "self", ".", "E", "=", "np", ".", "zeros", "(", "1", ",", "dtype", "=", "np", ".", "float32", ")", ".", "reshape", "(", "1", ",", "1", ")", "\n", "self", ".", "F", "=", "np", ".", "zeros", "(", "(", "len", "(", "Z", ")", ",", "3", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "self", ".", "N_cumsum", "=", "np", ".", "concatenate", "(", "[", "[", "0", "]", ",", "np", ".", "cumsum", "(", "self", ".", "N", ")", "]", ")", "\n", "self", ".", "addID", "=", "False", "\n", "self", ".", "dtypes", ",", "dtypes2", "=", "self", ".", "get_dtypes", "(", ")", "\n", "self", ".", "dtypes", ".", "update", "(", "dtypes2", ")", "# merge all dtypes in single dict", "\n", "self", ".", "device", "=", "\"cpu\"", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.None.ase_calculator.Molecule.get": [[70, 81], ["ase_calculator.Molecule.__getitem__", "ase_calculator.Molecule.pop", "data[].to"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.__getitem__", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.None.ase_calculator.Molecule.to"], ["", "def", "get", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Get the molecule representation in the expected format for the GemNet model.\n        \"\"\"", "\n", "data", "=", "self", ".", "__getitem__", "(", "0", ")", "\n", "for", "var", "in", "[", "\"E\"", ",", "\"F\"", "]", ":", "\n", "            ", "data", ".", "pop", "(", "var", ")", "# not needed i.e.e not kown -> want to calculate this", "\n", "# push to the selected device", "\n", "", "for", "key", "in", "data", ":", "\n", "            ", "data", "[", "key", "]", "=", "data", "[", "key", "]", ".", "to", "(", "self", ".", "device", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.None.ase_calculator.Molecule.update": [[82, 94], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "R", ")", ":", "\n", "        ", "\"\"\"\n        Update the position of the atoms.\n        Graph representation of the molecule might change if the atom positions are updated.\n\n        Parameters\n        ----------\n        R: torch.Tensor (nAtoms, 3)\n            Positions of the atoms in A\u00b0.\n        \"\"\"", "\n", "assert", "self", ".", "R", ".", "shape", "==", "R", ".", "shape", "\n", "self", ".", "R", "=", "R", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.None.ase_calculator.Molecule.to": [[95, 100], ["None"], "methods", ["None"], ["", "def", "to", "(", "self", ",", "device", ")", ":", "\n", "        ", "\"\"\"\n        Changes the device of the returned tensors in the .get() method.\n        \"\"\"", "\n", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.None.ase_calculator.GNNCalculator.__init__": [[124, 146], ["ase.calculators.calculator.Calculator.__init__"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "molecule", ",", "\n", "model", ",", "\n", "atoms", "=", "None", ",", "\n", "restart", "=", "None", ",", "\n", "add_atom_energies", "=", "False", ",", "\n", "label", "=", "\"gemnet_calc\"", ",", "# ase settings", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "restart", "=", "restart", ",", "label", "=", "label", ",", "atoms", "=", "atoms", ",", "**", "kwargs", ")", "\n", "self", ".", "molecule", "=", "molecule", "\n", "self", ".", "model", "=", "model", "\n", "# atom energies: EPBE0_atom (in eV) from QM7-X", "\n", "self", ".", "add_atom_energies", "=", "add_atom_energies", "\n", "self", ".", "atom_energies", "=", "{", "\n", "1", ":", "-", "13.641404161", ",", "\n", "6", ":", "-", "1027.592489146", ",", "\n", "7", ":", "-", "1484.274819088", ",", "\n", "8", ":", "-", "2039.734879322", ",", "\n", "16", ":", "-", "10828.707468187", ",", "\n", "17", ":", "-", "12516.444619523", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.None.ase_calculator.GNNCalculator.calculate": [[148, 171], ["super().calculate", "ase_calculator.GNNCalculator.molecule.update", "ase_calculator.GNNCalculator.molecule.get", "ase_calculator.GNNCalculator.model.predict", "float", "forces.numpy", "numpy.sum"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.None.ase_calculator.GNNCalculator.calculate", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.update", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.None.ase_calculator.Molecule.get", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.predict"], ["", "def", "calculate", "(", "\n", "self", ",", "atoms", "=", "None", ",", "properties", "=", "[", "\"energy\"", ",", "\"forces\"", "]", ",", "system_changes", "=", "all_changes", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "calculate", "(", "atoms", ",", "properties", ",", "system_changes", ")", "\n", "\n", "# atoms.positions changes in each time step", "\n", "# -> need to recompute indices ", "\n", "self", ".", "molecule", ".", "update", "(", "R", "=", "atoms", ".", "positions", ")", "\n", "\n", "# get new indices etc.", "\n", "inputs", "=", "self", ".", "molecule", ".", "get", "(", ")", "\n", "\n", "# predict the energy and forces", "\n", "energy", ",", "forces", "=", "self", ".", "model", ".", "predict", "(", "inputs", ")", "\n", "\n", "# uncomment to add atomic reference energies", "\n", "energy", "=", "float", "(", "energy", ")", "# to scalar", "\n", "if", "self", ".", "add_atom_energies", ":", "\n", "            ", "energy", "+=", "np", ".", "sum", "(", "[", "self", ".", "atom_energies", "[", "z", "]", "for", "z", "in", "atoms", ".", "numbers", "]", ")", "\n", "\n", "# store energy and forces in the calculator dictionary", "\n", "", "self", ".", "results", "[", "\"energy\"", "]", "=", "energy", "\n", "self", ".", "results", "[", "\"forces\"", "]", "=", "forces", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.None.ase_calculator.MDSimulator.__init__": [[203, 267], ["ase.Atoms", "ase_calculator.GNNCalculator", "logging.info", "ase.io.trajectory.Trajectory", "ase_calculator.MDSimulator.dyn.attach", "ase_calculator.MDSimulator.dyn.attach", "ase.Atoms.set_velocities", "ase.md.velocitydistribution.MaxwellBoltzmannDistribution", "ase.md.velocitydistribution.Stationary", "dynamics.lower", "logging.info", "ase.md.verlet.VelocityVerlet", "ase.md.MDLogger", "dynamics.lower", "logging.info", "ase.md.langevin.Langevin", "UserWarning"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "molecule", ",", "\n", "model", ",", "\n", "dynamics", ":", "str", "=", "\"langevin\"", ",", "\n", "max_steps", ":", "int", "=", "100", ",", "# max_steps * time is total time length of trajectory", "\n", "time", ":", "float", "=", "0.5", ",", "# in fs", "\n", "temperature", ":", "float", "=", "300", ",", "# in K", "\n", "langevin_friction", ":", "float", "=", "0.002", ",", "\n", "interval", ":", "int", "=", "10", ",", "\n", "traj_path", "=", "\"md_sim.traj\"", ",", "\n", "vel", "=", "None", ",", "\n", "logfile", "=", "\"-\"", ",", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "max_steps", "=", "max_steps", "\n", "\n", "atoms", "=", "Atoms", "(", "\n", "positions", "=", "molecule", ".", "R", ",", "numbers", "=", "molecule", ".", "Z", "\n", ")", "# positions in A, numbers in integers (1=H, etc.)", "\n", "\n", "atoms", ".", "calc", "=", "GNNCalculator", "(", "molecule", ",", "model", "=", "model", ",", "atoms", "=", "atoms", ")", "\n", "\n", "# Initializes velocities", "\n", "#TODO: Implement a check for that switch", "\n", "if", "vel", "is", "not", "None", ":", "\n", "            ", "atoms", ".", "set_velocities", "(", "vel", ")", "\n", "", "else", ":", "\n", "# Set the momenta to a Maxwell-Boltzmann distribution", "\n", "            ", "MaxwellBoltzmannDistribution", "(", "\n", "atoms", ",", "\n", "temp", "=", "temperature", "*", "units", ".", "kB", ",", "# kB: Boltzmann constant, eV/K", "\n", "# temperature_K = temperature   # only works in newer ase versions", "\n", ")", "\n", "# Set the center-of-mass momentum to zero", "\n", "Stationary", "(", "atoms", ")", "\n", "\n", "", "self", ".", "dyn", "=", "None", "\n", "# Select MD simulation", "\n", "if", "dynamics", ".", "lower", "(", ")", "==", "\"verlet\"", ":", "\n", "            ", "logging", ".", "info", "(", "\"Selected MD integrator: Verlet\"", ")", "\n", "# total energy will always be constant", "\n", "self", ".", "dyn", "=", "VelocityVerlet", "(", "atoms", ",", "timestep", "=", "time", "*", "units", ".", "fs", ")", "\n", "", "elif", "dynamics", ".", "lower", "(", ")", "==", "\"langevin\"", ":", "\n", "            ", "logging", ".", "info", "(", "\"Selected MD integrator: Langevin\"", ")", "\n", "# each atom is coupled to a heat bath through a fluctuating force and a friction term", "\n", "self", ".", "dyn", "=", "Langevin", "(", "\n", "atoms", ",", "\n", "timestep", "=", "time", "*", "units", ".", "fs", ",", "\n", "temperature", "=", "temperature", "*", "units", ".", "kB", ",", "# kB: Boltzmann constant, eV/K", "\n", "# temperature_K = temperature,           # only works in newer ase versions", "\n", "friction", "=", "langevin_friction", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "raise", "UserWarning", "(", "\n", "f\"Unkown MD integrator. I only know 'verlet' and 'langevin' but {dynamics} was given.\"", "\n", ")", "\n", "\n", "", "logging", ".", "info", "(", "f\"Save trajectory to {traj_path}\"", ")", "\n", "self", ".", "traj", "=", "Trajectory", "(", "traj_path", ",", "\"w\"", ",", "atoms", ")", "\n", "self", ".", "dyn", ".", "attach", "(", "self", ".", "traj", ".", "write", ",", "interval", "=", "interval", ")", "\n", "self", ".", "dyn", ".", "attach", "(", "\n", "MDLogger", "(", "self", ".", "dyn", ",", "atoms", ",", "logfile", ",", "peratom", "=", "False", ",", "mode", "=", "\"a\"", ")", ",", "\n", "interval", "=", "interval", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.None.ase_calculator.MDSimulator.run": [[269, 272], ["ase_calculator.MDSimulator.dyn.run", "ase_calculator.MDSimulator.traj.close"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.None.train_seml.run"], ["", "def", "run", "(", "self", ")", ":", "\n", "        ", "self", ".", "dyn", ".", "run", "(", "self", ".", "max_steps", ")", "\n", "self", ".", "traj", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.None.train_seml.collect_stats": [[27, 30], ["seml.collect_exp_stats"], "function", ["None"], ["@", "ex", ".", "post_run_hook", "\n", "def", "collect_stats", "(", "_run", ")", ":", "\n", "    ", "seml", ".", "collect_exp_stats", "(", "_run", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.None.train_seml.config": [[32, 39], ["ex.observers.append", "seml.create_mongodb_observer"], "function", ["None"], ["", "@", "ex", ".", "config", "\n", "def", "config", "(", ")", ":", "\n", "    ", "overwrite", "=", "None", "\n", "db_collection", "=", "None", "\n", "if", "db_collection", "is", "not", "None", ":", "\n", "        ", "ex", ".", "observers", ".", "append", "(", "\n", "seml", ".", "create_mongodb_observer", "(", "db_collection", ",", "overwrite", "=", "overwrite", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.None.train_seml.run": [[42, 388], ["torch.manual_seed", "logging.info", "logging.info", "torch.cuda.device_count", "torch.cuda.is_available", "logging.info", "logging.info", "logging.info", "logging.info", "os.path.join", "os.path.join", "logging.info", "gemnet.model.gemnet.GemNet", "torch.device", "gemnet.model.gemnet.GemNet.to", "torch.utils.tensorboard.SummaryWriter", "logging.info", "gemnet.training.data_container.DataContainer", "gemnet.training.data_provider.DataProvider.get_dataset", "gemnet.training.data_provider.DataProvider.get_dataset", "logging.info", "gemnet.training.trainer.Trainer", "gemnet.training.metrics.Metrics", "gemnet.training.metrics.Metrics", "gemnet.training.metrics.BestMetrics", "os.path.exists", "logging.info", "int", "range", "logging.warning", "logging.warning", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "logging.info", "gemnet.training.data_provider.DataProvider", "gemnet.training.data_container.DataContainer", "logging.info", "gemnet.training.data_provider.DataProvider", "logging.info", "logging.info", "gemnet.training.data_provider.DataProvider", "logging.info", "torch.load", "gemnet.model.gemnet.GemNet.load_state_dict", "torch.load", "gemnet.training.trainer.Trainer.load_state_dict", "gemnet.training.metrics.BestMetrics.restore", "logging.info", "int", "logging.info", "gemnet.training.metrics.BestMetrics.inititalize", "sum", "ex.current_run.info.update", "numpy.ceil", "gemnet.training.trainer.Trainer.train_on_batch", "str", "torch.cuda.is_available", "len", "len", "torch.utils.tensorboard.SummaryWriter.add_scalar", "torch.save", "torch.save", "gemnet.training.trainer.Trainer.save_variable_backups", "gemnet.training.trainer.Trainer.load_averaged_variables", "range", "gemnet.training.metrics.BestMetrics.write", "train[].result", "validation[].result", "logging.info", "gemnet.training.trainer.Trainer.decay_maybe", "train[].write", "validation[].write", "train[].reset_states", "validation[].reset_states", "gemnet.training.trainer.Trainer.restore_variable_backups", "gemnet.training.metrics.BestMetrics.items", "random.SystemRandom().choice", "p.numel", "time.perf_counter", "time.perf_counter", "ex.current_run.info.update", "gemnet.training.trainer.Trainer.schedulers[].get_last_lr", "int", "gemnet.training.trainer.Trainer.test_on_batch", "gemnet.training.metrics.BestMetrics.update", "torch.save", "range", "os.path.basename", "gemnet.model.gemnet.GemNet.parameters", "gemnet.model.gemnet.GemNet.state_dict", "gemnet.training.trainer.Trainer.state_dict", "numpy.ceil", "gemnet.model.gemnet.GemNet.state_dict", "locals().items", "random.SystemRandom", "train_seml.run.id_generator"], "function", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.None.ase_calculator.Molecule.to", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.get_dataset", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.get_dataset", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.load_state_dict", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.load_state_dict", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.restore", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.inititalize", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.update", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.train_on_batch", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.save_variable_backups", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.load_averaged_variables", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.write", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.result", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.result", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.decay_maybe", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.write", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.write", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.reset_states", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.reset_states", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.restore_variable_backups", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.items", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.update", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.test_on_batch", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.update", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.state_dict", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.state_dict", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.state_dict", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.items"], ["", "", "@", "ex", ".", "automain", "\n", "def", "run", "(", "\n", "num_spherical", ",", "\n", "num_radial", ",", "\n", "num_blocks", ",", "\n", "emb_size_atom", ",", "\n", "emb_size_edge", ",", "\n", "emb_size_trip", ",", "\n", "emb_size_quad", ",", "\n", "emb_size_rbf", ",", "\n", "emb_size_cbf", ",", "\n", "emb_size_sbf", ",", "\n", "num_before_skip", ",", "\n", "num_after_skip", ",", "\n", "num_concat", ",", "\n", "num_atom", ",", "\n", "emb_size_bil_quad", ",", "\n", "emb_size_bil_trip", ",", "\n", "triplets_only", ",", "\n", "forces_coupled", ",", "\n", "direct_forces", ",", "\n", "mve", ",", "\n", "cutoff", ",", "\n", "int_cutoff", ",", "\n", "envelope_exponent", ",", "\n", "extensive", ",", "\n", "output_init", ",", "\n", "scale_file", ",", "\n", "data_seed", ",", "\n", "dataset", ",", "\n", "val_dataset", ",", "\n", "num_train", ",", "\n", "num_val", ",", "\n", "logdir", ",", "\n", "loss", ",", "\n", "tfseed", ",", "\n", "num_steps", ",", "\n", "rho_force", ",", "\n", "ema_decay", ",", "\n", "weight_decay", ",", "\n", "grad_clip_max", ",", "\n", "agc", ",", "\n", "decay_patience", ",", "\n", "decay_factor", ",", "\n", "decay_cooldown", ",", "\n", "batch_size", ",", "\n", "evaluation_interval", ",", "\n", "patience", ",", "\n", "save_interval", ",", "\n", "learning_rate", ",", "\n", "warmup_steps", ",", "\n", "decay_steps", ",", "\n", "decay_rate", ",", "\n", "staircase", ",", "\n", "restart", ",", "\n", "comment", ",", "\n", ")", ":", "\n", "\n", "    ", "torch", ".", "manual_seed", "(", "tfseed", ")", "\n", "\n", "logging", ".", "info", "(", "\"Start training\"", ")", "\n", "# log hyperparameters", "\n", "logging", ".", "info", "(", "\n", "\"Hyperparams: \\n\"", "+", "\"\\n\"", ".", "join", "(", "f\"{key}: {val}\"", "for", "key", ",", "val", "in", "locals", "(", ")", ".", "items", "(", ")", ")", "\n", ")", "\n", "num_gpus", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "cuda_available", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "logging", ".", "info", "(", "f\"Available GPUs: {num_gpus}\"", ")", "\n", "logging", ".", "info", "(", "f\"CUDA Available: {cuda_available}\"", ")", "\n", "if", "num_gpus", "==", "0", ":", "\n", "        ", "logging", ".", "warning", "(", "\"No GPUs were found. Training is run on CPU!\"", ")", "\n", "", "if", "not", "cuda_available", ":", "\n", "        ", "logging", ".", "warning", "(", "\"CUDA unavailable. Training is run on CPU!\"", ")", "\n", "\n", "# Used for creating a \"unique\" id for a run (almost impossible to generate the same twice)", "\n", "", "def", "id_generator", "(", "\n", "size", "=", "6", ",", "chars", "=", "string", ".", "ascii_uppercase", "+", "string", ".", "ascii_lowercase", "+", "string", ".", "digits", "\n", ")", ":", "\n", "        ", "return", "\"\"", ".", "join", "(", "random", ".", "SystemRandom", "(", ")", ".", "choice", "(", "chars", ")", "for", "_", "in", "range", "(", "size", ")", ")", "\n", "\n", "# A unique directory name is created for this run based on the input", "\n", "", "if", "(", "restart", "is", "None", ")", "or", "(", "restart", "==", "\"None\"", ")", ":", "\n", "        ", "directory", "=", "(", "\n", "logdir", "\n", "+", "\"/\"", "\n", "+", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"%Y%m%d_%H%M%S\"", ")", "\n", "+", "\"_\"", "\n", "+", "id_generator", "(", ")", "\n", "+", "\"_\"", "\n", "+", "os", ".", "path", ".", "basename", "(", "dataset", ")", "\n", "+", "\"_\"", "\n", "+", "str", "(", "comment", ")", "\n", ")", "\n", "", "else", ":", "\n", "        ", "directory", "=", "restart", "\n", "\n", "", "logging", ".", "info", "(", "f\"Directory: {directory}\"", ")", "\n", "logging", ".", "info", "(", "\"Create directories\"", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "directory", ",", "exist_ok", "=", "True", ")", "\n", "\n", "", "best_dir", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "\"best\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "best_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "best_dir", ")", "\n", "", "log_dir", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "\"logs\"", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "log_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "log_dir", ")", "\n", "\n", "", "extension", "=", "\".pth\"", "\n", "log_path_model", "=", "f\"{log_dir}/model{extension}\"", "\n", "log_path_training", "=", "f\"{log_dir}/training{extension}\"", "\n", "best_path_model", "=", "f\"{best_dir}/model{extension}\"", "\n", "\n", "logging", ".", "info", "(", "\"Initialize model\"", ")", "\n", "model", "=", "GemNet", "(", "\n", "num_spherical", "=", "num_spherical", ",", "\n", "num_radial", "=", "num_radial", ",", "\n", "num_blocks", "=", "num_blocks", ",", "\n", "emb_size_atom", "=", "emb_size_atom", ",", "\n", "emb_size_edge", "=", "emb_size_edge", ",", "\n", "emb_size_trip", "=", "emb_size_trip", ",", "\n", "emb_size_quad", "=", "emb_size_quad", ",", "\n", "emb_size_rbf", "=", "emb_size_rbf", ",", "\n", "emb_size_cbf", "=", "emb_size_cbf", ",", "\n", "emb_size_sbf", "=", "emb_size_sbf", ",", "\n", "num_before_skip", "=", "num_before_skip", ",", "\n", "num_after_skip", "=", "num_after_skip", ",", "\n", "num_concat", "=", "num_concat", ",", "\n", "num_atom", "=", "num_atom", ",", "\n", "emb_size_bil_quad", "=", "emb_size_bil_quad", ",", "\n", "emb_size_bil_trip", "=", "emb_size_bil_trip", ",", "\n", "num_targets", "=", "2", "if", "mve", "else", "1", ",", "\n", "triplets_only", "=", "triplets_only", ",", "\n", "direct_forces", "=", "direct_forces", ",", "\n", "forces_coupled", "=", "forces_coupled", ",", "\n", "cutoff", "=", "cutoff", ",", "\n", "int_cutoff", "=", "int_cutoff", ",", "\n", "envelope_exponent", "=", "envelope_exponent", ",", "\n", "activation", "=", "\"swish\"", ",", "\n", "extensive", "=", "extensive", ",", "\n", "output_init", "=", "output_init", ",", "\n", "scale_file", "=", "scale_file", ",", "\n", ")", "\n", "# push to GPU if available", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "model", ".", "to", "(", "device", ")", "\n", "\n", "# Initialize summary writer", "\n", "summary_writer", "=", "SummaryWriter", "(", "log_dir", ")", "\n", "train", "=", "{", "}", "\n", "validation", "=", "{", "}", "\n", "\n", "logging", ".", "info", "(", "\"Load dataset\"", ")", "\n", "data_container", "=", "DataContainer", "(", "\n", "dataset", ",", "cutoff", "=", "cutoff", ",", "int_cutoff", "=", "int_cutoff", ",", "triplets_only", "=", "triplets_only", "\n", ")", "\n", "\n", "if", "val_dataset", "is", "not", "None", ":", "\n", "# Initialize DataProvider", "\n", "        ", "if", "num_train", "==", "0", ":", "\n", "            ", "num_train", "=", "len", "(", "data_container", ")", "\n", "", "logging", ".", "info", "(", "f\"Training data size: {num_train}\"", ")", "\n", "data_provider", "=", "DataProvider", "(", "\n", "data_container", ",", "\n", "num_train", ",", "\n", "0", ",", "\n", "batch_size", ",", "\n", "seed", "=", "data_seed", ",", "\n", "shuffle", "=", "True", ",", "\n", "random_split", "=", "True", ",", "\n", ")", "\n", "\n", "# Initialize validation datasets", "\n", "val_data_container", "=", "DataContainer", "(", "\n", "val_dataset", ",", "\n", "cutoff", "=", "cutoff", ",", "\n", "int_cutoff", "=", "int_cutoff", ",", "\n", "triplets_only", "=", "triplets_only", ",", "\n", ")", "\n", "if", "num_val", "==", "0", ":", "\n", "            ", "num_val", "=", "len", "(", "val_data_container", ")", "\n", "", "logging", ".", "info", "(", "f\"Validation data size: {num_val}\"", ")", "\n", "val_data_provider", "=", "DataProvider", "(", "\n", "val_data_container", ",", "\n", "0", ",", "\n", "num_val", ",", "\n", "batch_size", ",", "\n", "seed", "=", "data_seed", ",", "\n", "shuffle", "=", "True", ",", "\n", "random_split", "=", "True", ",", "\n", ")", "\n", "", "else", ":", "\n", "# Initialize DataProvider (splits dataset into 3 sets based on data_seed and provides tf.datasets)", "\n", "        ", "logging", ".", "info", "(", "f\"Training data size: {num_train}\"", ")", "\n", "logging", ".", "info", "(", "f\"Validation data size: {num_val}\"", ")", "\n", "assert", "num_train", ">", "0", "\n", "assert", "num_val", ">", "0", "\n", "data_provider", "=", "DataProvider", "(", "\n", "data_container", ",", "\n", "num_train", ",", "\n", "num_val", ",", "\n", "batch_size", ",", "\n", "seed", "=", "data_seed", ",", "\n", "shuffle", "=", "True", ",", "\n", "random_split", "=", "True", ",", "\n", ")", "\n", "val_data_provider", "=", "data_provider", "\n", "\n", "# Initialize datasets", "\n", "", "train", "[", "\"dataset_iter\"", "]", "=", "data_provider", ".", "get_dataset", "(", "\"train\"", ")", "\n", "validation", "[", "\"dataset_iter\"", "]", "=", "val_data_provider", ".", "get_dataset", "(", "\"val\"", ")", "\n", "\n", "\n", "logging", ".", "info", "(", "\"Prepare training\"", ")", "\n", "# Initialize trainer", "\n", "trainer", "=", "Trainer", "(", "\n", "model", ",", "\n", "learning_rate", "=", "learning_rate", ",", "\n", "decay_steps", "=", "decay_steps", ",", "\n", "decay_rate", "=", "decay_rate", ",", "\n", "warmup_steps", "=", "warmup_steps", ",", "\n", "weight_decay", "=", "weight_decay", ",", "\n", "ema_decay", "=", "ema_decay", ",", "\n", "decay_patience", "=", "decay_patience", ",", "\n", "decay_factor", "=", "decay_factor", ",", "\n", "decay_cooldown", "=", "decay_cooldown", ",", "\n", "grad_clip_max", "=", "grad_clip_max", ",", "\n", "rho_force", "=", "rho_force", ",", "\n", "mve", "=", "mve", ",", "\n", "loss", "=", "loss", ",", "\n", "staircase", "=", "staircase", ",", "\n", "agc", "=", "agc", ",", "\n", ")", "\n", "\n", "# Initialize metrics", "\n", "train", "[", "\"metrics\"", "]", "=", "Metrics", "(", "\"train\"", ",", "trainer", ".", "tracked_metrics", ",", "ex", ")", "\n", "validation", "[", "\"metrics\"", "]", "=", "Metrics", "(", "\"val\"", ",", "trainer", ".", "tracked_metrics", ",", "ex", ")", "\n", "\n", "# Save/load best recorded loss (only the best model is saved)", "\n", "metrics_best", "=", "BestMetrics", "(", "best_dir", ",", "validation", "[", "\"metrics\"", "]", ")", "\n", "\n", "# Set up checkpointing", "\n", "# Restore latest checkpoint", "\n", "if", "os", ".", "path", ".", "exists", "(", "log_path_model", ")", ":", "\n", "        ", "logging", ".", "info", "(", "\"Restoring model and trainer\"", ")", "\n", "model_checkpoint", "=", "torch", ".", "load", "(", "log_path_model", ")", "\n", "model", ".", "load_state_dict", "(", "model_checkpoint", "[", "\"model\"", "]", ")", "\n", "\n", "train_checkpoint", "=", "torch", ".", "load", "(", "log_path_training", ")", "\n", "trainer", ".", "load_state_dict", "(", "train_checkpoint", "[", "\"trainer\"", "]", ")", "\n", "# restore the best saved results", "\n", "metrics_best", ".", "restore", "(", ")", "\n", "logging", ".", "info", "(", "f\"Restored best metrics: {metrics_best.loss}\"", ")", "\n", "step_init", "=", "int", "(", "train_checkpoint", "[", "\"step\"", "]", ")", "\n", "", "else", ":", "\n", "        ", "logging", ".", "info", "(", "\"Freshly initialize model\"", ")", "\n", "metrics_best", ".", "inititalize", "(", ")", "\n", "step_init", "=", "0", "\n", "\n", "", "if", "ex", "is", "not", "None", ":", "\n", "        ", "ex", ".", "current_run", ".", "info", "=", "{", "\"directory\"", ":", "directory", "}", "\n", "# save the number of parameters", "\n", "nparams", "=", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", ")", "\n", "ex", ".", "current_run", ".", "info", ".", "update", "(", "{", "\"nParams\"", ":", "nparams", "}", ")", "\n", "\n", "# Training loop", "\n", "", "logging", ".", "info", "(", "\"Start training\"", ")", "\n", "\n", "steps_per_epoch", "=", "int", "(", "np", ".", "ceil", "(", "num_train", "/", "batch_size", ")", ")", "\n", "for", "step", "in", "range", "(", "step_init", "+", "1", ",", "num_steps", "+", "1", ")", ":", "\n", "# start after evaluation to not include time on validation set", "\n", "        ", "if", "ex", "is", "not", "None", ":", "\n", "            ", "if", "step", "==", "evaluation_interval", "+", "1", ":", "\n", "                ", "start", "=", "time", ".", "perf_counter", "(", ")", "\n", "", "if", "step", "==", "2", "*", "evaluation_interval", "-", "1", ":", "\n", "                ", "end", "=", "time", ".", "perf_counter", "(", ")", "\n", "time_delta", "=", "end", "-", "start", "\n", "nsteps", "=", "evaluation_interval", "-", "2", "\n", "ex", ".", "current_run", ".", "info", ".", "update", "(", "\n", "{", "\"seconds_per_step\"", ":", "time_delta", "/", "nsteps", ",", "\n", "\"min_per_epoch\"", ":", "int", "(", "time_delta", "/", "nsteps", "*", "steps_per_epoch", "*", "100", "/", "60", ")", "/", "100", "# two digits only", "\n", "}", "\n", ")", "\n", "\n", "# keep track of the learning rate", "\n", "", "", "if", "step", "%", "10", "==", "0", ":", "\n", "            ", "lr", "=", "trainer", ".", "schedulers", "[", "0", "]", ".", "get_last_lr", "(", ")", "[", "0", "]", "\n", "summary_writer", ".", "add_scalar", "(", "\"lr\"", ",", "lr", ",", "global_step", "=", "step", ")", "\n", "\n", "# Perform training step", "\n", "", "trainer", ".", "train_on_batch", "(", "train", "[", "\"dataset_iter\"", "]", ",", "train", "[", "\"metrics\"", "]", ")", "\n", "\n", "# Save progress", "\n", "if", "step", "%", "save_interval", "==", "0", ":", "\n", "            ", "torch", ".", "save", "(", "{", "\"model\"", ":", "model", ".", "state_dict", "(", ")", "}", ",", "log_path_model", ")", "\n", "torch", ".", "save", "(", "\n", "{", "\"trainer\"", ":", "trainer", ".", "state_dict", "(", ")", ",", "\"step\"", ":", "step", "}", ",", "log_path_training", "\n", ")", "\n", "\n", "# Check performance on the validation set", "\n", "", "if", "step", "%", "evaluation_interval", "==", "0", ":", "\n", "\n", "# Save backup variables and load averaged variables", "\n", "            ", "trainer", ".", "save_variable_backups", "(", ")", "\n", "trainer", ".", "load_averaged_variables", "(", ")", "\n", "\n", "# Compute averages", "\n", "for", "i", "in", "range", "(", "int", "(", "np", ".", "ceil", "(", "num_val", "/", "batch_size", ")", ")", ")", ":", "\n", "                ", "trainer", ".", "test_on_batch", "(", "validation", "[", "\"dataset_iter\"", "]", ",", "validation", "[", "\"metrics\"", "]", ")", "\n", "\n", "# Update and save best result", "\n", "", "if", "validation", "[", "\"metrics\"", "]", ".", "loss", "<", "metrics_best", ".", "loss", ":", "\n", "                ", "metrics_best", ".", "update", "(", "step", ",", "validation", "[", "\"metrics\"", "]", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "best_path_model", ")", "\n", "\n", "# write to summary writer", "\n", "", "metrics_best", ".", "write", "(", "summary_writer", ",", "step", ")", "\n", "\n", "epoch", "=", "step", "//", "steps_per_epoch", "\n", "train_metrics_res", "=", "train", "[", "\"metrics\"", "]", ".", "result", "(", "append_tag", "=", "False", ")", "\n", "val_metrics_res", "=", "validation", "[", "\"metrics\"", "]", ".", "result", "(", "append_tag", "=", "False", ")", "\n", "metrics_strings", "=", "[", "\n", "f\"{key}: train={train_metrics_res[key]:.6f}, val={val_metrics_res[key]:.6f}\"", "\n", "for", "key", "in", "validation", "[", "\"metrics\"", "]", ".", "keys", "\n", "]", "\n", "logging", ".", "info", "(", "\n", "f\"{step}/{num_steps} (epoch {epoch}): \"", "+", "\"; \"", ".", "join", "(", "metrics_strings", ")", "\n", ")", "\n", "\n", "# decay learning rate on plateau", "\n", "trainer", ".", "decay_maybe", "(", "validation", "[", "\"metrics\"", "]", ".", "loss", ")", "\n", "\n", "train", "[", "\"metrics\"", "]", ".", "write", "(", "summary_writer", ",", "step", ")", "\n", "validation", "[", "\"metrics\"", "]", ".", "write", "(", "summary_writer", ",", "step", ")", "\n", "train", "[", "\"metrics\"", "]", ".", "reset_states", "(", ")", "\n", "validation", "[", "\"metrics\"", "]", ".", "reset_states", "(", ")", "\n", "\n", "# Restore backup variables", "\n", "trainer", ".", "restore_variable_backups", "(", ")", "\n", "\n", "# early stopping", "\n", "if", "step", "-", "metrics_best", ".", "step", ">", "patience", "*", "evaluation_interval", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "return", "{", "key", "+", "\"_best\"", ":", "val", "for", "key", ",", "val", "in", "metrics_best", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.__init__": [[82, 260], ["super().__init__", "layers.scaling.AutomaticFit.reset", "layers.basis_layers.BesselBasisLayer", "layers.basis_layers.SphericalBasisLayer", "layers.base_layers.Dense", "layers.efficient.EfficientInteractionDownProjection", "layers.base_layers.Dense", "layers.base_layers.Dense", "layers.embedding_block.AtomEmbedding", "layers.embedding_block.EdgeEmbedding", "range", "range", "torch.nn.ModuleList", "torch.nn.ModuleList", "layers.basis_layers.SphericalBasisLayer", "layers.basis_layers.TensorBasisLayer", "layers.base_layers.Dense", "layers.base_layers.Dense", "layers.efficient.EfficientInteractionDownProjection", "int_blocks.append", "out_blocks.append", "interaction_block", "layers.atom_update_block.OutputBlock"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.AutomaticFit.reset"], ["def", "__init__", "(", "\n", "self", ",", "\n", "num_spherical", ":", "int", ",", "\n", "num_radial", ":", "int", ",", "\n", "num_blocks", ":", "int", ",", "\n", "emb_size_atom", ":", "int", ",", "\n", "emb_size_edge", ":", "int", ",", "\n", "emb_size_trip", ":", "int", ",", "\n", "emb_size_quad", ":", "int", ",", "\n", "emb_size_rbf", ":", "int", ",", "\n", "emb_size_cbf", ":", "int", ",", "\n", "emb_size_sbf", ":", "int", ",", "\n", "emb_size_bil_quad", ":", "int", ",", "\n", "emb_size_bil_trip", ":", "int", ",", "\n", "num_before_skip", ":", "int", ",", "\n", "num_after_skip", ":", "int", ",", "\n", "num_concat", ":", "int", ",", "\n", "num_atom", ":", "int", ",", "\n", "triplets_only", ":", "bool", ",", "\n", "num_targets", ":", "int", "=", "1", ",", "\n", "direct_forces", ":", "bool", "=", "False", ",", "\n", "cutoff", ":", "float", "=", "5.0", ",", "\n", "int_cutoff", ":", "float", "=", "10.0", ",", "# no effect for GemNet-(d)T", "\n", "envelope_exponent", ":", "int", "=", "5", ",", "\n", "extensive", "=", "True", ",", "\n", "forces_coupled", ":", "bool", "=", "False", ",", "\n", "output_init", "=", "\"HeOrthogonal\"", ",", "\n", "activation", ":", "str", "=", "\"swish\"", ",", "\n", "scale_file", "=", "None", ",", "\n", "name", "=", "\"gemnet\"", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "num_blocks", ">", "0", "\n", "self", ".", "num_targets", "=", "num_targets", "\n", "self", ".", "num_blocks", "=", "num_blocks", "\n", "self", ".", "extensive", "=", "extensive", "\n", "\n", "self", ".", "forces_coupled", "=", "forces_coupled", "\n", "\n", "AutomaticFit", ".", "reset", "(", ")", "# make sure that queue is empty (avoid potential error)", "\n", "\n", "# GemNet variants", "\n", "self", ".", "direct_forces", "=", "direct_forces", "\n", "self", ".", "triplets_only", "=", "triplets_only", "\n", "\n", "### ---------------------------------- Basis Functions ---------------------------------- ###", "\n", "self", ".", "rbf_basis", "=", "BesselBasisLayer", "(", "\n", "num_radial", ",", "cutoff", "=", "cutoff", ",", "envelope_exponent", "=", "envelope_exponent", "\n", ")", "\n", "if", "not", "self", ".", "triplets_only", ":", "\n", "            ", "self", ".", "cbf_basis", "=", "SphericalBasisLayer", "(", "\n", "num_spherical", ",", "\n", "num_radial", ",", "\n", "cutoff", "=", "int_cutoff", ",", "\n", "envelope_exponent", "=", "envelope_exponent", ",", "\n", "efficient", "=", "False", ",", "\n", ")", "\n", "\n", "self", ".", "sbf_basis", "=", "TensorBasisLayer", "(", "\n", "num_spherical", ",", "\n", "num_radial", ",", "\n", "cutoff", "=", "cutoff", ",", "\n", "envelope_exponent", "=", "envelope_exponent", ",", "\n", "efficient", "=", "True", ",", "\n", ")", "\n", "\n", "", "self", ".", "cbf_basis3", "=", "SphericalBasisLayer", "(", "\n", "num_spherical", ",", "\n", "num_radial", ",", "\n", "cutoff", "=", "cutoff", ",", "\n", "envelope_exponent", "=", "envelope_exponent", ",", "\n", "efficient", "=", "True", ",", "\n", ")", "\n", "### ------------------------------------------------------------------------------------- ###", "\n", "\n", "### ------------------------------- Share Down Projections ------------------------------ ###", "\n", "# Share down projection across all interaction blocks", "\n", "if", "not", "self", ".", "triplets_only", ":", "\n", "            ", "self", ".", "mlp_rbf4", "=", "Dense", "(", "\n", "num_radial", ",", "\n", "emb_size_rbf", ",", "\n", "activation", "=", "None", ",", "\n", "name", "=", "\"MLP_rbf4_shared\"", ",", "\n", "bias", "=", "False", ",", "\n", ")", "\n", "self", ".", "mlp_cbf4", "=", "Dense", "(", "\n", "num_radial", "*", "num_spherical", ",", "\n", "emb_size_cbf", ",", "\n", "activation", "=", "None", ",", "\n", "name", "=", "\"MLP_cbf4_shared\"", ",", "\n", "bias", "=", "False", ",", "\n", ")", "\n", "self", ".", "mlp_sbf4", "=", "EfficientInteractionDownProjection", "(", "\n", "num_spherical", "**", "2", ",", "num_radial", ",", "emb_size_sbf", ",", "name", "=", "\"MLP_sbf4_shared\"", "\n", ")", "\n", "\n", "", "self", ".", "mlp_rbf3", "=", "Dense", "(", "\n", "num_radial", ",", "\n", "emb_size_rbf", ",", "\n", "activation", "=", "None", ",", "\n", "name", "=", "\"MLP_rbf3_shared\"", ",", "\n", "bias", "=", "False", ",", "\n", ")", "\n", "self", ".", "mlp_cbf3", "=", "EfficientInteractionDownProjection", "(", "\n", "num_spherical", ",", "num_radial", ",", "emb_size_cbf", ",", "name", "=", "\"MLP_cbf3_shared\"", "\n", ")", "\n", "\n", "# Share the dense Layer of the atom embedding block accross the interaction blocks", "\n", "self", ".", "mlp_rbf_h", "=", "Dense", "(", "\n", "num_radial", ",", "\n", "emb_size_rbf", ",", "\n", "activation", "=", "None", ",", "\n", "name", "=", "\"MLP_rbfh_shared\"", ",", "\n", "bias", "=", "False", ",", "\n", ")", "\n", "self", ".", "mlp_rbf_out", "=", "Dense", "(", "\n", "num_radial", ",", "\n", "emb_size_rbf", ",", "\n", "activation", "=", "None", ",", "\n", "name", "=", "\"MLP_rbfout_shared\"", ",", "\n", "bias", "=", "False", ",", "\n", ")", "\n", "### ------------------------------------------------------------------------------------- ###", "\n", "\n", "# Embedding block", "\n", "self", ".", "atom_emb", "=", "AtomEmbedding", "(", "emb_size_atom", ")", "\n", "self", ".", "edge_emb", "=", "EdgeEmbedding", "(", "\n", "emb_size_atom", ",", "num_radial", ",", "emb_size_edge", ",", "activation", "=", "activation", "\n", ")", "\n", "\n", "out_blocks", "=", "[", "]", "\n", "int_blocks", "=", "[", "]", "\n", "\n", "# Interaction Blocks", "\n", "interaction_block", "=", "(", "\n", "InteractionBlockTripletsOnly", "if", "self", ".", "triplets_only", "else", "InteractionBlock", "\n", ")", "# GemNet-(d)Q or -(d)T", "\n", "for", "i", "in", "range", "(", "num_blocks", ")", ":", "\n", "            ", "int_blocks", ".", "append", "(", "\n", "interaction_block", "(", "\n", "emb_size_atom", "=", "emb_size_atom", ",", "\n", "emb_size_edge", "=", "emb_size_edge", ",", "\n", "emb_size_trip", "=", "emb_size_trip", ",", "\n", "emb_size_quad", "=", "emb_size_quad", ",", "\n", "emb_size_rbf", "=", "emb_size_rbf", ",", "\n", "emb_size_cbf", "=", "emb_size_cbf", ",", "\n", "emb_size_sbf", "=", "emb_size_sbf", ",", "\n", "emb_size_bil_trip", "=", "emb_size_bil_trip", ",", "\n", "emb_size_bil_quad", "=", "emb_size_bil_quad", ",", "\n", "num_before_skip", "=", "num_before_skip", ",", "\n", "num_after_skip", "=", "num_after_skip", ",", "\n", "num_concat", "=", "num_concat", ",", "\n", "num_atom", "=", "num_atom", ",", "\n", "activation", "=", "activation", ",", "\n", "scale_file", "=", "scale_file", ",", "\n", "name", "=", "f\"IntBlock_{i+1}\"", ",", "\n", ")", "\n", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "num_blocks", "+", "1", ")", ":", "\n", "            ", "out_blocks", ".", "append", "(", "\n", "OutputBlock", "(", "\n", "emb_size_atom", "=", "emb_size_atom", ",", "\n", "emb_size_edge", "=", "emb_size_edge", ",", "\n", "emb_size_rbf", "=", "emb_size_rbf", ",", "\n", "nHidden", "=", "num_atom", ",", "\n", "num_targets", "=", "num_targets", ",", "\n", "activation", "=", "activation", ",", "\n", "output_init", "=", "output_init", ",", "\n", "direct_forces", "=", "direct_forces", ",", "\n", "scale_file", "=", "scale_file", ",", "\n", "name", "=", "f\"OutBlock_{i}\"", ",", "\n", ")", "\n", ")", "\n", "\n", "", "self", ".", "out_blocks", "=", "torch", ".", "nn", ".", "ModuleList", "(", "out_blocks", ")", "\n", "self", ".", "int_blocks", "=", "torch", ".", "nn", ".", "ModuleList", "(", "int_blocks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.calculate_interatomic_vectors": [[261, 287], ["torch.sqrt", "torch.sum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "calculate_interatomic_vectors", "(", "R", ",", "id_s", ",", "id_t", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n            R: Tensor, shape = (nAtoms,3)\n                Atom positions.\n            id_s: Tensor, shape = (nEdges,)\n                Indices of the source atom of the edges.\n            id_t: Tensor, shape = (nEdges,)\n                Indices of the target atom of the edges.\n\n        Returns\n        -------\n            (D_st, V_st): tuple\n                D_st: Tensor, shape = (nEdges,)\n                    Distance from atom t to s.\n                V_st: Tensor, shape = (nEdges,)\n                    Unit direction from atom t to s.\n        \"\"\"", "\n", "Rt", "=", "R", "[", "id_t", "]", "\n", "Rs", "=", "R", "[", "id_s", "]", "\n", "V_st", "=", "Rt", "-", "Rs", "# s -> t", "\n", "D_st", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "V_st", "**", "2", ",", "dim", "=", "1", ")", ")", "\n", "V_st", "=", "V_st", "/", "D_st", "[", "...", ",", "None", "]", "\n", "return", "D_st", ",", "V_st", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.calculate_neighbor_angles": [[288, 312], ["torch.sum", "torch.cross().norm", "torch.max", "torch.atan2", "torch.tensor", "torch.cross"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "calculate_neighbor_angles", "(", "R_ac", ",", "R_ab", ")", ":", "\n", "        ", "\"\"\"Calculate angles between atoms c <- a -> b.\n\n        Parameters\n        ----------\n            R_ac: Tensor, shape = (N,3)\n                Vector from atom a to c.\n            R_ab: Tensor, shape = (N,3)\n                Vector from atom a to b.\n\n        Returns\n        -------\n            angle_cab: Tensor, shape = (N,)\n                Angle between atoms c <- a -> b.\n        \"\"\"", "\n", "# cos(alpha) = (u * v) / (|u|*|v|)", "\n", "x", "=", "torch", ".", "sum", "(", "R_ac", "*", "R_ab", ",", "dim", "=", "1", ")", "# shape = (N,)", "\n", "# sin(alpha) = |u x v| / (|u|*|v|)", "\n", "y", "=", "torch", ".", "cross", "(", "R_ac", ",", "R_ab", ")", ".", "norm", "(", "dim", "=", "-", "1", ")", "# shape = (N,)", "\n", "# avoid that for y == (0,0,0) the gradient wrt. y becomes NaN", "\n", "y", "=", "torch", ".", "max", "(", "y", ",", "torch", ".", "tensor", "(", "1e-9", ")", ")", "\n", "angle", "=", "torch", ".", "atan2", "(", "y", ",", "x", ")", "\n", "return", "angle", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.vector_rejection": [[313, 333], ["torch.sum", "torch.sum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "vector_rejection", "(", "R_ab", ",", "P_n", ")", ":", "\n", "        ", "\"\"\"\n        Project the vector R_ab onto a plane with normal vector P_n.\n\n        Parameters\n        ----------\n            R_ab: Tensor, shape = (N,3)\n                Vector from atom a to b.\n            P_n: Tensor, shape = (N,3)\n                Normal vector of a plane onto which to project R_ab.\n\n        Returns\n        -------\n            R_ab_proj: Tensor, shape = (N,3)\n                Projected vector (orthogonal to P_n).\n        \"\"\"", "\n", "a_x_b", "=", "torch", ".", "sum", "(", "R_ab", "*", "P_n", ",", "dim", "=", "-", "1", ")", "\n", "b_x_b", "=", "torch", ".", "sum", "(", "P_n", "*", "P_n", ",", "dim", "=", "-", "1", ")", "\n", "return", "R_ab", "-", "(", "a_x_b", "/", "b_x_b", ")", "[", ":", ",", "None", "]", "*", "P_n", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.calculate_angles": [[334, 419], ["gemnet.GemNet.calculate_neighbor_angles", "gemnet.GemNet.vector_rejection", "gemnet.GemNet.calculate_neighbor_angles", "gemnet.GemNet.vector_rejection", "gemnet.GemNet.calculate_neighbor_angles"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.calculate_neighbor_angles", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.vector_rejection", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.calculate_neighbor_angles", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.vector_rejection", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.calculate_neighbor_angles"], ["", "@", "staticmethod", "\n", "def", "calculate_angles", "(", "\n", "R", ",", "\n", "id_c", ",", "\n", "id_a", ",", "\n", "id4_int_b", ",", "\n", "id4_int_a", ",", "\n", "id4_expand_abd", ",", "\n", "id4_reduce_cab", ",", "\n", "id4_expand_intm_db", ",", "\n", "id4_reduce_intm_ca", ",", "\n", "id4_expand_intm_ab", ",", "\n", "id4_reduce_intm_ab", ",", "\n", ")", ":", "\n", "        ", "\"\"\"Calculate angles for quadruplet-based message passing.\n\n        Parameters\n        ----------\n            R: Tensor, shape = (nAtoms,3)\n                Atom positions.\n            id_c: Tensor, shape = (nEdges,)\n                Indices of atom c (source atom of edge).\n            id_a: Tensor, shape = (nEdges,)\n                Indices of atom a (target atom of edge).\n            id4_int_b: torch.Tensor, shape (nInterEdges,)\n                Indices of the atom b of the interaction edge.\n            id4_int_a: torch.Tensor, shape (nInterEdges,)\n                Indices of the atom a of the interaction edge.\n            id4_expand_abd: torch.Tensor, shape (nQuadruplets,)\n                Indices to map from intermediate d->b to quadruplet d->b.\n            id4_reduce_cab: torch.Tensor, shape (nQuadruplets,)\n                Indices to map from intermediate c->a to quadruplet c->a.\n            id4_expand_intm_db: torch.Tensor, shape (intmTriplets,)\n                Indices to map d->b to intermediate d->b.\n            id4_reduce_intm_ca: torch.Tensor, shape (intmTriplets,)\n                Indices to map c->a to intermediate c->a.\n            id4_expand_intm_ab: torch.Tensor, shape (intmTriplets,)\n                Indices to map b-a to intermediate b-a of the quadruplet's part a-b<-d.\n            id4_reduce_intm_ab: torch.Tensor, shape (intmTriplets,)\n                Indices to map b-a to intermediate b-a of the quadruplet's part c->a-b.\n\n        Returns\n        -------\n            angle_cab: Tensor, shape = (nQuadruplets,)\n                Angle between atoms c <- a -> b.\n            angle_abd: Tensor, shape = (intmTriplets,)\n                Angle between atoms a <- b -> d.\n            angle_cabd: Tensor, shape = (nQuadruplets,)\n                Angle between atoms c <- a-b -> d.\n        \"\"\"", "\n", "# ---------------------------------- a - b <- d ---------------------------------- #", "\n", "Ra", "=", "R", "[", "id4_int_a", "[", "id4_expand_intm_ab", "]", "]", "# a       (intmTriplets,3)", "\n", "Rb", "=", "R", "[", "id4_int_b", "[", "id4_expand_intm_ab", "]", "]", "# b       (intmTriplets,3)", "\n", "# Rb = R[id_a[id4_expand_intm_db]      # d       (intmTriplets,3)", "\n", "Rd", "=", "R", "[", "id_c", "[", "id4_expand_intm_db", "]", "]", "# d       (intmTriplets,3)", "\n", "\n", "R_ba", "=", "Ra", "-", "Rb", "# (intmTriplets,3)", "\n", "R_bd", "=", "Rd", "-", "Rb", "# (intmTriplets,3)", "\n", "angle_abd", "=", "GemNet", ".", "calculate_neighbor_angles", "(", "R_ba", ",", "R_bd", ")", "# (intmTriplets,)", "\n", "\n", "# project for calculating gamma", "\n", "R_bd_proj", "=", "GemNet", ".", "vector_rejection", "(", "R_bd", ",", "R_ba", ")", "# a - b -| d", "\n", "R_bd_proj", "=", "R_bd_proj", "[", "id4_expand_abd", "]", "# (nQuadruplets,)", "\n", "\n", "# --------------------------------- c -> a <- b ---------------------------------- #", "\n", "Rc", "=", "R", "[", "id_c", "[", "id4_reduce_intm_ca", "]", "]", "# c      (intmTriplets,3)", "\n", "Ra", "=", "R", "[", "id_a", "[", "id4_reduce_intm_ca", "]", "]", "# a      (intmTriplets,3)", "\n", "# Ra = R[id4_int_a[id4_reduce_intm_ab]] # a      (intmTriplets,3)", "\n", "Rb", "=", "R", "[", "id4_int_b", "[", "id4_reduce_intm_ab", "]", "]", "# b      (intmTriplets,3)", "\n", "\n", "R_ac", "=", "Rc", "-", "Ra", "# (intmTriplets,3)", "\n", "R_ab", "=", "Rb", "-", "Ra", "# (intmTriplets,3)", "\n", "angle_cab", "=", "GemNet", ".", "calculate_neighbor_angles", "(", "R_ab", ",", "R_ac", ")", "# (intmTriplets,)", "\n", "angle_cab", "=", "angle_cab", "[", "id4_reduce_cab", "]", "# (nQuadruplets,)", "\n", "\n", "# project for calculating gamma", "\n", "R_ac_proj", "=", "GemNet", ".", "vector_rejection", "(", "R_ac", ",", "R_ab", ")", "# c |- a - b", "\n", "R_ac_proj", "=", "R_ac_proj", "[", "id4_reduce_cab", "]", "# (nQuadruplets,)", "\n", "\n", "# -------------------------------- c -> a - b <- d -------------------------------- #", "\n", "angle_cabd", "=", "GemNet", ".", "calculate_neighbor_angles", "(", "\n", "R_ac_proj", ",", "R_bd_proj", "\n", ")", "# (nQuadruplets,)", "\n", "\n", "return", "angle_cab", ",", "angle_abd", ",", "angle_cabd", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.calculate_angles3": [[420, 452], ["gemnet.GemNet.calculate_neighbor_angles"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.calculate_neighbor_angles"], ["", "@", "staticmethod", "\n", "def", "calculate_angles3", "(", "R", ",", "id_c", ",", "id_a", ",", "id3_reduce_ca", ",", "id3_expand_ba", ")", ":", "\n", "        ", "\"\"\"Calculate angles for triplet-based message passing.\n\n        Parameters\n        ----------\n            R: Tensor, shape = (nAtoms,3)\n                Atom positions.\n            id_c: Tensor, shape = (nEdges,)\n                Indices of atom c (source atom of edge).\n            id_a: Tensor, shape = (nEdges,)\n                Indices of atom a (target atom of edge).\n            id3_reduce_ca: Tensor, shape = (nTriplets,)\n                Edge indices of edge c -> a of the triplets.\n            id3_expand_ba: Tensor, shape = (nTriplets,)\n                Edge indices of edge b -> a of the triplets.\n\n        Returns\n        -------\n            angle_cab: Tensor, shape = (nTriplets,)\n                Angle between atoms c <- a -> b.\n        \"\"\"", "\n", "Rc", "=", "R", "[", "id_c", "[", "id3_reduce_ca", "]", "]", "\n", "Ra", "=", "R", "[", "id_a", "[", "id3_reduce_ca", "]", "]", "\n", "Rb", "=", "R", "[", "id_c", "[", "id3_expand_ba", "]", "]", "\n", "\n", "# difference vectors", "\n", "R_ac", "=", "Rc", "-", "Ra", "# shape = (nTriplets,3)", "\n", "R_ab", "=", "Rb", "-", "Ra", "# shape = (nTriplets,3)", "\n", "\n", "# angle in triplets", "\n", "return", "GemNet", ".", "calculate_neighbor_angles", "(", "R_ac", ",", "R_ab", ")", "# (nTriplets,)", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.forward": [[453, 616], ["gemnet.GemNet.calculate_interatomic_vectors", "gemnet.GemNet.rbf_basis", "gemnet.GemNet.calculate_angles3", "gemnet.GemNet.cbf_basis3", "gemnet.GemNet.atom_emb", "gemnet.GemNet.edge_emb", "gemnet.GemNet.mlp_rbf3", "gemnet.GemNet.mlp_cbf3", "gemnet.GemNet.mlp_rbf_h", "gemnet.GemNet.mlp_rbf_out", "range", "gemnet.GemNet.calculate_interatomic_vectors", "gemnet.GemNet.calculate_angles", "gemnet.GemNet.cbf_basis", "gemnet.GemNet.sbf_basis", "gemnet.GemNet.mlp_rbf4", "gemnet.GemNet.mlp_cbf4", "gemnet.GemNet.mlp_sbf4", "torch.max", "torch_scatter.scatter", "torch_scatter.scatter", "torch_scatter.scatter", "torch_scatter.scatter", "range", "torch.stack", "int", "torch.autograd.grad", "torch_scatter.scatter.sum", "torch.autograd.grad", "E_a[].sum"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.calculate_interatomic_vectors", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.calculate_angles3", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.calculate_interatomic_vectors", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.calculate_angles"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "Z", ",", "R", "=", "inputs", "[", "\"Z\"", "]", ",", "inputs", "[", "\"R\"", "]", "\n", "id_a", ",", "id_c", ",", "id_undir", ",", "id_swap", "=", "(", "\n", "inputs", "[", "\"id_a\"", "]", ",", "\n", "inputs", "[", "\"id_c\"", "]", ",", "\n", "inputs", "[", "\"id_undir\"", "]", ",", "\n", "inputs", "[", "\"id_swap\"", "]", ",", "\n", ")", "\n", "id3_expand_ba", ",", "id3_reduce_ca", "=", "inputs", "[", "\"id3_expand_ba\"", "]", ",", "inputs", "[", "\"id3_reduce_ca\"", "]", "\n", "if", "not", "self", ".", "triplets_only", ":", "\n", "            ", "batch_seg", ",", "Kidx4", ",", "Kidx3", "=", "(", "\n", "inputs", "[", "\"batch_seg\"", "]", ",", "\n", "inputs", "[", "\"Kidx4\"", "]", ",", "\n", "inputs", "[", "\"Kidx3\"", "]", ",", "\n", ")", "\n", "id4_int_b", ",", "id4_int_a", "=", "inputs", "[", "\"id4_int_b\"", "]", ",", "inputs", "[", "\"id4_int_a\"", "]", "\n", "id4_reduce_ca", ",", "id4_expand_db", "=", "(", "\n", "inputs", "[", "\"id4_reduce_ca\"", "]", ",", "\n", "inputs", "[", "\"id4_expand_db\"", "]", ",", "\n", ")", "\n", "id4_reduce_cab", ",", "id4_expand_abd", "=", "(", "\n", "inputs", "[", "\"id4_reduce_cab\"", "]", ",", "\n", "inputs", "[", "\"id4_expand_abd\"", "]", ",", "\n", ")", "\n", "id4_reduce_intm_ca", ",", "id4_expand_intm_db", "=", "(", "\n", "inputs", "[", "\"id4_reduce_intm_ca\"", "]", ",", "\n", "inputs", "[", "\"id4_expand_intm_db\"", "]", ",", "\n", ")", "\n", "id4_reduce_intm_ab", ",", "id4_expand_intm_ab", "=", "(", "\n", "inputs", "[", "\"id4_reduce_intm_ab\"", "]", ",", "\n", "inputs", "[", "\"id4_expand_intm_ab\"", "]", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "batch_seg", ",", "Kidx4", ",", "Kidx3", "=", "inputs", "[", "\"batch_seg\"", "]", ",", "None", ",", "inputs", "[", "\"Kidx3\"", "]", "\n", "id4_int_b", ",", "id4_int_a", "=", "None", ",", "None", "\n", "id4_reduce_ca", ",", "id4_expand_db", "=", "None", ",", "None", "\n", "id4_reduce_cab", ",", "id4_expand_abd", "=", "None", ",", "None", "\n", "id4_reduce_intm_ca", ",", "id4_expand_intm_db", "=", "None", ",", "None", "\n", "id4_reduce_intm_ab", ",", "id4_expand_intm_ab", "=", "None", ",", "None", "\n", "\n", "", "if", "not", "self", ".", "direct_forces", ":", "\n", "            ", "inputs", "[", "\"R\"", "]", ".", "requires_grad", "=", "True", "\n", "\n", "# Calculate distances", "\n", "", "D_ca", ",", "V_ca", "=", "self", ".", "calculate_interatomic_vectors", "(", "R", ",", "id_c", ",", "id_a", ")", "\n", "\n", "if", "not", "self", ".", "triplets_only", ":", "\n", "            ", "D_ab", ",", "_", "=", "self", ".", "calculate_interatomic_vectors", "(", "R", ",", "id4_int_b", ",", "id4_int_a", ")", "\n", "\n", "# Calculate angles", "\n", "Phi_cab", ",", "Phi_abd", ",", "Theta_cabd", "=", "self", ".", "calculate_angles", "(", "\n", "R", ",", "\n", "id_c", ",", "\n", "id_a", ",", "\n", "id4_int_b", ",", "\n", "id4_int_a", ",", "\n", "id4_expand_abd", ",", "\n", "id4_reduce_cab", ",", "\n", "id4_expand_intm_db", ",", "\n", "id4_reduce_intm_ca", ",", "\n", "id4_expand_intm_ab", ",", "\n", "id4_reduce_intm_ab", ",", "\n", ")", "\n", "\n", "cbf4", "=", "self", ".", "cbf_basis", "(", "D_ab", ",", "Phi_abd", ",", "id4_expand_intm_ab", ",", "None", ")", "\n", "sbf4", "=", "self", ".", "sbf_basis", "(", "D_ca", ",", "Phi_cab", ",", "Theta_cabd", ",", "id4_reduce_ca", ",", "Kidx4", ")", "\n", "\n", "", "rbf", "=", "self", ".", "rbf_basis", "(", "D_ca", ")", "\n", "# Triplet Interaction", "\n", "Angles3_cab", "=", "self", ".", "calculate_angles3", "(", "\n", "R", ",", "id_c", ",", "id_a", ",", "id3_reduce_ca", ",", "id3_expand_ba", "\n", ")", "\n", "cbf3", "=", "self", ".", "cbf_basis3", "(", "D_ca", ",", "Angles3_cab", ",", "id3_reduce_ca", ",", "Kidx3", ")", "\n", "\n", "# Embedding block", "\n", "h", "=", "self", ".", "atom_emb", "(", "Z", ")", "# (nAtoms, emb_size_atom)", "\n", "m", "=", "self", ".", "edge_emb", "(", "h", ",", "rbf", ",", "id_c", ",", "id_a", ")", "# (nEdges, emb_size_edge)", "\n", "\n", "# Shared Down Projections", "\n", "if", "not", "self", ".", "triplets_only", ":", "\n", "            ", "rbf4", "=", "self", ".", "mlp_rbf4", "(", "rbf", ")", "\n", "cbf4", "=", "self", ".", "mlp_cbf4", "(", "cbf4", ")", "\n", "sbf4", "=", "self", ".", "mlp_sbf4", "(", "sbf4", ")", "\n", "", "else", ":", "\n", "            ", "rbf4", "=", "None", "\n", "cbf4", "=", "None", "\n", "sbf4", "=", "None", "\n", "\n", "", "rbf3", "=", "self", ".", "mlp_rbf3", "(", "rbf", ")", "\n", "cbf3", "=", "self", ".", "mlp_cbf3", "(", "cbf3", ")", "\n", "\n", "rbf_h", "=", "self", ".", "mlp_rbf_h", "(", "rbf", ")", "\n", "rbf_out", "=", "self", ".", "mlp_rbf_out", "(", "rbf", ")", "\n", "\n", "E_a", ",", "F_ca", "=", "self", ".", "out_blocks", "[", "0", "]", "(", "h", ",", "m", ",", "rbf_out", ",", "id_a", ")", "\n", "# (nAtoms, num_targets), (nEdges, num_targets)", "\n", "\n", "for", "i", "in", "range", "(", "self", ".", "num_blocks", ")", ":", "\n", "# Interaction block", "\n", "            ", "h", ",", "m", "=", "self", ".", "int_blocks", "[", "i", "]", "(", "\n", "h", "=", "h", ",", "\n", "m", "=", "m", ",", "\n", "rbf4", "=", "rbf4", ",", "\n", "cbf4", "=", "cbf4", ",", "\n", "sbf4", "=", "sbf4", ",", "\n", "Kidx4", "=", "Kidx4", ",", "\n", "rbf3", "=", "rbf3", ",", "\n", "cbf3", "=", "cbf3", ",", "\n", "Kidx3", "=", "Kidx3", ",", "\n", "id_swap", "=", "id_swap", ",", "\n", "id3_expand_ba", "=", "id3_expand_ba", ",", "\n", "id3_reduce_ca", "=", "id3_reduce_ca", ",", "\n", "id4_reduce_ca", "=", "id4_reduce_ca", ",", "\n", "id4_expand_intm_db", "=", "id4_expand_intm_db", ",", "\n", "id4_expand_abd", "=", "id4_expand_abd", ",", "\n", "rbf_h", "=", "rbf_h", ",", "\n", "id_c", "=", "id_c", ",", "\n", "id_a", "=", "id_a", ",", "\n", ")", "# (nAtoms, emb_size_atom), (nEdges, emb_size_edge)", "\n", "\n", "E", ",", "F", "=", "self", ".", "out_blocks", "[", "i", "+", "1", "]", "(", "h", ",", "m", ",", "rbf_out", ",", "id_a", ")", "\n", "# (nAtoms, num_targets), (nEdges, num_targets)", "\n", "F_ca", "+=", "F", "\n", "E_a", "+=", "E", "\n", "\n", "", "nMolecules", "=", "torch", ".", "max", "(", "batch_seg", ")", "+", "1", "\n", "if", "self", ".", "extensive", ":", "\n", "            ", "E_a", "=", "scatter", "(", "E_a", ",", "batch_seg", ",", "dim", "=", "0", ",", "dim_size", "=", "nMolecules", ",", "reduce", "=", "\"add\"", ")", "\n", "# (nMolecules, num_targets)", "\n", "", "else", ":", "\n", "            ", "E_a", "=", "scatter", "(", "E_a", ",", "batch_seg", ",", "dim", "=", "0", ",", "dim_size", "=", "nMolecules", ",", "reduce", "=", "\"mean\"", ")", "\n", "# (nMolecules, num_targets)", "\n", "\n", "", "if", "self", ".", "direct_forces", ":", "\n", "            ", "nAtoms", "=", "Z", ".", "shape", "[", "0", "]", "\n", "if", "self", ".", "forces_coupled", ":", "# enforce F_abs_ji = F_ca", "\n", "                ", "nEdges", "=", "id_c", ".", "shape", "[", "0", "]", "\n", "F_ca", "=", "scatter", "(", "F_ca", ",", "id_undir", ",", "dim", "=", "0", ",", "dim_size", "=", "int", "(", "nEdges", "/", "2", ")", ",", "reduce", "=", "\"mean\"", ")", "\n", "# (nEdges/2, num_targets)", "\n", "F_ca", "=", "F_ca", "[", "id_undir", "]", "# (nEdges, num_targets)", "\n", "\n", "# map forces in edge directions", "\n", "", "F_ji", "=", "F_ca", "[", ":", ",", ":", ",", "None", "]", "*", "V_ca", "[", ":", ",", "None", ",", ":", "]", "# (nEdges, num_targets, 3)", "\n", "F_j", "=", "scatter", "(", "F_ji", ",", "id_a", ",", "dim", "=", "0", ",", "dim_size", "=", "nAtoms", ",", "reduce", "=", "\"add\"", ")", "\n", "# (nAtoms, num_targets, 3)", "\n", "", "else", ":", "\n", "\n", "            ", "if", "self", ".", "num_targets", ">", "1", ":", "\n", "                ", "forces", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "self", ".", "num_targets", ")", ":", "\n", "# maybe this can be solved differently", "\n", "                    ", "forces", "+=", "[", "\n", "-", "torch", ".", "autograd", ".", "grad", "(", "\n", "E_a", "[", ":", ",", "i", "]", ".", "sum", "(", ")", ",", "inputs", "[", "\"R\"", "]", ",", "create_graph", "=", "True", "\n", ")", "[", "0", "]", "\n", "]", "\n", "", "F_j", "=", "torch", ".", "stack", "(", "forces", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "F_j", "=", "-", "torch", ".", "autograd", ".", "grad", "(", "E_a", ".", "sum", "(", ")", ",", "inputs", "[", "\"R\"", "]", ",", "create_graph", "=", "True", ")", "[", "0", "]", "\n", "\n", "", "inputs", "[", "\"R\"", "]", ".", "requires_grad", "=", "False", "\n", "\n", "", "return", "E_a", ",", "F_j", "# (nMolecules, num_targets),  (nEdges, num_targets)", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.load_tfmodel": [[617, 778], ["tf.train.load_checkpoint", "gemnet.GemNet.load_tfmodel.copy_"], "methods", ["None"], ["", "def", "load_tfmodel", "(", "self", ",", "path", ")", ":", "\n", "\n", "        ", "reader", "=", "tf", ".", "train", ".", "load_checkpoint", "(", "path", ")", "\n", "\n", "def", "copy_", "(", "src", ",", "name", ")", ":", "\n", "            ", "W", "=", "reader", ".", "get_tensor", "(", "f\"{name}/.ATTRIBUTES/VARIABLE_VALUE\"", ")", "\n", "if", "name", "[", "-", "12", ":", "]", "==", "\"scale_factor\"", ":", "# only floats not numpy arrays", "\n", "                ", "W", "=", "torch", ".", "tensor", "(", "W", ")", "\n", "", "else", ":", "\n", "                ", "W", "=", "torch", ".", "from_numpy", "(", "W", ")", "\n", "", "if", "name", "[", "-", "6", ":", "]", "==", "\"kernel\"", ":", "\n", "                ", "if", "len", "(", "W", ".", "shape", ")", "==", "2", ":", "\n", "                    ", "W", "=", "W", ".", "t", "(", ")", "\n", "\n", "", "", "src", ".", "data", ".", "copy_", "(", "W", ")", "\n", "\n", "", "copy_", "(", "self", ".", "rbf_basis", ".", "frequencies", ",", "\"rbf_basis/frequencies\"", ")", "\n", "copy_", "(", "self", ".", "atom_emb", ".", "embeddings", ".", "weight", ",", "\"atom_emb/embeddings\"", ")", "\n", "copy_", "(", "self", ".", "edge_emb", ".", "dense", ".", "weight", ",", "\"edge_emb/dense/kernel\"", ")", "\n", "\n", "shared_mlps", "=", "[", "\"mlp_cbf3\"", ",", "\"mlp_rbf3\"", ",", "\"mlp_rbf_h\"", ",", "\"mlp_rbf_out\"", "]", "\n", "if", "not", "self", ".", "triplets_only", ":", "\n", "            ", "shared_mlps", "+=", "[", "\"mlp_rbf4\"", ",", "\"mlp_cbf4\"", ",", "\"mlp_sbf4\"", "]", "\n", "\n", "", "for", "layer", "in", "shared_mlps", ":", "\n", "            ", "copy_", "(", "getattr", "(", "self", ",", "layer", ")", ".", "weight", ",", "f\"{layer}/kernel\"", ")", "\n", "\n", "", "for", "i", ",", "block", "in", "enumerate", "(", "self", ".", "int_blocks", ")", ":", "\n", "            ", "if", "not", "self", ".", "triplets_only", ":", "\n", "## quadruplet interaction", "\n", "# kernels", "\n", "                ", "for", "layer", "in", "[", "\n", "\"dense_db\"", ",", "\n", "\"mlp_rbf\"", ",", "\n", "\"mlp_cbf\"", ",", "\n", "\"mlp_sbf\"", ",", "\n", "\"down_projection\"", ",", "\n", "\"up_projection_ca\"", ",", "\n", "\"up_projection_ac\"", ",", "\n", "]", ":", "\n", "                    ", "copy_", "(", "\n", "getattr", "(", "block", ".", "quad_interaction", ",", "layer", ")", ".", "weight", ",", "\n", "f\"int_blocks/{i}/quad_interaction/{layer}/kernel\"", ",", "\n", ")", "\n", "# scaling factors", "\n", "", "for", "layer", "in", "[", "\"rbf\"", ",", "\"cbf\"", ",", "\"sbf_sum\"", "]", ":", "\n", "                    ", "copy_", "(", "\n", "getattr", "(", "block", ".", "quad_interaction", ",", "f\"scale_{layer}\"", ")", ".", "scale_factor", ",", "\n", "f\"int_blocks/{i}/quad_interaction/scale_{layer}/scale_factor\"", ",", "\n", ")", "\n", "\n", "## triplet interaction", "\n", "# kernels", "\n", "", "", "for", "layer", "in", "[", "\n", "\"dense_ba\"", ",", "\n", "\"mlp_rbf\"", ",", "\n", "\"mlp_cbf\"", ",", "\n", "\"down_projection\"", ",", "\n", "\"up_projection_ac\"", ",", "\n", "\"up_projection_ca\"", ",", "\n", "]", ":", "\n", "                ", "copy_", "(", "\n", "getattr", "(", "block", ".", "trip_interaction", ",", "layer", ")", ".", "weight", ",", "\n", "f\"int_blocks/{i}/trip_interaction/{layer}/kernel\"", ",", "\n", ")", "\n", "# scaling factors", "\n", "", "for", "layer", "in", "[", "\"rbf\"", ",", "\"cbf_sum\"", "]", ":", "\n", "                ", "copy_", "(", "\n", "getattr", "(", "block", ".", "trip_interaction", ",", "f\"scale_{layer}\"", ")", ".", "scale_factor", ",", "\n", "f\"int_blocks/{i}/trip_interaction/scale_{layer}/scale_factor\"", ",", "\n", ")", "\n", "\n", "## atom update", "\n", "# block.atom_update", "\n", "", "copy_", "(", "\n", "block", ".", "atom_update", ".", "dense_rbf", ".", "weight", ",", "\n", "f\"int_blocks/{i}/atom_update/dense_rbf/kernel\"", ",", "\n", ")", "\n", "copy_", "(", "\n", "block", ".", "atom_update", ".", "scale_sum", ".", "scale_factor", ",", "\n", "f\"int_blocks/{i}/atom_update/scale_sum/scale_factor\"", ",", "\n", ")", "\n", "copy_", "(", "\n", "block", ".", "atom_update", ".", "layers", "[", "0", "]", ".", "weight", ",", "\n", "f\"int_blocks/{i}/atom_update/layers/0/kernel\"", ",", "\n", ")", "\n", "# residual blocks", "\n", "for", "j", ",", "res_layer", "in", "enumerate", "(", "block", ".", "atom_update", ".", "layers", "[", "1", ":", "]", ")", ":", "\n", "                ", "j", "=", "j", "+", "1", "\n", "for", "k", ",", "layer", "in", "enumerate", "(", "res_layer", ".", "dense_mlp", ")", ":", "\n", "                    ", "copy_", "(", "\n", "layer", ".", "weight", ",", "\n", "f\"int_blocks/{i}/atom_update/layers/{j}/dense_mlp/layer_with_weights-{k}/kernel\"", ",", "\n", ")", "\n", "\n", "## rest", "\n", "", "", "copy_", "(", "\n", "block", ".", "concat_layer", ".", "dense", ".", "weight", ",", "\n", "f\"int_blocks/{i}/concat_layer/dense/kernel\"", ",", "\n", ")", "\n", "copy_", "(", "block", ".", "dense_ca", ".", "weight", ",", "f\"int_blocks/{i}/dense_ca/kernel\"", ")", "\n", "# after skip", "\n", "for", "j", ",", "res_layer", "in", "enumerate", "(", "block", ".", "layers_after_skip", ")", ":", "\n", "                ", "for", "k", ",", "layer", "in", "enumerate", "(", "res_layer", ".", "dense_mlp", ")", ":", "\n", "                    ", "copy_", "(", "\n", "layer", ".", "weight", ",", "\n", "f\"int_blocks/{i}/layers_after_skip/{j}/dense_mlp/layer_with_weights-{k}/kernel\"", ",", "\n", ")", "\n", "# before skip", "\n", "", "", "for", "j", ",", "res_layer", "in", "enumerate", "(", "block", ".", "layers_before_skip", ")", ":", "\n", "                ", "for", "k", ",", "layer", "in", "enumerate", "(", "res_layer", ".", "dense_mlp", ")", ":", "\n", "                    ", "copy_", "(", "\n", "layer", ".", "weight", ",", "\n", "f\"int_blocks/{i}/layers_before_skip/{j}/dense_mlp/layer_with_weights-{k}/kernel\"", ",", "\n", ")", "\n", "# after concat", "\n", "", "", "for", "j", ",", "res_layer", "in", "enumerate", "(", "block", ".", "residual_m", ")", ":", "\n", "                ", "for", "k", ",", "layer", "in", "enumerate", "(", "res_layer", ".", "dense_mlp", ")", ":", "\n", "                    ", "copy_", "(", "\n", "layer", ".", "weight", ",", "\n", "f\"int_blocks/{i}/residual_m/{j}/dense_mlp/layer_with_weights-{k}/kernel\"", ",", "\n", ")", "\n", "\n", "## output blocks", "\n", "", "", "", "for", "i", ",", "block", "in", "enumerate", "(", "self", ".", "out_blocks", ")", ":", "\n", "# dense layers", "\n", "            ", "copy_", "(", "block", ".", "dense_rbf", ".", "weight", ",", "f\"out_blocks/{i}/dense_rbf/kernel\"", ")", "\n", "copy_", "(", "block", ".", "layers", "[", "0", "]", ".", "weight", ",", "f\"out_blocks/{i}/layers/0/kernel\"", ")", "\n", "# residual blocks", "\n", "for", "j", ",", "res_layer", "in", "enumerate", "(", "block", ".", "layers", "[", "1", ":", "]", ")", ":", "\n", "                ", "j", "=", "j", "+", "1", "\n", "for", "k", ",", "layer", "in", "enumerate", "(", "res_layer", ".", "dense_mlp", ")", ":", "\n", "                    ", "copy_", "(", "\n", "layer", ".", "weight", ",", "\n", "f\"out_blocks/{i}/layers/{j}/dense_mlp/layer_with_weights-{k}/kernel\"", ",", "\n", ")", "\n", "\n", "# final dense layer", "\n", "", "", "copy_", "(", "block", ".", "out_energy", ".", "weight", ",", "f\"out_blocks/{i}/out_energy/kernel\"", ")", "\n", "# scaling factors", "\n", "copy_", "(", "\n", "block", ".", "scale_sum", ".", "scale_factor", ",", "f\"out_blocks/{i}/scale_sum/scale_factor\"", "\n", ")", "\n", "\n", "if", "self", ".", "direct_forces", ":", "\n", "# dense layers", "\n", "                ", "copy_", "(", "block", ".", "out_forces", ".", "weight", ",", "f\"out_blocks/{i}/out_forces/kernel\"", ")", "\n", "copy_", "(", "block", ".", "out_forces", ".", "bias", ",", "f\"out_blocks/{i}/out_forces/bias\"", ")", "\n", "copy_", "(", "block", ".", "seq_forces", "[", "0", "]", ".", "weight", ",", "f\"out_blocks/{i}/seq_forces/0/kernel\"", ")", "\n", "# scaling factors", "\n", "copy_", "(", "\n", "block", ".", "scale_rbf", ".", "scale_factor", ",", "\n", "f\"out_blocks/{i}/scale_rbf/scale_factor\"", ",", "\n", ")", "\n", "# residual blocks", "\n", "for", "j", ",", "res_layer", "in", "enumerate", "(", "block", ".", "seq_forces", "[", "1", ":", "]", ")", ":", "\n", "                    ", "j", "=", "j", "+", "1", "\n", "for", "k", ",", "layer", "in", "enumerate", "(", "res_layer", ".", "dense_mlp", ")", ":", "\n", "                        ", "copy_", "(", "\n", "layer", ".", "weight", ",", "\n", "f\"out_blocks/{i}/seq_forces/{j}/dense_mlp/layer_with_weights-{k}/kernel\"", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.predict": [[780, 785], ["gemnet.GemNet.", "E.detach().cpu.detach().cpu.detach().cpu", "F.detach().cpu.detach().cpu.detach().cpu", "E.detach().cpu.detach().cpu.detach", "F.detach().cpu.detach().cpu.detach"], "methods", ["None"], ["", "", "", "", "", "def", "predict", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "E", ",", "F", "=", "self", "(", "inputs", ")", "\n", "E", "=", "E", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "F", "=", "F", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "return", "E", ",", "F", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.load_weights": [[786, 788], ["gemnet.GemNet.load_state_dict", "torch.load"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.load_state_dict"], ["", "def", "load_weights", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "load_state_dict", "(", "torch", ".", "load", "(", "path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.gemnet.GemNet.save_weights": [[789, 791], ["torch.save", "gemnet.GemNet.state_dict"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.state_dict"], ["", "def", "save_weights", "(", "self", ",", "path", ")", ":", "\n", "        ", "torch", ".", "save", "(", "self", ".", "state_dict", "(", ")", ",", "path", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.initializers._standardize": [[4, 18], ["torch.var_mean", "len"], "function", ["None"], ["def", "_standardize", "(", "kernel", ")", ":", "\n", "    ", "\"\"\"\n    Makes sure that Var(W) = 1 and E[W] = 0\n    \"\"\"", "\n", "eps", "=", "1e-6", "\n", "\n", "if", "len", "(", "kernel", ".", "shape", ")", "==", "3", ":", "\n", "        ", "axis", "=", "[", "0", ",", "1", "]", "# last dimension is output dimension", "\n", "", "else", ":", "\n", "        ", "axis", "=", "1", "\n", "\n", "", "var", ",", "mean", "=", "torch", ".", "var_mean", "(", "kernel", ",", "dim", "=", "axis", ",", "unbiased", "=", "True", ",", "keepdim", "=", "True", ")", "\n", "kernel", "=", "(", "kernel", "-", "mean", ")", "/", "(", "var", "+", "eps", ")", "**", "0.5", "\n", "return", "kernel", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.initializers.he_orthogonal_init": [[20, 41], ["torch.nn.init.orthogonal_", "len", "torch.nn.init.orthogonal_.shape[].numel", "torch.no_grad", "initializers._standardize"], "function", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.initializers._standardize"], ["", "def", "he_orthogonal_init", "(", "tensor", ")", ":", "\n", "    ", "\"\"\"\n    Generate a weight matrix with variance according to He initialization.\n    Based on a random (semi-)orthogonal matrix neural networks\n    are expected to learn better when features are decorrelated\n    (stated by eg. \"Reducing overfitting in deep networks by decorrelating representations\",\n    \"Dropout: a simple way to prevent neural networks from overfitting\",\n    \"Exact solutions to the nonlinear dynamics of learning in deep linear neural networks\")\n    \"\"\"", "\n", "tensor", "=", "torch", ".", "nn", ".", "init", ".", "orthogonal_", "(", "tensor", ")", "\n", "\n", "if", "len", "(", "tensor", ".", "shape", ")", "==", "3", ":", "\n", "        ", "fan_in", "=", "tensor", ".", "shape", "[", ":", "-", "1", "]", ".", "numel", "(", ")", "\n", "", "else", ":", "\n", "        ", "fan_in", "=", "tensor", ".", "shape", "[", "1", "]", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "tensor", ".", "data", "=", "_standardize", "(", "tensor", ".", "data", ")", "\n", "tensor", ".", "data", "*=", "(", "1", "/", "fan_in", ")", "**", "0.5", "\n", "\n", "", "return", "tensor", "\n", "", ""]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.utils.read_json": [[4, 12], ["path.endswith", "UserWarning", "open", "json.load"], "function", ["None"], ["def", "read_json", "(", "path", ")", ":", "\n", "    ", "\"\"\" \"\"\"", "\n", "if", "not", "path", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "        ", "raise", "UserWarning", "(", "f\"Path {path} is not a json-path.\"", ")", "\n", "\n", "", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "content", "=", "json", ".", "load", "(", "f", ")", "\n", "", "return", "content", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.utils.update_json": [[14, 22], ["utils.read_json", "read_json.update", "utils.write_json", "path.endswith", "UserWarning"], "function", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.utils.read_json", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.update", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.utils.write_json"], ["", "def", "update_json", "(", "path", ",", "data", ")", ":", "\n", "    ", "\"\"\" \"\"\"", "\n", "if", "not", "path", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "        ", "raise", "UserWarning", "(", "f\"Path {path} is not a json-path.\"", ")", "\n", "\n", "", "content", "=", "read_json", "(", "path", ")", "\n", "content", ".", "update", "(", "data", ")", "\n", "write_json", "(", "path", ",", "content", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.utils.write_json": [[24, 31], ["path.endswith", "UserWarning", "open", "json.dump"], "function", ["None"], ["", "def", "write_json", "(", "path", ",", "data", ")", ":", "\n", "    ", "\"\"\" \"\"\"", "\n", "if", "not", "path", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "        ", "raise", "UserWarning", "(", "f\"Path {path} is not a json-path.\"", ")", "\n", "\n", "", "with", "open", "(", "path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "data", ",", "f", ",", "ensure_ascii", "=", "False", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.utils.read_value_json": [[33, 41], ["utils.read_json", "read_json.keys"], "function", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.utils.read_json"], ["", "", "def", "read_value_json", "(", "path", ",", "key", ")", ":", "\n", "    ", "\"\"\" \"\"\"", "\n", "content", "=", "read_json", "(", "path", ")", "\n", "\n", "if", "key", "in", "content", ".", "keys", "(", ")", ":", "\n", "        ", "return", "content", "[", "key", "]", "\n", "", "else", ":", "\n", "        ", "return", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.interaction_block.InteractionBlock.__init__": [[49, 157], ["super().__init__", "base_layers.Dense", "interaction_block.QuadrupletInteraction", "interaction_block.TripletInteraction", "torch.nn.ModuleList", "torch.nn.ModuleList", "atom_update_block.AtomUpdateBlock", "embedding_block.EdgeEmbedding", "torch.nn.ModuleList", "name.split", "base_layers.ResidualLayer", "base_layers.ResidualLayer", "base_layers.ResidualLayer", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "emb_size_atom", ",", "\n", "emb_size_edge", ",", "\n", "emb_size_trip", ",", "\n", "emb_size_quad", ",", "\n", "emb_size_rbf", ",", "\n", "emb_size_cbf", ",", "\n", "emb_size_sbf", ",", "\n", "emb_size_bil_trip", ",", "\n", "emb_size_bil_quad", ",", "\n", "num_before_skip", ",", "\n", "num_after_skip", ",", "\n", "num_concat", ",", "\n", "num_atom", ",", "\n", "activation", "=", "None", ",", "\n", "scale_file", "=", "None", ",", "\n", "name", "=", "\"Interaction\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "name", "=", "name", "\n", "\n", "block_nr", "=", "name", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", "\n", "\n", "## -------------------------------------------- Message Passing ------------------------------------------- ##", "\n", "# Dense transformation of skip connection", "\n", "self", ".", "dense_ca", "=", "Dense", "(", "\n", "emb_size_edge", ",", "\n", "emb_size_edge", ",", "\n", "activation", "=", "activation", ",", "\n", "bias", "=", "False", ",", "\n", "name", "=", "\"dense_ca\"", ",", "\n", ")", "\n", "\n", "# Quadruplet Interaction", "\n", "self", ".", "quad_interaction", "=", "QuadrupletInteraction", "(", "\n", "emb_size_edge", "=", "emb_size_edge", ",", "\n", "emb_size_quad", "=", "emb_size_quad", ",", "\n", "emb_size_bilinear", "=", "emb_size_bil_quad", ",", "\n", "emb_size_rbf", "=", "emb_size_rbf", ",", "\n", "emb_size_cbf", "=", "emb_size_cbf", ",", "\n", "emb_size_sbf", "=", "emb_size_sbf", ",", "\n", "activation", "=", "activation", ",", "\n", "scale_file", "=", "scale_file", ",", "\n", "name", "=", "f\"QuadInteraction_{block_nr}\"", ",", "\n", ")", "\n", "\n", "# Triplet Interaction", "\n", "self", ".", "trip_interaction", "=", "TripletInteraction", "(", "\n", "emb_size_edge", "=", "emb_size_edge", ",", "\n", "emb_size_trip", "=", "emb_size_trip", ",", "\n", "emb_size_bilinear", "=", "emb_size_bil_trip", ",", "\n", "emb_size_rbf", "=", "emb_size_rbf", ",", "\n", "emb_size_cbf", "=", "emb_size_cbf", ",", "\n", "activation", "=", "activation", ",", "\n", "scale_file", "=", "scale_file", ",", "\n", "name", "=", "f\"TripInteraction_{block_nr}\"", ",", "\n", ")", "\n", "\n", "## ---------------------------------------- Update Edge Embeddings ---------------------------------------- ##", "\n", "# Residual layers before skip connection", "\n", "self", ".", "layers_before_skip", "=", "torch", ".", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "ResidualLayer", "(", "\n", "emb_size_edge", ",", "activation", "=", "activation", ",", "name", "=", "f\"res_bef_skip_{i}\"", "\n", ")", "\n", "for", "i", "in", "range", "(", "num_before_skip", ")", "\n", "]", "\n", ")", "\n", "\n", "# Residual layers after skip connection", "\n", "self", ".", "layers_after_skip", "=", "torch", ".", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "ResidualLayer", "(", "\n", "emb_size_edge", ",", "activation", "=", "activation", ",", "name", "=", "f\"res_aft_skip_{i}\"", "\n", ")", "\n", "for", "i", "in", "range", "(", "num_after_skip", ")", "\n", "]", "\n", ")", "\n", "\n", "## ---------------------------------------- Update Atom Embeddings ---------------------------------------- ##", "\n", "self", ".", "atom_update", "=", "AtomUpdateBlock", "(", "\n", "emb_size_atom", "=", "emb_size_atom", ",", "\n", "emb_size_edge", "=", "emb_size_edge", ",", "\n", "emb_size_rbf", "=", "emb_size_rbf", ",", "\n", "nHidden", "=", "num_atom", ",", "\n", "activation", "=", "activation", ",", "\n", "scale_file", "=", "scale_file", ",", "\n", "name", "=", "f\"AtomUpdate_{block_nr}\"", ",", "\n", ")", "\n", "\n", "## ------------------------------ Update Edge Embeddings with Atom Embeddings ----------------------------- ##", "\n", "self", ".", "concat_layer", "=", "EdgeEmbedding", "(", "\n", "emb_size_atom", ",", "\n", "emb_size_edge", ",", "\n", "emb_size_edge", ",", "\n", "activation", "=", "activation", ",", "\n", "name", "=", "\"concat\"", ",", "\n", ")", "\n", "self", ".", "residual_m", "=", "torch", ".", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "ResidualLayer", "(", "emb_size_edge", ",", "activation", "=", "activation", ",", "name", "=", "f\"res_m_{i}\"", ")", "\n", "for", "i", "in", "range", "(", "num_concat", ")", "\n", "]", "\n", ")", "\n", "\n", "self", ".", "inv_sqrt_2", "=", "1", "/", "(", "2.0", "**", "0.5", ")", "\n", "self", ".", "inv_sqrt_3", "=", "1", "/", "(", "3.0", "**", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.interaction_block.InteractionBlock.forward": [[158, 235], ["interaction_block.InteractionBlock.dense_ca", "interaction_block.InteractionBlock.quad_interaction", "interaction_block.InteractionBlock.trip_interaction", "enumerate", "enumerate", "interaction_block.InteractionBlock.atom_update", "interaction_block.InteractionBlock.concat_layer", "enumerate", "layer", "layer", "layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "\n", "h", ",", "\n", "m", ",", "\n", "rbf4", ",", "\n", "cbf4", ",", "\n", "sbf4", ",", "\n", "Kidx4", ",", "\n", "rbf3", ",", "\n", "cbf3", ",", "\n", "Kidx3", ",", "\n", "id_swap", ",", "\n", "id3_expand_ba", ",", "\n", "id3_reduce_ca", ",", "\n", "id4_reduce_ca", ",", "\n", "id4_expand_intm_db", ",", "\n", "id4_expand_abd", ",", "\n", "rbf_h", ",", "\n", "id_c", ",", "\n", "id_a", ")", ":", "\n", "        ", "\"\"\"\n        Returns\n        -------\n            h: Tensor, shape=(nEdges, emb_size_atom)\n                Atom embeddings.\n            m: Tensor, shape=(nEdges, emb_size_edge)\n                Edge embeddings (c->a).\n        \"\"\"", "\n", "# Initial transformation", "\n", "x_ca_skip", "=", "self", ".", "dense_ca", "(", "m", ")", "# (nEdges, emb_size_edge)", "\n", "\n", "x4", "=", "self", ".", "quad_interaction", "(", "\n", "m", ",", "\n", "rbf4", ",", "\n", "cbf4", ",", "\n", "sbf4", ",", "\n", "Kidx4", ",", "\n", "id_swap", ",", "\n", "id4_reduce_ca", ",", "\n", "id4_expand_intm_db", ",", "\n", "id4_expand_abd", ",", "\n", ")", "\n", "x3", "=", "self", ".", "trip_interaction", "(", "m", ",", "rbf3", ",", "cbf3", ",", "Kidx3", ",", "id_swap", ",", "id3_expand_ba", ",", "id3_reduce_ca", ")", "\n", "\n", "## ---------------------- Merge Embeddings after Quadruplet and Triplet Interaction ---------------------- ##", "\n", "x", "=", "x_ca_skip", "+", "x3", "+", "x4", "# (nEdges, emb_size_edge)", "\n", "x", "=", "x", "*", "self", ".", "inv_sqrt_3", "\n", "\n", "## --------------------------------------- Update Edge Embeddings ---------------------------------------- ##", "\n", "# Transformations before skip connection", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers_before_skip", ")", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "# (nEdges, emb_size_edge)", "\n", "\n", "# Skip connection", "\n", "", "m", "=", "m", "+", "x", "# (nEdges, emb_size_edge)", "\n", "m", "=", "m", "*", "self", ".", "inv_sqrt_2", "\n", "\n", "# Transformations after skip connection", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers_after_skip", ")", ":", "\n", "            ", "m", "=", "layer", "(", "m", ")", "# (nEdges, emb_size_edge)", "\n", "\n", "## --------------------------------------- Update Atom Embeddings ---------------------------------------- ##", "\n", "", "h2", "=", "self", ".", "atom_update", "(", "h", ",", "m", ",", "rbf_h", ",", "id_a", ")", "\n", "\n", "# Skip connection", "\n", "h", "=", "h", "+", "h2", "# (nAtoms, emb_size_atom)", "\n", "h", "=", "h", "*", "self", ".", "inv_sqrt_2", "\n", "\n", "## ----------------------------- Update Edge Embeddings with Atom Embeddings ----------------------------- ##", "\n", "m2", "=", "self", ".", "concat_layer", "(", "h", ",", "m", ",", "id_c", ",", "id_a", ")", "# (nEdges, emb_size_edge)", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "residual_m", ")", ":", "\n", "            ", "m2", "=", "layer", "(", "m2", ")", "# (nEdges, emb_size_edge)", "\n", "\n", "# Skip connection", "\n", "", "m", "=", "m", "+", "m2", "# (nEdges, emb_size_edge)", "\n", "m", "=", "m", "*", "self", ".", "inv_sqrt_2", "\n", "return", "h", ",", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.interaction_block.InteractionBlockTripletsOnly.__init__": [[269, 362], ["super().__init__", "base_layers.Dense", "interaction_block.TripletInteraction", "torch.nn.ModuleList", "torch.nn.ModuleList", "atom_update_block.AtomUpdateBlock", "embedding_block.EdgeEmbedding", "torch.nn.ModuleList", "name.split", "base_layers.ResidualLayer", "base_layers.ResidualLayer", "base_layers.ResidualLayer", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "emb_size_atom", ",", "\n", "emb_size_edge", ",", "\n", "emb_size_trip", ",", "\n", "emb_size_quad", ",", "\n", "emb_size_rbf", ",", "\n", "emb_size_cbf", ",", "\n", "emb_size_bil_trip", ",", "\n", "num_before_skip", ",", "\n", "num_after_skip", ",", "\n", "num_concat", ",", "\n", "num_atom", ",", "\n", "activation", "=", "None", ",", "\n", "scale_file", "=", "None", ",", "\n", "name", "=", "\"Interaction\"", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "name", "=", "name", "\n", "\n", "block_nr", "=", "name", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", "\n", "\n", "## -------------------------------------------- Message Passing ------------------------------------------- ##", "\n", "# Dense transformation of skip connection", "\n", "self", ".", "dense_ca", "=", "Dense", "(", "\n", "emb_size_edge", ",", "\n", "emb_size_edge", ",", "\n", "activation", "=", "activation", ",", "\n", "bias", "=", "False", ",", "\n", "name", "=", "\"dense_ca\"", ",", "\n", ")", "\n", "\n", "# Triplet Interaction", "\n", "self", ".", "trip_interaction", "=", "TripletInteraction", "(", "\n", "emb_size_edge", "=", "emb_size_edge", ",", "\n", "emb_size_trip", "=", "emb_size_trip", ",", "\n", "emb_size_bilinear", "=", "emb_size_bil_trip", ",", "\n", "emb_size_rbf", "=", "emb_size_rbf", ",", "\n", "emb_size_cbf", "=", "emb_size_cbf", ",", "\n", "activation", "=", "activation", ",", "\n", "scale_file", "=", "scale_file", ",", "\n", "name", "=", "f\"TripInteraction_{block_nr}\"", ",", "\n", ")", "\n", "\n", "## ---------------------------------------- Update Edge Embeddings ---------------------------------------- ##", "\n", "# Residual layers before skip connection", "\n", "self", ".", "layers_before_skip", "=", "torch", ".", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "ResidualLayer", "(", "\n", "emb_size_edge", ",", "activation", "=", "activation", ",", "name", "=", "f\"res_bef_skip_{i}\"", "\n", ")", "\n", "for", "i", "in", "range", "(", "num_before_skip", ")", "\n", "]", "\n", ")", "\n", "\n", "# Residual layers after skip connection", "\n", "self", ".", "layers_after_skip", "=", "torch", ".", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "ResidualLayer", "(", "\n", "emb_size_edge", ",", "activation", "=", "activation", ",", "name", "=", "f\"res_aft_skip_{i}\"", "\n", ")", "\n", "for", "i", "in", "range", "(", "num_after_skip", ")", "\n", "]", "\n", ")", "\n", "\n", "## ---------------------------------------- Update Atom Embeddings ---------------------------------------- ##", "\n", "self", ".", "atom_update", "=", "AtomUpdateBlock", "(", "\n", "emb_size_atom", "=", "emb_size_atom", ",", "\n", "emb_size_edge", "=", "emb_size_edge", ",", "\n", "emb_size_rbf", "=", "emb_size_rbf", ",", "\n", "nHidden", "=", "num_atom", ",", "\n", "activation", "=", "activation", ",", "\n", "scale_file", "=", "scale_file", ",", "\n", "name", "=", "f\"AtomUpdate_{block_nr}\"", ",", "\n", ")", "\n", "\n", "## ------------------------------ Update Edge Embeddings with Atom Embeddings ----------------------------- ##", "\n", "self", ".", "concat_layer", "=", "EdgeEmbedding", "(", "\n", "emb_size_atom", ",", "\n", "emb_size_edge", ",", "\n", "emb_size_edge", ",", "\n", "activation", "=", "activation", ",", "\n", "name", "=", "\"concat\"", ",", "\n", ")", "\n", "self", ".", "residual_m", "=", "torch", ".", "nn", ".", "ModuleList", "(", "\n", "[", "\n", "ResidualLayer", "(", "emb_size_edge", ",", "activation", "=", "activation", ",", "name", "=", "f\"res_m_{i}\"", ")", "\n", "for", "i", "in", "range", "(", "num_concat", ")", "\n", "]", "\n", ")", "\n", "\n", "self", ".", "inv_sqrt_2", "=", "1", "/", "(", "2.0", "**", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.interaction_block.InteractionBlockTripletsOnly.forward": [[363, 423], ["interaction_block.InteractionBlockTripletsOnly.dense_ca", "interaction_block.InteractionBlockTripletsOnly.trip_interaction", "enumerate", "enumerate", "interaction_block.InteractionBlockTripletsOnly.atom_update", "interaction_block.InteractionBlockTripletsOnly.concat_layer", "enumerate", "layer", "layer", "layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "\n", "h", ",", "\n", "m", ",", "\n", "rbf3", ",", "\n", "cbf3", ",", "\n", "Kidx3", ",", "\n", "id_swap", ",", "\n", "id3_expand_ba", ",", "\n", "id3_reduce_ca", ",", "\n", "rbf_h", ",", "\n", "id_c", ",", "\n", "id_a", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"\n        Returns\n        -------\n            h: Tensor, shape=(nEdges, emb_size_atom)\n                Atom embeddings.\n            m: Tensor, shape=(nEdges, emb_size_edge)\n                Edge embeddings (c->a).\n        \"\"\"", "\n", "# Initial transformation", "\n", "x_ca_skip", "=", "self", ".", "dense_ca", "(", "m", ")", "# (nEdges, emb_size_edge)", "\n", "\n", "x3", "=", "self", ".", "trip_interaction", "(", "m", ",", "rbf3", ",", "cbf3", ",", "Kidx3", ",", "id_swap", ",", "id3_expand_ba", ",", "id3_reduce_ca", ")", "\n", "\n", "## ----------------------------- Merge Embeddings after Triplet Interaction ------------------------------ ##", "\n", "x", "=", "x_ca_skip", "+", "x3", "# (nEdges, emb_size_edge)", "\n", "x", "=", "x", "*", "self", ".", "inv_sqrt_2", "\n", "\n", "## ---------------------------------------- Update Edge Embeddings --------------------------------------- ##", "\n", "# Transformations before skip connection", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers_before_skip", ")", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "# (nEdges, emb_size_edge)", "\n", "\n", "# Skip connection", "\n", "", "m", "=", "m", "+", "x", "# (nEdges, emb_size_edge)", "\n", "m", "=", "m", "*", "self", ".", "inv_sqrt_2", "\n", "\n", "# Transformations after skip connection", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers_after_skip", ")", ":", "\n", "            ", "m", "=", "layer", "(", "m", ")", "# (nEdges, emb_size_edge)", "\n", "\n", "## ---------------------------------------- Update Atom Embeddings --------------------------------------- ##", "\n", "", "h2", "=", "self", ".", "atom_update", "(", "h", ",", "m", ",", "rbf_h", ",", "id_a", ")", "# (nAtoms, emb_size_atom)", "\n", "\n", "# Skip connection", "\n", "h", "=", "h", "+", "h2", "# (nAtoms, emb_size_atom)", "\n", "h", "=", "h", "*", "self", ".", "inv_sqrt_2", "\n", "\n", "## ----------------------------- Update Edge Embeddings with Atom Embeddings ----------------------------- ##", "\n", "m2", "=", "self", ".", "concat_layer", "(", "h", ",", "m", ",", "id_c", ",", "id_a", ")", "# (nEdges, emb_size_edge)", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "residual_m", ")", ":", "\n", "            ", "m2", "=", "layer", "(", "m2", ")", "# (nEdges, emb_size_edge)", "\n", "\n", "# Skip connection", "\n", "", "m", "=", "m", "+", "m2", "# (nEdges, emb_size_edge)", "\n", "m", "=", "m", "*", "self", ".", "inv_sqrt_2", "\n", "return", "h", ",", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.interaction_block.QuadrupletInteraction.__init__": [[449, 516], ["super().__init__", "base_layers.Dense", "base_layers.Dense", "scaling.ScalingFactor", "base_layers.Dense", "scaling.ScalingFactor", "efficient.EfficientInteractionBilinear", "scaling.ScalingFactor", "base_layers.Dense", "base_layers.Dense", "base_layers.Dense"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "emb_size_edge", ",", "\n", "emb_size_quad", ",", "\n", "emb_size_bilinear", ",", "\n", "emb_size_rbf", ",", "\n", "emb_size_cbf", ",", "\n", "emb_size_sbf", ",", "\n", "activation", "=", "None", ",", "\n", "scale_file", "=", "None", ",", "\n", "name", "=", "\"QuadrupletInteraction\"", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "name", "=", "name", "\n", "\n", "# Dense transformation", "\n", "self", ".", "dense_db", "=", "Dense", "(", "\n", "emb_size_edge", ",", "\n", "emb_size_edge", ",", "\n", "activation", "=", "activation", ",", "\n", "bias", "=", "False", ",", "\n", "name", "=", "\"dense_db\"", ",", "\n", ")", "\n", "\n", "# Up projections of basis representations, bilinear layer and scaling factors", "\n", "self", ".", "mlp_rbf", "=", "Dense", "(", "\n", "emb_size_rbf", ",", "emb_size_edge", ",", "activation", "=", "None", ",", "name", "=", "\"MLP_rbf4_2\"", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "scale_rbf", "=", "ScalingFactor", "(", "scale_file", "=", "scale_file", ",", "name", "=", "name", "+", "\"_had_rbf\"", ")", "\n", "\n", "self", ".", "mlp_cbf", "=", "Dense", "(", "\n", "emb_size_cbf", ",", "emb_size_quad", ",", "activation", "=", "None", ",", "name", "=", "\"MLP_cbf4_2\"", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "scale_cbf", "=", "ScalingFactor", "(", "scale_file", "=", "scale_file", ",", "name", "=", "name", "+", "\"_had_cbf\"", ")", "\n", "\n", "self", ".", "mlp_sbf", "=", "EfficientInteractionBilinear", "(", "\n", "emb_size_quad", ",", "emb_size_sbf", ",", "emb_size_bilinear", ",", "name", "=", "\"MLP_sbf4_2\"", "\n", ")", "\n", "self", ".", "scale_sbf_sum", "=", "ScalingFactor", "(", "\n", "scale_file", "=", "scale_file", ",", "name", "=", "name", "+", "\"_sum_sbf\"", "\n", ")", "# combines scaling for bilinear layer and summation", "\n", "\n", "# Down and up projections", "\n", "self", ".", "down_projection", "=", "Dense", "(", "\n", "emb_size_edge", ",", "\n", "emb_size_quad", ",", "\n", "activation", "=", "activation", ",", "\n", "bias", "=", "False", ",", "\n", "name", "=", "\"dense_down\"", ",", "\n", ")", "\n", "self", ".", "up_projection_ca", "=", "Dense", "(", "\n", "emb_size_bilinear", ",", "\n", "emb_size_edge", ",", "\n", "activation", "=", "activation", ",", "\n", "bias", "=", "False", ",", "\n", "name", "=", "\"dense_up_ca\"", ",", "\n", ")", "\n", "self", ".", "up_projection_ac", "=", "Dense", "(", "\n", "emb_size_bilinear", ",", "\n", "emb_size_edge", ",", "\n", "activation", "=", "activation", ",", "\n", "bias", "=", "False", ",", "\n", "name", "=", "\"dense_up_ac\"", ",", "\n", ")", "\n", "\n", "self", ".", "inv_sqrt_2", "=", "1", "/", "(", "2.0", "**", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.interaction_block.QuadrupletInteraction.forward": [[517, 567], ["interaction_block.QuadrupletInteraction.dense_db", "interaction_block.QuadrupletInteraction.scale_rbf", "interaction_block.QuadrupletInteraction.down_projection", "interaction_block.QuadrupletInteraction.scale_cbf", "interaction_block.QuadrupletInteraction.mlp_sbf", "interaction_block.QuadrupletInteraction.scale_sbf_sum", "interaction_block.QuadrupletInteraction.up_projection_ca", "interaction_block.QuadrupletInteraction.up_projection_ac", "interaction_block.QuadrupletInteraction.mlp_rbf", "interaction_block.QuadrupletInteraction.mlp_cbf"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "\n", "m", ",", "\n", "rbf", ",", "\n", "cbf", ",", "\n", "sbf", ",", "\n", "Kidx4", ",", "\n", "id_swap", ",", "\n", "id4_reduce_ca", ",", "\n", "id4_expand_intm_db", ",", "\n", "id4_expand_abd", ")", ":", "\n", "        ", "\"\"\"\n        Returns\n        -------\n            m: Tensor, shape=(nEdges, emb_size_edge)\n                Edge embeddings (c->a).\n        \"\"\"", "\n", "x_db", "=", "self", ".", "dense_db", "(", "m", ")", "# (nEdges, emb_size_edge)", "\n", "\n", "# Transform via radial bessel basis", "\n", "x_db2", "=", "x_db", "*", "self", ".", "mlp_rbf", "(", "rbf", ")", "# (nEdges, emb_size_edge)", "\n", "x_db", "=", "self", ".", "scale_rbf", "(", "x_db", ",", "x_db2", ")", "\n", "\n", "# Down project embeddings", "\n", "x_db", "=", "self", ".", "down_projection", "(", "x_db", ")", "# (nEdges, emb_size_quad)", "\n", "\n", "# Transform via circular spherical bessel basis", "\n", "x_db", "=", "x_db", "[", "id4_expand_intm_db", "]", "# (intmTriplets, emb_size_quad)", "\n", "x_db2", "=", "x_db", "*", "self", ".", "mlp_cbf", "(", "cbf", ")", "# (intmTriplets, emb_size_quad)", "\n", "x_db", "=", "self", ".", "scale_cbf", "(", "x_db", ",", "x_db2", ")", "\n", "\n", "# Transform via spherical bessel basis", "\n", "x_db", "=", "x_db", "[", "id4_expand_abd", "]", "# (nQuadruplets, emb_size_quad)", "\n", "x", "=", "self", ".", "mlp_sbf", "(", "sbf", ",", "x_db", ",", "id4_reduce_ca", ",", "Kidx4", ")", "# (nEdges, emb_size_bilinear)", "\n", "x", "=", "self", ".", "scale_sbf_sum", "(", "x_db", ",", "x", ")", "\n", "\n", "# Basis representation:", "\n", "# rbf(d_db)", "\n", "# cbf(d_ba, angle_abd)", "\n", "# sbf(d_ca, angle_cab, angle_cabd)", "\n", "\n", "# Upproject embeddings", "\n", "x_ca", "=", "self", ".", "up_projection_ca", "(", "x", ")", "# (nEdges, emb_size_edge)", "\n", "x_ac", "=", "self", ".", "up_projection_ac", "(", "x", ")", "# (nEdges, emb_size_edge)", "\n", "\n", "# Merge interaction of c->a and a->c", "\n", "x_ac", "=", "x_ac", "[", "id_swap", "]", "# swap to add to edge a->c and not c->a", "\n", "x4", "=", "x_ca", "+", "x_ac", "\n", "x4", "=", "x4", "*", "self", ".", "inv_sqrt_2", "\n", "\n", "return", "x4", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.interaction_block.TripletInteraction.__init__": [[591, 652], ["super().__init__", "base_layers.Dense", "base_layers.Dense", "scaling.ScalingFactor", "efficient.EfficientInteractionBilinear", "scaling.ScalingFactor", "base_layers.Dense", "base_layers.Dense", "base_layers.Dense"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "emb_size_edge", ",", "\n", "emb_size_trip", ",", "\n", "emb_size_bilinear", ",", "\n", "emb_size_rbf", ",", "\n", "emb_size_cbf", ",", "\n", "activation", "=", "None", ",", "\n", "scale_file", "=", "None", ",", "\n", "name", "=", "\"TripletInteraction\"", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "name", "=", "name", "\n", "\n", "# Dense transformation", "\n", "self", ".", "dense_ba", "=", "Dense", "(", "\n", "emb_size_edge", ",", "\n", "emb_size_edge", ",", "\n", "activation", "=", "activation", ",", "\n", "bias", "=", "False", ",", "\n", "name", "=", "\"dense_ba\"", ",", "\n", ")", "\n", "\n", "# Down projections of basis representations, bilinear layer and scaling factors", "\n", "self", ".", "mlp_rbf", "=", "Dense", "(", "\n", "emb_size_rbf", ",", "emb_size_edge", ",", "activation", "=", "None", ",", "name", "=", "\"MLP_rbf3_2\"", ",", "bias", "=", "False", "\n", ")", "\n", "self", ".", "scale_rbf", "=", "ScalingFactor", "(", "scale_file", "=", "scale_file", ",", "name", "=", "name", "+", "\"_had_rbf\"", ")", "\n", "\n", "self", ".", "mlp_cbf", "=", "EfficientInteractionBilinear", "(", "\n", "emb_size_trip", ",", "emb_size_cbf", ",", "emb_size_bilinear", ",", "name", "=", "\"MLP_cbf3_2\"", "\n", ")", "\n", "self", ".", "scale_cbf_sum", "=", "ScalingFactor", "(", "\n", "scale_file", "=", "scale_file", ",", "name", "=", "name", "+", "\"_sum_cbf\"", "\n", ")", "# combines scaling for bilinear layer and summation", "\n", "\n", "# Down and up projections", "\n", "self", ".", "down_projection", "=", "Dense", "(", "\n", "emb_size_edge", ",", "\n", "emb_size_trip", ",", "\n", "activation", "=", "activation", ",", "\n", "bias", "=", "False", ",", "\n", "name", "=", "\"dense_down\"", ",", "\n", ")", "\n", "self", ".", "up_projection_ca", "=", "Dense", "(", "\n", "emb_size_bilinear", ",", "\n", "emb_size_edge", ",", "\n", "activation", "=", "activation", ",", "\n", "bias", "=", "False", ",", "\n", "name", "=", "\"dense_up_ca\"", ",", "\n", ")", "\n", "self", ".", "up_projection_ac", "=", "Dense", "(", "\n", "emb_size_bilinear", ",", "\n", "emb_size_edge", ",", "\n", "activation", "=", "activation", ",", "\n", "bias", "=", "False", ",", "\n", "name", "=", "\"dense_up_ac\"", ",", "\n", ")", "\n", "\n", "self", ".", "inv_sqrt_2", "=", "1", "/", "(", "2.0", ")", "**", "0.5", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.interaction_block.TripletInteraction.forward": [[653, 697], ["interaction_block.TripletInteraction.dense_ba", "interaction_block.TripletInteraction.mlp_rbf", "interaction_block.TripletInteraction.scale_rbf", "interaction_block.TripletInteraction.down_projection", "interaction_block.TripletInteraction.mlp_cbf", "interaction_block.TripletInteraction.scale_cbf_sum", "interaction_block.TripletInteraction.up_projection_ca", "interaction_block.TripletInteraction.up_projection_ac"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "\n", "m", ",", "\n", "rbf3", ",", "\n", "cbf3", ",", "\n", "Kidx3", ",", "\n", "id_swap", ",", "\n", "id3_expand_ba", ",", "\n", "id3_reduce_ca", ")", ":", "\n", "        ", "\"\"\"\n        Returns\n        -------\n            m: Tensor, shape=(nEdges, emb_size_edge)\n                Edge embeddings (c->a).\n        \"\"\"", "\n", "# Dense transformation", "\n", "x_ba", "=", "self", ".", "dense_ba", "(", "m", ")", "# (nEdges, emb_size_edge)", "\n", "\n", "# Transform via radial bessel basis", "\n", "mlp_rbf", "=", "self", ".", "mlp_rbf", "(", "rbf3", ")", "# (nEdges, emb_size_edge)", "\n", "x_ba2", "=", "x_ba", "*", "mlp_rbf", "\n", "x_ba", "=", "self", ".", "scale_rbf", "(", "x_ba", ",", "x_ba2", ")", "\n", "\n", "x_ba", "=", "self", ".", "down_projection", "(", "x_ba", ")", "# (nEdges, emb_size_trip)", "\n", "\n", "# Transform via circular spherical basis", "\n", "x_ba", "=", "x_ba", "[", "id3_expand_ba", "]", "# (nTriplets, emb_size_trip)", "\n", "\n", "# Efficient bilinear layer", "\n", "x", "=", "self", ".", "mlp_cbf", "(", "cbf3", ",", "x_ba", ",", "id3_reduce_ca", ",", "Kidx3", ")", "# (nEdges, emb_size_bilinear)", "\n", "x", "=", "self", ".", "scale_cbf_sum", "(", "x_ba", ",", "x", ")", "\n", "\n", "# Basis representation:", "\n", "# rbf(d_ba)", "\n", "# cbf(d_ca, angle_cab)", "\n", "\n", "# Up project embeddings", "\n", "x_ca", "=", "self", ".", "up_projection_ca", "(", "x", ")", "# (nEdges, emb_size_edge)", "\n", "x_ac", "=", "self", ".", "up_projection_ac", "(", "x", ")", "# (nEdges, emb_size_edge)", "\n", "\n", "# Merge interaction of c->a and a->c", "\n", "x_ac", "=", "x_ac", "[", "id_swap", "]", "# swap to add to edge a->c and not c->a", "\n", "x3", "=", "x_ca", "+", "x_ac", "\n", "x3", "=", "x3", "*", "self", ".", "inv_sqrt_2", "\n", "return", "x3", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.AutomaticFit.__init__": [[16, 34], ["scaling.AutomaticFit.load_maybe", "scaling.AutomaticFit._add2queue"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.AutomaticFit.load_maybe", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.AutomaticFit._add2queue"], ["def", "__init__", "(", "self", ",", "variable", ",", "scale_file", ",", "name", ")", ":", "\n", "        ", "self", ".", "variable", "=", "variable", "# variable to find value for", "\n", "self", ".", "scale_file", "=", "scale_file", "\n", "self", ".", "_name", "=", "name", "\n", "\n", "self", ".", "_fitted", "=", "False", "\n", "self", ".", "load_maybe", "(", ")", "\n", "\n", "# first instance created", "\n", "if", "AutomaticFit", ".", "fitting_mode", "and", "not", "self", ".", "_fitted", ":", "\n", "\n", "# if first layer set to active", "\n", "            ", "if", "AutomaticFit", ".", "activeVar", "is", "None", ":", "\n", "                ", "AutomaticFit", ".", "activeVar", "=", "self", "\n", "AutomaticFit", ".", "queue", "=", "[", "]", "# initialize", "\n", "# else add to queue", "\n", "", "else", ":", "\n", "                ", "self", ".", "_add2queue", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.AutomaticFit.reset": [[35, 38], ["None"], "methods", ["None"], ["", "", "", "def", "reset", "(", ")", ":", "\n", "        ", "AutomaticFit", ".", "activeVar", "=", "None", "\n", "AutomaticFit", ".", "all_processed", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.AutomaticFit.fitting_completed": [[39, 41], ["None"], "methods", ["None"], ["", "def", "fitting_completed", "(", ")", ":", "\n", "        ", "return", "AutomaticFit", ".", "queue", "is", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.AutomaticFit.set2fitmode": [[42, 45], ["scaling.AutomaticFit.reset"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.AutomaticFit.reset"], ["", "def", "set2fitmode", "(", ")", ":", "\n", "        ", "AutomaticFit", ".", "reset", "(", ")", "\n", "AutomaticFit", ".", "fitting_mode", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.AutomaticFit._add2queue": [[46, 55], ["logging.debug", "ValueError"], "methods", ["None"], ["", "def", "_add2queue", "(", "self", ")", ":", "\n", "        ", "logging", ".", "debug", "(", "f\"Add {self._name} to queue.\"", ")", "\n", "# check that same variable is not added twice", "\n", "for", "var", "in", "AutomaticFit", ".", "queue", ":", "\n", "            ", "if", "self", ".", "_name", "==", "var", ".", "_name", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"Variable with the same name ({self._name}) was already added to queue!\"", "\n", ")", "\n", "", "", "AutomaticFit", ".", "queue", "+=", "[", "self", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.AutomaticFit.set_next_active": [[56, 67], ["queue.pop", "len", "logging.debug"], "methods", ["None"], ["", "def", "set_next_active", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Set the next variable in the queue that should be fitted.\n        \"\"\"", "\n", "queue", "=", "AutomaticFit", ".", "queue", "\n", "if", "len", "(", "queue", ")", "==", "0", ":", "\n", "            ", "logging", ".", "debug", "(", "\"Processed all variables.\"", ")", "\n", "AutomaticFit", ".", "queue", "=", "None", "\n", "AutomaticFit", ".", "activeVar", "=", "None", "\n", "return", "\n", "", "AutomaticFit", ".", "activeVar", "=", "queue", ".", "pop", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.AutomaticFit.load_maybe": [[68, 82], ["utils.read_value_json", "logging.info", "logging.debug", "torch.no_grad", "scaling.AutomaticFit.variable.copy_", "torch.tensor", "scaling.AutomaticFit.variable.numpy"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.utils.read_value_json"], ["", "def", "load_maybe", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Load variable from file or set to initial value of the variable.\n        \"\"\"", "\n", "value", "=", "read_value_json", "(", "self", ".", "scale_file", ",", "self", ".", "_name", ")", "\n", "if", "value", "is", "None", ":", "\n", "            ", "logging", ".", "info", "(", "\n", "f\"Initialize variable {self._name}' to {self.variable.numpy():.3f}\"", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_fitted", "=", "True", "\n", "logging", ".", "debug", "(", "f\"Set scale factor {self._name} : {value}\"", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "variable", ".", "copy_", "(", "torch", ".", "tensor", "(", "value", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.AutoScaleFit.__init__": [[96, 101], ["scaling.AutomaticFit.__init__", "scaling.AutoScaleFit._init_stats"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.AutoScaleFit._init_stats"], ["def", "__init__", "(", "self", ",", "variable", ",", "scale_file", ",", "name", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "variable", ",", "scale_file", ",", "name", ")", "\n", "\n", "if", "not", "self", ".", "_fitted", ":", "\n", "            ", "self", ".", "_init_stats", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.AutoScaleFit._init_stats": [[102, 106], ["None"], "methods", ["None"], ["", "", "def", "_init_stats", "(", "self", ")", ":", "\n", "        ", "self", ".", "variance_in", "=", "0", "\n", "self", ".", "variance_out", "=", "0", "\n", "self", ".", "nSamples", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.AutoScaleFit.observe": [[107, 121], ["torch.mean", "torch.mean", "torch.var", "torch.var"], "methods", ["None"], ["", "def", "observe", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "\"\"\"\n        Observe variances for inut x and output y.\n        The scaling factor alpha is calculated s.t. Var(alpha * y) ~ Var(x)\n        \"\"\"", "\n", "if", "self", ".", "_fitted", ":", "\n", "            ", "return", "\n", "\n", "# only track stats for current variable", "\n", "", "if", "AutomaticFit", ".", "activeVar", "==", "self", ":", "\n", "            ", "nSamples", "=", "y", ".", "shape", "[", "0", "]", "\n", "self", ".", "variance_in", "+=", "torch", ".", "mean", "(", "torch", ".", "var", "(", "x", ",", "dim", "=", "0", ")", ")", "*", "nSamples", "\n", "self", ".", "variance_out", "+=", "torch", ".", "mean", "(", "torch", ".", "var", "(", "y", ",", "dim", "=", "0", ")", ")", "*", "nSamples", "\n", "self", ".", "nSamples", "+=", "nSamples", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.AutoScaleFit.fit": [[122, 148], ["numpy.sqrt", "logging.info", "utils.update_json", "scaling.AutoScaleFit.set_next_active", "ValueError", "torch.no_grad", "scaling.AutoScaleFit.variable.copy_", "float", "scaling.AutoScaleFit.variable.numpy", "scaling.AutoScaleFit.variance_in.numpy", "scaling.AutoScaleFit.variance_out.numpy"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.utils.update_json", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.AutomaticFit.set_next_active"], ["", "", "def", "fit", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Fit the scaling factor based on the observed variances.\n        \"\"\"", "\n", "if", "AutomaticFit", ".", "activeVar", "==", "self", ":", "\n", "            ", "if", "self", ".", "variance_in", "==", "0", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "f\"Did not track the variable {self._name}. Add observe calls to track the variance before and after.\"", "\n", ")", "\n", "\n", "# calculate variance preserving scaling factor", "\n", "", "self", ".", "variance_in", "=", "self", ".", "variance_in", "/", "self", ".", "nSamples", "\n", "self", ".", "variance_out", "=", "self", ".", "variance_out", "/", "self", ".", "nSamples", "\n", "\n", "ratio", "=", "self", ".", "variance_out", "/", "self", ".", "variance_in", "\n", "value", "=", "np", ".", "sqrt", "(", "1", "/", "ratio", ",", "dtype", "=", "\"float32\"", ")", "\n", "logging", ".", "info", "(", "\n", "f\"Variable: {self._name}, Var_in: {self.variance_in.numpy():.3f}, Var_out: {self.variance_out.numpy():.3f}, \"", "\n", "+", "f\"Ratio: {ratio:.3f} => Scaling factor: {value:.3f}\"", "\n", ")", "\n", "\n", "# set variable to calculated value", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "self", ".", "variable", ".", "copy_", "(", "self", ".", "variable", "*", "value", ")", "\n", "", "update_json", "(", "self", ".", "scale_file", ",", "{", "self", ".", "_name", ":", "float", "(", "self", ".", "variable", ".", "numpy", "(", ")", ")", "}", ")", "\n", "self", ".", "set_next_active", "(", ")", "# set next variable in queue to active", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.ScalingFactor.__init__": [[162, 169], ["super().__init__", "torch.nn.Parameter", "scaling.AutoScaleFit", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__"], ["def", "__init__", "(", "self", ",", "scale_file", ",", "name", ",", "device", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "scale_factor", "=", "torch", ".", "nn", ".", "Parameter", "(", "\n", "torch", ".", "tensor", "(", "1.0", ",", "device", "=", "device", ")", ",", "requires_grad", "=", "False", "\n", ")", "\n", "self", ".", "autofit", "=", "AutoScaleFit", "(", "self", ".", "scale_factor", ",", "scale_file", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.ScalingFactor.forward": [[170, 175], ["scaling.ScalingFactor.autofit.observe"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.scaling.AutoScaleFit.observe"], ["", "def", "forward", "(", "self", ",", "x_ref", ",", "y", ")", ":", "\n", "        ", "y", "=", "y", "*", "self", ".", "scale_factor", "\n", "self", ".", "autofit", ".", "observe", "(", "x_ref", ",", "y", ")", "\n", "\n", "return", "y", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.base_layers.Dense.__init__": [[19, 38], ["super().__init__", "torch.nn.Linear", "base_layers.Dense.reset_parameters", "isinstance", "activation.lower.lower.lower", "base_layers.ScaledSiLU", "torch.nn.Identity", "NotImplementedError"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.atom_update_block.OutputBlock.reset_parameters"], ["def", "__init__", "(", "\n", "self", ",", "in_features", ",", "out_features", ",", "bias", "=", "False", ",", "activation", "=", "None", ",", "name", "=", "None", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "linear", "=", "torch", ".", "nn", ".", "Linear", "(", "in_features", ",", "out_features", ",", "bias", "=", "bias", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "self", ".", "weight", "=", "self", ".", "linear", ".", "weight", "\n", "self", ".", "bias", "=", "self", ".", "linear", ".", "bias", "\n", "\n", "if", "isinstance", "(", "activation", ",", "str", ")", ":", "\n", "            ", "activation", "=", "activation", ".", "lower", "(", ")", "\n", "", "if", "activation", "in", "[", "\"swish\"", ",", "\"silu\"", "]", ":", "\n", "            ", "self", ".", "_activation", "=", "ScaledSiLU", "(", ")", "\n", "", "elif", "activation", "is", "None", ":", "\n", "            ", "self", ".", "_activation", "=", "torch", ".", "nn", ".", "Identity", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\n", "\"Activation function not implemented for GemNet (yet).\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.base_layers.Dense.reset_parameters": [[40, 44], ["initializers.he_orthogonal_init", "base_layers.Dense.linear.bias.data.fill_"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.initializers.he_orthogonal_init"], ["", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "he_orthogonal_init", "(", "self", ".", "linear", ".", "weight", ")", "\n", "if", "self", ".", "linear", ".", "bias", "is", "not", "None", ":", "\n", "            ", "self", ".", "linear", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.base_layers.Dense.forward": [[45, 49], ["base_layers.Dense.linear", "base_layers.Dense._activation"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "linear", "(", "x", ")", "\n", "x", "=", "self", ".", "_activation", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.base_layers.ScaledSiLU.__init__": [[52, 56], ["super().__init__", "torch.nn.SiLU"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "scale_factor", "=", "1", "/", "0.6", "\n", "self", ".", "_activation", "=", "torch", ".", "nn", ".", "SiLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.base_layers.ScaledSiLU.forward": [[57, 59], ["base_layers.ScaledSiLU._activation"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "_activation", "(", "x", ")", "*", "self", ".", "scale_factor", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.base_layers.ResidualLayer.__init__": [[75, 84], ["super().__init__", "torch.nn.Sequential", "base_layers.Dense", "range"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__"], ["def", "__init__", "(", "self", ",", "units", ":", "int", ",", "nLayers", ":", "int", "=", "2", ",", "activation", "=", "None", ",", "name", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense_mlp", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "*", "[", "\n", "Dense", "(", "units", ",", "units", ",", "activation", "=", "activation", ",", "bias", "=", "False", ")", "\n", "for", "i", "in", "range", "(", "nLayers", ")", "\n", "]", "\n", ")", "\n", "self", ".", "inv_sqrt_2", "=", "1", "/", "(", "2.0", "**", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.base_layers.ResidualLayer.forward": [[85, 90], ["base_layers.ResidualLayer.dense_mlp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "inputs", ")", ":", "\n", "        ", "x", "=", "self", ".", "dense_mlp", "(", "inputs", ")", "\n", "x", "=", "inputs", "+", "x", "\n", "x", "=", "x", "*", "self", ".", "inv_sqrt_2", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.embedding_block.AtomEmbedding.__init__": [[17, 25], ["super().__init__", "torch.nn.Embedding", "torch.nn.init.uniform_", "numpy.sqrt", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__"], ["def", "__init__", "(", "self", ",", "emb_size", ",", "name", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "emb_size", "=", "emb_size", "\n", "\n", "# Atom embeddings: We go up to Pu (94). Use 93 dimensions because of 0-based indexing", "\n", "self", ".", "embeddings", "=", "torch", ".", "nn", ".", "Embedding", "(", "93", ",", "emb_size", ")", "\n", "# init by uniform distribution", "\n", "torch", ".", "nn", ".", "init", ".", "uniform_", "(", "self", ".", "embeddings", ".", "weight", ",", "a", "=", "-", "np", ".", "sqrt", "(", "3", ")", ",", "b", "=", "np", ".", "sqrt", "(", "3", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.embedding_block.AtomEmbedding.forward": [[26, 35], ["embedding_block.AtomEmbedding.embeddings"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "Z", ")", ":", "\n", "        ", "\"\"\"\n        Returns\n        -------\n            h: Tensor, shape=(nAtoms, emb_size)\n                Atom embeddings.\n        \"\"\"", "\n", "h", "=", "self", ".", "embeddings", "(", "Z", "-", "1", ")", "# -1 because Z.min()=1 (==Hydrogen)", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.embedding_block.EdgeEmbedding.__init__": [[53, 59], ["super().__init__", "base_layers.Dense"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__"], ["def", "__init__", "(", "\n", "self", ",", "atom_features", ",", "edge_features", ",", "out_features", ",", "activation", "=", "None", ",", "name", "=", "None", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "in_features", "=", "2", "*", "atom_features", "+", "edge_features", "\n", "self", ".", "dense", "=", "Dense", "(", "in_features", ",", "out_features", ",", "activation", "=", "activation", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.embedding_block.EdgeEmbedding.forward": [[60, 76], ["torch.cat", "embedding_block.EdgeEmbedding.dense"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h", ",", "m_rbf", ",", "idnb_a", ",", "idnb_c", ",", ")", ":", "\n", "        ", "\"\"\"\n        Returns\n        -------\n            m_ca: Tensor, shape=(nEdges, emb_size)\n                Edge embeddings.\n        \"\"\"", "\n", "# m_rbf: shape (nEdges, nFeatures)", "\n", "# in embedding block: m_rbf = rbf ; In interaction block: m_rbf = m_ca", "\n", "\n", "h_a", "=", "h", "[", "idnb_a", "]", "# shape=(nEdges, emb_size)", "\n", "h_c", "=", "h", "[", "idnb_c", "]", "# shape=(nEdges, emb_size)", "\n", "\n", "m_ca", "=", "torch", ".", "cat", "(", "[", "h_a", ",", "h_c", ",", "m_rbf", "]", ",", "dim", "=", "-", "1", ")", "# (nEdges, 2*emb_size+nFeatures)", "\n", "m_ca", "=", "self", ".", "dense", "(", "m_ca", ")", "# (nEdges, emb_size)", "\n", "return", "m_ca", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.efficient.EfficientInteractionDownProjection.__init__": [[19, 33], ["super().__init__", "efficient.EfficientInteractionDownProjection.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.atom_update_block.OutputBlock.reset_parameters"], ["def", "__init__", "(", "\n", "self", ",", "\n", "num_spherical", ":", "int", ",", "\n", "num_radial", ":", "int", ",", "\n", "emb_size_interm", ":", "int", ",", "\n", "name", "=", "\"EfficientDownProj\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "num_spherical", "=", "num_spherical", "\n", "self", ".", "num_radial", "=", "num_radial", "\n", "self", ".", "emb_size_interm", "=", "emb_size_interm", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.efficient.EfficientInteractionDownProjection.reset_parameters": [[34, 40], ["torch.nn.Parameter", "initializers.he_orthogonal_init", "torch.empty"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.initializers.he_orthogonal_init"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "\n", "torch", ".", "empty", "(", "(", "self", ".", "num_spherical", ",", "self", ".", "num_radial", ",", "self", ".", "emb_size_interm", ")", ")", ",", "\n", "requires_grad", "=", "True", ",", "\n", ")", "\n", "he_orthogonal_init", "(", "self", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.efficient.EfficientInteractionDownProjection.forward": [[41, 58], ["torch.matmul", "rbf_W1.permute.permute.permute", "torch.transpose"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tbf", ")", ":", "\n", "        ", "\"\"\"\n        Returns\n        -------\n            (rbf_W1, sph): tuple\n            - rbf_W1: Tensor, shape=(nEdges, emb_size_interm, num_spherical)\n            - sph: Tensor, shape=(nEdges, Kmax, num_spherical)\n        \"\"\"", "\n", "rbf_env", ",", "sph", "=", "tbf", "\n", "# (num_spherical, nEdges, num_radial), (nEdges, Kmax, num_spherical) ;  Kmax = maximum number of neighbors of the edges", "\n", "\n", "# MatMul: mul + sum over num_radial", "\n", "rbf_W1", "=", "torch", ".", "matmul", "(", "rbf_env", ",", "self", ".", "weight", ")", "# (num_spherical, nEdges , emb_size_interm)", "\n", "rbf_W1", "=", "rbf_W1", ".", "permute", "(", "1", ",", "2", ",", "0", ")", "# (nEdges, emb_size_interm, num_spherical)", "\n", "\n", "sph", "=", "torch", ".", "transpose", "(", "sph", ",", "1", ",", "2", ")", "# (nEdges, num_spherical, Kmax)", "\n", "return", "rbf_W1", ",", "sph", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.efficient.EfficientInteractionHadamard.__init__": [[72, 78], ["super().__init__", "efficient.EfficientInteractionHadamard.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.atom_update_block.OutputBlock.reset_parameters"], ["def", "__init__", "(", "self", ",", "emb_size_interm", ":", "int", ",", "emb_size", ":", "int", ",", "name", "=", "\"EfficientHadamard\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "emb_size_interm", "=", "emb_size_interm", "\n", "self", ".", "emb_size", "=", "emb_size", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.efficient.EfficientInteractionHadamard.reset_parameters": [[79, 84], ["torch.nn.Parameter", "initializers.he_orthogonal_init", "torch.empty"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.initializers.he_orthogonal_init"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "\n", "torch", ".", "empty", "(", "(", "self", ".", "emb_size", ",", "1", ",", "self", ".", "emb_size_interm", ")", ",", "requires_grad", "=", "True", ")", "\n", ")", "\n", "he_orthogonal_init", "(", "self", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.efficient.EfficientInteractionHadamard.forward": [[85, 118], ["torch.zeros", "torch.matmul", "torch.matmul", "torch.transpose", "torch.max", "torch.matmul", "torch.max", "torch.tensor", "torch.matmul.permute"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "basis", ",", "m", ",", "id_reduce", ",", "Kidx", ")", ":", "\n", "        ", "\"\"\"\n        Returns\n        -------\n            m_ca: Tensor, shape=(nEdges, emb_size)\n                Edge embeddings.\n        \"\"\"", "\n", "# quadruplets: m = m_db , triplets: m = m_ba", "\n", "# num_spherical is actually num_spherical**2 for quadruplets", "\n", "rbf_W1", ",", "sph", "=", "basis", "# (nEdges, emb_size_interm, num_spherical) ,  (nEdges, num_spherical, Kmax)", "\n", "nEdges", "=", "rbf_W1", ".", "shape", "[", "0", "]", "\n", "\n", "# Create (zero-padded) dense matrix of the neighboring edge embeddings.", "\n", "# maximum number of neighbors, catch empty id_reduce_ji with maximum", "\n", "if", "sph", ".", "shape", "[", "2", "]", "==", "0", ":", "\n", "            ", "Kmax", "=", "0", "\n", "", "else", ":", "\n", "            ", "Kmax", "=", "torch", ".", "max", "(", "torch", ".", "max", "(", "Kidx", "+", "1", ")", ",", "torch", ".", "tensor", "(", "0", ")", ")", "\n", "", "m2", "=", "torch", ".", "zeros", "(", "nEdges", ",", "Kmax", ",", "self", ".", "emb_size", ",", "device", "=", "self", ".", "weight", ".", "device", ",", "dtype", "=", "m", ".", "dtype", ")", "\n", "m2", "[", "id_reduce", ",", "Kidx", "]", "=", "m", "# (nQuadruplets or nTriplets, emb_size) -> (nEdges, Kmax, emb_size)", "\n", "\n", "sum_k", "=", "torch", ".", "matmul", "(", "sph", ",", "m2", ")", "# (nEdges, num_spherical, emb_size)", "\n", "\n", "# MatMul: mul + sum over num_spherical", "\n", "rbf_W1_sum_k", "=", "torch", ".", "matmul", "(", "\n", "rbf_W1", ",", "sum_k", "\n", ")", "# (nEdges, emb_size_interm, emb_size)", "\n", "\n", "# MatMul: mul + sum over emb_size_interm", "\n", "m_ca", "=", "torch", ".", "matmul", "(", "self", ".", "weight", ",", "rbf_W1_sum_k", ".", "permute", "(", "2", ",", "1", ",", "0", ")", ")", "[", ":", ",", "0", "]", "# (emb_size, nEdges)", "\n", "m_ca", "=", "torch", ".", "transpose", "(", "m_ca", ",", "0", ",", "1", ")", "# (nEdges, emb_size)", "\n", "\n", "return", "m_ca", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.efficient.EfficientInteractionBilinear.__init__": [[136, 149], ["super().__init__", "efficient.EfficientInteractionBilinear.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.atom_update_block.OutputBlock.reset_parameters"], ["def", "__init__", "(", "\n", "self", ",", "\n", "emb_size", ":", "int", ",", "\n", "emb_size_interm", ":", "int", ",", "\n", "units_out", ":", "int", ",", "\n", "name", "=", "\"EfficientBilinear\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "emb_size", "=", "emb_size", "\n", "self", ".", "emb_size_interm", "=", "emb_size_interm", "\n", "self", ".", "units_out", "=", "units_out", "\n", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.efficient.EfficientInteractionBilinear.reset_parameters": [[150, 158], ["torch.nn.Parameter", "initializers.he_orthogonal_init", "torch.empty"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.initializers.he_orthogonal_init"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "self", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "\n", "torch", ".", "empty", "(", "\n", "(", "self", ".", "emb_size", ",", "self", ".", "emb_size_interm", ",", "self", ".", "units_out", ")", ",", "\n", "requires_grad", "=", "True", ",", "\n", ")", "\n", ")", "\n", "he_orthogonal_init", "(", "self", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.efficient.EfficientInteractionBilinear.forward": [[159, 190], ["torch.zeros", "torch.matmul", "torch.matmul", "torch.matmul", "torch.sum", "torch.max", "torch.matmul.permute", "torch.max", "torch.tensor"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "basis", ",", "m", ",", "id_reduce", ",", "Kidx", ")", ":", "\n", "        ", "\"\"\"\n        Returns\n        -------\n            m_ca: Tensor, shape=(nEdges, units_out)\n                Edge embeddings.\n        \"\"\"", "\n", "# quadruplets: m = m_db , triplets: m = m_ba", "\n", "# num_spherical is actually num_spherical**2 for quadruplets", "\n", "rbf_W1", ",", "sph", "=", "basis", "# (nEdges, emb_size_interm, num_spherical) ,  (nEdges, num_spherical, Kmax)", "\n", "nEdges", "=", "rbf_W1", ".", "shape", "[", "0", "]", "\n", "\n", "# Create (zero-padded) dense matrix of the neighboring edge embeddings.", "\n", "# maximum number of neighbors, catch empty id_reduce_ji with maximum", "\n", "Kmax", "=", "0", "if", "sph", ".", "shape", "[", "2", "]", "==", "0", "else", "torch", ".", "max", "(", "torch", ".", "max", "(", "Kidx", "+", "1", ")", ",", "torch", ".", "tensor", "(", "0", ")", ")", "\n", "m2", "=", "torch", ".", "zeros", "(", "nEdges", ",", "Kmax", ",", "self", ".", "emb_size", ",", "device", "=", "self", ".", "weight", ".", "device", ",", "dtype", "=", "m", ".", "dtype", ")", "\n", "m2", "[", "id_reduce", ",", "Kidx", "]", "=", "m", "# (nQuadruplets or nTriplets, emb_size) -> (nEdges, Kmax, emb_size)", "\n", "\n", "sum_k", "=", "torch", ".", "matmul", "(", "sph", ",", "m2", ")", "# (nEdges, num_spherical, emb_size)", "\n", "\n", "# MatMul: mul + sum over num_spherical", "\n", "rbf_W1_sum_k", "=", "torch", ".", "matmul", "(", "\n", "rbf_W1", ",", "sum_k", "\n", ")", "# (nEdges, emb_size_interm, emb_size)", "\n", "\n", "# Bilinear: Sum over emb_size_interm and emb_size", "\n", "m_ca", "=", "torch", ".", "matmul", "(", "\n", "rbf_W1_sum_k", ".", "permute", "(", "2", ",", "0", ",", "1", ")", ",", "self", ".", "weight", "\n", ")", "# (emb_size, nEdges, units_out)", "\n", "m_ca", "=", "torch", ".", "sum", "(", "m_ca", ",", "dim", "=", "0", ")", "# (nEdges, units_out)", "\n", "return", "m_ca", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.atom_update_block.AtomUpdateBlock.__init__": [[27, 45], ["super().__init__", "base_layers.Dense", "scaling.ScalingFactor", "atom_update_block.AtomUpdateBlock.get_mlp"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.atom_update_block.AtomUpdateBlock.get_mlp"], ["def", "__init__", "(", "\n", "self", ",", "\n", "emb_size_atom", ":", "int", ",", "\n", "emb_size_edge", ":", "int", ",", "\n", "emb_size_rbf", ":", "int", ",", "\n", "nHidden", ":", "int", ",", "\n", "activation", "=", "None", ",", "\n", "scale_file", "=", "None", ",", "\n", "name", ":", "str", "=", "\"atom_update\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "emb_size_edge", "=", "emb_size_edge", "\n", "\n", "self", ".", "dense_rbf", "=", "Dense", "(", "emb_size_rbf", ",", "emb_size_edge", ",", "activation", "=", "None", ",", "bias", "=", "False", ")", "\n", "self", ".", "scale_sum", "=", "ScalingFactor", "(", "scale_file", "=", "scale_file", ",", "name", "=", "name", "+", "\"_sum\"", ")", "\n", "\n", "self", ".", "layers", "=", "self", ".", "get_mlp", "(", "emb_size_atom", ",", "nHidden", ",", "activation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.atom_update_block.AtomUpdateBlock.get_mlp": [[46, 54], ["base_layers.Dense", "torch.nn.ModuleList", "base_layers.ResidualLayer", "range"], "methods", ["None"], ["", "def", "get_mlp", "(", "self", ",", "units", ",", "nHidden", ",", "activation", ")", ":", "\n", "        ", "dense1", "=", "Dense", "(", "self", ".", "emb_size_edge", ",", "units", ",", "activation", "=", "activation", ",", "bias", "=", "False", ")", "\n", "res", "=", "[", "\n", "ResidualLayer", "(", "units", ",", "nLayers", "=", "2", ",", "activation", "=", "activation", ")", "\n", "for", "i", "in", "range", "(", "nHidden", ")", "\n", "]", "\n", "mlp", "=", "[", "dense1", "]", "+", "res", "\n", "return", "torch", ".", "nn", ".", "ModuleList", "(", "mlp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.atom_update_block.AtomUpdateBlock.forward": [[55, 73], ["atom_update_block.AtomUpdateBlock.dense_rbf", "torch_scatter.scatter", "atom_update_block.AtomUpdateBlock.scale_sum", "enumerate", "layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h", ",", "m", ",", "rbf", ",", "id_j", ")", ":", "\n", "        ", "\"\"\"\n        Returns\n        -------\n            h: Tensor, shape=(nAtoms, emb_size_atom)\n                Atom embedding.\n        \"\"\"", "\n", "nAtoms", "=", "h", ".", "shape", "[", "0", "]", "\n", "\n", "mlp_rbf", "=", "self", ".", "dense_rbf", "(", "rbf", ")", "# (nEdges, emb_size_edge)", "\n", "x", "=", "m", "*", "mlp_rbf", "\n", "\n", "x2", "=", "scatter", "(", "x", ",", "id_j", ",", "dim", "=", "0", ",", "dim_size", "=", "nAtoms", ",", "reduce", "=", "\"add\"", ")", "\n", "x", "=", "self", ".", "scale_sum", "(", "m", ",", "x2", ")", "# (nAtoms, emb_size_edge)", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "            ", "x", "=", "layer", "(", "x", ")", "# (nAtoms, emb_size_atom)", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.atom_update_block.OutputBlock.__init__": [[99, 144], ["atom_update_block.AtomUpdateBlock.__init__", "isinstance", "base_layers.Dense", "base_layers.Dense", "atom_update_block.OutputBlock.reset_parameters", "scaling.ScalingFactor", "atom_update_block.OutputBlock.get_mlp", "base_layers.Dense"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.atom_update_block.OutputBlock.reset_parameters", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.atom_update_block.AtomUpdateBlock.get_mlp"], ["def", "__init__", "(", "\n", "self", ",", "\n", "emb_size_atom", ":", "int", ",", "\n", "emb_size_edge", ":", "int", ",", "\n", "emb_size_rbf", ":", "int", ",", "\n", "nHidden", ":", "int", ",", "\n", "num_targets", ":", "int", ",", "\n", "activation", "=", "None", ",", "\n", "direct_forces", "=", "True", ",", "\n", "output_init", "=", "\"HeOrthogonal\"", ",", "\n", "scale_file", "=", "None", ",", "\n", "name", ":", "str", "=", "\"output\"", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "\n", "name", "=", "name", ",", "\n", "emb_size_atom", "=", "emb_size_atom", ",", "\n", "emb_size_edge", "=", "emb_size_edge", ",", "\n", "emb_size_rbf", "=", "emb_size_rbf", ",", "\n", "nHidden", "=", "nHidden", ",", "\n", "activation", "=", "activation", ",", "\n", "scale_file", "=", "scale_file", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "\n", "assert", "isinstance", "(", "output_init", ",", "str", ")", "\n", "self", ".", "output_init", "=", "output_init", "\n", "self", ".", "direct_forces", "=", "direct_forces", "\n", "self", ".", "dense_rbf", "=", "Dense", "(", "emb_size_rbf", ",", "emb_size_edge", ",", "activation", "=", "None", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "seq_energy", "=", "self", ".", "layers", "# inherited from parent class", "\n", "# do not add bias to final layer to enforce that prediction for an atom ", "\n", "# without any edge embeddings is zero", "\n", "self", ".", "out_energy", "=", "Dense", "(", "emb_size_atom", ",", "num_targets", ",", "bias", "=", "False", ",", "activation", "=", "None", ")", "\n", "\n", "if", "self", ".", "direct_forces", ":", "\n", "            ", "self", ".", "scale_rbf", "=", "ScalingFactor", "(", "scale_file", "=", "scale_file", ",", "name", "=", "name", "+", "\"_had\"", ")", "\n", "self", ".", "seq_forces", "=", "self", ".", "get_mlp", "(", "emb_size_edge", ",", "nHidden", ",", "activation", ")", "\n", "# no bias in final layer to ensure continuity", "\n", "self", ".", "out_forces", "=", "Dense", "(", "\n", "emb_size_edge", ",", "num_targets", ",", "bias", "=", "False", ",", "activation", "=", "None", "\n", ")", "\n", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.atom_update_block.OutputBlock.reset_parameters": [[145, 156], ["atom_update_block.OutputBlock.output_init.lower", "initializers.he_orthogonal_init", "initializers.he_orthogonal_init", "atom_update_block.OutputBlock.output_init.lower", "torch.nn.init.zeros_", "UserWarning", "torch.nn.init.zeros_"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.initializers.he_orthogonal_init", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.model.initializers.he_orthogonal_init"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "output_init", ".", "lower", "(", ")", "==", "\"heorthogonal\"", ":", "\n", "            ", "he_orthogonal_init", "(", "self", ".", "out_energy", ".", "weight", ")", "\n", "if", "self", ".", "direct_forces", ":", "\n", "                ", "he_orthogonal_init", "(", "self", ".", "out_forces", ".", "weight", ")", "\n", "", "", "elif", "self", ".", "output_init", ".", "lower", "(", ")", "==", "\"zeros\"", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "out_energy", ".", "weight", ")", "\n", "if", "self", ".", "direct_forces", ":", "\n", "                ", "torch", ".", "nn", ".", "init", ".", "zeros_", "(", "self", ".", "out_forces", ".", "weight", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "UserWarning", "(", "f\"Unknown output_init: {self.output_init}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.atom_update_block.OutputBlock.forward": [[157, 194], ["atom_update_block.OutputBlock.dense_rbf", "torch_scatter.scatter", "atom_update_block.OutputBlock.scale_sum", "enumerate", "atom_update_block.OutputBlock.out_energy", "layer", "atom_update_block.OutputBlock.scale_rbf", "enumerate", "atom_update_block.OutputBlock.out_forces", "layer"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "h", ",", "m", ",", "rbf", ",", "id_j", ")", ":", "\n", "        ", "\"\"\"\n        Returns\n        -------\n            (E, F): tuple\n            - E: Tensor, shape=(nAtoms, num_targets)\n            - F: Tensor, shape=(nEdges, num_targets)\n            Energy and force prediction\n        \"\"\"", "\n", "nAtoms", "=", "h", ".", "shape", "[", "0", "]", "\n", "\n", "rbf_mlp", "=", "self", ".", "dense_rbf", "(", "rbf", ")", "# (nEdges, emb_size_edge)", "\n", "x", "=", "m", "*", "rbf_mlp", "\n", "\n", "# -------------------------------------- Energy Prediction -------------------------------------- #", "\n", "x_E", "=", "scatter", "(", "x", ",", "id_j", ",", "dim", "=", "0", ",", "dim_size", "=", "nAtoms", ",", "reduce", "=", "\"add\"", ")", "# (nAtoms, emb_size_edge)", "\n", "x_E", "=", "self", ".", "scale_sum", "(", "m", ",", "x_E", ")", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "seq_energy", ")", ":", "\n", "            ", "x_E", "=", "layer", "(", "x_E", ")", "# (nAtoms, emb_size_atom)", "\n", "\n", "", "x_E", "=", "self", ".", "out_energy", "(", "x_E", ")", "# (nAtoms, num_targets)", "\n", "\n", "# --------------------------------------- Force Prediction -------------------------------------- #", "\n", "if", "self", ".", "direct_forces", ":", "\n", "\n", "            ", "x_F", "=", "self", ".", "scale_rbf", "(", "m", ",", "x", ")", "\n", "\n", "for", "i", ",", "layer", "in", "enumerate", "(", "self", ".", "seq_forces", ")", ":", "\n", "                ", "x_F", "=", "layer", "(", "x_F", ")", "# (nEdges, emb_size_edge)", "\n", "\n", "", "x_F", "=", "self", ".", "out_forces", "(", "x_F", ")", "# (nEdges, num_targets)", "\n", "", "else", ":", "\n", "            ", "x_F", "=", "0", "\n", "# ----------------------------------------------------------------------------------------------- #", "\n", "\n", "", "return", "x_E", ",", "x_F", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_utils.Jn": [[7, 12], ["scipy.special.spherical_jn"], "function", ["None"], ["def", "Jn", "(", "r", ",", "n", ")", ":", "\n", "    ", "\"\"\"\n    numerical spherical bessel functions of order n\n    \"\"\"", "\n", "return", "sp", ".", "spherical_jn", "(", "n", ",", "r", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_utils.Jn_zeros": [[14, 30], ["numpy.zeros", "numpy.zeros", "range", "numpy.arange", "numpy.arange", "range", "scipy.optimize.brentq"], "function", ["None"], ["", "def", "Jn_zeros", "(", "n", ",", "k", ")", ":", "\n", "    ", "\"\"\"\n    Compute the first k zeros of the spherical bessel functions up to order n (excluded)\n    \"\"\"", "\n", "zerosj", "=", "np", ".", "zeros", "(", "(", "n", ",", "k", ")", ",", "dtype", "=", "\"float32\"", ")", "\n", "zerosj", "[", "0", "]", "=", "np", ".", "arange", "(", "1", ",", "k", "+", "1", ")", "*", "np", ".", "pi", "\n", "points", "=", "np", ".", "arange", "(", "1", ",", "k", "+", "n", ")", "*", "np", ".", "pi", "\n", "racines", "=", "np", ".", "zeros", "(", "k", "+", "n", "-", "1", ",", "dtype", "=", "\"float32\"", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "n", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "k", "+", "n", "-", "1", "-", "i", ")", ":", "\n", "            ", "foo", "=", "brentq", "(", "Jn", ",", "points", "[", "j", "]", ",", "points", "[", "j", "+", "1", "]", ",", "(", "i", ",", ")", ")", "\n", "racines", "[", "j", "]", "=", "foo", "\n", "", "points", "=", "racines", "\n", "zerosj", "[", "i", "]", "[", ":", "k", "]", "=", "racines", "[", ":", "k", "]", "\n", "\n", "", "return", "zerosj", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_utils.spherical_bessel_formulas": [[32, 45], ["sympy.symbols", "range", "sympy.sin", "sympy.simplify", "sympy.sin", "sympy.diff", "sympy.simplify"], "function", ["None"], ["", "def", "spherical_bessel_formulas", "(", "n", ")", ":", "\n", "    ", "\"\"\"\n    Computes the sympy formulas for the spherical bessel functions up to order n (excluded)\n    \"\"\"", "\n", "x", "=", "sym", ".", "symbols", "(", "\"x\"", ")", "\n", "# j_i = (-x)^i * (1/x * d/dx)^\u00ee * sin(x)/x", "\n", "j", "=", "[", "sym", ".", "sin", "(", "x", ")", "/", "x", "]", "# j_0", "\n", "a", "=", "sym", ".", "sin", "(", "x", ")", "/", "x", "\n", "for", "i", "in", "range", "(", "1", ",", "n", ")", ":", "\n", "        ", "b", "=", "sym", ".", "diff", "(", "a", ",", "x", ")", "/", "x", "\n", "j", "+=", "[", "sym", ".", "simplify", "(", "b", "*", "(", "-", "x", ")", "**", "i", ")", "]", "\n", "a", "=", "sym", ".", "simplify", "(", "b", ")", "\n", "", "return", "j", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_utils.bessel_basis": [[47, 81], ["basis_utils.Jn_zeros", "range", "basis_utils.spherical_bessel_formulas", "sympy.symbols", "range", "range", "range", "numpy.array", "sympy.simplify", "basis_utils.Jn", "f[].subs"], "function", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_utils.Jn_zeros", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_utils.spherical_bessel_formulas", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_utils.Jn"], ["", "def", "bessel_basis", "(", "n", ",", "k", ")", ":", "\n", "    ", "\"\"\"\n    Compute the sympy formulas for the normalized and rescaled spherical bessel functions up to\n    order n (excluded) and maximum frequency k (excluded).\n\n    Returns:\n        bess_basis: list\n            Bessel basis formulas taking in a single argument x.\n            Has length n where each element has length k. -> In total n*k many.\n    \"\"\"", "\n", "zeros", "=", "Jn_zeros", "(", "n", ",", "k", ")", "\n", "normalizer", "=", "[", "]", "\n", "for", "order", "in", "range", "(", "n", ")", ":", "\n", "        ", "normalizer_tmp", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k", ")", ":", "\n", "            ", "normalizer_tmp", "+=", "[", "0.5", "*", "Jn", "(", "zeros", "[", "order", ",", "i", "]", ",", "order", "+", "1", ")", "**", "2", "]", "\n", "", "normalizer_tmp", "=", "(", "\n", "1", "/", "np", ".", "array", "(", "normalizer_tmp", ")", "**", "0.5", "\n", ")", "# sqrt(2/(j_l+1)**2) , sqrt(1/c**3) not taken into account yet", "\n", "normalizer", "+=", "[", "normalizer_tmp", "]", "\n", "\n", "", "f", "=", "spherical_bessel_formulas", "(", "n", ")", "\n", "x", "=", "sym", ".", "symbols", "(", "\"x\"", ")", "\n", "bess_basis", "=", "[", "]", "\n", "for", "order", "in", "range", "(", "n", ")", ":", "\n", "        ", "bess_basis_tmp", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "k", ")", ":", "\n", "            ", "bess_basis_tmp", "+=", "[", "\n", "sym", ".", "simplify", "(", "\n", "normalizer", "[", "order", "]", "[", "i", "]", "*", "f", "[", "order", "]", ".", "subs", "(", "x", ",", "zeros", "[", "order", ",", "i", "]", "*", "x", ")", "\n", ")", "\n", "]", "\n", "", "bess_basis", "+=", "[", "bess_basis_tmp", "]", "\n", "", "return", "bess_basis", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_utils.sph_harm_prefactor": [[83, 105], ["numpy.math.factorial", "numpy.math.factorial", "abs", "abs"], "function", ["None"], ["", "def", "sph_harm_prefactor", "(", "l", ",", "m", ")", ":", "\n", "    ", "\"\"\"Computes the constant pre-factor for the spherical harmonic of degree l and order m.\n\n    Parameters\n    ----------\n        l: int\n            Degree of the spherical harmonic. l >= 0\n        m: int\n            Order of the spherical harmonic. -l <= m <= l\n\n    Returns\n    -------\n        factor: float\n\n    \"\"\"", "\n", "# sqrt((2*l+1)/4*pi * (l-m)!/(l+m)! )", "\n", "return", "(", "\n", "(", "2", "*", "l", "+", "1", ")", "\n", "/", "(", "4", "*", "np", ".", "pi", ")", "\n", "*", "np", ".", "math", ".", "factorial", "(", "l", "-", "abs", "(", "m", ")", ")", "\n", "/", "np", ".", "math", ".", "factorial", "(", "l", "+", "abs", "(", "m", ")", ")", "\n", ")", "**", "0.5", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_utils.associated_legendre_polynomials": [[107, 172], ["sympy.symbols", "range", "range", "range", "range", "range", "sympy.simplify", "sympy.simplify", "sympy.simplify", "range", "range", "sympy.simplify", "range", "sympy.simplify", "numpy.math.factorial", "numpy.math.factorial"], "function", ["None"], ["", "def", "associated_legendre_polynomials", "(", "L", ",", "zero_m_only", "=", "True", ",", "pos_m_only", "=", "True", ")", ":", "\n", "    ", "\"\"\"Computes string formulas of the associated legendre polynomials up to degree L (excluded).\n\n    Parameters\n    ----------\n        L: int\n            Degree up to which to calculate the associated legendre polynomials (degree L is excluded).\n        zero_m_only: bool\n            If True only calculate the polynomials for the polynomials where m=0.\n        pos_m_only: bool\n            If True only calculate the polynomials for the polynomials where m>=0. Overwritten by zero_m_only.\n\n    Returns\n    -------\n        polynomials: list\n            Contains the sympy functions of the polynomials (in total L many if zero_m_only is True else L^2 many).\n    \"\"\"", "\n", "# calculations from http://web.cmb.usc.edu/people/alber/Software/tomominer/docs/cpp/group__legendre__polynomials.html", "\n", "z", "=", "sym", ".", "symbols", "(", "\"z\"", ")", "\n", "P_l_m", "=", "[", "[", "0", "]", "*", "(", "2", "*", "l", "+", "1", ")", "for", "l", "in", "range", "(", "L", ")", "]", "# for order l: -l <= m <= l", "\n", "\n", "P_l_m", "[", "0", "]", "[", "0", "]", "=", "1", "\n", "if", "L", ">", "0", ":", "\n", "        ", "if", "zero_m_only", ":", "\n", "# m = 0", "\n", "            ", "P_l_m", "[", "1", "]", "[", "0", "]", "=", "z", "\n", "for", "l", "in", "range", "(", "2", ",", "L", ")", ":", "\n", "                ", "P_l_m", "[", "l", "]", "[", "0", "]", "=", "sym", ".", "simplify", "(", "\n", "(", "(", "2", "*", "l", "-", "1", ")", "*", "z", "*", "P_l_m", "[", "l", "-", "1", "]", "[", "0", "]", "-", "(", "l", "-", "1", ")", "*", "P_l_m", "[", "l", "-", "2", "]", "[", "0", "]", ")", "/", "l", "\n", ")", "\n", "", "return", "P_l_m", "\n", "", "else", ":", "\n", "# for m >= 0", "\n", "            ", "for", "l", "in", "range", "(", "1", ",", "L", ")", ":", "\n", "                ", "P_l_m", "[", "l", "]", "[", "l", "]", "=", "sym", ".", "simplify", "(", "\n", "(", "1", "-", "2", "*", "l", ")", "*", "(", "1", "-", "z", "**", "2", ")", "**", "0.5", "*", "P_l_m", "[", "l", "-", "1", "]", "[", "l", "-", "1", "]", "\n", ")", "# P_00, P_11, P_22, P_33", "\n", "\n", "", "for", "m", "in", "range", "(", "0", ",", "L", "-", "1", ")", ":", "\n", "                ", "P_l_m", "[", "m", "+", "1", "]", "[", "m", "]", "=", "sym", ".", "simplify", "(", "\n", "(", "2", "*", "m", "+", "1", ")", "*", "z", "*", "P_l_m", "[", "m", "]", "[", "m", "]", "\n", ")", "# P_10, P_21, P_32, P_43", "\n", "\n", "", "for", "l", "in", "range", "(", "2", ",", "L", ")", ":", "\n", "                ", "for", "m", "in", "range", "(", "l", "-", "1", ")", ":", "# P_20, P_30, P_31", "\n", "                    ", "P_l_m", "[", "l", "]", "[", "m", "]", "=", "sym", ".", "simplify", "(", "\n", "(", "\n", "(", "2", "*", "l", "-", "1", ")", "*", "z", "*", "P_l_m", "[", "l", "-", "1", "]", "[", "m", "]", "\n", "-", "(", "l", "+", "m", "-", "1", ")", "*", "P_l_m", "[", "l", "-", "2", "]", "[", "m", "]", "\n", ")", "\n", "/", "(", "l", "-", "m", ")", "\n", ")", "\n", "\n", "", "", "if", "not", "pos_m_only", ":", "\n", "# for m < 0: P_l(-m) = (-1)^m * (l-m)!/(l+m)! * P_lm", "\n", "                ", "for", "l", "in", "range", "(", "1", ",", "L", ")", ":", "\n", "                    ", "for", "m", "in", "range", "(", "1", ",", "l", "+", "1", ")", ":", "# P_1(-1), P_2(-1) P_2(-2)", "\n", "                        ", "P_l_m", "[", "l", "]", "[", "-", "m", "]", "=", "sym", ".", "simplify", "(", "\n", "(", "-", "1", ")", "**", "m", "\n", "*", "np", ".", "math", ".", "factorial", "(", "l", "-", "m", ")", "\n", "/", "np", ".", "math", ".", "factorial", "(", "l", "+", "m", ")", "\n", "*", "P_l_m", "[", "l", "]", "[", "m", "]", "\n", ")", "\n", "\n", "", "", "", "return", "P_l_m", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_utils.real_sph_harm": [[174, 254], ["sympy.symbols", "basis_utils.associated_legendre_polynomials", "range", "sympy.symbols", "range", "sympy.simplify", "sympy.symbols", "range", "range", "range", "range", "sympy.symbols", "sympy.symbols", "range", "range", "range", "len", "basis_utils.sph_harm_prefactor", "sympy.simplify", "sympy.simplify", "range", "isinstance", "[].subs", "len", "sympy.simplify", "sympy.cos", "sympy.cos", "sympy.sin", "[].subs", "sympy.atan2", "basis_utils.sph_harm_prefactor", "basis_utils.sph_harm_prefactor"], "function", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_utils.associated_legendre_polynomials", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_utils.sph_harm_prefactor", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_utils.sph_harm_prefactor", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_utils.sph_harm_prefactor"], ["", "", "", "def", "real_sph_harm", "(", "L", ",", "spherical_coordinates", ",", "zero_m_only", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Computes formula strings of the the real part of the spherical harmonics up to degree L (excluded).\n    Variables are either spherical coordinates phi and theta (or cartesian coordinates x,y,z) on the UNIT SPHERE.\n\n    Parameters\n    ----------\n        L: int\n            Degree up to which to calculate the spherical harmonics (degree L is excluded).\n        spherical_coordinates: bool\n            - True: Expects the input of the formula strings to be phi and theta.\n            - False: Expects the input of the formula strings to be x, y and z.\n        zero_m_only: bool\n            If True only calculate the harmonics where m=0.\n\n    Returns\n    -------\n        Y_lm_real: list\n            Computes formula strings of the the real part of the spherical harmonics up\n            to degree L (where degree L is not excluded).\n            In total L^2 many sph harm exist up to degree L (excluded). However, if zero_m_only only is True then\n            the total count is reduced to be only L many.\n    \"\"\"", "\n", "z", "=", "sym", ".", "symbols", "(", "\"z\"", ")", "\n", "P_l_m", "=", "associated_legendre_polynomials", "(", "L", ",", "zero_m_only", ")", "\n", "if", "zero_m_only", ":", "\n", "# for all m != 0: Y_lm = 0", "\n", "        ", "Y_l_m", "=", "[", "[", "0", "]", "for", "l", "in", "range", "(", "L", ")", "]", "\n", "", "else", ":", "\n", "        ", "Y_l_m", "=", "[", "[", "0", "]", "*", "(", "2", "*", "l", "+", "1", ")", "for", "l", "in", "range", "(", "L", ")", "]", "# for order l: -l <= m <= l", "\n", "\n", "# convert expressions to spherical coordiantes", "\n", "", "if", "spherical_coordinates", ":", "\n", "# replace z by cos(theta)", "\n", "        ", "theta", "=", "sym", ".", "symbols", "(", "\"theta\"", ")", "\n", "for", "l", "in", "range", "(", "L", ")", ":", "\n", "            ", "for", "m", "in", "range", "(", "len", "(", "P_l_m", "[", "l", "]", ")", ")", ":", "\n", "                ", "if", "not", "isinstance", "(", "P_l_m", "[", "l", "]", "[", "m", "]", ",", "int", ")", ":", "\n", "                    ", "P_l_m", "[", "l", "]", "[", "m", "]", "=", "P_l_m", "[", "l", "]", "[", "m", "]", ".", "subs", "(", "z", ",", "sym", ".", "cos", "(", "theta", ")", ")", "\n", "\n", "## calculate Y_lm", "\n", "# Y_lm = N * P_lm(cos(theta)) * exp(i*m*phi)", "\n", "#             { sqrt(2) * (-1)^m * N * P_l|m| * sin(|m|*phi)   if m < 0", "\n", "# Y_lm_real = { Y_lm                                           if m = 0", "\n", "#             { sqrt(2) * (-1)^m * N * P_lm * cos(m*phi)       if m > 0", "\n", "\n", "", "", "", "", "for", "l", "in", "range", "(", "L", ")", ":", "\n", "        ", "Y_l_m", "[", "l", "]", "[", "0", "]", "=", "sym", ".", "simplify", "(", "sph_harm_prefactor", "(", "l", ",", "0", ")", "*", "P_l_m", "[", "l", "]", "[", "0", "]", ")", "# Y_l0", "\n", "\n", "", "if", "not", "zero_m_only", ":", "\n", "        ", "phi", "=", "sym", ".", "symbols", "(", "\"phi\"", ")", "\n", "for", "l", "in", "range", "(", "1", ",", "L", ")", ":", "\n", "# m > 0", "\n", "            ", "for", "m", "in", "range", "(", "1", ",", "l", "+", "1", ")", ":", "\n", "                ", "Y_l_m", "[", "l", "]", "[", "m", "]", "=", "sym", ".", "simplify", "(", "\n", "2", "**", "0.5", "\n", "*", "(", "-", "1", ")", "**", "m", "\n", "*", "sph_harm_prefactor", "(", "l", ",", "m", ")", "\n", "*", "P_l_m", "[", "l", "]", "[", "m", "]", "\n", "*", "sym", ".", "cos", "(", "m", "*", "phi", ")", "\n", ")", "\n", "# m < 0", "\n", "", "for", "m", "in", "range", "(", "1", ",", "l", "+", "1", ")", ":", "\n", "                ", "Y_l_m", "[", "l", "]", "[", "-", "m", "]", "=", "sym", ".", "simplify", "(", "\n", "2", "**", "0.5", "\n", "*", "(", "-", "1", ")", "**", "m", "\n", "*", "sph_harm_prefactor", "(", "l", ",", "-", "m", ")", "\n", "*", "P_l_m", "[", "l", "]", "[", "m", "]", "\n", "*", "sym", ".", "sin", "(", "m", "*", "phi", ")", "\n", ")", "\n", "\n", "# convert expressions to cartesian coordinates", "\n", "", "", "if", "not", "spherical_coordinates", ":", "\n", "# replace phi by atan2(y,x)", "\n", "            ", "x", "=", "sym", ".", "symbols", "(", "\"x\"", ")", "\n", "y", "=", "sym", ".", "symbols", "(", "\"y\"", ")", "\n", "for", "l", "in", "range", "(", "L", ")", ":", "\n", "                ", "for", "m", "in", "range", "(", "len", "(", "Y_l_m", "[", "l", "]", ")", ")", ":", "\n", "                    ", "Y_l_m", "[", "l", "]", "[", "m", "]", "=", "sym", ".", "simplify", "(", "Y_l_m", "[", "l", "]", "[", "m", "]", ".", "subs", "(", "phi", ",", "sym", ".", "atan2", "(", "y", ",", "x", ")", ")", ")", "\n", "", "", "", "", "return", "Y_l_m", "\n", "", ""]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.envelope.Envelope.__init__": [[14, 21], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__"], ["def", "__init__", "(", "self", ",", "p", ",", "name", "=", "\"envelope\"", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "assert", "p", ">", "0", "\n", "self", ".", "p", "=", "p", "\n", "self", ".", "a", "=", "-", "(", "self", ".", "p", "+", "1", ")", "*", "(", "self", ".", "p", "+", "2", ")", "/", "2", "\n", "self", ".", "b", "=", "self", ".", "p", "*", "(", "self", ".", "p", "+", "2", ")", "\n", "self", ".", "c", "=", "-", "self", ".", "p", "*", "(", "self", ".", "p", "+", "1", ")", "/", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.envelope.Envelope.forward": [[22, 30], ["torch.where", "torch.zeros_like"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "d_scaled", ")", ":", "\n", "        ", "env_val", "=", "(", "\n", "1", "\n", "+", "self", ".", "a", "*", "d_scaled", "**", "self", ".", "p", "\n", "+", "self", ".", "b", "*", "d_scaled", "**", "(", "self", ".", "p", "+", "1", ")", "\n", "+", "self", ".", "c", "*", "d_scaled", "**", "(", "self", ".", "p", "+", "2", ")", "\n", ")", "\n", "return", "torch", ".", "where", "(", "d_scaled", "<", "1", ",", "env_val", ",", "torch", ".", "zeros_like", "(", "d_scaled", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_layers.BesselBasisLayer.__init__": [[23, 43], ["super().__init__", "envelope.Envelope", "torch.nn.Parameter", "torch.Tensor", "numpy.arange"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "num_radial", ":", "int", ",", "\n", "cutoff", ":", "float", ",", "\n", "envelope_exponent", ":", "int", "=", "5", ",", "\n", "name", "=", "\"bessel_basis\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_radial", "=", "num_radial", "\n", "self", ".", "inv_cutoff", "=", "1", "/", "cutoff", "\n", "self", ".", "norm_const", "=", "(", "2", "*", "self", ".", "inv_cutoff", ")", "**", "0.5", "\n", "\n", "self", ".", "envelope", "=", "Envelope", "(", "envelope_exponent", ")", "\n", "\n", "# Initialize frequencies at canonical positions", "\n", "self", ".", "frequencies", "=", "torch", ".", "nn", ".", "Parameter", "(", "\n", "data", "=", "torch", ".", "Tensor", "(", "\n", "np", ".", "pi", "*", "np", ".", "arange", "(", "1", ",", "self", ".", "num_radial", "+", "1", ",", "dtype", "=", "np", ".", "float32", ")", "\n", ")", ",", "\n", "requires_grad", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_layers.BesselBasisLayer.forward": [[45, 50], ["basis_layers.BesselBasisLayer.envelope", "torch.sin"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "d", ")", ":", "\n", "        ", "d", "=", "d", "[", ":", ",", "None", "]", "# (nEdges,1)", "\n", "d_scaled", "=", "d", "*", "self", ".", "inv_cutoff", "\n", "env", "=", "self", ".", "envelope", "(", "d_scaled", ")", "\n", "return", "env", "*", "self", ".", "norm_const", "*", "torch", ".", "sin", "(", "self", ".", "frequencies", "*", "d_scaled", ")", "/", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_layers.SphericalBasisLayer.__init__": [[70, 117], ["super().__init__", "envelope.Envelope", "basis_utils.bessel_basis", "basis_utils.real_sph_harm", "basis_layers.SphericalBasisLayer.register_buffer", "sympy.symbols", "sympy.symbols", "range", "torch.zeros", "len", "range", "sympy.lambdify", "basis_layers.SphericalBasisLayer.sph_funcs.append", "basis_layers.SphericalBasisLayer.sph_funcs.append", "basis_layers.SphericalBasisLayer.bessel_funcs.append", "sympy.lambdify", "sympy.lambdify", "torch.zeros_like", "sympy.lambdify."], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_utils.bessel_basis", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_utils.real_sph_harm"], ["def", "__init__", "(", "\n", "self", ",", "\n", "num_spherical", ":", "int", ",", "\n", "num_radial", ":", "int", ",", "\n", "cutoff", ":", "float", ",", "\n", "envelope_exponent", ":", "int", "=", "5", ",", "\n", "efficient", ":", "bool", "=", "False", ",", "\n", "name", ":", "str", "=", "\"spherical_basis\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "num_radial", "<=", "64", "\n", "self", ".", "efficient", "=", "efficient", "\n", "self", ".", "num_radial", "=", "num_radial", "\n", "self", ".", "num_spherical", "=", "num_spherical", "\n", "self", ".", "envelope", "=", "Envelope", "(", "envelope_exponent", ")", "\n", "self", ".", "inv_cutoff", "=", "1", "/", "cutoff", "\n", "\n", "# retrieve formulas", "\n", "bessel_formulas", "=", "bessel_basis", "(", "num_spherical", ",", "num_radial", ")", "\n", "Y_lm", "=", "real_sph_harm", "(", "\n", "num_spherical", ",", "spherical_coordinates", "=", "True", ",", "zero_m_only", "=", "True", "\n", ")", "\n", "self", ".", "sph_funcs", "=", "[", "]", "# (num_spherical,)", "\n", "self", ".", "bessel_funcs", "=", "[", "]", "# (num_spherical * num_radial,)", "\n", "self", ".", "norm_const", "=", "self", ".", "inv_cutoff", "**", "1.5", "\n", "self", ".", "register_buffer", "(", "\n", "\"device_buffer\"", ",", "torch", ".", "zeros", "(", "0", ")", ",", "persistent", "=", "False", "\n", ")", "# dummy buffer to get device of layer", "\n", "\n", "# convert to torch functions", "\n", "x", "=", "sym", ".", "symbols", "(", "\"x\"", ")", "\n", "theta", "=", "sym", ".", "symbols", "(", "\"theta\"", ")", "\n", "modules", "=", "{", "\"sin\"", ":", "torch", ".", "sin", ",", "\"cos\"", ":", "torch", ".", "cos", ",", "\"sqrt\"", ":", "torch", ".", "sqrt", "}", "\n", "m", "=", "0", "# only single angle", "\n", "for", "l", "in", "range", "(", "len", "(", "Y_lm", ")", ")", ":", "# num_spherical", "\n", "            ", "if", "l", "==", "0", ":", "\n", "# Y_00 is only a constant -> function returns value and not tensor", "\n", "                ", "first_sph", "=", "sym", ".", "lambdify", "(", "[", "theta", "]", ",", "Y_lm", "[", "l", "]", "[", "m", "]", ",", "modules", ")", "\n", "self", ".", "sph_funcs", ".", "append", "(", "\n", "lambda", "theta", ":", "torch", ".", "zeros_like", "(", "theta", ")", "+", "first_sph", "(", "theta", ")", "\n", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "sph_funcs", ".", "append", "(", "sym", ".", "lambdify", "(", "[", "theta", "]", ",", "Y_lm", "[", "l", "]", "[", "m", "]", ",", "modules", ")", ")", "\n", "", "for", "n", "in", "range", "(", "num_radial", ")", ":", "\n", "                ", "self", ".", "bessel_funcs", ".", "append", "(", "\n", "sym", ".", "lambdify", "(", "[", "x", "]", ",", "bessel_formulas", "[", "l", "]", "[", "n", "]", ",", "modules", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_layers.SphericalBasisLayer.forward": [[119, 163], ["basis_layers.SphericalBasisLayer.envelope", "torch.stack", "torch.stack", "f", "f", "torch.transpose.view", "sph.view.view.view", "torch.transpose.view", "torch.transpose", "torch.zeros", "torch.max", "torch.max", "torch.tensor"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "D_ca", ",", "Angle_cab", ",", "id3_reduce_ca", ",", "Kidx", ")", ":", "\n", "\n", "        ", "d_scaled", "=", "D_ca", "*", "self", ".", "inv_cutoff", "# (nEdges,)", "\n", "u_d", "=", "self", ".", "envelope", "(", "d_scaled", ")", "\n", "rbf", "=", "[", "f", "(", "d_scaled", ")", "for", "f", "in", "self", ".", "bessel_funcs", "]", "\n", "# s: 0 0 0 0 1 1 1 1 ...", "\n", "# r: 0 1 2 3 0 1 2 3 ...", "\n", "rbf", "=", "torch", ".", "stack", "(", "rbf", ",", "dim", "=", "1", ")", "# (nEdges, num_spherical * num_radial)", "\n", "rbf", "=", "rbf", "*", "self", ".", "norm_const", "\n", "rbf_env", "=", "u_d", "[", ":", ",", "None", "]", "*", "rbf", "# (nEdges, num_spherical * num_radial)", "\n", "\n", "sph", "=", "[", "f", "(", "Angle_cab", ")", "for", "f", "in", "self", ".", "sph_funcs", "]", "\n", "sph", "=", "torch", ".", "stack", "(", "sph", ",", "dim", "=", "1", ")", "# (nTriplets, num_spherical)", "\n", "\n", "if", "not", "self", ".", "efficient", ":", "\n", "            ", "rbf_env", "=", "rbf_env", "[", "id3_reduce_ca", "]", "# (nTriplets, num_spherical * num_radial)", "\n", "rbf_env", "=", "rbf_env", ".", "view", "(", "-", "1", ",", "self", ".", "num_spherical", ",", "self", ".", "num_radial", ")", "\n", "# e.g. num_spherical = 3, num_radial = 2", "\n", "# z_ln: l: 0 0  1 1  2 2", "\n", "#       n: 0 1  0 1  0 1", "\n", "sph", "=", "sph", ".", "view", "(", "-", "1", ",", "self", ".", "num_spherical", ",", "1", ")", "# (nTriplets, num_spherical, 1)", "\n", "# e.g. num_spherical = 3, num_radial = 2", "\n", "# Y_lm: l: 0 0  1 1  2 2", "\n", "#       m: 0 0  0 0  0 0", "\n", "out", "=", "(", "rbf_env", "*", "sph", ")", ".", "view", "(", "-", "1", ",", "self", ".", "num_spherical", "*", "self", ".", "num_radial", ")", "\n", "return", "out", "# (nTriplets, num_spherical * num_radial)", "\n", "", "else", ":", "\n", "            ", "rbf_env", "=", "rbf_env", ".", "view", "(", "-", "1", ",", "self", ".", "num_spherical", ",", "self", ".", "num_radial", ")", "\n", "rbf_env", "=", "torch", ".", "transpose", "(", "\n", "rbf_env", ",", "0", ",", "1", "\n", ")", "# (num_spherical, nEdges, num_radial)", "\n", "\n", "# Zero padded dense matrix", "\n", "# maximum number of neighbors, catch empty id_reduce_ji with maximum", "\n", "Kmax", "=", "0", "if", "sph", ".", "shape", "[", "0", "]", "==", "0", "else", "torch", ".", "max", "(", "torch", ".", "max", "(", "Kidx", "+", "1", ")", ",", "torch", ".", "tensor", "(", "0", ")", ")", "\n", "nEdges", "=", "d_scaled", ".", "shape", "[", "0", "]", "\n", "\n", "sph2", "=", "torch", ".", "zeros", "(", "\n", "nEdges", ",", "Kmax", ",", "self", ".", "num_spherical", ",", "device", "=", "self", ".", "device_buffer", ".", "device", ",", "dtype", "=", "sph", ".", "dtype", "\n", ")", "\n", "sph2", "[", "id3_reduce_ca", ",", "Kidx", "]", "=", "sph", "\n", "\n", "# (num_spherical, nEdges, num_radial), (nEdges, Kmax, num_spherical)", "\n", "return", "rbf_env", ",", "sph2", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_layers.TensorBasisLayer.__init__": [[183, 237], ["super().__init__", "envelope.Envelope", "basis_utils.bessel_basis", "basis_utils.real_sph_harm", "sympy.symbols", "sympy.symbols", "sympy.symbols", "range", "basis_layers.TensorBasisLayer.register_buffer", "len", "range", "range", "len", "basis_layers.TensorBasisLayer.bessel_funcs.append", "sympy.lambdify", "basis_layers.TensorBasisLayer.sph_funcs.append", "basis_layers.TensorBasisLayer.sph_funcs.append", "sympy.lambdify", "torch.arange", "sympy.lambdify", "torch.zeros_like", "sympy.lambdify."], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_utils.bessel_basis", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_utils.real_sph_harm"], ["def", "__init__", "(", "\n", "self", ",", "\n", "num_spherical", ":", "int", ",", "\n", "num_radial", ":", "int", ",", "\n", "cutoff", ":", "float", ",", "\n", "envelope_exponent", ":", "int", "=", "5", ",", "\n", "efficient", "=", "False", ",", "\n", "name", ":", "str", "=", "\"tensor_basis\"", ",", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "num_radial", "<=", "64", "\n", "self", ".", "num_radial", "=", "num_radial", "\n", "self", ".", "num_spherical", "=", "num_spherical", "\n", "self", ".", "efficient", "=", "efficient", "\n", "\n", "self", ".", "inv_cutoff", "=", "1", "/", "cutoff", "\n", "self", ".", "envelope", "=", "Envelope", "(", "envelope_exponent", ")", "\n", "\n", "# retrieve formulas", "\n", "bessel_formulas", "=", "bessel_basis", "(", "num_spherical", ",", "num_radial", ")", "\n", "Y_lm", "=", "real_sph_harm", "(", "\n", "num_spherical", ",", "spherical_coordinates", "=", "True", ",", "zero_m_only", "=", "False", "\n", ")", "\n", "self", ".", "sph_funcs", "=", "[", "]", "# (num_spherical**2,)", "\n", "self", ".", "bessel_funcs", "=", "[", "]", "# (num_spherical * num_radial,)", "\n", "self", ".", "norm_const", "=", "self", ".", "inv_cutoff", "**", "1.5", "\n", "\n", "# convert to tensorflow functions", "\n", "x", "=", "sym", ".", "symbols", "(", "\"x\"", ")", "\n", "theta", "=", "sym", ".", "symbols", "(", "\"theta\"", ")", "\n", "phi", "=", "sym", ".", "symbols", "(", "\"phi\"", ")", "\n", "modules", "=", "{", "\"sin\"", ":", "torch", ".", "sin", ",", "\"cos\"", ":", "torch", ".", "cos", ",", "\"sqrt\"", ":", "torch", ".", "sqrt", "}", "\n", "for", "l", "in", "range", "(", "len", "(", "Y_lm", ")", ")", ":", "# num_spherical", "\n", "            ", "for", "m", "in", "range", "(", "len", "(", "Y_lm", "[", "l", "]", ")", ")", ":", "\n", "                ", "if", "(", "\n", "l", "==", "0", "\n", ")", ":", "# Y_00 is only a constant -> function returns value and not tensor", "\n", "                    ", "first_sph", "=", "sym", ".", "lambdify", "(", "[", "theta", ",", "phi", "]", ",", "Y_lm", "[", "l", "]", "[", "m", "]", ",", "modules", ")", "\n", "self", ".", "sph_funcs", ".", "append", "(", "\n", "lambda", "theta", ",", "phi", ":", "torch", ".", "zeros_like", "(", "theta", ")", "\n", "+", "first_sph", "(", "theta", ",", "phi", ")", "\n", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "sph_funcs", ".", "append", "(", "\n", "sym", ".", "lambdify", "(", "[", "theta", ",", "phi", "]", ",", "Y_lm", "[", "l", "]", "[", "m", "]", ",", "modules", ")", "\n", ")", "\n", "", "", "for", "j", "in", "range", "(", "num_radial", ")", ":", "\n", "                ", "self", ".", "bessel_funcs", ".", "append", "(", "\n", "sym", ".", "lambdify", "(", "[", "x", "]", ",", "bessel_formulas", "[", "l", "]", "[", "j", "]", ",", "modules", ")", "\n", ")", "\n", "\n", "", "", "self", ".", "register_buffer", "(", "\n", "\"degreeInOrder\"", ",", "torch", ".", "arange", "(", "num_spherical", ")", "*", "2", "+", "1", ",", "persistent", "=", "False", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.layers.basis_layers.TensorBasisLayer.forward": [[239, 296], ["basis_layers.TensorBasisLayer.envelope", "torch.stack", "torch.transpose.view", "torch.repeat_interleave", "torch.stack", "f", "torch.transpose.view", "f", "torch.repeat_interleave", "torch.transpose", "torch.zeros", "torch.max", "torch.max", "torch.tensor"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "D_ca", ",", "Alpha_cab", ",", "Theta_cabd", ",", "id4_reduce_ca", ",", "Kidx", ")", ":", "\n", "\n", "        ", "d_scaled", "=", "D_ca", "*", "self", ".", "inv_cutoff", "\n", "u_d", "=", "self", ".", "envelope", "(", "d_scaled", ")", "\n", "\n", "rbf", "=", "[", "f", "(", "d_scaled", ")", "for", "f", "in", "self", ".", "bessel_funcs", "]", "\n", "# s: 0 0 0 0 1 1 1 1 ...", "\n", "# r: 0 1 2 3 0 1 2 3 ...", "\n", "rbf", "=", "torch", ".", "stack", "(", "rbf", ",", "dim", "=", "1", ")", "# (nEdges, num_spherical * num_radial)", "\n", "rbf", "=", "rbf", "*", "self", ".", "norm_const", "\n", "\n", "rbf_env", "=", "u_d", "[", ":", ",", "None", "]", "*", "rbf", "# (nEdges, num_spherical * num_radial)", "\n", "rbf_env", "=", "rbf_env", ".", "view", "(", "\n", "(", "-", "1", ",", "self", ".", "num_spherical", ",", "self", ".", "num_radial", ")", "\n", ")", "# (nEdges, num_spherical, num_radial)", "\n", "rbf_env", "=", "torch", ".", "repeat_interleave", "(", "\n", "rbf_env", ",", "self", ".", "degreeInOrder", ",", "dim", "=", "1", "\n", ")", "# (nEdges, num_spherical**2, num_radial)", "\n", "\n", "if", "not", "self", ".", "efficient", ":", "\n", "            ", "rbf_env", "=", "rbf_env", ".", "view", "(", "\n", "(", "-", "1", ",", "self", ".", "num_spherical", "**", "2", "*", "self", ".", "num_radial", ")", "\n", ")", "# (nEdges, num_spherical**2 * num_radial)", "\n", "rbf_env", "=", "rbf_env", "[", "\n", "id4_reduce_ca", "\n", "]", "# (nQuadruplets, num_spherical**2 * num_radial)", "\n", "# e.g. num_spherical = 3, num_radial = 2", "\n", "# j_ln: l: 0  0    1  1  1  1  1  1    2  2  2  2  2  2  2  2  2  2", "\n", "#       n: 0  1    0  1  0  1  0  1    0  1  0  1  0  1  0  1  0  1", "\n", "\n", "", "sph", "=", "[", "f", "(", "Alpha_cab", ",", "Theta_cabd", ")", "for", "f", "in", "self", ".", "sph_funcs", "]", "\n", "sph", "=", "torch", ".", "stack", "(", "sph", ",", "dim", "=", "1", ")", "# (nQuadruplets, num_spherical**2)", "\n", "\n", "if", "not", "self", ".", "efficient", ":", "\n", "            ", "sph", "=", "torch", ".", "repeat_interleave", "(", "\n", "sph", ",", "self", ".", "num_radial", ",", "axis", "=", "1", "\n", ")", "# (nQuadruplets, num_spherical**2 * num_radial)", "\n", "# e.g. num_spherical = 3, num_radial = 2", "\n", "# Y_lm: l: 0  0    1  1  1  1  1  1    2  2  2  2  2  2  2  2  2  2", "\n", "#       m: 0  0   -1 -1  0  0  1  1   -2 -2 -1 -1  0  0  1  1  2  2", "\n", "return", "rbf_env", "*", "sph", "# (nQuadruplets, num_spherical**2 * num_radial)", "\n", "\n", "", "else", ":", "\n", "            ", "rbf_env", "=", "torch", ".", "transpose", "(", "rbf_env", ",", "0", ",", "1", ")", "# (num_spherical**2, nEdges, num_radial)", "\n", "\n", "# Zero padded dense matrix", "\n", "# maximum number of neighbors, catch empty id_reduce_ji with maximum", "\n", "Kmax", "=", "0", "if", "sph", ".", "shape", "[", "0", "]", "==", "0", "else", "torch", ".", "max", "(", "torch", ".", "max", "(", "Kidx", "+", "1", ")", ",", "torch", ".", "tensor", "(", "0", ")", ")", "\n", "nEdges", "=", "d_scaled", ".", "shape", "[", "0", "]", "\n", "\n", "sph2", "=", "torch", ".", "zeros", "(", "\n", "nEdges", ",", "Kmax", ",", "self", ".", "num_spherical", "**", "2", ",", "device", "=", "self", ".", "degreeInOrder", ".", "device", ",", "dtype", "=", "sph", ".", "dtype", "\n", ")", "\n", "sph2", "[", "id4_reduce_ca", ",", "Kidx", "]", "=", "sph", "\n", "\n", "# (num_spherical**2, nEdges, num_radial), (nEdges, Kmax, num_spherical**2)", "\n", "return", "rbf_env", ",", "sph2", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.ema_decay.ExponentialMovingAverage.__init__": [[30, 49], ["list", "ValueError", "p.clone().detach", "weakref.ref", "p.clone"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "parameters", ":", "Iterable", "[", "torch", ".", "nn", ".", "Parameter", "]", ",", "\n", "decay", ":", "float", ",", "\n", "use_num_updates", ":", "bool", "=", "False", ",", "\n", ")", ":", "\n", "        ", "if", "decay", "<", "0.0", "or", "decay", ">", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Decay must be between 0 and 1\"", ")", "\n", "", "self", ".", "decay", "=", "decay", "\n", "self", ".", "num_updates", "=", "0", "if", "use_num_updates", "else", "None", "\n", "parameters", "=", "list", "(", "parameters", ")", "\n", "self", ".", "shadow_params", "=", "[", "p", ".", "clone", "(", ")", ".", "detach", "(", ")", "for", "p", "in", "parameters", "if", "p", ".", "requires_grad", "]", "\n", "self", ".", "collected_params", "=", "[", "]", "\n", "# By maintaining only a weakref to each parameter,", "\n", "# we maintain the old GC behaviour of ExponentialMovingAverage:", "\n", "# if the model goes out of scope but the ExponentialMovingAverage", "\n", "# is kept, no references to the model or its parameters will be", "\n", "# maintained, and the model will be cleaned up.", "\n", "self", ".", "_params_refs", "=", "[", "weakref", ".", "ref", "(", "p", ")", "for", "p", "in", "parameters", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.ema_decay.ExponentialMovingAverage._get_parameters": [[50, 67], ["any", "p", "ValueError"], "methods", ["None"], ["", "def", "_get_parameters", "(", "\n", "self", ",", "parameters", ":", "Optional", "[", "Iterable", "[", "torch", ".", "nn", ".", "Parameter", "]", "]", "\n", ")", "->", "Iterable", "[", "torch", ".", "nn", ".", "Parameter", "]", ":", "\n", "        ", "if", "parameters", "is", "None", ":", "\n", "            ", "parameters", "=", "[", "p", "(", ")", "for", "p", "in", "self", ".", "_params_refs", "]", "\n", "if", "any", "(", "p", "is", "None", "for", "p", "in", "parameters", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"(One of) the parameters with which this \"", "\n", "\"ExponentialMovingAverage \"", "\n", "\"was initialized no longer exists (was garbage collected);\"", "\n", "\" please either provide `parameters` explicitly or keep \"", "\n", "\"the model to which they belong from being garbage \"", "\n", "\"collected.\"", "\n", ")", "\n", "", "return", "parameters", "\n", "", "else", ":", "\n", "            ", "return", "parameters", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.ema_decay.ExponentialMovingAverage.update": [[68, 94], ["ema_decay.ExponentialMovingAverage._get_parameters", "min", "torch.no_grad", "zip", "tmp.mul_", "s_param.sub_"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.ema_decay.ExponentialMovingAverage._get_parameters"], ["", "", "def", "update", "(", "self", ",", "parameters", ":", "Optional", "[", "Iterable", "[", "torch", ".", "nn", ".", "Parameter", "]", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Update currently maintained parameters.\n\n        Call this every time the parameters are updated, such as the result of\n        the `optimizer.step()` call.\n\n        Args:\n          parameters: Iterable of `torch.nn.Parameter`; usually the same set of\n            parameters used to initialize this object. If `None`, the\n            parameters with which this `ExponentialMovingAverage` was\n            initialized will be used.\n        \"\"\"", "\n", "parameters", "=", "self", ".", "_get_parameters", "(", "parameters", ")", "\n", "decay", "=", "self", ".", "decay", "\n", "if", "self", ".", "num_updates", "is", "not", "None", ":", "\n", "            ", "self", ".", "num_updates", "+=", "1", "\n", "decay", "=", "min", "(", "decay", ",", "(", "1", "+", "self", ".", "num_updates", ")", "/", "(", "10", "+", "self", ".", "num_updates", ")", ")", "\n", "", "one_minus_decay", "=", "1.0", "-", "decay", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "parameters", "=", "[", "p", "for", "p", "in", "parameters", "if", "p", ".", "requires_grad", "]", "\n", "for", "s_param", ",", "param", "in", "zip", "(", "self", ".", "shadow_params", ",", "parameters", ")", ":", "\n", "                ", "tmp", "=", "s_param", "-", "param", "\n", "# tmp will be a new tensor so we can do in-place", "\n", "tmp", ".", "mul_", "(", "one_minus_decay", ")", "\n", "s_param", ".", "sub_", "(", "tmp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.ema_decay.ExponentialMovingAverage.copy_to": [[95, 111], ["ema_decay.ExponentialMovingAverage._get_parameters", "zip", "param.data.copy_"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.ema_decay.ExponentialMovingAverage._get_parameters"], ["", "", "", "def", "copy_to", "(", "\n", "self", ",", "parameters", ":", "Optional", "[", "Iterable", "[", "torch", ".", "nn", ".", "Parameter", "]", "]", "=", "None", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Copy current parameters into given collection of parameters.\n\n        Args:\n          parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n            updated with the stored moving averages. If `None`, the\n            parameters with which this `ExponentialMovingAverage` was\n            initialized will be used.\n        \"\"\"", "\n", "parameters", "=", "self", ".", "_get_parameters", "(", "parameters", ")", "\n", "for", "s_param", ",", "param", "in", "zip", "(", "self", ".", "shadow_params", ",", "parameters", ")", ":", "\n", "            ", "if", "param", ".", "requires_grad", ":", "\n", "                ", "param", ".", "data", ".", "copy_", "(", "s_param", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.ema_decay.ExponentialMovingAverage.store": [[112, 124], ["ema_decay.ExponentialMovingAverage._get_parameters", "param.clone"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.ema_decay.ExponentialMovingAverage._get_parameters"], ["", "", "", "def", "store", "(", "self", ",", "parameters", ":", "Optional", "[", "Iterable", "[", "torch", ".", "nn", ".", "Parameter", "]", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Save the current parameters for restoring later.\n\n        Args:\n          parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n            temporarily stored. If `None`, the parameters of with which this\n            `ExponentialMovingAverage` was initialized will be used.\n        \"\"\"", "\n", "parameters", "=", "self", ".", "_get_parameters", "(", "parameters", ")", "\n", "self", ".", "collected_params", "=", "[", "\n", "param", ".", "clone", "(", ")", "for", "param", "in", "parameters", "if", "param", ".", "requires_grad", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.ema_decay.ExponentialMovingAverage.restore": [[126, 146], ["ema_decay.ExponentialMovingAverage._get_parameters", "zip", "param.data.copy_"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.ema_decay.ExponentialMovingAverage._get_parameters"], ["", "def", "restore", "(", "\n", "self", ",", "parameters", ":", "Optional", "[", "Iterable", "[", "torch", ".", "nn", ".", "Parameter", "]", "]", "=", "None", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Restore the parameters stored with the `store` method.\n        Useful to validate the model with EMA parameters without affecting the\n        original optimization process. Store the parameters before the\n        `copy_to` method. After validation (or model saving), use this to\n        restore the former parameters.\n\n        Args:\n          parameters: Iterable of `torch.nn.Parameter`; the parameters to be\n            updated with the stored parameters. If `None`, the\n            parameters with which this `ExponentialMovingAverage` was\n            initialized will be used.\n        \"\"\"", "\n", "parameters", "=", "self", ".", "_get_parameters", "(", "parameters", ")", "\n", "for", "c_param", ",", "param", "in", "zip", "(", "self", ".", "collected_params", ",", "parameters", ")", ":", "\n", "            ", "if", "param", ".", "requires_grad", ":", "\n", "                ", "param", ".", "data", ".", "copy_", "(", "c_param", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.ema_decay.ExponentialMovingAverage.state_dict": [[147, 157], ["None"], "methods", ["None"], ["", "", "", "def", "state_dict", "(", "self", ")", "->", "dict", ":", "\n", "        ", "r\"\"\"Returns the state of the ExponentialMovingAverage as a dict.\"\"\"", "\n", "# Following PyTorch conventions, references to tensors are returned:", "\n", "# \"returns a reference to the state and not its copy!\" -", "\n", "# https://pytorch.org/tutorials/beginner/saving_loading_models.html#what-is-a-state-dict", "\n", "return", "{", "\n", "\"decay\"", ":", "self", ".", "decay", ",", "\n", "\"num_updates\"", ":", "self", ".", "num_updates", ",", "\n", "\"shadow_params\"", ":", "self", ".", "shadow_params", ",", "\n", "\"collected_params\"", ":", "self", ".", "collected_params", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.ema_decay.ExponentialMovingAverage.load_state_dict": [[159, 187], ["copy.deepcopy", "isinstance", "all", "isinstance", "all", "ValueError", "isinstance", "isinstance", "isinstance"], "methods", ["None"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ":", "dict", ")", "->", "None", ":", "\n", "        ", "r\"\"\"Loads the ExponentialMovingAverage state.\n\n        Args:\n            state_dict (dict): EMA state. Should be an object returned\n                from a call to :meth:`state_dict`.\n        \"\"\"", "\n", "# deepcopy, to be consistent with module API", "\n", "state_dict", "=", "copy", ".", "deepcopy", "(", "state_dict", ")", "\n", "self", ".", "decay", "=", "state_dict", "[", "\"decay\"", "]", "\n", "if", "self", ".", "decay", "<", "0.0", "or", "self", ".", "decay", ">", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "\"Decay must be between 0 and 1\"", ")", "\n", "", "self", ".", "num_updates", "=", "state_dict", "[", "\"num_updates\"", "]", "\n", "assert", "self", ".", "num_updates", "is", "None", "or", "isinstance", "(", "\n", "self", ".", "num_updates", ",", "int", "\n", ")", ",", "\"Invalid num_updates\"", "\n", "self", ".", "shadow_params", "=", "state_dict", "[", "\"shadow_params\"", "]", "\n", "assert", "isinstance", "(", "self", ".", "shadow_params", ",", "list", ")", ",", "\"shadow_params must be a list\"", "\n", "assert", "all", "(", "\n", "isinstance", "(", "p", ",", "torch", ".", "Tensor", ")", "for", "p", "in", "self", ".", "shadow_params", "\n", ")", ",", "\"shadow_params must all be Tensors\"", "\n", "self", ".", "collected_params", "=", "state_dict", "[", "\"collected_params\"", "]", "\n", "assert", "isinstance", "(", "\n", "self", ".", "collected_params", ",", "list", "\n", ")", ",", "\"collected_params must be a list\"", "\n", "assert", "all", "(", "\n", "isinstance", "(", "p", ",", "torch", ".", "Tensor", ")", "for", "p", "in", "self", ".", "collected_params", "\n", ")", ",", "\"collected_params must all be Tensors\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer.__init__": [[24, 92], ["data_container.DataContainer._load_npz", "numpy.concatenate", "data_container.DataContainer.get_dtypes", "data_container.DataContainer.dtypes.update", "isinstance", "transform", "len", "len", "numpy.cumsum"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer._load_npz", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer.get_dtypes", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.update"], ["def", "__init__", "(", "\n", "self", ",", "\n", "path", ",", "\n", "cutoff", ",", "\n", "int_cutoff", ",", "\n", "triplets_only", "=", "False", ",", "\n", "transforms", "=", "None", ",", "\n", "addID", "=", "False", ",", "\n", ")", ":", "\n", "        ", "self", ".", "index_keys", "=", "[", "\n", "\"batch_seg\"", ",", "\n", "\"id_undir\"", ",", "\n", "\"id_swap\"", ",", "\n", "\"id_c\"", ",", "\n", "\"id_a\"", ",", "\n", "\"id3_expand_ba\"", ",", "\n", "\"id3_reduce_ca\"", ",", "\n", "\"Kidx3\"", ",", "\n", "]", "\n", "if", "not", "triplets_only", ":", "\n", "            ", "self", ".", "index_keys", "+=", "[", "\n", "\"id4_int_b\"", ",", "\n", "\"id4_int_a\"", ",", "\n", "\"id4_reduce_ca\"", ",", "\n", "\"id4_expand_db\"", ",", "\n", "\"id4_reduce_cab\"", ",", "\n", "\"id4_expand_abd\"", ",", "\n", "\"Kidx4\"", ",", "\n", "\"id4_reduce_intm_ca\"", ",", "\n", "\"id4_expand_intm_db\"", ",", "\n", "\"id4_reduce_intm_ab\"", ",", "\n", "\"id4_expand_intm_ab\"", ",", "\n", "]", "\n", "", "self", ".", "triplets_only", "=", "triplets_only", "\n", "self", ".", "cutoff", "=", "cutoff", "\n", "self", ".", "int_cutoff", "=", "int_cutoff", "\n", "self", ".", "addID", "=", "addID", "\n", "self", ".", "keys", "=", "[", "\"N\"", ",", "\"Z\"", ",", "\"R\"", ",", "\"F\"", ",", "\"E\"", "]", "\n", "if", "addID", ":", "\n", "            ", "self", ".", "keys", "+=", "[", "\"id\"", "]", "\n", "\n", "", "self", ".", "_load_npz", "(", "path", ",", "self", ".", "keys", ")", "# set keys as attributes", "\n", "\n", "if", "transforms", "is", "None", ":", "\n", "            ", "self", ".", "transforms", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "assert", "isinstance", "(", "transforms", ",", "(", "list", ",", "tuple", ")", ")", "\n", "self", ".", "transforms", "=", "transforms", "\n", "\n", "# modify dataset", "\n", "", "for", "transform", "in", "self", ".", "transforms", ":", "\n", "            ", "transform", "(", "self", ")", "\n", "\n", "", "assert", "self", ".", "R", "is", "not", "None", "\n", "assert", "self", ".", "N", "is", "not", "None", "\n", "assert", "self", ".", "Z", "is", "not", "None", "\n", "assert", "self", ".", "E", "is", "not", "None", "\n", "assert", "self", ".", "F", "is", "not", "None", "\n", "\n", "assert", "len", "(", "self", ".", "E", ")", ">", "0", "\n", "assert", "len", "(", "self", ".", "F", ")", ">", "0", "\n", "\n", "self", ".", "E", "=", "self", ".", "E", "[", ":", ",", "None", "]", "# shape=(nMolecules,1)", "\n", "self", ".", "N_cumsum", "=", "np", ".", "concatenate", "(", "[", "[", "0", "]", ",", "np", ".", "cumsum", "(", "self", ".", "N", ")", "]", ")", "\n", "\n", "self", ".", "dtypes", ",", "dtypes2", "=", "self", ".", "get_dtypes", "(", ")", "\n", "self", ".", "dtypes", ".", "update", "(", "dtypes2", ")", "# merge all dtypes in single dict", "\n", "self", ".", "targets", "=", "[", "\"E\"", ",", "\"F\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer._load_npz": [[93, 114], ["numpy.load", "data.keys", "setattr", "UserWarning"], "methods", ["None"], ["", "def", "_load_npz", "(", "self", ",", "path", ",", "keys", ")", ":", "\n", "        ", "\"\"\"Load the keys from the file and set as attributes.\n\n        Parameters\n        ----------\n        path: str\n            Absolute path of the dataset (in npz-format).\n        keys: list\n            Contains keys in the dataset to load and set as attributes.\n\n        Returns\n        -------\n        None\n        \"\"\"", "\n", "with", "np", ".", "load", "(", "path", ",", "allow_pickle", "=", "True", ")", "as", "data", ":", "\n", "            ", "for", "key", "in", "keys", ":", "\n", "                ", "if", "key", "not", "in", "data", ".", "keys", "(", ")", ":", "\n", "                    ", "if", "key", "!=", "\"F\"", ":", "\n", "                        ", "raise", "UserWarning", "(", "f\"Can not find key {key} in the dataset.\"", ")", "\n", "", "", "else", ":", "\n", "                    ", "setattr", "(", "self", ",", "key", ",", "data", "[", "key", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer._bmat_fast": [[115, 152], ["numpy.concatenate", "numpy.zeros", "numpy.cumsum", "numpy.concatenate", "numpy.zeros", "numpy.cumsum", "numpy.concatenate", "scipy.csr_matrix", "len", "len", "scipy.csr_matrix", "len", "len", "range", "range", "len", "len"], "methods", ["None"], ["", "", "", "", "@", "staticmethod", "\n", "def", "_bmat_fast", "(", "mats", ")", ":", "\n", "        ", "\"\"\"Combines multiple adjacency matrices into single sparse block matrix.\n\n        Parameters\n        ----------\n            mats: list\n                Has adjacency matrices as elements.\n\n        Returns\n        -------\n            adj_matrix: sp.csr_matrix\n                Combined adjacency matrix (sparse block matrix)\n        \"\"\"", "\n", "assert", "len", "(", "mats", ")", ">", "0", "\n", "new_data", "=", "np", ".", "concatenate", "(", "[", "mat", ".", "data", "for", "mat", "in", "mats", "]", ")", "\n", "\n", "ind_offset", "=", "np", ".", "zeros", "(", "1", "+", "len", "(", "mats", ")", ",", "dtype", "=", "\"int32\"", ")", "\n", "ind_offset", "[", "1", ":", "]", "=", "np", ".", "cumsum", "(", "[", "mat", ".", "shape", "[", "0", "]", "for", "mat", "in", "mats", "]", ")", "\n", "new_indices", "=", "np", ".", "concatenate", "(", "\n", "[", "mats", "[", "i", "]", ".", "indices", "+", "ind_offset", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "mats", ")", ")", "]", "\n", ")", "\n", "\n", "indptr_offset", "=", "np", ".", "zeros", "(", "1", "+", "len", "(", "mats", ")", ")", "\n", "indptr_offset", "[", "1", ":", "]", "=", "np", ".", "cumsum", "(", "[", "mat", ".", "nnz", "for", "mat", "in", "mats", "]", ")", "\n", "new_indptr", "=", "np", ".", "concatenate", "(", "\n", "[", "mats", "[", "i", "]", ".", "indptr", "[", "i", ">=", "1", ":", "]", "+", "indptr_offset", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "mats", ")", ")", "]", "\n", ")", "\n", "\n", "# Resulting matrix shape: sum of matrices", "\n", "shape", "=", "(", "ind_offset", "[", "-", "1", "]", ",", "ind_offset", "[", "-", "1", "]", ")", "\n", "\n", "# catch case with no edges", "\n", "if", "len", "(", "new_data", ")", "==", "0", ":", "\n", "            ", "return", "sp", ".", "csr_matrix", "(", "shape", ")", "\n", "\n", "", "return", "sp", ".", "csr_matrix", "(", "(", "new_data", ",", "new_indices", ",", "new_indptr", ")", ",", "shape", "=", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer.__len__": [[153, 155], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "N", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer.__getitem__": [[156, 409], ["isinstance", "isinstance", "isinstance", "numpy.repeat", "numpy.zeros", "numpy.zeros", "numpy.zeros", "enumerate", "data_container.DataContainer._bmat_fast", "data_container.DataContainer.nonzero", "numpy.stack", "numpy.concatenate().astype", "numpy.arange", "numpy.concatenate().astype", "int", "numpy.arange", "numpy.concatenate", "scipy.csr_matrix", "data_container.DataContainer.get_triplets", "data_container.DataContainer.get_quadruplets", "data.update", "data_container.DataContainer.convert_to_tensor", "list", "numpy.arange", "numpy.arange", "numpy.sum", "numpy.linalg.norm", "scipy.csr_matrix", "scipy.eye", "adj_matrices.append", "data_container.DataContainer._bmat_fast", "data_container.DataContainer.nonzero", "len", "idx_data.keys", "data_container.DataContainer.convert_to_tensor", "len", "numpy.argsort", "numpy.unique", "data_container.DataContainer.ragged_range", "numpy.array", "data.update", "data_container.DataContainer.convert_to_tensor", "len", "numpy.argsort", "numpy.unique", "data_container.DataContainer.ragged_range", "numpy.array", "min", "len", "numpy.sum", "numpy.sum", "scipy.csr_matrix", "scipy.eye", "adj_matrices_int.append", "numpy.array", "numpy.concatenate", "len", "numpy.concatenate", "len", "numpy.arange", "len", "len"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer._bmat_fast", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer.get_triplets", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer.get_quadruplets", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.update", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer.convert_to_tensor", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer._bmat_fast", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer.convert_to_tensor", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer.ragged_range", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.update", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer.convert_to_tensor", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer.ragged_range"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n            idx: array-like\n                Ids of the molecules to get.\n\n        Returns\n        -------\n            data: dict\n                nMolecules = len(idx)\n                nAtoms = total sum of atoms in the selected molecules\n                Contains following keys and values:\n\n                - id: np.ndarray, shape (nMolecules,)\n                    Ids of the molecules in the dataset.\n                - N: np.ndarray, shape (nMolecules,)\n                    Number of atoms in the molecules.\n                - Z: np.ndarray, shape (nAtoms,)\n                    Atomic numbers (dt. Ordnungszahl).\n                - R: np.ndarray, shape (nAtoms,3)\n                    Atom positions in \u00b0A.\n                - F: np.ndarray, shape (nAtoms,3)\n                    Forces at the atoms in eV/\u00b0A.\n                - E: np.ndarray, shape (nMolecules,1)\n                    Energy of the molecule in eV.\n                - batch_seg: np.ndarray, shape (nAtoms,)\n                    Contains the index of the sample the atom belongs to.\n                    E.g. [0,0,0, 1,1,1,1, 2,...] where first molecule has 3 atoms,\n                    second molecule has 4 atoms etc.\n                - id_c: np.ndarray, shape (nEdges,)\n                    Indices of edges' source atom.\n                - id_a: np.ndarray, shape (nEdges,)\n                    Indices of edges' target atom.\n                - id_undir: np.ndarray, shape (nEdges,)\n                    Indices where the same index denotes opposite edges, c-> and a->c.\n                - id_swap: np.ndarray, shape (nEdges,)\n                    Indices to map c->a to a->c.\n                - id3_expand_ba: np.ndarray, shape (nTriplets,)\n                    Indices to map the edges from c->a to b->a in the triplet-based massage passing.\n                - id3_reduce_ca: np.ndarray, shape (nTriplets,)\n                    Indices to map the edges from c->a to c->a in the triplet-based massage passing.\n                - Kidx3: np.ndarray, shape (nTriplets,)\n                    Indices to reshape the neighbor indices b->a into a dense matrix.\n                - id4_int_a: np.ndarray, shape (nInterEdges,)\n                    Indices of the atom a of the interaction edge.\n                - id4_int_b: np.ndarray, shape (nInterEdges,)\n                    Indices of the atom b of the interaction edge.\n                - id4_reduce_ca: np.ndarray, shape (nQuadruplets,)\n                    Indices to map c->a to c->a in quadruplet-message passing.\n                - id4_expand_db: np.ndarray, shape (nQuadruplets,)\n                    Indices to map c->a to d->b in quadruplet-message passing.\n                - id4_reduce_intm_ca: np.ndarray, shape (intmTriplets,)\n                    Indices to map c->a to intermediate c->a.\n                - id4_expand_intm_db: np.ndarray, shape (intmTriplets,)\n                    Indices to map d->b to intermediate d->b.\n                - id4_reduce_intm_ab: np.ndarray, shape (intmTriplets,)\n                    Indices to map b-a to intermediate b-a of the quadruplet's part c->a-b.\n                - id4_expand_intm_ab: np.ndarray, shape (intmTriplets,)\n                    Indices to map b-a to intermediate b-a of the quadruplet's part a-b<-d.\n                - id4_reduce_cab: np.ndarray, shape (nQuadruplets,)\n                    Indices to map from intermediate c->a to quadruplet c->a.\n                - id4_expand_abd: np.ndarray, shape (nQuadruplets,)\n                    Indices to map from intermediate d->b to quadruplet d->b.\n                - Kidx4: np.ndarray, shape (nTriplets,)\n                    Indices to reshape the neighbor indices d->b into a dense matrix.\n        \"\"\"", "\n", "if", "isinstance", "(", "idx", ",", "(", "int", ",", "np", ".", "int64", ",", "np", ".", "int32", ")", ")", ":", "\n", "            ", "idx", "=", "[", "idx", "]", "\n", "", "if", "isinstance", "(", "idx", ",", "tuple", ")", ":", "\n", "            ", "idx", "=", "list", "(", "idx", ")", "\n", "", "if", "isinstance", "(", "idx", ",", "slice", ")", ":", "\n", "            ", "idx", "=", "np", ".", "arange", "(", "idx", ".", "start", ",", "min", "(", "idx", ".", "stop", ",", "len", "(", "self", ")", ")", ",", "idx", ".", "step", ")", "\n", "\n", "", "data", "=", "{", "}", "\n", "if", "self", ".", "addID", ":", "\n", "            ", "data", "[", "\"id\"", "]", "=", "self", ".", "id", "[", "idx", "]", "\n", "", "data", "[", "\"E\"", "]", "=", "self", ".", "E", "[", "idx", "]", "\n", "data", "[", "\"N\"", "]", "=", "self", ".", "N", "[", "idx", "]", "\n", "data", "[", "\"batch_seg\"", "]", "=", "np", ".", "repeat", "(", "np", ".", "arange", "(", "len", "(", "idx", ")", ",", "dtype", "=", "np", ".", "int32", ")", ",", "data", "[", "\"N\"", "]", ")", "\n", "\n", "data", "[", "\"Z\"", "]", "=", "np", ".", "zeros", "(", "np", ".", "sum", "(", "data", "[", "\"N\"", "]", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "data", "[", "\"R\"", "]", "=", "np", ".", "zeros", "(", "[", "np", ".", "sum", "(", "data", "[", "\"N\"", "]", ")", ",", "3", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "data", "[", "\"F\"", "]", "=", "np", ".", "zeros", "(", "[", "np", ".", "sum", "(", "data", "[", "\"N\"", "]", ")", ",", "3", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n", "nend", "=", "0", "\n", "adj_matrices", "=", "[", "]", "\n", "adj_matrices_int", "=", "[", "]", "\n", "for", "k", ",", "i", "in", "enumerate", "(", "idx", ")", ":", "\n", "            ", "n", "=", "data", "[", "\"N\"", "]", "[", "k", "]", "\n", "nstart", "=", "nend", "\n", "nend", "=", "nstart", "+", "n", "\n", "s", ",", "e", "=", "(", "\n", "self", ".", "N_cumsum", "[", "i", "]", ",", "\n", "self", ".", "N_cumsum", "[", "i", "+", "1", "]", ",", "\n", ")", "# start and end idx of atoms belonging to molecule", "\n", "\n", "data", "[", "\"F\"", "]", "[", "nstart", ":", "nend", "]", "=", "self", ".", "F", "[", "s", ":", "e", "]", "\n", "data", "[", "\"Z\"", "]", "[", "nstart", ":", "nend", "]", "=", "self", ".", "Z", "[", "s", ":", "e", "]", "\n", "R", "=", "self", ".", "R", "[", "s", ":", "e", "]", "\n", "data", "[", "\"R\"", "]", "[", "nstart", ":", "nend", "]", "=", "R", "\n", "\n", "D_ij", "=", "np", ".", "linalg", ".", "norm", "(", "R", "[", ":", ",", "None", ",", ":", "]", "-", "R", "[", "None", ",", ":", ",", ":", "]", ",", "axis", "=", "-", "1", ")", "\n", "# get adjacency matrix for embeddings", "\n", "adj_mat", "=", "sp", ".", "csr_matrix", "(", "D_ij", "<=", "self", ".", "cutoff", ")", "\n", "adj_mat", "-=", "sp", ".", "eye", "(", "n", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "adj_matrices", ".", "append", "(", "adj_mat", ")", "\n", "\n", "if", "not", "self", ".", "triplets_only", ":", "\n", "# get adjacency matrix for interaction", "\n", "                ", "adj_mat", "=", "sp", ".", "csr_matrix", "(", "D_ij", "<=", "self", ".", "int_cutoff", ")", "\n", "adj_mat", "-=", "sp", ".", "eye", "(", "n", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "adj_matrices_int", ".", "append", "(", "adj_mat", ")", "\n", "\n", "#### Indices of the moleule structure", "\n", "", "", "idx_data", "=", "{", "key", ":", "None", "for", "key", "in", "self", ".", "index_keys", "if", "key", "!=", "\"batch_seg\"", "}", "\n", "# Entry A_ij is edge j -> i (!)", "\n", "adj_matrix", "=", "self", ".", "_bmat_fast", "(", "adj_matrices", ")", "\n", "idx_t", ",", "idx_s", "=", "adj_matrix", ".", "nonzero", "(", ")", "# target and source nodes", "\n", "\n", "if", "not", "self", ".", "triplets_only", ":", "\n", "# Entry A_ij is edge j -> i (!)", "\n", "            ", "adj_matrix_int", "=", "self", ".", "_bmat_fast", "(", "adj_matrices_int", ")", "\n", "idx_int_t", ",", "idx_int_s", "=", "adj_matrix_int", ".", "nonzero", "(", ")", "# target and source nodes", "\n", "\n", "# catch no edge case", "\n", "", "if", "len", "(", "idx_t", ")", "==", "0", ":", "\n", "            ", "for", "key", "in", "idx_data", ".", "keys", "(", ")", ":", "\n", "                ", "data", "[", "key", "]", "=", "np", ".", "array", "(", "[", "]", ",", "dtype", "=", "\"int32\"", ")", "\n", "", "return", "self", ".", "convert_to_tensor", "(", "data", ")", "\n", "\n", "# Get mask for undirected edges               0     1      nEdges/2  nEdges/2+1", "\n", "# change order of indices such that edge = [[0,1],[0,2], ..., [1,0], [2,0], ...]", "\n", "", "edges", "=", "np", ".", "stack", "(", "[", "idx_t", ",", "idx_s", "]", ",", "axis", "=", "0", ")", "\n", "mask", "=", "edges", "[", "0", "]", "<", "edges", "[", "1", "]", "\n", "edges", "=", "edges", "[", ":", ",", "mask", "]", "\n", "edges", "=", "np", ".", "concatenate", "(", "[", "edges", ",", "edges", "[", ":", ":", "-", "1", "]", "]", ",", "axis", "=", "-", "1", ")", ".", "astype", "(", "\"int32\"", ")", "\n", "idx_t", ",", "idx_s", "=", "edges", "[", "0", "]", ",", "edges", "[", "1", "]", "\n", "indices", "=", "np", ".", "arange", "(", "len", "(", "mask", ")", "/", "2", ",", "dtype", "=", "\"int32\"", ")", "\n", "idx_data", "[", "\"id_undir\"", "]", "=", "np", ".", "concatenate", "(", "2", "*", "[", "indices", "]", ",", "axis", "=", "-", "1", ")", ".", "astype", "(", "\"int32\"", ")", "\n", "\n", "idx_data", "[", "\"id_c\"", "]", "=", "idx_s", "# node c is source", "\n", "idx_data", "[", "\"id_a\"", "]", "=", "idx_t", "# node a is target", "\n", "\n", "if", "not", "self", ".", "triplets_only", ":", "\n", "            ", "idx_data", "[", "\"id4_int_a\"", "]", "=", "idx_int_t", "\n", "idx_data", "[", "\"id4_int_b\"", "]", "=", "idx_int_s", "\n", "#                                    0         1       ... nEdges/2  nEdges/2+1", "\n", "## swap indices a->c to c->a:   [nEdges/2  nEdges/2+1  ...     0        1 ...   ]", "\n", "", "N_undir_edges", "=", "int", "(", "len", "(", "idx_s", ")", "/", "2", ")", "\n", "ind", "=", "np", ".", "arange", "(", "N_undir_edges", ",", "dtype", "=", "\"int32\"", ")", "\n", "id_swap", "=", "np", ".", "concatenate", "(", "[", "ind", "+", "N_undir_edges", ",", "ind", "]", ")", "\n", "idx_data", "[", "\"id_swap\"", "]", "=", "id_swap", "\n", "\n", "# assign an edge_id to each edge", "\n", "edge_ids", "=", "sp", ".", "csr_matrix", "(", "\n", "(", "np", ".", "arange", "(", "len", "(", "idx_s", ")", ")", ",", "(", "idx_t", ",", "idx_s", ")", ")", ",", "\n", "shape", "=", "adj_matrix", ".", "shape", ",", "\n", "dtype", "=", "\"int32\"", ",", "\n", ")", "\n", "\n", "#### ------------------------------------ Triplets ------------------------------------ ####", "\n", "id3_expand_ba", ",", "id3_reduce_ca", "=", "self", ".", "get_triplets", "(", "idx_s", ",", "idx_t", ",", "edge_ids", ")", "\n", "# embed msg from c -> a with all quadruplets for k and l: c -> a <- k <- l", "\n", "# id3_reduce_ca is for k -> a -> c but we want c -> a <- k", "\n", "id3_reduce_ca", "=", "id_swap", "[", "id3_reduce_ca", "]", "\n", "\n", "# --------------------- Needed for efficient implementation --------------------- #", "\n", "if", "len", "(", "id3_reduce_ca", ")", ">", "0", ":", "\n", "# id_reduce_ca must be sorted (i.e. grouped would suffice) for ragged_range !", "\n", "            ", "idx_sorted", "=", "np", ".", "argsort", "(", "id3_reduce_ca", ")", "\n", "id3_reduce_ca", "=", "id3_reduce_ca", "[", "idx_sorted", "]", "\n", "id3_expand_ba", "=", "id3_expand_ba", "[", "idx_sorted", "]", "\n", "_", ",", "K", "=", "np", ".", "unique", "(", "id3_reduce_ca", ",", "return_counts", "=", "True", ")", "\n", "idx_data", "[", "\"Kidx3\"", "]", "=", "DataContainer", ".", "ragged_range", "(", "\n", "K", "\n", ")", "# K = [1 4 2 3] -> Kidx3 = [0  0 1 2 3  0 1  0 1 2] , (nTriplets,)", "\n", "", "else", ":", "\n", "            ", "idx_data", "[", "\"Kidx3\"", "]", "=", "np", ".", "array", "(", "[", "]", ",", "dtype", "=", "\"int32\"", ")", "\n", "# ------------------------------------------------------------------------------- #", "\n", "\n", "", "idx_data", "[", "\"id3_expand_ba\"", "]", "=", "id3_expand_ba", "# (nTriplets,)", "\n", "idx_data", "[", "\"id3_reduce_ca\"", "]", "=", "id3_reduce_ca", "# (nTriplets,)", "\n", "\n", "# node indices in triplet", "\n", "# id3_c = idx_s[id3_reduce_ca]", "\n", "# id3_a = idx_t[id3_reduce_ca]", "\n", "# assert np.all(id3_j == idx_t[id3_expand_ba])", "\n", "# id3_b = idx_s[id3_expand_ba]", "\n", "#### ---------------------------------------------------------------------------------- ####", "\n", "\n", "if", "self", ".", "triplets_only", ":", "\n", "            ", "data", ".", "update", "(", "idx_data", ")", "\n", "return", "self", ".", "convert_to_tensor", "(", "data", ")", "\n", "\n", "#### ----------------------------------- Quadruplets ---------------------------------- ####", "\n", "\n", "# get quadruplets", "\n", "", "output", "=", "self", ".", "get_quadruplets", "(", "\n", "idx_s", ",", "idx_t", ",", "adj_matrix", ",", "edge_ids", ",", "idx_int_s", ",", "idx_int_t", "\n", ")", "\n", "(", "\n", "id4_reduce_ca", ",", "\n", "id4_expand_db", ",", "\n", "id4_reduce_cab", ",", "\n", "id4_expand_abd", ",", "\n", "id4_reduce_intm_ca", ",", "\n", "id4_expand_intm_db", ",", "\n", "id4_reduce_intm_ab", ",", "\n", "id4_expand_intm_ab", ",", "\n", ")", "=", "output", "\n", "\n", "# --------------------- Needed for efficient implementation --------------------- #", "\n", "if", "len", "(", "id4_reduce_ca", ")", ">", "0", ":", "\n", "# id4_reduce_ca has to be sorted (i.e. grouped would suffice) for ragged range !", "\n", "            ", "sorted_idx", "=", "np", ".", "argsort", "(", "id4_reduce_ca", ")", "\n", "id4_reduce_ca", "=", "id4_reduce_ca", "[", "sorted_idx", "]", "\n", "id4_expand_db", "=", "id4_expand_db", "[", "sorted_idx", "]", "\n", "id4_reduce_cab", "=", "id4_reduce_cab", "[", "sorted_idx", "]", "\n", "id4_expand_abd", "=", "id4_expand_abd", "[", "sorted_idx", "]", "\n", "\n", "_", ",", "K", "=", "np", ".", "unique", "(", "id4_reduce_ca", ",", "return_counts", "=", "True", ")", "\n", "# K = [1 4 2 3] -> Kidx4 = [0  0 1 2 3  0 1  0 1 2]", "\n", "idx_data", "[", "\"Kidx4\"", "]", "=", "DataContainer", ".", "ragged_range", "(", "K", ")", "# (nQuadruplets,)", "\n", "", "else", ":", "\n", "            ", "idx_data", "[", "\"Kidx4\"", "]", "=", "np", ".", "array", "(", "[", "]", ",", "dtype", "=", "\"int32\"", ")", "\n", "# ------------------------------------------------------------------------------- #", "\n", "\n", "", "idx_data", "[", "\"id4_reduce_ca\"", "]", "=", "id4_reduce_ca", "# (nQuadruplets,)", "\n", "idx_data", "[", "\"id4_expand_db\"", "]", "=", "id4_expand_db", "# (nQuadruplets,)", "\n", "idx_data", "[", "\"id4_reduce_cab\"", "]", "=", "id4_reduce_cab", "# (nQuadruplets,)", "\n", "idx_data", "[", "\"id4_expand_abd\"", "]", "=", "id4_expand_abd", "# (nQuadruplets,)", "\n", "idx_data", "[", "\"id4_reduce_intm_ca\"", "]", "=", "id4_reduce_intm_ca", "# (intmTriplets,)", "\n", "idx_data", "[", "\"id4_expand_intm_db\"", "]", "=", "id4_expand_intm_db", "# (intmTriplets,)", "\n", "idx_data", "[", "\"id4_reduce_intm_ab\"", "]", "=", "id4_reduce_intm_ab", "# (intmTriplets,)", "\n", "idx_data", "[", "\"id4_expand_intm_ab\"", "]", "=", "id4_expand_intm_ab", "# (intmTriplets,)", "\n", "\n", "# # node indices in quadruplet", "\n", "# idx_c = idx_s[id4_reduce_ca]", "\n", "# idx_a = idx_t[id4_reduce_ca]", "\n", "# idx_b = idx_t[id4_expand_db]", "\n", "# idx_d = idx_s[id4_expand_db]", "\n", "# assert np.all(idx_c == idx_s[id4_reduce_intm_ca][id4_reduce_cab])", "\n", "# assert np.all(idx_a == idx_t[id4_reduce_intm_ca][id4_reduce_cab])", "\n", "# assert np.all(idx_a == idx_int_t[id4_reduce_intm_ab][id4_reduce_cab])", "\n", "# assert np.all(idx_a == idx_int_t[id4_expand_intm_ab][id4_expand_abd])", "\n", "# assert np.all(idx_b == idx_int_s[id4_reduce_intm_ab][id4_reduce_cab])", "\n", "# assert np.all(idx_b == idx_int_s[id4_expand_intm_ab][id4_expand_abd])", "\n", "# assert np.all(idx_b == idx_t[id4_expand_intm_db][id4_expand_abd])", "\n", "# assert np.all(idx_d == idx_s[id4_expand_intm_db][id4_expand_abd])", "\n", "\n", "data", ".", "update", "(", "idx_data", ")", "\n", "return", "self", ".", "convert_to_tensor", "(", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer.get_triplets": [[410, 426], ["edge_ids[].data.astype().flatten", "edge_ids[].tocoo().row.astype().flatten", "edge_ids[].data.astype", "edge_ids[].tocoo().row.astype", "edge_ids[].tocoo"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_triplets", "(", "idx_s", ",", "idx_t", ",", "edge_ids", ")", ":", "\n", "        ", "\"\"\"\n        Get triplets c -> a <- b\n        \"\"\"", "\n", "# Edge indices of triplets k -> a -> i", "\n", "id3_expand_ba", "=", "edge_ids", "[", "idx_s", "]", ".", "data", ".", "astype", "(", "\"int32\"", ")", ".", "flatten", "(", ")", "\n", "id3_reduce_ca", "=", "edge_ids", "[", "idx_s", "]", ".", "tocoo", "(", ")", ".", "row", ".", "astype", "(", "\"int32\"", ")", ".", "flatten", "(", ")", "\n", "\n", "id3_i", "=", "idx_t", "[", "id3_reduce_ca", "]", "\n", "id3_k", "=", "idx_s", "[", "id3_expand_ba", "]", "\n", "mask", "=", "id3_i", "!=", "id3_k", "\n", "id3_expand_ba", "=", "id3_expand_ba", "[", "mask", "]", "\n", "id3_reduce_ca", "=", "id3_reduce_ca", "[", "mask", "]", "\n", "\n", "return", "id3_expand_ba", ",", "id3_reduce_ca", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer.get_quadruplets": [[427, 489], ["adj_matrix[].sum().A1.astype", "adj_matrix[].sum().A1.astype", "edge_ids[].data.astype().flatten", "edge_ids[].data.astype().flatten", "data_container.DataContainer.repeat_blocks", "numpy.repeat", "numpy.repeat", "numpy.repeat", "numpy.repeat", "numpy.arange", "numpy.arange", "numpy.arange", "edge_ids[].data.astype", "edge_ids[].data.astype", "len", "len", "len", "adj_matrix[].sum", "adj_matrix[].sum"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer.repeat_blocks"], ["", "@", "staticmethod", "\n", "def", "get_quadruplets", "(", "idx_s", ",", "idx_t", ",", "adj_matrix", ",", "edge_ids", ",", "idx_int_s", ",", "idx_int_t", ")", ":", "\n", "        ", "\"\"\"\n        c -> a - b <- d where D_ab <= int_cutoff; D_ca & D_db <= cutoff\n        \"\"\"", "\n", "# Number of incoming edges to target and source node of interaction edges", "\n", "nNeighbors_t", "=", "adj_matrix", "[", "idx_int_t", "]", ".", "sum", "(", "axis", "=", "1", ")", ".", "A1", ".", "astype", "(", "\"int32\"", ")", "\n", "nNeighbors_s", "=", "adj_matrix", "[", "idx_int_s", "]", ".", "sum", "(", "axis", "=", "1", ")", ".", "A1", ".", "astype", "(", "\"int32\"", ")", "\n", "id4_reduce_intm_ca", "=", "(", "\n", "edge_ids", "[", "idx_int_t", "]", ".", "data", ".", "astype", "(", "\"int32\"", ")", ".", "flatten", "(", ")", "\n", ")", "# (intmTriplets,)", "\n", "id4_expand_intm_db", "=", "(", "\n", "edge_ids", "[", "idx_int_s", "]", ".", "data", ".", "astype", "(", "\"int32\"", ")", ".", "flatten", "(", ")", "\n", ")", "# (intmTriplets,)", "\n", "# note that id4_reduce_intm_ca and id4_expand_intm_db have the same shape but", "\n", "# id4_reduce_intm_ca[i] and id4_expand_intm_db[i] may not belong to the same interacting quadruplet !", "\n", "\n", "# each reduce edge (c->a) has to be repeated as often as there are neighbors for node b", "\n", "# vice verca for the edges of the source node (d->b) and node a", "\n", "id4_reduce_cab", "=", "DataContainer", ".", "repeat_blocks", "(", "\n", "nNeighbors_t", ",", "nNeighbors_s", "\n", ")", "# (nQuadruplets,)", "\n", "id4_reduce_ca", "=", "id4_reduce_intm_ca", "[", "id4_reduce_cab", "]", "# intmTriplets -> nQuadruplets", "\n", "\n", "N", "=", "np", ".", "repeat", "(", "nNeighbors_t", ",", "nNeighbors_s", ")", "\n", "id4_expand_abd", "=", "np", ".", "repeat", "(", "\n", "np", ".", "arange", "(", "len", "(", "id4_expand_intm_db", ")", ")", ",", "N", "\n", ")", "# (nQuadruplets,)", "\n", "id4_expand_db", "=", "id4_expand_intm_db", "[", "id4_expand_abd", "]", "# intmTriplets -> nQuadruplets", "\n", "\n", "id4_reduce_intm_ab", "=", "np", ".", "repeat", "(", "\n", "np", ".", "arange", "(", "len", "(", "idx_int_t", ")", ")", ",", "nNeighbors_t", "\n", ")", "# (intmTriplets,)", "\n", "id4_expand_intm_ab", "=", "np", ".", "repeat", "(", "\n", "np", ".", "arange", "(", "len", "(", "idx_int_t", ")", ")", ",", "nNeighbors_s", "\n", ")", "# (intmTriplets,)", "\n", "\n", "# Mask out all quadruplets where nodes appear more than once", "\n", "idx_c", "=", "idx_s", "[", "id4_reduce_ca", "]", "\n", "idx_a", "=", "idx_t", "[", "id4_reduce_ca", "]", "\n", "idx_b", "=", "idx_t", "[", "id4_expand_db", "]", "\n", "idx_d", "=", "idx_s", "[", "id4_expand_db", "]", "\n", "\n", "mask1", "=", "idx_c", "!=", "idx_b", "\n", "mask2", "=", "idx_a", "!=", "idx_d", "\n", "mask3", "=", "idx_c", "!=", "idx_d", "\n", "mask", "=", "mask1", "*", "mask2", "*", "mask3", "# logical and", "\n", "\n", "id4_reduce_ca", "=", "id4_reduce_ca", "[", "mask", "]", "\n", "id4_expand_db", "=", "id4_expand_db", "[", "mask", "]", "\n", "id4_reduce_cab", "=", "id4_reduce_cab", "[", "mask", "]", "\n", "id4_expand_abd", "=", "id4_expand_abd", "[", "mask", "]", "\n", "\n", "return", "(", "\n", "id4_reduce_ca", ",", "\n", "id4_expand_db", ",", "\n", "id4_reduce_cab", ",", "\n", "id4_expand_abd", ",", "\n", "id4_reduce_intm_ca", ",", "\n", "id4_expand_intm_db", ",", "\n", "id4_reduce_intm_ab", ",", "\n", "id4_expand_intm_ab", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer.convert_to_tensor": [[491, 495], ["torch.tensor"], "methods", ["None"], ["", "def", "convert_to_tensor", "(", "self", ",", "data", ")", ":", "\n", "        ", "for", "key", "in", "data", ":", "\n", "            ", "data", "[", "key", "]", "=", "torch", ".", "tensor", "(", "data", "[", "key", "]", ",", "dtype", "=", "self", ".", "dtypes", "[", "key", "]", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer.get_dtypes": [[496, 519], ["None"], "methods", ["None"], ["", "def", "get_dtypes", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns\n        -------\n            dtypes: tuple\n                (dtypes_input, dtypes_target) TF input types for the inputs and targets\n                stored in dicts.\n        \"\"\"", "\n", "# dtypes of dataset values", "\n", "dtypes_input", "=", "{", "}", "\n", "if", "self", ".", "addID", ":", "\n", "            ", "dtypes_input", "[", "\"id\"", "]", "=", "torch", ".", "int64", "\n", "", "dtypes_input", "[", "\"Z\"", "]", "=", "torch", ".", "int64", "\n", "dtypes_input", "[", "\"N\"", "]", "=", "torch", ".", "int64", "\n", "dtypes_input", "[", "\"R\"", "]", "=", "torch", ".", "float32", "\n", "for", "key", "in", "self", ".", "index_keys", ":", "\n", "            ", "dtypes_input", "[", "key", "]", "=", "torch", ".", "int64", "\n", "\n", "", "dtypes_target", "=", "{", "}", "\n", "dtypes_target", "[", "\"E\"", "]", "=", "torch", ".", "float32", "\n", "dtypes_target", "[", "\"F\"", "]", "=", "torch", ".", "float32", "\n", "\n", "return", "dtypes_input", ",", "dtypes_target", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer.repeat_blocks": [[520, 547], ["numba.njit", "numpy.arange", "numpy.empty", "enumerate", "numpy.sum", "range"], "methods", ["None"], ["", "@", "staticmethod", "\n", "@", "numba", ".", "njit", "(", "nogil", "=", "True", ")", "\n", "def", "repeat_blocks", "(", "sizes", ",", "repeats", ")", ":", "\n", "        ", "\"\"\"Repeat blocks of indices.\n        From https://stackoverflow.com/questions/51154989/numpy-vectorized-function-to-repeat-blocks-of-consecutive-elements\n\n        Examples\n        --------\n            sizes = [1,3,2] ; repeats = [3,2,3]\n            Return: [0 0 0  1 2 3 1 2 3  4 5 4 5 4 5]\n            sizes = [0,3,2] ; repeats = [3,2,3]\n            Return: [0 1 2 0 1 2  3 4 3 4 3 4]\n            sizes = [2,3,2] ; repeats = [2,0,2]\n            Return: [0 1 0 1  5 6 5 6]\n        \"\"\"", "\n", "a", "=", "np", ".", "arange", "(", "np", ".", "sum", "(", "sizes", ")", ")", "\n", "indices", "=", "np", ".", "empty", "(", "(", "sizes", "*", "repeats", ")", ".", "sum", "(", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "start", "=", "0", "\n", "oi", "=", "0", "\n", "for", "i", ",", "size", "in", "enumerate", "(", "sizes", ")", ":", "\n", "            ", "end", "=", "start", "+", "size", "\n", "for", "_", "in", "range", "(", "repeats", "[", "i", "]", ")", ":", "\n", "                ", "oe", "=", "oi", "+", "size", "\n", "indices", "[", "oi", ":", "oe", "]", "=", "a", "[", "start", ":", "end", "]", "\n", "oi", "=", "oe", "\n", "", "start", "=", "end", "\n", "", "return", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_container.DataContainer.ragged_range": [[548, 566], ["numba.njit", "numpy.arange", "numpy.empty", "sizes.max", "sizes.sum"], "methods", ["None"], ["", "@", "staticmethod", "\n", "@", "numba", ".", "njit", "(", "nogil", "=", "True", ")", "\n", "def", "ragged_range", "(", "sizes", ")", ":", "\n", "        ", "\"\"\"\n        -------\n        Example\n        -------\n            sizes = [1,3,2] ;\n            Return: [0  0 1 2  0 1]\n        \"\"\"", "\n", "a", "=", "np", ".", "arange", "(", "sizes", ".", "max", "(", ")", ")", "\n", "indices", "=", "np", ".", "empty", "(", "sizes", ".", "sum", "(", ")", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "start", "=", "0", "\n", "for", "size", "in", "sizes", ":", "\n", "            ", "end", "=", "start", "+", "size", "\n", "indices", "[", "start", ":", "end", "]", "=", "a", "[", ":", "size", "]", "\n", "start", "=", "end", "\n", "", "return", "indices", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.__init__": [[20, 25], ["os.path.join"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "path", ",", "metrics", ",", "assert_exist", "=", "True", ")", ":", "\n", "        ", "self", ".", "path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "\"best_metrics.npz\"", ")", "\n", "self", ".", "metrics", "=", "metrics", "\n", "self", ".", "assert_exist", "=", "assert_exist", "\n", "self", ".", "state", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.inititalize": [[26, 30], ["numpy.savez"], "methods", ["None"], ["", "def", "inititalize", "(", "self", ")", ":", "\n", "        ", "self", ".", "state", "=", "{", "f\"{k}_{self.metrics.tag}\"", ":", "np", ".", "inf", "for", "k", "in", "self", ".", "metrics", ".", "keys", "}", "\n", "self", ".", "state", "[", "\"step\"", "]", "=", "0", "\n", "np", ".", "savez", "(", "self", ".", "path", ",", "**", "self", ".", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.restore": [[31, 43], ["os.path.isfile", "logging.warning", "metrics.BestMetrics.inititalize", "numpy.load", "UserWarning", "v.item", "numpy.load.items"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.inititalize", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.items"], ["", "def", "restore", "(", "self", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "isfile", "(", "self", ".", "path", ")", ":", "\n", "            ", "string", "=", "f\"Best metrics can not be restored as the file does not exist in the given path: {self.path}\"", "\n", "if", "self", ".", "assert_exist", ":", "\n", "                ", "raise", "UserWarning", "(", "string", ")", "\n", "\n", "", "string", "+=", "\"\\n Will initialize the best metrics.\"", "\n", "logging", ".", "warning", "(", "string", ")", "\n", "self", ".", "inititalize", "(", ")", "\n", "", "else", ":", "\n", "            ", "loss_file", "=", "np", ".", "load", "(", "self", ".", "path", ")", "\n", "self", ".", "state", "=", "{", "k", ":", "v", ".", "item", "(", ")", "for", "k", ",", "v", "in", "loss_file", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.items": [[44, 46], ["metrics.BestMetrics.state.items"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.items"], ["", "", "def", "items", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "state", ".", "items", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.update": [[47, 51], ["metrics.BestMetrics.state.update", "numpy.savez", "metrics.result"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.update", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.result"], ["", "def", "update", "(", "self", ",", "step", ",", "metrics", ")", ":", "\n", "        ", "self", ".", "state", "[", "\"step\"", "]", "=", "step", "\n", "self", ".", "state", ".", "update", "(", "metrics", ".", "result", "(", ")", ")", "\n", "np", ".", "savez", "(", "self", ".", "path", ",", "**", "self", ".", "state", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.write": [[52, 56], ["metrics.BestMetrics.state.items", "summary_writer.add_scalar"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.items"], ["", "def", "write", "(", "self", ",", "summary_writer", ",", "step", ")", ":", "\n", "        ", "for", "key", ",", "val", "in", "self", ".", "state", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "!=", "\"step\"", ":", "\n", "                ", "summary_writer", ".", "add_scalar", "(", "key", "+", "\"_best\"", ",", "val", ",", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.loss": [[57, 60], ["None"], "methods", ["None"], ["", "", "", "@", "property", "\n", "def", "loss", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "state", "[", "\"loss_val\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.step": [[61, 64], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "step", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "state", "[", "\"step\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.MeanMetric.__init__": [[67, 69], ["metrics.MeanMetric.reset_states"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.reset_states"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset_states", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.MeanMetric.update_state": [[70, 73], ["None"], "methods", ["None"], ["", "def", "update_state", "(", "self", ",", "values", ",", "sample_weight", ")", ":", "\n", "        ", "self", ".", "values", "+=", "sample_weight", "*", "values", "\n", "self", ".", "sample_weights", "+=", "sample_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.MeanMetric.result": [[74, 76], ["None"], "methods", ["None"], ["", "def", "result", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "values", "/", "self", ".", "sample_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.MeanMetric.reset_states": [[77, 80], ["None"], "methods", ["None"], ["", "def", "reset_states", "(", "self", ")", ":", "\n", "        ", "self", ".", "sample_weights", "=", "0", "\n", "self", ".", "values", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.__init__": [[95, 104], ["metrics.MeanMetric"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "tag", ",", "keys", ",", "ex", "=", "None", ")", ":", "\n", "        ", "self", ".", "tag", "=", "tag", "\n", "self", ".", "keys", "=", "keys", "\n", "self", ".", "ex", "=", "ex", "\n", "\n", "assert", "\"loss\"", "in", "self", ".", "keys", "\n", "self", ".", "mean_metrics", "=", "{", "}", "\n", "for", "key", "in", "self", ".", "keys", ":", "\n", "            ", "self", ".", "mean_metrics", "[", "key", "]", "=", "MeanMetric", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.update_state": [[105, 119], ["set().issubset", "set", "metrics.Metrics.mean_metrics[].update_state", "set", "updates[].cpu", "updates.keys"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.update_state"], ["", "", "def", "update_state", "(", "self", ",", "nsamples", ",", "**", "updates", ")", ":", "\n", "        ", "\"\"\"Update the metrics.\n\n        Parameters\n        ----------\n            nsamples: int\n                Number of samples for which the updates where calculated on.\n            updates: dict\n                Contains metric updates.\n        \"\"\"", "\n", "assert", "set", "(", "updates", ".", "keys", "(", ")", ")", ".", "issubset", "(", "set", "(", "self", ".", "keys", ")", ")", "\n", "for", "key", "in", "updates", ":", "\n", "            ", "self", ".", "mean_metrics", "[", "key", "]", ".", "update_state", "(", "\n", "updates", "[", "key", "]", ".", "cpu", "(", ")", ",", "sample_weight", "=", "nsamples", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.write": [[121, 134], ["metrics.Metrics.result().items", "summary_writer.add_scalar", "metrics.Metrics.ex.current_run.info[].append", "metrics.Metrics.result", "metrics.Metrics.ex.current_run.info[].append"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.items", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.result"], ["", "", "def", "write", "(", "self", ",", "summary_writer", ",", "step", ")", ":", "\n", "        ", "\"\"\"Write metrics to summary_writer (and the Sacred experiment).\"\"\"", "\n", "for", "key", ",", "val", "in", "self", ".", "result", "(", ")", ".", "items", "(", ")", ":", "\n", "            ", "summary_writer", ".", "add_scalar", "(", "key", ",", "val", ",", "global_step", "=", "step", ")", "\n", "if", "self", ".", "ex", "is", "not", "None", ":", "\n", "                ", "if", "key", "not", "in", "self", ".", "ex", ".", "current_run", ".", "info", ":", "\n", "                    ", "self", ".", "ex", ".", "current_run", ".", "info", "[", "key", "]", "=", "[", "]", "\n", "", "self", ".", "ex", ".", "current_run", ".", "info", "[", "key", "]", ".", "append", "(", "val", ")", "\n", "\n", "", "", "if", "self", ".", "ex", "is", "not", "None", ":", "\n", "            ", "if", "f\"step_{self.tag}\"", "not", "in", "self", ".", "ex", ".", "current_run", ".", "info", ":", "\n", "                ", "self", ".", "ex", ".", "current_run", ".", "info", "[", "f\"step_{self.tag}\"", "]", "=", "[", "]", "\n", "", "self", ".", "ex", ".", "current_run", ".", "info", "[", "f\"step_{self.tag}\"", "]", ".", "append", "(", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.reset_states": [[135, 138], ["metrics.Metrics.mean_metrics[].reset_states"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.reset_states"], ["", "", "def", "reset_states", "(", "self", ")", ":", "\n", "        ", "for", "key", "in", "self", ".", "keys", ":", "\n", "            ", "self", ".", "mean_metrics", "[", "key", "]", ".", "reset_states", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.result": [[139, 156], ["metrics.Metrics.mean_metrics[].result().numpy().item", "metrics.Metrics.mean_metrics[].result().numpy", "metrics.Metrics.mean_metrics[].result"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.result"], ["", "", "def", "result", "(", "self", ",", "append_tag", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Parameters\n        ----------\n            append_tag: bool\n                If True append the tag to the key of the returned dict\n\n        Returns\n        -------\n            result_dict: dict\n                Contains the numpy values of the metrics.\n        \"\"\"", "\n", "result_dict", "=", "{", "}", "\n", "for", "key", "in", "self", ".", "keys", ":", "\n", "            ", "result_key", "=", "f\"{key}_{self.tag}\"", "if", "append_tag", "else", "key", "\n", "result_dict", "[", "result_key", "]", "=", "self", ".", "mean_metrics", "[", "key", "]", ".", "result", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "", "return", "result_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.loss": [[157, 160], ["metrics.Metrics.mean_metrics[].result().numpy().item", "metrics.Metrics.mean_metrics[].result().numpy", "metrics.Metrics.mean_metrics[].result"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.result"], ["", "@", "property", "\n", "def", "loss", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "mean_metrics", "[", "\"loss\"", "]", ".", "result", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.schedules.LinearWarmupExponentialDecay.__init__": [[22, 47], ["torch.optim.lr_scheduler.LambdaLR.__init__", "min", "int"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "optimizer", ",", "\n", "warmup_steps", ",", "\n", "decay_steps", ",", "\n", "decay_rate", ",", "\n", "staircase", "=", "False", ",", "\n", "last_step", "=", "-", "1", ",", "\n", "verbose", "=", "False", ",", "\n", ")", ":", "\n", "        ", "assert", "decay_rate", "<=", "1", "\n", "\n", "if", "warmup_steps", "==", "0", ":", "\n", "            ", "warmup_steps", "=", "1", "\n", "\n", "", "def", "lr_lambda", "(", "step", ")", ":", "\n", "# step starts at 0", "\n", "            ", "warmup", "=", "min", "(", "1", "/", "warmup_steps", "+", "1", "/", "warmup_steps", "*", "step", ",", "1", ")", "\n", "exponent", "=", "step", "/", "decay_steps", "\n", "if", "staircase", ":", "\n", "                ", "exponent", "=", "int", "(", "exponent", ")", "\n", "", "decay", "=", "decay_rate", "**", "exponent", "\n", "return", "warmup", "*", "decay", "\n", "\n", "", "super", "(", ")", ".", "__init__", "(", "optimizer", ",", "lr_lambda", ",", "last_epoch", "=", "last_step", ",", "verbose", "=", "verbose", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.__init__": [[48, 101], ["float", "trainer.Trainer.reset_optimizer"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.reset_optimizer"], ["def", "__init__", "(", "\n", "self", ",", "\n", "model", ",", "\n", "learning_rate", ":", "float", "=", "1e-3", ",", "\n", "decay_steps", ":", "int", "=", "100000", ",", "\n", "decay_rate", ":", "float", "=", "0.96", ",", "\n", "warmup_steps", ":", "int", "=", "0", ",", "\n", "weight_decay", ":", "float", "=", "0.001", ",", "\n", "staircase", ":", "bool", "=", "False", ",", "\n", "grad_clip_max", ":", "float", "=", "1000", ",", "\n", "decay_patience", ":", "int", "=", "10", ",", "# decay lr on plateau by decay_factor", "\n", "decay_factor", ":", "float", "=", "0.5", ",", "\n", "decay_cooldown", ":", "int", "=", "10", ",", "\n", "ema_decay", ":", "float", "=", "0.999", ",", "\n", "rho_force", ":", "float", "=", "0.99", ",", "\n", "loss", ":", "str", "=", "\"mae\"", ",", "# else use rmse", "\n", "mve", ":", "bool", "=", "False", ",", "\n", "agc", "=", "False", ",", "\n", ")", ":", "\n", "        ", "assert", "0", "<=", "rho_force", "<=", "1", "\n", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "ema_decay", "=", "ema_decay", "\n", "self", ".", "grad_clip_max", "=", "grad_clip_max", "\n", "self", ".", "rho_force", "=", "float", "(", "rho_force", ")", "\n", "self", ".", "mve", "=", "mve", "\n", "self", ".", "loss", "=", "loss", "\n", "self", ".", "agc", "=", "agc", "\n", "\n", "if", "mve", ":", "\n", "            ", "self", ".", "tracked_metrics", "=", "[", "\n", "\"loss\"", ",", "\n", "\"energy_mae\"", ",", "\n", "\"energy_nll\"", ",", "\n", "\"energy_var\"", ",", "\n", "\"force_mae\"", ",", "\n", "\"force_rmse\"", ",", "\n", "\"force_nll\"", ",", "\n", "\"force_var\"", ",", "\n", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "tracked_metrics", "=", "[", "\"loss\"", ",", "\"energy_mae\"", ",", "\"force_mae\"", ",", "\"force_rmse\"", "]", "\n", "\n", "", "self", ".", "reset_optimizer", "(", "\n", "learning_rate", ",", "\n", "weight_decay", ",", "\n", "warmup_steps", ",", "\n", "decay_steps", ",", "\n", "decay_rate", ",", "\n", "staircase", ",", "\n", "decay_patience", ",", "\n", "decay_factor", ",", "\n", "decay_cooldown", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.reset_optimizer": [[103, 202], ["trainer.ReduceLROnPlateau", "ema_decay.ExponentialMovingAverage", "trainer.Trainer.model.named_parameters", "torch.optim.AdamW", "schedules.LinearWarmupExponentialDecay", "torch.optim.Adam", "schedules.LinearWarmupExponentialDecay", "trainer.MultiWrapper", "trainer.MultiWrapper", "torch.optim.Adam", "schedules.LinearWarmupExponentialDecay", "trainer.MultiWrapper", "trainer.MultiWrapper", "trainer.Trainer.model.named_parameters", "trainer.Trainer.model.parameters", "trainer.Trainer.model.parameters"], "methods", ["None"], ["", "def", "reset_optimizer", "(", "\n", "self", ",", "\n", "learning_rate", ",", "\n", "weight_decay", ",", "\n", "warmup_steps", ",", "\n", "decay_steps", ",", "\n", "decay_rate", ",", "\n", "staircase", ",", "\n", "decay_patience", ",", "\n", "decay_factor", ",", "\n", "decay_cooldown", ",", "\n", ")", ":", "\n", "        ", "if", "weight_decay", ">", "0", ":", "\n", "            ", "adamW_params", "=", "[", "]", "\n", "rest_params", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "param", ".", "requires_grad", ":", "\n", "                    ", "if", "\"atom_emb\"", "in", "name", ":", "\n", "                        ", "rest_params", "+=", "[", "param", "]", "\n", "continue", "\n", "", "if", "\"frequencies\"", "in", "name", ":", "\n", "                        ", "rest_params", "+=", "[", "param", "]", "\n", "continue", "\n", "", "if", "\"bias\"", "in", "name", ":", "\n", "                        ", "rest_params", "+=", "[", "param", "]", "\n", "continue", "\n", "", "adamW_params", "+=", "[", "param", "]", "\n", "\n", "# AdamW optimizer", "\n", "", "", "AdamW", "=", "torch", ".", "optim", ".", "AdamW", "(", "\n", "adamW_params", ",", "\n", "lr", "=", "learning_rate", ",", "\n", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "\n", "eps", "=", "1e-07", ",", "\n", "weight_decay", "=", "weight_decay", ",", "\n", "amsgrad", "=", "True", ",", "\n", ")", "\n", "lr_schedule_AdamW", "=", "LinearWarmupExponentialDecay", "(", "\n", "AdamW", ",", "warmup_steps", ",", "decay_steps", ",", "decay_rate", ",", "staircase", "\n", ")", "\n", "\n", "# Adam: Optimzer for embeddings, frequencies and biases", "\n", "Adam", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "rest_params", ",", "\n", "lr", "=", "learning_rate", ",", "\n", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "\n", "eps", "=", "1e-07", ",", "\n", "amsgrad", "=", "True", ",", "\n", ")", "\n", "lr_schedule_Adam", "=", "LinearWarmupExponentialDecay", "(", "\n", "Adam", ",", "warmup_steps", ",", "decay_steps", ",", "decay_rate", ",", "staircase", "\n", ")", "\n", "\n", "# Wrap multiple optimizers to ease optimizer calls later on", "\n", "self", ".", "schedulers", "=", "MultiWrapper", "(", "\n", "lr_schedule_AdamW", ",", "lr_schedule_Adam", "\n", ")", "\n", "self", ".", "optimizers", "=", "MultiWrapper", "(", "AdamW", ",", "Adam", ")", "\n", "\n", "\n", "", "else", ":", "\n", "# Adam: Optimzer for all parameters", "\n", "            ", "Adam", "=", "torch", ".", "optim", ".", "Adam", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "learning_rate", ",", "\n", "betas", "=", "(", "0.9", ",", "0.999", ")", ",", "\n", "eps", "=", "1e-07", ",", "\n", "amsgrad", "=", "True", ",", "\n", ")", "\n", "lr_schedule_Adam", "=", "LinearWarmupExponentialDecay", "(", "\n", "Adam", ",", "warmup_steps", ",", "decay_steps", ",", "decay_rate", ",", "staircase", "\n", ")", "\n", "\n", "# Also wrap single optimizer for unified interface later", "\n", "self", ".", "schedulers", "=", "MultiWrapper", "(", "lr_schedule_Adam", ")", "\n", "self", ".", "optimizers", "=", "MultiWrapper", "(", "Adam", ")", "\n", "\n", "# Learning rate decay on plateau", "\n", "", "self", ".", "plateau_callback", "=", "ReduceLROnPlateau", "(", "\n", "optimizer", "=", "self", ".", "optimizers", ",", "\n", "scheduler", "=", "self", ".", "schedulers", ",", "\n", "factor", "=", "decay_factor", ",", "\n", "patience", "=", "decay_patience", ",", "\n", "cooldown", "=", "decay_cooldown", ",", "\n", "verbose", "=", "True", ",", "\n", ")", "\n", "\n", "if", "self", ".", "agc", ":", "\n", "# adaptive gradient clipping should not modify the last layer (see paper)", "\n", "            ", "self", ".", "params_except_last", "=", "[", "]", "\n", "for", "name", ",", "param", "in", "self", ".", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "param", ".", "requires_grad", ":", "\n", "                    ", "if", "\"out_energy\"", "in", "name", ":", "\n", "                        ", "self", ".", "params_except_last", "+=", "[", "param", "]", "\n", "", "if", "\"out_forces\"", "in", "name", ":", "\n", "                        ", "self", ".", "params_except_last", "+=", "[", "param", "]", "\n", "\n", "", "", "", "", "self", ".", "exp_decay", "=", "ExponentialMovingAverage", "(", "\n", "[", "p", "for", "p", "in", "self", ".", "model", ".", "parameters", "(", ")", "if", "p", ".", "requires_grad", "]", ",", "self", ".", "ema_decay", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.save_variable_backups": [[204, 206], ["trainer.Trainer.exp_decay.store"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.ema_decay.ExponentialMovingAverage.store"], ["", "def", "save_variable_backups", "(", "self", ")", ":", "\n", "        ", "self", ".", "exp_decay", ".", "store", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.load_averaged_variables": [[207, 209], ["trainer.Trainer.exp_decay.copy_to"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.ema_decay.ExponentialMovingAverage.copy_to"], ["", "def", "load_averaged_variables", "(", "self", ")", ":", "\n", "        ", "self", ".", "exp_decay", ".", "copy_to", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.restore_variable_backups": [[210, 212], ["trainer.Trainer.exp_decay.restore"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.restore"], ["", "def", "restore_variable_backups", "(", "self", ")", ":", "\n", "        ", "self", ".", "exp_decay", ".", "restore", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.decay_maybe": [[213, 215], ["trainer.Trainer.plateau_callback.step"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.step"], ["", "def", "decay_maybe", "(", "self", ",", "val_loss", ")", ":", "\n", "        ", "self", ".", "plateau_callback", ".", "step", "(", "val_loss", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer._unitwise_norm": [[216, 224], ["x.norm", "x.norm", "tuple", "range"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_unitwise_norm", "(", "x", ",", "norm_type", "=", "2.0", ")", ":", "\n", "        ", "if", "x", ".", "ndim", "<=", "1", ":", "\n", "            ", "return", "x", ".", "norm", "(", "norm_type", ")", "\n", "", "else", ":", "\n", "# works for nn.ConvNd and nn,Linear where output dim is first in the kernel/weight tensor", "\n", "# might need special cases for other weights (possibly MHA) where this may not be true", "\n", "            ", "return", "x", ".", "norm", "(", "norm_type", ",", "dim", "=", "tuple", "(", "range", "(", "1", ",", "x", ".", "ndim", ")", ")", ",", "keepdim", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer._adaptive_gradient_clipping": [[225, 249], ["torch.no_grad", "isinstance", "Trainer._unitwise_norm().clamp_().mul_", "trainer.Trainer._unitwise_norm", "torch.where", "p.grad.copy_", "Trainer._unitwise_norm().clamp_", "trainer.Trainer._unitwise_norm", "trainer.Trainer._unitwise_norm"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer._unitwise_norm", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer._unitwise_norm", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer._unitwise_norm"], ["", "", "@", "staticmethod", "\n", "def", "_adaptive_gradient_clipping", "(", "parameters", ",", "clip_factor", "=", "0.05", ",", "eps", "=", "1e-3", ",", "norm_type", "=", "2.0", ")", ":", "\n", "        ", "\"\"\"\n        https://github.com/rwightman/pytorch-image-models/blob/master/timm/utils/agc.py\n\n        Adapted from High-Performance Large-Scale Image Recognition Without Normalization:\n        https://github.com/deepmind/deepmind-research/blob/master/nfnets/optim.py\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "parameters", ",", "torch", ".", "Tensor", ")", ":", "\n", "                ", "parameters", "=", "[", "parameters", "]", "\n", "", "for", "p", "in", "parameters", ":", "\n", "                ", "if", "p", ".", "grad", "is", "None", ":", "\n", "                    ", "continue", "\n", "", "p_data", "=", "p", "\n", "g_data", "=", "p", ".", "grad", "\n", "max_norm", "=", "(", "\n", "Trainer", ".", "_unitwise_norm", "(", "p_data", ",", "norm_type", "=", "norm_type", ")", "\n", ".", "clamp_", "(", "min", "=", "eps", ")", "\n", ".", "mul_", "(", "clip_factor", ")", "\n", ")", "\n", "grad_norm", "=", "Trainer", ".", "_unitwise_norm", "(", "g_data", ",", "norm_type", "=", "norm_type", ")", "\n", "clipped_grad", "=", "g_data", "*", "(", "max_norm", "/", "grad_norm", ".", "clamp", "(", "min", "=", "1e-6", ")", ")", "\n", "new_grads", "=", "torch", ".", "where", "(", "grad_norm", "<", "max_norm", ",", "g_data", ",", "clipped_grad", ")", "\n", "p", ".", "grad", ".", "copy_", "(", "new_grads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.scale_shared_grads": [[250, 279], ["torch.no_grad", "trainer.Trainer.scale_shared_grads.scale_grad"], "methods", ["None"], ["", "", "", "def", "scale_shared_grads", "(", "self", ")", ":", "\n", "        ", "\"\"\"Divide the gradients of the layers that are shared across multiple blocks\n        by the number the weights are shared for\n        \"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "\n", "            ", "def", "scale_grad", "(", "param", ",", "scale_factor", ")", ":", "\n", "                ", "if", "param", ".", "grad", "is", "None", ":", "\n", "                    ", "return", "\n", "", "g_data", "=", "param", ".", "grad", "\n", "new_grads", "=", "g_data", "/", "scale_factor", "\n", "param", ".", "grad", ".", "copy_", "(", "new_grads", ")", "\n", "\n", "", "shared_int_layers", "=", "[", "\n", "self", ".", "model", ".", "mlp_rbf3", ",", "\n", "self", ".", "model", ".", "mlp_cbf3", ",", "\n", "self", ".", "model", ".", "mlp_rbf_h", ",", "\n", "]", "\n", "if", "not", "self", ".", "model", ".", "triplets_only", ":", "\n", "                ", "shared_int_layers", "+=", "[", "\n", "self", ".", "model", ".", "mlp_rbf4", ",", "\n", "self", ".", "model", ".", "mlp_cbf4", ",", "\n", "self", ".", "model", ".", "mlp_sbf4", ",", "\n", "]", "\n", "\n", "", "for", "layer", "in", "shared_int_layers", ":", "\n", "                ", "scale_grad", "(", "layer", ".", "weight", ",", "self", ".", "model", ".", "num_blocks", ")", "\n", "# output block is shared for +1 blocks", "\n", "", "scale_grad", "(", "self", ".", "model", ".", "mlp_rbf_out", ".", "weight", ",", "self", ".", "model", ".", "num_blocks", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.get_mae": [[280, 285], ["torch.nn.functional.l1_loss"], "methods", ["None"], ["", "", "def", "get_mae", "(", "self", ",", "targets", ",", "pred", ")", ":", "\n", "        ", "\"\"\"\n        Mean Absolute Error\n        \"\"\"", "\n", "return", "torch", ".", "nn", ".", "functional", ".", "l1_loss", "(", "pred", ",", "targets", ",", "reduction", "=", "\"mean\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.get_rmse": [[286, 291], ["torch.mean", "torch.norm"], "methods", ["None"], ["", "def", "get_rmse", "(", "self", ",", "targets", ",", "pred", ")", ":", "\n", "        ", "\"\"\"\n        Mean L2 Error\n        \"\"\"", "\n", "return", "torch", ".", "mean", "(", "torch", ".", "norm", "(", "(", "pred", "-", "targets", ")", ",", "p", "=", "2", ",", "dim", "=", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.get_nll": [[292, 295], ["torch.nn.functional.gaussian_nll_loss"], "methods", ["None"], ["", "def", "get_nll", "(", "self", ",", "targets", ",", "mean_pred", ",", "var_pred", ")", ":", "\n", "        ", "return", "torch", ".", "nn", ".", "functional", ".", "gaussian_nll_loss", "(", "\n", "mean_pred", ",", "targets", ",", "var_pred", ",", "reduction", "=", "\"mean\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.predict": [[297, 311], ["trainer.Trainer.model", "torch.nn.functional.softplus", "torch.nn.functional.softplus", "len"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "inputs", ")", ":", "\n", "\n", "        ", "energy", ",", "forces", "=", "self", ".", "model", "(", "inputs", ")", "\n", "\n", "if", "self", ".", "mve", ":", "\n", "            ", "mean_energy", "=", "energy", "[", ":", ",", ":", "1", "]", "\n", "var_energy", "=", "torch", ".", "nn", ".", "functional", ".", "softplus", "(", "energy", "[", ":", ",", "1", ":", "]", ")", "\n", "mean_forces", "=", "forces", "[", ":", ",", "0", ",", ":", "]", "\n", "var_forces", "=", "torch", ".", "nn", ".", "functional", ".", "softplus", "(", "forces", "[", ":", ",", "1", ",", ":", "]", ")", "\n", "return", "mean_energy", ",", "var_energy", ",", "mean_forces", ",", "var_forces", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "forces", ".", "shape", ")", "==", "3", ":", "\n", "                ", "forces", "=", "forces", "[", ":", ",", "0", "]", "\n", "", "return", "energy", ",", "None", ",", "forces", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.dict2device": [[312, 319], ["torch.device", "data[].to", "torch.cuda.is_available"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.None.ase_calculator.Molecule.to"], ["", "", "@", "staticmethod", "\n", "def", "dict2device", "(", "data", ",", "device", "=", "None", ")", ":", "\n", "        ", "if", "device", "is", "None", ":", "\n", "            ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "\"cpu\"", ")", "\n", "", "for", "key", "in", "data", ":", "\n", "            ", "data", "[", "key", "]", "=", "data", "[", "key", "]", ".", "to", "(", "device", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.predict_on_batch": [[320, 324], ["next", "trainer.Trainer.dict2device", "trainer.Trainer.predict"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.dict2device", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.predict"], ["", "def", "predict_on_batch", "(", "self", ",", "dataset_iter", ")", ":", "\n", "        ", "inputs", ",", "_", "=", "next", "(", "dataset_iter", ")", "\n", "inputs", "=", "self", ".", "dict2device", "(", "inputs", ")", "\n", "return", "self", ".", "predict", "(", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.train_on_batch": [[325, 410], ["trainer.Trainer.model.train", "next", "trainer.Trainer.predict", "trainer.Trainer.optimizers.zero_grad", "loss.detach.detach.backward", "trainer.Trainer.scale_shared_grads", "trainer.Trainer.optimizers.step", "trainer.Trainer.schedulers.step", "trainer.Trainer.exp_decay.update", "loss.detach.detach.detach", "trainer.Trainer.dict2device", "trainer.Trainer.dict2device", "trainer.Trainer.get_nll", "trainer.Trainer.get_nll", "trainer.Trainer.get_mae", "trainer.Trainer._adaptive_gradient_clipping", "torch.nn.utils.clip_grad_norm_", "torch.no_grad", "trainer.Trainer.get_mae", "trainer.Trainer.get_rmse", "trainer.Trainer.model.parameters", "trainer.Trainer.get_mae", "trainer.Trainer.get_mae", "trainer.Trainer.get_rmse", "metrics.update_state", "metrics.update_state", "metrics.update_state", "metrics.update_state", "trainer.Trainer.get_rmse", "trainer.Trainer.get_mae"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.predict", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.zero_grad", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.scale_shared_grads", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.step", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.step", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.update", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.dict2device", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.dict2device", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.get_nll", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.get_nll", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.get_mae", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer._adaptive_gradient_clipping", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.get_mae", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.get_rmse", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.get_mae", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.get_mae", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.get_rmse", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.update_state", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.update_state", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.update_state", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.update_state", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.get_rmse", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.get_mae"], ["", "def", "train_on_batch", "(", "self", ",", "dataset_iter", ",", "metrics", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "inputs", ",", "targets", "=", "next", "(", "dataset_iter", ")", "\n", "# push to GPU if available", "\n", "inputs", ",", "targets", "=", "self", ".", "dict2device", "(", "inputs", ")", ",", "self", ".", "dict2device", "(", "targets", ")", "\n", "\n", "mean_energy", ",", "var_energy", ",", "mean_forces", ",", "var_forces", "=", "self", ".", "predict", "(", "inputs", ")", "\n", "\n", "if", "self", ".", "mve", ":", "\n", "            ", "energy_nll", "=", "self", ".", "get_nll", "(", "targets", "[", "\"E\"", "]", ",", "mean_energy", ",", "var_energy", ")", "\n", "force_nll", "=", "self", ".", "get_nll", "(", "targets", "[", "\"F\"", "]", ",", "mean_forces", ",", "var_forces", ")", "\n", "loss", "=", "energy_nll", "*", "(", "1", "-", "self", ".", "rho_force", ")", "+", "self", ".", "rho_force", "*", "force_nll", "\n", "", "else", ":", "\n", "            ", "energy_mae", "=", "self", ".", "get_mae", "(", "targets", "[", "\"E\"", "]", ",", "mean_energy", ")", "\n", "if", "self", ".", "loss", "==", "\"mae\"", ":", "\n", "                ", "force_metric", "=", "self", ".", "get_mae", "(", "targets", "[", "\"F\"", "]", ",", "mean_forces", ")", "\n", "", "else", ":", "\n", "                ", "force_metric", "=", "self", ".", "get_rmse", "(", "targets", "[", "\"F\"", "]", ",", "mean_forces", ")", "\n", "", "loss", "=", "energy_mae", "*", "(", "1", "-", "self", ".", "rho_force", ")", "+", "self", ".", "rho_force", "*", "force_metric", "\n", "\n", "", "self", ".", "optimizers", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "self", ".", "scale_shared_grads", "(", ")", "\n", "\n", "if", "self", ".", "agc", ":", "\n", "            ", "self", ".", "_adaptive_gradient_clipping", "(", "\n", "self", ".", "params_except_last", ",", "clip_factor", "=", "self", ".", "grad_clip_max", "\n", ")", "\n", "", "else", ":", "\n", "            ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "self", ".", "model", ".", "parameters", "(", ")", ",", "max_norm", "=", "self", ".", "grad_clip_max", "\n", ")", "\n", "\n", "", "self", ".", "optimizers", ".", "step", "(", ")", "\n", "self", ".", "schedulers", ".", "step", "(", ")", "\n", "self", ".", "exp_decay", ".", "update", "(", ")", "\n", "\n", "# no gradients needed anymore", "\n", "loss", "=", "loss", ".", "detach", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "if", "self", ".", "mve", ":", "\n", "                ", "energy_mae", "=", "self", ".", "get_mae", "(", "targets", "[", "\"E\"", "]", ",", "mean_energy", ")", "\n", "force_mae", "=", "self", ".", "get_mae", "(", "targets", "[", "\"F\"", "]", ",", "mean_forces", ")", "\n", "force_rmse", "=", "self", ".", "get_rmse", "(", "targets", "[", "\"F\"", "]", ",", "mean_forces", ")", "\n", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "loss", "==", "\"mae\"", ":", "\n", "                    ", "force_mae", "=", "force_metric", "\n", "force_rmse", "=", "self", ".", "get_rmse", "(", "targets", "[", "\"F\"", "]", ",", "mean_forces", ")", "\n", "", "else", ":", "\n", "                    ", "force_mae", "=", "self", ".", "get_mae", "(", "targets", "[", "\"F\"", "]", ",", "mean_forces", ")", "\n", "force_rmse", "=", "force_metric", "\n", "\n", "", "", "if", "self", ".", "mve", ":", "\n", "# update molecule metrics", "\n", "                ", "metrics", ".", "update_state", "(", "\n", "nsamples", "=", "mean_energy", ".", "shape", "[", "0", "]", ",", "\n", "loss", "=", "loss", ",", "\n", "energy_mae", "=", "energy_mae", ",", "\n", "energy_nll", "=", "energy_nll", ",", "\n", "energy_var", "=", "var_energy", ",", "\n", ")", "\n", "# update atom metrics", "\n", "metrics", ".", "update_state", "(", "\n", "nsamples", "=", "mean_forces", ".", "shape", "[", "0", "]", ",", "\n", "force_mae", "=", "force_mae", ",", "\n", "force_rmse", "=", "force_rmse", ",", "\n", "force_nll", "=", "force_nll", ",", "\n", "force_var", "=", "var_forces", ",", "\n", ")", "\n", "", "else", ":", "\n", "# update molecule metrics", "\n", "                ", "metrics", ".", "update_state", "(", "\n", "nsamples", "=", "mean_energy", ".", "shape", "[", "0", "]", ",", "\n", "loss", "=", "loss", ",", "\n", "energy_mae", "=", "energy_mae", ",", "\n", ")", "\n", "# update atom metrics", "\n", "metrics", ".", "update_state", "(", "\n", "nsamples", "=", "mean_forces", ".", "shape", "[", "0", "]", ",", "\n", "force_mae", "=", "force_mae", ",", "\n", "force_rmse", "=", "force_rmse", ",", "\n", ")", "\n", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.test_on_batch": [[411, 471], ["trainer.Trainer.model.eval", "next", "trainer.Trainer.dict2device", "trainer.Trainer.dict2device", "trainer.Trainer.predict", "torch.no_grad", "trainer.Trainer.get_mae", "trainer.Trainer.get_mae", "trainer.Trainer.get_rmse", "torch.no_grad", "trainer.Trainer.predict", "trainer.Trainer.get_nll", "trainer.Trainer.get_nll", "metrics.update_state", "metrics.update_state", "metrics.update_state", "metrics.update_state"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.dict2device", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.dict2device", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.predict", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.get_mae", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.get_mae", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.get_rmse", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.predict", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.get_nll", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.get_nll", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.update_state", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.update_state", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.update_state", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.Metrics.update_state"], ["", "def", "test_on_batch", "(", "self", ",", "dataset_iter", ",", "metrics", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "inputs", ",", "targets", "=", "next", "(", "dataset_iter", ")", "\n", "# push to GPU if available", "\n", "inputs", ",", "targets", "=", "self", ".", "dict2device", "(", "inputs", ")", ",", "self", ".", "dict2device", "(", "targets", ")", "\n", "\n", "if", "self", ".", "model", ".", "direct_forces", ":", "\n", "# do not need any gradients -> reduce memory consumption", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "mean_energy", ",", "var_energy", ",", "mean_forces", ",", "var_forces", "=", "self", ".", "predict", "(", "inputs", ")", "\n", "", "", "else", ":", "\n", "# need gradient for forces", "\n", "            ", "mean_energy", ",", "var_energy", ",", "mean_forces", ",", "var_forces", "=", "self", ".", "predict", "(", "inputs", ")", "\n", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "energy_mae", "=", "self", ".", "get_mae", "(", "targets", "[", "\"E\"", "]", ",", "mean_energy", ")", "\n", "force_mae", "=", "self", ".", "get_mae", "(", "targets", "[", "\"F\"", "]", ",", "mean_forces", ")", "\n", "force_rmse", "=", "self", ".", "get_rmse", "(", "targets", "[", "\"F\"", "]", ",", "mean_forces", ")", "\n", "\n", "if", "self", ".", "mve", ":", "\n", "                ", "energy_nll", "=", "self", ".", "get_nll", "(", "targets", "[", "\"E\"", "]", ",", "mean_energy", ",", "var_energy", ")", "\n", "loss", "=", "energy_nll", "*", "(", "1", "-", "self", ".", "rho_force", ")", "+", "self", ".", "rho_force", "*", "force_mae", "\n", "force_nll", "=", "self", ".", "get_nll", "(", "targets", "[", "\"F\"", "]", ",", "mean_forces", ",", "var_forces", ")", "\n", "loss", "=", "energy_nll", "*", "(", "1", "-", "self", ".", "rho_force", ")", "+", "self", ".", "rho_force", "*", "force_nll", "\n", "\n", "# update molecule metrics", "\n", "metrics", ".", "update_state", "(", "\n", "nsamples", "=", "mean_energy", ".", "shape", "[", "0", "]", ",", "\n", "loss", "=", "loss", ",", "\n", "energy_mae", "=", "energy_mae", ",", "\n", "energy_nll", "=", "energy_nll", ",", "\n", "energy_var", "=", "var_energy", ",", "\n", ")", "\n", "# update atom metrics", "\n", "metrics", ".", "update_state", "(", "\n", "nsamples", "=", "mean_forces", ".", "shape", "[", "0", "]", ",", "\n", "force_mae", "=", "force_mae", ",", "\n", "force_rmse", "=", "force_rmse", ",", "\n", "force_nll", "=", "force_nll", ",", "\n", "force_var", "=", "var_forces", ",", "\n", ")", "\n", "\n", "", "else", ":", "\n", "                ", "force_metric", "=", "force_mae", "if", "self", ".", "loss", "==", "\"mae\"", "else", "force_rmse", "\n", "loss", "=", "(", "1", "-", "self", ".", "rho_force", ")", "*", "energy_mae", "+", "self", ".", "rho_force", "*", "force_metric", "\n", "\n", "# update molecule metrics", "\n", "metrics", ".", "update_state", "(", "\n", "nsamples", "=", "mean_energy", ".", "shape", "[", "0", "]", ",", "\n", "loss", "=", "loss", ",", "\n", "energy_mae", "=", "energy_mae", ",", "\n", ")", "\n", "# update atom metrics", "\n", "metrics", ".", "update_state", "(", "\n", "nsamples", "=", "mean_forces", ".", "shape", "[", "0", "]", ",", "\n", "force_mae", "=", "force_mae", ",", "\n", "force_rmse", "=", "force_rmse", ",", "\n", ")", "\n", "\n", "", "", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.eval_on_batch": [[472, 480], ["trainer.Trainer.model.eval", "torch.no_grad", "next", "trainer.Trainer.predict", "trainer.Trainer.dict2device", "trainer.Trainer.dict2device"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.predict", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.dict2device", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.dict2device"], ["", "def", "eval_on_batch", "(", "self", ",", "dataset_iter", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", ",", "targets", "=", "next", "(", "dataset_iter", ")", "\n", "# push to GPU if available", "\n", "inputs", ",", "targets", "=", "self", ".", "dict2device", "(", "inputs", ")", ",", "self", ".", "dict2device", "(", "targets", ")", "\n", "energy", ",", "_", ",", "forces", ",", "_", "=", "self", ".", "predict", "(", "inputs", ")", "\n", "", "return", "(", "energy", ",", "forces", ")", ",", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.state_dict": [[481, 498], ["state_dict.update", "trainer.Trainer.__dict__.items", "getattr().state_dict", "getattr"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.update", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.items", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.state_dict"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the state of the trainer and all subinstancces except the model.\"\"\"", "\n", "state_dict", "=", "{", "\n", "key", ":", "value", "\n", "for", "key", ",", "value", "in", "self", ".", "__dict__", ".", "items", "(", ")", "\n", "if", "key", "\n", "not", "in", "[", "\n", "\"model\"", ",", "\n", "\"schedulers\"", ",", "\n", "\"optimizers\"", ",", "\n", "\"plateau_callback\"", ",", "\n", "\"exp_decay\"", ",", "\n", "]", "\n", "}", "\n", "for", "attr", "in", "[", "\"schedulers\"", ",", "\"optimizers\"", ",", "\"plateau_callback\"", ",", "\"exp_decay\"", "]", ":", "\n", "            ", "state_dict", ".", "update", "(", "{", "attr", ":", "getattr", "(", "self", ",", "attr", ")", ".", "state_dict", "(", ")", "}", ")", "\n", "", "return", "state_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.Trainer.load_state_dict": [[499, 521], ["trainer.Trainer.__dict__.update", "getattr().load_state_dict", "trainer.Trainer.state_dict.items", "getattr"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.update", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.load_state_dict", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.items"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Loads the schedulers state.\n\n        Args:\n            state_dict (dict): scheduler state. Should be an object returned\n                from a call to :meth:`state_dict`.\n        \"\"\"", "\n", "trainer_dict", "=", "{", "\n", "key", ":", "value", "\n", "for", "key", ",", "value", "in", "self", ".", "state_dict", ".", "items", "(", ")", "\n", "if", "key", "\n", "not", "in", "[", "\n", "\"model\"", ",", "\n", "\"schedulers\"", ",", "\n", "\"optimizers\"", ",", "\n", "\"plateau_callback\"", ",", "\n", "\"exp_decay\"", ",", "\n", "]", "\n", "}", "\n", "self", ".", "__dict__", ".", "update", "(", "trainer_dict", ")", "\n", "for", "attr", "in", "[", "\"schedulers\"", ",", "\"optimizers\"", ",", "\"plateau_callback\"", ",", "\"exp_decay\"", "]", ":", "\n", "            ", "getattr", "(", "self", ",", "attr", ")", ".", "load_state_dict", "(", "state_dict", "[", "attr", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.ReduceLROnPlateau.__init__": [[575, 631], ["isinstance", "isinstance", "trainer.ReduceLROnPlateau._init_is_better", "trainer.ReduceLROnPlateau._reset", "ValueError", "isinstance", "isinstance", "len", "len", "isinstance", "TypeError", "type", "type"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.ReduceLROnPlateau._init_is_better", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.ReduceLROnPlateau._reset"], ["def", "__init__", "(", "\n", "self", ",", "\n", "optimizer", ",", "\n", "scheduler", ",", "\n", "factor", "=", "0.1", ",", "\n", "patience", "=", "10", ",", "\n", "threshold", "=", "1e-4", ",", "\n", "max_reduce", "=", "10", ",", "\n", "cooldown", "=", "0", ",", "\n", "threshold_mode", "=", "\"rel\"", ",", "\n", "min_lr", "=", "0", ",", "\n", "eps", "=", "1e-8", ",", "\n", "mode", "=", "\"min\"", ",", "\n", "verbose", "=", "False", ",", "\n", ")", ":", "\n", "\n", "        ", "if", "factor", ">=", "1.0", ":", "\n", "            ", "raise", "ValueError", "(", "f\"Factor should be < 1.0 but is {factor}.\"", ")", "\n", "", "self", ".", "factor", "=", "factor", "\n", "self", ".", "optimizer", "=", "optimizer", "\n", "self", ".", "scheduler", "=", "scheduler", "\n", "\n", "if", "isinstance", "(", "optimizer", ",", "MultiWrapper", ")", ":", "\n", "            ", "self", ".", "optimizer", "=", "optimizer", ".", "wrapped", "\n", "", "if", "isinstance", "(", "scheduler", ",", "MultiWrapper", ")", ":", "\n", "            ", "self", ".", "scheduler", "=", "scheduler", ".", "wrapped", "\n", "\n", "", "if", "not", "isinstance", "(", "self", ".", "optimizer", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "self", ".", "optimizer", "=", "[", "self", ".", "optimizer", "]", "\n", "", "if", "not", "isinstance", "(", "self", ".", "scheduler", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "            ", "self", ".", "scheduler", "=", "[", "self", ".", "scheduler", "]", "\n", "\n", "", "assert", "len", "(", "self", ".", "optimizer", ")", "==", "len", "(", "self", ".", "scheduler", ")", "\n", "\n", "for", "opt", "in", "self", ".", "optimizer", ":", "\n", "# Attach optimizer", "\n", "            ", "if", "not", "isinstance", "(", "opt", ",", "torch", ".", "optim", ".", "Optimizer", ")", ":", "\n", "                ", "raise", "TypeError", "(", "f\"{type(opt).__name__} is not an Optimizer but is of type {type(opt)}\"", ")", "\n", "\n", "", "", "self", ".", "patience", "=", "patience", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "cooldown", "=", "cooldown", "\n", "self", ".", "cooldown_counter", "=", "0", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "threshold", "=", "threshold", "\n", "self", ".", "threshold_mode", "=", "threshold_mode", "\n", "self", ".", "best", "=", "None", "\n", "self", ".", "num_bad_steps", "=", "None", "\n", "self", ".", "mode_worse", "=", "None", "# the worse value for the chosen mode", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "last_step", "=", "0", "\n", "self", ".", "_init_is_better", "(", "\n", "mode", "=", "mode", ",", "threshold", "=", "threshold", ",", "threshold_mode", "=", "threshold_mode", "\n", ")", "\n", "self", ".", "_reset", "(", ")", "\n", "self", ".", "_reduce_counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.ReduceLROnPlateau._reset": [[632, 637], ["None"], "methods", ["None"], ["", "def", "_reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Resets num_bad_steps counter and cooldown counter.\"\"\"", "\n", "self", ".", "best", "=", "self", ".", "mode_worse", "\n", "self", ".", "cooldown_counter", "=", "0", "\n", "self", ".", "num_bad_steps", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.ReduceLROnPlateau.step": [[638, 658], ["float", "trainer.ReduceLROnPlateau.is_better", "trainer.ReduceLROnPlateau._reduce"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.ReduceLROnPlateau.is_better", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.ReduceLROnPlateau._reduce"], ["", "def", "step", "(", "self", ",", "metrics", ")", ":", "\n", "# convert `metrics` to float, in case it's a zero-dim Tensor", "\n", "        ", "current", "=", "float", "(", "metrics", ")", "\n", "step", "=", "self", ".", "last_step", "+", "1", "\n", "self", ".", "last_step", "=", "step", "\n", "\n", "if", "self", ".", "is_better", "(", "current", ",", "self", ".", "best", ")", ":", "\n", "            ", "self", ".", "best", "=", "current", "\n", "self", ".", "num_bad_steps", "=", "0", "\n", "", "else", ":", "\n", "            ", "self", ".", "num_bad_steps", "+=", "1", "\n", "\n", "", "if", "self", ".", "in_cooldown", ":", "\n", "            ", "self", ".", "cooldown_counter", "-=", "1", "\n", "self", ".", "num_bad_steps", "=", "0", "# ignore any bad steps in cooldown", "\n", "\n", "", "if", "self", ".", "num_bad_steps", ">", "self", ".", "patience", ":", "\n", "            ", "self", ".", "_reduce", "(", "step", ")", "\n", "self", ".", "cooldown_counter", "=", "self", ".", "cooldown", "\n", "self", ".", "num_bad_steps", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.ReduceLROnPlateau._reduce": [[659, 671], ["zip", "hasattr", "logging.info", "ValueError"], "methods", ["None"], ["", "", "def", "_reduce", "(", "self", ",", "step", ")", ":", "\n", "        ", "self", ".", "_reduce_counter", "+=", "1", "\n", "\n", "for", "optimzer", ",", "schedule", "in", "zip", "(", "self", ".", "optimizer", ",", "self", ".", "scheduler", ")", ":", "\n", "            ", "if", "hasattr", "(", "schedule", ",", "\"base_lrs\"", ")", ":", "\n", "                ", "schedule", ".", "base_lrs", "=", "[", "lr", "*", "self", ".", "factor", "for", "lr", "in", "schedule", ".", "base_lrs", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"Schedule does not have attribute 'base_lrs' for the learning rate.\"", "\n", ")", "\n", "", "", "if", "self", ".", "verbose", ":", "\n", "            ", "logging", ".", "info", "(", "f\"Step {step}: reducing on plateu by {self.factor}.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.ReduceLROnPlateau.in_cooldown": [[672, 675], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "in_cooldown", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cooldown_counter", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.ReduceLROnPlateau.is_better": [[676, 690], ["None"], "methods", ["None"], ["", "def", "is_better", "(", "self", ",", "a", ",", "best", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "\"min\"", "and", "self", ".", "threshold_mode", "==", "\"rel\"", ":", "\n", "            ", "rel_epsilon", "=", "1.0", "-", "self", ".", "threshold", "\n", "return", "a", "<", "best", "*", "rel_epsilon", "\n", "\n", "", "elif", "self", ".", "mode", "==", "\"min\"", "and", "self", ".", "threshold_mode", "==", "\"abs\"", ":", "\n", "            ", "return", "a", "<", "best", "-", "self", ".", "threshold", "\n", "\n", "", "elif", "self", ".", "mode", "==", "\"max\"", "and", "self", ".", "threshold_mode", "==", "\"rel\"", ":", "\n", "            ", "rel_epsilon", "=", "self", ".", "threshold", "+", "1.0", "\n", "return", "a", ">", "best", "*", "rel_epsilon", "\n", "\n", "", "else", ":", "# mode == 'max' and epsilon_mode == 'abs':", "\n", "            ", "return", "a", ">", "best", "+", "self", ".", "threshold", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.ReduceLROnPlateau._init_is_better": [[691, 705], ["ValueError", "ValueError"], "methods", ["None"], ["", "", "def", "_init_is_better", "(", "self", ",", "mode", ",", "threshold", ",", "threshold_mode", ")", ":", "\n", "        ", "if", "mode", "not", "in", "{", "\"min\"", ",", "\"max\"", "}", ":", "\n", "            ", "raise", "ValueError", "(", "\"mode \"", "+", "mode", "+", "\" is unknown!\"", ")", "\n", "", "if", "threshold_mode", "not", "in", "{", "\"rel\"", ",", "\"abs\"", "}", ":", "\n", "            ", "raise", "ValueError", "(", "\"threshold mode \"", "+", "threshold_mode", "+", "\" is unknown!\"", ")", "\n", "\n", "", "if", "mode", "==", "\"min\"", ":", "\n", "            ", "self", ".", "mode_worse", "=", "np", ".", "inf", "\n", "", "else", ":", "# mode == 'max':", "\n", "            ", "self", ".", "mode_worse", "=", "-", "np", ".", "inf", "\n", "\n", "", "self", ".", "mode", "=", "mode", "\n", "self", ".", "threshold", "=", "threshold", "\n", "self", ".", "threshold_mode", "=", "threshold_mode", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.ReduceLROnPlateau.state_dict": [[706, 711], ["trainer.ReduceLROnPlateau.__dict__.items"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.items"], ["", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "return", "{", "\n", "key", ":", "value", "\n", "for", "key", ",", "value", "in", "self", ".", "__dict__", ".", "items", "(", ")", "\n", "if", "key", "not", "in", "[", "\"optimizer\"", ",", "\"scheduler\"", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.ReduceLROnPlateau.load_state_dict": [[713, 717], ["trainer.ReduceLROnPlateau.__dict__.update", "trainer.ReduceLROnPlateau._init_is_better"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.metrics.BestMetrics.update", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.ReduceLROnPlateau._init_is_better"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "self", ".", "__dict__", ".", "update", "(", "state_dict", ")", "\n", "self", ".", "_init_is_better", "(", "\n", "mode", "=", "self", ".", "mode", ",", "threshold", "=", "self", ".", "threshold", ",", "threshold_mode", "=", "self", ".", "threshold_mode", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.__init__": [[721, 723], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "*", "ops", ")", ":", "\n", "        ", "self", ".", "wrapped", "=", "ops", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.__getitem__": [[724, 726], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "wrapped", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.zero_grad": [[727, 730], ["op.zero_grad"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.zero_grad"], ["", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "for", "op", "in", "self", ".", "wrapped", ":", "\n", "            ", "op", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.step": [[731, 734], ["op.step"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.step"], ["", "", "def", "step", "(", "self", ")", ":", "\n", "        ", "for", "op", "in", "self", ".", "wrapped", ":", "\n", "            ", "op", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.state_dict": [[735, 738], ["opt.state_dict", "enumerate"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.state_dict"], ["", "", "def", "state_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the overall state dict of the wrapped instances.\"\"\"", "\n", "return", "{", "i", ":", "opt", ".", "state_dict", "(", ")", "for", "i", ",", "opt", "in", "enumerate", "(", "self", ".", "wrapped", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.load_state_dict": [[739, 745], ["enumerate", "opt.load_state_dict"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.trainer.MultiWrapper.load_state_dict"], ["", "def", "load_state_dict", "(", "self", ",", "state_dict", ")", ":", "\n", "        ", "\"\"\"Load the state_dict for each wrapped instance.\n        Assumes the order is the same as when the state_dict was loaded\n        \"\"\"", "\n", "for", "i", ",", "opt", "in", "enumerate", "(", "self", ".", "wrapped", ")", ":", "\n", "            ", "opt", ".", "load_state_dict", "(", "state_dict", "[", "i", "]", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.__init__": [[52, 81], ["len", "numpy.random.RandomState", "data_provider.DataProvider._random_split_data", "data_provider.DataProvider._manual_split_data"], "methods", ["home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider._random_split_data", "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider._manual_split_data"], ["def", "__init__", "(", "\n", "self", ",", "\n", "data_container", ",", "\n", "ntrain", ":", "int", ",", "\n", "nval", ":", "int", ",", "\n", "batch_size", ":", "int", "=", "1", ",", "\n", "seed", ":", "int", "=", "None", ",", "\n", "random_split", ":", "bool", "=", "False", ",", "\n", "shuffle", ":", "bool", "=", "True", ",", "\n", "sample_with_replacement", ":", "bool", "=", "False", ",", "\n", "split", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "self", ".", "kwargs", "=", "kwargs", "\n", "self", ".", "data_container", "=", "data_container", "\n", "self", ".", "_ndata", "=", "len", "(", "data_container", ")", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "seed", "=", "seed", "\n", "self", ".", "random_split", "=", "random_split", "\n", "self", ".", "shuffle", "=", "shuffle", "\n", "self", ".", "sample_with_replacement", "=", "sample_with_replacement", "\n", "\n", "# Random state parameter, such that random operations are reproducible if wanted", "\n", "self", ".", "_random_state", "=", "np", ".", "random", ".", "RandomState", "(", "seed", "=", "seed", ")", "\n", "\n", "if", "split", "is", "None", ":", "\n", "            ", "self", ".", "nsamples", ",", "self", ".", "idx", "=", "self", ".", "_random_split_data", "(", "ntrain", ",", "nval", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "nsamples", ",", "self", ".", "idx", "=", "self", ".", "_manual_split_data", "(", "split", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider._manual_split_data": [[82, 101], ["isinstance", "isinstance", "TypeError", "numpy.load.endswith", "numpy.load", "numpy.array", "len", "numpy.load.keys", "numpy.load.keys"], "methods", ["None"], ["", "", "def", "_manual_split_data", "(", "self", ",", "split", ")", ":", "\n", "\n", "        ", "if", "isinstance", "(", "split", ",", "(", "dict", ",", "str", ")", ")", ":", "\n", "            ", "if", "isinstance", "(", "split", ",", "str", ")", ":", "\n", "# split is the path to the file containing the indices", "\n", "                ", "assert", "split", ".", "endswith", "(", "\".npz\"", ")", ",", "\"'split' has to be a .npz file if 'split' is of type str\"", "\n", "split", "=", "np", ".", "load", "(", "split", ")", "\n", "\n", "", "keys", "=", "[", "\"train\"", ",", "\"val\"", ",", "\"test\"", "]", "\n", "for", "key", "in", "keys", ":", "\n", "                ", "assert", "key", "in", "split", ".", "keys", "(", ")", ",", "f\"{key} is not in {[k for k in split.keys()]}\"", "\n", "\n", "", "idx", "=", "{", "key", ":", "np", ".", "array", "(", "split", "[", "key", "]", ")", "for", "key", "in", "keys", "}", "\n", "nsamples", "=", "{", "key", ":", "len", "(", "idx", "[", "key", "]", ")", "for", "key", "in", "keys", "}", "\n", "\n", "return", "nsamples", ",", "idx", "\n", "\n", "", "else", ":", "\n", "            ", "raise", "TypeError", "(", "\"'split' has to be either of type str or dict if not None.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider._random_split_data": [[102, 127], ["numpy.arange", "data_provider.DataProvider._random_state.permutation", "data_provider.DataProvider._random_state.choice"], "methods", ["None"], ["", "", "def", "_random_split_data", "(", "self", ",", "ntrain", ",", "nval", ")", ":", "\n", "\n", "        ", "nsamples", "=", "{", "\n", "\"train\"", ":", "ntrain", ",", "\n", "\"val\"", ":", "nval", ",", "\n", "\"test\"", ":", "self", ".", "_ndata", "-", "ntrain", "-", "nval", ",", "\n", "}", "\n", "\n", "all_idx", "=", "np", ".", "arange", "(", "self", ".", "_ndata", ")", "\n", "if", "self", ".", "random_split", ":", "\n", "# Shuffle indices", "\n", "            ", "all_idx", "=", "self", ".", "_random_state", ".", "permutation", "(", "all_idx", ")", "\n", "\n", "", "if", "self", ".", "sample_with_replacement", ":", "\n", "# Sample with replacement so as to train an ensemble of Dimenets", "\n", "            ", "all_idx", "=", "self", ".", "_random_state", ".", "choice", "(", "all_idx", ",", "self", ".", "_ndata", ",", "replace", "=", "True", ")", "\n", "\n", "# Store indices of training, validation and test data", "\n", "", "idx", "=", "{", "\n", "\"train\"", ":", "all_idx", "[", "0", ":", "ntrain", "]", ",", "\n", "\"val\"", ":", "all_idx", "[", "ntrain", ":", "ntrain", "+", "nval", "]", ",", "\n", "\"test\"", ":", "all_idx", "[", "ntrain", "+", "nval", ":", "]", ",", "\n", "}", "\n", "\n", "return", "nsamples", ",", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.save_split": [[128, 136], ["isinstance", "path.endswith", "numpy.savez"], "methods", ["None"], ["", "def", "save_split", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"\n        Save the split of the samples to path.\n        Data has keys 'train', 'val', 'test'.\n        \"\"\"", "\n", "assert", "isinstance", "(", "path", ",", "str", ")", "\n", "assert", "path", ".", "endswith", "(", "\".npz\"", ")", ",", "\"'path' has to end with .npz\"", "\n", "np", ".", "savez", "(", "path", ",", "**", "self", ".", "idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.DataProvider.get_dataset": [[137, 175], ["torch.utils.data.sampler.BatchSampler", "torch.utils.data.DataLoader", "data_provider.DataProvider.get_dataset.generator"], "methods", ["None"], ["", "def", "get_dataset", "(", "self", ",", "split", ",", "batch_size", "=", "None", ")", ":", "\n", "        ", "assert", "split", "in", "self", ".", "idx", "\n", "if", "batch_size", "is", "None", ":", "\n", "            ", "batch_size", "=", "self", ".", "batch_size", "\n", "", "shuffle", "=", "self", ".", "shuffle", "if", "split", "==", "\"train\"", "else", "False", "\n", "\n", "indices", "=", "self", ".", "idx", "[", "split", "]", "\n", "if", "shuffle", ":", "\n", "            ", "torch_generator", "=", "torch", ".", "Generator", "(", ")", "\n", "if", "self", ".", "seed", "is", "not", "None", ":", "\n", "                ", "torch_generator", ".", "manual_seed", "(", "self", ".", "seed", ")", "\n", "", "idx_sampler", "=", "SubsetRandomSampler", "(", "indices", ",", "torch_generator", ")", "\n", "dataset", "=", "self", ".", "data_container", "\n", "", "else", ":", "\n", "            ", "subset", "=", "Subset", "(", "self", ".", "data_container", ",", "indices", ")", "\n", "idx_sampler", "=", "SequentialSampler", "(", "subset", ")", "\n", "dataset", "=", "subset", "\n", "\n", "", "batch_sampler", "=", "BatchSampler", "(", "\n", "idx_sampler", ",", "batch_size", "=", "batch_size", ",", "drop_last", "=", "False", "\n", ")", "\n", "\n", "dataloader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "sampler", "=", "batch_sampler", ",", "\n", "collate_fn", "=", "functools", ".", "partial", "(", "collate", ",", "target_keys", "=", "self", ".", "data_container", ".", "targets", ")", ",", "\n", "pin_memory", "=", "True", ",", "# load on CPU push to GPU", "\n", "**", "self", ".", "kwargs", "\n", ")", "\n", "\n", "# loop infinitely", "\n", "# we use the generator as the rest of the code is based on steps and not epochs", "\n", "def", "generator", "(", ")", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "for", "inputs", ",", "targets", "in", "dataloader", ":", "\n", "                    ", "yield", "inputs", ",", "targets", "\n", "\n", "", "", "", "return", "generator", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.TUM-DAML_gemnet_pytorch.training.data_provider.collate": [[11, 24], ["None"], "function", ["None"], ["def", "collate", "(", "batch", ",", "target_keys", ")", ":", "\n", "    ", "\"\"\"\n    custom batching function because batches have variable shape\n    \"\"\"", "\n", "batch", "=", "batch", "[", "0", "]", "# already batched: Batching happens in DataContainer", "\n", "inputs", "=", "{", "}", "\n", "targets", "=", "{", "}", "\n", "for", "key", "in", "batch", ":", "\n", "        ", "if", "key", "in", "target_keys", ":", "\n", "            ", "targets", "[", "key", "]", "=", "batch", "[", "key", "]", "\n", "", "else", ":", "\n", "            ", "inputs", "[", "key", "]", "=", "batch", "[", "key", "]", "\n", "", "", "return", "inputs", ",", "targets", "\n", "\n"]]}